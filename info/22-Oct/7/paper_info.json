[
  {
    "id": "arXiv:2210.02447",
    "title": "Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting  Models",
    "abstract": "Machine learning based traffic forecasting models leverage sophisticated\nspatiotemporal auto-correlations to provide accurate predictions of city-wide\ntraffic states. However, existing methods assume a reliable and unbiased\nforecasting environment, which is not always available in the wild. In this\nwork, we investigate the vulnerability of spatiotemporal traffic forecasting\nmodels and propose a practical adversarial spatiotemporal attack framework.\nSpecifically, instead of simultaneously attacking all geo-distributed data\nsources, an iterative gradient-guided node saliency method is proposed to\nidentify the time-dependent set of victim nodes. Furthermore, we devise a\nspatiotemporal gradient descent based scheme to generate real-valued\nadversarial traffic states under a perturbation constraint. Meanwhile, we\ntheoretically demonstrate the worst performance bound of adversarial traffic\nforecasting attacks. Extensive experiments on two real-world datasets show that\nthe proposed two-step framework achieves up to $67.8\\%$ performance degradation\non various advanced spatiotemporal forecasting models. Remarkably, we also show\nthat adversarial training with our proposed attacks can significantly improve\nthe robustness of spatiotemporal traffic forecasting models. Our code is\navailable in \\url{https://github.com/luckyfan-cs/ASTFA}.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Fan Liu",
      "Hao Liu",
      "Wenzhao Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02447"
  },
  {
    "id": "arXiv:2210.02448",
    "title": "TgDLF2.0: Theory-guided deep-learning for electrical load forecasting  via Transformer and transfer learning",
    "abstract": "Electrical energy is essential in today's society. Accurate electrical load\nforecasting is beneficial for better scheduling of electricity generation and\nsaving electrical energy. In this paper, we propose theory-guided deep-learning\nload forecasting 2.0 (TgDLF2.0) to solve this issue, which is an improved\nversion of the theory-guided deep-learning framework for load forecasting via\nensemble long short-term memory (TgDLF). TgDLF2.0 introduces the deep-learning\nmodel Transformer and transfer learning on the basis of dividing the electrical\nload into dimensionless trends and local fluctuations, which realizes the\nutilization of domain knowledge, captures the long-term dependency of the load\nseries, and is more appropriate for realistic scenarios with scarce samples.\nCross-validation experiments on different districts show that TgDLF2.0 is\napproximately 16% more accurate than TgDLF and saves more than half of the\ntraining time. TgDLF2.0 with 50% weather noise has the same accuracy as TgDLF\nwithout noise, which proves its robustness. We also preliminarily mine the\ninterpretability of Transformer in TgDLF2.0, which may provide future potential\nfor better theory guidance. Furthermore, experiments demonstrate that transfer\nlearning can accelerate convergence of the model in half the number of training\nepochs and achieve better performance.",
    "descriptor": "",
    "authors": [
      "Jiaxin Gao",
      "Wenbo Hu",
      "Dongxiao Zhang",
      "Yuntian Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02448"
  },
  {
    "id": "arXiv:2210.02449",
    "title": "DEGAN: Time Series Anomaly Detection using Generative Adversarial  Network Discriminators and Density Estimation",
    "abstract": "Developing efficient time series anomaly detection techniques is important to\nmaintain service quality and provide early alarms. Generative neural network\nmethods are one class of the unsupervised approaches that are achieving\nincreasing attention in recent years. In this paper, we have proposed an\nunsupervised Generative Adversarial Network (GAN)-based anomaly detection\nframework, DEGAN. It relies solely on normal time series data as input to train\na well-configured discriminator (D) into a standalone anomaly predictor. In\nthis framework, time series data is processed by the sliding window method.\nExpected normal patterns in data are leveraged to develop a generator (G)\ncapable of generating normal data patterns. Normal data is also utilized in\nhyperparameter tuning and D model selection steps. Validated D models are then\nextracted and applied to evaluate unseen (testing) time series and identify\npatterns that have anomalous characteristics. Kernel density estimation (KDE)\nis applied to data points that are likely to be anomalous to generate\nprobability density functions on the testing time series. The segments with the\nhighest relative probabilities are detected as anomalies. To evaluate the\nperformance, we tested on univariate acceleration time series for five miles of\na Class I railroad track. We implemented the framework to detect the real\nanomalous observations identified by operators. The results show that\nleveraging the framework with a CNN D architecture results in average best\nrecall and precision of 80% and 86%, respectively, which demonstrates that a\nwell-trained standalone D model has the potential to be a reliable anomaly\ndetector. Moreover, the influence of GAN hyperparameters, GAN architectures,\nsliding window sizes, clustering of time series, and model validation with\nlabeled/unlabeled data were also investigated.",
    "descriptor": "",
    "authors": [
      "Yueyan Gu",
      "Farrokh Jazizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.02449"
  },
  {
    "id": "arXiv:2210.02450",
    "title": "Learning from aggregated data with a maximum entropy model",
    "abstract": "Aggregating a dataset, then injecting some noise, is a simple and common way\nto release differentially private data.However, aggregated data -- even without\nnoise -- is not an appropriate input for machine learning classifiers.In this\nwork, we show how a new model, similar to a logistic regression, may be learned\nfrom aggregated data only by approximating the unobserved feature distribution\nwith a maximum entropy hypothesis. The resulting model is a Markov Random Field\n(MRF), and we detail how to apply, modify and scale a MRF training algorithm to\nour setting. Finally we present empirical evidence on several public datasets\nthat the model learned this way can achieve performances comparable to those of\na logistic model trained with the full unaggregated data.",
    "descriptor": "",
    "authors": [
      "Alexandre Gilotte",
      "Ahmed Ben Yahmed",
      "David Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02450"
  },
  {
    "id": "arXiv:2210.02476",
    "title": "BaseTransformers: Attention over base data-points for One Shot Learning",
    "abstract": "Few shot classification aims to learn to recognize novel categories using\nonly limited samples per category. Most current few shot methods use a base\ndataset rich in labeled examples to train an encoder that is used for obtaining\nrepresentations of support instances for novel classes. Since the test\ninstances are from a distribution different to the base distribution, their\nfeature representations are of poor quality, degrading performance. In this\npaper we propose to make use of the well-trained feature representations of the\nbase dataset that are closest to each support instance to improve its\nrepresentation during meta-test time. To this end, we propose BaseTransformers,\nthat attends to the most relevant regions of the base dataset feature space and\nimproves support instance representations. Experiments on three benchmark data\nsets show that our method works well for several backbones and achieves\nstate-of-the-art results in the inductive one shot setting. Code is available\nat github.com/mayug/BaseTransformers",
    "descriptor": "\nComments: Paper accepted at British Machine Vision Conference 2022\n",
    "authors": [
      "Mayug Maniparambil",
      "Kevin McGuinness",
      "Noel O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02476"
  },
  {
    "id": "arXiv:2210.02487",
    "title": "Token Classification for Disambiguating Medical Abbreviations",
    "abstract": "Abbreviations are unavoidable yet critical parts of the medical text. Using\nabbreviations, especially in clinical patient notes, can save time and space,\nprotect sensitive information, and help avoid repetitions. However, most\nabbreviations might have multiple senses, and the lack of a standardized\nmapping system makes disambiguating abbreviations a difficult and\ntime-consuming task. The main objective of this study is to examine the\nfeasibility of token classification methods for medical abbreviation\ndisambiguation. Specifically, we explore the capability of token classification\nmethods to deal with multiple unique abbreviations in a single text. We use two\npublic datasets to compare and contrast the performance of several transformer\nmodels pre-trained on different scientific and medical corpora. Our proposed\ntoken classification approach outperforms the more commonly used text\nclassification models for the abbreviation disambiguation task. In particular,\nthe SciBERT model shows a strong performance for both token and text\nclassification tasks over the two considered datasets. Furthermore, we find\nthat abbreviation disambiguation performance for the text classification models\nbecomes comparable to that of token classification only when postprocessing is\napplied to their predictions, which involves filtering possible labels for an\nabbreviation based on the training data.",
    "descriptor": "",
    "authors": [
      "Mucahit Cevik",
      "Sanaz Mohammad Jafari",
      "Mitchell Myers",
      "Savas Yildirim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02487"
  },
  {
    "id": "arXiv:2210.02490",
    "title": "Analyzing historical diagnosis code data from NIH N3C and RECOVER  Programs using deep learning to determine risk factors for Long Covid",
    "abstract": "Post-acute sequelae of SARS-CoV-2 infection (PASC) or Long COVID is an\nemerging medical condition that has been observed in several patients with a\npositive diagnosis for COVID-19. Historical Electronic Health Records (EHR)\nlike diagnosis codes, lab results and clinical notes have been analyzed using\ndeep learning and have been used to predict future clinical events. In this\npaper, we propose an interpretable deep learning approach to analyze historical\ndiagnosis code data from the National COVID Cohort Collective (N3C) to find the\nrisk factors contributing to developing Long COVID. Using our deep learning\napproach, we are able to predict if a patient is suffering from Long COVID from\na temporally ordered list of diagnosis codes up to 45 days post the first COVID\npositive test or diagnosis for each patient, with an accuracy of 70.48\\%. We\nare then able to examine the trained model using Gradient-weighted Class\nActivation Mapping (GradCAM) to give each input diagnoses a score. The highest\nscored diagnosis were deemed to be the most important for making the correct\nprediction for a patient. We also propose a way to summarize these top\ndiagnoses for each patient in our cohort and look at their temporal trends to\ndetermine which codes contribute towards a positive Long COVID diagnosis.",
    "descriptor": "",
    "authors": [
      "Saurav Sengupta",
      "Johanna Loomba",
      "Suchetha Sharma",
      "Donald E. Brown",
      "Lorna Thorpe",
      "Melissa A Haendel",
      "Christopher G Chute",
      "Stephanie Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02490"
  },
  {
    "id": "arXiv:2210.02493",
    "title": "Depth Is All You Need for Monocular 3D Detection",
    "abstract": "A key contributor to recent progress in 3D detection from single images is\nmonocular depth estimation. Existing methods focus on how to leverage depth\nexplicitly, by generating pseudo-pointclouds or providing attention cues for\nimage features. More recent works leverage depth prediction as a pretraining\ntask and fine-tune the depth representation while training it for 3D detection.\nHowever, the adaptation is insufficient and is limited in scale by manual\nlabels. In this work, we propose to further align depth representation with the\ntarget domain in unsupervised fashions. Our methods leverage commonly available\nLiDAR or RGB videos during training time to fine-tune the depth representation,\nwhich leads to improved 3D detectors. Especially when using RGB videos, we show\nthat our two-stage training by first generating pseudo-depth labels is critical\nbecause of the inconsistency in loss distribution between the two tasks. With\neither type of reference data, our multi-task learning approach improves over\nthe state of the art on both KITTI and NuScenes, while matching the test-time\ncomplexity of its single task sub-network.",
    "descriptor": "",
    "authors": [
      "Dennis Park",
      "Jie Li",
      "Dian Chen",
      "Vitor Guizilini",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02493"
  },
  {
    "id": "arXiv:2210.02494",
    "title": "Model Reference Gaussian Process Regression: Data-Driven Output Feedback  Controller",
    "abstract": "Data-driven controls using Gaussian process regression have recently gained\nmuch attention. In such approaches, system identification by Gaussian process\nregression is mostly followed by model-based controller designs. However, the\noutcomes of Gaussian process regression are often too complicated to apply\nconventional control designs, which makes the numerical design such as model\npredictive control employed in many cases. To overcome the restriction, our\nidea is to perform Gaussian process regression to the inverse of the plant with\nthe same input/output data for the conventional regression. With the inverse,\none can design a model reference controller without resorting to numerical\ncontrol methods. This paper considers single-input single-output (SISO)\ndiscrete-time nonlinear systems of minimum phase with relative degree one. It\nis highlighted that the model reference Gaussian process regression controller\nis designed directly from pre-collected input/output data without system\nidentification.",
    "descriptor": "\nComments: 6 pages, 5 figures, submitted to American Control Conference 2023\n",
    "authors": [
      "Hyuntae Kim",
      "Hamin Chang",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02494"
  },
  {
    "id": "arXiv:2210.02496",
    "title": "Designing Strategyproof Election Systems with Score Voting",
    "abstract": "We focus on the strategyproofness of voting systems where voters must choose\na number of options among several possibilities. These systems include those\nthat are used for Participatory Budgeting, where we organize an election to\ndetermine the allocation of a community's budget (city, region, etc.) dedicated\nto the financing of projects.\nWe present a model for studying voting mechanisms and the Constrained Change\nProperty (CCP), which will be used to design voting mechanisms that are always\nstrategyproof. We also define a new notion of social choice function and use it\nto design a new class of utilitarian voting mechanisms that we call score\nvoting. We prove that the mechanisms designed with core voting with a neutral\nscore function are equivalent to knapsack voting on the same instance and that\nany score voting designed with a total score function is strategyproof if and\nonly if its score function satisfies CCP.\nThese results are combined to devise an algorithm that can find the closest\ntotal score function that makes any given score voting to be strategyproof.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Johanne Cohen",
      "Daniel Cordeiro",
      "Valentin Dardilhac",
      "Victor Glaser"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.02496"
  },
  {
    "id": "arXiv:2210.02498",
    "title": "Honest Students from Untrusted Teachers: Learning an Interpretable  Question-Answering Pipeline from a Pretrained Language Model",
    "abstract": "Explainable question answering systems should produce not only accurate\nanswers but also rationales that justify their reasoning and allow humans to\ncheck their work. But what sorts of rationales are useful and how can we train\nsystems to produce them? We propose a new style of rationale for open-book\nquestion answering, called \\emph{markup-and-mask}, which combines aspects of\nextractive and free-text explanations. In the markup phase, the passage is\naugmented with free-text markup that enables each sentence to stand on its own\noutside the discourse context. In the masking phase, a sub-span of the\nmarked-up passage is selected. To train a system to produce markup-and-mask\nrationales without annotations, we leverage in-context learning. Specifically,\nwe generate silver annotated data by sending a series of prompts to a frozen\npretrained language model, which acts as a teacher. We then fine-tune a smaller\nstudent model by training on the subset of rationales that led to correct\nanswers. The student is \"honest\" in the sense that it is a pipeline: the\nrationale acts as a bottleneck between the passage and the answer, while the\n\"untrusted\" teacher operates under no such constraints. Thus, we offer a new\nway to build trustworthy pipeline systems from a combination of end-task\nannotations and frozen pretrained language models.",
    "descriptor": "",
    "authors": [
      "Jacob Eisenstein",
      "Daniel Andor",
      "Bernd Bohnet",
      "Michael Collins",
      "David Mimno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02498"
  },
  {
    "id": "arXiv:2210.02502",
    "title": "On Adversarial Robustness of Deep Image Deblurring",
    "abstract": "Recent approaches employ deep learning-based solutions for the recovery of a\nsharp image from its blurry observation. This paper introduces adversarial\nattacks against deep learning-based image deblurring methods and evaluates the\nrobustness of these neural networks to untargeted and targeted attacks. We\ndemonstrate that imperceptible distortion can significantly degrade the\nperformance of state-of-the-art deblurring networks, even producing drastically\ndifferent content in the output, indicating the strong need to include\nadversarially robust training not only in classification but also for image\nrecovery.",
    "descriptor": "\nComments: ICIP 2022\n",
    "authors": [
      "Kanchana Vaishnavi Gandikota",
      "Paramanand Chandramouli",
      "Michael Moeller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.02502"
  },
  {
    "id": "arXiv:2210.02506",
    "title": "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors",
    "abstract": "Video game testing requires game-specific knowledge as well as common sense\nreasoning about the events in the game. While AI-driven agents can satisfy the\nfirst requirement, it is not yet possible to meet the second requirement\nautomatically. Therefore, video game testing often still relies on manual\ntesting, and human testers are required to play the game thoroughly to detect\nbugs. As a result, it is challenging to fully automate game testing. In this\nstudy, we explore the possibility of leveraging the zero-shot capabilities of\nlarge language models for video game bug detection. By formulating the bug\ndetection problem as a question-answering task, we show that large language\nmodels can identify which event is buggy in a sequence of textual descriptions\nof events from a game. To this end, we introduce the GameBugDescriptions\nbenchmark dataset, which consists of 167 buggy gameplay videos and a total of\n334 question-answer pairs across 8 games. We extensively evaluate the\nperformance of six models across the OPT and InstructGPT large language model\nfamilies on our benchmark dataset. Our results show promising results for\nemploying language models to detect video game bugs. With the proper prompting\ntechnique, we could achieve an accuracy of 70.66%, and on some video games, up\nto 78.94%. Our code, evaluation data and the benchmark can be found on\nhttps://asgaardlab.github.io/LLMxBugs",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Taesiri",
      "Finlay Macklon",
      "Yihe Wang",
      "Hengshuo Shen",
      "Cor-Paul Bezemer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.02506"
  },
  {
    "id": "arXiv:2210.02509",
    "title": "Revisiting Syllables in Language Modelling and their Application on  Low-Resource Machine Translation",
    "abstract": "Language modelling and machine translation tasks mostly use subword or\ncharacter inputs, but syllables are seldom used. Syllables provide shorter\nsequences than characters, require less-specialised extracting rules than\nmorphemes, and their segmentation is not impacted by the corpus size. In this\nstudy, we first explore the potential of syllables for open-vocabulary language\nmodelling in 21 languages. We use rule-based syllabification methods for six\nlanguages and address the rest with hyphenation, which works as a\nsyllabification proxy. With a comparable perplexity, we show that syllables\noutperform characters and other subwords. Moreover, we study the importance of\nsyllables on neural machine translation for a non-related and low-resource\nlanguage-pair (Spanish--Shipibo-Konibo). In pairwise and multilingual systems,\nsyllables outperform unsupervised subwords, and further morphological\nsegmentation methods, when translating into a highly synthetic language with a\ntransparent orthography (Shipibo-Konibo). Finally, we perform some human\nevaluation, and discuss limitations and opportunities.",
    "descriptor": "\nComments: COLING 2022, short-paper\n",
    "authors": [
      "Arturo Oncevay",
      "Kervy Dante Rivas Rojas",
      "Liz Karen Chavez Sanchez",
      "Roberto Zariquiey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02509"
  },
  {
    "id": "arXiv:2210.02511",
    "title": "TartanCalib: Iterative Wide-Angle Lens Calibration using Adaptive  SubPixel Refinement of AprilTags",
    "abstract": "Wide-angle cameras are uniquely positioned for mobile robots, by virtue of\nthe rich information they provide in a small, light, and cost-effective form\nfactor. An accurate calibration of the intrinsics and extrinsics is a critical\npre-requisite for using the edge of a wide-angle lens for depth perception and\nodometry. Calibrating wide-angle lenses with current state-of-the-art\ntechniques yields poor results due to extreme distortion at the edge, as most\nalgorithms assume a lens with low to medium distortion closer to a pinhole\nprojection. In this work we present our methodology for accurate wide-angle\ncalibration. Our pipeline generates an intermediate model, and leverages it to\niteratively improve feature detection and eventually the camera parameters. We\ntest three key methods to utilize intermediate camera models: (1) undistorting\nthe image into virtual pinhole cameras, (2) reprojecting the target into the\nimage frame, and (3) adaptive subpixel refinement. Combining adaptive subpixel\nrefinement and feature reprojection significantly improves reprojection errors\nby up to 26.59 %, helps us detect up to 42.01 % more features, and improves\nperformance in the downstream task of dense depth mapping. Finally, TartanCalib\nis open-source and implemented into an easy-to-use calibration toolbox. We also\nprovide a translation layer with other state-of-the-art works, which allows for\nregressing generic models with thousands of parameters or using a more robust\nsolver. To this end, TartanCalib is the tool of choice for wide-angle\ncalibration. Project website and code: this http URL",
    "descriptor": "",
    "authors": [
      "Bardienus P Duisterhof",
      "Yaoyu Hu",
      "Si Heng Teng",
      "Michael Kaess",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02511"
  },
  {
    "id": "arXiv:2210.02515",
    "title": "Learning with Limited Samples -- Meta-Learning and Applications to  Communication Systems",
    "abstract": "Deep learning has achieved remarkable success in many machine learning tasks\nsuch as image classification, speech recognition, and game playing. However,\nthese breakthroughs are often difficult to translate into real-world\nengineering systems because deep learning models require a massive number of\ntraining samples, which are costly to obtain in practice. To address labeled\ndata scarcity, few-shot meta-learning optimizes learning algorithms that can\nefficiently adapt to new tasks quickly. While meta-learning is gaining\nsignificant interest in the machine learning literature, its working principles\nand theoretic fundamentals are not as well understood in the engineering\ncommunity.\nThis review monograph provides an introduction to meta-learning by covering\nprinciples, algorithms, theory, and engineering applications. After introducing\nmeta-learning in comparison with conventional and joint learning, we describe\nthe main meta-learning algorithms, as well as a general bilevel optimization\nframework for the definition of meta-learning techniques. Then, we summarize\nknown results on the generalization capabilities of meta-learning from a\nstatistical learning viewpoint. Applications to communication systems,\nincluding decoding and power allocation, are discussed next, followed by an\nintroduction to aspects related to the integration of meta-learning with\nemerging computing technologies, namely neuromorphic and quantum computing. The\nmonograph is concluded with an overview of open research challenges.",
    "descriptor": "\nComments: This is the first draft of this monograph submitted for review. Comments are very welcome\n",
    "authors": [
      "Lisha Chen",
      "Sharu Theresa Jose",
      "Ivana Nikoloska",
      "Sangwoo Park",
      "Tianyi Chen",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02515"
  },
  {
    "id": "arXiv:2210.02516",
    "title": "Equalizing Credit Opportunity in Algorithms: Aligning Algorithmic  Fairness Research with U.S. Fair Lending Regulation",
    "abstract": "Credit is an essential component of financial wellbeing in America, and\nunequal access to it is a large factor in the economic disparities between\ndemographic groups that exist today. Today, machine learning algorithms,\nsometimes trained on alternative data, are increasingly being used to determine\naccess to credit, yet research has shown that machine learning can encode many\ndifferent versions of \"unfairness,\" thus raising the concern that banks and\nother financial institutions could -- potentially unwittingly -- engage in\nillegal discrimination through the use of this technology. In the US, there are\nlaws in place to make sure discrimination does not happen in lending and\nagencies charged with enforcing them. However, conversations around fair credit\nmodels in computer science and in policy are often misaligned: fair machine\nlearning research often lacks legal and practical considerations specific to\nexisting fair lending policy, and regulators have yet to issue new guidance on\nhow, if at all, credit risk models should be utilizing practices and techniques\nfrom the research community. This paper aims to better align these sides of the\nconversation. We describe the current state of credit discrimination regulation\nin the United States, contextualize results from fair ML research to identify\nthe specific fairness concerns raised by the use of machine learning in\nlending, and discuss regulatory opportunities to address these concerns.",
    "descriptor": "",
    "authors": [
      "I. Elizabeth Kumar",
      "Keegan E. Hines",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.02516"
  },
  {
    "id": "arXiv:2210.02517",
    "title": "Athletic Mobile Manipulator System for Robotic Wheelchair Tennis",
    "abstract": "Athletics are a quintessential and universal expression of humanity. From\nFrench monks who in the 12th century invented jeu de paume, the precursor to\nmodern lawn tennis, back to the K'iche' people who played the Maya Ballgame as\na form of religious expression over three thousand years ago, humans have\nsought to train their minds and bodies to excel in sporting contests. Advances\nin robotics are opening up the possibility of robots in sports. Yet, key\nchallenges remain, as most prior works in robotics for sports are limited to\npristine sensing environments, do not require significant force generation, or\nare on miniaturized scales unsuited for joint human-robot play. In this paper,\nwe propose the first open-source, autonomous robot for playing regulation\nwheelchair tennis. We demonstrate the performance of our full-stack system in\nexecuting ground strokes and evaluate each of the system's hardware and\nsoftware components. The goal of this paper is to (1) inspire more research in\nhuman-scale robot athletics and (2) establish the first baseline towards\ndeveloping a robot in future work that can serve as a teammate for mixed,\nhuman-robot doubles play. Our paper contributes to the science of systems\ndesign and poses a set of key challenges for the robotics community to address\nin striving towards a vision of human-robot collaboration in sports.",
    "descriptor": "\nComments: 8 pages, under review at RA-L\n",
    "authors": [
      "Zulfiqar Zaidi",
      "Daniel Martin",
      "Nathaniel Belles",
      "Viacheslav Zakharov",
      "Arjun Krishna",
      "Kin Man Lee",
      "Peter Wagstaff",
      "Sumedh Naik",
      "Matthew Sklar",
      "Sugju Choi",
      "Yoshiki Kakehi",
      "Ruturaj Patil",
      "Divya Mallemadugula",
      "Florian Pesce",
      "Peter Wilson",
      "Wendell Hom",
      "Matan Diamond",
      "Bryan Zhao",
      "Nina Moorman",
      "Rohan Paleja",
      "Letian Chen",
      "Esmaeil Seraj",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02517"
  },
  {
    "id": "arXiv:2210.02522",
    "title": "Glowing in the Dark Uncovering IPv6 Address Discovery and Scanning  Strategies in the Wild",
    "abstract": "In this work we identify scanning strategies of IPv6 scanners on the\nInternet. We offer a unique perspective on the behavior of IPv6 scanners by\nconducting controlled experiments leveraging a large and unused /56 IPv6\nsubnet. We selectively make parts of the subnet visible to scanners by hosting\napplications that make direct or indirect contact with IPv6- capable servers on\nthe Internet. By careful experiment design, we mitigate the effects of hidden\nvariables on scans sent to our /56 subnet and establish causal relationships\nbetween IPv6 host activity types and the scanner attention they evoke. We show\nthat IPv6 host activities e.g., Web browsing, membership in the NTP pool and\nTor network, cause scanners to send a magnitude higher number of unsolicited IP\nscans and reverse DNS queries to our subnet than before. DNS scanners focus\ntheir scans in narrow regions of the address space where our applications are\nhosted whereas IP scanners broadly scan the entire subnet. Even after the host\nactivity from our subnet subsides, we observe persistent residual scanning to\nportions of the address space that previously hosted applications",
    "descriptor": "\nComments: 13 pages, 18 pages with appendix + bib, To appear in USENIX Security '23\n",
    "authors": [
      "Hammas Bin Tanveer",
      "Rachee Singh",
      "Paul Pearce",
      "Rishab Nithyanand"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.02522"
  },
  {
    "id": "arXiv:2210.02523",
    "title": "Dual-Domain Cross-Iteration Squeeze-Excitation Network for Sparse  Reconstruction of Brain MRI",
    "abstract": "Magnetic resonance imaging (MRI) is one of the most commonly applied tests in\nneurology and neurosurgery. However, the utility of MRI is largely limited by\nits long acquisition time, which might induce many problems including patient\ndiscomfort and motion artifacts. Acquiring fewer k-space sampling is a\npotential solution to reducing the total scanning time. However, it can lead to\nsevere aliasing reconstruction artifacts and thus affect the clinical\ndiagnosis. Nowadays, deep learning has provided new insights into the sparse\nreconstruction of MRI. In this paper, we present a new approach to this problem\nthat iteratively fuses the information of k-space and MRI images using novel\ndual Squeeze-Excitation Networks and Cross-Iteration Residual Connections. This\nstudy included 720 clinical multi-coil brain MRI cases adopted from the\nopen-source deidentified fastMRI Dataset. 8-folder downsampling rate was\napplied to generate the sparse k-space. Results showed that the average\nreconstruction error over 120 testing cases by our proposed method was 2.28%,\nwhich outperformed the existing image-domain prediction (6.03%, p<0.001),\nk-space synthesis (6.12%, p<0.001), and dual-domain feature fusion (4.05%,\np<0.001).",
    "descriptor": "\nComments: 4 pages, 5 figures, 2 tables\n",
    "authors": [
      "Xiongchao Chen",
      "Yoshihisa Shinagawa",
      "Zhigang Peng",
      "Gerardo Hermosillo Valadez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02523"
  },
  {
    "id": "arXiv:2210.02524",
    "title": "Experiments in Underwater Feature Tracking with Performance Guarantees  Using a Small AUV",
    "abstract": "We present the results of experiments performed using a small autonomous\nunderwater vehicle to determine the location of an isobath within a bounded\narea. The primary contribution of this work is to implement and integrate\nseveral recent developments real-time planning for environmental mapping, and\nto demonstrate their utility in a challenging practical example. We model the\nbathymetry within the operational area using a Gaussian process and propose a\nreward function that represents the task of mapping a desired isobath. As is\ncommon in applications where plans must be continually updated based on\nreal-time sensor measurements, we adopt a receding horizon framework where the\nvehicle continually computes near-optimal paths. The sequence of paths does\nnot, in general, inherit the optimality properties of each individual path. Our\nreal-time planning implementation incorporates recent results that lead to\nperformance guarantees for receding-horizon planning.",
    "descriptor": "\nComments: 7 pages, 6 figures, 1 table, IROS 2022\n",
    "authors": [
      "Benjamin Biggs",
      "Hans He",
      "James McMahon",
      "Daniel J. Stilwell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02524"
  },
  {
    "id": "arXiv:2210.02526",
    "title": "\"No, they did not\": Dialogue response dynamics in pre-trained language  models",
    "abstract": "A critical component of competence in language is being able to identify\nrelevant components of an utterance and reply appropriately. In this paper we\nexamine the extent of such dialogue response sensitivity in pre-trained\nlanguage models, conducting a series of experiments with a particular focus on\nsensitivity to dynamics involving phenomena of at-issueness and ellipsis. We\nfind that models show clear sensitivity to a distinctive role of embedded\nclauses, and a general preference for responses that target main clause content\nof prior utterances. However, the results indicate mixed and generally weak\ntrends with respect to capturing the full range of dynamics involved in\ntargeting at-issue versus not-at-issue content. Additionally, models show\nfundamental limitations in grasp of the dynamics governing ellipsis, and\nresponse selections show clear interference from superficial factors that\noutweigh the influence of principled discourse constraints.",
    "descriptor": "\nComments: 12 pages, 8 figures, COLING 2022, see this https URL for codes and material\n",
    "authors": [
      "Sanghee J. Kim",
      "Lang Yu",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02526"
  },
  {
    "id": "arXiv:2210.02527",
    "title": "Toward Knowledge-Driven Speech-Based Models of Depression: Leveraging  Spectrotemporal Variations in Speech Vowels",
    "abstract": "Psychomotor retardation associated with depression has been linked with\ntangible differences in vowel production. This paper investigates a\nknowledge-driven machine learning (ML) method that integrates spectrotemporal\ninformation of speech at the vowel-level to identify the depression. Low-level\nspeech descriptors are learned by a convolutional neural network (CNN) that is\ntrained for vowel classification. The temporal evolution of those low-level\ndescriptors is modeled at the high-level within and across utterances via a\nlong short-term memory (LSTM) model that takes the final depression decision. A\nmodified version of the Local Interpretable Model-agnostic Explanations (LIME)\nis further used to identify the impact of the low-level spectrotemporal vowel\nvariation on the decisions and observe the high-level temporal change of the\ndepression likelihood. The proposed method outperforms baselines that model the\nspectrotemporal information in speech without integrating the vowel-based\ninformation, as well as ML models trained with conventional prosodic and\nspectrotemporal features. The conducted explainability analysis indicates that\nspectrotemporal information corresponding to non-vowel segments less important\nthan the vowel-based information. Explainability of the high-level information\ncapturing the segment-by-segment decisions is further inspected for\nparticipants with and without depression. The findings from this work can\nprovide the foundation toward knowledge-driven interpretable decision-support\nsystems that can assist clinicians to better understand fine-grain temporal\nchanges in speech data, ultimately augmenting mental health diagnosis and care.",
    "descriptor": "\nComments: oral presentation for BHI 2022\n",
    "authors": [
      "Kexin Feng",
      "Theodora Chaspari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02527"
  },
  {
    "id": "arXiv:2210.02533",
    "title": "Towards Semi-automatic Detection and Localization of Indoor  Accessibility Issues using Mobile Depth Scanning and Computer Vision",
    "abstract": "To help improve the safety and accessibility of indoor spaces, researchers\nand health professionals have created assessment instruments that enable\nhomeowners and trained experts to audit and improve homes. With advances in\ncomputer vision, augmented reality (AR), and mobile sensors, new approaches are\nnow possible. We introduce RASSAR (Room Accessibility and Safety Scanning in\nAugmented Reality), a new proof-of-concept prototype for semi-automatically\nidentifying, categorizing, and localizing indoor accessibility and safety\nissues using LiDAR + camera data, machine learning, and AR. We present an\noverview of the current RASSAR prototype and a preliminary evaluation in a\nsingle home.",
    "descriptor": "\nComments: Workshop paper presented at \"The 1st ASSETS'22 Workshop on The Future or urban Accessibility (UrbanAccess'22)\"\n",
    "authors": [
      "Xia Su",
      "Kaiming Cheng",
      "Han Zhang",
      "Jaewook Lee",
      "Jon E. Froehlich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.02533"
  },
  {
    "id": "arXiv:2210.02534",
    "title": "Performing live time-traversal queries on RDF datasets",
    "abstract": "This article introduces a methodology to perform live time-traversal queries\non RDF datasets and software based on this procedure. It offers a solution to\nmanage the provenance and change-tracking of entities described using RDF.\nAlthough these two aspects are crucial factors in ensuring verifiability and\ntrust, some of the most prominent knowledge bases - including DBpedia,\nWikidata, Yago, and the Dynamic Linked Data Observatory - do not support\ntime-agnostic SPARQL queries, i.e. queries across the various statuses an\nentity may have assumed in time. The OpenCitations Data Model (OCDM) describes\none possible way to track provenance and entities' changes in RDF datasets, and\nit allows restoring an entity to a specific status in time (i.e. a snapshot) by\napplying SPARQL update queries. The methodology and library presented in this\narticle are based on the rationale introduced in the OCDM. We also develop\nbenchmarks proving that such a procedure is efficient for specific queries and\nless efficient for others. To date, as far as we know, our library is the only\nsoftware supporting all the time-related retrieval functionalities without\npre-indexing data.",
    "descriptor": "\nComments: 35 pages, 8 figures, submitted to the Semantic Web Journal (this https URL)\n",
    "authors": [
      "Arcangelo Massari",
      "Silvio Peroni"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.02534"
  },
  {
    "id": "arXiv:2210.02535",
    "title": "Attention-based Ingredient Phrase Parser",
    "abstract": "As virtual personal assistants have now penetrated the consumer market, with\nproducts such as Siri and Alexa, the research community has produced several\nworks on task-oriented dialogue tasks such as hotel booking, restaurant\nbooking, and movie recommendation. Assisting users to cook is one of these\ntasks that are expected to be solved by intelligent assistants, where\ningredients and their corresponding attributes, such as name, unit, and\nquantity, should be provided to users precisely and promptly. However, existing\ningredient information scraped from the cooking website is in the unstructured\nform with huge variation in the lexical structure, for example, '1 garlic\nclove, crushed', and '1 (8 ounce) package cream cheese, softened', making it\ndifficult to extract information exactly. To provide an engaged and successful\nconversational service to users for cooking tasks, we propose a new ingredient\nparsing model that can parse an ingredient phrase of recipes into the structure\nform with its corresponding attributes with over 0.93 F1-score. Experimental\nresults show that our model achieves state-of-the-art performance on AllRecipes\nand Food.com datasets.",
    "descriptor": "\nComments: ESANN 2022 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning\n",
    "authors": [
      "Zhengxiang Shi",
      "Pin Ni",
      "Meihui Wang",
      "To Eun Kim",
      "Aldo Lipani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02535"
  },
  {
    "id": "arXiv:2210.02541",
    "title": "Inserting or Stretching Points in Finite Difference Discretizations",
    "abstract": "Partial differential equations sometimes have critical points where the\nsolution or some of its derivatives are discontinuous. The simplest example is\na discontinuity in the initial condition. It is well known that those decrease\nthe accuracy of finite difference methods. A common remedy is to stretch the\ngrid, such that many more grid points are present near the critical points, and\nfewer where the solution is deemed smooth. An alternative solution is to insert\npoints such that the discontinuities fall in the middle of two grid points.\nThis note compares the accuracy of both approaches in the context of the\npricing of financial derivative contracts in the Black-Scholes model and\nproposes a simple fast cubic stretching.",
    "descriptor": "",
    "authors": [
      "Jherek Healy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.02541"
  },
  {
    "id": "arXiv:2210.02543",
    "title": "Diverse End User Requirements",
    "abstract": "As part of our larger research effort to improve support for diverse end user\nhuman-centric aspects during software development, we wanted to better\nunderstand how developers currently go about addressing these challenging\nhuman-centric aspects of their end users in contemporary software development\nprojects. We wanted to find out which are the key end user human-centric\naspects that software developers currently find challenging to address, and how\nthey currently go about trying to address diverse end user human-centric\naspects. We wanted to find out what sorts of end user human-centric aspects\nthey tend to encounter, which ones they view as more important and which more\nchallenging to address, what techniques (if any) they currently use to address\n(some of) them, and where they perceive further research in this area could be\ndone to provide them practical support. To this end we carried out a detailed\nonline survey of developers and development team managers, receiving 60 usable\nresponses. We interviewed 12 developers and managers from a range of different\npractice domains, role specialisations and experience levels to explore further\ndetails about issues.",
    "descriptor": "\nComments: ED&I Book chapter submission\n",
    "authors": [
      "John Grundy",
      "Tanjila Kanij",
      "Jennifer McIntosh",
      "Hourieh Khalajzadeh",
      "Ingo Mueller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.02543"
  },
  {
    "id": "arXiv:2210.02545",
    "title": "JoeyS2T: Minimalistic Speech-to-Text Modeling with JoeyNMT",
    "abstract": "JoeyS2T is a JoeyNMT extension for speech-to-text tasks such as automatic\nspeech recognition and end-to-end speech translation. It inherits the core\nphilosophy of JoeyNMT, a minimalist NMT toolkit built on PyTorch, seeking\nsimplicity and accessibility. JoeyS2T's workflow is self-contained, starting\nfrom data pre-processing, over model training and prediction to evaluation, and\nis seamlessly integrated into JoeyNMT's compact and simple code base. On top of\nJoeyNMT's state-of-the-art Transformer-based encoder-decoder architecture,\nJoeyS2T provides speech-oriented components such as convolutional layers,\nSpecAugment, CTC-loss, and WER evaluation. Despite its simplicity compared to\nprior implementations, JoeyS2T performs competitively on English speech\nrecognition and English-to-German speech translation benchmarks. The\nimplementation is accompanied by a walk-through tutorial and available on\nhttps://github.com/may-/joeys2t.",
    "descriptor": "\nComments: EMNLP 2022 demo track\n",
    "authors": [
      "Mayumi Ohta",
      "Julia Kreutzer",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02545"
  },
  {
    "id": "arXiv:2210.02549",
    "title": "Benchmarking Learning Efficiency in Deep Reservoir Computing",
    "abstract": "It is common to evaluate the performance of a machine learning model by\nmeasuring its predictive power on a test dataset. This approach favors\ncomplicated models that can smoothly fit complex functions and generalize well\nfrom training data points. Although essential components of intelligence, speed\nand data efficiency of this learning process are rarely reported or compared\nbetween different candidate models. In this paper, we introduce a benchmark of\nincreasingly difficult tasks together with a data efficiency metric to measure\nhow quickly machine learning models learn from training data. We compare the\nlearning speed of some established sequential supervised models, such as RNNs,\nLSTMs, or Transformers, with relatively less known alternative models based on\nreservoir computing. The proposed tasks require a wide range of computational\nprimitives, such as memory or the ability to compute Boolean functions, to be\neffectively solved. Surprisingly, we observe that reservoir computing systems\nthat rely on dynamically evolving feature maps learn faster than fully\nsupervised methods trained with stochastic gradient optimization while\nachieving comparable accuracy scores. The code, benchmark, trained models, and\nresults to reproduce our experiments are available at\nhttps://github.com/hugcis/benchmark_learning_efficiency/ .",
    "descriptor": "\nComments: Conference on Lifelong Learning Agents, Aug 2022, Montreal, Canada\n",
    "authors": [
      "Hugo Cisneros",
      "Josef Sivic",
      "Tomas Mikolov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02549"
  },
  {
    "id": "arXiv:2210.02552",
    "title": "Towards Safe Mechanical Ventilation Treatment Using Deep Offline  Reinforcement Learning",
    "abstract": "Mechanical ventilation is a key form of life support for patients with\npulmonary impairment. Healthcare workers are required to continuously adjust\nventilator settings for each patient, a challenging and time consuming task.\nHence, it would be beneficial to develop an automated decision support tool to\noptimize ventilation treatment. We present DeepVent, a Conservative Q-Learning\n(CQL) based offline Deep Reinforcement Learning (DRL) agent that learns to\npredict the optimal ventilator parameters for a patient to promote 90 day\nsurvival. We design a clinically relevant intermediate reward that encourages\ncontinuous improvement of the patient vitals as well as addresses the challenge\nof sparse reward in RL. We find that DeepVent recommends ventilation parameters\nwithin safe ranges, as outlined in recent clinical trials. The CQL algorithm\noffers additional safety by mitigating the overestimation of the value\nestimates of out-of-distribution states/actions. We evaluate our agent using\nFitted Q Evaluation (FQE) and demonstrate that it outperforms physicians from\nthe MIMIC-III dataset.",
    "descriptor": "\nComments: to be published in IAAI (Innovative Applications of Artificial Intelligence) 2023\n",
    "authors": [
      "Flemming Kondrup",
      "Thomas Jiralerspong",
      "Elaine Lau",
      "Nathan de Lara",
      "Jacob Shkrob",
      "My Duc Tran",
      "Doina Precup",
      "Sumana Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02552"
  },
  {
    "id": "arXiv:2210.02553",
    "title": "Water Simulation and Rendering from a Still Photograph",
    "abstract": "We propose an approach to simulate and render realistic water animation from\na single still input photograph. We first segment the water surface, estimate\nrendering parameters, and compute water reflection textures with a combination\nof neural networks and traditional optimization techniques. Then we propose an\nimage-based screen space local reflection model to render the water surface\noverlaid on the input image and generate real-time water animation. Our\napproach creates realistic results with no user intervention for a wide variety\nof natural scenes containing large bodies of water with different lighting and\nwater surface conditions. Since our method provides a 3D representation of the\nwater surface, it naturally enables direct editing of water parameters and also\nsupports interactive applications like adding synthetic objects to the scene.",
    "descriptor": "\nComments: Accepted for publication at ACM SIGGRAPH Asia (Conference Papers). Videos, demos and updates will be on the project website: this https URL\n",
    "authors": [
      "Ryusuke Sugimoto",
      "Mingming He",
      "Jing Liao",
      "Pedro V. Sander"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02553"
  },
  {
    "id": "arXiv:2210.02558",
    "title": "Improved Anomaly Detection by Using the Attention-Based Isolation Forest",
    "abstract": "A new modification of Isolation Forest called Attention-Based Isolation\nForest (ABIForest) for solving the anomaly detection problem is proposed. It\nincorporates the attention mechanism in the form of the Nadaraya-Watson\nregression into the Isolation Forest for improving solution of the anomaly\ndetection problem. The main idea underlying the modification is to assign\nattention weights to each path of trees with learnable parameters depending on\ninstances and trees themselves. The Huber's contamination model is proposed to\nbe used for defining the attention weights and their parameters. As a result,\nthe attention weights are linearly depend on the learnable attention parameters\nwhich are trained by solving the standard linear or quadratic optimization\nproblem. ABIForest can be viewed as the first modification of Isolation Forest,\nwhich incorporates the attention mechanism in a simple way without applying\ngradient-based algorithms. Numerical experiments with synthetic and real\ndatasets illustrate outperforming results of ABIForest. The code of proposed\nalgorithms is available.",
    "descriptor": "",
    "authors": [
      "Lev V. Utkin",
      "Andrey Y. Ageev",
      "Andrei V. Konstantinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02558"
  },
  {
    "id": "arXiv:2210.02563",
    "title": "Integrable cross-field generation based on imposed singularity  configuration -- the 2D manifold case --",
    "abstract": "This work presents the mathematical foundations for the generation of\nintegrable cross-field on 2D manifolds based on user-imposed singularity\nconfiguration. In this paper, we either use singularities that appear\nnaturally, e.g., by solving a non-linear problem, or use as an input\nuser-defined singularity pattern, possibly with high valence singularities that\ntypically do not appear in cross-field computations. This singularity set is\nunder the constraint of Abel-Jacobi's conditions for valid singularity\nconfigurations. The main contribution of the paper is the development of a\nformulation that allows computing an integrable isotropic 2D cross-field from a\ngiven set of singularities through the resolution of only two linear PDEs. To\naddress the issue of possible suboptimal singularities' distribution, we also\npresent the mathematical setting for the generation of an integrable\nanisotropic 2D cross-field based on a user-imposed singularity pattern. The\ndeveloped formulations support both an isotropic and an anisotropic\nblock-structured quad mesh generation.\nKeywords: integrable 2D cross-field, valid singularity configuration, quad\nlayout, quad meshing",
    "descriptor": "",
    "authors": [
      "Jovana Jezdimirovi\u0107",
      "Alexandre Chemin",
      "Jean-Fran\u00e7ois Remacle"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.02563"
  },
  {
    "id": "arXiv:2210.02565",
    "title": "Windowed Green Function MoM for Second-Kind Surface Integral Equation  Formulations of Layered Media Electromagnetic Scattering Problems",
    "abstract": "This paper presents a second-kind surface integral equation method for the\nnumerical solution of frequency-domain electromagnetic scattering problems by\nlocally perturbed layered media in three spatial dimensions. Unlike standard\napproaches, the proposed methodology does not involve the use of layer Green\nfunctions. It instead leverages an indirect M\\\"uller formulation in terms of\nfree-space Green functions that entails integration over the entire unbounded\npenetrable boundary. The integral equation domain is effectively reduced to a\nsmall-area surface by means of the windowed Green function method, which\nexhibits high-order convergence as the size of the truncated surface increases.\nThe resulting (second-kind) windowed integral equation is then numerically\nsolved by means of the standard Galerkin method of moments (MoM) using RWG\nbasis functions. The methodology is validated by comparison with Mie-series and\nSommerfeld-integral exact solutions as well as against a layer Green\nfunction-based MoM. Challenging examples including realistic structures\nrelevant to the design of plasmonic solar cells and all-dielectric\nmetasurfaces, demonstrate the applicability, efficiency, and accuracy of the\nproposed methodology.",
    "descriptor": "",
    "authors": [
      "Rodrigo Arrieta",
      "Carlos P\u00e9rez-Arancibia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Signal Processing (eess.SP)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02565"
  },
  {
    "id": "arXiv:2210.02570",
    "title": "Revisiting Structured Dropout",
    "abstract": "Large neural networks are often overparameterised and prone to overfitting,\nDropout is a widely used regularization technique to combat overfitting and\nimprove model generalization. However, unstructured Dropout is not always\neffective for specific network architectures and this has led to the formation\nof multiple structured Dropout approaches to improve model performance and,\nsometimes, reduce the computational resources required for inference. In this\nwork, we revisit structured Dropout comparing different Dropout approaches to\nnatural language processing and computer vision tasks for multiple\nstate-of-the-art networks. Additionally, we devise an approach to structured\nDropout we call \\textbf{\\emph{ProbDropBlock}} which drops contiguous blocks\nfrom feature maps with a probability given by the normalized feature salience\nvalues. We find that with a simple scheduling strategy the proposed approach to\nstructured Dropout consistently improved model performance compared to\nbaselines and other Dropout approaches on a diverse range of tasks and models.\nIn particular, we show \\textbf{\\emph{ProbDropBlock}} improves RoBERTa\nfinetuning on MNLI by $0.22\\%$, and training of ResNet50 on ImageNet by\n$0.28\\%$.",
    "descriptor": "",
    "authors": [
      "Yiren Zhao",
      "Oluwatomisin Dada",
      "Xitong Gao",
      "Robert D Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02570"
  },
  {
    "id": "arXiv:2210.02573",
    "title": "Bi-Stride Multi-Scale Graph Neural Network for Mesh-Based Physical  Simulation",
    "abstract": "Learning physical systems on unstructured meshes by flat Graph neural\nnetworks (GNNs) faces the challenge of modeling the long-range interactions due\nto the scaling complexity w.r.t. the number of nodes, limiting the\ngeneralization under mesh refinement. On regular grids, the convolutional\nneural networks (CNNs) with a U-net structure can resolve this challenge by\nefficient stride, pooling, and upsampling operations. Nonetheless, these tools\nare much less developed for graph neural networks (GNNs), especially when GNNs\nare employed for learning large-scale mesh-based physics. The challenges arise\nfrom the highly irregular meshes and the lack of effective ways to construct\nthe multi-level structure without losing connectivity. Inspired by the\nbipartite graph determination algorithm, we introduce Bi-Stride Multi-Scale\nGraph Neural Network (BSMS-GNN) by proposing \\textit{bi-stride} as a simple\npooling strategy for building the multi-level GNN. \\textit{Bi-stride} pools\nnodes by striding every other BFS frontier; it 1) works robustly on any\nchallenging mesh in the wild, 2) avoids using a mesh generator at coarser\nlevels, 3) avoids the spatial proximity for building coarser levels, and 4)\nuses non-parametrized aggregating/returning instead of MLPs during pooling and\nunpooling. Experiments show that our framework significantly outperforms the\nstate-of-the-art method's computational efficiency in representative\nphysics-based simulation cases.",
    "descriptor": "",
    "authors": [
      "Yadi Cao",
      "Menglei Chai",
      "Minchen Li",
      "Chenfanfu Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02573"
  },
  {
    "id": "arXiv:2210.02574",
    "title": "Privacy-Preserving Text Classification on BERT Embeddings with  Homomorphic Encryption",
    "abstract": "Embeddings, which compress information in raw text into semantics-preserving\nlow-dimensional vectors, have been widely adopted for their efficacy. However,\nrecent research has shown that embeddings can potentially leak private\ninformation about sensitive attributes of the text, and in some cases, can be\ninverted to recover the original input text. To address these growing privacy\nchallenges, we propose a privatization mechanism for embeddings based on\nhomomorphic encryption, to prevent potential leakage of any piece of\ninformation in the process of text classification. In particular, our method\nperforms text classification on the encryption of embeddings from\nstate-of-the-art models like BERT, supported by an efficient GPU implementation\nof CKKS encryption scheme. We show that our method offers encrypted protection\nof BERT embeddings, while largely preserving their utility on downstream text\nclassification tasks.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Garam Lee",
      "Minsoo Kim",
      "Jai Hyun Park",
      "Seung-won Hwang",
      "Jung Hee Cheon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02574"
  },
  {
    "id": "arXiv:2210.02576",
    "title": "Reading Chinese in Natural Scenes with a Bag-of-Radicals Prior",
    "abstract": "Scene text recognition (STR) on Latin datasets has been extensively studied\nin recent years, and state-of-the-art (SOTA) models often reach high accuracy.\nHowever, the performance on non-Latin transcripts, such as Chinese, is not\nsatisfactory. In this paper, we collect six open-source Chinese STR datasets\nand evaluate a series of classic methods performing well on Latin datasets,\nfinding a significant performance drop. To improve the performance on Chinese\ndatasets, we propose a novel radical-embedding (RE) representation to utilize\nthe ideographic descriptions of Chinese characters. The ideographic\ndescriptions of Chinese characters are firstly converted to bags of radicals\nand then fused with learnable character embeddings by a\ncharacter-vector-fusion-module (CVFM). In addition, we utilize a bag of\nradicals as supervision signals for multi-task training to improve the\nideographic structure perception of our model. Experiments show performance of\nthe model with RE + CVFM + multi-task training is superior compared with the\nbaseline on six Chinese STR datasets. In addition, we utilize a bag of radicals\nas supervision signals for multi-task training to improve the ideographic\nstructure perception of our model. Experiments show performance of the model\nwith RE + CVFM + multi-task training is superior compared with the baseline on\nsix Chinese STR datasets.",
    "descriptor": "\nComments: Accepted by BMVC 2022\n",
    "authors": [
      "Liu Yongbin",
      "Liu Qingjie",
      "Chen Jiaxin",
      "Wang Yunhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02576"
  },
  {
    "id": "arXiv:2210.02577",
    "title": "A Closer Look at Robustness to L-infinity and Spatial Perturbations and  their Composition",
    "abstract": "In adversarial machine learning, the popular $\\ell_\\infty$ threat model has\nbeen the focus of much previous work. While this mathematical definition of\nimperceptibility successfully captures an infinite set of additive image\ntransformations that a model should be robust to, this is only a subset of all\ntransformations which leave the semantic label of an image unchanged. Indeed,\nprevious work also considered robustness to spatial attacks as well as other\nsemantic transformations; however, designing defense methods against the\ncomposition of spatial and $\\ell_{\\infty}$ perturbations remains relatively\nunderexplored. In the following, we improve the understanding of this seldom\ninvestigated compositional setting. We prove theoretically that no linear\nclassifier can achieve more than trivial accuracy against a composite adversary\nin a simple statistical setting, illustrating its difficulty. We then\ninvestigate how state-of-the-art $\\ell_{\\infty}$ defenses can be adapted to\nthis novel threat model and study their performance against compositional\nattacks. We find that our newly proposed TRADES$_{\\text{All}}$ strategy\nperforms the strongest of all. Analyzing its logit's Lipschitz constant for RT\ntransformations of different sizes, we find that TRADES$_{\\text{All}}$ remains\nstable over a wide range of RT transformations with and without $\\ell_\\infty$\nperturbations.",
    "descriptor": "\nComments: 16 pages, 5 figures, and 3 tables\n",
    "authors": [
      "Luke Rowe",
      "Benjamin Th\u00e9rien",
      "Krzysztof Czarnecki",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02577"
  },
  {
    "id": "arXiv:2210.02578",
    "title": "AOE-Net: Entities Interactions Modeling with Adaptive Attention  Mechanism for Temporal Action Proposals Generation",
    "abstract": "Temporal action proposal generation (TAPG) is a challenging task, which\nrequires localizing action intervals in an untrimmed video. Intuitively, we as\nhumans, perceive an action through the interactions between actors, relevant\nobjects, and the surrounding environment. Despite the significant progress of\nTAPG, a vast majority of existing methods ignore the aforementioned principle\nof the human perceiving process by applying a backbone network into a given\nvideo as a black-box. In this paper, we propose to model these interactions\nwith a multi-modal representation network, namely, Actors-Objects-Environment\nInteraction Network (AOE-Net). Our AOE-Net consists of two modules, i.e.,\nperception-based multi-modal representation (PMR) and boundary-matching module\n(BMM). Additionally, we introduce adaptive attention mechanism (AAM) in PMR to\nfocus only on main actors (or relevant objects) and model the relationships\namong them. PMR module represents each video snippet by a visual-linguistic\nfeature, in which main actors and surrounding environment are represented by\nvisual information, whereas relevant objects are depicted by linguistic\nfeatures through an image-text model. BMM module processes the sequence of\nvisual-linguistic features as its input and generates action proposals.\nComprehensive experiments and extensive ablation studies on ActivityNet-1.3 and\nTHUMOS-14 datasets show that our proposed AOE-Net outperforms previous\nstate-of-the-art methods with remarkable performance and generalization for\nboth TAPG and temporal action detection. To prove the robustness and\neffectiveness of AOE-Net, we further conduct an ablation study on egocentric\nvideos, i.e. EPIC-KITCHENS 100 dataset. Source code is available upon\nacceptance.",
    "descriptor": "\nComments: Accepted for publication in International Journal of Computer Vision\n",
    "authors": [
      "Khoa Vo",
      "Sang Truong",
      "Kashu Yamazaki",
      "Bhiksha Raj",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02578"
  },
  {
    "id": "arXiv:2210.02579",
    "title": "DigiFace-1M: 1 Million Digital Face Images for Face Recognition",
    "abstract": "State-of-the-art face recognition models show impressive accuracy, achieving\nover 99.8% on Labeled Faces in the Wild (LFW) dataset. Such models are trained\non large-scale datasets that contain millions of real human face images\ncollected from the internet. Web-crawled face images are severely biased (in\nterms of race, lighting, make-up, etc) and often contain label noise. More\nimportantly, the face images are collected without explicit consent, raising\nethical concerns. To avoid such problems, we introduce a large-scale synthetic\ndataset for face recognition, obtained by rendering digital faces using a\ncomputer graphics pipeline. We first demonstrate that aggressive data\naugmentation can significantly reduce the synthetic-to-real domain gap. Having\nfull control over the rendering pipeline, we also study how each attribute\n(e.g., variation in facial pose, accessories and textures) affects the\naccuracy. Compared to SynFace, a recent method trained on GAN-generated\nsynthetic faces, we reduce the error rate on LFW by 52.5% (accuracy from 91.93%\nto 96.17%). By fine-tuning the network on a smaller number of real face images\nthat could reasonably be obtained with consent, we achieve accuracy that is\ncomparable to the methods trained on millions of real face images.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Gwangbin Bae",
      "Martin de La Gorce",
      "Tadas Baltrusaitis",
      "Charlie Hewitt",
      "Dong Chen",
      "Julien Valentin",
      "Roberto Cipolla",
      "Jingjing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02579"
  },
  {
    "id": "arXiv:2210.02580",
    "title": "Functional Labeled Optimal Partitioning",
    "abstract": "Peak detection is a problem in sequential data analysis that involves\ndifferentiating regions with higher counts (peaks) from regions with lower\ncounts (background noise).\nIt is crucial to correctly predict areas that deviate from the background\nnoise, in both the train and test sets of labels.\nDynamic programming changepoint algorithms have been proposed to solve the\npeak detection problem by constraining the mean to alternatively increase and\nthen decrease.\nThe current constrained changepoint algorithms only create predictions on the\ntest set, while completely ignoring the train set.\nChangepoint algorithms that are both accurate when fitting the train set, and\nmake predictions on the test set, have been proposed but not in the context of\npeak detection models.\nWe propose to resolve these issues by creating a new dynamic programming\nalgorithm, FLOPART, that has zero train label errors, and is able to provide\nhighly accurate predictions on the test set.\nWe provide an empirical analysis that shows FLOPART has a similar time\ncomplexity while being more accurate than the existing algorithms in terms of\ntrain and test label errors.",
    "descriptor": "",
    "authors": [
      "Toby D. Hocking",
      "Jacob M. Kaufman",
      "Alyssa J. Stenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02580"
  },
  {
    "id": "arXiv:2210.02582",
    "title": "Romeo and Juliet Meeting in Forest Like Regions",
    "abstract": "The game of rendezvous with adversaries is a game on a graph played by two\nplayers: Facilitator and Divider. Facilitator has two agents and Divider has a\nteam of $k \\ge 1$ agents. While the initial positions of Facilitator's agents\nare fixed, Divider gets to select the initial positions of his agents. Then,\nthey take turns to move their agents to adjacent vertices (or stay put) with\nFacilitator's goal to bring both her agents at same vertex and Divider's goal\nto prevent it. The computational question of interest is to determine if\nFacilitator has a winning strategy against Divider with $k$ agents. Fomin,\nGolovach, and Thilikos [WG, 2021] introduced this game and proved that it is\nPSPACE-hard and co-W[2]-hard parameterized by the number of agents.\nThis hardness naturally motivates the structural parameterization of the\nproblem. The authors proved that it admits an FPT algorithm when parameterized\nby the modular width and the number of allowed rounds. However, they left open\nthe complexity of the problem from the perspective of other structural\nparameters. In particular, they explicitly asked whether the problem admits an\nFPT or XP-algorithm with respect to the treewidth of the input graph. We answer\nthis question in the negative and show that Rendezvous is co-NP-hard even for\ngraphs of constant treewidth. Further, we show that the problem is co-W[1]-hard\nwhen parameterized by the feedback vertex set number and the number of agents,\nand is unlikely to admit a polynomial kernel when parameterized by the vertex\ncover number and the number of agents. Complementing these hardness results, we\nshow that the Rendezvous is FPT when parameterized by both the vertex cover\nnumber and the solution size. Finally, for graphs of treewidth at most two and\ngirds, we show that the problem can be solved in polynomial time.",
    "descriptor": "\nComments: A shorter version of this work has been accepted for presentation at the 42nd IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS), 2022\n",
    "authors": [
      "Neeldhara Misra",
      "Manas Mulpuri",
      "Prafullkumar Tale",
      "Gaurav Viramgami"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.02582"
  },
  {
    "id": "arXiv:2210.02585",
    "title": "Query The Agent: Improving sample efficiency through epistemic  uncertainty estimation",
    "abstract": "Curricula for goal-conditioned reinforcement learning agents typically rely\non poor estimates of the agent's epistemic uncertainty or fail to consider the\nagents' epistemic uncertainty altogether, resulting in poor sample efficiency.\nWe propose a novel algorithm, Query The Agent (QTA), which significantly\nimproves sample efficiency by estimating the agent's epistemic uncertainty\nthroughout the state space and setting goals in highly uncertain areas.\nEncouraging the agent to collect data in highly uncertain states allows the\nagent to improve its estimation of the value function rapidly. QTA utilizes a\nnovel technique for estimating epistemic uncertainty, Predictive Uncertainty\nNetworks (PUN), to allow QTA to assess the agent's uncertainty in all\npreviously observed states. We demonstrate that QTA offers decisive sample\nefficiency improvements over preexisting methods.",
    "descriptor": "\nComments: Submitted to ICLR 2023\n",
    "authors": [
      "Julian Alverio",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02585"
  },
  {
    "id": "arXiv:2210.02586",
    "title": "Parity in Markets -- Methods, Costs, and Consequences",
    "abstract": "Fisher markets are those where buyers with budgets compete for scarce items,\na natural model for many real world markets including online advertising. We\nshow how market designers can use taxes or subsidies in Fisher markets to\nensure that market equilibrium outcomes fall within certain constraints. We\nadapt various types of fairness constraints proposed in existing literature to\nthe market case and show who benefits and who loses from these constraints, as\nwell as the extent to which properties of markets including Pareto optimality,\nenvy-freeness, and incentive compatibility are preserved. We find that several\nprior proposed constraints applied to markets can hurt the groups they are\nintended to help.",
    "descriptor": "",
    "authors": [
      "Alexander Peysakhovich",
      "Christian Kroer",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.02586"
  },
  {
    "id": "arXiv:2210.02588",
    "title": "Stochastic Neuromorphic Circuits for Solving MAXCUT",
    "abstract": "Finding the maximum cut of a graph (MAXCUT) is a classic optimization problem\nthat has motivated parallel algorithm development. While approximate algorithms\nto MAXCUT offer attractive theoretical guarantees and demonstrate compelling\nempirical performance, such approximation approaches can shift the dominant\ncomputational cost to the stochastic sampling operations. Neuromorphic\ncomputing, which uses the organizing principles of the nervous system to\ninspire new parallel computing architectures, offers a possible solution. One\nubiquitous feature of natural brains is stochasticity: the individual elements\nof biological neural networks possess an intrinsic randomness that serves as a\nresource enabling their unique computational capacities. By designing circuits\nand algorithms that make use of randomness similarly to natural brains, we\nhypothesize that the intrinsic randomness in microelectronics devices could be\nturned into a valuable component of a neuromorphic architecture enabling more\nefficient computations. Here, we present neuromorphic circuits that transform\nthe stochastic behavior of a pool of random devices into useful correlations\nthat drive stochastic solutions to MAXCUT. We show that these circuits perform\nfavorably in comparison to software solvers and argue that this neuromorphic\nhardware implementation provides a path for scaling advantages. This work\ndemonstrates the utility of combining neuromorphic principles with intrinsic\nrandomness as a computational resource for new computational architectures.",
    "descriptor": "",
    "authors": [
      "Bradley H. Theilman",
      "Yipu Wang",
      "Ojas D. Parekh",
      "William Severa",
      "J. Darby Smith",
      "James B. Aimone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.02588"
  },
  {
    "id": "arXiv:2210.02589",
    "title": "Spot-on: A Checkpointing Framework for Fault-Tolerant Long-running  Workloads on Cloud Spot Instances",
    "abstract": "Spot instances offer a cost-effective solution for applications running in\nthe cloud computing environment. However, it is challenging to run long-running\njobs on spot instances because they are subject to unpredictable evictions.\nHere, we present Spot-on, a generic software framework that supports\nfault-tolerant long-running workloads on spot instances through checkpoint and\nrestart. Spot-on leverages existing checkpointing packages and is compatible\nwith the major cloud vendors. Using a genomics application as a test case, we\ndemonstrated that Spot-on supports both application-specific and transparent\ncheckpointing methods. Compared to running applications using on-demand\ninstances, it allows the completion of these workloads for a significant\nreduction in computing costs. Compared to running applications using\napplication-specific checkpoint mechanisms, transparent checkpoint-protected\napplications reduce runtime by up to 40%, leading to further cost savings of up\nto 86%.",
    "descriptor": "\nComments: 3 pages, 3 figures, accepted to \"Third International Symposium on Checkpointing for Supercomputing (SuperCheck-SC22) this https URL\n",
    "authors": [
      "Ashley Tung",
      "Haiyan Wang",
      "Yue Li",
      "Zhong Wang",
      "Jingchao Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.02589"
  },
  {
    "id": "arXiv:2210.02590",
    "title": "Star-Graph Multimodal Matching Component Analysis for Data Fusion and  Transfer Learning",
    "abstract": "Previous matching component analysis (MCA) techniques map two data domains to\na common domain for further processing in data fusion and transfer learning\ncontexts. In this paper, we extend these techniques to the star-graph\nmultimodal (SGM) case in which one particular data domain is connected to $m$\nothers via an objective function. We provide a particular feasible point for\nthe resulting trace maximization problem in closed form and algorithms for its\ncomputation and iterative improvement, leading to our main result, the SGM\nmaps. We also provide numerical examples demonstrating that SGM is capable of\nencoding into its maps more information than MCA when few training points are\navailable. In addition, we develop a further generalization of the MCA\ncovariance constraint, eliminating a previous feasibility condition and\nallowing larger values of the rank of the prescribed covariance matrix.",
    "descriptor": "",
    "authors": [
      "Nick Lorenzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02590"
  },
  {
    "id": "arXiv:2210.02592",
    "title": "CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised  learning of speech representations",
    "abstract": "While Self-Supervised Learning has helped reap the benefit of the scale from\nthe available unlabeled data, the learning paradigms are continuously being\nbettered. We present a new pre-training strategy named ccc-wav2vec 2.0, which\nuses clustering and an augmentation-based cross-contrastive loss as its\nself-supervised objective. Through the clustering module, we scale down the\ninfluence of those negative examples that are highly similar to the positive.\nThe Cross-Contrastive loss is computed between the encoder output of the\noriginal sample and the quantizer output of its augmentation and vice-versa,\nbringing robustness to the pre-training strategy. ccc-wav2vec 2.0 achieves up\nto 15.6% and 12.7% relative WER improvement over the baseline wav2vec 2.0 on\nthe test-clean and test-other sets, respectively, of LibriSpeech, without the\nuse of any language model. The proposed method also achieves up to 14.9%\nrelative WER improvement over the baseline wav2vec 2.0 when fine-tuned on\nSwitchboard data. We make all our codes publicly available on GitHub.",
    "descriptor": "\nComments: To appear at IEEE SLT 2022\n",
    "authors": [
      "Vasista Sai Lodagala",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02592"
  },
  {
    "id": "arXiv:2210.02594",
    "title": "Reward-Mixing MDPs with a Few Latent Contexts are Learnable",
    "abstract": "We consider episodic reinforcement learning in reward-mixing Markov decision\nprocesses (RMMDPs): at the beginning of every episode nature randomly picks a\nlatent reward model among $M$ candidates and an agent interacts with the MDP\nthroughout the episode for $H$ time steps. Our goal is to learn a near-optimal\npolicy that nearly maximizes the $H$ time-step cumulative rewards in such a\nmodel. Previous work established an upper bound for RMMDPs for $M=2$. In this\nwork, we resolve several open questions remained for the RMMDP model. For an\narbitrary $M\\ge2$, we provide a sample-efficient\nalgorithm--$\\texttt{EM}^2$--that outputs an $\\epsilon$-optimal policy using\n$\\tilde{O} \\left(\\epsilon^{-2} \\cdot S^d A^d \\cdot \\texttt{poly}(H, Z)^d\n\\right)$ episodes, where $S, A$ are the number of states and actions\nrespectively, $H$ is the time-horizon, $Z$ is the support size of reward\ndistributions and $d=\\min(2M-1,H)$. Our technique is a higher-order extension\nof the method-of-moments based approach, nevertheless, the design and analysis\nof the \\algname algorithm requires several new ideas beyond existing\ntechniques. We also provide a lower bound of $(SA)^{\\Omega(\\sqrt{M})} /\n\\epsilon^{2}$ for a general instance of RMMDP, supporting that super-polynomial\nsample complexity in $M$ is necessary.",
    "descriptor": "",
    "authors": [
      "Jeongyeol Kwon",
      "Yonathan Efroni",
      "Constantine Caramanis",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02594"
  },
  {
    "id": "arXiv:2210.02596",
    "title": "Role of Deep Learning in Wireless Communications",
    "abstract": "Traditional communication system design has always been based on the paradigm\nof first establishing a mathematical model of the communication channel, then\ndesigning and optimizing the system according to the model. The advent of\nmodern machine learning techniques, specifically deep neural networks, has\nopened up opportunities for data-driven system design and optimization. This\narticle draws examples from the optimization of reconfigurable intelligent\nsurface, distributed channel estimation and feedback for multiuser beamforming,\nand active sensing for millimeter wave (mmWave) initial alignment to illustrate\nthat a data-driven design that bypasses explicit channel modelling can often\ndiscover excellent solutions to communication system design and optimization\nproblems that are otherwise computationally difficult to solve. We show that by\nperforming an end-to-end training of a deep neural network using a large number\nof channel samples, a machine learning based approach can potentially provide\nsignificant system-level improvements as compared to the traditional\nmodel-based approach for solving optimization problems. The key to the\nsuccessful applications of machine learning techniques is in choosing the\nappropriate neural network architecture to match the underlying problem\nstructure.",
    "descriptor": "\nComments: 13 pages, 12 figures, To appear in IEEE BITS the Information Theory Magazine\n",
    "authors": [
      "Wei Yu",
      "Foad Sohrabi",
      "Tao Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02596"
  },
  {
    "id": "arXiv:2210.02601",
    "title": "From Threat Reports to Continuous Threat Intelligence: A Comparison of  Attack Technique Extraction Methods from Textual Artifacts",
    "abstract": "The cyberthreat landscape is continuously evolving. Hence, continuous\nmonitoring and sharing of threat intelligence have become a priority for\norganizations. Threat reports, published by cybersecurity vendors, contain\ndetailed descriptions of attack Tactics, Techniques, and Procedures (TTP)\nwritten in an unstructured text format. Extracting TTP from these reports aids\ncybersecurity practitioners and researchers learn and adapt to evolving attacks\nand in planning threat mitigation. Researchers have proposed TTP extraction\nmethods in the literature, however, not all of these proposed methods are\ncompared to one another or to a baseline. \\textit{The goal of this study is to\naid cybersecurity researchers and practitioners choose attack technique\nextraction methods for monitoring and sharing threat intelligence by comparing\nthe underlying methods from the TTP extraction studies in the literature.} In\nthis work, we identify ten existing TTP extraction studies from the literature\nand implement five methods from the ten studies. We find two methods, based on\nTerm Frequency-Inverse Document Frequency(TFIDF) and Latent Semantic Indexing\n(LSI), outperform the other three methods with a F1 score of 84\\% and 83\\%,\nrespectively. We observe the performance of all methods in F1 score drops in\nthe case of increasing the class labels exponentially. We also implement and\nevaluate an oversampling strategy to mitigate class imbalance issues.\nFurthermore, oversampling improves the classification performance of TTP\nextraction. We provide recommendations from our findings for future\ncybersecurity researchers, such as the construction of a benchmark dataset from\na large corpus; and the selection of textual features of TTP. Our work, along\nwith the dataset and implementation source code, can work as a baseline for\ncybersecurity researchers to test and compare the performance of future TTP\nextraction methods.",
    "descriptor": "",
    "authors": [
      "Md Rayhanur Rahman",
      "Laurie Williams"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02601"
  },
  {
    "id": "arXiv:2210.02602",
    "title": "Convergence rates of the Kaczmarz-Tanabe method for linear systems",
    "abstract": "In this paper, we investigate the Kaczmarz-Tanabe method for exact and\ninexact linear systems. The Kaczmarz-Tanabe method is derived from the Kaczmarz\nmethod, but is more stable than that. We analyze the convergence and the\nconvergence rate of the Kaczmarz-Tanabe method based on the singular value\ndecomposition theory, and discover two important factors, i.e., the second\nmaximum singular value of $Q$ and the minimum non-zero singular value of $A$,\nthat influence the convergence speed and the amplitude of fluctuation of the\nKaczmarz-Tanabe method (even for the Kaczmarz method). Numerical tests verify\nthe theoretical results of the Kaczmarz-Tanabe method.",
    "descriptor": "",
    "authors": [
      "Chuan-gang Kang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02602"
  },
  {
    "id": "arXiv:2210.02607",
    "title": "Transferring dense object detection models to event-based data",
    "abstract": "Event-based image representations are fundamentally different to traditional\ndense images. This poses a challenge to apply current state-of-the-art models\nfor object detection as they are designed for dense images. In this work we\nevaluate the YOLO object detection model on event data. To this end we replace\ndense-convolution layers by either sparse convolutions or asynchronous sparse\nconvolutions which enables direct processing of event-based images and compare\nthe performance and runtime to feeding event-histograms into\ndense-convolutions. Here, hyper-parameters are shared across all variants to\nisolate the effect sparse-representation has on detection performance.\nAt this, we show that current sparse-convolution implementations cannot\ntranslate their theoretical lower computation requirements into an improved\nruntime.",
    "descriptor": "",
    "authors": [
      "Vincenz Mechler",
      "Pavel Rojtberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02607"
  },
  {
    "id": "arXiv:2210.02611",
    "title": "$(1-\u03b5)$-approximate fully dynamic densest subgraph: linear space  and faster update time",
    "abstract": "We consider the problem of maintaining a $(1-\\epsilon)$-approximation to the\ndensest subgraph (DSG) in an undirected multigraph as it undergoes edge\ninsertions and deletions (the fully dynamic setting). Sawlani and Wang [SW20]\ndeveloped a data structure that, for any given $\\epsilon > 0$, maintains a\n$(1-\\epsilon)$-approximation with $O(\\log^4 n/\\epsilon^6)$ worst-case update\ntime for edge operations, and $O(1)$ query time for reporting the density\nvalue. Their data structure was the first to achieve near-optimal\napproximation, and improved previous work that maintained a $(1/4 - \\epsilon)$\napproximation in amortized polylogarithmic update time [BHNT15]. In this paper\nwe develop a data structure for $(1-\\epsilon)$-approximate DSG that improves\nthe one from [SW20] in two aspects. First, the data structure uses linear space\nimproving the space bound in [SW20] by a logarithmic factor. Second, the data\nstructure maintains a $(1-\\epsilon)$-approximation in amortized $O(\\log^2\nn/\\epsilon^4)$ time per update while simultaneously guaranteeing that the worst\ncase update time is $O(\\log^3 n \\log \\log n/\\epsilon^6)$. We believe that the\nspace and update time improvements are valuable for current large scale graph\ndata sets. The data structure extends in a natural fashion to hypergraphs and\nyields improvements in space and update times over recent work [BBCG22] that\nbuilds upon [SW20].",
    "descriptor": "",
    "authors": [
      "Chandra Chekuri",
      "Kent Quanrud"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02611"
  },
  {
    "id": "arXiv:2210.02612",
    "title": "Lyapunov Function Consistent Adaptive Network Signal Control with Back  Pressure and Reinforcement Learning",
    "abstract": "This research studies the network traffic signal control problem. It uses the\nLyapunov control function to derive the back pressure method, which is equal to\ndifferential queue lengths weighted by intersection lane flows. Lyapunov\ncontrol theory is a platform that unifies several current theories for\nintersection signal control. We further use the theorem to derive the\nflow-based and other pressure-based signal control algorithms. For example, the\nDynamic, Optimal, Real-time Algorithm for Signals (DORAS) algorithm may be\nderived by defining the Lyapunov function as the sum of queue length. The study\nthen utilizes the back pressure as a reward in the reinforcement learning (RL)\nbased network signal control, whose agent is trained with double Deep Q-Network\n(Double-DQN). The proposed algorithm is compared with several traditional and\nRL-based methods under passenger traffic flow and mixed flow with freight\ntraffic, respectively. The numerical tests are conducted on a single corridor\nand on a local grid network under three traffic demand scenarios of low,\nmedium, and heavy traffic, respectively. The numerical simulation demonstrates\nthat the proposed algorithm outperforms the others in terms of the average\nvehicle waiting time on the network.",
    "descriptor": "",
    "authors": [
      "Chaolun Ma",
      "Bruce Wang",
      "Zihao Li",
      "Ahmadreza Mahmoudzadeh",
      "Yunlong Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02612"
  },
  {
    "id": "arXiv:2210.02614",
    "title": "Federated Learning with Server Learning: Enhancing Performance for  Non-IID Data",
    "abstract": "Federated learning (FL) has become a popular means for distributed learning\nat clients using local data samples. However, recent studies have shown that FL\nmay experience slow learning and poor performance when client data are not\nindependent and identically distributed (IID). This paper proposes a new\nfederated learning algorithm, where the central server has access to a small\ndataset, learns from it, and fuses the knowledge into the global model through\nthe federated learning process. This new approach, referred to as Federated\nlearning with Server Learning or FSL, is complementary to and can be combined\nwith other FL learning algorithms. We prove the convergence of FSL and\ndemonstrate its benefits through analysis and simulations. We also reveal an\ninherent trade-off: when the current model is far from any local minimizer,\nserver learning can significantly improve and accelerate FL. On the other hand,\nwhen the model is close to a local minimizer, server learning could potentially\naffect the convergence neighborhood of FL due to variances in the estimated\ngradient used by the server. We show via simulations that such trade-off can be\ntuned easily to provide significant benefits, even when the server dataset is\nvery small.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Van Sy Mai",
      "Richard J. La",
      "Tao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02614"
  },
  {
    "id": "arXiv:2210.02615",
    "title": "Learning to Reason With Relational Abstractions",
    "abstract": "Large language models have recently shown promising progress in mathematical\nreasoning when fine-tuned with human-generated sequences walking through a\nsequence of solution steps. However, the solution sequences are not formally\nstructured and the resulting model-generated sequences may not reflect the kind\nof systematic reasoning we might expect an expert human to produce. In this\npaper, we study how to build stronger reasoning capability in language models\nusing the idea of relational abstractions. We introduce new types of sequences\nthat more explicitly provide an abstract characterization of the transitions\nthrough intermediate solution steps to the goal state. We find that models that\nare supplied with such sequences as prompts can solve tasks with a\nsignificantly higher accuracy, and models that are trained to produce such\nsequences solve problems better than those that are trained with previously\nused human-generated sequences and other baselines. Our work thus takes several\nsteps toward elucidating and improving how language models perform on tasks\nrequiring multi-step mathematical reasoning.",
    "descriptor": "",
    "authors": [
      "Andrew J. Nam",
      "Mengye Ren",
      "Chelsea Finn",
      "James L. McClelland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02615"
  },
  {
    "id": "arXiv:2210.02616",
    "title": "Digital Twin-Empowered Network Planning for Multi-Tier Computing",
    "abstract": "In this paper, we design a resource management scheme to support stateful\napplications, which will be prevalent in 6G networks. Different from stateless\napplications, stateful applications require context data while executing\ncomputing tasks from user terminals (UTs). Using a multi-tier computing\nparadigm with servers deployed at the core network, gateways, and base stations\nto support stateful applications, we aim to optimize long-term resource\nreservation by jointly minimizing the usage of computing, storage, and\ncommunication resources and the cost from reconfiguring resource reservation.\nThe coupling among different resources and the impact of UT mobility create\nchallenges in resource management. To address the challenges, we develop\ndigital twin (DT) empowered network planning with two elements, i.e.,\nmulti-resource reservation and resource reservation reconfiguration. First, DTs\nare designed for collecting UT status data, based on which UTs are grouped\naccording to their mobility patterns. Second, an algorithm is proposed to\ncustomize resource reservation for different groups to satisfy their different\nresource demands. Last, a Meta-learning-based approach is developed to\nreconfigure resource reservation for balancing the network resource usage and\nthe reconfiguration cost. Simulation results demonstrate that the proposed\nDT-empowered network planning outperforms benchmark frameworks by using less\nresources and incurring lower reconfiguration costs.",
    "descriptor": "\nComments: accepted by the Journal of Communications and Information Networks\n",
    "authors": [
      "Conghao Zhou",
      "Jie Gao",
      "Mushu Li",
      "Xuemin",
      "Shen",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02616"
  },
  {
    "id": "arXiv:2210.02617",
    "title": "Generalization Properties of Retrieval-based Models",
    "abstract": "Many modern high-performing machine learning models such as GPT-3 primarily\nrely on scaling up models, e.g., transformer networks. Simultaneously, a\nparallel line of work aims to improve the model performance by augmenting an\ninput instance with other (labeled) instances during inference. Examples of\nsuch augmentations include task-specific prompts and similar examples retrieved\nfrom the training data by a nonparametric component. Remarkably,\nretrieval-based methods have enjoyed success on a wide range of problems,\nranging from standard natural language processing and vision tasks to protein\nfolding, as demonstrated by many recent efforts, including WebGPT and\nAlphaFold. Despite growing literature showcasing the promise of these models,\nthe theoretical underpinning for such models remains underexplored. In this\npaper, we present a formal treatment of retrieval-based models to characterize\ntheir generalization ability. In particular, we focus on two classes of\nretrieval-based classification approaches: First, we analyze a local learning\nframework that employs an explicit local empirical risk minimization based on\nretrieved examples for each input instance. Interestingly, we show that\nbreaking down the underlying learning task into local sub-tasks enables the\nmodel to employ a low complexity parametric component to ensure good overall\naccuracy. The second class of retrieval-based approaches we explore learns a\nglobal model using kernel methods to directly map an input instance and\nretrieved examples to a prediction, without explicitly solving a local learning\ntask.",
    "descriptor": "",
    "authors": [
      "Soumya Basu",
      "Ankit Singh Rawat",
      "Manzil Zaheer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02617"
  },
  {
    "id": "arXiv:2210.02618",
    "title": "Dynamic Stochastic Ensemble with Adversarial Robust Lottery Ticket  Subnetworks",
    "abstract": "Adversarial attacks are considered the intrinsic vulnerability of CNNs.\nDefense strategies designed for attacks have been stuck in the adversarial\nattack-defense arms race, reflecting the imbalance between attack and defense.\nDynamic Defense Framework (DDF) recently changed the passive safety status quo\nbased on the stochastic ensemble model. The diversity of subnetworks, an\nessential concern in the DDF, can be effectively evaluated by the adversarial\ntransferability between different networks. Inspired by the poor adversarial\ntransferability between subnetworks of scratch tickets with various remaining\nratios, we propose a method to realize the dynamic stochastic ensemble defense\nstrategy. We discover the adversarial transferable diversity between robust\nlottery ticket subnetworks drawn from different basic structures and sparsity.\nThe experimental results suggest that our method achieves better robust and\nclean recognition accuracy by adversarial transferable diversity, which would\ndecrease the reliability of attacks.",
    "descriptor": "",
    "authors": [
      "Qi Peng",
      "Wenlin Liu",
      "Ruoxi Qin",
      "Libin Hou",
      "Bin Yan",
      "Linyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02618"
  },
  {
    "id": "arXiv:2210.02620",
    "title": "Inference Latency Prediction at the Edge",
    "abstract": "With the growing workload of inference tasks on mobile devices,\nstate-of-the-art neural architectures (NAs) are typically designed through\nNeural Architecture Search (NAS) to identify NAs with good tradeoffs between\naccuracy and efficiency (e.g., latency). Since measuring the latency of a huge\nset of candidate architectures during NAS is not scalable, approaches are\nneeded for predicting end-to-end inference latency on mobile devices. Such\npredictions are challenging due to hardware heterogeneity, optimizations\napplied by ML frameworks, and the diversity of neural architectures. Motivated\nby these challenges, in this paper, we first quantitatively assess\ncharacteristics of neural architectures and mobile devices that have\nsignificant effects on inference latency. Based on this assessment, we propose\na latency prediction framework which addresses these challenges by developing\noperation-wise latency predictors, under a variety of settings and a number of\nhardware devices, with multi-core CPUs and GPUs, achieving high accuracy in\nend-to-end latency prediction, as shown by our comprehensive evaluations. To\nillustrate that our approach does not require expensive data collection, we\nalso show that accurate predictions can be achieved on real-world NAs using\nonly small amounts of profiling data.",
    "descriptor": "",
    "authors": [
      "Zhuojin Li",
      "Marco Paolieri",
      "Leana Golubchik"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02620"
  },
  {
    "id": "arXiv:2210.02621",
    "title": "U3E: Unsupervised and Erasure-based Evidence Extraction for Machine  Reading Comprehension",
    "abstract": "More tasks in Machine Reading Comprehension(MRC) require, in addition to\nanswer prediction, the extraction of evidence sentences that support the\nanswer. However, the annotation of supporting evidence sentences is usually\ntime-consuming and labor-intensive. In this paper, to address this issue and\nconsidering that most of the existing extraction methods are semi-supervised,\nwe propose an unsupervised evidence extraction method (U3E). U3E takes the\nchanges after sentence-level feature erasure in the document as input,\nsimulating the decline in problem-solving ability caused by human memory\ndecline. In order to make selections on the basis of fully understanding the\nsemantics of the original text, we also propose metrics to quickly select the\noptimal memory model for this input changes. To compare U3E with typical\nevidence extraction methods and investigate its effectiveness in evidence\nextraction, we conduct experiments on different datasets. Experimental results\nshow that U3E is simple but effective, not only extracting evidence more\naccurately, but also significantly improving model performance.",
    "descriptor": "",
    "authors": [
      "Suzhe He",
      "Shumin Shi",
      "Chenghao Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02621"
  },
  {
    "id": "arXiv:2210.02622",
    "title": "Training Diverse High-Dimensional Controllers by Scaling Covariance  Matrix Adaptation MAP-Annealing",
    "abstract": "Pre-training a diverse set of robot controllers in simulation has enabled\nrobots to adapt online to damage in robot locomotion tasks. However, finding\ndiverse, high-performing controllers requires specialized hardware and\nextensive tuning of a large number of hyperparameters. On the other hand, the\nCovariance Matrix Adaptation MAP-Annealing algorithm, an evolution strategies\n(ES)-based quality diversity algorithm, does not have these limitations and has\nbeen shown to achieve state-of-the-art performance in standard benchmark\ndomains. However, CMA-MAE cannot scale to modern neural network controllers due\nto its quadratic complexity. We leverage efficient approximation methods in ES\nto propose three new CMA-MAE variants that scale to very high dimensions. Our\nexperiments show that the variants outperform ES-based baselines in benchmark\nrobotic locomotion tasks, while being comparable with state-of-the-art deep\nreinforcement learning-based quality diversity algorithms. Source code and\nvideos are available at https://scalingcmamae.github.io",
    "descriptor": "",
    "authors": [
      "Bryon Tjanaka",
      "Matthew C. Fontaine",
      "Aniruddha Kalkar",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.02622"
  },
  {
    "id": "arXiv:2210.02623",
    "title": "TensorAnalyzer: Identification of Urban Patterns in Big Cities using  Non-Negative Tensor Factorization",
    "abstract": "Extracting relevant urban patterns from multiple data sources can be\ndifficult using classical clustering algorithms since we have to make a\nsuitable setup of the hyperparameters of the algorithms and deal with outliers.\nIt should be addressed correctly to help urban planners in the decision-making\nprocess for the further development of a big city. For instance, experts' main\ninterest in criminology is comprehending the relationship between crimes and\nthe socio-economic characteristics at specific georeferenced locations. In\naddition, the classical clustering algorithms take little notice of the\nintricate spatial correlations in georeferenced data sources. This paper\npresents a new approach to detecting the most relevant urban patterns from\nmultiple data sources based on tensor decomposition. Compared to classical\nmethods, the proposed approach's performance is attested to validate the\nidentified patterns' quality. The result indicates that the approach can\neffectively identify functional patterns to characterize the data set for\nfurther analysis in achieving good clustering quality. Furthermore, we\ndeveloped a generic framework named TensorAnalyzer, where the effectiveness and\nusefulness of the proposed methodology are tested by a set of experiments and a\nreal-world case study showing the relationship between the crime events around\nschools and students performance and other variables involved in the analysis.",
    "descriptor": "",
    "authors": [
      "Jaqueline Silveira",
      "Germain Garc\u00eda",
      "Afonso Paiva",
      "Marcelo Nery",
      "Sergio Adorno",
      "Luis Gustavo Nonato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02623"
  },
  {
    "id": "arXiv:2210.02627",
    "title": "Improving the Domain Adaptation of Retrieval Augmented Generation (RAG)  Models for Open Domain Question Answering",
    "abstract": "Retrieval Augment Generation (RAG) is a recent advancement in Open-Domain\nQuestion Answering (ODQA). RAG has only been trained and explored with a\nWikipedia-based external knowledge base and is not optimized for use in other\nspecialized domains such as healthcare and news. In this paper, we evaluate the\nimpact of joint training of the retriever and generator components of RAG for\nthe task of domain adaptation in ODQA. We propose \\textit{RAG-end2end}, an\nextension to RAG, that can adapt to a domain-specific knowledge base by\nupdating all components of the external knowledge base during training. In\naddition, we introduce an auxiliary training signal to inject more\ndomain-specific knowledge. This auxiliary signal forces \\textit{RAG-end2end} to\nreconstruct a given sentence by accessing the relevant information from the\nexternal knowledge base. Our novel contribution is unlike RAG, RAG-end2end does\njoint training of the retriever and generator for the end QA task and domain\nadaptation. We evaluate our approach with datasets from three domains:\nCOVID-19, News, and Conversations, and achieve significant performance\nimprovements compared to the original RAG model. Our work has been open-sourced\nthrough the Huggingface Transformers library, attesting to our work's\ncredibility and technical consistency.",
    "descriptor": "\nComments: This paper is awaiting publication at Transactions of the Association for Computational Linguistics. This is a pre-MIT Press publication version. For associated huggingface transformers code, see this https URL\n",
    "authors": [
      "Shamane Siriwardhana",
      "Rivindu Weerasekera",
      "Elliott Wen",
      "Tharindu Kaluarachchi",
      "Rajib Rana",
      "Suranga Nanayakkara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.02627"
  },
  {
    "id": "arXiv:2210.02628",
    "title": "Cooperative Coverage with a Leader and a Wingmate in  Communication-Constrained Environments",
    "abstract": "We consider a mission framework in which two unmanned vehicles (UVs), a\nleader and a wingmate, are required to provide cooperative coverage of an\nenvironment while being within a short communication range. This framework\nfinds applications in underwater and/or military domains, where certain\nconstraints are imposed on communication by either the application or the\nenvironment. An important objective of missions within this framework is to\nminimize the total travel and communication costs of the leader-wingmate duo.\nIn this paper, we propose and formulate the problem of finding routes for the\nUVs that minimize the sum of their travel and communication costs as a network\noptimization problem of the form of a binary program (BP). The BP is\ncomputationally expensive, with the time required to compute optimal solutions\nincreasing rapidly with the problem size. To address this challenge, here, we\npropose two algorithms, an approximation algorithm and a heuristic algorithm,\nto solve large-scale instances of the problem swiftly. We demonstrate the\neffectiveness and the scalability of these algorithms through an analysis of\nextensive numerical simulations performed over 500 instances, with the number\nof targets in the instances ranging from 6 to 100.",
    "descriptor": "",
    "authors": [
      "Sai Krishna Kanth Hari",
      "Sivakumar Rathinam",
      "Swaroop Darbha",
      "David W. Casbeer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02628"
  },
  {
    "id": "arXiv:2210.02630",
    "title": "MechRetro is a chemical-mechanism-driven graph learning framework for  interpretable retrosynthesis prediction and pathway planning",
    "abstract": "Leveraging artificial intelligence for automatic retrosynthesis speeds up\norganic pathway planning in digital laboratories. However, existing deep\nlearning approaches are unexplainable, like \"black box\" with few insights,\nnotably limiting their applications in real retrosynthesis scenarios. Here, we\npropose MechRetro, a chemical-mechanism-driven graph learning framework for\ninterpretable retrosynthetic prediction and pathway planning, which learns\nseveral retrosynthetic actions to simulate a reverse reaction via elaborate\nself-adaptive joint learning. By integrating chemical knowledge as prior\ninformation, we design a novel Graph Transformer architecture to adaptively\nlearn discriminative and chemically meaningful molecule representations,\nhighlighting the strong capacity in molecule feature representation learning.\nWe demonstrate that MechRetro outperforms the state-of-the-art approaches for\nretrosynthetic prediction with a large margin on large-scale benchmark\ndatasets. Extending MechRetro to the multi-step retrosynthesis analysis, we\nidentify efficient synthetic routes via an interpretable reasoning mechanism,\nleading to a better understanding in the realm of knowledgeable synthetic\nchemists. We also showcase that MechRetro discovers a novel pathway for\nprotokylol, along with energy scores for uncertainty assessment, broadening the\napplicability for practical scenarios. Overall, we expect MechRetro to provide\nmeaningful insights for high-throughput automated organic synthesis in drug\ndiscovery.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Chao Pang",
      "Yuzhe Wang",
      "Yi Jiang",
      "Junru Jin",
      "Sirui Liang",
      "Quan Zou",
      "Leyi Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.02630"
  },
  {
    "id": "arXiv:2210.02631",
    "title": "Data-driven Approaches to Surrogate Machine Learning Model Development",
    "abstract": "We demonstrate the adaption of three established methods to the field of\nsurrogate machine learning model development. These methods are data\naugmentation, custom loss functions and transfer learning. Each of these\nmethods have seen widespread use in the field of machine learning, however,\nhere we apply them specifically to surrogate machine learning model\ndevelopment. The machine learning model that forms the basis behind this work\nwas intended to surrogate a traditional engineering model used in the UK\nnuclear industry. Previous performance of this model has been hampered by poor\nperformance due to limited training data. Here, we demonstrate that through a\ncombination of additional techniques, model performance can be significantly\nimproved. We show that each of the aforementioned techniques have utility in\ntheir own right and in combination with one another. However, we see them best\napplied as part of a transfer learning operation. Five pre-trained surrogate\nmodels produced prior to this research were further trained with an augmented\ndataset and with our custom loss function. Through the combination of all three\ntechniques, we see a significant improvement in model performance.",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "H. Rhys Jones",
      "Tingting Mu",
      "Andrei C. Popescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02631"
  },
  {
    "id": "arXiv:2210.02636",
    "title": "Geodesic Graph Neural Network for Efficient Graph Representation  Learning",
    "abstract": "Recently, Graph Neural Networks (GNNs) have been applied to graph learning\ntasks and achieved state-of-the-art results. However, many competitive methods\nemploy preprocessing on the target nodes, such as subgraph extraction and\ncustomized labeling, to capture some information that is hard to be learned by\nnormal GNNs. Such operations are time-consuming and do not scale to large\ngraphs. In this paper, we propose an efficient GNN framework called Geodesic\nGNN (GDGNN). It injects conditional relationships between nodes into the model\nwithout labeling. Specifically, we view the shortest paths between two nodes as\nthe spatial graph context of the neighborhood around them. The GNN embeddings\nof nodes on the shortest paths are used to generate geodesic representations.\nConditioned on the geodesic representations, GDGNN is able to generate node,\nlink, and graph representations that carry much richer structural information\nthan plain GNNs. We theoretically prove that GDGNN is more powerful than plain\nGNNs, and present experimental results to show that GDGNN achieves highly\ncompetitive performance with state-of-the-art GNN models on link prediction and\ngraph classification tasks while taking significantly less time.",
    "descriptor": "",
    "authors": [
      "Lecheng Kong",
      "Yixin Chen",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02636"
  },
  {
    "id": "arXiv:2210.02637",
    "title": "IR2Net: Information Restriction and Information Recovery for Accurate  Binary Neural Networks",
    "abstract": "Weight and activation binarization can efficiently compress deep neural\nnetworks and accelerate model inference, but cause severe accuracy degradation.\nExisting optimization methods for binary neural networks (BNNs) focus on\nfitting full-precision networks to reduce quantization errors, and suffer from\nthe trade-off between accuracy and computational complexity. In contrast,\nconsidering the limited learning ability and information loss caused by the\nlimited representational capability of BNNs, we propose IR$^2$Net to stimulate\nthe potential of BNNs and improve the network accuracy by restricting the input\ninformation and recovering the feature information, including: 1) information\nrestriction: for a BNN, by evaluating the learning ability on the input\ninformation, discarding some of the information it cannot focus on, and\nlimiting the amount of input information to match its learning ability; 2)\ninformation recovery: due to the information loss in forward propagation, the\noutput feature information of the network is not enough to support accurate\nclassification. By selecting some shallow feature maps with richer information,\nand fusing them with the final feature maps to recover the feature information.\nIn addition, the computational cost is reduced by streamlining the information\nrecovery method to strike a better trade-off between accuracy and efficiency.\nExperimental results demonstrate that our approach still achieves comparable\naccuracy even with $ \\sim $10x floating-point operations (FLOPs) reduction for\nResNet-18. The models and code are available at\nhttps://github.com/pingxue-hfut/IR2Net.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Ping Xue",
      "Yang Lu",
      "Jingfei Chang",
      "Xing Wei",
      "Zhen Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02637"
  },
  {
    "id": "arXiv:2210.02638",
    "title": "What Can We Compute in a Single Round of the Congested Clique?",
    "abstract": "We study the computational power of one-round distributed algorithms in the\ncongested clique model. We show that any one-round algorithm that computes a\nminimum spanning tree (MST) in the unicast congested clique must use a link\nbandwidth of $\\Omega(\\log^3 n)$ bits in the worst case. This is the first round\ncomplexity lower bound in the unicast congested clique for a problem where the\noutput size is small, i.e., $O(n\\log n)$ bits. Our main technical contribution\nis to investigate one-round algorithms in the broadcast congested clique and,\nequivalently, the distributed graph sketching model where the nodes send their\nmessage to a referee who computes the output. First, we present a tight lower\nbound of $\\Omega(n)$ bits for the message size of computing a breadth-first\nsearch tree. Then, we prove that computing a $k$-edge connected spanning\nsubgraph ($k$-ECSS) requires messages of size at least $\\Omega \\left(\nk\\log^2(n/k) \\right)$. We also show that verifying whether a given vertex\ncoloring forms a weak 2-coloring of the input graph requires messages of\n$\\Omega(n^{1/3}\\log^{2/3}n)$ bits, and the same lower bound holds for verifying\nwhether a subset of nodes forms a maximal independent set or a minimal\ndominating set. Interestingly, it turns out that the same class of lower bound\ngraphs for the distributed sketching model is versatile enough to yield a space\nlower bound of $\\Omega(n^2)$ bits for verifying symmetry breaking problems such\nas weak $2$-coloring in the fully dynamic turnstile model, where the input\narrives as a stream of edges. We also (nearly) settle the space complexity of\nthe $k$-ECSS problem in the streaming model by extending the work of Kapralov\net al. (FOCS 2017): We prove a communication complexity lower bound for a\ndirect sum variant of the $\\text{UR}_k^{\\subset}$ problem and show that this\nimplies $\\Omega(k\\,n\\log^2(n/k))$ bits of memory for computing a $k$-ECSS.",
    "descriptor": "",
    "authors": [
      "Peter Robinson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02638"
  },
  {
    "id": "arXiv:2210.02640",
    "title": "ForestQB: An Adaptive Query Builder to Support Wildlife Research",
    "abstract": "This paper presents ForestQB, a SPARQL query builder, to assist Bioscience\nand Wildlife Researchers in accessing Linked-Data. As they are unfamiliar with\nthe Semantic Web and the data ontologies, ForestQB aims to empower them to\nbenefit from using Linked-Data to extract valuable information without having\nto grasp the nature of the data and its underlying technologies. ForestQB is\nintegrating Form-Based Query builders with Natural Language to simplify query\nconstruction to match the user requirements. Demo available at\nhttps://iotgarage.net/demo/forestQB",
    "descriptor": "\nComments: In Proceedings of the 12th International Semantic Web Conference (Posters & Demonstrations Track), 2022\n",
    "authors": [
      "Omar Mussa",
      "Omer Rana",
      "Beno\u00eet Goossens",
      "Pablo Orozco-terWengel",
      "Charith Perera"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.02640"
  },
  {
    "id": "arXiv:2210.02642",
    "title": "Feasibility on Detecting Door Slamming towards Monitoring Early Signs of  Domestic Violence",
    "abstract": "By using low-cost microcontrollers and TinyML, we investigate the feasibility\nof detecting potential early warning signs of domestic violence and other\nanti-social behaviors within the home. We created a machine learning model to\ndetermine if a door was closed aggressively by analyzing audio data and feeding\nthis into a convolutional neural network to classify the sample. Under test\nconditions, with no background noise, accuracy of 88.89\\% was achieved,\ndeclining to 87.50\\% when assorted background noises were mixed in at a\nrelative volume of 0.5 times that of the sample. The model is then deployed on\nan Arduino Nano BLE 33 Sense attached to the door, and only begins sampling\nonce an acceleration greater than a predefined threshold acceleration is\ndetected. The predictions made by the model can then be sent via BLE to another\ndevice, such as a smartphone of Raspberry Pi.",
    "descriptor": "\nComments: In Proceedings of the 2022 IEEE/ACM Seventh International Conference on Internet-of-Things Design and Implementation (IoTDI) 2022\n",
    "authors": [
      "Osian Morgan",
      "Hakan Kayan",
      "Charith Perera"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02642"
  },
  {
    "id": "arXiv:2210.02643",
    "title": "Automatic Scene-based Topic Channel Construction System for E-Commerce",
    "abstract": "Scene marketing that well demonstrates user interests within a certain\nscenario has proved effective for offline shopping. To conduct scene marketing\nfor e-commerce platforms, this work presents a novel product form, scene-based\ntopic channel which typically consists of a list of diverse products belonging\nto the same usage scenario and a topic title that describes the scenario with\nmarketing words. As manual construction of channels is time-consuming due to\nbillions of products as well as dynamic and diverse customers' interests, it is\nnecessary to leverage AI techniques to automatically construct channels for\ncertain usage scenarios and even discover novel topics. To be specific, we\nfirst frame the channel construction task as a two-step problem, i.e.,\nscene-based topic generation and product clustering, and propose an E-commerce\nScene-based Topic Channel construction system (i.e., ESTC) to achieve automated\nproduction, consisting of scene-based topic generation model for the e-commerce\ndomain, product clustering on the basis of topic similarity, as well as quality\ncontrol based on automatic model filtering and human screening. Extensive\noffline experiments and online A/B test validates the effectiveness of such a\nnovel product form as well as the proposed system. In addition, we also\nintroduce the experience of deploying the proposed system on a real-world\ne-commerce recommendation platform.",
    "descriptor": "",
    "authors": [
      "Peng Lin",
      "Yanyan Zou",
      "Lingfei Wu",
      "Mian Ma",
      "Zhuoye Ding",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02643"
  },
  {
    "id": "arXiv:2210.02648",
    "title": "Self-triggered Consensus of Multi-agent Systems with Quantized Relative  State Measurements",
    "abstract": "This paper addresses the consensus problem of first-order continuous-time\nmulti-agent systems over undirected graphs. Each agent samples relative state\nmeasurements in a self-triggered fashion and broadcasts the sum of the\nmeasurements to its neighbors. Moreover, finite-level dynamic quantizers with\nzooming-in capability is applied to the measurements. The proposed joint design\nmethod of quantization and self-triggered sampling achieves asymptotic\nconsensus without Zeno behaviors. Sampling times are determined explicitly with\niterative procedures including the computation of the Lambert function. We\nintroduce a new semi-norm for the consensus analysis of multi-agent systems. A\nsimulation example is provided to illustrate the effectiveness of the proposed\nprotocol.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Masashi Wakaiki"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02648"
  },
  {
    "id": "arXiv:2210.02650",
    "title": "PrivacyCube: A Tangible Device for Improving Privacy Awareness in IoT",
    "abstract": "Consumers increasingly bring IoT devices into their living spaces without\nunderstanding how their data is collected, processed, and used. We present\nPrivacyCube, a novel tangible device designed to explore the extent to which\nprivacy awareness in smart homes can be elevated. PrivacyCube visualises IoT\ndevices' data consumption displaying privacy-related notices. PrivacyCube aims\nat assisting families to (i) understand key privacy aspects better and (ii)\nhave conversations around data management practices of IoT devices. Thus,\nfamilies can learn and make informed privacy decisions collectively.",
    "descriptor": "\nComments: In Proceedings of the 2022 IEEE/ACM Seventh International Conference on Internet-of-Things Design and Implementation (IoTDI) 2022\n",
    "authors": [
      "Bayan Al Muhander",
      "Omer Rana",
      "Nalin Arachchilage",
      "Charith Perera"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02650"
  },
  {
    "id": "arXiv:2210.02651",
    "title": "Tracking the Evolution of Static Code Warnings: the State-of-the-Art and  a Better Approach",
    "abstract": "Static bug detection tools help developers detect problems in the code,\nincluding bad programming practices and potential defects. However, it is known\nthat static bug detectors remain underutilized due to various reasons. Recent\nadvances to incorporate static bug detectors in modern software development\nworkflows, such as in code review and continuous integration, are shown capable\nof better motivating developers to fix the reported warnings on the fly.\nMoreover, tracking the static code warnings will benefit many downstream\nsoftware engineering tasks, such as learning the fix patterns for automated\nprogram repair and learning which warnings are of more interest, so they can be\nprioritized automatically. Hence, precisely tracking the warnings by static bug\ndetectors is critical to improve the utilization of static bug detectors\nfurther.\nIn this paper, we study the effectiveness of the state-of-the-art (SOA)\nsolution in tracking the warnings by static bug detectors and propose a better\nsolution based on our analysis of the insufficiencies of the SOA solution. In\nparticular, we examined over 2000 commits in four large-scale open-source\nsystems (i.e., JClouds, Kafka, Spring-boot, and Guava) and crafted a dataset of\n3,452 static code warnings by two static bug detectors (i.e., Spotbugs and\nPMD). We manually uncover the ground-truth evolution status of the static\nwarnings: persistent, resolved, or newly-introduced. Moreover, upon manual\nanalysis, we identified the main reasons behind the insufficiencies of the SOA\nsolution. Finally, we propose a better approach to improving the tracking of\nstatic warnings over software development history. Our evaluation shows that\nour proposed approach provides a significant improvement in terms of the\nprecision of the tracking, i.e., from 66.9% to 90.0%.",
    "descriptor": "",
    "authors": [
      "Junjie Li",
      "Jinqiu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.02651"
  },
  {
    "id": "arXiv:2210.02653",
    "title": "Stabilization-free serendipity virtual element method for plane  elasticity",
    "abstract": "We present a higher order stabilization-free virtual element method applied\nto plane elasticity problems. We utilize a serendipity approach to reduce the\ntotal number of degrees of freedom from the corresponding high-order\napproximations. The well-posedness of the problem is numerically studied via an\neigenanalysis. The method is then applied to several benchmark problems from\nlinear elasticity and we show that the method delivers optimal convergence\nrates in $L^2$ and energy seminorm that match theoretical estimates as well as\nthe convergence rates from higher order virtual element methods.",
    "descriptor": "\nComments: 23 pages, 17 figures. arXiv admin note: text overlap with arXiv:2202.10037\n",
    "authors": [
      "Alvin Chen",
      "N. Sukumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02653"
  },
  {
    "id": "arXiv:2210.02654",
    "title": "Learning Algorithms for Intelligent Agents and Mechanisms",
    "abstract": "In this thesis, we research learning algorithms for optimal decision making\nin two different contexts, Reinforcement Learning in Part I and Auction Design\nin Part II.\nReinforcement learning (RL) is an area of machine learning that is concerned\nwith how an agent should act in an environment in order to maximize its\ncumulative reward over time. In Chapter 2, inspired by statistical physics, we\ndevelop a novel approach to Reinforcement Learning (RL) that not only learns\noptimal policies with enhanced desirable properties but also sheds new light on\nmaximum entropy RL. In Chapter 3, we tackle the generalization problem in RL\nusing a Bayesian perspective. We show that imperfect knowledge of the\nenvironments dynamics effectively turn a fully-observed Markov Decision Process\n(MDP) into a Partially Observed MDP (POMDP) that we call the Epistemic POMDP.\nInformed by this observation, we develop a new policy learning algorithm LEEP\nwhich has improved generalization properties.\nDesigning an incentive compatible, individually rational auction that\nmaximizes revenue is a challenging and intractable problem. Recently, deep\nlearning based approaches have been proposed to learn optimal auctions from\ndata. While successful, this approach suffers from a few limitations, including\nsample inefficiency, lack of generalization to new auctions, and training\ndifficulties. In Chapter 4, we construct a symmetry preserving neural network\narchitecture, EquivariantNet, suitable for anonymous auctions. EquivariantNet\nis not only more sample efficient but is also able to learn auction rules that\ngeneralize well to other settings. In Chapter 5, we propose a novel formulation\nof the auction learning problem as a two player game. The resulting learning\nalgorithm, ALGNet, is easier to train, more reliable and better suited for non\nstationary settings.",
    "descriptor": "\nComments: PhD thesis (Princeton University, 2022)\n",
    "authors": [
      "Jad Rahme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02654"
  },
  {
    "id": "arXiv:2210.02655",
    "title": "Domain Generalization via Contrastive Causal Learning",
    "abstract": "Domain Generalization (DG) aims to learn a model that can generalize well to\nunseen target domains from a set of source domains. With the idea of invariant\ncausal mechanism, a lot of efforts have been put into learning robust causal\neffects which are determined by the object yet insensitive to the domain\nchanges. Despite the invariance of causal effects, they are difficult to be\nquantified and optimized. Inspired by the ability that humans adapt to new\nenvironments by prior knowledge, We develop a novel Contrastive Causal Model\n(CCM) to transfer unseen images to taught knowledge which are the features of\nseen images, and quantify the causal effects based on taught knowledge.\nConsidering the transfer is affected by domain shifts in DG, we propose a more\ninclusive causal graph to describe DG task. Based on this causal graph, CCM\ncontrols the domain factor to cut off excess causal paths and uses the\nremaining part to calculate the causal effects of images to labels via the\nfront-door criterion. Specifically, CCM is composed of three components: (i)\ndomain-conditioned supervised learning which teaches CCM the correlation\nbetween images and labels, (ii) causal effect learning which helps CCM measure\nthe true causal effects of images to labels, (iii) contrastive similarity\nlearning which clusters the features of images that belong to the same class\nand provides the quantification of similarity. Finally, we test the performance\nof CCM on multiple datasets including PACS, OfficeHome, and TerraIncognita. The\nextensive experiments demonstrate that CCM surpasses the previous DG methods\nwith clear margins.",
    "descriptor": "",
    "authors": [
      "Qiaowei Miao",
      "Junkun Yuan",
      "Kun Kuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02655"
  },
  {
    "id": "arXiv:2210.02656",
    "title": "Trust in Motion: Capturing Trust Ascendancy in Open-Source Projects  using Hybrid AI",
    "abstract": "Open-source is frequently described as a driver for unprecedented\ncommunication and collaboration, and the process works best when projects\nsupport teamwork. Yet, their cooperation processes in no way protect project\ncontributors from considerations of trust, power, and influence. Indeed,\nachieving the level of trust necessary to contribute to a project and thus\ninfluence its direction is a constant process of change, and developers take\nmany different routes over many communication channels to achieve it. We refer\nto this process of influence-seeking and trust-building, trust ascendancy.\nThis paper describes a methodology for understanding the notion of trust\nascendancy, and introduces the capabilities that are needed to localizing trust\nascendancy operations happening over open-source projects. Much of the prior\nwork in understanding trust in open-source software development has focused on\na static view of the problem, and study it using different forms of quantity\nmeasures. However, trust ascendancy is not static but rather adapt to changes\nin the open-source ecosystem in response to developer role changes, new\nfunctionality, new technologies, and so on. This paper is the first attempt to\narticulate and study these signals, from a dynamic view of the problem. In that\nrespect, we identify related work that may help illuminate research challenges,\nimplementation tradeoffs, and complementary solutions.\nOur preliminary results show the effectiveness of our method at capturing the\ntrust ascendancy developed by individuals involved in a well-documented 2020\nsocial engineering attack. Our future plans highlight research challenges, and\nencourage cross-disciplinary collaboration to create more automated, accurate,\nand efficient ways to modeling and then tracking trust ascendancy in\nopen-source projects.",
    "descriptor": "\nComments: 6 pages, 4 figures, two tables\n",
    "authors": [
      "Huascar Sanchez",
      "Briland Hitaj"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02656"
  },
  {
    "id": "arXiv:2210.02657",
    "title": "Predictive Edge Caching through Deep Mining of Sequential Patterns in  User Content Retrievals",
    "abstract": "Edge caching plays an increasingly important role in boosting user content\nretrieval performance while reducing redundant network traffic. The\neffectiveness of caching ultimately hinges on the accuracy of predicting\ncontent popularity in the near future. However, at the network edge, content\npopularity can be extremely dynamic due to diverse user content retrieval\nbehaviors and the low-degree of user multiplexing. It's challenging for the\ntraditional reactive caching systems to keep up with the dynamic content\npopularity patterns. In this paper, we propose a novel Predictive Edge Caching\n(PEC) system that predicts the future content popularity using fine-grained\nlearning models that mine sequential patterns in user content retrieval\nbehaviors, and opportunistically prefetches contents predicted to be popular in\nthe near future using idle network bandwidth. Through extensive experiments\ndriven by real content retrieval traces, we demonstrate that PEC can adapt to\nhighly dynamic content popularity, and significantly improve cache hit ratio\nand reduce user content retrieval latency over the state-of-art caching\npolicies. More broadly, our study demonstrates that edge caching performance\ncan be boosted by deep mining of user content retrieval behaviors.",
    "descriptor": "",
    "authors": [
      "Chen Li",
      "Xiaoyu Wang",
      "Tongyu Zong",
      "Houwei Cao",
      "Yong Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02657"
  },
  {
    "id": "arXiv:2210.02658",
    "title": "Learning functional sections in medical conversations: iterative  pseudo-labeling and human-in-the-loop approach",
    "abstract": "Medical conversations between patients and medical professionals have\nimplicit functional sections, such as \"history taking\", \"summarization\",\n\"education\", and \"care plan.\" In this work, we are interested in learning to\nautomatically extract these sections. A direct approach would require\ncollecting large amounts of expert annotations for this task, which is\ninherently costly due to the contextual inter-and-intra variability between\nthese sections. This paper presents an approach that tackles the problem of\nlearning to classify medical dialogue into functional sections without\nrequiring a large number of annotations. Our approach combines pseudo-labeling\nand human-in-the-loop. First, we bootstrap using weak supervision with\npseudo-labeling to generate dialogue turn-level pseudo-labels and train a\ntransformer-based model, which is then applied to individual sentences to\ncreate noisy sentence-level labels. Second, we iteratively refine\nsentence-level labels using a cluster-based human-in-the-loop approach. Each\niteration requires only a few dozen annotator decisions. We evaluate the\nresults on an expert-annotated dataset of 100 dialogues and find that while our\nmodels start with 69.5% accuracy, we can iteratively improve it to 82.5%. The\ncode used to perform all experiments described in this paper can be found here:\nhttps://github.com/curai/curai-research/functional-sections.",
    "descriptor": "",
    "authors": [
      "Mengqian Wang",
      "Ilya Valmianski",
      "Xavier Amatriain",
      "Anitha Kannan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02658"
  },
  {
    "id": "arXiv:2210.02659",
    "title": "Explainable Abuse Detection as Intent Classification and Slot Filling",
    "abstract": "To proactively offer social media users a safe online experience, there is a\nneed for systems that can detect harmful posts and promptly alert platform\nmoderators. In order to guarantee the enforcement of a consistent policy,\nmoderators are provided with detailed guidelines. In contrast, most\nstate-of-the-art models learn what abuse is from labelled examples and as a\nresult base their predictions on spurious cues, such as the presence of group\nidentifiers, which can be unreliable. In this work we introduce the concept of\npolicy-aware abuse detection, abandoning the unrealistic expectation that\nsystems can reliably learn which phenomena constitute abuse from inspecting the\ndata alone. We propose a machine-friendly representation of the policy that\nmoderators wish to enforce, by breaking it down into a collection of intents\nand slots. We collect and annotate a dataset of 3,535 English posts with such\nslots, and show how architectures for intent classification and slot filling\ncan be used for abuse detection, while providing a rationale for model\ndecisions.",
    "descriptor": "\nComments: 14 pages, 2 figures, to be published in TACL (pre-MIT Press publication version)\n",
    "authors": [
      "Agostina Calabrese",
      "Bj\u00f6rn Ross",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02659"
  },
  {
    "id": "arXiv:2210.02660",
    "title": "Representing Marginalized Populations: Challenges in Anthropographics",
    "abstract": "Anthropographics are human-shaped visualizations that have primarily been\nused within visualization research and data journalism to show humanitarian and\ndemographic data. However, anthropographics have typically been produced by a\nsmall group of designers, researchers, and journalists, and most use\nhomogeneous representations of marginalized populations-representations that\nmight have problematic implications for how viewers perceive the people they\nrepresent. In this paper, we use a critical lens to examine anthropographic\nvisualization practices in projects about marginalized populations. We present\ncritiques that identify three potential challenges related to the use of\nanthropographics and highlight possible unintended consequences-namely (1)\ncreating homogeneous depictions of marginalized populations, (2) treating\nmarginalization as an inclusion criteria, and (3) insufficiently\ncontextualizing datasets about marginalization. Finally, we highlight\nopportunities for anthropographics research, including the need to develop\ntechniques for representing demographic differences between marginalized\npopulations and for studies exploring other potential effects of\nanthropographics.",
    "descriptor": "",
    "authors": [
      "Priya Dhawka",
      "Helen Ai He",
      "Wesley Willett"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02660"
  },
  {
    "id": "arXiv:2210.02661",
    "title": "Topological Continual Learning with Wasserstein Distance and Barycenter",
    "abstract": "Continual learning in neural networks suffers from a phenomenon called\ncatastrophic forgetting, in which a network quickly forgets what was learned in\na previous task. The human brain, however, is able to continually learn new\ntasks and accumulate knowledge throughout life. Neuroscience findings suggest\nthat continual learning success in the human brain is potentially associated\nwith its modular structure and memory consolidation mechanisms. In this paper\nwe propose a novel topological regularization that penalizes cycle structure in\na neural network during training using principled theory from persistent\nhomology and optimal transport. The penalty encourages the network to learn\nmodular structure during training. The penalization is based on the closed-form\nexpressions of the Wasserstein distance and barycenter for the topological\nfeatures of a 1-skeleton representation for the network. Our topological\ncontinual learning method combines the proposed regularization with a tiny\nepisodic memory to mitigate forgetting. We demonstrate that our method is\neffective in both shallow and deep network architectures for multiple image\nclassification datasets.",
    "descriptor": "",
    "authors": [
      "Tananun Songdechakraiwut",
      "Xiaoshuang Yin",
      "Barry D. Van Veen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02661"
  },
  {
    "id": "arXiv:2210.02663",
    "title": "Towards Better Semantic Understanding of Mobile Interfaces",
    "abstract": "Improving the accessibility and automation capabilities of mobile devices can\nhave a significant positive impact on the daily lives of countless users. To\nstimulate research in this direction, we release a human-annotated dataset with\napproximately 500k unique annotations aimed at increasing the understanding of\nthe functionality of UI elements. This dataset augments images and view\nhierarchies from RICO, a large dataset of mobile UIs, with annotations for\nicons based on their shapes and semantics, and associations between different\nelements and their corresponding text labels, resulting in a significant\nincrease in the number of UI elements and the categories assigned to them. We\nalso release models using image-only and multimodal inputs; we experiment with\nvarious architectures and study the benefits of using multimodal inputs on the\nnew dataset. Our models demonstrate strong performance on an evaluation set of\nunseen apps, indicating their generalizability to newer screens. These models,\ncombined with the new dataset, can enable innovative functionalities like\nreferring to UI elements by their labels, improved coverage and better\nsemantics for icons etc., which would go a long way in making UIs more usable\nfor everyone.",
    "descriptor": "\nComments: This paper is to be published at COLING 2022\n",
    "authors": [
      "Srinivas Sunkara",
      "Maria Wang",
      "Lijuan Liu",
      "Gilles Baechler",
      "Yu-Chung Hsiao",
      "Jindong",
      "Chen",
      "Abhanshu Sharma",
      "James Stout"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02663"
  },
  {
    "id": "arXiv:2210.02665",
    "title": "Vision-Based Defect Classification and Weight Estimation of Rice Kernels",
    "abstract": "Rice is one of the main staple food in many areas of the world. The quality\nestimation of rice kernels are crucial in terms of both food safety and\nsocio-economic impact. This was usually carried out by quality inspectors in\nthe past, which may result in both objective and subjective inaccuracies. In\nthis paper, we present an automatic visual quality estimation system of rice\nkernels, to classify the sampled rice kernels according to their types of\nflaws, and evaluate their quality via the weight ratios of the perspective\nkernel types. To compensate for the imbalance of different kernel numbers and\nclassify kernels with multiple flaws accurately, we propose a multi-stage\nworkflow which is able to locate the kernels in the captured image and classify\ntheir properties. We define a novel metric to measure the relative weight of\neach kernel in the image from its area, such that the relative weight of each\ntype of kernels with regard to the all samples can be computed and used as the\nbasis for rice quality estimation. Various experiments are carried out to show\nthat our system is able to output precise results in a contactless way and\nreplace tedious and error-prone manual works.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Xiang Wang",
      "Kai Wang",
      "Xiaohong Li",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02665"
  },
  {
    "id": "arXiv:2210.02666",
    "title": "When not to use machine learning: a perspective on potential and  limitations",
    "abstract": "The unparalleled success of artificial intelligence (AI) in the technology\nsector has catalyzed an enormous amount of research in the scientific\ncommunity. It has proven to be a powerful tool, but as with any rapidly\ndeveloping field, the deluge of information can be overwhelming, confusing and\nsometimes misleading. This can make it easy to become lost in the same hype\ncycles that have historically ended in the periods of scarce funding and\ndepleted expectations known as AI Winters. Furthermore, while the importance of\ninnovative, high-risk research cannot be overstated, it is also imperative to\nunderstand the fundamental limits of available techniques, especially in young\nfields where the rules appear to be constantly rewritten and as the likelihood\nof application to high-stakes scenarios increases. In this perspective, we\nhighlight the guiding principles of data-driven modeling, how these principles\nimbue models with almost magical predictive power, and how they also impose\nlimitations on the scope of problems they can address. Particularly,\nunderstanding when not to use data-driven techniques, such as machine learning,\nis not something commonly explored, but is just as important as knowing how to\napply the techniques properly. We hope that the discussion to follow provides\nresearchers throughout the sciences with a better understanding of when said\ntechniques are appropriate, the pitfalls to watch for, and most importantly,\nthe confidence to leverage the power they can provide.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "M. R. Carbone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2210.02666"
  },
  {
    "id": "arXiv:2210.02667",
    "title": "A Human Rights-Based Approach to Responsible AI",
    "abstract": "Research on fairness, accountability, transparency and ethics of AI-based\ninterventions in society has gained much-needed momentum in recent years.\nHowever it lacks an explicit alignment with a set of normative values and\nprinciples that guide this research and interventions. Rather, an implicit\nconsensus is often assumed to hold for the values we impart into our models -\nsomething that is at odds with the pluralistic world we live in. In this paper,\nwe put forth the doctrine of universal human rights as a set of globally\nsalient and cross-culturally recognized set of values that can serve as a\ngrounding framework for explicit value alignment in responsible AI - and\ndiscuss its efficacy as a framework for civil society partnership and\nparticipation. We argue that a human rights framework orients the research in\nthis space away from the machines and the risks of their biases, and towards\nhumans and the risks to their rights, essentially helping to center the\nconversation around who is harmed, what harms they face, and how those harms\nmay be mitigated.",
    "descriptor": "\nComments: Presented as a (non-archival) poster at the 2022 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization or (EAAMO '22)\n",
    "authors": [
      "Vinodkumar Prabhakaran",
      "Margaret Mitchell",
      "Timnit Gebru",
      "Iason Gabriel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.02667"
  },
  {
    "id": "arXiv:2210.02670",
    "title": "Unconditional stability and error analysis of an Euler IMEX-SAV scheme  for the micropolar Navier-Stokes equations",
    "abstract": "In this paper, we consider numerical approximations for solving the\nmicropolar Navier-Stokes (MNS) equations, that couples the Navier-Stokes\nequations and the angular momentum equation together. By combining the scalar\nauxiliary variable (SAV) approach for the convective terms and some subtle\nimplicit-explicit (IMEX) treatments for the coupling terms, we propose a\ndecoupled, linear and unconditionally energy stable scheme for this system. We\nfurther derive rigorous error estimates for the velocity, pressure and angular\nvelocity in two dimensions without any condition on the time step. Numerical\nexamples are presented to verify the theoretical findings and show the\nperformances of the scheme.",
    "descriptor": "\nComments: 27 pages, 39 figures. arXiv admin note: text overlap with arXiv:2104.00229 by other authors\n",
    "authors": [
      "Xiaodi Zhang",
      "Xiaonian Long"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02670"
  },
  {
    "id": "arXiv:2210.02671",
    "title": "Transformers Implement First-Order Logic with Majority Quantifiers",
    "abstract": "Characterizing the implicit structure of the computation within neural\nnetworks is a foundational problem in the area of deep learning\ninterpretability. Can their inner decision process be captured symbolically in\nsome familiar logic? We show that any transformer neural network can be\ntranslated into an equivalent fixed-size first-order logic formula which may\nalso use majority quantifiers. The idea is to simulate transformers with highly\nuniform threshold circuits and leverage known theoretical connections between\ncircuits and logic. Our findings also reveal the surprising fact that the\nentire transformer computation can be reduced merely to the division of two\n(large) integers. While our results are most pertinent for transformers, they\napply equally to a broader class of neural network architectures, namely those\nwith a fixed-depth uniform computation graph made up of standard neural net\ncomponents, which includes feedforward and convolutional networks.",
    "descriptor": "",
    "authors": [
      "William Merrill",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.02671"
  },
  {
    "id": "arXiv:2210.02672",
    "title": "Orthogonal Non-negative Matrix Factorization: a  Maximum-Entropy-Principle Approach",
    "abstract": "In this paper, we introduce a new methodology to solve the orthogonal\nnon-negative matrix factorization (ONMF) problem, where the objective is to\napproximate an input data matrix by the product of two non-negative matrices,\nthe features matrix and the mixing matrix, while one of them is orthogonal. We\nshow how the ONMF can be interpreted as a specific facility-location problem\n(FLP), and adapt a maximum-entropy-principle based solution for FLP to the ONMF\nproblem. The proposed approach guarantees orthogonality of the features or the\nmixing matrix, while ensuring that both of the matrix factors are non-negative.\nAlso, the features (mixing) matrix has exactly one non-zero element across each\nrow (column), providing the maximum sparsity of the orthogonal factor. This\nenables a semantic interpretation of the underlying data matrix using\nnon-overlapping features. The experiments on synthetic data and a standard\nmicroarray dataset demonstrate significant improvements in terms of sparsity\nand orthogonality scores of features (mixing) matrices, while achieving\napproximately the same or better (up to 3%) reconstruction errors.",
    "descriptor": "",
    "authors": [
      "Salar Basiri",
      "Mustafa Kapadia",
      "Srinivasa Salapaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.02672"
  },
  {
    "id": "arXiv:2210.02673",
    "title": "On the Interplay Between Deadline-Constrained Traffic and the Number of  Allowed Retransmissions in Random Access Networks",
    "abstract": "In this paper, a network comprising wireless devices equipped with buffers\ntransmitting deadline-constrained data packets over a slotted-ALOHA\nrandom-access channel is studied. Although communication protocols facilitating\nretransmissions increase reliability, packet transmission from the queue\nexperiences delays and thus, packets with time constraints might be dropped\nbefore being successfully transmitted, while at the same time causing the queue\nsize of the buffer to increase. Towards understanding the trade-off between\nreliability and delays that might lead to packet drops due to the\ndeadline-constrained bursty traffic with retransmissions, a scenario of a\nwireless network utilizing a slotted-ALOHA random-access channel is\ninvestigated. The main focus is to reveal and investigate further the trade-off\nbetween the number of retransmissions and the packet deadline as a function of\nthe arrival rate. Hence, we are able to determine numerically the optimal\nprobability of transmissions and number of retransmissions, given the packet\narrival rate and the packet deadline. The analysis of the system was done by\nmeans of discrete-time Markov chains. Two scenarios are studied: i) the\ncollision channel model (in which a receiver can decode only when a single\npacket is transmitted), and ii) the case for which receivers have multi-packet\nreception capabilities. A performance evaluation for a user with different\ntransmit probability and number of retransmissions is conducted, demonstrating\ntheir impact on the average drop rate and throughput, while at the same time\nshowing that there exists a set of values, under which improved performance can\nbe acquired.",
    "descriptor": "",
    "authors": [
      "Nikolaos Nomikos",
      "Themistoklis Charalambous",
      "Yvonne-Anne Pignolet",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.02673"
  },
  {
    "id": "arXiv:2210.02675",
    "title": "Look Ma, Only 400 Samples! Revisiting the Effectiveness of Automatic  N-Gram Rule Generation for Spelling Normalization in Filipino",
    "abstract": "With 84.75 million Filipinos online, the ability for models to process online\ntext is crucial for developing Filipino NLP applications. To this end, spelling\ncorrection is a crucial preprocessing step for downstream processing. However,\nthe lack of data prevents the use of language models for this task. In this\npaper, we propose an N-Gram + Damerau Levenshtein distance model with automatic\nrule extraction. We train the model on 300 samples, and show that despite\nlimited training data, it achieves good performance and outperforms other deep\nlearning approaches in terms of accuracy and edit distance. Moreover, the model\n(1) requires little compute power, (2) trains in little time, thus allowing for\nretraining, and (3) is easily interpretable, allowing for direct\ntroubleshooting, highlighting the success of traditional approaches over more\ncomplex deep learning models in settings where data is unavailable.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Lorenzo Jaime Yu Flores"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02675"
  },
  {
    "id": "arXiv:2210.02676",
    "title": "Uncertainty Estimation for Multi-view Data: The Power of Seeing the  Whole Picture",
    "abstract": "Uncertainty estimation is essential to make neural networks trustworthy in\nreal-world applications. Extensive research efforts have been made to quantify\nand reduce predictive uncertainty. However, most existing works are designed\nfor unimodal data, whereas multi-view uncertainty estimation has not been\nsufficiently investigated. Therefore, we propose a new multi-view\nclassification framework for better uncertainty estimation and out-of-domain\nsample detection, where we associate each view with an uncertainty-aware\nclassifier and combine the predictions of all the views in a principled way.\nThe experimental results with real-world datasets demonstrate that our proposed\napproach is an accurate, reliable, and well-calibrated classifier, which\npredominantly outperforms the multi-view baselines tested in terms of expected\ncalibration error, robustness to noise, and accuracy for the in-domain sample\nclassification and the out-of-domain sample detection tasks.",
    "descriptor": "\nComments: Accepted at NeurIPS2022\n",
    "authors": [
      "Myong Chol Jung",
      "He Zhao",
      "Joanna Dipnall",
      "Belinda Gabbe",
      "Lan Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02676"
  },
  {
    "id": "arXiv:2210.02678",
    "title": "Effective Metaheuristic Based Classifiers for Multiclass Intrusion  Detection",
    "abstract": "Network security has become the biggest concern in the area of cyber security\nbecause of the exponential growth in computer networks and applications.\nIntrusion detection plays an important role in the security of information\nsystems or networks devices. The purpose of an intrusion detection system (IDS)\nis to detect malicious activities and then generate an alarm against these\nactivities. Having a large amount of data is one of the key problems in\ndetecting attacks. Most of the intrusion detection systems use all features of\ndatasets to evaluate the models and result in is, low detection rate, high\ncomputational time and uses of many computer resources. For fast attacks\ndetection IDS needs a lightweight data. A feature selection method plays a key\nrole to select best features to achieve maximum accuracy. This research work\nconduct experiments by considering on two updated attacks datasets, UNSW-NB15\nand CICDDoS2019. This work suggests a wrapper based Genetic Algorithm (GA)\nfeatures selection method with ensemble classifiers. GA select the best feature\nsubsets and achieve high accuracy, detection rate (DR) and low false alarm rate\n(FAR) compared to existing approaches. This research focuses on multi-class\nclassification. Implements two ensemble methods: stacking and bagging to detect\ndifferent types of attacks. The results show that GA improve the accuracy\nsignificantly with stacking ensemble classifier.",
    "descriptor": "\nComments: 17 single column pages\n",
    "authors": [
      "Zareen Fatima",
      "Arshad Ali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02678"
  },
  {
    "id": "arXiv:2210.02680",
    "title": "DReS-FL: Dropout-Resilient Secure Federated Learning for Non-IID Clients  via Secret Data Sharing",
    "abstract": "Federated learning (FL) strives to enable collaborative training of machine\nlearning models without centrally collecting clients' private data. Different\nfrom centralized training, the local datasets across clients in FL are\nnon-independent and identically distributed (non-IID). In addition, the\ndata-owning clients may drop out of the training process arbitrarily. These\ncharacteristics will significantly degrade the training performance. This paper\nproposes a Dropout-Resilient Secure Federated Learning (DReS-FL) framework\nbased on Lagrange coded computing (LCC) to tackle both the non-IID and dropout\nproblems. The key idea is to utilize Lagrange coding to secretly share the\nprivate datasets among clients so that each client receives an encoded version\nof the global dataset, and the local gradient computation over this dataset is\nunbiased. To correctly decode the gradient at the server, the gradient function\nhas to be a polynomial in a finite field, and thus we construct polynomial\ninteger neural networks (PINNs) to enable our framework. Theoretical analysis\nshows that DReS-FL is resilient to client dropouts and provides privacy\nprotection for the local datasets. Furthermore, we experimentally demonstrate\nthat DReS-FL consistently leads to significant performance gains over baseline\nmethods.",
    "descriptor": "\nComments: This paper was accepted to NeurIPS 2022\n",
    "authors": [
      "Jiawei Shao",
      "Yuchang Sun",
      "Songze Li",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02680"
  },
  {
    "id": "arXiv:2210.02683",
    "title": "A Machine Learning Based Approach to Categorize Research Journals",
    "abstract": "In this modern technological era, categorization and ranking of research\njournals is gaining popularity among researchers and scientists. It plays a\nsignificant role for publication of their research findings in a quality\njournal. Although, many research works exist on journal categorization and\nranking, however, there is a lack of research works to categorize and predict\nthe journals using suitable machine learning techniques. This work aims to\ncategorize and predict various academic research journals. This work suggests a\nhybrid predictive model comprising of five steps. The first step is to prepare\nthe dataset with twenty features. The second step is to pre-process the\ndataset. The third step is to apply an appropriate clustering algorithm for\ncategorization. The fourth step is to apply appropriate feature selection\ntechniques to get an effective subset of features. The fifth step involves some\nensemble plus non ensemble methods to train the model. The model is trained on\na full set of features, and a selected subset of features is obtained by\napplying three feature selection techniques. After model training, the\nprediction results are evaluated in terms of precision, recall, and accuracy.\nThe results can help the researchers and the practitioners in predicting the\njournal category.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Rabia Shabbir Ranjha",
      "Arshad Ali",
      "Shahid Yousaf"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.02683"
  },
  {
    "id": "arXiv:2210.02685",
    "title": "A Real2Sim2Real Method for Robust Object Grasping with Neural Surface  Reconstruction",
    "abstract": "Recent 3D-based manipulation methods either directly predict the grasp pose\nusing 3D neural networks, or solve the grasp pose using similar objects\nretrieved from shape databases. However, the former faces generalizability\nchallenges when testing with new robot arms or unseen objects; and the latter\nassumes that similar objects exist in the databases. We hypothesize that recent\n3D modeling methods provides a path towards building digital replica of the\nevaluation scene that affords physical simulation and supports robust\nmanipulation algorithm learning. We propose to reconstruct high-quality meshes\nfrom real-world point clouds using state-of-the-art neural surface\nreconstruction method (the Real2Sim step). Because most simulators take meshes\nfor fast simulation, the reconstructed meshes enable grasp pose labels\ngeneration without human efforts. The generated labels can train grasp network\nthat performs robustly in the real evaluation scene (the Sim2Real step). In\nsynthetic and real experiments, we show that the Real2Sim2Real pipeline\nperforms better than baseline grasp networks trained with a large dataset and a\ngrasp sampling method with retrieval-based reconstruction. The benefit of the\nReal2Sim2Real pipeline comes from 1) decoupling scene modeling and grasp\nsampling into sub-problems, and 2) both sub-problems can be solved with\nsufficiently high quality using recent 3D learning algorithms and mesh-based\nphysical simulation techniques.",
    "descriptor": "\nComments: Video presentation available at this https URL\n",
    "authors": [
      "Luobin Wang",
      "Runlin Guo",
      "Quan Vuong",
      "Yuzhe Qin",
      "Hao Su",
      "Henrik Christensen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02685"
  },
  {
    "id": "arXiv:2210.02689",
    "title": "Neural Matching Fields: Implicit Representation of Matching Fields for  Visual Correspondence",
    "abstract": "Existing pipelines of semantic correspondence commonly include extracting\nhigh-level semantic features for the invariance against intra-class variations\nand background clutters. This architecture, however, inevitably results in a\nlow-resolution matching field that additionally requires an ad-hoc\ninterpolation process as a post-processing for converting it into a\nhigh-resolution one, certainly limiting the overall performance of matching\nresults. To overcome this, inspired by recent success of implicit neural\nrepresentation, we present a novel method for semantic correspondence, called\nNeural Matching Field (NeMF). However, complicacy and high-dimensionality of a\n4D matching field are the major hindrances, which we propose a cost embedding\nnetwork to process a coarse cost volume to use as a guidance for establishing\nhigh-precision matching field through the following fully-connected network.\nNevertheless, learning a high-dimensional matching field remains challenging\nmainly due to computational complexity, since a naive exhaustive inference\nwould require querying from all pixels in the 4D space to infer pixel-wise\ncorrespondences. To overcome this, we propose adequate training and inference\nprocedures, which in the training phase, we randomly sample matching candidates\nand in the inference phase, we iteratively performs PatchMatch-based inference\nand coordinate optimization at test time. With these combined, competitive\nresults are attained on several standard benchmarks for semantic\ncorrespondence. Code and pre-trained weights are available at\nhttps://ku-cvlab.github.io/NeMF/.",
    "descriptor": "\nComments: NeurIPS2022 camera ready\n",
    "authors": [
      "Sunghwan Hong",
      "Jisu Nam",
      "Seokju Cho",
      "Susung Hong",
      "Sangryul Jeon",
      "Dongbo Min",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02689"
  },
  {
    "id": "arXiv:2210.02690",
    "title": "Efficiency of local Vanka smoother geometric multigrid preconditioning  for space-time finite element methods to the Navier-Stokes equations",
    "abstract": "Numerical simulation of incompressible viscous flow, in particular in three\nspace dimensions, continues to remain a challenging task. Space-time finite\nelement methods feature the natural construction of higher order discretization\nschemes. They offer the potential to achieve accurate results on\ncomputationally feasible grids. Linearizing the resulting algebraic problems by\nNewton's method yields linear systems with block matrices built of $(k+1)\\times\n(k+1)$ saddle point systems, where $k$ denotes the polynomial order of the\nvariational time discretization. We demonstrate numerically the efficiency of\npreconditioning GMRES iterations for solving these linear systems by a\n$V$-cycle geometric multigrid approach based on a local Vanka smoother. The\nstudies are done for the two- and three-dimensional benchmark problem of flow\naround a cylinder. Here, the robustness of the solver with respect to the\npiecewise polynomial order $k$ in time is analyzed and proved numerically.",
    "descriptor": "",
    "authors": [
      "Mathias Anselmann",
      "Markus Bause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02690"
  },
  {
    "id": "arXiv:2210.02692",
    "title": "Safety-based Speed Control of a Wheelchair using Robust Adaptive Model  Predictive Control",
    "abstract": "Electric-powered wheelchair plays an important role in providing\naccessibility for people with mobility impairment. Ensuring the safety of\nwheelchair operation in different application scenarios and for diverse users\nis crucial when the designing controller for tracking tasks. In this work, we\npropose a safety-based speed tracking control algorithm for wheelchair systems\nwith external disturbances and uncertain parameters at the dynamic level. The\nset-membership approach is applied to estimate the sets of uncertain parameters\nonline and a designed model predictive control scheme with online model and\ncontrol parameter adaptation is presented to guarantee safety-related\nconstraints during the tracking process. The proposed controller can drive the\nwheelchair speed to a desired reference within safety constraints. For the\ninadmissible reference that violates the constraints, the proposed controller\ncan steer the system to the neighbourhood of the closest admissible reference.\nThe effectiveness of the proposed control scheme is validated based on the\nhigh-fidelity speed tracking results of two tasks that involve feasible and\ninfeasible references.",
    "descriptor": "",
    "authors": [
      "Meng Yuan",
      "Ye Wang",
      "Lei Li",
      "Tianyou Chai",
      "Wei Tech Ang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02692"
  },
  {
    "id": "arXiv:2210.02693",
    "title": "Focal and Global Spatial-Temporal Transformer for Skeleton-based Action  Recognition",
    "abstract": "Despite great progress achieved by transformer in various vision tasks, it is\nstill underexplored for skeleton-based action recognition with only a few\nattempts. Besides, these methods directly calculate the pair-wise global\nself-attention equally for all the joints in both the spatial and temporal\ndimensions, undervaluing the effect of discriminative local joints and the\nshort-range temporal dynamics. In this work, we propose a novel Focal and\nGlobal Spatial-Temporal Transformer network (FG-STFormer), that is equipped\nwith two key components: (1) FG-SFormer: focal joints and global parts coupling\nspatial transformer. It forces the network to focus on modelling correlations\nfor both the learned discriminative spatial joints and human body parts\nrespectively. The selective focal joints eliminate the negative effect of\nnon-informative ones during accumulating the correlations. Meanwhile, the\ninteractions between the focal joints and body parts are incorporated to\nenhance the spatial dependencies via mutual cross-attention. (2) FG-TFormer:\nfocal and global temporal transformer. Dilated temporal convolution is\nintegrated into the global self-attention mechanism to explicitly capture the\nlocal temporal motion patterns of joints or body parts, which is found to be\nvital important to make temporal transformer work. Extensive experimental\nresults on three benchmarks, namely NTU-60, NTU-120 and NW-UCLA, show our\nFG-STFormer surpasses all existing transformer-based methods, and compares\nfavourably with state-of-the art GCN-based methods.",
    "descriptor": "\nComments: Accepted by ACCV2022\n",
    "authors": [
      "Zhimin Gao",
      "Peitao Wang",
      "Pei Lv",
      "Xiaoheng Jiang",
      "Qidong Liu",
      "Pichao Wang",
      "Mingliang Xu",
      "Wanqing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02693"
  },
  {
    "id": "arXiv:2210.02694",
    "title": "Probabilistic partition of unity networks for high-dimensional  regression problems",
    "abstract": "We explore the probabilistic partition of unity network (PPOU-Net) model in\nthe context of high-dimensional regression problems. With the PPOU-Nets, the\ntarget function for any given input is approximated by a mixture of experts\nmodel, where each cluster is associated with a fixed-degree polynomial. The\nweights of the clusters are determined by a DNN that defines a partition of\nunity. The weighted average of the polynomials approximates the target function\nand produces uncertainty quantification naturally. Our training strategy\nleverages automatic differentiation and the expectation maximization (EM)\nalgorithm. During the training, we (i) apply gradient descent to update the DNN\ncoefficients; (ii) update the polynomial coefficients using weighted\nleast-squares solves; and (iii) compute the variance of each cluster according\nto a closed-form formula derived from the EM algorithm. The PPOU-Nets\nconsistently outperform the baseline fully-connected neural networks of\ncomparable sizes in numerical experiments of various data dimensions. We also\nexplore the proposed model in applications of quantum computing, where the\nPPOU-Nets act as surrogate models for cost landscapes associated with\nvariational quantum circuits.",
    "descriptor": "",
    "authors": [
      "Tiffany Fan",
      "Nathaniel Trask",
      "Marta D'Elia",
      "Eric Darve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.02694"
  },
  {
    "id": "arXiv:2210.02695",
    "title": "Different Perspectives on FLP Impossibility",
    "abstract": "We demonstrate possibility for vector consensus under the model and\nconditions used by Fischer, Lynch, and Patterson (FLP) to prove impossibility\nof binary consensus - full asynchrony and one faulty process. Under that model,\nwe also demonstrate that with any binary consensus protocol: i) binary outcome\nis produced from a vector value; ii) elaboration on a vector value is an\nunavoidable necessity; and iii) binary agreement can be reached with voting on\na vector value. Key finding: the FLP impossibility result is about\nimpossibility to produce a binary value from any allowed vector value, i.e.,\nfrom any data set assembled from an allowed initial state.",
    "descriptor": "",
    "authors": [
      "Ivan Klianev"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.02695"
  },
  {
    "id": "arXiv:2210.02697",
    "title": "DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General  Objects Based on Simulation",
    "abstract": "Object grasping using dexterous hands is a crucial yet challenging task for\nrobotic dexterous manipulation. Compared with the field of object grasping with\nparallel grippers, dexterous grasping is very under-explored, partially owing\nto the lack of a large-scale dataset. In this work, we present a large-scale\nsimulated dataset, DexGraspNet, for robotic dexterous grasping, along with a\nhighly efficient synthesis method for diverse dexterous grasping synthesis.\nLeveraging a highly accelerated differentiable force closure estimator, we, for\nthe first time, are able to synthesize stable and diverse grasps efficiently\nand robustly. We choose ShadowHand, a dexterous gripper commonly seen in\nrobotics, and generated 1.32 million grasps for 5355 objects, covering more\nthan 133 object categories and containing more than 200 diverse grasps for each\nobject instance, with all grasps having been validated by the physics\nsimulator. Compared to the previous dataset generated by GraspIt!, our dataset\nhas not only more objects and grasps, but also higher diversity and quality.\nVia performing cross-dataset experiments, we show that training several\nalgorithms of dexterous grasp synthesis on our datasets significantly\noutperforms training on the previous one, demonstrating the large scale and\ndiversity of DexGraspNet. We will release the data and tools upon acceptance.",
    "descriptor": "",
    "authors": [
      "Ruicheng Wang",
      "Jialiang Zhang",
      "Jiayi Chen",
      "Yinzhen Xu",
      "Puhao Li",
      "Tengyu Liu",
      "He Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02697"
  },
  {
    "id": "arXiv:2210.02700",
    "title": "Minimal-order Appointed-time Unknown Input Observers: Design and  Applications",
    "abstract": "This paper presents a framework on minimal-order appointed-time unknown input\nobservers for linear systems based on the pairwise observer structure. A\nminimal-order appointed-time observer is first proposed for the linear system\nwithout the unknown input, which can estimate the state exactly at the preset\ntime by seeking for the unique solution of a system of linear equations. To\nfurther release the computational burden, another form of the appointed-time\nobserver is designed. For the general linear system with the unknown input\nacting on both the system dynamics and the measured output, the model\nreconfiguration is made to decouple the effect of the unknown input, and the\ngap between the existing reduced-order appointed-time unknown input observer\nand the possible minimal-order appointed-time observer is revealed. Based on\nthe reconstructed model, the minimal-order appointed-time unknown input\nobserver is presented to realize state estimation of linear system with the\nunknown input at the arbitrarily small preset time. The minimal-order\nappointed-time unknown input observer is then applied to the design of fully\ndistributed adaptive output-feedback attack-free consensus protocols for linear\nmulti-agent systems.",
    "descriptor": "",
    "authors": [
      "Yuezu Lv",
      "Zhongkui Li",
      "Zhisheng Duan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02700"
  },
  {
    "id": "arXiv:2210.02702",
    "title": "Block-Structured Optimization for Subgraph Detection in Interdependent  Networks",
    "abstract": "We propose a generalized framework for block-structured nonconvex\noptimization, which can be applied to structured subgraph detection in\ninterdependent networks, such as multi-layer networks, temporal networks,\nnetworks of networks, and many others. Specifically, we design an effective,\nefficient, and parallelizable projection algorithm, namely Graph\nBlock-structured Gradient Projection (GBGP), to optimize a general non-linear\nfunction subject to graph-structured constraints. We prove that our algorithm:\n1) runs in nearly-linear time on the network size; 2) enjoys a theoretical\napproximation guarantee. Moreover, we demonstrate how our framework can be\napplied to two very practical applications and conduct comprehensive\nexperiments to show the effectiveness and efficiency of our proposed algorithm.",
    "descriptor": "\nComments: Accepted by ICDM-2019\n",
    "authors": [
      "Fei Jie",
      "Chunpai Wang",
      "Feng Chen",
      "Lei Li",
      "Xindong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02702"
  },
  {
    "id": "arXiv:2210.02703",
    "title": "Teaching Neural Module Networks to Do Arithmetic",
    "abstract": "Answering complex questions that require multi-step multi-type reasoning over\nraw text is challenging, especially when conducting numerical reasoning. Neural\nModule Networks(NMNs), follow the programmer-interpreter framework and design\ntrainable modules to learn different reasoning skills. However, NMNs only have\nlimited reasoning abilities, and lack numerical reasoning capability. We\nup-grade NMNs by: (a) bridging the gap between its interpreter and the complex\nquestions; (b) introducing addition and subtraction modules that perform\nnumerical reasoning over numbers. On a subset of DROP, experimental results\nshow that our proposed methods enhance NMNs' numerical reasoning skills by\n17.7% improvement of F1 score and significantly outperform previous\nstate-of-the-art models.",
    "descriptor": "\nComments: 9 pages including appendix, camera-ready version of COLING 2022\n",
    "authors": [
      "Jiayi Chen",
      "Xiao-Yu Guo",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02703"
  },
  {
    "id": "arXiv:2210.02704",
    "title": "hyperbox-brain: A Toolbox for Hyperbox-based Machine Learning Algorithms",
    "abstract": "Hyperbox-based machine learning algorithms are an important and popular\nbranch of machine learning in the construction of classifiers using fuzzy sets\nand logic theory and neural network architectures. This type of learning is\ncharacterised by many strong points of modern predictors such as a high\nscalability, explainability, online adaptation, effective learning from a small\namount of data, native ability to deal with missing data and accommodating new\nclasses. Nevertheless, there is no comprehensive existing package for\nhyperbox-based machine learning which can serve as a benchmark for research and\nallow non-expert users to apply these algorithms easily. hyperbox-brain is an\nopen-source Python library implementing the leading hyperbox-based machine\nlearning algorithms. This library exposes a unified API which closely follows\nand is compatible with the renowned scikit-learn and numpy toolboxes. The\nlibrary may be installed from Python Package Index (PyPI) and the conda package\nmanager and is distributed under the GPL-3 license. The source code,\ndocumentation, detailed tutorials, and the full descriptions of the API are\navailable at https://uts-caslab.github.io/hyperbox-brain.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Thanh Tung Khuat",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02704"
  },
  {
    "id": "arXiv:2210.02709",
    "title": "Embodied Referring Expression for Manipulation Question Answering in  Interactive Environment",
    "abstract": "Embodied agents are expected to perform more complicated tasks in an\ninteractive environment, with the progress of Embodied AI in recent years.\nExisting embodied tasks including Embodied Referring Expression (ERE) and other\nQA-form tasks mainly focuses on interaction in term of linguistic instruction.\nTherefore, enabling the agent to manipulate objects in the environment for\nexploration actively has become a challenging problem for the community. To\nsolve this problem, We introduce a new embodied task: Remote Embodied\nManipulation Question Answering (REMQA) to combine ERE with manipulation tasks.\nIn the REMQA task, the agent needs to navigate to a remote position and perform\nmanipulation with the target object to answer the question. We build a\nbenchmark dataset for the REMQA task in the AI2-THOR simulator. To this end, a\nframework with 3D semantic reconstruction and modular network paradigms is\nproposed. The evaluation of the proposed framework on the REMQA dataset is\npresented to validate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Qie Sima",
      "Sinan Tan",
      "Huaping Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02709"
  },
  {
    "id": "arXiv:2210.02710",
    "title": "Reduced Membrane Model for Liquid Crystal Polymer Networks: Asymptotics  and Computation",
    "abstract": "We examine a reduced membrane model of liquid crystal polymer networks (LCNs)\nvia asymptotics and computation. This model requires solving a minimization\nproblem for a non-convex stretching energy. We show a formal asymptotic\nderivation of the $2D$ membrane model from $3D$ rubber elasticity. We construct\napproximate solutions with point defects. We design a finite element method\nwith regularization, and propose a nonlinear gradient flow with Newton inner\niteration to solve the non-convex discrete minimization problem. We present\nnumerical simulations of practical interests to illustrate the ability of the\nmodel and our method to capture rich physical phenomena.",
    "descriptor": "\nComments: 44 pages, 22 figures\n",
    "authors": [
      "Lucas Bouck",
      "Ricardo H. Nochetto",
      "Shuo Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02710"
  },
  {
    "id": "arXiv:2210.02713",
    "title": "On Optimal Learning Under Targeted Data Poisoning",
    "abstract": "Consider the task of learning a hypothesis class $\\mathcal{H}$ in the\npresence of an adversary that can replace up to an $\\eta$ fraction of the\nexamples in the training set with arbitrary adversarial examples. The adversary\naims to fail the learner on a particular target test point $x$ which is known\nto the adversary but not to the learner. In this work we aim to characterize\nthe smallest achievable error $\\epsilon=\\epsilon(\\eta)$ by the learner in the\npresence of such an adversary in both realizable and agnostic settings. We\nfully achieve this in the realizable setting, proving that\n$\\epsilon=\\Theta(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where\n$\\mathtt{VC}(\\mathcal{H})$ is the VC dimension of $\\mathcal{H}$. Remarkably, we\nshow that the upper bound can be attained by a deterministic learner. In the\nagnostic setting we reveal a more elaborate landscape: we devise a\ndeterministic learner with a multiplicative regret guarantee of $\\epsilon \\leq\nC\\cdot\\mathtt{OPT} + O(\\mathtt{VC}(\\mathcal{H})\\cdot \\eta)$, where $C > 1$ is a\nuniversal numerical constant. We complement this by showing that for any\ndeterministic learner there is an attack which worsens its error to at least\n$2\\cdot \\mathtt{OPT}$. This implies that a multiplicative deterioration in the\nregret is unavoidable in this case. Finally, the algorithms we develop for\nachieving the optimal rates are inherently improper. Nevertheless, we show that\nfor a variety of natural concept classes, such as linear classifiers, it is\npossible to retain the dependence $\\epsilon=\\Theta_{\\mathcal{H}}(\\eta)$ by a\nproper algorithm in the realizable setting. Here $\\Theta_{\\mathcal{H}}$\nconceals a polynomial dependence on $\\mathtt{VC}(\\mathcal{H})$.",
    "descriptor": "",
    "authors": [
      "Steve Hanneke",
      "Amin Karbasi",
      "Mohammad Mahmoody",
      "Idan Mehalel",
      "Shay Moran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02713"
  },
  {
    "id": "arXiv:2210.02716",
    "title": "Computing groups of Hecke characters",
    "abstract": "We describe algorithms to represent and compute groups of Hecke characters.\nWe make use of an id{\\`e}lic point of view and obtain the whole family of such\ncharacters, including transcendental ones. We also show how to isolate the\nalgebraic characters, which are of particular interest in number theory. This\nwork has been implemented in Pari/GP, and we illustrate our work with a variety\nof explicit examples using our implementation.",
    "descriptor": "",
    "authors": [
      "Pascal Molin",
      "Aurel Page"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2210.02716"
  },
  {
    "id": "arXiv:2210.02717",
    "title": "Analysis of IRS-Assisted Downlink Wireless Networks over Generalized  Fading",
    "abstract": "Future wireless networks are expected to provide high spectral efficiency,\nlow hardware cost, and scalable connectivity. An appealing option to meet these\nrequirements is the intelligent reflective surface (IRS), which guarantees a\nsmart propagation environment by adjusting the phase shift and direction of\nreceived signals. However, the composite channel of IRS-assisted wireless\nnetworks, which is composed of a direct link and cascaded link aided by the\nIRS, has made it challenging to carry out system design and analysis. This\nmotivates us to find tractable and accurate channel modeling methods to model\nmultiple types of channels. To this end, we adopt mixture Gamma distributions\nto model the direct link, the cascaded link, and the mixture channel. Moreover,\nthis channel modeling method can be applied to various transmission\nenvironments with an arbitrary type of fading as the underlying fading of each\nlink. Additionally, a unified stochastic geometric framework is introduced\nbased on this tractable channel model. First, we derived distributions of the\ncascaded link and the mixture channel by proving multipliability and quadratic\nform of mixture Gamma distributed channels. Then, we carried out a stochastic\ngeometric analysis of the system performance of the IRS-assisted wireless\nnetwork with the proposed channel modeling method. Our simulation shows that\nthe mixture Gamma distributed approximation method guarantees high accuracy and\npromotes the feasibility of system performance analysis of IRS-assisted\nnetworks with complicated propagation environments, especially with a\ngeneralized fading model. Furthermore, the proposed analytical framework\nprovides positive insights into the system design regarding reliability and\nefficiency.",
    "descriptor": "",
    "authors": [
      "Yunli Li",
      "Young Jin Chun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.02717"
  },
  {
    "id": "arXiv:2210.02719",
    "title": "Continuous Diagnosis and Prognosis by Controlling the Update Process of  Deep Neural Networks",
    "abstract": "Continuous diagnosis and prognosis are essential for intensive care patients.\nIt can provide more opportunities for timely treatment and rational resource\nallocation, especially for sepsis, a main cause of death in ICU, and COVID-19,\na new worldwide epidemic. Although deep learning methods have shown their great\nsuperiority in many medical tasks, they tend to catastrophically forget, over\nfit, and get results too late when performing diagnosis and prognosis in the\ncontinuous mode. In this work, we summarized the three requirements of this\ntask, proposed a new concept, continuous classification of time series (CCTS),\nand designed a novel model training method, restricted update strategy of\nneural networks (RU). In the context of continuous prognosis, our method\noutperformed all baselines and achieved the average accuracy of 90%, 97%, and\n85% on sepsis prognosis, COVID-19 mortality prediction, and eight diseases\nclassification. Superiorly, our method can also endow deep learning with\ninterpretability, having the potential to explore disease mechanisms and\nprovide a new horizon for medical research. We have achieved disease staging\nfor sepsis and COVID-19, discovering four stages and three stages with their\ntypical biomarkers respectively. Further, our method is a data-agnostic and\nmodel-agnostic plug-in, it can be used to continuously prognose other diseases\nwith staging and even implement CCTS in other fields.",
    "descriptor": "\nComments: 41 pages, 15 figures\n",
    "authors": [
      "Chenxi Sun",
      "Hongyan Li",
      "Moxian Song",
      "Derun Cai",
      "Baofeng Zhang",
      "Shenda Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02719"
  },
  {
    "id": "arXiv:2210.02720",
    "title": "Understanding Gradient Regularization in Deep Learning: Efficient  Finite-Difference Computation and Implicit Bias",
    "abstract": "Gradient regularization (GR) is a method that penalizes the gradient norm of\nthe training loss during training. Although some studies have reported that GR\nimproves generalization performance in deep learning, little attention has been\npaid to it from the algorithmic perspective, that is, the algorithms of GR that\nefficiently improve performance. In this study, we first reveal that a specific\nfinite-difference computation, composed of both gradient ascent and descent\nsteps, reduces the computational cost for GR. In addition, this computation\nempirically achieves better generalization performance. Next, we theoretically\nanalyze a solvable model, a diagonal linear network, and clarify that GR has a\ndesirable implicit bias in a certain problem. In particular, learning with the\nfinite-difference GR chooses better minima as the ascent step size becomes\nlarger. Finally, we demonstrate that finite-difference GR is closely related to\nsome other algorithms based on iterative ascent and descent steps for exploring\nflat minima: sharpness-aware minimization and the flooding method. We reveal\nthat flooding performs finite-difference GR in an implicit way. Thus, this work\nbroadens our understanding of GR in both practice and theory.",
    "descriptor": "",
    "authors": [
      "Ryo Karakida",
      "Tomoumi Takase",
      "Tomohiro Hayase",
      "Kazuki Osawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02720"
  },
  {
    "id": "arXiv:2210.02723",
    "title": "A novel Lagrange Multiplier approach with relaxation for gradient flows",
    "abstract": "In this paper, we propose a novel Lagrange Multiplier approach, named\nzero-factor (ZF) approach to solve a series of gradient flow problems. The\nnumerical schemes based on the new algorithm are unconditionally energy stable\nwith the original energy and do not require any extra assumption conditions. We\nalso prove that the ZF schemes with specific zero factors lead to the popular\nSAV-type method. To reduce the computation cost and improve the accuracy and\nconsistency, we propose a zero-factor approach with relaxation, which we named\nthe relaxed zero-factor (RZF) method, to design unconditional energy stable\nschemes for gradient flows. The RZF schemes can be proved to be unconditionally\nenergy stable with respect to a modified energy that is closer to the original\nenergy, and provide a very simple calculation process. The variation of the\nintroduced zero factor is highly consistent with the nonlinear free energy\nwhich implies that the introduced ZF method is a very efficient way to capture\nthe sharp dissipation of nonlinear free energy. Several numerical examples are\nprovided to demonstrate the improved efficiency and accuracy of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Zhengguang Liu",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.02723"
  },
  {
    "id": "arXiv:2210.02724",
    "title": "Leveraging Instance Features for Label Aggregation in Programmatic Weak  Supervision",
    "abstract": "Programmatic Weak Supervision (PWS) has emerged as a widespread paradigm to\nsynthesize training labels efficiently. The core component of PWS is the label\nmodel, which infers true labels by aggregating the outputs of multiple noisy\nsupervision sources abstracted as labeling functions (LFs). Existing\nstatistical label models typically rely only on the outputs of LF, ignoring the\ninstance features when modeling the underlying generative process. In this\npaper, we attempt to incorporate the instance features into a statistical label\nmodel via the proposed FABLE. In particular, it is built on a mixture of\nBayesian label models, each corresponding to a global pattern of correlation,\nand the coefficients of the mixture components are predicted by a Gaussian\nProcess classifier based on instance features. We adopt an auxiliary\nvariable-based variational inference algorithm to tackle the non-conjugate\nissue between the Gaussian Process and Bayesian label models. Extensive\nempirical comparison on eleven benchmark datasets sees FABLE achieving the\nhighest averaged performance across nine baselines.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jieyu Zhang",
      "Linxin Song",
      "Alexander Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02724"
  },
  {
    "id": "arXiv:2210.02725",
    "title": "Exploiting NOMA and RIS in Integrated Sensing and Communication",
    "abstract": "A novel integrated sensing and communication (ISAC) system is proposed, where\na dual-functional base station is utilized to transmit the superimposed\nnon-orthogonal multiple access (NOMA) communication signal for serving\ncommunication users and sensing targets simultaneously. Furthermore, a new\nreconfigurable intelligent surface (RIS)-aided-sensing structure is also\nproposed to address the significant path loss or blockage of LoS links for the\nsensing task. Based on this setup, the beampattern gain at the RIS for the\nradar target is derived and adopted as a sensing metric. The objective of this\npaper is to maximize the minimum beampattern gain by jointly optimizing active\nbeamforming, power allocation coefficients and passive beamforming. To tackle\nthe non-convexity of the formulated optimization problem, the beampattern gain\nand constraints are first transformed into more tractable forms. Then, an\niterative block coordinate descent (IBCD) algorithm is proposed by employing\nsuccessive convex approximation (SCA), Schur complement, semidefinite\nrelaxation (SDR) and sequential rank-one constraint relaxation (SRCR) methods.\nTo reduce the complexity of the proposed IBCD algorithm, a low-complexity\niterative alternating optimization (IAO) algorithm is proposed. Particularly,\nthe active beamforming is optimized by solving a semidefinite programming (SDP)\nproblem and the closed-form solutions of the power allocation coefficients are\nderived. Numerical results show that: i) the proposed RIS-NOMA-ISAC system\nalways outperforms the RIS-ISAC system without NOMA in beampattern gain and\nillumination power; ii) the low-complexity IAO algorithm achieves a comparable\nperformance to that achieved by the IBCD algorithm. iii) high beampattern gain\ncan be achieved by the proposed joint optimization algorithms in underloaded\nand overloaded communication scenarios.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2208.04786\n",
    "authors": [
      "Jiakuo Zuo",
      "Yuanwei Liu",
      "Chenming Zhu",
      "Yixuan Zou",
      "Dengyin Zhang",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02725"
  },
  {
    "id": "arXiv:2210.02729",
    "title": "Join-Chain Network: A Logical Reasoning View of the Multi-head Attention  in Transformer",
    "abstract": "Developing neural architectures that are capable of logical reasoning has\nbecome increasingly important for a wide range of applications (e.g., natural\nlanguage processing). Towards this grand objective, we first propose a symbolic\nreasoning architecture that chain FOET, which is particularly useful for\nmodeling natural languages. To endow it with differentiable learning\ncapability, we closely examine various neural operators for approximating the\nsymbolic join-chains. Interestingly, we find that the widely used multi-head\nself-attention module in transformer can be understood as a special neural\noperator that implements the union bound of the join operator in probabilistic\npredicate space. Our analysis not only provides a new perspective on the\nmechanism of the pretrained models such as BERT for natural language\nunderstanding, but also suggests several important future improvement\ndirections.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Jianyi Zhang",
      "Yiran Chen",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02729"
  },
  {
    "id": "arXiv:2210.02731",
    "title": "PSVRF: Learning to restore Pitch-Shifted Voice without reference",
    "abstract": "Pitch scaling algorithms have a significant impact on the security of\nAutomatic Speaker Verification (ASV) systems. Although numerous anti-spoofing\nalgorithms have been proposed to identify the pitch-shifted voice and even\nrestore it to the original version, they either have poor performance or\nrequire the original voice as a reference, limiting the prospects of\napplications. In this paper, we propose a no-reference approach termed\nPSVRF$^1$ for high-quality restoration of pitch-shifted voice. Experiments on\nAISHELL-1 and AISHELL-3 demonstrate that PSVRF can restore the voice disguised\nby various pitch-scaling techniques, which obviously enhances the robustness of\nASV systems to pitch-scaling attacks. Furthermore, the performance of PSVRF\neven surpasses that of the state-of-the-art reference-based approach.",
    "descriptor": "",
    "authors": [
      "Yangfu Li",
      "Xiaodan Lin",
      "Jiaxin Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02731"
  },
  {
    "id": "arXiv:2210.02733",
    "title": "FedGraph: an Aggregation Method from Graph Perspective",
    "abstract": "With the increasingly strengthened data privacy act and the difficult data\ncentralization, Federated Learning (FL) has become an effective solution to\ncollaboratively train the model while preserving each client's privacy. FedAvg\nis a standard aggregation algorithm that makes the proportion of dataset size\nof each client as aggregation weight. However, it can't deal with\nnon-independent and identically distributed (non-i.i.d) data well because of\nits fixed aggregation weights and the neglect of data distribution. In this\npaper, we propose an aggregation strategy that can effectively deal with\nnon-i.i.d dataset, namely FedGraph, which can adjust the aggregation weights\nadaptively according to the training condition of local models in whole\ntraining process. The FedGraph takes three factors into account from coarse to\nfine: the proportion of each local dataset size, the topology factor of model\ngraphs, and the model weights. We calculate the gravitational force between\nlocal models by transforming the local models into topology graphs. The\nFedGraph can explore the internal correlation between local models better\nthrough the weighted combination of the proportion each local dataset, topology\nstructure, and model weights. The proposed FedGraph has been applied to the\nMICCAI Federated Tumor Segmentation Challenge 2021 (FeTS) datasets, and the\nvalidation results show that our method surpasses the previous state-of-the-art\nby 2.76 mean Dice Similarity Score. The source code will be available at\nGithub.",
    "descriptor": "",
    "authors": [
      "Zhifang Deng",
      "Xiaohong Huang",
      "Dandan Li",
      "Xueguang Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02733"
  },
  {
    "id": "arXiv:2210.02735",
    "title": "What Should the System Do Next?: Operative Action Captioning for  Estimating System Actions",
    "abstract": "Such human-assisting systems as robots need to correctly understand the\nsurrounding situation based on observations and output the required support\nactions for humans. Language is one of the important channels to communicate\nwith humans, and the robots are required to have the ability to express their\nunderstanding and action planning results. In this study, we propose a new task\nof operative action captioning that estimates and verbalizes the actions to be\ntaken by the system in a human-assisting domain. We constructed a system that\noutputs a verbal description of a possible operative action that changes the\ncurrent state to the given target state. We collected a dataset consisting of\ntwo images as observations, which express the current state and the state\nchanged by actions, and a caption that describes the actions that change the\ncurrent state to the target state, by crowdsourcing in daily life situations.\nThen we constructed a system that estimates operative action by a caption.\nSince the operative action's caption is expected to contain some state-changing\nactions, we use scene-graph prediction as an auxiliary task because the events\nwritten in the scene graphs correspond to the state changes. Experimental\nresults showed that our system successfully described the operative actions\nthat should be conducted between the current and target states. The auxiliary\ntasks that predict the scene graphs improved the quality of the estimation\nresults.",
    "descriptor": "\nComments: Under review in ICRA2023\n",
    "authors": [
      "Taiki Nakamura",
      "Seiya Kawano",
      "Akishige Yuguchi",
      "Yasutomo Kawanishi",
      "Koichiro Yoshino"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02735"
  },
  {
    "id": "arXiv:2210.02737",
    "title": "Spatial-Temporal Graph Convolutional Gated Recurrent Network for Traffic  Forecasting",
    "abstract": "As an important part of intelligent transportation systems, traffic\nforecasting has attracted tremendous attention from academia and industry.\nDespite a lot of methods being proposed for traffic forecasting, it is still\ndifficult to model complex spatial-temporal dependency. Temporal dependency\nincludes short-term dependency and long-term dependency, and the latter is\noften overlooked. Spatial dependency can be divided into two parts:\ndistance-based spatial dependency and hidden spatial dependency. To model\ncomplex spatial-temporal dependency, we propose a novel framework for traffic\nforecasting, named Spatial-Temporal Graph Convolutional Gated Recurrent Network\n(STGCGRN). We design an attention module to capture long-term dependency by\nmining periodic information in traffic data. We propose a Double Graph\nConvolution Gated Recurrent Unit (DGCGRU) to capture spatial dependency, which\nintegrates graph convolutional network and GRU. The graph convolution part\nmodels distance-based spatial dependency with the distance-based predefined\nadjacency matrix and hidden spatial dependency with the self-adaptive adjacency\nmatrix, respectively. Specially, we employ the multi-head mechanism to capture\nmultiple hidden dependencies. In addition, the periodic pattern of each\nprediction node may be different, which is often ignored, resulting in mutual\ninterference of periodic information among nodes when modeling spatial\ndependency. For this, we explore the architecture of model and improve the\nperformance. Experiments on four datasets demonstrate the superior performance\nof our model.",
    "descriptor": "",
    "authors": [
      "Le Zhao",
      "Mingcai Chen",
      "Yuntao Du",
      "Haiyang Yang",
      "Chongjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02737"
  },
  {
    "id": "arXiv:2210.02742",
    "title": "Towards the Multiple Constant Multiplication at Minimal Hardware Cost",
    "abstract": "Multiple Constant Multiplication (MCM) over integers is a frequent operation\narising in embedded systems that require highly optimized hardware. An\nefficient way is to replace costly generic multiplication by bit-shifts and\nadditions, i.e. a multiplierless circuit. In this work, we improve the\nstate-of-the-art optimal approach for MCM, based on Integer Linear Programming\n(ILP). We introduce a new lower-level hardware cost, based on counting the\nnumber of one-bit adders and demonstrate that it is strongly correlated with\nthe LUT count. This new model for the multiplierless MCM circuits permitted us\nto consider intermediate truncations that permit to significantly save\nresources when a full output precision is not required. We incorporate the\nerror propagation rules into our ILP model to guarantee a user-given error\nbound on the MCM results. The proposed ILP models for multiple flavors of MCM\nare implemented as an open-source tool and, combined with the FloPoCo code\ngenerator, provide a complete coefficient-to-VHDL flow. We evaluate our models\nin extensive experiments, and propose an in-depth analysis of the impact that\ndesign metrics have on actually synthesized hardware.",
    "descriptor": "\nComments: 10 pages, 3 tables, 6 figures, journal submission\n",
    "authors": [
      "R\u00e9mi Garcia",
      "Anastasia Volkova"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.02742"
  },
  {
    "id": "arXiv:2210.02746",
    "title": "The Sound of Silence: Efficiency of First Digit Features in Synthetic  Audio Detection",
    "abstract": "The recent integration of generative neural strategies and audio processing\ntechniques have fostered the widespread of synthetic speech synthesis or\ntransformation algorithms. This capability proves to be harmful in many legal\nand informative processes (news, biometric authentication, audio evidence in\ncourts, etc.). Thus, the development of efficient detection algorithms is both\ncrucial and challenging due to the heterogeneity of forgery techniques.\nThis work investigates the discriminative role of silenced parts in synthetic\nspeech detection and shows how first digit statistics extracted from MFCC\ncoefficients can efficiently enable a robust detection. The proposed procedure\nis computationally-lightweight and effective on many different algorithms since\nit does not rely on large neural detection architecture and obtains an accuracy\nabove 90\\% in most of the classes of the ASVSpoof dataset.",
    "descriptor": "\nComments: Accepted at WIFS 2022\n",
    "authors": [
      "Daniele Mari",
      "Federica Latora",
      "Simone Milani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02746"
  },
  {
    "id": "arXiv:2210.02747",
    "title": "Flow Matching for Generative Modeling",
    "abstract": "We introduce a new paradigm for generative modeling built on Continuous\nNormalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale.\nSpecifically, we present the notion of Flow Matching (FM), a simulation-free\napproach for training CNFs based on regressing vector fields of fixed\nconditional probability paths. Flow Matching is compatible with a general\nfamily of Gaussian probability paths for transforming between noise and data\nsamples -- which subsumes existing diffusion paths as specific instances.\nInterestingly, we find that employing FM with diffusion paths results in a more\nrobust and stable alternative for training diffusion models. Furthermore, Flow\nMatching opens the door to training CNFs with other, non-diffusion probability\npaths. An instance of particular interest is using Optimal Transport (OT)\ndisplacement interpolation to define the conditional probability paths. These\npaths are more efficient than diffusion paths, provide faster training and\nsampling, and result in better generalization. Training CNFs using Flow\nMatching on ImageNet leads to state-of-the-art performance in terms of both\nlikelihood and sample quality, and allows fast and reliable sample generation\nusing off-the-shelf numerical ODE solvers.",
    "descriptor": "",
    "authors": [
      "Yaron Lipman",
      "Ricky T. Q. Chen",
      "Heli Ben-Hamu",
      "Maximilian Nickel",
      "Matt Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02747"
  },
  {
    "id": "arXiv:2210.02748",
    "title": "CLAD: A Contrastive Learning based Approach for Background Debiasing",
    "abstract": "Convolutional neural networks (CNNs) have achieved superhuman performance in\nmultiple vision tasks, especially image classification. However, unlike humans,\nCNNs leverage spurious features, such as background information to make\ndecisions. This tendency creates different problems in terms of robustness or\nweak generalization performance. Through our work, we introduce a contrastive\nlearning-based approach (CLAD) to mitigate the background bias in CNNs. CLAD\nencourages semantic focus on object foregrounds and penalizes learning features\nfrom irrelavant backgrounds. Our method also introduces an efficient way of\nsampling negative samples. We achieve state-of-the-art results on the\nBackground Challenge dataset, outperforming the previous benchmark with a\nmargin of 4.1\\%. Our paper shows how CLAD serves as a proof of concept for\ndebiasing of spurious features, such as background and texture (in\nsupplementary material).",
    "descriptor": "\nComments: Accepted to British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Ke Wang",
      "Harshitha Machiraju",
      "Oh-Hyeon Choung",
      "Michael Herzog",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.02748"
  },
  {
    "id": "arXiv:2210.02750",
    "title": "Meta Reinforcement Learning for Optimal Design of Legged Robots",
    "abstract": "The process of robot design is a complex task and the majority of design\ndecisions are still based on human intuition or tedious manual tuning. A more\ninformed way of facing this task is computational design methods where design\nparameters are concurrently optimized with corresponding controllers. Existing\napproaches, however, are strongly influenced by predefined control rules or\nmotion templates and cannot provide end-to-end solutions. In this paper, we\npresent a design optimization framework using model-free meta reinforcement\nlearning, and its application to the optimizing kinematics and actuator\nparameters of quadrupedal robots. We use meta reinforcement learning to train a\nlocomotion policy that can quickly adapt to different designs. This policy is\nused to evaluate each design instance during the design optimization. We\ndemonstrate that the policy can control robots of different designs to track\nrandom velocity commands over various rough terrains. With controlled\nexperiments, we show that the meta policy achieves close-to-optimal performance\nfor each design instance after adaptation. Lastly, we compare our results\nagainst a model-based baseline and show that our approach allows higher\nperformance while not being constrained by predefined motions or gait patterns.",
    "descriptor": "\nComments: 8 pages. To be published in IEEE Robotics and Automation Letters (RA-L) and ICRA 2023\n",
    "authors": [
      "\u00c1lvaro Belmonte-Baeza",
      "Joonho Lee",
      "Giorgio Valsecchi",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02750"
  },
  {
    "id": "arXiv:2210.02753",
    "title": "Communities as Vague Operators: Epistemological Questions for a Critical  Heuristics of Community Detection Algorithms",
    "abstract": "In this article, we aim to analyse the nature and epistemic consequences of\nwhat figures in network science as patterns of nodes and edges called\n'communities'. Tracing these as multi-faceted and ambivalent, we propose to\ndescribe the concept of community as a 'vague operator' related to Susan Leigh\nStar's notion of the boundary object but more loose, like a collection of\nhints, and propose that the ability to construct different modes of faceting\nthat are both vague and hyper-precise, in semiotic, technical and social terms\nis core both to digital politics and the analysis of 'communities'. Engaging\nwith these formations in terms drawn from mathematics and software studies\nenables a wider mapping of their formation. Disentangling different lineages in\nnetwork science then allows us to contextualise the founding account of\n'community' popularised by Michelle Girvan and Mark Newman in 2002. After\nstudying one particular community detection algorithm, the so called 'Louvain\nalgorithm', we comment on controversies arising with some of their more\nambiguous applications. We argue that 'community' can act as a real abstraction\nwith the power to reshape social relations such as producing echo chambers in\nsocial networking sites. To rework the epistemological terms of community\ndetection, we draw on debates and propositions in the literature of network\nscience to imagine a 'critical heuristics' that embraces partiality, epistemic\nhumbleness, reflexivity and artificiality.",
    "descriptor": "\nComments: 30 pages, 3 figures; parts of this article were presented in seminars at the Centre for Digital Inquiry at Warwick University and the Digital Democracies Institute at Simon Fraser University\n",
    "authors": [
      "Dominik Schindler",
      "Matthew Fuller"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02753"
  },
  {
    "id": "arXiv:2210.02755",
    "title": "Audio-Visual Face Reenactment",
    "abstract": "This work proposes a novel method to generate realistic talking head videos\nusing audio and visual streams. We animate a source image by transferring head\nmotion from a driving video using a dense motion field generated using\nlearnable keypoints. We improve the quality of lip sync using audio as an\nadditional input, helping the network to attend to the mouth region. We use\nadditional priors using face segmentation and face mesh to improve the\nstructure of the reconstructed faces. Finally, we improve the visual quality of\nthe generations by incorporating a carefully designed identity-aware generator\nmodule. The identity-aware generator takes the source image and the warped\nmotion features as input to generate a high-quality output with fine-grained\ndetails. Our method produces state-of-the-art results and generalizes well to\nunseen faces, languages, and voices. We comprehensively evaluate our approach\nusing multiple metrics and outperforming the current techniques both\nqualitative and quantitatively. Our work opens up several applications,\nincluding enabling low bandwidth video calls. We release a demo video and\nadditional information at\nthis http URL",
    "descriptor": "\nComments: Winter Conference on Applications of Computer Vision (WACV), 2023\n",
    "authors": [
      "Madhav Agarwal",
      "Rudrabha Mukhopadhyay",
      "Vinay Namboodiri",
      "C V Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02755"
  },
  {
    "id": "arXiv:2210.02756",
    "title": "Pressure-robust and conforming discretization of the Stokes equations on  anisotropic meshes",
    "abstract": "Pressure-robust discretizations for incompressible flows have been in the\nfocus of research for the past years. Many publications construct exactly\ndivergence-free methods or use a reconstruction approach [13] for existing\nmethods like the Crouzeix--Raviart element in order to achieve\npressure-robustness. To the best of our knowledge, except for our recent\npublications [3,4], all those articles impose a condition on the\nshape-regularity of the mesh, and the two mentioned papers that allow for\nanisotropic elements use a non-conforming velocity approximation. Based on the\nclassical Bernardi--Raugel element we provide a conforming pressure-robust\ndiscretization using the reconstruction approach on anisotropic meshes.\nNumerical examples support the theory.",
    "descriptor": "",
    "authors": [
      "Volker Kempf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02756"
  },
  {
    "id": "arXiv:2210.02757",
    "title": "Learning Consistency-Aware Unsigned Distance Functions Progressively  from Raw Point Clouds",
    "abstract": "Surface reconstruction for point clouds is an important task in 3D computer\nvision. Most of the latest methods resolve this problem by learning signed\ndistance functions (SDF) from point clouds, which are limited to reconstructing\nshapes or scenes with closed surfaces. Some other methods tried to represent\nshapes or scenes with open surfaces using unsigned distance functions (UDF)\nwhich are learned from large scale ground truth unsigned distances. However,\nthe learned UDF is hard to provide smooth distance fields near the surface due\nto the noncontinuous character of point clouds. In this paper, we propose a\nnovel method to learn consistency-aware unsigned distance functions directly\nfrom raw point clouds. We achieve this by learning to move 3D queries to reach\nthe surface with a field consistency constraint, where we also enable to\nprogressively estimate a more accurate surface. Specifically, we train a neural\nnetwork to gradually infer the relationship between 3D queries and the\napproximated surface by searching for the moving target of queries in a dynamic\nway, which results in a consistent field around the surface. Meanwhile, we\nintroduce a polygonization algorithm to extract surfaces directly from the\ngradient field of the learned UDF. The experimental results in surface\nreconstruction for synthetic and real scan data show significant improvements\nover the state-of-the-art under the widely used benchmarks.",
    "descriptor": "",
    "authors": [
      "Junsheng Zhou",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Yi Fang",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02757"
  },
  {
    "id": "arXiv:2210.02760",
    "title": "Cyber-Resilient Privacy Preservation and Secure Billing Approach for  Smart Energy Metering Devices",
    "abstract": "Most of the smart applications, such as smart energy metering devices, demand\nstrong privacy preservation to strengthen data privacy. However, it is\ndifficult to protect the privacy of the smart device data, especially on the\nclient side. It is mainly because payment for billing is computed by the server\ndeployed at the client's side, and it is highly challenging to prevent the\nleakage of client's information to unauthorised users. Various researchers have\ndiscussed this problem and have proposed different privacy preservation\ntechniques. Conventional techniques suffer from the problem of high\ncomputational and communication overload on the client side. In addition, the\nperformance of these techniques deteriorates due to computational complexity\nand their inability to handle the security of large-scale data. Due to these\nlimitations, it becomes easy for the attackers to introduce malicious attacks\non the server, posing a significant threat to data security. In this context,\nthis proposal intends to design novel privacy preservation and secure billing\nframework using deep learning techniques to ensure data security in smart\nenergy metering devices. This research aims to overcome the limitations of the\nexisting techniques to achieve robust privacy preservation in smart devices and\nincrease the cyber resilience of these devices.",
    "descriptor": "\nComments: Journal article\n",
    "authors": [
      "Venkatesh Kumar M"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.02760"
  },
  {
    "id": "arXiv:2210.02761",
    "title": "Learning Autonomous Vehicle Safety Concepts from Demonstrations",
    "abstract": "Evaluating the safety of an autonomous vehicle (AV) depends on the behavior\nof surrounding agents which can be heavily influenced by factors such as\nenvironmental context and informally-defined driving etiquette. A key challenge\nis in determining a minimum set of assumptions on what constitutes reasonable\nforeseeable behaviors of other road users for the development of AV safety\nmodels and techniques. In this paper, we propose a data-driven AV safety design\nmethodology that first learns ``reasonable'' behavioral assumptions from data,\nand then synthesizes an AV safety concept using these learned behavioral\nassumptions. We borrow techniques from control theory, namely high order\ncontrol barrier functions and Hamilton-Jacobi reachability, to provide\ninductive bias to aid interpretability, verifiability, and tractability of our\napproach. In our experiments, we learn an AV safety concept using\ndemonstrations collected from a highway traffic-weaving scenario, compare our\nlearned concept to existing baselines, and showcase its efficacy in evaluating\nreal-world driving logs.",
    "descriptor": "",
    "authors": [
      "Karen Leung",
      "Sushant Veer",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02761"
  },
  {
    "id": "arXiv:2210.02762",
    "title": "Vision Transformer Based Model for Describing a Set of Images as a Story",
    "abstract": "Visual Story-Telling is the process of forming a multi-sentence story from a\nset of images. Appropriately including visual variation and contextual\ninformation captured inside the input images is one of the most challenging\naspects of visual storytelling. Consequently, stories developed from a set of\nimages often lack cohesiveness, relevance, and semantic relationship. In this\npaper, we propose a novel Vision Transformer Based Model for describing a set\nof images as a story. The proposed method extracts the distinct features of the\ninput images using a Vision Transformer (ViT). Firstly, input images are\ndivided into 16X16 patches and bundled into a linear projection of flattened\npatches. The transformation from a single image to multiple image patches\ncaptures the visual variety of the input visual patterns. These features are\nused as input to a Bidirectional-LSTM which is part of the sequence encoder.\nThis captures the past and future image context of all image patches. Then, an\nattention mechanism is implemented and used to increase the discriminatory\ncapacity of the data fed into the language model, i.e. a Mogrifier-LSTM. The\nperformance of our proposed model is evaluated using the Visual Story-Telling\ndataset (VIST), and the results show that our model outperforms the current\nstate of the art models.",
    "descriptor": "",
    "authors": [
      "Zainy M. Malakan",
      "Ghulam Mubashar Hassan",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02762"
  },
  {
    "id": "arXiv:2210.02766",
    "title": "AutoQC: Automated Synthesis of Quantum Circuits Using Neural Network",
    "abstract": "While the ability to build quantum computers is improving dramatically,\ndeveloping quantum algorithms is limited and relies on human insight and\ningenuity. Although a number of quantum programming languages have been\ndeveloped, it is challenging for software developers who are not familiar with\nquantum computing to learn and use these languages. It is, therefore, necessary\nto develop tools to support developing new quantum algorithms and programs\nautomatically. This paper proposes AutoQC, an approach to automatically\nsynthesizing quantum circuits using the neural network from input and output\npairs. We consider a quantum circuit a sequence of quantum gates and synthesize\na quantum circuit probabilistically by prioritizing with a neural network at\neach step. The experimental results highlight the ability of AutoQC to\nsynthesize some essential quantum circuits at a lower cost.",
    "descriptor": "\nComments: 9 pages, 15 figures\n",
    "authors": [
      "Kentaro Murakami",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.02766"
  },
  {
    "id": "arXiv:2210.02768",
    "title": "Distilling Task-specific Logical Rules from Large Pre-trained Models",
    "abstract": "Logical rules, both transferable and explainable, are widely used as weakly\nsupervised signals for many downstream tasks such as named entity tagging. To\nreduce the human effort of writing rules, previous researchers adopt an\niterative approach to automatically learn logical rules from several seed\nrules. However, obtaining more seed rules can only be accomplished by extra\nhuman annotation with heavy costs. Limited by the size and quality of the seed\nrules, the model performance of previous systems is bounded. In this paper, we\ndevelop a novel framework STREAM to distill task-specific logical rules from\nlarge pre-trained models. Specifically, we borrow recent prompt-based language\nmodels as the knowledge expert to yield initial seed rules, and based on the\nformed high-quality instance pool that acts as an intermediary role, we keep\nteaching the expert to fit our task and learning task-specific logical rules.\nExperiments on three public named entity tagging benchmarks demonstrate the\neffectiveness of our proposed framework. With several predefined prompt\ntemplates, our system has gained significant improvements over previous\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Tao Chen",
      "Luxin Liu",
      "Xuepeng Jia",
      "Baoliang Cui",
      "Haihong Tang",
      "Siliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02768"
  },
  {
    "id": "arXiv:2210.02769",
    "title": "Artificial virtuous agents in a multiagent tragedy of the commons",
    "abstract": "Although virtue ethics has repeatedly been proposed as a suitable framework\nfor the development of artificial moral agents (AMAs), it has been proven\ndifficult to approach from a computational perspective. In this work, we\npresent the first technical implementation of artificial virtuous agents (AVAs)\nin moral simulations. First, we review previous conceptual and technical work\nin artificial virtue ethics and describe a functionalistic path to AVAs based\non dispositional virtues, bottom-up learning, and top-down eudaimonic reward.\nWe then provide the details of a technical implementation in a moral simulation\nbased on a tragedy of the commons scenario. The experimental results show how\nthe AVAs learn to tackle cooperation problems while exhibiting core features of\ntheir theoretical counterpart, including moral character, dispositional\nvirtues, learning from experience, and the pursuit of eudaimonia. Ultimately,\nwe argue that virtue ethics provides a compelling path toward morally excellent\nmachines and that our work provides an important starting point for such\nendeavors.",
    "descriptor": "\nComments: 18 pages, 5 figures, 3 tables. AI & SOCIETY (2022)\n",
    "authors": [
      "Jakob Stenseke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02769"
  },
  {
    "id": "arXiv:2210.02771",
    "title": "Modelling Commonsense Properties using Pre-Trained Bi-Encoders",
    "abstract": "Grasping the commonsense properties of everyday concepts is an important\nprerequisite to language understanding. While contextualised language models\nare reportedly capable of predicting such commonsense properties with\nhuman-level accuracy, we argue that such results have been inflated because of\nthe high similarity between training and test concepts. This means that models\nwhich capture concept similarity can perform well, even if they do not capture\nany knowledge of the commonsense properties themselves. In settings where there\nis no overlap between the properties that are considered during training and\ntesting, we find that the empirical performance of standard language models\ndrops dramatically. To address this, we study the possibility of fine-tuning\nlanguage models to explicitly model concepts and their properties. In\nparticular, we train separate concept and property encoders on two types of\nreadily available data: extracted hyponym-hypernym pairs and generic sentences.\nOur experimental results show that the resulting encoders allow us to predict\ncommonsense properties with much higher accuracy than is possible by directly\nfine-tuning language models. We also present experimental results for the\nrelated task of unsupervised hypernym discovery.",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Amit Gajbhiye",
      "Luis Espinosa-Anke",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02771"
  },
  {
    "id": "arXiv:2210.02772",
    "title": "Product Portfolio Management in Competitive Environments",
    "abstract": "Product diversity is one of the prominent factors for customers'\nsatisfaction, while from the firms' perspective, the additional engineering\ncosts required for product diversity should not exceed the acquired profits\nfrom the increase in their market share. Thus, one of the critical\ndecision-making tasks for companies is the selection of an optimal mix of\nproducts, namely product portfolio management (PPM). Traditional studies on PPM\nproblem have paid relatively less attention to the actions of other\ncompetitors. In this paper, we study PPM problem in a competitive environment\nwhere each firm's objective is to maximize its expected shared surplus. We\nmodel the competition with an $n$-player game that optimal product portfolios\nare driven from its Nash equilibrium. Utility functions are determined by the\nexpected value of the shared surplus. We analyze the strategic behavior of\nfirms to determine their optimal product portfolios.",
    "descriptor": "",
    "authors": [
      "Samira Hossein Ghorban",
      "Bardyaa Hesaam"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.02772"
  },
  {
    "id": "arXiv:2210.02773",
    "title": "Computing Threshold Budgets in Discrete-Bidding Games",
    "abstract": "In a two-player zero-sum graph game, the players move a token throughout the\ngraph to produce an infinite play, which determines the winner of the game.\n\\emph{Bidding games} are graph games in which in each turn, an auction\n(bidding) determines which player moves the token: the players have budgets,\nand in each turn, both players simultaneously submit bids that do not exceed\ntheir available budgets, the higher bidder moves the token, and pays the bid to\nthe lower bidder. We distinguish between {\\em continuous}- and {\\em\ndiscrete}-bidding games. In the latter, the granularity of the players' bids is\nrestricted, e.g., bids must be given in cents. Continuous-bidding games are\nwell understood, however, from a practical standpoint, discrete-bidding games\nare more appealing.\nIn this paper we focus on discrete-bidding games. We study the problem of\nfinding {\\em threshold budgets}; namely, a necessary and sufficient initial\nbudget for winning the game. Previously, the properties of threshold budgets\nwere only studied for reachability games. For parity discrete-bidding games,\nthresholds were known to exist, but their structure was not understood. We\ndescribe two algorithms for finding threshold budgets in parity\ndiscrete-bidding games. The first algorithm is a fixed-point algorithm, and it\nreveals the structure of the threshold budgets in these games. Second, we show\nthat the problem of finding threshold budgets is in \\NP and co\\NP for parity\ndiscrete-bidding games. Previously, only exponential-time algorithms where\nknown for reachability and parity objectives. A corollary of this proof is a\nconstruction of strategies that use polynomial-size memory.",
    "descriptor": "\nComments: The full version of a paper published at FSTTCS 2022\n",
    "authors": [
      "Guy Avni",
      "Suman Sadhukhan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.02773"
  },
  {
    "id": "arXiv:2210.02775",
    "title": "Paging with Succinct Predictions",
    "abstract": "Paging is a prototypical problem in the area of online algorithms. It has\nalso played a central role in the development of learning-augmented algorithms\n-- a recent line of research that aims to ameliorate the shortcomings of\nclassical worst-case analysis by giving algorithms access to predictions. Such\npredictions can typically be generated using a machine learning approach, but\nthey are inherently imperfect. Previous work on learning-augmented paging has\ninvestigated predictions on (i) when the current page will be requested again\n(reoccurrence predictions), (ii) the current state of the cache in an optimal\nalgorithm (state predictions), (iii) all requests until the current page gets\nrequested again, and (iv) the relative order in which pages are requested.\nWe study learning-augmented paging from the new perspective of requiring the\nleast possible amount of predicted information. More specifically, the\npredictions obtained alongside each page request are limited to one bit only.\nWe consider two natural such setups: (i) discard predictions, in which the\npredicted bit denotes whether or not it is ``safe'' to evict this page, and\n(ii) phase predictions, where the bit denotes whether the current page will be\nrequested in the next phase (for an appropriate partitioning of the input into\nphases). We develop algorithms for each of the two setups that satisfy all\nthree desirable properties of learning-augmented algorithms -- that is, they\nare consistent, robust and smooth -- despite being limited to a one-bit\nprediction per request. We also present lower bounds establishing that our\nalgorithms are essentially best possible.",
    "descriptor": "",
    "authors": [
      "Antonios Antoniadis",
      "Joan Boyar",
      "Marek Eli\u00e1\u0161",
      "Lene M. Favrholdt",
      "Ruben Hoeksma",
      "Kim S. Larsen",
      "Adam Polak",
      "Bertrand Simon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.02775"
  },
  {
    "id": "arXiv:2210.02785",
    "title": "FloatingFusion: Depth from ToF and Image-stabilized Stereo Cameras",
    "abstract": "High-accuracy per-pixel depth is vital for computational photography, so\nsmartphones now have multimodal camera systems with time-of-flight (ToF) depth\nsensors and multiple color cameras. However, producing accurate high-resolution\ndepth is still challenging due to the low resolution and limited active\nillumination power of ToF sensors. Fusing RGB stereo and ToF information is a\npromising direction to overcome these issues, but a key problem remains: to\nprovide high-quality 2D RGB images, the main color sensor's lens is optically\nstabilized, resulting in an unknown pose for the floating lens that breaks the\ngeometric relationships between the multimodal image sensors. Leveraging ToF\ndepth estimates and a wide-angle RGB camera, we design an automatic calibration\ntechnique based on dense 2D/3D matching that can estimate camera extrinsic,\nintrinsic, and distortion parameters of a stabilized main RGB sensor from a\nsingle snapshot. This lets us fuse stereo and ToF cues via a correlation\nvolume. For fusion, we apply deep learning via a real-world training dataset\nwith depth supervision estimated by a neural reconstruction method. For\nevaluation, we acquire a test dataset using a commercial high-power depth\ncamera and show that our approach achieves higher accuracy than existing\nbaselines.",
    "descriptor": "",
    "authors": [
      "Andreas Meuleman",
      "Hakyeong Kim",
      "James Tompkin",
      "Min H. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02785"
  },
  {
    "id": "arXiv:2210.02795",
    "title": "Why Should I Choose You? AutoXAI: A Framework for Selecting and Tuning  eXplainable AI Solutions",
    "abstract": "In recent years, a large number of XAI (eXplainable Artificial Intelligence)\nsolutions have been proposed to explain existing ML (Machine Learning) models\nor to create interpretable ML models. Evaluation measures have recently been\nproposed and it is now possible to compare these XAI solutions. However,\nselecting the most relevant XAI solution among all this diversity is still a\ntedious task, especially when meeting specific needs and constraints. In this\npaper, we propose AutoXAI, a framework that recommends the best XAI solution\nand its hyperparameters according to specific XAI evaluation metrics while\nconsidering the user's context (dataset, ML model, XAI needs and constraints).\nIt adapts approaches from context-aware recommender systems and strategies of\noptimization and evaluation from AutoML (Automated Machine Learning). We apply\nAutoXAI to two use cases, and show that it recommends XAI solutions adapted to\nthe user's needs with the best hyperparameters matching the user's constraints.",
    "descriptor": "\nComments: 16 pages, 7 figures, to be published in CIKM2022\n",
    "authors": [
      "Robin Cugny",
      "Julien Aligon",
      "Max Chevalier",
      "Geoffrey Roman Jimenez",
      "Olivier Teste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02795"
  },
  {
    "id": "arXiv:2210.02796",
    "title": "Hypernetwork approach to Bayesian MAML",
    "abstract": "The main goal of Few-Shot learning algorithms is to enable learning from\nsmall amounts of data. One of the most popular and elegant Few-Shot learning\napproaches is Model-Agnostic Meta-Learning (MAML). The main idea behind this\nmethod is to learn shared universal weights of a meta-model, which then are\nadapted for specific tasks. However, due to limited data size, the method\nsuffers from over-fitting and poorly quantifies uncertainty. Bayesian\napproaches could, in principle, alleviate these shortcomings by learning weight\ndistributions in place of point-wise weights. Unfortunately, previous Bayesian\nmodifications of MAML are limited in a way similar to the classic MAML, e.g.,\ntask-specific adaptations must share the same structure and can not diverge\nmuch from the universal meta-model. Additionally, task-specific distributions\nare considered as posteriors to the universal distributions working as priors,\nand optimizing them jointly with gradients is hard and poses a risk of getting\nstuck in local optima.\nIn this paper, we propose BayesianHyperShot, a novel generalization of\nBayesian MAML, which employs Bayesian principles along with Hypernetworks for\nMAML. We achieve better convergence than the previous methods by classically\nlearning universal weights. Furthermore, Bayesian treatment of the specific\ntasks enables uncertainty quantification, and high flexibility of task\nadaptations is achieved using Hypernetworks instead of gradient-based updates.\nConsequently, the proposed approach not only improves over the previous\nmethods, both classic and Bayesian MAML in several standard Few-Shot learning\nbenchmarks but also benefits from the properties of the Bayesian framework.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.15745\n",
    "authors": [
      "Piotr Borycki",
      "Piotr Kubacki",
      "Marcin Przewi\u0119\u017alikowski",
      "Tomasz Ku\u015bmierczyk",
      "Jacek Tabor",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02796"
  },
  {
    "id": "arXiv:2210.02798",
    "title": "Data Augmentation-free Unsupervised Learning for 3D Point Cloud  Understanding",
    "abstract": "Unsupervised learning on 3D point clouds has undergone a rapid evolution,\nespecially thanks to data augmentation-based contrastive methods. However, data\naugmentation is not ideal as it requires a careful selection of the type of\naugmentations to perform, which in turn can affect the geometric and semantic\ninformation learned by the network during self-training. To overcome this\nissue, we propose an augmentation-free unsupervised approach for point clouds\nto learn transferable point-level features via soft clustering, named SoftClu.\nSoftClu assumes that the points belonging to a cluster should be close to each\nother in both geometric and feature spaces. This differs from typical\ncontrastive learning, which builds similar representations for a whole point\ncloud and its augmented versions. We exploit the affiliation of points to their\nclusters as a proxy to enable self-training through a pseudo-label prediction\ntask. Under the constraint that these pseudo-labels induce the equipartition of\nthe point cloud, we cast SoftClu as an optimal transport problem. We formulate\nan unsupervised loss to minimize the standard cross-entropy between\npseudo-labels and predicted labels. Experiments on downstream applications,\nsuch as 3D object classification, part segmentation, and semantic segmentation,\nshow the effectiveness of our framework in outperforming state-of-the-art\ntechniques.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Guofeng Mei",
      "Cristiano Saltori",
      "Fabio Poiesi",
      "Jian Zhang",
      "Elisa Ricci",
      "Nicu Sebe",
      "Qiang Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02798"
  },
  {
    "id": "arXiv:2210.02804",
    "title": "Just ClozE! A Fast and Simple Method for Evaluating the Factual  Consistency in Abstractive Summarization",
    "abstract": "The issue of factual consistency in abstractive summarization has attracted\nmuch attention in recent years, and the evaluation of factual consistency\nbetween summary and document has become an important and urgent task. Most of\nthe current evaluation metrics are adopted from the question answering (QA).\nHowever, the application of QA-based metrics is extremely time-consuming in\npractice, causing the iteration cycle of abstractive summarization research to\nbe severely prolonged. In this paper, we propose a new method called ClozE to\nevaluate factual consistency by cloze model, instantiated based on masked\nlanguage model(MLM), with strong interpretability and substantially higher\nspeed. We demonstrate that ClozE can reduce the evaluation time by nearly\n96$\\%$ relative to QA-based metrics while retaining their interpretability and\nperformance through experiments on six human-annotated datasets and a\nmeta-evaluation benchmark GO FIGURE \\citep{gabriel2020go}. We also implement\nexperiments to further demonstrate more characteristics of ClozE in terms of\nperformance and speed. In addition, we conduct an experimental analysis of the\nlimitations of ClozE, which suggests future research directions. The code and\nmodels for ClozE will be released upon the paper acceptance.",
    "descriptor": "\nComments: The manuscript for EMNLP 2022\n",
    "authors": [
      "Yiyang Li",
      "Lei Li",
      "Qing Yang",
      "Marina Litvak",
      "Natalia Vanetik",
      "Dingxin Hu",
      "Yuze Li",
      "Yanquan Zhou",
      "Dongliang Xu",
      "Xuanyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02804"
  },
  {
    "id": "arXiv:2210.02807",
    "title": "A Review of Multilingualism in and for Ontologies",
    "abstract": "The Multilingual Semantic Web has been in focus for over a decade.\nMultilingualism in Linked Data and RDF has shown substantial adoption, but this\nis unclear for ontologies since the last review 15 years ago. One of the design\ngoals for OWL was internationalisation, with the aim that an ontology is usable\nacross languages and cultures. Much research to improve on multilingual\nontologies has taken place in the meantime, and presumably multilingual linked\ndata could use multilingual ontologies. Therefore, this review seeks to (i)\nelucidate and compare the modelling options for multilingual ontologies, (ii)\nexamine extant ontologies for their multilingualism, and (iii) evaluate\nontology editors for their ability to manage a multilingual ontology. Nine\ndifferent principal approaches for modelling multilinguality in ontologies were\nidentified, which fall into either of the following approaches: using\nmultilingual labels, linguistic models, or a mapping-based approach. They are\ncompared on design by means of an ad hoc visualisation mode of modelling\nmultilingual information for ontologies, shortcomings, and what issues they aim\nto solve. For the ontologies, we extracted production-level and accessible\nontologies from BioPortal and the LOV repositories, which had, at best, 6.77%\nand 15.74% multilingual ontologies, respectively, where most of them have only\npartial translations and they all use a labels-based approach only. Based on a\nset of nine tool requirements for managing multilingual ontologies, the\nassessment of seven relevant ontology editors showed that there are significant\ngaps in tooling support, with VocBench 3 nearest of meeting them all. This\nstock-taking may function as a new baseline and motivate new research\ndirections for multilingual ontologies.",
    "descriptor": "\nComments: 22 pages, 10 figures, 8 tables; soon to be submitted to an international journal\n",
    "authors": [
      "Frances Gillis-Webber",
      "C. Maria Keet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02807"
  },
  {
    "id": "arXiv:2210.02808",
    "title": "Effective Self-supervised Pre-training on Low-compute networks without  Distillation",
    "abstract": "Despite the impressive progress of self-supervised learning (SSL), its\napplicability to low-compute networks has received limited attention. Reported\nperformance has trailed behind standard supervised pre-training by a large\nmargin, barring self-supervised learning from making an impact on models that\nare deployed on device. Most prior works attribute this poor performance to the\ncapacity bottleneck of the low-compute networks and opt to bypass the problem\nthrough the use of knowledge distillation (KD). In this work, we revisit SSL\nfor efficient neural networks, taking a closer at what are the detrimental\nfactors causing the practical limitations, and whether they are intrinsic to\nthe self-supervised low-compute setting. We find that, contrary to accepted\nknowledge, there is no intrinsic architectural bottleneck, we diagnose that the\nperformance bottleneck is related to the model complexity vs regularization\nstrength trade-off. In particular, we start by empirically observing that the\nuse of local views can have a dramatic impact on the effectiveness of the SSL\nmethods. This hints at view sampling being one of the performance bottlenecks\nfor SSL on low-capacity networks. We hypothesize that the view sampling\nstrategy for large neural networks, which requires matching views in very\ndiverse spatial scales and contexts, is too demanding for low-capacity\narchitectures. We systematize the design of the view sampling mechanism,\nleading to a new training methodology that consistently improves the\nperformance across different SSL methods (e.g. MoCo-v2, SwAV, DINO), different\nlow-size networks (e.g. MobileNetV2, ResNet18, ResNet34, ViT-Ti), and different\ntasks (linear probe, object detection, instance segmentation and\nsemi-supervised learning). Our best models establish a new state-of-the-art for\nSSL methods on low-compute networks despite not using a KD loss term.",
    "descriptor": "",
    "authors": [
      "Fuwen Tan",
      "Fatemeh Saleh",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02808"
  },
  {
    "id": "arXiv:2210.02821",
    "title": "Microsoft Defender Will Be Defended: MemoryRanger Prevents Blinding  Windows AV",
    "abstract": "Windows OS is facing a huge rise in kernel attacks. An overview of popular\ntechniques that result in loading kernel drivers will be presented. One of the\nkey targets of modern threats is disabling and blinding Microsoft Defender, a\ndefault Windows AV. The analysis of recent driver-based attacks will be given,\nthe challenge is to block them. The survey of user- and kernel-level attacks on\nMicrosoft Defender will be given. One of the recently published attackers\ntechniques abuses Mandatory Integrity Control (MIC) and Security Reference\nMonitor (SRM) by modifying Integrity Level and Debug Privileges for the\nMicrosoft Defender via syscalls. However, this user-mode attack can be blocked\nvia the Windows 'trust labels' mechanism. The presented paper discovered the\ninternals of MIC and SRM, including the analysis of Microsoft Defender during\nmalware detection. We show how attackers can attack Microsoft Defender using a\nkernel-mode driver. This driver modifies the fields of the Token structure\nallocated for the Microsoft Defender application. The presented attack resulted\nin disabling Microsoft Defender, without terminating any of its processes and\nwithout triggering any Windows security features, such as PatchGuard. The\ncustomized hypervisor-based solution named MemoryRanger was used to protect the\nWindows Defender kernel structures. The experiments show that MemoryRanger\nsuccessfully restricts access to the sensitive kernel data from illegal access\nattempts with affordable performance degradation.",
    "descriptor": "\nComments: 29 pages, 17 figures, 1 table, In Proceedings of the ADFSL 2022, USA\n",
    "authors": [
      "Denis Pogonin",
      "Igor Korkin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.02821"
  },
  {
    "id": "arXiv:2210.02826",
    "title": "Single-Use Delegatable Signatures Based on Smart Contracts",
    "abstract": "Delegation of cryptographic signing rights has found many application in the\nliterature and the real world. However, despite very advanced functionalities\nand specific use cases, existing solutions share the natural limitation that\nthe number of usages of these signing rights cannot be efficiently limited, but\nusers can at most be disincentivized to abuse their rights.\nIn this paper, we suggest a solution to this problem based on blockchains. We\nlet a user define a smart contract defining delegated signing rights, which\nneeds to be triggered to successfully sign a message. By leveraging the\nimmutability of the blockchain, our construction can now guarantee that a\nuser-defined threshold of signature invocations cannot be exceeded, thereby\ncircumventing the need for dedicated hardware or similar assistance in existing\nconstructions for one-time programs.\nWe discuss different constructions supporting different features, and provide\nconcrete implementations in the Solidity language of the Ethereum blockchain,\nproving the real-world efficiency and feasibility of our construction.",
    "descriptor": "\nComments: The 16th International Workshop on Frontiers in Availability, Reliability and Security (FARES 2021)\n",
    "authors": [
      "Stephan Krenn",
      "Thomas Lor\u00fcnser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02826"
  },
  {
    "id": "arXiv:2210.02829",
    "title": "Melody Infilling with User-Provided Structural Context",
    "abstract": "This paper proposes a novel Transformer-based model for music score\ninfilling, to generate a music passage that fills in the gap between given past\nand future contexts. While existing infilling approaches can generate a passage\nthat connects smoothly locally with the given contexts, they do not take into\naccount the musical form or structure of the music and may therefore generate\noverly smooth results. To address this issue, we propose a structure-aware\nconditioning approach that employs a novel attention-selecting module to supply\nuser-provided structure-related information to the Transformer for infilling.\nWith both objective and subjective evaluations, we show that the proposed model\ncan harness the structural information effectively and generate melodies in the\nstyle of pop of higher quality than the two existing structure-agnostic\ninfilling models.",
    "descriptor": "",
    "authors": [
      "Chih-Pin Tan",
      "Alvin W.Y. Su",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02829"
  },
  {
    "id": "arXiv:2210.02830",
    "title": "KnowledgeShovel: An AI-in-the-Loop Document Annotation System for  Scientific Knowledge Base Construction",
    "abstract": "Constructing a comprehensive, accurate, and useful scientific knowledge base\nis crucial for human researchers synthesizing scientific knowledge and for\nenabling Al-driven scientific discovery. However, the current process is\ndifficult, error-prone, and laborious due to (1) the enormous amount of\nscientific literature available; (2) the highly-specialized scientific domains;\n(3) the diverse modalities of information (text, figure, table); and, (4) the\nsilos of scientific knowledge in different publications with inconsistent\nformats and structures. Informed by a formative study and iterated with\nparticipatory design workshops, we designed and developed KnowledgeShovel, an\nAl-in-the-Loop document annotation system for researchers to construct\nscientific knowledge bases. The design of KnowledgeShovel introduces a\nmulti-step multi-modal human-AI collaboration pipeline that aligns with users'\nexisting workflows to improve data accuracy while reducing the human burden. A\nfollow-up user evaluation with 7 geoscience researchers shows that\nKnowledgeShovel can enable efficient construction of scientific knowledge bases\nwith satisfactory accuracy.",
    "descriptor": "\nComments: 33 pages, 17 figures, manuscript submitted to CHI2023\n",
    "authors": [
      "Shao Zhang",
      "Yuting Jia",
      "Hui Xu",
      "Dakuo Wang",
      "Toby Jia-jun Li",
      "Ying Wen",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02830"
  },
  {
    "id": "arXiv:2210.02832",
    "title": "Dynamic Voltage Stiffness Control Technique for a Virtual Oscillator  based Grid-forming Controller",
    "abstract": "Virtual oscillator control is the latest control technique for grid-forming\ninverters. Virtual Oscillator based Controllers (VOCs) provide all the\nsteady-state droop functionalities of conventional droop controllers and, in\naddition, the time-domain synchronization with a connected electrical network.\nHowever, existing literature does not consider the aspect of dynamic control\nover the voltage stiffness of a VOC. Voltage stiffness is a vital parameter for\na grid-forming inverter. If the voltage stiffness is too high, the inverter\npicks up all the reactive power demand of the PCC. In contrast, if the\nstiffness is too low, the inverter does not participate in voltage regulation\nat all. Limiting the reactive power output during a higher voltage sag,\nespecially when connected to a weak grid, is challenging for a VOC. Entering\ninto the current control mode is the existing solution, but it severely affects\nthe effective synchronization between the VOC and the voltages of the PCC. As a\nresult, the grid-forming mode of operation becomes inefficient. This article\nhas introduced a Virtual Impedance (VIm) based dynamic voltage stiffness\ncontrol technique for VOCs. The systematic design procedure for the proposed\nvoltage stiffness controller is presented. In addition, a rigorous approach for\nstability analysis is presented.",
    "descriptor": "\nComments: 8 pages, 16 figures\n",
    "authors": [
      "Ritwik Ghosh",
      "Narsa Reddy Tummuru",
      "Bharat Singh Rajpuohit"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02832"
  },
  {
    "id": "arXiv:2210.02833",
    "title": "Matching Text and Audio Embeddings: Exploring Transfer-learning  Strategies for Language-based Audio Retrieval",
    "abstract": "We present an analysis of large-scale pretrained deep learning models used\nfor cross-modal (text-to-audio) retrieval. We use embeddings extracted by these\nmodels in a metric learning framework to connect matching pairs of audio and\ntext. Shallow neural networks map the embeddings to a common dimensionality.\nOur system, which is an extension of our submission to the Language-based Audio\nRetrieval Task of the DCASE Challenge 2022, employs the RoBERTa foundation\nmodel as the text embedding extractor. A pretrained PANNs model extracts the\naudio embeddings. To improve the generalisation of our model, we investigate\nhow pretraining with audio and associated noisy text collected from the online\nplatform Freesound improves the performance of our method. Furthermore, our\nablation study reveals that the proper choice of the loss function and\nfine-tuning the pretrained models are essential in training a competitive\nretrieval system.",
    "descriptor": "\nComments: 5 pages, 2 figures. Accepted at Detection and Classification of Acoustic Scenes and Events 2022 (DCASE2022)\n",
    "authors": [
      "Benno Weck",
      "Miguel P\u00e9rez Fern\u00e1ndez",
      "Holger Kirchhoff",
      "Xavier Serra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02833"
  },
  {
    "id": "arXiv:2210.02834",
    "title": "Robust Double-Encoder Network for RGB-D Panoptic Segmentation",
    "abstract": "Perception is crucial for robots that act in real-world environments, as\nautonomous systems need to see and understand the world around them to act\nappropriately. Panoptic segmentation provides an interpretation of the scene by\ncomputing a pixel-wise semantic label together with instance IDs. In this\npaper, we address panoptic segmentation using RGB-D data of indoor scenes. We\npropose a novel encoder-decoder neural network that processes RGB and depth\nseparately through two encoders. The features of the individual encoders are\nprogressively merged at different resolutions, such that the RGB features are\nenhanced using complementary depth information. We propose a novel merging\napproach called ResidualExcite, which reweighs each entry of the feature map\naccording to its importance. With our double-encoder architecture, we are\nrobust to missing cues. In particular, the same model can train and infer on\nRGB-D, RGB-only, and depth-only input data, without the need to train\nspecialized models. We evaluate our method on publicly available datasets and\nshow that our approach achieves superior results compared to other common\napproaches for panoptic segmentation.",
    "descriptor": "",
    "authors": [
      "Matteo Sodano",
      "Federico Magistri",
      "Tiziano Guadagnino",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02834"
  },
  {
    "id": "arXiv:2210.02835",
    "title": "Sequentially Swapping Tokens: Further on Graph Classes",
    "abstract": "We study the following variant of the 15 puzzle. Given a graph and two token\nplacements on the vertices, we want to find a walk of the minimum length (if\nany exists) such that the sequence of token swappings along the walk obtains\none of the given token placements from the other one. This problem was\nintroduced as Sequential Token Swapping by Yamanaka et al. [JGAA 2019], who\nshowed that the problem is intractable in general but polynomial-time solvable\nfor trees, complete graphs, and cycles. In this paper, we present a\npolynomial-time algorithm for block-cactus graphs, which include all previously\nknown cases. We also present general tools for showing the hardness of problem\non restricted graph classes such as chordal graphs and chordal bipartite\ngraphs. We also show that the problem is hard on grids and king's graphs, which\nare the graphs corresponding to the 15 puzzle and its variant with relaxed\nmoves.",
    "descriptor": "\nComments: 28 pages, 15 figures, SOFSEM 2023\n",
    "authors": [
      "Hironori Kiya",
      "Yuto Okada",
      "Hirotaka Ono",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02835"
  },
  {
    "id": "arXiv:2210.02837",
    "title": "Cloud Hopping; Navigating in 3D Uneven Environments via Supervoxels and  Control Lyapunov Function",
    "abstract": "This paper presents a novel feedback motion planning method for mobile robot\nnavigation in 3D uneven terrains. We take advantage of the \\textit{supervoxel}\nrepresentation of point clouds, which enables a compact connectivity graph of\ntraversable regions on the point cloud maps. Given this graph of traversable\nareas, our approach navigates the robot to any reachable goal pose using a\ncontrol Lyapunov function (cLf) and a navigation function. The cLf ensures the\nkinodynamic feasibility and target convergence of the generated motion plans,\nwhile the navigation function optimizes the resulting feedback motion plans. We\ncarried out navigation experiments in real and simulated 3D uneven terrains. In\nall circumstances, the experimental findings show that our approach performs\nsuperior to the baselines, proving the approach's efficiency and adaptability\nto navigate a robot in challenging uneven 3D terrains. The proposed method can\nalso navigate a robot with a particular objective, e.g., shortest-distance or\nleast-inclined plan. We compared our approach to well-established\nsampling-based motion planners in which our method outperformed all other\nplanners in terms of execution time and resulting path length. Finally, we\nprovide an open-source implementation of the proposed method to benefit the\nrobotics community.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Fetullah Atas",
      "Grzegorz Cielniak",
      "Lars Grimstad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02837"
  },
  {
    "id": "arXiv:2210.02840",
    "title": "Deep Reinforcement Learning based Evasion Generative Adversarial Network  for Botnet Detection",
    "abstract": "Botnet detectors based on machine learning are potential targets for\nadversarial evasion attacks. Several research works employ adversarial training\nwith samples generated from generative adversarial nets (GANs) to make the\nbotnet detectors adept at recognising adversarial evasions. However, the\nsynthetic evasions may not follow the original semantics of the input samples.\nThis paper proposes a novel GAN model leveraged with deep reinforcement\nlearning (DRL) to explore semantic aware samples and simultaneously harden its\ndetection. A DRL agent is used to attack the discriminator of the GAN that acts\nas a botnet detector. The discriminator is trained on the crafted perturbations\nby the agent during the GAN training, which helps the GAN generator converge\nearlier than the case without DRL. We name this model RELEVAGAN, i.e. [\"relive\na GAN\" or deep REinforcement Learning-based Evasion Generative Adversarial\nNetwork] because, with the help of DRL, it minimises the GAN's job by letting\nits generator explore the evasion samples within the semantic limits. During\nthe GAN training, the attacks are conducted to adjust the discriminator weights\nfor learning crafted perturbations by the agent. RELEVAGAN does not require\nadversarial training for the ML classifiers since it can act as an adversarial\nsemantic-aware botnet detection model. Code will be available at\nhttps://github.com/rhr407/RELEVAGAN.",
    "descriptor": "",
    "authors": [
      "Rizwan Hamid Randhawa",
      "Nauman Aslam",
      "Mohammad Alauthman",
      "Muhammad Khalid",
      "Husnain Rafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02840"
  },
  {
    "id": "arXiv:2210.02841",
    "title": "Detecting Irregular Network Activity with Adversarial Learning and  Expert Feedback",
    "abstract": "Anomaly detection is a ubiquitous and challenging task relevant across many\ndisciplines. With the vital role communication networks play in our daily\nlives, the security of these networks is imperative for smooth functioning of\nsociety. To this end, we propose a novel self-supervised deep learning\nframework CAAD for anomaly detection in wireless communication systems.\nSpecifically, CAAD employs contrastive learning in an adversarial setup to\nlearn effective representations of normal and anomalous behavior in wireless\nnetworks. We conduct rigorous performance comparisons of CAAD with several\nstate-of-the-art anomaly detection techniques and verify that CAAD yields a\nmean performance improvement of 92.84%. Additionally, we also augment CAAD\nenabling it to systematically incorporate expert feedback through a novel\ncontrastive learning feedback loop to improve the learned representations and\nthereby reduce prediction uncertainty (CAAD-EF). We view CAAD-EF as a novel,\nholistic and widely applicable solution to anomaly detection.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Gopikrishna Rathinavel",
      "Nikhil Muralidhar",
      "Timothy O'Shea",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02841"
  },
  {
    "id": "arXiv:2210.02843",
    "title": "CIR-Net: Cross-modality Interaction and Refinement for RGB-D Salient  Object Detection",
    "abstract": "Focusing on the issue of how to effectively capture and utilize\ncross-modality information in RGB-D salient object detection (SOD) task, we\npresent a convolutional neural network (CNN) model, named CIR-Net, based on the\nnovel cross-modality interaction and refinement. For the cross-modality\ninteraction, 1) a progressive attention guided integration unit is proposed to\nsufficiently integrate RGB-D feature representations in the encoder stage, and\n2) a convergence aggregation structure is proposed, which flows the RGB and\ndepth decoding features into the corresponding RGB-D decoding streams via an\nimportance gated fusion unit in the decoder stage. For the cross-modality\nrefinement, we insert a refinement middleware structure between the encoder and\nthe decoder, in which the RGB, depth, and RGB-D encoder features are further\nrefined by successively using a self-modality attention refinement unit and a\ncross-modality weighting refinement unit. At last, with the gradually refined\nfeatures, we predict the saliency map in the decoder stage. Extensive\nexperiments on six popular RGB-D SOD benchmarks demonstrate that our network\noutperforms the state-of-the-art saliency detectors both qualitatively and\nquantitatively.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing 2022, 16 pages, 11 figures\n",
    "authors": [
      "Runmin Cong",
      "Qinwei Lin",
      "Chen Zhang",
      "Chongyi Li",
      "Xiaochun Cao",
      "Qingming Huang",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02843"
  },
  {
    "id": "arXiv:2210.02844",
    "title": "How Far Are We from Real Synonym Substitution Attacks?",
    "abstract": "In this paper, we explore the following question: how far are we from real\nsynonym substitution attacks (SSAs). We approach this question by examining how\nSSAs replace words in the original sentence and show that there are still\nunresolved obstacles that make current SSAs generate invalid adversarial\nsamples. We reveal that four widely used word substitution methods generate a\nlarge fraction of invalid substitution words that are ungrammatical or do not\npreserve the original sentence's semantics. Next, we show that the semantic and\ngrammatical constraints used in SSAs for detecting invalid word replacements\nare highly insufficient in detecting invalid adversarial samples. Our work is\nan important stepping stone to constructing better SSAs in the future.",
    "descriptor": "\nComments: Preprint, work in progress\n",
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02844"
  },
  {
    "id": "arXiv:2210.02845",
    "title": "A unified steady and unsteady formulation for hydrodynamic potential  flow simulations with fully nonlinear free surface boundary conditions",
    "abstract": "This work discusses the correct modeling of the fully nonlinear free surface\nboundary conditions to be prescribed in water waves flow simulations based on\npotential flow theory. The main goal of such a discussion is that of\nidentifying a mathematical formulation and a numerical treatment that can be\nused both to carry out transient simulations, and to compute steady solutions\n-- for any flow admitting them. In the literature on numerical towing tank in\nfact, steady and unsteady fully nonlinear potential flow solvers are\ncharacterized by different mathematical formulations. The kinematic and dynamic\nfully nonlinear free surface boundary conditions are discussed, and in\nparticular it is proven that the kinematic free surface boundary condition,\nwritten in semi-Lagrangian form, can be substituted by an equivalent non\npenetration boundary condition by all means identical to the one used on the\nsurface of floating bodies or on the basin bottom. The simplified mathematical\nproblem obtained is discretized over space and time via Boundary Element Method\n(BEM) and Implicit Backward Difference Formula (BDF) scheme, respectively. The\nresults confirm that the solver implemented is able to solve steady potential\nflow problems just by eliminating null time derivatives in the unsteady\nformulation. Numerical results obtained confirm that the solver implemented is\nable to accurately reproduce results of classical steady flow solvers available\nin the literature.",
    "descriptor": "",
    "authors": [
      "Andrea Mola",
      "Nicola Giuliani",
      "\u00d3scar Crego",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.02845"
  },
  {
    "id": "arXiv:2210.02847",
    "title": "A Distributed System-level Diagnosis Model for the Implementation of  Unreliable Failure Detectors",
    "abstract": "Reliable systems require effective monitoring techniques for fault\nidentification. System-level diagnosis was originally proposed in the 1960s as\na test-based approach to monitor and identify faulty components of a general\nsystem. Over the last decades, several diagnosis models and strategies have\nbeen proposed, based on different fault models, and applied to the most diverse\ntypes of computer systems. In the 1990s, unreliable failure detectors emerged\nas an abstraction to enable consensus in asynchronous systems subject to crash\nfaults. Since then, failure detectors have become the \\textit{de facto}\nstandard for monitoring distributed systems. The purpose of the present work is\nto fill a conceptual gap by presenting a distributed diagnosis model that is\nconsistent with unreliable failure detectors. Results are presented for the\nnumber of tests/monitoring messages required, latency for event detection, as\nwell as completeness and accuracy. Three different failure detectors compliant\nwith the proposed model are presented, including vRing and vCube which provide\nscalable alternatives to the traditional all-monitor-all strategy adopted by\nmost existing failure detectors.",
    "descriptor": "",
    "authors": [
      "Elias P. Duarte Jr.",
      "Luiz A. Rodrigues",
      "Edson T. Camargo",
      "Rogerio Turchetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.02847"
  },
  {
    "id": "arXiv:2210.02849",
    "title": "XDoc: Unified Pre-training for Cross-Format Document Understanding",
    "abstract": "The surge of pre-training has witnessed the rapid development of document\nunderstanding recently. Pre-training and fine-tuning framework has been\neffectively used to tackle texts in various formats, including plain texts,\ndocument texts, and web texts. Despite achieving promising performance,\nexisting pre-trained models usually target one specific document format at one\ntime, making it difficult to combine knowledge from multiple document formats.\nTo address this, we propose XDoc, a unified pre-trained model which deals with\ndifferent document formats in a single model. For parameter efficiency, we\nshare backbone parameters for different formats such as the word embedding\nlayer and the Transformer layers. Meanwhile, we introduce adaptive layers with\nlightweight parameters to enhance the distinction across different formats.\nExperimental results have demonstrated that with only 36.7% parameters, XDoc\nachieves comparable or even better performance on a variety of downstream tasks\ncompared with the individual pre-trained models, which is cost effective for\nreal-world deployment. The code and pre-trained models will be publicly\navailable at \\url{https://aka.ms/xdoc}.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Jingye Chen",
      "Tengchao Lv",
      "Lei Cui",
      "Cha Zhang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02849"
  },
  {
    "id": "arXiv:2210.02853",
    "title": "NeuDep: Neural Binary Memory Dependence Analysis",
    "abstract": "Determining whether multiple instructions can access the same memory location\nis a critical task in binary analysis. It is challenging as statically\ncomputing precise alias information is undecidable in theory. The problem\naggravates at the binary level due to the presence of compiler optimizations\nand the absence of symbols and types. Existing approaches either produce\nsignificant spurious dependencies due to conservative analysis or scale poorly\nto complex binaries.\nWe present a new machine-learning-based approach to predict memory\ndependencies by exploiting the model's learned knowledge about how binary\nprograms execute. Our approach features (i) a self-supervised procedure that\npretrains a neural net to reason over binary code and its dynamic value flows\nthrough memory addresses, followed by (ii) supervised finetuning to infer the\nmemory dependencies statically. To facilitate efficient learning, we develop\ndedicated neural architectures to encode the heterogeneous inputs (i.e., code,\ndata values, and memory addresses from traces) with specific modules and fuse\nthem with a composition learning strategy.\nWe implement our approach in NeuDep and evaluate it on 41 popular software\nprojects compiled by 2 compilers, 4 optimizations, and 4 obfuscation passes. We\ndemonstrate that NeuDep is more precise (1.5x) and faster (3.5x) than the\ncurrent state-of-the-art. Extensive probing studies on security-critical\nreverse engineering tasks suggest that NeuDep understands memory access\npatterns, learns function signatures, and is able to match indirect calls. All\nthese tasks either assist or benefit from inferring memory dependencies.\nNotably, NeuDep also outperforms the current state-of-the-art on these tasks.",
    "descriptor": "\nComments: ESEC/FSE 2022\n",
    "authors": [
      "Kexin Pei",
      "Dongdong She",
      "Michael Wang",
      "Scott Geng",
      "Zhou Xuan",
      "Yaniv David",
      "Junfeng Yang",
      "Suman Jana",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.02853"
  },
  {
    "id": "arXiv:2210.02856",
    "title": "On Clustering Trend in Language Evolution Based on Dynamical Behaviors  of Multi-Agent Model",
    "abstract": "Computer model has been extensively adopted to overcome the time limitation\nof language evolution by transforming language theory into physical modeling\nmechanism, which helps to explore the general laws of the evolution. In this\npaper, a multi-agent model is designed to simulate the evolution process of\nlanguage in human settlements, with the network topology being lattice. The\nlanguage of each node in the lattice will evolve gradually under the influence\nof its own fixed evolutionary direction and neighbors. According to the\ncomputational experiment results, it is discovered that the state points of\nlanguages always converge into several clusters during evolution process, which\ngives us an insight into language evolution.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Li Liu",
      "Chen Diao",
      "Ning Cai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.02856"
  },
  {
    "id": "arXiv:2210.02857",
    "title": "Time Will Change Things: An Empirical Study on Dynamic Language  Understanding in Social Media Classification",
    "abstract": "Language features are ever-evolving in the real-world social media\nenvironment. Many trained models in natural language understanding (NLU),\nineffective in semantic inference for unseen features, might consequently\nstruggle with the deteriorating performance in dynamicity. To address this\nchallenge, we empirically study social media NLU in a dynamic setup, where\nmodels are trained on the past data and test on the future. It better reflects\nthe realistic practice compared to the commonly-adopted static setup of random\ndata split. To further analyze model adaption to the dynamicity, we explore the\nusefulness of leveraging some unlabeled data created after a model is trained.\nThe performance of unsupervised domain adaption baselines based on\nauto-encoding and pseudo-labeling and a joint framework coupling them both are\nexamined in the experiments. Substantial results on four social media tasks\nimply the universally negative effects of evolving environments over\nclassification accuracy, while auto-encoding and pseudo-labeling\ncollaboratively show the best robustness in dynamicity.",
    "descriptor": "",
    "authors": [
      "Yuji Zhang",
      "Jing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02857"
  },
  {
    "id": "arXiv:2210.02862",
    "title": "Causal Inference for Chatting Handoff",
    "abstract": "Aiming to ensure chatbot quality by predicting chatbot failure and enabling\nhuman-agent collaboration, Machine-Human Chatting Handoff (MHCH) has attracted\nlots of attention from both industry and academia in recent years. However,\nmost existing methods mainly focus on the dialogue context or assist with\nglobal satisfaction prediction based on multi-task learning, which ignore the\ngrounded relationships among the causal variables, like the user state and\nlabor cost. These variables are significantly associated with handoff\ndecisions, resulting in prediction bias and cost increasement. Therefore, we\npropose Causal-Enhance Module (CEM) by establishing the causal graph of MHCH\nbased on these two variables, which is a simple yet effective module and can be\neasy to plug into the existing MHCH methods. For the impact of users, we use\nthe user state to correct the prediction bias according to the causal\nrelationship of multi-task. For the labor cost, we train an auxiliary cost\nsimulator to calculate unbiased labor cost through counterfactual learning so\nthat a model becomes cost-aware. Extensive experiments conducted on four\nreal-world benchmarks demonstrate the effectiveness of CEM in generally\nimproving the performance of existing MHCH methods without any elaborated model\ncrafting.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Shanshan Zhong",
      "Jinghui Qin",
      "Zhongzhan Huang",
      "Daifeng Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02862"
  },
  {
    "id": "arXiv:2210.02864",
    "title": "DBkWik++ -- Multi Source Matching of Knowledge Graphs",
    "abstract": "Large knowledge graphs like DBpedia and YAGO are always based on the same\nsource, i.e., Wikipedia. But there are more wikis that contain information\nabout long-tail entities such as wiki hosting platforms like Fandom. In this\npaper, we present the approach and analysis of DBkWik++, a fused Knowledge\nGraph from thousands of wikis. A modified version of the DBpedia framework is\napplied to each wiki which results in many isolated Knowledge Graphs. With an\nincremental merge based approach, we reuse one-to-one matching systems to solve\nthe multi source KG matching task. Based on this alignment we create a\nconsolidated knowledge graph with more than 15 million instances.",
    "descriptor": "\nComments: Published at KGSWC 2022\n",
    "authors": [
      "Sven Hertling",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.02864"
  },
  {
    "id": "arXiv:2210.02866",
    "title": "Knowing Where to Look: A Planning-based Architecture to Automate the  Gaze Behavior of Social Robots",
    "abstract": "Gaze cues play an important role in human communication and are used to\ncoordinate turn-taking and joint attention, as well as to regulate intimacy. In\norder to have fluent conversations with people, social robots need to exhibit\nhuman-like gaze behavior. Previous Gaze Control Systems (GCS) in HRI have\nautomated robot gaze using data-driven or heuristic approaches. However, these\nsystems tend to be mainly reactive in nature. Planning the robot gaze ahead of\ntime could help in achieving more realistic gaze behavior and better eye-head\ncoordination. In this paper, we propose and implement a novel planning-based\nGCS. We evaluate our system in a comparative within-subjects user study (N=26)\nbetween a reactive system and our proposed system. The results show that the\nusers preferred the proposed system and that it was significantly more\ninterpretable and better at regulating intimacy.",
    "descriptor": "\nComments: accepted for publication in the 31st IEEE International Conference on Robot & Human Interactive Communication (RO-MAN 2022)\n",
    "authors": [
      "Chinmaya Mishra",
      "Gabriel Skantze"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02866"
  },
  {
    "id": "arXiv:2210.02870",
    "title": "Smooth Non-Rigid Shape Matching via Effective Dirichlet Energy  Optimization",
    "abstract": "We introduce pointwise map smoothness via the Dirichlet energy into the\nfunctional map pipeline, and propose an algorithm for optimizing it\nefficiently, which leads to high-quality results in challenging settings.\nSpecifically, we first formulate the Dirichlet energy of the pulled-back shape\ncoordinates, as a way to evaluate smoothness of a pointwise map across discrete\nsurfaces. We then extend the recently proposed discrete solver and show how a\nstrategy based on auxiliary variable reformulation allows us to optimize\npointwise map smoothness alongside desirable functional map properties such as\nbijectivity. This leads to an efficient map refinement strategy that\nsimultaneously improves functional and point-to-point correspondences,\nobtaining smooth maps even on non-isometric shape pairs. Moreover, we\ndemonstrate that several previously proposed methods for computing smooth maps\ncan be reformulated as variants of our approach, which allows us to compare\ndifferent formulations in a consistent framework. Finally, we compare these\nmethods both on existing benchmarks and on a new rich dataset that we\nintroduce, which contains non-rigid, non-isometric shape pairs with\ninter-category and cross-category correspondences. Our work leads to a general\nframework for optimizing and analyzing map smoothness both conceptually and in\nchallenging practical settings.",
    "descriptor": "\nComments: Main Manuscript: 10 pages, 5 Figures, 3 Tables // Supplementary: 4 pages, 3 Figures, 5 Tables\n",
    "authors": [
      "Robin Magnet",
      "Jing Ren",
      "Olga Sorkine-Hornung",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.02870"
  },
  {
    "id": "arXiv:2210.02871",
    "title": "Self-Distillation for Further Pre-training of Transformers",
    "abstract": "Pre-training a large transformer model on a massive amount of unlabeled data\nand fine-tuning it on labeled datasets for diverse downstream tasks has proven\nto be a successful strategy, for a variety of vision and natural language\nprocessing tasks. However, direct fine-tuning of the pre-trained model may be\nsuboptimal if there exist large discrepancies across data domains for\npre-training and fine-tuning. To tackle this issue, several previous studies\nhave proposed further pre-training strategies, where we continue to pre-train\nthe model on the target unlabeled dataset before fine-tuning. However, all of\nthem solely focus on language models and we empirically find that a Vision\nTransformer is vulnerable to overfitting as we continue to pretrain the model\non target unlabeled data. In order to tackle this limitation, we propose\nself-distillation as a regularization for a further pre-training stage.\nSpecifically, we first further pre-train the initial pre-trained model on the\ntarget unlabeled data and then consider it as a teacher for self-distillation.\nThen we take the same initial pre-trained model as a student and enforce its\nhidden representations to be close to those of the teacher while optimizing the\nstudent with a masked auto-encoding objective. We empirically validate the\nefficacy of self-distillation on a variety of benchmark datasets for image and\ntext classification tasks. Experimentally, we show that our proposed method\noutperforms all the relevant baselines. Theoretically, we analyze the proposed\nmethod with a simplified model to understand how self-distillation for further\npre-training can potentially help improve the performance of the downstream\ntasks.",
    "descriptor": "",
    "authors": [
      "Seanie Lee",
      "Minki Kang",
      "Juho Lee",
      "Sung Ju Hwang",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02871"
  },
  {
    "id": "arXiv:2210.02872",
    "title": "Text-driven Video Prediction",
    "abstract": "Current video generation models usually convert signals indicating appearance\nand motion received from inputs (e.g., image, text) or latent spaces (e.g.,\nnoise vectors) into consecutive frames, fulfilling a stochastic generation\nprocess for the uncertainty introduced by latent code sampling. However, this\ngeneration pattern lacks deterministic constraints for both appearance and\nmotion, leading to uncontrollable and undesirable outcomes. To this end, we\npropose a new task called Text-driven Video Prediction (TVP). Taking the first\nframe and text caption as inputs, this task aims to synthesize the following\nframes. Specifically, appearance and motion components are provided by the\nimage and caption separately. The key to addressing the TVP task depends on\nfully exploring the underlying motion information in text descriptions, thus\nfacilitating plausible video generation. In fact, this task is intrinsically a\ncause-and-effect problem, as the text content directly influences the motion\nchanges of frames. To investigate the capability of text in causal inference\nfor progressive motion information, our TVP framework contains a Text Inference\nModule (TIM), producing step-wise embeddings to regulate motion inference for\nsubsequent frames. In particular, a refinement mechanism incorporating global\nmotion semantics guarantees coherent generation. Extensive experiments are\nconducted on Something-Something V2 and Single Moving MNIST datasets.\nExperimental results demonstrate that our model achieves better results over\nother baselines, verifying the effectiveness of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Xue Song",
      "Jingjing Chen",
      "Bin Zhu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02872"
  },
  {
    "id": "arXiv:2210.02873",
    "title": "Blockchain-based Monitoring for Poison Attack Detection in Decentralized  Federated Learning",
    "abstract": "Federated Learning (FL) is a machine learning technique that addresses the\nprivacy challenges in terms of access rights of local datasets by enabling the\ntraining of a model across nodes holding their data samples locally. To achieve\ndecentralized federated learning, blockchain-based FL was proposed as a\ndistributed FL architecture. In decentralized FL, the chief is eliminated from\nthe learning process as workers collaborate between each other to train the\nglobal model. Decentralized FL applications need to account for the additional\ndelay incurred by blockchain-based FL deployments. Particularly in this\nsetting, to detect targeted/untargeted poisoning attacks, we investigate the\nend-to-end learning completion latency of a realistic decentralized FL process\nprotected against poisoning attacks. We propose a technique which consists in\ndecoupling the monitoring phase from the detection phase in defenses against\npoisoning attacks in a decentralized federated learning deployment that aim at\nmonitoring the behavior of the workers. We demonstrate that our proposed\nblockchain-based monitoring improved network scalability, robustness and time\nefficiency. The parallelization of operations results in minimized latency over\nthe end-to-end communication, computation, and consensus delays incurred during\nthe FL and blockchain operations.",
    "descriptor": "",
    "authors": [
      "Ranwa Al Mallah",
      "David Lopez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02873"
  },
  {
    "id": "arXiv:2210.02875",
    "title": "Binding Language Models in Symbolic Languages",
    "abstract": "Though end-to-end neural approaches have recently been dominating NLP tasks\nin both performance and ease-of-use, they lack interpretability and robustness.\nWe propose Binder, a training-free neural-symbolic framework that maps the task\ninput to a program, which (1) allows binding a unified API of language model\n(LM) functionalities to a programming language (e.g., SQL, Python) to extend\nits grammar coverage and thus tackle more diverse questions, (2) adopts an LM\nas both the program parser and the underlying model called by the API during\nexecution, and (3) requires only a few in-context exemplar annotations.\nSpecifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only\na few in-context exemplars, Codex is able to identify the part of the task\ninput that cannot be answerable by the original programming language, correctly\ngenerate API calls to prompt Codex to solve the unanswerable part, and identify\nwhere to place the API calls while being compatible with the original grammar.\nIn the execution stage, Codex can perform versatile functionalities (e.g.,\ncommonsense QA, information extraction) given proper prompts in the API calls.\nBinder achieves state-of-the-art results on WikiTableQuestions and TabFact\ndatasets, with explicit output programs that benefit human debugging. Note that\nprevious best systems are all finetuned on tens of thousands of task-specific\nsamples, while Binder only uses dozens of annotations as in-context exemplars\nwithout any training. Our code is available at https://github.com/HKUNLP/Binder .",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Zhoujun Cheng",
      "Tianbao Xie",
      "Peng Shi",
      "Chengzu Li",
      "Rahul Nadkarni",
      "Yushi Hu",
      "Caiming Xiong",
      "Dragomir Radev",
      "Mari Ostendorf",
      "Luke Zettlemoyer",
      "Noah A. Smith",
      "Tao Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02875"
  },
  {
    "id": "arXiv:2210.02883",
    "title": "A Novel Energy Efficiency Metric for Next Generation Wireless  Communication Networks",
    "abstract": "As a core performance metric for green communications, the conventional\nenergy efficiency definition has successfully resolved many issues in the\nenergy efficient wireless network design. In the past several generations of\nwireless communication networks, the traditional energy efficiency measure\nplays an important role to guide many energy saving techniques for slow varying\ntraffic profiles. However, for the next generation wireless networks, the\ntraditional energy efficiency fails to capture the traffic and capacity\nvariations of wireless networks in temporal or spatial domains, which is shown\nto be quite popular, especially with ultra-scale multiple antennas and\nspace-air-ground integrated network. In this paper, we present a novel energy\nefficiency metric named integrated relative energy efficiency (IREE), which is\nable to jointly measure the traffic profiles and the network capacities from\nthe energy efficiency perspective. On top of that, the IREE based green\ntrade-offs have been investigated and compared with the conventional energy\nefficient design. Moreover, we apply the IREE based green trade-offs to\nevaluate several candidate technologies for 6G networks, including\nreconfigurable intelligent surfaces and space-air-ground integrated network.\nThrough some analytical and numerical results, we show that the proposed IREE\nmetric is able to capture the wireless traffic and capacity mismatch property,\nwhich is significantly different from the conventional energy efficiency\nmetric. Since the IREE oriented design or deployment strategy is able to\nconsider the network capacity improvement and the wireless traffic matching\nsimultaneously, it can be regarded as a useful guidance for future energy\nefficient network design.",
    "descriptor": "",
    "authors": [
      "Tao Yu",
      "Shunqing Zhang",
      "Xiaojing Chen",
      "Xin Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02883"
  },
  {
    "id": "arXiv:2210.02884",
    "title": "Vision+X: A Survey on Multimodal Learning in the Light of Data",
    "abstract": "We are perceiving and communicating with the world in a multisensory manner,\nwhere different information sources are sophisticatedly processed and\ninterpreted by separate parts of the human brain to constitute a complex, yet\nharmonious and unified sensing system. To endow the machines with true\nintelligence, the multimodal machine learning that incorporates data from\nvarious modalities has become an increasingly popular research area with\nemerging technical advances in recent years. In this paper, we present a survey\non multimodal machine learning from a novel perspective considering not only\nthe purely technical aspects but also the nature of different data modalities.\nWe analyze the commonness and uniqueness of each data format ranging from\nvision, audio, text and others, and then present the technical development\ncategorized by the combination of Vision+X, where the vision data play a\nfundamental role in most multimodal learning works. We investigate the existing\nliterature on multimodal learning from both the representation learning and\ndownstream application levels, and provide an additional comparison in the\nlight of their technical connections with the data nature, e.g., the semantic\nconsistency between image objects and textual descriptions, or the rhythm\ncorrespondence between video dance moves and musical beats. The exploitation of\nthe alignment, as well as the existing gap between the intrinsic nature of data\nmodality and the technical designs, will benefit future research studies to\nbetter address and solve a specific challenge related to the concrete\nmultimodal task, and to prompt a unified multimodal machine learning framework\ncloser to a real human intelligence system.",
    "descriptor": "\nComments: Survey paper on multimodal learning, 21 pages\n",
    "authors": [
      "Ye Zhu",
      "Yu Wu",
      "Nicu Sebe",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02884"
  },
  {
    "id": "arXiv:2210.02885",
    "title": "RankMe: Assessing the downstream performance of pretrained  self-supervised representations by their rank",
    "abstract": "Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid\ndevelopment, with the emergence of many method variations and few principled\nguidelines that would help practitioners to successfully deploy those methods.\nThe main reason for that pitfall actually comes from JE-SSL's core principle of\nnot employing any input reconstruction. Without any visual clue, it becomes\nextremely cryptic to judge the quality of a learned representation without\nhaving access to a labelled dataset. We hope to correct those limitations by\nproviding a single -- theoretically motivated -- criterion that reflects the\nquality of learned JE-SSL representations: their effective rank. Albeit simple\nand computationally friendly, this method -- coined RankMe -- allows one to\nassess the performance of JE-SSL representations, even on different downstream\ndatasets, without requiring any labels, training or parameters to tune. Through\nthorough empirical experiments involving hundreds of repeated training\nepisodes, we demonstrate how RankMe can be used for hyperparameter selection\nwith nearly no loss in final performance compared to the current selection\nmethod that involve dataset labels. We hope that RankMe will facilitate the use\nof JE-SSL in domains with little or no labeled data.",
    "descriptor": "",
    "authors": [
      "Quentin Garrido",
      "Randall Balestriero",
      "Laurent Najman",
      "Yann Lecun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02885"
  },
  {
    "id": "arXiv:2210.02886",
    "title": "Optimal Stochastic Resource Allocation for Distributed Quantum Computing",
    "abstract": "With the advent of interconnected quantum computers, i.e., distributed\nquantum computing (DQC), multiple quantum computers can now collaborate via\nquantum networks to perform massively complex computational tasks. However, DQC\nfaces problems sharing quantum information because it cannot be cloned or\nduplicated between quantum computers. Thanks to advanced quantum mechanics,\nquantum computers can teleport quantum information across quantum networks.\nHowever, challenges to utilizing efficiently quantum resources, e.g., quantum\ncomputers and quantum channels, arise in DQC due to their capabilities and\nproperties, such as uncertain qubit fidelity and quantum channel noise. In this\npaper, we propose a resource allocation scheme for DQC based on stochastic\nprogramming to minimize the total deployment cost for quantum resources.\nEssentially, the two-stage stochastic programming model is formulated to handle\nthe uncertainty of quantum computing demands, computing power, and fidelity in\nquantum networks. The performance evaluation demonstrates the effectiveness and\nability of the proposed scheme to balance the utilization of quantum computers\nand on-demand quantum computers while minimizing the overall cost of\nprovisioning under uncertainty.",
    "descriptor": "\nComments: 6 pages, 8 figures, conference\n",
    "authors": [
      "Napat Ngoenriang",
      "Minrui Xu",
      "Sucha Supittayapornpong",
      "Dusit Niyato",
      "Han Yu",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02886"
  },
  {
    "id": "arXiv:2210.02887",
    "title": "DQC$^2$O: Distributed Quantum Computing for Collaborative Optimization  in Future Networks",
    "abstract": "With the advantages of high-speed parallel processing, quantum computers can\nefficiently solve large-scale complex optimization problems in future networks.\nHowever, due to the uncertain qubit fidelity and quantum channel noise,\ndistributed quantum computing which relies on quantum networks connected\nthrough entanglement faces a lot of challenges for exchanging information\nacross quantum computers. In this paper, we propose an adaptive distributed\nquantum computing approach to manage quantum computers and quantum channels for\nsolving optimization tasks in future networks. Firstly, we describe the\nfundamentals of quantum computing and its distributed concept in quantum\nnetworks. Secondly, to address the uncertainty of future demands of\ncollaborative optimization tasks and instability over quantum networks, we\npropose a quantum resource allocation scheme based on stochastic programming\nfor minimizing quantum resource consumption. Finally, based on the proposed\napproach, we discuss the potential applications for collaborative optimization\nin future networks, such as smart grid management, IoT cooperation, and UAV\ntrajectory planning. Promising research directions that can lead to the design\nand implementation of future distributed quantum computing frameworks are also\nhighlighted.",
    "descriptor": "",
    "authors": [
      "Napat Ngoenriang",
      "Minrui Xu",
      "Jiawen Kang",
      "Dusit Niyato",
      "Han Yu",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02887"
  },
  {
    "id": "arXiv:2210.02889",
    "title": "A Distributional Lens for Multi-Aspect Controllable Text Generation",
    "abstract": "Multi-aspect controllable text generation is a more challenging and practical\ntask than single-aspect control. Existing methods achieve complex multi-aspect\ncontrol by fusing multiple controllers learned from single-aspect, but suffer\nfrom attribute degeneration caused by the mutual interference of these\ncontrollers. To address this, we provide observations on attribute fusion from\na distributional perspective and propose to directly search for the\nintersection areas of multiple attribute distributions as their combination for\ngeneration. Our method first estimates the attribute space with an autoencoder\nstructure. Afterward, we iteratively approach the intersections by jointly\nminimizing distances to points representing different attributes. Finally, we\nmap them to attribute-relevant sentences with a prefix-tuning-based decoder.\nExperiments on the three-aspect control task, including sentiment, topic, and\ndetoxification aspects, reveal that our method outperforms several strong\nbaselines on attribute relevance and text quality and achieves the SOTA.\nFurther analysis also supplies some explanatory support for the effectiveness\nof our approach.",
    "descriptor": "\nComments: 21pages, 21figures, EMNLP2022\n",
    "authors": [
      "Yuxuan Gu",
      "Xiaocheng Feng",
      "Sicheng Ma",
      "Lingyuan Zhang",
      "Heng Gong",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02889"
  },
  {
    "id": "arXiv:2210.02890",
    "title": "Multiview Contextual Commonsense Inference: A New Dataset and Task",
    "abstract": "Contextual commonsense inference is the task of generating various types of\nexplanations around the events in a dyadic dialogue, including cause,\nmotivation, emotional reaction, and others. Producing a coherent and\nnon-trivial explanation requires awareness of the dialogue's structure and of\nhow an event is grounded in the context. In this work, we create CICEROv2, a\ndataset consisting of 8,351 instances from 2,379 dialogues, containing multiple\nhuman-written answers for each contextual commonsense inference question,\nrepresenting a type of explanation on cause, subsequent event, motivation, and\nemotional reaction. We show that the inferences in CICEROv2 are more\nsemantically diverse than other contextual commonsense inference datasets. To\nsolve the inference task, we propose a collection of pre-training objectives,\nincluding concept denoising and utterance sorting to prepare a pre-trained\nmodel for the downstream contextual commonsense inference task. Our results\nshow that the proposed pre-training objectives are effective at adapting the\npre-trained T5-Large model for the contextual commonsense inference task.",
    "descriptor": "",
    "authors": [
      "Siqi Shen",
      "Deepanway Ghosal",
      "Navonil Majumder",
      "Henry Lim",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02890"
  },
  {
    "id": "arXiv:2210.02891",
    "title": "Transferring Knowledge for Reinforcement Learning in Contact-Rich  Manipulation",
    "abstract": "In manufacturing, assembly tasks have been a challenge for learning\nalgorithms due to variant dynamics of different environments. Reinforcement\nlearning (RL) is a promising framework to automatically learn these tasks, yet\nit is still not easy to apply a learned policy or skill, that is the ability of\nsolving a task, to a similar environment even if the deployment conditions are\nonly slightly different. In this paper, we address the challenge of\ntransferring knowledge within a family of similar tasks by leveraging multiple\nskill priors. We propose to learn prior distribution over the specific skill\nrequired to accomplish each task and compose the family of skill priors to\nguide learning the policy for a new task by comparing the similarity between\nthe target task and the prior ones. Our method learns a latent action space\nrepresenting the skill embedding from demonstrated trajectories for each prior\ntask. We have evaluated our method on a set of peg-in-hole insertion tasks and\ndemonstrate better generalization to new tasks that have never been encountered\nduring training.",
    "descriptor": "",
    "authors": [
      "Quantao Yang",
      "Johannes A. Stork",
      "Todor Stoyanov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02891"
  },
  {
    "id": "arXiv:2210.02897",
    "title": "Embedding-Assisted Attentional Deep Learning for Real-World RF  Fingerprinting of Bluetooth",
    "abstract": "A scalable and computationally efficient framework is designed to fingerprint\nreal-world Bluetooth devices. We propose an embedding-assisted attentional\nframework (Mbed-ATN) suitable for fingerprinting actual Bluetooth devices. Its\ngeneralization capability is analyzed in different settings and the effect of\nsample length and anti-aliasing decimation is demonstrated. The embedding\nmodule serves as a dimensionality reduction unit that maps the high dimensional\n3D input tensor to a 1D feature vector for further processing by the ATN\nmodule. Furthermore, unlike the prior research in this field, we closely\nevaluate the complexity of the model and test its fingerprinting capability\nwith real-world Bluetooth dataset collected under a different time frame and\nexperimental setting while being trained on another. Our study reveals 7.3x and\n65.2x lesser memory usage with Mbed-ATN architecture in contrast to Oracle at\ninput sample lengths of M=10 kS and M=100 kS respectively. Further, the\nproposed Mbed-ATN showcases 16.9X fewer FLOPs and 7.5x lesser trainable\nparameters when compared to Oracle. Finally, we show that when subject to\nanti-aliasing decimation and at greater input sample lengths of 1 MS, the\nproposed Mbed-ATN framework results in a 5.32x higher TPR, 37.9% fewer false\nalarms, and 6.74x higher accuracy under the challenging real-world setting.",
    "descriptor": "\nComments: under review for possible journal publication\n",
    "authors": [
      "Anu Jagannath",
      "Jithin Jagannath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02897"
  },
  {
    "id": "arXiv:2210.02898",
    "title": "Learning Disentangled Representations for Natural Language Definitions",
    "abstract": "Disentangling the encodings of neural models is a fundamental aspect for\nimproving interpretability, semantic control and downstream task performance in\nNatural Language Processing. Currently, most disentanglement methods are\nunsupervised or rely on synthetic datasets with known generative factors. We\nargue that recurrent syntactic and semantic regularities in textual data can be\nused to provide the models with both structural biases and generative factors.\nWe leverage the semantic structures present in a representative and\nsemantically dense category of sentence types, definitional sentences, for\ntraining a Variational Autoencoder to learn disentangled representations. Our\nexperimental results show that the proposed model outperforms unsupervised\nbaselines on several qualitative and quantitative benchmarks for\ndisentanglement, and it also improves the results in the downstream task of\ndefinition modeling.",
    "descriptor": "",
    "authors": [
      "Danilo S. Carvalho",
      "Giangiacomo Mercatali",
      "Yingji Zhang",
      "Andre Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02898"
  },
  {
    "id": "arXiv:2210.02899",
    "title": "Self-supervised Learning for Clustering of Wireless Spectrum Activity",
    "abstract": "In recent years, much work has been done on processing of wireless spectral\ndata involving machine learning techniques in domain-related problems for\ncognitive radio networks, such as anomaly detection, modulation classification,\ntechnology classification and device fingerprinting. Most of the solutions are\nbased on labeled data, created in a controlled manner and processed with\nsupervised learning approaches. Labeling spectral data is a laborious and\nexpensive process, being one of the main drawbacks of using supervised\napproaches. In this paper, we introduce self-supervised learning for exploring\nspectral activities using real-world, unlabeled data. We show that the proposed\nmodel achieves superior performance regarding the quality of extracted features\nand clustering performance. We achieve reduction of the feature vectors size by\n2 orders of magnitude (from 3601 to 20), while improving performance by 2 to\n2.5 times across the evaluation metrics, supported by visual assessment. Using\n15 days of continuous narrowband spectrum sensing data, we found that 17% of\nthe spectrogram slices contain no or very weak transmissions, 36% contain\nmostly IEEE 802.15.4, 26% contain coexisting IEEE 802.15.4 with LoRA and\nproprietary activity, 12% contain LoRA with variable background noise and 9%\ncontain only dotted activity, representing LoRA and proprietary transmissions.",
    "descriptor": "",
    "authors": [
      "Ljupcho Milosheski",
      "Gregor Cerar",
      "Bla\u017e Bertalani\u010d",
      "Carolina Fortuna",
      "Mihael Mohor\u010di\u010d"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02899"
  },
  {
    "id": "arXiv:2210.02904",
    "title": "WakeUpNet: A Mobile-Transformer based Framework for End-to-End Streaming  Voice Trigger",
    "abstract": "End-to-end models have gradually become the main technical stream for voice\ntrigger, aiming to achieve an utmost prediction accuracy but with a small\nfootprint. In present paper, we propose an end-to-end voice trigger framework,\nnamely WakeupNet, which is basically structured on a Transformer encoder. The\npurpose of this framework is to explore the context-capturing capability of\nTransformer, as sequential information is vital for wakeup-word detection.\nHowever, the conventional Transformer encoder is too large to fit our task. To\naddress this issue, we introduce different model compression approaches to\nshrink the vanilla one into a tiny one, called mobile-Transformer. To evaluate\nthe performance of mobile-Transformer, we conduct extensive experiments on a\nlarge public-available dataset HiMia. The obtained results indicate that\nintroduced mobile-Transformer significantly outperforms other frequently used\nmodels for voice trigger in both clean and noisy scenarios.",
    "descriptor": "",
    "authors": [
      "Zixing Zhang",
      "Thorin Farnsworth",
      "Senling Lin",
      "Salah Karout"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.02904"
  },
  {
    "id": "arXiv:2210.02905",
    "title": "Joint Entropy Search for Multi-objective Bayesian Optimization",
    "abstract": "Many real-world problems can be phrased as a multi-objective optimization\nproblem, where the goal is to identify the best set of compromises between the\ncompeting objectives. Multi-objective Bayesian optimization (BO) is a sample\nefficient strategy that can be deployed to solve these vector-valued\noptimization problems where access is limited to a number of noisy objective\nfunction evaluations. In this paper, we propose a novel information-theoretic\nacquisition function for BO called Joint Entropy Search (JES), which considers\nthe joint information gain for the optimal set of inputs and outputs. We\npresent several analytical approximations to the JES acquisition function and\nalso introduce an extension to the batch setting. We showcase the effectiveness\nof this new approach on a range of synthetic and real-world problems in terms\nof the hypervolume and its weighted variants.",
    "descriptor": "\nComments: NeurIPS 2022. 49 pages. Code available at this https URL\n",
    "authors": [
      "Ben Tu",
      "Axel Gandy",
      "Nikolas Kantas",
      "Behrang Shafei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02905"
  },
  {
    "id": "arXiv:2210.02910",
    "title": "Federated Boosted Decision Trees with Differential Privacy",
    "abstract": "There is great demand for scalable, secure, and efficient privacy-preserving\nmachine learning models that can be trained over distributed data. While deep\nlearning models typically achieve the best results in a centralized non-secure\nsetting, different models can excel when privacy and communication constraints\nare imposed. Instead, tree-based approaches such as XGBoost have attracted much\nattention for their high performance and ease of use; in particular, they often\nachieve state-of-the-art results on tabular data. Consequently, several recent\nworks have focused on translating Gradient Boosted Decision Tree (GBDT) models\nlike XGBoost into federated settings, via cryptographic mechanisms such as\nHomomorphic Encryption (HE) and Secure Multi-Party Computation (MPC). However,\nthese do not always provide formal privacy guarantees, or consider the full\nrange of hyperparameters and implementation settings. In this work, we\nimplement the GBDT model under Differential Privacy (DP). We propose a general\nframework that captures and extends existing approaches for differentially\nprivate decision trees. Our framework of methods is tailored to the federated\nsetting, and we show that with a careful choice of techniques it is possible to\nachieve very high utility while maintaining strong levels of privacy.",
    "descriptor": "\nComments: Full version of a paper to appear at ACM CCS'22\n",
    "authors": [
      "Samuel Maddock",
      "Graham Cormode",
      "Tianhao Wang",
      "Carsten Maple",
      "Somesh Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02910"
  },
  {
    "id": "arXiv:2210.02912",
    "title": "CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated  Learning",
    "abstract": "Federated Learning (FL) is a setting for training machine learning models in\ndistributed environments where the clients do not share their raw data but\ninstead send model updates to a server. However, model updates can be subject\nto attacks and leak private information. Differential Privacy (DP) is a leading\nmitigation strategy which involves adding noise to clipped model updates,\ntrading off performance for strong theoretical privacy guarantees. Previous\nwork has shown that the threat model of DP is conservative and that the\nobtained guarantees may be vacuous or may not directly translate to information\nleakage in practice. In this paper, we aim to achieve a tighter measurement of\nthe model exposure by considering a realistic threat model. We propose a novel\nmethod, CANIFE, that uses canaries - carefully crafted samples by a strong\nadversary to evaluate the empirical privacy of a training round. We apply this\nattack to vision models trained on CIFAR-10 and CelebA and to language models\ntrained on Sent140 and Shakespeare. In particular, in realistic FL scenarios,\nwe demonstrate that the empirical epsilon obtained with CANIFE is 2-7x lower\nthan the theoretical bound.",
    "descriptor": "",
    "authors": [
      "Samuel Maddock",
      "Alexandre Sablayrolles",
      "Pierre Stock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.02912"
  },
  {
    "id": "arXiv:2210.02914",
    "title": "Generative Entity Typing with Curriculum Learning",
    "abstract": "Entity typing aims to assign types to the entity mentions in given texts. The\ntraditional classification-based entity typing paradigm has two unignorable\ndrawbacks: 1) it fails to assign an entity to the types beyond the predefined\ntype set, and 2) it can hardly handle few-shot and zero-shot situations where\nmany long-tail types only have few or even no training instances. To overcome\nthese drawbacks, we propose a novel generative entity typing (GET) paradigm:\ngiven a text with an entity mention, the multiple types for the role that the\nentity plays in the text are generated with a pre-trained language model (PLM).\nHowever, PLMs tend to generate coarse-grained types after fine-tuning upon the\nentity typing dataset. Besides, we only have heterogeneous training data\nconsisting of a small portion of human-annotated data and a large portion of\nauto-generated but low-quality data. To tackle these problems, we employ\ncurriculum learning (CL) to train our GET model upon the heterogeneous data,\nwhere the curriculum could be self-adjusted with the self-paced learning\naccording to its comprehension of the type granularity and data heterogeneity.\nOur extensive experiments upon the datasets of different languages and\ndownstream tasks justify the superiority of our GET model over the\nstate-of-the-art entity typing models. The code has been released on\nhttps://github.com/siyuyuan/GET.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Siyu Yuan",
      "Deqing Yang",
      "Jiaqing Liang",
      "Zhixu Li",
      "Jinxi Liu",
      "Jingyue Huang",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02914"
  },
  {
    "id": "arXiv:2210.02925",
    "title": "Yet another proof of Parikh's Theorem",
    "abstract": "Parikh's Theorem says that the Parikh image of a context-free language is\nsemilinear. We give a short proof of Parikh's Theorem using the formulation of\nVerma, Seidl, and Schwentick in terms of Presburger arithmetic. The proof\nrelies on an Eulerian property of derivation trees of context-free languages\nand was inspired by Hierholzer's algorithm; it does not use the Chomsky normal\nform.",
    "descriptor": "",
    "authors": [
      "Manfred Kufleitner"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.02925"
  },
  {
    "id": "arXiv:2210.02927",
    "title": "An Energy Balance Cluster Network Framework Based on SWIPT",
    "abstract": "Wireless NanoSensor Network (WNSN) is a brand-new type of sensor network with\nbroad application prospects. In view of the limited energy of nano-nodes and\nunstable links in WNSNs, we propose an energy balance cluster network framework\n(EBCNF) based on Simultaneous Wireless Information and Power Transfer (SWIPT).\nThe EBCNF framework extends the network lifetime of nanonodes and uses a\nclustering algorithm called EBACC (an energy balance algorithm for\nintra-cluster and inter-cluster nodes) to make the energy consumption of nodes\nmore uniform. Simulation shows that the EBCNF framework can make the network\nenergy consumption more uniform, reduce the error rate of data transmission and\nthe average network throughput, and can be used as an effective routing\nframework for WNSNs.",
    "descriptor": "\nComments: 22 pages,11 figures,submitted to Nano Communication Networks\n",
    "authors": [
      "Juan Xu",
      "Ruofan Wang",
      "Yan Zhang",
      "Hongmin Huang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.02927"
  },
  {
    "id": "arXiv:2210.02928",
    "title": "MuRAG: Multimodal Retrieval-Augmented Generator for Open Question  Answering over Images and Text",
    "abstract": "While language Models store a massive amount of world knowledge implicitly in\ntheir parameters, even very large models often fail to encode information about\nrare entities and events, while incurring huge computational costs. Recently,\nretrieval-augmented models, such as REALM, RAG, and RETRO, have incorporated\nworld knowledge into language generation by leveraging an external\nnon-parametric index and have demonstrated impressive performance with\nconstrained model sizes. However, these methods are restricted to retrieving\nonly textual knowledge, neglecting the ubiquitous amount of knowledge in other\nmodalities like images -- much of which contains information not covered by any\ntext. To address this limitation, we propose the first Multimodal\nRetrieval-Augmented Transformer (MuRAG), which accesses an external\nnon-parametric multimodal memory to augment language generation. MuRAG is\npre-trained with a mixture of large-scale image-text and text-only corpora\nusing a joint contrastive and generative loss. We perform experiments on two\ndifferent datasets that require retrieving and reasoning over both images and\ntext to answer a given query: WebQA, and MultimodalQA. Our results show that\nMuRAG achieves state-of-the-art accuracy, outperforming existing models by\n10-20\\% absolute on both datasets and under both distractor and full-wiki\nsettings.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Wenhu Chen",
      "Hexiang Hu",
      "Xi Chen",
      "Pat Verga",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02928"
  },
  {
    "id": "arXiv:2210.02930",
    "title": "Data-Driven Meets Navigation: Concepts, Models, and Experimental  Validation",
    "abstract": "The purpose of navigation is to determine the position, velocity, and\norientation of manned and autonomous platforms, humans, and animals. Obtaining\naccurate navigation commonly requires fusion between several sensors, such as\ninertial sensors and global navigation satellite systems, in a model-based,\nnonlinear estimation framework. Recently, data-driven approaches applied in\nvarious fields show state-of-the-art performance, compared to model-based\nmethods. In this paper we review multidisciplinary, data-driven based\nnavigation algorithms developed and experimentally proven at the Autonomous\nNavigation and Sensor Fusion Lab (ANSFL) including algorithms suitable for\nhuman and animal applications, varied autonomous platforms, and multi-purpose\nnavigation and fusion approaches",
    "descriptor": "\nComments: 22 pages, 13 figures\n",
    "authors": [
      "Itzik Klein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02930"
  },
  {
    "id": "arXiv:2210.02933",
    "title": "Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question  Answering",
    "abstract": "A common thread of open-domain question answering (QA) models employs a\nretriever-reader pipeline that first retrieves a handful of relevant passages\nfrom Wikipedia and then peruses the passages to produce an answer. However,\neven state-of-the-art readers fail to capture the complex relationships between\nentities appearing in questions and retrieved passages, leading to answers that\ncontradict the facts. In light of this, we propose a novel knowledge Graph\nenhanced passage reader, namely Grape, to improve the reader performance for\nopen-domain QA. Specifically, for each pair of question and retrieved passage,\nwe first construct a localized bipartite graph, attributed to entity embeddings\nextracted from the intermediate layer of the reader model. Then, a graph neural\nnetwork learns relational knowledge while fusing graph and contextual\nrepresentations into the hidden states of the reader model. Experiments on\nthree open-domain QA benchmarks show Grape can improve the state-of-the-art\nperformance by up to 2.2 exact match score with a negligible overhead increase,\nwith the same retriever and retrieved passages. Our code is publicly available\nat https://github.com/jumxglhf/GRAPE.",
    "descriptor": "\nComments: Findings of EMNLP2022\n",
    "authors": [
      "Mingxuan Ju",
      "Wenhao Yu",
      "Tong Zhao",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02933"
  },
  {
    "id": "arXiv:2210.02935",
    "title": "A Review of Uncertainty Calibration in Pretrained Object Detectors",
    "abstract": "In the field of deep learning based computer vision, the development of deep\nobject detection has led to unique paradigms (e.g., two-stage or set-based) and\narchitectures (e.g., Faster-RCNN or DETR) which enable outstanding performance\non challenging benchmark datasets. Despite this, the trained object detectors\ntypically do not reliably assess uncertainty regarding their own knowledge, and\nthe quality of their probabilistic predictions is usually poor. As these are\noften used to make subsequent decisions, such inaccurate probabilistic\npredictions must be avoided. In this work, we investigate the uncertainty\ncalibration properties of different pretrained object detection architectures\nin a multi-class setting. We propose a framework to ensure a fair, unbiased,\nand repeatable evaluation and conduct detailed analyses assessing the\ncalibration under distributional changes (e.g., distributional shift and\napplication to out-of-distribution data). Furthermore, by investigating the\ninfluence of different detector paradigms, post-processing steps, and suitable\nchoices of metrics, we deliver novel insights into why poor detector\ncalibration emerges. Based on these insights, we are able to improve the\ncalibration of a detector by simply finetuning its last layer.",
    "descriptor": "\nComments: 17 pages, 6 figures, submitted to IJCV\n",
    "authors": [
      "Denis Huseljic",
      "Marek Herde",
      "Mehmet Muejde",
      "Bernhard Sick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02935"
  },
  {
    "id": "arXiv:2210.02938",
    "title": "Debiasing isn't enough! -- On the Effectiveness of Debiasing MLMs and  their Social Biases in Downstream Tasks",
    "abstract": "We study the relationship between task-agnostic intrinsic and task-specific\nextrinsic social bias evaluation measures for Masked Language Models (MLMs),\nand find that there exists only a weak correlation between these two types of\nevaluation measures. Moreover, we find that MLMs debiased using different\nmethods still re-learn social biases during fine-tuning on downstream tasks. We\nidentify the social biases in both training instances as well as their assigned\nlabels as reasons for the discrepancy between intrinsic and extrinsic bias\nevaluation measurements. Overall, our findings highlight the limitations of\nexisting MLM bias evaluation measures and raise concerns on the deployment of\nMLMs in downstream applications using those measures.",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Masahiro Kaneko",
      "Danushka Bollegala",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02938"
  },
  {
    "id": "arXiv:2210.02940",
    "title": "Communication-Efficient and Drift-Robust Federated Learning via Elastic  Net",
    "abstract": "Federated learning (FL) is a distributed method to train a global model over\na set of local clients while keeping data localized. It reduces the risks of\nprivacy and security but faces important challenges including expensive\ncommunication costs and client drift issues. To address these issues, we\npropose FedElasticNet, a communication-efficient and drift-robust FL framework\nleveraging the elastic net. It repurposes two types of the elastic net\nregularizers (i.e., $\\ell_1$ and $\\ell_2$ penalties on the local model\nupdates): (1) the $\\ell_1$-norm regularizer sparsifies the local updates to\nreduce the communication costs and (2) the $\\ell_2$-norm regularizer resolves\nthe client drift problem by limiting the impact of drifting local updates due\nto data heterogeneity. FedElasticNet is a general framework for FL; hence,\nwithout additional costs, it can be integrated into prior FL techniques, e.g.,\nFedAvg, FedProx, SCAFFOLD, and FedDyn. We show that our framework effectively\nresolves the communication cost and client drift problems simultaneously.",
    "descriptor": "",
    "authors": [
      "Seonhyeong Kim",
      "Jiheon Woo",
      "Daewon Seo",
      "Yongjune Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02940"
  },
  {
    "id": "arXiv:2210.02941",
    "title": "Augmentor or Filter? Reconsider the Role of Pre-trained Language Model  in Text Classification Augmentation",
    "abstract": "Text augmentation is one of the most effective techniques to solve the\ncritical problem of insufficient data in text classification. Existing text\naugmentation methods achieve hopeful performance in few-shot text data\naugmentation. However, these methods usually lead to performance degeneration\non public datasets due to poor quality augmentation instances. Our study shows\nthat even employing pre-trained language models, existing text augmentation\nmethods generate numerous low-quality instances and lead to the feature space\nshift problem in augmentation instances. However, we note that the pre-trained\nlanguage model is good at finding low-quality instances provided that it has\nbeen fine-tuned on the target dataset. To alleviate the feature space shift and\nperformance degeneration in existing text augmentation methods, we propose\nBOOSTAUG, which reconsiders the role of the language model in text augmentation\nand emphasizes the augmentation instance filtering rather than generation. We\nevaluate BOOSTAUG on both sentence-level text classification and aspect-based\nsentiment classification. The experimental results on seven commonly used text\nclassification datasets show that our augmentation method obtains\nstate-of-the-art performance. Moreover, BOOSTAUG is a flexible framework; we\nrelease the code which can help improve existing augmentation methods.",
    "descriptor": "\nComments: Source code and examples: this https URL\n",
    "authors": [
      "Heng Yang",
      "Ke Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02941"
  },
  {
    "id": "arXiv:2210.02943",
    "title": "On Explaining Confounding Bias",
    "abstract": "When analyzing large datasets, analysts are often interested in the\nexplanations for surprising or unexpected results produced by their queries. In\nthis work, we focus on aggregate SQL queries that expose correlations in the\ndata. A major challenge that hinders the interpretation of such queries is\nconfounding bias, which can lead to an unexpected correlation. We generate\nexplanations in terms of a set of confounding variables that explain the\nunexpected correlation observed in a query. We propose to mine candidate\nconfounding variables from external sources since, in many real-life scenarios,\nthe explanations are not solely contained in the input data. We present an\nefficient algorithm that finds the optimal subset of attributes (mined from\nexternal sources and the input dataset) that explain the unexpected\ncorrelation. This algorithm is embodied in a system called MESA. We demonstrate\nexperimentally over multiple real-life datasets and through a user study that\nour approach generates insightful explanations, outperforming existing methods\nthat search for explanations only in the input data. We further demonstrate the\nrobustness of our system to missing data and the ability of MESA to handle\ninput datasets containing millions of tuples and an extensive search space of\ncandidate confounding attributes.",
    "descriptor": "",
    "authors": [
      "Brit Youngmann",
      "Michael Cafarella",
      "Yuval Moskovitch",
      "Babak Salimi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.02943"
  },
  {
    "id": "arXiv:2210.02946",
    "title": "VLSNR:Vision-Linguistics Coordination Time Sequence-aware News  Recommendation",
    "abstract": "News representation and user-oriented modeling are both essential for news\nrecommendation. Most existing methods are based on textual information but\nignore the visual information and users' dynamic interests. However, compared\nto textual only content, multimodal semantics is beneficial for enhancing the\ncomprehension of users' temporal and long-lasting interests. In our work, we\npropose a vision-linguistics coordinate time sequence news recommendation.\nFirstly, a pretrained multimodal encoder is applied to embed images and texts\ninto the same feature space. Then the self-attention network is used to learn\nthe chronological sequence. Additionally, an attentional GRU network is\nproposed to model user preference in terms of time adequately. Finally, the\nclick history and user representation are embedded to calculate the ranking\nscores for candidate news. Furthermore, we also construct a large scale\nmultimodal news recommendation dataset V-MIND. Experimental results show that\nour model outperforms baselines and achieves SOTA on our independently\nconstructed dataset.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Songhao Han",
      "Wei Huang",
      "Xiaotian Luan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.02946"
  },
  {
    "id": "arXiv:2210.02952",
    "title": "Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation",
    "abstract": "Prompt tuning, or the conditioning of a frozen pretrained language model\n(PLM) with soft prompts learned from data, has demonstrated impressive\nperformance on a wide range of NLP tasks. However, prompt tuning requires a\nlarge training dataset to be effective and is outperformed by finetuning the\nentire PLM in data-scarce regimes. Previous work\n\\citep{gu-etal-2022-ppt,vu-etal-2022-spot} proposed to transfer soft prompts\npretrained on the source domain to the target domain. In this paper, we explore\ndomain adaptation for prompt tuning, a problem setting where unlabeled data\nfrom the target domain are available during pretraining. We propose bOosting\nPrompt TunIng with doMain Adaptation (OPTIMA), which regularizes the decision\nboundary to be smooth around regions where source and target data distributions\nare similar. Extensive experiments demonstrate that OPTIMA significantly\nenhances the transferability and sample-efficiency of prompt tuning compared to\nstrong baselines. Moreover, in few-shot settings, OPTIMA exceeds full-model\ntuning by a large margin.",
    "descriptor": "\nComments: 13 pages, 11 figures, Findings of EMNLP 2022\n",
    "authors": [
      "Xu Guo",
      "Boyang Li",
      "Han Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02952"
  },
  {
    "id": "arXiv:2210.02953",
    "title": "Video Referring Expression Comprehension via Transformer with  Content-aware Query",
    "abstract": "Video Referring Expression Comprehension (REC) aims to localize a target\nobject in video frames referred by the natural language expression. Recently,\nthe Transformerbased methods have greatly boosted the performance limit.\nHowever, we argue that the current query design is suboptima and suffers from\ntwo drawbacks: 1) the slow training convergence process; 2) the lack of\nfine-grained alignment. To alleviate this, we aim to couple the pure learnable\nqueries with the content information. Specifically, we set up a fixed number of\nlearnable bounding boxes across the frame and the aligned region features are\nemployed to provide fruitful clues. Besides, we explicitly link certain phrases\nin the sentence to the semantically relevant visual areas. To this end, we\nintroduce two new datasets (i.e., VID-Entity and VidSTG-Entity) by augmenting\nthe VIDSentence and VidSTG datasets with the explicitly referred words in the\nwhole sentence, respectively. Benefiting from this, we conduct the fine-grained\ncross-modal alignment at the region-phrase level, which ensures more detailed\nfeature representations. Incorporating these two designs, our proposed model\n(dubbed as ContFormer) achieves the state-of-the-art performance on widely\nbenchmarked datasets. For example on VID-Entity dataset, compared to the\nprevious SOTA, ContFormer achieves 8.75% absolute improvement on Accu.@0.6.",
    "descriptor": "",
    "authors": [
      "Ji Jiang",
      "Meng Cao",
      "Tengtao Song",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02953"
  },
  {
    "id": "arXiv:2210.02956",
    "title": "Are word boundaries useful for unsupervised language learning?",
    "abstract": "Word or word-fragment based Language Models (LM) are typically preferred over\ncharacter-based ones in many downstream applications. This may not be\nsurprising as words seem more linguistically relevant units than characters.\nWords provide at least two kinds of relevant information: boundary information\nand meaningful units. However, word boundary information may be absent or\nunreliable in the case of speech input (word boundaries are not marked\nexplicitly in the speech stream). Here, we systematically compare LSTMs as a\nfunction of the input unit (character, phoneme, word, word part), with or\nwithout gold boundary information. We probe linguistic knowledge in the\nnetworks at the lexical, syntactic and semantic levels using three\nspeech-adapted black box NLP psycholinguistically-inpired benchmarks (pWUGGY,\npBLIMP, pSIMI). We find that the absence of boundaries costs between 2\\% and\n28\\% in relative performance depending on the task. We show that gold\nboundaries can be replaced by automatically found ones obtained with an\nunsupervised segmentation algorithm, and that even modest segmentation\nperformance gives a gain in performance on two of the three tasks compared to\nbasic character/phone based models without boundary information.",
    "descriptor": "\nComments: This is an archived version from September 2020\n",
    "authors": [
      "Tu Anh Nguyen",
      "Maureen de Seyssel",
      "Robin Algayres",
      "Patricia Roze",
      "Ewan Dunbar",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02956"
  },
  {
    "id": "arXiv:2210.02959",
    "title": "POPNASv2: An Efficient Multi-Objective Neural Architecture Search  Technique",
    "abstract": "Automating the research for the best neural network model is a task that has\ngained more and more relevance in the last few years. In this context, Neural\nArchitecture Search (NAS) represents the most effective technique whose results\nrival the state of the art hand-crafted architectures. However, this approach\nrequires a lot of computational capabilities as well as research time, which\nmakes prohibitive its usage in many real-world scenarios. With its sequential\nmodel-based optimization strategy, Progressive Neural Architecture Search\n(PNAS) represents a possible step forward to face this resources issue. Despite\nthe quality of the found network architectures, this technique is still limited\nin research time. A significant step in this direction has been done by\nPareto-Optimal Progressive Neural Architecture Search (POPNAS), which expands\nPNAS with a time predictor to enable a trade-off between search time and\naccuracy, considering a multi-objective optimization problem. This paper\nproposes a new version of the Pareto-Optimal Progressive Neural Architecture\nSearch, called POPNASv2. Our approach enhances its first version and improves\nits performance. We expanded the search space by adding new operators and\nimproved the quality of both predictors to build more accurate Pareto fronts.\nMoreover, we introduced cell equivalence checks and enriched the search\nstrategy with an adaptive greedy exploration step. Our efforts allow POPNASv2\nto achieve PNAS-like performance with an average 4x factor search time\nspeed-up.",
    "descriptor": "",
    "authors": [
      "Andrea Falanti",
      "Eugenio Lomurno",
      "Stefano Samele",
      "Danilo Ardagna",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02959"
  },
  {
    "id": "arXiv:2210.02963",
    "title": "Valuing Uncertainties in Wind Generation: An Agent-Based Optimization  Approach",
    "abstract": "The increasing integration of variable renewable energy sources such as wind\nand solar will require new methods of managing generation uncertainty. Existing\npractices of uncertainty management for these resources largely focuses around\nmodifying the energy offers of such resources in the quantity domain and from a\ncentralized system operator consideration of these uncertainties. This paper\nproposes an approach to instead consider these uncertainties in the price\ndomain, where more uncertain power is offered at a higher price instead of\nrestricting the quantity offered. We demonstrate system-level impacts on a\nmodified version of the RTS-GMLC system where wind generators create market\noffers valuing their uncertainties over scenario set of day-ahead production\nforecasts. The results are compared with a dispatch method in which wind energy\nis offered at zero marginal price and restricted based on the forecast\npercentile.",
    "descriptor": "\nComments: 6 pages, 3 figures. Submitted to the 2023 American Control Conference (ACC)\n",
    "authors": [
      "Daniel Shen",
      "Marija Ilic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02963"
  },
  {
    "id": "arXiv:2210.02964",
    "title": "Designing a Robust Low-Level Agnostic Controller for a Quadrotor with  Actor-Critic Reinforcement Learning",
    "abstract": "Purpose: Real-life applications using quadrotors introduce a number of\ndisturbances and time-varying properties that pose a challenge to flight\ncontrollers. We observed that, when a quadrotor is tasked with picking up and\ndropping a payload, traditional PID and RL-based controllers found in\nliterature struggle to maintain flight after the vehicle changes its dynamics\ndue to interaction with this external object.\nMethods: In this work, we introduce domain randomization during the training\nphase of a low-level waypoint guidance controller based on Soft Actor-Critic.\nThe resulting controller is evaluated on the proposed payload pick up and drop\ntask with added disturbances that emulate real-life operation of the vehicle.\nResults & Conclusion: We show that, by introducing a certain degree of\nuncertainty in quadrotor dynamics during training, we can obtain a controller\nthat is capable to perform the proposed task using a larger variation of\nquadrotor parameters. Additionally, the RL-based controller outperforms a\ntraditional positional PID controller with optimized gains in this task, while\nremaining agnostic to different simulation parameters.",
    "descriptor": "",
    "authors": [
      "Guilherme Siqueira Eduardo",
      "Wouter Caarls"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02964"
  },
  {
    "id": "arXiv:2210.02965",
    "title": "Tensor-product space-time goal-oriented error control and adaptivity  with partition-of-unity dual-weighted residuals for nonstationary flow  problems",
    "abstract": "In this work, the dual-weighted residual method is applied to a space-time\nformulation of nonstationary Stokes and Navier-Stokes flow. Tensor-product\nspace-time finite elements are being used to discretize the variational\nformulation with discontinuous Galerkin finite elements in time and inf-sup\nstable Taylor-Hood finite element pairs in space. To estimate the error in a\nquantity of interest and drive adaptive refinement in time and space, we\ndemonstrate how the dual-weighted residual method for incompressible flow can\nbe extended to a partition of unity based error localization. We derive the\nspace-time Newton method for the Navier-Stokes equations and substantiate our\nmethodology on 2D benchmark problems from computational fluid mechanics.",
    "descriptor": "\nComments: 34 pages, 13 figures\n",
    "authors": [
      "Julian Roth",
      "Jan Philipp Thiele",
      "Uwe K\u00f6cher",
      "Thomas Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02965"
  },
  {
    "id": "arXiv:2210.02967",
    "title": "Few-shot Generation of Personalized Neural Surrogates for Cardiac  Simulation via Bayesian Meta-Learning",
    "abstract": "Clinical adoption of personalized virtual heart simulations faces challenges\nin model personalization and expensive computation. While an ideal solution is\nan efficient neural surrogate that at the same time is personalized to an\nindividual subject, the state-of-the-art is either concerned with personalizing\nan expensive simulation model, or learning an efficient yet generic surrogate.\nThis paper presents a completely new concept to achieve personalized neural\nsurrogates in a single coherent framework of meta-learning (metaPNS). Instead\nof learning a single neural surrogate, we pursue the process of learning a\npersonalized neural surrogate using a small amount of context data from a\nsubject, in a novel formulation of few-shot generative modeling underpinned by:\n1) a set-conditioned neural surrogate for cardiac simulation that, conditioned\non subject-specific context data, learns to generate query simulations not\nincluded in the context set, and 2) a meta-model of amortized variational\ninference that learns to condition the neural surrogate via simple feed-forward\nembedding of context data. As test time, metaPNS delivers a personalized neural\nsurrogate by fast feed-forward embedding of a small and flexible number of data\navailable from an individual, achieving -- for the first time --\npersonalization and surrogate construction for expensive simulations in one\nend-to-end learning framework. Synthetic and real-data experiments demonstrated\nthat metaPNS was able to improve personalization and predictive accuracy in\ncomparison to conventionally-optimized cardiac simulation models, at a fraction\nof computation.",
    "descriptor": "",
    "authors": [
      "Xiajun Jiang",
      "Zhiyuan Li",
      "Ryan Missel",
      "Md Shakil Zaman",
      "Brian Zenger",
      "Wilson W. Good",
      "Rob S. MacLeod",
      "John L. Sapp",
      "Linwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02967"
  },
  {
    "id": "arXiv:2210.02969",
    "title": "Guess the Instruction! Making Language Models Stronger Zero-Shot  Learners",
    "abstract": "Meta-training, which fine-tunes the language model (LM) on various downstream\ntasks by maximizing the likelihood of the target label given the task\ninstruction and input instance, has improved the zero-shot task generalization\nperformance. However, meta-trained LMs still struggle to generalize to\nchallenging tasks containing novel labels unseen during meta-training. In this\npaper, we propose Flipped Learning, an alternative method of meta-training\nwhich trains the LM to generate the task instruction given the input instance\nand label. During inference, the LM trained with Flipped Learning, referred to\nas Flipped, selects the label option that is most likely to generate the task\ninstruction. On 14 tasks of the BIG-bench benchmark, the 3B-sized Flipped\noutperforms 4 times larger zero-shot T0-11B and even a 60 times larger 3-shot\nGPT-3 (175B) on average by 1.8% and 3.1%, respectively. Flipped gives\nparticularly large improvements on unseen labels, outperforming T0-11B by up to\n+20% average F1 score. This indicates that the strong task generalization of\nFlipped comes from improved generalization to novel labels. We release our code\nat https://github.com/seonghyeonye/Flipped-Learning.",
    "descriptor": "",
    "authors": [
      "Seonghyeon Ye",
      "Doyoung Kim",
      "Joel Jang",
      "Joongbo Shin",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02969"
  },
  {
    "id": "arXiv:2210.02971",
    "title": "Robust tube-based LPV-MPC for autonomous lane keeping",
    "abstract": "This paper proposes a control architecture for autonomous lane keeping by a\nvehicle. In this paper, the vehicle dynamics consist of two parts: lateral and\nlongitudinal dynamics. Therefore, the control architecture comprises two\nsubsequent controllers. A longitudinal model predictive control (MPC) makes the\nvehicle track the desired longitudinal speeds that are assumed to be generated\nby a speed planner. The longitudinal speeds are then passed to a lateral MPC\nfor lane keeping. Due to the dependence of the lateral dynamics on the\nlongitudinal speed, they are represented in a linear parameter-varying (LPV)\nform, where its scheduling parameter is the longitudinal speed of the vehicle.\nIn order to deal with the imprecise information of the future longitudinal\nspeed (the scheduling parameter), a bound of uncertainty is considered around\nthe nominal trajectory of the future longitudinal velocities. Then, a\ntube-based LPV- MPC is adopted to control the lateral dynamics for attaining\nthe lane keeping goal. In the end, the effectiveness of the proposed methods is\nillustrated by carrying out simulation tests.",
    "descriptor": "",
    "authors": [
      "Maryam Nezami",
      "Hossam Seddik Abbas",
      "Ngoc Thinh Nguyen",
      "Georg Schildbach"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02971"
  },
  {
    "id": "arXiv:2210.02974",
    "title": "Fault Diagnosis using eXplainable AI: a Transfer Learning-based Approach  for Rotating Machinery exploiting Augmented Synthetic Data",
    "abstract": "Artificial Intelligence (AI) is one of the approaches that has been proposed\nto analyze the collected data (e.g., vibration signals) providing a diagnosis\nof the asset's operating condition. It is known that models trained with\nlabeled data (supervised) achieve excellent results, but two main problems make\ntheir application in production processes difficult: (i) impossibility or long\ntime to obtain a sample of all operational conditions (since faults seldom\nhappen) and (ii) high cost of experts to label all acquired data. Another\nlimitating factor for the applicability of AI approaches in this context is the\nlack of interpretability of the models (black-boxes), which reduces the\nconfidence of the diagnosis and trust/adoption from users. To overcome these\nproblems, a new generic and interpretable approach for classifying faults in\nrotating machinery based on transfer learning from augmented synthetic data to\nreal rotating machinery is here proposed, namelly FaultD-XAI (Fault Diagnosis\nusing eXplainable AI). To provide scalability using transfer learning,\nsynthetic vibration signals are created mimicking the characteristic behavior\nof failures in operation. The application of Gradient-weighted Class Activation\nMapping (Grad-CAM) with 1D Convolutional Neural Network (1D CNN) allows the\ninterpretation of results, supporting the user in decision making and\nincreasing diagnostic confidence. The proposed approach not only obtained\npromising diagnostic performance, but was also able to learn characteristics\nused by experts to identify conditions in a source domain and apply them in\nanother target domain. The experimental results suggest a promising approach on\nexploiting transfer learning, synthetic data and explainable artificial\nintelligence for fault diagnosis. Lastly, to guarantee reproducibility and\nfoster research in the field, the developed dataset is made publicly available.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Lucas Costa Brito",
      "Gian Antonio Susto Jorge Nei Brito",
      "Marcus Antonio Viana Duarte"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02974"
  },
  {
    "id": "arXiv:2210.02976",
    "title": "A new efficient explicit Deferred Correction framework: analysis and  applications to hyperbolic PDEs and adaptivity",
    "abstract": "The Deferred Correction is an iterative procedure used to design numerical\nmethods for systems of ODEs, characterized by an increasing accuracy at each\niteration. The main advantage of this framework is the automatic way of getting\narbitrarily high order methods, which can be put in Runge-Kutta form, based on\nthe definition of subtimenodes in each timestep. The drawback is a larger\ncomputational cost with respect to the most used Runge-Kutta methods. To reduce\nsuch cost, in an explicit setting, we propose an efficient modification: we\nremove the unnecessary subtimenodes in all the iterations, introducing\ninterpolation processes between them. We provide the Butcher tableaux of the\nnovel methods and we study their stability, showing that in some cases the\ncomputational advantage does not affect the stability. The flexibility of the\nnovel modification allows nontrivial applications to PDEs and construction of\nadaptive methods. The good performances of the introduced methods are broadly\ntested on several benchmarks both in the ODE and PDE settings.",
    "descriptor": "\nComments: 52 pages and 48 figures in the main document 36 pages and 9 figures in the supplementary material\n",
    "authors": [
      "Lorenzo Micalizzi",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02976"
  },
  {
    "id": "arXiv:2210.02978",
    "title": "Remembering Netizens: An interview with Ronda Hauben, co-author of  Netizens: On the history and impact of Usenet and the Internet (1997)",
    "abstract": "Netizens, Michael and Ronda Hauben's foundational treatise on Usenet and the\nInternet, was first published in print 25 years ago. In this piece, we trace\nthe history and impact of the book and of Usenet itself, contextualising them\nwithin the contemporary and modern-day scholarship on virtual communities,\nonline culture, and Internet history. We discuss the Net as a tool of\nempowerment, and touch on the social, technical, and economic issues related to\nthe maintenance of shared network infrastructures and to the preservation and\ncommodification of Usenet archives. Our interview with Ronda Hauben offers a\nretrospective look at the development of online communities, their impact, and\nhow they are studied. She recounts her own introduction to the online world, as\nwell as the impetus and writing process for Netizens. She presents Michael\nHauben's conception of \"netizens\" as contributory citizens of the Net (rather\nthan mere users of it) and the \"electronic commons\" they built up, and argues\nthat this collaborative and collectivist model has been overwhelmed and\nendangered by the privatisation and commercialisation of the Internet and its\ncommunities.",
    "descriptor": "\nComments: 24 pages, 0 figures\n",
    "authors": [
      "Tristan Miller",
      "Camille Paloque-Berg\u00e8s",
      "Avery Dame-Griff"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.02978"
  },
  {
    "id": "arXiv:2210.02980",
    "title": "Deep Learning of Near Field Beam Focusing in Terahertz Wideband Massive  MIMO Systems",
    "abstract": "Employing large antenna arrays and utilizing large bandwidth have the\npotential of bringing very high data rates to future wireless communication\nsystems. To achieve that, however, new challenges associated with these systems\nneed to be addressed. First, the large array aperture brings the communications\nto the near-field region, where the far-field assumptions no longer hold.\nSecond, the analog-only (phase shifter based) beamforming architectures result\nin performance degradation in wideband systems due to their frequency\nunawareness. To address these problems, this paper proposes a low-complexity\nfrequency-aware near-field beamforming framework for hybrid time-delay (TD) and\nphase-shifter (PS) based RF architectures. Specifically, a \\textit{signal model\ninspired online learning} framework is proposed to learn the phase shifts of\nthe quantized analog phase-shifters. Thanks to the model-inspired design, the\nproposed learning approach has fast convergence performance. Further, a\nlow-complexity \\textit{geometry-assisted} method is developed to configure the\ndelay settings of the TD units. Simulation results highlight the efficacy of\nthe proposed solution in achieving robust near-field beamforming performance\nfor wideband large antenna array systems.",
    "descriptor": "\nComments: The code files will be available on the DeepMIMO website this https URL\n",
    "authors": [
      "Yu Zhang",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02980"
  },
  {
    "id": "arXiv:2210.02983",
    "title": "GNSS/MEMS-INS Integration for Drone Navigation using EKF on Lie Groups",
    "abstract": "Building upon the theory of Kalman Filtering on Lie Groups, this paper\ndescribes an Extended Kalman Filter and Smoother for Loosely Coupled\nIntegration of GNSS/INS tailored for post-processing applications. The approach\nemploys a dynamic model on a matrix Lie Group that aggregates position,\nvelocity, attitude, and the IMU biases as a single element of a Lie group. The\ndevelopment was motivated by a drone-borne Differential Interferometric SAR\n(DinSAR) application, which requires high-precision navigation information for\nshort-flight missions using low-cost MEMS sensors. The filter and the\nRauch-Tung-Striebel (RTS) smoother are both implemented and validated. The\npaper also presents a novel algorithm to initialize the heading value as an\nalternative to gyro-compassing or magnetometer-based alignments. The\nMahalanobis Distance and the $\\chi^2$-test are employed during the filter\nupdate step to address the practical issue of outlier rejection for the GNSS\nmeasurements. The paper uses synthetic data to compare classic navigation\nschemes based on multiplicative quaternions and Euler angles. Finally, real\ndata experiments demonstrate that the Kalman Filter based on Lie Groups\nperforms better DinSAR processing than state-of-the-art commercial software.",
    "descriptor": "",
    "authors": [
      "Marcos R. Fernandes",
      "Giorgio M. Magalh\u00e3es",
      "Yusef C\u00e1ceres",
      "Jo\u00e3o B. R. do Val"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02983"
  },
  {
    "id": "arXiv:2210.02984",
    "title": "The Lie Derivative for Measuring Learned Equivariance",
    "abstract": "Equivariance guarantees that a model's predictions capture key symmetries in\ndata. When an image is translated or rotated, an equivariant model's\nrepresentation of that image will translate or rotate accordingly. The success\nof convolutional neural networks has historically been tied to translation\nequivariance directly encoded in their architecture. The rising success of\nvision transformers, which have no explicit architectural bias towards\nequivariance, challenges this narrative and suggests that augmentations and\ntraining data might also play a significant role in their performance. In order\nto better understand the role of equivariance in recent vision models, we\nintroduce the Lie derivative, a method for measuring equivariance with strong\nmathematical foundations and minimal hyperparameters. Using the Lie derivative,\nwe study the equivariance properties of hundreds of pretrained models, spanning\nCNNs, transformers, and Mixer architectures. The scale of our analysis allows\nus to separate the impact of architecture from other factors like model size or\ntraining method. Surprisingly, we find that many violations of equivariance can\nbe linked to spatial aliasing in ubiquitous network layers, such as pointwise\nnon-linearities, and that as models get larger and more accurate they tend to\ndisplay more equivariance, regardless of architecture. For example,\ntransformers can be more equivariant than convolutional neural networks after\ntraining.",
    "descriptor": "",
    "authors": [
      "Nate Gruver",
      "Marc Finzi",
      "Micah Goldblum",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02984"
  },
  {
    "id": "arXiv:2210.02986",
    "title": "What Do I Need to Design for Co-Design? Supporting Co-design as a  Designerly Practice",
    "abstract": "Co-design practices have been used for decades to support participatory\nengagement in design work. However, despite a wide range of materials that\ndescribe the design and commitments of numerous co-design experiences, few\ndescriptions of the knowledge that guides designers when creating these\nexperiences exist. Thus, we ask: What kind of knowledge do designers need to\ndesign co-design experiences? What form(s) could intermediate-level knowledge\nfor co-design take? To answer these questions, we adopted a\nco/auto-ethnographic and Research-through-Design approach to reflexively engage\nwith our design decisions, outcomes, and challenges related to two virtual\nco-design workshops. We constructed a set of four multi-dimensional\nfacets(Rhythms of Engagement, Material Engagement, Ludic Engagement, and\nConceptual Achievement) and three roles (designer, researcher, facilitator) to\nconsider when creating co-design experiences. We illustrate these facets and\nroles through examples, building new \\textit{intermediate-level knowledge} to\nsupport future co-design research and design, framing co-design as a designerly\npractice.",
    "descriptor": "\nComments: 34 pages, 8 figures\n",
    "authors": [
      "Shruthi Sai Chivukula",
      "Colin M Gray"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02986"
  },
  {
    "id": "arXiv:2210.02987",
    "title": "TrustVault: A privacy-first data wallet for the European Blockchain  Services Infrastructure",
    "abstract": "The European Union is on course to introduce a European Digital Identity that\nwill be available to all EU citizens and businesses. This will have a huge\nimpact on how citizens and businesses interact online. Big Tech companies\ncurrently dictate how digital identities are used. As a result, they have\namassed vast amounts of private user data. Movements like Self-Sovereign\nIdentity aim to give users control over their online identity. TrustVault is\nthe first data wallet that gives users back control of their identity and all\ntheir data. TrustVault allows users to store all their data on their\nsmartphones and control with whom they share it. The user has fine-grained\naccess control based on verifiable user attributes. EBSI connects TrustVault to\nthe European Self-Sovereign Identity Framework allowing users to use Verifiable\nCredentials from public and private institutions in their access control\npolicies. The system is serverless and has no Trusted Third Parties. TrustVault\nreplaces the for-profit infrastructure of Big Tech with a public and\ntransparent platform for innovation.",
    "descriptor": "",
    "authors": [
      "Sharif Jacobino",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.02987"
  },
  {
    "id": "arXiv:2210.02989",
    "title": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using  Synthetic Data",
    "abstract": "Recent success in fine-tuning large models, that are pretrained on broad data\nat scale, on downstream tasks has led to a significant paradigm shift in deep\nlearning, from task-centric model design to task-agnostic representation\nlearning and task-specific fine-tuning. As the representations of pretrained\nmodels are used as a foundation for different downstream tasks, this paper\nproposes a new task-agnostic framework, \\textit{SynBench}, to measure the\nquality of pretrained representations using synthetic data. We set up a\nreference by a theoretically-derived robustness-accuracy tradeoff of the class\nconditional Gaussian mixture. Given a pretrained model, the representations of\ndata synthesized from the Gaussian mixture are used to compare with our\nreference to infer the quality.By comparing the ratio of area-under-curve\nbetween the raw data and their representations, SynBench offers a quantifiable\nscore for robustness-accuracy performance benchmarking. Our framework applies\nto a wide range of pretrained models taking continuous data inputs and is\nindependent of the downstream tasks and datasets. Evaluated with several\npretrained vision transformer models, the experimental results show that our\nSynBench score well matches the actual linear probing performance of the\npre-trained model when fine-tuned on downstream tasks. Moreover, our framework\ncan be used to inform the design of robust linear probing on pretrained\nrepresentations to mitigate the robustness-accuracy tradeoff in downstream\ntasks.",
    "descriptor": "",
    "authors": [
      "Ching-Yun Ko",
      "Pin-Yu Chen",
      "Jeet Mohapatra",
      "Payel Das",
      "Luca Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02989"
  },
  {
    "id": "arXiv:2210.02991",
    "title": "Cross-Modality Domain Adaptation for Freespace Detection: A Simple yet  Effective Baseline",
    "abstract": "As one of the fundamental functions of autonomous driving system, freespace\ndetection aims at classifying each pixel of the image captured by the camera as\ndrivable or non-drivable. Current works of freespace detection heavily rely on\nlarge amount of densely labeled training data for accuracy and robustness,\nwhich is time-consuming and laborious to collect and annotate. To the best of\nour knowledge, we are the first work to explore unsupervised domain adaptation\nfor freespace detection to alleviate the data limitation problem with synthetic\ndata. We develop a cross-modality domain adaptation framework which exploits\nboth RGB images and surface normal maps generated from depth images. A\nCollaborative Cross Guidance (CCG) module is proposed to leverage the context\ninformation of one modality to guide the other modality in a cross manner, thus\nrealizing inter-modality intra-domain complement. To better bridge the domain\ngap between source domain (synthetic data) and target domain (real-world data),\nwe also propose a Selective Feature Alignment (SFA) module which only aligns\nthe features of consistent foreground area between the two domains, thus\nrealizing inter-domain intra-modality adaptation. Extensive experiments are\nconducted by adapting three different synthetic datasets to one real-world\ndataset for freespace detection respectively. Our method performs closely to\nfully supervised freespace detection methods (93.08 v.s. 97.50 F1 score) and\noutperforms other general unsupervised domain adaptation methods for semantic\nsegmentation with large margins, which shows the promising potential of domain\nadaptation for freespace detection.",
    "descriptor": "\nComments: ACM Multimedia 2022\n",
    "authors": [
      "Yuanbin Wang",
      "Leyan Zhu",
      "Shaofei Huang",
      "Tianrui Hui",
      "Xiaojie Li",
      "Fei Wang",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02991"
  },
  {
    "id": "arXiv:2210.02994",
    "title": "Scaffolding Ethics-Focused Methods for Practice Resonance",
    "abstract": "Numerous methods and tools have been proposed to motivate or support ethical\nawareness in design practice. However, many existing resources are not easily\ndiscoverable by practitioners. One reason being that they are framed using\nlanguage that is not immediately accessible or resonant with the felt\ncomplexity of everyday practice. In this paper, we propose a set of\nempirically-supported \"intentions\" to frame practitioners' selection of\nrelevant ethics-focused methods based on interviews with practitioners from a\nrange of technology and design professions, and then leverage these intentions\nin the design and iterative evaluation of a website that allows practitioners\nto identify supports for ethics-focused action in their work context. Building\non these findings, we propose a set of heuristics to evaluate the practice\nresonance of resources to support ethics-focused practice, laying the\ngroundwork for increased ecological resonance of ethics-focused methods and\nmethod selection tools.",
    "descriptor": "",
    "authors": [
      "Colin M. Gray",
      "Shruthi Sai Chivukula",
      "Thomas Carlock",
      "Ziqing Li",
      "Ja-Nae Duane"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02994"
  },
  {
    "id": "arXiv:2210.02995",
    "title": "Compressed Vision for Efficient Video Understanding",
    "abstract": "Experience and reasoning occur across multiple temporal scales: milliseconds,\nseconds, hours or days. The vast majority of computer vision research, however,\nstill focuses on individual images or short videos lasting only a few seconds.\nThis is because handling longer videos require more scalable approaches even to\nprocess them. In this work, we propose a framework enabling research on\nhour-long videos with the same hardware that can now process second-long\nvideos. We replace standard video compression, e.g. JPEG, with neural\ncompression and show that we can directly feed compressed videos as inputs to\nregular video networks. Operating on compressed videos improves efficiency at\nall pipeline levels -- data transfer, speed and memory -- making it possible to\ntrain models faster and on much longer videos. Processing compressed signals\nhas, however, the downside of precluding standard augmentation techniques if\ndone naively. We address that by introducing a small network that can apply\ntransformations to latent codes corresponding to commonly used augmentations in\nthe original video space. We demonstrate that with our compressed vision\npipeline, we can train video models more efficiently on popular benchmarks such\nas Kinetics600 and COIN. We also perform proof-of-concept experiments with new\ntasks defined over hour-long videos at standard frame rates. Processing such\nlong videos is impossible without using compressed representation.",
    "descriptor": "\nComments: ACCV\n",
    "authors": [
      "Olivia Wiles",
      "Joao Carreira",
      "Iain Barr",
      "Andrew Zisserman",
      "Mateusz Malinowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02995"
  },
  {
    "id": "arXiv:2210.02997",
    "title": "Expander Graph Propagation",
    "abstract": "Deploying graph neural networks (GNNs) on whole-graph classification or\nregression tasks is known to be challenging: it often requires computing node\nfeatures that are mindful of both local interactions in their neighbourhood and\nthe global context of the graph structure. GNN architectures that navigate this\nspace need to avoid pathological behaviours, such as bottlenecks and\noversquashing, while ideally having linear time and space complexity\nrequirements. In this work, we propose an elegant approach based on propagating\ninformation over expander graphs. We provide an efficient method for\nconstructing expander graphs of a given size, and use this insight to propose\nthe EGP model. We show that EGP is able to address all of the above concerns,\nwhile requiring minimal effort to set up, and provide evidence of its empirical\nutility on relevant datasets and baselines in the Open Graph Benchmark.\nImportantly, using expander graphs as a template for message passing\nnecessarily gives rise to negative curvature. While this appears to be\ncounterintuitive in light of recent related work on oversquashing, we\ntheoretically demonstrate that negatively curved edges are likely to be\nrequired to obtain scalable message passing without bottlenecks. To the best of\nour knowledge, this is a previously unstudied result in the context of graph\nrepresentation learning, and we believe our analysis paves the way to a novel\nclass of scalable methods to counter oversquashing in GNNs.",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Andreea Deac",
      "Marc Lackenby",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02997"
  },
  {
    "id": "arXiv:2210.03002",
    "title": "Practitioner Trajectories of Engagement with Ethics-Focused Method  Creation",
    "abstract": "Design and technology practitioners are increasingly aware of the ethical\nimpact of their work practices, desiring tools to support their ethical\nawareness across a range of contexts. In this paper, we report on findings from\na series of co-design workshops with technology and design practitioners that\nsupported their creation of a bespoke ethics-focused action plan. Using a\nqualitative content analysis and thematic analysis approach, we identified a\nrange of roles and process moves that practitioners employed and illustrate the\ninterplay of these elements of practitioners' instrumental judgment through a\nseries of three cases, which includes evolution of the action plan itself, the\nethical dilemmas or areas of support the action plan was intended to support,\nand how the action plan represents resonance for the practitioner that created\nit. We conclude with implications for supporting ethics in socio-technical\npractice and opportunities for the further development of ethics-focused\nmethods that are resonant with the realities of practice.",
    "descriptor": "",
    "authors": [
      "Colin M. Gray",
      "Ikechukwu Obi",
      "Shruthi Sai Chivukula",
      "Ziqing Li",
      "Thomas Carlock",
      "Matthew Will",
      "Anne C. Pivonka",
      "Janna Johns",
      "Brookley Rigsbee",
      "Ambika R. Menon",
      "Aayushi Bharadwaj"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03002"
  },
  {
    "id": "arXiv:2210.03003",
    "title": "Enhancing Code Classification by Mixup-Based Data Augmentation",
    "abstract": "Recently, deep neural networks (DNNs) have been widely applied in programming\nlanguage understanding. Generally, training a DNN model with competitive\nperformance requires massive and high-quality labeled training data. However,\ncollecting and labeling such data is time-consuming and labor-intensive. To\ntackle this issue, data augmentation has been a popular solution, which\ndelicately increases the training data size, e.g., adversarial example\ngeneration. However, few works focus on employing it for programming\nlanguage-related tasks. In this paper, we propose a Mixup-based data\naugmentation approach, MixCode, to enhance the source code classification task.\nFirst, we utilize multiple code refactoring methods to generate\nlabel-consistent code data. Second, the Mixup technique is employed to mix the\noriginal code and transformed code to form the new training data to train the\nmodel. We evaluate MixCode on two programming languages (JAVA and Python), two\ncode tasks (problem classification and bug detection), four datasets (JAVA250,\nPython800, CodRep1, and Refactory), and 5 model architectures. Experimental\nresults demonstrate that MixCode outperforms the standard data augmentation\nbaseline by up to 6.24\\% accuracy improvement and 26.06\\% robustness\nimprovement.",
    "descriptor": "",
    "authors": [
      "Zeming Dong",
      "Qiang Hu",
      "Yuejun Guo",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03003"
  },
  {
    "id": "arXiv:2210.03005",
    "title": "To Softmax, or not to Softmax: that is the question when applying Active  Learning for Transformer Models",
    "abstract": "Despite achieving state-of-the-art results in nearly all Natural Language\nProcessing applications, fine-tuning Transformer-based language models still\nrequires a significant amount of labeled data to work. A well known technique\nto reduce the amount of human effort in acquiring a labeled dataset is\n\\textit{Active Learning} (AL): an iterative process in which only the minimal\namount of samples is labeled. AL strategies require access to a quantified\nconfidence measure of the model predictions. A common choice is the softmax\nactivation function for the final layer. As the softmax function provides\nmisleading probabilities, this paper compares eight alternatives on seven\ndatasets. Our almost paradoxical finding is that most of the methods are too\ngood at identifying the true most uncertain samples (outliers), and that\nlabeling therefore exclusively outliers results in worse performance. As a\nheuristic we propose to systematically ignore samples, which results in\nimprovements of various methods compared to the softmax function.",
    "descriptor": "",
    "authors": [
      "Julius Gonsior",
      "Christian Falkenberg",
      "Silvio Magino",
      "Anja Reusch",
      "Maik Thiele",
      "Wolfgang Lehner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.03005"
  },
  {
    "id": "arXiv:2210.03006",
    "title": "Random Max-CSPs Inherit Algorithmic Hardness from Spin Glasses",
    "abstract": "We study random constraint satisfaction problems (CSPs) in the unsatisfiable\nregime. We relate the structure of near-optimal solutions for any Max-CSP to\nthat for an associated spin glass on the hypercube, using the Guerra-Toninelli\ninterpolation from statistical physics. The noise stability polynomial of the\nCSP's predicate is, up to a constant, the mixture polynomial of the associated\nspin glass. We prove two main consequences:\n1) We relate the maximum fraction of constraints that can be satisfied in a\nrandom Max-CSP to the ground state energy density of the corresponding spin\nglass. Since the latter value can be computed with the Parisi formula, we\nprovide numerical values for some popular CSPs.\n2) We prove that a Max-CSP possesses generalized versions of the overlap gap\nproperty if and only if the same holds for the corresponding spin glass. We\ntransfer results from Huang et al. [arXiv:2110.07847, 2021] to obstruct\nalgorithms with overlap concentration on a large class of Max-CSPs. This\nimmediately includes local classical and local quantum algorithms.",
    "descriptor": "\nComments: 32 pages, 1 table\n",
    "authors": [
      "Chris Jones",
      "Kunal Marwaha",
      "Juspreet Singh Sandhu",
      "Jonathan Shi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.03006"
  },
  {
    "id": "arXiv:2210.03007",
    "title": "XDGAN: Multi-Modal 3D Shape Generation in 2D Space",
    "abstract": "Generative models for 2D images has recently seen tremendous progress in\nquality, resolution and speed as a result of the efficiency of 2D convolutional\narchitectures. However it is difficult to extend this progress into the 3D\ndomain since most current 3D representations rely on custom network components.\nThis paper addresses a central question: Is it possible to directly leverage 2D\nimage generative models to generate 3D shapes instead? To answer this, we\npropose XDGAN, an effective and fast method for applying 2D image GAN\narchitectures to the generation of 3D object geometry combined with additional\nsurface attributes, like color textures and normals. Specifically, we propose a\nnovel method to convert 3D shapes into compact 1-channel geometry images and\nleverage StyleGAN3 and image-to-image translation networks to generate 3D\nobjects in 2D space. The generated geometry images are quick to convert to 3D\nmeshes, enabling real-time 3D object synthesis, visualization and interactive\nediting. Moreover, the use of standard 2D architectures can help bring more 2D\nadvances into the 3D realm. We show both quantitatively and qualitatively that\nour method is highly effective at various tasks such as 3D shape generation,\nsingle view reconstruction and shape manipulation, while being significantly\nfaster and more flexible compared to recent 3D generative models.",
    "descriptor": "",
    "authors": [
      "Hassan Abu Alhaija",
      "Alara Dirik",
      "Andr\u00e9 Kn\u00f6rig",
      "Sanja Fidler",
      "Maria Shugrina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03007"
  },
  {
    "id": "arXiv:2210.03008",
    "title": "Residual-based error correction for neural operator accelerated  infinite-dimensional Bayesian inverse problems",
    "abstract": "We explore using neural operators, or neural network representations of\nnonlinear maps between function spaces, to accelerate infinite-dimensional\nBayesian inverse problems (BIPs) with models governed by nonlinear parametric\npartial differential equations (PDEs). Neural operators have gained significant\nattention in recent years for their ability to approximate the\nparameter-to-solution maps defined by PDEs using as training data solutions of\nPDEs at a limited number of parameter samples. The computational cost of BIPs\ncan be drastically reduced if the large number of PDE solves required for\nposterior characterization are replaced with evaluations of trained neural\noperators. However, reducing error in the resulting BIP solutions via reducing\nthe approximation error of the neural operators in training can be challenging\nand unreliable. We provide an a priori error bound result that implies certain\nBIPs can be ill-conditioned to the approximation error of neural operators,\nthus leading to inaccessible accuracy requirements in training. To reliably\ndeploy neural operators in BIPs, we consider a strategy for enhancing the\nperformance of neural operators, which is to correct the prediction of a\ntrained neural operator by solving a linear variational problem based on the\nPDE residual. We show that a trained neural operator with error correction can\nachieve a quadratic reduction of its approximation error, all while retaining\nsubstantial computational speedups of posterior sampling when models are\ngoverned by highly nonlinear PDEs. The strategy is applied to two numerical\nexamples of BIPs based on a nonlinear reaction--diffusion problem and\ndeformation of hyperelastic materials. We demonstrate that posterior\nrepresentations of the two BIPs produced using trained neural operators are\ngreatly and consistently enhanced by error correction.",
    "descriptor": "",
    "authors": [
      "Lianghao Cao",
      "Thomas O'Leary-Roseberry",
      "Prashant K. Jha",
      "J. Tinsley Oden",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03008"
  },
  {
    "id": "arXiv:2210.03011",
    "title": "Uncovering the Structural Fairness in Graph Contrastive Learning",
    "abstract": "Recent studies show that graph convolutional network (GCN) often performs\nworse for low-degree nodes, exhibiting the so-called structural unfairness for\ngraphs with long-tailed degree distributions prevalent in the real world. Graph\ncontrastive learning (GCL), which marries the power of GCN and contrastive\nlearning, has emerged as a promising self-supervised approach for learning node\nrepresentations. How does GCL behave in terms of structural fairness?\nSurprisingly, we find that representations obtained by GCL methods are already\nfairer to degree bias than those learned by GCN. We theoretically show that\nthis fairness stems from intra-community concentration and inter-community\nscatter properties of GCL, resulting in a much clear community structure to\ndrive low-degree nodes away from the community boundary. Based on our\ntheoretical analysis, we further devise a novel graph augmentation method,\ncalled GRAph contrastive learning for DEgree bias (GRADE), which applies\ndifferent strategies to low- and high-degree nodes. Extensive experiments on\nvarious benchmarks and evaluation protocols validate the effectiveness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Ruijia Wang",
      "Xiao Wang",
      "Chuan Shi",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03011"
  },
  {
    "id": "arXiv:2210.03012",
    "title": "Fast and robust parameter estimation with uncertainty quantification for  the cardiac function",
    "abstract": "Parameter estimation and uncertainty quantification are crucial in\ncomputational cardiology, as they enable the construction of digital twins that\nfaithfully replicate the behavior of physical patients. Robust and efficient\nmathematical methods must be designed to fit many model parameters starting\nfrom a few, possibly non-invasive, noisy observations. Moreover, the effective\nclinical translation requires short execution times and a small amount of\ncomputational resources. In the framework of Bayesian statistics, we combine\nMaximum a Posteriori estimation and Hamiltonian Monte Carlo to find an\napproximation of model parameters and their posterior distributions. To reduce\nthe computational effort, we employ an accurate Artificial Neural Network\nsurrogate of 3D cardiac electromechanics model coupled with a 0D\ncardiocirculatory model. Fast simulations and minimal memory requirements are\nachieved by using matrix-free methods, automatic differentiation and automatic\nvectorization. Furthermore, we account for the surrogate modeling error and\nmeasurement error. We perform three different in silico test cases, ranging\nfrom the ventricular function to the entire cardiovascular system, involving\nwhole-heart mechanics, arterial and venous circulation. The proposed method is\nrobust when high levels of signal-to-noise ratio are present in the quantities\nof interest in combination with a random initialization of the model parameters\nin suitable intervals. As a matter of fact, by employing a single central\nprocessing unit on a standard laptop and a few hours of computations, we attain\nsmall relative errors for all model parameters and we estimate posterior\ndistributions that contain the true values inside the 90% credibility regions.\nWith these benefits, our approach meets the requirements for clinical\nexploitation, while being compliant with Green Computing practices.",
    "descriptor": "",
    "authors": [
      "Matteo Salvador",
      "Francesco Regazzoni",
      "Luca Dede'",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03012"
  },
  {
    "id": "arXiv:2210.03014",
    "title": "EvilScreen Attack: Smart TV Hijacking via Multi-channel Remote Control  Mimicry",
    "abstract": "Modern smart TVs often communicate with their remote controls (including\nthose smart phone simulated ones) using multiple wireless channels (e.g.,\nInfrared, Bluetooth, and Wi-Fi). However, this multi-channel remote control\ncommunication introduces a new attack surface. An inherent security flaw is\nthat remote controls of most smart TVs are designed to work in a benign\nenvironment rather than an adversarial one, and thus wireless communications\nbetween a smart TV and its remote controls are not strongly protected.\nAttackers could leverage such flaw to abuse the remote control communication\nand compromise smart TV systems. In this paper, we propose EvilScreen, a novel\nattack that exploits ill-protected remote control communications to access\nprotected resources of a smart TV or even control the screen. EvilScreen\nexploits a multi-channel remote control mimicry vulnerability present in today\nsmart TVs. Unlike other attacks, which compromise the TV system by exploiting\ncode vulnerabilities or malicious third-party apps, EvilScreen directly reuses\ncommands of different remote controls, combines them together to circumvent\ndeployed authentication and isolation policies, and finally accesses or\ncontrols TV resources remotely. We evaluated eight mainstream smart TVs and\nfound that they are all vulnerable to EvilScreen attacks, including a Samsung\nproduct adopting the ISO/IEC security specification.",
    "descriptor": "",
    "authors": [
      "Yiwei Zhang",
      "Siqi Ma",
      "Tiancheng Chen",
      "Juanru Li",
      "Robert H. Deng",
      "Elisa Bertino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03014"
  },
  {
    "id": "arXiv:2210.03016",
    "title": "\"A Special Operation\": A Quantitative Approach to Dissecting and  Comparing Different Media Ecosystems' Coverage of the Russo-Ukrainian War",
    "abstract": "The coverage of the Russian invasion of Ukraine has varied widely between\nWestern, Russian, and Chinese media ecosystems with propaganda, disinformation,\nand narrative spins present in all three. By utilizing the normalized pointwise\nmutual information metric, differential sentiment analysis, word2vec models,\nand partially labeled Dirichlet allocation, we present a quantitative analysis\nof the differences in coverage amongst these three news ecosystems. We find\nthat while the Western press outlets have focused on the military and\nhumanitarian aspects of the war, Russian media have focused on the purported\njustifications for the \"special military operation\" such as the presence in\nUkraine of \"bio-weapons\" and \"neo-nazis\", and Chinese news media have\nconcentrated on the conflict's diplomatic and economic consequences. Detecting\nthe presence of several Russian disinformation narratives in the articles of\nseveral Chinese outlets, we finally measure the degree to which Russian media\nhas influenced Chinese coverage across Chinese outlets' news articles, Weibo\naccounts, and Twitter accounts. Our analysis indicates that since the Russian\ninvasion of Ukraine, Chinese state media outlets have increasingly cited\nRussian outlets as news sources and spread Russian disinformation narratives.",
    "descriptor": "\nComments: Accepted to ICWSM 2023\n",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03016"
  },
  {
    "id": "arXiv:2210.03018",
    "title": "Measuring Fine-Grained Semantic Equivalence with Abstract Meaning  Representation",
    "abstract": "Identifying semantically equivalent sentences is important for many\ncross-lingual and mono-lingual NLP tasks. Current approaches to semantic\nequivalence take a loose, sentence-level approach to \"equivalence,\" despite\nprevious evidence that fine-grained differences and implicit content have an\neffect on human understanding (Roth and Anthonio, 2021) and system performance\n(Briakou and Carpuat, 2021). In this work, we introduce a novel, more sensitive\nmethod of characterizing semantic equivalence that leverages Abstract Meaning\nRepresentation graph structures. We develop an approach, which can be used with\neither gold or automatic AMR annotations, and demonstrate that our solution is\nin fact finer-grained than existing corpus filtering methods and more accurate\nat predicting strictly equivalent sentences than existing semantic similarity\nmetrics. We suggest that our finer-grained measure of semantic equivalence\ncould limit the workload in the task of human post-edited machine translation\nand in human evaluation of sentence similarity.",
    "descriptor": "",
    "authors": [
      "Shira Wein",
      "Zhuxin Wang",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03018"
  },
  {
    "id": "arXiv:2210.03019",
    "title": "Comparative Analysis and Calibration of Low Cost Resistive and  Capacitive Soil Moisture Sensor",
    "abstract": "Soil moisture is an essential parameter in agriculture. It determines several\nenvironmental and agricultural activities such as climate change, drought\nprediction, irrigation, etc. Smart irrigation management requires continuous\nsoil moisture monitoring to reduce unnecessary water usage. In recent times,\nthe use of low-cost sensors is becoming popular among farmers for soil moisture\nmonitoring. In this paper, a comparison of low-cost resistive and capacitive\nsoil moisture sensors is demonstrated in two ways. One way is the calibration\nof the sensors in gravimetric and volumetric water content, and the other is\nthe sensors' response analysis when different quantities of water are added to\nthe same amount of soil. The analysis shown in this work is essential before\nchoosing cost-effective sensors for any soil moisture monitoring platform.",
    "descriptor": "",
    "authors": [
      "Sourodip Chowdhury",
      "Shaunak Sen",
      "S. Janardhanan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03019"
  },
  {
    "id": "arXiv:2210.03020",
    "title": "Model-Driven Engineering for Formal Verification and Security Testing of  Authentication Protocols",
    "abstract": "Even if the verification of authentication protocols can be achieved by means\nof formal analysis, the modelling of such an activity is an error-prone task\ndue to the lack of automated and integrated processes. This paper proposes a\ncomprehensive approach, based on the Unified Modeling Language (UML) profiling\ntechnique and on model-transformation, to enable automatic analysis of\nauthentication protocols starting from high-level models. In particular, a\nUML-based approach is able to generate an annotated model of communication\nprotocols from which formal notations (e.g., AnBx, Tamarin) can be generated.\nSuch models in lower-level languages can be analysed with existing solvers\nand/or with traditional testing techniques by means of test case generation\napproaches. The industrial impact of the research is high due to the growing\nneed of security and the necessity to connect industrial processes and\nequipment to virtualised computing infrastructures. The research is conducted\non two case studies: railway signalling systems and blockchain based\napplications.",
    "descriptor": "\nComments: Editor: Ib\\'eria Medeiros. 18th European Dependable Computing Conference (EDCC 2022), September 12-15, 2022, Zaragoza, Spain. Student Forum Proceedings - EDCC 2022\n",
    "authors": [
      "Mariapia Raimondo",
      "Stefano Marrone",
      "Angelo Palladino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03020"
  },
  {
    "id": "arXiv:2210.03021",
    "title": "Explanations as Programs in Probabilistic Logic Programming",
    "abstract": "The generation of comprehensible explanations is an essential feature of\nmodern artificial intelligence systems. In this work, we consider probabilistic\nlogic programming, an extension of logic programming which can be useful to\nmodel domains with relational structure and uncertainty. Essentially, a program\nspecifies a probability distribution over possible worlds (i.e., sets of\nfacts). The notion of explanation is typically associated with that of a world,\nso that one often looks for the most probable world as well as for the worlds\nwhere the query is true. Unfortunately, such explanations exhibit no causal\nstructure. In particular, the chain of inferences required for a specific\nprediction (represented by a query) is not shown. In this paper, we propose a\nnovel approach where explanations are represented as programs that are\ngenerated from a given query by a number of unfolding-like transformations.\nHere, the chain of inferences that proves a given query is made explicit.\nFurthermore, the generated explanations are minimal (i.e., contain no\nirrelevant information) and can be parameterized w.r.t. a specification of\nvisible predicates, so that the user may hide uninteresting details from\nexplanations.",
    "descriptor": "\nComments: Published as: Vidal, G. (2022). Explanations as Programs in Probabilistic Logic Programming. In: Hanus, M., Igarashi, A. (eds) Functional and Logic Programming. FLOPS 2022. Lecture Notes in Computer Science, vol 13215. Springer, Cham. The final authenticated publication is available online at this https URL\n",
    "authors": [
      "Germ\u00e1n Vidal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.03021"
  },
  {
    "id": "arXiv:2210.03022",
    "title": "Stateful active facilitator: Coordination and Environmental  Heterogeneity in Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "In cooperative multi-agent reinforcement learning, a team of agents works\ntogether to achieve a common goal. Different environments or tasks may require\nvarying degrees of coordination among agents in order to achieve the goal in an\noptimal way. The nature of coordination will depend on properties of the\nenvironment -- its spatial layout, distribution of obstacles, dynamics, etc. We\nterm this variation of properties within an environment as heterogeneity.\nExisting literature has not sufficiently addressed the fact that different\nenvironments may have different levels of heterogeneity. We formalize the\nnotions of coordination level and heterogeneity level of an environment and\npresent HECOGrid, a suite of multi-agent RL environments that facilitates\nempirical evaluation of different MARL approaches across different levels of\ncoordination and environmental heterogeneity by providing a quantitative\ncontrol over coordination and heterogeneity levels of the environment. Further,\nwe propose a Centralized Training Decentralized Execution learning approach\ncalled Stateful Active Facilitator (SAF) that enables agents to work\nefficiently in high-coordination and high-heterogeneity environments through a\ndifferentiable and shared knowledge source used during training and dynamic\nselection from a shared pool of policies. We evaluate SAF and compare its\nperformance against baselines IPPO and MAPPO on HECOGrid. Our results show that\nSAF consistently outperforms the baselines across different tasks and different\nheterogeneity and coordination levels.",
    "descriptor": "",
    "authors": [
      "Dianbo Liu",
      "Vedant Shah",
      "Oussama Boussif",
      "Cristian Meo",
      "Anirudh Goyal",
      "Tianmin Shu",
      "Michael Mozer",
      "Nicolas Heess",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03022"
  },
  {
    "id": "arXiv:2210.03026",
    "title": "Computing Race Variants in Message-Passing Concurrent Programming with  Selective Receives",
    "abstract": "Message-passing concurrency is a popular computation model that underlies\nseveral programming languages like, e.g., Erlang, Akka, and (to some extent) Go\nand Rust. In particular, we consider a message-passing concurrent language with\ndynamic process spawning and selective receives, i.e., where messages can only\nbe consumed by the target process when they match a specific constraint (e.g.,\nthe case of Erlang). In this work, we introduce a notion of trace that can be\nseen as an abstraction of a class of causally equivalent executions (i.e.,\nwhich produce the same outcome). We then show that execution traces can be used\nto identify message races. We provide constructive definitions to compute\nmessage races as well as to produce so-called race variants, which can then be\nused to drive new executions which are not causally equivalent to the previous\nones. This is an essential ingredient of state-space exploration techniques for\nprogram verification.",
    "descriptor": "\nComments: Published as: Vidal, G. (2022). Computing Race Variants in Message-Passing Concurrent Programming with Selective Receives. In: Mousavi, M.R., Philippou, A. (eds) FORTE 2022. Lecture Notes in Computer Science, vol 13273. Springer, Cham. The final authenticated publication is available online at this https URL arXiv admin note: text overlap with arXiv:2112.12869\n",
    "authors": [
      "Germ\u00e1n Vidal"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.03026"
  },
  {
    "id": "arXiv:2210.03027",
    "title": "AnimeTAB: A new guitar tablature dataset of anime and game music",
    "abstract": "While guitar tablature has become a popular topic in MIR research, there\nexists no such a guitar tablature dataset that focuses on the soundtracks of\nanime and video games, which have a surprisingly broad and growing audience\namong the youths. In this paper, we present AnimeTAB, a fingerstyle guitar\ntablature dataset in MusicXML format, which provides more high-quality guitar\ntablature for both researchers and guitar players. AnimeTAB contains 412 full\ntracks and 547 clips, the latter are annotated with musical structures (intro,\nverse, chorus, and bridge). An accompanying analysis toolkit, TABprocessor, is\nincluded to further facilitate its use. This includes functions for melody and\nbassline extraction, key detection, and chord labeling, which are implemented\nusing rule-based algorithms. We evaluated each of these functions against a\nmanually annotated ground truth. Finally, as an example, we performed a music\nand technique analysis of AnimeTAB using TABprocessor. Our data and code have\nbeen made publicly available for composers, performers, and music information\nretrieval (MIR) researchers alike.",
    "descriptor": "",
    "authors": [
      "Yuecheng Zhou",
      "Yaolong Ju",
      "Lingyun Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03027"
  },
  {
    "id": "arXiv:2210.03028",
    "title": "Detecting Narrative Elements in Informational Text",
    "abstract": "Automatic extraction of narrative elements from text, combining narrative\ntheories with computational models, has been receiving increasing attention\nover the last few years. Previous works have utilized the oral narrative theory\nby Labov and Waletzky to identify various narrative elements in personal\nstories texts. Instead, we direct our focus to informational texts,\nspecifically news stories. We introduce NEAT (Narrative Elements AnnoTation) -\na novel NLP task for detecting narrative elements in raw text. For this\npurpose, we designed a new multi-label narrative annotation scheme, better\nsuited for informational text (e.g. news media), by adapting elements from the\nnarrative theory of Labov and Waletzky (Complication and Resolution) and adding\na new narrative element of our own (Success). We then used this scheme to\nannotate a new dataset of 2,209 sentences, compiled from 46 news articles from\nvarious category domains. We trained a number of supervised models in several\ndifferent setups over the annotated dataset to identify the different narrative\nelements, achieving an average F1 score of up to 0.77. The results demonstrate\nthe holistic nature of our annotation scheme as well as its robustness to\ndomain category.",
    "descriptor": "\nComments: Accepted to Finding of NAACL 2022. Dataset is available at this https URL arXiv admin note: substantial text overlap with arXiv:2007.04874\n",
    "authors": [
      "Effi Levi",
      "Guy Mor",
      "Tamir Sheafer",
      "Shaul R. Shenhav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03028"
  },
  {
    "id": "arXiv:2210.03029",
    "title": "Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization",
    "abstract": "During zero-shot inference with language models (LMs), using hard prompts\nalone may not be able to fully describe the target task. In this paper, we\nexplore how the retrieval of soft prompts obtained through prompt tuning can\nassist hard prompts in zero-shot task generalization. Specifically, we train\nsoft prompt embeddings for each prompt through prompt tuning, store the samples\nof the training instances (hard prompt + input instances) mapped with the\nprompt embeddings, and retrieve the corresponding prompt embedding of the\ntraining instance closest to the query instance during inference. Results show\nthis simple approach enhances the performance of T0 on unseen tasks by\noutperforming it on 10 out of 11 datasets as well as improving the mean\naccuracy of T0 on BIG-bench benchmark by 2.39% points while adding only 0.007%\nadditional parameters. Also, using interpolation of multiple embeddings and\nvariance-based ranking further improve accuracy and robustness to different\nevaluation prompts, widening the performance gap. Finally, we find that\nretrieving source embeddings trained on similar answer choice formats is more\nimportant than those on similar task types. Model checkpoints and code\nimplementation are available at https://github.com/seonghyeonye/RoSPr.",
    "descriptor": "",
    "authors": [
      "Seonghyeon Ye",
      "Joel Jang",
      "Doyoung Kim",
      "Yongrae Jo",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03029"
  },
  {
    "id": "arXiv:2210.03037",
    "title": "Conversational Semantic Role Labeling with Predicate-Oriented Latent  Graph",
    "abstract": "Conversational semantic role labeling (CSRL) is a newly proposed task that\nuncovers the shallow semantic structures in a dialogue text. Unfortunately\nseveral important characteristics of the CSRL task have been overlooked by the\nexisting works, such as the structural information integration, near-neighbor\ninfluence. In this work, we investigate the integration of a latent graph for\nCSRL. We propose to automatically induce a predicate-oriented latent graph\n(POLar) with a predicate-centered Gaussian mechanism, by which the nearer and\ninformative words to the predicate will be allocated with more attention. The\nPOLar structure is then dynamically pruned and refined so as to best fit the\ntask need. We additionally introduce an effective dialogue-level pre-trained\nlanguage model, CoDiaBERT, for better supporting multiple utterance sentences\nand handling the speaker coreference issue in CSRL. Our system outperforms\nbest-performing baselines on three benchmark CSRL datasets with big margins,\nespecially achieving over 4% F1 score improvements on the cross-utterance\nargument detection. Further analyses are presented to better understand the\neffectiveness of our proposed methods.",
    "descriptor": "",
    "authors": [
      "Hao Fei",
      "Shengqiong Wu",
      "Meishan Zhang",
      "Yafeng Ren",
      "Donghong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03037"
  },
  {
    "id": "arXiv:2210.03040",
    "title": "Rolling Shutter Inversion: Bring Rolling Shutter Images to High  Framerate Global Shutter Video",
    "abstract": "A single rolling-shutter (RS) image may be viewed as a row-wise combination\nof a sequence of global-shutter (GS) images captured by a (virtual) moving GS\ncamera within the exposure duration. Although RS cameras are widely used, the\nRS effect causes obvious image distortion especially in the presence of fast\ncamera motion, hindering downstream computer vision tasks. In this paper, we\npropose to invert the RS image capture mechanism, i.e., recovering a continuous\nhigh framerate GS video from two time-consecutive RS frames. We call this task\nthe RS temporal super-resolution (RSSR) problem. The RSSR is a very challenging\ntask, and to our knowledge, no practical solution exists to date. This paper\npresents a novel deep-learning based solution. By leveraging the multi-view\ngeometry relationship of the RS imaging process, our learning-based framework\nsuccessfully achieves high framerate GS generation. Specifically, three novel\ncontributions can be identified: (i) novel formulations for bidirectional RS\nundistortion flows under constant velocity as well as constant acceleration\nmotion model. (ii) a simple linear scaling operation, which bridges the RS\nundistortion flow and regular optical flow. (iii) a new mutual conversion\nscheme between varying RS undistortion flows that correspond to different\nscanlines. Our method also exploits the underlying spatial-temporal geometric\nrelationships within a deep learning framework, where no additional supervision\nis required beyond the necessary middle-scanline GS image. Building upon these\ncontributions, we represent the very first rolling-shutter temporal\nsuper-resolution deep-network that is able to recover high framerate GS videos\nfrom just two RS frames. Extensive experimental results on both synthetic and\nreal data show that our proposed method can produce high-quality GS image\nsequences with rich details, outperforming the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), 16 Pages, 14 Figures\n",
    "authors": [
      "Bin Fan",
      "Yuchao Dai",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03040"
  },
  {
    "id": "arXiv:2210.03042",
    "title": "Perception of Personality Traits in Crowds of Virtual Humans",
    "abstract": "This paper proposes a perceptual visual analysis regarding the personality of\nvirtual humans. Many studies have presented findings regarding the way human\nbeings perceive virtual humans with respect to their faces, body animation,\nmotion in the virtual environment and etc. We are interested in investigating\nthe way people perceive visual manifestations of virtual humans' personality\ntraits when they are interactive and organized in groups. Many applications in\ngames and movies can benefit from the findings regarding the perceptual\nanalysis with the main goal to provide more realistic characters and improve\nthe users' experience. We provide experiments with subjects and obtained\nresults indicate that, although is very subtle, people perceive more the\nextraversion (the personality trait that we measured), into the crowds of\nvirtual humans, when interacting with virtual humans behaviors, than when just\nobserving as a spectator camera.",
    "descriptor": "\nComments: 9 pages, 7 figures, 1 table\n",
    "authors": [
      "Lucas Nardino",
      "Enzo Krzmienszki",
      "Vin\u00edcius Jurinic Cassol",
      "Diogo Schaffer",
      "Victor Fl\u00e1vio de Andrade Araujo",
      "Rodolfo Migon Favaretto",
      "Felipe Elsner",
      "Gabriel Fonseca Silva",
      "Soraia Raupp Musse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03042"
  },
  {
    "id": "arXiv:2210.03043",
    "title": "Feature-Realistic Neural Fusion for Real-Time, Open Set Scene  Understanding",
    "abstract": "General scene understanding for robotics requires flexible semantic\nrepresentation, so that novel objects and structures which may not have been\nknown at training time can be identified, segmented and grouped. We present an\nalgorithm which fuses general learned features from a standard pre-trained\nnetwork into a highly efficient 3D geometric neural field representation during\nreal-time SLAM. The fused 3D feature maps inherit the coherence of the neural\nfield's geometry representation. This means that tiny amounts of human\nlabelling interacting at runtime enable objects or even parts of objects to be\nrobustly and accurately segmented in an open set manner.",
    "descriptor": "\nComments: For our project page, see this https URL\n",
    "authors": [
      "Kirill Mazur",
      "Edgar Sucar",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03043"
  },
  {
    "id": "arXiv:2210.03044",
    "title": "Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning  Ticket's Mask?",
    "abstract": "Modern deep learning involves training costly, highly overparameterized\nnetworks, thus motivating the search for sparser networks that can still be\ntrained to the same accuracy as the full network (i.e. matching). Iterative\nmagnitude pruning (IMP) is a state of the art algorithm that can find such\nhighly sparse matching subnetworks, known as winning tickets. IMP operates by\niterative cycles of training, masking smallest magnitude weights, rewinding\nback to an early training point, and repeating. Despite its simplicity, the\nunderlying principles for when and how IMP finds winning tickets remain\nelusive. In particular, what useful information does an IMP mask found at the\nend of training convey to a rewound network near the beginning of training? How\ndoes SGD allow the network to extract this information? And why is iterative\npruning needed? We develop answers in terms of the geometry of the error\nlandscape. First, we find that$\\unicode{x2014}$at higher\nsparsities$\\unicode{x2014}$pairs of pruned networks at successive pruning\niterations are connected by a linear path with zero error barrier if and only\nif they are matching. This indicates that masks found at the end of training\nconvey the identity of an axial subspace that intersects a desired linearly\nconnected mode of a matching sublevel set. Second, we show SGD can exploit this\ninformation due to a strong form of robustness: it can return to this mode\ndespite strong perturbations early in training. Third, we show how the flatness\nof the error landscape at the end of training determines a limit on the\nfraction of weights that can be pruned at each iteration of IMP. Finally, we\nshow that the role of retraining in IMP is to find a network with new small\nweights to prune. Overall, these results make progress toward demystifying the\nexistence of winning tickets by revealing the fundamental role of error\nlandscape geometry.",
    "descriptor": "\nComments: The first three authors contributed equally\n",
    "authors": [
      "Mansheej Paul",
      "Feng Chen",
      "Brett W. Larsen",
      "Jonathan Frankle",
      "Surya Ganguli",
      "Gintare Karolina Dziugaite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03044"
  },
  {
    "id": "arXiv:2210.03050",
    "title": "State-of-the-art generalisation research in NLP: a taxonomy and review",
    "abstract": "The ability to generalise well is one of the primary desiderata of natural\nlanguage processing NLP). Yet, what `good generalisation' entails and how it\nshould be evaluated is not well understood, nor are there any common standards\nto evaluate it. In this paper, we aim to lay the ground-work to improve both of\nthese issues. We present a taxonomy for characterising and understanding\ngeneralisation research in NLP, we use that taxonomy to present a comprehensive\nmap of published generalisation studies, and we make recommendations for which\nareas might deserve attention in the future. Our taxonomy is based on an\nextensive literature review of generalisation research, and contains five axes\nalong which studies can differ: their main motivation, the type of\ngeneralisation they aim to solve, the type of data shift they consider, the\nsource by which this data shift is obtained, and the locus of the shift within\nthe modelling pipeline. We use our taxonomy to classify over 400 previous\npapers that test generalisation, for a total of more than 600 individual\nexperiments. Considering the results of this review, we present an in-depth\nanalysis of the current state of generalisation research in NLP, and make\nrecommendations for the future. Along with this paper, we release a webpage\nwhere the results of our review can be dynamically explored, and which we\nintend to up-date as new NLP generalisation studies are published. With this\nwork, we aim to make steps towards making state-of-the-art generalisation\ntesting the new status quo in NLP.",
    "descriptor": "\nComments: 35 pages of content + 72 pages of references\n",
    "authors": [
      "Dieuwke Hupkes",
      "Mario Giulianelli",
      "Verna Dankers",
      "Mikel Artetxe",
      "Yanai Elazar",
      "Tiago Pimentel",
      "Christos Christodoulopoulos",
      "Karim Lasri",
      "Naomi Saphra",
      "Arabella Sinclair",
      "Dennis Ulmer",
      "Florian Schottmann",
      "Khuyagbaatar Batsuren",
      "Kaiser Sun",
      "Koustuv Sinha",
      "Leila Khalatbari",
      "Rita Frieske",
      "Ryan Cotterell",
      "Zhijing Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03050"
  },
  {
    "id": "arXiv:2210.03052",
    "title": "ByteTransformer: A High-Performance Transformer Boosted for  Variable-Length Inputs",
    "abstract": "Transformer is the cornerstone model of Natural Language Processing (NLP)\nover the past decade. Despite its great success in Deep Learning (DL)\napplications, the increasingly growing parameter space required by transformer\nmodels boosts the demand on accelerating the performance of transformer models.\nIn addition, NLP problems can commonly be faced with variable-length sequences\nsince their word numbers can vary among sentences. Existing DL frameworks need\nto pad variable-length sequences to the maximal length, which, however, leads\nto significant memory and computational overhead. In this paper, we present\nByteTransformer, a high-performance transformer boosted for variable-length\ninputs. We propose a zero padding algorithm that enables the whole transformer\nto be free from redundant computations on useless padded tokens. Besides the\nalgorithmic level optimization, we provide architectural-aware optimizations\nfor transformer functioning modules, especially the performance-critical\nalgorithm, multi-head attention (MHA). Experimental results on an NVIDIA A100\nGPU with variable-length sequence inputs validate that our fused MHA (FMHA)\noutperforms the standard PyTorch MHA by 6.13X. The end-to-end performance of\nByteTransformer for a standard BERT transformer model surpasses the\nstate-of-the-art Transformer frameworks, such as PyTorch JIT, TensorFlow XLA,\nTencent TurboTransformer and NVIDIA FasterTransformer, by 87\\%, 131\\%, 138\\%\nand 46\\%, respectively.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Yujia Zhai",
      "Chengquan Jiang",
      "Leyuan Wang",
      "Xiaoying Jia",
      "Shang Zhang",
      "Zizhong Chen",
      "Xin Liu",
      "Yibo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03052"
  },
  {
    "id": "arXiv:2210.03053",
    "title": "Reinforcement Learning with Large Action Spaces for Neural Machine  Translation",
    "abstract": "Applying Reinforcement learning (RL) following maximum likelihood estimation\n(MLE) pre-training is a versatile method for enhancing neural machine\ntranslation (NMT) performance. However, recent work has argued that the gains\nproduced by RL for NMT are mostly due to promoting tokens that have already\nreceived a fairly high probability in pre-training. We hypothesize that the\nlarge action space is a main obstacle to RL's effectiveness in MT, and conduct\ntwo sets of experiments that lend support to our hypothesis. First, we find\nthat reducing the size of the vocabulary improves RL's effectiveness. Second,\nwe find that effectively reducing the dimension of the action space without\nchanging the vocabulary also yields notable improvement as evaluated by BLEU,\nsemantic similarity, and human evaluation. Indeed, by initializing the\nnetwork's final fully connected layer (that maps the network's internal\ndimension to the vocabulary dimension), with a layer that generalizes over\nsimilar actions, we obtain a substantial improvement in RL performance: 1.5\nBLEU points on average.",
    "descriptor": "\nComments: Accepted for Coling\n",
    "authors": [
      "Asaf Yehudai",
      "Leshem Choshen",
      "Lior Fox",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03053"
  },
  {
    "id": "arXiv:2210.03055",
    "title": "Lattice Linear Problems vs Algorithms",
    "abstract": "Modeling problems using predicates that induce a partial order among global\nstates was introduced as a way to permit asynchronous execution in\nmultiprocessor systems. A key property of them is that the predicate induces\none lattice in the state space which guarantees that the execution is correct\neven if nodes execute with old information about their neighbours.\nUnfortunately, many interesting problems do not exhibit lattice linearity. This\nissue was alleviated with the introduction of eventually lattice linear\nalgorithms. Such algorithms induce a partial order in a subset of the state\nspace even though the problem cannot be defined by a predicate under which the\nstates form a partial order.\nThis paper focuses on analyzing and differentiating between lattice linear\nproblems and algorithms. It also introduces a new class of algorithms called\n(fully) lattice linear algorithms. A characteristic of these algorithms is that\nthe entire reachable state space is partitioned into one or more lattices and\nthe initial state locks into one of these lattices. Thus, under a few\nadditional constraints, the initial state can uniquely determine the final\nstate. For demonstration, we present lattice linear self-stabilizing algorithms\nfor minimal dominating set and graph colouring problems, and a parallel\nprocessing 2-approximation algorithm for vertex cover.\nThe algorithm for minimal dominating set converges in $n$ moves, and that for\ngraph colouring converges in $n+2m$ moves. These algorithms preserve this time\ncomplexity while allowing the nodes to execute asynchronously and take actions\nbased on old or inconsistent information about their neighbours. They present\nan improvement to the existing algorithms present in the literature. The\nalgorithm for vertex cover is the first lattice linear approximation algorithm\nfor an NP-Hard problem; it converges in $n$ moves.",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta",
      "Sandeep S Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.03055"
  },
  {
    "id": "arXiv:2210.03057",
    "title": "Language Models are Multilingual Chain-of-Thought Reasoners",
    "abstract": "We evaluate the reasoning abilities of large language models in multilingual\nsettings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by\nmanually translating 250 grade-school math problems from the GSM8K dataset\n(Cobbe et al., 2021) into ten typologically diverse languages. We find that the\nability to solve MGSM problems via chain-of-thought prompting emerges with\nincreasing model scale, and that models have strikingly strong multilingual\nreasoning abilities, even in underrepresented languages such as Bengali and\nSwahili. Finally, we show that the multilingual reasoning abilities of language\nmodels extend to other tasks such as commonsense reasoning and word-in-context\nsemantic judgment. The MGSM benchmark is publicly available at\nhttps://github.com/google-research/url-nlp.",
    "descriptor": "",
    "authors": [
      "Freda Shi",
      "Mirac Suzgun",
      "Markus Freitag",
      "Xuezhi Wang",
      "Suraj Srivats",
      "Soroush Vosoughi",
      "Hyung Won Chung",
      "Yi Tay",
      "Sebastian Ruder",
      "Denny Zhou",
      "Dipanjan Das",
      "Jason Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03057"
  },
  {
    "id": "arXiv:2210.03060",
    "title": "LODUS: A Multi-Level Framework for Simulating Environment and Population  -- A Contagion Experiment on a Pandemic World",
    "abstract": "Nowadays we are experiencing a way of life that never existed before. The\npandemic has sharply changed our habits, customs, and behavior. In addition, a\nlot of work was suddenly requested for city managers challenging them to\ndevelop strategies to try stopping the pandemic progression. Urban environments\nmust be dynamic and managers need fast decisions when working on crisis\nsituations. In this paper we present LODUS, a framework able to simulate urban\nenvironments on a multi-level approach, combining macro and micro simulation\ninformation in order to provide accurate information about population dynamics.\nFurthermore, the framework LODUS is a powerful tool when performing an urban\nviability study, since the simulation results are able to highlight and predict\nattention points prior to an urban environment to be built.",
    "descriptor": "\nComments: 9 pages, 7 figures, 4 equations\n",
    "authors": [
      "Gabriel Fonseca Silva",
      "Vin\u00edcius Cassol",
      "Amyr Borges Fortes Neto",
      "Andre Antonitsch",
      "Diogo Schaffer",
      "Soraia Raupp Musse",
      "Rodrigo de Marsillac Linn"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03060"
  },
  {
    "id": "arXiv:2210.03061",
    "title": "Structure Representation Network and Uncertainty Feedback Learning for  Dense Non-Uniform Fog Removal",
    "abstract": "Few existing image defogging or dehazing methods consider dense and\nnon-uniform particle distributions, which usually happen in smoke, dust and\nfog. Dealing with these dense and/or non-uniform distributions can be\nintractable, since fog's attenuation and airlight (or veiling effect)\nsignificantly weaken the background scene information in the input image. To\naddress this problem, we introduce a structure-representation network with\nuncertainty feedback learning. Specifically, we extract the feature\nrepresentations from a pre-trained Vision Transformer (DINO-ViT) module to\nrecover the background information. To guide our network to focus on\nnon-uniform fog areas, and then remove the fog accordingly, we introduce the\nuncertainty feedback learning, which produces the uncertainty maps, that have\nhigher uncertainty in denser fog regions, and can be regarded as an attention\nmap that represents fog's density and uneven distribution. Based on the\nuncertainty map, our feedback network refines our defogged output iteratively.\nMoreover, to handle the intractability of estimating the atmospheric light\ncolors, we exploit the grayscale version of our input image, since it is less\naffected by varying light colors that are possibly present in the input image.\nThe experimental results demonstrate the effectiveness of our method both\nquantitatively and qualitatively compared to the state-of-the-art methods in\nhandling dense and non-uniform fog or smoke.",
    "descriptor": "\nComments: Accepted to ACCV2022, data in this https URL\n",
    "authors": [
      "Yeying Jin",
      "Wending Yan",
      "Wenhan Yang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03061"
  },
  {
    "id": "arXiv:2210.03065",
    "title": "MOCAS: A Multimodal Dataset for Objective Cognitive Workload Assessment  on Simultaneous Tasks",
    "abstract": "This paper presents MOCAS, a multimodal dataset dedicated for human cognitive\nworkload (CWL) assessment. In contrast to existing datasets based on virtual\ngame stimuli, the data in MOCAS was collected from realistic closed-circuit\ntelevision (CCTV) monitoring tasks, increasing its applicability for real-world\nscenarios. To build MOCAS, two off-the-shelf wearable sensors and one webcam\nwere utilized to collect physiological signals and behavioral features from 21\nhuman subjects. After each task, participants reported their CWL by completing\nthe NASA-Task Load Index (NASA-TLX) and Instantaneous Self-Assessment (ISA).\nPersonal background (e.g., personality and prior experience) was surveyed using\ndemographic and Big Five Factor personality questionnaires, and two domains of\nsubjective emotion information (i.e., arousal and valence) were obtained from\nthe Self-Assessment Manikin, which could serve as potential indicators for\nimproving CWL recognition performance. Technical validation was conducted to\ndemonstrate that target CWL levels were elicited during simultaneous CCTV\nmonitoring tasks; its results support the high quality of the collected\nmultimodal signals.",
    "descriptor": "",
    "authors": [
      "Wonse Jo",
      "Ruiqi Wang",
      "Su Sun",
      "Revanth Krishna Senthilkumaran",
      "Daniel Foti",
      "Byung-Cheol Min"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.03065"
  },
  {
    "id": "arXiv:2210.03068",
    "title": "InferES : A Natural Language Inference Corpus for Spanish Featuring  Negation-Based Contrastive and Adversarial Examples",
    "abstract": "In this paper, we present InferES - an original corpus for Natural Language\nInference (NLI) in European Spanish. We propose, implement, and analyze a\nvariety of corpus-creating strategies utilizing expert linguists and crowd\nworkers. The objectives behind InferES are to provide high-quality data, and,\nat the same time to facilitate the systematic evaluation of automated systems.\nSpecifically, we focus on measuring and improving the performance of machine\nlearning systems on negation-based adversarial examples and their ability to\ngeneralize across out-of-distribution topics.\nWe train two transformer models on InferES (8,055 gold examples) in a variety\nof scenarios. Our best model obtains 72.8% accuracy, leaving a lot of room for\nimprovement. The \"hypothesis-only\" baseline performs only 2%-5% higher than\nmajority, indicating much fewer annotation artifacts than prior work. We find\nthat models trained on InferES generalize very well across topics (both in- and\nout-of-distribution) and perform moderately well on negation-based adversarial\nexamples.",
    "descriptor": "\nComments: Accepted at COLING 2022\n",
    "authors": [
      "Venelin Kovatchev",
      "Mariona Taul\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03068"
  },
  {
    "id": "arXiv:2210.03069",
    "title": "A Better Way to Decay: Proximal Gradient Training Algorithms for Neural  Nets",
    "abstract": "Weight decay is one of the most widely used forms of regularization in deep\nlearning, and has been shown to improve generalization and robustness. The\noptimization objective driving weight decay is a sum of losses plus a term\nproportional to the sum of squared weights. This paper argues that stochastic\ngradient descent (SGD) may be an inefficient algorithm for this objective. For\nneural networks with ReLU activations, solutions to the weight decay objective\nare equivalent to those of a different objective in which the regularization\nterm is instead a sum of products of $\\ell_2$ (not squared) norms of the input\nand output weights associated each ReLU. This alternative (and effectively\nequivalent) regularization suggests a novel proximal gradient algorithm for\nnetwork training. Theory and experiments support the new training approach,\nshowing that it can converge much faster to the sparse solutions it shares with\nstandard weight decay training.",
    "descriptor": "",
    "authors": [
      "Liu Yang",
      "Jifan Zhang",
      "Joseph Shenouda",
      "Dimitris Papailiopoulos",
      "Kangwook Lee",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03069"
  },
  {
    "id": "arXiv:2210.03070",
    "title": "Toxicity in Multilingual Machine Translation at Scale",
    "abstract": "Machine Translation systems can produce different types of errors, some of\nwhich get characterized as critical or catastrophic due to the specific\nnegative impact they can have on users. Automatic or human evaluation metrics\ndo not necessarily differentiate between such critical errors and more\ninnocuous ones. In this paper we focus on one type of critical error: added\ntoxicity. We evaluate and analyze added toxicity when translating a large\nevaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic\naxes) from English into 164 languages. The toxicity automatic evaluation shows\nthat added toxicity across languages varies from 0% to 5%. The output languages\nwith the most added toxicity tend to be low-resource ones, and the demographic\naxes with the most added toxicity include sexual orientation, gender and sex,\nand ability. We also perform human evaluation on a subset of 8 directions,\nconfirming the prevalence of true added toxicity.\nWe use a measurement of the amount of source contribution to the translation,\nwhere a low source contribution implies hallucination, to interpret what causes\ntoxicity. We observe that the source contribution is somewhat correlated with\ntoxicity but that 45.6% of added toxic words have a high source contribution,\nsuggesting that much of the added toxicity may be due to mistranslations.\nCombining the signal of source contribution level with a measurement of\ntranslation robustness allows us to flag 22.3% of added toxicity, suggesting\nthat added toxicity may be related to both hallucination and the stability of\ntranslations in different contexts. Given these findings, our recommendations\nto reduce added toxicity are to curate training data to avoid mistranslations,\nmitigate hallucination and check unstable translations.",
    "descriptor": "",
    "authors": [
      "Marta R. Costa-juss\u00e0",
      "Eric Smith",
      "Christophe Ropers",
      "Daniel Licht",
      "Javier Ferrando",
      "Carlos Escolano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03070"
  },
  {
    "id": "arXiv:2210.03072",
    "title": "IJCB 2022 Mobile Behavioral Biometrics Competition (MobileB2C)",
    "abstract": "This paper describes the experimental framework and results of the IJCB 2022\nMobile Behavioral Biometrics Competition (MobileB2C). The aim of MobileB2C is\nbenchmarking mobile user authentication systems based on behavioral biometric\ntraits transparently acquired by mobile devices during ordinary Human-Computer\nInteraction (HCI), using a novel public database, BehavePassDB, and a standard\nexperimental protocol. The competition is divided into four tasks corresponding\nto typical user activities: keystroke, text reading, gallery swiping, and\ntapping. The data are composed of touchscreen data and several background\nsensor data simultaneously acquired. \"Random\" (different users with different\ndevices) and \"skilled\" (different user on the same device attempting to imitate\nthe legitimate one) impostor scenarios are considered. The results achieved by\nthe participants show the feasibility of user authentication through behavioral\nbiometrics, although this proves to be a non-trivial challenge. MobileB2C will\nbe established as an on-going competition.",
    "descriptor": "",
    "authors": [
      "Giuseppe Stragapede",
      "Ruben Vera-Rodriguez",
      "Ruben Tolosana",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia",
      "Sanka Rasnayaka",
      "Sachith Seneviratne",
      "Vipula Dissanayake",
      "Jonathan Liebers",
      "Ashhadul Islam",
      "Samir Brahim Belhaouari",
      "Sumaiya Ahmad",
      "Suraiya Jabin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03072"
  },
  {
    "id": "arXiv:2210.03073",
    "title": "Moving Virtual Agents Forward in Space and Time",
    "abstract": "This article proposes an adaptation from the model of Bianco for\nfast-forwarding agents in crowd simulation, which enables us to accurately fast\nforward agents in time. Besides being able to jump from one position to\nanother, agents are able to stay inside their track, it means, the new position\nis calculated taking into account the original global path the agent would\nfollow, if not being fast-forwarded. Obstacles and other agents around are also\ntaken into account when calculating the new position. In addition, we included\na personality aspect on agents, which affect their behaviors and, also, be\ntaken into account when jumping to a future time and space. We conducted some\nexperiments to validate our model, which shows that it was able to indeed fast\nforward agents from a position to another, in a coherent time, sticking to a\ngiven global path while avoiding collisions. Finally, we present a use case,\nshowing that our method can fit inside a \"Fog of War\" system.",
    "descriptor": "\nComments: 10 pages, 5 figures, 5 tables, 2 equations\n",
    "authors": [
      "Gabriel F. Silva",
      "Paulo Knob",
      "Carlos G. Johansson",
      "Douglas A. Schlatter",
      "Soraia R. Musse"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.03073"
  },
  {
    "id": "arXiv:2210.03078",
    "title": "Rainier: Reinforced Knowledge Introspector for Commonsense Question  Answering",
    "abstract": "Knowledge underpins reasoning. Recent research demonstrates that when\nrelevant knowledge is provided as additional context to commonsense question\nanswering (QA), it can substantially enhance the performance even on top of\nstate-of-the-art. The fundamental challenge is where and how to find such\nknowledge that is high quality and on point with respect to the question;\nknowledge retrieved from knowledge bases are incomplete and knowledge generated\nfrom language models are inconsistent.\nWe present Rainier, or Reinforced Knowledge Introspector, that learns to\ngenerate contextually relevant knowledge in response to given questions. Our\napproach starts by imitating knowledge generated by GPT-3, then learns to\ngenerate its own knowledge via reinforcement learning where rewards are shaped\nbased on the increased performance on the resulting question answering. Rainier\ndemonstrates substantial and consistent performance gains when tested over 9\ndifferent commonsense benchmarks: including 5 in-domain benchmarks that are\nseen during reinforcement learning, as well as 4 out-of-domain benchmarks that\nare kept unseen. Our work is the first to report that knowledge generated by\nmodels that are orders of magnitude smaller than GPT-3, even without direct\nsupervision on the knowledge itself, can exceed the quality of knowledge\nelicited from GPT-3 for commonsense QA.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (Main Conference)\n",
    "authors": [
      "Jiacheng Liu",
      "Skyler Hallinan",
      "Ximing Lu",
      "Pengfei He",
      "Sean Welleck",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03078"
  },
  {
    "id": "arXiv:2210.03080",
    "title": "Explainable Verbal Deception Detection using Transformers",
    "abstract": "People are regularly confronted with potentially deceptive statements (e.g.,\nfake news, misleading product reviews, or lies about activities). Only few\nworks on automated text-based deception detection have exploited the potential\nof deep learning approaches. A critique of deep-learning methods is their lack\nof interpretability, preventing us from understanding the underlying\n(linguistic) mechanisms involved in deception. However, recent advancements\nhave made it possible to explain some aspects of such models. This paper\nproposes and evaluates six deep-learning models, including combinations of BERT\n(and RoBERTa), MultiHead Attention, co-attentions, and transformers. To\nunderstand how the models reach their decisions, we then examine the model's\npredictions with LIME. We then zoom in on vocabulary uniqueness and the\ncorrelation of LIWC categories with the outcome class (truthful vs deceptive).\nThe findings suggest that our transformer-based models can enhance automated\ndeception detection performances (+2.11% in accuracy) and show significant\ndifferences pertinent to the usage of LIWC features in truthful and deceptive\nstatements.",
    "descriptor": "",
    "authors": [
      "Loukas Ilias",
      "Felix Soldner",
      "Bennett Kleinberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03080"
  },
  {
    "id": "arXiv:2210.03087",
    "title": "Iterative Vision-and-Language Navigation",
    "abstract": "We present Iterative Vision-and-Language Navigation (IVLN), a paradigm for\nevaluating language-guided agents navigating in a persistent environment over\ntime. Existing Vision-and-Language Navigation (VLN) benchmarks erase the\nagent's memory at the beginning of every episode, testing the ability to\nperform cold-start navigation with no prior information. However, deployed\nrobots occupy the same environment for long periods of time. The IVLN paradigm\naddresses this disparity by training and evaluating VLN agents that maintain\nmemory across tours of scenes that consist of up to 100 ordered\ninstruction-following Room-to-Room (R2R) episodes, each defined by an\nindividual language instruction and a target path. We present discrete and\ncontinuous Iterative Room-to-Room (IR2R) benchmarks comprising about 400 tours\neach in 80 indoor scenes. We find that extending the implicit memory of\nhigh-performing transformer VLN agents is not sufficient for IVLN, but agents\nthat build maps can benefit from environment persistence, motivating a renewed\nfocus on map-building agents in VLN.",
    "descriptor": "",
    "authors": [
      "Jacob Krantz",
      "Shurjo Banerjee",
      "Wang Zhu",
      "Jason Corso",
      "Peter Anderson",
      "Stefan Lee",
      "Jesse Thomason"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03087"
  },
  {
    "id": "arXiv:2210.03092",
    "title": "ARS2: Adaptive Ranking-based Sample Selection for Weakly supervised  Class-imbalanced Text Classification",
    "abstract": "To obtain a large amount of training labels inexpensively, researchers have\nrecently adopted the weak supervision (WS) paradigm, which leverages labeling\nrules to synthesize training labels rather than using individual annotations to\nachieve competitive results for natural language processing (NLP) tasks.\nHowever, data imbalance is often overlooked in applying the WS paradigm,\ndespite being a common issue in a variety of NLP tasks. To address this\nchallenge, we propose Adaptive Ranking-based Sample Selection (ARS2), a\nmodel-agnostic framework to alleviate the data imbalance issue in the WS\nparadigm. Specifically, it calculates a probabilistic margin score based on the\noutput of the current model to measure and rank the cleanliness of each data\npoint. Then, the ranked data are sampled based on both class-wise and\nrule-aware ranking. In particular, the two sample strategies corresponds to our\nmotivations: (1) to train the model with balanced data batches to reduce the\ndata imbalance issue and (2) to exploit the expertise of each labeling rule for\ncollecting clean samples. Experiments on four text classification datasets with\nfour different imbalance ratios show that ARS2 outperformed the\nstate-of-the-art imbalanced learning and WS methods, leading to a 2%-57.8%\nimprovement on their F1-score.",
    "descriptor": "",
    "authors": [
      "Linxin Song",
      "Jieyu Zhang",
      "Tianxiang Yang",
      "Masayuki Goto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03092"
  },
  {
    "id": "arXiv:2210.03093",
    "title": "Edge-Varying Fourier Graph Networks for Multivariate Time Series  Forecasting",
    "abstract": "The key problem in multivariate time series (MTS) analysis and forecasting\naims to disclose the underlying couplings between variables that drive the\nco-movements. Considerable recent successful MTS methods are built with graph\nneural networks (GNNs) due to their essential capacity for relational modeling.\nHowever, previous work often used a static graph structure of time-series\nvariables for modeling MTS failing to capture their ever-changing correlations\nover time. To this end, a fully-connected supra-graph connecting any two\nvariables at any two timestamps is adaptively learned to capture the\nhigh-resolution variable dependencies via an efficient graph convolutional\nnetwork. Specifically, we construct the Edge-Varying Fourier Graph Networks\n(EV-FGN) equipped with Fourier Graph Shift Operator (FGSO) which efficiently\nperforms graph convolution in the frequency domain. As a result, a\nhigh-efficiency scale-free parameter learning scheme is derived for MTS\nanalysis and forecasting according to the convolution theorem. Extensive\nexperiments show that EV-FGN outperforms state-of-the-art methods on seven\nreal-world MTS datasets.",
    "descriptor": "",
    "authors": [
      "Kun Yi",
      "Qi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03093"
  },
  {
    "id": "arXiv:2210.03094",
    "title": "VIMA: General Robot Manipulation with Multimodal Prompts",
    "abstract": "Prompt-based learning has emerged as a successful paradigm in natural\nlanguage processing, where a single general-purpose language model can be\ninstructed to perform any task specified by input prompts. Yet task\nspecification in robotics comes in various forms, such as imitating one-shot\ndemonstrations, following language instructions, and reaching visual goals.\nThey are often considered different tasks and tackled by specialized models.\nThis work shows that we can express a wide spectrum of robot manipulation tasks\nwith multimodal prompts, interleaving textual and visual tokens. We design a\ntransformer-based generalist robot agent, VIMA, that processes these prompts\nand outputs motor actions autoregressively. To train and evaluate VIMA, we\ndevelop a new simulation benchmark with thousands of procedurally-generated\ntabletop tasks with multimodal prompts, 600K+ expert trajectories for imitation\nlearning, and four levels of evaluation protocol for systematic generalization.\nVIMA achieves strong scalability in both model capacity and data size. It\noutperforms prior SOTA methods in the hardest zero-shot generalization setting\nby up to $2.9\\times$ task success rate given the same training data. With\n$10\\times$ less training data, VIMA still performs $2.7\\times$ better than the\ntop competing approach. We open-source all code, pretrained models, dataset,\nand simulation benchmark at https://vimalabs.github.io",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Yunfan Jiang",
      "Agrim Gupta",
      "Zichen Zhang",
      "Guanzhi Wang",
      "Yongqiang Dou",
      "Yanjun Chen",
      "Li Fei-Fei",
      "Anima Anandkumar",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03094"
  },
  {
    "id": "arXiv:2210.03102",
    "title": "Ambiguous Images With Human Judgments for Robust Visual Event  Classification",
    "abstract": "Contemporary vision benchmarks predominantly consider tasks on which humans\ncan achieve near-perfect performance. However, humans are frequently presented\nwith visual data that they cannot classify with 100% certainty, and models\ntrained on standard vision benchmarks achieve low performance when evaluated on\nthis data. To address this issue, we introduce a procedure for creating\ndatasets of ambiguous images and use it to produce SQUID-E (\"Squidy\"), a\ncollection of noisy images extracted from videos. All images are annotated with\nground truth values and a test set is annotated with human uncertainty\njudgments. We use this dataset to characterize human uncertainty in vision\ntasks and evaluate existing visual event classification models. Experimental\nresults suggest that existing vision models are not sufficiently equipped to\nprovide meaningful outputs for ambiguous images and that datasets of this\nnature can be used to assess and improve such models through model training and\ndirect evaluation of model calibration. These findings motivate large-scale\nambiguous dataset creation and further research focusing on noisy visual data.",
    "descriptor": "\nComments: 10 pages, NeurIPS 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Kate Sanders",
      "Reno Kriz",
      "Anqi Liu",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03102"
  },
  {
    "id": "arXiv:2210.03103",
    "title": "Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!",
    "abstract": "We introduce a formalization and benchmark for the unsupervised anomaly\ndetection task in the distribution-shift scenario. Our work builds upon the\niWildCam dataset, and, to the best of our knowledge, we are the first to\npropose such an approach for visual data. We empirically validate that\nenvironment-aware methods perform better in such cases when compared with the\nbasic Empirical Risk Minimization (ERM). We next propose an extension for\ngenerating positive samples for contrastive methods that considers the\nenvironment labels when training, improving the ERM baseline score by 8.7%.",
    "descriptor": "",
    "authors": [
      "Stefan Smeu",
      "Elena Burceanu",
      "Andrei Liviu Nicolicioiu",
      "Emanuela Haller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03103"
  },
  {
    "id": "arXiv:2210.03104",
    "title": "Distributionally Adaptive Meta Reinforcement Learning",
    "abstract": "Meta-reinforcement learning algorithms provide a data-driven way to acquire\npolicies that quickly adapt to many tasks with varying rewards or dynamics\nfunctions. However, learned meta-policies are often effective only on the exact\ntask distribution on which they were trained and struggle in the presence of\ndistribution shift of test-time rewards or transition dynamics. In this work,\nwe develop a framework for meta-RL algorithms that are able to behave\nappropriately under test-time distribution shifts in the space of tasks. Our\nframework centers on an adaptive approach to distributional robustness that\ntrains a population of meta-policies to be robust to varying levels of\ndistribution shift. When evaluated on a potentially shifted test-time\ndistribution of tasks, this allows us to choose the meta-policy with the most\nappropriate level of robustness, and use it to perform fast adaptation. We\nformally show how our framework allows for improved regret under distribution\nshift, and empirically show its efficacy on simulated robotics problems under a\nwide range of distribution shifts.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Anurag Ajay",
      "Abhishek Gupta",
      "Dibya Ghosh",
      "Sergey Levine",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03104"
  },
  {
    "id": "arXiv:2210.03105",
    "title": "Mask3D for 3D Semantic Instance Segmentation",
    "abstract": "Modern 3D semantic instance segmentation approaches predominantly rely on\nspecialized voting mechanisms followed by carefully designed geometric\nclustering techniques. Building on the successes of recent Transformer-based\nmethods for object detection and image segmentation, we propose the first\nTransformer-based approach for 3D semantic instance segmentation. We show that\nwe can leverage generic Transformer building blocks to directly predict\ninstance masks from 3D point clouds. In our model called Mask3D each object\ninstance is represented as an instance query. Using Transformer decoders, the\ninstance queries are learned by iteratively attending to point cloud features\nat multiple scales. Combined with point features, the instance queries directly\nyield all instance masks in parallel. Mask3D has several advantages over\ncurrent state-of-the-art approaches, since it neither relies on (1) voting\nschemes which require hand-selected geometric properties (such as centers) nor\n(2) geometric grouping mechanisms requiring manually-tuned hyper-parameters\n(e.g. radii) and (3) enables a loss that directly optimizes instance masks.\nMask3D sets a new state-of-the-art on ScanNet test (+6.2 mAP), S3DIS 6-fold\n(+10.1 mAP), STPLS3D (+11.2 mAP) and ScanNet200 test (+12.4 mAP).",
    "descriptor": "",
    "authors": [
      "Jonas Schult",
      "Francis Engelmann",
      "Alexander Hermans",
      "Or Litany",
      "Siyu Tang",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03105"
  },
  {
    "id": "arXiv:2210.03109",
    "title": "Real-World Robot Learning with Masked Visual Pre-training",
    "abstract": "In this work, we explore self-supervised visual pre-training on images from\ndiverse, in-the-wild videos for real-world robotic tasks. Like prior work, our\nvisual representations are pre-trained via a masked autoencoder (MAE), frozen,\nand then passed into a learnable control module. Unlike prior work, we show\nthat the pre-trained representations are effective across a range of real-world\nrobotic tasks and embodiments. We find that our encoder consistently\noutperforms CLIP (up to 75%), supervised ImageNet pre-training (up to 81%), and\ntraining from scratch (up to 81%). Finally, we train a 307M parameter vision\ntransformer on a massive collection of 4.5M images from the Internet and\negocentric videos, and demonstrate clearly the benefits of scaling visual\npre-training for robot learning.",
    "descriptor": "\nComments: CoRL 2022; Project page: this https URL\n",
    "authors": [
      "Ilija Radosavovic",
      "Tete Xiao",
      "Stephen James",
      "Pieter Abbeel",
      "Jitendra Malik",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03109"
  },
  {
    "id": "arXiv:2210.03112",
    "title": "A New Path: Scaling Vision-and-Language Navigation with Synthetic  Instructions and Imitation Learning",
    "abstract": "Recent studies in Vision-and-Language Navigation (VLN) train RL agents to\nexecute natural-language navigation instructions in photorealistic\nenvironments, as a step towards intelligent agents or robots that can follow\nhuman instructions. However, given the scarcity of human instruction data and\nlimited diversity in the training environments, these agents still struggle\nwith complex language grounding and spatial language understanding.\nPre-training on large text and image-text datasets from the web has been\nextensively explored but the improvements are limited. To address the scarcity\nof in-domain instruction data, we investigate large-scale augmentation with\nsynthetic instructions. We take 500+ indoor environments captured in\ndensely-sampled 360 deg panoramas, construct navigation trajectories through\nthese panoramas, and generate a visually-grounded instruction for each\ntrajectory using Marky (Wang et al., 2022), a high-quality multilingual\nnavigation instruction generator. To further increase the variability of the\ntrajectories, we also synthesize image observations from novel viewpoints using\nan image-to-image GAN. The resulting dataset of 4.2M instruction-trajectory\npairs is two orders of magnitude larger than existing human-annotated datasets,\nand contains a wider variety of environments and viewpoints. To efficiently\nleverage data at this scale, we train a transformer agent with imitation\nlearning for over 700M steps of experience. On the challenging Room-across-Room\ndataset, our approach outperforms all existing RL agents, improving the\nstate-of-the-art NDTW from 71.1 to 79.1 in seen environments, and from 64.6 to\n66.8 in unseen test environments. Our work points to a new path to improving\ninstruction-following agents, emphasizing large-scale imitation learning and\nthe development of synthetic instruction generation capabilities.",
    "descriptor": "",
    "authors": [
      "Aishwarya Kamath",
      "Peter Anderson",
      "Su Wang",
      "Jing Yu Koh",
      "Alexander Ku",
      "Austin Waters",
      "Yinfei Yang",
      "Jason Baldridge",
      "Zarana Parekh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03112"
  },
  {
    "id": "arXiv:2210.03113",
    "title": "IR-MCL: Implicit Representation-Based Online Global Localization",
    "abstract": "Determining the state of a mobile robot is an essential building block of\nrobot navigation systems. In this paper, we address the problem of estimating\nthe robots pose in an indoor environment using 2D LiDAR data and investigate\nhow modern environment models can improve gold standard Monte-Carlo\nlocalization (MCL) systems. We propose a neural occupancy field (NOF) to\nimplicitly represent the scene using a neural network. With the pretrained\nnetwork, we can synthesize 2D LiDAR scans for an arbitrary robot pose through\nvolume rendering. Based on the implicit representation, we can obtain the\nsimilarity between a synthesized and actual scan as an observation model and\nintegrate it into an MCL system to perform accurate localization. We evaluate\nour approach on five sequences of a self-recorded dataset and three publicly\navailable datasets. We show that we can accurately and efficiently localize a\nrobot using our approach surpassing the localization performance of\nstate-of-the-art methods. The experiments suggest that the presented implicit\nrepresentation is able to predict more accurate 2D LiDAR scans leading to an\nimproved observation model for our particle filter-based localization. The code\nof our approach is released at: https://github.com/PRBonn/ir-mcl.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Haofei Kuang",
      "Xieyuanli Chen",
      "Tiziano Guadagnino",
      "Nicky Zimmerman",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03113"
  },
  {
    "id": "arXiv:2210.03114",
    "title": "CLIP model is an Efficient Continual Learner",
    "abstract": "The continual learning setting aims to learn new tasks over time without\nforgetting the previous ones. The literature reports several significant\nefforts to tackle this problem with limited or no access to previous task data.\nAmong such efforts, typical solutions offer sophisticated techniques involving\nmemory replay, knowledge distillation, model regularization, and dynamic\nnetwork expansion. The resulting methods have a retraining cost at each\nlearning task, dedicated memory requirements, and setting-specific design\nchoices. In this work, we show that a frozen CLIP (Contrastive Language-Image\nPretraining) model offers astounding continual learning performance without any\nfine-tuning (zero-shot evaluation). We evaluate CLIP under a variety of\nsettings including class-incremental, domain-incremental and task-agnostic\nincremental learning on five popular benchmarks (ImageNet-100 & 1K, CORe50,\nCIFAR-100, and TinyImageNet). Without any bells and whistles, the CLIP model\noutperforms the state-of-the-art continual learning approaches in the majority\nof the settings. We show the effect on the CLIP model's performance by varying\ntext inputs with simple prompt templates. To the best of our knowledge, this is\nthe first work to report the CLIP zero-shot performance in a continual setting.\nWe advocate the use of this strong yet embarrassingly simple baseline for\nfuture comparisons in the continual learning tasks.",
    "descriptor": "",
    "authors": [
      "Vishal Thengane",
      "Salman Khan",
      "Munawar Hayat",
      "Fahad Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03114"
  },
  {
    "id": "arXiv:2210.03115",
    "title": "SimPer: Simple Self-Supervised Learning of Periodic Targets",
    "abstract": "From human physiology to environmental evolution, important processes in\nnature often exhibit meaningful and strong periodic or quasi-periodic changes.\nDue to their inherent label scarcity, learning useful representations for\nperiodic tasks with limited or no supervision is of great benefit. Yet,\nexisting self-supervised learning (SSL) methods overlook the intrinsic\nperiodicity in data, and fail to learn representations that capture periodic or\nfrequency attributes. In this paper, we present SimPer, a simple contrastive\nSSL regime for learning periodic information in data. To exploit the periodic\ninductive bias, SimPer introduces customized augmentations, feature similarity\nmeasures, and a generalized contrastive loss for learning efficient and robust\nperiodic representations. Extensive experiments on common real-world tasks in\nhuman behavior analysis, environmental sensing, and healthcare domains verify\nthe superior performance of SimPer compared to state-of-the-art SSL methods,\nhighlighting its intriguing properties including better data efficiency,\nrobustness to spurious correlations, and generalization to distribution shifts.\nCode and data are available at: https://github.com/YyzHarry/SimPer.",
    "descriptor": "\nComments: Code and data are available at this https URL\n",
    "authors": [
      "Yuzhe Yang",
      "Xin Liu",
      "Jiang Wu",
      "Silviu Borac",
      "Dina Katabi",
      "Ming-Zher Poh",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03115"
  },
  {
    "id": "arXiv:2210.03116",
    "title": "Content-Based Search for Deep Generative Models",
    "abstract": "The growing proliferation of pretrained generative models has made it\ninfeasible for a user to be fully cognizant of every model in existence. To\naddress this need, we introduce the task of content-based model search: given a\nquery and a large set of generative models, find the models that best match the\nquery. Because each generative model produces a distribution of images, we\nformulate the search problem as an optimization to maximize the probability of\ngenerating a query match given a model. We develop approximations to make this\nproblem tractable when the query is an image, a sketch, a text description,\nanother generative model, or a combination of the above. We benchmark our\nmethod in both accuracy and speed over a set of generative models. We\ndemonstrate that our model search retrieves suitable models for image editing\nand reconstruction, few-shot transfer learning, and latent space interpolation.\nFinally, we deploy our search algorithm to our online generative model-sharing\nplatform at https://modelverse.cs.cmu.edu.",
    "descriptor": "\nComments: Modelverse platform: this https URL GitHub: this https URL\n",
    "authors": [
      "Daohan Lu",
      "Sheng-Yu Wang",
      "Nupur Kumari",
      "Rohan Agarwal",
      "David Bau",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03116"
  },
  {
    "id": "arXiv:2210.03117",
    "title": "MaPLe: Multi-modal Prompt Learning",
    "abstract": "Pre-trained vision-language (V-L) models such as CLIP have shown excellent\ngeneralization ability to downstream tasks. However, they are sensitive to the\nchoice of input text prompts and require careful selection of prompt templates\nto perform well. Inspired by the Natural Language Processing (NLP) literature,\nrecent CLIP adaptation approaches learn prompts as the textual inputs to\nfine-tune CLIP for downstream tasks. We note that using prompting to adapt\nrepresentations in a single branch of CLIP (language or vision) is sub-optimal\nsince it does not allow the flexibility to dynamically adjust both\nrepresentation spaces on a downstream task. In this work, we propose\nMulti-modal Prompt Learning (MaPLe) for both vision and language branches to\nimprove alignment between the vision and language representations. Our design\npromotes strong coupling between the vision-language prompts to ensure mutual\nsynergy and discourages learning independent uni-modal solutions. Further, we\nlearn separate prompts across different early stages to progressively model the\nstage-wise feature relationships to allow rich context learning. We evaluate\nthe effectiveness of our approach on three representative tasks of\ngeneralization to novel classes, new target datasets and unseen domain shifts.\nCompared with the state-of-the-art method Co-CoOp, MaPLe exhibits favorable\nperformance and achieves an absolute gain of 3.45% on novel classes and 2.72%\non overall harmonic-mean, averaged over 11 diverse image recognition datasets.\nCode: https://tinyurl.com/2dzs8f3w.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Muhammad Uzair Khattak",
      "Hanoona Rasheed",
      "Muhammad Maaz",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03117"
  },
  {
    "id": "arXiv:2210.03118",
    "title": "Unsupervised confidence for LiDAR depth maps and applications",
    "abstract": "Depth perception is pivotal in many fields, such as robotics and autonomous\ndriving, to name a few. Consequently, depth sensors such as LiDARs rapidly\nspread in many applications. The 3D point clouds generated by these sensors\nmust often be coupled with an RGB camera to understand the framed scene\nsemantically. Usually, the former is projected over the camera image plane,\nleading to a sparse depth map. Unfortunately, this process, coupled with the\nintrinsic issues affecting all the depth sensors, yields noise and gross\noutliers in the final output. Purposely, in this paper, we propose an effective\nunsupervised framework aimed at explicitly addressing this issue by learning to\nestimate the confidence of the LiDAR sparse depth map and thus allowing for\nfiltering out the outliers. Experimental results on the KITTI dataset highlight\nthat our framework excels for this purpose. Moreover, we demonstrate how this\nachievement can improve a wide range of tasks.",
    "descriptor": "\nComments: IROS 2022. Code available at this https URL\n",
    "authors": [
      "Andrea Conti",
      "Matteo Poggi",
      "Filippo Aleotti",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03118"
  },
  {
    "id": "arXiv:2210.01919",
    "title": "Convex and Nonconvex Sublinear Regression with Application to  Data-driven Learning of Reach Sets",
    "abstract": "We consider estimating a compact set from finite data by approximating the\nsupport function of that set via sublinear regression. Support functions\nuniquely characterize a compact set up to closure of convexification, and are\nsublinear (convex as well as positive homogeneous of degree one). Conversely,\nany sublinear function is the support function of a compact set. We leverage\nthis property to transcribe the task of learning a compact set to that of\nlearning its support function. We propose two algorithms to perform the\nsublinear regression, one via convex and another via nonconvex programming. The\nconvex programming approach involves solving a quadratic program (QP) followed\nby a linear program (LP), and is referred to as QP-LP. The nonconvex\nprogramming approach involves training a input sublinear neural network. We\nillustrate the proposed methods via numerical examples on learning the reach\nsets of controlled dynamics subject to set-valued input uncertainties from\ntrajectory data.",
    "descriptor": "",
    "authors": [
      "Shadi Haddad",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01919"
  },
  {
    "id": "arXiv:2210.02445",
    "title": "Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive  Networks",
    "abstract": "Localizing anatomical landmarks are important tasks in medical image\nanalysis. However, the landmarks to be localized often lack prominent visual\nfeatures. Their locations are elusive and easily confused with the background,\nand thus precise localization highly depends on the context formed by their\nsurrounding areas. In addition, the required precision is usually higher than\nsegmentation and object detection tasks. Therefore, localization has its unique\nchallenges different from segmentation or detection. In this paper, we propose\na zoom-in attentive network (ZIAN) for anatomical landmark localization in\nocular images. First, a coarse-to-fine, or \"zoom-in\" strategy is utilized to\nlearn the contextualized features in different scales. Then, an attentive\nfusion module is adopted to aggregate multi-scale features, which consists of\n1) a co-attention network with a multiple regions-of-interest (ROIs) scheme\nthat learns complementary features from the multiple ROIs, 2) an\nattention-based fusion module which integrates the multi-ROIs features and\nnon-ROI features. We evaluated ZIAN on two open challenge tasks, i.e., the\nfovea localization in fundus images and scleral spur localization in AS-OCT\nimages. Experiments show that ZIAN achieves promising performances and\noutperforms state-of-the-art localization methods. The source code and trained\nmodels of ZIAN are available at\nhttps://github.com/leixiaofeng-astar/OMIA9-ZIAN.",
    "descriptor": "",
    "authors": [
      "Xiaofeng Lei",
      "Shaohua Li",
      "Xinxing Xu",
      "Huazhu Fu",
      "Yong Liu",
      "Yih-Chung Tham",
      "Yangqin Feng",
      "Mingrui Tan",
      "Yanyu Xu",
      "Jocelyn Hui Lin Goh",
      "Rick Siow Mong Goh",
      "Ching-Yu Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02445"
  },
  {
    "id": "arXiv:2210.02482",
    "title": "Fisher information lower bounds for sampling",
    "abstract": "We prove two lower bounds for the complexity of non-log-concave sampling\nwithin the framework of Balasubramanian et al. (2022), who introduced the use\nof Fisher information (FI) bounds as a notion of approximate first-order\nstationarity in sampling. Our first lower bound shows that averaged LMC is\noptimal for the regime of large FI by reducing the problem of finding\nstationary points in non-convex optimization to sampling. Our second lower\nbound shows that in the regime of small FI, obtaining a FI of at most\n$\\varepsilon^2$ from the target distribution requires\n$\\text{poly}(1/\\varepsilon)$ queries, which is surprising as it rules out the\nexistence of high-accuracy algorithms (e.g., algorithms using\nMetropolis-Hastings filters) in this context.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Sinho Chewi",
      "Patrik Gerber",
      "Holden Lee",
      "Chen Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.02482"
  },
  {
    "id": "arXiv:2210.02499",
    "title": "A Dynamic Grouping Strategy for Beyond Diagonal Reconfigurable  Intelligent Surfaces with Hybrid Transmitting and Reflecting Mode",
    "abstract": "Beyond diagonal reconfigurable intelligent surface (BD-RIS) is a novel branch\nof RIS which breaks through the limitation of traditional RIS with diagonal\nscattering matrices. However, the existing research focuses on BD-RIS with\nfixed architectures regardless of channel state information (CSI), which limit\nthe achievable performance of BD-RIS. To solve this issue, in this paper, we\npropose a novel dynamically group-connected BD-RIS based on a dynamic grouping\nstrategy. Specifically, RIS antennas are dynamically divided into several\nsubsets adapting to the CSI, yielding a permuted block-diagonal scattering\nmatrix. To verify the effectiveness of the proposed dynamically group-connected\nBD-RIS, we propose an efficient algorithm to optimize the BD-RIS with dynamic\ngrouping for a BD-RIS-assisted multi-user multiple-input single-output system.\nSimulation results show that the proposed dynamically group-connected\narchitecture outperforms fixed group-connected architectures.",
    "descriptor": "\nComments: 5 pages, 5 figures, sumbitted to IEEE journal for publication\n",
    "authors": [
      "Hongyu Li",
      "Shanpu Shen",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.02499"
  },
  {
    "id": "arXiv:2210.02505",
    "title": "A novel non-linear transformation based multi-user identification  algorithm for fixed text keystroke behavioral dynamics",
    "abstract": "In this paper, we propose a new technique to uniquely classify and identify\nmultiple users accessing a single application using keystroke dynamics. This\nproblem is usually encountered when multiple users have legitimate access to\nshared computers and accounts, where, at times, one user can inadvertently be\nlogged in on another user's account. Since the login processes are usually\nbypassed at this stage, we rely on keystroke dynamics in order to tell users\napart. Our algorithm uses the quantile transform and techniques from\nlocalization to classify and identify users. Specifically, we use an algorithm\nknown as ordinal Unfolding based Localization (UNLOC), which uses only ordinal\ndata obtained from comparing distance proxies, by \"locating\" users in a reduced\nPCA/Kernel-PCA/t-SNE space based on their typing patterns. Our results are\nvalidated with the help of benchmark keystroke datasets and show that our\nalgorithm outperforms other methods.",
    "descriptor": "\nComments: The paper has been accepted to IEEE Transactions on Biometrics, Behavior, and Identity Science\n",
    "authors": [
      "Chinmay Sahu",
      "Mahesh Banavar",
      "Stephanie Schuckers"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02505"
  },
  {
    "id": "arXiv:2210.02544",
    "title": "Deep learning for ECoG brain-computer interface: end-to-end vs.  hand-crafted features",
    "abstract": "In brain signal processing, deep learning (DL) models have become commonly\nused. However, the performance gain from using end-to-end DL models compared to\nconventional ML approaches is usually significant but moderate, typically at\nthe cost of increased computational load and deteriorated explainability. The\ncore idea behind deep learning approaches is scaling the performance with\nbigger datasets. However, brain signals are temporal data with a low\nsignal-to-noise ratio, uncertain labels, and nonstationary data in time. Those\nfactors may influence the training process and slow down the models'\nperformance improvement. These factors' influence may differ for end-to-end DL\nmodel and one using hand-crafted features. As not studied before, this paper\ncompares models that use raw ECoG signal and time-frequency features for BCI\nmotor imagery decoding. We investigate whether the current dataset size is a\nstronger limitation for any models. Finally, obtained filters were compared to\nidentify differences between hand-crafted features and optimized with\nbackpropagation. To compare the effectiveness of both strategies, we used a\nmultilayer perceptron and a mix of convolutional and LSTM layers that were\nalready proved effective in this task. The analysis was performed on the\nlong-term clinical trial database (almost 600 minutes of recordings) of a\ntetraplegic patient executing motor imagery tasks for 3D hand translation. For\na given dataset, the results showed that end-to-end training might not be\nsignificantly better than the hand-crafted features-based model. The\nperformance gap is reduced with bigger datasets, but considering the increased\ncomputational load, end-to-end training may not be profitable for this\napplication.",
    "descriptor": "",
    "authors": [
      "Maciej \u015aliwowski",
      "Matthieu Martin",
      "Antoine Souloumiac",
      "Pierre Blanchart",
      "Tetiana Aksenova"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02544"
  },
  {
    "id": "arXiv:2210.02550",
    "title": "Conservative Evolution of Black Hole Perturbations with Time-Symmetric  Numerical Methods",
    "abstract": "The scheduled launch of the LISA Mission in the next decade has called\nattention to the gravitational self-force problem. Despite an extensive body of\ntheoretical work, long-time numerical computations of gravitational waves from\nextreme-mass-ratio-inspirals remain challenging. This work proposes a class of\nnumerical evolution schemes suitable to this problem based on Hermite\nintegration. Their most important feature is time-reversal symmetry and\nunconditional stability, which enables these methods to preserve symplectic\nstructure, energy, momentum and other Noether charges over long time periods.\nWe apply Noether's theorem to the master fields of black hole perturbation\ntheory on a hyperboloidal slice of Schwarzschild spacetime to show that there\nexist constants of evolution that numerical simulations must preserve. We\ndemonstrate that time-symmetric integration schemes based on a 2-point Taylor\nexpansion (such as Hermite integration) numerically conserve these quantities,\nunlike schemes based on a 1-point Taylor expansion (such as Runge-Kutta). This\nmakes time-symmetric schemes ideal for long-time EMRI simulations.",
    "descriptor": "\nComments: 43 pages, 8 figures\n",
    "authors": [
      "Michael F. O'Boyle",
      "Charalampos Markakis",
      "Lidia J. Gomes Da Silva",
      "Rodrigo Panosso Macedo",
      "Juan A. Valiente Kroon"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02550"
  },
  {
    "id": "arXiv:2210.02557",
    "title": "Minimizing File Transfer Time in Opportunistic Spectrum Access Model",
    "abstract": "We study the file transfer problem in opportunistic spectrum access (OSA)\nmodel, which has been widely studied in throughput-oriented applications for\nmax-throughput strategies and in delay-related works that commonly assume\nidentical channel rates and fixed file sizes. Our work explicitly considers\nminimizing the file transfer time for a given file in a set of\nheterogeneous-rate Bernoulli channels, showing that max-throughput policy\ndoesn't minimize file transfer time in general. We formulate a mathematical\nframework for static extend to dynamic policies by mapping our file transfer\nproblem to a stochastic shortest path problem. We analyze the performance of\nour proposed static and dynamic optimal policies over the max-throughput\npolicy. We propose a mixed-integer programming formulation as an efficient\nalternative way to obtain the dynamic optimal policy and show a huge reduction\nin computation time. Then, we propose a heuristic policy that takes into\naccount the performance-complexity tradeoff and consider the online\nimplementation with unknown channel parameters. Furthermore, we present\nnumerical simulations to support our analytical results and discuss the effect\nof switching delay on different policies. Finally, we extend the file transfer\nproblem to Markovian channels and demonstrate the impact of the correlation of\neach channel.",
    "descriptor": "\nComments: To appear in IEEE Transactions on Mobile Computing. arXiv admin note: substantial text overlap with arXiv:2109.11624\n",
    "authors": [
      "Jie Hu",
      "Vishwaraj Doshi",
      "Do Young Eun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.02557"
  },
  {
    "id": "arXiv:2210.02560",
    "title": "Bifurcation analysis of Bogdanov-Takens bifurcations in delay  differential equations",
    "abstract": "In this paper, we will perform the parameter-dependent center manifold\nreduction near the generic and transcritical codimension two Bogdanov-Takens\nbifurcation in classical delay differential equations (DDEs). Using a\ngeneralization of the Lindstedt-Poincar\\'e method to approximate the homoclinic\nsolution allows us to initialize the continuation of the homoclinic bifurcation\ncurves emanating from these points. The normal form transformation is derived\nin the functional analytic perturbation framework for dual semigroups (sun-star\ncalculus) using a normalization technique based on the Fredholm alternative.\nThe obtained expressions give explicit formulas, which have been implemented in\nthe freely available bifurcation software package DDE-BifTool. The\neffectiveness is demonstrated on various models.",
    "descriptor": "\nComments: 128 pages, 39 images\n",
    "authors": [
      "M.M. Bosschaert",
      "Yu.A. Kuznetsov"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02560"
  },
  {
    "id": "arXiv:2210.02562",
    "title": "Dueling Convex Optimization with General Preferences",
    "abstract": "We address the problem of \\emph{convex optimization with dueling feedback},\nwhere the goal is to minimize a convex function given a weaker form of\n\\emph{dueling} feedback. Each query consists of two points and the dueling\nfeedback returns a (noisy) single-bit binary comparison of the function values\nof the two queried points. The translation of the function values to the single\ncomparison bit is through a \\emph{transfer function}. This problem has been\naddressed previously for some restricted classes of transfer functions, but\nhere we consider a very general transfer function class which includes all\nfunctions that can be approximated by a finite polynomial with a minimal degree\n$p$. Our main contribution is an efficient algorithm with convergence rate of\n$\\smash{\\widetilde O}(\\epsilon^{-4p})$ for a smooth convex objective function,\nand an optimal rate of $\\smash{\\widetilde O}(\\epsilon^{-2p})$ when the\nobjective is smooth and strongly convex.",
    "descriptor": "",
    "authors": [
      "Aadirupa Saha",
      "Tomer Koren",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02562"
  },
  {
    "id": "arXiv:2210.02564",
    "title": "Optima and Simplicity in Nature",
    "abstract": "Why are simple, regular, and symmetric shapes common in nature? Many natural\nshapes arise as solutions to energy minimisation or other optimisation\nproblems, but is there a general relation between optima and simple, regular\nshapes and geometries? Here we argue from algorithmic information theory that\nfor objective functions common in nature -- based on physics and engineering\nlaws -- optimal geometries will be simple, regular, and symmetric. Further, we\nderive a null model prediction that if a given geometry is an optimal solution\nfor one natural objective function, then it is a priori more likely to be\noptimal or close to optimal for another objective function.",
    "descriptor": "",
    "authors": [
      "Kamaludin Dingle"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.02564"
  },
  {
    "id": "arXiv:2210.02587",
    "title": "Astrobotics: Swarm Robotics for Astrophysical Studies",
    "abstract": "This paper introduces the emerging field of astrobotics, that is, a\nrecently-established branch of robotics to be of service to astrophysics and\nobservational astronomy. We first describe a modern requirement of dark matter\nstudies, i.e., the generation of the map of the observable universe, using\nastrobots. Astrobots differ from conventional two-degree-of-freedom robotic\nmanipulators in two respects. First, the dense formation of astrobots give rise\nto the extremely overlapping dynamics of neighboring astrobots which make them\nseverely subject to collisions. Second, the structure of astrobots and their\nmechanical specifications are specialized due to the embedded optical fibers\npassed through them. We focus on the coordination problem of astrobots whose\nsolutions shall be collision-free, fast execution, and complete in terms of the\nastrobots' convergence rates. We also illustrate the significant impact of\nastrobots assignments to observational targets on the quality of coordination\nsolutions To present the current state of the field, we elaborate the open\nproblems including next-generation astrophysical projects including 20,000\nastrobots, and other fields, such as space debris tracking, in which astrobots\nmay be potentially used",
    "descriptor": "",
    "authors": [
      "Matin Macktoobian",
      "Denis Gillet",
      "Jean-Paul Kneib"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02587"
  },
  {
    "id": "arXiv:2210.02593",
    "title": "Be Prospective, Not Retrospective: A Philosophy for Advancing  Reproducibility in Modern Biological Research",
    "abstract": "The ubiquity of computation in modern scientific research inflicts new\nchallenges for reproducibility. While most journals now require code and data\nbe made available, the standards for organization, annotation, and validation\nremain lax, making the data and code often difficult to decipher or practically\nuse. I believe that this is due to the documentation, collation, and validation\nof code and data only being done in retrospect. In this essay, I reflect on my\nexperience contending with these challenges and present a philosophy for\nprioritizing reproducibility in modern biological research where balancing\ncomputational analysis and wet-lab experiments is commonplace. Modern tools\nused in scientific workflows (such as GitHub repositories) lend themselves well\nto this philosophy where reproducibility begins at project inception, not\ncompletion. To that end, I present and provide a programming-language agnostic\ntemplate architecture that can be immediately copied and made bespoke to your\nnext paper, whether your lab work is wet, dry, or somewhere in between.",
    "descriptor": "",
    "authors": [
      "Griffin Chure"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.02593"
  },
  {
    "id": "arXiv:2210.02595",
    "title": "Exploration of A Self-Supervised Speech Model: A Study on Emotional  Corpora",
    "abstract": "Self-supervised speech models have grown fast during the past few years and\nhave proven feasible for use in various downstream tasks. Some recent work has\nstarted to look at the characteristics of these models, yet many concerns have\nnot been fully addressed. In this work, we conduct a study on emotional corpora\nto explore a popular self-supervised model -- wav2vec 2.0. Via a set of\nquantitative analysis, we mainly demonstrate that: 1) wav2vec 2.0 appears to\ndiscard paralinguistic information that is less useful for word recognition\npurposes; 2) for emotion recognition, representations from the middle layer\nalone perform as well as those derived from layer averaging, while the final\nlayer results in the worst performance in some cases; 3) current\nself-supervised models may not be the optimal solution for downstream tasks\nthat make use of non-lexical features. Our work provides novel findings that\nwill aid future research in this area and theoretical basis for the use of\nexisting models.",
    "descriptor": "\nComments: Accepted for SLT 2022\n",
    "authors": [
      "Yuanchao Li",
      "Yumnah Mohamied",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02595"
  },
  {
    "id": "arXiv:2210.02600",
    "title": "Learning convergence prediction of astrobots in multi-object  spectrographs",
    "abstract": "Astrobot swarms are used to capture astronomical signals to generate the map\nof the observable universe for the purpose of dark energy studies. The\nconvergence of each swarm in the course of its coordination has to surpass a\nparticular threshold to yield a satisfactory map. The current coordination\nmethods do not always reach desired convergence rates. Moreover, these methods\nare so complicated that one cannot formally verify their results without\nresource-demanding simulations. Thus, we use support vector machines to train a\nmodel which can predict the convergence of a swarm based on the data of\nprevious coordination of that swarm. Given a fixed parity, i.e., the rotation\ndirection of the outer arm of an astrobot, corresponding to a swarm, our\nalgorithm reaches a better predictive performance compared to the state of the\nart. Additionally, we revise our algorithm to solve a more generalized\nconvergence prediction problem according to which the parities of astrobots may\ndiffer. We present the prediction results of a generalized scenario, associated\nwith a 487-astrobot swarm, which are interestingly efficient and collision-free\ngiven the excessive complexity of this scenario compared to the constrained\none.",
    "descriptor": "",
    "authors": [
      "Matin Macktoobian",
      "Francesco Basciani",
      "Denis Gillet",
      "Jean-Paul Kneib"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02600"
  },
  {
    "id": "arXiv:2210.02604",
    "title": "Spectral Regularization Allows Data-frugal Learning over Combinatorial  Spaces",
    "abstract": "Data-driven machine learning models are being increasingly employed in\nseveral important inference problems in biology, chemistry, and physics which\nrequire learning over combinatorial spaces. Recent empirical evidence (see,\ne.g., [1], [2], [3]) suggests that regularizing the spectral representation of\nsuch models improves their generalization power when labeled data is scarce.\nHowever, despite these empirical studies, the theoretical underpinning of when\nand how spectral regularization enables improved generalization is poorly\nunderstood. In this paper, we focus on learning pseudo-Boolean functions and\ndemonstrate that regularizing the empirical mean squared error by the L_1 norm\nof the spectral transform of the learned function reshapes the loss landscape\nand allows for data-frugal learning, under a restricted secant condition on the\nlearner's empirical error measured against the ground truth function. Under a\nweaker quadratic growth condition, we show that stationary points which also\napproximately interpolate the training data points achieve statistically\noptimal generalization performance. Complementing our theory, we empirically\ndemonstrate that running gradient descent on the regularized loss results in a\nbetter generalization performance compared to baseline algorithms in several\ndata-scarce real-world problems.",
    "descriptor": "",
    "authors": [
      "Amirali Aghazadeh",
      "Nived Rajaraman",
      "Tony Tu",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02604"
  },
  {
    "id": "arXiv:2210.02635",
    "title": "Research on the quantity and brightness evolution characteristics of  Photospheric Bright Points groups",
    "abstract": "Context. Photospheric bright points (BPs), as the smallest magnetic element\nof the photosphere and the footpoint tracer of the magnetic flux tube, are of\ngreat significance to the study of BPs. Compared with the study of the\ncharacteristics and evolution of a few specific BPs, the study of BPs groups\ncan provide us with a better understanding of the characteristics and overall\nactivities of BPs groups. Aims. We aim to find out the evolution\ncharacteristics of the brightness and number of BPs groups at different\nbrightness levels, and how these characteristics differ between quiet and\nactive regions. Methods. We propose a hybrid BPs detection model (HBD Model)\ncombining traditional technology and neural network. The Model is used to\ndetect and calculate the BPs brightness characteristics of each frame of\ncontinuous high resolution image sequences of active and quiet regions in\nTiO-band of a pair of BBSO. Using machine learning clustering method, the PBs\nof each frame was divided into four levels groups (level1-level4) according to\nthe brightness from low to high. Finally, Fourier transform and inverse Fourier\ntransform are used to analyze the evolution of BPs brightness and quantity in\nthese four levels groups. Results. The activities of BPs groups are not random\nand disorderly. In different levels of brightness, their quantity and\nbrightness evolution show complex changes. Among the four levels of brightness,\nBPs in the active region were more active and intense than those in the quiet\nregion. However, the quantity and brightness evolution of BPs groups in the\nquiet region showed the characteristics of large periodic changes and small\nperiodic changes in the medium and high brightness levels (level3 and level4).\nThe brightness evolution of PBs group in the quiet region has obvious periodic\nchanges, but the active region is in a completely random and violent\nfluctuation state.",
    "descriptor": "",
    "authors": [
      "HaiCheng Bai"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02635"
  },
  {
    "id": "arXiv:2210.02646",
    "title": "Magnetic Schr\u00f6dinger operators and landscape functions",
    "abstract": "We study localization properties of low-lying eigenfunctions of magnetic\nSchr\\\"odinger operators $$\\frac{1}{2} \\left(- i\\nabla - A(x)\\right)^2 \\phi +\nV(x) \\phi = \\lambda \\phi,$$ where $V:\\Omega \\rightarrow \\mathbb{R}_{\\geq 0}$ is\na given potential and $A:\\Omega \\rightarrow \\mathbb{R}^d$ induces a magnetic\nfield. We extend the Filoche-Mayboroda inequality and prove a refined\ninequality in the magnetic setting which can predict the points where\nlow-energy eigenfunctions are localized. This result is new even in the case of\nvanishing magnetic field. Numerical examples illustrate the results.",
    "descriptor": "",
    "authors": [
      "Jeremy G. Hoskins",
      "Hadrian Quan",
      "Stefan Steinerberger"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02646"
  },
  {
    "id": "arXiv:2210.02647",
    "title": "Ensemble Kalman Filtering for Glacier Modeling",
    "abstract": "Working with a two-stage ice sheet model, we explore how statistical data\nassimilation methods can be used to improve predictions of glacier melt and\nrelatedly, sea level rise. We find that the EnKF improves model runs\ninitialized using incorrect initial conditions or parameters, providing us with\nbetter models of future glacier melt. We explore the necessary number of\nobservations needed to produce an accurate model run. Further, we determine\nthat the deviations from the truth in output that stem from having few data\npoints in the pre-satellite era can be corrected with modern observation data.\nFinally, using data derived from our improved model we calculate sea level rise\nand model storm surges to understand the affect caused by sea level rise.",
    "descriptor": "",
    "authors": [
      "Emily Corcoran",
      "Logan Knudsen",
      "Hannah Park-Kaufmann"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02647"
  },
  {
    "id": "arXiv:2210.02684",
    "title": "Conformal Isometry of Lie Group Representation in Recurrent Network of  Grid Cells",
    "abstract": "The activity of the grid cell population in the medial entorhinal cortex\n(MEC) of the brain forms a vector representation of the self-position of the\nanimal. Recurrent neural networks have been developed to explain the properties\nof the grid cells by transforming the vector based on the input velocity, so\nthat the grid cells can perform path integration. In this paper, we investigate\nthe algebraic, geometric, and topological properties of grid cells using\nrecurrent network models. Algebraically, we study the Lie group and Lie algebra\nof the recurrent transformation as a representation of self-motion.\nGeometrically, we study the conformal isometry of the Lie group representation\nof the recurrent network where the local displacement of the vector in the\nneural space is proportional to the local displacement of the agent in the 2D\nphysical space. We then focus on a simple non-linear recurrent model that\nunderlies the continuous attractor neural networks of grid cells. Our numerical\nexperiments show that conformal isometry leads to hexagon periodic patterns of\nthe response maps of grid cells and our model is capable of accurate path\nintegration.",
    "descriptor": "",
    "authors": [
      "Dehong Xu",
      "Ruiqi Gao",
      "Wen-Hao Zhang",
      "Xue-Xin Wei",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02684"
  },
  {
    "id": "arXiv:2210.02698",
    "title": "A Fast Butterfly-compressed Hadamard-Babich Integrator for  High-Frequency Helmholtz Equations in Inhomogeneous Media with Arbitrary  Sources",
    "abstract": "We present a butterfly-compressed representation of the Hadamard-Babich (HB)\nansatz for the Green's function of the high-frequency Helmholtz equation in\nsmooth inhomogeneous media. For a computational domain discretized with $N_v$\ndiscretization cells, the proposed algorithm first solves and tabulates the\nphase and HB coefficients via eikonal and transport equations with observation\npoints and point sources located at the Chebyshev nodes using a set of much\ncoarser computation grids, and then butterfly compresses the resulting HB\ninteractions from all $N_v$ cell centers to each other. The overall CPU time\nand memory requirement scale as $O(N_v\\log^2N_v)$ for any bounded 2D domains\nwith arbitrary excitation sources. A direct extension of this scheme to bounded\n3D domains yields an $O(N_v^{4/3})$ CPU complexity, which can be further\nreduced to quasi-linear complexities with proposed remedies. The scheme can\nalso efficiently handle scattering problems involving inclusions in\ninhomogeneous media. Although the current construction of our HB integrator\ndoes not accommodate caustics, the resulting HB integrator itself can be\napplied to certain sources, such as concave-shaped sources, to produce caustic\neffects. Compared to finite-difference frequency-domain (FDFD) methods, the\nproposed HB integrator is free of numerical dispersion and requires fewer\ndiscretization points per wavelength. As a result, it can solve\nwave-propagation problems well beyond the capability of existing solvers.\nRemarkably, the proposed scheme can accurately model wave propagation in 2D\ndomains with 640 wavelengths per direction and in 3D domains with 54\nwavelengths per direction on a state-the-art supercomputer at Lawrence Berkeley\nNational Laboratory.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Jian Song",
      "Robert Burridge",
      "Jianliang Qian"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02698"
  },
  {
    "id": "arXiv:2210.02726",
    "title": "Parameter estimation tools for cardiovascular flow modeling of fetal  circulation",
    "abstract": "Usually, clinicians assess the correct hemodynamic behavior and fetal\nwell-being during the gestational age thanks to their professional expertise,\nwith the support of some indices defined for Doppler fetal waveforms. Although\nthis approach has demonstrated to be satisfactory in the most of the cases, it\ncan be largely improved with the aid of more advanced techniques, i.e.\nnumerical analysis and simulation. Another key aspect limiting the analysis is\nthat clinicians rely on a limited number of Doppler waveforms observed during\nthe clinical examination. Moreover, the use of simple velocimetric indicators\nfor deriving possible malfunctions of the fetal cardiovascular system can be\nmisleading, being the fetal assessment based on a mere statistical analysis\n(comparison with physiological ranges), without any deep physio-pathological\ninterpretations of the observed hemodynamic changes. The use of a lumped\nmathematical model, properly describing the entire fetal cardiovascular system,\nwould be absolutely helpful in this context: by targeting physiological model\nparameters on the clinical reliefs, we could gain deep insights of the full\nsystem. The calibration of model parameters may also help in formulating\npatient-specific early diagnosis of fetal pathologies. In the present work, we\ndevelop a robust parameter estimation algorithm based on two different\noptimization methods using synthetic data. In particular, we deal with the\ninverse problem of recognizing the most significant parameters of a lumped\nfetal circulation model by using time tracings of fetal blood flows and\npressures obtained by the model. This represents a first methodological work\nfor the assessment of the accuracy in the identification of model parameters of\nan algorithm based on closed-loop mathematical model of fetal circulation and\nopens the way to the application of the algorithm to clinical data.",
    "descriptor": "\nComments: 33 pages, 6 figures\n",
    "authors": [
      "Gabriella Bretti",
      "Roberto Natalini",
      "Annalisa Pascarella",
      "Giancarlo Pennati",
      "Daniele Peri",
      "Giuseppe Pontrelli"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02726"
  },
  {
    "id": "arXiv:2210.02738",
    "title": "Sparse Approximation Over the Cube",
    "abstract": "This paper presents an anlysis of the NP-hard minimization problem $\\min\n\\{\\|b - Ax\\|_2: \\ x \\in [0,1]^n, | \\text{supp}(x) | \\leq \\sigma\\}$, where\n$\\text{supp}(x) = \\{i \\in [n]: x_i \\neq 0\\}$ and $\\sigma$ is a positive\ninteger. The object of investigation is a natural relaxation where we replace\n$| \\text{supp}(x) | \\leq \\sigma$ by $\\sum_i x_i \\leq \\sigma$. Our analysis\nincludes a probabilistic view on when the relaxation is exact. We also consider\nthe problem from a deterministic point of view and provide a bound on the\ndistance between the images of optimal solutions of the original problem and\nits relaxation under $A$. This leads to an algorithm for generic matrices $A\n\\in \\mathbb{Z}^{m \\times n}$ and achieves a polynomial running time provided\nthat $m$ and $\\|A\\|_{\\infty}$ are fixed.",
    "descriptor": "",
    "authors": [
      "Sabrina Bruckmeier",
      "Christoph Hunkenschr\u00f6der",
      "Robert Weismantel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.02738"
  },
  {
    "id": "arXiv:2210.02745",
    "title": "MuS2: A Benchmark for Sentinel-2 Multi-Image Super-Resolution",
    "abstract": "Insufficient spatial resolution of satellite imagery, including Sentinel-2\ndata, is a serious limitation in many practical use cases. To mitigate this\nproblem, super-resolution reconstruction is receiving considerable attention\nfrom the remote sensing community. When it is performed from multiple images\ncaptured at subsequent revisits, it may benefit from information fusion,\nleading to enhanced reconstruction accuracy. One of the obstacles in\nmulti-image super-resolution consists in the scarcity of real-life benchmark\ndatasets -- most of the research was performed for simulated data which do not\nfully reflect the operating conditions. In this letter, we introduce a new MuS2\nbenchmark for multi-image super-resolution reconstruction of Sentinel-2 images,\nwith WorldView-2 imagery used as the high-resolution reference. Within MuS2, we\npublish the first end-to-end evaluation procedure for this problem which we\nexpect to help the researchers in advancing the state of the art in multi-image\nsuper-resolution for Sentinel-2 imagery.",
    "descriptor": "\nComments: Submitted to IEEE Geoscience and Remote Sensing Letters\n",
    "authors": [
      "Pawel Kowaleczko",
      "Tomasz Tarasiewicz",
      "Maciej Ziaja",
      "Daniel Kostrzewa",
      "Jakub Nalepa",
      "Przemyslaw Rokita",
      "Michal Kawulok"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02745"
  },
  {
    "id": "arXiv:2210.02851",
    "title": "Anomaly detection using data depth: multivariate case",
    "abstract": "Anomaly detection is a branch of machine learning and data analysis which\naims at identifying observations that exhibit abnormal behaviour. Be it\nmeasurement errors, disease development, severe weather, production quality\ndefault(s) (items) or failed equipment, financial frauds or crisis events,\ntheir on-time identification, isolation and explanation constitute an important\ntask in almost any branch of industry and science. By providing a robust\nordering, data depth -- statistical function that measures belongingness of any\npoint of the space to a data set -- becomes a particularly useful tool for\ndetection of anomalies. Already known for its theoretical properties, data\ndepth has undergone substantial computational developments in the last decade\nand particularly recent years, which has made it applicable for\ncontemporary-sized problems of data analysis and machine learning.\nIn this article, data depth is studied as an efficient anomaly detection\ntool, assigning abnormality labels to observations with lower depth values, in\na multivariate setting. Practical questions of necessity and reasonability of\ninvariances and shape of the depth function, its robustness and computational\ncomplexity, choice of the threshold are discussed. Illustrations include\nuse-cases that underline advantageous behaviour of data depth in various\nsettings.",
    "descriptor": "",
    "authors": [
      "Pavlo Mozharovskyi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.02851"
  },
  {
    "id": "arXiv:2210.02881",
    "title": "Antibody Representation Learning for Drug Discovery",
    "abstract": "Therapeutic antibody development has become an increasingly popular approach\nfor drug development. To date, antibody therapeutics are largely developed\nusing large scale experimental screens of antibody libraries containing\nhundreds of millions of antibody sequences. The high cost and difficulty of\ndeveloping therapeutic antibodies create a pressing need for computational\nmethods to predict antibody properties and create bespoke designs. However, the\nrelationship between antibody sequence and activity is a complex physical\nprocess and traditional iterative design approaches rely on large scale assays\nand random mutagenesis. Deep learning methods have emerged as a promising way\nto learn antibody property predictors, but predicting antibody properties and\ntarget-specific activities depends critically on the choice of antibody\nrepresentations and data linking sequences to properties is often limited.\nExisting works have not yet investigated the value, limitations and\nopportunities of these methods in application to antibody-based drug discovery.\nIn this paper, we present results on a novel SARS-CoV-2 antibody binding\ndataset and an additional benchmark dataset. We compare three classes of\nmodels: conventional statistical sequence models, supervised learning on each\ndataset independently, and fine-tuning an antibody specific pre-trained\nlanguage model. Experimental results suggest that self-supervised pretraining\nof feature representation consistently offers significant improvement in over\nprevious approaches. We also investigate the impact of data size on the model\nperformance, and discuss challenges and opportunities that the machine learning\ncommunity can address to advance in silico engineering and design of\ntherapeutic antibodies.",
    "descriptor": "",
    "authors": [
      "Lin Li",
      "Esther Gupta",
      "John Spaeth",
      "Leslie Shing",
      "Tristan Bepler",
      "Rajmonda Sulo Caceres"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02881"
  },
  {
    "id": "arXiv:2210.02882",
    "title": "Scaling up Stochastic Gradient Descent for Non-convex Optimisation",
    "abstract": "Stochastic gradient descent (SGD) is a widely adopted iterative method for\noptimizing differentiable objective functions. In this paper, we propose and\ndiscuss a novel approach to scale up SGD in applications involving non-convex\nfunctions and large datasets. We address the bottleneck problem arising when\nusing both shared and distributed memory. Typically, the former is bounded by\nlimited computation resources and bandwidth whereas the latter suffers from\ncommunication overheads. We propose a unified distributed and parallel\nimplementation of SGD (named DPSGD) that relies on both asynchronous\ndistribution and lock-free parallelism. By combining two strategies into a\nunified framework, DPSGD is able to strike a better trade-off between local\ncomputation and communication. The convergence properties of DPSGD are studied\nfor non-convex problems such as those arising in statistical modelling and\nmachine learning. Our theoretical analysis shows that DPSGD leads to speed-up\nwith respect to the number of cores and number of workers while guaranteeing an\nasymptotic convergence rate of $O(1/\\sqrt{T})$ given that the number of cores\nis bounded by $T^{1/4}$ and the number of workers is bounded by $T^{1/2}$ where\n$T$ is the number of iterations. The potential gains that can be achieved by\nDPSGD are demonstrated empirically on a stochastic variational inference\nproblem (Latent Dirichlet Allocation) and on a deep reinforcement learning\n(DRL) problem (advantage actor critic - A2C) resulting in two algorithms: DPSVI\nand HSA2C. Empirical results validate our theoretical findings. Comparative\nstudies are conducted to show the performance of the proposed DPSGD against the\nstate-of-the-art DRL algorithms.",
    "descriptor": "",
    "authors": [
      "Saad Mohamad",
      "Hamad Alamri",
      "Abdelhamid Bouchachia"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02882"
  },
  {
    "id": "arXiv:2210.02939",
    "title": "Fault-tolerant Coding for Entanglement-Assisted Communication",
    "abstract": "Channel capacities quantify the optimal rates of sending information reliably\nover noisy channels. Usually, the study of capacities assumes that the circuits\nwhich sender and receiver use for encoding and decoding consist of perfectly\nnoiseless gates. In the case of communication over quantum channels, however,\nthis assumption is widely believed to be unrealistic, even in the long-term,\ndue to the fragility of quantum information, which is affected by the process\nof decoherence. Christandl and M\\\"uller-Hermes have therefore initiated the\nstudy of fault-tolerant channel coding for quantum channels, i.e. coding\nschemes where encoder and decoder circuits are affected by noise, and have used\ntechniques from fault-tolerant quantum computing to establish coding theorems\nfor sending classical and quantum information in this scenario. Here, we extend\nthese methods to the case of entanglement-assisted communication, in particular\nproving that the fault-tolerant capacity approaches the usual capacity when the\ngate error approaches zero. A main tool, which might be of independent\ninterest, is the introduction of fault-tolerant entanglement distillation. We\nfurthermore focus on the modularity of the techniques used, so that they can be\neasily adopted in other fault-tolerant communication scenarios.",
    "descriptor": "",
    "authors": [
      "Paula Belzig",
      "Matthias Christandl",
      "Alexander M\u00fcller-Hermes"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.02939"
  },
  {
    "id": "arXiv:2210.02992",
    "title": "COVID-19 Detection Using Segmentation, Region Extraction and  Classification Pipeline",
    "abstract": "Purpose The main purpose in this study is to propose a pipeline for COVID-19\ndetection from a big and challenging database of Computed Tomography (CT)\nimages. The proposed pipeline includes a segmentation part, a region of\ninterest extraction part, and a classifier part. Methods The methodology used\nin the segmentation part is traditional segmentation methods as well as UNet\nbased segmentation. In the classification part a Convolutional Neural Network\n(CNN) was used to take the final diagnosis decisions. Results In the\nsegmentation part, the proposed segmentation methods show high dice scores on a\npublicly vailable dataset. In the classification part, the results show high\naccuracy on the validation partition of COV19-CT-DB dataset as well as higher\nprecision, recall, and macro F1 score. The classification results were compared\nto our previous works other studies as well as on the same dataset. Conclusions\nThe improved work in this paper proposes efficient pipeline with a potential of\nhaving clinical usage for COVID-19 detection and diagnosis via CT images.\nThe code is on github at https://github.com/IDU-CVLab/COV19D_3rd",
    "descriptor": "",
    "authors": [
      "Kenan Morani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02992"
  },
  {
    "id": "arXiv:2210.02996",
    "title": "Synergistic information supports modality integration and flexible  learning in neural networks solving multiple tasks",
    "abstract": "Striking progress has recently been made in understanding human cognition by\nanalyzing how its neuronal underpinnings are engaged in different modes of\ninformation processing. Specifically, neural information can be decomposed into\nsynergistic, redundant, and unique features, with synergistic components being\nparticularly aligned with complex cognition. However, two fundamental questions\nremain unanswered: (a) precisely how and why a cognitive system can become\nhighly synergistic; and (b) how these informational states map onto artificial\nneural networks in various learning modes. To address these questions, here we\nemploy an information-decomposition framework to investigate the information\nprocessing strategies adopted by simple artificial neural networks performing a\nvariety of cognitive tasks in both supervised and reinforcement learning\nsettings. Our results show that synergy increases as neural networks learn\nmultiple diverse tasks. Furthermore, performance in tasks requiring integration\nof multiple information sources critically relies on synergistic neurons.\nFinally, randomly turning off neurons during training through dropout increases\nnetwork redundancy, corresponding to an increase in robustness. Overall, our\nresults suggest that while redundant information is required for robustness to\nperturbations in the learning process, synergistic information is used to\ncombine information from multiple modalities -- and more generally for flexible\nand efficient learning. These findings open the door to new ways of\ninvestigating how and why learning systems employ specific\ninformation-processing strategies, and support the principle that the capacity\nfor general-purpose learning critically relies in the system's information\ndynamics.",
    "descriptor": "\nComments: 33 pages, 15 figures\n",
    "authors": [
      "Alexandra M. Proca",
      "Fernando E. Rosas",
      "Andrea I. Luppi",
      "Daniel Bor",
      "Matthew Crosby",
      "Pedro A.M. Mediano"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02996"
  },
  {
    "id": "arXiv:2210.02998",
    "title": "A Novel Attention Mechanism Using Anatomical Prior Probability Maps for  Thoracic Disease Classification from X-Ray Images",
    "abstract": "Computer-aided disease diagnosis and prognosis based on medical images is a\nrapidly emerging field. Many Convolutional Neural Network (CNN) architectures\nhave been developed by researchers for disease classification and localization\nfrom chest X-ray images. It is known that different thoracic disease lesions\nare more likely to occur in specific anatomical regions compared to others.\nBased on this knowledge, we first estimate a disease-dependent spatial\nprobability, i.e., an anatomical prior, that indicates the probability of\noccurrence of a disease in a specific region in a chest X-ray image. Next, we\ndevelop a novel attention-based classification model that combines information\nfrom the estimated anatomical prior and automatically extracted chest region of\ninterest (ROI) masks to provide attention to the feature maps generated from a\ndeep convolution network. Unlike previous works that utilize various\nself-attention mechanisms, the proposed method leverages the extracted chest\nROI masks along with the probabilistic anatomical prior information, which\nselects the region of interest for different diseases to provide attention. The\nproposed method shows superior performance in disease classification on the NIH\nChestX-ray14 dataset compared to existing state-of-the-art methods while\nreaching an area under the ROC curve (AUC) of 0.8427. Regarding disease\nlocalization, the proposed method shows competitive performance compared to\nstate-of-the-art methods, achieving an accuracy of 61% with an Intersection\nover Union (IoU) threshold of 0.3. The proposed method can also be generalized\nto other medical image-based disease classification and localization tasks\nwhere the probability of occurrence of the lesion is dependent on specific\nanatomical sites.",
    "descriptor": "",
    "authors": [
      "Md. Iqbal Hossain",
      "S. M. Jawwad Hossain",
      "Mohammad Zunaed",
      "Taufiq Hasan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02998"
  },
  {
    "id": "arXiv:2210.02999",
    "title": "NLTS Hamiltonians from classical LTCs",
    "abstract": "We provide a completely self-contained construction of a family of NLTS\nHamiltonians [Freedman and Hastings, 2014] based on ideas from [Anshu,\nBreuckmann, and Nirkhe, 2022], [Cross, He, Natarajan, Szegedy, and Zhu, 2022]\nand [Eldar and Harrow, 2017]. Crucially, it does not require optimal-parameter\nquantum LDPC codes and can be built from simple classical LTCs such as the\nrepetition code on an expander graph. Furthermore, it removes the constant-rate\nrequirement from the construction of Anshu, Breuckmann, and Nirkhe.",
    "descriptor": "\nComments: 4 pages, 0 figures\n",
    "authors": [
      "Zhiyang He",
      "Chinmay Nirkhe"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.02999"
  },
  {
    "id": "arXiv:2210.03030",
    "title": "Learning many-body Hamiltonians with Heisenberg-limited scaling",
    "abstract": "Learning a many-body Hamiltonian from its dynamics is a fundamental problem\nin physics. In this work, we propose the first algorithm to achieve the\nHeisenberg limit for learning an interacting $N$-qubit local Hamiltonian. After\na total evolution time of $\\mathcal{O}(\\epsilon^{-1})$, the proposed algorithm\ncan efficiently estimate any parameter in the $N$-qubit Hamiltonian to\n$\\epsilon$-error with high probability. The proposed algorithm is robust\nagainst state preparation and measurement error, does not require eigenstates\nor thermal states, and only uses $\\mathrm{polylog}(\\epsilon^{-1})$ experiments.\nIn contrast, the best previous algorithms, such as recent works using\ngradient-based optimization or polynomial interpolation, require a total\nevolution time of $\\mathcal{O}(\\epsilon^{-2})$ and $\\mathcal{O}(\\epsilon^{-2})$\nexperiments. Our algorithm uses ideas from quantum simulation to decouple the\nunknown $N$-qubit Hamiltonian $H$ into noninteracting patches, and learns $H$\nusing a quantum-enhanced divide-and-conquer approach. We prove a matching lower\nbound to establish the asymptotic optimality of our algorithm.",
    "descriptor": "\nComments: 11 pages, 1 figure + 27-page appendix\n",
    "authors": [
      "Hsin-Yuan Huang",
      "Yu Tong",
      "Di Fang",
      "Yuan Su"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03030"
  },
  {
    "id": "arXiv:2210.03047",
    "title": "Conditional Feature Importance for Mixed Data",
    "abstract": "Despite the popularity of feature importance measures in interpretable\nmachine learning, the statistical adequacy of these methods is rarely\ndiscussed. From a statistical perspective, a major distinction is between\nanalyzing a variable's importance before and after adjusting for covariates -\ni.e., between marginal and conditional measures. Our work draws attention to\nthis rarely acknowledged, yet crucial distinction and showcases its\nimplications. Further, we reveal that for testing conditional feature\nimportance (CFI), only few methods are available and practitioners have\nhitherto been severely restricted in method application due to mismatching data\nrequirements. Most real-world data exhibits complex feature dependencies and\nincorporates both continuous and categorical data (mixed data). Both properties\nare oftentimes neglected by CFI measures. To fill this gap, we propose to\ncombine the conditional predictive impact (CPI) framework (arXiv:1901.09917)\nwith sequential knockoff sampling (arXiv:2010.14026). The CPI enables CFI\nmeasurement that controls for any feature dependencies by sampling valid\nknockoffs - hence, generating synthetic data with similar statistical\nproperties - for the data to be analyzed. Sequential knockoffs were\ndeliberately designed to handle mixed data and thus allow us to extend the CPI\napproach to such datasets. We demonstrate through numerous simulations and a\nreal-world example that our proposed workflow controls type I error, achieves\nhigh power and is in line with results given by other CFI measures, whereas\nmarginal feature importance metrics result in misleading interpretations. Our\nfindings highlight the necessity of developing statistically adequate,\nspecialized methods for mixed data.",
    "descriptor": "",
    "authors": [
      "Kristin Blesch",
      "David S. Watson",
      "Marvin N. Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03047"
  },
  {
    "id": "arXiv:2210.03048",
    "title": "Scalable Experimental Bounds for Entangled Quantum State Fidelities",
    "abstract": "Estimating the state preparation fidelity of highly entangled states on noisy\nintermediate-scale quantum (NISQ) devices is an important task for benchmarking\nand application considerations. Unfortunately, exact fidelity measurements\nquickly become prohibitively expensive, as they scale exponentially as O(3^N)\nfor N-qubit states, using full state tomography with measurements in all Pauli\nbases combinations.\nHowever, it is known [Somma et.al. 2006] that the complexity can be\ndrastically reduced when looking at fidelity lower bounds for states that\nexhibit symmetries, such as Dicke States and GHZ States. For larger states,\nthese bounds have so far not been tight enough to provide reasonable\nestimations on today's (2022) NISQ devices. In this work, for the first time\nand more than 15 years after the theoretical introduction, we report meaningful\nlower bounds for the state preparation fidelity of all Dicke States up to N=10\nand all GHZ states up to N=20 on Quantinuum H1 ion-trap systems using efficient\nimplementations of recently proposed scalable circuits for these states.\nFor example, we give state preparation fidelity lower bounds of (i) 0.46 for\nthe Dicke State |D10,5> and (ii) 0.73 for the GHZ State |G20>. These match or\nexceed exact fidelity records recently achieved on superconducting systems for\nthe much smaller states |D6,3> and |G5>, respectively. Furthermore, we provide\nevidence that for large Dicke States |DN,N/2>, we can resort to a GHZ-based\napproximate state preparation to achieve better fidelity.",
    "descriptor": "",
    "authors": [
      "Shamminuj Aktar",
      "Andreas B\u00e4rtschi",
      "Abdel-Hameed A. Badawy",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03048"
  },
  {
    "id": "arXiv:2210.03064",
    "title": "Robust thresholds: Counting triangle factors and A shorter proof of the  robust Corr\u00e1di-Hajnal Theorem",
    "abstract": "We show that the distribution of perfect matchings in an $r$-uniform\nhypergraph on $n$ vertices induced by the edges of an $r$-partite super-regular\ngraph is $O(1/n^{r-1})$-spread. This yields a short proof of the robust\nCorr\\'adi-Hajnal Theorem recently obtained by Allen et al., that there is $C>0$\nsuch that, for a graph $G$ with minimum degree $2n/3$, a random subgraph of $G$\nwhere each edge is retained with probability $C(\\log n)^{1/3}n^{-2/3}$ contains\na triangle factor with high probability. We also show that the number of\ntriangle factors in a graph with minimum degree $2n/3$ is at least\n$(cn)^{2n/3}$ for a constant $c>0$, addressing a question of Allen et al.",
    "descriptor": "\nComments: 7 pages with 2 page appendix\n",
    "authors": [
      "Huy Tuan Pham"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.03064"
  },
  {
    "id": "arXiv:2210.03067",
    "title": "Few-Shot Calibration of Set Predictors via Meta-Learned  Cross-Validation-Based Conformal Prediction",
    "abstract": "Conventional frequentist learning is known to yield poorly calibrated models\nthat fail to reliably quantify the uncertainty of their decisions. Bayesian\nlearning can improve calibration, but formal guarantees apply only under\nrestrictive assumptions about correct model specification. Conformal prediction\n(CP) offers a general framework for the design of set predictors with\ncalibration guarantees that hold regardless of the underlying data generation\nmechanism. However, when training data are limited, CP tends to produce large,\nand hence uninformative, predicted sets. This paper introduces a novel\nmeta-learning solution that aims at reducing the set prediction size. Unlike\nprior work, the proposed meta-learning scheme, referred to as meta-XB, (i)\nbuilds on cross-validation-based CP, rather than the less efficient\nvalidation-based CP; and (ii) preserves formal per-task calibration guarantees,\nrather than less stringent task-marginal guarantees. Finally, meta-XB is\nextended to adaptive non-conformal scores, which are shown empirically to\nfurther enhance marginal per-input calibration.",
    "descriptor": "\nComments: submitted for journal publication\n",
    "authors": [
      "Sangwoo Park",
      "Kfir M. Cohen",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03067"
  },
  {
    "id": "arXiv:2210.03096",
    "title": "Accelerated Single-Call Methods for Constrained Min-Max Optimization",
    "abstract": "We study first-order methods for constrained min-max optimization. Existing\nmethods either requires two gradient calls or two projections in each\niteration, which may be costly in applications. In this paper, we first show\nthat the Optimistic Gradient (OG) method, a single-call single-projection\nalgorithm, has $O(\\frac{1}{\\sqrt{T}})$ convergence rate for inclusion problems\nwith operators that satisfy the weak Minty variation inequality (MVI). Our\nsecond result is the first single-call single-projection algorithm -- the\nAccelerated Reflected Gradient (ARG) method that achieves the optimal\n$O(\\frac{1}{T})$ convergence rate for inclusion problems that satisfy negative\ncomonotonicity. Both the weak MVI and negative comonotonicity are well-studied\nassumptions and capture a rich set of non-convex non-concave min-max\noptimization problems. Finally, we show that the Reflected Gradient (RG)\nmethod, another single-call single-projection algorithm, has\n$O(\\frac{1}{\\sqrt{T}})$ last-iterate convergence rate for constrained\nconvex-concave min-max optimization, answering an open problem of [Hsieh et al,\n2019].",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Yang Cai",
      "Weiqiang Zheng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03096"
  },
  {
    "id": "arXiv:1812.10528",
    "title": "Adversarial Attack and Defense on Graph Data: A Survey",
    "abstract": "Comments: Published on IEEE TKDE. For more open-source and up-to-date information, please check our Github repository: this https URL",
    "descriptor": "\nComments: Published on IEEE TKDE. For more open-source and up-to-date information, please check our Github repository: this https URL\n",
    "authors": [
      "Lichao Sun",
      "Yingtong Dou",
      "Carl Yang",
      "Ji Wang",
      "Yixin Liu",
      "Philip S. Yu",
      "Lifang He",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1812.10528"
  },
  {
    "id": "arXiv:1906.08283",
    "title": "Minimum Stein Discrepancy Estimators",
    "abstract": "Comments: Accepted for publication at NeurIPS 2019",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2019\n",
    "authors": [
      "Alessandro Barp",
      "Francois-Xavier Briol",
      "Andrew B. Duncan",
      "Mark Girolami",
      "Lester Mackey"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.08283"
  },
  {
    "id": "arXiv:1909.01013",
    "title": "Duality Regularization for Unsupervised Bilingual Lexicon Induction",
    "abstract": "Duality Regularization for Unsupervised Bilingual Lexicon Induction",
    "descriptor": "",
    "authors": [
      "Xuefeng Bai",
      "Yue Zhang",
      "Hailong Cao",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1909.01013"
  },
  {
    "id": "arXiv:1909.08061",
    "title": "Construction of sequences with high nonlinear complexity from a  generalization of the Hermitian function field",
    "abstract": "Construction of sequences with high nonlinear complexity from a  generalization of the Hermitian function field",
    "descriptor": "",
    "authors": [
      "Alonso S. Castellanos",
      "Luciane Quoos",
      "Guilherme Tizziotti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.08061"
  },
  {
    "id": "arXiv:2002.01048",
    "title": "Multi-Channel Attention Selection GANs for Guided Image-to-Image  Translation",
    "abstract": "Comments: Accepted to TPAMI, an extended version of a paper published in CVPR2019. arXiv admin note: substantial text overlap with arXiv:1904.06807",
    "descriptor": "\nComments: Accepted to TPAMI, an extended version of a paper published in CVPR2019. arXiv admin note: substantial text overlap with arXiv:1904.06807\n",
    "authors": [
      "Hao Tang",
      "Philip H.S. Torr",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2002.01048"
  },
  {
    "id": "arXiv:2007.01834",
    "title": "Universal Distances for Extended Persistence",
    "abstract": "Comments: 43 pages + 11 pages appendix, 19 figures, LaTeX; moved an appendix to arXiv:2108.09298, added a note of caution regarding variants of the bottleneck distance, rewrote the proof of lemma 4.6, generalization of results to restricted extended persistence diagrams, added discussion of relations to interleaving distances of sheaves and of Reeb graphs, updated references, several minor edits",
    "descriptor": "\nComments: 43 pages + 11 pages appendix, 19 figures, LaTeX; moved an appendix to arXiv:2108.09298, added a note of caution regarding variants of the bottleneck distance, rewrote the proof of lemma 4.6, generalization of results to restricted extended persistence diagrams, added discussion of relations to interleaving distances of sheaves and of Reeb graphs, updated references, several minor edits\n",
    "authors": [
      "Ulrich Bauer",
      "Magnus Bakke Botnan",
      "Benedikt Fluhr"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2007.01834"
  },
  {
    "id": "arXiv:2008.10838",
    "title": "FedCVT: Semi-supervised Vertical Federated Learning with Cross-view  Training",
    "abstract": "Comments: accepted by ACM Transactions on Intelligent Systems and Technology Volume 13 Issue 4 August 2022",
    "descriptor": "\nComments: accepted by ACM Transactions on Intelligent Systems and Technology Volume 13 Issue 4 August 2022\n",
    "authors": [
      "Yan Kang",
      "Yang Liu",
      "Xinle Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.10838"
  },
  {
    "id": "arXiv:2010.01044",
    "title": "Multilevel quasi-Monte Carlo for random elliptic eigenvalue problems I:  Regularity and error analysis",
    "abstract": "Multilevel quasi-Monte Carlo for random elliptic eigenvalue problems I:  Regularity and error analysis",
    "descriptor": "",
    "authors": [
      "Alexander D. Gilbert",
      "Robert Scheichl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.01044"
  },
  {
    "id": "arXiv:2010.02502",
    "title": "Denoising Diffusion Implicit Models",
    "abstract": "Comments: ICLR 2021; updated connections with ODEs at page 6, fixed some typos in the proof",
    "descriptor": "\nComments: ICLR 2021; updated connections with ODEs at page 6, fixed some typos in the proof\n",
    "authors": [
      "Jiaming Song",
      "Chenlin Meng",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.02502"
  },
  {
    "id": "arXiv:2010.13563",
    "title": "A Unified Framework for Double Sweep Methods for the Helmholtz Equation",
    "abstract": "A Unified Framework for Double Sweep Methods for the Helmholtz Equation",
    "descriptor": "",
    "authors": [
      "Nacime Bouziani",
      "Fr\u00e9d\u00e9ric Nataf",
      "Pierre-Henri Tournier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.13563"
  },
  {
    "id": "arXiv:2012.04646",
    "title": "Spectral clustering via adaptive layer aggregation for multi-layer  networks",
    "abstract": "Comments: 74 pages",
    "descriptor": "\nComments: 74 pages\n",
    "authors": [
      "Sihan Huang",
      "Haolei Weng",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.04646"
  },
  {
    "id": "arXiv:2101.09391",
    "title": "Learning Setup Policies: Reliable Transition Between Locomotion  Behaviours",
    "abstract": "Comments: Published in IEEE Robotics and Automation Letters ( Volume: 7, Issue: 4, October 2022) Page(s): 11958 - 11965 this https URL",
    "descriptor": "\nComments: Published in IEEE Robotics and Automation Letters ( Volume: 7, Issue: 4, October 2022) Page(s): 11958 - 11965 this https URL\n",
    "authors": [
      "Brendan Tidd",
      "Nicolas Hudson",
      "Akansel Cosgun",
      "Jurgen Leitner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09391"
  },
  {
    "id": "arXiv:2102.03539",
    "title": "Sill-Net: Feature Augmentation with Separated Illumination  Representation",
    "abstract": "Sill-Net: Feature Augmentation with Separated Illumination  Representation",
    "descriptor": "",
    "authors": [
      "Haipeng Zhang",
      "Zhong Cao",
      "Ziang Yan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.03539"
  },
  {
    "id": "arXiv:2102.07684",
    "title": "Fair and Optimal Cohort Selection for Linear Utilities",
    "abstract": "Comments: This paper has been subsumed by the arXiv paper arXiv:2009.02207",
    "descriptor": "\nComments: This paper has been subsumed by the arXiv paper arXiv:2009.02207\n",
    "authors": [
      "Konstantina Bairaktari",
      "Huy Le Nguyen",
      "Jonathan Ullman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07684"
  },
  {
    "id": "arXiv:2102.10217",
    "title": "Fast and Sample-Efficient Federated Low Rank Matrix Recovery from  column-wise Linear and Quadratic Projections",
    "abstract": "Comments: To appear in IEEE Transactions on Information Theory (T-IT)",
    "descriptor": "\nComments: To appear in IEEE Transactions on Information Theory (T-IT)\n",
    "authors": [
      "Seyedehsara",
      "Nayer",
      "Namrata Vaswani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.10217"
  },
  {
    "id": "arXiv:2103.02728",
    "title": "Morality, Machines and the Interpretation Problem: A Value-based,  Wittgensteinian Approach to Building Moral Agents",
    "abstract": "Morality, Machines and the Interpretation Problem: A Value-based,  Wittgensteinian Approach to Building Moral Agents",
    "descriptor": "",
    "authors": [
      "Cosmin Badea",
      "Gregory Artus"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.02728"
  },
  {
    "id": "arXiv:2103.03407",
    "title": "Multilevel quasi-Monte Carlo for random elliptic eigenvalue problems II:  Efficient algorithms and numerical results",
    "abstract": "Multilevel quasi-Monte Carlo for random elliptic eigenvalue problems II:  Efficient algorithms and numerical results",
    "descriptor": "",
    "authors": [
      "Alexander D. Gilbert",
      "Robert Scheichl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.03407"
  },
  {
    "id": "arXiv:2103.07751",
    "title": "Unsupervised Image Transformation Learning via Generative Adversarial  Networks",
    "abstract": "Unsupervised Image Transformation Learning via Generative Adversarial  Networks",
    "descriptor": "",
    "authors": [
      "Kaiwen Zha",
      "Yujun Shen",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.07751"
  },
  {
    "id": "arXiv:2105.00433",
    "title": "Who's Afraid of Adversarial Transferability?",
    "abstract": "Who's Afraid of Adversarial Transferability?",
    "descriptor": "",
    "authors": [
      "Ziv Katzir",
      "Yuval Elovici"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00433"
  },
  {
    "id": "arXiv:2105.01029",
    "title": "Initialization and Regularization of Factorized Neural Layers",
    "abstract": "Comments: ICLR 2021 camera-ready, amended due to error pointed out in arXiv:2209.13569v1 (amendment shown in blue)",
    "descriptor": "\nComments: ICLR 2021 camera-ready, amended due to error pointed out in arXiv:2209.13569v1 (amendment shown in blue)\n",
    "authors": [
      "Mikhail Khodak",
      "Neil Tenenholtz",
      "Lester Mackey",
      "Nicol\u00f2 Fusi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.01029"
  },
  {
    "id": "arXiv:2106.02558",
    "title": "Bayesian Risk Markov Decision Processes",
    "abstract": "Bayesian Risk Markov Decision Processes",
    "descriptor": "",
    "authors": [
      "Yifan Lin",
      "Yuxuan Ren",
      "Enlu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02558"
  },
  {
    "id": "arXiv:2106.14922",
    "title": "Cosmic-CoNN: A Cosmic Ray Detection Deep-Learning Framework, Dataset,  and Toolkit",
    "abstract": "Comments: 17 pages, 10 figures, 4 tables. Submitted to AAS Journals. See this https URL for the open-source software and this https URL for the dataset",
    "descriptor": "\nComments: 17 pages, 10 figures, 4 tables. Submitted to AAS Journals. See this https URL for the open-source software and this https URL for the dataset\n",
    "authors": [
      "Chengyuan Xu",
      "Curtis McCully",
      "Boning Dong",
      "D. Andrew Howell",
      "Pradeep Sen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14922"
  },
  {
    "id": "arXiv:2106.16209",
    "title": "A data-centric approach for improving ambiguous labels with combined  semi-supervised classification and clustering",
    "abstract": "Comments: Source code is available at this https URL, Datasets available at this https URL",
    "descriptor": "\nComments: Source code is available at this https URL, Datasets available at this https URL\n",
    "authors": [
      "Lars Schmarje",
      "Monty Santarossa",
      "Simon-Martin Schr\u00f6der",
      "Claudius Zelenka",
      "Rainer Kiko",
      "Jenny Stracke",
      "Nina Volkmann",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16209"
  },
  {
    "id": "arXiv:2107.02027",
    "title": "Efficient Sequence Packing without Cross-contamination: Accelerating  Large Language Models without Impacting Performance",
    "abstract": "Comments: Significantly new version with different authors and much more content. Much larger variety in experiments and exhaustive SOTA analysis",
    "descriptor": "\nComments: Significantly new version with different authors and much more content. Much larger variety in experiments and exhaustive SOTA analysis\n",
    "authors": [
      "Mario Michael Krell",
      "Matej Kosec",
      "Sergio P. Perez",
      "Andrew Fitzgibbon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02027"
  },
  {
    "id": "arXiv:2107.06226",
    "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial  Coverage",
    "abstract": "Comments: We changed the title from the first version. This is a longer version of the article accepted in ICLR 2022. We added a new algorithm CPPO-LR where the constraint is given in a log-likelihood form and how to instantiate CPPO on (nonparametric) linear MDPs",
    "descriptor": "\nComments: We changed the title from the first version. This is a longer version of the article accepted in ICLR 2022. We added a new algorithm CPPO-LR where the constraint is given in a log-likelihood form and how to instantiate CPPO on (nonparametric) linear MDPs\n",
    "authors": [
      "Masatoshi Uehara",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06226"
  },
  {
    "id": "arXiv:2107.11077",
    "title": "Reservoir Computing Approach for Gray Images Segmentation",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Petia Koprinkova-Hristova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.11077"
  },
  {
    "id": "arXiv:2107.13682",
    "title": "Bayesian Embeddings for Few-Shot Open World Recognition",
    "abstract": "Bayesian Embeddings for Few-Shot Open World Recognition",
    "descriptor": "",
    "authors": [
      "John Willes",
      "James Harrison",
      "Ali Harakeh",
      "Chelsea Finn",
      "Marco Pavone",
      "Steven Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13682"
  },
  {
    "id": "arXiv:2108.01994",
    "title": "Staged trees and asymmetry-labeled DAGs",
    "abstract": "Staged trees and asymmetry-labeled DAGs",
    "descriptor": "",
    "authors": [
      "Gherardo Varando",
      "Federico Carli",
      "Manuele Leonelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01994"
  },
  {
    "id": "arXiv:2108.08481",
    "title": "Neural Operator: Learning Maps Between Function Spaces",
    "abstract": "Neural Operator: Learning Maps Between Function Spaces",
    "descriptor": "",
    "authors": [
      "Nikola Kovachki",
      "Zongyi Li",
      "Burigede Liu",
      "Kamyar Azizzadenesheli",
      "Kaushik Bhattacharya",
      "Andrew Stuart",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.08481"
  },
  {
    "id": "arXiv:2108.09134",
    "title": "Accelerating Federated Learning with a Global Biased Optimiser",
    "abstract": "Accelerating Federated Learning with a Global Biased Optimiser",
    "descriptor": "",
    "authors": [
      "Jed Mills",
      "Jia Hu",
      "Geyong Min",
      "Rui Jin",
      "Siwei Zheng",
      "Jin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.09134"
  },
  {
    "id": "arXiv:2109.04786",
    "title": "Wi-Fi Meets ML: A Survey on Improving IEEE 802.11 Performance with  Machine Learning",
    "abstract": "Comments: 54 pages, 23 figures, 384 references",
    "descriptor": "\nComments: 54 pages, 23 figures, 384 references\n",
    "authors": [
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Piotr Gaw\u0142owicz",
      "Jorge Torres G\u00f3mez",
      "Boris Bellalta",
      "Anatolij Zubow",
      "Falko Dressler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.04786"
  },
  {
    "id": "arXiv:2109.06422",
    "title": "Cross-Region Domain Adaptation for Class-level Alignment",
    "abstract": "Comments: Under review in Computer Vision and Image Understanding",
    "descriptor": "\nComments: Under review in Computer Vision and Image Understanding\n",
    "authors": [
      "Zhijie Wang",
      "Xing Liu",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06422"
  },
  {
    "id": "arXiv:2109.06699",
    "title": "An Apparatus for the Simulation of Breathing Disorders: Physically  Meaningful Generation of Surrogate Data",
    "abstract": "An Apparatus for the Simulation of Breathing Disorders: Physically  Meaningful Generation of Surrogate Data",
    "descriptor": "",
    "authors": [
      "Harry J. Davies",
      "Ghena Hammour",
      "Hongjian Xiao",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06699"
  },
  {
    "id": "arXiv:2109.06716",
    "title": "HPOBench: A Collection of Reproducible Multi-Fidelity Benchmark Problems  for HPO",
    "abstract": "Comments: Published at NeurIPS Datasets and Benchmarks Track 2021. Updated version",
    "descriptor": "\nComments: Published at NeurIPS Datasets and Benchmarks Track 2021. Updated version\n",
    "authors": [
      "Katharina Eggensperger",
      "Philipp M\u00fcller",
      "Neeratyoy Mallik",
      "Matthias Feurer",
      "Ren\u00e9 Sass",
      "Aaron Klein",
      "Noor Awad",
      "Marius Lindauer",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06716"
  },
  {
    "id": "arXiv:2109.07706",
    "title": "Basil: A Fast and Byzantine-Resilient Approach for Decentralized  Training",
    "abstract": "Comments: Final version was accepted for publication in IEEE JSAC Series on Machine Learning for Communications and Networks. A part of the work was presented at the NeurIPS Workshop on Privacy in Machine Learning, 2021",
    "descriptor": "\nComments: Final version was accepted for publication in IEEE JSAC Series on Machine Learning for Communications and Networks. A part of the work was presented at the NeurIPS Workshop on Privacy in Machine Learning, 2021\n",
    "authors": [
      "Ahmed Roushdy Elkordy",
      "Saurav Prakash",
      "A. Salman Avestimehr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07706"
  },
  {
    "id": "arXiv:2110.15162",
    "title": "Exoplanet atmosphere evolution: emulation with neural networks",
    "abstract": "Comments: 16 pages, 10 figures. Submitted to MNRAS",
    "descriptor": "\nComments: 16 pages, 10 figures. Submitted to MNRAS\n",
    "authors": [
      "James G. Rogers",
      "Cl\u00e0udia Jan\u00f3 Mu\u00f1oz",
      "James E. Owen",
      "Lucas T. Makinen"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15162"
  },
  {
    "id": "arXiv:2111.00036",
    "title": "Real-Time Detection of Anomalies in Large-Scale Transient Surveys",
    "abstract": "Comments: 27 pages, 23 figures, accepted for publication in MNRAS",
    "descriptor": "\nComments: 27 pages, 23 figures, accepted for publication in MNRAS\n",
    "authors": [
      "Daniel Muthukrishna",
      "Kaisey S. Mandel",
      "Michelle Lochner",
      "Sara Webb",
      "Gautham Narayan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00036"
  },
  {
    "id": "arXiv:2111.01629",
    "title": "Accelerating Algebraic Multigrid Methods via Artificial Neural Networks",
    "abstract": "Accelerating Algebraic Multigrid Methods via Artificial Neural Networks",
    "descriptor": "",
    "authors": [
      "Paola F. Antonietti",
      "Matteo Caldana",
      "Luca Dede'"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01629"
  },
  {
    "id": "arXiv:2111.04946",
    "title": "Graph-Based Depth Denoising & Dequantization for Point Cloud Enhancement",
    "abstract": "Comments: 16 pages,14 figures",
    "descriptor": "\nComments: 16 pages,14 figures\n",
    "authors": [
      "Xue Zhang",
      "Gene Cheung",
      "Jiahao Pang",
      "Yash Sanghvi",
      "Abhiram Gnanasambandam",
      "Stanley H. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.04946"
  },
  {
    "id": "arXiv:2111.13091",
    "title": "Asynchronous Session-Based Concurrency: Deadlock-freedom in Cyclic  Process Networks",
    "abstract": "Comments: Extended version of arXiv:2110.00146, doi:10.4204/EPTCS.347.3 and arXiv:2209.06820, doi:10.4204/EPTCS.368.5",
    "descriptor": "\nComments: Extended version of arXiv:2110.00146, doi:10.4204/EPTCS.347.3 and arXiv:2209.06820, doi:10.4204/EPTCS.368.5\n",
    "authors": [
      "Bas van den Heuvel",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.13091"
  },
  {
    "id": "arXiv:2111.14341",
    "title": "OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of  Individual Nuisances in Natural Images",
    "abstract": "Comments: Project webpage: this http URL, this work is accepted as Oral at ECCV 2022",
    "descriptor": "\nComments: Project webpage: this http URL, this work is accepted as Oral at ECCV 2022\n",
    "authors": [
      "Bingchen Zhao",
      "Shaozuo Yu",
      "Wufei Ma",
      "Mingxin Yu",
      "Shenxiao Mei",
      "Angtian Wang",
      "Ju He",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14341"
  },
  {
    "id": "arXiv:2111.15664",
    "title": "OCR-free Document Understanding Transformer",
    "abstract": "Comments: ECCV 2022. (v5) update table 2 and figures; add LayoutLM and update scores with the latest test script at this https URL",
    "descriptor": "\nComments: ECCV 2022. (v5) update table 2 and figures; add LayoutLM and update scores with the latest test script at this https URL\n",
    "authors": [
      "Geewook Kim",
      "Teakgyu Hong",
      "Moonbin Yim",
      "Jeongyeon Nam",
      "Jinyoung Park",
      "Jinyeong Yim",
      "Wonseok Hwang",
      "Sangdoo Yun",
      "Dongyoon Han",
      "Seunghyun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15664"
  },
  {
    "id": "arXiv:2112.10308",
    "title": "Analysis of preintegration followed by quasi-Monte Carlo integration for  distribution functions and densities",
    "abstract": "Analysis of preintegration followed by quasi-Monte Carlo integration for  distribution functions and densities",
    "descriptor": "",
    "authors": [
      "Alexander D. Gilbert",
      "Frances Y. Kuo",
      "Ian H. Sloan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.10308"
  },
  {
    "id": "arXiv:2201.01165",
    "title": "An Efficient Contact Algorithm for Rigid/Deformable Interaction based on  the Dual Mortar Method",
    "abstract": "An Efficient Contact Algorithm for Rigid/Deformable Interaction based on  the Dual Mortar Method",
    "descriptor": "",
    "authors": [
      "R. Pinto Carvalho",
      "A. M. Couto Carneiro",
      "F. M. Andrade Pires",
      "A. Popp"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.01165"
  },
  {
    "id": "arXiv:2201.02074",
    "title": "EM-driven unsupervised learning for efficient motion segmentation",
    "abstract": "Comments: Accepted to : IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
    "descriptor": "\nComments: Accepted to : IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Etienne Meunier",
      "Ana\u00efs Badoual",
      "Patrick Bouthemy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.02074"
  },
  {
    "id": "arXiv:2201.02080",
    "title": "BERN2: an advanced neural biomedical named entity recognition and  normalization tool",
    "abstract": "Comments: Published in Bioinformatics 2022. Web service available at this http URL Code available at this https URL",
    "descriptor": "\nComments: Published in Bioinformatics 2022. Web service available at this http URL Code available at this https URL\n",
    "authors": [
      "Mujeen Sung",
      "Minbyul Jeong",
      "Yonghwa Choi",
      "Donghyeon Kim",
      "Jinhyuk Lee",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.02080"
  },
  {
    "id": "arXiv:2201.04800",
    "title": "Online State Estimation for Supervisor Synthesis in Discrete-Event  Systems with Communication Delays and Losses",
    "abstract": "Online State Estimation for Supervisor Synthesis in Discrete-Event  Systems with Communication Delays and Losses",
    "descriptor": "",
    "authors": [
      "Yunfeng Hou",
      "Yunfeng Ji",
      "Gang Wang",
      "Ching-Yen Weng",
      "Qingdu Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04800"
  },
  {
    "id": "arXiv:2201.10160",
    "title": "Data-driven Mutation Analysis for Cyber-Physical Systems",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Enrico Vigan\u00f2",
      "Oscar Cornejo",
      "Fabrizio Pastore",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.10160"
  },
  {
    "id": "arXiv:2201.10305",
    "title": "Mutual information neural estimation for unsupervised multi-modal  registration of brain images",
    "abstract": "Comments: 4 pages, 4 figures, 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), oral presentation",
    "descriptor": "\nComments: 4 pages, 4 figures, 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), oral presentation\n",
    "authors": [
      "Gerard Snaauw",
      "Michele Sasdelli",
      "Gabriel Maicas",
      "Stephan Lau",
      "Johan Verjans",
      "Mark Jenkinson",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10305"
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2022",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2022\n",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11932"
  },
  {
    "id": "arXiv:2201.12157",
    "title": "Towards Multi-class Pre-movement Classification",
    "abstract": "Towards Multi-class Pre-movement Classification",
    "descriptor": "",
    "authors": [
      "Hao Jia",
      "Zhe Sun",
      "Feng Duan",
      "Yu Zhang",
      "Cesar F. Caiafa",
      "Jordi Sol\u00e9-Casals"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.12157"
  },
  {
    "id": "arXiv:2201.12558",
    "title": "The KFIoU Loss for Rotated Object Detection",
    "abstract": "Comments: 17 pages, 6 figures, 7 tables, TensorFlow code: this https URL, PyTorch code: this https URL",
    "descriptor": "\nComments: 17 pages, 6 figures, 7 tables, TensorFlow code: this https URL, PyTorch code: this https URL\n",
    "authors": [
      "Xue Yang",
      "Yue Zhou",
      "Gefan Zhang",
      "Jirui Yang",
      "Wentao Wang",
      "Junchi Yan",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12558"
  },
  {
    "id": "arXiv:2202.00046",
    "title": "Finding Directions in GAN's Latent Space for Neural Face Reenactment",
    "abstract": "Comments: Accepted for publication in BMVC 2022. Project page: this https URL Code: this https URL",
    "descriptor": "\nComments: Accepted for publication in BMVC 2022. Project page: this https URL Code: this https URL\n",
    "authors": [
      "Stella Bounareli",
      "Vasileios Argyriou",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00046"
  },
  {
    "id": "arXiv:2202.00185",
    "title": "LayoutEnhancer: Generating Good Indoor Layouts from Imperfect Data",
    "abstract": "Comments: preprint of ACM SIGGRAPH Asia 2022 Conference Paper, 14 pages including appendix and supplementary figures, 16 figures",
    "descriptor": "\nComments: preprint of ACM SIGGRAPH Asia 2022 Conference Paper, 14 pages including appendix and supplementary figures, 16 figures\n",
    "authors": [
      "Kurt Leimer",
      "Paul Guerrero",
      "Tomer Weiss",
      "Przemyslaw Musialski"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00185"
  },
  {
    "id": "arXiv:2202.04307",
    "title": "Conditional Motion In-betweening",
    "abstract": "Conditional Motion In-betweening",
    "descriptor": "",
    "authors": [
      "Jihoon Kim",
      "Taehyun Byun",
      "Seungyoun Shin",
      "Jungdam Won",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.04307"
  },
  {
    "id": "arXiv:2202.06393",
    "title": "Comparing the Perceived Legitimacy of Content Moderation Processes:  Contractors, Algorithms, Expert Panels, and Digital Juries",
    "abstract": "Comments: This paper will appear at CSCW 2022",
    "descriptor": "\nComments: This paper will appear at CSCW 2022\n",
    "authors": [
      "Christina A. Pan",
      "Sahil Yakhmi",
      "Tara P. Iyer",
      "Evan Strasnick",
      "Amy X. Zhang",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06393"
  },
  {
    "id": "arXiv:2202.06693",
    "title": "On Payment Channels in Asynchronous Money Transfer Systems",
    "abstract": "On Payment Channels in Asynchronous Money Transfer Systems",
    "descriptor": "",
    "authors": [
      "Oded Naor",
      "Idit Keidar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.06693"
  },
  {
    "id": "arXiv:2202.10145",
    "title": "Information Revelation Through Signalling",
    "abstract": "Comments: To appear in Systems and Control Letters",
    "descriptor": "\nComments: To appear in Systems and Control Letters\n",
    "authors": [
      "Reema Deori",
      "Ankur A. Kulkarni"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.10145"
  },
  {
    "id": "arXiv:2202.11823",
    "title": "Differentially Private Speaker Anonymization",
    "abstract": "Differentially Private Speaker Anonymization",
    "descriptor": "",
    "authors": [
      "Ali Shahin Shamsabadi",
      "Brij Mohan Lal Srivastava",
      "Aur\u00e9lien Bellet",
      "Nathalie Vauquier",
      "Emmanuel Vincent",
      "Mohamed Maouche",
      "Marc Tommasi",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.11823"
  },
  {
    "id": "arXiv:2202.12521",
    "title": "How to reduce the search space of Entity Resolution: with Blocking or  Nearest Neighbor search?",
    "abstract": "How to reduce the search space of Entity Resolution: with Blocking or  Nearest Neighbor search?",
    "descriptor": "",
    "authors": [
      "George Papadakis",
      "Marco Fisichella",
      "Franziska Schoger",
      "George Mandilaras",
      "Nikolaus Augsten",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.12521"
  },
  {
    "id": "arXiv:2203.00281",
    "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for  Grammar Induction and Text Representation",
    "abstract": "Comments: To be published on EMNLP 2022",
    "descriptor": "\nComments: To be published on EMNLP 2022\n",
    "authors": [
      "Xiang Hu",
      "Haitao Mi",
      "Liang Li",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.00281"
  },
  {
    "id": "arXiv:2203.00913",
    "title": "A Principled Design of Image Representation: Towards Forensic Tasks",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022, this https URL",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022, this https URL\n",
    "authors": [
      "Shuren Qi",
      "Yushu Zhang",
      "Chao Wang",
      "Jiantao Zhou",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.00913"
  },
  {
    "id": "arXiv:2203.04589",
    "title": "A New Global Divergence Free and Pressure-Robust HDG Method for  Tangential Boundary Control of Stokes Equations",
    "abstract": "A New Global Divergence Free and Pressure-Robust HDG Method for  Tangential Boundary Control of Stokes Equations",
    "descriptor": "",
    "authors": [
      "Gang Chen",
      "Wei Gong",
      "Mariano Mateos",
      "John R. Singler",
      "Yangwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.04589"
  },
  {
    "id": "arXiv:2203.04695",
    "title": "Structured Multi-task Learning for Molecular Property Prediction",
    "abstract": "Structured Multi-task Learning for Molecular Property Prediction",
    "descriptor": "",
    "authors": [
      "Shengchao Liu",
      "Meng Qu",
      "Zuobai Zhang",
      "Huiyu Cai",
      "Jian Tang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.04695"
  },
  {
    "id": "arXiv:2203.04907",
    "title": "KPE: Keypoint Pose Encoding for Transformer-based Image Generation",
    "abstract": "KPE: Keypoint Pose Encoding for Transformer-based Image Generation",
    "descriptor": "",
    "authors": [
      "Soon Yau Cheong",
      "Armin Mustafa",
      "Andrew Gilbert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04907"
  },
  {
    "id": "arXiv:2203.05557",
    "title": "Conditional Prompt Learning for Vision-Language Models",
    "abstract": "Comments: CVPR 2022. Update: Adds results on the DOSCO (DOmain Shift in COntext) benchmark",
    "descriptor": "\nComments: CVPR 2022. Update: Adds results on the DOSCO (DOmain Shift in COntext) benchmark\n",
    "authors": [
      "Kaiyang Zhou",
      "Jingkang Yang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05557"
  },
  {
    "id": "arXiv:2203.08479",
    "title": "Data Efficient 3D Learner via Knowledge Transferred from 2D Model",
    "abstract": "Data Efficient 3D Learner via Knowledge Transferred from 2D Model",
    "descriptor": "",
    "authors": [
      "Ping-Chung Yu",
      "Cheng Sun",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08479"
  },
  {
    "id": "arXiv:2203.12023",
    "title": "Generative Modeling Helps Weak Supervision (and Vice Versa)",
    "abstract": "Generative Modeling Helps Weak Supervision (and Vice Versa)",
    "descriptor": "",
    "authors": [
      "Benedikt Boecking",
      "Nicholas Roberts",
      "Willie Neiswanger",
      "Stefano Ermon",
      "Frederic Sala",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.12023"
  },
  {
    "id": "arXiv:2203.13371",
    "title": "FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot  Video Understanding Tasks",
    "abstract": "Comments: Accepted at BMVC 2022. It includes the supplementary material. The margins and page size were modified to fit the arXiv ID stamp on the left side",
    "descriptor": "\nComments: Accepted at BMVC 2022. It includes the supplementary material. The margins and page size were modified to fit the arXiv ID stamp on the left side\n",
    "authors": [
      "Santiago Castro",
      "Fabian Caba Heilbron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13371"
  },
  {
    "id": "arXiv:2203.15447",
    "title": "Transfer Learning Framework for Low-Resource Text-to-Speech using a  Large-Scale Unlabeled Speech Corpus",
    "abstract": "Comments: Accepted by Interspeech2022",
    "descriptor": "\nComments: Accepted by Interspeech2022\n",
    "authors": [
      "Minchan Kim",
      "Myeonghun Jeong",
      "Byoung Jin Choi",
      "Sunghwan Ahn",
      "Joun Yeop Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15447"
  },
  {
    "id": "arXiv:2203.16811",
    "title": "Approximate Sensitivity Conditioning and Singular Perturbation Analysis  for Power Converters",
    "abstract": "Approximate Sensitivity Conditioning and Singular Perturbation Analysis  for Power Converters",
    "descriptor": "",
    "authors": [
      "Kaushik Gajula",
      "Lalit Kishore Marepalli",
      "Luis Herrera"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16811"
  },
  {
    "id": "arXiv:2203.17118",
    "title": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "abstract": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "descriptor": "",
    "authors": [
      "Harrie Oosterhuis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.17118"
  },
  {
    "id": "arXiv:2203.17272",
    "title": "MyStyle: A Personalized Generative Prior",
    "abstract": "Comments: SIGGRAPH ASIA 2022, Project webpage: this https URL, Video: this https URL",
    "descriptor": "\nComments: SIGGRAPH ASIA 2022, Project webpage: this https URL, Video: this https URL\n",
    "authors": [
      "Yotam Nitzan",
      "Kfir Aberman",
      "Qiurui He",
      "Orly Liba",
      "Michal Yarom",
      "Yossi Gandelsman",
      "Inbar Mosseri",
      "Yael Pritch",
      "Daniel Cohen-or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17272"
  },
  {
    "id": "arXiv:2204.00032",
    "title": "Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets",
    "abstract": "Comments: ACM CCS 2022",
    "descriptor": "\nComments: ACM CCS 2022\n",
    "authors": [
      "Florian Tram\u00e8r",
      "Reza Shokri",
      "Ayrton San Joaquin",
      "Hoang Le",
      "Matthew Jagielski",
      "Sanghyun Hong",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.00032"
  },
  {
    "id": "arXiv:2204.05422",
    "title": "SATA: Sparsity-Aware Training Accelerator for Spiking Neural Networks",
    "abstract": "Comments: 13 pages. Accepted to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (2022)",
    "descriptor": "\nComments: 13 pages. Accepted to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (2022)\n",
    "authors": [
      "Ruokai Yin",
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.05422"
  },
  {
    "id": "arXiv:2204.07637",
    "title": "Towards a Stronger Theory for Permutation-based Evolutionary Algorithms",
    "abstract": "Comments: Conference version with an appendix containing the proofs omitted for reasons of space",
    "descriptor": "\nComments: Conference version with an appendix containing the proofs omitted for reasons of space\n",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07637"
  },
  {
    "id": "arXiv:2204.08942",
    "title": "The Binary Rank of Circulant Block Matrices",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Ishay Haviv",
      "Michal Parnas"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.08942"
  },
  {
    "id": "arXiv:2204.10757",
    "title": "FaithDial: A Faithful Benchmark for Information-Seeking Dialogue",
    "abstract": "Comments: TACL 2022 (20 pages, 3 figures, 10 tables)",
    "descriptor": "\nComments: TACL 2022 (20 pages, 3 figures, 10 tables)\n",
    "authors": [
      "Nouha Dziri",
      "Ehsan Kamalloo",
      "Sivan Milton",
      "Osmar Zaiane",
      "Mo Yu",
      "Edoardo M. Ponti",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.10757"
  },
  {
    "id": "arXiv:2204.11417",
    "title": "Uncoupled Learning Dynamics with $O(\\log T)$ Swap Regret in Multiplayer  Games",
    "abstract": "Comments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback and minor corrections",
    "descriptor": "\nComments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback and minor corrections\n",
    "authors": [
      "Ioannis Anagnostides",
      "Gabriele Farina",
      "Christian Kroer",
      "Chung-Wei Lee",
      "Haipeng Luo",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11417"
  },
  {
    "id": "arXiv:2204.11424",
    "title": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "abstract": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "descriptor": "",
    "authors": [
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.11424"
  },
  {
    "id": "arXiv:2204.12303",
    "title": "On converses to the polynomial method",
    "abstract": "Comments: 13 pages. Some typos of a previous version were corrected and the journal reference was added",
    "descriptor": "\nComments: 13 pages. Some typos of a previous version were corrected and the journal reference was added\n",
    "authors": [
      "Jop Bri\u00ebt",
      "Francisco Escudero Guti\u00e9rrez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2204.12303"
  },
  {
    "id": "arXiv:2205.00155",
    "title": "Real-Time Gait Phase and Task Estimation for Controlling a Powered Ankle  Exoskeleton on Extremely Uneven Terrain",
    "abstract": "Real-Time Gait Phase and Task Estimation for Controlling a Powered Ankle  Exoskeleton on Extremely Uneven Terrain",
    "descriptor": "",
    "authors": [
      "Roberto Leo Medrano",
      "Gray Cortright Thomas",
      "Connor G. Keais",
      "Elliott J. Rouse",
      "Robert D. Gregg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.00155"
  },
  {
    "id": "arXiv:2205.00218",
    "title": "Distributed exponential state estimation of linear systems over jointly  connected switching networks",
    "abstract": "Distributed exponential state estimation of linear systems over jointly  connected switching networks",
    "descriptor": "",
    "authors": [
      "Tao Liu",
      "Jie Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.00218"
  },
  {
    "id": "arXiv:2205.01858",
    "title": "DeeptDCS: Deep Learning-Based Estimation of Currents Induced During  Transcranial Direct Current Stimulation",
    "abstract": "DeeptDCS: Deep Learning-Based Estimation of Currents Induced During  Transcranial Direct Current Stimulation",
    "descriptor": "",
    "authors": [
      "Xiaofan Jia",
      "Sadeed Bin Sayed",
      "Nahian Ibn Hasan",
      "Luis J. Gomez",
      "Guang-Bin Huang",
      "Abdulkadir C. Yucel"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01858"
  },
  {
    "id": "arXiv:2205.01902",
    "title": "Pik-Fix: Restoring and Colorizing Old Photos",
    "abstract": "Comments: WACV 2022; code: this https URL arXiv admin note: text overlap with arXiv:2202.02606",
    "descriptor": "\nComments: WACV 2022; code: this https URL arXiv admin note: text overlap with arXiv:2202.02606\n",
    "authors": [
      "Runsheng Xu",
      "Zhengzhong Tu",
      "Yuanqi Du",
      "Xiaoyu Dong",
      "Jinlong Li",
      "Zibo Meng",
      "Jiaqi Ma",
      "Alan Bovik",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01902"
  },
  {
    "id": "arXiv:2205.02668",
    "title": "A Market for Trading Forecasts: A Wagering Mechanism",
    "abstract": "A Market for Trading Forecasts: A Wagering Mechanism",
    "descriptor": "",
    "authors": [
      "Aitazaz Ali Raja",
      "Pierre Pinson",
      "Jalal Kazempour",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.02668"
  },
  {
    "id": "arXiv:2205.04547",
    "title": "Machine Learning Diffusion Monte Carlo Energies",
    "abstract": "Machine Learning Diffusion Monte Carlo Energies",
    "descriptor": "",
    "authors": [
      "Kevin Ryczko",
      "Jaron T. Krogel",
      "Isaac Tamblyn"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.04547"
  },
  {
    "id": "arXiv:2205.05507",
    "title": "TextMatcher: Cross-Attentional Neural Network to Compare Image and Text",
    "abstract": "Comments: Accepted at the 25th International Conference on Discovery Science 2022, 15 pages",
    "descriptor": "\nComments: Accepted at the 25th International Conference on Discovery Science 2022, 15 pages\n",
    "authors": [
      "Valentina Arrigoni",
      "Luisa Repele",
      "Dario Marino Saccavino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05507"
  },
  {
    "id": "arXiv:2205.06926",
    "title": "Toward a Geometrical Understanding of Self-supervised Contrastive  Learning",
    "abstract": "Toward a Geometrical Understanding of Self-supervised Contrastive  Learning",
    "descriptor": "",
    "authors": [
      "Romain Cosentino",
      "Anirvan Sengupta",
      "Salman Avestimehr",
      "Mahdi Soltanolkotabi",
      "Antonio Ortega",
      "Ted Willke",
      "Mariano Tepper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.06926"
  },
  {
    "id": "arXiv:2205.07087",
    "title": "Pattern reconstruction with restricted Boltzmann machines",
    "abstract": "Pattern reconstruction with restricted Boltzmann machines",
    "descriptor": "",
    "authors": [
      "Giuseppe Genovese"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07087"
  },
  {
    "id": "arXiv:2205.08780",
    "title": "Visual Attention-based Self-supervised Absolute Depth Estimation using  Geometric Priors in Autonomous Driving",
    "abstract": "Comments: Published on IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: Published on IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Jie Xiang",
      "Yun Wang",
      "Lifeng An",
      "Haiyang Liu",
      "Zijun Wang",
      "Jian Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.08780"
  },
  {
    "id": "arXiv:2205.09867",
    "title": "Gender Bias in Meta-Embeddings",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Masahiro Kaneko",
      "Danushka Bollegala",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09867"
  },
  {
    "id": "arXiv:2205.10625",
    "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language  Models",
    "abstract": "Least-to-Most Prompting Enables Complex Reasoning in Large Language  Models",
    "descriptor": "",
    "authors": [
      "Denny Zhou",
      "Nathanael Sch\u00e4rli",
      "Le Hou",
      "Jason Wei",
      "Nathan Scales",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Claire Cui",
      "Olivier Bousquet",
      "Quoc Le",
      "Ed Chi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10625"
  },
  {
    "id": "arXiv:2205.11396",
    "title": "Cross-mode Stabilized Stochastic Shallow Water Systems Using Stochastic  Finite Element Methods",
    "abstract": "Cross-mode Stabilized Stochastic Shallow Water Systems Using Stochastic  Finite Element Methods",
    "descriptor": "",
    "authors": [
      "Chen Chen",
      "Clint Dawson",
      "Eirik Valseth"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.11396"
  },
  {
    "id": "arXiv:2205.12548",
    "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
    "abstract": "Comments: EMNLP 2022. Code available at this https URL",
    "descriptor": "\nComments: EMNLP 2022. Code available at this https URL\n",
    "authors": [
      "Mingkai Deng",
      "Jianyu Wang",
      "Cheng-Ping Hsieh",
      "Yihan Wang",
      "Han Guo",
      "Tianmin Shu",
      "Meng Song",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12548"
  },
  {
    "id": "arXiv:2205.12569",
    "title": "Towards a Fair Comparison and Realistic Evaluation Framework of Android  Malware Detectors based on Static Analysis and Machine Learning",
    "abstract": "Towards a Fair Comparison and Realistic Evaluation Framework of Android  Malware Detectors based on Static Analysis and Machine Learning",
    "descriptor": "",
    "authors": [
      "Borja Molina-Coronado",
      "Usue Mori",
      "Alexander Mendiburu",
      "Jose Miguel-Alonso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.12569"
  },
  {
    "id": "arXiv:2205.13349",
    "title": "Learning What and Where -- Unsupervised Disentangling Location and  Identity Tracking",
    "abstract": "Learning What and Where -- Unsupervised Disentangling Location and  Identity Tracking",
    "descriptor": "",
    "authors": [
      "Manuel Traub",
      "Sebastian Otte",
      "Tobias Menge",
      "Matthias Karlbauer",
      "Jannik Th\u00fcmmel",
      "Martin V. Butz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13349"
  },
  {
    "id": "arXiv:2205.13613",
    "title": "Circumventing Backdoor Defenses That Are Based on Latent Separability",
    "abstract": "Circumventing Backdoor Defenses That Are Based on Latent Separability",
    "descriptor": "",
    "authors": [
      "Xiangyu Qi",
      "Tinghao Xie",
      "Yiming Li",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13613"
  },
  {
    "id": "arXiv:2205.14276",
    "title": "So3krates: Equivariant attention for interactions on arbitrary  length-scales in molecular systems",
    "abstract": "So3krates: Equivariant attention for interactions on arbitrary  length-scales in molecular systems",
    "descriptor": "",
    "authors": [
      "J. Thorben Frank",
      "Oliver T. Unke",
      "Klaus-Robert M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14276"
  },
  {
    "id": "arXiv:2205.14332",
    "title": "V4D: Voxel for 4D Novel View Synthesis",
    "abstract": "V4D: Voxel for 4D Novel View Synthesis",
    "descriptor": "",
    "authors": [
      "Wanshui Gan",
      "Hongbin Xu",
      "Yi Huang",
      "Shifeng Chen",
      "Naoto Yokoya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14332"
  },
  {
    "id": "arXiv:2205.14428",
    "title": "Go Beyond Multiple Instance Neural Networks: Deep-learning Models based  on Local Pattern Aggregation",
    "abstract": "Go Beyond Multiple Instance Neural Networks: Deep-learning Models based  on Local Pattern Aggregation",
    "descriptor": "",
    "authors": [
      "Linpeng Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14428"
  },
  {
    "id": "arXiv:2205.15701",
    "title": "Provable General Function Class Representation Learning in Multitask  Bandits and MDPs",
    "abstract": "Provable General Function Class Representation Learning in Multitask  Bandits and MDPs",
    "descriptor": "",
    "authors": [
      "Rui Lu",
      "Andrew Zhao",
      "Simon S. Du",
      "Gao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15701"
  },
  {
    "id": "arXiv:2206.01366",
    "title": "Supernet Training for Federated Image Classification under System  Heterogeneity",
    "abstract": "Comments: Oral paper on ICML 22 Workshop: \"Dynamic Neural Networks\"; Under review",
    "descriptor": "\nComments: Oral paper on ICML 22 Workshop: \"Dynamic Neural Networks\"; Under review\n",
    "authors": [
      "Taehyeon Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01366"
  },
  {
    "id": "arXiv:2206.01563",
    "title": "Optimal Weak to Strong Learning",
    "abstract": "Optimal Weak to Strong Learning",
    "descriptor": "",
    "authors": [
      "Kasper Green Larsen",
      "Martin Ritzert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01563"
  },
  {
    "id": "arXiv:2206.04572",
    "title": "Log-Concave and Multivariate Canonical Noise Distributions for  Differential Privacy",
    "abstract": "Comments: 10 pages before references, 1 Figure",
    "descriptor": "\nComments: 10 pages before references, 1 Figure\n",
    "authors": [
      "Jordan Awan",
      "Jinshuo Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.04572"
  },
  {
    "id": "arXiv:2206.06119",
    "title": "Satellite-based high-resolution maps of cocoa for C\u00f4te d'Ivoire and  Ghana",
    "abstract": "Satellite-based high-resolution maps of cocoa for C\u00f4te d'Ivoire and  Ghana",
    "descriptor": "",
    "authors": [
      "Nikolai Kalischek",
      "Nico Lang",
      "C\u00e9cile Renier",
      "Rodrigo Caye Daudt",
      "Thomas Addoah",
      "William Thompson",
      "Wilma J. Blaser-Hart",
      "Rachael Garrett",
      "Konrad Schindler",
      "Jan D. Wegner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06119"
  },
  {
    "id": "arXiv:2206.07760",
    "title": "Multiscale methods for signal selection in single-cell data",
    "abstract": "Comments: 32 pages, 15 figures, 1 table. Revised and published in Entropy, special issue Applications of Topological Data Analysis in the Life Sciences",
    "descriptor": "\nComments: 32 pages, 15 figures, 1 table. Revised and published in Entropy, special issue Applications of Topological Data Analysis in the Life Sciences\n",
    "authors": [
      "Renee S. Hoekzema",
      "Lewis Marsh",
      "Otto Sumray",
      "Thomas M. Carroll",
      "Xin Lu",
      "Helen M. Byrne",
      "Heather A. Harrington"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Spectral Theory (math.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07760"
  },
  {
    "id": "arXiv:2206.08287",
    "title": "Definition drives design: Disability models and mechanisms of bias in AI  technologies",
    "abstract": "Comments: 36 pages, 1 figure, 2 tables. Keywords: artificial intelligence; critical disability studies; information and communication technologies; data analytics; data science; fairness, accountability, transparency, and ethics",
    "descriptor": "\nComments: 36 pages, 1 figure, 2 tables. Keywords: artificial intelligence; critical disability studies; information and communication technologies; data analytics; data science; fairness, accountability, transparency, and ethics\n",
    "authors": [
      "Denis Newman-Griffis",
      "Jessica Sage Rauchberg",
      "Rahaf Alharbi",
      "Louise Hickman",
      "Harry Hochheiser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.08287"
  },
  {
    "id": "arXiv:2206.09120",
    "title": "Pursuit of a Discriminative Representation for Multiple Subspaces via  Sequential Games",
    "abstract": "Comments: main body is 16 pages and has 5 figures; appendix is 17 pages and has 6 figures",
    "descriptor": "\nComments: main body is 16 pages and has 5 figures; appendix is 17 pages and has 6 figures\n",
    "authors": [
      "Druv Pai",
      "Michael Psenka",
      "Chih-Yuan Chiu",
      "Manxi Wu",
      "Edgar Dobriban",
      "Yi Ma"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09120"
  },
  {
    "id": "arXiv:2206.10561",
    "title": "Fair Queuing Aware Congestion Control",
    "abstract": "Fair Queuing Aware Congestion Control",
    "descriptor": "",
    "authors": [
      "Maximilian Bachl"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.10561"
  },
  {
    "id": "arXiv:2206.11198",
    "title": "General Univariate Estimation-of-Distribution Algorithms",
    "abstract": "Comments: Conference version with missing proofs in the appendix",
    "descriptor": "\nComments: Conference version with missing proofs in the appendix\n",
    "authors": [
      "Benjamin Doerr",
      "Marc Dufay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11198"
  },
  {
    "id": "arXiv:2206.11233",
    "title": "Automatic autism spectrum disorder detection using artificial  intelligence methods with MRI neuroimaging: A review",
    "abstract": "Automatic autism spectrum disorder detection using artificial  intelligence methods with MRI neuroimaging: A review",
    "descriptor": "",
    "authors": [
      "Parisa Moridian",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Salam Salloum-Asfar",
      "Delaram Sadeghi",
      "Marjane Khodatars",
      "Afshin Shoeibi",
      "Abbas Khosravi",
      "Sai Ho Ling",
      "Abdulhamit Subasi",
      "Roohallah Alizadehsani",
      "Juan M. Gorriz",
      "Sara A Abdulla",
      "U. Rajendra Acharya"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.11233"
  },
  {
    "id": "arXiv:2206.11346",
    "title": "Constrained Stochastic Nonconvex Optimization with State-dependent  Markov Data",
    "abstract": "Comments: 2 figures",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Abhishek Roy",
      "Krishnakumar Balasubramanian",
      "Saeed Ghadimi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11346"
  },
  {
    "id": "arXiv:2206.11834",
    "title": "Non-Determinism and the Lawlessness of Machine Learning Code",
    "abstract": "Comments: Proceedings of the 2022 Symposium on Computer Science and Law (CSLAW '22)",
    "descriptor": "\nComments: Proceedings of the 2022 Symposium on Computer Science and Law (CSLAW '22)\n",
    "authors": [
      "A. Feder Cooper",
      "Jonathan Frankle",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11834"
  },
  {
    "id": "arXiv:2206.14666",
    "title": "Conditionally Elicitable Dynamic Risk Measures for Deep Reinforcement  Learning",
    "abstract": "Comments: 40 pages, 7 figures",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Anthony Coache",
      "Sebastian Jaimungal",
      "\u00c1lvaro Cartea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2206.14666"
  },
  {
    "id": "arXiv:2207.01145",
    "title": "Populating Memory in Continual Learning with Consistency Aware Sampling",
    "abstract": "Populating Memory in Continual Learning with Consistency Aware Sampling",
    "descriptor": "",
    "authors": [
      "Julio Hurtado",
      "Alain Raymond-Saez",
      "Vladimir Araujo",
      "Vincenzo Lomonaco",
      "Alvaro Soto",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01145"
  },
  {
    "id": "arXiv:2207.01567",
    "title": "Back to MLP: A Simple Baseline for Human Motion Prediction",
    "abstract": "Comments: Accepted to WACV 2023; Code available at this https URL",
    "descriptor": "\nComments: Accepted to WACV 2023; Code available at this https URL\n",
    "authors": [
      "Wen Guo",
      "Yuming Du",
      "Xi Shen",
      "Vincent Lepetit",
      "Xavier Alameda-Pineda",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01567"
  },
  {
    "id": "arXiv:2207.02098",
    "title": "Neural Networks and the Chomsky Hierarchy",
    "abstract": "Neural Networks and the Chomsky Hierarchy",
    "descriptor": "",
    "authors": [
      "Gr\u00e9goire Del\u00e9tang",
      "Anian Ruoss",
      "Jordi Grau-Moya",
      "Tim Genewein",
      "Li Kevin Wenliang",
      "Elliot Catt",
      "Chris Cundy",
      "Marcus Hutter",
      "Shane Legg",
      "Joel Veness",
      "Pedro A. Ortega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.02098"
  },
  {
    "id": "arXiv:2207.03881",
    "title": "The Power of Transfer Learning in Agricultural Applications: AgriNet",
    "abstract": "Comments: Accepted by Frontiers in Plant Science",
    "descriptor": "\nComments: Accepted by Frontiers in Plant Science\n",
    "authors": [
      "Zahraa Al Sahili",
      "Mariette Awad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03881"
  },
  {
    "id": "arXiv:2207.05480",
    "title": "Temporal Disentanglement of Representations for Improved Generalisation  in Reinforcement Learning",
    "abstract": "Temporal Disentanglement of Representations for Improved Generalisation  in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Mhairi Dunion",
      "Trevor McInroe",
      "Kevin Sebastian Luck",
      "Josiah Hanna",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05480"
  },
  {
    "id": "arXiv:2207.05987",
    "title": "DocPrompting: Generating Code by Retrieving the Docs",
    "abstract": "DocPrompting: Generating Code by Retrieving the Docs",
    "descriptor": "",
    "authors": [
      "Shuyan Zhou",
      "Uri Alon",
      "Frank F. Xu",
      "Zhiruo Wang",
      "Zhengbao Jiang",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.05987"
  },
  {
    "id": "arXiv:2207.06224",
    "title": "Beyond Hard Labels: Investigating data label distributions",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Vasco Grossmann",
      "Lars Schmarje",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06224"
  },
  {
    "id": "arXiv:2207.06283",
    "title": "Implicit Neural Representations for Generative Modeling of Living Cell  Shapes",
    "abstract": "Comments: MICCAI 2022",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "David Wiesner",
      "Julian Suk",
      "Sven Dummer",
      "David Svoboda",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06283"
  },
  {
    "id": "arXiv:2207.06374",
    "title": "Grassmannian packings: Trust-region stochastic tuning for matrix  incoherence",
    "abstract": "Comments: Accepted in 58th Annual Allerton Conference Proceedings",
    "descriptor": "\nComments: Accepted in 58th Annual Allerton Conference Proceedings\n",
    "authors": [
      "Josiah Park",
      "Carlos Saltijeral",
      "Ming Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2207.06374"
  },
  {
    "id": "arXiv:2207.09185",
    "title": "Multimodal hierarchical Variational AutoEncoders with Factor Analysis  latent space",
    "abstract": "Comments: 21 pages main work, 2 pages supplementary, 14 figures",
    "descriptor": "\nComments: 21 pages main work, 2 pages supplementary, 14 figures\n",
    "authors": [
      "Alejandro Guerrero-L\u00f3pez",
      "Carlos Sevilla-Salcedo",
      "Vanessa G\u00f3mez-Verdejo",
      "Pablo M. Olmos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09185"
  },
  {
    "id": "arXiv:2207.09542",
    "title": "Controllable Data Generation by Deep Learning: A Review",
    "abstract": "Controllable Data Generation by Deep Learning: A Review",
    "descriptor": "",
    "authors": [
      "Shiyu Wang",
      "Yuanqi Du",
      "Xiaojie Guo",
      "Bo Pan",
      "Zhaohui Qin",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09542"
  },
  {
    "id": "arXiv:2207.10960",
    "title": "Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)",
    "abstract": "Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)",
    "descriptor": "",
    "authors": [
      "Mathieu Pont",
      "Jules Vidal",
      "Julien Tierny"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10960"
  },
  {
    "id": "arXiv:2207.10970",
    "title": "Opportunistic hip fracture risk prediction in Men from X-ray: Findings  from the Osteoporosis in Men (MrOS) Study",
    "abstract": "Comments: Oral Presentation at MICCAI 2022 Workshop (PRIME), Considered for best paper award Predictive Intelligence in Medicine. PRIME 2022. Lecture Notes in Computer Science, vol 13564",
    "descriptor": "\nComments: Oral Presentation at MICCAI 2022 Workshop (PRIME), Considered for best paper award Predictive Intelligence in Medicine. PRIME 2022. Lecture Notes in Computer Science, vol 13564\n",
    "authors": [
      "Lars Schmarje",
      "Stefan Reinhold",
      "Timo Damm",
      "Eric Orwoll",
      "Claus-C. Gl\u00fcer",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10970"
  },
  {
    "id": "arXiv:2207.11784",
    "title": "CARGO: AI-Guided Dependency Analysis for Migrating Monolithic  Applications to Microservices Architecture",
    "abstract": "Comments: ACM Distinguished Paper ASE '22, October 10-14, 2022, Ann Arbor, MI, USA",
    "descriptor": "\nComments: ACM Distinguished Paper ASE '22, October 10-14, 2022, Ann Arbor, MI, USA\n",
    "authors": [
      "Vikram Nitin",
      "Shubhi Asthana",
      "Baishakhi Ray",
      "Rahul Krishna"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11784"
  },
  {
    "id": "arXiv:2207.11832",
    "title": "New Additive Spanner Lower Bounds by an Unlayered Obstacle Product",
    "abstract": "Comments: FOCS 2022, fixed Definition 3",
    "descriptor": "\nComments: FOCS 2022, fixed Definition 3\n",
    "authors": [
      "Greg Bodwin",
      "Gary Hoppenworth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.11832"
  },
  {
    "id": "arXiv:2207.13283",
    "title": "INTERACT: Achieving Low Sample and Communication Complexities in  Decentralized Bilevel Learning over Networks",
    "abstract": "INTERACT: Achieving Low Sample and Communication Complexities in  Decentralized Bilevel Learning over Networks",
    "descriptor": "",
    "authors": [
      "Zhuqing Liu",
      "Xin Zhang",
      "Prashant Khanduri",
      "Songtao Lu",
      "Jia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.13283"
  },
  {
    "id": "arXiv:2207.14550",
    "title": "Best-of-Both-Worlds Algorithms for Partial Monitoring",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Taira Tsuchiya",
      "Shinji Ito",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.14550"
  },
  {
    "id": "arXiv:2208.02788",
    "title": "Continuous guts poker and numerical optimization of generalized  recursive games",
    "abstract": "Continuous guts poker and numerical optimization of generalized  recursive games",
    "descriptor": "",
    "authors": [
      "Kevin Buck",
      "Jae Hwan Lee",
      "Jacob Platnick",
      "Aric Wheeler",
      "Kevin Zumbrun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.02788"
  },
  {
    "id": "arXiv:2208.02947",
    "title": "Joint Attention-Driven Domain Fusion and Noise-Tolerant Learning for  Multi-Source Domain Adaptation",
    "abstract": "Joint Attention-Driven Domain Fusion and Noise-Tolerant Learning for  Multi-Source Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Tong Xu",
      "Lin Wang",
      "Wu Ning",
      "Chunyan Lyu",
      "Kejun Wang",
      "Chenhui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.02947"
  },
  {
    "id": "arXiv:2208.03650",
    "title": "A Game-Theoretic Perspective of Generalization in Reinforcement Learning",
    "abstract": "A Game-Theoretic Perspective of Generalization in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Chang Yang",
      "Ruiyu Wang",
      "Xinrun Wang",
      "Zhen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.03650"
  },
  {
    "id": "arXiv:2208.04933",
    "title": "Simplified State Space Layers for Sequence Modeling",
    "abstract": "Simplified State Space Layers for Sequence Modeling",
    "descriptor": "",
    "authors": [
      "Jimmy T.H. Smith",
      "Andrew Warrington",
      "Scott W. Linderman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.04933"
  },
  {
    "id": "arXiv:2208.07261",
    "title": "Bias amplification in experimental social networks is reduced by  resampling",
    "abstract": "Bias amplification in experimental social networks is reduced by  resampling",
    "descriptor": "",
    "authors": [
      "Mathew D. Hardy",
      "Bill D. Thompson",
      "P.M. Krafft",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07261"
  },
  {
    "id": "arXiv:2208.07655",
    "title": "A Hybrid Deep Feature-Based Deformable Image Registration Method for  Pathological Images",
    "abstract": "Comments: 23 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 23 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chulong Zhang",
      "Yuming Jiang",
      "Na Li",
      "Zhicheng Zhang",
      "Md Tauhidul Islam",
      "Jingjing Dai",
      "Lin Liu",
      "Wenfeng He",
      "Wenjian Qin",
      "Jing Xiong",
      "Yaoqin Xie",
      "Xiaokun Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.07655"
  },
  {
    "id": "arXiv:2208.08225",
    "title": "On the Role of Negative Precedent in Legal Outcome Prediction",
    "abstract": "On the Role of Negative Precedent in Legal Outcome Prediction",
    "descriptor": "",
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell",
      "Simone Teufel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08225"
  },
  {
    "id": "arXiv:2208.09796",
    "title": "Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train  Humans in Lipreading at Scale",
    "abstract": "Comments: Accepted at WACV 2023",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Aditya Agarwal",
      "Bipasha Sen",
      "Rudrabha Mukhopadhyay",
      "Vinay Namboodiri",
      "C.V Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09796"
  },
  {
    "id": "arXiv:2208.10967",
    "title": "The Value of Out-of-Distribution Data",
    "abstract": "Comments: To be presented as a short paper at the Out-of-Distribution Generalization in Computer Vision (OOD-CV) workshop, ECCV 2022, Tel Aviv, Israel",
    "descriptor": "\nComments: To be presented as a short paper at the Out-of-Distribution Generalization in Computer Vision (OOD-CV) workshop, ECCV 2022, Tel Aviv, Israel\n",
    "authors": [
      "Ashwin De Silva",
      "Rahul Ramesh",
      "Carey E. Priebe",
      "Pratik Chaudhari",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.10967"
  },
  {
    "id": "arXiv:2208.14681",
    "title": "When Variable-Length Codes Meet the Field of Error Detection",
    "abstract": "When Variable-Length Codes Meet the Field of Error Detection",
    "descriptor": "",
    "authors": [
      "Jean N\u00e9raud"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.14681"
  },
  {
    "id": "arXiv:2209.01198",
    "title": "Estimation of Correlation Matrices from Limited time series Data using  Machine Learning",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Nikhil Easaw",
      "Woo Soek Lee",
      "Prashant Singh Lohiya",
      "Sarika Jalan",
      "Priodyuti Pradhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.01198"
  },
  {
    "id": "arXiv:2209.02550",
    "title": "Efficient search of active inference policy spaces using k-means",
    "abstract": "Comments: Code available on Github, results in appendix. This version: fixes typos, phrasing; final submitted version",
    "descriptor": "\nComments: Code available on Github, results in appendix. This version: fixes typos, phrasing; final submitted version\n",
    "authors": [
      "Alex B. Kiefer",
      "Mahault Albarracin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.02550"
  },
  {
    "id": "arXiv:2209.02970",
    "title": "Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence",
    "abstract": "Comments: Added the Chinese version and is now a bilingual paper",
    "descriptor": "\nComments: Added the Chinese version and is now a bilingual paper\n",
    "authors": [
      "Junjie Wang",
      "Yuxiang Zhang",
      "Lin Zhang",
      "Ping Yang",
      "Xinyu Gao",
      "Ziwei Wu",
      "Xiaoqun Dong",
      "Junqing He",
      "Jianheng Zhuo",
      "Qi Yang",
      "Yongfeng Huang",
      "Xiayu Li",
      "Yanghan Wu",
      "Junyu Lu",
      "Xinyu Zhu",
      "Weifeng Chen",
      "Ting Han",
      "Kunhao Pan",
      "Rui Wang",
      "Hao Wang",
      "Xiaojun Wu",
      "Zhongshen Zeng",
      "Chongpei Chen",
      "Ruyi Gan",
      "Jiaxing Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.02970"
  },
  {
    "id": "arXiv:2209.03791",
    "title": "Applying Transformer-based Text Summarization for Keyphrase Generation",
    "abstract": "Comments: 15 pages, 4 figures. DAMDID-2022",
    "descriptor": "\nComments: 15 pages, 4 figures. DAMDID-2022\n",
    "authors": [
      "Anna Glazkova",
      "Dmitry Morozov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03791"
  },
  {
    "id": "arXiv:2209.04747",
    "title": "Diffusion Models in Vision: A Survey",
    "abstract": "Comments: 20 pages, 3 figures",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Florinel-Alin Croitoru",
      "Vlad Hondru",
      "Radu Tudor Ionescu",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04747"
  },
  {
    "id": "arXiv:2209.04825",
    "title": "Rethink Decision Tree Traversal",
    "abstract": "Rethink Decision Tree Traversal",
    "descriptor": "",
    "authors": [
      "Jinxiong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.04825"
  },
  {
    "id": "arXiv:2209.06049",
    "title": "Pre-training Transformers on Indian Legal Text",
    "abstract": "Pre-training Transformers on Indian Legal Text",
    "descriptor": "",
    "authors": [
      "Shounak Paul",
      "Arpan Mandal",
      "Pawan Goyal",
      "Saptarshi Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06049"
  },
  {
    "id": "arXiv:2209.06394",
    "title": "Classical Sequence Match is a Competitive Few-Shot One-Class Learner",
    "abstract": "Comments: COLING 2022; Added a missing citation compared with the last version",
    "descriptor": "\nComments: COLING 2022; Added a missing citation compared with the last version\n",
    "authors": [
      "Mengting Hu",
      "Hang Gao",
      "Yinhao Bai",
      "Mingming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06394"
  },
  {
    "id": "arXiv:2209.07157",
    "title": "On the detrimental effect of invariances in the likelihood for  variational inference",
    "abstract": "On the detrimental effect of invariances in the likelihood for  variational inference",
    "descriptor": "",
    "authors": [
      "Richard Kurle",
      "Ralf Herbrich",
      "Tim Januschowski",
      "Yuyang Wang",
      "Jan Gasthaus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07157"
  },
  {
    "id": "arXiv:2209.07474",
    "title": "On the Surprising Effectiveness of Transformers in Low-Labeled Video  Recognition",
    "abstract": "On the Surprising Effectiveness of Transformers in Low-Labeled Video  Recognition",
    "descriptor": "",
    "authors": [
      "Farrukh Rahman",
      "\u00d6mer Mubarek",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07474"
  },
  {
    "id": "arXiv:2209.07603",
    "title": "Hub-aware Random Walk Graph Embedding Methods for Classification",
    "abstract": "Comments: Submitted to journal for possible publication",
    "descriptor": "\nComments: Submitted to journal for possible publication\n",
    "authors": [
      "Aleksandar Tom\u010di\u0107",
      "Milo\u0161 Savi\u0107",
      "Milo\u0161 Radovanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.07603"
  },
  {
    "id": "arXiv:2209.08627",
    "title": "Is Stochastic Gradient Descent Near Optimal?",
    "abstract": "Is Stochastic Gradient Descent Near Optimal?",
    "descriptor": "",
    "authors": [
      "Yifan Zhu",
      "Hong Jun Jeon",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08627"
  },
  {
    "id": "arXiv:2209.10767",
    "title": "DRAMA: Joint Risk Localization and Captioning in Driving",
    "abstract": "Comments: WACV 2023 (Winter Conference on Applications of Computer Vision)",
    "descriptor": "\nComments: WACV 2023 (Winter Conference on Applications of Computer Vision)\n",
    "authors": [
      "Srikanth Malla",
      "Chiho Choi",
      "Isht Dwivedi",
      "Joon Hee Choi",
      "Jiachen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.10767"
  },
  {
    "id": "arXiv:2209.10930",
    "title": "MGTR: End-to-End Mutual Gaze Detection with Transformer",
    "abstract": "Comments: ACCV2022 accepted paper",
    "descriptor": "\nComments: ACCV2022 accepted paper\n",
    "authors": [
      "Hang Guo",
      "Zhengxi Hu",
      "Jingtai Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10930"
  },
  {
    "id": "arXiv:2209.13226",
    "title": "Optimization of Annealed Importance Sampling Hyperparameters",
    "abstract": "Optimization of Annealed Importance Sampling Hyperparameters",
    "descriptor": "",
    "authors": [
      "Shirin Goshtasbpour",
      "Fernando Perez-Cruz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13226"
  },
  {
    "id": "arXiv:2209.13232",
    "title": "A Survey on Graph Neural Networks and Graph Transformers in Computer  Vision: A Task-Oriented Perspective",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Chaoqi Chen",
      "Yushuang Wu",
      "Qiyuan Dai",
      "Hong-Yu Zhou",
      "Mutian Xu",
      "Sibei Yang",
      "Xiaoguang Han",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13232"
  },
  {
    "id": "arXiv:2209.13258",
    "title": "OSDP: Optimal Sharded Data Parallel for Distributed Deep Learning",
    "abstract": "OSDP: Optimal Sharded Data Parallel for Distributed Deep Learning",
    "descriptor": "",
    "authors": [
      "Youhe Jiang",
      "Xupeng Miao",
      "Xiaonan Nie",
      "Bin Cui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.13258"
  },
  {
    "id": "arXiv:2209.13667",
    "title": "Robust MADER: Decentralized and Asynchronous Multiagent Trajectory  Planner Robust to Communication Delay",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Kota Kondo",
      "Jesus Tordesillas",
      "Reinaldo Figueroa",
      "Juan Rached",
      "Joseph Merkel",
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.13667"
  },
  {
    "id": "arXiv:2209.14171",
    "title": "Programmable and Customized Intelligence for Traffic Steering in 5G  Networks Using Open RAN Architectures",
    "abstract": "Comments: 15 pages, 2 algorithms, 1 table, 11 figures, 42 references",
    "descriptor": "\nComments: 15 pages, 2 algorithms, 1 table, 11 figures, 42 references\n",
    "authors": [
      "Andrea Lacava",
      "Michele Polese",
      "Rajarajan Sivaraj",
      "Rahul Soundrarajan",
      "Bhawani Shanker Bhati",
      "Tarunjeet Singh",
      "Tommaso Zugno",
      "Francesca Cuomo",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.14171"
  },
  {
    "id": "arXiv:2209.14406",
    "title": "Biological connectomes as a representation for the architecture of  artificial neural networks",
    "abstract": "Biological connectomes as a representation for the architecture of  artificial neural networks",
    "descriptor": "",
    "authors": [
      "Samuel Schmidgall",
      "Catherine Schuman",
      "Maryam Parsa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14406"
  },
  {
    "id": "arXiv:2209.14529",
    "title": "Motion and Appearance Adaptation for Cross-Domain Motion Transfer",
    "abstract": "Comments: fix bugs",
    "descriptor": "\nComments: fix bugs\n",
    "authors": [
      "Borun Xu",
      "Biao Wang",
      "Jinhong Deng",
      "Jiale Tao",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.14529"
  },
  {
    "id": "arXiv:2209.14647",
    "title": "Bounded Future MS-TCN++ for surgical gesture recognition",
    "abstract": "Comments: 17 pages, 7 figures, 1 table, Accepted to ECCV-MCV",
    "descriptor": "\nComments: 17 pages, 7 figures, 1 table, Accepted to ECCV-MCV\n",
    "authors": [
      "Adam Goldbraikh",
      "Netanell Avisdris",
      "Carla M. Pugh",
      "Shlomi Laufer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.14647"
  },
  {
    "id": "arXiv:2209.14914",
    "title": "Quantum invariants for the graph isomorphism problem",
    "abstract": "Quantum invariants for the graph isomorphism problem",
    "descriptor": "",
    "authors": [
      "Hern\u00e1n I. de la Cruz",
      "Fernando L. Pelayo",
      "Vicente Pascual",
      "Jose J. Paulet",
      "Fernando Cuartero",
      "Luis Llana",
      "Mauro Mezzini"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2209.14914"
  },
  {
    "id": "arXiv:2209.14981",
    "title": "Stop Wasting My Time! Saving Days of ImageNet and BERT Training with  Latest Weight Averaging",
    "abstract": "Stop Wasting My Time! Saving Days of ImageNet and BERT Training with  Latest Weight Averaging",
    "descriptor": "",
    "authors": [
      "Jean Kaddour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.14981"
  },
  {
    "id": "arXiv:2209.15111",
    "title": "Quantifying Harm",
    "abstract": "Comments: 17 pages, under submission",
    "descriptor": "\nComments: 17 pages, under submission\n",
    "authors": [
      "Sander Beckers",
      "Hana Chockler",
      "Joseph Y. Halpern"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.15111"
  },
  {
    "id": "arXiv:2209.15159",
    "title": "MobileViTv3: Mobile-Friendly Vision Transformer with Simple and  Effective Fusion of Local, Global and Input Features",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Shakti N. Wadekar",
      "Abhishek Chaurasia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15159"
  },
  {
    "id": "arXiv:2209.15439",
    "title": "Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain  Supervision for Domain-adaptive Action Detection",
    "abstract": "Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain  Supervision for Domain-adaptive Action Detection",
    "descriptor": "",
    "authors": [
      "Yifan Lu",
      "Gurkirt Singh",
      "Suman Saha",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15439"
  },
  {
    "id": "arXiv:2209.15589",
    "title": "Where Should I Spend My FLOPS? Efficiency Evaluations of Visual  Pre-training Methods",
    "abstract": "Where Should I Spend My FLOPS? Efficiency Evaluations of Visual  Pre-training Methods",
    "descriptor": "",
    "authors": [
      "Skanda Koppula",
      "Yazhe Li",
      "Evan Shelhamer",
      "Andrew Jaegle",
      "Nikhil Parthasarathy",
      "Relja Arandjelovic",
      "Jo\u00e3o Carreira",
      "Olivier H\u00e9naff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15589"
  },
  {
    "id": "arXiv:2210.00440",
    "title": "Grouped self-attention mechanism for a memory-efficient Transformer",
    "abstract": "Comments: 10 pages, 3 figures, under review as a conference paper at ICLR 2023",
    "descriptor": "\nComments: 10 pages, 3 figures, under review as a conference paper at ICLR 2023\n",
    "authors": [
      "Bumjun Jung",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00440"
  },
  {
    "id": "arXiv:2210.00482",
    "title": "Compositional Generalization in Unsupervised Compositional  Representation Learning: A Study on Disentanglement and Emergent Language",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhenlin Xu",
      "Marc Niethammer",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00482"
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": "Comments: This paper is the full version of a paper to appear in CCS 2022",
    "descriptor": "\nComments: This paper is the full version of a paper to appear in CCS 2022\n",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00486"
  },
  {
    "id": "arXiv:2210.00562",
    "title": "RISC-V Toolchain and Agile Development based Open-source Neuromorphic  Processor",
    "abstract": "Comments: Corrected and updated",
    "descriptor": "\nComments: Corrected and updated\n",
    "authors": [
      "Jiulong Wang",
      "Ruopu Wu",
      "Guokai Chen",
      "Xuhao Chen",
      "Boran Liu",
      "Jixiang Zong",
      "Di Zhao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00562"
  },
  {
    "id": "arXiv:2210.00721",
    "title": "Efficient acoustic feature transformation in mismatched environments  using a Guided-GAN",
    "abstract": "Comments: Final published version available at: Efficient acoustic feature transformation in mismatched environments using a Guided-GAN. Speech Communication, 143, pp.10-20",
    "descriptor": "\nComments: Final published version available at: Efficient acoustic feature transformation in mismatched environments using a Guided-GAN. Speech Communication, 143, pp.10-20\n",
    "authors": [
      "Walter Heymans",
      "Marelie H. Davel",
      "Charl van Heerden"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.00721"
  },
  {
    "id": "arXiv:2210.00747",
    "title": "Stochastic optimization of a mixed moving average process for  controlling non-Markovian streamflow environments",
    "abstract": "Stochastic optimization of a mixed moving average process for  controlling non-Markovian streamflow environments",
    "descriptor": "",
    "authors": [
      "Hidekazu Yoshioka",
      "Tomohiro Tanaka",
      "Yumi Yoshioka",
      "Ayumi Hashiguchi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00747"
  },
  {
    "id": "arXiv:2210.00805",
    "title": "Limitations of neural network training due to numerical instability of  backpropagation",
    "abstract": "Limitations of neural network training due to numerical instability of  backpropagation",
    "descriptor": "",
    "authors": [
      "Clemens Karner",
      "Vladimir Kazeev",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00805"
  },
  {
    "id": "arXiv:2210.00823",
    "title": "BVI-VFI: A Video Quality Database for Video Frame Interpolation",
    "abstract": "BVI-VFI: A Video Quality Database for Video Frame Interpolation",
    "descriptor": "",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00823"
  },
  {
    "id": "arXiv:2210.01063",
    "title": "On Stability and Generalization of Bilevel Optimization Problem",
    "abstract": "On Stability and Generalization of Bilevel Optimization Problem",
    "descriptor": "",
    "authors": [
      "Meng Ding",
      "Mingxi Lei",
      "Yunwen Lei",
      "Di Wang",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01063"
  },
  {
    "id": "arXiv:2210.01073",
    "title": "Distributed-Something: scripts to leverage AWS storage and computing for  distributed workflows at scale",
    "abstract": "Comments: 16 pages, 1 figure",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Erin Weisbart",
      "Beth A. Cimini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.01073"
  },
  {
    "id": "arXiv:2210.01162",
    "title": "Learning Minimally-Violating Continuous Control for Infeasible Linear  Temporal Logic Specifications",
    "abstract": "Learning Minimally-Violating Continuous Control for Infeasible Linear  Temporal Logic Specifications",
    "descriptor": "",
    "authors": [
      "Mingyu Cai",
      "Makai Mann",
      "Zachary Serlin",
      "Kevin Leahy",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01162"
  },
  {
    "id": "arXiv:2210.01203",
    "title": "Influence Maximization: Divide and Conquer",
    "abstract": "Influence Maximization: Divide and Conquer",
    "descriptor": "",
    "authors": [
      "Siddharth Patwardhan",
      "Filippo Radicchi",
      "Santo Fortunato"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.01203"
  },
  {
    "id": "arXiv:2210.01421",
    "title": "Learning of Dynamical Systems under Adversarial Attacks -- Null Space  Property Perspective",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Han Feng",
      "Baturalp Yalcin",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.01421"
  },
  {
    "id": "arXiv:2210.01656",
    "title": "Improving Quantum Classifier Performance in NISQ Computers by Voting  Strategy from Ensemble Learning",
    "abstract": "Comments: 6 pages, 5 figures",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Ruiyang Qin",
      "Zhiding Liang",
      "Jinglei Cheng",
      "Peter Kogge",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.01656"
  },
  {
    "id": "arXiv:2210.01796",
    "title": "Multi-objective Deep Data Generation with Correlated Property Control",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2022",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2022\n",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Xuanyang Lin",
      "Bo Pan",
      "Yuanqi Du",
      "Yinkai Wang",
      "Yanfang Ye",
      "Ashley Ann Petersen",
      "Austin Leitgeb",
      "Saleh AlKhalifa",
      "Kevin Minbiole",
      "Bill Wuest",
      "Amarda Shehu",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01796"
  },
  {
    "id": "arXiv:2210.01887",
    "title": "Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose  Transfer by Permuting Textures",
    "abstract": "Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose  Transfer by Permuting Textures",
    "descriptor": "",
    "authors": [
      "Nannan Li",
      "Kevin J. Shih",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01887"
  },
  {
    "id": "arXiv:2210.01936",
    "title": "When and why vision-language models behave like bags-of-words, and what  to do about it?",
    "abstract": "Comments: Fixed a typo in the title",
    "descriptor": "\nComments: Fixed a typo in the title\n",
    "authors": [
      "Mert Yuksekgonul",
      "Federico Bianchi",
      "Pratyusha Kalluri",
      "Dan Jurafsky",
      "James Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01936"
  },
  {
    "id": "arXiv:2210.01944",
    "title": "A Framework for Large Scale Synthetic Graph Dataset Generation",
    "abstract": "A Framework for Large Scale Synthetic Graph Dataset Generation",
    "descriptor": "",
    "authors": [
      "Sajad Darabi",
      "Piotr Bigaj",
      "Dawid Majchrowski",
      "Pawel Morkisz",
      "Alex Fit-Florea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.01944"
  },
  {
    "id": "arXiv:2210.01963",
    "title": "COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge  and Inheritance in Pre-trained Language Models",
    "abstract": "Comments: WIP; to be submitted to [REDACTED]; now also contains Acknowledgments",
    "descriptor": "\nComments: WIP; to be submitted to [REDACTED]; now also contains Acknowledgments\n",
    "authors": [
      "Kanishka Misra",
      "Julia Taylor Rayz",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01963"
  },
  {
    "id": "arXiv:2210.01964",
    "title": "The Calibration Generalization Gap",
    "abstract": "Comments: Appeared at ICML 2022 Workshop on Distribution-Free Uncertainty Quantification",
    "descriptor": "\nComments: Appeared at ICML 2022 Workshop on Distribution-Free Uncertainty Quantification\n",
    "authors": [
      "A. Michael Carrell",
      "Neil Mallinar",
      "James Lucas",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01964"
  },
  {
    "id": "arXiv:2210.01970",
    "title": "Evaluate & Evaluation on the Hub: Better Best Practices for Data and  Model Measurements",
    "abstract": "Evaluate & Evaluation on the Hub: Better Best Practices for Data and  Model Measurements",
    "descriptor": "",
    "authors": [
      "Leandro von Werra",
      "Lewis Tunstall",
      "Abhishek Thakur",
      "Alexandra Sasha Luccioni",
      "Tristan Thrush",
      "Aleksandra Piktus",
      "Felix Marty",
      "Nazneen Rajani",
      "Victor Mustar",
      "Helen Ngo",
      "Omar Sanseviero",
      "Mario \u0160a\u0161ko",
      "Albert Villanova",
      "Quentin Lhoest",
      "Julien Chaumond",
      "Margaret Mitchell",
      "Alexander M. Rush",
      "Thomas Wolf",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01970"
  },
  {
    "id": "arXiv:2210.02000",
    "title": "Internal Longest Palindrome Queries in Optimal Time",
    "abstract": "Internal Longest Palindrome Queries in Optimal Time",
    "descriptor": "",
    "authors": [
      "Kazuki Mitani",
      "Takuya Mieno",
      "Kazuhisa Seto",
      "Takashi Horiyama"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02000"
  },
  {
    "id": "arXiv:2210.02071",
    "title": "Advanced Deep Learning Architectures for Accurate Detection of  Subsurface Tile Drainage Pipes from Remote Sensing Images",
    "abstract": "Comments: Accepted in SPIE Remote Sensing (ESI22R). For code visit: this https URL",
    "descriptor": "\nComments: Accepted in SPIE Remote Sensing (ESI22R). For code visit: this https URL\n",
    "authors": [
      "Tom-Lukas Breitkopf",
      "Leonard W. Hackel",
      "Mahdyar Ravanbakhsh",
      "Anne-Karin Cooke",
      "Sandra Willkommen",
      "Stefan Broda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.02071"
  },
  {
    "id": "arXiv:2210.02127",
    "title": "Visual-Inertial and Leg Odometry Fusion for Dynamic Locomotion",
    "abstract": "Comments: Submitted to IEEE International Conference on Robotics and Automation (ICRA), 2023",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA), 2023\n",
    "authors": [
      "Victor Dh\u00e9din",
      "Haolong Li",
      "Shahram Khorshidi",
      "Lukas Mack",
      "Adithya Kumar Chinnakkonda Ravi",
      "Avadesh Meduri",
      "Paarth Shah",
      "Felix Grimminger",
      "Ludovic Righetti",
      "Majid Khadiv",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02127"
  },
  {
    "id": "arXiv:2210.02166",
    "title": "Generalized Moving Horizon Estimation for Nonlinear Systems with  Robustness to Measurement Outliers",
    "abstract": "Generalized Moving Horizon Estimation for Nonlinear Systems with  Robustness to Measurement Outliers",
    "descriptor": "",
    "authors": [
      "Wenhan Cao",
      "Chang Liu",
      "Zhiqian Lan",
      "Yingxi Piao",
      "Shengbo Eben Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02166"
  },
  {
    "id": "arXiv:2210.02292",
    "title": "Double-Ended Palindromic Trees: A Linear-Time Data Structure and Its  Applications",
    "abstract": "Comments: Minor corrections and modifications. 67 pages, 3 tables, 15 algorithms",
    "descriptor": "\nComments: Minor corrections and modifications. 67 pages, 3 tables, 15 algorithms\n",
    "authors": [
      "Qisheng Wang",
      "Ming Yang",
      "Xinrui Zhu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.02292"
  },
  {
    "id": "arXiv:2210.02415",
    "title": "A Fourier Approach to Mixture Learning",
    "abstract": "Comments: To appear at NeurIPS 2022; v2 corrected author information",
    "descriptor": "\nComments: To appear at NeurIPS 2022; v2 corrected author information\n",
    "authors": [
      "Mingda Qiao",
      "Guru Guruganesh",
      "Ankit Singh Rawat",
      "Avinava Dubey",
      "Manzil Zaheer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02415"
  },
  {
    "id": "arXiv:2210.02441",
    "title": "Ask Me Anything: A simple strategy for prompting language models",
    "abstract": "Ask Me Anything: A simple strategy for prompting language models",
    "descriptor": "",
    "authors": [
      "Simran Arora",
      "Avanika Narayan",
      "Mayee F. Chen",
      "Laurel Orr",
      "Neel Guha",
      "Kush Bhatia",
      "Ines Chami",
      "Frederic Sala",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02441"
  }
]
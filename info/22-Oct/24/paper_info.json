[
  {
    "id": "arXiv:2210.11475",
    "title": "On the economic viability of solar energy when upgrading cellular  networks",
    "abstract": "The massive increase of data traffic, the widespread proliferation of\nwireless applications and the full-scale deployment of 5G and the IoT, imply a\nsteep increase in cellular networks energy use, resulting in a significant\ncarbon footprint. This paper presents a comprehensive model to show the\ninteraction between the networking and energy features of the problem and study\nthe economical and technical viability of green networking. Solar equipment,\ncell zooming, energy management and dynamic user allocation are considered in\nthe upgrading network planning process. We propose a mixed-integer optimization\nmodel to minimize long-term capital costs and operational energy expenditures\nin a heterogeneous on-grid cellular network with different types of base\nstation, including solar. Based on eight scenarios where realistic costs of\nsolar panels, batteries, and inverters were considered, we first found that\nsolar base stations are currently not economically interesting for cellular\noperators. We next studied the impact of a significant and progressive carbon\ntax on reducing greenhouse gas emissions (GHG). We found that, at current\nenergy and equipment prices, a carbon tax ten-fold the current value is the\nonly element that could make green base stations economically viable.",
    "descriptor": "\nComments: 25 pages, 12 figures, 51 references, journal paper to ieee transaciton green communications and networks\n",
    "authors": [
      "Zineb Garroussi",
      "Abdoul Wassi Badirou",
      "Mathieu D'amours",
      "Andr\u00e9 Girard",
      "Brunilde Sans\u00f2"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Networking and Internet Architecture (cs.NI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11475"
  },
  {
    "id": "arXiv:2210.11476",
    "title": "Encoding nonlinear and unsteady aerodynamics of limit cycle oscillations  using nonlinear sparse Bayesian learning",
    "abstract": "This paper investigates the applicability of a recently-proposed nonlinear\nsparse Bayesian learning (NSBL) algorithm to identify and estimate the complex\naerodynamics of limit cycle oscillations. NSBL provides a semi-analytical\nframework for determining the data-optimal sparse model nested within a\n(potentially) over-parameterized model. This is particularly relevant to\nnonlinear dynamical systems where modelling approaches involve the use of\nphysics-based and data-driven components. In such cases, the data-driven\ncomponents, where analytical descriptions of the physical processes are not\nreadily available, are often prone to overfitting, meaning that the empirical\naspects of these models will often involve the calibration of an unnecessarily\nlarge number of parameters. While it may be possible to fit the data well, this\ncan become an issue when using these models for predictions in regimes that are\ndifferent from those where the data was recorded. In view of this, it is\ndesirable to not only calibrate the model parameters, but also to identify the\noptimal compromise between data-fit and model complexity. In this paper, this\nis achieved for an aeroelastic system where the structural dynamics are\nwell-known and described by a differential equation model, coupled with a\nsemi-empirical aerodynamic model for laminar separation flutter resulting in\nlow-amplitude limit cycle oscillations. For the purpose of illustrating the\nbenefit of the algorithm, in this paper, we use synthetic data to demonstrate\nthe ability of the algorithm to correctly identify the optimal model and model\nparameters, given a known data-generating model. The synthetic data are\ngenerated from a forward simulation of a known differential equation model with\nparameters selected so as to mimic the dynamics observed in wind-tunnel\nexperiments.",
    "descriptor": "",
    "authors": [
      "Rimple Sandhu",
      "Brandon Robinson",
      "Mohammad Khalil",
      "Chris L. Pettit",
      "Dominique Poirel",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11476"
  },
  {
    "id": "arXiv:2210.11477",
    "title": "Multiscale Topology Optimization Considering Local and Global Buckling  Response",
    "abstract": "Much work has been done in multiscale topology optimization for maximum\nstiffness or minimum compliance design. Such approaches date back to the\noriginal homogenization-based work by Bends{\\o}e and Kikuchi from 1988, which\nlately has been revived due to advances in manufacturing methods like additive\nmanufacturing. Orthotropic microstructures locally oriented in principal stress\ndirections provide for highly efficient stiffness optimal designs, whereas for\nthe pure stiffness objective, porous isotropic microstructures are sub-optimal\nand hence not useful. It has, however, been postulated and exemplified that\nisotropic microstructures (infill) may enhance structural buckling stability\nbut this has yet to be directly proven and optimized. In this work, we optimize\nbuckling stability of multiscale structures with isotropic porous infill. To do\nthis, we establish local density dependent Willam-Warnke yield surfaces based\non buckling estimates from Bloch-Floquet-based cell analysis to predict local\ninstability of the homogenized materials. These local buckling-based stress\nconstraints are combined with a global buckling criterion to obtain topology\noptimized designs that take both local and global buckling stability into\naccount. De-homogenized structures with small and large cell sizes confirm\nvalidity of the approach and demonstrate huge structural gains as well as time\nsavings compared to standard singlescale approaches.",
    "descriptor": "\nComments: Submitted to Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Christoffer Fyllgraf Christensen",
      "Fengwen Wang",
      "Ole Sigmund"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11477"
  },
  {
    "id": "arXiv:2210.11479",
    "title": "Exploitation of material consolidation trade-offs in a multi-tier  complex supply networks",
    "abstract": "While consolidation strategies form the backbone of many supply chain\noptimisation problems, exploitation of multi-tier material relationships\nthrough consolidation remains an understudied area, despite being a prominent\nfeature of industries that produce complex made-to-order products. In this\npaper, we propose an optimisation framework for exploiting multi-to-multi\nrelationship between tiers of a supply chain. The resulting formulation is\nflexible such that quantity discounts, inventory holding and transport costs\ncan be included. The framework introduces a new trade-off between the tiers,\nresulting in cost reductions at one tier at the expense of increased costs in\nthe other tier, which helps to reduce the overall procurement cost in the\nsupply chain. A mixed integer linear programming model is developed and tested\nwith a range of small to large-scale test problems from aerospace\nmanufacturing. Our comparison to benchmark results show that there is indeed a\ncost trade-off between two tiers, and that its reduction can be achieved using\na holistic approach to reconfiguration. Costs are decreased when second tier\nfixed ordering costs and the number of machining options increase.\nConsolidation results in less inventory holding costs for all cases. A number\nof secondary effects such as simplified supplier selection may also be\nobserved.",
    "descriptor": "\nComments: (under review)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Muhannad Alomari",
      "James Arney",
      "Ajith Kumar Parlikad",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11479"
  },
  {
    "id": "arXiv:2210.11481",
    "title": "Improving aircraft performance using machine learning: a review",
    "abstract": "This review covers the new developments in machine learning (ML) that are\nimpacting the multi-disciplinary area of aerospace engineering, including\nfundamental fluid dynamics (experimental and numerical), aerodynamics,\nacoustics, combustion and structural health monitoring. We review the state of\nthe art, gathering the advantages and challenges of ML methods across different\naerospace disciplines and provide our view on future opportunities. The basic\nconcepts and the most relevant strategies for ML are presented together with\nthe most relevant applications in aerospace engineering, revealing that ML is\nimproving aircraft performance and that these techniques will have a large\nimpact in the near future.",
    "descriptor": "",
    "authors": [
      "Soledad Le Clainche",
      "Esteban Ferrer",
      "Sam Gibson",
      "Elisabeth Cross",
      "Alessandro Parente",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.11481"
  },
  {
    "id": "arXiv:2210.11496",
    "title": "Optical Networking in Future-land: From Optical-bypass-enabled to  Optical-processing-enabled Paradigm",
    "abstract": "Conventional wisdom in designing the optical switching nodes is rooted in the\nintuition that when an optical channel crossing an intermediate node, it should\nbe maximally isolated from other optical channels to avoid interference. Such\nlong-established paradigm perceiving the interference of optical channels\ntransiting at the same node as an adversarial factor and should therefore\ncircumvent, albeit reasonable, may leave vast unexplored opportunities. Indeed,\nrapid advances in all-optical signal processing technologies has brought\nopportunities to re-define the optical node architecture by upgrading its naive\nfunctionalities from simply add/drop and cross-connecting to proactively mixing\noptical channels in photonic domain. Specifically, all-optical channel (de-)\naggregation technologies have been remarkably advancing in recent years,\npermitting two or more optical channels at lower bit-rate and/or modulation\nformats could be all-optically aggregated to a single channel of higher-rate\nand/or higher-order modulation format and vice versa. Such evolutionary\ntechnique is poised to disrupt the existing ecosystem for optical network\ndesign and planning, and thus necessitates for a radical change to unlock new\npotentials. In addressing this disruptive idea, we present a new paradigm for\nfuture optical networks, namely, optical-processing-enabled networks powered by\nin-network all-optical mixing capability. We introduce the operational\nprinciple of optical channel (de-) aggregation and show how spectrally\nbeneficial such innovative operations could yield by an illustrative example.\nNext, in order to maximize the aggregation opportunity, we present a\nmathematical model for optimal routing based on integer linear programming\nmodel. Numerical results on the realistic network topology COST239 are provided\nto quantify the spectral gain of aggregation-aware routing compared to the\nconventional one.",
    "descriptor": "\nComments: 8 figures, 2 tables, pre-proof version of OQE journal\n",
    "authors": [
      "Dao Thanh Hai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.11496"
  },
  {
    "id": "arXiv:2210.11498",
    "title": "Balanced Adversarial Training: Balancing Tradeoffs between Fickleness  and Obstinacy in NLP Models",
    "abstract": "Traditional (fickle) adversarial examples involve finding a small\nperturbation that does not change an input's true label but confuses the\nclassifier into outputting a different prediction. Conversely, obstinate\nadversarial examples occur when an adversary finds a small perturbation that\npreserves the classifier's prediction but changes the true label of an input.\nAdversarial training and certified robust training have shown some\neffectiveness in improving the robustness of machine learnt models to fickle\nadversarial examples. We show that standard adversarial training methods\nfocused on reducing vulnerability to fickle adversarial examples may make a\nmodel more vulnerable to obstinate adversarial examples, with experiments for\nboth natural language inference and paraphrase identification tasks. To counter\nthis phenomenon, we introduce Balanced Adversarial Training, which incorporates\ncontrastive learning to increase robustness against both fickle and obstinate\nadversarial examples.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Hannah Chen",
      "Yangfeng Ji",
      "David Evans"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11498"
  },
  {
    "id": "arXiv:2210.11501",
    "title": "Trust-as-a-Service: A reputation-enabled trust framework for 5G networks",
    "abstract": "Trust, security, and privacy are three of the major pillars to assemble the\nfifth generation network and beyond. Despite such pillars are principally\ninterconnected, they arise a multitude of challenges to be addressed\nseparately. 5G ought to offer flexible and pervasive computing capabilities\nacross multiple domains according to user demands and assuring trustworthy\nnetwork providers. Distributed marketplaces expect to boost the trading of\nheterogeneous resources so as to enable the establishment of pervasive service\nchains between cross-domains. Nevertheless, the need for reliable parties as\n``marketplace operators'' plays a pivotal role to achieving a trustworthy\necosystem. One of the principal blockages in managing foreseeable networks is\nthe need of adapting previous trust models to accomplish the new network and\nbusiness requirements. In this regard, this article is centered on trust\nmanagement of 5G multi-party networks. The design of a reputation-based trust\nframework is proposed as a Trust-as-a-Service (TaaS) solution for any\ndistributed multi-stakeholder environment where zero trust and zero-touch\nprinciples should be met. Besides, a literature review is also conducted to\nrecognize the network and business requirements currently envisaged. Finally,\nthe validation of the proposed trust framework is performed in a real research\nenvironment, the 5GBarcelona testbed, leveraging 12% of a 2.1GHz CPU with 20\ncores and 2% of the 30GiB memory. In this regard, these outcomes reveal the\nfeasibility of the TaaS solution in the context of determining reliable network\noperators.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Mar\u00eda Jorquera Valero",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Manuel Gil P\u00e9rez",
      "Alberto Huertas Celdr\u00e1n",
      "Gregorio Mart\u00ednez P\u00e9rez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.11501"
  },
  {
    "id": "arXiv:2210.11502",
    "title": "Multimodal Neural Network For Demand Forecasting",
    "abstract": "Demand forecasting applications have immensely benefited from the\nstate-of-the-art Deep Learning methods used for time series forecasting.\nTraditional uni-modal models are predominantly seasonality driven which attempt\nto model the demand as a function of historic sales along with information on\nholidays and promotional events. However, accurate and robust sales forecasting\ncalls for accommodating multiple other factors, such as natural calamities,\npandemics, elections, etc., impacting the demand for products and product\ncategories in general. We propose a multi-modal sales forecasting network that\ncombines real-life events from news articles with traditional data such as\nhistorical sales and holiday information. Further, we fuse information from\ngeneral product trends published by Google trends. Empirical results show\nstatistically significant improvements in the SMAPE error metric with an\naverage improvement of 7.37% against the existing state-of-the-art sales\nforecasting techniques on a real-world supermarket dataset.",
    "descriptor": "\nComments: Accepted at ICONIP 2022\n",
    "authors": [
      "Nitesh Kumar",
      "Kumar Dheenadayalan",
      "Suprabath Reddy",
      "Sumant Kulkarni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11502"
  },
  {
    "id": "arXiv:2210.11510",
    "title": "Nonlinear Attitude Estimation Using Intermittent and Multi-Rate Vector  Measurements",
    "abstract": "This paper considers the problem of nonlinear attitude estimation for a rigid\nbody system using intermittent and multi-rate inertial vector measurements as\nwell as continuous (high-rate) angular velocity measurements. Two types of\nhybrid attitude observers on Lie group $SO(3)$ are proposed. First, we propose\na hybrid attitude observer where almost global asymptotic stability is\nguaranteed using the notion of almost global input-to-state stability on\nmanifolds. Thereafter, this hybrid attitude observer is extended by introducing\na switching mechanism to achieve global asymptotic stability. Both simulation\nand experimental results are presented to illustrate the performance of the\nproposed hybrid observers.",
    "descriptor": "\nComments: 14 pages, 7 figures, submitted to IEEE TAC\n",
    "authors": [
      "Miaomiao Wang",
      "Abdelhamid Tayebi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11510"
  },
  {
    "id": "arXiv:2210.11511",
    "title": "Overexposure Mask Fusion: Generalizable Reverse ISP Multi-Step  Refinement",
    "abstract": "With the advent of deep learning methods replacing the ISP in transforming\nsensor RAW readings into RGB images, numerous methodologies solidified into\nreal-life applications. Equally potent is the task of inverting this process\nwhich will have applications in enhancing computational photography tasks that\nare conducted in the RAW domain, addressing lack of available RAW data while\nreaping from the benefits of performing tasks directly on sensor readings. This\npaper's proposed methodology is a state-of-the-art solution to the task of RAW\nreconstruction, and the multi-step refinement process integrating an\noverexposure mask is novel in three ways: instead of from RGB to bayer, the\npipeline trains from RGB to demosaiced RAW allowing use of perceptual loss\nfunctions; the multi-step processes has greatly enhanced the performance of the\nbaseline U-Net from start to end; the pipeline is a generalizable process of\nrefinement that can enhance other high performance methodologies that support\nend-to-end learning.",
    "descriptor": "\nComments: 15 pages, 8 figures, ECCV\n",
    "authors": [
      "Jinha Kim",
      "Jun Jiang",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.11511"
  },
  {
    "id": "arXiv:2210.11512",
    "title": "Communication breakdown: On the low mutual intelligibility between human  and neural captioning",
    "abstract": "We compare the 0-shot performance of a neural caption-based image retriever\nwhen given as input either human-produced captions or captions generated by a\nneural captioner. We conduct this comparison on the recently introduced\nImageCoDe data-set \\citep{Krojer:etal:2022}, which contains hard distractors\nnearly identical to the images to be retrieved. We find that the neural\nretriever has much higher performance when fed neural rather than human\ncaptions, despite the fact that the former, unlike the latter, were generated\nwithout awareness of the distractors that make the task hard. Even more\nremarkably, when the same neural captions are given to human subjects, their\nretrieval performance is almost at chance level. Our results thus add to the\ngrowing body of evidence that, even when the ``language'' of neural models\nresembles English, this superficial resemblance might be deeply misleading.",
    "descriptor": "\nComments: Accepted as a short paper at EMNLP 2022\n",
    "authors": [
      "Roberto Dess\u00ec",
      "Eleonora Gualdoni",
      "Francesca Franzon",
      "Gemma Boleda",
      "Marco Baroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11512"
  },
  {
    "id": "arXiv:2210.11513",
    "title": "Learning Sample Reweighting for Accuracy and Adversarial Robustness",
    "abstract": "There has been great interest in enhancing the robustness of neural network\nclassifiers to defend against adversarial perturbations through adversarial\ntraining, while balancing the trade-off between robust accuracy and standard\naccuracy. We propose a novel adversarial training framework that learns to\nreweight the loss associated with individual training samples based on a notion\nof class-conditioned margin, with the goal of improving robust generalization.\nWe formulate weighted adversarial training as a bilevel optimization problem\nwith the upper-level problem corresponding to learning a robust classifier, and\nthe lower-level problem corresponding to learning a parametric function that\nmaps from a sample's \\textit{multi-class margin} to an importance weight.\nExtensive experiments demonstrate that our approach consistently improves both\nclean and robust accuracy compared to related methods and state-of-the-art\nbaselines.",
    "descriptor": "",
    "authors": [
      "Chester Holtz",
      "Tsui-Wei Weng",
      "Gal Mishne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11513"
  },
  {
    "id": "arXiv:2210.11517",
    "title": "A Security and Trust Framework for Decentralized 5G Marketplaces",
    "abstract": "5G networks intend to cover user demands through multi-party collaborations\nin a secure and trustworthy manner. To this end, marketplaces play a pivotal\nrole as enablers for network service consumers and infrastructure providers to\noffer, negotiate, and purchase 5G resources and services. Nevertheless,\nmarketplaces often do not ensure trustworthy networking by analyzing the\nsecurity and trust of their members and offers. This paper presents a security\nand trust framework to enable the selection of reliable third-party providers\nbased on their history and reputation. In addition, it also introduces a reward\nand punishment mechanism to continuously update trust scores according to\nsecurity events. Finally, we showcase a real use case in which the security and\ntrust framework is being applied.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Mar\u00eda Jorquera Valero",
      "Manuel Gil P\u00e9rez",
      "Gregorio Mart\u00ednez P\u00e9rez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11517"
  },
  {
    "id": "arXiv:2210.11522",
    "title": "Composing Ensembles of Pre-trained Models via Iterative Consensus",
    "abstract": "Large pre-trained models exhibit distinct and complementary capabilities\ndependent on the data they are trained on. Language models such as GPT-3 are\ncapable of textual reasoning but cannot understand visual information, while\nvision models such as DALL-E can generate photorealistic photos but fail to\nunderstand complex language descriptions. In this work, we propose a unified\nframework for composing ensembles of different pre-trained models -- combining\nthe strengths of each individual model to solve various multimodal problems in\na zero-shot manner. We use pre-trained models as \"generators\" or \"scorers\" and\ncompose them via closed-loop iterative consensus optimization. The generator\nconstructs proposals and the scorers iteratively provide feedback to refine the\ngenerated result. Such closed-loop communication enables models to correct\nerrors caused by other models, significantly boosting performance on downstream\ntasks, e.g. improving accuracy on grade school math problems by 7.5%, without\nrequiring any model finetuning. We demonstrate that consensus achieved by an\nensemble of scorers outperforms the feedback of a single scorer, by leveraging\nthe strengths of each expert model. Results show that the proposed method can\nbe used as a general purpose framework for a wide range of zero-shot multimodal\ntasks, such as image generation, video question answering, mathematical\nreasoning, and robotic manipulation. Project page:\nhttps://energy-based-model.github.io/composing-pretrained-models.",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Yilun Du",
      "Joshua B. Tenenbaum",
      "Antonio Torralba",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11522"
  },
  {
    "id": "arXiv:2210.11528",
    "title": "Unsupervised Text Deidentification",
    "abstract": "Deidentification seeks to anonymize textual data prior to distribution.\nAutomatic deidentification primarily uses supervised named entity recognition\nfrom human-labeled data points. We propose an unsupervised deidentification\nmethod that masks words that leak personally-identifying information. The\napproach utilizes a specially trained reidentification model to identify\nindividuals from redacted personal documents. Motivated by K-anonymity based\nprivacy, we generate redactions that ensure a minimum reidentification rank for\nthe correct profile of the document. To evaluate this approach, we consider the\ntask of deidentifying Wikipedia Biographies, and evaluate using an adversarial\nreidentification metric. Compared to a set of unsupervised baselines, our\napproach deidentifies documents more completely while removing fewer words.\nQualitatively, we see that the approach eliminates many identifying aspects\nthat would fall outside of the common named entity based approach.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "John X. Morris",
      "Justin T. Chiu",
      "Ramin Zabih",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11528"
  },
  {
    "id": "arXiv:2210.11533",
    "title": "Design Representation as Semantic Networks",
    "abstract": "Design representation is a common task in the design process to facilitate\nlearning, analysis, redesign, communication, and other design activities.\nTraditional representation techniques rely on human expertise and manual\nconstruction and are difficult to repeat and scale. Here, we propose a\nmethodology that utilizes a pre-trained large-scale cross-domain design\nknowledge base to automatically generate design representation as a semantic\nnetwork, i.e., a network of the entities and relations, based on design\ndescriptions in texts or natural languages. Our methodology requires no ad hoc\nstatistics. Based on a participatory study, we reveal the effectiveness and\ndifferences of the semantic network representations that are automatically\ngenerated with alternative knowledge bases. The findings illuminate future\nresearch directions to enhance design representation as semantic networks.",
    "descriptor": "",
    "authors": [
      "Serhad Sarica",
      "Ji Han",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11533"
  },
  {
    "id": "arXiv:2210.11534",
    "title": "Designing ReachBot: System Design Process with a Case Study of a Martian  Lava Tube Mission",
    "abstract": "In this paper we present a trade study-based method to optimize the\narchitecture of ReachBot, a new robotic concept that uses deployable booms as\nprismatic joints for mobility in environments with adverse gravity conditions\nand challenging terrain. Specifically, we introduce a design process wherein we\nanalyze the compatibility of ReachBot's design with its mission. We incorporate\nterrain parameters and mission requirements to produce a final design optimized\nfor mission-specific objectives. ReachBot's design parameters include (1)\nnumber of booms, (2) positions and orientations of the booms on ReachBot's\nchassis, (3) boom maximum extension, (4) boom cross-sectional geometry, and (5)\nnumber of active/passive degrees-of-freedom at each joint. Using first-order\napproximations, we analyze the relationships between these parameters and\nvarious performance metrics including stability, manipulability, and mechanical\ninterference. We apply our method to a mission where ReachBot navigates and\ngathers data from a martian lava tube. The resulting design is shown in Fig. 1.",
    "descriptor": "",
    "authors": [
      "Stephanie Newdick",
      "Tony G. Chen",
      "Benjamin Hockman",
      "Edward Schmerling",
      "Mark R. Cutkosky",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11534"
  },
  {
    "id": "arXiv:2210.11536",
    "title": "CONSISTENT: Open-Ended Question Generation From News Articles",
    "abstract": "Recent work on question generation has largely focused on factoid questions\nsuch as who, what, where, when about basic facts. Generating open-ended why,\nhow, what, etc. questions that require long-form answers have proven more\ndifficult. To facilitate the generation of open-ended questions, we propose\nCONSISTENT, a new end-to-end system for generating open-ended questions that\nare answerable from and faithful to the input text. Using news articles as a\ntrustworthy foundation for experimentation, we demonstrate our model's strength\nover several baselines using both automatic and human=based evaluations. We\ncontribute an evaluation dataset of expert-generated open-ended questions.We\ndiscuss potential downstream applications for news media organizations.",
    "descriptor": "\nComments: EMNLP 2022 Findings\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Justin Lewis",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11536"
  },
  {
    "id": "arXiv:2210.11539",
    "title": "ConfMix: Unsupervised Domain Adaptation for Object Detection via  Confidence-based Mixing",
    "abstract": "Unsupervised Domain Adaptation (UDA) for object detection aims to adapt a\nmodel trained on a source domain to detect instances from a new target domain\nfor which annotations are not available. Different from traditional approaches,\nwe propose ConfMix, the first method that introduces a sample mixing strategy\nbased on region-level detection confidence for adaptive object detector\nlearning. We mix the local region of the target sample that corresponds to the\nmost confident pseudo detections with a source image, and apply an additional\nconsistency loss term to gradually adapt towards the target data distribution.\nIn order to robustly define a confidence score for a region, we exploit the\nconfidence score per pseudo detection that accounts for both the\ndetector-dependent confidence and the bounding box uncertainty. Moreover, we\npropose a novel pseudo labelling scheme that progressively filters the pseudo\ntarget detections using the confidence metric that varies from a loose to\nstrict manner along the training. We perform extensive experiments with three\ndatasets, achieving state-of-the-art performance in two of them and approaching\nthe supervised target model performance in the other. Code is available at:\nhttps://github.com/giuliomattolin/ConfMix.",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Giulio Mattolin",
      "Luca Zanella",
      "Elisa Ricci",
      "Yiming Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11539"
  },
  {
    "id": "arXiv:2210.11542",
    "title": "Sketching Meets Differential Privacy: Fast Algorithm for Dynamic  Kronecker Projection Maintenance",
    "abstract": "Projection maintenance is one of the core data structure tasks. Efficient\ndata structures for projection maintenance have led to recent breakthroughs in\nmany convex programming algorithms. In this work, we further extend this\nframework to the Kronecker product structure. Given a constraint matrix ${\\sf\nA}$ and a positive semi-definite matrix $W\\in \\mathbb{R}^{n\\times n}$ with a\nsparse eigenbasis, we consider the task of maintaining the projection in the\nform of ${\\sf B}^\\top({\\sf B}{\\sf B}^\\top)^{-1}{\\sf B}$, where ${\\sf B}={\\sf\nA}(W\\otimes I)$ or ${\\sf B}={\\sf A}(W^{1/2}\\otimes W^{1/2})$. At each\niteration, the weight matrix $W$ receives a low rank change and we receive a\nnew vector $h$. The goal is to maintain the projection matrix and answer the\nquery ${\\sf B}^\\top({\\sf B}{\\sf B}^\\top)^{-1}{\\sf B}h$ with good approximation\nguarantees. We design a fast dynamic data structure for this task and it is\nrobust against an adaptive adversary. Following the work of [Beimel, Kaplan,\nMansour, Nissim, Saranurak and Stemmer, STOC'22], we use tools from\ndifferential privacy to reduce the randomness required by the data structure\nand further improve the running time.",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Xin Yang",
      "Yuanyuan Yang",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11542"
  },
  {
    "id": "arXiv:2210.11543",
    "title": "Object Goal Navigation Based on Semantics and RGB Ego View",
    "abstract": "This paper presents an architecture and methodology to empower a service\nrobot to navigate an indoor environment with semantic decision making, given\nRGB ego view. This method leverages the knowledge of robot's actuation\ncapability and that of scenes, objects and their relations -- represented in a\nsemantic form. The robot navigates based on GeoSem map - a relational\ncombination of geometric and semantic map. The goal given to the robot is to\nfind an object in a unknown environment with no navigational map and only\negocentric RGB camera perception. The approach is tested both on a simulation\nenvironment and real life indoor settings. The presented approach was found to\noutperform human users in gamified evaluations with respect to average\ncompletion time.",
    "descriptor": "\nComments: IROS 2022 AI&R Workshop\n",
    "authors": [
      "Snehasis Banerjee",
      "Brojeshwar Bhowmick",
      "Ruddra Dev Roychoudhury"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11543"
  },
  {
    "id": "arXiv:2210.11545",
    "title": "Transferring learned patterns from ground-based field imagery to predict  UAV-based imagery for crop and weed semantic segmentation in precision crop  farming",
    "abstract": "Weed and crop segmentation is becoming an increasingly integral part of\nprecision farming that leverages the current computer vision and deep learning\ntechnologies. Research has been extensively carried out based on images\ncaptured with a camera from various platforms. Unmanned aerial vehicles (UAVs)\nand ground-based vehicles including agricultural robots are the two popular\nplatforms for data collection in fields. They all contribute to site-specific\nweed management (SSWM) to maintain crop yield. Currently, the data from these\ntwo platforms is processed separately, though sharing the same semantic objects\n(weed and crop). In our paper, we have developed a deep convolutional network\nthat enables to predict both field and aerial images from UAVs for weed\nsegmentation and mapping with only field images provided in the training phase.\nThe network learning process is visualized by feature maps at shallow and deep\nlayers. The results show that the mean intersection of union (IOU) values of\nthe segmentation for the crop (maize), weeds, and soil background in the\ndeveloped model for the field dataset are 0.744, 0.577, 0.979, respectively,\nand the performance of aerial images from an UAV with the same model, the IOU\nvalues of the segmentation for the crop (maize), weeds and soil background are\n0.596, 0.407, and 0.875, respectively. To estimate the effect on the use of\nplant protection agents, we quantify the relationship between herbicide\nspraying saving rate and grid size (spraying resolution) based on the predicted\nweed map. The spraying saving rate is up to 90% when the spraying resolution is\nat 1.78 x 1.78 cm2. The study shows that the developed deep convolutional\nneural network could be used to classify weeds from both field and aerial\nimages and delivers satisfactory results.",
    "descriptor": "",
    "authors": [
      "Junfeng Gao",
      "Wenzhi Liao",
      "David Nuyttens",
      "Peter Lootens",
      "Erik Alexandersson",
      "Jan Pieters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11545"
  },
  {
    "id": "arXiv:2210.11546",
    "title": "Proof of Backhaul: Trustfree Measurement of Broadband Bandwidth",
    "abstract": "Recent years have seen the emergence of decentralized wireless networks\nconsisting of nodes hosted by many individuals and small enterprises,\nreawakening the decades-old dream of open networking. These networks have been\ndeployed in an organic, distributed manner and are driven by new economic\nmodels resting on tokenized incentives. A critical requirement for the\nincentives to scale is the ability to prove network performance in a\ndecentralized trustfree manner, i.e., a Byzantine fault tolerant network\ntelemetry system. In this paper, we present a Proof of Backhaul (PoB) protocol\nwhich measures the bandwidth of the (broadband) backhaul link of a wireless\naccess point, termed prover, in a decentralized and trustfree manner. In\nparticular, our proposed protocol is the first one to satisfy the following two\nproperties: (1) Trustfree. Bandwidth measurement is secure against Byzantine\nattacks by collaborations of challenge servers and the prover. (2) Open. The\nbarrier-to-entry for being a challenge server is low; there is no requirement\nof having a low latency and high throughput path to the measured link. At a\nhigh-level, our protocol aggregates the challenge traffic from multiple\nchallenge servers and uses cryptographic primitives to ensure that a subset of\nchallengers or, even challengers and provers, cannot maliciously modify results\nin their favor. A formal security model allows us to establish guarantees of\naccurate bandwidth measurement as a function of the fraction of malicious\nactors. Our evaluation shows that our PoB protocol can verify backhaul\nbandwidth of up to 1000 Mbps with less than 8% error using measurements lasting\nonly 100 ms. The measurement accuracy is not affected in the presence of\ncorrupted challengers. Importantly, the basic verification protocol lends\nitself to a minor modification that can measure available bandwidth even in the\npresence of cross-traffic.",
    "descriptor": "",
    "authors": [
      "Peiyao Sheng",
      "Nikita Yadav",
      "Vishal Sevani",
      "Arun Babu",
      "SVR Anand",
      "Himanshu Tyagi",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.11546"
  },
  {
    "id": "arXiv:2210.11549",
    "title": "H4VDM: H.264 Video Device Matching",
    "abstract": "Methods that can determine if two given video sequences are captured by the\nsame device (e.g., mobile telephone or digital camera) can be used in many\nforensics tasks. In this paper we refer to this as \"video device matching\". In\nopen-set video forensics scenarios it is easier to determine if two video\nsequences were captured with the same device than identifying the specific\ndevice. In this paper, we propose a technique for open-set video device\nmatching. Given two H.264 compressed video sequences, our method can determine\nif they are captured by the same device, even if our method has never\nencountered the device in training. We denote our proposed technique as H.264\nVideo Device Matching (H4VDM). H4VDM uses H.264 compression information\nextracted from video sequences to make decisions. It is more robust against\nartifacts that alter camera sensor fingerprints, and it can be used to analyze\nrelatively small fragments of the H.264 sequence. We trained and tested our\nmethod on a publicly available video forensics dataset consisting of 35\ndevices, where our proposed method demonstrated good performance.",
    "descriptor": "",
    "authors": [
      "Ziyue Xiang",
      "Paolo Bestagini",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.11549"
  },
  {
    "id": "arXiv:2210.11554",
    "title": "6D Pose Estimation for Textureless Objects on RGB Frames using  Multi-View Optimization",
    "abstract": "6D pose estimation of textureless objects is a valuable but challenging task\nfor many robotic applications. In this work, we propose a framework to address\nthis challenge using only RGB images acquired from multiple viewpoints. The\ncore idea of our approach is to decouple 6D pose estimation into a sequential\ntwo-step process, first estimating the 3D translation and then the 3D rotation\nof each object. This decoupled formulation first resolves the scale and depth\nambiguities in single RGB images, and uses these estimates to accurately\nidentify the object orientation in the second stage, which is greatly\nsimplified with an accurate scale estimate. Moreover, to accommodate the\nmulti-modal distribution present in rotation space, we develop an optimization\nscheme that explicitly handles object symmetries and counteracts measurement\nuncertainties. In comparison to the state-of-the-art multi-view approach, we\ndemonstrate that the proposed approach achieves substantial improvements on a\nchallenging 6D pose estimation dataset for textureless objects.",
    "descriptor": "",
    "authors": [
      "Jun Yang",
      "Wenjie Xue",
      "Sahar Ghavidel",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11554"
  },
  {
    "id": "arXiv:2210.11557",
    "title": "Learning Attention Propagation for Compositional Zero-Shot Learning",
    "abstract": "Compositional zero-shot learning aims to recognize unseen compositions of\nseen visual primitives of object classes and their states. While all primitives\n(states and objects) are observable during training in some combination, their\ncomplex interaction makes this task especially hard. For example, wet changes\nthe visual appearance of a dog very differently from a bicycle. Furthermore, we\nargue that relationships between compositions go beyond shared states or\nobjects. A cluttered office can contain a busy table; even though these\ncompositions don't share a state or object, the presence of a busy table can\nguide the presence of a cluttered office. We propose a novel method called\nCompositional Attention Propagated Embedding (CAPE) as a solution. The key\nintuition to our method is that a rich dependency structure exists between\ncompositions arising from complex interactions of primitives in addition to\nother dependencies between compositions. CAPE learns to identify this structure\nand propagates knowledge between them to learn class embedding for all seen and\nunseen compositions. In the challenging generalized compositional zero-shot\nsetting, we show that our method outperforms previous baselines to set a new\nstate-of-the-art on three publicly available benchmarks.",
    "descriptor": "",
    "authors": [
      "Muhammad Gul Zain Ali Khan",
      "Muhammad Ferjad Naeem",
      "Luc Van Gool",
      "Alain Pagani",
      "Didier Stricker",
      "Muhammad Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11557"
  },
  {
    "id": "arXiv:2210.11560",
    "title": "Finding Dataset Shortcuts with Grammar Induction",
    "abstract": "Many NLP datasets have been found to contain shortcuts: simple decision rules\nthat achieve surprisingly high accuracy. However, it is difficult to discover\nshortcuts automatically. Prior work on automatic shortcut detection has focused\non enumerating features like unigrams or bigrams, which can find only low-level\nshortcuts, or relied on post-hoc model interpretability methods like saliency\nmaps, which reveal qualitative patterns without a clear statistical\ninterpretation. In this work, we propose to use probabilistic grammars to\ncharacterize and discover shortcuts in NLP datasets. Specifically, we use a\ncontext-free grammar to model patterns in sentence classification datasets and\nuse a synchronous context-free grammar to model datasets involving sentence\npairs. The resulting grammars reveal interesting shortcut features in a number\nof datasets, including both simple and high-level features, and automatically\nidentify groups of test examples on which conventional classifiers fail.\nFinally, we show that the features we discover can be used to generate\ndiagnostic contrast examples and incorporated into standard robust optimization\nmethods to improve worst-group accuracy.",
    "descriptor": "\nComments: EMNLP 2022. Our code is publicly available at this https URL\n",
    "authors": [
      "Dan Friedman",
      "Alexander Wettig",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11560"
  },
  {
    "id": "arXiv:2210.11561",
    "title": "Low-Rank Representations Towards Classification Problem of Complex  Networks",
    "abstract": "Complex networks representing social interactions, brain activities,\nmolecular structures have been studied widely to be able to understand and\npredict their characteristics as graphs. Models and algorithms for these\nnetworks are used in real-life applications, such as search engines, and\nrecommender systems. In general, such networks are modelled by constructing a\nlow-dimensional Euclidean embedding of the vertices of the network, where\nproximity of the vertices in the Euclidean space hints the likelihood of an\nedge (link). In this work, we study the performance of such low-rank\nrepresentations of real-life networks on a network classification problem.",
    "descriptor": "\nComments: Accepted by 2022 30th Signal Processing and Communications Applications Conference (SIU)\n",
    "authors": [
      "Murat \u00c7elik",
      "Ali Baran Ta\u015fdemir",
      "Lale \u00d6zkahya"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11561"
  },
  {
    "id": "arXiv:2210.11563",
    "title": "Dense Paraphrasing for Textual Enrichment",
    "abstract": "Understanding inferences and answering questions from text requires more than\nmerely recovering surface arguments, adjuncts, or strings associated with the\nquery terms. As humans, we interpret sentences as contextualized components of\na narrative or discourse, by both filling in missing information, and reasoning\nabout event consequences. In this paper, we define the process of rewriting a\ntextual expression (lexeme or phrase) such that it reduces ambiguity while also\nmaking explicit the underlying semantics that is not (necessarily) expressed in\nthe economy of sentence structure as Dense Paraphrasing (DP). We build the\nfirst complete DP dataset, provide the scope and design of the annotation task,\nand present results demonstrating how this DP process can enrich a source text\nto improve inferencing and QA task performance. The data and the source code\nwill be publicly available.",
    "descriptor": "",
    "authors": [
      "Jingxuan Tu",
      "Kyeongmin Rim",
      "Eben Holderness",
      "James Pustejovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11563"
  },
  {
    "id": "arXiv:2210.11566",
    "title": "Rethinking Learning Approaches for Long-Term Action Anticipation",
    "abstract": "Action anticipation involves predicting future actions having observed the\ninitial portion of a video. Typically, the observed video is processed as a\nwhole to obtain a video-level representation of the ongoing activity in the\nvideo, which is then used for future prediction. We introduce ANTICIPATR which\nperforms long-term action anticipation leveraging segment-level representations\nlearned using individual segments from different activities, in addition to a\nvideo-level representation. We propose a two-stage learning approach to train a\nnovel transformer-based model that uses these two types of representations to\ndirectly predict a set of future action instances over any given anticipation\nduration. Results on Breakfast, 50Salads, Epic-Kitchens-55, and EGTEA Gaze+\ndatasets demonstrate the effectiveness of our approach.",
    "descriptor": "\nComments: Accepted at ECCV'22. Project page: this http URL\n",
    "authors": [
      "Megha Nawhal",
      "Akash Abdu Jyothi",
      "Greg Mori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11566"
  },
  {
    "id": "arXiv:2210.11570",
    "title": "Online Resource Allocation with Buyback: Optimal Algorithms via  Primal-Dual",
    "abstract": "Motivated by applications in cloud computing spot markets and selling banner\nads on popular websites, we study the online resource allocation problem with\n\"costly buyback\". To model this problem, we consider the classic edge-weighted\nfractional online matching problem with a tweak, where the decision maker can\nrecall (i.e., buyback) any fraction of an offline resource that is\npre-allocated to an earlier online vertex; however, by doing so not only the\ndecision maker loses the previously allocated reward (which equates the\nedge-weight), it also has to pay a non-negative constant factor $f$ of this\nedge-weight as an extra penalty. Parameterizing the problem by the buyback\nfactor $f$, our main result is obtaining optimal competitive algorithms for all\npossible values of $f$ through a novel primal-dual family of algorithms. We\nestablish the optimality of our results by obtaining separate lower-bounds for\neach of small and large buyback factor regimes, and showing how our primal-dual\nalgorithm exactly matches this lower-bound by appropriately tuning a parameter\nas a function of $f$. We further study lower and upper bounds on the\ncompetitive ratio in variants of this model, e.g., single-resource with\ndifferent demand sizes, or matching with deterministic integral allocations. We\nshow how algorithms in the our family of primal-dual algorithms can obtain the\nexact optimal competitive ratio in all of these variants -- which in turn\ndemonstrates the power of our algorithmic framework for online resource\nallocations with costly buyback.",
    "descriptor": "",
    "authors": [
      "Farbod Ekbatani",
      "Yiding Feng",
      "Rad Niazadeh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11570"
  },
  {
    "id": "arXiv:2210.11571",
    "title": "TrustBoost: Boosting Trust among Interoperable Blockchains",
    "abstract": "Currently there exist many blockchains with weak trust guarantees, limiting\napplications and participation. Existing solutions to boost the trust using a\nstronger blockchain, e.g., via checkpointing, requires the weaker blockchain to\ngive up sovereignty. In this paper we propose a family of protocols in which\nmultiple blockchains interact to create a combined ledger with boosted trust.\nWe show that even if several of the interacting blockchains cease to provide\nsecurity guarantees, the combined ledger continues to be secure - our\nTrustBoost protocols achieve the optimal threshold of tolerating the insecure\nblockchains. Furthermore, the protocol simply operates via smart contracts and\nrequire no change to the underlying consensus protocols of the participating\nblockchains, a form of \"consensus on top of consensus\". The protocols are\nlightweight and can be used on specific (e.g., high value) transactions; we\ndemonstrate the practicality by implementing and deploying TrustBoost as\ncross-chain smart contracts in the Cosmos ecosystem using approximately 3,000\nlines of Rust code, made available as open source. Our evaluation shows that\nusing 10 Cosmos chains in a local testnet, TrustBoost has a gas cost of roughly\n$2 with a latency of 2 minutes per request, which is in line with the cost on a\nhigh security chain such as Bitcoin or Ethereum.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Xuechao Wang",
      "Peiyao Sheng",
      "Sreeram Kannan",
      "Kartik Nayak",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11571"
  },
  {
    "id": "arXiv:2210.11572",
    "title": "LiBeamsNet: AUV Velocity Vector Estimation in Situations of Limited DVL  Beam Measurements",
    "abstract": "Autonomous underwater vehicles (AUVs) are employed for marine applications\nand can operate in deep underwater environments beyond human reach. A standard\nsolution for the autonomous navigation problem can be obtained by fusing the\ninertial navigation system and the Doppler velocity log sensor (DVL). The\nlatter measures four beam velocities to estimate the vehicle's velocity vector.\nIn real-world scenarios, the DVL may receive less than three beam velocities if\nthe AUV operates in complex underwater environments. In such conditions, the\nvehicle's velocity vector could not be estimated leading to a navigation\nsolution drift and in some situations the AUV is required to abort the mission\nand return to the surface. To circumvent such a situation, in this paper we\npropose a deep learning framework, LiBeamsNet, that utilizes the inertial data\nand the partial beam velocities to regress the missing beams in two missing\nbeams scenarios. Once all the beams are obtained, the vehicle's velocity vector\ncan be estimated. The approach performance was validated by sea experiments in\nthe Mediterranean Sea. The results show up to 7.2% speed error in the vehicle's\nvelocity vector estimation in a scenario that otherwise could not provide an\nestimate.",
    "descriptor": "",
    "authors": [
      "Nadav Cohen",
      "Itzik Klein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11572"
  },
  {
    "id": "arXiv:2210.11579",
    "title": "Model-based Lifelong Reinforcement Learning with Bayesian Exploration",
    "abstract": "We propose a model-based lifelong reinforcement-learning approach that\nestimates a hierarchical Bayesian posterior distilling the common structure\nshared across different tasks. The learned posterior combined with a\nsample-based Bayesian exploration procedure increases the sample efficiency of\nlearning across a family of related tasks. We first derive an analysis of the\nrelationship between the sample complexity and the initialization quality of\nthe posterior in the finite MDP setting. We next scale the approach to\ncontinuous-state domains by introducing a Variational Bayesian Lifelong\nReinforcement Learning algorithm that can be combined with recent model-based\ndeep RL methods, and that exhibits backward transfer. Experimental results on\nseveral challenging domains show that our algorithms achieve both better\nforward and backward transfer performance than state-of-the-art lifelong RL\nmethods.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Haotian Fu",
      "Shangqun Yu",
      "Michael Littman",
      "George Konidaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11579"
  },
  {
    "id": "arXiv:2210.11582",
    "title": "Deep Learning for Diagonal Earlobe Crease Detection",
    "abstract": "An article published on Medical News Today in June 2022 presented a\nfundamental question in its title: Can an earlobe crease predict heart attacks?\nThe author explained that end arteries supply the heart and ears. In other\nwords, if they lose blood supply, no other arteries can take over, resulting in\ntissue damage. Consequently, some earlobes have a diagonal crease, line, or\ndeep fold that resembles a wrinkle. In this paper, we take a step toward\ndetecting this specific marker, commonly known as DELC or Frank's Sign. For\nthis reason, we have made the first DELC dataset available to the public. In\naddition, we have investigated the performance of numerous cutting-edge\nbackbones on annotated photos. Experimentally, we demonstrate that it is\npossible to solve this challenge by combining pre-trained encoders with a\ncustomized classifier to achieve 97.7% accuracy. Moreover, we have analyzed the\nbackbone trade-off between performance and size, estimating MobileNet as the\nmost promising encoder.",
    "descriptor": "",
    "authors": [
      "Sara L. Almonacid-Uribe",
      "Oliverio J. Santana",
      "Daniel Hern\u00e1ndez-Sosa",
      "David Freire-Obreg\u00f3n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11582"
  },
  {
    "id": "arXiv:2210.11584",
    "title": "Towards Human-centered Explainable AI: User Studies for Model  Explanations",
    "abstract": "Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI\nresearch. A better understanding of the needs of XAI users, as well as\nhuman-centered evaluations of explainable models are both a necessity and a\nchallenge. In this paper, we explore how HCI and AI researchers conduct user\nstudies in XAI applications based on a systematic literature review. After\nidentifying and thoroughly analyzing 85 core papers with human-based XAI\nevaluations over the past five years, we categorize them along the measured\ncharacteristics of explanatory methods, namely trust, understanding, fairness,\nusability, and human-AI team performance. Our research shows that XAI is\nspreading more rapidly in certain application domains, such as recommender\nsystems than in others, but that user evaluations are still rather sparse and\nincorporate hardly any insights from cognitive or social sciences. Based on a\ncomprehensive discussion of best practices, i.e., common models, design\nchoices, and measures in user studies, we propose practical guidelines on\ndesigning and conducting user studies for XAI researchers and practitioners.\nLastly, this survey also highlights several open research directions,\nparticularly linking psychological science and human-centered XAI.",
    "descriptor": "",
    "authors": [
      "Yao Rong",
      "Tobias Leemann",
      "Thai-trang Nguyen",
      "Lisa Fiedler",
      "Tina Seidel",
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11584"
  },
  {
    "id": "arXiv:2210.11589",
    "title": "Monotonic Risk Relationships under Distribution Shifts for Regularized  Risk Minimization",
    "abstract": "Machine learning systems are often applied to data that is drawn from a\ndifferent distribution than the training distribution. Recent work has shown\nthat for a variety of classification and signal reconstruction problems, the\nout-of-distribution performance is strongly linearly correlated with the\nin-distribution performance. If this relationship or more generally a monotonic\none holds, it has important consequences. For example, it allows to optimize\nperformance on one distribution as a proxy for performance on the other. In\nthis paper, we study conditions under which a monotonic relationship between\nthe performances of a model on two distributions is expected. We prove an exact\nasymptotic linear relation for squared error and a monotonic relation for\nmisclassification error for ridge-regularized general linear models under\ncovariate shift, as well as an approximate linear relation for linear inverse\nproblems.",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Daniel LeJeune",
      "Jiayu Liu",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11589"
  },
  {
    "id": "arXiv:2210.11590",
    "title": "XC: Exploring Quantitative Use Cases for Explanations in 3D Object  Detection",
    "abstract": "Explainable AI (XAI) methods are frequently applied to obtain qualitative\ninsights about deep models' predictions. However, such insights need to be\ninterpreted by a human observer to be useful. In this paper, we aim to use\nexplanations directly to make decisions without human observers. We adopt two\ngradient-based explanation methods, Integrated Gradients (IG) and backprop, for\nthe task of 3D object detection. Then, we propose a set of quantitative\nmeasures, named Explanation Concentration (XC) scores, that can be used for\ndownstream tasks. These scores quantify the concentration of attributions\nwithin the boundaries of detected objects. We evaluate the effectiveness of XC\nscores via the task of distinguishing true positive (TP) and false positive\n(FP) detected objects in the KITTI and Waymo datasets. The results demonstrate\nan improvement of more than 100\\% on both datasets compared to other heuristics\nsuch as random guesses and the number of LiDAR points in the bounding box,\nraising confidence in XC's potential for application in more use cases. Our\nresults also indicate that computationally expensive XAI methods like IG may\nnot be more valuable when used quantitatively compare to simpler methods.",
    "descriptor": "\nComments: Accepted at 1st Workshop on eXplainable AI approaches for debugging and diagnosis (XAI4Debugging@NeurIPS2021)\n",
    "authors": [
      "Sunsheng Gu",
      "Vahdat Abdelzad",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11590"
  },
  {
    "id": "arXiv:2210.11592",
    "title": "New data poison attacks on machine learning classifiers for mobile  exfiltration",
    "abstract": "Most recent studies have shown several vulnerabilities to attacks with the\npotential to jeopardize the integrity of the model, opening in a few recent\nyears a new window of opportunity in terms of cyber-security. The main interest\nof this paper is directed towards data poisoning attacks involving\nlabel-flipping, this kind of attacks occur during the training phase, being the\naim of the attacker to compromise the integrity of the targeted machine\nlearning model by drastically reducing the overall accuracy of the model and/or\nachieving the missclassification of determined samples. This paper is conducted\nwith intention of proposing two new kinds of data poisoning attacks based on\nlabel-flipping, the targeted of the attack is represented by a variety of\nmachine learning classifiers dedicated for malware detection using mobile\nexfiltration data. With that, the proposed attacks are proven to be\nmodel-agnostic, having successfully corrupted a wide variety of machine\nlearning models; Logistic Regression, Decision Tree, Random Forest and KNN are\nsome examples. The first attack is performs label-flipping actions randomly\nwhile the second attacks performs label flipping only one of the 2 classes in\nparticular. The effects of each attack are analyzed in further detail with\nspecial emphasis on the accuracy drop and the misclassification rate. Finally,\nthis paper pursuits further research direction by suggesting the development of\na defense technique that could promise a feasible detection and/or mitigation\nmechanisms; such technique should be capable of conferring a certain level of\nrobustness to a target model against potential attackers.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.10276\n",
    "authors": [
      "Miguel A. Ramirez",
      "Sangyoung Yoon",
      "Ernesto Damiani",
      "Hussam Al Hamadi",
      "Claudio Agostino Ardagna",
      "Nicola Bena",
      "Young-Ji Byon",
      "Tae-Yeon Kim",
      "Chung-Suk Cho",
      "Chan Yeob Yeun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11592"
  },
  {
    "id": "arXiv:2210.11594",
    "title": "Photo-realistic 360 Head Avatars in the Wild",
    "abstract": "Delivering immersive, 3D experiences for human communication requires a\nmethod to obtain 360 degree photo-realistic avatars of humans. To make these\nexperiences accessible to all, only commodity hardware, like mobile phone\ncameras, should be necessary to capture the data needed for avatar creation.\nFor avatars to be rendered realistically from any viewpoint, we require\ntraining images and camera poses from all angles. However, we cannot rely on\nthere being trackable features in the foreground or background of all images\nfor use in estimating poses, especially from the side or back of the head. To\novercome this, we propose a novel landmark detector trained on synthetic data\nto estimate camera poses from 360 degree mobile phone videos of a human head\nfor use in a multi-stage optimization process which creates a photo-realistic\navatar. We perform validation experiments with synthetic data and showcase our\nmethod on 360 degree avatars trained from mobile phone videos.",
    "descriptor": "\nComments: ECCV 2022 Workshop on Computer Vision for Metaverse\n",
    "authors": [
      "Stanislaw Szymanowicz",
      "Virginia Estellers",
      "Tadas Baltrusaitis",
      "Matthew Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11594"
  },
  {
    "id": "arXiv:2210.11598",
    "title": "Identifying Human Strategies for Generating Word-Level Adversarial  Examples",
    "abstract": "Adversarial examples in NLP are receiving increasing research attention. One\nline of investigation is the generation of word-level adversarial examples\nagainst fine-tuned Transformer models that preserve naturalness and\ngrammaticality. Previous work found that human- and machine-generated\nadversarial examples are comparable in their naturalness and grammatical\ncorrectness. Most notably, humans were able to generate adversarial examples\nmuch more effortlessly than automated attacks. In this paper, we provide a\ndetailed analysis of exactly how humans create these adversarial examples. By\nexploring the behavioural patterns of human workers during the generation\nprocess, we identify statistically significant tendencies based on which words\nhumans prefer to select for adversarial replacement (e.g., word frequencies,\nword saliencies, sentiment) as well as where and when words are replaced in an\ninput sequence. With our findings, we seek to inspire efforts that harness\nhuman strategies for more robust NLP models.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Maximilian Mozes",
      "Bennett Kleinberg",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11598"
  },
  {
    "id": "arXiv:2210.11599",
    "title": "The VolcTrans System for WMT22 Multilingual Machine Translation Task",
    "abstract": "This report describes our VolcTrans system for the WMT22 shared task on\nlarge-scale multilingual machine translation. We participated in the\nunconstrained track which allows the use of external resources. Our system is a\ntransformerbased multilingual model trained on data from multiple sources\nincluding the public training set from the data track, NLLB data provided by\nMeta AI, self-collected parallel corpora, and pseudo bitext from\nback-translation. A series of heuristic rules clean both bilingual and\nmonolingual texts. On the official test set, our system achieves 17.3 BLEU,\n21.9 spBLEU, and 41.9 chrF2++ on average over all language pairs. The average\ninference speed is 11.5 sentences per second using a single Nvidia Tesla V100\nGPU. Our code and trained models are available at\nhttps://github.com/xian8/wmt22",
    "descriptor": "\nComments: WMT 2022, 8 pages\n",
    "authors": [
      "Xian Qian",
      "Kai Hu",
      "Jiaqiang Wang",
      "Yifeng Liu",
      "Xingyuan Pan",
      "Jun Cao",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11599"
  },
  {
    "id": "arXiv:2210.11601",
    "title": "gSuite: A Flexible and Framework Independent Benchmark Suite for Graph  Neural Network Inference on GPUs",
    "abstract": "As the interest to Graph Neural Networks (GNNs) is growing, the importance of\nbenchmarking and performance characterization studies of GNNs is increasing. So\nfar, we have seen many studies that investigate and present the performance and\ncomputational efficiency of GNNs. However, the work done so far has been\ncarried out using a few high-level GNN frameworks. Although these frameworks\nprovide ease of use, they contain too many dependencies to other existing\nlibraries. The layers of implementation details and the dependencies complicate\nthe performance analysis of GNN models that are built on top of these\nframeworks, especially while using architectural simulators. Furthermore,\ndifferent approaches on GNN computation are generally overlooked in prior\ncharacterization studies, and merely one of the common computational models is\nevaluated. Based on these shortcomings and needs that we observed, we developed\na benchmark suite that is framework independent, supporting versatile\ncomputational models, easily configurable and can be used with architectural\nsimulators without additional effort.\nOur benchmark suite, which we call gSuite, makes use of only hardware\nvendor's libraries and therefore it is independent of any other frameworks.\ngSuite enables performing detailed performance characterization studies on GNN\nInference using both contemporary GPU profilers and architectural GPU\nsimulators. To illustrate the benefits of our new benchmark suite, we perform a\ndetailed characterization study with a set of well-known GNN models with\nvarious datasets; running gSuite both on a real GPU card and a timing-detailed\nGPU simulator. We also implicate the effect of computational models on\nperformance. We use several evaluation metrics to rigorously measure the\nperformance of GNN computation.",
    "descriptor": "\nComments: IEEE International Symposium on Workload Characterization (IISWC) 2022\n",
    "authors": [
      "Taha Tekdo\u011fan",
      "Serkan G\u00f6kta\u015f",
      "Ayse Yilmazer-Metin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.11601"
  },
  {
    "id": "arXiv:2210.11603",
    "title": "3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows",
    "abstract": "Text-to-image AI systems are capable of generating novel images for\ninspiration, but their applications for 3D design workflows and how designers\ncan build 3D models using AI-provided inspiration is less understood. To\ninvestigate this, we integrated DALL-E, GPT-3, and CLIP within a CAD software\nin 3DALL-E, a plugin that allows users to construct text and image prompts\nbased on what they are modelling. In a study with 13 designers, we found that\ndesigners saw great potential to incorporate 3DALL-E into their workflows and\nto use text-to-image AI for reference images, renders, materials, and design\nconsiderations. Additionally, we elaborate on prompting patterns and provide\nmeasures of prompt complexity observed across participants. We conclude on a\ndiscussion of how 3DALL-E can merge with existing generative design workflows\nand propose prompt bibliographies as a form of human-AI design history.",
    "descriptor": "",
    "authors": [
      "Vivian Liu",
      "Jo Vermeulen",
      "George Fitzmaurice",
      "Justin Matejka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.11603"
  },
  {
    "id": "arXiv:2210.11604",
    "title": "Horizon-Free Reinforcement Learning for Latent Markov Decision Processes",
    "abstract": "We study regret minimization for reinforcement learning (RL) in Latent Markov\nDecision Processes (LMDPs) with context in hindsight. We design a novel\nmodel-based algorithmic framework which can be instantiated with both a\nmodel-optimistic and a value-optimistic solver. We prove an\n$\\widetilde{O}\\left(\\sqrt{M \\Gamma S A K}\\right)$ regret bound where $M$ is the\nnumber of contexts, $S$ is the number of states, $A$ is the number of actions,\n$K$ is the number of episodes, and $\\Gamma \\le S$ is the maximum transition\ndegree of any state-action pair. The regret bound only scales logarithmically\nwith the planning horizon, thus yielding the first (nearly) horizon-free regret\nbound for LMDP. Key in our proof is an analysis of the total variance of alpha\nvectors, which is carefully bounded by a recursion-based technique. We\ncomplement our positive result with a novel $\\Omega\\left(\\sqrt{M S A K}\\right)$\nregret lower bound with $\\Gamma = 2$, which shows our upper bound minimax\noptimal when $\\Gamma$ is a constant. Our lower bound relies on new\nconstructions of hard instances and an argument based on the symmetrization\ntechnique from theoretical computer science, both of which are technically\ndifferent from existing lower bound proof for MDPs, and thus can be of\nindependent interest.",
    "descriptor": "\nComments: 26 pages, 1 figure\n",
    "authors": [
      "Runlong Zhou",
      "Ruosong Wang",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11604"
  },
  {
    "id": "arXiv:2210.11607",
    "title": "On the robustness of inverse scattering for penetrable, homogeneous  objects with complicated boundary",
    "abstract": "The acoustic inverse obstacle scattering problem consists of determining the\nshape of a domain from measurements of the scattered far field due to some set\nof incident fields (probes). For a penetrable object with known sound speed,\nthis can be accomplished by treating the boundary alone as an unknown curve.\nAlternatively, one can treat the entire object as unknown and use a more\ngeneral volumetric representation, without making use of the known sound speed.\nBoth lead to strongly nonlinear and nonconvex optimization problems for which\nrecursive linearization provides a useful framework for numerical analysis.\nAfter extending our shape optimization approach developed earlier for\nimpenetrable bodies, we carry out a systematic study of both methods and\ncompare their performance on a variety of examples. Our findings indicate that\nthe volumetric approach is more robust, even though the number of degrees of\nfreedom is significantly larger. We conclude with a discussion of this\nphenomenon and potential directions for further research.",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Carlos Borges",
      "Manas Rachh",
      "Leslie Greengard"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11607"
  },
  {
    "id": "arXiv:2210.11608",
    "title": "Tag-Set-Sequence Learning for Generating Question-Answer Pairs",
    "abstract": "Transformer-based QG models can generate question-answer pairs (QAPs) with\nhigh qualities, but may also generate silly questions for certain texts. We\npresent a new method called tag-set sequence learning to tackle this problem,\nwhere a tag-set sequence is a sequence of tag sets to capture the syntactic and\nsemantic information of the underlying sentence, and a tag set consists of one\nor more language feature tags, including, for example, semantic-role-labeling,\npart-of-speech, named-entity-recognition, and sentiment-indication tags. We\nconstruct a system called TSS-Learner to learn tag-set sequences from given\ndeclarative sentences and the corresponding interrogative sentences, and derive\nanswers to the latter. We train a TSS-Learner model for the English language\nusing a small training dataset and show that it can indeed generate adequate\nQAPs for certain texts that transformer-based models do poorly. Human\nevaluation on the QAPs generated by TSS-Learner over SAT practice reading tests\nis encouraging.",
    "descriptor": "",
    "authors": [
      "Cheng Zhang",
      "Jie Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11608"
  },
  {
    "id": "arXiv:2210.11610",
    "title": "Large Language Models Can Self-Improve",
    "abstract": "Large Language Models (LLMs) have achieved excellent performances in various\ntasks. However, fine-tuning an LLM requires extensive supervision. Human, on\nthe other hand, may improve their reasoning abilities by self-thinking without\nexternal inputs. In this work, we demonstrate that an LLM is also capable of\nself-improving with only unlabeled datasets. We use a pre-trained LLM to\ngenerate \"high-confidence\" rationale-augmented answers for unlabeled questions\nusing Chain-of-Thought prompting and self-consistency, and fine-tune the LLM\nusing those self-generated solutions as target outputs. We show that our\napproach improves the general reasoning ability of a 540B-parameter LLM\n(74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and\n63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance,\nwithout any ground truth label. We conduct ablation studies and show that\nfine-tuning on reasoning is critical for self-improvement.",
    "descriptor": "",
    "authors": [
      "Jiaxin Huang",
      "Shixiang Shane Gu",
      "Le Hou",
      "Yuexin Wu",
      "Xuezhi Wang",
      "Hongkun Yu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11610"
  },
  {
    "id": "arXiv:2210.11616",
    "title": "Generalized Reciprocal Perspective",
    "abstract": "Across many domains, real-world problems can be represented as a network.\nNodes represent domain-specific elements and edges capture the relationship\nbetween elements. Leveraging high-performance computing and optimized link\nprediction algorithms, it is increasingly possible to evaluate every possible\ncombination of nodal pairs enabling the generation of a comprehensive\nprediction matrix (CPM) that places an individual link prediction score in the\ncontext of all possible links involving either node (providing data-driven\ncontext). Historically, this contextual information has been ignored given\nexponentially growing problem sizes resulting in computational intractability;\nhowever, we demonstrate that expending high-performance compute resources to\ngenerate CPMs is a worthwhile investment given the improvement in predictive\nperformance. In this work, we generalize for all pairwise link-prediction tasks\nour novel semi-supervised machine learning method, denoted Reciprocal\nPerspective (RP). We demonstrate that RP significantly improves link prediction\naccuracy by leveraging the wealth of information in a CPM. Context-based\nfeatures are extracted from the CPM for use in a stacked classifier and we\ndemonstrate that the application of RP in a cascade almost always results in\nsignificantly (p < 0.05) improved predictions. These results on RS-type\nproblems suggest that RP is applicable to a broad range of link prediction\nproblems.",
    "descriptor": "",
    "authors": [
      "Kevin Dick",
      "Daniel G. Kyrollos",
      "James R. Green"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11616"
  },
  {
    "id": "arXiv:2210.11617",
    "title": "Boosting Natural Language Generation from Instructions with  Meta-Learning",
    "abstract": "Recent work has shown that language models (LMs) trained with multi-task\n\\textit{instructional learning} (MTIL) can solve diverse NLP tasks in zero- and\nfew-shot settings with improved performance compared to prompt tuning. MTIL\nillustrates that LMs can extract and use information about the task from\ninstructions beyond the surface patterns of the inputs and outputs. This\nsuggests that meta-learning may further enhance the utilization of instructions\nfor effective task transfer. In this paper we investigate whether meta-learning\napplied to MTIL can further improve generalization to unseen tasks in a\nzero-shot setting. Specifically, we propose to adapt meta-learning to MTIL in\nthree directions: 1) Model Agnostic Meta Learning (MAML), 2) Hyper-Network\n(HNet) based adaptation to generate task specific parameters conditioned on\ninstructions, and 3) an approach combining HNet and MAML. Through extensive\nexperiments on the large scale Natural Instructions V2 dataset, we show that\nour proposed approaches significantly improve over strong baselines in\nzero-shot settings. In particular, meta-learning improves the effectiveness of\ninstructions and is most impactful when the test tasks are strictly zero-shot\n(i.e. no similar tasks in the training set) and are \"hard\" for LMs,\nillustrating the potential of meta-learning for MTIL for out-of-distribution\ntasks.",
    "descriptor": "",
    "authors": [
      "Budhaditya Deb",
      "Guoqing Zheng",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11617"
  },
  {
    "id": "arXiv:2210.11618",
    "title": "Multitasking Models are Robust to Structural Failure: A Neural Model for  Bilingual Cognitive Reserve",
    "abstract": "We find a surprising connection between multitask learning and robustness to\nneuron failures. Our experiments show that bilingual language models retain\nhigher performance under various neuron perturbations, such as random\ndeletions, magnitude pruning and weight noise compared to equivalent\nmonolingual ones. We provide a theoretical justification for this robustness by\nmathematically analyzing linear representation learning and showing that\nmultitasking creates more robust representations. Our analysis connects\nrobustness to spectral properties of the learned representation and proves that\nmultitasking leads to higher robustness for diverse task vectors. We\nopen-source our code and models:\nhttps://github.com/giannisdaras/multilingual_robustness",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. 22 pages, 11 Figures\n",
    "authors": [
      "Giannis Daras",
      "Negin Raoof",
      "Zoi Gkalitsiou",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11618"
  },
  {
    "id": "arXiv:2210.11620",
    "title": "LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness",
    "abstract": "Recent studies show that training deep neural networks (DNNs) with Lipschitz\nconstraints are able to enhance adversarial robustness and other model\nproperties such as stability. In this paper, we propose a layer-wise orthogonal\ntraining method (LOT) to effectively train 1-Lipschitz convolution layers via\nparametrizing an orthogonal matrix with an unconstrained matrix. We then\nefficiently compute the inverse square root of a convolution kernel by\ntransforming the input domain to the Fourier frequency domain. On the other\nhand, as existing works show that semi-supervised training helps improve\nempirical robustness, we aim to bridge the gap and prove that semi-supervised\nlearning also improves the certified robustness of Lipschitz-bounded models. We\nconduct comprehensive evaluations for LOT under different settings. We show\nthat LOT significantly outperforms baselines regarding deterministic l2\ncertified robustness, and scales to deeper neural networks. Under the\nsupervised scenario, we improve the state-of-the-art certified robustness for\nall architectures (e.g. from 59.04% to 63.50% on CIFAR-10 and from 32.57% to\n34.59% on CIFAR-100 at radius rho = 36/255 for 40-layer networks). With\nsemi-supervised learning over unlabelled data, we are able to improve\nstate-of-the-art certified robustness on CIFAR-10 at rho = 108/255 from 36.04%\nto 42.39%. In addition, LOT consistently outperforms baselines on different\nmodel architectures with only 1/3 evaluation time.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Xiaojun Xu",
      "Linyi Li",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11620"
  },
  {
    "id": "arXiv:2210.11621",
    "title": "SMaLL-100: Introducing Shallow Multilingual Machine Translation Model  for Low-Resource Languages",
    "abstract": "In recent years, multilingual machine translation models have achieved\npromising performance on low-resource language pairs by sharing information\nbetween similar languages, thus enabling zero-shot translation. To overcome the\n\"curse of multilinguality\", these models often opt for scaling up the number of\nparameters, which makes their use in resource-constrained environments\nchallenging. We introduce SMaLL-100, a distilled version of the M2M-100 (12B)\nmodel, a massively multilingual machine translation model covering 100\nlanguages. We train SMaLL-100 with uniform sampling across all language pairs\nand therefore focus on preserving the performance of low-resource languages. We\nevaluate SMaLL-100 on different low-resource benchmarks: FLORES-101, Tatoeba,\nand TICO-19 and demonstrate that it outperforms previous massively multilingual\nmodels of comparable sizes (200-600M) while improving inference latency and\nmemory usage. Additionally, our model achieves comparable results to M2M-100\n(1.2B), while being 3.6x smaller and 4.3x faster at inference. Code and\npre-trained models: https://github.com/alirezamshi/small100",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Alireza Mohammadshahi",
      "Vassilina Nikoulina",
      "Alexandre Berard",
      "Caroline Brun",
      "James Henderson",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11621"
  },
  {
    "id": "arXiv:2210.11624",
    "title": "Sparse Dynamical Features generation, application to Parkinson's Disease  diagnosis",
    "abstract": "In this study we focus on the diagnosis of Parkinson's Disease (PD) based on\nelectroencephalogram (EEG) signals. We propose a new approach inspired by the\nfunctioning of the brain that uses the dynamics, frequency and temporal content\nof EEGs to extract new demarcating features of the disease. The method was\nevaluated on a publicly available dataset containing EEG signals recorded\nduring a 3-oddball auditory task involving N = 50 subjects, of whom 25 suffer\nfrom PD. By extracting two features, and separating them with a straight line\nusing a Linear Discriminant Analysis (LDA) classifier, we can separate the\nhealthy from the unhealthy subjects with an accuracy of 90% (p <\n1.8$\\times$10-5) using a single channel. By aggregating the information from\nthree channels and making them vote, we obtain an accuracy of 94 %, a\nsensitivity of 96 % and a specificity of 92 %. The evaluation was carried out\nusing a nested leave-one-out cross-validation procedure, thus preventing data\nleakage problems and giving a less biased evaluation. Several tests were\ncarried out to assess the validity and robustness of our approach, including\nthe test where we use only half the available data for training. Under this\nconstraint, the model achieves an accuracy of 89.4 %.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Houssem Meghnoudj",
      "Bogdan Robu",
      "Mazen Alamir"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11624"
  },
  {
    "id": "arXiv:2210.11628",
    "title": "Can Domains Be Transferred Across Languages in Multi-Domain Multilingual  Neural Machine Translation?",
    "abstract": "Previous works mostly focus on either multilingual or multi-domain aspects of\nneural machine translation (NMT). This paper investigates whether the domain\ninformation can be transferred across languages on the composition of\nmulti-domain and multilingual NMT, particularly for the incomplete data\ncondition where in-domain bitext is missing for some language pairs. Our\nresults in the curated leave-one-domain-out experiments show that multi-domain\nmultilingual (MDML) NMT can boost zero-shot translation performance up to +10\ngains on BLEU, as well as aid the generalisation of multi-domain NMT to the\nmissing domain. We also explore strategies for effective integration of\nmultilingual and multi-domain NMT, including language and domain tag\ncombination and auxiliary task training. We find that learning domain-aware\nrepresentations and adding target-language tags to the encoder leads to\neffective MDML-NMT.",
    "descriptor": "\nComments: WMT2022\n",
    "authors": [
      "Thuy-Trang Vu",
      "Shahram Khadivi",
      "Xuanli He",
      "Dinh Phung",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11628"
  },
  {
    "id": "arXiv:2210.11630",
    "title": "Using Large Language Models to Enhance Programming Error Messages",
    "abstract": "A key part of learning to program is learning to understand programming error\nmessages. They can be hard to interpret and identifying the cause of errors can\nbe time-consuming. One factor in this challenge is that the messages are\ntypically intended for an audience that already knows how to program, or even\nfor programming environments that then use the information to highlight areas\nin code. Researchers have been working on making these errors more novice\nfriendly since the 1960s, however progress has been slow. The present work\ncontributes to this stream of research by using large language models to\nenhance programming error messages with explanations of the errors and\nsuggestions on how to fix the error. Large language models can be used to\ncreate useful and novice-friendly enhancements to programming error messages\nthat sometimes surpass the original programming error messages in\ninterpretability and actionability. These results provide further evidence of\nthe benefits of large language models for computing educators, highlighting\ntheir use in areas known to be challenging for students. We further discuss the\nbenefits and downsides of large language models and highlight future streams of\nresearch for enhancing programming error messages.",
    "descriptor": "\nComments: 7 pages, accepted for publication at SIGCSE TS 2023\n",
    "authors": [
      "Juho Leinonen",
      "Arto Hellas",
      "Sami Sarsa",
      "Brent Reeves",
      "Paul Denny",
      "James Prather",
      "Brett A. Becker"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11630"
  },
  {
    "id": "arXiv:2210.11633",
    "title": "Graphically Structured Diffusion Models",
    "abstract": "We introduce a framework for automatically defining and learning deep\ngenerative models with problem-specific structure. We tackle problem domains\nthat are more traditionally solved by algorithms such as sorting, constraint\nsatisfaction for Sudoku, and matrix factorization. Concretely, we train\ndiffusion models with an architecture tailored to the problem specification.\nThis problem specification should contain a graphical model describing\nrelationships between variables, and often benefits from explicit\nrepresentation of subcomputations. Permutation invariances can also be\nexploited. Across a diverse set of experiments we improve the scaling\nrelationship between problem dimension and our model's performance, in terms of\nboth training time and final accuracy.",
    "descriptor": "",
    "authors": [
      "Christian Weilbach",
      "William Harvey",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.11633"
  },
  {
    "id": "arXiv:2210.11634",
    "title": "A polynomial-time algorithm to solve the large scale of airplane  refueling problem",
    "abstract": "Airplane refueling problem (ARP) is a scheduling problem with an objective\nfunction of fractional form. Given a fleet of $n$ airplanes with mid-air\nrefueling technique, each airplane has a specific fuel capacity and fuel\nconsumption rate. The fleet starts to fly together to a same target and during\nthe trip each airplane could instantaneously refuel to other airplanes and then\nbe dropped out. The question is how to find the best refueling policy to make\nthe last remaining airplane travels the farthest. We give a definition of the\nsequential feasible solution and construct a sequential search algorithm, whose\ncomputational complexity depends on the number of sequential feasible solutions\nreferred to $Q_n$. By utilizing combination and recurrence ideas, we prove that\nthe the upper bound of $Q_n$ is $2^{n-2}$. Then we focus on the worst-case and\ninvestigate the complexity of the sequential search algorithm from a dynamic\nperspective. Given a worst-case instance under some assumptions, we prove that\nthere must exist an index $m$ such that when $n$ is greater than $2m$, $Q_n$\nturns out to be upper bounded by $\\frac{m^2}{n}C_n^m$. Here the index $m$ is a\nconstant and could be regarded as an \"inflection point\": with the increasing\nscale of input $n$, $Q_n$ turns out to be a polynomial function of $n$. Hence,\nthe sequential search algorithm turns out to run in polynomial time of $n$.\nMoreover, we build an efficient computability scheme by which we shall predict\nthe complexity of $Q_n$ to choose a proper algorithm considering the available\nrunning time for decision makers or users.",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Jinchuan Cui",
      "Xiaoya Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11634"
  },
  {
    "id": "arXiv:2210.11636",
    "title": "Self-Censorship Under Law: A Case Study of The Hong Kong National  Security Law",
    "abstract": "We study how aggressive legislation can increase self-censorship and alter\nonline discourse, using Hong Kong's National Security Law as a case study. We\ncollect a dataset of 7 million historical Tweets from Hong Kong users,\nsupplemented with historical snapshots of Tweet streams collected by other\nresearchers. We find that Hong Kong users demonstrate two types of\nself-censorship, and that the rate of self-censorship continues to increase.\nFirst, we find that Hong Kong users are more likely than a control group,\nsampled randomly from historical snapshots of Tweet streams, to remove past\nonline activity. They are 35.74% more likely than this group to make their\naccounts private, and over two times as likely to delete past posts. We also\nfind that since the passing of the National Security Law, Hong Kongers are\ncontinuing to speak less about politically sensitive topics that have been\ncensored on social media platforms in mainland China.",
    "descriptor": "",
    "authors": [
      "Mona Wang",
      "Jonathan Mayer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.11636"
  },
  {
    "id": "arXiv:2210.11637",
    "title": "Slippage-robust Gaze Tracking for Near-eye Display",
    "abstract": "In recent years, head-mounted near-eye display devices have become the key\nhardware foundation for virtual reality and augmented reality. Thus\nhead-mounted gaze tracking technology has received attention as an essential\npart of human-computer interaction. However, unavoidable slippage of\nhead-mounted devices (HMD) often results higher gaze tracking errors and\nhinders the practical usage of HMD. To tackle this problem, we propose a\nslippage-robust gaze tracking for near-eye display method based on the aspheric\neyeball model and accurately compute the eyeball optical axis and rotation\ncenter. We tested several methods on datasets with slippage and the\nexperimental results show that the proposed method significantly outperforms\nthe previous method (almost double the suboptimal method).",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Wei Zhang",
      "Jiaxi Cao",
      "Xiang Wang",
      "Enqi Tian",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11637"
  },
  {
    "id": "arXiv:2210.11639",
    "title": "HesScale: Scalable Computation of Hessian Diagonals",
    "abstract": "Second-order optimization uses curvature information about the objective\nfunction, which can help in faster convergence. However, such methods typically\nrequire expensive computation of the Hessian matrix, preventing their usage in\na scalable way. The absence of efficient ways of computation drove the most\nwidely used methods to focus on first-order approximations that do not capture\nthe curvature information. In this paper, we develop HesScale, a scalable\napproach to approximating the diagonal of the Hessian matrix, to incorporate\nsecond-order information in a computationally efficient manner. We show that\nHesScale has the same computational complexity as backpropagation. Our results\non supervised classification show that HesScale achieves high approximation\naccuracy, allowing for scalable and efficient second-order optimization.",
    "descriptor": "",
    "authors": [
      "Mohamed Elsayed",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11639"
  },
  {
    "id": "arXiv:2210.11640",
    "title": "Sinophobia, misogyny, facism, and many more: A multi-ethnic approach to  identifying anti-Asian racism in social media",
    "abstract": "Anti-Asian hate/toxic/racial speech has recently increased, especially in\nresponse to the outbreak of COVID-19. However, heavy focus on the COVID-19\ncontext and subsequent Sinophobia may have over-represented Chinese-attacking\nphenomena rather than offering insights applicable to pan-Asian communities. To\nfill this gap, this paper underscores a cross-ethnic contextual understanding\nby taking a multi-ethnic approach to identifying and describing anti-Asian\nracism expressed in Twitter. The study examines (1) cross-ethnicity difference\n(or similarity) of anti-Asian expressions; (2) temporal dynamics of\ncross-ethnicity difference/similarity; (3) topical contexts underlying\nanti-Asian tweets; and (4) comparison between Sinophobic tweets and pan-Asian\nor non-Chinese Asian targeting tweets. The study uses a 12 month-long\nlarge-scale tweets that contain ethnicity-indicative search keywords, from\nwhich anti-Asian tweets are identified using deep-learning models. Multiple\ncorrespondence analysis and topic modeling are employed to address research\nquestions. Results show anti-Asian speeches are fragmented into several\ndistinctive groups, and such groupings change dynamically in response to\npolitical, social, and cultural reality surrounding ethnic relations. Findings\nsuggest that China is not a representative entity for pan-Asian ethnicity: Most\nof the times during the observed period, anti-China tweets are positioned\ndistantly from generically mentioned anti-Asian tweets in the $n$-gram-based\nmultidimensional space. Moreover, generic anti-Asian tweets show greater\ntopical similarities to the combined set of tweets that attack other Asian\nethnic groups than to the anti-China tweets. Pan-Asian tweets and\nChina-specific tweets become semantically similar in the aftermath of the\npandemic outbreak (from Feb. 2020 to Apr. 2020) yet only temporarily.",
    "descriptor": "",
    "authors": [
      "Sanyam Lakhanpal",
      "Zhemin Zhang",
      "Qian Li",
      "Kookjin Lee",
      "Doowon Kim",
      "Heewon Chae",
      "Hazel K. Kwon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11640"
  },
  {
    "id": "arXiv:2210.11642",
    "title": "Improving Semi-supervised End-to-end Automatic Speech Recognition using  CycleGAN and Inter-domain Losses",
    "abstract": "We propose a novel method that combines CycleGAN and inter-domain losses for\nsemi-supervised end-to-end automatic speech recognition. Inter-domain loss\ntargets the extraction of an intermediate shared representation of speech and\ntext inputs using a shared network. CycleGAN uses cycle-consistent loss and the\nidentity mapping loss to preserve relevant characteristics of the input feature\nafter converting from one domain to another. As such, both approaches are\nsuitable to train end-to-end models on unpaired speech-text inputs. In this\npaper, we exploit the advantages from both inter-domain loss and CycleGAN to\nachieve better shared representation of unpaired speech and text inputs and\nthus improve the speech-to-text mapping. Our experimental results on the WSJ\neval92 and Voxforge (non English) show 8~8.5% character error rate reduction\nover the baseline, and the results on LibriSpeech test_clean also show\nnoticeable improvement.",
    "descriptor": "\nComments: 6 pages + 2 references, 6 figures, accepted by SLT2022\n",
    "authors": [
      "Chia-Yu Li",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11642"
  },
  {
    "id": "arXiv:2210.11643",
    "title": "All Politics is Local: Redistricting via Local Fairness",
    "abstract": "In this paper, we propose to use the concept of local fairness for auditing\nand ranking redistricting plans. Given a redistricting plan, a deviating group\nis a population-balanced contiguous region in which a majority of individuals\nare of the same interest and in the minority of their respective districts;\nsuch a set of individuals have a justified complaint with how the redistricting\nplan was drawn. A redistricting plan with no deviating groups is called locally\nfair. We show that the problem of auditing a given plan for local fairness is\nNP-complete. We present an MCMC approach for auditing as well as ranking\nredistricting plans. We also present a dynamic programming based algorithm for\nthe auditing problem that we use to demonstrate the efficacy of our MCMC\napproach. Using these tools, we test local fairness on real-world election\ndata, showing that it is indeed possible to find plans that are almost or\nexactly locally fair. Further, we show that such plans can be generated while\nsacrificing very little in terms of compactness and existing fairness measures\nsuch as competitiveness of the districts or seat shares of the plans.",
    "descriptor": "",
    "authors": [
      "Shao-Heng Ko",
      "Erin Taylor",
      "Pankaj K. Agarwal",
      "Kamesh Munagala"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11643"
  },
  {
    "id": "arXiv:2210.11647",
    "title": "Approaches to Identify Vulnerabilities to Misinformation: A Research  Agenda",
    "abstract": "Given the prevalence of online misinformation and our scarce cognitive\ncapacity, Internet users have been shown to frequently fall victim to such\ninformation. As some studies have investigated psychological factors that make\npeople susceptible to believe or share misinformation, some ongoing research\nfurther put these findings into practice by objectively identifying when and\nwhich users are vulnerable to misinformation. In this position paper, we\nhighlight two ongoing avenues of research to identify vulnerable users:\ndetecting cognitive biases and exploring misinformation spreaders. We also\ndiscuss the potential implications of these objective approaches: discovering\nmore cohorts of vulnerable users and prompting interventions to more\neffectively address the right group of users. Lastly, we point out two of the\nunderstudied contexts for misinformation vulnerability research as\nopportunities for future research.",
    "descriptor": "\nComments: Position paper to a CHI 2022 workshop: Designing Credibility Tools To Combat Mis/Disinformation\n",
    "authors": [
      "Nattapat Boonprakong",
      "Benjamin Tag",
      "Tilman Dingler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.11647"
  },
  {
    "id": "arXiv:2210.11648",
    "title": "Two-stage Stochastic Matching and Pricing with Applications to Ride  Hailing",
    "abstract": "Matching and pricing are two critical levers in two-sided marketplaces to\nconnect demand and supply. The platform can produce more efficient matching and\npricing decisions by batching the demand requests. We initiate the study of the\ntwo-stage stochastic matching problem, with or without pricing, to enable the\nplatform to make improved decisions in a batch with an eye toward the imminent\nfuture demand requests. This problem is motivated in part by applications in\nonline marketplaces such as ride hailing platforms.\nWe design online competitive algorithms for vertex-weighted (or unweighted)\ntwo-stage stochastic matching for maximizing supply efficiency, and two-stage\njoint matching and pricing for maximizing market efficiency. In the former\nproblem, using a randomized primal-dual algorithm applied to a family of\n``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio\nagainst the optimum offline benchmark. Using a factor revealing program and\nconnections to submodular optimization, we improve this ratio against the\noptimum online benchmark to $(1-1/e+1/e^2)\\approx 0.767$ for the unweighted and\n$0.761$ for the weighted case. In the latter problem, we design optimal\n$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from\nthe ex-ante prophet inequality literature. We also show an improved\n$(1-1/e)$-competitive algorithm for the special case of demand efficiency\nobjective using the correlation gap of submodular functions. Finally, we\ncomplement our theoretical study by using DiDi's ride-sharing dataset for\nChengdu city and numerically evaluating the performance of our proposed\nalgorithms in practical instances of this problem.",
    "descriptor": "\nComments: Conference version: SODA 2021; Journal version: Operations Research\n",
    "authors": [
      "Yiding Feng",
      "Rad Niazadeh",
      "Amin Saberi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11648"
  },
  {
    "id": "arXiv:2210.11652",
    "title": "Motion Primitives Based Kinodynamic RRT for Autonomous Vehicle  Navigation in Complex Environments",
    "abstract": "In this work, we have implemented a SLAM-assisted navigation module for a\nreal autonomous vehicle with unknown dynamics. The navigation objective is to\nreach a desired goal configuration along a collision-free trajectory while\nadhering to the dynamics of the system. Specifically, we use LiDAR-based Hector\nSLAM for building the map of the environment, detecting obstacles, and for\ntracking vehicle's conformance to the trajectory as it passes through various\nstates. For motion planning, we use rapidly exploring random trees (RRTs) on a\nset of generated motion primitives to search for dynamically feasible\ntrajectory sequences and collision-free path to the goal. We demonstrate\ncomplex maneuvers such as parallel parking, perpendicular parking, and\nreversing motion by the real vehicle in a constrained environment using the\npresented approach.",
    "descriptor": "",
    "authors": [
      "Shubham Kedia",
      "Sambhu Harimanas Karumanchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11652"
  },
  {
    "id": "arXiv:2210.11653",
    "title": "PaCo: Parameter-Compositional Multi-Task Reinforcement Learning",
    "abstract": "The purpose of multi-task reinforcement learning (MTRL) is to train a single\npolicy that can be applied to a set of different tasks. Sharing parameters\nallows us to take advantage of the similarities among tasks. However, the gaps\nbetween contents and difficulties of different tasks bring us challenges on\nboth which tasks should share the parameters and what parameters should be\nshared, as well as the optimization challenges due to parameter sharing. In\nthis work, we introduce a parameter-compositional approach (PaCo) as an attempt\nto address these challenges. In this framework, a policy subspace represented\nby a set of parameters is learned. Policies for all the single tasks lie in\nthis subspace and can be composed by interpolating with the learned set. It\nallows not only flexible parameter sharing but also a natural way to improve\ntraining. We demonstrate the state-of-the-art performance on Meta-World\nbenchmarks, verifying the effectiveness of the proposed approach.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Lingfeng Sun",
      "Haichao Zhang",
      "Wei Xu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11653"
  },
  {
    "id": "arXiv:2210.11655",
    "title": "Safety-aware time-optimal motion planning with uncertain human state  estimation",
    "abstract": "Human awareness in robot motion planning is crucial for seamless interaction\nwith humans. Many existing techniques slow down, stop, or change the robot's\ntrajectory locally to avoid collisions with humans. Although using the\ninformation on the human's state in the path planning phase could reduce future\ninterference with the human's movements and make safety stops less frequent,\nsuch an approach is less widespread. This paper proposes a novel approach to\nembedding a human model in the robot's path planner. The method explicitly\naddresses the problem of minimizing the path execution time, including\nslowdowns and stops owed to the proximity of humans. For this purpose, it\nconverts safety speed limits into configuration-space cost functions that drive\nthe path's optimization. The costmap can be updated based on the observed or\npredicted state of the human. The method can handle deterministic and\nprobabilistic representations of the human state and is independent of the\nprediction algorithm. Numerical and experimental results on an industrial\ncollaborative cell demonstrate that the proposed approach consistently reduces\nthe robot's execution time and avoids unnecessary safety speed reductions.",
    "descriptor": "\nComments: Accepted in IEEE Robotics and Automation Letters, 2022\n",
    "authors": [
      "Marco Faroni",
      "Manuel Beschi",
      "Nicola Pedrocchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11655"
  },
  {
    "id": "arXiv:2210.11656",
    "title": "Evolutionary sparse data-driven discovery of complex multibody system  dynamics",
    "abstract": "The value of unknown parameters of multibody systems is crucial for\nprediction, monitoring, and control, sometimes estimated using a biased\nphysics-based model leading to incorrect outcomes. Discovering motion equations\nof multibody systems from time-series data is challenging as they consist of\ncomplex rational functions, constants as function arguments, and diverse\nfunction terms, which are not trivial to guess. This study aims at developing\nan evolutionary symbolic sparse regression approach for the system\nidentification of multibody systems. The procedure discovers equations of\nmotion and system parameters appearing as either constant values in function\narguments or coefficients of function expressions. A genetic programming\nalgorithm is written to generate symbolic function expressions, in which a\nhard-thresholding regression method is embedded. In an evolutionary manner, the\ncomplex functional forms, constant arguments, and unknown coefficients are\nidentified to eventually discover the governing equation of a given system. A\nfitness measure is presented to promote parsimony in distilled equations and\nreduction in fit-to-data error. Hybrid discrete-continuous dynamical systems\nare also investigated, for which an approach is suggested to determine both\nmode number and system submodels. The performance and efficiency of the\nsuggested evolutionary symbolic sparse regression methodology are evaluated in\na simulation environment. The capability of the developed approach is also\ndemonstrated by studying several multibody systems. The procedure is efficient\nand gives the possibility to estimate system parameters and distill respective\ngoverning equations. This technique reduces the risk that the function\ndictionary does not cover all functionality required to unravel hidden physical\nlaws and the need for prior knowledge of the mechanism of interest.",
    "descriptor": "",
    "authors": [
      "Ehsan Askari",
      "Guillaume Crevecoeur"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11656"
  },
  {
    "id": "arXiv:2210.11660",
    "title": "Learning Action Duration and Synergy in Task Planning for Human-Robot  Collaboration",
    "abstract": "A good estimation of the actions' cost is key in task planning for\nhuman-robot collaboration. The duration of an action depends on agents'\ncapabilities and the correlation between actions performed simultaneously by\nthe human and the robot. This paper proposes an approach to learning actions'\ncosts and coupling between actions executed concurrently by humans and robots.\nWe leverage the information from past executions to learn the average duration\nof each action and a synergy coefficient representing the effect of an action\nperformed by the human on the duration of the action performed by the robot\n(and vice versa). We implement the proposed method in a simulated scenario\nwhere both agents can access the same area simultaneously. Safety measures\nrequire the robot to slow down when the human is close, denoting a bad synergy\nof tasks operating in the same area. We show that our approach can learn such\nbad couplings so that a task planner can leverage this information to find\nbetter plans.",
    "descriptor": "\nComments: Accepted at IEEE Int. Conf. on Emerging Technology and Factory Automation, 2022\n",
    "authors": [
      "Samuele Sandrini",
      "Marco Faroni",
      "Nicola Pedrocchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11660"
  },
  {
    "id": "arXiv:2210.11662",
    "title": "Local Bayesian optimization via maximizing probability of descent",
    "abstract": "Local optimization presents a promising approach to expensive,\nhigh-dimensional black-box optimization by sidestepping the need to globally\nexplore the search space. For objective functions whose gradient cannot be\nevaluated directly, Bayesian optimization offers one solution -- we construct a\nprobabilistic model of the objective, design a policy to learn about the\ngradient at the current location, and use the resulting information to navigate\nthe objective landscape. Previous work has realized this scheme by minimizing\nthe variance in the estimate of the gradient, then moving in the direction of\nthe expected gradient. In this paper, we re-examine and refine this approach.\nWe demonstrate that, surprisingly, the expected value of the gradient is not\nalways the direction maximizing the probability of descent, and in fact, these\ndirections may be nearly orthogonal. This observation then inspires an elegant\noptimization scheme seeking to maximize the probability of descent while moving\nin the direction of most-probable descent. Experiments on both synthetic and\nreal-world objectives show that our method outperforms previous realizations of\nthis optimization scheme and is competitive against other, significantly more\ncomplicated baselines.",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Quan Nguyen",
      "Kaiwen Wu",
      "Jacob R. Gardner",
      "Roman Garnett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11662"
  },
  {
    "id": "arXiv:2210.11664",
    "title": "Promoting Rigour in Blockchains Energy & Environmental Footprint  Research: A Systematic Literature Review",
    "abstract": "There is a growing interest in understanding the energy and environmental\nfootprint of digital currencies, specifically in cryptocurrencies such as\nBitcoin and Ethereum. These cryptocurrencies are operated by a geographically\ndistributed network of computing nodes, making it hard to accurately estimate\ntheir energy consumption.\nExisting studies, both in academia and industry, attempt to model the\ncryptocurrencies energy consumption often based on a number of assumptions for\ninstance about the hardware in use or geographic distribution of the computing\nnodes. A number of these studies has already been widely criticized for their\ndesign choices and subsequent over or under-estimation of the energy use.\nIn this study, we evaluate the reliability of prior models and estimates by\nleveraging existing scientific literature from fields cognizant of blockchain\nsuch as social energy sciences and information systems. We first design a\nquality assessment framework based on existing research, we then conduct a\nsystematic literature review examining scientific and non-academic literature\ndemonstrating common issues and potential avenues of addressing these issues.\nOur goal with this article is to to advance the field by promoting scientific\nrigor in studies focusing on Blockchain's energy footprint. To that end, we\nprovide a novel set of codes of conduct for the five most widely used research\nmethodologies: quantitative energy modeling, literature reviews, data analysis\n\\& statistics, case studies, and experiments. We envision that these codes of\nconduct would assist in standardizing the design and assessment of studies\nfocusing on blockchain-based systems' energy and environmental footprint.",
    "descriptor": "\nComments: This article is currently under peer review\n",
    "authors": [
      "Ashish Rajendra Sai",
      "Harald Vranken"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.11664"
  },
  {
    "id": "arXiv:2210.11666",
    "title": "Doctors Handwritten Prescription Recognition System In Multi Language  Using Deep Learning",
    "abstract": "Doctors typically write in incomprehensible handwriting, making it difficult\nfor both the general public and some pharmacists to understand the medications\nthey have prescribed. It is not ideal for them to write the prescription\nquietly and methodically because they will be dealing with dozens of patients\nevery day and will be swamped with work.As a result, their handwriting is\nillegible. This may result in reports or prescriptions consisting of short\nforms and cursive writing that a typical person or pharmacist won't be able to\nread properly, which will cause prescribed medications to be misspelled.\nHowever, some individuals are accustomed to writing prescriptions in regional\nlanguages because we all live in an area with a diversity of regional\nlanguages. It makes analyzing the content much more challenging. So, in this\nproject, we'll use a recognition system to build a tool that can translate the\nhandwriting of physicians in any language. This system will be made into an\napplication which is fully autonomous in functioning. As the user uploads the\nprescription image the program will pre-process the image by performing image\npre-processing, and word segmentations initially before processing the image\nfor training. And it will be done for every language we require the model to\ndetect. And as of the deduction model will be made using deep learning\ntechniques including CNN, RNN, and LSTM, which are utilized to train the model.\nTo match words from various languages that will be written in the system,\nUnicode will be used. Furthermore, fuzzy search and market basket analysis are\nemployed to offer an end result that will be optimized from the pharmaceutical\ndatabase and displayed to the user as a structured output.",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Pavithiran G",
      "Sharan Padmanabhan",
      "Nuvvuru Divya",
      "Aswathy V",
      "Irene Jerusha P",
      "Chandar B"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.11666"
  },
  {
    "id": "arXiv:2210.11668",
    "title": "RGB-Only Reconstruction of Tabletop Scenes for Collision-Free  Manipulator Control",
    "abstract": "We present a system for collision-free control of a robot manipulator that\nuses only RGB views of the world. Perceptual input of a tabletop scene is\nprovided by multiple images of an RGB camera (without depth) that is either\nhandheld or mounted on the robot end effector. A NeRF-like process is used to\nreconstruct the 3D geometry of the scene, from which the Euclidean full signed\ndistance function (ESDF) is computed. A model predictive control algorithm is\nthen used to control the manipulator to reach a desired pose while avoiding\nobstacles in the ESDF. We show results on a real dataset collected and\nannotated in our lab.",
    "descriptor": "\nComments: Submitted to ICRA 2023. Project page at this https URL\n",
    "authors": [
      "Zhenggang Tang",
      "Balakumar Sundaralingam",
      "Jonathan Tremblay",
      "Bowen Wen",
      "Ye Yuan",
      "Stephen Tyree",
      "Charles Loop",
      "Alexander Schwing",
      "Stan Birchfield"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11668"
  },
  {
    "id": "arXiv:2210.11670",
    "title": "SIT at MixMT 2022: Fluent Translation Built on Giant Pre-trained Models",
    "abstract": "This paper describes the Stevens Institute of Technology's submission for the\nWMT 2022 Shared Task: Code-mixed Machine Translation (MixMT). The task\nconsisted of two subtasks, subtask $1$ Hindi/English to Hinglish and subtask\n$2$ Hinglish to English translation. Our findings lie in the improvements made\nthrough the use of large pre-trained multilingual NMT models and in-domain\ndatasets, as well as back-translation and ensemble techniques. The translation\noutput is automatically evaluated against the reference translations using\nROUGE-L and WER. Our system achieves the $1^{st}$ position on subtask $2$\naccording to ROUGE-L, WER, and human evaluation, $1^{st}$ position on subtask\n$1$ according to WER and human evaluation, and $3^{rd}$ position on subtask $1$\nwith respect to ROUGE-L metric.",
    "descriptor": "",
    "authors": [
      "Abdul Rafae Khan",
      "Hrishikesh Kanade",
      "Girish Amar Budhrani",
      "Preet Jhanglani",
      "Jia Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11670"
  },
  {
    "id": "arXiv:2210.11672",
    "title": "Stochastic Adaptive Activation Function",
    "abstract": "The simulation of human neurons and neurotransmission mechanisms has been\nrealized in deep neural networks based on the theoretical implementations of\nactivation functions. However, recent studies have reported that the threshold\npotential of neurons exhibits different values according to the locations and\ntypes of individual neurons, and that the activation functions have limitations\nin terms of representing this variability. Therefore, this study proposes a\nsimple yet effective activation function that facilitates different thresholds\nand adaptive activations according to the positions of units and the contexts\nof inputs. Furthermore, the proposed activation function mathematically\nexhibits a more generalized form of Swish activation function, and thus we\ndenoted it as Adaptive SwisH (ASH). ASH highlights informative features that\nexhibit large values in the top percentiles in an input, whereas it rectifies\nlow values. Most importantly, ASH exhibits trainable, adaptive, and\ncontext-aware properties compared to other activation functions. Furthermore,\nASH represents general formula of the previously studied activation function\nand provides a reasonable mathematical background for the superior performance.\nTo validate the effectiveness and robustness of ASH, we implemented ASH into\nmany deep learning models for various tasks, including classification,\ndetection, segmentation, and image generation. Experimental analysis\ndemonstrates that our activation function can provide the benefits of more\naccurate prediction and earlier convergence in many deep learning applications.",
    "descriptor": "",
    "authors": [
      "Kyungsu Lee",
      "Jaeseung Yang",
      "Haeyun Lee",
      "Jae Youn Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.11672"
  },
  {
    "id": "arXiv:2210.11673",
    "title": "Strategies and Vulnerabilities of Participants in Venezuelan Influence  Operations",
    "abstract": "Studies of online influence operations, coordinated efforts to disseminate\nand amplify disinformation, focus on forensic analysis of social networks or of\npublicly available datasets of trolls and bot accounts. However, little is\nknown about the experiences and challenges of human participants in influence\noperations. We conducted semi-structured interviews with 19 influence\noperations participants that contribute to the online image of Venezuela, to\nunderstand their incentives, capabilities, and strategies to promote content\nwhile evading detection. To validate a subset of their answers, we performed a\nquantitative investigation using data collected over almost four months, from\nTwitter accounts they control.\nWe found diverse participants that include pro-government and opposition\nsupporters, operatives and grassroots campaigners, and sockpuppet account\nowners and real users. While pro-government and opposition participants have\nsimilar goals and promotion strategies, they differ in their motivation,\norganization, adversaries and detection avoidance strategies. We report the\nPatria framework, a government platform for operatives to log activities and\nreceive benefits. We systematize participant strategies to promote political\ncontent, and to evade and recover from Twitter penalties. We identify\nvulnerability points associated with these strategies, and suggest more nuanced\ndefenses against influence operations.",
    "descriptor": "",
    "authors": [
      "Ruben Recabarren",
      "Bogdan Carbunar",
      "Nestor Hernandez",
      "Ashfaq Ali Shafin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11673"
  },
  {
    "id": "arXiv:2210.11674",
    "title": "WristSketcher: Creating Dynamic Sketches in AR with a Sensing Wristband",
    "abstract": "Restricted by the limited interaction area of native AR glasses (e.g., touch\nbars), it is challenging to create sketches in AR glasses. Recent works have\nattempted to use mobile devices (e.g., tablets) or mid-air bare-hand gestures\nto expand the interactive spaces and can work as the 2D/3D sketching input\ninterfaces for AR glasses. Between them, mobile devices allow for accurate\nsketching but are often heavy to carry, while sketching with bare hands is\nzero-burden but can be inaccurate due to arm instability. In addition, mid-air\nbare-hand sketching can easily lead to social misunderstandings and its\nprolonged use can cause arm fatigue. As a new attempt, in this work, we present\nWristSketcher, a new AR system based on a flexible sensing wristband for\ncreating 2D dynamic sketches, featuring an almost zero-burden authoring model\nfor accurate and comfortable sketch creation in real-world scenarios.\nSpecifically, we have streamlined the interaction space from the mid-air to the\nsurface of a lightweight sensing wristband, and implemented AR sketching and\nassociated interaction commands by developing a gesture recognition method\nbased on the sensing pressure points on the wristband. The set of interactive\ngestures used by our WristSketcher is determined by a heuristic study on user\npreferences. Moreover, we endow our WristSketcher with the ability of animation\ncreation, allowing it to create dynamic and expressive sketches. Experimental\nresults demonstrate that our WristSketcher i) faithfully recognizes users'\ngesture interactions with a high accuracy of 96.0%; ii) achieves higher\nsketching accuracy than Freehand sketching; iii) achieves high user\nsatisfaction in ease of use, usability and functionality; and iv) shows\ninnovation potentials in art creation, memory aids, and entertainment\napplications.",
    "descriptor": "",
    "authors": [
      "Enting Ying",
      "TianYang Xiong",
      "Shihui Guo",
      "Ming Qiu",
      "YiPeng Qin",
      "Hongbo Fu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11674"
  },
  {
    "id": "arXiv:2210.11675",
    "title": "Fuzzy Granular-Ball Computing Framework and Its Implementation in SVM",
    "abstract": "Most existing fuzzy computing methods use points as input, which is the\nfinest granularity from the perspective of granular computing. Consequently,\nthese classifiers are neither efficient nor robust to label noise. Therefore,\nwe propose a framework for a fuzzy granular-ball computational classifier by\nintroducing granular-ball computing into fuzzy set. The computational framework\nis based on the granular-balls input rather than points; therefore, it is more\nefficient and robust than traditional fuzzy methods. Furthermore, the framework\nis extended to the fuzzy support vector machine (FSVM), and granular ball fuzzy\nSVM (GBFSVM) is derived. The experimental results demonstrate the effectiveness\nand efficiency of GBFSVM.",
    "descriptor": "",
    "authors": [
      "Shuyin Xia",
      "Xiaoyu Lian",
      "Yabin Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11675"
  },
  {
    "id": "arXiv:2210.11678",
    "title": "Energy stability and error estimates of a maximum bound principle  preserving scheme for the dynamic Ginzburg-Landau equations of  superconductivity",
    "abstract": "The paper proposes a decoupled numerical scheme of the time-dependent\nGinzburg-Landau equations under temporal gauge. For the order parameter and the\nmagnetic potential, the discrete scheme adopts the second type Ned${\\rm\n\\acute{e}}$lec element and the linear element for spatial discretization,\nrespectively, and a fully linearized backward Euler method and the first order\nexponential time differencing method for time discretization, respectively. The\nmaximum bound principle of the order parameter and the energy dissipation law\nin the discrete sense are proved for this finite element-based scheme. This\nallows the application of the adaptive time stepping method which can\nsignificantly speed up long-time simulations compared to existing numerical\nschemes, especially for superconductors with complicated shapes. The error\nestimate is rigorously established in the fully discrete sense. Numerical\nexamples verify the theoretical results of the proposed scheme and demonstrate\nthe vortex motions of superconductors in an external magnetic field.",
    "descriptor": "",
    "authors": [
      "Limin Ma",
      "Zhonghua Qiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11678"
  },
  {
    "id": "arXiv:2210.11680",
    "title": "Twin Contrastive Learning for Online Clustering",
    "abstract": "This paper proposes to perform online clustering by conducting twin\ncontrastive learning (TCL) at the instance and cluster level. Specifically, we\nfind that when the data is projected into a feature space with a dimensionality\nof the target cluster number, the rows and columns of its feature matrix\ncorrespond to the instance and cluster representation, respectively. Based on\nthe observation, for a given dataset, the proposed TCL first constructs\npositive and negative pairs through data augmentations. Thereafter, in the row\nand column space of the feature matrix, instance- and cluster-level contrastive\nlearning are respectively conducted by pulling together positive pairs while\npushing apart the negatives. To alleviate the influence of intrinsic\nfalse-negative pairs and rectify cluster assignments, we adopt a\nconfidence-based criterion to select pseudo-labels for boosting both the\ninstance- and cluster-level contrastive learning. As a result, the clustering\nperformance is further improved. Besides the elegant idea of twin contrastive\nlearning, another advantage of TCL is that it could independently predict the\ncluster assignment for each instance, thus effortlessly fitting online\nscenarios. Extensive experiments on six widely-used image and text benchmarks\ndemonstrate the effectiveness of TCL. The code will be released on GitHub.",
    "descriptor": "",
    "authors": [
      "Yunfan Li",
      "Mouxing Yang",
      "Dezhong Peng",
      "Taihao Li",
      "Jiantao Huang",
      "Xi Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11680"
  },
  {
    "id": "arXiv:2210.11684",
    "title": "Adaptive Control of Unknown Time Varying Dynamical Systems with Regret  Guarantees",
    "abstract": "The study of online control of unknown time varying dynamical systems is a\nrelatively under-explored topic. Motivated by the general impossibility result\nfor unknown time varying dynamical systems, which states that sub-linear regret\nmay not be achievable even for $\\mathcal{O}(1)$ number of changes, we study the\nfollowing question: {\\it can we achieve sub-linear regret with respect to a\nstronger notion of variability like the number of changes, which includes a\nvery broad range of scenarios}? And {\\it under what system, information and\ncost structures assumptions can such guarantees be given}? We propose an online\ncontrol algorithm that continuously updates its estimate to track the changes\nand an online optimizer to simultaneously optimize the control policy. %We\npropose an online control algorithm that employs a \\emph{change point\ndetection} algorithm to detect and track the changes and an online optimizer to\nsimultaneously optimize the control policy. We show that our algorithm can\nachieve a sub-linear regret with respect to a stronger notion of variability\nunder two settings: (i) matched disturbance system with general convex cost\nfunctions, (ii) general system with linear cost functions. Specifically, a\nregret of $\\Gamma^{1/5}_TT^{4/5}$ can be achieved, where $\\Gamma_T$ is the\nnumber of changes in the underlying system and $T$ is the duration of the\ncontrol episode.",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Ruijie Du",
      "Yanning Shen",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11684"
  },
  {
    "id": "arXiv:2210.11689",
    "title": "SLING: Sino Linguistic Evaluation of Large Language Models",
    "abstract": "To understand what kinds of linguistic knowledge are encoded by pretrained\nChinese language models (LMs), we introduce the benchmark of Sino LINGuistics\n(SLING), which consists of 38K minimal sentence pairs in Mandarin Chinese\ngrouped into 9 high-level linguistic phenomena. Each pair demonstrates the\nacceptability contrast of a specific syntactic or semantic phenomenon (e.g.,\nThe keys are lost vs. The keys is lost), and an LM should assign lower\nperplexity to the acceptable sentence. In contrast to the CLiMP dataset (Xiang\net al., 2021), which also contains Chinese minimal pairs and was created by\ntranslating the vocabulary of the English BLiMP dataset, the minimal pairs in\nSLING are derived primarily by applying syntactic and lexical transformations\nto naturally-occurring, linguist-annotated sentences from the Chinese Treebank\n9.0, thus addressing severe issues in CLiMP's data generation process. We test\n18 publicly available pretrained monolingual (e.g., BERT-base-zh, CPM) and\nmulti-lingual (e.g., mT5, XLM) language models on SLING. Our experiments show\nthat the average accuracy for LMs is far below human performance (69.7% vs.\n97.1%), while BERT-base-zh achieves the highest accuracy (84.8%) of all tested\nLMs, even much larger ones. Additionally, we find that most LMs have a strong\ngender and number (singular/plural) bias, and they perform better on local\nphenomena than hierarchical ones.",
    "descriptor": "\nComments: 29 pages, EMNLP 2022 camera ready\n",
    "authors": [
      "Yixiao Song",
      "Kalpesh Krishna",
      "Rajesh Bhatt",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11689"
  },
  {
    "id": "arXiv:2210.11691",
    "title": "FogROS G: Enabling Secure, Connected and Mobile Fog Robotics with Global  Addressability",
    "abstract": "Fog Robotics renders networked robots with greater mobility, on-demand\ncompute capabilities and better energy efficiency by offloading heavy robotics\nworkloads to nearby Edge and distant Cloud data centers. However, as the\nde-facto standard for implementing fog robotics applications, Robot Operating\nSystem (ROS) and its successor ROS2 fail to provide fog robots with a\nmobile-friendly and secure communication infrastructure.\nIn this work, we present FogROS G, a secure routing framework that connects\nrobotics software components from different physical locations, networks, Data\nDistribution Service (DDS) and ROS distributions. FogROS G indexes networked\nrobots with globally unique 256-bit names that remains constant even if the\nrobot roams between multiple administrative network domains. FogROS G leverages\nGlobal Data Plane, a global and secure peer-to-peer routing infrastructure\nbetween the names, guaranteeing that only authenticated party can send to or\nreceive from the robot. FogROS G adopts a proxy-based design that connect nodes\nfrom ROS1 and ROS2 with mainstream DDS vendors; this can be done without any\nchanges to the application code.",
    "descriptor": "\nComments: 5 pages, 5 figures. Published at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022 Cloud Robotics Workshop\n",
    "authors": [
      "Kaiyuan Chen",
      "Jiachen Yuan",
      "Nikhil Jha",
      "Jeffrey Ichnowski",
      "John Kubiatowicz",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11691"
  },
  {
    "id": "arXiv:2210.11692",
    "title": "Competing Bandits in Time Varying Matching Markets",
    "abstract": "We study the problem of online learning in two-sided non-stationary matching\nmarkets, where the objective is to converge to a stable match. In particular,\nwe consider the setting where one side of the market, the arms, has fixed known\nset of preferences over the other side, the players. While this problem has\nbeen studied when the players have fixed but unknown preferences, in this work\nwe study the problem of how to learn when the preferences of the players are\ntime varying. We propose the {\\it Restart Competing Bandits (RCB)} algorithm,\nwhich combines a simple {\\it restart strategy} to handle the non-stationarity\nwith the {\\it competing bandits} algorithm \\citep{liu2020competing} designed\nfor the stationary case. We show that, with the proposed algorithm, each player\nreceives a uniform sub-linear regret of\n{$\\widetilde{\\mathcal{O}}(L^{1/2}_TT^{1/2})$} up to the number of changes in\nthe underlying preference of agents, $L_T$. We also discuss extensions of this\nalgorithm to the case where the number of changes need not be known a priori.",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Chinmay Maheshwari",
      "Pramod P. Khargonekar",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.11692"
  },
  {
    "id": "arXiv:2210.11693",
    "title": "Amos: An Adam-style Optimizer with Adaptive Weight Decay towards  Model-Oriented Scale",
    "abstract": "We present Amos, a stochastic gradient-based optimizer designed for training\ndeep neural networks. It can be viewed as an Adam optimizer with theoretically\nsupported, adaptive learning-rate decay and weight decay. A key insight behind\nAmos is that it leverages model-specific information to determine the initial\nlearning-rate and decaying schedules. When used for pre-training BERT variants\nand T5, Amos consistently converges faster than the state-of-the-art settings\nof AdamW, achieving better validation loss within <=70% training steps and\ntime, while requiring <=51% memory for slot variables. Our code is open-sourced\nat: https://github.com/google-research/jestimator",
    "descriptor": "",
    "authors": [
      "Ran Tian",
      "Ankur P. Parikh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11693"
  },
  {
    "id": "arXiv:2210.11694",
    "title": "Multi-View Reasoning: Consistent Contrastive Learning for Math Word  Problem",
    "abstract": "Math word problem solver requires both precise relation reasoning about\nquantities in the text and reliable generation for the diverse equation.\nCurrent sequence-to-tree or relation extraction methods regard this only from a\nfixed view, struggling to simultaneously handle complex semantics and diverse\nequations. However, human solving naturally involves two consistent reasoning\nviews: top-down and bottom-up, just as math equations also can be expressed in\nmultiple equivalent forms: pre-order and post-order. We propose a multi-view\nconsistent contrastive learning for a more complete semantics-to-equation\nmapping. The entire process is decoupled into two independent but consistent\nviews: top-down decomposition and bottom-up construction, and the two reasoning\nviews are aligned in multi-granularity for consistency, enhancing global\ngeneration and precise reasoning. Experiments on multiple datasets across two\nlanguages show our approach significantly outperforms the existing baselines,\nespecially on complex problems. We also show after consistent alignment,\nmulti-view can absorb the merits of both views and generate more diverse\nresults consistent with the mathematical laws.",
    "descriptor": "\nComments: 14 pages, 5 figures, 3 appendix figures\n",
    "authors": [
      "Wenqi Zhang",
      "Yongliang Shen",
      "Yanna Ma",
      "Xiaoxia Cheng",
      "Zeqi Tan",
      "Qingpeng Nong",
      "Weiming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11694"
  },
  {
    "id": "arXiv:2210.11695",
    "title": "Global Counterfactual Explainer for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) find applications in various domains such as\ncomputational biology, natural language processing, and computer security.\nOwing to their popularity, there is an increasing need to explain GNN\npredictions since GNNs are black-box machine learning models. One way to\naddress this is counterfactual reasoning where the objective is to change the\nGNN prediction by minimal changes in the input graph. Existing methods for\ncounterfactual explanation of GNNs are limited to instance-specific local\nreasoning. This approach has two major limitations of not being able to offer\nglobal recourse policies and overloading human cognitive ability with too much\ninformation. In this work, we study the global explainability of GNNs through\nglobal counterfactual reasoning. Specifically, we want to find a small set of\nrepresentative counterfactual graphs that explains all input graphs. Towards\nthis goal, we propose GCFExplainer, a novel algorithm powered by\nvertex-reinforced random walks on an edit map of graphs with a greedy summary.\nExtensive experiments on real graph datasets show that the global explanation\nfrom GCFExplainer provides important high-level insights of the model behavior\nand achieves a 46.9% gain in recourse coverage and a 9.5% reduction in recourse\ncost compared to the state-of-the-art local counterfactual explainers.",
    "descriptor": "\nComments: Accepted to WSDM 2023\n",
    "authors": [
      "Mert Kosan",
      "Zexi Huang",
      "Sourav Medya",
      "Sayan Ranu",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11695"
  },
  {
    "id": "arXiv:2210.11697",
    "title": "Optimal Pose Estimation and Covariance Analysis with Simultaneous  Localization and Mapping Applications",
    "abstract": "This work provides a theoretical analysis for optimally solving the pose\nestimation problem using total least squares for vector observations from\nlandmark features, which is central to applications involving simultaneous\nlocalization and mapping. First, the optimization process is formulated with\nobservation vectors extracted from point-cloud features. Then, error-covariance\nexpressions are derived. The attitude and position estimates obtained via the\nderived optimization process are proven to reach the bounds defined by the\nCram\\'er-Rao lower bound under the small-angle approximation of attitude\nerrors. A fully populated observation noise-covariance matrix is assumed as the\nweight in the cost function to cover the most general case of the sensor\nuncertainty. This includes more generic correlations in the errors than\nprevious cases involving an isotropic noise assumption. The proposed solution\nis verified using Monte Carlo simulations and an experiment with an actual\nLIDAR to validate the error-covariance analysis.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.11522\n",
    "authors": [
      "Saeed Maleki",
      "Adhiti Raman",
      "Yang Cheng",
      "John Crassidis",
      "Matthias Schmid"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.11697"
  },
  {
    "id": "arXiv:2210.11698",
    "title": "Learning Robust Dynamics through Variational Sparse Gating",
    "abstract": "Learning world models from their sensory inputs enables agents to plan for\nactions by imagining their future outcomes. World models have previously been\nshown to improve sample-efficiency in simulated environments with few objects,\nbut have not yet been applied successfully to environments with many objects.\nIn environments with many objects, often only a small number of them are moving\nor interacting at the same time. In this paper, we investigate integrating this\ninductive bias of sparse interactions into the latent dynamics of world models\ntrained from pixels. First, we introduce Variational Sparse Gating (VSG), a\nlatent dynamics model that updates its feature dimensions sparsely through\nstochastic binary gates. Moreover, we propose a simplified architecture Simple\nVariational Sparse Gating (SVSG) that removes the deterministic pathway of\nprevious models, resulting in a fully stochastic transition function that\nleverages the VSG mechanism. We evaluate the two model architectures in the\nBringBackShapes (BBS) environment that features a large number of moving\nobjects and partial observability, demonstrating clear improvements over prior\nmodels.",
    "descriptor": "",
    "authors": [
      "Arnav Kumar Jain",
      "Shivakanth Sujit",
      "Shruti Joshi",
      "Vincent Michalski",
      "Danijar Hafner",
      "Samira Ebrahimi-Kahou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11698"
  },
  {
    "id": "arXiv:2210.11702",
    "title": "TAP: Transparent and Privacy-Preserving Data Services",
    "abstract": "Users today expect more security from services that handle their data. In\naddition to traditional data privacy and integrity requirements, they expect\ntransparency, i.e., that the service's processing of the data is verifiable by\nusers and trusted auditors. Our goal is to build a multi-user system that\nprovides data privacy, integrity, and transparency for a large number of\noperations, while achieving practical performance.\nTo this end, we first identify the limitations of existing approaches that\nuse authenticated data structures. We find that they fall into two categories:\n1) those that hide each user's data from other users, but have a limited range\nof verifiable operations (e.g., CONIKS, Merkle2, and Proofs of Liabilities),\nand 2) those that support a wide range of verifiable operations, but make all\ndata publicly visible (e.g., IntegriDB and FalconDB). We then present TAP to\naddress the above limitations. The key component of TAP is a novel tree data\nstructure that supports efficient result verification, and relies on\nindependent audits that use zero-knowledge range proofs to show that the tree\nis constructed correctly without revealing user data. TAP supports a broad\nrange of verifiable operations, including quantiles and sample standard\ndeviations. We conduct a comprehensive evaluation of TAP, and compare it\nagainst two state-of-the-art baselines, namely IntegriDB and Merkle2, showing\nthat the system is practical at scale.",
    "descriptor": "\nComments: Accepted for USENIX Security 2023\n",
    "authors": [
      "Daniel Reijsbergen",
      "Aung Maw",
      "Zheng Yang",
      "Tien Tuan Anh Dinh",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11702"
  },
  {
    "id": "arXiv:2210.11703",
    "title": "SCL: A Secure Concurrency Layer For Paranoid Stateful Lambdas",
    "abstract": "We propose a federated Function-as-a-Service (FaaS) execution model that\nprovides secure and stateful execution in both Cloud and Edge environments. The\nFaaS workers, called Paranoid Stateful Lambdas (PSLs), collaborate with one\nanother to perform large parallel computations. We exploit cryptographically\nhardened and mobile bundles of data, called DataCapsules, to provide persistent\nstate for our PSLs, whose execution is protected using hardware-secured TEEs.\nTo make PSLs easy to program and performant, we build the familiar Key-Value\nStore interface on top of DataCapsules in a way that allows amortization of\ncryptographic operations. We demonstrate PSLs functioning in an edge\nenvironment running on a group of Intel NUCs with SGXv2.\nAs described, our Secure Concurrency Layer (SCL), provides\neventually-consistent semantics over written values using untrusted and\nunordered multicast. All SCL communication is encrypted, unforgeable, and\nprivate. For durability, updates are recorded in replicated DataCapsules, which\nare append-only cryptographically-hardened blockchain with confidentiality,\nintegrity, and provenance guarantees. Values for inactive keys are stored in a\nlog-structured merge-tree (LSM) in the same DataCapsule. SCL features a variety\nof communication optimizations, such as an efficient message passing framework\nthat reduces the latency up to 44x from the Intel SGX SDK, and an actor-based\ncryptographic processing architecture that batches cryptographic operations and\nincreases throughput by 81x.",
    "descriptor": "\nComments: 14 pages, 11 figures, 2 tables\n",
    "authors": [
      "Kaiyuan Chen",
      "Alexander Thomas",
      "Hanming Lu",
      "William Mullen",
      "Jeffery Ichnowski",
      "Rahul Arya",
      "Nivedha Krishnakumar",
      "Ryan Teoh",
      "Willis Wang",
      "Anthony Joseph",
      "John Kubiatowicz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.11703"
  },
  {
    "id": "arXiv:2210.11704",
    "title": "Accessible Survey of Evolutionary Robotics and Potential Future Research  Directions",
    "abstract": "This paper reviews various Evolutionary Approaches applied to the domain of\nEvolutionary Robotics with the intention of resolving difficult problems in the\nareas of robotic design and control. Evolutionary Robotics is a fast-growing\nfield that has attracted substantial research attention in recent years. The\npaper thus collates recent findings along with some anticipated applications.\nThe reviewed literature is organized systematically to give a categorical\noverview of recent developments and is presented in tabulated form for quick\nreference. We discuss the outstanding potentialities and challenges that exist\nin robotics from an ER perspective, with the belief that these will be have the\ncapacity to be addressed in the near future via the application of evolutionary\napproaches. The primary objective of this study is to explore the applicability\nof Evolutionary Approaches in robotic application development. We believe that\nthis study will enable the researchers to utilize Evolutionary Approaches to\nsolve complex outstanding problems in robotics.",
    "descriptor": "",
    "authors": [
      "Hari Mohan Pandey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11704"
  },
  {
    "id": "arXiv:2210.11705",
    "title": "Efficiently Tuned Parameters are Task Embeddings",
    "abstract": "Intermediate-task transfer can benefit a wide range of NLP tasks with\nproperly selected source datasets. However, it is computationally infeasible to\nexperiment with all intermediate transfer combinations, making choosing a\nuseful source task a challenging problem. In this paper, we anticipate that\ntask-specific parameters updated in parameter-efficient tuning methods are\nlikely to encode task-specific information. Therefore, such parameters can be\npredictive for inter-task transferability. Thus, we propose to exploit these\nefficiently tuned parameters as off-the-shelf task embeddings for the efficient\nselection of source datasets for intermediate-task transfer. We experiment with\n11 text classification tasks and 11 question answering tasks. Experimental\nresults show that our approach can consistently outperform existing inter-task\ntransferability prediction methods while being conceptually simple and\ncomputationally efficient. Our analysis also reveals that the ability of\nefficiently tuned parameters on transferability prediction is disentangled with\ntheir in-task performance. This allows us to use parameters from early\ncheckpoints as task embeddings to further improve efficiency.",
    "descriptor": "\nComments: EMNLP 2022 (main conference)\n",
    "authors": [
      "Wangchunshu Zhou",
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11705"
  },
  {
    "id": "arXiv:2210.11707",
    "title": "Video Summarization Overview",
    "abstract": "With the broad growth of video capturing devices and applications on the web,\nit is more demanding to provide desired video content for users efficiently.\nVideo summarization facilitates quickly grasping video content by creating a\ncompact summary of videos. Much effort has been devoted to automatic video\nsummarization, and various problem settings and approaches have been proposed.\nOur goal is to provide an overview of this field. This survey covers early\nstudies as well as recent approaches which take advantage of deep learning\ntechniques. We describe video summarization approaches and their underlying\nconcepts. We also discuss benchmarks and evaluations. We overview how prior\nwork addressed evaluation and detail the pros and cons of the evaluation\nprotocols. Last but not least, we discuss open challenges in this field.",
    "descriptor": "\nComments: 53 pages\n",
    "authors": [
      "Mayu Otani",
      "Yale Song",
      "Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11707"
  },
  {
    "id": "arXiv:2210.11708",
    "title": "Metric-guided Distillation: Distilling Knowledge from the Metric to  Ranker and Retriever for Generative Commonsense Reasoning",
    "abstract": "Commonsense generation aims to generate a realistic sentence describing a\ndaily scene under the given concepts, which is very challenging, since it\nrequires models to have relational reasoning and compositional generalization\ncapabilities. Previous work focuses on retrieving prototype sentences for the\nprovided concepts to assist generation. They first use a sparse retriever to\nretrieve candidate sentences, then re-rank the candidates with a ranker.\nHowever, the candidates returned by their ranker may not be the most relevant\nsentences, since the ranker treats all candidates equally without considering\ntheir relevance to the reference sentences of the given concepts. Another\nproblem is that re-ranking is very expensive, but only using retrievers will\nseriously degrade the performance of their generation models. To solve these\nproblems, we propose the metric distillation rule to distill knowledge from the\nmetric (e.g., BLEU) to the ranker. We further transfer the critical knowledge\nsummarized by the distilled ranker to the retriever. In this way, the relevance\nscores of candidate sentences predicted by the ranker and retriever will be\nmore consistent with their quality measured by the metric. Experimental results\non the CommonGen benchmark verify the effectiveness of our proposed method: (1)\nOur generation model with the distilled ranker achieves a new state-of-the-art\nresult. (2) Our generation model with the distilled retriever even surpasses\nthe previous SOTA.",
    "descriptor": "",
    "authors": [
      "Xingwei He",
      "Yeyun Gong",
      "A-Long Jin",
      "Weizhen Qi",
      "Hang Zhang",
      "Jian Jiao",
      "Bartuer Zhou",
      "Biao Cheng",
      "SM Yiu",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11708"
  },
  {
    "id": "arXiv:2210.11711",
    "title": "Modelling Multi-relations for Convolutional-based Knowledge Graph  Embedding",
    "abstract": "Representation learning of knowledge graphs aims to embed entities and\nrelations into low-dimensional vectors. Most existing works only consider the\ndirect relations or paths between an entity pair. It is considered that such\napproaches disconnect the semantic connection of multi-relations between an\nentity pair, and we propose a convolutional and multi-relational representation\nlearning model, ConvMR. The proposed ConvMR model addresses the multi-relation\nissue in two aspects: (1) Encoding the multi-relations between an entity pair\ninto a unified vector that maintains the semantic connection. (2) Since not all\nrelations are necessary while joining multi-relations, we propose an\nattention-based relation encoder to automatically assign weights to different\nrelations based on semantic hierarchy. Experimental results on two popular\ndatasets, FB15k-237 and WN18RR, achieved consistent improvements on the mean\nrank. We also found that ConvMR is efficient to deal with less frequent\nentities.",
    "descriptor": "\nComments: Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022\n",
    "authors": [
      "Sirui Li",
      "Kok Wai Wong",
      "Dengya Zhu",
      "Chun Che Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11711"
  },
  {
    "id": "arXiv:2210.11714",
    "title": "Design a Sustainable Micro-mobility Future: Trends and Challenges in the  United States and European Union Using Natural Language Processing Techniques",
    "abstract": "Micro-mobility devices are rapidly gaining popularity since people could\nbenefit from their efficiency, low cost and sustainability. However, people\nstill face challenges that detain the development and full integration of these\ndevices. In the present study, we examined people's opinions and experiences\nabout micro-mobility in the US and the EU using social media data on Twitter.\nWe made use of topic modeling based on advanced natural language processing\ntechniques and categorized the data into seven topics: promotion and service,\nmobility, technical features, acceptance, recreation, infrastructure and\nregulations. Furthermore, using sentiment analysis, we investigated people's\npositive and negative attitudes towards specific aspects of these topics and\ncompared the patterns of the trends and challenges in the US and the EU. We\nfound that 1) promotion and service included the majority of Twitter\ndiscussions in the both regions, 2) the EU had more positive opinions than the\nUS, 3) micro-mobility devices were more widely used for utilitarian mobility\nand recreational purposes in the EU than in the US, and 4) compared to the EU,\npeople in the US had many more concerns related to infrastructure and\nregulation issues. These findings help us understand the trends and challenges\nand prioritize different aspects in micro-mobility to improve their safety and\nexperience across the two areas for designing a more sustainable micro-mobility\nfuture.",
    "descriptor": "\nComments: 33 pages, 4 figures\n",
    "authors": [
      "Lilit Avetisyan",
      "Chengxin Zhang",
      "Sue Bai",
      "Ehsan Moradi Pari",
      "Fred Feng",
      "Shan Bao",
      "Feng Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11714"
  },
  {
    "id": "arXiv:2210.11715",
    "title": "Empathetic Dialogue Generation via Sensitive Emotion Recognition and  Sensible Knowledge Selection",
    "abstract": "Empathy, which is widely used in psychological counselling, is a key trait of\neveryday human conversations. Equipped with commonsense knowledge, current\napproaches to empathetic response generation focus on capturing implicit\nemotion within dialogue context, where the emotions are treated as a static\nvariable throughout the conversations. However, emotions change dynamically\nbetween utterances, which makes previous works difficult to perceive the\nemotion flow and predict the correct emotion of the target response, leading to\ninappropriate response. Furthermore, simply importing commonsense knowledge\nwithout harmonization may trigger the conflicts between knowledge and emotion,\nwhich confuse the model to choose incorrect information to guide the generation\nprocess. To address the above problems, we propose a Serial Encoding and\nEmotion-Knowledge interaction (SEEK) method for empathetic dialogue generation.\nWe use a fine-grained encoding strategy which is more sensitive to the emotion\ndynamics (emotion flow) in the conversations to predict the emotion-intent\ncharacteristic of response. Besides, we design a novel framework to model the\ninteraction between knowledge and emotion to generate more sensible response.\nExtensive experiments on EmpatheticDialogues demonstrate that SEEK outperforms\nthe strong baselines in both automatic and manual evaluations.",
    "descriptor": "",
    "authors": [
      "Lanrui Wang",
      "Jiangnan Li",
      "Zheng Lin",
      "Fandong Meng",
      "Chenxu Yang",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11715"
  },
  {
    "id": "arXiv:2210.11717",
    "title": "A Survey of Data Optimization for Problems in Computer Vision Datasets",
    "abstract": "Recent years have witnessed remarkable progress in artificial intelligence\n(AI) thanks to refined deep network structures, powerful computing devices, and\nlarge-scale labeled datasets. However, researchers have mainly invested in the\noptimization of models and computational devices, leading to the fact that good\nmodels and powerful computing devices are currently readily available, while\ndatasets are still stuck at the initial stage of large-scale but low quality.\nData becomes a major obstacle to AI development. Taking note of this, we dig\ndeeper and find that there has been some but unstructured work on data\noptimization. They focus on various problems in datasets and attempt to improve\ndataset quality by optimizing its structure to facilitate AI development. In\nthis paper, we present the first review of recent advances in this area. First,\nwe summarize and analyze various problems that exist in large-scale computer\nvision datasets. We then define data optimization and classify data\noptimization algorithms into three directions according to the optimization\nform: data sampling, data subset selection, and active learning. Next, we\norganize these data optimization works according to data problems addressed,\nand provide a systematic and comparative description. Finally, we summarize the\nexisting literature and propose some potential future research topics.",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Zhijing Wan",
      "Zhixiang Wang",
      "CheukTing Chung",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11717"
  },
  {
    "id": "arXiv:2210.11718",
    "title": "CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement  Transformers",
    "abstract": "Learning based 6D object pose estimation methods rely on computing large\nintermediate pose representations and/or iteratively refining an initial\nestimation with a slow render-compare pipeline. This paper introduces a novel\nmethod we call Cascaded Pose Refinement Transformers, or CRT-6D. We replace the\ncommonly used dense intermediate representation with a sparse set of features\nsampled from the feature pyramid we call OSKFs(Object Surface Keypoint\nFeatures) where each element corresponds to an object keypoint. We employ\nlightweight deformable transformers and chain them together to iteratively\nrefine proposed poses over the sampled OSKFs. We achieve inference runtimes 2x\nfaster than the closest real-time state of the art methods while supporting up\nto 21 objects on a single model. We demonstrate the effectiveness of CRT-6D by\nperforming extensive experiments on the LM-O and YCBV datasets. Compared to\nreal-time methods, we achieve state of the art on LM-O and YCB-V, falling\nslightly behind methods with inference runtimes one order of magnitude higher.\nThe source code is available at: https://github.com/PedroCastro/CRT-6D",
    "descriptor": "\nComments: Accepted at WACV2023\n",
    "authors": [
      "Pedro Castro",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11718"
  },
  {
    "id": "arXiv:2210.11719",
    "title": "Context-Enhanced Stereo Transformer",
    "abstract": "Stereo depth estimation is of great interest for computer vision research.\nHowever, existing methods struggles to generalize and predict reliably in\nhazardous regions, such as large uniform regions. To overcome these\nlimitations, we propose Context Enhanced Path (CEP). CEP improves the\ngeneralization and robustness against common failure cases in existing\nsolutions by capturing the long-range global information. We construct our\nstereo depth estimation model, Context Enhanced Stereo Transformer (CSTR), by\nplugging CEP into the state-of-the-art stereo depth estimation method Stereo\nTransformer. CSTR is examined on distinct public datasets, such as Scene Flow,\nMiddlebury-2014, KITTI-2015, and MPI-Sintel. We find CSTR outperforms prior\napproaches by a large margin. For example, in the zero-shot synthetic-to-real\nsetting, CSTR outperforms the best competing approaches on Middlebury-2014\ndataset by 11%. Our extensive experiments demonstrate that the long-range\ninformation is critical for stereo matching task and CEP successfully captures\nsuch information.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Weiyu Guo",
      "Zhaoshuo Li",
      "Yongkui Yang",
      "Zheng Wang",
      "Russell H. Taylor",
      "Mathias Unberath",
      "Alan Yuille",
      "Yingwei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11719"
  },
  {
    "id": "arXiv:2210.11720",
    "title": "MCSCSet: A Specialist-annotated Dataset for Medical-domain Chinese  Spelling Correction",
    "abstract": "Chinese Spelling Correction (CSC) is gaining increasing attention due to its\npromise of automatically detecting and correcting spelling errors in Chinese\ntexts. Despite its extensive use in many applications, like search engines and\noptical character recognition systems, little has been explored in medical\nscenarios in which complex and uncommon medical entities are easily misspelled.\nCorrecting the misspellings of medical entities is arguably more difficult than\nthose in the open domain due to its requirements of specificdomain knowledge.\nIn this work, we define the task of Medical-domain Chinese Spelling Correction\nand propose MCSCSet, a large scale specialist-annotated dataset that contains\nabout 200k samples. In contrast to the existing open-domain CSC datasets,\nMCSCSet involves: i) extensive real-world medical queries collected from\nTencent Yidian, ii) corresponding misspelled sentences manually annotated by\nmedical specialists. To ensure automated dataset curation, MCSCSet further\noffers a medical confusion set consisting of the commonly misspelled characters\nof given Chinese medical terms. This enables one to create the medical\nmisspelling dataset automatically. Extensive empirical studies have shown\nsignificant performance gaps between the open-domain and medical-domain\nspelling correction, highlighting the need to develop high-quality datasets\nthat allow for Chinese spelling correction in specific domains. Moreover, our\nwork benchmarks several representative Chinese spelling correction models,\nestablishing baselines for future work.",
    "descriptor": "\nComments: The full version of CIKM 2022 accepted resource paper \"MCSCSet: A Specialist-annotated Dataset for Medical-domain Chinese Spelling Correction\". (this https URL)\n",
    "authors": [
      "Wangjie Jiang",
      "Zhihao Ye",
      "Zijing Ou",
      "Ruihui Zhao",
      "Jianguang Zheng",
      "Yi Liu",
      "Siheng Li",
      "Bang Liu",
      "Yujiu Yang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11720"
  },
  {
    "id": "arXiv:2210.11722",
    "title": "Adaptive re-calibration of channel-wise features for Adversarial Audio  Classification",
    "abstract": "DeepFake Audio, unlike DeepFake images and videos, has been relatively less\nexplored from detection perspective, and the solutions which exist for the\nsynthetic speech classification either use complex networks or dont generalize\nto different varieties of synthetic speech obtained using different generative\nand optimization-based methods. Through this work, we propose a channel-wise\nrecalibration of features using attention feature fusion for synthetic speech\ndetection and compare its performance against different detection methods\nincluding End2End models and Resnet-based models on synthetic speech generated\nusing Text to Speech and Vocoder systems like WaveNet, WaveRNN, Tactotron, and\nWaveGlow. We also experiment with Squeeze Excitation (SE) blocks in our Resnet\nmodels and found that the combination was able to get better performance. In\naddition to the analysis, we also demonstrate that the combination of Linear\nfrequency cepstral coefficients (LFCC) and Mel Frequency cepstral coefficients\n(MFCC) using the attentional feature fusion technique creates better input\nfeatures representations which can help even simpler models generalize well on\nsynthetic speech classification tasks. Our models (Resnet based using feature\nfusion) trained on Fake or Real (FoR) dataset and were able to achieve 95% test\naccuracy with the FoR data, and an average of 90% accuracy with samples we\ngenerated using different generative models after adapting this framework.",
    "descriptor": "\nComments: 7 pages, 8 figures, 4 tables\n",
    "authors": [
      "Vardhan Dongre",
      "Abhinav Thimma Reddy",
      "Nikhitha Reddeddy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11722"
  },
  {
    "id": "arXiv:2210.11723",
    "title": "Evidence of Vocal Tract Articulation in Self-Supervised Learning of  Speech",
    "abstract": "Numerous self-supervised learning (SSL) models for speech have been proposed\nfor pre-training models of speech representations, and recent SSL models are\nvery successful in diverse downstream tasks. To understand such utilities,\nprevious works probe representations of speech models to reveal which & how\nspeech related information is encoded in the learned representations. While\nencoding properties have been extensively explored from the perspective of\nacoustics, phonetics, and semantics, the physical grounding by speech\nproduction has not yet received full attention. To bridge this gap, we conduct\na comprehensive analysis to link speech representations to articulatory\ntrajectories measured by electromagnetic articulography (EMA). Our analysis is\nbased on a linear probing approach where we measure articulatory score as an\naverage correlation of linear mapping to EMA. We analyze a set of SSL models\nselected from the leaderboard of the SU- PERB benchmark and perform further\ndetailed analyses on two major models, Wav2Vec 2.0 and HuBERT. Surprisingly,\nrepresentations from the recent speech SSL models are highly correlated with\nEMA traces (best: r = 0.81), and only 5 minutes were sufficient to train a\nlinear model with high performance (r = 0.77). Our findings suggest that SSL\nmodels learn to closely align with continuous articulations and provide a novel\ninsight into speech SSL.",
    "descriptor": "",
    "authors": [
      "Cheol Jun Cho",
      "Peter Wu",
      "Abdelrahman Mohamed",
      "Gopala K. Anumanchipalli"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11723"
  },
  {
    "id": "arXiv:2210.11725",
    "title": "AROS: Affordance Recognition with One-Shot Human Stances",
    "abstract": "We present AROS, a one-shot learning approach that uses an explicit\nrepresentation of interactions between highly-articulated human poses and 3D\nscenes. The approach is one-shot as the method does not require re-training to\nadd new affordance instances. Furthermore, only one or a small handful of\nexamples of the target pose are needed to describe the interaction. Given a 3D\nmesh of a previously unseen scene, we can predict affordance locations that\nsupport the interactions and generate corresponding articulated 3D human bodies\naround them. We evaluate on three public datasets of scans of real environments\nwith varied degrees of noise. Via rigorous statistical analysis of crowdsourced\nevaluations, results show that our one-shot approach outperforms data-intensive\nbaselines by up to 80\\%.",
    "descriptor": "\nComments: 8 figures, 5 tables, supplementary material\n",
    "authors": [
      "Abel Pacheco-Ortega",
      "Walterio Mayol-Cuevas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11725"
  },
  {
    "id": "arXiv:2210.11726",
    "title": "A critical review of cyber-physical security for building automation  systems",
    "abstract": "Modern Building Automation Systems (BASs), as the brain that enables the\nsmartness of a smart building, often require increased connectivity both among\nsystem components as well as with outside entities, such as optimized\nautomation via outsourced cloud analytics and increased building-grid\nintegrations. However, increased connectivity and accessibility come with\nincreased cyber security threats. BASs were historically developed as closed\nenvironments with limited cyber-security considerations. As a result, BASs in\nmany buildings are vulnerable to cyber-attacks that may cause adverse\nconsequences, such as occupant discomfort, excessive energy usage, and\nunexpected equipment downtime. Therefore, there is a strong need to advance the\nstate-of-the-art in cyber-physical security for BASs and provide practical\nsolutions for attack mitigation in buildings. However, an inclusive and\nsystematic review of BAS vulnerabilities, potential cyber-attacks with impact\nassessment, detection & defense approaches, and cyber-secure resilient control\nstrategies is currently lacking in the literature. This review paper fills the\ngap by providing a comprehensive up-to-date review of cyber-physical security\nfor BASs at three levels in commercial buildings: management level, automation\nlevel, and field level. The general BASs vulnerabilities and protocol-specific\nvulnerabilities for the four dominant BAS protocols are reviewed, followed by a\ndiscussion on four attack targets and seven potential attack scenarios. The\nimpact of cyber-attacks on BASs is summarized as signal corruption, signal\ndelaying, and signal blocking. The typical cyber-attack detection and defense\napproaches are identified at the three levels. Cyber-secure resilient control\nstrategies for BASs under attack are categorized into passive and active\nresilient control schemes. Open challenges and future opportunities are finally\ndiscussed.",
    "descriptor": "\nComments: 38 pages, 7 figures, 6 tables, submitted to Annual Reviews in Control\n",
    "authors": [
      "Guowen Li",
      "Lingyu Ren",
      "Yangyang Fu",
      "Zhiyao Yang",
      "Veronica Adetola",
      "Jin Wen",
      "Qi Zhu",
      "Teresa Wu",
      "K. Selcuk Candanf",
      "Zheng O'Neill"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11726"
  },
  {
    "id": "arXiv:2210.11728",
    "title": "Distilling the Undistillable: Learning from a Nasty Teacher",
    "abstract": "The inadvertent stealing of private/sensitive information using Knowledge\nDistillation (KD) has been getting significant attention recently and has\nguided subsequent defense efforts considering its critical nature. Recent work\nNasty Teacher proposed to develop teachers which can not be distilled or\nimitated by models attacking it. However, the promise of confidentiality\noffered by a nasty teacher is not well studied, and as a further step to\nstrengthen against such loopholes, we attempt to bypass its defense and steal\n(or extract) information in its presence successfully. Specifically, we analyze\nNasty Teacher from two different directions and subsequently leverage them\ncarefully to develop simple yet efficient methodologies, named as HTC and SCM,\nwhich increase the learning from Nasty Teacher by upto 68.63% on standard\ndatasets. Additionally, we also explore an improvised defense method based on\nour insights of stealing. Our detailed set of experiments and ablations on\ndiverse models/settings demonstrate the efficacy of our approach.",
    "descriptor": "\nComments: Published in main track of ECCV 2022, 17 pages with references, 5 figures, 6 tables\n",
    "authors": [
      "Surgan Jandial",
      "Yash Khasbage",
      "Arghya Pal",
      "Vineeth N Balasubramanian",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11728"
  },
  {
    "id": "arXiv:2210.11729",
    "title": "An Exploration of Data Efficiency in Intra-Dataset Task Transfer for  Dialog Understanding",
    "abstract": "Transfer learning is an exciting area of Natural Language Processing that has\nthe potential to both improve model performance and increase data efficiency.\nThis study explores the effects of varying quantities of target task training\ndata on sequential transfer learning in the dialog domain. We hypothesize that\na model can utilize the information learned from a source task to better learn\na target task, thereby reducing the number of target task training samples\nrequired. Unintuitively, our data shows that often target task training data\nsize has minimal effect on how sequential transfer learning performs compared\nto the same model without transfer learning. Our results lead us to believe\nthat this unexpected result could be due to the effects of catastrophic\nforgetting, motivating further work into methods that prevent such forgetting.",
    "descriptor": "",
    "authors": [
      "Josiah Ross",
      "Luke Yoffe",
      "Alon Albalak",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11729"
  },
  {
    "id": "arXiv:2210.11730",
    "title": "Privacy-Preserved Neural Graph Similarity Learning",
    "abstract": "To develop effective and efficient graph similarity learning (GSL) models, a\nseries of data-driven neural algorithms have been proposed in recent years.\nAlthough GSL models are frequently deployed in privacy-sensitive scenarios, the\nuser privacy protection of neural GSL models has not drawn much attention. To\ncomprehensively understand the privacy protection issues, we first introduce\nthe concept of attackable representation to systematically characterize the\nprivacy attacks that each model can face. Inspired by the qualitative results,\nwe propose a novel Privacy-Preserving neural Graph Matching network model,\nnamed PPGM, for graph similarity learning. To prevent reconstruction attacks,\nthe proposed model does not communicate node-level representations between\ndevices. Instead, we learn multi-perspective graph representations based on\nlearnable context vectors. To alleviate the attacks to graph properties, the\nobfuscated features that contain information from both graphs are communicated.\nIn this way, the private properties of each graph can be difficult to infer.\nBased on the node-graph matching techniques while calculating the obfuscated\nfeatures, PPGM can also be effective in similarity measuring. To quantitatively\nevaluate the privacy-preserving ability of neural GSL models, we further\npropose an evaluation protocol via training supervised black-box attack models.\nExtensive experiments on widely-used benchmarks show the effectiveness and\nstrong privacy-protection ability of the proposed model PPGM. The code is\navailable at: https://github.com/RUCAIBox/PPGM.",
    "descriptor": "\nComments: Accepted by ICDM 2022 as a regular paper\n",
    "authors": [
      "Yupeng Hou",
      "Wayne Xin Zhao",
      "Yaliang Li",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11730"
  },
  {
    "id": "arXiv:2210.11731",
    "title": "Analogical Concept Memory for Architectures Implementing the Common  Model of Cognition",
    "abstract": "Architectures that implement the Common Model of Cognition - Soar, ACT-R, and\nSigma - have a prominent place in research on cognitive modeling as well as on\ndesigning complex intelligent agents. In this paper, we explore how\ncomputational models of analogical processing can be brought into these\narchitectures to enable concept acquisition from examples obtained\ninteractively. We propose a new analogical concept memory for Soar that\naugments its current system of declarative long-term memories. We frame the\nproblem of concept learning as embedded within the larger context of\ninteractive task learning (ITL) and embodied language processing (ELP). We\ndemonstrate that the analogical learning methods implemented in the proposed\nmemory can quickly learn a diverse types of novel concepts that are useful not\nonly in recognition of a concept in the environment but also in action\nselection. Our approach has been instantiated in an implemented cognitive\nsystem AILEEN and evaluated on a simulated robotic domain.",
    "descriptor": "\nComments: Under review at Cognitive Systems Research. arXiv admin note: substantial text overlap with arXiv:2006.01962\n",
    "authors": [
      "Shiwali Mohan",
      "Matthew Klenk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11731"
  },
  {
    "id": "arXiv:2210.11735",
    "title": "Extracted BERT Model Leaks More Information than You Think!",
    "abstract": "The collection and availability of big data, combined with advances in\npre-trained models (e.g. BERT), have revolutionized the predictive performance\nof natural language processing tasks. This allows corporations to provide\nmachine learning as a service (MLaaS) by encapsulating fine-tuned BERT-based\nmodels as APIs. Due to significant commercial interest, there has been a surge\nof attempts to steal re mote services via model extraction. Although previous\nworks have made progress in defending against model extraction attacks, there\nhas been little discussion on their performance in preventing privacy leakage.\nThis work bridges this gap by launching an attribute inference attack against\nthe extracted BERT model. Our extensive experiments reveal that model\nextraction can cause severe privacy leakage even when victim models are\nfacilitated with advanced defensive strategies.",
    "descriptor": "\nComments: accepted to EMNLP2022. arXiv admin note: text overlap with arXiv:2105.10909\n",
    "authors": [
      "Xuanli He",
      "Chen Chen",
      "Lingjuan Lyu",
      "Qiongkai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11735"
  },
  {
    "id": "arXiv:2210.11743",
    "title": "$A^2RID$ -- Anonymous Direct Authentication and Remote Identification of  Commercial Drones",
    "abstract": "The recent worldwide introduction of RemoteID (RID) regulations forces all\nUnmanned Aircrafts (UAs), a.k.a. drones, to broadcast in plaintext on the\nwireless channel their identity and real-time location, for accounting and\nmonitoring purposes. Although improving drones' monitoring and situational\nawareness, the RID rule also generates significant privacy concerns for UAs'\noperators, threatened by the ease of tracking of UAs and related\nconfidentiality and privacy concerns connected with the broadcasting of\nplaintext identity information. In this paper, we propose $A^2RID$, a protocol\nsuite for anonymous direct authentication and remote identification of\nheterogeneous commercial UAs. $A^2RID$ integrates and adapts protocols for\nanonymous message signing to work in the UA domain, coping with the constraints\nof commercial drones and the tight real-time requirements imposed by the RID\nregulation. Overall, the protocols in the $A^2RID$ suite allow a UA\nmanufacturer to pick the configuration that best suits the capabilities and\nconstraints of the drone, i.e., either a processing-intensive but\nmemory-lightweight solution (namely, $CS-A^2RID$) or a computationally-friendly\nbut memory-hungry approach (namely, $DS-A^2RID$). Besides formally defining the\nprotocols and formally proving their security in our setting, we also implement\nand test them on real heterogeneous hardware platforms, i.e., the Holybro X-500\nand the ESPcopter, releasing open-source the produced code. For all the\nprotocols, we demonstrated experimentally the capability of generating\nanonymous RemoteID messages well below the time bound of $1$ second required by\nRID, while at the same time having quite a limited impact on the energy budget\nof the drone.",
    "descriptor": "",
    "authors": [
      "Eva Wisse",
      "Pietro Tedeschi",
      "Savio Sciancalepore",
      "Roberto Di Pietro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.11743"
  },
  {
    "id": "arXiv:2210.11744",
    "title": "AfroLID: A Neural Language Identification Tool for African Languages",
    "abstract": "Language identification (LID) is a crucial precursor for NLP, especially for\nmining web data. Problematically, most of the world's $7000$+ languages today\nare not covered by LID technologies. We address this pressing issue for Africa\nby introducing~\\ourLID, a neural LID toolkit for $517$ African languages and\nvarieties.~\\ourLID~exploits a multi-domain web dataset manually curated from\nacross $14$ language families utilizing five orthographic systems. When\nevaluated on our blind Test set,~\\ourLID~achieves $95.89$ $F_1$-score. We also\ncompare~\\ourLID~to five existing LID tools that each cover a small number of\nAfrican languages, finding it to outperform them on most languages. We further\nshow the utility of~\\ourLID~in the wild by testing it on the acutely\nunder-served Twitter domain. Finally, we offer a number of controlled case\nstudies and perform a linguistically-motivated error analysis that allow us to\nboth showcase~\\ourLID's powerful capabilities and limitations.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Main conference\n",
    "authors": [
      "Ife Adebara",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Alcides Alcoba Inciarte"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11744"
  },
  {
    "id": "arXiv:2210.11745",
    "title": "BC-IoDT: Blockchain-based Framework for Authentication in Internet of  Drone Things",
    "abstract": "We leverage blockchain technology for drone node authentication in internet\nof drone things (IoDT). During the authentication procedure, the credentials of\ndrone nodes are examined to remove malicious nodes from the system. In IoDT,\ndrones are responsible for gathering data and transmitting it to cluster heads\n(CHs) for further processing. The CH collects and organizes data. Due to\ncomputational load, their energy levels rapidly deplete. To overcome this\nproblem, we present a low-energy adaptive clustering hierarchy (R2D) protocol\nbased on distance, degree, and residual energy. R2D is used to replace CHs with\nnormal nodes based on the biggest residual energy, the degree, and the shortest\ndistance from BS. The cost of keeping a big volume of data on the blockchain is\nhigh. We employ the Interplanetary File System (IPFS), to address this issue.\nMoreover, IPFS protects user data using the industry-standard encryption\ntechnique AES-128. This standard compares well to other current encryption\nmethods. Using a consensus mechanism based on proof of work requires a high\namount of computing resources for transaction verification. The suggested\napproach leverages a consensus mechanism known as proof of authority (PoA) to\naddress this problem . The results of the simulations indicate that the\nsuggested system model functions effectively and efficiently. A formal security\nanalysis is conducted to assess the smart contract's resistance to attacks.",
    "descriptor": "\nComments: 6 pages, 3 figures, ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond\n",
    "authors": [
      "Junaid Akram",
      "Awais Akram",
      "Rutvij H. Jhaveri",
      "Mamoun Alazab",
      "Haoran Chi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.11745"
  },
  {
    "id": "arXiv:2210.11747",
    "title": "When Wireless Hierarchical Federated Learning Meets Physical Layer  Security: A Finite Blocklength Approach",
    "abstract": "In this paper, the wireless hierarchical federated learning (HFL) is\nrevisited by considering physical layer security (PLS). First, we establish a\nframework for this new problem. Then, we propose a practical finite blocklength\n(FBL) coding scheme for the wireless HFL in the presence of PLS, which is\nself-secure when the coding blocklength is lager than a certain threshold.\nFinally, the study of this paper is further explained via numerical examples\nand simulation results.",
    "descriptor": "\nComments: submitted to IEEE Infocom 2023\n",
    "authors": [
      "Haonan Zhang",
      "Chuanchuan Yang",
      "Bin Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11747"
  },
  {
    "id": "arXiv:2210.11750",
    "title": "Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data",
    "abstract": "3D LiDAR sensors are indispensable for the robust vision of autonomous mobile\nrobots. However, deploying LiDAR-based perception algorithms often fails due to\na domain gap from the training environment, such as inconsistent angular\nresolution and missing properties. Existing studies have tackled the issue by\nlearning inter-domain mapping, while the transferability is constrained by the\ntraining configuration and the training is susceptible to peculiar lossy noises\ncalled ray-drop. To address the issue, this paper proposes a generative model\nof LiDAR range images applicable to the data-level domain transfer. Motivated\nby the fact that LiDAR measurement is based on point-by-point range imaging, we\ntrain an implicit image representation-based generative adversarial networks\nalong with a differentiable ray-drop effect. We demonstrate the fidelity and\ndiversity of our model in comparison with the point-based and image-based\nstate-of-the-art generative models. We also showcase upsampling and restoration\napplications. Furthermore, we introduce a Sim2Real application for LiDAR\nsemantic segmentation. We demonstrate that our method is effective as a\nrealistic ray-drop simulator and outperforms state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Kazuto Nakashima",
      "Yumi Iwashita",
      "Ryo Kurazume"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.11750"
  },
  {
    "id": "arXiv:2210.11753",
    "title": "TransLIST: A Transformer-Based Linguistically Informed Sanskrit  Tokenizer",
    "abstract": "Sanskrit Word Segmentation (SWS) is essential in making digitized texts\navailable and in deploying downstream tasks. It is, however, non-trivial\nbecause of the sandhi phenomenon that modifies the characters at the word\nboundaries, and needs special treatment. Existing lexicon driven approaches for\nSWS make use of Sanskrit Heritage Reader, a lexicon-driven shallow parser, to\ngenerate the complete candidate solution space, over which various methods are\napplied to produce the most valid solution. However, these approaches fail\nwhile encountering out-of-vocabulary tokens. On the other hand, purely\nengineering methods for SWS have made use of recent advances in deep learning,\nbut cannot make use of the latent word information on availability.\nTo mitigate the shortcomings of both families of approaches, we propose\nTransformer based Linguistically Informed Sanskrit Tokenizer (TransLIST)\nconsisting of (1) a module that encodes the character input along with\nlatent-word information, which takes into account the sandhi phenomenon\nspecific to SWS and is apt to work with partial or no candidate solutions, (2)\na novel soft-masked attention to prioritize potential candidate words and (3) a\nnovel path ranking algorithm to rectify the corrupted predictions. Experiments\non the benchmark datasets for SWS show that TransLIST outperforms the current\nstate-of-the-art system by an average 7.2 points absolute gain in terms of\nperfect match (PM) metric. The codebase and datasets are publicly available at\nhttps://github.com/rsingha108/TransLIST",
    "descriptor": "\nComments: Accepted at EMNLP22 (Findings)\n",
    "authors": [
      "Jivnesh Sandhan",
      "Rathin Singha",
      "Narein Rao",
      "Suvendu Samanta",
      "Laxmidhar Behera",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11753"
  },
  {
    "id": "arXiv:2210.11755",
    "title": "online and lightweight kernel-based approximated policy iteration for  dynamic p-norm linear adaptive filtering",
    "abstract": "This paper introduces a solution to the problem of selecting dynamically\n(online) the ``optimal'' p-norm to combat outliers in linear adaptive filtering\nwithout any knowledge on the probability density function of the outliers. The\nproposed online and data-driven framework is built on kernel-based\nreinforcement learning (KBRL). To this end, novel Bellman mappings on\nreproducing kernel Hilbert spaces (RKHSs) are introduced. These mappings do not\nrequire any knowledge on transition probabilities of Markov decision processes,\nand are nonexpansive with respect to the underlying Hilbertian norm. The\nfixed-point sets of the proposed Bellman mappings are utilized to build an\napproximate policy-iteration (API) framework for the problem at hand. To\naddress the ``curse of dimensionality'' in RKHSs, random Fourier features are\nutilized to bound the computational complexity of the API. Numerical tests on\nsynthetic data for several outlier scenarios demonstrate the superior\nperformance of the proposed API framework over several non-RL and KBRL schemes.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2210.11317\n",
    "authors": [
      "Yuki Akiyama",
      "Minh Vu",
      "Konstantinos Slavakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11755"
  },
  {
    "id": "arXiv:2210.11757",
    "title": "University of Cape Town's WMT22 System: Multilingual Machine Translation  for Southern African Languages",
    "abstract": "The paper describes the University of Cape Town's submission to the\nconstrained track of the WMT22 Shared Task: Large-Scale Machine Translation\nEvaluation for African Languages. Our system is a single multilingual\ntranslation model that translates between English and 8 South / South East\nAfrican Languages, as well as between specific pairs of the African languages.\nWe used several techniques suited for low-resource machine translation (MT),\nincluding overlap BPE, back-translation, synthetic training data generation,\nand adding more translation directions during training. Our results show the\nvalue of these techniques, especially for directions where very little or no\nbilingual training data is available.",
    "descriptor": "\nComments: 10 pages, WMT22\n",
    "authors": [
      "Khalid N. Elmadani",
      "Francois Meyer",
      "Jan Buys"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11757"
  },
  {
    "id": "arXiv:2210.11759",
    "title": "Syntax-guided Localized Self-attention by Constituency Syntactic  Distance",
    "abstract": "Recent works have revealed that Transformers are implicitly learning the\nsyntactic information in its lower layers from data, albeit is highly dependent\non the quality and scale of the training data. However, learning syntactic\ninformation from data is not necessary if we can leverage an external syntactic\nparser, which provides better parsing quality with well-defined syntactic\nstructures. This could potentially improve Transformer's performance and sample\nefficiency. In this work, we propose a syntax-guided localized self-attention\nfor Transformer that allows directly incorporating grammar structures from an\nexternal constituency parser. It prohibits the attention mechanism to\noverweight the grammatically distant tokens over close ones. Experimental\nresults show that our model could consistently improve translation performance\non a variety of machine translation datasets, ranging from small to large\ndataset sizes, and with different source languages.",
    "descriptor": "",
    "authors": [
      "Shengyuan Hou",
      "Jushi Kai",
      "Haotian Xue",
      "Bingyu Zhu",
      "Bo Yuan",
      "Longtao Huang",
      "Xinbing Wang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11759"
  },
  {
    "id": "arXiv:2210.11761",
    "title": "RVE Analysis in LS-DYNA for High-fidelity Multiscale Material Modeling",
    "abstract": "In modern engineering designs, advanced materials (e.g.,\nfiber/particle-reinforced polymers, metallic alloys, laminar composites, etc.)\nare widely used, where microscale heterogeneities such as grains, inclusions,\nvoids, micro-cracks, and interfaces significantly affect the macroscopic\nconstitutive behaviors. Obviously, an accurate description of the multiscale\nmaterial behaviors is of great importance to the success of material design and\nstructural analysis. The Representative Volume Element (RVE) analysis method\nprovides a rigorous means to obtain homogenized macroscopic material properties\nat the upper length scale from the properties of the material constituents and\nstructures at a lower length scale. Recently, we have developed an RVE module\n(keyword: *RVE_ANALYSIS_FEM) in the multiphysics simulation software LS-DYNA to\nenable high-fidelity virtual testing of numerically re-constructed material\nsamples at user-specified characteristic length scales. In this article, a\nbrief introduction to this new feature will be given.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Haoyan Wei",
      "Dandan Lyu",
      "Wei Hu",
      "C.T. Wu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11761"
  },
  {
    "id": "arXiv:2210.11762",
    "title": "Detecting Unintended Social Bias in Toxic Language Datasets",
    "abstract": "With the rise of online hate speech, automatic detection of Hate Speech,\nOffensive texts as a natural language processing task is getting popular.\nHowever, very little research has been done to detect unintended social bias\nfrom these toxic language datasets. This paper introduces a new dataset\nToxicBias curated from the existing dataset of Kaggle competition named \"Jigsaw\nUnintended Bias in Toxicity Classification\". We aim to detect social biases,\ntheir categories, and targeted groups. The dataset contains instances annotated\nfor five different bias categories, viz., gender, race/ethnicity, religion,\npolitical, and LGBTQ. We train transformer-based models using our curated\ndatasets and report baseline performance for bias identification, target\ngeneration, and bias implications. Model biases and their mitigation are also\ndiscussed in detail. Our study motivates a systematic extraction of social bias\ndata from toxic language datasets. All the codes and dataset used for\nexperiments in this work are publicly available",
    "descriptor": "",
    "authors": [
      "Nihar Sahoo",
      "Himanshu Gupta",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11762"
  },
  {
    "id": "arXiv:2210.11766",
    "title": "CEFR-Based Sentence Difficulty Annotation and Assessment",
    "abstract": "Controllable text simplification is a crucial assistive technique for\nlanguage learning and teaching. One of the primary factors hindering its\nadvancement is the lack of a corpus annotated with sentence difficulty levels\nbased on language ability descriptions. To address this problem, we created the\nCEFR-based Sentence Profile (CEFR-SP) corpus, containing 17k English sentences\nannotated with the levels based on the Common European Framework of Reference\nfor Languages assigned by English-education professionals. In addition, we\npropose a sentence-level assessment model to handle unbalanced level\ndistribution because the most basic and highly proficient sentences are\nnaturally scarce. In the experiments in this study, our method achieved a\nmacro-F1 score of 84.5% in the level assessment, thus outperforming strong\nbaselines employed in readability assessment.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Yuki Arase",
      "Satoru Uchida",
      "Tomoyuki Kajiwara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11766"
  },
  {
    "id": "arXiv:2210.11768",
    "title": "Augmentation with Projection: Towards an Effective and Efficient Data  Augmentation Paradigm for Distillation",
    "abstract": "Knowledge distillation is one of the primary methods of transferring\nknowledge from large to small models. However, it requires massive\ntask-specific data, which may not be plausible in many real-world applications.\nData augmentation methods such as representation interpolation, token\nreplacement, or augmentation with models are applied to tackle this problem.\nHowever, these data augmentation methods either potentially cause shifts in\ndecision boundaries (representation interpolation), are not expressive enough\n(token replacement), or introduce too much computational overhead (augmentation\nwith models). To this end, we propose AugPro (Augmentation with Projection), an\neffective and efficient data augmentation method for distillation. Our method\nbuilds on top of representation interpolation augmentation methods to maintain\nthe diversity of expressions and converts the augmented data to tokens to avoid\nshifting decision boundaries. It uses simple operations that come with little\ncomputational overhead. The results on multiple GLUE tasks show that our\nmethods can improve distillation performance by a large margin at a low time\ncost.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Ziqi Wang",
      "Yuexin Wu",
      "Frederick Liu",
      "Daogao Liu",
      "Le Hou",
      "Hongkun Yu",
      "Jing Li",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11768"
  },
  {
    "id": "arXiv:2210.11771",
    "title": "InforMask: Unsupervised Informative Masking for Language Model  Pretraining",
    "abstract": "Masked language modeling is widely used for pretraining large language models\nfor natural language understanding (NLU). However, random masking is\nsuboptimal, allocating an equal masking rate for all tokens. In this paper, we\npropose InforMask, a new unsupervised masking strategy for training masked\nlanguage models. InforMask exploits Pointwise Mutual Information (PMI) to\nselect the most informative tokens to mask. We further propose two\noptimizations for InforMask to improve its efficiency. With a one-off\npreprocessing step, InforMask outperforms random masking and previously\nproposed masking strategies on the factual recall benchmark LAMA and the\nquestion answering benchmark SQuAD v1 and v2.",
    "descriptor": "",
    "authors": [
      "Nafis Sadeq",
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11771"
  },
  {
    "id": "arXiv:2210.11773",
    "title": "SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval",
    "abstract": "Sampling proper negatives from a large document pool is vital to effectively\ntrain a dense retrieval model. However, existing negative sampling strategies\nsuffer from the uninformative or false negative problem. In this work, we\nempirically show that according to the measured relevance scores, the negatives\nranked around the positives are generally more informative and less likely to\nbe false negatives. Intuitively, these negatives are not too hard (\\emph{may be\nfalse negatives}) or too easy (\\emph{uninformative}). They are the ambiguous\nnegatives and need more attention during training. Thus, we propose a simple\nambiguous negatives sampling method, SimANS, which incorporates a new sampling\nprobability distribution to focusing on sampling more ambiguous negatives.\nExtensive experiments on four public and one industry datasets show the\neffectiveness of our approach. Our code and data are publicly available at the\nlink: \\url{https://github.com/microsoft/SimXNS}.",
    "descriptor": "\nComments: 12 pages, accepted by EMNLP 2022\n",
    "authors": [
      "Kun Zhou",
      "Yeyun Gong",
      "Xiao Liu",
      "Wayne Xin Zhao",
      "Yelong Shen",
      "Anlei Dong",
      "Jingwen Lu",
      "Rangan Majumder",
      "Ji-Rong Wen",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11773"
  },
  {
    "id": "arXiv:2210.11774",
    "title": "Left ideal LRPC codes and a ROLLO-type cryptosystem based on group  algebras",
    "abstract": "In this paper we introduce left ideal low-rank parity-check codes by using\ngroup algebras and we finally use them to extend ROLLO-I KEM.",
    "descriptor": "\nComments: This is an extended abstract. Comments are welcome!\n",
    "authors": [
      "Martino Borello",
      "Paolo Santonastaso",
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2210.11774"
  },
  {
    "id": "arXiv:2210.11777",
    "title": "Analyzing and Evaluating Faithfulness in Dialogue Summarization",
    "abstract": "Dialogue summarization is abstractive in nature, making it suffer from\nfactual errors. The factual correctness of summaries has the highest priority\nbefore practical applications. Many efforts have been made to improve\nfaithfulness in text summarization. However, there is a lack of systematic\nstudy on dialogue summarization systems. In this work, we first perform the\nfine-grained human analysis on the faithfulness of dialogue summaries and\nobserve that over 35% of generated summaries are faithfully inconsistent\nrespective the source dialogues. Furthermore, we present a new model-level\nfaithfulness evaluation method. It examines generation models with multi-choice\nquestions created by rule-based transformations. Experimental results show that\nour evaluation schema is a strong proxy for the factual correctness of\nsummarization models. The human-annotated faithfulness samples and the\nevaluation toolkit are released to facilitate future research toward faithful\ndialogue summarization.",
    "descriptor": "\nComments: EMNLP 2022 - Long Paper - 12 pages\n",
    "authors": [
      "Bin Wang",
      "Chen Zhang",
      "Yan Zhang",
      "Yiming Chen",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11777"
  },
  {
    "id": "arXiv:2210.11778",
    "title": "Rerouting Planar Curves and Disjoint Paths",
    "abstract": "In this paper, we consider a transformation of $k$ disjoint paths in a graph.\nFor a graph and a pair of $k$ disjoint paths $\\mathcal{P}$ and $\\mathcal{Q}$\nconnecting the same set of terminal pairs, we aim to determine whether\n$\\mathcal{P}$ can be transformed to $\\mathcal{Q}$ by repeatedly replacing one\npath with another path so that the intermediates are also $k$ disjoint paths.\nThe problem is called Disjoint Paths Reconfiguration. We first show that\nDisjoint Paths Reconfiguration is PSPACE-complete even when $k=2$. On the other\nhand, we prove that, when the graph is embedded on a plane and all paths in\n$\\mathcal{P}$ and $\\mathcal{Q}$ connect the boundaries of two faces, Disjoint\nPaths Reconfiguration can be solved in polynomial time. The algorithm is based\non a topological characterization for rerouting curves on a plane using the\nalgebraic intersection number. We also consider a transformation of disjoint\n$s$-$t$ paths as a variant. We show that the disjoint $s$-$t$ paths\nreconfiguration problem in planar graphs can be determined in polynomial time,\nwhile the problem is PSPACE-complete in general.",
    "descriptor": "",
    "authors": [
      "Takehiro Ito",
      "Yuni Iwamasa",
      "Naonori Kakimura",
      "Yusuke Kobayashi",
      "Shun-ichi Maezawa",
      "Yuta Nozaki",
      "Yoshio Okamoto",
      "Kenta Ozeki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.11778"
  },
  {
    "id": "arXiv:2210.11779",
    "title": "Reaching Through Latent Space: From Joint Statistics to Path Planning in  Manipulation",
    "abstract": "We present a novel approach to path planning for robotic manipulators, in\nwhich paths are produced via iterative optimisation in the latent space of a\ngenerative model of robot poses. Constraints are incorporated through the use\nof constraint satisfaction classifiers operating on the same space.\nOptimisation leverages gradients through our learned models that provide a\nsimple way to combine goal reaching objectives with constraint satisfaction,\neven in the presence of otherwise non-differentiable constraints. Our models\nare trained in a task-agnostic manner on randomly sampled robot poses. In\nbaseline comparisons against a number of widely used planners, we achieve\ncommensurate performance in terms of task success, planning time and path\nlength, performing successful path planning with obstacle avoidance on a real\n7-DoF robot arm.",
    "descriptor": "\nComments: 10 pages, 6 figures, 4 tables\n",
    "authors": [
      "Chia-Man Hung",
      "Shaohong Zhong",
      "Walter Goodwin",
      "Oiwi Parker Jones",
      "Martin Engelcke",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11779"
  },
  {
    "id": "arXiv:2210.11783",
    "title": "DARWIN: Survival of the Fittest Fuzzing Mutators",
    "abstract": "Fuzzing is an automated software testing technique broadly adopted by the\nindustry. A popular variant is mutation-based fuzzing, which discovers a large\nnumber of bugs in practice. While the research community has studied\nmutation-based fuzzing for years now, the algorithms' interactions within the\nfuzzer are highly complex and can, together with the randomness in every\ninstance of a fuzzer, lead to unpredictable effects. Most efforts to improve\nthis fragile interaction focused on optimizing seed scheduling. However,\nreal-world results like Google's FuzzBench highlight that these approaches do\nnot consistently show improvements in practice. Another approach to improve the\nfuzzing process algorithmically is optimizing mutation scheduling.\nUnfortunately, existing mutation scheduling approaches also failed to convince\nbecause of missing real-world improvements or too many user-controlled\nparameters whose configuration requires expert knowledge about the target\nprogram. This leaves the challenging problem of cleverly processing test cases\nand achieving a measurable improvement unsolved.\nWe present DARWIN, a novel mutation scheduler and the first to show fuzzing\nimprovements in a realistic scenario without the need to introduce additional\nuser-configurable parameters, opening this approach to the broad fuzzing\ncommunity. DARWIN uses an Evolution Strategy to systematically optimize and\nadapt the probability distribution of the mutation operators during fuzzing. We\nimplemented a prototype based on the popular general-purpose fuzzer AFL. DARWIN\nsignificantly outperforms the state-of-the-art mutation scheduler and the AFL\nbaseline in our own coverage experiment, in FuzzBench, and by finding 15 out of\n21 bugs the fastest in the MAGMA benchmark. Finally, DARWIN found 20 unique\nbugs (including one novel bug), 66% more than AFL, in widely-used real-world\napplications.",
    "descriptor": "",
    "authors": [
      "Patrick Jauernig",
      "Domagoj Jakobovic",
      "Stjepan Picek",
      "Emmanuel Stapf",
      "Ahmad-Reza Sadeghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11783"
  },
  {
    "id": "arXiv:2210.11784",
    "title": "A Simple Deterministic Distributed Low-Diameter Clustering",
    "abstract": "We give a simple, local process for nodes in an undirected graph to form\nnon-adjacent clusters that (1) have at most a polylogarithmic diameter and (2)\ncontain at least half of all vertices. Efficient deterministic distributed\nclustering algorithms for computing strong-diameter network decompositions and\nother key tools follow immediately. Overall, our process is a direct and\ndrastically simplified way for computing these fundamental objects.",
    "descriptor": "",
    "authors": [
      "V\u00e1clav Rozho\u0148",
      "Bernhard Haeupler",
      "Christoph Grunau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.11784"
  },
  {
    "id": "arXiv:2210.11787",
    "title": "Modeling Document-level Temporal Structures for Building Temporal  Dependency Graphs",
    "abstract": "We propose to leverage news discourse profiling to model document-level\ntemporal structures for building temporal dependency graphs. Our key\nobservation is that the functional roles of sentences used for profiling news\ndiscourse signify different time frames relevant to a news story and can,\ntherefore, help to recover the global temporal structure of a document. Our\nanalyses and experiments with the widely used knowledge distillation technique\nshow that discourse profiling effectively identifies distant inter-sentence\nevent and (or) time expression pairs that are temporally related and otherwise\ndifficult to locate.",
    "descriptor": "\nComments: AACL 2022\n",
    "authors": [
      "Prafulla Kumar Choubey",
      "Ruihong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11787"
  },
  {
    "id": "arXiv:2210.11790",
    "title": "FoSR: First-order spectral rewiring for addressing oversquashing in GNNs",
    "abstract": "Graph neural networks (GNNs) are able to leverage the structure of graph data\nby passing messages along the edges of the graph. While this allows GNNs to\nlearn features depending on the graph structure, for certain graph topologies\nit leads to inefficient information propagation and a problem known as\noversquashing. This has recently been linked with the curvature and spectral\ngap of the graph. On the other hand, adding edges to the message-passing graph\ncan lead to increasingly similar node representations and a problem known as\noversmoothing. We propose a computationally efficient algorithm that prevents\noversquashing by systematically adding edges to the graph based on spectral\nexpansion. We combine this with a relational architecture, which lets the GNN\npreserve the original graph structure and provably prevents oversmoothing. We\nfind experimentally that our algorithm outperforms existing graph rewiring\nmethods in several graph classification tasks.",
    "descriptor": "",
    "authors": [
      "Kedar Karhadkar",
      "Pradeep Kr. Banerjee",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11790"
  },
  {
    "id": "arXiv:2210.11791",
    "title": "Cross-chain Swaps with Preferences",
    "abstract": "Extreme valuation and volatility of cryptocurrencies require investors to\ndiversify often which demands secure exchange protocols. A cross-chain swap\nprotocol allows distrusting parties to securely exchange their assets. However,\nthe current models and protocols assume predefined user preferences for\nacceptable outcomes. This paper presents a generalized model of swaps that\nallows each party to specify its preferences on the subsets of its incoming and\noutgoing assets. It shows that the existing swap protocols are not necessarily\na strong Nash equilibrium in this model. It characterizes the class of swap\ngraphs that have protocols that are safe, live and a strong Nash equilibrium,\nand presents such a protocol for this class. Further, it shows that deciding\nwhether a swap is in this class is NP-hard through a reduction from 3SAT, and\nfurther is $\\Sigma_2^{\\mathsf{P}}$-complete through a reduction from\n$\\exists\\forall\\mathsf{DNF}$.",
    "descriptor": "",
    "authors": [
      "Eric Chan",
      "Marek Chrobak",
      "Mohsen Lesani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11791"
  },
  {
    "id": "arXiv:2210.11794",
    "title": "Diffuser: Efficient Transformers with Multi-hop Attention Diffusion for  Long Sequences",
    "abstract": "Efficient Transformers have been developed for long sequence modeling, due to\ntheir subquadratic memory and time complexity. Sparse Transformer is a popular\napproach to improving the efficiency of Transformers by restricting\nself-attention to locations specified by the predefined sparse patterns.\nHowever, leveraging sparsity may sacrifice expressiveness compared to\nfull-attention, when important token correlations are multiple hops away. To\ncombine advantages of both the efficiency of sparse transformer and the\nexpressiveness of full-attention Transformer, we propose \\textit{Diffuser}, a\nnew state-of-the-art efficient Transformer. Diffuser incorporates all token\ninteractions within one attention layer while maintaining low computation and\nmemory costs. The key idea is to expand the receptive field of sparse attention\nusing Attention Diffusion, which computes multi-hop token correlations based on\nall paths between corresponding disconnected tokens, besides attention among\nneighboring tokens. Theoretically, we show the expressiveness of Diffuser as a\nuniversal sequence approximator for sequence-to-sequence modeling, and\ninvestigate its ability to approximate full-attention by analyzing the graph\nexpander property from the spectral perspective. Experimentally, we investigate\nthe effectiveness of Diffuser with extensive evaluations, including language\nmodeling, image modeling, and Long Range Arena (LRA). Evaluation results show\nthat Diffuser achieves improvements by an average of 0.94% on text\nclassification tasks and 2.30% on LRA, with 1.67$\\times$ memory savings\ncompared to state-of-the-art benchmarks, which demonstrates superior\nperformance of Diffuser in both expressiveness and efficiency aspects.",
    "descriptor": "",
    "authors": [
      "Aosong Feng",
      "Irene Li",
      "Yuang Jiang",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11794"
  },
  {
    "id": "arXiv:2210.11795",
    "title": "PoseScript: 3D Human Poses from Natural Language",
    "abstract": "Natural language is leveraged in many computer vision tasks such as image\ncaptioning, cross-modal retrieval or visual question answering, to provide\nfine-grained semantic information. While human pose is key to human\nunderstanding, current 3D human pose datasets lack detailed language\ndescriptions. In this work, we introduce the PoseScript dataset, which pairs a\nfew thousand 3D human poses from AMASS with rich human-annotated descriptions\nof the body parts and their spatial relationships. To increase the size of this\ndataset to a scale compatible with typical data hungry learning algorithms, we\npropose an elaborate captioning process that generates automatic synthetic\ndescriptions in natural language from given 3D keypoints. This process extracts\nlow-level pose information -- the posecodes -- using a set of simple but\ngeneric rules on the 3D keypoints. The posecodes are then combined into higher\nlevel textual descriptions using syntactic rules. Automatic annotations\nsubstantially increase the amount of available data, and make it possible to\neffectively pretrain deep models for finetuning on human captions. To\ndemonstrate the potential of annotated poses, we show applications of the\nPoseScript dataset to retrieval of relevant poses from large-scale datasets and\nto synthetic pose generation, both based on a textual pose description.",
    "descriptor": "\nComments: Published in ECCV 2022\n",
    "authors": [
      "Ginger Delmas",
      "Philippe Weinzaepfel",
      "Thomas Lucas",
      "Francesc Moreno-Noguer",
      "Gr\u00e9gory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11795"
  },
  {
    "id": "arXiv:2210.11796",
    "title": "Differentiable Constrained Imitation Learning for Robot Motion Planning  and Control",
    "abstract": "Motion planning and control are crucial components of robotics applications.\nHere, spatio-temporal hard constraints like system dynamics and safety\nboundaries (e.g., obstacles in automated driving) restrict the robot's motions.\nDirect methods from optimal control solve a constrained optimization problem.\nHowever, in many applications finding a proper cost function is inherently\ndifficult because of the weighting of partially conflicting objectives. On the\nother hand, Imitation Learning (IL) methods such as Behavior Cloning (BC)\nprovide a intuitive framework for learning decision-making from offline\ndemonstrations and constitute a promising avenue for planning and control in\ncomplex robot applications. Prior work primarily relied on soft-constraint\napproaches, which use additional auxiliary loss terms describing the\nconstraints. However, catastrophic safety-critical failures might occur in\nout-of-distribution (OOD) scenarios. This work integrates the flexibility of IL\nwith hard constraint handling in optimal control. Our approach constitutes a\ngeneral framework for constraint robotic motion planning and control using\noffline IL. Hard constraints are integrated into the learning problem in a\ndifferentiable manner, via explicit completion and gradient-based correction.\nSimulated experiments of mobile robot navigation and automated driving provide\nevidence for the performance of the proposed method.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Christopher Diehl",
      "Janis Adamek",
      "Martin Kr\u00fcger",
      "Frank Hoffmann",
      "Torsten Bertram"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11796"
  },
  {
    "id": "arXiv:2210.11800",
    "title": "Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation  Extraction",
    "abstract": "Relation extraction (RE) has achieved remarkable progress with the help of\npre-trained language models. However, existing RE models are usually incapable\nof handling two situations: implicit expressions and long-tail relation types,\ncaused by language complexity and data sparsity. In this paper, we introduce a\nsimple enhancement of RE using $k$ nearest neighbors ($k$NN-RE). $k$NN-RE\nallows the model to consult training relations at test time through a\nnearest-neighbor search and provides a simple yet effective means to tackle the\ntwo issues above. Additionally, we observe that $k$NN-RE serves as an effective\nway to leverage distant supervision (DS) data for RE. Experimental results show\nthat the proposed $k$NN-RE achieves state-of-the-art performances on a variety\nof supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with\noutperforming the best model to date on the i2b2 and Wiki80 datasets in the\nsetting of allowing using DS. Our code and models are available at:\nhttps://github.com/YukinoWan/kNN-RE.",
    "descriptor": "",
    "authors": [
      "Zhen Wan",
      "Qianying Liu",
      "Zhuoyuan Mao",
      "Fei Cheng",
      "Sadao Kurohashi",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11800"
  },
  {
    "id": "arXiv:2210.11801",
    "title": "Random Actions vs Random Policies: Bootstrapping Model-Based Direct  Policy Search",
    "abstract": "This paper studies the impact of the initial data gathering method on the\nsubsequent learning of a dynamics model. Dynamics models approximate the true\ntransition function of a given task, in order to perform policy search directly\non the model rather than on the costly real system. This study aims to\ndetermine how to bootstrap a model as efficiently as possible, by comparing\ninitialization methods employed in two different policy search frameworks in\nthe literature. The study focuses on the model performance under the\nepisode-based framework of Evolutionary methods using probabilistic ensembles.\nExperimental results show that various task-dependant factors can be\ndetrimental to each method, suggesting to explore hybrid approaches.",
    "descriptor": "\nComments: ICML 2022 Workshop Adaptive Experimental Design and Active Learning in the Real World\n",
    "authors": [
      "Elias Hanna",
      "Alex Coninx",
      "St\u00e9phane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11801"
  },
  {
    "id": "arXiv:2210.11803",
    "title": "Revisiting Checkpoint Averaging for Neural Machine Translation",
    "abstract": "Checkpoint averaging is a simple and effective method to boost the\nperformance of converged neural machine translation models. The calculation is\ncheap to perform and the fact that the translation improvement almost comes for\nfree, makes it widely adopted in neural machine translation research. Despite\nthe popularity, the method itself simply takes the mean of the model parameters\nfrom several checkpoints, the selection of which is mostly based on empirical\nrecipes without many justifications. In this work, we revisit the concept of\ncheckpoint averaging and consider several extensions. Specifically, we\nexperiment with ideas such as using different checkpoint selection strategies,\ncalculating weighted average instead of simple mean, making use of gradient\ninformation and fine-tuning the interpolation weights on development data. Our\nresults confirm the necessity of applying checkpoint averaging for optimal\nperformance, but also suggest that the landscape between the converged\ncheckpoints is rather flat and not much further improvement compared to simple\naveraging is to be obtained.",
    "descriptor": "\nComments: accepted at AACL2022\n",
    "authors": [
      "Yingbo Gao",
      "Christian Herold",
      "Zijian Yang",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11803"
  },
  {
    "id": "arXiv:2210.11804",
    "title": "Discovering New Intents Using Latent Variables",
    "abstract": "Discovering new intents is of great significance to establishing Bootstrapped\nTask-Oriented Dialogue System. Most existing methods either lack the ability to\ntransfer prior knowledge in the known intent data or fall into the dilemma of\nforgetting prior knowledge in the follow-up. More importantly, these methods do\nnot deeply explore the intrinsic structure of unlabeled data, so they can not\nseek out the characteristics that make an intent in general. In this paper,\nstarting from the intuition that discovering intents could be beneficial to the\nidentification of the known intents, we propose a probabilistic framework for\ndiscovering intents where intent assignments are treated as latent variables.\nWe adopt Expectation Maximization framework for optimization. Specifically, In\nE-step, we conduct discovering intents and explore the intrinsic structure of\nunlabeled data by the posterior of intent assignments. In M-step, we alleviate\nthe forgetting of prior knowledge transferred from known intents by optimizing\nthe discrimination of labeled data. Extensive experiments conducted in three\nchallenging real-world datasets demonstrate our method can achieve substantial\nimprovements.",
    "descriptor": "",
    "authors": [
      "Yunhua Zhou",
      "Peiju Liu",
      "Yuxin Wang",
      "Xipeng QIu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11804"
  },
  {
    "id": "arXiv:2210.11805",
    "title": "Robustifying Sentiment Classification by Maximally Exploiting Few  Counterfactuals",
    "abstract": "For text classification tasks, finetuned language models perform remarkably\nwell. Yet, they tend to rely on spurious patterns in training data, thus\nlimiting their performance on out-of-distribution (OOD) test data. Among recent\nmodels aiming to avoid this spurious pattern problem, adding extra\ncounterfactual samples to the training data has proven to be very effective.\nYet, counterfactual data generation is costly since it relies on human\nannotation. Thus, we propose a novel solution that only requires annotation of\na small fraction (e.g., 1%) of the original training data, and uses automatic\ngeneration of extra counterfactuals in an encoding vector space. We demonstrate\nthe effectiveness of our approach in sentiment classification, using IMDb data\nfor training and other sets for OOD tests (i.e., Amazon, SemEval and Yelp). We\nachieve noticeable accuracy improvements by adding only 1% manual\ncounterfactuals: +3% compared to adding +100% in-distribution training samples,\n+1.3% compared to alternate counterfactual approaches.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Maarten De Raedt",
      "Fr\u00e9deric Godin",
      "Chris Develder",
      "Thomas Demeester"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11805"
  },
  {
    "id": "arXiv:2210.11806",
    "title": "Reusing Keywords for Fine-grained Representations and Matchings",
    "abstract": "Question retrieval aims to find the semantically equivalent questions for a\nnew question, suffering from a key challenge -- lexical gap. Previous solutions\nmainly focus on the translation model, topic model and deep learning\ntechniques. Distinct from the previous solutions, we propose new insights of\nreusing important keywords to construct fine-grained semantic representations\nof questions and then fine-grained matchings for estimating the semantic\nsimilarity of two questions. Accordingly, we design a fine-grained matching\nnetwork by reusing the important keywords. In the network, two cascaded units\nare proposed: (i) fine-grained representation unit, which uses multi-level\nkeyword sets to represent question semantics of different granularity; (ii)\nfine-grained matching unit, which first generates multiple comparable\nrepresentation pairs for two questions, i.e., keyword set pairs, and then\nmatches the two questions from multiple granularities and multiple views by\nusing the comparable representation pairs, i.e., from global matching to local\nmatching and from lexical matching to semantic matching. To get the multi-level\nkeyword sets of a question, we propose a cross-task weakly supervised\nextraction model that applies question-question labeled signals from the\ntraining set of question retrieval to supervise the keyword extraction process.\nTo construct the comparable keyword set pairs, we design a pattern-based\nassignment method to construct the comparable keyword set pairs from the\nmulti-level keyword sets of two questions. We conduct extensive experiments on\nthree public datasets and the experimental results show that our proposed model\noutperforms the state-of-the-art solutions.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Li Chong",
      "Denghao Ma",
      "Yueguo Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11806"
  },
  {
    "id": "arXiv:2210.11807",
    "title": "Is Encoder-Decoder Redundant for Neural Machine Translation?",
    "abstract": "Encoder-decoder architecture is widely adopted for sequence-to-sequence\nmodeling tasks. For machine translation, despite the evolution from long\nshort-term memory networks to Transformer networks, plus the introduction and\ndevelopment of attention mechanism, encoder-decoder is still the de facto\nneural network architecture for state-of-the-art models. While the motivation\nfor decoding information from some hidden space is straightforward, the strict\nseparation of the encoding and decoding steps into an encoder and a decoder in\nthe model architecture is not necessarily a must. Compared to the task of\nautoregressive language modeling in the target language, machine translation\nsimply has an additional source sentence as context. Given the fact that neural\nlanguage models nowadays can already handle rather long contexts in the target\nlanguage, it is natural to ask whether simply concatenating the source and\ntarget sentences and training a language model to do translation would work. In\nthis work, we investigate the aforementioned concept for machine translation.\nSpecifically, we experiment with bilingual translation, translation with\nadditional target monolingual data, and multilingual translation. In all cases,\nthis alternative approach performs on par with the baseline encoder-decoder\nTransformer, suggesting that an encoder-decoder architecture might be redundant\nfor neural machine translation.",
    "descriptor": "\nComments: accepted at AACL2022\n",
    "authors": [
      "Yingbo Gao",
      "Christian Herold",
      "Zijian Yang",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11807"
  },
  {
    "id": "arXiv:2210.11810",
    "title": "Unsupervised Image Semantic Segmentation through Superpixels and Graph  Neural Networks",
    "abstract": "Unsupervised image segmentation is an important task in many real-world\nscenarios where labelled data is of scarce availability. In this paper we\npropose a novel approach that harnesses recent advances in unsupervised\nlearning using a combination of Mutual Information Maximization (MIM), Neural\nSuperpixel Segmentation and Graph Neural Networks (GNNs) in an end-to-end\nmanner, an approach that has not been explored yet. We take advantage of the\ncompact representation of superpixels and combine it with GNNs in order to\nlearn strong and semantically meaningful representations of images.\nSpecifically, we show that our GNN based approach allows to model interactions\nbetween distant pixels in the image and serves as a strong prior to existing\nCNNs for an improved accuracy. Our experiments reveal both the qualitative and\nquantitative advantages of our approach compared to current state-of-the-art\nmethods over four popular datasets.",
    "descriptor": "",
    "authors": [
      "Moshe Eliasof",
      "Nir Ben Zikri",
      "Eran Treister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11810"
  },
  {
    "id": "arXiv:2210.11815",
    "title": "Self-Supervised Pretraining on Satellite Imagery: a Case Study on  Label-Efficient Vehicle Detection",
    "abstract": "In defense-related remote sensing applications, such as vehicle detection on\nsatellite imagery, supervised learning requires a huge number of labeled\nexamples to reach operational performances. Such data are challenging to obtain\nas it requires military experts, and some observables are intrinsically rare.\nThis limited labeling capability, as well as the large number of unlabeled\nimages available due to the growing number of sensors, make object detection on\nremote sensing imagery highly relevant for self-supervised learning. We study\nin-domain self-supervised representation learning for object detection on very\nhigh resolution optical satellite imagery, that is yet poorly explored. For the\nfirst time to our knowledge, we study the problem of label efficiency on this\ntask. We use the large land use classification dataset Functional Map of the\nWorld to pretrain representations with an extension of the Momentum Contrast\nframework. We then investigate this model's transferability on a real-world\ntask of fine-grained vehicle detection and classification on Preligens\nproprietary data, which is designed to be representative of an operational use\ncase of strategic site surveillance. We show that our in-domain self-supervised\nlearning model is competitive with ImageNet pretraining, and outperforms it in\nthe low-label regime.",
    "descriptor": "",
    "authors": [
      "Jules BOURCIER",
      "Thomas Floquet",
      "Gohar Dashyan",
      "Tugdual Ceillier",
      "Karteek Alahari",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11815"
  },
  {
    "id": "arXiv:2210.11817",
    "title": "GaitMAST: Motion-Aware Spatio-Temporal Feature Learning Network for  Cross-View Gait Recognition",
    "abstract": "As a unique biometric that can be perceived at a distance, gait has broad\napplications in person authentication, social security and so on. Existing gait\nrecognition methods pay attention to extracting either spatial or\nspatiotemporal representations. However, they barely consider extracting\ndiverse motion features, a fundamental characteristic in gaits, from gait\nsequences. In this paper, we propose a novel motion-aware spatiotemporal\nfeature learning network for gait recognition, termed GaitMAST, which can\nunleash the potential of motion-aware features. In the shallow layer,\nspecifically, we propose a dual-path frame-level feature extractor, in which\none path extracts overall spatiotemporal features and the other extracts motion\nsalient features by focusing on dynamic regions. In the deeper layers, we\ndesign a two-branch clip-level feature extractor, in which one focuses on\nfine-grained spatial information and the other on motion detail preservation.\nConsequently, our GaitMAST preserves the individual's unique walking patterns\nwell, further enhancing the robustness of spatiotemporal features. Extensive\nexperimental results on two commonly-used cross-view gait datasets demonstrate\nthe superior performance of GaitMAST over existing state-of-the-art methods. On\nCASIA-B, our model achieves an average rank-1 accuracy of 94.1%. In particular,\nGaitMAST achieves rank-1 accuracies of 96.1% and 88.1% under the bag-carry and\ncoat wearing conditions, respectively, outperforming the second best by a large\nmargin and demonstrating its robustness against spatial variations.",
    "descriptor": "",
    "authors": [
      "Jingqi Li",
      "Jiaqi Gao",
      "Yuzhen Zhang",
      "Hongming Shan",
      "Junping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11817"
  },
  {
    "id": "arXiv:2210.11818",
    "title": "Non-binary Codes for Correcting a Burst of at Most t Deletions",
    "abstract": "The problem of correcting deletions has received significant attention,\npartly because of the prevalence of these errors in DNA data storage. In this\npaper, we study the problem of correcting a consecutive burst of at most $t$\ndeletions in non-binary sequences. We first propose a non-binary code\ncorrecting a burst of at most 2 deletions for $q$-ary alphabets. Afterwards, we\nextend this result to the case where the length of the burst can be at most $t$\nwhere $t$ is a constant. Finally, we consider the setup where the sequences\nthat are transmitted are permutations. The proposed codes are the largest known\nfor their respective parameter regimes.",
    "descriptor": "\nComments: 20 pages. The paper has been submitted to IEEE Transactions on Information Theory. Furthermore, the paper was presented in part at the ISIT2021 and Allerton2022\n",
    "authors": [
      "Shuche Wang",
      "Yuanyuan Tang",
      "Jin Sima",
      "Ryan Gabrys",
      "Farzad Farnoud"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11818"
  },
  {
    "id": "arXiv:2210.11820",
    "title": "A drag-and-drop proof tactic",
    "abstract": "We explore the features of a user interface where formal proofs can be built\nthrough gestural actions. In particular, we show how proof construction steps\ncan be associated to drag-and-drop actions. We argue that this can provide\nquick and intuitive proof construction steps. This work builds on theoretical\ntools coming from deep inference. It also resumes and integrates some ideas of\nthe former proof-by-pointing project.",
    "descriptor": "",
    "authors": [
      "Pablo Donato",
      "Pierre-Yves Strub",
      "Benjamin Werner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.11820"
  },
  {
    "id": "arXiv:2210.11825",
    "title": "Integrating Policy Summaries with Reward Decomposition for Explaining  Reinforcement Learning Agents",
    "abstract": "Explaining the behavior of reinforcement learning agents operating in\nsequential decision-making settings is challenging, as their behavior is\naffected by a dynamic environment and delayed rewards. Methods that help users\nunderstand the behavior of such agents can roughly be divided into local\nexplanations that analyze specific decisions of the agents and global\nexplanations that convey the general strategy of the agents. In this work, we\nstudy a novel combination of local and global explanations for reinforcement\nlearning agents. Specifically, we combine reward decomposition, a local\nexplanation method that exposes which components of the reward function\ninfluenced a specific decision, and HIGHLIGHTS, a global explanation method\nthat shows a summary of the agent's behavior in decisive states. We conducted\ntwo user studies to evaluate the integration of these explanation methods and\ntheir respective benefits. Our results show significant benefits for both\nmethods. In general, we found that the local reward decomposition was more\nuseful for identifying the agents' priorities. However, when there was only a\nminor difference between the agents' preferences, then the global information\nprovided by HIGHLIGHTS additionally improved participants' understanding.",
    "descriptor": "",
    "authors": [
      "Yael Septon",
      "Tobias Huber",
      "Elisabeth Andr\u00e9",
      "Ofra Amir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11825"
  },
  {
    "id": "arXiv:2210.11826",
    "title": "3D Human Pose Estimation in Multi-View Operating Room Videos Using  Differentiable Camera Projections",
    "abstract": "3D human pose estimation in multi-view operating room (OR) videos is a\nrelevant asset for person tracking and action recognition. However, the\nsurgical environment makes it challenging to find poses due to sterile\nclothing, frequent occlusions, and limited public data. Methods specifically\ndesigned for the OR are generally based on the fusion of detected poses in\nmultiple camera views. Typically, a 2D pose estimator such as a convolutional\nneural network (CNN) detects joint locations. Then, the detected joint\nlocations are projected to 3D and fused over all camera views. However,\naccurate detection in 2D does not guarantee accurate localisation in 3D space.\nIn this work, we propose to directly optimise for localisation in 3D by\ntraining 2D CNNs end-to-end based on a 3D loss that is backpropagated through\neach camera's projection parameters. Using videos from the MVOR dataset, we\nshow that this end-to-end approach outperforms optimisation in 2D space.",
    "descriptor": "\nComments: 12 pages, 4 figures, submitted to the 2022 AE-CAI Special Issue of Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization\n",
    "authors": [
      "Beerend G.A. Gerats",
      "Jelmer M. Wolterink",
      "Ivo A.M.J. Broeders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11826"
  },
  {
    "id": "arXiv:2210.11828",
    "title": "Towards Employing Recommender Systems for Supporting Data and Algorithm  Sharing",
    "abstract": "Data and algorithm sharing is an imperative part of data and AI-driven\neconomies. The efficient sharing of data and algorithms relies on the active\ninterplay between users, data providers, and algorithm providers. Although\nrecommender systems are known to effectively interconnect users and items in\ne-commerce settings, there is a lack of research on the applicability of\nrecommender systems for data and algorithm sharing. To fill this gap, we\nidentify six recommendation scenarios for supporting data and algorithm\nsharing, where four of these scenarios substantially differ from the\ntraditional recommendation scenarios in e-commerce applications. We evaluate\nthese recommendation scenarios using a novel dataset based on interaction data\nof the OpenML data and algorithm sharing platform, which we also provide for\nthe scientific community. Specifically, we investigate three types of\nrecommendation approaches, namely popularity-, collaboration-, and\ncontent-based recommendations. We find that collaboration-based recommendations\nprovide the most accurate recommendations in all scenarios. Plus, the\nrecommendation accuracy strongly depends on the specific scenario, e.g.,\nalgorithm recommendations for users are a more difficult problem than algorithm\nrecommendations for datasets. Finally, the content-based approach generates the\nleast popularity-biased recommendations that cover the most datasets and\nalgorithms.",
    "descriptor": "\nComments: Accepted to the DataEconomy Workshop at CoNEXT'22\n",
    "authors": [
      "M\u00fcllner Peter",
      "Schmerda Stefan",
      "Theiler Dieter",
      "Lindstaedt Stefanie",
      "Kowald Dominik"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11828"
  },
  {
    "id": "arXiv:2210.11831",
    "title": "Management of Machine Learning Lifecycle Artifacts: A Survey",
    "abstract": "The explorative and iterative nature of developing and operating machine\nlearning (ML) applications leads to a variety of artifacts, such as datasets,\nfeatures, models, hyperparameters, metrics, software, configurations, and logs.\nIn order to enable comparability, reproducibility, and traceability of these\nartifacts across the ML lifecycle steps and iterations, systems and tools have\nbeen developed to support their collection, storage, and management. It is\noften not obvious what precise functional scope such systems offer so that the\ncomparison and the estimation of synergy effects between candidates are quite\nchallenging. In this paper, we aim to give an overview of systems and platforms\nwhich support the management of ML lifecycle artifacts. Based on a systematic\nliterature review, we derive assessment criteria and apply them to a\nrepresentative selection of more than 60 systems and platforms.",
    "descriptor": "",
    "authors": [
      "Marius Schlegel",
      "Kai-Uwe Sattler"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11831"
  },
  {
    "id": "arXiv:2210.11832",
    "title": "AI-HRI Brings New Dimensions to Human-Aware Design for Human-Aware AI",
    "abstract": "Since the first AI-HRI held at the 2014 AAAI Fall Symposium Series, a lot of\nthe presented research and discussions have emphasized how artificial\nintelligence (AI) developments can benefit human-robot interaction (HRI). This\nportrays HRI as an application, a source of domain-specific problems to solve,\nto the AI community. Likewise, this portrays AI as a tool, a source of\nsolutions available for relevant problems, to the HRI community. However,\nmembers of the AI-HRI research community will point out that the relationship\nhas a deeper synergy than matchmaking problems and solutions -- there are\ninsights from each field that impact how the other one thinks about the world\nand performs scientific research. There is no greater opportunity for sharing\nperspectives at the moment than human-aware AI, which studies how to account\nfor the fact that people are more than a source of data or part of an\nalgorithm. We will explore how AI-HRI can change the way researchers think\nabout human-aware AI, from observation through validation, to make even the\nalgorithmic design process human-aware.",
    "descriptor": "\nComments: Accepted for presentation at the AAAI 2022 Fall Symposium Series, in the symposium for Artificial Intelligence for Human-Robot Interaction\n",
    "authors": [
      "Richard G. Freedman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11832"
  },
  {
    "id": "arXiv:2210.11833",
    "title": "Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with  Synthetic Data",
    "abstract": "Ground Penetrating Radar (GPR) has been widely used to estimate the healthy\noperation of some urban roads and underground facilities. When identifying\nsubsurface anomalies by GPR in an area, the obtained data could be unbalanced,\nand the numbers and types of possible underground anomalies could not be\nacknowledged in advance. In this paper, a novel method is proposed to improve\nthe subsurface anomaly detection from GPR B-scan images. A normal (i.e. without\nsubsurface objects) GPR image section is firstly collected in the detected\narea. Concerning that the GPR image is essentially the representation of\nelectromagnetic (EM) wave and propagation time, and to preserve both the\nsubsurface background and objects' details, the normal GPR image is segmented\nand then fused with simulated GPR images that contain different kinds of\nobjects to generate the synthetic data for the detection area based on the\nwavelet decompositions. Pre-trained CNNs could then be fine-tuned with the\nsynthetic data, and utilized to extract features of segmented GPR images\nsubsequently obtained in the detection area. The extracted features could be\nclassified by the one-class learning algorithm in the feature space without\npre-set anomaly types or numbers. The conducted experiments demonstrate that\nfine-tuning the pre-trained CNN with the proposed synthetic data could\neffectively improve the feature extraction of the network for the objects in\nthe detection area. Besides, the proposed method requires only a section of\nnormal data that could be easily obtained in the detection area, and could also\nmeet the timeliness requirements in practical applications.",
    "descriptor": "",
    "authors": [
      "Xiren Zhou",
      "Shikang Liu",
      "Ao Chen",
      "Yizhan Fan",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11833"
  },
  {
    "id": "arXiv:2210.11834",
    "title": "Optimal Contextual Bandits with Knapsacks under Realizibility via  Regression Oracles",
    "abstract": "We study the stochastic contextual bandit with knapsacks (CBwK) problem,\nwhere each action, taken upon a context, not only leads to a random reward but\nalso costs a random resource consumption in a vector form. The challenge is to\nmaximize the total reward without violating the budget for each resource. We\nstudy this problem under a general realizability setting where the expected\nreward and expected cost are functions of contexts and actions in some given\ngeneral function classes $\\mathcal{F}$ and $\\mathcal{G}$, respectively.\nExisting works on CBwK are restricted to the linear function class since they\nuse UCB-type algorithms, which heavily rely on the linear form and thus are\ndifficult to extend to general function classes. Motivated by online regression\noracles that have been successfully applied to contextual bandits, we propose\nthe first universal and optimal algorithmic framework for CBwK by reducing it\nto online regression. We also establish the lower regret bound to show the\noptimality of our algorithm for a variety of function classes.",
    "descriptor": "",
    "authors": [
      "Yuxuan Han",
      "Jialin Zeng",
      "Yang Wang",
      "Yang Xiang",
      "Jiheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11834"
  },
  {
    "id": "arXiv:2210.11835",
    "title": "A Textless Metric for Speech-to-Speech Comparison",
    "abstract": "This paper proposes a textless speech-to-speech comparison metric that allows\ncomparing a speech hypothesis with a speech reference without falling-back to\ntheir text transcripts. We leverage recently proposed speech2unit encoders\n(such as HuBERT) to pseudo-transcribe the speech utterances into discrete\nacoustic units and propose a simple neural architecture that learns a\nspeech-based metric which correlates well with its text-based counterpart. Such\na textless metric could ultimately be interesting for speech-to-speech\ntranslation evaluation (for oral languages or languages with no reliable ASR\nsystem available).",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Laurent Besacier",
      "Swen Ribeiro",
      "Olivier Galibert",
      "Ioan Calapodescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11835"
  },
  {
    "id": "arXiv:2210.11836",
    "title": "Structural Kernel Search via Bayesian Optimization and Symbolical  Optimal Transport",
    "abstract": "Despite recent advances in automated machine learning, model selection is\nstill a complex and computationally intensive process. For Gaussian processes\n(GPs), selecting the kernel is a crucial task, often done manually by the\nexpert. Additionally, evaluating the model selection criteria for Gaussian\nprocesses typically scales cubically in the sample size, rendering kernel\nsearch particularly computationally expensive. We propose a novel, efficient\nsearch method through a general, structured kernel space. Previous methods\nsolved this task via Bayesian optimization and relied on measuring the distance\nbetween GP's directly in function space to construct a kernel-kernel. We\npresent an alternative approach by defining a kernel-kernel over the symbolic\nrepresentation of the statistical hypothesis that is associated with a kernel.\nWe empirically show that this leads to a computationally more efficient way of\nsearching through a discrete kernel space.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Matthias Bitzer",
      "Mona Meister",
      "Christoph Zimmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11836"
  },
  {
    "id": "arXiv:2210.11837",
    "title": "The use of the word  \"\\{gamma}\\u{psion}\u03bd\u03b1\u03b9\\k{appa}\u03bf\\k{appa}\u03c4\u03bf\u03bd\u03b9\u03b1\"  (femicide) in Greek-speaking Twitter",
    "abstract": "Between 2019 and 2022, Greek media attention has been attracted by a rather\nunusually high number of femicide cases which have been trending for several\nweeks up to months in the public debate and one of the contributing factors is\nthe feedback loop between traditional media and social media. In this paper we\nare investigating the use of the term\n\"\\{gamma}\\u{psion}{\\nu}{\\alpha}{\\iota}\\k{appa}{\\omicron}\\k{appa}{\\tau}{\\omicron}{\\nu}{\\iota}{\\alpha}\"\n(femicide) in Greek speaking twitter. More specifically, we approach the\nproblem from a stance detection perspective, aiming to automatically identify\nuser position with regards to the feministic semantics of the word. We also\ndiscuss findings from an identity analysis perspective and intercorrelations\nwith hate speech that have been identified in the collected corpus of tweets.",
    "descriptor": "",
    "authors": [
      "Aglaia Aggistrioti",
      "Efstathia Bambili",
      "Nikoleta Gkatzoli",
      "Athina Kontostavlaki",
      "Ioanna Tsounidi",
      "Konstantinos Perifanos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11837"
  },
  {
    "id": "arXiv:2210.11839",
    "title": "Improving Energy Efficiency of Permissioned Blockchains Using FPGAs",
    "abstract": "Permissioned blockchains like Hyperledger Fabric have become quite popular\nfor implementation of enterprise applications. Recent research has mainly\nfocused on improving performance of permissioned blockchains without any\nconsideration of their power/energy consumption. In this paper, we conduct a\ncomprehensive empirical study to understand energy efficiency\n(throughput/energy) of validator peer in Hyperledger Fabric (a major bottleneck\nnode). We pick a number of optimizations for validator peer from literature\n(allocated CPUs, software block cache and FPGA based accelerator). First, we\npropose a methodology to measure power/energy consumption of the two resulting\ncompute platforms (CPU-only and CPU+FPGA). Then, we use our methodology to\nevaluate energy efficiency of a diverse set of validator peer configurations,\nand present many useful insights. With careful selection of software\noptimizations and FPGA accelerator configuration, we improved energy efficiency\nof validator peer by 10$\\times$ compared to vanilla validator peer (i.e.,\nenergy-aware provisioning of validator peer can deliver 10$\\times$ more\nthroughput while consuming the same amount of energy). In absolute terms, this\nmeans 23,000 tx/s with power consumption of 118W from a validator peer using\nsoftware block cache running on a 4-core server with AMD/Xilinx Alveo U250 FPGA\ncard.",
    "descriptor": "\nComments: Accepted at ICPADS 2022\n",
    "authors": [
      "Nathania Santoso",
      "Haris Javaid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.11839"
  },
  {
    "id": "arXiv:2210.11841",
    "title": "Diffusion Visual Counterfactual Explanations",
    "abstract": "Visual Counterfactual Explanations (VCEs) are an important tool to understand\nthe decisions of an image classifier. They are 'small' but 'realistic' semantic\nchanges of the image changing the classifier decision. Current approaches for\nthe generation of VCEs are restricted to adversarially robust models and often\ncontain non-realistic artefacts, or are limited to image classification\nproblems with few classes. In this paper, we overcome this by generating\nDiffusion Visual Counterfactual Explanations (DVCEs) for arbitrary ImageNet\nclassifiers via a diffusion process. Two modifications to the diffusion process\nare key for our DVCEs: first, an adaptive parameterization, whose\nhyperparameters generalize across images and models, together with distance\nregularization and late start of the diffusion process, allow us to generate\nimages with minimal semantic changes to the original ones but different\nclassification. Second, our cone regularization via an adversarially robust\nmodel ensures that the diffusion process does not converge to trivial\nnon-semantic changes, but instead produces realistic images of the target class\nwhich achieve high confidence by the classifier.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Maximilian Augustin",
      "Valentyn Boreiko",
      "Francesco Croce",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11841"
  },
  {
    "id": "arXiv:2210.11843",
    "title": "Low-Resources Project-Specific Code Summarization",
    "abstract": "Code summarization generates brief natural language descriptions of source\ncode pieces, which can assist developers in understanding code and reduce\ndocumentation workload. Recent neural models on code summarization are trained\nand evaluated on large-scale multi-project datasets consisting of independent\ncode-summary pairs. Despite the technical advances, their effectiveness on a\nspecific project is rarely explored. In practical scenarios, however,\ndevelopers are more concerned with generating high-quality summaries for their\nworking projects. And these projects may not maintain sufficient documentation,\nhence having few historical code-summary pairs. To this end, we investigate\nlow-resource project-specific code summarization, a novel task more consistent\nwith the developers' requirements. To better characterize project-specific\nknowledge with limited training samples, we propose a meta transfer learning\nmethod by incorporating a lightweight fine-tuning mechanism into a\nmeta-learning framework. Experimental results on nine real-world projects\nverify the superiority of our method over alternative ones and reveal how the\nproject-specific knowledge is learned.",
    "descriptor": "\nComments: Accepted by ASE 2022\n",
    "authors": [
      "Rui Xie",
      "Tianxiang Hu",
      "Wei Ye",
      "Shikun Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11843"
  },
  {
    "id": "arXiv:2210.11845",
    "title": "A Stability Analysis of Modified Patankar-Runge-Kutta methods for a  nonlinear Production-Destruction System",
    "abstract": "Modified Patankar-Runge-Kutta (MPRK) methods preserve the positivity as well\nas conservativity of a production-destruction system (PDS) of ordinary\ndifferential equations for all time step sizes. As a result, higher order MPRK\nschemes do not belong to the class of general linear methods, i.e. the iterates\nare generated by a nonlinear map $\\mathbf g$ even when the PDS is linear.\nMoreover, due to the conservativity of the method, the map $\\mathbf g$\npossesses non-hyperbolic fixed points.\nRecently, a new theorem for the investigation of stability properties of\nnon-hyperbolic fixed points of a nonlinear iteration map was developed. We\napply this theorem to understand the stability properties of a family of second\norder MPRK methods when applied to a nonlinear PDS of ordinary differential\nequations. It is shown that the fixed points are stable for all time step sizes\nand members of the MPRK family. Finally, experiments are presented to\nnumerically support the theoretical claims.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Thomas Izgin",
      "Stefan Kopecz",
      "Andreas Meister"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11845"
  },
  {
    "id": "arXiv:2210.11846",
    "title": "Counterfactual Explanations for Reinforcement Learning",
    "abstract": "While AI algorithms have shown remarkable success in various fields, their\nlack of transparency hinders their application to real-life tasks. Although\nexplanations targeted at non-experts are necessary for user trust and human-AI\ncollaboration, the majority of explanation methods for AI are focused on\ndevelopers and expert users. Counterfactual explanations are local explanations\nthat offer users advice on what can be changed in the input for the output of\nthe black-box model to change. Counterfactuals are user-friendly and provide\nactionable advice for achieving the desired output from the AI system. While\nextensively researched in supervised learning, there are few methods applying\nthem to reinforcement learning (RL). In this work, we explore the reasons for\nthe underrepresentation of a powerful explanation method in RL. We start by\nreviewing the current work in counterfactual explanations in supervised\nlearning. Additionally, we explore the differences between counterfactual\nexplanations in supervised learning and RL and identify the main challenges\nthat prevent adoption of methods from supervised in reinforcement learning.\nFinally, we redefine counterfactuals for RL and propose research directions for\nimplementing counterfactuals in RL.",
    "descriptor": "\nComments: 35 pages, 6 figures\n",
    "authors": [
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11846"
  },
  {
    "id": "arXiv:2210.11852",
    "title": "Influencing factors of Twitter mentions of scientific papers",
    "abstract": "Purpose: This paper explores the influencing factors of Twitter mentions of\nscientific papers. The results can help to understand the relationships between\nvarious altmetrics. Design/methodology/approach: Data on research mentions in\nAltmetric.com and a multiple linear regression analysis are used. Findings: The\nnumber of mainstream news is the factor that most influences the number of\nmentions on Twitter, followed by its influence on public policies through\nreferences in reports. The influence is weaker in the case of mentions on\nWikipedia and the fact of dealing with a highly topical issue such as COVID-19.\nThe recommendation of experts and mentions in patent applications have a\nnegative influence, while the consolidation of knowledge in the form of a\nreview does not have a significant influence. Research limitations: A specific\nfield was studied in a specific time period. Studying other fields and/or\ndifferent time periods might result in different findings. Practical\nimplications: Governments increasingly push researchers toward activities with\nsocietal impact and this study can help understand how different factors affect\nsocial media attention. Originality/value: Understanding social media attention\nof research is essential when implementing societal impact indicators.",
    "descriptor": "\nComments: 14 pages, 7 tables\n",
    "authors": [
      "Pablo Dorta-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.11852"
  },
  {
    "id": "arXiv:2210.11860",
    "title": "Spectral Probing",
    "abstract": "Linguistic information is encoded at varying timescales (subwords, phrases,\netc.) and communicative levels, such as syntax and semantics. Contextualized\nembeddings have analogously been found to capture these phenomena at\ndistinctive layers and frequencies. Leveraging these findings, we develop a\nfully learnable frequency filter to identify spectral profiles for any given\ntask. It enables vastly more granular analyses than prior handcrafted filters,\nand improves on efficiency. After demonstrating the informativeness of spectral\nprobing over manual filters in a monolingual setting, we investigate its\nmultilingual characteristics across seven diverse NLP tasks in six languages.\nOur analyses identify distinctive spectral profiles which quantify cross-task\nsimilarity in a linguistically intuitive manner, while remaining consistent\nacross languages-highlighting their potential as robust, lightweight task\ndescriptors.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (Main Conference)\n",
    "authors": [
      "Max M\u00fcller-Eberstein",
      "Rob van der Goot",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11860"
  },
  {
    "id": "arXiv:2210.11870",
    "title": "LittleBird: Efficient Faster & Longer Transformer for Question Answering",
    "abstract": "BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a\nlimitation dealing with long inputs due to its attention mechanism. Longformer,\nETC and BigBird addressed this issue and effectively solved the quadratic\ndependency problem. However we find that these models are not sufficient, and\npropose LittleBird, a novel model based on BigBird with improved speed and\nmemory footprint while maintaining accuracy. In particular, we devise a more\nflexible and efficient position representation method based on Attention with\nLinear Biases (ALiBi). We also show that replacing the method of global\ninformation represented in the BigBird with pack and unpack attention is more\neffective. The proposed model can work on long inputs even after being\npre-trained on short inputs, and can be trained efficiently reusing existing\npre-trained language model for short inputs. This is a significant benefit for\nlow-resource languages where large amounts of long text data are difficult to\nobtain. As a result, our experiments show that LittleBird works very well in a\nvariety of languages, achieving high performance in question answering tasks,\nparticularly in KorQuAD2.0, Korean Question Answering Dataset for long\nparagraphs.",
    "descriptor": "",
    "authors": [
      "Minchul Lee",
      "Kijong Han",
      "Myeong Cheol Shin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11870"
  },
  {
    "id": "arXiv:2210.11877",
    "title": "Design and Validation of a Multi-Arm Robotic Platform for Scientific  Exploration",
    "abstract": "There are a large number of robotic platforms with two or more arms targeting\nsurgical applications. Despite that, very few groups have employed such\nplatforms for scientific exploration. Possible applications of a multi-arm\nplatform in scientific exploration involve the study of the mechanisms of\nintractable diseases by using organoids (i.e., miniature human organs). The\nstudy of organoids requires the preparation of a cranial window which is done\nby carefully removing an 8 mm patch of the mouse skull. In this work, we\npresent the first prototype of the AI robot science platform for scientific\nexperimentation, its digital twins, and perform validation experiments under\nteleoperation. The experiments showcase the dexterity of the platform by\nperforming peg transfer, gauze cutting, mock experiments using eggs, and the\nworld's first teleoperated drilling for a cranial window. The digital twins and\nrelated control software are freely available for noncommercial use at\nhttps://AISciencePlatform.github.io.",
    "descriptor": "\nComments: First draft, 9 pages, 13 figures, to be submitted to IEEE\n",
    "authors": [
      "Murilo Marques Marinho",
      "Juan Jos\u00e9 Quiroz-Oma\u00f1a",
      "Kanako Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11877"
  },
  {
    "id": "arXiv:2210.11879",
    "title": "GLCC: A General Framework for Graph-level Clustering",
    "abstract": "This paper studies the problem of graph-level clustering, which is a novel\nyet challenging task. This problem is critical in a variety of real-world\napplications such as protein clustering and genome analysis in bioinformatics.\nRecent years have witnessed the success of deep clustering coupled with graph\nneural networks (GNNs). However, existing methods focus on clustering among\nnodes given a single graph, while exploring clustering on multiple graphs is\nstill under-explored. In this paper, we propose a general graph-level\nclustering framework named Graph-Level Contrastive Clustering (GLCC) given\nmultiple graphs. Specifically, GLCC first constructs an adaptive affinity graph\nto explore instance- and cluster-level contrastive learning (CL).\nInstance-level CL leverages graph Laplacian based contrastive loss to learn\nclustering-friendly representations while cluster-level CL captures\ndiscriminative cluster representations incorporating neighbor information of\neach sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the\noptimization of representation learning. The two steps can be alternatively\ntrained to collaborate and benefit each other. Experiments on a range of\nwell-known datasets demonstrate the superiority of our proposed GLCC over\ncompetitive baselines.",
    "descriptor": "",
    "authors": [
      "Wei Ju",
      "Yiyang Gu",
      "Binqi Chen",
      "Gongbo Sun",
      "Yifang Qin",
      "Xingyuming Liu",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11879"
  },
  {
    "id": "arXiv:2210.11881",
    "title": "Solving the Probabilistic Profitable Tour Problem on a Tree",
    "abstract": "The profitable tour problem (PTP) is a well-known NP-hard routing problem\nsearching for a tour visiting a subset of customers while maximizing profit as\nthe difference between total revenue collected and traveling costs. PTP is\nknown to be solvable in polynomial time when special structures of the\nunderlying graph are considered. However, the computational complexity of the\ncorresponding probabilistic generalizations is still an open issue in many\ncases. In this paper, we analyze the probabilistic PTP where customers are\nlocated on a tree and need, with a known probability, for a service provision\nat a predefined prize. The problem objective is to select a priori a subset of\ncustomers with whom to commit the service so to maximize the expected profit.\nWe provide a polynomial time algorithm computing the optimal solution in\n$O(n^2)$, where $n$ is the number of nodes in the tree.",
    "descriptor": "",
    "authors": [
      "Enrico Angelelli",
      "Renata Mansini",
      "Romeo Rizzi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11881"
  },
  {
    "id": "arXiv:2210.11882",
    "title": "A Low-Power 1 Gb/s Line Driver with Configurable Pre-Emphasis for Lossy  Transmission Lines",
    "abstract": "A line driver with configurable pre-emphasis is implemented in a 65 nm CMOS\nprocess. The driver utilizes a three-tap feed-forward equalization (FFE)\narchitecture. The relative delays between the taps are selectable in increments\nof 1/16th of the unit interval (UI) via an 8-stage delay-locked loop (DLL) and\ndigital interpolator. It is also possible to control the output amplitude and\nsource impedance for each tap via a programmable array of eight source-series\nterminated (SST) drivers. The entire design consumes 9 mW from a 1.2 V supply\nat 1 Gb/s.",
    "descriptor": "\nComments: Submitted to JINST\n",
    "authors": [
      "Nicholas St. John",
      "Soumyajit Mandal",
      "Grzegorz W. Deptuch",
      "Eric Raguzin",
      "Sergio Rescia"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11882"
  },
  {
    "id": "arXiv:2210.11884",
    "title": "Sum Capacity Maximization in Multi-Hop Mobile Networks with Flying Base  Stations",
    "abstract": "Deployment of multi-hop network of unmanned aerial vehicles (UAVs) acting as\nflying base stations (FlyBSs) presents a remarkable potential to effectively\nenhance the performance of wireless networks. Such potential enhancement,\nhowever, relies on an efficient positioning of the FlyBSs as well as a\nmanagement of resources. In this paper, we study the problem of sum capacity\nmaximization in an extended model for mobile networks where multiple FlyBSs are\ndeployed between the ground base station and the users. Due to an inclusion of\nmultiple hops, the existing solutions for two-hop networks cannot be applied\ndue to the incurred backhaul constraints for each hop. To this end, we propose\nan analytical approach based on an alternating optimization of the FlyBSs' 3D\npositions as well as the association of the users to the FlyBSs over time. The\nproposed optimization is provided under practical constraints on the FlyBS's\nflying speed and altitude as well as the constraints on the achievable capacity\nat the backhaul link. The proposed solution is of a low complexity and extends\nthe sum capacity by 23%-38% comparing to state-of-the-art solutions.",
    "descriptor": "\nComments: Accepted in IEEE GLOBECOM 2022\n",
    "authors": [
      "Mohammadsaleh Nikooroo",
      "Omid Esrafilian",
      "Zdenek Becvar",
      "David Gesbert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11884"
  },
  {
    "id": "arXiv:2210.11885",
    "title": "Deep LSTM Spoken Term Detection using Wav2Vec 2.0 Recognizer",
    "abstract": "In recent years, the standard hybrid DNN-HMM speech recognizers are\noutperformed by the end-to-end speech recognition systems. One of the very\npromising approaches is the grapheme Wav2Vec 2.0 model, which uses the\nself-supervised pretraining approach combined with transfer learning of the\nfine-tuned speech recognizer. Since it lacks the pronunciation vocabulary and\nlanguage model, the approach is suitable for tasks where obtaining such models\nis not easy or almost impossible.\nIn this paper, we use the Wav2Vec speech recognizer in the task of spoken\nterm detection over a large set of spoken documents. The method employs a deep\nLSTM network which maps the recognized hypothesis and the searched term into a\nshared pronunciation embedding space in which the term occurrences and the\nassigned scores are easily computed.\nThe paper describes a bootstrapping approach that allows the transfer of the\nknowledge contained in traditional pronunciation vocabulary of DNN-HMM hybrid\nASR into the context of grapheme-based Wav2Vec. The proposed method outperforms\nthe previously published system based on the combination of the DNN-HMM hybrid\nASR and phoneme recognizer by a large margin on the MALACH data in both English\nand Czech languages.",
    "descriptor": "",
    "authors": [
      "Jan \u0160vec",
      "Jan Lehe\u010dka",
      "Lubo\u0161 \u0160m\u00eddl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11885"
  },
  {
    "id": "arXiv:2210.11888",
    "title": "STAR: SQL Guided Pre-Training for Context-dependent Text-to-SQL Parsing",
    "abstract": "In this paper, we propose a novel SQL guided pre-training framework STAR for\ncontext-dependent text-to-SQL parsing, which leverages contextual information\nto enrich natural language (NL) utterance and table schema representations for\ntext-to-SQL conversations. Concretely, we propose two novel pre-training\nobjectives which respectively explore the context-dependent interactions of NL\nutterances and SQL queries within each text-to-SQL conversation: (i) schema\nstate tracking (SST) objective that tracks and explores the schema states of\ncontext-dependent SQL queries in the form of schema-states by predicting and\nupdating the value of each schema slot during interaction; (ii) utterance\ndependency tracking (UDT) objective that employs weighted contrastive learning\nto pull together two semantically similar NL utterances and push away the\nrepresentations of semantically dissimilar NL utterances within each\nconversation. In addition, we construct a high-quality large-scale\ncontext-dependent text-to-SQL conversation corpus to pre-train STAR. Extensive\nexperiments show that STAR achieves new state-of-the-art performance on two\ndownstream benchmarks (SParC and CoSQL), significantly outperforming previous\npre-training methods and ranking first on the leaderboard. We believe the\nrelease of the constructed corpus, codebase and pre-trained STAR checkpoints\nwould push forward the research in this area. For reproducibility, we release\nour code and data at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/star.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zefeng Cai",
      "Xiangyu Li",
      "Binyuan Hui",
      "Min Yang",
      "Bowen Li",
      "Binhua Li",
      "Zheng Cao",
      "Weijie Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11888"
  },
  {
    "id": "arXiv:2210.11892",
    "title": "BioLORD: Learning Ontological Representations from Definitions (for  Biomedical Concepts and their Textual Descriptions)",
    "abstract": "This work introduces BioLORD, a new pre-training strategy for producing\nmeaningful representations for clinical sentences and biomedical concepts.\nState-of-the-art methodologies operate by maximizing the similarity in\nrepresentation of names referring to the same concept, and preventing collapse\nthrough contrastive learning. However, because biomedical names are not always\nself-explanatory, it sometimes results in non-semantic representations. BioLORD\novercomes this issue by grounding its concept representations using\ndefinitions, as well as short descriptions derived from a multi-relational\nknowledge graph consisting of biomedical ontologies. Thanks to this grounding,\nour model produces more semantic concept representations that match more\nclosely the hierarchical structure of ontologies. BioLORD establishes a new\nstate of the art for text similarity on both clinical sentences (MedSTS) and\nbiomedical concepts (MayoSRS).",
    "descriptor": "\nComments: Accepted in Findings of EMNLP 2022\n",
    "authors": [
      "Fran\u00e7ois Remy",
      "Kris Demuynck",
      "Thomas Demeester"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11892"
  },
  {
    "id": "arXiv:2210.11895",
    "title": "Spoken Term Detection and Relevance Score Estimation using Dot-Product  of Pronunciation Embeddings",
    "abstract": "The paper describes a novel approach to Spoken Term Detection (STD) in large\nspoken archives using deep LSTM networks. The work is based on the previous\napproach of using Siamese neural networks for STD and naturally extends it to\ndirectly localize a spoken term and estimate its relevance score. The phoneme\nconfusion network generated by a phoneme recognizer is processed by the deep\nLSTM network which projects each segment of the confusion network into an\nembedding space. The searched term is projected into the same embedding space\nusing another deep LSTM network. The relevance score is then computed using a\nsimple dot-product in the embedding space and calibrated using a sigmoid\nfunction to predict the probability of occurrence. The location of the searched\nterm is then estimated from the sequence of output probabilities. The deep LSTM\nnetworks are trained in a self-supervised manner from paired recognition\nhypotheses on word and phoneme levels. The method is experimentally evaluated\non MALACH data in English and Czech languages.",
    "descriptor": "",
    "authors": [
      "Jan \u0160vec",
      "Lubo\u0161 \u0160m\u00eddl",
      "Josef V. Psutka",
      "Ale\u0161 Pra\u017e\u00e1k"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11895"
  },
  {
    "id": "arXiv:2210.11899",
    "title": "A Semi-supervised Approach for a Better Translation of Sentiment in  Dialectical Arabic UGT",
    "abstract": "In the online world, Machine Translation (MT) systems are extensively used to\ntranslate User-Generated Text (UGT) such as reviews, tweets, and social media\nposts, where the main message is often the author's positive or negative\nattitude towards the topic of the text. However, MT systems still lack accuracy\nin some low-resource languages and sometimes make critical translation errors\nthat completely flip the sentiment polarity of the target word or phrase and\nhence delivers a wrong affect message. This is particularly noticeable in texts\nthat do not follow common lexico-grammatical standards such as the dialectical\nArabic (DA) used on online platforms. In this research, we aim to improve the\ntranslation of sentiment in UGT written in the dialectical versions of the\nArabic language to English. Given the scarcity of gold-standard parallel data\nfor DA-EN in the UGT domain, we introduce a semi-supervised approach that\nexploits both monolingual and parallel data for training an NMT system\ninitialised by a cross-lingual language model trained with supervised and\nunsupervised modeling objectives. We assess the accuracy of sentiment\ntranslation by our proposed system through a numerical 'sentiment-closeness'\nmeasure as well as human evaluation. We will show that our semi-supervised MT\nsystem can significantly help with correcting sentiment errors detected in the\nonline translation of dialectical Arabic UGT.",
    "descriptor": "\nComments: WANLP2022 at EMNLP 2022\n",
    "authors": [
      "Hadeel Saadany",
      "Constantin Orasan",
      "Emad Mohamed",
      "Ashraf Tantawy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11899"
  },
  {
    "id": "arXiv:2210.11900",
    "title": "Turning Fixed to Adaptive: Integrating Post-Evaluation into Simultaneous  Machine Translation",
    "abstract": "Simultaneous machine translation (SiMT) starts its translation before reading\nthe whole source sentence and employs either fixed or adaptive policy to\ngenerate the target sentence. Compared to the fixed policy, the adaptive policy\nachieves better latency-quality tradeoffs by adopting a flexible translation\npolicy. If the policy can evaluate rationality before taking action, the\nprobability of incorrect actions will also decrease. However, previous methods\nlack evaluation of actions before taking them. In this paper, we propose a\nmethod of performing the adaptive policy via integrating post-evaluation into\nthe fixed policy. Specifically, whenever a candidate token is generated, our\nmodel will evaluate the rationality of the next action by measuring the change\nin the source content. Our model will then take different actions based on the\nevaluation results. Experiments on three translation tasks show that our method\ncan exceed strong baselines under all latency.",
    "descriptor": "\nComments: Accept to EMNLP 2022. 15 pages, 6 figures\n",
    "authors": [
      "Shoutao Guo",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11900"
  },
  {
    "id": "arXiv:2210.11905",
    "title": "Exploration of the Usage of Color Terms by Color-blind Participants in  Online Discussion Platforms",
    "abstract": "Prominent questions about the role of sensory vs. linguistic input in the way\nwe acquire and use language have been extensively studied in the\npsycholinguistic literature. However, the relative effect of various factors in\na person's overall experience on their linguistic system remains unclear. We\nstudy this question by making a step forward towards a better understanding of\nthe conceptual perception of colors by color-blind individuals, as reflected in\ntheir spontaneous linguistic productions. Using a novel and carefully curated\ndataset, we show that red-green color-blind speakers use the \"red\" and \"green\"\ncolor terms in less predictable contexts, and in linguistic environments\nevoking mental image to a lower extent, when compared to their normal-sighted\ncounterparts. These findings shed some new and interesting light on the role of\nsensory experience on our linguistic system.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (main conference), 13 pages\n",
    "authors": [
      "Ella Rabinovich",
      "Boaz Carmeli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11905"
  },
  {
    "id": "arXiv:2210.11907",
    "title": "Collaborative Image Understanding",
    "abstract": "Automatically understanding the contents of an image is a highly relevant\nproblem in practice. In e-commerce and social media settings, for example, a\ncommon problem is to automatically categorize user-provided pictures. Nowadays,\na standard approach is to fine-tune pre-trained image models with\napplication-specific data. Besides images, organizations however often also\ncollect collaborative signals in the context of their application, in\nparticular how users interacted with the provided online content, e.g., in\nforms of viewing, rating, or tagging. Such signals are commonly used for item\nrecommendation, typically by deriving latent user and item representations from\nthe data. In this work, we show that such collaborative information can be\nleveraged to improve the classification process of new images. Specifically, we\npropose a multitask learning framework, where the auxiliary task is to\nreconstruct collaborative latent item representations. A series of experiments\non datasets from e-commerce and social media demonstrates that considering\ncollaborative signals helps to significantly improve the performance of the\nmain task of image classification by up to 9.1%.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Koby Bibas",
      "Oren Sar Shalom",
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11907"
  },
  {
    "id": "arXiv:2210.11909",
    "title": "Boosting vision transformers for image retrieval",
    "abstract": "Vision transformers have achieved remarkable progress in vision tasks such as\nimage classification and detection. However, in instance-level image retrieval,\ntransformers have not yet shown good performance compared to convolutional\nnetworks. We propose a number of improvements that make transformers outperform\nthe state of the art for the first time. (1) We show that a hybrid architecture\nis more effective than plain transformers, by a large margin. (2) We introduce\ntwo branches collecting global (classification token) and local (patch tokens)\ninformation, from which we form a global image representation. (3) In each\nbranch, we collect multi-layer features from the transformer encoder,\ncorresponding to skip connections across distant layers. (4) We enhance\nlocality of interactions at the deeper layers of the encoder, which is the\nrelative weakness of vision transformers. We train our model on all commonly\nused training sets and, for the first time, we make fair comparisons separately\nper training set. In all cases, we outperform previous models based on global\nrepresentation. Public code is available at\nhttps://github.com/dealicious-inc/DToP.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Chull Hwan Song",
      "Jooyoung Yoon",
      "Shunghyun Choi",
      "Yannis Avrithis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11909"
  },
  {
    "id": "arXiv:2210.11910",
    "title": "An Approach to Build Consistent Software Architecture Diagrams Using  Devops System Descriptors",
    "abstract": "System architecture diagrams play an essential role in understanding system\narchitecture. They encourage more active discussion among participants and make\nit easier to recall system details. However, system architecture diagrams often\ndiverge from the software. As a result, they can interfere with the\nunderstanding and maintenance of the software. We propose an approach to build\nsystem architecture diagrams using DevOps system descriptors to improve the\nconsistency of architecture diagrams. To produce our approach, we survey\nproblems with architecture diagrams in the software industry, developing\nguidelines for creating architecture diagrams. Next, we produce a taxonomy for\nsystem descriptor concepts and a process to convert system descriptors into\narchitecture diagrams. We evaluate our approach through a case study. In this\ncase study, we defined a Docker Compose descriptor for a newsfeed system and\ntransformed it into a system architectural diagram using the proposed approach.\nOur results indicate that, currently, system descriptors generally lead to\nconsistent diagrams only to a limited extent. However, the case study's\nobservations indicate that the proposed approach is promising and demonstrates\nthat system descriptors have the potential to create more consistent\narchitectural diagrams. Further evaluation in controlled and empirical\nexperiments is necessary to test our hypothesis in more detail.",
    "descriptor": "\nComments: Accepted to ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems (Models 2022)\n",
    "authors": [
      "Jalves Nicacio",
      "Fabio Petrillo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11910"
  },
  {
    "id": "arXiv:2210.11912",
    "title": "$m^4Adapter$: Multilingual Multi-Domain Adaptation for Machine  Translation with a Meta-Adapter",
    "abstract": "Multilingual neural machine translation models (MNMT) yield state-of-the-art\nperformance when evaluated on data from a domain and language pair seen at\ntraining time. However, when a MNMT model is used to translate under domain\nshift or to a new language pair, performance drops dramatically. We consider a\nvery challenging scenario: adapting the MNMT model both to a new domain and to\na new language pair at the same time. In this paper, we propose $m^4Adapter$\n(Multilingual Multi-Domain Adaptation for Machine Translation with a\nMeta-Adapter), which combines domain and language knowledge using meta-learning\nwith adapters. We present results showing that our approach is a\nparameter-efficient solution which effectively adapts a model to both a new\nlanguage pair and a new domain, while outperforming other adapter methods. An\nablation study also shows that our approach more effectively transfers domain\nknowledge across different languages and language information across different\ndomains.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Wen Lai",
      "Alexandra Chronopoulou",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11912"
  },
  {
    "id": "arXiv:2210.11913",
    "title": "NEREL-BIO: A Dataset of Biomedical Abstracts Annotated with Nested Named  Entities",
    "abstract": "This paper describes NEREL-BIO -- an annotation scheme and corpus of PubMed\nabstracts in Russian and smaller number of abstracts in English. NEREL-BIO\nextends the general domain dataset NEREL by introducing domain-specific entity\ntypes. NEREL-BIO annotation scheme covers both general and biomedical domains\nmaking it suitable for domain transfer experiments. NEREL-BIO provides\nannotation for nested named entities as an extension of the scheme employed for\nNEREL. Nested named entities may cross entity boundaries to connect to shorter\nentities nested within longer entities, making them harder to detect.\nNEREL-BIO contains annotations for 700+ Russian and 100+ English abstracts.\nAll English PubMed annotations have corresponding Russian counterparts. Thus,\nNEREL-BIO comprises the following specific features: annotation of nested named\nentities, it can be used as a benchmark for cross-domain (NEREL -> NEREL-BIO)\nand cross-language (English -> Russian) transfer. We experiment with both\ntransformer-based sequence models and machine reading comprehension (MRC)\nmodels and report their results.\nThe dataset is freely available at https://github.com/nerel-ds/NEREL-BIO.",
    "descriptor": "\nComments: Submitted to Bioinformatics (Publisher: Oxford University Press)\n",
    "authors": [
      "Natalia Loukachevitch",
      "Suresh Manandhar",
      "Elina Baral",
      "Igor Rozhkov",
      "Pavel Braslavski",
      "Vladimir Ivanov",
      "Tatiana Batura",
      "Elena Tutubalina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11913"
  },
  {
    "id": "arXiv:2210.11915",
    "title": "Efficient identification of informative features in simulation-based  inference",
    "abstract": "Simulation-based Bayesian inference (SBI) can be used to estimate the\nparameters of complex mechanistic models given observed model outputs without\nrequiring access to explicit likelihood evaluations. A prime example for the\napplication of SBI in neuroscience involves estimating the parameters governing\nthe response dynamics of Hodgkin-Huxley (HH) models from electrophysiological\nmeasurements, by inferring a posterior over the parameters that is consistent\nwith a set of observations. To this end, many SBI methods employ a set of\nsummary statistics or scientifically interpretable features to estimate a\nsurrogate likelihood or posterior. However, currently, there is no way to\nidentify how much each summary statistic or feature contributes to reducing\nposterior uncertainty. To address this challenge, one could simply compare the\nposteriors with and without a given feature included in the inference process.\nHowever, for large or nested feature sets, this would necessitate repeatedly\nestimating the posterior, which is computationally expensive or even\nprohibitive. Here, we provide a more efficient approach based on the SBI method\nneural likelihood estimation (NLE): We show that one can marginalize the\ntrained surrogate likelihood post-hoc before inferring the posterior to assess\nthe contribution of a feature. We demonstrate the usefulness of our method by\nidentifying the most important features for inferring parameters of an example\nHH neuron model. Beyond neuroscience, our method is generally applicable to SBI\nworkflows that rely on data features for inference used in other scientific\nfields.",
    "descriptor": "",
    "authors": [
      "Jonas Beck",
      "Michael Deistler",
      "Yves Bernaerts",
      "Jakob Macke",
      "Philipp Berens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11915"
  },
  {
    "id": "arXiv:2210.11917",
    "title": "A portable coding strategy to exploit vectorization on combustion  simulations",
    "abstract": "The complexity of combustion simulations demands the latest high-performance\ncomputing tools to accelerate its time-to-solution results. A current trend on\nHPC systems is the utilization of CPUs with SIMD or vector extensions to\nexploit data parallelism. Our work proposes a strategy to improve the automatic\nvectorization of finite element-based scientific codes. The approach applies a\nparametric configuration to the data structures to help the compiler detect the\nblock of codes that can take advantage of vector computation while maintaining\nthe code portable. A detailed analysis of the computational impact of this\nmethodology on the different stages of a CFD solver is studied on the\nPRECCINSTA burner simulation. Our parametric implementation has proven to help\nthe compiler generate more vector instructions in the assembly operation: this\nresults in a reduction of up to 9.3 times of the total executed instruction\nmaintaining constant the Instructions Per Cycle and the CPU frequency. The\nproposed strategy improves the performance of the CFD case under study up to\n4.67 times on the MareNostrum 4 supercomputer.",
    "descriptor": "",
    "authors": [
      "Fabio Banchelli",
      "Guillermo Oyarzun",
      "Marta Garcia-Gasulla",
      "Filippo Mantovani",
      "Ambrus Both",
      "Guillaume Houzeaux",
      "Daniel Mira"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11917"
  },
  {
    "id": "arXiv:2210.11918",
    "title": "Splay Top Trees",
    "abstract": "The top tree data structure is an important and fundamental tool in dynamic\ngraph algorithms. Top trees have existed for decades, and today serve as an\ningredient in many state-of-the-art algorithms for dynamic graphs. In this\nwork, we give a new direct proof of the existence of top trees, facilitating\nsimpler and more direct implementations of top trees, based on ideas from splay\ntrees. This result hinges on new insights into the structure of top trees, and\nin particular the structure of each root path in a top tree.",
    "descriptor": "\nComments: 27 pages, 6 figures, accepted for publication at SOSA'23\n",
    "authors": [
      "Jacob Holm",
      "Eva Rotenberg",
      "Alice Ryhl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11918"
  },
  {
    "id": "arXiv:2210.11923",
    "title": "RollBack: A New Time-Agnostic Replay Attack Against the Automotive  Remote Keyless Entry Systems",
    "abstract": "Today's RKE systems implement disposable rolling codes, making every key fob\nbutton press unique, effectively preventing simple replay attacks. However, a\nprior attack called RollJam was proven to break all rolling code-based systems\nin general. By a careful sequence of signal jamming, capturing, and replaying,\nan attacker can become aware of the subsequent valid unlock signal that has not\nbeen used yet. RollJam, however, requires continuous deployment indefinitely\nuntil it is exploited. Otherwise, the captured signals become invalid if the\nkey fob is used again without RollJam in place. We introduce RollBack, a new\nreplay-and-resynchronize attack against most of today's RKE systems. In\nparticular, we show that even though the one-time code becomes invalid in\nrolling code systems, replaying a few previously captured signals consecutively\ncan trigger a rollback-like mechanism in the RKE system. Put differently, the\nrolling codes become resynchronized back to a previous code used in the past\nfrom where all subsequent yet already used signals work again. Moreover, the\nvictim can still use the key fob without noticing any difference before and\nafter the attack. Unlike RollJam, RollBack does not necessitate jamming at all.\nFurthermore, it requires signal capturing only once and can be exploited at any\ntime in the future as many times as desired. This time-agnostic property is\nparticularly attractive to attackers, especially in car-sharing/renting\nscenarios where accessing the key fob is straightforward. However, while\nRollJam defeats virtually any rolling code-based system, vehicles might have\nadditional anti-theft measures against malfunctioning key fobs, hence against\nRollBack. Our ongoing analysis (covering Asian vehicle manufacturers for the\ntime being) against different vehicle makes and models has revealed that ~70%\nof them are vulnerable to RollBack.",
    "descriptor": "\nComments: 24 pages, 5 figures Under submission to a journal\n",
    "authors": [
      "Levente Csikor",
      "Hoon Wei Lim",
      "Jun Wen Wong",
      "Soundarya Ramesh",
      "Rohini Poolat Parameswarath",
      "Mun Choon Chan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11923"
  },
  {
    "id": "arXiv:2210.11924",
    "title": "Men Also Do Laundry: Multi-Attribute Bias Amplification",
    "abstract": "As computer vision systems become more widely deployed, there is increasing\nconcern from both the research community and the public that these systems are\nnot only reproducing but amplifying harmful social biases. The phenomenon of\nbias amplification, which is the focus of this work, refers to models\namplifying inherent training set biases at test time. Existing metrics measure\nbias amplification with respect to single annotated attributes (e.g.,\n$\\texttt{computer}$). However, several visual datasets consist of images with\nmultiple attribute annotations. We show models can learn to exploit\ncorrelations with respect to multiple attributes (e.g., {$\\texttt{computer}$,\n$\\texttt{keyboard}$}), which are not accounted for by current metrics. In\naddition, we show current metrics can give the erroneous impression that\nminimal or no bias amplification has occurred as they involve aggregating over\npositive and negative values. Further, these metrics lack a clear desired\nvalue, making them difficult to interpret. To address these shortcomings, we\npropose a new metric: Multi-Attribute Bias Amplification. We validate our\nproposed metric through an analysis of gender bias amplification on the COCO\nand imSitu datasets. Finally, we benchmark bias mitigation methods using our\nproposed metric, suggesting possible avenues for future bias mitigation",
    "descriptor": "",
    "authors": [
      "Dora Zhao",
      "Jerone T.A. Andrews",
      "Alice Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11924"
  },
  {
    "id": "arXiv:2210.11928",
    "title": "Rational Ponzi Games in Algorithmic Stablecoin",
    "abstract": "Algorithmic stablecoins (AS) are one special type of stablecoins that are not\nbacked by any asset (equiv. without collateral). They stand to revolutionize\nthe way a sovereign fiat operates. As implemented, these coins are poorly\nstabilized in most cases, easily deviating from the price target or even\nfalling into a catastrophic collapse (a.k.a. Death spiral), and are as a result\ndismissed as a Ponzi scheme. However, is this the whole picture? In this paper,\nwe try to reveal the truth and clarify such a deceptive concept. We find that\nPonzi is basically a financial protocol that pays existing investors with funds\ncollected from new ones. Running a Ponzi, however, does not necessarily imply\nthat any participant is in any sense losing out, as long as the game can be\nperpetually rolled over. Economists call such realization as a \\textit{rational\nPonzi game}. We thereby propose a rational model in the context of AS and draw\nits holding conditions. We apply the model to examine: \\textit{whether or not\nthe algorithmic stablecoin is a rational Ponzi game.} Accordingly, we discuss\ntwo types of algorithmic stablecoins (\\text{Rebase} \\& \\text{Seigniorage\nshares}) and dig into the historical market performance of two impactful\nprojects (\\text{Ampleforth} \\& \\text{TerraUSD}, respectively) to demonstrate\nthe effectiveness of our model.",
    "descriptor": "\nComments: Conceptual version\n",
    "authors": [
      "Shange Fu",
      "Qin Wang",
      "Jiangshan Yu",
      "Shiping Chen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11928"
  },
  {
    "id": "arXiv:2210.11929",
    "title": "LiteVL: Efficient Video-Language Learning with Enhanced Spatial-Temporal  Modeling",
    "abstract": "Recent large-scale video-language pre-trained models have shown appealing\nperformance on various downstream tasks. However, the pre-training process is\ncomputationally expensive due to the requirement of millions of video-text\npairs and the redundant data structure of each video. To mitigate these\nproblems, we propose LiteVL, which adapts a pre-trained image-language model\nBLIP into a video-text model directly on downstream tasks, without heavy\npre-training. To enhance the temporal modeling lacking in the image-language\nmodel, we propose to add temporal attention modules in the image encoder of\nBLIP with dynamic temporal scaling. Besides the model-wise adaptation, we also\npropose a non-parametric pooling mechanism to adaptively reweight the\nfine-grained video embedding conditioned on the text. Experimental results on\ntext-video retrieval and video question answering show that the proposed LiteVL\neven outperforms previous video-language pre-trained models by a clear margin,\nthough without any video-language pre-training.",
    "descriptor": "\nComments: 13 pages, 6 figures, accepted by EMNLP 2022 main conference\n",
    "authors": [
      "Dongsheng Chen",
      "Chaofan Tao",
      "Lu Hou",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11929"
  },
  {
    "id": "arXiv:2210.11932",
    "title": "Message Transmission and Common Randomness Generation over MIMO Slow  Fading Channels with Arbitrary Channel State Distribution",
    "abstract": "We investigate the problem of message transmission and the problem of common\nrandomness (CR) generation over single-user multiple-input multiple-output\n(MIMO) slow fading channels with average input power constraint, additive white\nGaussian noise (AWGN), arbitrary state distribution and with complete channel\nstate information available at the receiver side (CSIR). First, we derive a\nlower and an upper bound on the outage transmission capacity of MIMO slow\nfading channels for arbitrary state distribution and show that the bounds\ncoincide except possibly at the points of discontinuity of the outage\ntransmission capacity, of which there are, at most, countably many. To prove\nthe lower bound on the outage transmission capacity, we also establish the\ncapacity of a specific compound MIMO Gaussian channel. Second, we define the\noutage CR capacity for a two-source model with unidirectional communication\nover a MIMO slow fading channel with arbitrary state distribution and establish\na lower and an upper bound on it using our bounds on the outage transmission\ncapacity of the MIMO slow fading channel.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.06451\n",
    "authors": [
      "Rami Ezzine",
      "Moritz Wiese",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11932"
  },
  {
    "id": "arXiv:2210.11933",
    "title": "Fine-grained Semantic Alignment Network for Weakly Supervised Temporal  Language Grounding",
    "abstract": "Temporal language grounding (TLG) aims to localize a video segment in an\nuntrimmed video based on a natural language description. To alleviate the\nexpensive cost of manual annotations for temporal boundary labels, we are\ndedicated to the weakly supervised setting, where only video-level descriptions\nare provided for training. Most of the existing weakly supervised methods\ngenerate a candidate segment set and learn cross-modal alignment through a\nMIL-based framework. However, the temporal structure of the video as well as\nthe complicated semantics in the sentence are lost during the learning. In this\nwork, we propose a novel candidate-free framework: Fine-grained Semantic\nAlignment Network (FSAN), for weakly supervised TLG. Instead of view the\nsentence and candidate moments as a whole, FSAN learns token-by-clip\ncross-modal semantic alignment by an iterative cross-modal interaction module,\ngenerates a fine-grained cross-modal semantic alignment map, and performs\ngrounding directly on top of the map. Extensive experiments are conducted on\ntwo widely-used benchmarks: ActivityNet-Captions, and DiDeMo, where our FSAN\nachieves state-of-the-art performance.",
    "descriptor": "\nComments: 11 pages, 4 figures, accepted by Findings of EMNLP 2021\n",
    "authors": [
      "Yuechen Wang",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11933"
  },
  {
    "id": "arXiv:2210.11934",
    "title": "An Analysis of Fusion Functions for Hybrid Retrieval",
    "abstract": "We study hybrid search in text retrieval where lexical and semantic search\nare fused together with the intuition that the two are complementary in how\nthey model relevance. In particular, we examine fusion by a convex combination\n(CC) of lexical and semantic scores, as well as the Reciprocal Rank Fusion\n(RRF) method, and identify their advantages and potential pitfalls. Contrary to\nexisting studies, we find RRF to be sensitive to its parameters; that the\nlearning of a CC fusion is generally agnostic to the choice of score\nnormalization; that CC outperforms RRF in in-domain and out-of-domain settings;\nand finally, that CC is sample efficient, requiring only a small set of\ntraining examples to tune its only parameter to a target domain.",
    "descriptor": "",
    "authors": [
      "Sebastian Bruch",
      "Siyu Gai",
      "Amir Ingber"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11934"
  },
  {
    "id": "arXiv:2210.11939",
    "title": "Automatic Cattle Identification using YOLOv5 and Mosaic Augmentation: A  Comparative Analysis",
    "abstract": "You Only Look Once (YOLO) is a single-stage object detection model popular\nfor real-time object detection, accuracy, and speed. This paper investigates\nthe YOLOv5 model to identify cattle in the yards. The current solution to\ncattle identification includes radio-frequency identification (RFID) tags. The\nproblem occurs when the RFID tag is lost or damaged. A biometric solution\nidentifies the cattle and helps to assign the lost or damaged tag or replace\nthe RFID-based system. Muzzle patterns in cattle are unique biometric solutions\nlike a fingerprint in humans. This paper aims to present our recent research in\nutilizing five popular object detection models, looking at the architecture of\nYOLOv5, investigating the performance of eight backbones with the YOLOv5 model,\nand the influence of mosaic augmentation in YOLOv5 by experimental results on\nthe available cattle muzzle images. Finally, we concluded with the excellent\npotential of using YOLOv5 in automatic cattle identification. Our experiments\nshow YOLOv5 with transformer performed best with mean Average Precision (mAP)\n0.5 (the average of AP when the IoU is greater than 50%) of 0.995, and mAP\n0.5:0.95 (the average of AP from 50% to 95% IoU with an interval of 5%) of\n0.9366. In addition, our experiments show the increase in accuracy of the model\nby using mosaic augmentation in all backbones used in our experiments.\nMoreover, we can also detect cattle with partial muzzle images.",
    "descriptor": "\nComments: Accepted in the Digital Image Computing: Techniques and Applications, 2022 (DICTA 2022)\n",
    "authors": [
      "Rabin Dulal",
      "Lihong Zheng",
      "Muhammad Ashad Kabir",
      "Shawn McGrath",
      "Jonathan Medway",
      "Dave Swain",
      "Will Swain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11939"
  },
  {
    "id": "arXiv:2210.11940",
    "title": "JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and  Tracking",
    "abstract": "Autonomous robotic systems operating in human environments must understand\ntheir surroundings to make accurate and safe decisions. In crowded human scenes\nwith close-up human-robot interaction and robot navigation, a deep\nunderstanding requires reasoning about human motion and body dynamics over time\nwith human body pose estimation and tracking. However, existing datasets either\ndo not provide pose annotations or include scene types unrelated to robotic\napplications. Many datasets also lack the diversity of poses and occlusions\nfound in crowded human scenes. To address this limitation we introduce\nJRDB-Pose, a large-scale dataset and benchmark for multi-person pose estimation\nand tracking using videos captured from a social navigation robot. The dataset\ncontains challenge scenes with crowded indoor and outdoor locations and a\ndiverse range of scales and occlusion types. JRDB-Pose provides human pose\nannotations with per-keypoint occlusion labels and track IDs consistent across\nthe scene. A public evaluation server is made available for fair evaluation on\na held-out test set. JRDB-Pose is available at https://jrdb.erc.monash.edu/ .",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Edward Vendrow",
      "Duy Tho Le",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11940"
  },
  {
    "id": "arXiv:2210.11941",
    "title": "DIICAN: Dual Time-scale State-Coupled Co-estimation of SOC, SOH and RUL  for Lithium-Ion Batteries",
    "abstract": "Accurate co-estimations of battery states, such as state-of-charge (SOC),\nstate-of-health (SOH,) and remaining useful life (RUL), are crucial to the\nbattery management systems to assure safe and reliable management. Although the\nexternal properties of the battery charge with the aging degree, batteries'\ndegradation mechanism shares similar evolving patterns. Since batteries are\ncomplicated chemical systems, these states are highly coupled with intricate\nelectrochemical processes. A state-coupled co-estimation method named Deep\nInter and Intra-Cycle Attention Network (DIICAN) is proposed in this paper to\nestimate SOC, SOH, and RUL, which organizes battery measurement data into the\nintra-cycle and inter-cycle time scales. And to extract degradation-related\nfeatures automatically and adapt to practical working conditions, the\nconvolutional neural network is applied. The state degradation attention unit\nis utilized to extract the battery state evolution pattern and evaluate the\nbattery degradation degree. To account for the influence of battery aging on\nthe SOC estimation, the battery degradation-related state is incorporated in\nthe SOC estimation for capacity calibration. The DIICAN method is validated on\nthe Oxford battery dataset. The experimental results show that the proposed\nmethod can achieve SOH and RUL co-estimation with high accuracy and effectively\nimprove SOC estimation accuracy for the whole lifespan.",
    "descriptor": "",
    "authors": [
      "Ningbo Cai",
      "Yuwen Qin",
      "Xin Chen",
      "Kai Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.11941"
  },
  {
    "id": "arXiv:2210.11942",
    "title": "Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent  Reinforcement Learning",
    "abstract": "Stackelberg Equilibria arise naturally in a range of popular learning\nproblems, such as in security games or automated mechanism design, and have\nreceived increasing attention in the reinforcement learning literature\nrecently. We present a general framework for implementing Stackelberg\nEquilibria search as a multi-agent RL problem, allowing a wide range of design\nchoices. We discuss how previous approaches can be seen as specific\ninstantiations of this framework. As a key insight, we note that the design\nspace allows for approaches not previously seen in the literature, for instance\nby leveraging multitask and meta-RL techniques for follower convergence. We\nevaluate examples of novel approaches predicted by our framework experimentally\non standard benchmark domains. Finally, we discuss directions for future work\nimplied by our work.",
    "descriptor": "",
    "authors": [
      "Matthias Gerstgrasser",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.11942"
  },
  {
    "id": "arXiv:2210.11946",
    "title": "RT-MOT: Confidence-Aware Real-Time Scheduling Framework for Multi-Object  Tracking Tasks",
    "abstract": "Different from existing MOT (Multi-Object Tracking) techniques that usually\naim at improving tracking accuracy and average FPS, real-time systems such as\nautonomous vehicles necessitate new requirements of MOT under limited computing\nresources: (R1) guarantee of timely execution and (R2) high tracking accuracy.\nIn this paper, we propose RT-MOT, a novel system design for multiple MOT tasks,\nwhich addresses R1 and R2. Focusing on multiple choices of a workload pair of\ndetection and association, which are two main components of the\ntracking-by-detection approach for MOT, we tailor a measure of object\nconfidence for RT-MOT and develop how to estimate the measure for the next\nframe of each MOT task. By utilizing the estimation, we make it possible to\npredict tracking accuracy variation according to different workload pairs to be\napplied to the next frame of an MOT task. Next, we develop a novel\nconfidence-aware real-time scheduling framework, which offers an offline timing\nguarantee for a set of MOT tasks based on non-preemptive fixed-priority\nscheduling with the smallest workload pair. At run-time, the framework checks\nthe feasibility of a priority-inversion associated with a larger workload pair,\nwhich does not compromise the timing guarantee of every task, and then chooses\na feasible scenario that yields the largest tracking accuracy improvement based\non the proposed prediction. Our experiment results demonstrate that RT-MOT\nsignificantly improves overall tracking accuracy by up to 1.5x, compared to\nexisting popular tracking-by-detection approaches, while guaranteeing timely\nexecution of all MOT tasks.",
    "descriptor": "\nComments: Accepted to 2022 Real-Time Systems Symposium (RTSS)\n",
    "authors": [
      "Donghwa Kang",
      "Seunghoon Lee",
      "Hoon Sung Chwa",
      "Seung-Hwan Bae",
      "Chang Mook Kang",
      "Jinkyu Lee",
      "Hyeongboo Baek"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11946"
  },
  {
    "id": "arXiv:2210.11947",
    "title": "Generalizing over Long Tail Concepts for Medical Term Normalization",
    "abstract": "Medical term normalization consists in mapping a piece of text to a large\nnumber of output classes. Given the small size of the annotated datasets and\nthe extremely long tail distribution of the concepts, it is of utmost\nimportance to develop models that are capable to generalize to scarce or unseen\nconcepts. An important attribute of most target ontologies is their\nhierarchical structure. In this paper we introduce a simple and effective\nlearning strategy that leverages such information to enhance the\ngeneralizability of both discriminative and generative models. The evaluation\nshows that the proposed strategy produces state-of-the-art performance on seen\nconcepts and consistent improvements on unseen ones, allowing also for\nefficient zero-shot knowledge transfer across text typologies and datasets.",
    "descriptor": "",
    "authors": [
      "Beatrice Portelli",
      "Simone Scaboro",
      "Enrico Santus",
      "Hooman Sedghamiz",
      "Emmanuele Chersoni",
      "Giuseppe Serra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11947"
  },
  {
    "id": "arXiv:2210.11948",
    "title": "lo-fi: distributed fine-tuning without communication",
    "abstract": "When fine-tuning large neural networks, it is common to use multiple nodes\nand to communicate gradients at each optimization step. By contrast, we\ninvestigate completely local fine-tuning, which we refer to as lo-fi. During\nlo-fi, each node is fine-tuned independently without any communication. Then,\nthe weights are averaged across nodes at the conclusion of fine-tuning. When\nfine-tuning DeiT-base and DeiT-large on ImageNet, this procedure matches\naccuracy in-distribution and improves accuracy under distribution shift\ncompared to the baseline, which observes the same amount of data but\ncommunicates gradients at each step. We also observe that lo-fi matches the\nbaseline's performance when fine-tuning OPT language models (up to 1.3B\nparameters) on Common Crawl. By removing the communication requirement, lo-fi\nreduces resource barriers for fine-tuning large models and enables fine-tuning\nin settings with prohibitive communication cost.",
    "descriptor": "",
    "authors": [
      "Mitchell Wortsman",
      "Suchin Gururangan",
      "Shen Li",
      "Ali Farhadi",
      "Ludwig Schmidt",
      "Michael Rabbat",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11948"
  },
  {
    "id": "arXiv:2210.11953",
    "title": "Real-time large-scale supplier order assignments across two-tiers of a  supply chain with penalty and dual-sourcing",
    "abstract": "Supplier selection and order allocation (SSOA) are key strategic decisions in\nsupply chain management which greatly impact the performance of the supply\nchain. The SSOA problem has been studied extensively but the lack of attention\npaid to scalability presents a significant gap preventing adoption of SSOA\nalgorithms by industrial practitioners. This paper presents a novel real-time\nlarge-scale industrial SSOA problem, which involves a multi-item,\nmulti-supplier environment with dual-sourcing and penalty constraints across\ntwo-tiers of a supply chain of a manufacturing company. The problem supports\nsupplier preferences to work with other suppliers through bidding. This is the\nlargest scale studied so far in literature, and needs to be solved in a\nreal-time auction environment, making computational complexity a key issue.\nFurthermore, order allocation needs to be undertaken on both supply tiers, with\ndynamically presented constraints where non-preferred allocation may results in\npenalties by the suppliers. We subsequently propose Mixed Integer Programming\nmodels for individual-tiers as well as an integrated problem, which are complex\ndue to NP-hard nature. The use case allows us to highlight how problem\nformulation, modelling and choice of modelling can help reduce complexity using\nMathematical Programming (MP) and Genetic Algorithm (GA) approaches. The\nresults show an interesting observation that MP outperforms GA to solve the\nindividual-tiers problem as well as the integrated problem. Sensitivity\nanalysis is presented for sourcing strategy, penalty threshold and penalty\nfactor. The developed model was successfully deployed in a supplier conference\nwhich helped in significant procurement cost reductions to the manufacturing\ncompany.",
    "descriptor": "\nComments: (under review)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Stephen Mak",
      "Ajith Kumar Parlikad",
      "Muhannad Alomari",
      "Linus Casassa",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11953"
  },
  {
    "id": "arXiv:2210.11954",
    "title": "A GA-like Dynamic Probability Method With Mutual Information for Feature  Selection",
    "abstract": "Feature selection plays a vital role in promoting the classifier's\nperformance. However, current methods ineffectively distinguish the complex\ninteraction in the selected features. To further remove these hidden negative\ninteractions, we propose a GA-like dynamic probability (GADP) method with\nmutual information which has a two-layer structure. The first layer applies the\nmutual information method to obtain a primary feature subset. The GA-like\ndynamic probability algorithm, as the second layer, mines more supportive\nfeatures based on the former candidate features. Essentially, the GA-like\nmethod is one of the population-based algorithms so its work mechanism is\nsimilar to the GA. Different from the popular works which frequently focus on\nimproving GA's operators for enhancing the search ability and lowering the\nconverge time, we boldly abandon GA's operators and employ the dynamic\nprobability that relies on the performance of each chromosome to determine\nfeature selection in the new generation. The dynamic probability mechanism\nsignificantly reduces the parameter number in GA that making it easy to use. As\neach gene's probability is independent, the chromosome variety in GADP is more\nnotable than in traditional GA, which ensures GADP has a wider search space and\nselects relevant features more effectively and accurately. To verify our\nmethod's superiority, we evaluate our method under multiple conditions on 15\ndatasets. The results demonstrate the outperformance of the proposed method.\nGenerally, it has the best accuracy. Further, we also compare the proposed\nmodel to the popular heuristic methods like POS, FPA, and WOA. Our model still\nowns advantages over them.",
    "descriptor": "\nComments: 18 pages; submitted to Applied Intelligence\n",
    "authors": [
      "Gaoshuai Wang",
      "Fabrice Lauri",
      "Amir Hajjam El Hassani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.11954"
  },
  {
    "id": "arXiv:2210.11960",
    "title": "Energy stable schemes for gradient flows based on the DVD method",
    "abstract": "The existing discrete variational derivative method is only second-order\naccurate and fully implicit. In this paper, we propose a framework to construct\nan arbitrary high-order implicit (original) energy stable scheme and a\nsecond-order semi-implicit (modified) energy stable scheme. Combined with the\nRunge--Kutta process, we can build an arbitrary high-order and unconditionally\n(original) energy stable scheme based on the discrete variational derivative\nmethod. The new energy stable scheme is implicit and leads to a large sparse\nnonlinear algebraic system at each time step, which can be efficiently solved\nby using an inexact Newton type algorithm. To avoid solving nonlinear algebraic\nsystems, we then present a relaxed discrete variational derivative method,\nwhich can construct second-order, linear, and unconditionally (modified) energy\nstable schemes. Several numerical simulations are performed to investigate the\nefficiency, stability, and accuracy of the newly proposed schemes.",
    "descriptor": "",
    "authors": [
      "Jizu Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11960"
  },
  {
    "id": "arXiv:2210.11966",
    "title": "A class of constacyclic codes are generalized Reed-Solomon codes",
    "abstract": "Maximum distance separable (MDS) codes are optimal in the sense that the\nminimum distance cannot be improved for a given length and code size. The most\nprominent MDS codes are generalized Reed-Solomon (GRS) codes. The square\n$\\mathcal{C}^{2}$ of a linear code $\\mathcal{C}$ is the linear code spanned by\nthe component-wise products of every pair of codewords in $\\mathcal{C}$. For an\nMDS code $\\mathcal{C}$, it is convenient to determine whether $\\mathcal{C}$ is\na GRS code by determining the dimension of $\\mathcal{C}^{2}$. In this paper, we\ninvestigate under what conditions that MDS constacyclic codes are GRS. For this\npurpose, we first study the square of constacyclic codes. Then, we give a\nsufficient condition that a constacyclic code is GRS. In particular, We provide\na necessary and sufficient condition that a constacyclic code of a prime length\nis GRS.",
    "descriptor": "",
    "authors": [
      "Hongwei Liu",
      "Shengwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11966"
  },
  {
    "id": "arXiv:2210.11968",
    "title": "CobNet: Cross Attention on Object and Background for Few-Shot  Segmentation",
    "abstract": "Few-shot segmentation aims to segment images containing objects from\npreviously unseen classes using only a few annotated samples. Most current\nmethods focus on using object information extracted, with the aid of human\nannotations, from support images to identify the same objects in new query\nimages. However, background information can also be useful to distinguish\nobjects from their surroundings. Hence, some previous methods also extract\nbackground information from the support images. In this paper, we argue that\nsuch information is of limited utility, as the background in different images\ncan vary widely. To overcome this issue, we propose CobNet which utilises\ninformation about the background that is extracted from the query images\nwithout annotations of those images. Experiments show that our method achieves\na mean Intersection-over-Union score of 61.4% and 37.8% for 1-shot segmentation\non PASCAL-5i and COCO-20i respectively, outperforming previous methods. It is\nalso shown to produce state-of-the-art performances of 53.7% for\nweakly-supervised few-shot segmentation, where no annotations are provided for\nthe support images.",
    "descriptor": "\nComments: Accepted to ICPR2022\n",
    "authors": [
      "Haoyan Guan",
      "Spratling Michae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11968"
  },
  {
    "id": "arXiv:2210.11970",
    "title": "Energy Efficiency of Massive Random Access in MIMO Quasi-Static Rayleigh  Fading Channels with Finite Blocklength",
    "abstract": "This paper considers the massive random access problem in MIMO quasi-static\nRayleigh fading channels. Specifically, we derive achievability and converse\nbounds on the minimum energy-per-bit required for each active user to transmit\n$J$ bits with blocklength $n$ and power $P$ under a per-user probability of\nerror (PUPE) constraint, in the cases with and without \\emph{a priori} channel\nstate information at the receiver (CSIR and no-CSI). In the case of no-CSI, we\nconsider both the settings with and without knowing the number $K_a$ of active\nusers. The achievability bounds rely on the design of the ``good region''.\nNumerical evaluation shows the gap between achievability and converse bounds is\nless than $2.5$ dB in the CSIR case and less than $4$ dB in the no-CSI case in\nmost considered regimes. When the distribution of $K_a$ is known, the\nperformance gap between the cases with and without knowing the value of $K_a$\nis small. For example, in the setup with blocklength $n=1000$, payload $J=100$,\nerror requirement $\\epsilon=0.001$, and $L=128$ receive antennas, compared to\nthe case with known $K_a$, the extra required energy-per-bit when $K_a$ is\nunknown and distributed as $K_a\\sim\\text{Binom}(K,0.4)$ is less than $0.3$ dB\non the converse side and $1.1$ dB on the achievability side. The spectral\nefficiency grows approximately linearly with $L$ in the CSIR case, whereas the\ngrowth rate decreases with no-CSI. Moreover, we study the performance of a\npilot-assisted scheme, which is suboptimal especially when $K_a$ is large.\nBuilding on non-asymptotic results, when all users are active and\n$J=\\Theta(1)$, we obtain scaling laws as follows: when $L=\\Theta\n\\left(n^2\\right)$ and $P=\\Theta\\left(\\frac{1}{n^2}\\right)$, one can reliably\nserve $K=\\mathcal{O}(n^2)$ users with no-CSI; under mild conditions with CSIR,\nthe PUPE requirement is satisfied if and only if $\\frac{nL\\ln\nKP}{K}=\\Omega\\left(1\\right)$.",
    "descriptor": "\nComments: 88 pages, 7 figures. Accepted by IEEE Transactions on Information Theory\n",
    "authors": [
      "Junyuan Gao",
      "Yongpeng Wu",
      "Shuo Shao",
      "Wei Yang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11970"
  },
  {
    "id": "arXiv:2210.11971",
    "title": "The Model Forest Ensemble Kalman Filter",
    "abstract": "Traditional data assimilation uses information obtained from the propagation\nof one physics-driven model and combines it with information derived from\nreal-world observations in order to obtain a better estimate of the truth of\nsome natural process. However, in many situations multiple simulation models\nthat describe the same physical phenomenon are available. Such models can have\ndifferent sources. On one hand there are theory-guided models are constructed\nfrom first physical principles, while on the other there are data-driven models\nthat are constructed from snapshots of high fidelity information. In this work\nwe provide a possible way to make use of this collection of models in data\nassimilation by generalizing the idea of model hierarchies into model forests\n-- collections of high fidelity and low fidelity models organized in a groping\nof model trees such as to capture various relationships between different\nmodels. We generalize the multifidelity ensemble Kalman filter that previously\noperated on model hierarchies into the model forest ensemble Kalman filter\nthrough a generalized theory of linear control variates. This new filter allows\nfor much more freedom when treading the line between accuracy and speed.\nNumerical experiments with a high fidelity quasi-geostrophic model and two of\nits low fidelity reduced order models validate the accuracy of our approach.",
    "descriptor": "",
    "authors": [
      "Andrey A Popov",
      "Adrian Sandu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11971"
  },
  {
    "id": "arXiv:2210.11973",
    "title": "Real-Time Constrained 6D Object-Pose Tracking of An In-Hand Suture  Needle for Minimally Invasive Robotic Surgery",
    "abstract": "Autonomous suturing has been a long-sought-after goal for surgical robotics.\nOutside of staged environments, accurate localization of suture needles is a\ncritical foundation for automating various suture needle manipulation tasks in\nthe real world. When localizing a needle held by a gripper, previous work\nusually tracks them separately without considering their relationship. Because\nof the significant errors that can arise in the stereo-triangulation of objects\nand instruments, their reconstructions may often not be consistent. This can\nlead to unrealistic tool-needle grasp reconstructions that are infeasible.\nInstead, an obvious strategy to improve localization would be to leverage\nconstraints that arise from contact, thereby constraining reconstructions of\nobjects and instruments into a jointly feasible space. In this work, we\nconsider feasible grasping constraints when tracking the 6D pose of an in-hand\nsuture needle. We propose a reparameterization trick to define a new state\nspace for describing a needle pose, where grasp constraints can be easily\ndefined and satisfied. Our proposed state space and feasible grasping\nconstraints are then incorporated into Bayesian filters for real-time needle\nlocalization. In the experiments, we show that our constrained methods\noutperform previous unconstrained/constrained tracking approaches and\ndemonstrate the importance of incorporating feasible grasping constraints into\nautomating suture needle manipulation tasks.",
    "descriptor": "",
    "authors": [
      "Zih-Yun Chiu",
      "Florian Richter",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11973"
  },
  {
    "id": "arXiv:2210.11974",
    "title": "Face Pyramid Vision Transformer",
    "abstract": "A novel Face Pyramid Vision Transformer (FPVT) is proposed to learn a\ndiscriminative multi-scale facial representations for face recognition and\nverification. In FPVT, Face Spatial Reduction Attention (FSRA) and\nDimensionality Reduction (FDR) layers are employed to make the feature maps\ncompact, thus reducing the computations. An Improved Patch Embedding (IPE)\nalgorithm is proposed to exploit the benefits of CNNs in ViTs (e.g., shared\nweights, local context, and receptive fields) to model lower-level edges to\nhigher-level semantic primitives. Within FPVT framework, a Convolutional\nFeed-Forward Network (CFFN) is proposed that extracts locality information to\nlearn low level facial information. The proposed FPVT is evaluated on seven\nbenchmark datasets and compared with ten existing state-of-the-art methods,\nincluding CNNs, pure ViTs, and Convolutional ViTs. Despite fewer parameters,\nFPVT has demonstrated excellent performance over the compared methods. Project\npage is available at https://khawar-islam.github.io/fpvt/",
    "descriptor": "\nComments: Accepted in BMVC 2022\n",
    "authors": [
      "Khawar Islam",
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11974"
  },
  {
    "id": "arXiv:2210.11978",
    "title": "DCL-SLAM: A Distributed Collaborative LiDAR SLAM Framework for a Robotic  Swarm",
    "abstract": "To execute collaborative tasks in unknown environments, a robotic swarm needs\nto establish a global reference frame and locate itself in a shared\nunderstanding of the environment. However, it faces many challenges in\nreal-world scenarios, such as the prior information about the environment being\nabsent and poor communication among the team members. This work presents\nDCL-SLAM, a fully distributed collaborative LiDAR SLAM framework intended for\nthe robotic swarm to simultaneously co-localize in an unknown environment with\nminimal information exchange. Based on ad-hoc wireless peer-to-peer\ncommunication (limited bandwidth and communication range), DCL-SLAM adopts the\nlightweight LiDAR-Iris descriptor for place recognition and does not require\nfull connectivity among teams. DCL-SLAM includes three main parts: a\nreplaceable single-robot front-end that produces LiDAR odometry results; a\ndistributed loop closure module that detects inter-robot loop closures with\nkeyframes; and a distributed back-end module that adapts distributed pose graph\noptimizer combined with a pairwise consistent measurement set maximization\nalgorithm to reject spurious inter-robot loop closures. We integrate our\nproposed framework with diverse open-source LiDAR odometry methods to show its\nversatility. The proposed system is extensively evaluated on benchmarking\ndatasets and field experiments over various scales and environments.\nExperimental result shows that DCL-SLAM achieves higher accuracy and lower\ncommunication bandwidth than other state-of-art multi-robot SLAM systems. The\nfull source code is available at https://github.com/zhongshp/DCL-SLAM.git.",
    "descriptor": "",
    "authors": [
      "Shipeng Zhong",
      "Yuhua Qi",
      "Zhiqiang Chen",
      "Jin Wu",
      "Hongbo Chen",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11978"
  },
  {
    "id": "arXiv:2210.11981",
    "title": "Named Entity Detection and Injection for Direct Speech Translation",
    "abstract": "In a sentence, certain words are critical for its semantic. Among them, named\nentities (NEs) are notoriously challenging for neural models. Despite their\nimportance, their accurate handling has been neglected in speech-to-text (S2T)\ntranslation research, and recent work has shown that S2T models perform poorly\nfor locations and notably person names, whose spelling is challenging unless\nknown in advance. In this work, we explore how to leverage dictionaries of NEs\nknown to likely appear in a given context to improve S2T model outputs. Our\nexperiments show that we can reliably detect NEs likely present in an utterance\nstarting from S2T encoder outputs. Indeed, we demonstrate that the current\ndetection quality is sufficient to improve NE accuracy in the translation with\na 31% reduction in person name errors.",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Marco Gaido",
      "Yun Tang",
      "Ilia Kulikov",
      "Rongqing Huang",
      "Hongyu Gong",
      "Hirofumi Inaguma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11981"
  },
  {
    "id": "arXiv:2210.11983",
    "title": "Pyrit: A Finite Element Based Field Simulation Software Written in  Python",
    "abstract": "Pyrit is a field simulation software based on the finite element method\nwritten in Python to solve coupled systems of partial differential equations.\nIt is designed as a modular software that is easily modifiable and extendable.\nThe framework can, therefore, be adapted to various activities, i.e. research,\neducation and industry collaboration.",
    "descriptor": "\nComments: 6 pages, 6 figures, The 20th International IGTE Symposium on Computational Methods in Electrical Engineering and Multiphysics\n",
    "authors": [
      "Jonas Bundschuh",
      "M. Greta Ruppert",
      "Yvonne Sp\u00e4ck-Leigsnering"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11983"
  },
  {
    "id": "arXiv:2210.11984",
    "title": "Shift-Reduce Task-Oriented Semantic Parsing with Stack-Transformers",
    "abstract": "Intelligent voice assistants, such as Apple Siri and Amazon Alexa, are widely\nused nowadays. These task-oriented dialog systems require a semantic parsing\nmodule in order to process user utterances and understand the action to be\nperformed. This semantic parsing component was initially implemented by\nrule-based or statistical slot-filling approaches for processing simple\nqueries; however, the appearance of more complex utterances demanded the\napplication of shift-reduce parsers or sequence-to-sequence models. While\nshift-reduce approaches initially demonstrated to be the best option, recent\nefforts on sequence-to-sequence systems pushed them to become the\nhighest-performing method for that task. In this article, we advance the\nresearch on shift-reduce semantic parsing for task-oriented dialog. In\nparticular, we implement novel shift-reduce parsers that rely on\nStack-Transformers. These allow to adequately model transition systems on the\ncutting-edge Transformer architecture, notably boosting shift-reduce parsing\nperformance. Additionally, we adapt alternative transition systems from\nconstituency parsing to task-oriented parsing, and empirically prove that the\nin-order algorithm substantially outperforms the commonly-used top-down\nstrategy. Finally, we extensively test our approach on multiple domains from\nthe Facebook TOP benchmark, improving over existing shift-reduce parsers and\nstate-of-the-art sequence-to-sequence models in both high-resource and\nlow-resource settings.",
    "descriptor": "",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11984"
  },
  {
    "id": "arXiv:2210.11987",
    "title": "Joint Speech Translation and Named Entity Recognition",
    "abstract": "Modern automatic translation systems aim at place the human at the center by\nproviding contextual support and knowledge. In this context, a critical task is\nenriching the output with information regarding the mentioned entities, which\nis currently achieved processing the generated translation with named entity\nrecognition (NER) and entity linking systems. In light of the recent promising\nresults shown by direct speech translation (ST) models and the known weaknesses\nof cascades (error propagation and additional latency), in this paper we\npropose multitask models that jointly perform ST and NER, and compare them with\na cascade baseline. The experimental results show that our models significantly\noutperform the cascade on the NER task (by 0.4-1.0 F1), without degradation in\nterms of translation quality, and with the same computational efficiency of a\nplain direct ST model.",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Marco Gaido",
      "Sara Papi",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11987"
  },
  {
    "id": "arXiv:2210.11989",
    "title": "Optimizing text representations to capture (dis)similarity between  political parties",
    "abstract": "Even though fine-tuned neural language models have been pivotal in enabling\n\"deep\" automatic text analysis, optimizing text representations for specific\napplications remains a crucial bottleneck. In this study, we look at this\nproblem in the context of a task from computational social science, namely\nmodeling pairwise similarities between political parties. Our research question\nis what level of structural information is necessary to create robust text\nrepresentation, contrasting a strongly informed approach (which uses both claim\nspan and claim category annotations) with approaches that forgo one or both\ntypes of annotation with document structure-based heuristics. Evaluating our\nmodels on the manifestos of German parties for the 2021 federal election. We\nfind that heuristics that maximize within-party over between-party similarity\nalong with a normalization step lead to reliable party similarity prediction,\nwithout the need for manual annotation.",
    "descriptor": "\nComments: Conference on Computational Natural Language Learning 2022\n",
    "authors": [
      "Tanise Ceron",
      "Nico Blokker",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11989"
  },
  {
    "id": "arXiv:2210.11990",
    "title": "An Empirical Study on Real Bug Fixes in Smart Contracts Projects",
    "abstract": "Blockchain uses cryptographic proof to replace trusted third parties to\nensure the correctness of the information, allowing any two willing parties to\ntransact directly with each other. Smart contracts are pieces of code that\nreside inside the blockchains and can be triggered to execute any transaction\nwhen specifically predefined conditions are satisfied. Being commonly used for\ncommercial transactions in blockchain makes the security of smart contracts\nparticularly important. Over the last few years, we have seen a great deal of\nacademic and practical interest in detecting and repairing the vulnerabilities\nin smart contracts developed for the Ethereum blockchain. In this paper, we\nconduct an empirical study on historical bug fixing versions of 46 real-world\nsmart contracts projects from Github, providing a multi-faceted discussion. In\nthis paper, we mainly explore the following four questions: File Type and\nAmount, Fix Complexity, Bug distribution, and Fix Patches. By analyzing the\nfile type, amount, and fix complexity, we find that about 80% of the\nbug-related commits modified no more than one solidity source file to fix bugs.\nUp to 80% of bugs in solidity source files can be fixed by less than three fix\nactions. Modification is the mostly used fix action, which involves three lines\nof code on average. By using the analysis tool Mythril to detect the\nvulnerabilities, we find that nearly 20% of the solidity files in our dataset\nhad or have had vulnerabilities. We finally find that the developers may not\nput much attention to fixing vulnerabilities reported by Mythril completely or\navoid introducing them again. Because vulnerabilities that have a high repair\npercentage usually have a high rate to be introduced again.",
    "descriptor": "\nComments: 18 pages, 11 figure. In the process of submission.(Journal of Systems and Software 2023)\n",
    "authors": [
      "Yilin Wang",
      "Xiangping Chen",
      "Yuan Huang",
      "Hao-Nan Zhu",
      "Jing Bian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11990"
  },
  {
    "id": "arXiv:2210.11991",
    "title": "Real-time Detection of 2D Tool Landmarks with Synthetic Training Data",
    "abstract": "In this paper a deep learning architecture is presented that can, in real\ntime, detect the 2D locations of certain landmarks of physical tools, such as a\nhammer or screwdriver. To avoid the labor of manual labeling, the network is\ntrained on synthetically generated data. Training computer vision models on\ncomputer generated images, while still achieving good accuracy on real images,\nis a challenge due to the difference in domain. The proposed method uses an\nadvanced rendering method in combination with transfer learning and an\nintermediate supervision architecture to address this problem. It is shown that\nthe model presented in this paper, named Intermediate Heatmap Model (IHM),\ngeneralizes to real images when trained on synthetic data. To avoid the need\nfor an exact textured 3D model of the tool in question, it is shown that the\nmodel will generalize to an unseen tool when trained on a set of different 3D\nmodels of the same type of tool. IHM is compared to two existing approaches to\nkeypoint detection and it is shown that it outperforms those at detecting tool\nlandmarks, trained on synthetic data.",
    "descriptor": "",
    "authors": [
      "Bram Vanherle",
      "Jeroen Put",
      "Nick Michiels",
      "Frank Van Reeth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11991"
  },
  {
    "id": "arXiv:2210.11992",
    "title": "Efficient Submodular Optimization under Noise: Local Search is Robust",
    "abstract": "The problem of monotone submodular maximization has been studied extensively\ndue to its wide range of applications. However, there are cases where one can\nonly access the objective function in a distorted or noisy form because of the\nuncertain nature or the errors involved in the evaluation. This paper considers\nthe problem of constrained monotone submodular maximization with noisy oracles\nintroduced by [Hassidim et al., 2017]. For a cardinality constraint, we propose\nan algorithm achieving a near-optimal\n$\\left(1-\\frac{1}{e}-O(\\varepsilon)\\right)$-approximation guarantee (for\narbitrary $\\varepsilon > 0$) with only a polynomial number of queries to the\nnoisy value oracle, which improves the exponential query complexity of [Singer\net al., 2018]. For general matroid constraints, we show the first constant\napproximation algorithm in the presence of noise. Our main approaches are to\ndesign a novel local search framework that can handle the effect of noise and\nto construct certain smoothing surrogate functions for noise reduction.",
    "descriptor": "",
    "authors": [
      "Lingxiao Huang",
      "Yuyi Wang",
      "Chunxue Yang",
      "Huanjian Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11992"
  },
  {
    "id": "arXiv:2210.11993",
    "title": "Bisparse Blind Deconvolution through Hierarchical Sparse Recovery",
    "abstract": "The bi-sparse blind deconvolution problem is studied -- that is, from the\nknowledge of $h*(Qb)$, where $Q$ is some linear operator, recovering $h$ and\n$b$, which are both assumed to be sparse. The approach rests upon lifting the\nproblem to a linear one, and then applying the hierarchical sparsity framework.\nIn particular, the efficient HiHTP algorithm is proposed for performing the\nrecovery. Then, under a random model on the matrix $Q$, it is theoretically\nshown that an $s$-sparse $h \\in \\mathbb{K}^\\mu$ and $\\sigma$-sparse $b \\in\n\\mathbb{K}^n$ with high probability can be recovered when $\\mu \\succcurlyeq\ns^{2}\\log(\\mu) + s^{2}\\sigma \\log(n)$.",
    "descriptor": "",
    "authors": [
      "Axel Flinth",
      "Ingo Roth",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11993"
  },
  {
    "id": "arXiv:2210.11994",
    "title": "GesPlayer: Using Augmented Gestures to Empower Video Players",
    "abstract": "In this paper, we introduce GesPlayer, a gesture-based empowered video player\nthat explores how users can experience their hands as an interface through\ngestures. We provide three semantic gestures based on the camera of a computer\nor other smart device to detect and adjust the progress of video playback,\nvolume, and screen brightness, respectively. Our goal is to enable users to\ncontrol video playback simply by their gestures in the air, without the need to\nuse a mouse or keyboard, especially when it is not convenient to do so.\nUltimately, we hope to expand our understanding of gesture-based interaction by\nunderstanding the inclusiveness of designing the hand as an interactive\ninterface, and further broaden the state of semantic gestures in an interactive\nenvironment through computational interaction methods.",
    "descriptor": "\nComments: 5 pages, 4 figures. Published at ACM ISS 2022 as a poster\n",
    "authors": [
      "Xiang Li",
      "Yuzheng Chen",
      "Xiaohang Tang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11994"
  },
  {
    "id": "arXiv:2210.11996",
    "title": "Unbalanced Triangle Detection and Enumeration Hardness for Unions of  Conjunctive Queries",
    "abstract": "We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)\nwith optimal time guarantees. More precisely, we wish to identify the queries\nthat can be solved with linear preprocessing time and constant delay. Despite\nthe basic nature of this problem, it was shown only recently that UCQs can be\nsolved within these time bounds if they admit free-connex union extensions,\neven if all individual CQs in the union are intractable with respect to the\nsame complexity measure. Our goal is to understand whether there exist\nadditional tractable UCQs, not covered by the currently known algorithms.\nAs a first step, we show that some previously unclassified UCQs are hard\nusing the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle\nlisting in graphs. As a second step, we identify a question about a variant of\nthis graph task which is unavoidable if we want to classify all self-join free\nUCQs: is it possible to decide the existence of a triangle in a\nvertex-unbalanced tripartite graph in linear time? We prove that this task is\nequivalent in hardness to some family of UCQs. Finally, we show a dichotomy for\nunions of two self-join-free CQs if we assume the answer to this question is\nnegative.\nAs a result, to reason about a class of enumeration problems defined by UCQs,\nit is enough to study the single decision problem of detecting triangles in\nunbalanced graphs. As of today, we know of no algorithm that comes close to\nsolving this decision problem within the required time bounds. Our conclusion\nis that, without a breakthrough for triangle detection, we have no hope to find\nan efficient algorithm for additional unions of two self-join free CQs. On the\nother hand, if we will one day have such a triangle detection algorithm, we\nwill immediately obtain an efficient algorithm for a family of UCQs that are\ncurrently not known to be tractable.",
    "descriptor": "",
    "authors": [
      "Karl Bringmann",
      "Nofar Carmeli"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11996"
  },
  {
    "id": "arXiv:2210.11997",
    "title": "Extending $\\mathrm{F}_1$ metric, probabilistic approach",
    "abstract": "This article explores the extension of well-known $\\mathrm{F}_1$ score used\nfor assessing the performance of binary classifiers. We propose the new metric\nusing probabilistic interpretation of precision, recall, specificity, and\nnegative predictive value. We describe its properties and compare it to common\nmetrics. Then we demonstrate its behavior in edge cases of the confusion\nmatrix. Finally, the properties of the metric are tested on binary classifier\ntrained on the real dataset.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Mikolaj Sitarz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11997"
  },
  {
    "id": "arXiv:2210.11999",
    "title": "On-Board Pedestrian Trajectory Prediction Using Behavioral Features",
    "abstract": "This paper presents a novel approach to pedestrian trajectory prediction for\non-board camera systems, which utilizes behavioral features of pedestrians that\ncan be inferred from visual observations. Our proposed method, called\nBehavior-Aware Pedestrian Trajectory Prediction (BA-PTP), processes multiple\ninput modalities, i.e. bounding boxes, body and head orientation of pedestrians\nas well as their pose, with independent encoding streams. The encodings of each\nstream are fused using a modality attention mechanism, resulting in a final\nembedding that is used to predict future bounding boxes in the image.\nIn experiments on two datasets for pedestrian behavior prediction, we\ndemonstrate the benefit of using behavioral features for pedestrian trajectory\nprediction and evaluate the effectiveness of the proposed encoding strategy.\nAdditionally, we investigate the relevance of different behavioral features on\nthe prediction performance based on an ablation study.",
    "descriptor": "\nComments: Accepted at ICMLA 2022, 7 pages, 3 figures, 3 tables\n",
    "authors": [
      "Phillip Czech",
      "Markus Braun",
      "Ulrich Kre\u00dfel",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11999"
  },
  {
    "id": "arXiv:2210.12001",
    "title": "When Expressivity Meets Trainability: Fewer than $n$ Neurons Can Work",
    "abstract": "Modern neural networks are often quite wide, causing large memory and\ncomputation costs. It is thus of great interest to train a narrower network.\nHowever, training narrow neural nets remains a challenging task. We ask two\ntheoretical questions: Can narrow networks have as strong expressivity as wide\nones? If so, does the loss function exhibit a benign optimization landscape? In\nthis work, we provide partially affirmative answers to both questions for\n1-hidden-layer networks with fewer than $n$ (sample size) neurons when the\nactivation is smooth. First, we prove that as long as the width $m \\geq 2n/d$\n(where $d$ is the input dimension), its expressivity is strong, i.e., there\nexists at least one global minimizer with zero training loss. Second, we\nidentify a nice local region with no local-min or saddle points. Nevertheless,\nit is not clear whether gradient descent can stay in this nice region. Third,\nwe consider a constrained optimization formulation where the feasible region is\nthe nice local region, and prove that every KKT point is a nearly global\nminimizer. It is expected that projected gradient methods converge to KKT\npoints under mild technical conditions, but we leave the rigorous convergence\nanalysis to future work. Thorough numerical results show that projected\ngradient methods on this constrained formulation significantly outperform SGD\nfor training narrow neural nets.",
    "descriptor": "\nComments: 39 Pages\n",
    "authors": [
      "Jiawei Zhang",
      "Yushun Zhang",
      "Mingyi Hong",
      "Ruoyu Sun",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12001"
  },
  {
    "id": "arXiv:2210.12002",
    "title": "An Adaptive Neighborhood Partition Full Conditional Mutual Information  Maximization Method for Feature Selection",
    "abstract": "Feature selection is used to eliminate redundant features and keep relevant\nfeatures, it can enhance machine learning algorithm's performance and\naccelerate computing speed. In various methods, mutual information has\nattracted increasingly more attention as it's an effective criterion to measure\nvariable correlation. However, current works mainly focus on maximizing the\nfeature relevancy with class label and minimizing the feature redundancy within\nselected features, we reckon that pursuing feature redundancy minimization is\nreasonable but not necessary because part of so-called redundant features also\ncarries some useful information to promote performance. In terms of mutual\ninformation calculation, it may distort the true relationship between two\nvariables without proper neighborhood partition. Traditional methods usually\nsplit the continuous variables into several intervals even ignore such\ninfluence. We theoretically prove how variable fluctuation negatively\ninfluences mutual information calculation. To remove the referred obstacles,\nfor feature selection method, we propose a full conditional mutual information\nmaximization method (FCMIM) which only considers the feature relevancy in two\naspects. For obtaining a better partition effect and eliminating the negative\ninfluence of attribute fluctuation, we put up an adaptive neighborhood\npartition algorithm (ANP) with the feedback of mutual information maximization\nalgorithm, the backpropagation process helps search for a proper neighborhood\npartition parameter. We compare our method with several mutual information\nmethods on 17 benchmark datasets. Results of FCMIM are better than other\nmethods based on different classifiers. Results show that ANP indeed promotes\nnearly all the mutual information methods' performance.",
    "descriptor": "\nComments: 21 pages; submitted to Expert Systems with Applications\n",
    "authors": [
      "Gaoshuai Wang",
      "Fabrice Lauri",
      "Pu Wang",
      "Hongyuan Luo",
      "Amir Hajjam lL Hassani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.12002"
  },
  {
    "id": "arXiv:2210.12003",
    "title": "HDHumans: A Hybrid Approach for High-fidelity Digital Humans",
    "abstract": "Photo-real digital human avatars are of enormous importance in graphics, as\nthey enable immersive communication over the globe, improve gaming and\nentertainment experiences, and can be particularly beneficial for AR and VR\nsettings. However, current avatar generation approaches either fall short in\nhigh-fidelity novel view synthesis, generalization to novel motions,\nreproduction of loose clothing, or they cannot render characters at the high\nresolution offered by modern displays. To this end, we propose HDHumans, which\nis the first method for HD human character synthesis that jointly produces an\naccurate and temporally coherent 3D deforming surface and highly\nphoto-realistic images of arbitrary novel views and of motions not seen at\ntraining time. At the technical core, our method tightly integrates a classical\ndeforming character template with neural radiance fields (NeRF). Our method is\ncarefully designed to achieve a synergy between classical surface deformation\nand NeRF. First, the template guides the NeRF, which allows synthesizing novel\nviews of a highly dynamic and articulated character and even enables the\nsynthesis of novel motions. Second, we also leverage the dense pointclouds\nresulting from NeRF to further improve the deforming surface via 3D-to-3D\nsupervision. We outperform the state of the art quantitatively and\nqualitatively in terms of synthesis quality and resolution, as well as the\nquality of 3D surface reconstruction.",
    "descriptor": "",
    "authors": [
      "Marc Habermann",
      "Lingjie Liu",
      "Weipeng Xu",
      "Gerard Pons-Moll",
      "Michael Zollhoefer",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12003"
  },
  {
    "id": "arXiv:2210.12006",
    "title": "Integrated Brier Score based Survival Cobra -- A regression based  approach",
    "abstract": "In this paper, we provide two novel regression-based integrations of combined\nregression strategy (COBRA) ensemble using Integrated Brier Score to predict\nconditional survival function. Our proposition includes a weighted version of\nall predictions based on Integrated Brier Score score made by all weak learners\nto predict the final survival function apart from the straight implementation.\nTwo different norms (Frobenius and Sup norm) used to figure out the proximity\npoints in the algorithm. Our implementations consider right-censored data too.\nWe illustrate the proposed algorithms through few real-life data analysis.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.11919\n",
    "authors": [
      "Rahul Goswami",
      "Arabin Kumar Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.12006"
  },
  {
    "id": "arXiv:2210.12007",
    "title": "Ethics for Digital Medicine: A Path for Ethical Emerging Medical IoT  Design",
    "abstract": "The dawn of the digital medicine era, ushered in by increasingly powerful\nembedded systems and Internet of Things (IoT) computing devices, is creating\nnew therapies and biomedical solutions that promise to positively transform our\nquality of life. However, the digital medicine revolution also creates\nunforeseen and complex ethical, regulatory, and societal issues. In this\narticle, we reflect on the ethical challenges facing digital medicine. We\ndiscuss the perils of ethical oversights in medical devices, and the role of\nprofessional codes and regulatory oversight towards the ethical design,\ndeployment, and operation of digital medicine devices that safely and\neffectively meet the needs of patients. We advocate for an ensemble approach of\nintensive education, programmable ethical behaviors, and ethical analysis\nframeworks, to prevent mishaps and sustain ethical innovation, design, and\nlifecycle management of emerging digital medicine devices.",
    "descriptor": "",
    "authors": [
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12007"
  },
  {
    "id": "arXiv:2210.12008",
    "title": "End-to-End Context-Aided Unicity Matching for Person Re-identification",
    "abstract": "Most existing person re-identification methods compute the matching relations\nbetween person images across camera views based on the ranking of the pairwise\nsimilarities. This matching strategy with the lack of the global viewpoint and\nthe context's consideration inevitably leads to ambiguous matching results and\nsub-optimal performance. Based on a natural assumption that images belonging to\nthe same person identity should not match with images belonging to multiple\ndifferent person identities across views, called the unicity of person matching\non the identity level, we propose an end-to-end person unicity matching\narchitecture for learning and refining the person matching relations. First, we\nadopt the image samples' contextual information in feature space to generate\nthe initial soft matching results by using graph neural networks. Secondly, we\nutilize the samples' global context relationship to refine the soft matching\nresults and reach the matching unicity through bipartite graph matching. Given\nfull consideration to real-world person re-identification applications, we\nachieve the unicity matching in both one-shot and multi-shot settings of person\nre-identification and further develop a fast version of the unicity matching\nwithout losing the performance. The proposed method is evaluated on five public\nbenchmarks, including four multi-shot datasets MSMT17, DukeMTMC, Market1501,\nCUHK03, and a one-shot dataset VIPeR. Experimental results show the superiority\nof the proposed method on performance and efficiency.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Min Cao",
      "Cong Ding",
      "Chen Chen",
      "Junchi Yan",
      "Yinqiang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12008"
  },
  {
    "id": "arXiv:2210.12015",
    "title": "Blocking Delaunay Triangulations from the Exterior",
    "abstract": "Given two distinct point sets $P$ and $Q$ in the plane, we say that $Q$\n\\emph{blocks} $P$ if no two points of $P$ are adjacent in any Delaunay\ntriangulation of $P\\cup Q$. Aichholzer et al. (2013) showed that any set $P$ of\n$n$ points in general position can be blocked by $\\frac{3}{2}n$ points and that\nevery set $P$ of $n$ points in convex position can be blocked by $\\frac{5}{4}n$\npoints. Moreover, they conjectured that, if $P$ is in convex position, $n$\nblocking points are sufficient and necessary. The necessity was recently shown\nby Biniaz (2021) who proved that every point set in general position requires\n$n$ blocking points.\nHere we investigate the variant, where blocking points can only lie outside\nof the convex hull of the given point set. We show that $\\frac{5}{4}n-O(1)$\nsuch \\emph{exterior-blocking} points are sometimes necessary, even if the given\npoint set is in convex position. As a consequence we obtain that, if the\nconjecture of Aichholzer et al. for the original setting was true, then minimal\nblocking sets of some point configurations $P$ would have to contain points\ninside of the convex hull of $P$.",
    "descriptor": "",
    "authors": [
      "Oswin Aichholzer",
      "Thomas Hackl",
      "Maarten L\u00f6ffler",
      "Alexander Pilz",
      "Irene Parada",
      "Manfred Scheucher",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.12015"
  },
  {
    "id": "arXiv:2210.12020",
    "title": "HCL: Improving Graph Representation with Hierarchical Contrastive  Learning",
    "abstract": "Contrastive learning has emerged as a powerful tool for graph representation\nlearning. However, most contrastive learning methods learn features of graphs\nwith fixed coarse-grained scale, which might underestimate either local or\nglobal information. To capture more hierarchical and richer representation, we\npropose a novel Hierarchical Contrastive Learning (HCL) framework that\nexplicitly learns graph representation in a hierarchical manner. Specifically,\nHCL includes two key components: a novel adaptive Learning to Pool (L2Pool)\nmethod to construct more reasonable multi-scale graph topology for more\ncomprehensive contrastive objective, a novel multi-channel pseudo-siamese\nnetwork to further enable more expressive learning of mutual information within\neach scale. Comprehensive experimental results show HCL achieves competitive\nperformance on 12 datasets involving node classification, node clustering and\ngraph classification. In addition, the visualization of learned representation\nreveals that HCL successfully captures meaningful characteristics of graphs.",
    "descriptor": "\nComments: published at The 21st International Semantic Web Conference ( ISWC 2022 )\n",
    "authors": [
      "Jun Wang",
      "Weixun Li",
      "Changyu Hou",
      "Xin Tang",
      "Yixuan Qiao",
      "Rui Fang",
      "Pengyong Li",
      "Peng Gao",
      "Guotong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12020"
  },
  {
    "id": "arXiv:2210.12022",
    "title": "Performance-Efficiency Trade-Offs in Adapting Language Models to Text  Classification Tasks",
    "abstract": "Pre-trained language models (LMs) obtain state-of-the-art performance when\nadapted to text classification tasks. However, when using such models in\nreal-world applications, efficiency considerations are paramount. In this\npaper, we study how different training procedures that adapt LMs to text\nclassification perform, as we vary model and train set size. More specifically,\nwe compare standard fine-tuning, prompting, and knowledge distillation (KD)\nwhen the teacher was trained with either fine-tuning or prompting. Our findings\nsuggest that even though fine-tuning and prompting work well to train large LMs\non large train sets, there are more efficient alternatives that can reduce\ncompute or data cost. Interestingly, we find that prompting combined with KD\ncan reduce compute and data cost at the same time.",
    "descriptor": "\nComments: AACL-IJCNLP 2022\n",
    "authors": [
      "Laura Aina",
      "Nikos Voskarides",
      "Roi Blanco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12022"
  },
  {
    "id": "arXiv:2210.12023",
    "title": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning  with Language Models",
    "abstract": "We have recently witnessed a number of impressive results on hard\nmathematical reasoning problems with language models. At the same time, the\nrobustness of these models has also been called into question; recent works\nhave shown that models can rely on shallow patterns in the problem description\nwhen predicting a solution. Building on the idea of behavioral testing, we\npropose a novel framework, which pins down the causal effect of various factors\nin the input, e.g., the surface form of the problem text, the operands and math\noperators on the output solution. By grounding the behavioral analysis in a\ncausal graph describing an intuitive reasoning process, we study the behavior\nof language models in terms of robustness and sensitivity to direct\ninterventions in the input space. We apply our framework on a test bed of\nbivariate math word problems. Our analysis shows that robustness does not\nappear to continuously improve as a function of scale, but that the recent LLM,\nGPT-3-Instruct (175B), achieves a dramatic improvement in both robustness and\nsensitivity, compared to all other GPT variants.",
    "descriptor": "\nComments: A shorter version of the paper was accepted at the MATH-AI Workshop at NeurIPS 2022\n",
    "authors": [
      "Alessandro Stolfo",
      "Zhijing Jin",
      "Kumar Shridhar",
      "Bernhard Sch\u00f6lkopf",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12023"
  },
  {
    "id": "arXiv:2210.12026",
    "title": "Ontology Development is Consensus Creation, Not (Merely) Representation",
    "abstract": "Ontology development methodologies emphasise knowledge gathering from domain\nexperts and documentary resources, and knowledge representation using an\nontology language such as OWL or FOL. However, working ontologists are often\nsurprised by how challenging and slow it can be to develop ontologies. Here,\nwith a particular emphasis on the sorts of ontologies that are content-heavy\nand intended to be shared across a community of users (reference ontologies),\nwe propose that a significant and heretofore under-emphasised contributor of\nchallenges during ontology development is the need to create, or bring about,\nconsensus in the face of disagreement. For this reason reference ontology\ndevelopment cannot be automated, at least within the limitations of existing AI\napproaches. Further, for the same reason ontologists are required to have\nspecific social-negotiating skills which are currently lacking in most\ntechnical curricula.",
    "descriptor": "",
    "authors": [
      "Fabian Neuhaus",
      "Janna Hastings"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12026"
  },
  {
    "id": "arXiv:2210.12027",
    "title": "Bootstrapping NLP tools across low-resourced African languages: an  overview and prospects",
    "abstract": "Computing and Internet access are substantially growing markets in Southern\nAfrica, which brings with it increasing demands for local content and tools in\nindigenous African languages. Since most of those languages are low-resourced,\nefforts have gone into the notion of bootstrapping tools for one African\nlanguage from another. This paper provides an overview of these efforts for\nNiger-Congo B (`Bantu') languages. Bootstrapping grammars for geographically\ndistant languages has been shown to still have positive outcomes for morphology\nand rules or grammar-based natural language generation. Bootstrapping with\ndata-driven approaches to NLP tasks is difficult to use meaningfully regardless\ngeographic proximity, which is largely due to lexical diversity due to both\northography and vocabulary. Cladistic approaches in comparative linguistics may\ninform bootstrapping strategies and similarity measures might serve as proxy\nfor bootstrapping potential as well, with both fertile ground for further\nresearch.",
    "descriptor": "\nComments: 13 pages, 3 tables, 2 figures\n",
    "authors": [
      "C. Maria Keet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12027"
  },
  {
    "id": "arXiv:2210.12030",
    "title": "Evolution of Neural Tangent Kernels under Benign and Adversarial  Training",
    "abstract": "Two key challenges facing modern deep learning are mitigating deep networks'\nvulnerability to adversarial attacks and understanding deep learning's\ngeneralization capabilities. Towards the first issue, many defense strategies\nhave been developed, with the most common being Adversarial Training (AT).\nTowards the second challenge, one of the dominant theories that has emerged is\nthe Neural Tangent Kernel (NTK) -- a characterization of neural network\nbehavior in the infinite-width limit. In this limit, the kernel is frozen, and\nthe underlying feature map is fixed. In finite widths, however, there is\nevidence that feature learning happens at the earlier stages of the training\n(kernel learning) before a second phase where the kernel remains fixed (lazy\ntraining). While prior work has aimed at studying adversarial vulnerability\nthrough the lens of the frozen infinite-width NTK, there is no work that\nstudies the adversarial robustness of the empirical/finite NTK during training.\nIn this work, we perform an empirical study of the evolution of the empirical\nNTK under standard and adversarial training, aiming to disambiguate the effect\nof adversarial training on kernel learning and lazy training. We find under\nadversarial training, the empirical NTK rapidly converges to a different kernel\n(and feature map) than standard training. This new kernel provides adversarial\nrobustness, even when non-robust training is performed on top of it.\nFurthermore, we find that adversarial training on top of a fixed kernel can\nyield a classifier with $76.1\\%$ robust accuracy under PGD attacks with\n$\\varepsilon = 4/255$ on CIFAR-10.",
    "descriptor": "\nComments: Accepted to the Conference on Advances in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Noel Loo",
      "Ramin Hasani",
      "Alexander Amini",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12030"
  },
  {
    "id": "arXiv:2210.12034",
    "title": "Proceedings of the Dialogue Robot Competition 2022",
    "abstract": "This proceedings contains papers on the dialogue systems developed by the\ntwelve teams participating in DRC2022, as well as an overview paper summarizing\nthe competition.",
    "descriptor": "\nComments: Proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Ryuichiro Higashinaka",
      "Takashi Minato",
      "Hiromitsu Nishizaki",
      "Takayuki Nagai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.12034"
  },
  {
    "id": "arXiv:2210.12035",
    "title": "BlanketGen -- A synthetic blanket occlusion augmentation pipeline for  MoCap datasets",
    "abstract": "Human motion analysis has seen drastic improvements recently, however, due to\nthe lack of representative datasets, in clinical in-bed scenarios, it is still\nlagging behind for clinical applications. To address this issue, we implemented\nBlanketGen, a pipeline that augments videos with synthetic blanket occlusions.\nWith this pipeline, we generated an augmented version of 3DPW called\nBlanketGen-3DPW (code and further information available at\nhttps://gitlab.inesctec.pt/brain-lab/brain-lab-public/blanket-gen-releases ).\nWe then used this new dataset to fine-tune HybrIK model to improve its\nperformance in these scenarios with promising results.",
    "descriptor": "\nComments: 5 pages, Code and further information to generate the dataset is available at: this https URL\n",
    "authors": [
      "Jo\u00e3o Carmona",
      "Tam\u00e1s Kar\u00e1csony",
      "Jo\u00e3o Paulo Silva Cunha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12035"
  },
  {
    "id": "arXiv:2210.12036",
    "title": "On the Longest Flip Sequence to Untangle Segments in the Plane",
    "abstract": "A set of segments in the plane may form a Euclidean TSP tour or a matching.\nOptimal TSP tours as well as minimum weight perfect matchings have no crossing\nsegments, but several heuristics and approximation algorithms may produce\nsolutions with crossings. To improve such solutions, we can successively apply\na flip operation that replaces a pair of crossing segments by non-crossing\nones. This paper considers the maximum number D(n) of flips performed on n\nsegments. First, we present reductions relating D(n) for different versions of\nmatchings and the TSP tour. Second, we show that if all except t points are in\nconvex position, then D(n) = O(tn^2), providing a smooth transition between the\nconvex O(n^2) bound and the general O(n^3) bound. Last, we show that if instead\nof counting the total number of flips, we only count the number of distinct\nflips, then the cubic upper bound improves to O(n^{8/3}).",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Bastien Rivier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.12036"
  },
  {
    "id": "arXiv:2210.12037",
    "title": "Exponentially Stable Adaptive Control Under Semi-PE Condition",
    "abstract": "A novel method of exponentially stable adaptive control to compensate for\nmatched parametric uncertainty under a mild condition of semi-persistent\nexcitation (s-PE) of a regressor with piecewise-constant rank and nullspace is\nproposed. It is based on the generalized dynamic regressor extension and mixing\nprocedure developed earlier by the authors, does not require high adaptive gain\nor data stacks and ensures: 1) exponential convergence of the tracking error to\nzero and the parameter one to a bounded set when the regressor is s-PE, 2)\nadjustable parameters transients of first-order type (each scalar parameter is\nadjusted using a separate first-order scalar differential equation), 3)\nalertness to change of the uncertainty parameters values, and 4) boundedness of\nall signals when the regressor is not s-PE. The main salient feature of the\nproposed approach is that the exponential stability is guaranteed when the\ncontroller parameters estimates converge to the values that are\nindistinguishable from the true ones. The results of numerical experiments\nfully support the theoretical analysis and demonstrate the advantages of the\nproposed method.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.12037"
  },
  {
    "id": "arXiv:2210.12040",
    "title": "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent  Semantic Communications",
    "abstract": "Semantic communication (SC) aims to communicate reliably with minimal data\ntransfer while simultaneously providing seamless connectivity to heterogeneous\nservices and users. In this paper, a novel emergent SC (ESC) system framework\nis proposed and is composed of a signaling game for emergent language design\nand a neuro-symbolic (NeSy) artificial intelligence (AI) approach for causal\nreasoning. In order to design the language, the signaling game is solved using\nan alternating maximization between the communicating node's utilities. The\nemergent language helps create a context-aware transmit vocabulary (minimal\nsemantic representation) and aids the reasoning process (enabling\ngeneralization to unseen scenarios) by splitting complex messages into simpler\nreasoning tasks for the receiver. The causal description at the transmitter is\nthen modeled (a neural component) as a posterior distribution of the relevant\nattributes present in the data. Using the reconstructed causal state, the\nreceiver evaluates a set of logical formulas (symbolic part) to execute its\ntask. The nodes NeSy reasoning components are implemented by the recently\nproposed AI tool called Generative Flow Networks, and they are optimized for\nhigher semantic reliability. The ESC system is designed to enhance the novel\nmetrics of semantic information, reliability, distortion and similarity that\nare designed using rigorous algebraic properties from category theory thereby\ngeneralizing the metrics beyond Shannon's notion of uncertainty. Simulation\nresults validate the ability of ESC to communicate efficiently (with reduced\nbits) and achieve better semantic reliability than conventional wireless and\nstate-of-the-art systems that do not exploit causal reasoning capabilities.",
    "descriptor": "",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.12040"
  },
  {
    "id": "arXiv:2210.12045",
    "title": "Optimization of side lobe level of linear antenna array using nature  optimized ants bridging solutions(NOABS)",
    "abstract": "Nature inspired algorithms has brought solutions to complex problems in\noptimization where the optimization and solution of complex problems is highly\ncomplex and nonlinear. There is a need to use proper design of the cost\nfunction or the fitness function in terms of the parameters to be optimized,\nthis can be used in solving any type of such problems. In this paper the nature\ninspired algorithms has played important role in the optimal design of antenna\narray with improved radiation characteristics. In this paper, 20 elements\nlinearly spaced array is used as an example of nature inspired optimization in\nantenna array system. This bridge inspired army ant algorithm(NOABS) is used to\nreduce the side lobes and to improve the other radiation characteristics to\nshow the effect of the optimization on design characteristics by implementation\nof NOABS nature inspired algorithm. The entire simulation is carried out on 20\nelements linear antenna array.",
    "descriptor": "",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Dr.Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.12045"
  },
  {
    "id": "arXiv:2210.12048",
    "title": "Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework",
    "abstract": "Bridging geometry and topology, curvature is a powerful and expressive\ninvariant. While the utility of curvature has been theoretically and\nempirically confirmed in the context of manifolds and graphs, its\ngeneralization to the emerging domain of hypergraphs has remained largely\nunexplored. On graphs, Ollivier-Ricci curvature measures differences between\nrandom walks via Wasserstein distances, thus grounding a geometric concept in\nideas from probability and optimal transport. We develop ORCHID, a flexible\nframework generalizing Ollivier-Ricci curvature to hypergraphs, and prove that\nthe resulting curvatures have favorable theoretical properties. Through\nextensive experiments on synthetic and real-world hypergraphs from different\ndomains, we demonstrate that ORCHID curvatures are both scalable and useful to\nperform a variety of hypergraph tasks in practice.",
    "descriptor": "",
    "authors": [
      "Corinna Coupette",
      "Sebastian Dalleiger",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12048"
  },
  {
    "id": "arXiv:2210.12050",
    "title": "Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of  Rewards",
    "abstract": "Derivative-free prompt learning has emerged as a lightweight alternative to\nprompt tuning, which only requires model inference to optimize the prompts.\nHowever, existing work did not take full advantage of the over-parameterized\ncharacteristics of large pre-trained language models (PLMs). In this paper, we\npropose Clip-Tuning, a simple yet effective method that adopts diverse frozen\n\"thinned\" networks of PLMs to obtain a mixture of rewards and thus advance the\nderivative-free prompt learning. The thinned networks consist of all the hidden\nunits that survive a stationary dropout strategy, whose inference predictions\nreflect an ensemble of partial views over prompted training samples. Our method\noutperforms previous gradient-free prompt learning methods and achieves parity\nwith gradient-based counterparts on seven language understanding benchmarks\nunder few-shot settings.",
    "descriptor": "\nComments: EMNLP 2022 (Findings)\n",
    "authors": [
      "Yekun Chai",
      "Shuohuan Wang",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12050"
  },
  {
    "id": "arXiv:2210.12051",
    "title": "The privacy issue of counterfactual explanations: explanation linkage  attacks",
    "abstract": "Black-box machine learning models are being used in more and more high-stakes\ndomains, which creates a growing need for Explainable AI (XAI). Unfortunately,\nthe use of XAI in machine learning introduces new privacy risks, which\ncurrently remain largely unnoticed. We introduce the explanation linkage\nattack, which can occur when deploying instance-based strategies to find\ncounterfactual explanations. To counter such an attack, we propose k-anonymous\ncounterfactual explanations and introduce pureness as a new metric to evaluate\nthe validity of these k-anonymous counterfactual explanations. Our results show\nthat making the explanations, rather than the whole dataset, k- anonymous, is\nbeneficial for the quality of the explanations.",
    "descriptor": "",
    "authors": [
      "Sofie Goethals",
      "Kenneth S\u00f6rensen",
      "David Martens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.12051"
  },
  {
    "id": "arXiv:2210.12053",
    "title": "Analysis of GMRES for Low-Rank and Small-Norm Perturbations of the  Identity Matrix",
    "abstract": "In many applications, linear systems arise where the coefficient matrix takes\nthe special form ${\\bf I} + {\\bf K} + {\\bf E}$, where ${\\bf I}$ is the identity\nmatrix of dimension $n$, ${\\rm rank}({\\bf K}) = p \\ll n$, and $\\|{\\bf E}\\| \\leq\n\\epsilon < 1$. GMRES convergence rates for linear systems with coefficient\nmatrices of the forms ${\\bf I} + {\\bf K}$ and ${\\bf I} + {\\bf E}$ are\nguaranteed by well-known theory, but only relatively weak convergence bounds\nspecific to matrices of the form ${\\bf I} + {\\bf K} + {\\bf E}$ currently exist.\nIn this paper, we explore the convergence properties of linear systems with\nsuch coefficient matrices by considering the pseudospectrum of ${\\bf I} + {\\bf\nK}$. We derive a bound for the GMRES residual in terms of $\\epsilon$ when\napproximately solving the linear system $({\\bf I} + {\\bf K} + {\\bf E}){\\bf x} =\n{\\bf b}$ and identify the eigenvalues of ${\\bf I} + {\\bf K}$ that are sensitive\nto perturbation. In particular, while a clustered spectrum away from the origin\nis often a good indicator of fast GMRES convergence, that convergence may be\nslow when some of those eigenvalues are ill-conditioned. We show there can be\nat most $2p$ eigenvalues of ${\\bf I} + {\\bf K}$ that are sensitive to small\nperturbations. We present numerical results when using GMRES to solve a\nsequence of linear systems of the form $({\\bf I} + {\\bf K}_j + {\\bf E}_j){\\bf\nx}_j = {\\bf b}_j$ that arise from the application of Broyden's method to solve\na nonlinear partial differential equation.",
    "descriptor": "",
    "authors": [
      "Arielle K. Carr",
      "Eric de Sturler",
      "Mark Embree"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.12053"
  },
  {
    "id": "arXiv:2210.12054",
    "title": "Towards Global Neural Network Abstractions with Locally-Exact  Reconstruction",
    "abstract": "Neural networks are a powerful class of non-linear functions. However, their\nblack-box nature makes it difficult to explain their behaviour and certify\ntheir safety. Abstraction techniques address this challenge by transforming the\nneural network into a simpler, over-approximated function. Unfortunately,\nexisting abstraction techniques are slack, which limits their applicability to\nsmall local regions of the input domain. In this paper, we propose Global\nInterval Neural Network Abstractions with Center-Exact Reconstruction\n(GINNACER). Our novel abstraction technique produces sound over-approximation\nbounds over the whole input domain while guaranteeing exact reconstructions for\nany given local input. Our experiments show that GINNACER is several orders of\nmagnitude tighter than state-of-the-art global abstraction techniques, while\nbeing competitive with local ones.",
    "descriptor": "\nComments: Under submission to the Neural Networks Journal\n",
    "authors": [
      "Edoardo Manino",
      "Iury Bessa",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12054"
  },
  {
    "id": "arXiv:2210.12055",
    "title": "Query Semantic Reconstruction for Background in Few-Shot Segmentation",
    "abstract": "Few-shot segmentation (FSS) aims to segment unseen classes using a few\nannotated samples. Typically, a prototype representing the foreground class is\nextracted from annotated support image(s) and is matched to features\nrepresenting each pixel in the query image. However, models learnt in this way\nare insufficiently discriminatory, and often produce false positives:\nmisclassifying background pixels as foreground. Some FSS methods try to address\nthis issue by using the background in the support image(s) to help identify the\nbackground in the query image. However, the backgrounds of theses images is\noften quite distinct, and hence, the support image background information is\nuninformative. This article proposes a method, QSR, that extracts the\nbackground from the query image itself, and as a result is better able to\ndiscriminate between foreground and background features in the query image.\nThis is achieved by modifying the training process to associate prototypes with\nclass labels including known classes from the training data and latent classes\nrepresenting unknown background objects. This class information is then used to\nextract a background prototype from the query image. To successfully associate\nprototypes with class labels and extract a background prototype that is capable\nof predicting a mask for the background regions of the image, the machinery for\nextracting and using foreground prototypes is induced to become more\ndiscriminative between different classes. Experiments for both 1-shot and\n5-shot FSS on both the PASCAL-5i and COCO-20i datasets demonstrate that the\nproposed method results in a significant improvement in performance for the\nbaseline methods it is applied to. As QSR operates only during training, these\nimproved results are produced with no extra computational complexity during\ntesting.",
    "descriptor": "",
    "authors": [
      "Haoyan Guan",
      "Michael Spratling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12055"
  },
  {
    "id": "arXiv:2210.12057",
    "title": "Efficient Global Planning in Large MDPs via Stochastic Primal-Dual  Optimization",
    "abstract": "We propose a new stochastic primal-dual optimization algorithm for planning\nin a large discounted Markov decision process with a generative model and\nlinear function approximation. Assuming that the feature map approximately\nsatisfies standard realizability and Bellman-closedness conditions and also\nthat the feature vectors of all state-action pairs are representable as convex\ncombinations of a small core set of state-action pairs, we show that our method\noutputs a near-optimal policy after a polynomial number of queries to the\ngenerative model. Our method is computationally efficient and comes with the\nmajor advantage that it outputs a single softmax policy that is compactly\nrepresented by a low-dimensional parameter vector, and does not need to execute\ncomputationally expensive local planning subroutines in runtime.",
    "descriptor": "\nComments: 20 pages including reference and appendix\n",
    "authors": [
      "Gergely Neu",
      "Nneka Okolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.12057"
  },
  {
    "id": "arXiv:2210.12059",
    "title": "Virtual Triggering: a Technique to Segment Cryptographic Processes in  Side Channel Traces",
    "abstract": "Side-Channel Attacks (SCAs) exploit data correla-tion in signals leaked from\ndevices to jeopardize confidentiality. Locating and synchronizing segments of\ninterest in traces from Cryptographic Processes (CPs) is a key step of the\nattack. The most common method consists in generating a trigger signal to\nindicate to the attacker the start of a CP. This paper proposes a method called\nVirtual Triggering (VT) that removes the need for the trigger signal and\nautomates trace segmentation. When the time between repetitions is not\nconstant, further trace alignment techniques are required. Building on VT, we\npropose a simple method to learn representative segment templates from a\nprofiling device similar to the victim, and to automatically locate and pull\nout these segments from other victim devices using simple pattern recognition.\nWe evaluate VT on screaming channel attacks [1], which initially used a\nFrequency Component (FC) known to appear at a single time in leaked signals, as\na trigger to segment traces. We demonstrate that VT not only performs\nequivalently to FC on a standard attack scenario, but we also show how using VT\nwith the automatic pullout technique improves the attack efficiency and enables\nmore realistic attack scenarios. Thanks to VT, screaming channel attacks can\nnow: (1) succeed with only half of the segments collected compared to the FC\ntrigger from the original attack; and (2) absorb time variations between CPs.",
    "descriptor": "\nComments: To appear at the IEEE International Workshop on Signal Processing Systems (SiPS) 2022. 6 pages, 11 figures, 2 algorithms\n",
    "authors": [
      "Jeremy Guillaume",
      "Maxime Pelcat",
      "Amor Nafkha",
      "Rub\u00e9n Salvador"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.12059"
  },
  {
    "id": "arXiv:2210.12061",
    "title": "Validation of Composite Systems by Discrepancy Propagation",
    "abstract": "Assessing the validity of a real-world system with respect to given quality\ncriteria is a common yet costly task in industrial applications due to the vast\nnumber of required real-world tests. Validating such systems by means of\nsimulation offers a promising and less expensive alternative, but requires an\nassessment of the simulation accuracy and therefore end-to-end measurements.\nAdditionally, covariate shifts between simulations and actual usage can cause\ndifficulties for estimating the reliability of such systems. In this work, we\npresent a validation method that propagates bounds on distributional\ndiscrepancy measures through a composite system, thereby allowing us to derive\nan upper bound on the failure probability of the real system from potentially\ninaccurate simulations. Each propagation step entails an optimization problem,\nwhere -- for measures such as maximum mean discrepancy (MMD) -- we develop\ntight convex relaxations based on semidefinite programs. We demonstrate that\nour propagation method yields valid and useful bounds for composite systems\nexhibiting a variety of realistic effects. In particular, we show that the\nproposed method can successfully account for data shifts within the\nexperimental design as well as model inaccuracies within the used simulation.",
    "descriptor": "\nComments: 20 pages incl. 10 pages appendix\n",
    "authors": [
      "David Reeb",
      "Kanil Patel",
      "Karim Barsim",
      "Martin Schiegg",
      "Sebastian Gerwinn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12061"
  },
  {
    "id": "arXiv:2210.12067",
    "title": "Efficient Dataset Distillation Using Random Feature Approximation",
    "abstract": "Dataset distillation compresses large datasets into smaller synthetic\ncoresets which retain performance with the aim of reducing the storage and\ncomputational burden of processing the entire dataset. Today's best-performing\nalgorithm, \\textit{Kernel Inducing Points} (KIP), which makes use of the\ncorrespondence between infinite-width neural networks and kernel-ridge\nregression, is prohibitively slow due to the exact computation of the neural\ntangent kernel matrix, scaling $O(|S|^2)$, with $|S|$ being the coreset size.\nTo improve this, we propose a novel algorithm that uses a random feature\napproximation (RFA) of the Neural Network Gaussian Process (NNGP) kernel, which\nreduces the kernel matrix computation to $O(|S|)$. Our algorithm provides at\nleast a 100-fold speedup over KIP and can run on a single GPU. Our new method,\ntermed an RFA Distillation (RFAD), performs competitively with KIP and other\ndataset condensation algorithms in accuracy over a range of large-scale\ndatasets, both in kernel regression and finite-width network training. We\ndemonstrate the effectiveness of our approach on tasks involving model\ninterpretability and privacy preservation.",
    "descriptor": "\nComments: Accepted to the Conference on the Advances in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Noel Loo",
      "Ramin Hasani",
      "Alexander Amini",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12067"
  },
  {
    "id": "arXiv:2210.12075",
    "title": "Neural Networks for Local Search and Crossover in Vehicle Routing: A  Possible Overkill?",
    "abstract": "Extensive research has been conducted, over recent years, on various ways of\nenhancing heuristic search for combinatorial optimization problems with machine\nlearning algorithms. In this study, we investigate the use of predictions from\ngraph neural networks (GNNs) in the form of heatmaps to improve the Hybrid\nGenetic Search (HGS), a state-of-the-art algorithm for the Capacitated Vehicle\nRouting Problem (CVRP). The crossover and local-search components of HGS are\ninstrumental in finding improved solutions, yet these components essentially\nrely on simple greedy or random choices. It seems intuitive to attempt to\nincorporate additional knowledge at these levels. Throughout a vast\nexperimental campaign on more than 10,000 problem instances, we show that\nexploiting more sophisticated strategies using measures of node relatedness\n(heatmaps, or simply distance) within these algorithmic components can\nsignificantly enhance performance. However, contrary to initial expectations,\nwe also observed that heatmaps did not present significant advantages over\nsimpler distance measures for these purposes. Therefore, we faced a common --\nthough rarely documented -- situation of overkill: GNNs can indeed improve\nperformance on an important optimization task, but an ablation analysis\ndemonstrated that simpler alternatives perform equally well.",
    "descriptor": "",
    "authors": [
      "\u00cdtalo Santana",
      "Andrea Lodi",
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12075"
  },
  {
    "id": "arXiv:2210.12077",
    "title": "Language-Integrated Query for Temporal Data (Extended version)",
    "abstract": "Modern applications often manage time-varying data. Despite decades of\nresearch on temporal databases, which culminated in the addition of temporal\ndata operations into the SQL:2011 standard, temporal data query and\nmanipulation operations are unavailable in most mainstream database management\nsystems, leaving developers with the unenviable task of implementing such\nfunctionality from scratch. In this paper, we extend \\emph{language-integrated\nquery} to support writing temporal queries and updates in a uniform host\nlanguage, with the language performing the required rewriting to emulate\ntemporal capabilities automatically on any standard relational database. We\nintroduce two core languages, $\\lambda_{\\mathsf{TLINQ}}$ and\n$\\lambda_{\\mathsf{VLINQ}}$, for manipulating transaction time and valid time\ndata respectively, and formalise existing implementation strategies by giving\nprovably correct semantics-preserving translations into a non-temporal core\nlanguage, $\\lambda_{\\mathsf{LINQ}}$. We show how existing work on query\nnormalisation supports a surprisingly simple implementation strategy for\n\\emph{sequenced joins}. We implement our approach in the Links programming\nlanguage, and describe a non-trivial case study based on curating COVID-19\nstatistics.",
    "descriptor": "\nComments: Extended version of paper accepted to GPCE 2022\n",
    "authors": [
      "Simon Fowler",
      "Vashti Galpin",
      "James Cheney"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.12077"
  },
  {
    "id": "arXiv:2210.12078",
    "title": "Experiencer-Specific Emotion and Appraisal Prediction",
    "abstract": "Emotion classification in NLP assigns emotions to texts, such as sentences or\nparagraphs. With texts like \"I felt guilty when he cried\", focusing on the\nsentence level disregards the standpoint of each participant in the situation:\nthe writer (\"I\") and the other entity (\"he\") could in fact have different\naffective states. The emotions of different entities have been considered only\npartially in emotion semantic role labeling, a task that relates semantic roles\nto emotion cue words. Proposing a related task, we narrow the focus on the\nexperiencers of events, and assign an emotion (if any holds) to each of them.\nTo this end, we represent each emotion both categorically and with appraisal\nvariables, as a psychological access to explaining why a person develops a\nparticular emotion. On an event description corpus, our experiencer-aware\nmodels of emotions and appraisals outperform the experiencer-agnostic\nbaselines, showing that disregarding event participants is an\noversimplification for the emotion detection task.",
    "descriptor": "\nComments: accepted to the NLPCSS workshop at EMNLP 2022\n",
    "authors": [
      "Maximilian Wegge",
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12078"
  },
  {
    "id": "arXiv:2210.12079",
    "title": "Do Vision-and-Language Transformers Learn Grounded Predicate-Noun  Dependencies?",
    "abstract": "Recent advances in vision-and-language modeling have seen the development of\nTransformer architectures that achieve remarkable performance on multimodal\nreasoning tasks. Yet, the exact capabilities of these black-box models are\nstill poorly understood. While much of previous work has focused on studying\ntheir ability to learn meaning at the word-level, their ability to track\nsyntactic dependencies between words has received less attention. We take a\nfirst step in closing this gap by creating a new multimodal task targeted at\nevaluating understanding of predicate-noun dependencies in a controlled setup.\nWe evaluate a range of state-of-the-art models and find that their performance\non the task varies considerably, with some models performing relatively well\nand others at chance level. In an effort to explain this variability, our\nanalyses indicate that the quality (and not only sheer quantity) of pretraining\ndata is essential. Additionally, the best performing models leverage\nfine-grained multimodal pretraining objectives in addition to the standard\nimage-text matching objectives. This study highlights that targeted and\ncontrolled evaluations are a crucial step for a precise and rigorous test of\nthe multimodal knowledge of vision-and-language models.",
    "descriptor": "\nComments: To appear at EMNLP 2022\n",
    "authors": [
      "Mitja Nikolaus",
      "Emmanuelle Salin",
      "Stephane Ayache",
      "Abdellah Fourtassi",
      "Benoit Favre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12079"
  },
  {
    "id": "arXiv:2210.12080",
    "title": "Monitoring Constraints in Business Processes Using Object-Centric  Constraint Graphs",
    "abstract": "Constraint monitoring aims to monitor the violation of constraints in\nbusiness processes, e.g., an invoice should be cleared within 48 hours after\nthe corresponding goods receipt, by analyzing event data. Existing techniques\nfor constraint monitoring assume that a single case notion exists in a business\nprocess, e.g., a patient in a healthcare process, and each event is associated\nwith the case notion. However, in reality, business processes are\nobject-centric, i.e., multiple case notions (objects) exist, and an event may\nbe associated with multiple objects. For instance, an Order-To-Cash (O2C)\nprocess involves order, item, delivery, etc., and they interact when executing\nan event, e.g., packing multiple items together for a delivery. The existing\ntechniques produce misleading insights when applied to such object-centric\nbusiness processes. In this work, we propose an approach to monitoring\nconstraints in object-centric business processes. To this end, we introduce\nObject-Centric Constraint Graphs (OCCGs) to represent constraints that consider\nthe interaction of objects. Next, we evaluate the constraints represented by\nOCCGs by analyzing Object-Centric Event Logs (OCELs) that store the interaction\nof different objects in events. We have implemented a web application to\nsupport the proposed approach and conducted two case studies using a real-life\nSAP ERP system.",
    "descriptor": "",
    "authors": [
      "Gyunam Park",
      "Wil. M. P. van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12080"
  },
  {
    "id": "arXiv:2210.12083",
    "title": "Do Content Management Systems Impact the Security of Free Content  Websites? A Correlation Analysis",
    "abstract": "This paper investigates the potential causes of the vulnerabilities of free\ncontent websites to address risks and maliciousness. Assembling more than 1,500\nwebsites with free and premium content, we identify their content management\nsystem (CMS) and malicious attributes. We use frequency analysis at both the\naggregate and per category of content (books, games, movies, music, and\nsoftware), utilizing the unpatched vulnerabilities, total vulnerabilities,\nmalicious count, and percentiles to uncover trends and affinities of usage and\nmaliciousness of CMS{'s} and their contribution to those websites. Moreover, we\nfind that, despite the significant number of custom code websites, the use of\nCMS{'s} is pervasive, with varying trends across types and categories. Finally,\nwe find that even a small number of unpatched vulnerabilities in popular\nCMS{'s} could be a potential cause for significant maliciousness.",
    "descriptor": "\nComments: 7 pages, 1 figure, 6 tables\n",
    "authors": [
      "Mohammed Alaqdhi",
      "Abdulrahman Alabduljabbar",
      "Kyle Thomas",
      "Saeed Salem",
      "DaeHun Nyang",
      "David Mohaisen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.12083"
  },
  {
    "id": "arXiv:2210.12084",
    "title": "Decoding a Neural Retriever's Latent Space for Query Suggestion",
    "abstract": "Neural retrieval models have superseded classic bag-of-words methods such as\nBM25 as the retrieval framework of choice. However, neural systems lack the\ninterpretability of bag-of-words models; it is not trivial to connect a query\nchange to a change in the latent space that ultimately determines the retrieval\nresults. To shed light on this embedding space, we learn a \"query decoder\"\nthat, given a latent representation of a neural search engine, generates the\ncorresponding query. We show that it is possible to decode a meaningful query\nfrom its latent representation and, when moving in the right direction in\nlatent space, to decode a query that retrieves the relevant paragraph. In\nparticular, the query decoder can be useful to understand \"what should have\nbeen asked\" to retrieve a particular paragraph from the collection. We employ\nthe query decoder to generate a large synthetic dataset of query reformulations\nfor MSMarco, leading to improved retrieval performance. On this data, we train\na pseudo-relevance feedback (PRF) T5 model for the application of query\nsuggestion that outperforms both query reformulation and PRF information\nretrieval baselines.",
    "descriptor": "",
    "authors": [
      "Leonard Adolphs",
      "Michelle Chen Huebscher",
      "Christian Buck",
      "Sertan Girgin",
      "Olivier Bachem",
      "Massimiliano Ciaramita",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12084"
  },
  {
    "id": "arXiv:2210.12086",
    "title": "Optimal Policies for Age and Distortion in a Discrete-Time Model",
    "abstract": "We study a discrete-time model where each packet has a cost of not being sent\n-- this cost might depend on the packet content. We study the tradeoff between\nthe age and the cost where the sender is confined to packet-based strategies.\nThe optimal tradeoff is found by an appropriate formulation of the problem as a\nMarkov Decision Process (MDP). We show that the optimal tradeoff can be\nattained with finite-memory policies and we devise an efficient policy\niteration algorithm to find these optimal policies. We further study a related\nproblem where the transmitted packets are subject to erasures. We show that the\noptimal policies for our problem are also optimal for this new setup. Allowing\ncoding across packets significantly extends the packet-based strategies. We\nshow that when the packet payloads are small, the performance can be improved\nby coding.",
    "descriptor": "\nComments: A short version of this work is presented at IEEE ITW 2021\n",
    "authors": [
      "Yunus Inan",
      "Reka Inovan",
      "Emre Telatar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.12086"
  },
  {
    "id": "arXiv:2210.12089",
    "title": "A Survey on Graph Counterfactual Explanations: Definitions, Methods,  Evaluation",
    "abstract": "In recent years, Graph Neural Networks have reported outstanding performance\nin tasks like community detection, molecule classification and link prediction.\nHowever, the black-box nature of these models prevents their application in\ndomains like health and finance, where understanding the models' decisions is\nessential. Counterfactual Explanations (CE) provide these understandings\nthrough examples. Moreover, the literature on CE is flourishing with novel\nexplanation methods which are tailored to graph learning.\nIn this survey, we analyse the existing Graph Counterfactual Explanation\nmethods, by providing the reader with an organisation of the literature\naccording to a uniform formal notation for definitions, datasets, and metrics,\nthus, simplifying potential comparisons w.r.t to the method advantages and\ndisadvantages. We discussed seven methods and sixteen synthetic and real\ndatasets providing details on the possible generation strategies. We highlight\nthe most common evaluation strategies and formalise nine of the metrics used in\nthe literature. We first introduce the evaluation framework GRETEL and how it\nis possible to extend and use it while providing a further dimension of\ncomparison encompassing reproducibility aspects. Finally, we provide a\ndiscussion on how counterfactual explanation interplays with privacy and\nfairness, before delving into open challenges and future works.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.04086 by other authors\n",
    "authors": [
      "Mario Alfonso Prado-Romero",
      "Bardh Prenkaj",
      "Giovanni Stilo",
      "Fosca Giannotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12089"
  },
  {
    "id": "arXiv:2210.12090",
    "title": "AutoPrognosis 2.0: Democratizing Diagnostic and Prognostic Modeling in  Healthcare with Automated Machine Learning",
    "abstract": "Diagnostic and prognostic models are increasingly important in medicine and\ninform many clinical decisions. Recently, machine learning approaches have\nshown improvement over conventional modeling techniques by better capturing\ncomplex interactions between patient covariates in a data-driven manner.\nHowever, the use of machine learning introduces a number of technical and\npractical challenges that have thus far restricted widespread adoption of such\ntechniques in clinical settings. To address these challenges and empower\nhealthcare professionals, we present a machine learning framework,\nAutoPrognosis 2.0, to develop diagnostic and prognostic models. AutoPrognosis\nleverages state-of-the-art advances in automated machine learning to develop\noptimized machine learning pipelines, incorporates model explainability tools,\nand enables deployment of clinical demonstrators, without requiring significant\ntechnical expertise. Our framework eliminates the major technical obstacles to\npredictive modeling with machine learning that currently impede clinical\nadoption. To demonstrate AutoPrognosis 2.0, we provide an illustrative\napplication where we construct a prognostic risk score for diabetes using the\nUK Biobank, a prospective study of 502,467 individuals. The models produced by\nour automated framework achieve greater discrimination for diabetes than expert\nclinical risk scores. Our risk score has been implemented as a web-based\ndecision support tool and can be publicly accessed by patients and clinicians\nworldwide. In addition, AutoPrognosis 2.0 is provided as an open-source python\npackage. By open-sourcing our framework as a tool for the community, clinicians\nand other medical practitioners will be able to readily develop new risk\nscores, personalized diagnostics, and prognostics using modern machine learning\ntechniques.",
    "descriptor": "",
    "authors": [
      "Fergus Imrie",
      "Bogdan Cebere",
      "Eoin F. McKinney",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12090"
  },
  {
    "id": "arXiv:2210.12091",
    "title": "Physical Layer Security in Random NOMA-Enabled Heterogeneous Networks",
    "abstract": "The performance of physical layer secrecy approach in non-orthogonal multiple\naccess (NOMA)-enabled heterogeneous networks (HetNets) is analyzed in this\npaper. A $K$-tier multi-cell HetNet is considered, comprising NOMA adopted in\nall tiers. The base stations, legitimate users (in a two-user NOMA setup), and\npassive eavesdroppers, all with single-antenna, are randomly distributed.\nAssuming independent Poisson point processes for node distribution, stochastic\ngeometry approaches are exploited to characterize the ergodic secrecy rate. A\nlower bound on the ergodic secrecy rate along with closed-form expressions for\nthe lower bound on the ergodic rates of the legitimate users in a special case\nare derived. Moreover, simpler expressions for the ergodic secrecy rate are\nobtained in the interference-limited regime with vanishing noise variance. The\neffect of multi-tier technology, NOMA, and physical layer secrecy are\ninvestigated using numerical results. The results reveal that applying HetNet\nto a secure multi-cell NOMA system improves the spectrum efficiency\nperformance.",
    "descriptor": "",
    "authors": [
      "Elmira Shahraki",
      "Mahtab Mirmohseni",
      "Hengameh Keshavarz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.12091"
  },
  {
    "id": "arXiv:2210.12092",
    "title": "Cyclic codes from low differentially uniform functions",
    "abstract": "Cyclic codes have many applications in consumer electronics, communication\nand data storage systems due to their efficient encoding and decoding\nalgorithms. An efficient approach to constructing cyclic codes is the sequence\napproach. In their articles [Discrete Math. 321, 2014] and [SIAM J. Discrete\nMath. 27(4), 2013], Ding and Zhou constructed several classes of cyclic codes\nfrom almost perfect nonlinear (APN) functions and planar functions over finite\nfields and presented some open problems on cyclic codes from highly nonlinear\nfunctions. This article focuses on these exciting works by investigating new\ninsights in this research direction. Specifically, its objective is twofold.\nThe first is to provide a complement with some former results and present\ncorrect proofs and statements on some known ones on the cyclic codes from the\nAPN functions. The second is studying the cyclic codes from some known\nfunctions processing low differential uniformity. Along with this article, we\nshall provide answers to some open problems presented in the literature. The\nfirst one concerns Open Problem 1, proposed by Ding and Zhou in Discrete Math.\n321, 2014. The two others are Open Problems 5.16 and 5.25, raised by Ding in\n[SIAM J. Discrete Math. 27(4), 2013].",
    "descriptor": "",
    "authors": [
      "Sihem Mesnager",
      "Minjia Shi",
      "Hongwei Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.12092"
  },
  {
    "id": "arXiv:2210.12095",
    "title": "Learning shape distributions from large databases of healthy organs:  applications to zero-shot and few-shot abnormal pancreas detection",
    "abstract": "We propose a scalable and data-driven approach to learn shape distributions\nfrom large databases of healthy organs. To do so, volumetric segmentation masks\nare embedded into a common probabilistic shape space that is learned with a\nvariational auto-encoding network. The resulting latent shape representations\nare leveraged to derive zeroshot and few-shot methods for abnormal shape\ndetection. The proposed distribution learning approach is illustrated on a\nlarge database of 1200 healthy pancreas shapes. Downstream qualitative and\nquantitative experiments are conducted on a separate test set of 224 pancreas\nfrom patients with mixed conditions. The abnormal pancreas detection AUC\nreached up to 65.41% in the zero-shot configuration, and 78.97% in the few-shot\nconfiguration with as few as 15 abnormal examples, outperforming a baseline\napproach based on the sole volume.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Rebeca V\u00e9til",
      "Cl\u00e9ment Abi Nader",
      "Alexandre B\u00f4ne",
      "Marie-Pierre Vullierme",
      "Marc-Michel Rohe\u00e9",
      "Pietro Gori",
      "Isabelle Bloch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12095"
  },
  {
    "id": "arXiv:2210.12096",
    "title": "Augmenting Multi-Turn Text-to-SQL Datasets with Self-Play",
    "abstract": "The task of context-dependent text-to-SQL aims to convert multi-turn user\nutterances to formal SQL queries. This is a challenging task due to both the\nscarcity of training data from which to learn complex contextual dependencies\nand to generalize to unseen databases. In this paper we explore augmenting the\ntraining datasets using self-play, which leverages contextual information to\nsynthesize new interactions to adapt the model to new databases. We first\ndesign a SQL-to-text model conditioned on a sampled goal query, which\nrepresents a user's intent, that then converses with a text-to-SQL semantic\nparser to generate new interactions. We then filter the synthesized\ninteractions and retrain the models with the augmented data. We find that\nself-play improves the accuracy of a strong baseline on SParC and CoSQL, two\nwidely used cross-domain text-to-SQL datasets. Our analysis shows that\nself-play simulates various conversational thematic relations, enhances\ncross-domain generalization and improves beam-search.",
    "descriptor": "",
    "authors": [
      "Qi Liu",
      "Zihuiwen Ye",
      "Tao Yu",
      "Phil Blunsom",
      "Linfeng Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12096"
  },
  {
    "id": "arXiv:2210.12098",
    "title": "Triplet Losses-based Matrix Factorization for Robust Recommendations",
    "abstract": "Much like other learning-based models, recommender systems can be affected by\nbiases in the training data. While typical evaluation metrics (e.g. hit rate)\nare not concerned with them, some categories of final users are heavily\naffected by these biases. In this work, we propose using multiple triplet\nlosses terms to extract meaningful and robust representations of users and\nitems. We empirically evaluate the soundness of such representations through\nseveral \"bias-aware\" evaluation metrics, as well as in terms of stability to\nchanges in the training set and agreement of the predictions variance w.r.t.\nthat of each user.",
    "descriptor": "",
    "authors": [
      "Flavio Giobergia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12098"
  },
  {
    "id": "arXiv:2210.12100",
    "title": "Boomerang: Local sampling on image manifolds using diffusion models",
    "abstract": "Diffusion models can be viewed as mapping points in a high-dimensional latent\nspace onto a low-dimensional learned manifold, typically an image manifold. The\nintermediate values between the latent space and image manifold can be\ninterpreted as noisy images which are determined by the noise scheduling scheme\nemployed during pre-training. We exploit this interpretation to introduce\nBoomerang, a local image manifold sampling approach using the dynamics of\ndiffusion models. We call it Boomerang because we first add noise to an input\nimage, moving it closer to the latent space, then bring it back to the image\nspace through diffusion dynamics. We use this method to generate images which\nare similar, but nonidentical, to the original input images on the image\nmanifold. We are able to set how close the generated image is to the original\nbased on how much noise we add. Additionally, the generated images have a\ndegree of stochasticity, allowing us to locally sample as many times as we want\nwithout repetition. We show three applications for which Boomerang can be used.\nFirst, we provide a framework for constructing privacy-preserving datasets\nhaving controllable degrees of anonymity. Second, we show how to use Boomerang\nfor data augmentation while staying on the image manifold. Third, we introduce\na framework for image super-resolution with 8x upsampling. Boomerang does not\nrequire any modification to the training of diffusion models and can be used\nwith pretrained models on a single, inexpensive GPU.",
    "descriptor": "",
    "authors": [
      "Lorenzo Luzi",
      "Ali Siahkoohi",
      "Paul M Mayer",
      "Josue Casco-Rodriguez",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12100"
  },
  {
    "id": "arXiv:2210.12101",
    "title": "Neural Network Approximations of PDEs Beyond Linearity: Representational  Perspective",
    "abstract": "A burgeoning line of research has developed deep neural networks capable of\napproximating the solutions to high dimensional PDEs, opening related lines of\ntheoretical inquiry focused on explaining how it is that these models appear to\nevade the curse of dimensionality. However, most theoretical analyses thus far\nhave been limited to linear PDEs. In this work, we take a step towards studying\nthe representational power of neural networks for approximating solutions to\nnonlinear PDEs. We focus on a class of PDEs known as \\emph{nonlinear elliptic\nvariational PDEs}, whose solutions minimize an \\emph{Euler-Lagrange} energy\nfunctional $\\mathcal{E}(u) = \\int_\\Omega L(\\nabla u) dx$. We show that if\ncomposing a function with Barron norm $b$ with $L$ produces a function of\nBarron norm at most $B_L b^p$, the solution to the PDE can be\n$\\epsilon$-approximated in the $L^2$ sense by a function with Barron norm\n$O\\left(\\left(dB_L\\right)^{p^{\\log(1/\\epsilon)}}\\right)$. By a classical result\ndue to Barron [1993], this correspondingly bounds the size of a 2-layer neural\nnetwork needed to approximate the solution. Treating $p, \\epsilon, B_L$ as\nconstants, this quantity is polynomial in dimension, thus showing neural\nnetworks can evade the curse of dimensionality. Our proof technique involves\nneurally simulating (preconditioned) gradient in an appropriate Hilbert space,\nwhich converges exponentially fast to the solution of the PDE, and such that we\ncan bound the increase of the Barron norm at each iterate. Our results subsume\nand substantially generalize analogous prior results for linear elliptic PDEs.",
    "descriptor": "",
    "authors": [
      "Tanya Marwah",
      "Zachary C. Lipton",
      "Jianfeng Lu",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.12101"
  },
  {
    "id": "arXiv:2210.12104",
    "title": "Towards transparent ANN wind turbine power curve models",
    "abstract": "Accurate wind turbine power curve models, which translate ambient conditions\ninto turbine power output, are crucial for wind energy to scale and fulfil its\nproposed role in the global energy transition. Machine learning methods, in\nparticular deep neural networks (DNNs), have shown significant advantages over\nparametric, physics-informed power curve modelling approaches. Nevertheless,\nthey are often criticised as opaque black boxes with no physical understanding\nof the system they model, which hinders their application in practice. We apply\nShapley values, a popular explainable artificial intelligence (XAI) method, to,\nfor the first time, uncover and validate the strategies learned by DNNs from\noperational wind turbine data. Our findings show that the trend towards ever\nlarger model architectures, driven by the focus on test-set performance, can\nresult in physically implausible model strategies, similar to the Clever Hans\neffect observed in classification. We, therefore, call for a more prominent\nrole of XAI methods in model selection and additionally offer a practical\nstrategy to use model explanations for wind turbine condition monitoring.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022 Workshop Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Simon Letzgus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.12104"
  },
  {
    "id": "arXiv:2210.12108",
    "title": "Adversarial Permutation Invariant Training for Universal Sound  Separation",
    "abstract": "Universal sound separation consists of separating mixes with arbitrary sounds\nof different types, and permutation invariant training (PIT) is used to train\nsource agnostic models that do so. In this work, we complement PIT with\nadversarial losses but find it challenging with the standard formulation used\nin speech source separation. We overcome this challenge with a novel\nI-replacement context-based adversarial loss, and by training with multiple\ndiscriminators. Our experiments show that by simply improving the loss (keeping\nthe same model and dataset) we obtain a non-negligible improvement of 1.4 dB\nSI-SNRi in the reverberant FUSS dataset. We also find adversarial PIT to be\neffective at reducing spectral holes, ubiquitous in mask-based separation\nmodels, which highlights the potential relevance of adversarial losses for\nsource separation.",
    "descriptor": "\nComments: Demo page: this http URL\n",
    "authors": [
      "Emilian Postolache",
      "Jordi Pons",
      "Santiago Pascual",
      "Joan Serr\u00e0"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.12108"
  },
  {
    "id": "arXiv:2210.12112",
    "title": "Describing Sets of Images with Textual-PCA",
    "abstract": "We seek to semantically describe a set of images, capturing both the\nattributes of single images and the variations within the set. Our procedure is\nanalogous to Principle Component Analysis, in which the role of projection\nvectors is replaced with generated phrases. First, a centroid phrase that has\nthe largest average semantic similarity to the images in the set is generated,\nwhere both the computation of the similarity and the generation are based on\npretrained vision-language models. Then, the phrase that generates the highest\nvariation among the similarity scores is generated, using the same models. The\nnext phrase maximizes the variance subject to being orthogonal, in the latent\nspace, to the highest-variance phrase, and the process continues. Our\nexperiments show that our method is able to convincingly capture the essence of\nimage sets and describe the individual elements in a semantically meaningful\nway within the context of the entire set. Our code is available at:\nhttps://github.com/OdedH/textual-pca.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP'22\n",
    "authors": [
      "Oded Hupert",
      "Idan Schwartz",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12112"
  },
  {
    "id": "arXiv:2210.12114",
    "title": "Modelling Control Arguments via Cooperation Logic in Unforeseen  Scenarios",
    "abstract": "The intent of control argumentation frameworks is to specifically model\nstrategic scenarios from the perspective of an agent by extending the standard\nmodel of argumentation framework in a way that takes unquantified uncertainty\nregarding arguments and attacks into account. They do not, however, adequately\naccount for coalition formation and interactions among a set of agents in an\nuncertain environment. To address this challenge, we propose a formalism of a\nmulti-agent scenario via cooperation logic and investigate agents' strategies\nand actions in a dynamic environment.",
    "descriptor": "\nComments: Thinking Fast and Slow in AI - AAAI 2022 Fall Symposium Series\n",
    "authors": [
      "Minal Suresh Patil"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12114"
  },
  {
    "id": "arXiv:2210.12115",
    "title": "Pedestrian Emergency Braking in Ten Weeks",
    "abstract": "In the last decade, research in the field of autonomous vehicles has grown\nimmensely, and there is a wealth of information available for researchers to\nrapidly establish an autonomous vehicle platform for basic maneuvers. In this\npaper, we design, implement, and test, in ten weeks, a PD approach to\nlongitudinal control for pedestrian emergency braking. We also propose a\nlateral controller with a similar design for future testing in lane following.\nUsing widely available tools, we demonstrate the safety of the vehicle in\npedestrian emergency braking scenarios.",
    "descriptor": "\nComments: Accepted for publication, 6 pages\n",
    "authors": [
      "Steven Nguyen",
      "Zillur Rahman",
      "Brendan Tan Morris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.12115"
  },
  {
    "id": "arXiv:2210.12116",
    "title": "Error analysis for a Crouzeix-Raviart approximation of the $p$-Dirichlet  problem",
    "abstract": "In the present paper, we examine a Crouzeix-Raviart approximation for\nnon-linear partial differential equations having a $(p,\\delta)$-structure for\nsome $p\\in (1,\\infty)$ and $\\delta\\ge 0$. We establish a priori error\nestimates, which are optimal for all $p\\in (1,\\infty)$ and $\\delta\\ge 0$,\nmedius error estimates, i.e., best-approximation results, and a primal-dual a\nposteriori error estimate, which is both reliable and efficient. The\ntheoretical findings are supported by numerical experiments.",
    "descriptor": "\nComments: 26 pages, 2 tables, 1 figure\n",
    "authors": [
      "Alex Kaltenbach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.12116"
  },
  {
    "id": "arXiv:2210.12122",
    "title": "Targeted active learning for probabilistic models",
    "abstract": "A fundamental task in science is to design experiments that yield valuable\ninsights about the system under study. Mathematically, these insights can be\nrepresented as a utility or risk function that shapes the value of conducting\neach experiment. We present PDBAL, a targeted active learning method that\nadaptively designs experiments to maximize scientific utility. PDBAL takes a\nuser-specified risk function and combines it with a probabilistic model of the\nexperimental outcomes to choose designs that rapidly converge on a high-utility\nmodel. We prove theoretical bounds on the label complexity of PDBAL and provide\nfast closed-form solutions for designing experiments with common exponential\nfamily likelihoods. In simulation studies, PDBAL consistently outperforms\nstandard untargeted approaches that focus on maximizing expected information\ngain over the design space. Finally, we demonstrate the scientific potential of\nPDBAL through a study on a large cancer drug screen dataset where PDBAL quickly\nrecovers the most efficacious drugs with a small fraction of the total number\nof experiments.",
    "descriptor": "",
    "authors": [
      "Christopher Tosh",
      "Mauricio Tec",
      "Wesley Tansey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12122"
  },
  {
    "id": "arXiv:2210.12124",
    "title": "Equivariant Networks for Zero-Shot Coordination",
    "abstract": "Successful coordination in Dec-POMDPs requires agents to adopt robust\nstrategies and interpretable styles of play for their partner. A common failure\nmode is symmetry breaking, when agents arbitrarily converge on one out of many\nequivalent but mutually incompatible policies. Commonly these examples include\npartial observability, e.g. waving your right hand vs. left hand to convey a\ncovert message. In this paper, we present a novel equivariant network\narchitecture for use in Dec-POMDPs that prevents the agent from learning\npolicies which break symmetries, doing so more effectively than prior methods.\nOur method also acts as a \"coordination-improvement operator\" for generic,\npre-trained policies, and thus may be applied at test-time in conjunction with\nany self-play algorithm. We provide theoretical guarantees of our work and test\non the AI benchmark task of Hanabi, where we demonstrate our methods\noutperforming other symmetry-aware baselines in zero-shot coordination, as well\nas able to improve the coordination ability of a variety of pre-trained\npolicies. In particular, we show our method can be used to improve on the state\nof the art for zero-shot coordination on the Hanabi benchmark.",
    "descriptor": "",
    "authors": [
      "Darius Muglich",
      "Christian Schroeder de Witt",
      "Elise van der Pol",
      "Shimon Whiteson",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12124"
  },
  {
    "id": "arXiv:2210.12126",
    "title": "Neural Fields for Robotic Object Manipulation from a Single Image",
    "abstract": "We present a unified and compact representation for object rendering, 3D\nreconstruction, and grasp pose prediction that can be inferred from a single\nimage within a few seconds. We achieve this by leveraging recent advances in\nthe Neural Radiance Field (NeRF) literature that learn category-level priors\nand fine-tune on novel objects with minimal data and time. Our insight is that\nwe can learn a compact shape representation and extract meaningful additional\ninformation from it, such as grasping poses. We believe this to be the first\nwork to retrieve grasping poses directly from a NeRF-based representation using\na single viewpoint (RGB-only), rather than going through a secondary network\nand/or representation. When compared to prior art, our method is two to three\norders of magnitude smaller while achieving comparable performance at view\nreconstruction and grasping. Accompanying our method, we also propose a new\ndataset of rendered shoes for training a sim-2-real NeRF method with grasping\nposes for different widths of grippers.",
    "descriptor": "\nComments: This is a reduced version of a paper submitted to ICRA 2023\n",
    "authors": [
      "Valts Blukis",
      "Taeyeop Lee",
      "Jonathan Tremblay",
      "Bowen Wen",
      "In So Kweon",
      "Kuk-Jin Yoon",
      "Dieter Fox",
      "Stan Birchfield"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12126"
  },
  {
    "id": "arXiv:2210.12130",
    "title": "Graph Few-shot Learning with Task-specific Structures",
    "abstract": "Graph few-shot learning is of great importance among various graph learning\ntasks. Under the few-shot scenario, models are often required to conduct\nclassification given limited labeled samples. Existing graph few-shot learning\nmethods typically leverage Graph Neural Networks (GNNs) and perform\nclassification across a series of meta-tasks. Nevertheless, these methods\ngenerally rely on the original graph (i.e., the graph that the meta-task is\nsampled from) to learn node representations. Consequently, the graph structure\nused in each meta-task is identical. Since the class sets are different across\nmeta-tasks, node representations should be learned in a task-specific manner to\npromote classification performance. Therefore, to adaptively learn node\nrepresentations across meta-tasks, we propose a novel framework that learns a\ntask-specific structure for each meta-task. To handle the variety of nodes\nacross meta-tasks, we extract relevant nodes and learn task-specific structures\nbased on node influence and mutual information. In this way, we can learn node\nrepresentations with the task-specific structure tailored for each meta-task.\nWe further conduct extensive experiments on five node classification datasets\nunder both single- and multiple-graph settings to validate the superiority of\nour framework over the state-of-the-art baselines. Our code is provided at\nhttps://github.com/SongW-SW/GLITTER.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Song Wang",
      "Chen Chen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.12130"
  },
  {
    "id": "arXiv:2210.12134",
    "title": "Audio-to-Intent Using Acoustic-Textual Subword Representations from  End-to-End ASR",
    "abstract": "Accurate prediction of the user intent to interact with a voice assistant\n(VA) on a device (e.g. on the phone) is critical for achieving naturalistic,\nengaging, and privacy-centric interactions with the VA. To this end, we present\na novel approach to predict the user's intent (the user speaking to the device\nor not) directly from acoustic and textual information encoded at subword\ntokens which are obtained via an end-to-end ASR model. Modeling directly the\nsubword tokens, compared to modeling of the phonemes and/or full words, has at\nleast two advantages: (i) it provides a unique vocabulary representation, where\neach token has a semantic meaning, in contrast to the phoneme-level\nrepresentations, (ii) each subword token has a reusable \"sub\"-word acoustic\npattern (that can be used to construct multiple full words), resulting in a\nlargely reduced vocabulary space than of the full words. To learn the subword\nrepresentations for the audio-to-intent classification, we extract: (i)\nacoustic information from an E2E-ASR model, which provides frame-level CTC\nposterior probabilities for the subword tokens, and (ii) textual information\nfrom a pre-trained continuous bag-of-words model capturing the semantic meaning\nof the subword tokens. The key to our approach is the way it combines acoustic\nsubword-level posteriors with text information using the notion of\npositional-encoding in order to account for multiple ASR hypotheses\nsimultaneously. We show that our approach provides more robust and richer\nrepresentations for audio-to-intent classification, and is highly accurate with\ncorrectly mitigating 93.3% of unintended user audio from invoking the smart\nassistant at 99% true positive rate.",
    "descriptor": "",
    "authors": [
      "Pranay Dighe",
      "Prateeth Nayak",
      "Oggi Rudovic",
      "Erik Marchi",
      "Xiaochuan Niu",
      "Ahmed Tewfik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.12134"
  },
  {
    "id": "arXiv:2210.12135",
    "title": "Geometric Sparse Coding in Wasserstein Space",
    "abstract": "Wasserstein dictionary learning is an unsupervised approach to learning a\ncollection of probability distributions that generate observed distributions as\nWasserstein barycentric combinations. Existing methods for Wasserstein\ndictionary learning optimize an objective that seeks a dictionary with\nsufficient representation capacity via barycentric interpolation to approximate\nthe observed training data, but without imposing additional structural\nproperties on the coefficients associated to the dictionary. This leads to\ndictionaries that densely represent the observed data, which makes\ninterpretation of the coefficients challenging and may also lead to poor\nempirical performance when using the learned coefficients in downstream tasks.\nIn contrast and motivated by sparse dictionary learning in Euclidean spaces, we\npropose a geometrically sparse regularizer for Wasserstein space that promotes\nrepresentations of a data point using only nearby dictionary elements. We show\nthis approach leads to sparse representations in Wasserstein space and\naddresses the problem of non-uniqueness of barycentric representation.\nMoreover, when data is generated as Wasserstein barycenters of fixed\ndistributions, this regularizer facilitates the recovery of the generating\ndistributions in cases that are ill-posed for unregularized Wasserstein\ndictionary learning. Through experimentation on synthetic and real data, we\nshow that our geometrically regularized approach yields sparser and more\ninterpretable dictionaries in Wasserstein space, which perform better in\ndownstream applications.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Marshall Mueller",
      "Shuchin Aeron",
      "James M. Murphy",
      "Abiy Tasissa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.12135"
  },
  {
    "id": "arXiv:2210.12137",
    "title": "A Multi-Scale Deep Learning Framework for Projecting Weather Extremes",
    "abstract": "Weather extremes are a major societal and economic hazard, claiming thousands\nof lives and causing billions of dollars in damage every year. Under climate\nchange, their impact and intensity are expected to worsen significantly.\nUnfortunately, general circulation models (GCMs), which are currently the\nprimary tool for climate projections, cannot characterize weather extremes\naccurately. To address this, we present a multi-resolution deep-learning\nframework that, firstly, corrects a GCM's biases by matching low-order and tail\nstatistics of its output with observations at coarse scales; and secondly,\nincreases the level of detail of the debiased GCM output by reconstructing the\nfiner scales as a function of the coarse scales. We use the proposed framework\nto generate statistically realistic realizations of the climate over Western\nEurope from a simple GCM corrected using observational atmospheric reanalysis.\nWe also discuss implications for probabilistic risk assessment of natural\ndisasters in a changing climate.",
    "descriptor": "",
    "authors": [
      "Antoine Blanchard",
      "Nishant Parashar",
      "Boyko Dodov",
      "Christian Lessig",
      "Themistoklis Sapsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.12137"
  },
  {
    "id": "arXiv:2210.12140",
    "title": "Explainability in autonomous pedagogically structured scenarios",
    "abstract": "We present the notion of explainability for decision-making processes in a\npedagogically structured autonomous environment. Multi-agent systems that are\nstructured pedagogically consist of pedagogical teachers and learners that\noperate in environments in which both are sometimes not fully aware of all the\nstates in the environment and beliefs of other agents thus making it\nchallenging to explain their decisions and actions with one another. This work\nemphasises the need for robust and iterative explanation-based communication\nbetween the pedagogical teacher and the learner. Explaining the rationale\nbehind multi-agent decisions in an interactive, partially observable\nenvironment is necessary to build trustworthy and reliable communication\nbetween pedagogical teachers and learners. Ongoing research is primarily\nfocused on explanations of the agents' behaviour towards humans, and there is a\nlack of research on inter-agent explainability.",
    "descriptor": "\nComments: Explainable Agency in Artificial Intelligence Workshop - 36th AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Minal Suresh Patil"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.12140"
  },
  {
    "id": "arXiv:2210.12148",
    "title": "Unsupervised Multi-object Segmentation by Predicting Probable Motion  Patterns",
    "abstract": "We propose a new approach to learn to segment multiple image objects without\nmanual supervision. The method can extract objects form still images, but uses\nvideos for supervision. While prior works have considered motion for\nsegmentation, a key insight is that, while motion can be used to identify\nobjects, not all objects are necessarily in motion: the absence of motion does\nnot imply the absence of objects. Hence, our model learns to predict image\nregions that are likely to contain motion patterns characteristic of objects\nmoving rigidly. It does not predict specific motion, which cannot be done\nunambiguously from a still image, but a distribution of possible motions, which\nincludes the possibility that an object does not move at all. We demonstrate\nthe advantage of this approach over its deterministic counterpart and show\nstate-of-the-art unsupervised object segmentation performance on simulated and\nreal-world benchmarks, surpassing methods that use motion even at test time. As\nour approach is applicable to variety of network architectures that segment the\nscenes, we also apply it to existing image reconstruction-based models showing\ndrastic improvement. Project page and code:\nhttps://www.robots.ox.ac.uk/~vgg/research/ppmp .",
    "descriptor": "",
    "authors": [
      "Laurynas Karazija",
      "Subhabrata Choudhury",
      "Iro Laina",
      "Christian Rupprecht",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12148"
  },
  {
    "id": "arXiv:2210.12150",
    "title": "Formalizing Chemical Theory using the Lean Theorem Prover",
    "abstract": "Chemical theory can be made more rigorous using the Lean theorem prover, an\ninteractive theorem prover for complex mathematics. We formalize the Langmuir\nand BET theories of adsorption, making each scientific premise clear and every\nstep of the derivations explicit. Lean's math library, mathlib, provides\nformally verified theorems for infinite geometries series, which are central to\nBET theory. While writing these proofs, Lean prompts us to include mathematical\nconstraints that were not originally reported. We also illustrate how Lean\nflexibly enables the reuse of proofs that build on more complex theories\nthrough the use of functions, definitions, and structures. Finally, we\nconstruct scientific frameworks for interoperable proofs, by creating\nstructures for classical thermodynamics and kinematics, using them to formalize\ngas law relationships like Boyle's Law and equations of motion underlying\nNewtonian mechanics, respectively. This approach can be extended to other\nfields, enabling the formalization of rich and complex theories in science and\nengineering.",
    "descriptor": "",
    "authors": [
      "Maxwell P. Bobbin",
      "Samiha Sharlin",
      "Parivash Feyzishendi",
      "An Hong Dang",
      "Catherine M. Wraback",
      "Tyler R. Josephson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.12150"
  },
  {
    "id": "arXiv:2210.12152",
    "title": "WikiWhy: Answering and Explaining Cause-and-Effect Questions",
    "abstract": "As large language models (LLMs) grow larger and more sophisticated, assessing\ntheir \"reasoning\" capabilities in natural language grows more challenging.\nRecent question answering (QA) benchmarks that attempt to assess reasoning are\noften limited by a narrow scope of covered situations and subject matters. We\nintroduce WikiWhy, a QA dataset built around a novel auxiliary task: explaining\nwhy an answer is true in natural language. WikiWhy contains over 9,000 \"why\"\nquestion-answer-rationale triples, grounded on Wikipedia facts across a diverse\nset of topics. Each rationale is a set of supporting statements connecting the\nquestion to the answer. WikiWhy serves as a benchmark for the reasoning\ncapabilities of LLMs because it demands rigorous explicit rationales for each\nanswer to demonstrate the acquisition of implicit commonsense knowledge, which\nis unlikely to be easily memorized. GPT-3 baselines achieve only 38.7%\nhuman-evaluated correctness in the end-to-end answer & explain condition,\nleaving significant room for future improvements.",
    "descriptor": "",
    "authors": [
      "Matthew Ho",
      "Aditya Sharma",
      "Justin Chang",
      "Michael Saxon",
      "Sharon Levy",
      "Yujie Lu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12152"
  },
  {
    "id": "arXiv:2210.12153",
    "title": "On amortizing convex conjugates for optimal transport",
    "abstract": "This paper focuses on computing the convex conjugate operation that arises\nwhen solving Euclidean Wasserstein-2 optimal transport problems. This\nconjugation, which is also referred to as the Legendre-Fenchel conjugate or\n$c$-transform, is considered difficult to compute and in practice,\nWasserstein-2 methods are limited by not being able to exactly conjugate the\ndual potentials in continuous space. I show that combining amortized\napproximations to the conjugate with a solver for fine-tuning is\ncomputationally easy. This combination significantly improves the quality of\ntransport maps learned for the Wasserstein-2 benchmark by Korotin et al. (2021)\nand is able to model many 2-dimensional couplings and flows considered in the\nliterature. All of the baselines, methods, and solvers in this paper are\navailable at this http URL",
    "descriptor": "",
    "authors": [
      "Brandon Amos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.12153"
  },
  {
    "id": "arXiv:2112.12572",
    "title": "Are E2E ASR models ready for an industrial usage?",
    "abstract": "The Automated Speech Recognition (ASR) community experiences a major turning\npoint with the rise of the fully-neural (End-to-End, E2E) approaches. At the\nsame time, the conventional hybrid model remains the standard choice for the\npractical usage of ASR. According to previous studies, the adoption of E2E ASR\nin real-world applications was hindered by two main limitations: their ability\nto generalize on unseen domains and their high operational cost. In this paper,\nwe investigate both above-mentioned drawbacks by performing a comprehensive\nmulti-domain benchmark of several contemporary E2E models and a hybrid\nbaseline. Our experiments demonstrate that E2E models are viable alternatives\nfor the hybrid approach, and even outperform the baseline both in accuracy and\nin operational efficiency. As a result, our study shows that the generalization\nand complexity issues are no longer the major obstacle for industrial\nintegration, and draws the community's attention to other potential limitations\nof the E2E approaches in some specific use-cases.",
    "descriptor": "",
    "authors": [
      "Valentin Vielzeuf",
      "Grigory Antipov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.12572"
  },
  {
    "id": "arXiv:2210.11478",
    "title": "Neural Co-Processors for Restoring Brain Function: Results from a  Cortical Model of Grasping",
    "abstract": "Objective: A major challenge in closed-loop brain-computer interfaces (BCIs)\nis finding optimal stimulation patterns as a function of ongoing neural\nactivity for different subjects and objectives. Traditional approaches, such as\nthose currently used for deep brain stimulation, have largely followed a trial-\nand-error strategy to search for effective open-loop stimulation parameters, a\nstrategy that is inefficient and does not generalize to closed-loop\nactivity-dependent stimulation. Approach: To achieve goal-directed closed-loop\nneurostimulation, we propose the use of brain co-processors, devices which\nexploit artificial intelligence (AI) to shape neural activity and bridge\ninjured neural circuits for targeted repair and rehabilitation. Here we\ninvestigate a specific type of co-processor called a \"neural co-processor\"\nwhich uses artificial neural networks (ANNs) to learn optimal closed-loop\nstimulation policies. The co-processor adapts the stimulation policy as the\nbiological circuit itself adapts to the stimulation, achieving a form of\nbrain-device co-adaptation. We tested the neural co-processor's ability to\nrestore function after stroke by simulating a variety of lesions in a\npreviously published cortical model of grasping. Main results: Our results show\nthat a neural co-processor can restore reaching and grasping function after a\nsimulated stroke in a cortical model, achieving recovery towards healthy\nfunction in the range 75-90%. Significance: This is the first proof-of-concept\ndemonstration, using computer simulations, of a neural co-processor for\nactivity-dependent closed-loop neurosimulation for optimizing a rehabilitation\ngoal after injury. Our results provide insights on how such co-processors may\neventually be developed for in vivo use to learn complex adaptive stimulation\npolicies for a variety of neural rehabilitation and neuroprosthetic\napplications.",
    "descriptor": "\nComments: 37 pages, 16 figures. Submitted the IOP Journal of Neural Engineering\n",
    "authors": [
      "Matthew J. Bryan",
      "Linxing Preston Jiang",
      "Rajesh P N Rao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11478"
  },
  {
    "id": "arXiv:2210.11482",
    "title": "A Methodology for the Prediction of Drug Target Interaction using CDK  Descriptors",
    "abstract": "Detecting probable Drug Target Interaction (DTI) is a critical task in drug\ndiscovery. Conventional DTI studies are expensive, labor-intensive, and take a\nlot of time, hence there are significant reasons to construct useful\ncomputational techniques that may successfully anticipate possible DTIs.\nAlthough certain methods have been developed for this cause, numerous\ninteractions are yet to be discovered, and prediction accuracy is still low. To\nmeet these challenges, we propose a DTI prediction model built on molecular\nstructure of drugs and sequence of target proteins. In the proposed model, we\nuse Simplified Molecular Input Line Entry System (SMILES) to create CDK\ndescriptors, Molecular ACCess System (MACCS) fingerprints, Electrotopological\nstate (Estate) fingerprints and amino acid sequences of targets to get Pseudo\nAmino Acid Composition (PseAAC). We target to evaluate performance of DTI\nprediction models using CDK descriptors. For comparison, we use benchmark data\nand evaluate models performance on two widely used fingerprints, MACCS\nfingerprints and Estate fingerprints. The evaluation of performances shows that\nCDK descriptors are superior at predicting DTIs. The proposed method also\noutperforms other previously published techniques significantly.",
    "descriptor": "\nComments: 12 pages, Accepted in ICONIP 2022\n",
    "authors": [
      "Tanya Liyaqat",
      "Tanvir Ahmad",
      "Chandni Saxena"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11482"
  },
  {
    "id": "arXiv:2210.11489",
    "title": "Machine-Learning Compression for Particle Physics Discoveries",
    "abstract": "In collider-based particle and nuclear physics experiments, data are produced\nat such extreme rates that only a subset can be recorded for later analysis.\nTypically, algorithms select individual collision events for preservation and\nstore the complete experimental response. A relatively new alternative strategy\nis to additionally save a partial record for a larger subset of events,\nallowing for later specific analysis of a larger fraction of events. We propose\na strategy that bridges these paradigms by compressing entire events for\ngeneric offline analysis but at a lower fidelity. An optimal-transport-based\n$\\beta$ Variational Autoencoder (VAE) is used to automate the compression and\nthe hyperparameter $\\beta$ controls the compression fidelity. We introduce a\nnew approach for multi-objective learning functions by simultaneously learning\na VAE appropriate for all values of $\\beta$ through parameterization. We\npresent an example use case, a di-muon resonance search at the Large Hadron\nCollider (LHC), where we show that simulated data compressed by our $\\beta$-VAE\nhas enough fidelity to distinguish distinct signal morphologies.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Jack H. Collins",
      "Yifeng Huang",
      "Simon Knapen",
      "Benjamin Nachman",
      "Daniel Whiteson"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.11489"
  },
  {
    "id": "arXiv:2210.11519",
    "title": "Discriminatory and orthogonal feature learning for noise robust keyword  spotting",
    "abstract": "Keyword Spotting (KWS) is an essential component in a smart device for\nalerting the system when a user prompts it with a command. As these devices are\ntypically constrained by computational and energy resources, the KWS model\nshould be designed with a small footprint. In our previous work, we developed\nlightweight dynamic filters which extract a robust feature map within a noisy\nenvironment. The learning variables of the dynamic filter are jointly optimized\nwith KWS weights by using Cross-Entropy (CE) loss. CE loss alone, however, is\nnot sufficient for high performance when the SNR is low. In order to train the\nnetwork for more robust performance in noisy environments, we introduce the LOw\nVariant Orthogonal (LOVO) loss. The LOVO loss is composed of a triplet loss\napplied on the output of the dynamic filter, a spectral norm-based orthogonal\nloss, and an inner class distance loss applied in the KWS model. These losses\nare particularly useful in encouraging the network to extract discriminatory\nfeatures in unseen noise environments.",
    "descriptor": "\nComments: Published in SPL\n",
    "authors": [
      "Donghyeon Kim",
      "Kyungdeuk Ko",
      "David K. Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11519"
  },
  {
    "id": "arXiv:2210.11523",
    "title": "Quantum Machine Learning using the ZXW-Calculus",
    "abstract": "The field of quantum machine learning (QML) explores how quantum computers\ncan be used to more efficiently solve machine learning problems. As an\napplication of hybrid quantum-classical algorithms, it promises a potential\nquantum advantages in the near term. In this thesis, we use the ZXW-calculus to\ndiagrammatically analyse two key problems that QML applications face.\nFirst, we discuss algorithms to compute gradients on quantum hardware that\nare needed to perform gradient-based optimisation for QML. Concretely, we give\nnew diagrammatic proofs of the common 2- and 4-term parameter shift rules used\nin the literature. Additionally, we derive a novel, generalised parameter shift\nrule with 2n terms that is applicable to gates that can be represented with n\nparametrised spiders in the ZXW-calculus. Furthermore, to the best of our\nknowledge, we give the first proof of a conjecture by Anselmetti et al. by\nproving a no-go theorem ruling out more efficient alternatives to the 4-term\nshift rule.\nSecondly, we analyse the gradient landscape of quantum ans\\\"atze for barren\nplateaus using both empirical and analytical techniques. Concretely, we develop\na tool that automatically calculates the variance of gradients and use it to\ndetect likely barren plateaus in commonly used quantum ans\\\"atze. Furthermore,\nwe formally prove the existence or absence of barren plateaus for a selection\nof ans\\\"atze using diagrammatic techniques from the ZXW-calculus.",
    "descriptor": "\nComments: Master's thesis\n",
    "authors": [
      "Mark Koch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.11523"
  },
  {
    "id": "arXiv:2210.11530",
    "title": "Theoretical analysis of deep neural networks for temporally dependent  observations",
    "abstract": "Deep neural networks are powerful tools to model observations over time with\nnon-linear patterns. Despite the widespread use of neural networks in such\nsettings, most theoretical developments of deep neural networks are under the\nassumption of independent observations, and theoretical results for temporally\ndependent observations are scarce. To bridge this gap, we study theoretical\nproperties of deep neural networks on modeling non-linear time series data.\nSpecifically, non-asymptotic bounds for prediction error of (sparse)\nfeed-forward neural network with ReLU activation function is established under\nmixing-type assumptions. These assumptions are mild such that they include a\nwide range of time series models including auto-regressive models. Compared to\nindependent observations, established convergence rates have additional\nlogarithmic factors to compensate for additional complexity due to dependence\namong data points. The theoretical results are supported via various numerical\nsimulation settings as well as an application to a macroeconomic data set.",
    "descriptor": "\nComments: 23 pages, 18 pages, accepted for publication in Neural Information Processing Systems\n",
    "authors": [
      "Mingliang Ma",
      "Abolfazl Safikhani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11530"
  },
  {
    "id": "arXiv:2210.11532",
    "title": "DNN-ForwardTesting: A New Trading Strategy Validation using Statistical  Timeseries Analysis and Deep Neural Networks",
    "abstract": "In general, traders test their trading strategies by applying them on the\nhistorical market data (backtesting), and then apply to the future trades the\nstrategy that achieved the maximum profit on such past data.\nIn this paper, we propose a new trading strategy, called DNN-forwardtesting,\nthat determines the strategy to apply by testing it on the possible future\npredicted by a deep neural network that has been designed to perform stock\nprice forecasts and trained with the market historical data.\nIn order to generate such an historical dataset, we first perform an\nexploratory data analysis on a set of ten securities and, in particular,\nanalize their volatility through a novel k-means-based procedure. Then, we\nrestrict the dataset to a small number of assets with the same volatility\ncoefficient and use such data to train a deep feed-forward neural network that\nforecasts the prices for the next 30 days of open stocks market. Finally, our\ntrading system calculates the most effective technical indicator by applying it\nto the DNNs predictions and uses such indicator to guide its trades.\nThe results confirm that neural networks outperform classical statistical\ntechniques when performing such forecasts, and their predictions allow to\nselect a trading strategy that, when applied to the real future, increases\nExpectancy, Sharpe, Sortino, and Calmar ratios with respect to the strategy\nselected through traditional backtesting.",
    "descriptor": "",
    "authors": [
      "Ivan Letteri",
      "Giuseppe Della Penna",
      "Giovanni De Gasperis",
      "Abeer Dyoub"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11532"
  },
  {
    "id": "arXiv:2210.11538",
    "title": "An Improved Algorithm for Clustered Federated Learning",
    "abstract": "In this paper, we address the dichotomy between heterogeneous models and\nsimultaneous training in Federated Learning (FL) via a clustering framework. We\ndefine a new clustering model for FL based on the (optimal) local models of the\nusers: two users belong to the same cluster if their local models are close;\notherwise they belong to different clusters. A standard algorithm for clustered\nFL is proposed in \\cite{ghosh_efficient_2021}, called \\texttt{IFCA}, which\nrequires \\emph{suitable} initialization and the knowledge of hyper-parameters\nlike the number of clusters (which is often quite difficult to obtain in\npractical applications) to converge. We propose an improved algorithm,\n\\emph{Successive Refine Federated Clustering Algorithm} (\\texttt{SR-FCA}),\nwhich removes such restrictive assumptions. \\texttt{SR-FCA} treats each user as\na singleton cluster as an initialization, and then successively refine the\ncluster estimation via exploiting similar users belonging to the same cluster.\nIn any intermediate step, \\texttt{SR-FCA} uses a robust federated learning\nalgorithm within each cluster to exploit simultaneous training and to correct\nclustering errors. Furthermore, \\texttt{SR-FCA} does not require any\n\\emph{good} initialization (warm start), both in theory and practice. We show\nthat with proper choice of learning rate, \\texttt{SR-FCA} incurs arbitrarily\nsmall clustering error. Additionally, we validate the performance of our\nalgorithm on standard FL datasets in non-convex problems like neural nets, and\nwe show the benefits of \\texttt{SR-FCA} over baselines.",
    "descriptor": "",
    "authors": [
      "Harshvardhan",
      "Avishek Ghosh",
      "Arya Mazumdar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11538"
  },
  {
    "id": "arXiv:2210.11562",
    "title": "Local SGD in Overparameterized Linear Regression",
    "abstract": "We consider distributed learning using constant stepsize SGD (DSGD) over\nseveral devices, each sending a final model update to a central server. In a\nfinal step, the local estimates are aggregated. We prove in the setting of\noverparameterized linear regression general upper bounds with matching lower\nbounds and derive learning rates for specific data generating distributions. We\nshow that the excess risk is of order of the variance provided the number of\nlocal nodes grows not too large with the global sample size. We further compare\nthe sample complexity of DSGD with the sample complexity of distributed ridge\nregression (DRR) and show that the excess SGD-risk is smaller than the excess\nRR-risk, where both sample complexities are of the same order.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Mike Nguyen",
      "Charly Kirst",
      "Nicole M\u00fccke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11562"
  },
  {
    "id": "arXiv:2210.11568",
    "title": "Polynomial computational complexity of matrix elements of  finite-rank-generated single-particle operators in products of finite bosonic  states",
    "abstract": "It is known that computing the permanent $\\mathop{\\rm Per}(1+A)$, where $A$\nis a finite-rank matrix requires a number of operations polynomial in the\nmatrix size. I generalize this result to the expectation values\n$\\left\\langle\\Psi| P(1+A) |\\Psi\\right\\rangle$, where $P()$ is the\nmultiplicative extension of a single-particle operator and\n$\\left|\\Psi\\right\\rangle$ is a product of a large number of identical finite\nbosonic states (i.e. bosonic states with a bounded number of bosons). I also\nimprove an earlier polynomial estimate for the fermionic version of the same\nproblem.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Dmitri A. Ivanov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.11568"
  },
  {
    "id": "arXiv:2210.11576",
    "title": "Monotonicity and Contraction on Polyhedral Cones",
    "abstract": "In this note, we study incremental stability of monotone dynamical systems\nwith respect to polyhedral cones. Using the half-space representation and the\nvertex representation, we propose three equivalent conditions to certify\nmonotonicity of a dynamical system with respect to a polyhedral cone. We then\nintroduce the notion of gauge norm associated with a cone and provide\nclosed-from formulas for computing gauge norms associated with polyhedral\ncones. A key feature of gauge norms is that contractivity of monotone systems\nwith respect to them can be efficiently characterized using simple\ninequalities. This result generalizes the well-known criteria for Hurwitzness\nof Metzler matrices and provides a scalable approach to search for Lyapunov\nfunctions of monotone systems with respect to polyhedral cones. Finally, we\nstudy the applications of our results in transient stability of dynamic flow\nnetworks and in scalable control design with safety guarantees.",
    "descriptor": "",
    "authors": [
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11576"
  },
  {
    "id": "arXiv:2210.11577",
    "title": "Global Convergence of Direct Policy Search for State-Feedback  $\\mathcal{H}_\\infty$ Robust Control: A Revisit of Nonsmooth Synthesis with  Goldstein Subdifferential",
    "abstract": "Direct policy search has been widely applied in modern reinforcement learning\nand continuous control. However, the theoretical properties of direct policy\nsearch on nonsmooth robust control synthesis have not been fully understood.\nThe optimal $\\mathcal{H}_\\infty$ control framework aims at designing a policy\nto minimize the closed-loop $\\mathcal{H}_\\infty$ norm, and is arguably the most\nfundamental robust control paradigm. In this work, we show that direct policy\nsearch is guaranteed to find the global solution of the robust\n$\\mathcal{H}_\\infty$ state-feedback control design problem. Notice that policy\nsearch for optimal $\\mathcal{H}_\\infty$ control leads to a constrained\nnonconvex nonsmooth optimization problem, where the nonconvex feasible set\nconsists of all the policies stabilizing the closed-loop dynamics. We show that\nfor this nonsmooth optimization problem, all Clarke stationary points are\nglobal minimum. Next, we identify the coerciveness of the closed-loop\n$\\mathcal{H}_\\infty$ objective function, and prove that all the sublevel sets\nof the resultant policy search problem are compact. Based on these properties,\nwe show that Goldstein's subgradient method and its implementable variants can\nbe guaranteed to stay in the nonconvex feasible set and eventually find the\nglobal optimal solution of the $\\mathcal{H}_\\infty$ state-feedback synthesis\nproblem. Our work builds a new connection between nonconvex nonsmooth\noptimization theory and robust control, leading to an interesting global\nconvergence result for direct policy search on optimal $\\mathcal{H}_\\infty$\nsynthesis.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Xingang Guo",
      "Bin Hu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11577"
  },
  {
    "id": "arXiv:2210.11588",
    "title": "Anchored Speech Recognition with Neural Transducers",
    "abstract": "Neural transducers have gained popularity in production ASR systems,\nachieving human level recognition accuracy on standard benchmark datasets.\nHowever, their performance significantly degrades in the presence of\ncrosstalks, especially when the background speech/noise is non-negligible as\ncompared to the primary speech (i.e. low signal-to-noise ratio). Anchored\nspeech recognition refers to a class of methods that use information from an\nanchor segment (e.g., wake-words) to recognize device-directed speech while\nignoring interfering background speech/noise. In this paper, we investigate\nanchored speech recognition in the context of neural transducers. We use a tiny\nauxiliary network to extract context information from the anchor segment, and\nexplore encoder biasing and joiner gating to guide the transducer towards the\ntarget speech. Moreover, to improve the robustness of context embedding\nextraction, we propose auxiliary training objectives to disentagle lexical\ncontent from speaking style. Our proposed methods are evaluated on synthetic\nLibriSpeech-based mixtures, where they improve word error rates by up to 36%\ncompared to a background augmentation baseline.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Desh Raj",
      "Junteng Jia",
      "Jay Mahadeokar",
      "Chunyang Wu",
      "Niko Moritz",
      "Xiaohui Zhang",
      "Ozlem Kalinli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11588"
  },
  {
    "id": "arXiv:2210.11612",
    "title": "Searching for a higher power in the human evaluation of MT",
    "abstract": "In MT evaluation, pairwise comparisons are conducted to identify the better\nsystem. In conducting the comparison, the experimenter must allocate a budget\nto collect Direct Assessment (DA) judgments. We provide a cost effective way to\nspend the budget, but show that typical budget sizes often do not allow for\nsolid comparison. Taking the perspective that the basis of solid comparison is\nin achieving statistical significance, we study the power (rate of achieving\nsignificance) on a large collection of pairwise DA comparisons. Due to the\nnature of statistical estimation, power is low for differentiating less than\n1-2 DA points, and to achieve a notable increase in power requires at least\n2-3x more samples. Applying variance reduction alone will not yield these\ngains, so we must face the reality of undetectable differences and spending\nincreases. In this context, we propose interim testing, an \"early stopping\"\ncollection procedure that yields more power per judgment collected, which\nadaptively focuses the budget on pairs that are borderline significant. Interim\ntesting can achieve up to a 27% efficiency gain when spending 3x the current\nbudget, or 18% savings at the current evaluation power.",
    "descriptor": "\nComments: WMT 2022\n",
    "authors": [
      "Johnny Tian-Zheng Wei",
      "Tom Kocmi",
      "Christian Federmann"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11612"
  },
  {
    "id": "arXiv:2210.11654",
    "title": "Improved Normalizing Flow-Based Speech Enhancement using an All-pole  Gammatone Filterbank for Conditional Input Representation",
    "abstract": "Deep generative models for Speech Enhancement (SE) received increasing\nattention in recent years. The most prominent example are Generative\nAdversarial Networks (GANs), while normalizing flows (NF) received less\nattention despite their potential. Building on previous work, architectural\nmodifications are proposed, along with an investigation of different\nconditional input representations. Despite being a common choice in related\nworks, Mel-spectrograms demonstrate to be inadequate for the given scenario.\nAlternatively, a novel All-Pole Gammatone filterbank (APG) with high temporal\nresolution is proposed. Although computational evaluation metric results would\nsuggest that state-of-the-art GAN-based methods perform best, a perceptual\nevaluation via a listening test indicates that the presented NF approach (based\non time domain and APG) performs best, especially at lower SNRs. On average,\nAPG outputs are rated as having good quality, which is unmatched by the other\nmethods, including GAN.",
    "descriptor": "\nComments: Accepted for Presentation at IEEE SLT 2022\n",
    "authors": [
      "Martin Strauss",
      "Matteo Torcoli",
      "Bernd Edler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11654"
  },
  {
    "id": "arXiv:2210.11657",
    "title": "MnEdgeNet -- Accurate Decomposition of Mixed Oxidation States for Mn XAS  and EELS L2,3 Edges without Reference and Calibration",
    "abstract": "Accurate decomposition of the mixed Mn oxidation states is highly important\nfor characterizing the electronic structures, charge transfer, and redox\ncenters for electronic, electrocatalytic, and energy storage materials that\ncontain Mn. Electron energy loss spectroscopy (EELS) and soft X-ray absorption\nspectroscopy (XAS) measurements of the Mn L2,3 edges are widely used for this\npurpose. To date, although the measurement of the Mn L2,3 edges is\nstraightforward given the sample is prepared properly, an accurate\ndecomposition of the mix valence states of Mn remains non-trivial. For both\nEELS and XAS, 2+, 3+, 4+ reference spectra need to be taken on the same\ninstrument/beamline and preferably in the same experimental session because the\ninstrumental resolution and the energy axis offset could vary from one session\nto another. To circumvent this hurdle, in this study, we adopted a deep\nlearning approach and developed a calibration-free and reference-free method to\ndecompose the oxidation state of Mn L2,3 edges for both EELS and XAS. To\nsynthesize physics-informed and ground-truth labeled training datasets, we\ncreated a forward model that takes into account plural scattering,\ninstrumentation broadening, noise, and energy axis offset. With that, we\ncreated a 1.2 million-spectrum database with a three-element oxidation state\ncomposition label. The library includes a sufficient variety of data including\nboth EELS and XAS spectra. By training on this large database, our\nconvolutional neural network achieves 85% accuracy on the validation dataset.\nWe tested the model and found it is robust against noise (down to PSNR of 10)\nand plural scattering (up to t/{\\lambda} = 1). We further validated the model\nagainst spectral data that were not used in training.",
    "descriptor": "",
    "authors": [
      "Huolin L. Xin",
      "Mike Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11657"
  },
  {
    "id": "arXiv:2210.11663",
    "title": "InfraRed Investigation in Singapore (IRIS) Observatory: Urban heat  island contributors and mitigators analysis using neighborhood-scale thermal  imaging",
    "abstract": "This paper studies heat fluxes from contributors and mitigators of urban heat\nislands using thermal images and weather data. Thermal images were collected\nfrom an observatory operating on the rooftop of a building between November\n2021 and April 2022. Over the same period, an automatic weather station network\nwas used to measure weather conditions at several locations on a university\ncampus in Singapore. From data collected by the observatory and the automatic\nweather station network, a method was developed to estimate the heat emitted by\nbuilding facades, vegetation, and traffic. Before performing the analysis of\nurban heat fluxes, it was observed that the surface temperature collected from\nthe observatory is sensitive to some variables. After the sensitivity analysis,\nthermal images were calibrated against measurements of the surface temperature\nin an outdoor environment. Finally, several contributors and mitigators of\nurban heat islands were analyzed from heat fluxes assessed with thermal images\nand weather data. According to thermal images collected by the rooftop\nobservatory, concrete walls are an important contributor to urban heat islands\ndue to the longwave radiation they emit at night. Vegetation, on the other\nhand, seems to be an effective mitigator because of latent heat fluxes\ngenerated by evapotranspiration. Traffic looks to be a negligible source of\nheat if considered over a small portion of a road. In the future, more efforts\ncan be made to estimate the magnitude of the heat released by an\nair-conditioning system from thermal images.",
    "descriptor": "",
    "authors": [
      "Miguel Martin",
      "Vasantha Ramani",
      "Clayton Miller"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.11663"
  },
  {
    "id": "arXiv:2210.11685",
    "title": "Quantum Algorithms for Geologic Fracture Networks",
    "abstract": "Solving large systems of equations is a challenge for modeling natural\nphenomena, such as simulating subsurface flow. To avoid systems that are\nintractable on current computers, it is often necessary to neglect information\nat small scales, an approach known as coarse-graining. For many practical\napplications, such as flow in porous, homogenous materials, coarse-graining\noffers a sufficiently-accurate approximation of the solution. Unfortunately,\nfractured systems cannot be accurately coarse-grained, as critical network\ntopology exists at the smallest scales, including topology that can push the\nnetwork across a percolation threshold. Therefore, new techniques are necessary\nto accurately model important fracture systems. Quantum algorithms for solving\nlinear systems offer a theoretically-exponential improvement over their\nclassical counterparts, and in this work we introduce two quantum algorithms\nfor fractured flow. The first algorithm, designed for future quantum computers\nwhich operate without error, has enormous potential, but we demonstrate that\ncurrent hardware is too noisy for adequate performance. The second algorithm,\ndesigned to be noise resilient, already performs well for problems of small to\nmedium size (order 10 to 1000 nodes), which we demonstrate experimentally and\nexplain theoretically. We expect further improvements by leveraging quantum\nerror mitigation and preconditioning.",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Jessie M. Henderson",
      "Marianna Podzorova",
      "M. Cerezo",
      "John K. Golden",
      "Leonard Gleyzer",
      "Hari S. Viswanathan",
      "Daniel O'Malley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11685"
  },
  {
    "id": "arXiv:2210.11737",
    "title": "Bayesian deep learning framework for uncertainty quantification in high  dimensions",
    "abstract": "We develop a novel deep learning method for uncertainty quantification in\nstochastic partial differential equations based on Bayesian neural network\n(BNN) and Hamiltonian Monte Carlo (HMC). A BNN efficiently learns the posterior\ndistribution of the parameters in deep neural networks by performing Bayesian\ninference on the network parameters. The posterior distribution is efficiently\nsampled using HMC to quantify uncertainties in the system. Several numerical\nexamples are shown for both forward and inverse problems in high dimension to\ndemonstrate the effectiveness of the proposed method for uncertainty\nquantification. These also show promising results that the computational cost\nis almost independent of the dimension of the problem demonstrating the\npotential of the method for tackling the so-called curse of dimensionality.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Jeahan Jung",
      "Minseok Choi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11737"
  },
  {
    "id": "arXiv:2210.11780",
    "title": "Correlating sparse sensing for network-wide traffic speed estimation: An  integrated graph tensor-based kriging approach",
    "abstract": "Traffic speed is central to characterizing the fluidity of the road network.\nMany transportation applications rely on it, such as real-time navigation,\ndynamic route planning, and congestion management. Rapid advances in sensing\nand communication techniques make traffic speed detection easier than ever.\nHowever, due to sparse deployment of static sensors or low penetration of\nmobile sensors, speeds detected are incomplete and far from network-wide use.\nIn addition, sensors are prone to error or missing data due to various kinds of\nreasons, speeds from these sensors can become highly noisy. These drawbacks\ncall for effective techniques to recover credible estimates from the incomplete\ndata. In this work, we first identify the problem as a spatiotemporal kriging\nproblem and propose a unified graph embedded tensor (SGET) learning framework\nfeaturing both low-rankness and multi-dimensional correlations for network-wide\ntraffic speed kriging under limited observations. To be specific, three types\nof speed correlation including temporal continuity, temporal periodicity, and\nspatial proximity are carefully chosen. We then design an efficient solution\nalgorithm via several effective numeric techniques to scale up the proposed\nmodel to network-wide kriging. By performing experiments on two public\nmillion-level traffic speed datasets, we finally draw the conclusion and find\nour proposed SGET achieves the state-of-the-art kriging performance even under\nlow observation rates, while at the same time saving more than half computing\ntime compared with baseline methods. Some insights into spatiotemporal traffic\ndata kriging at the network level are provided as well.",
    "descriptor": "",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Yunpeng Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11780"
  },
  {
    "id": "arXiv:2210.11786",
    "title": "A Q# Implementation of a Quantum Lookup Table for Quantum Arithmetic  Functions",
    "abstract": "In this paper, we present Q# implementations for arbitrary single-variabled\nfixed-point arithmetic operations for a gate-based quantum computer based on\nlookup tables (LUTs). In general, this is an inefficent way of implementing a\nfunction since the number of inputs can be large or even infinite. However, if\nthe input domain can be bounded and there can be some error tolerance in the\noutput (both of which are often the case in practical use-cases), the quantum\nLUT implementation of certain quantum arithmetic functions can be more\nefficient than their corresponding reversible arithmetic implementations. We\ndiscuss the implementation of the LUT using Q\\# and its approximation errors.\nWe then show examples of how to use the LUT to implement quantum arithmetic\nfunctions and compare the resources required for the implementation with the\ncurrent state-of-the-art bespoke implementations of some commonly used\narithmetic functions. The implementation of the LUT is designed for use by\npractitioners to use when implementing end-to-end quantum algorithms. In\naddition, given its well-defined approximation errors, the LUT implementation\nmakes for a clear benchmark for evaluating the efficiency of bespoke quantum\narithmetic circuits .",
    "descriptor": "",
    "authors": [
      "Rajiv Krishnakumar",
      "Mathias Soeken",
      "Martin Roetteler",
      "William J. Zeng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.11786"
  },
  {
    "id": "arXiv:2210.11797",
    "title": "Hybridised multigrid preconditioners for a compatible finite element  dynamical core",
    "abstract": "Compatible finite element discretisations for the atmospheric equations of\nmotion have recently attracted considerable interest. Semi-implicit\ntimestepping methods require the repeated solution of a large saddle-point\nsystem of linear equations. Preconditioning this system is challenging since\nthe velocity mass matrix is non-diagonal, leading to a dense Schur complement.\nHybridisable discretisations overcome this issue: weakly enforcing continuity\nof the velocity field with Lagrange multipliers leads to a sparse system of\nequations, which has a similar structure to the pressure Schur complement in\ntraditional approaches. We describe how the hybridised sparse system can be\npreconditioned with a non-nested two-level preconditioner. To solve the coarse\nsystem, we use the multigrid pressure solver that is employed in the\napproximate Schur complement method previously proposed by the some of the\nauthors. Our approach significantly reduces the number of solver iterations.\nThe method shows excellent performance and scales to large numbers of cores in\nthe Met Office next-generation climate- and weather prediction model LFRic.",
    "descriptor": "\nComments: 23 pages, 13 figures, 5 tables; submitted to Quarterly Journal of the Royal Meteorological Society\n",
    "authors": [
      "Jack D. Betteridge",
      "Colin J. Cotter",
      "Thomas H. Gibson",
      "Matthew J. Griffith",
      "Thomas Melvin",
      "Eike H. M\u00fcller"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.11797"
  },
  {
    "id": "arXiv:2210.11819",
    "title": "Coupled dynamics of endemic disease transmission and gradual awareness  diffusion in multiplex networks",
    "abstract": "Understanding the interplay between human behavioral phenomena and infectious\ndisease dynamics has been one of the central challenges of mathematical\nepidemiology. However, socio-cognitive processes critical for the initiation of\ndesired behavioral responses during an outbreak have often been neglected or\noversimplified in earlier models. Combining the microscopic Markov chain\napproach with the law of total probability, we herein institute a mathematical\nmodel describing the dynamic interplay between stage-based progression of\nawareness diffusion and endemic disease transmission in multiplex networks. We\nanalytically derived the epidemic thresholds for both discrete-time and\ncontinuous-time versions of our model, and we numerically demonstrated the\naccuracy of our analytic arguments in capturing the time course and the\nsteady-state of the coupled disease-awareness dynamics. We found that our model\nis exact for arbitrary unclustered multiplex networks, outperforming a widely\nadopted probability-tree-based method, both in the prediction of the\ntime-evolution of a contagion and in the final epidemic size. Our findings show\nthat informing the unaware individuals about the circulating disease will not\nbe sufficient for the prevention of an outbreak unless the distributed\ninformation triggers strong awareness of infection risks with adequate\nprotective measures, and that the immunity of highly-aware individuals can\nelevate the epidemic threshold, but only if the rate of transition from weak to\nstrong awareness is sufficiently high. Our study thus reveals that awareness\ndiffusion and other behavioral parameters can nontrivially interact when\nproducing their effects on epidemiological dynamics of an infectious disease,\nsuggesting that future public health measures should not ignore this complex\nbehavioral interplay and its influence on contagion transmission in\nmultilayered networked systems.",
    "descriptor": "",
    "authors": [
      "Qingchu Wu",
      "Tarik Hadzibeganovic",
      "Xiao-Pu Han"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.11819"
  },
  {
    "id": "arXiv:2210.11822",
    "title": "Valuing Vicinity: Memory attention framework for context-based semantic  segmentation in histopathology",
    "abstract": "The segmentation of histopathological whole slide images into tumourous and\nnon-tumourous types of tissue is a challenging task that requires the\nconsideration of both local and global spatial contexts to classify tumourous\nregions precisely. The identification of subtypes of tumour tissue complicates\nthe issue as the sharpness of separation decreases and the pathologist's\nreasoning is even more guided by spatial context. However, the identification\nof detailed types of tissue is crucial for providing personalized cancer\ntherapies. Due to the high resolution of whole slide images, existing semantic\nsegmentation methods, restricted to isolated image sections, are incapable of\nprocessing context information beyond. To take a step towards better context\ncomprehension, we propose a patch neighbour attention mechanism to query the\nneighbouring tissue context from a patch embedding memory bank and infuse\ncontext embeddings into bottleneck hidden feature maps. Our memory attention\nframework (MAF) mimics a pathologist's annotation procedure -- zooming out and\nconsidering surrounding tissue context. The framework can be integrated into\nany encoder-decoder segmentation method. We evaluate the MAF on a public breast\ncancer and an internal kidney cancer data set using famous segmentation models\n(U-Net, DeeplabV3) and demonstrate the superiority over other\ncontext-integrating algorithms -- achieving a substantial improvement of up to\n$17\\%$ on Dice score. The code is publicly available at:\nhttps://github.com/tio-ikim/valuing-vicinity",
    "descriptor": "",
    "authors": [
      "Oliver Ester",
      "Fabian H\u00f6rst",
      "Constantin Seibold",
      "Julius Keyl",
      "Saskia Ting",
      "Nikolaos Vasileiadis",
      "Jessica Schmitz",
      "Philipp Ivanyi",
      "Viktor Gr\u00fcnwald",
      "Jan Hinrich Br\u00e4sen",
      "Jan Egger",
      "Jens Kleesiek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11822"
  },
  {
    "id": "arXiv:2210.11844",
    "title": "Cox-Hawkes: doubly stochastic spatiotemporal Poisson processes",
    "abstract": "Hawkes processes are point process models that have been used to capture\nself-excitatory behavior in social interactions, neural activity, earthquakes\nand viral epidemics. They can model the occurrence of the times and locations\nof events. Here we develop a new class of spatiotemporal Hawkes processes that\ncan capture both triggering and clustering behavior and we provide an efficient\nmethod for performing inference. We use a log-Gaussian Cox process (LGCP) as\nprior for the background rate of the Hawkes process which gives arbitrary\nflexibility to capture a wide range of underlying background effects (for\ninfectious diseases these are called endemic effects). The Hawkes process and\nLGCP are computationally expensive due to the former having a likelihood with\nquadratic complexity in the number of observations and the latter involving\ninversion of the precision matrix which is cubic in observations. Here we\npropose a novel approach to perform MCMC sampling for our Hawkes process with\nLGCP background, using pre-trained Gaussian Process generators which provide\ndirect and cheap access to samples during inference. We show the efficacy and\nflexibility of our approach in experiments on simulated data and use our\nmethods to uncover the trends in a dataset of reported crimes in the US.",
    "descriptor": "\nComments: 8 Figures, 27 pages without references, 3 pages of references\n",
    "authors": [
      "Xenia Miscouridou",
      "Samir Bhatt",
      "George Mohler",
      "Seth Flaxman",
      "Swapnil Mishra"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11844"
  },
  {
    "id": "arXiv:2210.11855",
    "title": "Learning in RKHM: a $C^*$-Algebraic Twist for Kernel Machines",
    "abstract": "Supervised learning in reproducing kernel Hilbert space (RKHS) and\nvector-valued RKHS (vvRKHS) has been investigated for more than 30 years. In\nthis paper, we provide a new twist to this rich literature by generalizing\nsupervised learning in RKHS and vvRKHS to reproducing kernel Hilbert\n$C^*$-module (RKHM), and show how to construct effective positive-definite\nkernels by considering the perspective of $C^*$-algebra. Unlike the cases of\nRKHS and vvRKHS, we can use $C^*$-algebras to enlarge representation spaces.\nThis enables us to construct RKHMs whose representation power goes beyond\nRKHSs, vvRKHSs, and existing methods such as convolutional neural networks. Our\nframework is suitable, for example, for effectively analyzing image data by\nallowing the interaction of Fourier components.",
    "descriptor": "",
    "authors": [
      "Yuka Hashimoto",
      "Masahiro Ikeda",
      "Hachem Kadri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2210.11855"
  },
  {
    "id": "arXiv:2210.11864",
    "title": "The sequence reconstruction problem for permutations with the Hamming  distance",
    "abstract": "V. Levenshtein first proposed the sequence reconstruction problem in 2001.\nThis problem studies the model where the same sequence from some set is\ntransmitted over multiple channels, and the decoder receives the different\noutputs. Assume that the transmitted sequence is at distance $d$ from some code\nand there are at most $r$ errors in every channel. Then the sequence\nreconstruction problem is to find the minimum number of channels required to\nrecover exactly the transmitted sequence that has to be greater than the\nmaximum intersection between two metric balls of radius $r$, where the distance\nbetween their centers is at least $d$. In this paper, we study the sequence\nreconstruction problem of permutations under the Hamming distance. In this\nmodel, we define a Cayley graph and find the exact value of the largest\nintersection of two metric balls in this graph under the Hamming distance for\n$r=4$ with $d\\geqslant 5$, and for $d=2r$.",
    "descriptor": "",
    "authors": [
      "Xiang Wang",
      "Elena V. Konstantinova"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11864"
  },
  {
    "id": "arXiv:2210.11874",
    "title": "Blind Polynomial Regression",
    "abstract": "Fitting a polynomial to observed data is an ubiquitous task in many signal\nprocessing and machine learning tasks, such as interpolation and prediction. In\nthat context, input and output pairs are available and the goal is to find the\ncoefficients of the polynomial. However, in many applications, the input may be\npartially known or not known at all, rendering conventional regression\napproaches not applicable. In this paper, we formally state the (potentially\npartial) blind regression problem, illustrate some of its theoretical\nproperties, and propose algorithmic approaches to solve it. As a case-study, we\napply our methods to a jitter-correction problem and corroborate its\nperformance.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Alberto Natali",
      "Geert Leus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11874"
  },
  {
    "id": "arXiv:2210.11880",
    "title": "QoS-Aware Sum Capacity Maximization for Mobile Internet of Things  Devices Served by UAVs",
    "abstract": "The use of unmanned aerial vehicles (UAVs) acting as flying base stations\n(FlyBSs) is considered as an effective tool to improve performance of the\nmobile networks. Nevertheless, such potential improvement requires an efficient\npositioning of the FlyBS. In this paper, we maximize the sum downlink capacity\nof the mobile Internet of Things devices (IoTD) served by the FlyBSs while a\nminimum required capacity to every device is guaranteed. To this end, we\npropose a geometrical approach allowing to derive the 3D positions of the FlyBS\nover time as the IoTDs move and we determine the transmission power allocation\nfor the IoTDs. The problem is formulated and solved under practical constraints\non the FlyBS's transmission and propulsion power consumption as well as on\nflying speed. The proposed solution is of a low complexity and increases the\nsum capacity by 15%-46% comparing to state-of-the-art works.",
    "descriptor": "\nComments: Accepted in IEEE PIMRC Workshops 2022\n",
    "authors": [
      "Mohammadsaleh Nikooroo",
      "Zdenek Becvar",
      "Omid Esrafilian",
      "David Gesbert"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11880"
  },
  {
    "id": "arXiv:2210.11925",
    "title": "Barrier Hamiltonian Monte Carlo",
    "abstract": "In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version\nof HMC which aims at sampling from a Gibbs distribution $\\pi$ on a manifold\n$\\mathsf{M}$, endowed with a Hessian metric $\\mathfrak{g}$ derived from a\nself-concordant barrier. Like Riemannian Manifold HMC, our method relies on\nHamiltonian dynamics which comprise $\\mathfrak{g}$. It incorporates the\nconstraints defining $\\mathsf{M}$ and is therefore able to exploit its\nunderlying geometry. We first introduce c-BHMC (continuous BHMC), for which we\nassume that the Hamiltonian dynamics can be integrated exactly, and show that\nit generates a Markov chain for which $\\pi$ is invariant. Secondly, we design\nn-BHMC (numerical BHMC), a Metropolis-Hastings algorithm which combines an\nacceptance filter including a \"reverse integration check\" and numerical\nintegrators of the Hamiltonian dynamics. Our main results establish that n-BHMC\ngenerates a reversible Markov chain with respect to $\\pi$. This is in contrast\nto existing algorithms which extend the HMC method to Riemannian manifolds, as\nthey do not deal with asymptotic bias. Our conclusions are supported by\nnumerical experiments where we consider target distributions defined on\npolytopes.",
    "descriptor": "",
    "authors": [
      "Maxence Noble",
      "Valentin De Bortoli",
      "Alain Durmus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.11925"
  },
  {
    "id": "arXiv:2210.11931",
    "title": "Deep Reinforcement Learning for Inverse Inorganic Materials Design",
    "abstract": "A major obstacle to the realization of novel inorganic materials with\ndesirable properties is the inability to perform efficient optimization across\nboth materials properties and synthesis of those materials. In this work, we\npropose a reinforcement learning (RL) approach to inverse inorganic materials\ndesign, which can identify promising compounds with specified properties and\nsynthesizability constraints. Our model learns chemical guidelines such as\ncharge and electronegativity neutrality while maintaining chemical diversity\nand uniqueness. We demonstrate a multi-objective RL approach, which can\ngenerate novel compounds with targeted materials properties including formation\nenergy and bulk/shear modulus alongside a lower sintering temperature synthesis\nobjectives. Using this approach, the model can predict promising compounds of\ninterest, while suggesting an optimized chemical design space for inorganic\nmaterials discovery.",
    "descriptor": "\nComments: NeurIPS AI4Mat Workshop 2022\n",
    "authors": [
      "Elton Pan",
      "Christopher Karpovich",
      "Elsa Olivetti"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11931"
  },
  {
    "id": "arXiv:2210.11943",
    "title": "Computer-Aided Cancer Diagnosis via Machine Learning and Deep Learning:  A comparative review",
    "abstract": "The past years have seen a considerable increase in cancer cases. However, a\ncancer diagnosis is often complex and depends on the types of images provided\nfor analysis. It requires highly skilled practitioners but is often\ntime-consuming and error-prone. If Machine Learning and deep learning\nalgorithms have been widely used, a comprehensive review of the techniques used\nfrom the pre-processing steps to the final prediction is lacking. With this\nreview, we aim to provide a comprehensive overview of the current steps\nrequired in building efficient and accurate machine learning algorithm for\ncancer prediction, detection and classification. To do so, we compile the\nresults of cancer related study using AI over the past years. We include\nvarious cancers that encompass different types of images, and therefore\ndifferent related techniques. We show that tremendous improvements have been\nmade in the early detection of cancerous tumors and tissues. The techniques\nused are various and often problem-tailored and our findings is confirmed\nthrough the study of a large number of research. Moreover, we investigate the\napproaches best suited for different types of images such as histology,\ndermoscopic, MRI, etc. With this work, we summarize the main finding over the\npast years in cancer detection using deep learning techniques. We discuss the\nchallenges of cancer research related to the large discrepancies in the images,\nand we provide some notable results in the field for lung, breast, and skin\ncancers.",
    "descriptor": "",
    "authors": [
      "Solene Bechelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11943"
  },
  {
    "id": "arXiv:2210.11950",
    "title": "Learning Graphical Factor Models with Riemannian Optimization",
    "abstract": "Graphical models and factor analysis are well-established tools in\nmultivariate statistics. While these models can be both linked to structures\nexhibited by covariance and precision matrices, they are generally not jointly\nleveraged within graph learning processes. This paper therefore addresses this\nissue by proposing a flexible algorithmic framework for graph learning under\nlow-rank structural constraints on the covariance matrix. The problem is\nexpressed as penalized maximum likelihood estimation of an elliptical\ndistribution (a generalization of Gaussian graphical models to possibly\nheavy-tailed distributions), where the covariance matrix is optionally\nconstrained to be structured as low-rank plus diagonal (low-rank factor model).\nThe resolution of this class of problems is then tackled with Riemannian\noptimization, where we leverage geometries of positive definite matrices and\npositive semi-definite matrices of fixed rank that are well suited to\nelliptical models. Numerical experiments on real-world data sets illustrate the\neffectiveness of the proposed approach.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Alexandre Hippert-Ferrer",
      "Florent Bouchard",
      "Ammar Mian",
      "Titouan Vayer",
      "Arnaud Breloy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11950"
  },
  {
    "id": "arXiv:2210.11961",
    "title": "Sets of mutually orthogoval projective and affine planes",
    "abstract": "A pair of planes, both projective or both affine, of the same order and on\nthe same pointset are orthogoval if each line of one plane intersects each line\nof the other plane in at most two points. In this paper we prove new\nconstructions for sets of mutually orthogoval planes, both projective and\naffine, and review known results that are equivalent to sets of more than two\nmutually orthogoval planes. We also discuss the connection between sets of\nmutually orthogoval planes and covering arrays.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Charles J. Colbourn",
      "Colin Ingalls",
      "Jonathan Jedwab",
      "Mark Saaltink",
      "Ken W. Smith",
      "Brett Stevens"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.11961"
  },
  {
    "id": "arXiv:2210.12029",
    "title": "Adversarial Transformer for Repairing Human Airway Segmentation",
    "abstract": "Discontinuity in the delineation of peripheral bronchioles hinders the\npotential clinical application of automated airway segmentation models.\nMoreover, the deployment of such models is limited by the data heterogeneity\nacross different centres, and pathological abnormalities also make achieving\naccurate robust segmentation in distal small airways difficult. Meanwhile, the\ndiagnosis and prognosis of lung diseases often rely on evaluating structural\nchanges in those anatomical regions. To address this gap, this paper presents a\npatch-scale adversarial-based refinement network that takes in preliminary\nsegmentation along with original CT images and outputs a refined mask of the\nairway structure. The method is validated on three different datasets\nencompassing healthy cases, cases with cystic fibrosis and cases with COVID-19.\nThe results are quantitatively evaluated by seven metrics and achieved more\nthan a 15% rise in detected length ratio and detected branch ratio, showing\npromising performance compared to previously proposed models. The visual\nillustration also proves our refinement guided by a patch-scale discriminator\nand centreline objective functions is effective in detecting discontinuities\nand missing bronchioles. Furthermore, the generalizability of our refinement\npipeline is tested on three previous models and improves their segmentation\ncompleteness significantly.",
    "descriptor": "\nComments: 8 Pages, 7 figures\n",
    "authors": [
      "Zeyu Tang",
      "Nan Yang",
      "Simon Walsh",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12029"
  },
  {
    "id": "arXiv:2210.12063",
    "title": "In-silico analysis of the influence of pulmonary vein configuration on  left atrial haemodynamics and thrombus formation in a large cohort",
    "abstract": "Atrial fibrillation (AF) is considered the most common human arrhythmia.\nAround 99\\% of thrombi in non-valvular AF are formed in the left atrial\nappendage (LAA). Studies suggest that abnormal LAA haemodynamics and the\nsubsequently stagnated flow are the factors triggering clot formation. However,\nthe relation between LAA morphology, the blood pattern and the triggering is\nnot fully understood. Moreover, the impact of structures such as the pulmonary\nveins (PVs) on LA haemodynamics has not been thoroughly studied due to the\ndifficulties of acquiring appropriate data. On the other hand, in-silico\nstudies and flow simulations allow a thorough analysis of haemodynamics,\nanalysing the 4D nature of blood flow patterns under different boundary\nconditions. However, the reduced number of cases reported on the literature of\nthese studies has been a limitation. The main goal of this work was to study\nthe influence of PVs on left atrium (LA) and LAA haemodynamics. Computational\nfluid dynamics simulations were run on 52 patients, the largest cohort so far\nin the literature, where different parameters were individually studied:\npulmonary veins orientation and configuration; LAA and LA volumes and its\nratio; and flow velocities. Our computational analysis showed how the right\npulmonary vein height and angulation have a great influence on LA\nhaemodynamics. Additionally, we found that LAA with great bending with its tip\npointing towards the mitral valve could contribute to favour flow stagnation.",
    "descriptor": "",
    "authors": [
      "Jordi Mill",
      "Josquin Harrison",
      "Benoit Legghe",
      "Andy L. Olivares",
      "Xabier Morales",
      "Jerome Noailly",
      "Xavier Iriart",
      "Hubert Cochet",
      "Maxime Sermesant",
      "Oscar Camara"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.12063"
  },
  {
    "id": "arXiv:2210.12064",
    "title": "Embedded Silicon-Organic Integrated Neuromorphic System",
    "abstract": "The development of artificial intelligence (AI) and robotics are both based\non the tenet of \"science and technology are people-oriented\", and both need to\nachieve efficient communication with the human brain. Based on\nmulti-disciplinary research in systems neuroscience, computer architecture, and\nfunctional organic materials, we proposed the concept of using AI to simulate\nthe operating principles and materials of the brain in hardware to develop\nbrain-inspired intelligence technology, and realized the preparation of\nneuromorphic computing devices and basic materials. We simulated neurons and\nneural networks in terms of material and morphology, using a variety of organic\npolymers as the base materials for neuroelectronic devices, for building neural\ninterfaces as well as organic neural devices and silicon neural computational\nmodules. We assemble organic artificial synapses with simulated neurons from\nsilicon-based Field-Programmable Gate Array (FPGA) into organic artificial\nneurons, the basic components of neural networks, and later construct\nbiological neural network models based on the interpreted neural circuits.\nFinally, we also discuss how to further build neuromorphic devices based on\nthese organic artificial neurons, which have both a neural interface friendly\nto nervous tissue and interact with information from real biological neural\nnetworks.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Shengjie Zheng",
      "Ling Liu",
      "Junjie Yang",
      "Jianwei Zhang",
      "Tao Su",
      "Bin Yue",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.12064"
  },
  {
    "id": "arXiv:2210.12068",
    "title": "Grid cells and their potential application in AI",
    "abstract": "Since their Nobel Prize winning discovery in 2005, grid cells have been\nstudied extensively by neuroscientists. Their multi-scale periodic firing rates\ntiling the environment as the animal moves around has been shown as critical\nfor path integration. Multiple experiments have shown that grid cells also fire\nfor other representations such as olfactory, attention mechanisms, imagined\nmovement, and concept organization potentially acting as a form of neural\nrecycling and showing the possible brain mechanism for cognitive maps that\nTolman envisioned in 1948. Grid cell integration into artificial neural\nnetworks may enable more robust, generalized, and smarter computers. In this\npaper we give an overview of grid cell research since their discovery, their\nrole in neuroscience and cognitive science, and possible future directions of\nartificial intelligence research.",
    "descriptor": "",
    "authors": [
      "Jason Toy"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12068"
  },
  {
    "id": "arXiv:2210.12082",
    "title": "A Non-Asymptotic Moreau Envelope Theory for High-Dimensional Generalized  Linear Models",
    "abstract": "We prove a new generalization bound that shows for any class of linear\npredictors in Gaussian space, the Rademacher complexity of the class and the\ntraining error under any continuous loss $\\ell$ can control the test error\nunder all Moreau envelopes of the loss $\\ell$. We use our finite-sample bound\nto directly recover the \"optimistic rate\" of Zhou et al. (2021) for linear\nregression with the square loss, which is known to be tight for minimal\n$\\ell_2$-norm interpolation, but we also handle more general settings where the\nlabel is generated by a potentially misspecified multi-index model. The same\nargument can analyze noisy interpolation of max-margin classifiers through the\nsquared hinge loss, and establishes consistency results in spiked-covariance\nsettings. More generally, when the loss is only assumed to be Lipschitz, our\nbound effectively improves Talagrand's well-known contraction lemma by a factor\nof two, and we prove uniform convergence of interpolators (Koehler et al. 2021)\nfor all smooth, non-negative losses. Finally, we show that application of our\ngeneralization bound using localized Gaussian width will generally be sharp for\nempirical risk minimizers, establishing a non-asymptotic Moreau envelope theory\nfor generalization that applies outside of proportional scaling regimes,\nhandles model misspecification, and complements existing asymptotic Moreau\nenvelope theories for M-estimation.",
    "descriptor": "\nComments: As published at NeurIPS 2022\n",
    "authors": [
      "Lijia Zhou",
      "Frederic Koehler",
      "Pragya Sur",
      "Danica J. Sutherland",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.12082"
  },
  {
    "id": "arXiv:2210.12097",
    "title": "Robust Singular Values based on L1-norm PCA",
    "abstract": "Singular-Value Decomposition (SVD) is a ubiquitous data analysis method in\nengineering, science, and statistics. Singular-value estimation, in particular,\nis of critical importance in an array of engineering applications, such as\nchannel estimation in communication systems, electromyography signal analysis,\nand image compression, to name just a few. Conventional SVD of a data matrix\ncoincides with standard Principal-Component Analysis (PCA). The L2-norm (sum of\nsquared values) formulation of PCA promotes peripheral data points and, thus,\nmakes PCA sensitive against outliers. Naturally, SVD inherits this outlier\nsensitivity. In this work, we present a novel robust non-parametric method for\nSVD and singular-value estimation based on a L1-norm (sum of absolute values)\nformulation, which we name L1-cSVD. Accordingly, the proposed method\ndemonstrates sturdy resistance against outliers and can facilitate more\nreliable data analysis and processing in a wide range of engineering\napplications.",
    "descriptor": "",
    "authors": [
      "Duc Le",
      "Panos P. Markopoulos"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12097"
  },
  {
    "id": "arXiv:2210.12113",
    "title": "Multitask Brain Tumor Inpainting with Diffusion Models: A Methodological  Report",
    "abstract": "Despite the ever-increasing interest in applying deep learning (DL) models to\nmedical imaging, the typical scarcity and imbalance of medical datasets can\nseverely impact the performance of DL models. The generation of synthetic data\nthat might be freely shared without compromising patient privacy is a\nwell-known technique for addressing these difficulties. Inpainting algorithms\nare a subset of DL generative models that can alter one or more regions of an\ninput image while matching its surrounding context and, in certain cases,\nnon-imaging input conditions. Although the majority of inpainting techniques\nfor medical imaging data use generative adversarial networks (GANs), the\nperformance of these algorithms is frequently suboptimal due to their limited\noutput variety, a problem that is already well-known for GANs. Denoising\ndiffusion probabilistic models (DDPMs) are a recently introduced family of\ngenerative networks that can generate results of comparable quality to GANs,\nbut with diverse outputs. In this paper, we describe a DDPM to execute multiple\ninpainting tasks on 2D axial slices of brain MRI with various sequences, and\npresent proof-of-concept examples of its performance in a variety of evaluation\nscenarios. Our model and a public online interface to try our tool are\navailable at: https://github.com/Mayo-Radiology-Informatics-Lab/MBTI",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Pouria Rouzrokh",
      "Bardia Khosravi",
      "Shahriar Faghani",
      "Mana Moassefi",
      "Sanaz Vahdati",
      "Bradley J. Erickson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12113"
  },
  {
    "id": "arXiv:2210.12142",
    "title": "Target Aware Poisson-Gaussian Noise Parameters Estimation from Noisy  Images",
    "abstract": "Digital sensors can lead to noisy results under many circumstances. To be\nable to remove the undesired noise from images, proper noise modeling and an\naccurate noise parameter estimation is crucial. In this project, we use a\nPoisson-Gaussian noise model for the raw-images captured by the sensor, as it\nfits the physical characteristics of the sensor closely. Moreover, we limit\nourselves to the case where observed (noisy), and ground-truth (noise-free)\nimage pairs are available. Using such pairs is beneficial for the noise\nestimation and is not widely studied in literature. Based on this model, we\nderive the theoretical maximum likelihood solution, discuss its practical\nimplementation and optimization. Further, we propose two algorithms based on\nvariance and cumulant statistics. Finally, we compare the results of our\nmethods with two different approaches, a CNN we trained ourselves, and another\none taken from literature. The comparison between all these methods shows that\nour algorithms outperform the others in terms of MSE and have good additional\nproperties.",
    "descriptor": "\nComments: 10 pages, 14 figures and 4 tables\n",
    "authors": [
      "\u00c9tienne Objois",
      "Kaan Okumu\u015f",
      "Nicolas B\u00e4hler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12142"
  },
  {
    "id": "arXiv:1810.01896",
    "title": "On Basis Constructions in Finite Element Exterior Calculus",
    "abstract": "Comments: The final publication is available at Springer via: this http URL",
    "descriptor": "\nComments: The final publication is available at Springer via: this http URL\n",
    "authors": [
      "Martin W. Licht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1810.01896"
  },
  {
    "id": "arXiv:1908.09881",
    "title": "Consistently estimating network statistics using Aggregated Relational  Data",
    "abstract": "Consistently estimating network statistics using Aggregated Relational  Data",
    "descriptor": "",
    "authors": [
      "Emily Breza",
      "Arun G. Chandrasekhar",
      "Shane Lubold",
      "Tyler H. McCormick",
      "Mengjie Pan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/1908.09881"
  },
  {
    "id": "arXiv:2002.09458",
    "title": "Sequential Submodular Maximization and Applications to Ranking an  Assortment of Products",
    "abstract": "Comments: Conference version: ACM EC 2022; journal version: Operation Research",
    "descriptor": "\nComments: Conference version: ACM EC 2022; journal version: Operation Research\n",
    "authors": [
      "Arash Asadpour",
      "Rad Niazadeh",
      "Amin Saberi",
      "Ali Shameli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.09458"
  },
  {
    "id": "arXiv:2005.02607",
    "title": "Towards quantum advantage via topological data analysis",
    "abstract": "Comments: 31+7 pages, 3 figures",
    "descriptor": "\nComments: 31+7 pages, 3 figures\n",
    "authors": [
      "Casper Gyurik",
      "Chris Cade",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.02607"
  },
  {
    "id": "arXiv:2005.07253",
    "title": "Information Design for Congested Social Services: Optimal Need-Based  Persuasion",
    "abstract": "Comments: Accepted for publication in Management Science. An earlier version of this work was accepted to the 21st ACM Conference on Economics and Computation (EC'20). 55 pages, 12 figures",
    "descriptor": "\nComments: Accepted for publication in Management Science. An earlier version of this work was accepted to the 21st ACM Conference on Economics and Computation (EC'20). 55 pages, 12 figures\n",
    "authors": [
      "Jerry Anunrojwong",
      "Krishnamurthy Iyer",
      "Vahideh Manshadi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2005.07253"
  },
  {
    "id": "arXiv:2006.15337",
    "title": "On Dualization over Distributive Lattices",
    "abstract": "On Dualization over Distributive Lattices",
    "descriptor": "",
    "authors": [
      "Khaled Elbassioni"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.15337"
  },
  {
    "id": "arXiv:2008.08451",
    "title": "Axioms for Defeat in Democratic Elections",
    "abstract": "Axioms for Defeat in Democratic Elections",
    "descriptor": "",
    "authors": [
      "Wesley H. Holliday",
      "Eric Pacuit"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2008.08451"
  },
  {
    "id": "arXiv:2011.03116",
    "title": "Behavioral Use Licensing for Responsible AI",
    "abstract": "Comments: Paper published at ACM FAccT 2022",
    "descriptor": "\nComments: Paper published at ACM FAccT 2022\n",
    "authors": [
      "Danish Contractor",
      "Daniel McDuff",
      "Julia Haines",
      "Jenny Lee",
      "Christopher Hines",
      "Brent Hecht",
      "Nicholas Vincent",
      "Hanlin Li"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2011.03116"
  },
  {
    "id": "arXiv:2011.07471",
    "title": "Tight Bounds for Adversarially Robust Streams and Sliding Windows via  Difference Estimators",
    "abstract": "Comments: FOCS 2021",
    "descriptor": "\nComments: FOCS 2021\n",
    "authors": [
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.07471"
  },
  {
    "id": "arXiv:2011.10446",
    "title": "Hop-Constrained Oblivious Routing",
    "abstract": "Comments: STOC 2021, invited to the corresponding special issue of SICOMP journal",
    "descriptor": "\nComments: STOC 2021, invited to the corresponding special issue of SICOMP journal\n",
    "authors": [
      "Mohsen Ghaffari",
      "Bernhard Haeupler",
      "Goran Zuzic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.10446"
  },
  {
    "id": "arXiv:2012.09302",
    "title": "TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural  Backdoors",
    "abstract": "Comments: Accepted as a full paper at EuroS&P 2022",
    "descriptor": "\nComments: Accepted as a full paper at EuroS&P 2022\n",
    "authors": [
      "Ren Pang",
      "Zheng Zhang",
      "Xiangshan Gao",
      "Zhaohan Xi",
      "Shouling Ji",
      "Peng Cheng",
      "Xiapu Luo",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.09302"
  },
  {
    "id": "arXiv:2102.09884",
    "title": "A Taxonomy of Assets for the Development of Software-Intensive Products  and Services",
    "abstract": "Comments: Submitted to the Journal of Systems and Software (JSS)",
    "descriptor": "\nComments: Submitted to the Journal of Systems and Software (JSS)\n",
    "authors": [
      "Ehsan Zabardast",
      "Javier Gonzalez-Huerta",
      "Tony Gorschek",
      "Darja \u0160mite",
      "Emil Al\u00e9groth",
      "Fabian Fagerholm"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09884"
  },
  {
    "id": "arXiv:2102.12562",
    "title": "Approximating the Derivative of Manifold-valued Functions",
    "abstract": "Comments: 26 pages, 5 figures",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Ralf Hielscher",
      "Laura Lippert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2102.12562"
  },
  {
    "id": "arXiv:2103.10145",
    "title": "Search and Matching for Adoption from Foster Care",
    "abstract": "Search and Matching for Adoption from Foster Care",
    "descriptor": "",
    "authors": [
      "Nils Olberg",
      "Ludwig Dierks",
      "Sven Seuken",
      "Vincent W. Slaugh",
      "M. Utku \u00dcnver"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.10145"
  },
  {
    "id": "arXiv:2104.04061",
    "title": "Transition from physical to online shopping alternatives due to the  COVID-19 pandemic",
    "abstract": "Transition from physical to online shopping alternatives due to the  COVID-19 pandemic",
    "descriptor": "",
    "authors": [
      "Claudia Andruetto",
      "Elisa Bin",
      "Yusak Susilo",
      "Anna Pernest\u00e5l"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.04061"
  },
  {
    "id": "arXiv:2105.01937",
    "title": "FLEX: Extrinsic Parameters-free Multi-view 3D Human Motion  Reconstruction",
    "abstract": "Comments: Accepted to ECCV22 Project page: this https URL Video: this https URL",
    "descriptor": "\nComments: Accepted to ECCV22 Project page: this https URL Video: this https URL\n",
    "authors": [
      "Brian Gordon",
      "Sigal Raab",
      "Guy Azov",
      "Raja Giryes",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.01937"
  },
  {
    "id": "arXiv:2105.03630",
    "title": "A Phase Theory of MIMO LTI Systems",
    "abstract": "A Phase Theory of MIMO LTI Systems",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Dan Wang",
      "Sei Zhen Khong",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.03630"
  },
  {
    "id": "arXiv:2106.00308",
    "title": "Fast Splitting Algorithms for Sparsity-Constrained and Noisy Group  Testing",
    "abstract": "Comments: Information and Inference: A Journal of the IMA",
    "descriptor": "\nComments: Information and Inference: A Journal of the IMA\n",
    "authors": [
      "Eric Price",
      "Jonathan Scarlett",
      "Nelvin Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00308"
  },
  {
    "id": "arXiv:2106.01528",
    "title": "Normalizing Flows for Knockoff-free Controlled Feature Selection",
    "abstract": "Comments: Accepted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 21 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: Accepted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 21 pages, 9 figures, 3 tables\n",
    "authors": [
      "Derek Hansen",
      "Brian Manzo",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01528"
  },
  {
    "id": "arXiv:2106.03725",
    "title": "Stability to Deformations of Manifold Filters and Manifold Neural  Networks",
    "abstract": "Comments: 18 pages; 5 figures",
    "descriptor": "\nComments: 18 pages; 5 figures\n",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03725"
  },
  {
    "id": "arXiv:2106.06610",
    "title": "Scalars are universal: Equivariant machine learning, structured like  classical physics",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Soledad Villar",
      "David W.Hogg",
      "Kate Storey-Fisher",
      "Weichi Yao",
      "Ben Blum-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06610"
  },
  {
    "id": "arXiv:2106.06927",
    "title": "Inverting Adversarially Robust Networks for Image Synthesis",
    "abstract": "Comments: Accepted at the 16th Asian Conference on Computer Vision (ACCV 2022)",
    "descriptor": "\nComments: Accepted at the 16th Asian Conference on Computer Vision (ACCV 2022)\n",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Raymond A. Yeh",
      "Minh N. Do",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06927"
  },
  {
    "id": "arXiv:2106.08504",
    "title": "A study on CFL conditions for the DG solution of conservation laws on  adaptive moving meshes",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Min Zhang",
      "Weizhang Huang",
      "Jianxian Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08504"
  },
  {
    "id": "arXiv:2106.12177",
    "title": "Imitation Learning: Progress, Taxonomies and Challenges",
    "abstract": "Imitation Learning: Progress, Taxonomies and Challenges",
    "descriptor": "",
    "authors": [
      "Boyuan Zheng",
      "Sunny Verma",
      "Jianlong Zhou",
      "Ivor Tsang",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.12177"
  },
  {
    "id": "arXiv:2108.09779",
    "title": "Transferring Dexterous Manipulation from GPU Simulation to a Remote  Real-World TriFinger",
    "abstract": "Comments: International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Arthur Allshire",
      "Mayank Mittal",
      "Varun Lodaya",
      "Viktor Makoviychuk",
      "Denys Makoviichuk",
      "Felix Widmaier",
      "Manuel W\u00fcthrich",
      "Stefan Bauer",
      "Ankur Handa",
      "Animesh Garg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09779"
  },
  {
    "id": "arXiv:2109.06717",
    "title": "Controllable Dialogue Generation with Disentangled Multi-grained Style  Specification and Attribute Consistency Reward",
    "abstract": "Comments: Accepted as a regular paper in IEEE/ACM TASLP",
    "descriptor": "\nComments: Accepted as a regular paper in IEEE/ACM TASLP\n",
    "authors": [
      "Zhe Hu",
      "Zhiwei Cao",
      "Hou Pong Chan",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Jinsong Su",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06717"
  },
  {
    "id": "arXiv:2109.14855",
    "title": "Sim2Real for Soft Robotic Fish via Differentiable Simulation",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "John Z. Zhang",
      "Yu Zhang",
      "Pingchuan Ma",
      "Elvis Nava",
      "Tao Du",
      "Philip Arm",
      "Wojciech Matusik",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14855"
  },
  {
    "id": "arXiv:2110.03135",
    "title": "Label Noise in Adversarial Training: A Novel Perspective to Study Robust  Overfitting",
    "abstract": "Label Noise in Adversarial Training: A Novel Perspective to Study Robust  Overfitting",
    "descriptor": "",
    "authors": [
      "Chengyu Dong",
      "Liyuan Liu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03135"
  },
  {
    "id": "arXiv:2110.04400",
    "title": "HydraSum: Disentangling Stylistic Features in Text Summarization using  Multi-Decoder Models",
    "abstract": "Comments: EMNLP2022",
    "descriptor": "\nComments: EMNLP2022\n",
    "authors": [
      "Tanya Goyal",
      "Nazneen Fatema Rajani",
      "Wenhao Liu",
      "Wojciech Kry\u015bci\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04400"
  },
  {
    "id": "arXiv:2110.11688",
    "title": "Differentially Private Coordinate Descent for Composite Empirical Risk  Minimization",
    "abstract": "Comments: 36 pages, 3 figures",
    "descriptor": "\nComments: 36 pages, 3 figures\n",
    "authors": [
      "Paul Mangold",
      "Aur\u00e9lien Bellet",
      "Joseph Salmon",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11688"
  },
  {
    "id": "arXiv:2110.13624",
    "title": "Technology Fitness Landscape for Design Innovation: A Deep Neural  Embedding Approach Based on Patent Data",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Shuo Jiang",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13624"
  },
  {
    "id": "arXiv:2111.00834",
    "title": "Fast Newton Iterative Method for Local Steric Poisson--Boltzmann  Theories in Biomolecular Solvation",
    "abstract": "Fast Newton Iterative Method for Local Steric Poisson--Boltzmann  Theories in Biomolecular Solvation",
    "descriptor": "",
    "authors": [
      "Minhong Chen",
      "Wei Dou",
      "Shenggao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00834"
  },
  {
    "id": "arXiv:2111.01877",
    "title": "AIT* and EIT*: Asymmetric bidirectional sampling-based path planning",
    "abstract": "Comments: 25 pages, 12 figures, 2 tables. Videos available at this https URL and this https URL",
    "descriptor": "\nComments: 25 pages, 12 figures, 2 tables. Videos available at this https URL and this https URL\n",
    "authors": [
      "Marlin P. Strub",
      "Jonathan D. Gammell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01877"
  },
  {
    "id": "arXiv:2111.03289",
    "title": "Improved Regret Analysis for Variance-Adaptive Linear Bandits and  Horizon-Free Linear Mixture MDPs",
    "abstract": "Comments: fixed error in the proof; improved the bound for MDPs",
    "descriptor": "\nComments: fixed error in the proof; improved the bound for MDPs\n",
    "authors": [
      "Yeoneung Kim",
      "Insoon Yang",
      "Kwang-Sung Jun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.03289"
  },
  {
    "id": "arXiv:2111.06806",
    "title": "First-Order Rewritability and Complexity of Two-Dimensional Temporal  Ontology-Mediated Queries",
    "abstract": "Comments: Accepted for JAIR",
    "descriptor": "\nComments: Accepted for JAIR\n",
    "authors": [
      "Alessandro Artale",
      "Roman Kontchakov",
      "Alisa Kovtunova",
      "Vladislav Ryzhikov",
      "Frank Wolter",
      "Michael Zakharyaschev"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.06806"
  },
  {
    "id": "arXiv:2111.10633",
    "title": "Sparse Tensor-based Multiscale Representation for Point Cloud Geometry  Compression",
    "abstract": "Comments: 17 pages, 15 figures",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Jianqiang Wang",
      "Dandan Ding",
      "Zhu Li",
      "Xiaoxing Feng",
      "Chuntong Cao",
      "Zhan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.10633"
  },
  {
    "id": "arXiv:2111.12673",
    "title": "Adaptively Calibrated Critic Estimates for Deep Reinforcement Learning",
    "abstract": "Comments: Submitted to RA-L",
    "descriptor": "\nComments: Submitted to RA-L\n",
    "authors": [
      "Nicolai Dorka",
      "Tim Welschehold",
      "Joschka Boedecker",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12673"
  },
  {
    "id": "arXiv:2111.13470",
    "title": "TDAM: Top-Down Attention Module for Contextually Guided Feature  Selection in CNNs",
    "abstract": "Comments: ECCV 2022 Camera Ready",
    "descriptor": "\nComments: ECCV 2022 Camera Ready\n",
    "authors": [
      "Shantanu Jaiswal",
      "Basura Fernando",
      "Cheston Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13470"
  },
  {
    "id": "arXiv:2111.15449",
    "title": "A Softmax-free Loss Function Based on Predefined Optimal-distribution of  Latent Features for Deep Learning Classifier",
    "abstract": "A Softmax-free Loss Function Based on Predefined Optimal-distribution of  Latent Features for Deep Learning Classifier",
    "descriptor": "",
    "authors": [
      "Qiuyu Zhu",
      "Xuewen Zu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15449"
  },
  {
    "id": "arXiv:2112.00016",
    "title": "Learning knot invariants across dimensions",
    "abstract": "Comments: v1: 35 pages, 6 figures; v2: 36 pages, 6 figures, figures updated, typos corrected",
    "descriptor": "\nComments: v1: 35 pages, 6 figures; v2: 36 pages, 6 figures, figures updated, typos corrected\n",
    "authors": [
      "Jessica Craven",
      "Mark Hughes",
      "Vishnu Jejjala",
      "Arjun Kar"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.00016"
  },
  {
    "id": "arXiv:2112.03432",
    "title": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "abstract": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03432"
  },
  {
    "id": "arXiv:2112.06776",
    "title": "Keyphrase Generation Beyond the Boundaries of Title and Abstract",
    "abstract": "Comments: 9 pages, 1 figure, 7 tables",
    "descriptor": "\nComments: 9 pages, 1 figure, 7 tables\n",
    "authors": [
      "Krishna Garg",
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06776"
  },
  {
    "id": "arXiv:2112.12572",
    "title": "Are E2E ASR models ready for an industrial usage?",
    "abstract": "Are E2E ASR models ready for an industrial usage?",
    "descriptor": "",
    "authors": [
      "Valentin Vielzeuf",
      "Grigory Antipov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.12572"
  },
  {
    "id": "arXiv:2112.13571",
    "title": "Chinese Learners' Phonetic Transfer of /i/ from Mandarin Chinese to  General American English: A Case Study of a Chinese Learner with Advanced  English",
    "abstract": "Comments: 5 pages, 4 tables and 1 figure",
    "descriptor": "\nComments: 5 pages, 4 tables and 1 figure\n",
    "authors": [
      "Lintao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.13571"
  },
  {
    "id": "arXiv:2112.14382",
    "title": "Self-Supervised Robustifying Guidance for Monocular 3D Face  Reconstruction",
    "abstract": "Comments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022. Evaluation code and datasets: this https URL",
    "descriptor": "\nComments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022. Evaluation code and datasets: this https URL\n",
    "authors": [
      "Hitika Tiwari",
      "Min-Hung Chen",
      "Yi-Min Tsai",
      "Hsien-Kai Kuo",
      "Hung-Jen Chen",
      "Kevin Jou",
      "K. S. Venkatesh",
      "Yong-Sheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14382"
  },
  {
    "id": "arXiv:2112.14889",
    "title": "Few-shot Backdoor Defense Using Shapley Estimation",
    "abstract": "Few-shot Backdoor Defense Using Shapley Estimation",
    "descriptor": "",
    "authors": [
      "Jiyang Guan",
      "Zhuozhuo Tu",
      "Ran He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.14889"
  },
  {
    "id": "arXiv:2201.06718",
    "title": "A Simple Evolutionary Algorithm for Multi-modal Multi-objective  Optimization",
    "abstract": "A Simple Evolutionary Algorithm for Multi-modal Multi-objective  Optimization",
    "descriptor": "",
    "authors": [
      "Tapabrata Ray",
      "Mohammad Mohiuddin Mamun",
      "Hemant Kumar Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.06718"
  },
  {
    "id": "arXiv:2201.07131",
    "title": "Leveraging Real Talking Faces via Self-Supervision for Robust Forgery  Detection",
    "abstract": "Comments: CVPR 2022. Code: this https URL",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL\n",
    "authors": [
      "Alexandros Haliassos",
      "Rodrigo Mira",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.07131"
  },
  {
    "id": "arXiv:2201.10442",
    "title": "Serving Deep Learning Models with Deduplication from Relational  Databases",
    "abstract": "Serving Deep Learning Models with Deduplication from Relational  Databases",
    "descriptor": "",
    "authors": [
      "Lixi Zhou",
      "Jiaqing Chen",
      "Amitabh Das",
      "Hong Min",
      "Lei Yu",
      "Ming Zhao",
      "Jia Zou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.10442"
  },
  {
    "id": "arXiv:2201.13202",
    "title": "ODSearch: Fast and Resource Efficient On-device Natural Language Search  for Fitness Trackers' Data",
    "abstract": "Comments: 23 pages, 11 figures, 10 tables",
    "descriptor": "\nComments: 23 pages, 11 figures, 10 tables\n",
    "authors": [
      "Reza Rawassizadeh",
      "Yi Rong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.13202"
  },
  {
    "id": "arXiv:2202.00574",
    "title": "Identifying Pauli spin blockade using deep learning",
    "abstract": "Identifying Pauli spin blockade using deep learning",
    "descriptor": "",
    "authors": [
      "Jonas Schuff",
      "Dominic T. Lennon",
      "Simon Geyer",
      "David L. Craig",
      "Federico Fedele",
      "Florian Vigneau",
      "Leon C. Camenzind",
      "Andreas V. Kuhlmann",
      "G. Andrew D. Briggs",
      "Dominik M. Zumb\u00fchl",
      "Dino Sejdinovic",
      "Natalia Ares"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00574"
  },
  {
    "id": "arXiv:2202.01943",
    "title": "PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization",
    "abstract": "PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization",
    "descriptor": "",
    "authors": [
      "Caio Davi",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01943"
  },
  {
    "id": "arXiv:2202.02216",
    "title": "Geometrically Higher Order Unfitted Space-Time Methods for PDEs on  Moving Domains",
    "abstract": "Geometrically Higher Order Unfitted Space-Time Methods for PDEs on  Moving Domains",
    "descriptor": "",
    "authors": [
      "Fabian Heimann",
      "Christoph Lehrenfeld",
      "Janosch Preu\u00df"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02216"
  },
  {
    "id": "arXiv:2202.04579",
    "title": "Neural Sheaf Diffusion: A Topological Perspective on Heterophily and  Oversmoothing in GNNs",
    "abstract": "Comments: Accepted to NeurIPS 2022. Contains 29 pages, 10 figures",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Contains 29 pages, 10 figures\n",
    "authors": [
      "Cristian Bodnar",
      "Francesco Di Giovanni",
      "Benjamin Paul Chamberlain",
      "Pietro Li\u00f2",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2202.04579"
  },
  {
    "id": "arXiv:2202.04829",
    "title": "Target-aware Molecular Graph Generation",
    "abstract": "Comments: Accepted by the 2nd AI4Science Workshop at the 39th International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: Accepted by the 2nd AI4Science Workshop at the 39th International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04829"
  },
  {
    "id": "arXiv:2202.05012",
    "title": "SUPA: A Lightweight Diagnostic Simulator for Machine Learning in  Particle Physics",
    "abstract": "SUPA: A Lightweight Diagnostic Simulator for Machine Learning in  Particle Physics",
    "descriptor": "",
    "authors": [
      "Atul Kumar Sinha",
      "Daniele Paliotta",
      "B\u00e1lint M\u00e1t\u00e9",
      "Sebastian Pina-Otey",
      "John A. Raine",
      "Tobias Golling",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05012"
  },
  {
    "id": "arXiv:2202.06991",
    "title": "Transformer Memory as a Differentiable Search Index",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yi Tay",
      "Vinh Q. Tran",
      "Mostafa Dehghani",
      "Jianmo Ni",
      "Dara Bahri",
      "Harsh Mehta",
      "Zhen Qin",
      "Kai Hui",
      "Zhe Zhao",
      "Jai Gupta",
      "Tal Schuster",
      "William W. Cohen",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06991"
  },
  {
    "id": "arXiv:2202.07136",
    "title": "Debiased Self-Training for Semi-Supervised Learning",
    "abstract": "Debiased Self-Training for Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Baixu Chen",
      "Junguang Jiang",
      "Ximei Wang",
      "Pengfei Wan",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07136"
  },
  {
    "id": "arXiv:2202.10803",
    "title": "A-Eye: Driving with the Eyes of AI for Corner Case Generation",
    "abstract": "A-Eye: Driving with the Eyes of AI for Corner Case Generation",
    "descriptor": "",
    "authors": [
      "Kamil Kowol",
      "Stefan Bracke",
      "Hanno Gottschalk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10803"
  },
  {
    "id": "arXiv:2202.11850",
    "title": "Robust Federated Learning with Connectivity Failures: A  Semi-Decentralized Framework with Collaborative Relaying",
    "abstract": "Robust Federated Learning with Connectivity Failures: A  Semi-Decentralized Framework with Collaborative Relaying",
    "descriptor": "",
    "authors": [
      "Michal Yemini",
      "Rajarshi Saha",
      "Emre Ozfatura",
      "Deniz G\u00fcnd\u00fcz",
      "Andrea J. Goldsmith"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.11850"
  },
  {
    "id": "arXiv:2202.14019",
    "title": "Domain Knowledge-Informed Self-Supervised Representations for Workout  Form Assessment",
    "abstract": "Domain Knowledge-Informed Self-Supervised Representations for Workout  Form Assessment",
    "descriptor": "",
    "authors": [
      "Paritosh Parmar",
      "Amol Gharat",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.14019"
  },
  {
    "id": "arXiv:2203.00804",
    "title": "NESTANets: Stable, accurate and efficient neural networks for  analysis-sparse inverse problems",
    "abstract": "NESTANets: Stable, accurate and efficient neural networks for  analysis-sparse inverse problems",
    "descriptor": "",
    "authors": [
      "Maksym Neyra-Nesterenko",
      "Ben Adcock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.00804"
  },
  {
    "id": "arXiv:2203.01116",
    "title": "Superiorized Adaptive Projected Subgradient Method with Application to  MIMO Detection",
    "abstract": "Comments: Submitted to IEEE Transactions on Signal Processing for possible publication",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal Processing for possible publication\n",
    "authors": [
      "Jochen Fink",
      "Renato L. G. Cavalcante",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.01116"
  },
  {
    "id": "arXiv:2203.02016",
    "title": "Interventions, Where and How? Experimental Design for Causal Models at  Scale",
    "abstract": "Comments: Presented at the thirty-sixth Conference on Neural Information Processing Systems (2022)",
    "descriptor": "\nComments: Presented at the thirty-sixth Conference on Neural Information Processing Systems (2022)\n",
    "authors": [
      "Panagiotis Tigas",
      "Yashas Annadani",
      "Andrew Jesson",
      "Bernhard Sch\u00f6lkopf",
      "Yarin Gal",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02016"
  },
  {
    "id": "arXiv:2203.02128",
    "title": "Distributionally Robust Bayesian Optimization with $\u03c6$-divergences",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Hisham Husain",
      "Vu Nguyen",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02128"
  },
  {
    "id": "arXiv:2203.05630",
    "title": "PLATO: Predicting Latent Affordances Through Object-Centric Play",
    "abstract": "PLATO: Predicting Latent Affordances Through Object-Centric Play",
    "descriptor": "",
    "authors": [
      "Suneel Belkhale",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05630"
  },
  {
    "id": "arXiv:2203.06314",
    "title": "Tensor Radiomics: Paradigm for Systematic Incorporation of  Multi-Flavoured Radiomics Features",
    "abstract": "Tensor Radiomics: Paradigm for Systematic Incorporation of  Multi-Flavoured Radiomics Features",
    "descriptor": "",
    "authors": [
      "Arman Rahmim",
      "Amirhosein Toosi",
      "Mohammad R. Salmanpour",
      "Natalia Dubljevic",
      "Ian Janzen",
      "Isaac Shiri",
      "Mohamad A. Ramezani",
      "Ren Yuan",
      "Cheryl Ho",
      "Habib Zaidi",
      "Calum MacAulay",
      "Carlos Uribe",
      "Fereshteh Yousefirizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.06314"
  },
  {
    "id": "arXiv:2203.07422",
    "title": "Bayesian-EUCLID: discovering hyperelastic material laws with  uncertainties",
    "abstract": "Comments: 36 pages, 17 figures",
    "descriptor": "\nComments: 36 pages, 17 figures\n",
    "authors": [
      "Akshay Joshi",
      "Prakash Thakolkaran",
      "Yiwen Zheng",
      "Maxime Escande",
      "Moritz Flaschel",
      "Laura De Lorenzis",
      "Siddhant Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.07422"
  },
  {
    "id": "arXiv:2203.08284",
    "title": "Minimizing Trust with Exclusively-Used Physically-Isolated Hardware",
    "abstract": "Minimizing Trust with Exclusively-Used Physically-Isolated Hardware",
    "descriptor": "",
    "authors": [
      "Zhihao Yao",
      "Seyed Mohammadjavad Seyed Talebi",
      "Mingyi Chen",
      "Ardalan Amiri Sani",
      "Thomas Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2203.08284"
  },
  {
    "id": "arXiv:2203.10557",
    "title": "A Neural-Symbolic Approach to Natural Language Understanding",
    "abstract": "A Neural-Symbolic Approach to Natural Language Understanding",
    "descriptor": "",
    "authors": [
      "Zhixuan Liu",
      "Zihao Wang",
      "Yuan Lin",
      "Hang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.10557"
  },
  {
    "id": "arXiv:2203.11163",
    "title": "Evaluating Token-Level and Passage-Level Dense Retrieval Models for Math  Information Retrieval",
    "abstract": "Evaluating Token-Level and Passage-Level Dense Retrieval Models for Math  Information Retrieval",
    "descriptor": "",
    "authors": [
      "Wei Zhong",
      "Jheng-Hong Yang",
      "Yuqing Xie",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.11163"
  },
  {
    "id": "arXiv:2203.12346",
    "title": "Robust Text Line Detection in Historical Documents: Learning and  Evaluation Methods",
    "abstract": "Robust Text Line Detection in Historical Documents: Learning and  Evaluation Methods",
    "descriptor": "",
    "authors": [
      "M\u00e9lodie Boillet",
      "Christopher Kermorvant",
      "Thierry Paquet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12346"
  },
  {
    "id": "arXiv:2204.02685",
    "title": "SecureBERT: A Domain-Specific Language Model for Cybersecurity",
    "abstract": "Comments: This is the initial draft of this work and it may contain errors and typos. The revised version has already been submitted to a venue",
    "descriptor": "\nComments: This is the initial draft of this work and it may contain errors and typos. The revised version has already been submitted to a venue\n",
    "authors": [
      "Ehsan Aghaei",
      "Xi Niu",
      "Waseem Shadid",
      "Ehab Al-Shaer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02685"
  },
  {
    "id": "arXiv:2204.03586",
    "title": "The combinator ${\\bf M}$ and the Mockingbird lattice",
    "abstract": "Comments: 30 pages. This is an extended version of arXiv:2204.02616",
    "descriptor": "\nComments: 30 pages. This is an extended version of arXiv:2204.02616\n",
    "authors": [
      "Samuele Giraudo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.03586"
  },
  {
    "id": "arXiv:2204.04292",
    "title": "Evolving Generalizable Actor-Critic Algorithms",
    "abstract": "Evolving Generalizable Actor-Critic Algorithms",
    "descriptor": "",
    "authors": [
      "Juan Jose Garau-Luis",
      "Yingjie Miao",
      "John D. Co-Reyes",
      "Aaron Parisi",
      "Jie Tan",
      "Esteban Real",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04292"
  },
  {
    "id": "arXiv:2204.04452",
    "title": "Refined Convergence and Topology Learning for Decentralized SGD with  Heterogeneous Data",
    "abstract": "Refined Convergence and Topology Learning for Decentralized SGD with  Heterogeneous Data",
    "descriptor": "",
    "authors": [
      "Batiste Le Bars",
      "Aur\u00e9lien Bellet",
      "Marc Tommasi",
      "Erick Lavoie",
      "Anne-Marie Kermarrec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04452"
  },
  {
    "id": "arXiv:2204.09273",
    "title": "Sound-Guided Semantic Video Generation",
    "abstract": "Sound-Guided Semantic Video Generation",
    "descriptor": "",
    "authors": [
      "Seung Hyun Lee",
      "Gyeongrok Oh",
      "Wonmin Byeon",
      "Chanyoung Kim",
      "Won Jeong Ryoo",
      "Sang Ho Yoon",
      "Hyunjun Cho",
      "Jihyun Bae",
      "Jinkyu Kim",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09273"
  },
  {
    "id": "arXiv:2204.09358",
    "title": "Generative or Contrastive? Phrase Reconstruction for Better Sentence  Representation Learning",
    "abstract": "Comments: A new version with significant changes of this paper is submitted recently",
    "descriptor": "\nComments: A new version with significant changes of this paper is submitted recently\n",
    "authors": [
      "Bohong Wu",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.09358"
  },
  {
    "id": "arXiv:2204.11804",
    "title": "Online Simulation Reduction",
    "abstract": "Comments: 24 pages, 4 algorithms, 1 table",
    "descriptor": "\nComments: 24 pages, 4 algorithms, 1 table\n",
    "authors": [
      "Pierre Ganty",
      "Nicolas Manini",
      "Francesco Ranzato"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.11804"
  },
  {
    "id": "arXiv:2204.12451",
    "title": "Understanding The Robustness in Vision Transformers",
    "abstract": "Understanding The Robustness in Vision Transformers",
    "descriptor": "",
    "authors": [
      "Daquan Zhou",
      "Zhiding Yu",
      "Enze Xie",
      "Chaowei Xiao",
      "Anima Anandkumar",
      "Jiashi Feng",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12451"
  },
  {
    "id": "arXiv:2205.01304",
    "title": "Efficient dynamic filter for robust and low computational feature  extraction",
    "abstract": "Comments: Accept to SLT2022",
    "descriptor": "\nComments: Accept to SLT2022\n",
    "authors": [
      "Donghyeon Kim",
      "Gwantae Kim",
      "Bokyeung Lee",
      "Jeong-gi Kwak",
      "David K. Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.01304"
  },
  {
    "id": "arXiv:2205.02697",
    "title": "Mode Reduction for Markov Jump Systems",
    "abstract": "Mode Reduction for Markov Jump Systems",
    "descriptor": "",
    "authors": [
      "Zhe Du",
      "Laura Balzano",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02697"
  },
  {
    "id": "arXiv:2205.05446",
    "title": "Predictive Compliance Monitoring in Process-Aware Information Systems:  State of the Art, Functionalities, Research Directions",
    "abstract": "Predictive Compliance Monitoring in Process-Aware Information Systems:  State of the Art, Functionalities, Research Directions",
    "descriptor": "",
    "authors": [
      "Stefanie Rinderle-Ma",
      "Karolin Winter",
      "Janik-Vasily Benzin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05446"
  },
  {
    "id": "arXiv:2205.05455",
    "title": "Final Iteration Convergence of Q-Learning: Switching System Approach",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.08583",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.08583\n",
    "authors": [
      "Donghwna Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05455"
  },
  {
    "id": "arXiv:2205.08232",
    "title": "LogicSolver: Towards Interpretable Math Word Problem Solving with  Logical Prompt-enhanced Learning",
    "abstract": "LogicSolver: Towards Interpretable Math Word Problem Solving with  Logical Prompt-enhanced Learning",
    "descriptor": "",
    "authors": [
      "Zhicheng Yang",
      "Jinghui Qin",
      "Jiaqi Chen",
      "Liang Lin",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.08232"
  },
  {
    "id": "arXiv:2205.08836",
    "title": "Large Neural Networks Learning from Scratch with Very Few Data and  without Explicit Regularization",
    "abstract": "Comments: 11 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: 11 pages, 3 figures, 4 tables\n",
    "authors": [
      "Christoph Linse",
      "Thomas Martinetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.08836"
  },
  {
    "id": "arXiv:2205.09113",
    "title": "Masked Autoencoders As Spatiotemporal Learners",
    "abstract": "Masked Autoencoders As Spatiotemporal Learners",
    "descriptor": "",
    "authors": [
      "Christoph Feichtenhofer",
      "Haoqi Fan",
      "Yanghao Li",
      "Kaiming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09113"
  },
  {
    "id": "arXiv:2205.09837",
    "title": "Summarization as Indirect Supervision for Relation Extraction",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Keming Lu",
      "I-Hung Hsu",
      "Wenxuan Zhou",
      "Mingyu Derek Ma",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09837"
  },
  {
    "id": "arXiv:2205.10577",
    "title": "Non-Autoregressive Neural Machine Translation: A Call for Clarity",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Robin M. Schmidt",
      "Telmo Pires",
      "Stephan Peitz",
      "Jonas L\u00f6\u00f6f"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10577"
  },
  {
    "id": "arXiv:2205.10828",
    "title": "What Do Compressed Multilingual Machine Translation Models Forget?",
    "abstract": "Comments: Accepted to Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Alireza Mohammadshahi",
      "Vassilina Nikoulina",
      "Alexandre Berard",
      "Caroline Brun",
      "James Henderson",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10828"
  },
  {
    "id": "arXiv:2205.11255",
    "title": "A Template-based Method for Constrained Neural Machine Translation",
    "abstract": "Comments: Accepted by EMNLP 2022 (main conference)",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (main conference)\n",
    "authors": [
      "Shuo Wang",
      "Peng Li",
      "Zhixing Tan",
      "Zhaopeng Tu",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11255"
  },
  {
    "id": "arXiv:2205.11275",
    "title": "RL with KL penalties is better viewed as Bayesian inference",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tomasz Korbak",
      "Ethan Perez",
      "Christopher L Buckley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11275"
  },
  {
    "id": "arXiv:2205.11432",
    "title": "Logical Reasoning with Span-Level Predictions for Interpretable and  Robust NLI Models",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Joe Stacey",
      "Pasquale Minervini",
      "Haim Dubossarsky",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11432"
  },
  {
    "id": "arXiv:2205.12491",
    "title": "Fine-grained Contrastive Learning for Relation Extraction",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "William Hogan",
      "Jiacheng Li",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12491"
  },
  {
    "id": "arXiv:2205.14204",
    "title": "Multimodal Masked Autoencoders Learn Transferable Representations",
    "abstract": "Multimodal Masked Autoencoders Learn Transferable Representations",
    "descriptor": "",
    "authors": [
      "Xinyang Geng",
      "Hao Liu",
      "Lisa Lee",
      "Dale Schuurmans",
      "Sergey Levine",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14204"
  },
  {
    "id": "arXiv:2205.14219",
    "title": "Controllable Text Generation with Neurally-Decomposed Oracle",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Tao Meng",
      "Sidi Lu",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14219"
  },
  {
    "id": "arXiv:2205.14282",
    "title": "Investigating End-user Acceptance of Last-mile Delivery by Autonomous  Vehicles in the United States",
    "abstract": "Investigating End-user Acceptance of Last-mile Delivery by Autonomous  Vehicles in the United States",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Olivia Verni",
      "Ian Moore",
      "Sall Aboubacar",
      "Jen Arriaza",
      "Sabrina Jivani",
      "Audrey Bennett",
      "Siqi Li",
      "Dongnanzi Zheng",
      "Stavros Zervoudakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.14282"
  },
  {
    "id": "arXiv:2205.15701",
    "title": "Provable General Function Class Representation Learning in Multitask  Bandits and MDPs",
    "abstract": "Provable General Function Class Representation Learning in Multitask  Bandits and MDPs",
    "descriptor": "",
    "authors": [
      "Rui Lu",
      "Andrew Zhao",
      "Simon S. Du",
      "Gao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15701"
  },
  {
    "id": "arXiv:2205.15764",
    "title": "SymFormer: End-to-end symbolic regression using transformer-based  architecture",
    "abstract": "SymFormer: End-to-end symbolic regression using transformer-based  architecture",
    "descriptor": "",
    "authors": [
      "Martin Vastl",
      "Jon\u00e1\u0161 Kulh\u00e1nek",
      "Ji\u0159\u00ed Kubal\u00edk",
      "Erik Derner",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15764"
  },
  {
    "id": "arXiv:2206.00730",
    "title": "The Phenomenon of Policy Churn",
    "abstract": "Comments: Published at NeurIPS 2022",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Tom Schaul",
      "Andr\u00e9 Barreto",
      "John Quan",
      "Georg Ostrovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00730"
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "descriptor": "",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01992"
  },
  {
    "id": "arXiv:2206.04176",
    "title": "VN-Transformer: Rotation-Equivariant Attention for Vector Neurons",
    "abstract": "Comments: Workshop on Machine Learning for Autonomous Driving, Conference on Neural Information Processing Systems (NeurIPS), 2022",
    "descriptor": "\nComments: Workshop on Machine Learning for Autonomous Driving, Conference on Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Serge Assaad",
      "Carlton Downey",
      "Rami Al-Rfou",
      "Nigamaa Nayakanti",
      "Ben Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04176"
  },
  {
    "id": "arXiv:2206.05644",
    "title": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "abstract": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "descriptor": "",
    "authors": [
      "Ildebrando Magnani"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05644"
  },
  {
    "id": "arXiv:2206.06968",
    "title": "On the necessity of the inf-sup condition for a mixed finite element  formulation",
    "abstract": "On the necessity of the inf-sup condition for a mixed finite element  formulation",
    "descriptor": "",
    "authors": [
      "Fleurianne Bertrand",
      "Daniele Boffi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06968"
  },
  {
    "id": "arXiv:2206.07332",
    "title": "Modelling of AC/DC Interactions of Converter-Interfaced Resources for  Harmonic Power-Flow Studies in Microgrids",
    "abstract": "Modelling of AC/DC Interactions of Converter-Interfaced Resources for  Harmonic Power-Flow Studies in Microgrids",
    "descriptor": "",
    "authors": [
      "Johanna Kristin Maria Becker",
      "Andreas Martin Kettner",
      "Yihui Zuo",
      "Federico Cecati",
      "Sante Pugliese",
      "Marco Liserre",
      "Mario Paolone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.07332"
  },
  {
    "id": "arXiv:2206.10255",
    "title": "GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without  Bells and Whistles",
    "abstract": "Comments: accepted by IEEE Transactions on Intelligent Vehicles",
    "descriptor": "\nComments: accepted by IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Jianan Liu",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Bing Zhu",
      "Qing-Long Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10255"
  },
  {
    "id": "arXiv:2206.10763",
    "title": "Simulated redistricting plans for the analysis and evaluation of  redistricting in the United States",
    "abstract": "Comments: 11 pages, 3 figures",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Cory McCartan",
      "Christopher T. Kenny",
      "Tyler Simko",
      "George Garcia III",
      "Kevin Wang",
      "Melissa Wu",
      "Shiro Kuriwaki",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.10763"
  },
  {
    "id": "arXiv:2206.11081",
    "title": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "abstract": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "descriptor": "",
    "authors": [
      "Hongjoon Ahn",
      "Yongyi Yang",
      "Quan Gan",
      "Taesup Moon",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11081"
  },
  {
    "id": "arXiv:2206.11426",
    "title": "On a class of geodesically convex optimization problems solved via  Euclidean MM methods",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Melanie Weber",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11426"
  },
  {
    "id": "arXiv:2206.13810",
    "title": "Gray Images of Cyclic Codes over $\\mathbb{Z}_{p^2}$ and  $\\mathbb{Z}_p\\mathbb{Z}_{p^2}",
    "abstract": "Gray Images of Cyclic Codes over $\\mathbb{Z}_{p^2}$ and  $\\mathbb{Z}_p\\mathbb{Z}_{p^2}",
    "descriptor": "",
    "authors": [
      "Minjia Shi",
      "Xuan Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.13810"
  },
  {
    "id": "arXiv:2206.13901",
    "title": "Value Function Decomposition for Iterative Design of Reinforcement  Learning Agents",
    "abstract": "Comments: 10 content pages, 12 Appendix pages, 19 figures",
    "descriptor": "\nComments: 10 content pages, 12 Appendix pages, 19 figures\n",
    "authors": [
      "James MacGlashan",
      "Evan Archer",
      "Alisa Devlic",
      "Takuma Seno",
      "Craig Sherstan",
      "Peter R. Wurman",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13901"
  },
  {
    "id": "arXiv:2206.14451",
    "title": "SRCN3D: Sparse R-CNN 3D Surround-View Camera Object Detection and  Tracking for Autonomous Driving",
    "abstract": "Comments: Add results on test set",
    "descriptor": "\nComments: Add results on test set\n",
    "authors": [
      "Yining Shi",
      "Jingyan Shen",
      "Yifan Sun",
      "Yunlong Wang",
      "Jiaxin Li",
      "Shiqi Sun",
      "Kun Jiang",
      "Diange Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14451"
  },
  {
    "id": "arXiv:2207.01560",
    "title": "High-Dimensional Private Empirical Risk Minimization by Greedy  Coordinate Descent",
    "abstract": "Comments: 27 pages, 4 figures",
    "descriptor": "\nComments: 27 pages, 4 figures\n",
    "authors": [
      "Paul Mangold",
      "Aur\u00e9lien Bellet",
      "Joseph Salmon",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01560"
  },
  {
    "id": "arXiv:2207.02159",
    "title": "Robustness Analysis of Video-Language Models Against Visual and Language  Perturbations",
    "abstract": "Comments: NeurIPS 2022 Datasets and Benchmarks Track. This projects webpage is located at this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Datasets and Benchmarks Track. This projects webpage is located at this https URL\n",
    "authors": [
      "Madeline C. Schiappa",
      "Shruti Vyas",
      "Hamid Palangi",
      "Yogesh S. Rawat",
      "Vibhav Vineet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.02159"
  },
  {
    "id": "arXiv:2207.04153",
    "title": "Probing Classifiers are Unreliable for Concept Removal and Detection",
    "abstract": "Probing Classifiers are Unreliable for Concept Removal and Detection",
    "descriptor": "",
    "authors": [
      "Abhinav Kumar",
      "Chenhao Tan",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04153"
  },
  {
    "id": "arXiv:2207.05691",
    "title": "The MuSe 2022 Multimodal Sentiment Analysis Challenge: Humor, Emotional  Reactions, and Stress",
    "abstract": "Comments: Baseline paper for the 3rd Multimodal Sentiment Analysis Challenge (MuSe) 2022, a full-day workshop at ACM Multimedia 2022",
    "descriptor": "\nComments: Baseline paper for the 3rd Multimodal Sentiment Analysis Challenge (MuSe) 2022, a full-day workshop at ACM Multimedia 2022\n",
    "authors": [
      "Lukas Christ",
      "Shahin Amiriparian",
      "Alice Baird",
      "Panagiotis Tzirakis",
      "Alexander Kathan",
      "Niklas M\u00fcller",
      "Lukas Stappen",
      "Eva-Maria Me\u00dfner",
      "Andreas K\u00f6nig",
      "Alan Cowen",
      "Erik Cambria",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.05691"
  },
  {
    "id": "arXiv:2207.06130",
    "title": "Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent  Variable Inference for Text Generation",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Jinyi Hu",
      "Xiaoyuan Yi",
      "Wenhao Li",
      "Maosong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.06130"
  },
  {
    "id": "arXiv:2207.06569",
    "title": "Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting",
    "abstract": "Comments: NM and JS co-first authors",
    "descriptor": "\nComments: NM and JS co-first authors\n",
    "authors": [
      "Neil Mallinar",
      "James B. Simon",
      "Amirhesam Abedsoltan",
      "Parthe Pandit",
      "Mikhail Belkin",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.06569"
  },
  {
    "id": "arXiv:2207.08208",
    "title": "Unsupervised Medical Image Translation with Adversarial Diffusion Models",
    "abstract": "Unsupervised Medical Image Translation with Adversarial Diffusion Models",
    "descriptor": "",
    "authors": [
      "Muzaffer \u00d6zbey",
      "Onat Dalmaz",
      "Salman UH Dar",
      "Hasan A Bedel",
      "\u015eaban \u00d6zturk",
      "Alper G\u00fcng\u00f6r",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08208"
  },
  {
    "id": "arXiv:2207.09239",
    "title": "Assaying Out-Of-Distribution Generalization in Transfer Learning",
    "abstract": "Assaying Out-Of-Distribution Generalization in Transfer Learning",
    "descriptor": "",
    "authors": [
      "Florian Wenzel",
      "Andrea Dittadi",
      "Peter Vincent Gehler",
      "Carl-Johann Simon-Gabriel",
      "Max Horn",
      "Dominik Zietlow",
      "David Kernert",
      "Chris Russell",
      "Thomas Brox",
      "Bernt Schiele",
      "Bernhard Sch\u00f6lkopf",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09239"
  },
  {
    "id": "arXiv:2207.10308",
    "title": "UniFed: A Benchmark for Federated Learning Frameworks",
    "abstract": "Comments: Code: this https URL Website: this https URL",
    "descriptor": "\nComments: Code: this https URL Website: this https URL\n",
    "authors": [
      "Xiaoyuan Liu",
      "Tianneng Shi",
      "Chulin Xie",
      "Qinbin Li",
      "Kangping Hu",
      "Haoyu Kim",
      "Xiaojun Xu",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10308"
  },
  {
    "id": "arXiv:2208.04761",
    "title": "Digital health shopping assistant with React Native: a simple  technological solution to a complex health problem",
    "abstract": "Digital health shopping assistant with React Native: a simple  technological solution to a complex health problem",
    "descriptor": "",
    "authors": [
      "Alina Govoruhina",
      "Anastasija Nikiforova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.04761"
  },
  {
    "id": "arXiv:2208.09632",
    "title": "Adam Can Converge Without Any Modification on Update Rules",
    "abstract": "Comments: 66 pages",
    "descriptor": "\nComments: 66 pages\n",
    "authors": [
      "Yushun Zhang",
      "Congliang Chen",
      "Naichen Shi",
      "Ruoyu Sun",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09632"
  },
  {
    "id": "arXiv:2208.11803",
    "title": "Practical Real Video Denoising with Realistic Degradation Model",
    "abstract": "Practical Real Video Denoising with Realistic Degradation Model",
    "descriptor": "",
    "authors": [
      "Jiezhang Cao",
      "Qin Wang",
      "Jingyun Liang",
      "Yulun Zhang",
      "Kai Zhang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.11803"
  },
  {
    "id": "arXiv:2209.00771",
    "title": "Optimizing the Performative Risk under Weak Convexity Assumptions",
    "abstract": "Comments: Neurips 2022 Workshop on Optimization for Machine Learning",
    "descriptor": "\nComments: Neurips 2022 Workshop on Optimization for Machine Learning\n",
    "authors": [
      "Yulai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.00771"
  },
  {
    "id": "arXiv:2209.00780",
    "title": "Index Tracking via Learning to Predict Market Sensitivities",
    "abstract": "Index Tracking via Learning to Predict Market Sensitivities",
    "descriptor": "",
    "authors": [
      "Yoonsik Hong",
      "Yanghoon Kim",
      "Jeonghun Kim",
      "Yongmin Choi"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.00780"
  },
  {
    "id": "arXiv:2209.01346",
    "title": "HammingMesh: A Network Topology for Large-Scale Deep Learning",
    "abstract": "Comments: published at ACM/IEEE Supercomputing (SC22)",
    "descriptor": "\nComments: published at ACM/IEEE Supercomputing (SC22)\n",
    "authors": [
      "Torsten Hoefler",
      "Tommaso Bonato",
      "Daniele De Sensi",
      "Salvatore Di Girolamo",
      "Shigang Li",
      "Marco Heddes",
      "Jon Belk",
      "Deepak Goel",
      "Miguel Castro",
      "Steve Scott"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2209.01346"
  },
  {
    "id": "arXiv:2209.01458",
    "title": "A Markov Process Theory for Network Growth Processes of DAG-based  Blockchain Systems",
    "abstract": "Comments: 49 pages, 9 figures",
    "descriptor": "\nComments: 49 pages, 9 figures\n",
    "authors": [
      "Xing-Shuo Song",
      "Quan-Lin Li",
      "Yan-Xia Chang",
      "Chi Zhang"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2209.01458"
  },
  {
    "id": "arXiv:2209.02299",
    "title": "A Survey of Machine Unlearning",
    "abstract": "Comments: discuss new and recent works as well as proof-reading",
    "descriptor": "\nComments: discuss new and recent works as well as proof-reading\n",
    "authors": [
      "Thanh Tam Nguyen",
      "Thanh Trung Huynh",
      "Phi Le Nguyen",
      "Alan Wee-Chung Liew",
      "Hongzhi Yin",
      "Quoc Viet Hung Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.02299"
  },
  {
    "id": "arXiv:2209.03115",
    "title": "Inference and Learning for Generative Capsule Models",
    "abstract": "Comments: 31 pages, 6 figures. This paper extends our previous work (arxiv:2103.06676) by covering the learning of the models as well as inference. Paper accepted for publication in Neural Computation",
    "descriptor": "\nComments: 31 pages, 6 figures. This paper extends our previous work (arxiv:2103.06676) by covering the learning of the models as well as inference. Paper accepted for publication in Neural Computation\n",
    "authors": [
      "Alfredo Nazabal",
      "Nikolaos Tsagkas",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03115"
  },
  {
    "id": "arXiv:2209.03522",
    "title": "Machine Learning Sensors for Diagnosis of COVID-19 Disease Using Routine  Blood Values for Internet of Things Application",
    "abstract": "Comments: 30 pages, 9 figures, 8 tables, 1 algorithm",
    "descriptor": "\nComments: 30 pages, 9 figures, 8 tables, 1 algorithm\n",
    "authors": [
      "Andrei Velichko",
      "Mehmet Tahir Huyut",
      "Maksim Belyaev",
      "Yuriy Izotov",
      "Dmitry Korzun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.03522"
  },
  {
    "id": "arXiv:2209.03755",
    "title": "Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against  Fact-Verification Systems",
    "abstract": "Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against  Fact-Verification Systems",
    "descriptor": "",
    "authors": [
      "Sahar Abdelnabi",
      "Mario Fritz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03755"
  },
  {
    "id": "arXiv:2209.05819",
    "title": "Numerical rank of kernel functions",
    "abstract": "Comments: 23 pages, 23 figures, 14 tables",
    "descriptor": "\nComments: 23 pages, 23 figures, 14 tables\n",
    "authors": [
      "Ritesh Khan",
      "V A Kandappan",
      "Sivaram Ambikasaran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.05819"
  },
  {
    "id": "arXiv:2209.07067",
    "title": "Efficient learning of nonlinear prediction models with time-series  privileged information",
    "abstract": "Efficient learning of nonlinear prediction models with time-series  privileged information",
    "descriptor": "",
    "authors": [
      "Bastian Jung",
      "Fredrik D Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07067"
  },
  {
    "id": "arXiv:2209.07859",
    "title": "Extracting Biomedical Factual Knowledge Using Pretrained Language Model  and Electronic Health Record Context",
    "abstract": "Comments: Presented at the AMIA 2022 Annual Symposium as an oral paper. Revised some content in Introduction and Related Work section",
    "descriptor": "\nComments: Presented at the AMIA 2022 Annual Symposium as an oral paper. Revised some content in Introduction and Related Work section\n",
    "authors": [
      "Zonghai Yao",
      "Yi Cao",
      "Zhichao Yang",
      "Vijeta Deshpande",
      "Hong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07859"
  },
  {
    "id": "arXiv:2209.09444",
    "title": "Vega-MT: The JD Explore Academy Translation System for WMT22",
    "abstract": "Comments: WMT 2022 (Among all constrained systems, Vega-MT won 7 champions, 2 runners-up and 1 third place w.r.t sacreBLEU, and won 8 champions and 2 runners-up w.r.t COMET.)",
    "descriptor": "\nComments: WMT 2022 (Among all constrained systems, Vega-MT won 7 champions, 2 runners-up and 1 third place w.r.t sacreBLEU, and won 8 champions and 2 runners-up w.r.t COMET.)\n",
    "authors": [
      "Changtong Zan",
      "Keqin Peng",
      "Liang Ding",
      "Baopu Qiu",
      "Boan Liu",
      "Shwai He",
      "Qingyu Lu",
      "Zheng Zhang",
      "Chuang Liu",
      "Weifeng Liu",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.09444"
  },
  {
    "id": "arXiv:2209.10614",
    "title": "Learning-Augmented Algorithms for Online Linear and Semidefinite  Programming",
    "abstract": "Comments: 44 pages, 3 figures. To appear in NeurIPS 2022",
    "descriptor": "\nComments: 44 pages, 3 figures. To appear in NeurIPS 2022\n",
    "authors": [
      "Elena Grigorescu",
      "Young-San Lin",
      "Sandeep Silwal",
      "Maoyuan Song",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.10614"
  },
  {
    "id": "arXiv:2209.10873",
    "title": "Turning Normalizing Flows into Monge Maps with Geodesic Gaussian  Preserving Flows",
    "abstract": "Turning Normalizing Flows into Monge Maps with Geodesic Gaussian  Preserving Flows",
    "descriptor": "",
    "authors": [
      "Guillaume Morel",
      "Lucas Drumetz",
      "Simon Bena\u00efchouche",
      "Nicolas Courty",
      "Fran\u00e7ois Rousseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10873"
  },
  {
    "id": "arXiv:2209.11518",
    "title": "Marine Video Kit: A New Marine Video Dataset for Content-based Analysis  and Retrieval",
    "abstract": "Comments: 12 pages of content with 2 pages of reference",
    "descriptor": "\nComments: 12 pages of content with 2 pages of reference\n",
    "authors": [
      "Quang-Trung Truong",
      "Tuan-Anh Vu",
      "Tan-Sang Ha",
      "Lokoc Jakub",
      "Yue Him Wong Tim",
      "Ajay Joneja",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11518"
  },
  {
    "id": "arXiv:2209.11920",
    "title": "Tradeoffs between convergence rate and noise amplification for  momentum-based accelerated optimization algorithms",
    "abstract": "Comments: 28 pages; 10 figures",
    "descriptor": "\nComments: 28 pages; 10 figures\n",
    "authors": [
      "Hesameddin Mohammadi",
      "Meisam Razaviyayn",
      "Mihailo R. Jovanovi\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11920"
  },
  {
    "id": "arXiv:2210.00518",
    "title": "High Precision Differentiation Techniques for Data-Driven Solution of  Nonlinear PDEs by Physics-Informed Neural Networks",
    "abstract": "Comments: 23 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 23 pages, 4 figures, 2 tables\n",
    "authors": [
      "Marat S. Mukhametzhanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00518"
  },
  {
    "id": "arXiv:2210.00571",
    "title": "Beyond the Existential Theory of the Reals",
    "abstract": "Beyond the Existential Theory of the Reals",
    "descriptor": "",
    "authors": [
      "Marcus Schaefer",
      "Daniel Stefankovic"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.00571"
  },
  {
    "id": "arXiv:2210.00805",
    "title": "Limitations of neural network training due to numerical instability of  backpropagation",
    "abstract": "Limitations of neural network training due to numerical instability of  backpropagation",
    "descriptor": "",
    "authors": [
      "Clemens Karner",
      "Vladimir Kazeev",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00805"
  },
  {
    "id": "arXiv:2210.00935",
    "title": "Analysis of (sub-)Riemannian PDE-G-CNNs",
    "abstract": "Comments: 28 pages, 19 figures",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Gijs Bellaard",
      "Daan L. J. Bon",
      "Gautam Pai",
      "Bart M. N. Smets",
      "Remco Duits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2210.00935"
  },
  {
    "id": "arXiv:2210.01739",
    "title": "Enabling a Zero Trust Architecture in a 5G-enabled Smart Grid",
    "abstract": "Enabling a Zero Trust Architecture in a 5G-enabled Smart Grid",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Alipour",
      "Saeid Ghasemshirazi",
      "Ghazaleh Shirvani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.01739"
  },
  {
    "id": "arXiv:2210.02952",
    "title": "Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation",
    "abstract": "Comments: 15 pages, 11 figures, Findings of EMNLP 2022",
    "descriptor": "\nComments: 15 pages, 11 figures, Findings of EMNLP 2022\n",
    "authors": [
      "Xu Guo",
      "Boyang Li",
      "Han Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02952"
  },
  {
    "id": "arXiv:2210.03992",
    "title": "Generative Language Models for Paragraph-Level Question Generation",
    "abstract": "Comments: EMNLP 2022 main conference",
    "descriptor": "\nComments: EMNLP 2022 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Fernando Alva-Manchego",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03992"
  },
  {
    "id": "arXiv:2210.04284",
    "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency  of Adapters",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Miao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04284"
  },
  {
    "id": "arXiv:2210.04573",
    "title": "HumSet: Dataset of Multilingual Information Extraction and  Classification for Humanitarian Crisis Response",
    "abstract": "HumSet: Dataset of Multilingual Information Extraction and  Classification for Humanitarian Crisis Response",
    "descriptor": "",
    "authors": [
      "Selim Fekih",
      "Nicolo' Tamagnone",
      "Benjamin Minixhofer",
      "Ranjan Shrestha",
      "Ximena Contla",
      "Ewan Oglethorpe",
      "Navid Rekabsaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04573"
  },
  {
    "id": "arXiv:2210.05078",
    "title": "Joint Human Orientation-Activity Recognition Using WiFi Signals for  Human-Machine Interaction",
    "abstract": "Joint Human Orientation-Activity Recognition Using WiFi Signals for  Human-Machine Interaction",
    "descriptor": "",
    "authors": [
      "Hojjat Salehinejad",
      "Navid Hasanzadeh",
      "Radomir Djogo",
      "Shahrokh Valaee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.05078"
  },
  {
    "id": "arXiv:2210.05330",
    "title": "Label Noise-Robust Learning using a Confidence-Based Sieving Strategy",
    "abstract": "Label Noise-Robust Learning using a Confidence-Based Sieving Strategy",
    "descriptor": "",
    "authors": [
      "Reihaneh Torkzadehmahani",
      "Reza Nasirigerdeh",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05330"
  },
  {
    "id": "arXiv:2210.05370",
    "title": "DeepPerform: An Efficient Approach for Performance Testing of  Resource-Constrained Neural Networks",
    "abstract": "Comments: This paper is accepted to IEEE/ACM International Conference on Automated Software Engineering 2022",
    "descriptor": "\nComments: This paper is accepted to IEEE/ACM International Conference on Automated Software Engineering 2022\n",
    "authors": [
      "Simin Chen",
      "Mirazul Haque",
      "Cong Liu",
      "Wei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.05370"
  },
  {
    "id": "arXiv:2210.06006",
    "title": "BEV-LaneDet: Fast Lane Detection on BEV Ground",
    "abstract": "Comments: 10 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 10 pages, 3 figures, 5 tables\n",
    "authors": [
      "Ruihao Wang",
      "Jian Qin",
      "Kaiying Li",
      "Dong Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06006"
  },
  {
    "id": "arXiv:2210.06110",
    "title": "Uplift and Upsample: Efficient 3D Human Pose Estimation with Uplifting  Transformers",
    "abstract": "Comments: Accepted at IEEE/CVF WACV 2023",
    "descriptor": "\nComments: Accepted at IEEE/CVF WACV 2023\n",
    "authors": [
      "Moritz Einfalt",
      "Katja Ludwig",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06110"
  },
  {
    "id": "arXiv:2210.06346",
    "title": "Predicting the clinical citation count of biomedical papers using  multilayer perceptron neural network",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Qikai Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06346"
  },
  {
    "id": "arXiv:2210.07432",
    "title": "Monte Carlo Augmented Actor-Critic for Sparse Reward Deep Reinforcement  Learning from Suboptimal Demonstrations",
    "abstract": "Comments: To be published in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 19 pages. 11 figures",
    "descriptor": "\nComments: To be published in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 19 pages. 11 figures\n",
    "authors": [
      "Albert Wilcox",
      "Ashwin Balakrishna",
      "Jules Dedieu",
      "Wyame Benslimane",
      "Daniel S. Brown",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07432"
  },
  {
    "id": "arXiv:2210.08340",
    "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI  Revolution",
    "abstract": "Comments: White paper, 8 pages + 3 pages of references, 0 figures",
    "descriptor": "\nComments: White paper, 8 pages + 3 pages of references, 0 figures\n",
    "authors": [
      "Anthony Zador",
      "Blake Richards",
      "Bence \u00d6lveczky",
      "Sean Escola",
      "Yoshua Bengio",
      "Kwabena Boahen",
      "Matthew Botvinick",
      "Dmitri Chklovskii",
      "Anne Churchland",
      "Claudia Clopath",
      "James DiCarlo",
      "Surya Ganguli",
      "Jeff Hawkins",
      "Konrad Koerding",
      "Alexei Koulakov",
      "Yann LeCun",
      "Timothy Lillicrap",
      "Adam Marblestone",
      "Bruno Olshausen",
      "Alexandre Pouget",
      "Cristina Savin",
      "Terrence Sejnowski",
      "Eero Simoncelli",
      "Sara Solla",
      "David Sussillo",
      "Andreas S. Tolias",
      "Doris Tsao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.08340"
  },
  {
    "id": "arXiv:2210.08459",
    "title": "StoryER: Automatic Story Evaluation via Ranking, Rating and Reasoning",
    "abstract": "Comments: accepted by EMNLP 2022",
    "descriptor": "\nComments: accepted by EMNLP 2022\n",
    "authors": [
      "Hong Chen",
      "Duc Minh Vo",
      "Hiroya Takamura",
      "Yusuke Miyao",
      "Hideki Nakayama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08459"
  },
  {
    "id": "arXiv:2210.08474",
    "title": "Sentence Representation Learning with Generative Objective rather than  Contrastive Objective",
    "abstract": "Comments: Accepted by the Main Conference of EMNLP 2022, long paper. arXiv admin note: substantial text overlap with arXiv:2204.09358",
    "descriptor": "\nComments: Accepted by the Main Conference of EMNLP 2022, long paper. arXiv admin note: substantial text overlap with arXiv:2204.09358\n",
    "authors": [
      "Bohong Wu",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08474"
  },
  {
    "id": "arXiv:2210.08574",
    "title": "Machine Learning based Discrimination for Excited State Promoted Readout",
    "abstract": "Comments: Accepted at ACM/IEE Quantum'22. 6 pages, 5 figures and 1 table",
    "descriptor": "\nComments: Accepted at ACM/IEE Quantum'22. 6 pages, 5 figures and 1 table\n",
    "authors": [
      "Utkarsh Azad",
      "Helena Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08574"
  },
  {
    "id": "arXiv:2210.08806",
    "title": "HCL-TAT: A Hybrid Contrastive Learning Method for Few-shot Event  Detection with Task-Adaptive Threshold",
    "abstract": "Comments: This paper has been accepted by Findings of EMNLP 2022",
    "descriptor": "\nComments: This paper has been accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Ruihan Zhang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08806"
  },
  {
    "id": "arXiv:2210.08836",
    "title": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "abstract": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "descriptor": "",
    "authors": [
      "Peirong Zhang",
      "Jiajia Jiang",
      "Yuliang Liu",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08836"
  },
  {
    "id": "arXiv:2210.09582",
    "title": "NADI 2022: The Third Nuanced Arabic Dialect Identification Shared Task",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2103.08466",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.08466\n",
    "authors": [
      "Muhammad Abdul-Mageed",
      "Chiyu Zhang",
      "AbdelRahim Elmadany",
      "Houda Bouamor",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09582"
  },
  {
    "id": "arXiv:2210.09914",
    "title": "Computing MEMs on Repetitive Text Collections",
    "abstract": "Computing MEMs on Repetitive Text Collections",
    "descriptor": "",
    "authors": [
      "Gonzalo Navarro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09914"
  },
  {
    "id": "arXiv:2210.10027",
    "title": "Maestro-U: Leveraging joint speech-text representation learning for zero  supervised speech ASR",
    "abstract": "Comments: Accepted by SLT 2022",
    "descriptor": "\nComments: Accepted by SLT 2022\n",
    "authors": [
      "Zhehuai Chen",
      "Ankur Bapna",
      "Andrew Rosenberg",
      "Yu Zhang",
      "Bhuvana Ramabhadran",
      "Pedro Moreno",
      "Nanxin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10027"
  },
  {
    "id": "arXiv:2210.10142",
    "title": "Graph Attention Networks Unveil Determinants of Intra- and Inter-city  Health Disparity",
    "abstract": "Graph Attention Networks Unveil Determinants of Intra- and Inter-city  Health Disparity",
    "descriptor": "",
    "authors": [
      "Chenyue Liu",
      "Chao Fan",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10142"
  },
  {
    "id": "arXiv:2210.10172",
    "title": "Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data  Structures",
    "abstract": "Comments: Updated abstract metadata formatting. Accepted in SODA'23",
    "descriptor": "\nComments: Updated abstract metadata formatting. Accepted in SODA'23\n",
    "authors": [
      "Timothy M. Chan",
      "Da Wei Zheng"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10172"
  },
  {
    "id": "arXiv:2210.10176",
    "title": "Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual  Question Answering",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Jialin Wu",
      "Raymond J. Mooney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10176"
  },
  {
    "id": "arXiv:2210.10240",
    "title": "Type-supervised sequence labeling based on the heterogeneous star graph  for named entity recognition",
    "abstract": "Type-supervised sequence labeling based on the heterogeneous star graph  for named entity recognition",
    "descriptor": "",
    "authors": [
      "Xueru Wen",
      "Changjiang Zhou",
      "Haotian Tang",
      "Luguang Liang",
      "Yu Jiang",
      "Hong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10240"
  },
  {
    "id": "arXiv:2210.10258",
    "title": "Continued Pretraining for Better Zero- and Few-Shot Promptability",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhaofeng Wu",
      "Robert L. Logan IV",
      "Pete Walsh",
      "Akshita Bhagia",
      "Dirk Groeneveld",
      "Sameer Singh",
      "Iz Beltagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10258"
  },
  {
    "id": "arXiv:2210.10262",
    "title": "Free energy model of emotional valence in dual-process perceptions",
    "abstract": "Free energy model of emotional valence in dual-process perceptions",
    "descriptor": "",
    "authors": [
      "Hideyoshi Yanagisawa",
      "Xiaoxiang Wu",
      "Kazutaka Ueda",
      "Takeo Kato"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.10262"
  },
  {
    "id": "arXiv:2210.10289",
    "title": "Language Model Decomposition: Quantifying the Dependency and Correlation  of Language Models",
    "abstract": "Comments: accepted by EMNLP 2022",
    "descriptor": "\nComments: accepted by EMNLP 2022\n",
    "authors": [
      "Hao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10289"
  },
  {
    "id": "arXiv:2210.10332",
    "title": "Revision Transformers: Getting RiT of No-Nos",
    "abstract": "Revision Transformers: Getting RiT of No-Nos",
    "descriptor": "",
    "authors": [
      "Felix Friedrich",
      "Wolfgang Stammer",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.10332"
  },
  {
    "id": "arXiv:2210.10473",
    "title": "FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping",
    "abstract": "Comments: Fixed the supplementary material layout in the end (past references). Added link to video results, which is mentioned in Results but was missing in the supplementary material",
    "descriptor": "\nComments: Fixed the supplementary material layout in the end (past references). Added link to video results, which is mentioned in Results but was missing in the supplementary material\n",
    "authors": [
      "Felix Rosberg",
      "Eren Erdal Aksoy",
      "Fernando Alonso-Fernandez",
      "Cristofer Englund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10473"
  },
  {
    "id": "arXiv:2210.10892",
    "title": "DEEP$^2$: Deep Learning Powered De-scattering with Excitation Patterning",
    "abstract": "DEEP$^2$: Deep Learning Powered De-scattering with Excitation Patterning",
    "descriptor": "",
    "authors": [
      "Navodini Wijethilake",
      "Mithunjha Anandakumar",
      "Cheng Zheng",
      "Peter T. C. So",
      "Murat Yildirim",
      "Dushan N. Wadduwage"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10892"
  },
  {
    "id": "arXiv:2210.10906",
    "title": "A baseline revisited: Pushing the limits of multi-segment models for  context-aware translation",
    "abstract": "A baseline revisited: Pushing the limits of multi-segment models for  context-aware translation",
    "descriptor": "",
    "authors": [
      "Suvodeep Majumder",
      "Stanislas Lauly",
      "Maria Nadejde",
      "Marcello Federico",
      "Georgiana Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10906"
  },
  {
    "id": "arXiv:2210.10920",
    "title": "DOT-VAE: Disentangling One Factor at a Time",
    "abstract": "DOT-VAE: Disentangling One Factor at a Time",
    "descriptor": "",
    "authors": [
      "Vaishnavi Patil",
      "Matthew Evanusa",
      "Joseph JaJa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.10920"
  },
  {
    "id": "arXiv:2210.10953",
    "title": "Discovering Many Diverse Solutions with Bayesian Optimization",
    "abstract": "Discovering Many Diverse Solutions with Bayesian Optimization",
    "descriptor": "",
    "authors": [
      "Natalie Maus",
      "Kaiwen Wu",
      "David Eriksson",
      "Jacob Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10953"
  },
  {
    "id": "arXiv:2210.10959",
    "title": "Uni6Dv3: 5D Anchor Mechanism for 6D Pose Estimation",
    "abstract": "Uni6Dv3: 5D Anchor Mechanism for 6D Pose Estimation",
    "descriptor": "",
    "authors": [
      "Jianqiu Chen",
      "Mingshan Sun",
      "Ye Zheng",
      "Tianpeng Bao",
      "Zhenyu He",
      "Donghai Li",
      "Guoqiang Jin",
      "Rui Zhao",
      "Liwei Wu",
      "Xiaoke Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10959"
  },
  {
    "id": "arXiv:2210.10992",
    "title": "NIFT: Neural Interaction Field and Template for Object Manipulation",
    "abstract": "NIFT: Neural Interaction Field and Template for Object Manipulation",
    "descriptor": "",
    "authors": [
      "Zeyu Huang",
      "Juzhan Xu",
      "Sisi Dai",
      "Kai Xu",
      "Hao Zhang",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.10992"
  },
  {
    "id": "arXiv:2210.11170",
    "title": "Coordinates Are NOT Lonely -- Codebook Prior Helps Implicit Neural 3D  Representations",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Fukun Yin",
      "Wen Liu",
      "Zilong Huang",
      "Pei Cheng",
      "Tao Chen",
      "Gang YU"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11170"
  },
  {
    "id": "arXiv:2210.11234",
    "title": "Development of a hardware-In-the-Loop (HIL) testbed for cyber-physical  security in smart buildings",
    "abstract": "Comments: to be published in 2023 ASHRAE Winter Conference",
    "descriptor": "\nComments: to be published in 2023 ASHRAE Winter Conference\n",
    "authors": [
      "Guowen Li",
      "Zhiyao Yang",
      "Yangyang Fu",
      "Lingyu Ren",
      "Zheng O'Neill",
      "Chirag Parikh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11234"
  },
  {
    "id": "arXiv:2210.11235",
    "title": "Interpretable Machine Learning for Detection and Classification of  Ransomware Families Based on API Calls",
    "abstract": "Interpretable Machine Learning for Detection and Classification of  Ransomware Families Based on API Calls",
    "descriptor": "",
    "authors": [
      "Rawshan Ara Mowri",
      "Madhuri Siddula",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11235"
  },
  {
    "id": "arXiv:2210.11292",
    "title": "Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts",
    "abstract": "Comments: Accepted by Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Xiangyang Liu",
      "Tianxiang Sun",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11292"
  },
  {
    "id": "arXiv:2210.11317",
    "title": "Dynamic selection of p-norm in linear adaptive filtering via online  kernel-based reinforcement learning",
    "abstract": "Dynamic selection of p-norm in linear adaptive filtering via online  kernel-based reinforcement learning",
    "descriptor": "",
    "authors": [
      "Minh Vu",
      "Yuki Akiyama",
      "Konstantinos Slavakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11317"
  },
  {
    "id": "arXiv:2210.11334",
    "title": "Proof of Unlearning: Definitions and Instantiation",
    "abstract": "Proof of Unlearning: Definitions and Instantiation",
    "descriptor": "",
    "authors": [
      "Jiasi Weng",
      "Shenglong Yao",
      "Yuefeng Du",
      "Junjie Huang",
      "Jian Weng",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11334"
  },
  {
    "id": "arXiv:2210.11366",
    "title": "Deep conditional transformation models for survival analysis",
    "abstract": "Deep conditional transformation models for survival analysis",
    "descriptor": "",
    "authors": [
      "Gabriele Campanella",
      "Lucas Kook",
      "Ida H\u00e4ggstr\u00f6m",
      "Torsten Hothorn",
      "Thomas J. Fuchs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11366"
  },
  {
    "id": "arXiv:2210.11416",
    "title": "Scaling Instruction-Finetuned Language Models",
    "abstract": "Comments: Public checkpoints: this https URL",
    "descriptor": "\nComments: Public checkpoints: this https URL\n",
    "authors": [
      "Hyung Won Chung",
      "Le Hou",
      "Shayne Longpre",
      "Barret Zoph",
      "Yi Tay",
      "William Fedus",
      "Eric Li",
      "Xuezhi Wang",
      "Mostafa Dehghani",
      "Siddhartha Brahma",
      "Albert Webson",
      "Shixiang Shane Gu",
      "Zhuyun Dai",
      "Mirac Suzgun",
      "Xinyun Chen",
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Gaurav Mishra",
      "Adams Yu",
      "Vincent Zhao",
      "Yanping Huang",
      "Andrew Dai",
      "Hongkun Yu",
      "Slav Petrov",
      "Ed H. Chi",
      "Jeff Dean",
      "Jacob Devlin",
      "Adam Roberts",
      "Denny Zhou",
      "Quoc V. Le",
      "Jason Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11416"
  },
  {
    "id": "arXiv:2210.11419",
    "title": "GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama  Registration Network",
    "abstract": "GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama  Registration Network",
    "descriptor": "",
    "authors": [
      "Jheng-Wei Su",
      "Chi-Han Peng",
      "Peter Wonka",
      "Hung-Kuo Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11419"
  }
]
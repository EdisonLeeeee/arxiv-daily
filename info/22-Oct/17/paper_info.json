[
  {
    "id": "arXiv:2210.07245",
    "title": "Autoencoder-Aided Visualization of Collections of Morse Complexes",
    "abstract": "Though analyzing a single scalar field using Morse complexes is well studied,\nthere are few techniques for visualizing a collection of Morse complexes. We\nfocus on analyses that are enabled by looking at a Morse complex as an embedded\ndomain decomposition. Specifically, we target 2D scalar fields, and we encode\nthe Morse complex through binary images of the boundaries of decomposition.\nThen we use image-based autoencoders to create a feature space for the Morse\ncomplexes. We apply additional dimensionality reduction methods to construct a\nscatterplot as a visual interface of the feature space. This allows us to\ninvestigate individual Morse complexes, as they relate to the collection,\nthrough interaction with the scatterplot. We demonstrate our approach using a\nsynthetic data set, microscopy images, and time-varying vorticity magnitude\nfields of flow. Through these, we show that our method can produce insights\nabout structures within the collection of Morse complexes.",
    "descriptor": "\nComments: Topo In Vis Workshop submission\n",
    "authors": [
      "Jixian Li",
      "Daniel Van Boxel",
      "Joshua A. Levine"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.07245"
  },
  {
    "id": "arXiv:2210.07246",
    "title": "Topics in Deep Learning and Optimization Algorithms for IoT Applications  in Smart Transportation",
    "abstract": "Nowadays, the Internet of Things (IoT) has become one of the most important\ntechnologies which enables a variety of connected and intelligent applications\nin smart cities. The smart decision making process of IoT devices not only\nrelies on the large volume of data collected from their sensors, but also\ndepends on advanced optimization theories and novel machine learning\ntechnologies which can process and analyse the collected data in specific\nnetwork structure. Therefore, it becomes practically important to investigate\nhow different optimization algorithms and machine learning techniques can be\nleveraged to improve system performance.\nAs one of the most important vertical domains for IoT applications, smart\ntransportation system has played a key role for providing real-world\ninformation and services to citizens by making their access to transport\nfacilities easier and thus it is one of the key application areas to be\nexplored in this thesis.\nIn a nutshell, this thesis covers three key topics related to applying\nmathematical optimization and deep learning methods to IoT networks. In the\nfirst topic, we propose an optimal transmission frequency management scheme\nusing decentralized ADMM-based method in a IoT network and introduce a\nmechanism to identify anomalies in data transmission frequency using an\nLSTM-based architecture. In the second topic, we leverage graph neural network\n(GNN) for demand prediction for shared bikes. In particular, we introduce a\nnovel architecture, i.e., attention-based spatial temporal graph convolutional\nnetwork (AST-GCN), to improve the prediction accuracy in real world datasets.\nIn the last topic, we consider a highway traffic network scenario where\nfrequent lane changing behaviors may occur with probability. A specific GNN\nbased anomaly detector is devised to reveal such a probability driven by data\ncollected in a dedicated mobility simulator.",
    "descriptor": "\nComments: The manuscript of thesis has been accepted and leads to the award of Master of Engineering in Dublin City University in September 2022\n",
    "authors": [
      "Hongde Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07246"
  },
  {
    "id": "arXiv:2210.07259",
    "title": "Skyplane: Optimizing Transfer Cost and Throughput Using Cloud-Aware  Overlays",
    "abstract": "Cloud applications are increasingly distributing data across multiple regions\nand cloud providers. Unfortunately, wide-area bulk data transfers are often\nslow, bottlenecking applications. We demonstrate that it is possible to\nsignificantly improve inter-region cloud bulk transfer throughput by adapting\nnetwork overlays to the cloud setting -- that is, by routing data through\nindirect paths at the application layer. However, directly applying network\noverlays in this setting can result in unacceptable increases in cloud egress\nprices. We present Skyplane, a system for bulk data transfer between cloud\nobject stores that uses cloud-aware network overlays to optimally navigate the\ntrade-off between price and performance. Skyplane's planner uses mixed-integer\nlinear programming to determine the optimal overlay path and resource\nallocation for data transfer, subject to user-provided constraints on price or\nperformance. Skyplane outperforms public cloud transfer services by up to\n$4.6\\times$ for transfers within one cloud and by up to $5.0\\times$ across\nclouds.",
    "descriptor": "\nComments: To appear at NSDI 2023\n",
    "authors": [
      "Paras Jain",
      "Sam Kumar",
      "Sarah Wooders",
      "Shishir G. Patil",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07259"
  },
  {
    "id": "arXiv:2210.07269",
    "title": "SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense  Reasoning Models",
    "abstract": "A common limitation of diagnostic tests for detecting social biases in NLP\nmodels is that they may only detect stereotypic associations that are\npre-specified by the designer of the test. Since enumerating all possible\nproblematic associations is infeasible, it is likely these tests fail to detect\nbiases that are present in a model but not pre-specified by the designer. To\naddress this limitation, we propose SODAPOP (SOcial bias Discovery from Answers\nabout PeOPle) in social commonsense question-answering. Our pipeline generates\nmodified instances from the Social IQa dataset (Sap et al., 2019) by (1)\nsubstituting names associated with different demographic groups, and (2)\ngenerating many distractor answers from a masked language model. By using a\nsocial commonsense model to score the generated distractors, we are able to\nuncover the model's stereotypic associations between demographic groups and an\nopen set of words. We also test SODAPOP on debiased models and show the\nlimitations of multiple state-of-the-art debiasing algorithms.",
    "descriptor": "",
    "authors": [
      "Haozhe An",
      "Zongxia Li",
      "Jieyu Zhao",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07269"
  },
  {
    "id": "arXiv:2210.07270",
    "title": "Multi-Task Learning for Joint Semantic Role and Proto-Role Labeling",
    "abstract": "We put forward an end-to-end multi-step machine learning model which jointly\nlabels semantic roles and the proto-roles of Dowty (1991), given a sentence and\nthe predicates therein. Our best architecture first learns argument spans\nfollowed by learning the argument's syntactic heads. This information is shared\nwith the next steps for predicting the semantic roles and proto-roles. We also\nexperiment with transfer learning from argument and head prediction to role and\nproto-role labeling. We compare using static and contextual embeddings for\nwords, arguments, and sentences. Unlike previous work, our model does not\nrequire pre-training or fine-tuning on additional tasks, beyond using\noff-the-shelf (static or contextual) embeddings and supervision. It also does\nnot require argument spans, their semantic roles, and/or their gold syntactic\nheads as additional input, because it learns to predict all these during\ntraining. Our multi-task learning model raises the state-of-the-art predictions\nfor most proto-roles.",
    "descriptor": "\nComments: 10 pages including references. 2 figures. First 2 authors contributed significantly\n",
    "authors": [
      "Aashish Arora",
      "Harshitha Malireddi",
      "Daniel Bauer",
      "Asad Sayeed",
      "Yuval Marton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07270"
  },
  {
    "id": "arXiv:2210.07271",
    "title": "BLOX: Macro Neural Architecture Search Benchmark and Algorithms",
    "abstract": "Neural architecture search (NAS) has been successfully used to design\nnumerous high-performance neural networks. However, NAS is typically\ncompute-intensive, so most existing approaches restrict the search to decide\nthe operations and topological structure of a single block only, then the same\nblock is stacked repeatedly to form an end-to-end model. Although such an\napproach reduces the size of search space, recent studies show that a macro\nsearch space, which allows blocks in a model to be different, can lead to\nbetter performance. To provide a systematic study of the performance of NAS\nalgorithms on a macro search space, we release Blox - a benchmark that consists\nof 91k unique models trained on the CIFAR-100 dataset. The dataset also\nincludes runtime measurements of all the models on a diverse set of hardware\nplatforms. We perform extensive experiments to compare existing algorithms that\nare well studied on cell-based search spaces, with the emerging blockwise\napproaches that aim to make NAS scalable to much larger macro search spaces.\nThe benchmark and code are available at https://github.com/SamsungLabs/blox.",
    "descriptor": "\nComments: Published in the Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks\n",
    "authors": [
      "Thomas Chun Pong Chau",
      "\u0141ukasz Dudziak",
      "Hongkai Wen",
      "Nicholas Donald Lane",
      "Mohamed S Abdelfattah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07271"
  },
  {
    "id": "arXiv:2210.07274",
    "title": "Proofs and Refutations for Intuitionistic and Second-Order Logic  (Extended Version)",
    "abstract": "The lambda-PRK-calculus is a typed lambda-calculus that exploits the duality\nbetween the notions of proof and refutation to provide a computational\ninterpretation for classical propositional logic. In this work, we extend\nlambda-PRK to encompass classical second-order logic, by incorporating\nparametric polymorphism and existential types. The system is shown to enjoy\ngood computational properties, such as type preservation, confluence, and\nstrong normalization, which is established by means of a reducibility argument.\nWe identify a syntactic restriction on proofs that characterizes exactly the\nintuitionistic fragment of second-order lambda-PRK, and we study canonicity\nresults.",
    "descriptor": "",
    "authors": [
      "Pablo Barenbaum",
      "Teodoro Freund"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07274"
  },
  {
    "id": "arXiv:2210.07277",
    "title": "The Hidden Uniform Cluster Prior in Self-Supervised Learning",
    "abstract": "A successful paradigm in representation learning is to perform\nself-supervised pretraining using tasks based on mini-batch statistics (e.g.,\nSimCLR, VICReg, SwAV, MSN). We show that in the formulation of all these\nmethods is an overlooked prior to learn features that enable uniform clustering\nof the data. While this prior has led to remarkably semantic representations\nwhen pretraining on class-balanced data, such as ImageNet, we demonstrate that\nit can hamper performance when pretraining on class-imbalanced data. By moving\naway from conventional uniformity priors and instead preferring power-law\ndistributed feature clusters, we show that one can improve the quality of the\nlearned representations on real-world class-imbalanced datasets. To demonstrate\nthis, we develop an extension of the Masked Siamese Networks (MSN) method to\nsupport the use of arbitrary features priors.",
    "descriptor": "",
    "authors": [
      "Mahmoud Assran",
      "Randall Balestriero",
      "Quentin Duval",
      "Florian Bordes",
      "Ishan Misra",
      "Piotr Bojanowski",
      "Pascal Vincent",
      "Michael Rabbat",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07277"
  },
  {
    "id": "arXiv:2210.07282",
    "title": "Harfang3D Dog-Fight Sandbox: A Reinforcement Learning Research Platform  for the Customized Control Tasks of Fighter Aircrafts",
    "abstract": "The advent of deep learning (DL) gave rise to significant breakthroughs in\nReinforcement Learning (RL) research. Deep Reinforcement Learning (DRL)\nalgorithms have reached super-human level skills when applied to vision-based\ncontrol problems as such in Atari 2600 games where environment states were\nextracted from pixel information. Unfortunately, these environments are far\nfrom being applicable to highly dynamic and complex real-world tasks as in\nautonomous control of a fighter aircraft since these environments only involve\n2D representation of a visual world. Here, we present a semi-realistic flight\nsimulation environment Harfang3D Dog-Fight Sandbox for fighter aircrafts. It is\naimed to be a flexible toolbox for the investigation of main challenges in\naviation studies using Reinforcement Learning. The program provides easy access\nto flight dynamics model, environment states, and aerodynamics of the plane\nenabling user to customize any specific task in order to build intelligent\ndecision making (control) systems via RL. The software also allows deployment\nof bot aircrafts and development of multi-agent tasks. This way, multiple\ngroups of aircrafts can be configured to be competitive or cooperative agents\nto perform complicated tasks including Dog Fight. During the experiments, we\ncarried out training for two different scenarios: navigating to a designated\nlocation and within visual range (WVR) combat, shortly Dog Fight. Using Deep\nReinforcement Learning techniques for both scenarios, we were able to train\ncompetent agents that exhibit human-like behaviours. Based on this results, it\nis confirmed that Harfang3D Dog-Fight Sandbox can be utilized as a 3D realistic\nRL research platform.",
    "descriptor": "\nComments: 18 pages, 18 figures,4 tables\n",
    "authors": [
      "Muhammed Murat \u00d6zbek",
      "S\u00fcleyman Y\u0131ld\u0131r\u0131m",
      "Muhammet Aksoy",
      "Eric Kernin",
      "Emre Koyuncu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07282"
  },
  {
    "id": "arXiv:2210.07285",
    "title": "3DEG: Data-Driven Descriptor Extraction for Global re-localization in  subterranean environments",
    "abstract": "Current global re-localization algorithms are built on top of localization\nand mapping methods and heavily rely on scan matching and direct point cloud\nfeature extraction and therefore are vulnerable in featureless demanding\nenvironments like caves and tunnels. In this article, we propose a novel global\nre-localization framework that: a) does not require an initial guess, like most\nmethods do, while b) it has the capability to offer the top-k candidates to\nchoose from and last but not least provides an event-based re-localization\ntrigger module for enabling, and c) supporting completely autonomous robotic\nmissions. With the focus on subterranean environments with low features, we opt\nto use descriptors based on range images from 3D LiDAR scans in order to\nmaintain the depth information of the environment. In our novel approach, we\nmake use of a state-of-the-art data-driven descriptor extraction framework for\nplace recognition and orientation regression and enhance it with the addition\nof a junction detection module that also utilizes the descriptors for\nclassification purposes.",
    "descriptor": "",
    "authors": [
      "Nikolaos Stathoulopoulos",
      "Anton Koval",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07285"
  },
  {
    "id": "arXiv:2210.07286",
    "title": "Augmenting Online Classes with an Attention Tracking Tool May Improve  Student Engagement",
    "abstract": "Online remote learning has certain advantages, such as higher flexibility and\ngreater inclusiveness. However, a caveat is the teachers' limited ability to\nmonitor student interaction during an online class, especially while teachers\nare sharing their screens. We have taken feedback from 12 teachers experienced\nin teaching undergraduate-level online classes on the necessity of an attention\ntracking tool to understand student engagement during an online class. This\npaper outlines the design of such a monitoring tool that automatically tracks\nthe attentiveness of the whole class by tracking students' gazes on the screen\nand alerts the teacher when the attention score goes below a certain threshold.\nWe assume the benefits are twofold; 1) teachers will be able to ascertain if\nthe students are attentive or being engaged with the lecture contents and 2)\nthe students will become more attentive in online classes because of this\npassive monitoring system. In this paper, we present the preliminary design and\nfeasibility of using the proposed tool and discuss its applicability in\naugmenting online classes. Finally, we surveyed 31 students asking their\nopinion on the usability as well as the ethical and privacy concerns of using\nsuch a monitoring tool.",
    "descriptor": "\nComments: 18 pages, 10 figures,\n",
    "authors": [
      "Arnab Sen Sharma",
      "Mohammad Ruhul Amin",
      "Muztaba Fuad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07286"
  },
  {
    "id": "arXiv:2210.07287",
    "title": "Tumor-location-guided CNNs for Pediatric Low-grade Glioma Molecular  Biomarker Classification Using MRI",
    "abstract": "Pediatric low-grade glioma (pLGG) is the most common type of brain cancer\namong children, and the identification of molecular markers for pLGG is crucial\nfor successful treatment planning. Current standard care is biopsy, which is\ninvasive. Thus, the non-invasive imaging-based approaches, where Machine\nLearning (ML) has a high potential, are impactful. Recently, we developed a\ntumor-location-based algorithm and demonstrated its potential to differentiate\npLGG molecular subtypes. In this work, we first reevaluated the performance of\nthe location-based algorithm on a larger pLGG dataset, which includes 214\npatients and achieved an area under the receiver operating characteristic curve\n(AUROC) of 77.90. A Convolutional Neural Network (CNN) based algorithm\nincreased the average AUROC to 86.11. Ultimately, we designed and implemented a\ntumor-location-guided CNN algorithm and achieved average AUROC of 88.64. Using\na repeated experiment approach with 100 runs, we ensured the results were\nreproducible and the improvement was statistically significant.",
    "descriptor": "",
    "authors": [
      "Khashayar Namdar",
      "Matthias W. Wagner",
      "Kareem Kudus",
      "Cynthia Hawkins",
      "Uri Tabori",
      "Brigit Ertl-Wagner",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07287"
  },
  {
    "id": "arXiv:2210.07290",
    "title": "A Dual Control Variate for doubly stochastic optimization and black-box  variational inference",
    "abstract": "In this paper, we aim at reducing the variance of doubly stochastic\noptimization, a type of stochastic optimization algorithm that contains two\nindependent sources of randomness: The subsampling of training data and the\nMonte Carlo estimation of expectations. Such an optimization regime often has\nthe issue of large gradient variance which would lead to a slow rate of\nconvergence. Therefore we propose Dual Control Variate, a new type of control\nvariate capable of reducing gradient variance from both sources jointly. The\ndual control variate is built upon approximation-based control variates and\nincremental gradient methods. We show that on doubly stochastic optimization\nproblems, compared with past variance reduction approaches that take only one\nsource of randomness into account, dual control variate leads to a gradient\nestimator of significant smaller variance and demonstrates superior performance\non real-world applications, like generalized linear models with dropout and\nblack-box variational inference.",
    "descriptor": "",
    "authors": [
      "Xi Wang",
      "Tomas Geffner",
      "Justin Domke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07290"
  },
  {
    "id": "arXiv:2210.07295",
    "title": "Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog",
    "abstract": "Traditional systems designed for task oriented dialog utilize knowledge\npresent only in structured knowledge sources to generate responses. However,\nrelevant information required to generate responses may also reside in\nunstructured sources, such as documents. Recent state of the art models such as\nHyKnow and SeKnow aimed at overcoming these challenges make limiting\nassumptions about the knowledge sources. For instance, these systems assume\nthat certain types of information, such as a phone number, is always present in\na structured KB while information about aspects such as entrance ticket prices\nwould always be available in documents.\nIn this paper, we create a modified version of the MutliWOZ based dataset\nprepared by SeKnow to demonstrate how current methods have significant\ndegradation in performance when strict assumptions about the source of\ninformation are removed. Then, in line with recent work exploiting pre-trained\nlanguage models, we fine-tune a BART based model using prompts for the tasks of\nquerying knowledge sources, as well as, for response generation, without making\nassumptions about the information present in each knowledge source. Through a\nseries of experiments, we demonstrate that our model is robust to perturbations\nto knowledge modality (source of information), and that it can fuse information\nfrom structured as well as unstructured knowledge to generate responses.",
    "descriptor": "",
    "authors": [
      "Mayank Mishra",
      "Danish Contractor",
      "Dinesh Raghu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07295"
  },
  {
    "id": "arXiv:2210.07296",
    "title": "A Conversationalist Approach to Information Quality in Information  Interaction and Retrieval",
    "abstract": "Rather than using (proxies of) end user or expert judgment to decide on the\nranking of information, this paper asks whether conversations about information\nquality might offer a feasible and valuable addition for ranking information.\nWe introduce a theoretical framework for information quality, outlining how\ninformation interaction should be perceived as a conversation and quality be\nevaluated as a conversational contribution. Next, an overview is given of\ndifferent systems of social alignment and their value for assessing quality and\nranking information. We propose that a collaborative approach to quality\nassessment is preferable and raise key questions about the feasibility and\nvalue of such an approach for ranking information. We conclude that information\nquality is an inherently interactive concept, which involves an interaction\nbetween users of different backgrounds and in different situations as well as\nof quality signals on users' search behavior and experience.",
    "descriptor": "\nComments: ACM CHIIR 2022 Workshop on Information Quality in Information Interaction and Retrieval, March 14--18, Regensburg, Germany\n",
    "authors": [
      "Frans van der Sluis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07296"
  },
  {
    "id": "arXiv:2210.07297",
    "title": "AMP: Automatically Finding Model Parallel Strategies with Heterogeneity  Awareness",
    "abstract": "Scaling up model sizes can lead to fundamentally new capabilities in many\nmachine learning (ML) tasks. However, training big models requires strong\ndistributed system expertise to carefully design model-parallel execution\nstrategies that suit the model architectures and cluster setups. In this paper,\nwe develop AMP, a framework that automatically derives such strategies. AMP\nidentifies a valid space of model parallelism strategies and efficiently\nsearches the space for high-performed strategies, by leveraging a cost model\ndesigned to capture the heterogeneity of the model and cluster specifications.\nUnlike existing methods, AMP is specifically tailored to support complex models\ncomposed of uneven layers and cluster setups with more heterogeneous\naccelerators and bandwidth. We evaluate AMP on popular models and cluster\nsetups from public clouds and show that AMP returns parallel strategies that\nmatch the expert-tuned strategies on typical cluster setups. On heterogeneous\nclusters or models with heterogeneous architectures, AMP finds strategies with\n1.54x and 1.77x higher throughput than state-of-the-art model-parallel systems,\nrespectively.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 (Paper ID: 12583)\n",
    "authors": [
      "Dacheng Li",
      "Hongyi Wang",
      "Eric Xing",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07297"
  },
  {
    "id": "arXiv:2210.07301",
    "title": "3D GAN Inversion with Pose Optimization",
    "abstract": "With the recent advances in NeRF-based 3D aware GANs quality, projecting an\nimage into the latent space of these 3D-aware GANs has a natural advantage over\n2D GAN inversion: not only does it allow multi-view consistent editing of the\nprojected image, but it also enables 3D reconstruction and novel view synthesis\nwhen given only a single image. However, the explicit viewpoint control acts as\na main hindrance in the 3D GAN inversion process, as both camera pose and\nlatent code have to be optimized simultaneously to reconstruct the given image.\nMost works that explore the latent space of the 3D-aware GANs rely on\nground-truth camera viewpoint or deformable 3D model, thus limiting their\napplicability. In this work, we introduce a generalizable 3D GAN inversion\nmethod that infers camera viewpoint and latent code simultaneously to enable\nmulti-view consistent semantic image editing. The key to our approach is to\nleverage pre-trained estimators for better initialization and utilize the\npixel-wise depth calculated from NeRF parameters to better reconstruct the\ngiven image. We conduct extensive experiments on image reconstruction and\nediting both quantitatively and qualitatively, and further compare our results\nwith 2D GAN-based editing to demonstrate the advantages of utilizing the latent\nspace of 3D GANs.",
    "descriptor": "",
    "authors": [
      "Jaehoon Ko",
      "Kyusun Cho",
      "Daewon Choi",
      "Kwangrok Ryoo",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07301"
  },
  {
    "id": "arXiv:2210.07302",
    "title": "Deep Reinforcement Learning-based Rebalancing Policies for Profit  Maximization of Relay Nodes in Payment Channel Networks",
    "abstract": "Payment channel networks (PCNs) are a layer-2 blockchain scalability\nsolution, with its main entity, the payment channel, enabling transactions\nbetween pairs of nodes \"off-chain,\" thus reducing the burden on the layer-1\nnetwork. Nodes with multiple channels can serve as relays for multihop payments\nover a path of channels: they relay payments of others by providing the\nliquidity of their channels, in exchange for part of the amount withheld as a\nfee. Relay nodes might after a while end up with one or more unbalanced\nchannels, and thus need to trigger a rebalancing operation. In this paper, we\nstudy how a relay node can maximize its profits from fees by using the\nrebalancing method of submarine swaps. We introduce a stochastic model to\ncapture the dynamics of a relay node observing random transaction arrivals and\nperforming occasional rebalancing operations, and express the system evolution\nas a Markov Decision Process. We formulate the problem of the maximization of\nthe node's fortune over time over all rebalancing policies, and approximate the\noptimal solution by designing a Deep Reinforcement Learning (DRL)-based\nrebalancing policy. We build a discrete event simulator of the system and use\nit to demonstrate the DRL policy's superior performance under most conditions\nby conducting a comparative study of different policies and parameterizations.\nIn all, our approach aims to be the first to introduce DRL for network\noptimization in the complex world of PCNs.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Nikolaos Papadis",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07302"
  },
  {
    "id": "arXiv:2210.07309",
    "title": "SHINE: SubHypergraph Inductive Neural nEtwork",
    "abstract": "Hypergraph neural networks can model multi-way connections among nodes of the\ngraphs, which are common in real-world applications such as genetic medicine.\nIn particular, genetic pathways or gene sets encode molecular functions driven\nby multiple genes, naturally represented as hyperedges. Thus, hypergraph-guided\nembedding can capture functional relations in learned representations. Existing\nhypergraph neural network models often focus on node-level or graph-level\ninference. There is an unmet need in learning powerful representations of\nsubgraphs of hypergraphs in real-world applications. For example, a cancer\npatient can be viewed as a subgraph of genes harboring mutations in the\npatient, while all the genes are connected by hyperedges that correspond to\npathways representing specific molecular functions. For accurate inductive\nsubgraph prediction, we propose SubHypergraph Inductive Neural nEtwork (SHINE).\nSHINE uses informative genetic pathways that encode molecular functions as\nhyperedges to connect genes as nodes. SHINE jointly optimizes the objectives of\nend-to-end subgraph classification and hypergraph nodes' similarity\nregularization. SHINE simultaneously learns representations for both genes and\npathways using strongly dual attention message passing. The learned\nrepresentations are aggregated via a subgraph attention layer and used to train\na multilayer perceptron for inductive subgraph inferencing. We evaluated SHINE\nagainst a wide array of state-of-the-art (hyper)graph neural networks, XGBoost,\nNMF and polygenic risk score models, using large scale NGS and curated\ndatasets. SHINE outperformed all comparison models significantly, and yielded\ninterpretable disease models with functional insights.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2210.07309"
  },
  {
    "id": "arXiv:2210.07311",
    "title": "Linker Code Size Optimization for Native Mobile Applications",
    "abstract": "Modern mobile applications have grown rapidly in binary size, which restricts\nuser growth and updates for existing users. Thus, reducing the binary size is\nimportant for application developers. Recent studies have shown the possibility\nof using link-time code size optimizations by re-invoking certain compiler\noptimizations on the linked intermediate representation of the program.\nHowever, such methods often incur significant build time overhead and require\nintrusive changes to the existing build pipeline. In this paper, we propose\nseveral novel optimization techniques that do not require significant\ncustomization to the build pipeline and reduce binary size with low build time\noverhead. As opposed to re-invoking the compiler during link time, we perform\ntrue linker optimization directly as optimization passes within the linker.\nThis enables more optimization opportunities such as pre-compiled libraries\nthat prior work often could not optimize. We evaluate our techniques on several\nopen-source and commercial iOS applications including NewsFeedApp,\nShortVideoApp, and CollaborationSuiteApp, each with hundreds of millions of\ndaily active users. Our technique on average achieves 12.6% binary size\nreduction across the three commercial applications without any user-perceivable\nperformance degradations.",
    "descriptor": "\nComments: 12 pages, 9 figures, 5 tables\n",
    "authors": [
      "Gai Liu",
      "Umar Farooq",
      "Chengyan Zhao",
      "Xia Liu",
      "Nian Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.07311"
  },
  {
    "id": "arXiv:2210.07312",
    "title": "Bootstrap Advantage Estimation for Policy Optimization in Reinforcement  Learning",
    "abstract": "This paper proposes an advantage estimation approach based on data\naugmentation for policy optimization. Unlike using data augmentation on the\ninput to learn value and policy function as existing methods use, our method\nuses data augmentation to compute a bootstrap advantage estimation. This\nBootstrap Advantage Estimation (BAE) is then used for learning and updating the\ngradient of policy and value function. To demonstrate the effectiveness of our\napproach, we conducted experiments on several environments. These environments\nare from three benchmarks: Procgen, Deepmind Control, and Pybullet, which\ninclude both image and vector-based observations; discrete and continuous\naction spaces. We observe that our method reduces the policy and the value loss\nbetter than the Generalized advantage estimation (GAE) method and eventually\nimproves cumulative return. Furthermore, our method performs better than two\nrecently proposed data augmentation techniques (RAD and DRAC). Overall, our\nmethod performs better empirically than baselines in sample efficiency and\ngeneralization, where the agent is tested in unseen environments.",
    "descriptor": "\nComments: Accepted at IEEE ICMLA 2022\n",
    "authors": [
      "Md Masudur Rahman",
      "Yexiang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07312"
  },
  {
    "id": "arXiv:2210.07313",
    "title": "Bootstrapping Multilingual Semantic Parsers using Large Language Models",
    "abstract": "Despite cross-lingual generalization demonstrated by pre-trained multilingual\nmodels, the translate-train paradigm of transferring English datasets across\nmultiple languages remains to be the key ingredient for training task-specific\nmultilingual models. However, for many low-resource languages, the availability\nof a reliable translation service entails significant amounts of costly\nhuman-annotated translation pairs. Further, the translation services for\nlow-resource languages may continue to be brittle due to domain mismatch\nbetween the task-specific input text and the general-purpose text used while\ntraining the translation models. We consider the task of multilingual semantic\nparsing and demonstrate the effectiveness and flexibility offered by large\nlanguage models (LLMs) for translating English datasets into several languages\nvia few-shot prompting. We provide (i) Extensive comparisons with prior\ntranslate-train methods across 50 languages demonstrating that LLMs can serve\nas highly effective data translators, outperforming prior translation based\nmethods on 40 out of 50 languages; (ii) A comprehensive study of the key design\nchoices that enable effective data translation via prompted LLMs.",
    "descriptor": "",
    "authors": [
      "Abhijeet Awasthi",
      "Nitish Gupta",
      "Bidisha Samanta",
      "Shachi Dave",
      "Sunita Sarawagi",
      "Partha Talukdar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07313"
  },
  {
    "id": "arXiv:2210.07315",
    "title": "Design and Evaluation of a Generic Visual SLAM Framework for  Multi-Camera Systems",
    "abstract": "Multi-camera systems have been shown to improve the accuracy and robustness\nof SLAM estimates, yet state-of-the-art SLAM systems predominantly support\nmonocular or stereo setups. This paper presents a generic sparse visual SLAM\nframework capable of running on any number of cameras and in any arrangement.\nOur SLAM system uses the generalized camera model, which allows us to represent\nan arbitrary multi-camera system as a single imaging device. Additionally, it\ntakes advantage of the overlapping fields of view (FoV) by extracting\ncross-matched features across cameras in the rig. This limits the linear rise\nin the number of features with the number of cameras and keeps the\ncomputational load in check while enabling an accurate representation of the\nscene. We evaluate our method in terms of accuracy, robustness, and run time on\nindoor and outdoor datasets that include challenging real-world scenarios such\nas narrow corridors, featureless spaces, and dynamic objects. We show that our\nsystem can adapt to different camera configurations and allows real-time\nexecution for typical robotic applications. Finally, we benchmark the impact of\nthe critical design parameters - the number of cameras and the overlap between\ntheir FoV that define the camera configuration for SLAM. All our software and\ndatasets are freely available for further research.",
    "descriptor": "",
    "authors": [
      "Pushyami Kaveti",
      "Arvind Thamilchelvan",
      "Hanumant Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07315"
  },
  {
    "id": "arXiv:2210.07316",
    "title": "MTEB: Massive Text Embedding Benchmark",
    "abstract": "Text embeddings are commonly evaluated on a small set of datasets from a\nsingle task not covering their possible applications to other tasks. It is\nunclear whether state-of-the-art embeddings on semantic textual similarity\n(STS) can be equally well applied to other tasks like clustering or reranking.\nThis makes progress in the field difficult to track, as various models are\nconstantly being proposed without proper evaluation. To solve this problem, we\nintroduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding\ntasks covering a total of 56 datasets and 112 languages. Through the\nbenchmarking of 33 models on MTEB, we establish the most comprehensive\nbenchmark of text embeddings to date. We find that no particular text embedding\nmethod dominates across all tasks. This suggests that the field has yet to\nconverge on a universal text embedding method and scale it up sufficiently to\nprovide state-of-the-art results on all embedding tasks. MTEB comes with\nopen-source code and a public leaderboard at\nhttps://huggingface.co/spaces/mteb/leaderboard.",
    "descriptor": "\nComments: 23 pages, 14 tables, 6 figures\n",
    "authors": [
      "Niklas Muennighoff",
      "Nouamane Tazi",
      "Lo\u00efc Magne",
      "Nils Reimers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07316"
  },
  {
    "id": "arXiv:2210.07317",
    "title": "A Large-Scale Annotated Multivariate Time Series Aviation Maintenance  Dataset from the NGAFID",
    "abstract": "This paper presents the largest publicly available, non-simulated, fleet-wide\naircraft flight recording and maintenance log data for use in predicting part\nfailure and maintenance need. We present 31,177 hours of flight data across\n28,935 flights, which occur relative to 2,111 unplanned maintenance events\nclustered into 36 types of maintenance issues. Flights are annotated as before\nor after maintenance, with some flights occurring on the day of maintenance.\nCollecting data to evaluate predictive maintenance systems is challenging\nbecause it is difficult, dangerous, and unethical to generate data from\ncompromised aircraft. To overcome this, we use the National General Aviation\nFlight Information Database (NGAFID), which contains flights recorded during\nregular operation of aircraft, and maintenance logs to construct a part failure\ndataset. We use a novel framing of Remaining Useful Life (RUL) prediction and\nconsider the probability that the RUL of a part is greater than 2 days. Unlike\nprevious datasets generated with simulations or in laboratory settings, the\nNGAFID Aviation Maintenance Dataset contains real flight records and\nmaintenance logs from different seasons, weather conditions, pilots, and flight\npatterns. Additionally, we provide Python code to easily download the dataset\nand a Colab environment to reproduce our benchmarks on three different models.\nOur dataset presents a difficult challenge for machine learning researchers and\na valuable opportunity to test and develop prognostic health management methods",
    "descriptor": "",
    "authors": [
      "Hong Yang",
      "Travis Desell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07317"
  },
  {
    "id": "arXiv:2210.07321",
    "title": "Machine Generated Text: A Comprehensive Survey of Threat Models and  Detection Methods",
    "abstract": "Advances in natural language generation (NLG) have resulted in machine\ngenerated text that is increasingly difficult to distinguish from human\nauthored text. Powerful open-source models are freely available, and\nuser-friendly tools democratizing access to generative models are\nproliferating. The great potential of state-of-the-art NLG systems is tempered\nby the multitude of avenues for abuse. Detection of machine generated text is a\nkey countermeasure for reducing abuse of NLG models, with significant technical\nchallenges and numerous open problems. We provide a survey that includes both\n1) an extensive analysis of threat models posed by contemporary NLG systems,\nand 2) the most complete review of machine generated text detection methods to\ndate. This survey places machine generated text within its cybersecurity and\nsocial context, and provides strong guidance for future work addressing the\nmost critical threat models, and ensuring detection systems themselves\ndemonstrate trustworthiness through fairness, robustness, and accountability.",
    "descriptor": "\nComments: Manuscript submitted to ACM Special Session on Trustworthy AI\n",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07321"
  },
  {
    "id": "arXiv:2210.07323",
    "title": "HuBERT-TR: Reviving Turkish Automatic Speech Recognition with  Self-supervised Speech Representation Learning",
    "abstract": "While the Turkish language is listed among low-resource languages, literature\non Turkish automatic speech recognition (ASR) is relatively old. In this paper,\nwe present HuBERT-TR, a speech representation model for Turkish based on\nHuBERT. HuBERT-TR achieves state-of-the-art results on several Turkish ASR\ndatasets. We investigate pre-training HuBERT for Turkish with large-scale data\ncurated from online resources. We pre-train HuBERT-TR using over 6,500 hours of\nspeech data curated from YouTube that includes extensive variability in terms\nof quality and genre. We show that pre-trained models within a multi-lingual\nsetup are inferior to language-specific models, where our Turkish model\nHuBERT-TR base performs better than its x10 times larger multi-lingual\ncounterpart XLS-R-1B. Moreover, we study the effect of scaling on ASR\nperformance by scaling our models up to 1B parameters. Our best model yields a\nstate-of-the-art word error rate of 4.97% on the Turkish Broadcast News\ndataset. Models are available at huggingface.co/asafaya .",
    "descriptor": "",
    "authors": [
      "Ali Safaya",
      "Engin Erzin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07323"
  },
  {
    "id": "arXiv:2210.07327",
    "title": "Machine Learning vs. Deep Learning in 5G Networks -- A Comparison of  Scientific Impact",
    "abstract": "Introduction of fifth generation (5G) wireless network technology has matched\nthe crucial need for high capacity and speed needs of the new generation mobile\napplications. Recent advances in Artificial Intelligence (AI) also empowered 5G\ncellular networks with two mainstreams as machine learning (ML) and deep\nlearning (DL) techniques. Our study aims to uncover the differences in\nscientific impact for these two techniques by the means of statistical\nbibliometrics. The performed analysis includes citation performance with\nrespect to indexing types, funding availability, journal or conference\npublishing options together with distributions of these metrics along years to\nevaluate the popularity trends in a detailed manner. Web of Science (WoS)\ndatabase host 2245 papers for ML and 1407 papers for DL-related studies. DL\nstudies, starting with 9% rate in 2013, has reached to 45% rate in 2022 among\nall DL and ML-related studies. Results related to scientific impact indicate\nthat DL studies get slightly more average normalized citation (2.256) compared\nto ML studies (2.118) in 5G, while SCI-Expanded indexed papers in both sides\ntend to have similar citation performance (3.165 and 3.162 respectively).\nML-related studies those are indexed in ESCI show twice citation performance\ncompared to DL. Conference papers in DL domain and journal papers in ML domain\nare superior in scientific interest to their counterparts with minor\ndifferences. Highest citation performance for ML studies is achieved for year\n2014, while this peak is observed for 2017 for DL studies. We can conclude that\nboth publication and citation rate for DL-related papers tend to increase and\noutperform ML-based studies in 5G domain by the means of citation metrics.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Ilker Turker",
      "Serhat Orkun Tan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07327"
  },
  {
    "id": "arXiv:2210.07329",
    "title": "Sample Efficient Dynamics Learning for Symmetrical Legged  Robots:Leveraging Physics Invariance and Geometric Symmetries",
    "abstract": "Model generalization of the underlying dynamics is critical for achieving\ndata efficiency when learning for robot control. This paper proposes a novel\napproach for learning dynamics leveraging the symmetry in the underlying\nrobotic system, which allows for robust extrapolation from fewer samples.\nExisting frameworks that represent all data in vector space fail to consider\nthe structured information of the robot, such as leg symmetry, rotational\nsymmetry, and physics invariance. As a result, these schemes require vast\namounts of training data to learn the system's redundant elements because they\nare learned independently. Instead, we propose considering the geometric prior\nby representing the system in symmetrical object groups and designing neural\nnetwork architecture to assess invariance and equivariance between the objects.\nFinally, we demonstrate the effectiveness of our approach by comparing the\ngeneralization to unseen data of the proposed model and the existing models. We\nalso implement a controller of a climbing robot based on learned inverse\ndynamics models. The results show that our method generates accurate control\ninputs that help the robot reach the desired state while requiring less\ntraining data than existing methods.",
    "descriptor": "",
    "authors": [
      "Jee-eun Lee",
      "Jaemin Lee",
      "Tirthankar Bandyopadhyay",
      "Luis Sentis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07329"
  },
  {
    "id": "arXiv:2210.07332",
    "title": "Secure Multiparty Computation for Synthetic Data Generation from  Distributed Data",
    "abstract": "Legal and ethical restrictions on accessing relevant data inhibit data\nscience research in critical domains such as health, finance, and education.\nSynthetic data generation algorithms with privacy guarantees are emerging as a\nparadigm to break this data logjam. Existing approaches, however, assume that\nthe data holders supply their raw data to a trusted curator, who uses it as\nfuel for synthetic data generation. This severely limits the applicability, as\nmuch of the valuable data in the world is locked up in silos, controlled by\nentities who cannot show their data to each other or a central aggregator\nwithout raising privacy concerns.\nTo overcome this roadblock, we propose the first solution in which data\nholders only share encrypted data for differentially private synthetic data\ngeneration. Data holders send shares to servers who perform Secure Multiparty\nComputation (MPC) computations while the original data stays encrypted.\nWe instantiate this idea in an MPC protocol for the Multiplicative Weights\nwith Exponential Mechanism (MWEM) algorithm to generate synthetic data based on\nreal data originating from many data holders without reliance on a single point\nof failure.",
    "descriptor": "",
    "authors": [
      "Mayana Pereira",
      "Sikha Pentyala",
      "Anderson Nascimento",
      "Rafael T. de Sousa Jr.",
      "Martine De Cock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07332"
  },
  {
    "id": "arXiv:2210.07333",
    "title": "Online Algorithms for the Santa Claus Problem",
    "abstract": "The Santa Claus problem is a fundamental problem in fair division: the goal\nis to partition a set of heterogeneous items among heterogeneous agents so as\nto maximize the minimum value of items received by any agent. In this paper, we\nstudy the online version of this problem where the items are not known in\nadvance and have to be assigned to agents as they arrive over time. If the\narrival order of items is arbitrary, then no good assignment rule exists in the\nworst case. However, we show that, if the arrival order is random, then for $n$\nagents and any $\\varepsilon > 0$, we can obtain a competitive ratio of\n$1-\\varepsilon$ when the optimal assignment gives value at least $\\Omega(\\log n\n/ \\varepsilon^2)$ to every agent (assuming each item has at most unit value).\nWe also show that this result is almost tight: namely, if the optimal solution\nhas value at most $C \\ln n / \\varepsilon$ for some constant $C$, then there is\nno $(1-\\varepsilon)$-competitive algorithm even for random arrival order.",
    "descriptor": "\nComments: to be published in NeurIPS '22, 15 pages, 1 figure\n",
    "authors": [
      "MohammadTaghi Hajiaghayi",
      "MohammadReza Khani",
      "Debmalya Panigrahi",
      "Max Springer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07333"
  },
  {
    "id": "arXiv:2210.07335",
    "title": "FOON Creation and Traversal for Recipe Generation",
    "abstract": "Task competition by robots is still off from being completely dependable and\nusable. One way a robot may decipher information given to it and accomplish\ntasks is by utilizing FOON, which stands for functional object-oriented\nnetwork. The network first needs to be created by having a human creates action\nnodes as well as input and output nodes in a .txt file. After the network is\nsizeable, utilization of this network allows for traversal of the network in a\nvariety of ways such as choosing steps via iterative deepening searching by\nusing the first seen valid option. Another mechanism is heuristics, such as\nchoosing steps based on the highest success rate or lowest amount of input\ningredients. Via any of these methods, a program can traverse the network given\nan output product, and derive the series of steps that need to be taken to\nproduce the output.",
    "descriptor": "",
    "authors": [
      "Raj Patel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07335"
  },
  {
    "id": "arXiv:2210.07337",
    "title": "Decomposition Theory Meets Reliability Analysis: Processing of  Computation-Intensive Dependent Tasks over Vehicular Clouds with Dynamic  Resources",
    "abstract": "Vehicular cloud (VC) is a promising technology for processing\ncomputation-intensive applications (CI-Apps) on smart vehicles. Implementing\nVCs over the network edge faces two key challenges: (C1) On-board computing\nresources of a single vehicle are often insufficient to process a CI-App; (C2)\nThe dynamics of available resources, caused by vehicles' mobility, hinder\nreliable CI-App processing. This work is among the first to jointly address\n(C1) and (C2), while considering two common CI-App graph representations,\ndirected acyclic graph (DAG) and undirected graph (UG). To address (C1), we\nconsider partitioning a CI-App with $m$ dependent (sub-)tasks into $k\\le m$\ngroups, which are dispersed across vehicles. To address (C2), we introduce a\ngeneralized reliability metric called conditional mean time to failure\n(C-MTTF). Subsequently, we increase the C-MTTF of dependent sub-tasks\nprocessing via introducing a general framework of redundancy-based processing\nof dependent sub-tasks over semi-dynamic VCs (RP-VC). We demonstrate that RP-VC\ncan be modeled as a non-trivial time-inhomogeneous semi-Markov process (I-SMP).\nTo analyze I-SMP and its reliability, we develop a novel mathematical\nframework, called event stochastic algebra ($\\langle e\\rangle$-algebra). Based\non $\\langle e\\rangle$-algebra, we propose decomposition theorem (DT) to\ntransform I-SMP to a decomposed time-homogeneous SMP (D-SMP). We subsequently\ncalculate the C-MTTF of our methodology. We demonstrate that $\\langle\ne\\rangle$-algebra and DT are general mathematical tools that can be used to\nanalyze other cloud-based networks. Simulation results reveal the exactness of\nour analytical results and the efficiency of our methodology in terms of\nacceptance and success rates of CI-App processing.",
    "descriptor": "",
    "authors": [
      "Payam Abdisarabshali",
      "Seyyedali Hosseinalipour",
      "Minghui Liwang",
      "Amir Rajabzadeh",
      "Mahmood Ahmadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07337"
  },
  {
    "id": "arXiv:2210.07338",
    "title": "Reinforcement Learning with Unbiased Policy Evaluation and Linear  Function Approximation",
    "abstract": "We provide performance guarantees for a variant of simulation-based policy\niteration for controlling Markov decision processes that involves the use of\nstochastic approximation algorithms along with state-of-the-art techniques that\nare useful for very large MDPs, including lookahead, function approximation,\nand gradient descent. Specifically, we analyze two algorithms; the first\nalgorithm involves a least squares approach where a new set of weights\nassociated with feature vectors is obtained via least squares minimization at\neach iteration and the second algorithm involves a two-time-scale stochastic\napproximation algorithm taking several steps of gradient descent towards the\nleast squares solution before obtaining the next iterate using a stochastic\napproximation algorithm.",
    "descriptor": "\nComments: 9 pages, 0 figures\n",
    "authors": [
      "Anna Winnicki",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07338"
  },
  {
    "id": "arXiv:2210.07340",
    "title": "LEAVES: Learning Views for Time-Series Data in Contrastive Learning",
    "abstract": "Contrastive learning, a self-supervised learning method that can learn\nrepresentations from unlabeled data, has been developed promisingly. Many\nmethods of contrastive learning depend on data augmentation techniques, which\ngenerate different views from the original signal. However, tuning policies and\nhyper-parameters for more effective data augmentation methods in contrastive\nlearning is often time and resource-consuming. Researchers have designed\napproaches to automatically generate new views for some input signals,\nespecially on the image data. But the view-learning method is not well\ndeveloped for time-series data. In this work, we propose a simple but effective\nmodule for automating view generation for time-series data in contrastive\nlearning, named learning views for time-series data (LEAVES). The proposed\nmodule learns the hyper-parameters for augmentations using adversarial training\nin contrastive learning. We validate the effectiveness of the proposed method\nusing multiple time-series datasets. The experiments demonstrate that the\nproposed method is more effective in finding reasonable views and performs\ndownstream tasks better than the baselines, including manually tuned\naugmentation-based contrastive learning methods and SOTA methods.",
    "descriptor": "",
    "authors": [
      "Han Yu",
      "Huiyuan Yang",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07340"
  },
  {
    "id": "arXiv:2210.07342",
    "title": "Cognitive-Driven Development Helps Software Teams to Keep Code Units  Under the Limit!",
    "abstract": "Software design techniques are undoubtedly crucial in the process of\ndesigning good software. Over the years, a large number of design techniques\nhave been proposed by both researchers and practitioners. Unfortunately,\ndespite their uniqueness, it is not uncommon to find software products that\nmake subpar design decisions, leading to design degradation challenges. One\npotential reason for this behavior is that developers do not have a clear\nvision of how much a code unit could grow; without this vision, a code unit can\ngrow endlessly, even when developers are equipped with an arsenal of design\npractices. Different than other design techniques, Cognitive Driven Development\n(CDD for short) focuses on 1) defining and 2) limiting the number of coding\nelements that developers could use at a given code unit.\nIn this paper, we report on the experiences of a software development team in\nusing CDD for building from scratch a learning management tool at Zup\nInnovation, a Brazilian tech company. By curating commit traces left in the\nrepositories, combined with the developers' perception, we organized a set of\nfindings and lessons that could be useful for those interested in adopting CDD.\nFor instance, we noticed that by using CDD, despite the evolution of the\nproduct, developers were able to keep the code units under a small amount of\nsize (in terms of size). Furthermore, although limiting the complexity is at\nthe heart of CDD, we also discovered that developers tend to relax this notion\nof limit so that they can cope with the different complexities of the software.\nStill, we noticed that CDD could also influence testing practices; limiting the\ncode units' size makes testing easier to perform.",
    "descriptor": "\nComments: 11 pages, submitted to ICSE-SEIP\n",
    "authors": [
      "Gustavo Pinto",
      "Alberto de Souza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.07342"
  },
  {
    "id": "arXiv:2210.07343",
    "title": "Scientific Impact of Graph-Based Approaches in Deep Learning Studies --  A Bibliometric Comparison",
    "abstract": "Applying graph-based approaches in deep learning receives more attention over\ntime. This study presents statistical analysis on the use of graph-based\napproaches in deep learning and examines the scientific impact of the related\narticles. Processing the data obtained from the Web of Science database,\nmetrics such as the type of the articles, funding availability, indexing type,\nannual average number of citations and the number of access were analyzed to\nquantitatively reveal the effects on the scientific audience. It's outlined\nthat deep learning-based studies gained momentum after year 2013, and the rate\nof graph-based approaches in all deep learning studies increased linearly from\n1% to 4% within the following 10 years. Conference publications scanned in the\nConference Proceeding Citation Index (CPCI) on the graph-based approaches\nreceive significantly more citations. The citation counts of the SCI-Expanded\nand Emerging SCI indexed publications of the two streams are close to each\nother. While the citation performances of the supported and unsupported\npublications of the two sides were similar, pure deep learning studies received\nmore citations on the journal publication side and graph-based approaches\nreceived more citations on the conference side. Despite their similar\nperformance in recent years, graph-based studies show twice more citation\nperformance as they get older, compared to traditional approaches. Annual\naverage citation performance per article for all deep learning studies is\n11.051 in 2014, while it is 22.483 for graph-based studies. Also, despite\nreceiving 16% more access, graph-based papers get almost the same overall\ncitation over time with the pure counterpart. This is an indication that\ngraph-based approaches need a greater bunch of attention to follow, while pure\ndeep learning counterpart is relatively simpler to get inside.",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Ilker Turker",
      "Serhat Orkun Tan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07343"
  },
  {
    "id": "arXiv:2210.07346",
    "title": "Demystifying Self-supervised Trojan Attacks",
    "abstract": "As an emerging machine learning paradigm, self-supervised learning (SSL) is\nable to learn high-quality representations for complex data without data\nlabels. Prior work shows that, besides obviating the reliance on labeling, SSL\nalso benefits adversarial robustness by making it more challenging for the\nadversary to manipulate model prediction. However, whether this robustness\nbenefit generalizes to other types of attacks remains an open question.\nWe explore this question in the context of trojan attacks by showing that SSL\nis comparably vulnerable as supervised learning to trojan attacks.\nSpecifically, we design and evaluate CTRL, an extremely simple self-supervised\ntrojan attack. By polluting a tiny fraction of training data (less than 1%)\nwith indistinguishable poisoning samples, CTRL causes any trigger-embedded\ninput to be misclassified to the adversary's desired class with a high\nprobability (over 99%) at inference. More importantly, through the lens of\nCTRL, we study the mechanisms underlying self-supervised trojan attacks. With\nboth empirical and analytical evidence, we reveal that the representation\ninvariance property of SSL, which benefits adversarial robustness, may also be\nthe very reason making SSL highly vulnerable to trojan attacks. We further\ndiscuss the fundamental challenges to defending against self-supervised trojan\nattacks, pointing to promising directions for future research.",
    "descriptor": "",
    "authors": [
      "Changjiang Li",
      "Ren Pang",
      "Zhaohan Xi",
      "Tianyu Du",
      "Shouling Ji",
      "Yuan Yao",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07346"
  },
  {
    "id": "arXiv:2210.07347",
    "title": "Disentanglement of Correlated Factors via Hausdorff Factorized Support",
    "abstract": "A grand goal in deep learning research is to learn representations capable of\ngeneralizing across distribution shifts. Disentanglement is one promising\ndirection aimed at aligning a models representations with the underlying\nfactors generating the data (e.g. color or background). Existing\ndisentanglement methods, however, rely on an often unrealistic assumption: that\nfactors are statistically independent. In reality, factors (like object color\nand shape) are correlated. To address this limitation, we propose a relaxed\ndisentanglement criterion - the Hausdorff Factorized Support (HFS) criterion -\nthat encourages a factorized support, rather than a factorial distribution, by\nminimizing a Hausdorff distance. This allows for arbitrary distributions of the\nfactors over their support, including correlations between them. We show that\nthe use of HFS consistently facilitates disentanglement and recovery of\nground-truth factors across a variety of correlation settings and benchmarks,\neven under severe training correlations and correlation shifts, with in parts\nover +60% in relative improvement over existing disentanglement methods. In\naddition, we find that leveraging HFS for representation learning can even\nfacilitate transfer to downstream tasks such as classification under\ndistribution shifts. We hope our original approach and positive empirical\nresults inspire further progress on the open problem of robust generalization.",
    "descriptor": "",
    "authors": [
      "Karsten Roth",
      "Mark Ibrahim",
      "Zeynep Akata",
      "Pascal Vincent",
      "Diane Bouchacourt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07347"
  },
  {
    "id": "arXiv:2210.07352",
    "title": "Predicting Fine-Tuning Performance with Probing",
    "abstract": "Large NLP models have recently shown impressive performance in language\nunderstanding tasks, typically evaluated by their fine-tuned performance.\nAlternatively, probing has received increasing attention as being a lightweight\nmethod for interpreting the intrinsic mechanisms of large NLP models. In\nprobing, post-hoc classifiers are trained on \"out-of-domain\" datasets that\ndiagnose specific abilities. While probing the language models has led to\ninsightful findings, they appear disjointed from the development of models.\nThis paper explores the utility of probing deep NLP models to extract a proxy\nsignal widely used in model development -- the fine-tuning performance. We find\nthat it is possible to use the accuracies of only three probing tests to\npredict the fine-tuning performance with errors $40\\%$ - $80\\%$ smaller than\nbaselines. We further discuss possible avenues where probing can empower the\ndevelopment of deep NLP models.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zining Zhu",
      "Soroosh Shahtalebi",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07352"
  },
  {
    "id": "arXiv:2210.07353",
    "title": "JOIST: A Joint Speech and Text Streaming Model For ASR",
    "abstract": "We present JOIST, an algorithm to train a streaming, cascaded, encoder\nend-to-end (E2E) model with both speech-text paired inputs, and text-only\nunpaired inputs. Unlike previous works, we explore joint training with both\nmodalities, rather than pre-training and fine-tuning. In addition, we explore\nJOIST using a streaming E2E model with an order of magnitude more data, which\nare also novelties compared to previous works. Through a series of ablation\nstudies, we explore different types of text modeling, including how to model\nthe length of the text sequence and the appropriate text sub-word unit\nrepresentation. We find that best text representation for JOIST improves WER\nacross a variety of search and rare-word test sets by 4-14% relative, compared\nto a model not trained with text. In addition, we quantitatively show that\nJOIST maintains streaming capabilities, which is important for good user-level\nexperience.",
    "descriptor": "",
    "authors": [
      "Tara N. Sainath",
      "Rohit Prabhavalkar",
      "Ankur Bapna",
      "Yu Zhang",
      "Zhouyuan Huo",
      "Zhehuai Chen",
      "Bo Li",
      "Weiran Wang",
      "Trevor Strohman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07353"
  },
  {
    "id": "arXiv:2210.07354",
    "title": "Finding Islands of Predictability in Action Forecasting",
    "abstract": "We address dense action forecasting: the problem of predicting future action\nsequence over long durations based on partial observation. Our key insight is\nthat future action sequences are more accurately modeled with variable, rather\nthan one, levels of abstraction, and that the optimal level of abstraction can\nbe dynamically selected during the prediction process. Our experiments show\nthat most parts of future action sequences can be predicted confidently in fine\ndetail only in small segments of future frames, which are effectively\n``islands'' of high model prediction confidence in a ``sea'' of uncertainty. We\npropose a combination Bayesian neural network and hierarchical convolutional\nsegmentation model to both accurately predict future actions and optimally\nselect abstraction levels. We evaluate this approach on standard datasets\nagainst existing state-of-the-art systems and demonstrate that our ``islands of\npredictability'' approach maintains fine-grained action predictions while also\nmaking accurate abstract predictions where systems were previously unable to do\nso, and thus results in substantial, monotonic increases in accuracy.",
    "descriptor": "",
    "authors": [
      "Daniel Scarafoni",
      "Irfan Essa",
      "Thomas Ploetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07354"
  },
  {
    "id": "arXiv:2210.07356",
    "title": "Consistency and Accuracy of CelebA Attribute Values",
    "abstract": "We report the first analysis of the experimental foundations of facial\nattribute classification. An experiment with two annotators independently\nassigning values shows that only 12 of 40 commonly-used attributes are assigned\nvalues with >= 95% consistency, and that three (high cheekbones, pointed nose,\noval face) have random consistency (50%). These results show that the binary\nface attributes currently used in this research area could re-focused to be\nmore objective. We identify 5,068 duplicate face appearances in CelebA, the\nmost widely used dataset in this research area, and find that individual\nattributes have contradicting values on from 10 to 860 of 5,068 duplicates.\nManual audit of a subset of CelebA estimates error rates as high as 40% for (no\nbeard=false), even though the labeling consistency experiment indicates that no\nbeard could be assigned with >= 95% consistency. Selecting the mouth slightly\nopen (MSO) attribute for deeper analysis, we estimate the error rate for\n(MSO=true) at about 20% and for (MSO=false) at about 2%. We create a corrected\nversion of the MSO attribute values, and compare classification models created\nusing the original versus corrected values. The corrected values enable a model\nthat achieves higher accuracy than has been previously reported for MSO. Also,\nScoreCAM visualizations show that the model created using the corrected\nattribute values is in fact more focused on the mouth region of the face. These\nresults show that the error rate in the current CelebA attribute values should\nbe reduced in order to enable learning of better models. The corrected\nattribute values for CelebA's MSO and the CelebA facial hair attributes will be\nmade available upon publication.",
    "descriptor": "",
    "authors": [
      "Haiyu Wu",
      "Grace Bezold",
      "Manuel G\u00fcnther",
      "Terrance Boult",
      "Michael C. King",
      "Kevin W. Bowyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07356"
  },
  {
    "id": "arXiv:2210.07360",
    "title": "Reducing Action Space: Reference-Model-Assisted Deep Reinforcement  Learning for Inverter-based Volt-Var Control",
    "abstract": "Reference-model-assisted deep reinforcement learning (DRL) for inverter-based\nVolt-Var Control (IB-VVC) in active distribution networks is proposed. We\ninvestigate that a large action space increases the learning difficulties of\nDRL and degrades the optimization performance in the process of generating data\nand training neural networks. To reduce the action space of DRL, we design a\nreference-model-assisted DRL approach. We introduce definitions of the\nreference model, reference-model-based optimization, and reference actions. The\nreference-model-assisted DRL learns the residual actions between the reference\nactions and optimal actions, rather than learning the optimal actions directly.\nSince the residual actions are considerably smaller than the optimal actions\nfor a reference model, we can design a smaller action space for the\nreference-model-assisted DRL. It reduces the learning difficulties of DRL and\noptimises the performance of the reference-model-assisted DRL approach. It is\nnoteworthy that the reference-model-assisted DRL approach is compatible with\nany policy gradient DRL algorithms for continuous action problems. This work\ntakes the soft actor-critic algorithm as an example and designs a\nreference-model-assisted soft actor-critic algorithm. Simulations show that 1)\nlarge action space degrades the performance of DRL in the whole training stage,\nand 2) reference-model-assisted DRL requires fewer iteration times and returns\na better optimization performance.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Qiong Liu",
      "Ye Guo",
      "Lirong Deng",
      "Haotian Liu",
      "Dongyu Li",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07360"
  },
  {
    "id": "arXiv:2210.07362",
    "title": "Can Demographic Factors Improve Text Classification? Revisiting  Demographic Adaptation in the Age of Transformers",
    "abstract": "Demographic factors (e.g., gender or age) shape our language. Previous work\nshowed that incorporating demographic factors can consistently improve\nperformance for various NLP tasks with traditional NLP models. In this work, we\ninvestigate whether these previous findings still hold with state-of-the-art\npretrained Transformer-based language models (PLMs). We use three common\nspecialization methods proven effective for incorporating external knowledge\ninto pretrained Transformers (e.g., domain-specific or geographic knowledge).\nWe adapt the language representations for the demographic dimensions of gender\nand age, using continuous language modeling and dynamic multi-task learning for\nadaptation, where we couple language modeling objectives with the prediction of\ndemographic classes. Our results when employing a multilingual PLM show\nsubstantial performance gains across four languages (English, German, French,\nand Danish), which is consistent with the results of previous work. However,\ncontrolling for confounding factors -- primarily domain and language\nproficiency of Transformer-based PLMs -- shows that downstream performance\ngains from our demographic adaptation do not actually stem from demographic\nknowledge. Our results indicate that demographic specialization of PLMs, while\nholding promise for positive societal impact, still represents an unsolved\nproblem for (modern) NLP.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.01029\n",
    "authors": [
      "Chia-Chien Hung",
      "Anne Lauscher",
      "Dirk Hovy",
      "Simone Paolo Ponzetto",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07362"
  },
  {
    "id": "arXiv:2210.07363",
    "title": "The Power of Multi-Step Vizing Chains",
    "abstract": "Recent papers [Ber'2022], [GP'2020], [DHZ'2019] have addressed different\nvariants of the (\\Delta + 1)-edge colouring problem by concatenating or gluing\ntogether many Vizing chains to form what Bernshteyn [Ber'2022] coined\n\\emph{multi-step Vizing chains}.\nIn this paper, we propose a slightly more general definition of this term. We\nthen apply multi-step Vizing chain constructions to prove combinatorial\nproperties of edge colourings that lead to (improved) algorithms for computing\nedge colouring across different models of computation.\nThis approach seems especially powerful for constructing augmenting subgraphs\nwhich respect some notion of locality.\nFirst, we construct strictly local multi-step Vizing chains and use them to\nshow a local version of Vizings Theorem thus confirming a recent conjecture of\nBonamy, Delcourt, Lang and Postle [BDLP'2020].\nOur proof is constructive and also implies an algorithm for computing such a\ncolouring.\nThen, we show that for any uncoloured edge there exists an augmenting\nsubgraph of size O(\\Delta^{6}\\log n), answering an open problem of Bernshteyn\n[Ber'2022]. Chang, He, Li, Pettie and Uitto [CHLPU'2018] show a lower bound of\n\\Omega(\\Delta \\log \\frac{n}{\\Delta}) for the size of such augmenting subgraphs,\nso the upper bound is tight up to \\Delta and constant factors.\nThese ideas also extend to give a faster deterministic LOCAL algorithm for\n(\\Delta + 1)-edge colouring running in \\tilde{O}(\\poly(\\Delta)\\log^6 n) rounds.\nThese results improve the recent breakthrough result of Bernshteyn [Ber'2022],\nwho showed the existence of augmenting subgraphs of size O(\\Delta^6\\log^2 n),\nand used these to give the first (\\Delta + 1)-edge colouring algorithm in the\nLOCAL model running in O(\\poly(\\Delta, \\log n)) rounds. ... (see paper for the\nremaining part of the abstract)",
    "descriptor": "\nComments: 31 pages, 3 figures\n",
    "authors": [
      "Aleksander B G Christiansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07363"
  },
  {
    "id": "arXiv:2210.07365",
    "title": "Is It Worth the (Environmental) Cost? Limited Evidence for the Benefits  of Diachronic Continuous Training",
    "abstract": "Language is constantly changing and evolving, leaving language models to\nquickly become outdated, both factually and linguistically. Recent research\nproposes we continuously update our models using new data. Continuous training\nallows us to teach language models about new events and facts and changing\nnorms. However, continuous training also means continuous costs. We show there\nis currently limited evidence for the benefits of continuous training, be it\nfor the actual downstream performance or the environmental cost. Our results\nshow continuous training does not significantly improve performance. While it\nis clear that, sooner or later, our language models need to be updated, it is\nunclear when this effort is worth the cost. We call for a critical reflection\nabout when and how to use continuous training and for more benchmarks to\nsupport this research direction.",
    "descriptor": "",
    "authors": [
      "Giuseppe Attanasio",
      "Debora Nozza",
      "Federico Bianchi",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07365"
  },
  {
    "id": "arXiv:2210.07370",
    "title": "M2D2: A Massively Multi-domain Language Modeling Dataset",
    "abstract": "We present M2D2, a fine-grained, massively multi-domain corpus for studying\ndomain adaptation in language models (LMs). M2D2 consists of 8.5B tokens and\nspans 145 domains extracted from Wikipedia and Semantic Scholar. Using\nontologies derived from Wikipedia and ArXiv categories, we organize the domains\nin each data source into 22 groups. This two-level hierarchy enables the study\nof relationships between domains and their effects on in- and out-of-domain\nperformance after adaptation. We also present a number of insights into the\nnature of effective domain adaptation in LMs, as examples of the new types of\nstudies M2D2 enables. To improve in-domain performance, we show the benefits of\nadapting the LM along a domain hierarchy; adapting to smaller amounts of\nfine-grained domain-specific data can lead to larger in-domain performance\ngains than larger amounts of weakly relevant data. We further demonstrate a\ntrade-off between in-domain specialization and out-of-domain generalization\nwithin and across ontologies, as well as a strong correlation between\nout-of-domain performance and lexical overlap between domains.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Machel Reid",
      "Victor Zhong",
      "Suchin Gururangan",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07370"
  },
  {
    "id": "arXiv:2210.07372",
    "title": "SWFormer: Sparse Window Transformer for 3D Object Detection in Point  Clouds",
    "abstract": "3D object detection in point clouds is a core component for modern robotics\nand autonomous driving systems. A key challenge in 3D object detection comes\nfrom the inherent sparse nature of point occupancy within the 3D scene. In this\npaper, we propose Sparse Window Transformer (SWFormer ), a scalable and\naccurate model for 3D object detection, which can take full advantage of the\nsparsity of point clouds. Built upon the idea of window-based Transformers,\nSWFormer converts 3D points into sparse voxels and windows, and then processes\nthese variable-length sparse windows efficiently using a bucketing scheme. In\naddition to self-attention within each spatial window, our SWFormer also\ncaptures cross-window correlation with multi-scale feature fusion and window\nshifting operations. To further address the unique challenge of detecting 3D\nobjects accurately from sparse features, we propose a new voxel diffusion\ntechnique. Experimental results on the Waymo Open Dataset show our SWFormer\nachieves state-of-the-art 73.36 L2 mAPH on vehicle and pedestrian for 3D object\ndetection on the official test set, outperforming all previous single-stage and\ntwo-stage models, while being much more efficient.",
    "descriptor": "",
    "authors": [
      "Pei Sun",
      "Mingxing Tan",
      "Weiyue Wang",
      "Chenxi Liu",
      "Fei Xia",
      "Zhaoqi Leng",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07372"
  },
  {
    "id": "arXiv:2210.07373",
    "title": "Mind the Labels: Describing Relations in Knowledge Graphs With  Pretrained Models",
    "abstract": "Pretrained language models (PLMs) for data-to-text (D2T) generation can use\nhuman-readable data labels such as column headings, keys, or relation names to\ngeneralize to out-of-domain examples. However, the models are well-known in\nproducing semantically inaccurate outputs if these labels are ambiguous or\nincomplete, which is often the case in D2T datasets. In this paper, we expose\nthis issue on the task of descibing a relation between two entities. For our\nexperiments, we collect a novel dataset for verbalizing a diverse set of 1,522\nunique relations from three large-scale knowledge graphs (Wikidata, DBPedia,\nYAGO). We find that although PLMs for D2T generation expectedly fail on unclear\ncases, models trained with a large variety of relation labels are surprisingly\nrobust in verbalizing novel, unseen relations. We argue that using data with a\ndiverse set of clear and meaningful labels is key to training D2T generation\nsystems capable of generalizing to novel domains.",
    "descriptor": "",
    "authors": [
      "Zden\u011bk Kasner",
      "Ioannis Konstas",
      "Ond\u0159ej Du\u0161ek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07373"
  },
  {
    "id": "arXiv:2210.07374",
    "title": "A Relational Macrostate Theory Guides Artificial Intelligence to Learn  Macro and Design Micro",
    "abstract": "The high dimesionality, non-linearity and emergent properties of complex\nsystems pose a challenge to identifying general laws in the same manner that\nhas been so successful in simpler physical systems. In the seminal work of\nAnderson on why more is different he pointed to how emergent, macroscale\npatterns break symmetries of the underlying microscale laws. Yet, less\nrecognized is that these large scale, emergent patterns must also retain some\nsymmetries of the microscale rules. Here we introduce a new, relational\nmacrostate theory (RMT) that defines macrostates in terms of symmetries between\ntwo mutually predictive observations, and develop a machine learning\narchitecture, MacroNet, that identifies which symmetries are preserved during\nthe mapping from micro-to-macro. Using this framework, we show how macrostates\ncan be identifed across systems ranging in complexity from the simplicity of\nthe simple harmonic oscillator to the much more complex spatial patterning\ncharacteristic of Turing instabilities. Furthermore, we show how our framework\ncan be used for the inverse design of microstates consistent with a given\nmacroscale property - in Turing patterns this allows us to design microstates\nwith a given specification of macroscale spatial patterning, and to identify\nwhich parameters most control these patterns. By demonstrating a general theory\nfor how macroscale properties emerge from conservation of symmetries in the\nmapping from micro-to-macro, we provide a machine learning framework that\nallows a unified approach to identifying macrostates in systems from the simple\nto complex, and allows the design of new examples consistent with a given\nmacroscale property.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yanbo Zhang",
      "Sara Imari Walker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2210.07374"
  },
  {
    "id": "arXiv:2210.07376",
    "title": "ScionFL: Secure Quantized Aggregation for Federated Learning",
    "abstract": "Privacy concerns in federated learning (FL) are commonly addressed with\nsecure aggregation schemes that prevent a central party from observing\nplaintext client updates. However, most such schemes neglect orthogonal FL\nresearch that aims at reducing communication between clients and the aggregator\nand is instrumental in facilitating cross-device FL with thousands and even\nmillions of (mobile) participants. In particular, quantization techniques can\ntypically reduce client-server communication by a factor of 32x.\nIn this paper, we unite both research directions by introducing an efficient\nsecure aggregation framework based on outsourced multi-party computation (MPC)\nthat supports any linear quantization scheme. Specifically, we design a novel\napproximate version of an MPC-based secure aggregation protocol with support\nfor multiple stochastic quantization schemes, including ones that utilize the\nrandomized Hadamard transform and Kashin's representation. In our empirical\nperformance evaluation, we show that with no additional overhead for clients\nand moderate inter-server communication, we achieve similar training accuracy\nas insecure schemes for standard FL benchmarks.\nBeyond this, we present an efficient extension to our secure quantized\naggregation framework that effectively defends against state-of-the-art\nuntargeted poisoning attacks.",
    "descriptor": "",
    "authors": [
      "Yaniv Ben-Itzhak",
      "Helen M\u00f6llering",
      "Benny Pinkas",
      "Thomas Schneider",
      "Ajith Suresh",
      "Oleksandr Tkachenko",
      "Shay Vargaftik",
      "Christian Weinert",
      "Hossein Yalame",
      "Avishay Yanai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07376"
  },
  {
    "id": "arXiv:2210.07380",
    "title": "Directed branching bisimulation via apartness and positive logic",
    "abstract": "Branching bisimulation is a relation on states of a labelled transition\nsystem, closely connected to Hennessy-Milner Logic with Until (HMLU): two\nstates are branching bisimilar if they validate the same HMLU formulas. In this\npaper, we introduce a directed notion of branching bisimulation, and show that\nfor a particular class of good, positive HMLU formulas, a state $p$ is directed\nbranching bisimilar to a state $q$ if and only if every good, positive HMLU\nformula true in $p$ is also true in $q$. We also introduce a novel logic,\nPositive Hennessy-Milner Logic with Until (PHMLU), and show that PHMLU formulas\ncan play the role of good, positive HMLU formulas in the above construction.\nAs part of these constructions, we make extensive use of notions of branching\napartness, the complement of branching bisimilarity. We introduce a notion of\ndirected branching apartness, and present a novel proof that if two states are\ndistinguished by a HMLU formula then they are branching apart. This proof\nproceeds by induction on the distinguishing formula.",
    "descriptor": "\nComments: 19 pages + appendices (26 pages total)\n",
    "authors": [
      "Herman Geuvers",
      "Anton Golov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.07380"
  },
  {
    "id": "arXiv:2210.07381",
    "title": "Frustratingly Easy Sentiment Analysis of Text Streams: Generating  High-Quality Emotion Arcs Using Emotion Lexicons",
    "abstract": "Automatically generated emotion arcs -- that capture how an individual or a\npopulation feels over time -- are widely used in industry and research.\nHowever, there is little work on evaluating the generated arcs. This is in part\ndue to the difficulty of establishing the true (gold) emotion arc. Our work,\nfor the first time, systematically and quantitatively evaluates automatically\ngenerated emotion arcs. We also compare two common ways of generating emotion\narcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. Using a\nnumber of diverse datasets, we systematically study the relationship between\nthe quality of an emotion lexicon and the quality of the emotion arc that can\nbe generated with it. We also study the relationship between the quality of an\ninstance-level emotion detection system (say from an ML model) and the quality\nof emotion arcs that can be generated with it. We show that despite being\nmarkedly poor at instance level, LexO methods are highly accurate at generating\nemotion arcs by aggregating information from hundreds of instances. This has\nwide-spread implications for commercial development, as well as research in\npsychology, public health, digital humanities, etc. that values simple\ninterpretable methods and disprefers the need for domain-specific training\ndata, programming expertise, and high-carbon-footprint models.",
    "descriptor": "",
    "authors": [
      "Daniela Teodorescu",
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07381"
  },
  {
    "id": "arXiv:2210.07382",
    "title": "Behavior Cloned Transformers are Neurosymbolic Reasoners",
    "abstract": "In this work, we explore techniques for augmenting interactive agents with\ninformation from symbolic modules, much like humans use tools like calculators\nand GPS systems to assist with arithmetic and navigation. We test our agent's\nabilities in text games -- challenging benchmarks for evaluating the multi-step\nreasoning abilities of game agents in grounded, language-based environments.\nOur experimental study indicates that injecting the actions from these symbolic\nmodules into the action space of a behavior cloned transformer agent increases\nperformance on four text game benchmarks that test arithmetic, navigation,\nsorting, and common sense reasoning by an average of 22%, allowing an agent to\nreach the highest possible performance on unseen games. This action injection\ntechnique is easily extended to new agents, environments, and symbolic modules.",
    "descriptor": "",
    "authors": [
      "Ruoyao Wang",
      "Peter Jansen",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Prithviraj Ammanabrolu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07382"
  },
  {
    "id": "arXiv:2210.07385",
    "title": "Synthesis of Proactive Sensor Placement In Probabilistic Attack Graphs",
    "abstract": "This paper studies the deployment of joint moving target defense (MTD) and\ndeception against multi-stage cyberattacks. Given the system equipped with MTD\nthat randomizes between different configurations, we investigate how to\nallocate a bounded number of sensors in each configuration to optimize the\nattack detection rate before the attacker achieves its objective. Specifically,\ntwo types of sensors are considered: intrusion detectors that are observable by\nthe attacker and stealthy sensors that are not observable to the attacker. We\npropose a two-step optimization-based approach for allocating intrusion\ndetectors and stealthy sensors: Firstly, the defender allocates intrusion\ndetectors assuming the attacker will best respond to evade detection by\nintrusion detectors. Secondly, the defender will allocate stealthy sensors,\ngiven the best response attack strategy computed in the first step, to further\nreduce the attacker's chance of success. We illustrate the effectiveness of the\nproposed methods using a cyber defense example.",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted to 2023 American Control Conference\n",
    "authors": [
      "Lening Li",
      "Haoxiang Ma",
      "Shuo Han",
      "Jie Fu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07385"
  },
  {
    "id": "arXiv:2210.07387",
    "title": "Amortized Inference for Heterogeneous Reconstruction in Cryo-EM",
    "abstract": "Cryo-electron microscopy (cryo-EM) is an imaging modality that provides\nunique insights into the dynamics of proteins and other building blocks of\nlife. The algorithmic challenge of jointly estimating the poses, 3D structure,\nand conformational heterogeneity of a biomolecule from millions of noisy and\nrandomly oriented 2D projections in a computationally efficient manner,\nhowever, remains unsolved. Our method, cryoFIRE, performs ab initio\nheterogeneous reconstruction with unknown poses in an amortized framework,\nthereby avoiding the computationally expensive step of pose search while\nenabling the analysis of conformational heterogeneity. Poses and conformation\nare jointly estimated by an encoder while a physics-based decoder aggregates\nthe images into an implicit neural representation of the conformational space.\nWe show that our method can provide one order of magnitude speedup on datasets\ncontaining millions of images without any loss of accuracy. We validate that\nthe joint estimation of poses and conformations can be amortized over the size\nof the dataset. For the first time, we prove that an amortized method can\nextract interpretable dynamic information from experimental datasets.",
    "descriptor": "",
    "authors": [
      "Axel Levy",
      "Gordon Wetzstein",
      "Julien Martel",
      "Frederic Poitevin",
      "Ellen D. Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.07387"
  },
  {
    "id": "arXiv:2210.07388",
    "title": "A Herglotz-based integrator for nonholonomic mechanical systems",
    "abstract": "We propose a numerical scheme for the time-integration of nonholonomic\nmechanical systems, both conservative and nonconservative. The scheme is\nobtained by simultaneously discretizing the constraint equations and the\nHerglotz variational principle. We validate the method using numerical\nsimulations and contrast them against the results of standard methods from the\nliterature.",
    "descriptor": "\nComments: 30 pages, 20 figures\n",
    "authors": [
      "Elias Maciel",
      "Inocencio Ortiz",
      "Christian E. Schaerer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07388"
  },
  {
    "id": "arXiv:2210.07394",
    "title": "Efficiently Computing Local Lipschitz Constants of Neural Networks via  Bound Propagation",
    "abstract": "Lipschitz constants are connected to many properties of neural networks, such\nas robustness, fairness, and generalization. Existing methods for computing\nLipschitz constants either produce relatively loose upper bounds or are limited\nto small networks. In this paper, we develop an efficient framework for\ncomputing the $\\ell_\\infty$ local Lipschitz constant of a neural network by\ntightly upper bounding the norm of Clarke Jacobian via linear bound\npropagation. We formulate the computation of local Lipschitz constants with a\nlinear bound propagation process on a high-order backward graph induced by the\nchain rule of Clarke Jacobian. To enable linear bound propagation, we derive\ntight linear relaxations for specific nonlinearities in Clarke Jacobian. This\nformulate unifies existing ad-hoc approaches such as RecurJac, which can be\nseen as a special case of ours with weaker relaxations. The bound propagation\nframework also allows us to easily borrow the popular Branch-and-Bound (BaB)\napproach from neural network verification to further tighten Lipschitz\nconstants. Experiments show that on tiny models, our method produces comparable\nbounds compared to exact methods that cannot scale to slightly larger models;\non larger models, our method efficiently produces tighter results than existing\nrelaxed or naive methods, and our method scales to much larger practical models\nthat previous works could not handle. We also demonstrate an application on\nprovable monotonicity analysis. Code is available at\nhttps://github.com/shizhouxing/Local-Lipschitz-Constants.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhouxing Shi",
      "Yihan Wang",
      "Huan Zhang",
      "Zico Kolter",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07394"
  },
  {
    "id": "arXiv:2210.07396",
    "title": "Caption supervision enables robust learners",
    "abstract": "Vision language models like CLIP are robust to natural distribution shifts,\nin part because CLIP learns on unstructured data using a technique called\ncaption supervision; the model inteprets image-linked texts as ground-truth\nlabels. In a carefully controlled comparison study, we show that CNNs trained\non a standard cross-entropy loss can also benefit from caption supervision, in\nsome cases even more than VL models, on the same data. To facilitate future\nexperiments with high-accuracy caption-supervised models, we introduce\nCaptionNet (https://github.com/penfever/CaptionNet/), which includes a\nclass-balanced, fully supervised dataset with over 50,000 new human-labeled\nImageNet-compliant samples which includes web-scraped captions. In a series of\nexperiments on CaptionNet, we show how the choice of loss function, data\nfiltration and supervision strategy enable robust computer vision. We also\nprovide the codebase necessary to reproduce our experiments at\nhttps://github.com/penfever/vlhub/",
    "descriptor": "",
    "authors": [
      "Benjamin Feuer",
      "Ameya Joshi",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07396"
  },
  {
    "id": "arXiv:2210.07397",
    "title": "A Concise Introduction to Reinforcement Learning in Robotics",
    "abstract": "One of the biggest hurdles robotics faces is the facet of sophisticated and\nhard-to-engineer behaviors. Reinforcement learning offers a set of tools, and a\nframework to address this problem. In parallel, the misgivings of robotics\noffer a solid testing ground and evaluation metric for advancements in\nreinforcement learning. The two disciplines go hand-in-hand, much like the\nfields of Mathematics and Physics. By means of this survey paper, we aim to\ninvigorate links between the research communities of the two disciplines by\nfocusing on the work done in reinforcement learning for locomotive and control\naspects of robotics. Additionally, we aim to highlight not only the notable\nsuccesses but also the key challenges of the application of Reinforcement\nLearning in Robotics. This paper aims to serve as a reference guide for\nresearchers in reinforcement learning applied to the field of robotics. The\nliterature survey is at a fairly introductory level, aimed at aspiring\nresearchers. Appropriately, we have covered the most essential concepts\nrequired for research in the field of reinforcement learning, with robotics in\nmind. Through a thorough analysis of this problem, we are able to manifest how\nreinforcement learning could be applied profitably, and also focus on\nopen-ended questions, as well as the potential for future research.",
    "descriptor": "\nComments: This paper was originally written in 2019\n",
    "authors": [
      "Akash Nagaraj",
      "Mukund Sood",
      "Bhagya M Patil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07397"
  },
  {
    "id": "arXiv:2210.07400",
    "title": "Real-time Action Recognition for Fine-Grained Actions and The Hand Wash  Dataset",
    "abstract": "In this paper we present a three-stream algorithm for real-time action\nrecognition and a new dataset of handwash videos, with the intent of aligning\naction recognition with real-world constraints to yield effective conclusions.\nA three-stream fusion algorithm is proposed, which runs both accurately and\nefficiently, in real-time even on low-powered systems such as a Raspberry Pi.\nThe cornerstone of the proposed algorithm is the incorporation of both spatial\nand temporal information, as well as the information of the objects in a video\nwhile using an efficient architecture, and Optical Flow computation to achieve\ncommendable results in real-time. The results achieved by this algorithm are\nbenchmarked on the UCF-101 as well as the HMDB-51 datasets, achieving an\naccuracy of 92.7% and 64.9% respectively. An important point to note is that\nthe algorithm is novel in the aspect that it is also able to learn the\nintricate differences between extremely similar actions, which would be\ndifficult even for the human eye. Additionally, noticing a dearth in the number\nof datasets for the recognition of very similar or fine-grained actions, this\npaper also introduces a new dataset that is made publicly available, the Hand\nWash Dataset with the intent of introducing a new benchmark for fine-grained\naction recognition tasks in the future.",
    "descriptor": "\nComments: This paper was originally written in early 2020\n",
    "authors": [
      "Akash Nagaraj",
      "Mukund Sood",
      "Chetna Sureka",
      "Gowri Srinivasa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.07400"
  },
  {
    "id": "arXiv:2210.07401",
    "title": "Estimation of the Sample Frechet Mean: A Convolutional Neural Network  Approach",
    "abstract": "This work addresses the rising demand for novel tools in statistical and\nmachine learning for \"graph-valued random variables\" by proposing a fast\nalgorithm to compute the sample Frechet mean, which replaces the concept of\nsample mean for graphs (or networks). We use convolutional neural networks to\nlearn the morphology of the graphs in a set of graphs. Our experiments on\nseveral ensembles of random graphs demonstrate that our method can reliably\nrecover the sample Frechet mean.",
    "descriptor": "",
    "authors": [
      "Adam Sanchez",
      "Fran\u00e7ois G. Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07401"
  },
  {
    "id": "arXiv:2210.07402",
    "title": "The two-sided Galois duals of multi-twisted codes",
    "abstract": "Characterizing the duals of linear codes with rich algebraic structures\nreceived great interest in recent decades. The beginning was by representing\ncyclic codes over finite fields as ideals in the polynomial ring. Subsequently,\nstudying the duals of constacyclic, quasi-cyclic, quasi-twisted, generalized\nquasi-cyclic, and multi-twisted codes appeared extensively in literature. We\nconsider the class of multi-twisted (MT) codes because it extends to all of\nthese codes. We describe a MT code $\\mathcal{C}$ as a module over a principal\nideal domain. Hence, $\\mathcal{C}$ has a generator polynomial matrix (GPM) that\nsatisfies an identical equation. The reduced GPM of $\\mathcal{C}$ is the\nHermite normal form of its GPM. We show that the Euclidean dual\n$\\mathcal{C}^\\perp$ of $\\mathcal{C}$ is MT as well. We prove a formula for a\nGPM of $\\mathcal{C}^\\perp$ using the identical equation of the reduced GPM of\n$\\mathcal{C}$. Then we aim to replace the Euclidean dual with the Galois dual.\nThe Galois inner product is an asymmetric form, so we distinguish between the\nright and left Galois duals. We show that the right and left Galois duals of a\nMT code are MT as well but with possibly different shift constants. Our study\nis the first to contain the right and left Galois duals of a linear code\nsimultaneously. This gives two advantages: establishing their interconnected\nidentities and introducing the two-sided Galois dual that has not previously\nappeared in the literature. We use a condition for the two-sided Galois dual of\na MT code to be MT, hence its GPM is characterized. Two special cases are also\nstudied, one when the right and left Galois duals trivially intersect and the\nother when they coincide. The latter case is considered for any linear code,\nwhere a necessary and sufficient condition is established for the equality of\nthe right and left Galois duals.",
    "descriptor": "",
    "authors": [
      "Ramy F. Taki Eldin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2210.07402"
  },
  {
    "id": "arXiv:2210.07403",
    "title": "The Immersed Boundary Double Layer (IBDL) Method",
    "abstract": "The Immersed Boundary (IB) method of Peskin (J. Comput. Phys., 1977) is\nuseful for problems involving fluid-structure interactions or complex\ngeometries. By making use of a regular grid that is independent of the\ngeometry, the IB framework yields a robust numerical scheme that can\nefficiently handle immersed deformable structures. The IB method has also been\nadapted to problems with prescribed motion and other PDEs with given boundary\ndata. IB methods for these problems traditionally involve penalty forces that\nonly approximately satisfy boundary conditions, or they are formulated as\nconstraint problems. In the latter approach, one must find the unknown forces\nby solving an equation that corresponds to a poorly conditioned first-kind\nintegral equation. This operation can therefore require a large number of\niterations of a Krylov method, and since a time-dependent problem requires this\nsolve at each time step, this method can be prohibitively inefficient without\npreconditioning. This dissertation introduces a new, well-conditioned IB\nformulation for boundary value problems, called the Immersed Boundary Double\nLayer (IBDL) method. We formulate it for Poisson, Helmholtz, Brinkman, Stokes,\nand Navier-Stokes equations and demonstrate its efficiency over the other\nconstraint method. In this new formulation, the equation for the unknown\nboundary distribution corresponds to a well-conditioned second-kind integral\nequation that can be solved efficiently with a small number of iterations of a\nKrylov method. Furthermore, the iteration count is independent of both the mesh\nsize and the boundary point spacing. The method converges away from the\nboundary, and when combined with a local interpolation, it converges in the\nentire PDE domain. Additionally, while the original constraint method applies\nonly to Dirichlet problems, the IBDL formulation can also be used for Neumann\nboundary conditions.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2203.12126\n",
    "authors": [
      "Brittany J. Leathers"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07403"
  },
  {
    "id": "arXiv:2210.07404",
    "title": "Early Discovery of Disappearing Entities in Microblogs",
    "abstract": "We make decisions by reacting to changes in the real world, in particular,\nthe emergence and disappearance of impermanent entities such as events,\nrestaurants, and services. Because we want to avoid missing out on\nopportunities or making fruitless actions after they have disappeared, it is\nimportant to know when entities disappear as early as possible. We thus tackle\nthe task of detecting disappearing entities from microblogs, whose posts\nmention various entities, in a timely manner. The major challenge is detecting\nuncertain contexts of disappearing entities from noisy microblog posts. To\ncollect these disappearing contexts, we design time-sensitive distant\nsupervision, which utilizes entities from the knowledge base and time-series\nposts, for this task to build large-scale Twitter datasets\\footnote{We will\nrelease the datasets (tweet IDs) used in the experiments to promote\nreproducibility.} for English and Japanese. To ensure robust detection in noisy\nenvironments, we refine pretrained word embeddings of the detection model on\nmicroblog streams of the target day. Experimental results on the Twitter\ndatasets confirmed the effectiveness of the collected labeled data and refined\nword embeddings; more than 70\\% of the detected disappearing entities in\nWikipedia are discovered earlier than the update on Wikipedia, and the average\nlead-time is over one month.",
    "descriptor": "",
    "authors": [
      "Satoshi Akasaki",
      "Naoki Yoshinaga",
      "Masashi Toyoda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07404"
  },
  {
    "id": "arXiv:2210.07407",
    "title": "Anomaly detection in dynamic networks",
    "abstract": "Detecting anomalies from a series of temporal networks has many applications,\nincluding road accidents in transport networks and suspicious events in social\nnetworks. While there are many methods for network anomaly detection,\nstatistical methods are under utilised in this space even though they have a\nlong history and proven capability in handling temporal dependencies. In this\npaper, we introduce \\textit{oddnet}, a feature-based network anomaly detection\nmethod that uses time series methods to model temporal dependencies. We\ndemonstrate the effectiveness of oddnet on synthetic and real-world datasets.\nThe R package oddnet implements this algorithm.",
    "descriptor": "",
    "authors": [
      "Sevvandi Kandanaarachchi",
      "Rob J Hyndman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07407"
  },
  {
    "id": "arXiv:2210.07411",
    "title": "A Novel Supervised Contrastive Regression Framework for Prediction of  Neurocognitive Measures Using Multi-Site Harmonized Diffusion MRI  Tractography",
    "abstract": "Neuroimaging-based prediction of neurocognitive measures is valuable for\nstudying how the brain's structure relates to cognitive function. However, the\naccuracy of prediction using popular linear regression models is relatively\nlow. We propose Supervised Contrastive Regression (SCR), a simple yet effective\nmethod that allows full supervision for contrastive learning in regression\ntasks. SCR performs supervised contrastive representation learning by using the\nabsolute difference between continuous regression labels (i.e. neurocognitive\nscores) to determine positive and negative pairs. We apply SCR to analyze a\nlarge-scale dataset including multi-site harmonized diffusion MRI and\nneurocognitive data from 8735 participants in the Adolescent Brain Cognitive\nDevelopment (ABCD) Study. We extract white matter microstructural measures\nusing a fine parcellation of white matter tractography into fiber clusters. We\npredict three scores related to domains of higher-order cognition (general\ncognitive ability, executive function, and learning/memory). To identify\nimportant fiber clusters for prediction of these neurocognitive scores, we\npropose a permutation feature importance method for high-dimensional data. We\nfind that SCR improves the accuracy of neurocognitive score prediction compared\nto other state-of-the-art methods. We find that the most predictive fiber\nclusters are predominantly located within the superficial white matter and\nprojection tracts, particularly the superficial frontal white matter and\nstriato-frontal connections. Overall, our results demonstrate the utility of\ncontrastive representation learning methods for regression, and in particular\nfor improving neuroimaging-based prediction of higher-order cognitive\nabilities.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Tengfei Xue",
      "Fan Zhang",
      "Leo R. Zekelman",
      "Chaoyi Zhang",
      "Yuqian Chen",
      "Suheyla Cetin-Karayumak",
      "Steve Pieper",
      "William M. Wells",
      "Yogesh Rathi",
      "Nikos Makris",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07411"
  },
  {
    "id": "arXiv:2210.07412",
    "title": "A Unified Cryptoprocessor for Lattice-based Signature and Key-exchange",
    "abstract": "We propose design methodologies for building a compact, unified and\nprogrammable cryptoprocessor architecture that computes post-quantum key\nagreement and digital signature. Synergies in the two types of cryptographic\nprimitives are used to make the cryptoprocessor compact. As a case study, the\ncryptoprocessor architecture has been optimized targeting the signature scheme\n'CRYSTALS-Dilithium' and the key encapsulation mechanism (KEM) 'Saber', both\nfinalists in the NIST's post-quantum cryptography standardization project. The\nprogrammable cryptoprocessor executes key generations, encapsulations,\ndecapsulations, signature generations, and signature verifications for all the\nsecurity levels of Dilithium and Saber. On a Xilinx Ultrascale+ FPGA, the\nproposed cryptoprocessor consumes 18,406 LUTs, 9,323 FFs, 4 DSPs, and 24 BRAMs.\nIt achieves 200 MHz clock frequency and finishes CCA-secure\nkey-generation/encapsulation/decapsulation operations for LightSaber in\n29.6/40.4/58.3$\\mu$s; for Saber in 54.9/69.7/94.9$\\mu$s; and for FireSaber in\n87.6/108.0/139.4$\\mu$s, respectively. It finishes key-generation/sign/verify\noperations for Dilithium-2 in 70.9/151.6/75.2$\\mu$s; for Dilithium-3 in\n114.7/237/127.6$\\mu$s; and for Dilithium-5 in 194.2/342.1/228.9$\\mu$s,\nrespectively, for the best-case scenario. On UMC 65nm library for ASIC the\nlatency is improved by a factor of two due to a 2x increase in clock frequency.",
    "descriptor": "\nComments: This paper will be published at IEEE Transactions on Computers\n",
    "authors": [
      "Aikata Aikata",
      "Ahmet Can Mert",
      "David Jacquemin",
      "Amitabh Das",
      "Donald Matthews",
      "Santosh Ghosh",
      "Sujoy Sinha Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.07412"
  },
  {
    "id": "arXiv:2210.07414",
    "title": "Human interaction networks reveal that large cities facilitate  segregation",
    "abstract": "A long-standing expectation is that large, dense, and cosmopolitan areas will\nsupport diverse interactions and socioeconomic mixing. It has been difficult to\nassess this hypothesis because past approaches to measuring socioeconomic\nmixing have relied on static residential housing data rather than real-life\ninteractions among people meeting at work, in places of leisure, and in home\nneighborhoods. Here we develop a new measure of interaction segegation (IS)\nthat captures the economic diversity of the set of people that a given person\nmeets in their everyday life. Leveraging cell phone mobility data to represent\n1.6 billion interactions among 9.6 million people in the United States, we\nmeasure interaction segregation across 382 Metropolitan Statistical Areas\n(MSAs) and 2829 counties. When averaged across all MSAs, interaction\nsegregation is 38% lower than a conventional static estimate, which means that\npeople meet diverse others mostly when outside their home neighborhoods. But,\nwe also find that interaction segregation is 67% higher in the 10 largest\nMetropolitan Statistical Areas (MSAs) than in small MSAs with fewer than\n100,000 residents. We find evidence that because large cities can offer a\ngreater choice of differentiated spaces targeted to specific socioeconomic\ngroups, they end up promoting -- rather than reducing -- everyday economic\nsegregation. We also discover that this segregation-increasing effect is\ncountered when hubs of interaction (e.g. shopping malls) are positioned to\nbridge diverse neighborhoods and thus attract people of all socioeconomic\nstatuses. Overall, our findings challenge a long-standing conjecture in human\ngeography and urban design, and highlight how built environment can both\nprevent and facilitate diverse human interactions.",
    "descriptor": "",
    "authors": [
      "Hamed Nilforoshan",
      "Wenli Looi",
      "Emma Pierson",
      "Blanca Villanueva",
      "Nic Fishman",
      "Yiling Chen",
      "John Sholar",
      "Beth Redbird",
      "David Grusky",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07414"
  },
  {
    "id": "arXiv:2210.07415",
    "title": "Noise Audits Improve Moral Foundation Classification",
    "abstract": "Morality plays an important role in culture, identity, and emotion. Recent\nadvances in natural language processing have shown that it is possible to\nclassify moral values expressed in text at scale. Morality classification\nrelies on human annotators to label the moral expressions in text, which\nprovides training data to achieve state-of-the-art performance. However, these\nannotations are inherently subjective and some of the instances are hard to\nclassify, resulting in noisy annotations due to error or lack of agreement. The\npresence of noise in training data harms the classifier's ability to accurately\nrecognize moral foundations from text. We propose two metrics to audit the\nnoise of annotations. The first metric is entropy of instance labels, which is\na proxy measure of annotator disagreement about how the instance should be\nlabeled. The second metric is the silhouette coefficient of a label assigned by\nan annotator to an instance. This metric leverages the idea that instances with\nthe same label should have similar latent representations, and deviations from\ncollective judgments are indicative of errors. Our experiments on three widely\nused moral foundations datasets show that removing noisy annotations based on\nthe proposed metrics improves classification performance.",
    "descriptor": "",
    "authors": [
      "Negar Mokhberian",
      "Frederic R. Hopp",
      "Bahareh Harandizadeh",
      "Fred Morstatter",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.07415"
  },
  {
    "id": "arXiv:2210.07416",
    "title": "GLACIAL: Granger and Learning-based Causality Analysis for Longitudinal  Studies",
    "abstract": "The Granger framework is widely used for discovering causal relationships\nbased on time-varying signals. Implementations of Granger causality (GC) are\nmostly developed for densely sampled timeseries data. A substantially different\nsetting, particularly common in population health applications, is the\nlongitudinal study design, where multiple individuals are followed and sparsely\nobserved for a limited number of times. Longitudinal studies commonly track\nmany variables, which are likely governed by nonlinear dynamics that might have\nindividual-specific idiosyncrasies and exhibit both direct and indirect causes.\nFurthermore, real-world longitudinal data often suffer from widespread\nmissingness. GC methods are not well-suited to handle these issues. In this\npaper, we intend to fill this methodological gap. We propose to marry the GC\nframework with a machine learning based prediction model. We call our approach\nGLACIAL, which stands for \"Granger and LeArning-based CausalIty Analysis for\nLongitudinal studies.\" GLACIAL treats individuals as independent samples and\nuses average prediction accuracy on hold-out individuals to test for effects of\ncausal relationships. GLACIAL employs a multi-task neural network trained with\ninput feature dropout to efficiently learn nonlinear dynamic relationships\nbetween a large number of variables, handle missing values, and probe causal\nlinks. Extensive experiments on synthetic and real data demonstrate the utility\nof GLACIAL and how it can outperform competitive baselines.",
    "descriptor": "",
    "authors": [
      "Minh Nguyen",
      "Gia H. Ngo",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.07416"
  },
  {
    "id": "arXiv:2210.07419",
    "title": "Continued fraction representations of the generalized operator entropy",
    "abstract": "The direct calculation of the Generalized operator entropy proves difficult\nby the appearance of rational exponents of matrices. The main motivation of\nthis work is to overcome these difficulties and to present a practical and\nefficient method for this calculation using its representation by the matrix\ncontinued fraction. At the end of our paper, we deduce a continued fraction\nexpansion of the Bregman operator divergence. Some numerical examples\nillutrating the theoretical result are discussed.",
    "descriptor": "",
    "authors": [
      "Sarra Ahallal",
      "Said Mennou",
      "Ali Kacha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2210.07419"
  },
  {
    "id": "arXiv:2210.07420",
    "title": "Learning to Efficiently Plan Robust Frictional Multi-Object Grasps",
    "abstract": "We consider a decluttering problem where multiple rigid convex polygonal\nobjects rest in randomly placed positions and orientations on a planar surface\nand must be efficiently transported to a packing box using both single and\nmulti-object grasps. Prior work considered frictionless multi-object grasping.\nIn this paper, we introduce friction to increase picks per hour. We train a\nneural network using real examples to plan robust multi-object grasps. In\nphysical experiments, we find an 11.7% increase in success rates, a 1.7x\nincrease in picks per hour, and an 8.2x decrease in grasp planning time\ncompared to prior work on multi-object grasping. Videos are available at\nhttps://youtu.be/pEZpHX5FZIs.",
    "descriptor": "",
    "authors": [
      "Wisdom C. Agboh",
      "Satvik Sharma",
      "Kishore Srinivas",
      "Mallika Parulekar",
      "Gaurav Datta",
      "Tianshuang Qiu",
      "Jeffrey Ichnowski",
      "Eugen Solowjow",
      "Mehmet Dogar",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07420"
  },
  {
    "id": "arXiv:2210.07423",
    "title": "Task Grouping for Multilingual Text Recognition",
    "abstract": "Most existing OCR methods focus on alphanumeric characters due to the\npopularity of English and numbers, as well as their corresponding datasets. On\nextending the characters to more languages, recent methods have shown that\ntraining different scripts with different recognition heads can greatly improve\nthe end-to-end recognition accuracy compared to combining characters from all\nlanguages in the same recognition head. However, we postulate that similarities\nbetween some languages could allow sharing of model parameters and benefit from\njoint training. Determining language groupings, however, is not immediately\nobvious. To this end, we propose an automatic method for multilingual text\nrecognition with a task grouping and assignment module using Gumbel-Softmax,\nintroducing a task grouping loss and weighted recognition loss to allow for\nsimultaneous training of the models and grouping modules. Experiments on MLT19\nlend evidence to our hypothesis that there is a middle ground between combining\nevery task together and separating every task that achieves a better\nconfiguration of task grouping/separation.",
    "descriptor": "\nComments: ECCV 2022: Text in Everything (TIE) Workshop (Oral)\n",
    "authors": [
      "Jing Huang",
      "Kevin J Liang",
      "Rama Kovvuri",
      "Tal Hassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07423"
  },
  {
    "id": "arXiv:2210.07424",
    "title": "Autoregressive Uncertainty Modeling for 3D Bounding Box Prediction",
    "abstract": "3D bounding boxes are a widespread intermediate representation in many\ncomputer vision applications. However, predicting them is a challenging task,\nlargely due to partial observability, which motivates the need for a strong\nsense of uncertainty. While many recent methods have explored better\narchitectures for consuming sparse and unstructured point cloud data, we\nhypothesize that there is room for improvement in the modeling of the output\ndistribution and explore how this can be achieved using an autoregressive\nprediction head. Additionally, we release a simulated dataset, COB-3D, which\nhighlights new types of ambiguity that arise in real-world robotics\napplications, where 3D bounding box prediction has largely been underexplored.\nWe propose methods for leveraging our autoregressive model to make high\nconfidence predictions and meaningful uncertainty measures, achieving strong\nresults on SUN-RGBD, Scannet, KITTI, and our new dataset.",
    "descriptor": "\nComments: In ECCV 2022. Code and dataset are available at this https URL\n",
    "authors": [
      "YuXuan Liu",
      "Nikhil Mishra",
      "Maximilian Sieb",
      "Yide Shentu",
      "Pieter Abbeel",
      "Xi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07424"
  },
  {
    "id": "arXiv:2210.07426",
    "title": "Skill-Based Reinforcement Learning with Intrinsic Reward Matching",
    "abstract": "While unsupervised skill discovery has shown promise in autonomously\nacquiring behavioral primitives, there is still a large methodological\ndisconnect between task-agnostic skill pretraining and downstream, task-aware\nfinetuning. We present Intrinsic Reward Matching (IRM), which unifies these two\nphases of learning via the $\\textit{skill discriminator}$, a pretraining model\ncomponent often discarded during finetuning. Conventional approaches finetune\npretrained agents directly at the policy level, often relying on expensive\nenvironment rollouts to empirically determine the optimal skill. However, often\nthe most concise yet complete description of a task is the reward function\nitself, and skill learning methods learn an $\\textit{intrinsic}$ reward\nfunction via the discriminator that corresponds to the skill policy. We propose\nto leverage the skill discriminator to $\\textit{match}$ the intrinsic and\ndownstream task rewards and determine the optimal skill for an unseen task\nwithout environment samples, consequently finetuning with greater\nsample-efficiency. Furthermore, we generalize IRM to sequence skills and solve\nmore complex, long-horizon tasks. We demonstrate that IRM is competitive with\nprevious skill selection methods on the Unsupervised Reinforcement Learning\nBenchmark and enables us to utilize pretrained skills far more effectively on\nchallenging tabletop manipulation tasks.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Ademi Adeniji",
      "Amber Xie",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07426"
  },
  {
    "id": "arXiv:2210.07428",
    "title": "A comparative study of the performance of different search algorithms on  FOON graphs",
    "abstract": "A robot finds it really hard to learn creatively and adapt to the new unseen\nchallenges. This is mainly because of the very limited information it has\naccess or experience towards. Paulius et al. \\cite{b4} presented a way to\nconstruct functional graphs which can encapsulate. Sakib et al. \\cite{b1}\nfurther expanded FOON objects for robotic cooking. This paper presents a\ncomparative study of Breadth First Search (BFS), Greedy Breadth First search\n(GBFS) with two heuristic functions, and Iterative Depth First Search (IDFS)\nand provides the comparison of their performance.",
    "descriptor": "",
    "authors": [
      "Kumar Shashwat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07428"
  },
  {
    "id": "arXiv:2210.07431",
    "title": "PCFG-based Natural Language Interface Improves Generalization for  Controlled Text Generation",
    "abstract": "Existing work on controlled text generation (CTG) assumes a control interface\nof categorical attributes. In this work, we propose a natural language (NL)\ninterface, where we craft a PCFG to embed the control attributes into natural\nlanguage commands, and propose variants of existing CTG models that take\ncommands as input. In our experiments, we design tailored setups to test\nmodel's generalization abilities. We find our PCFG-based command generation\napproach is effective for handling unseen commands compared to fix-set\ntemplates; our proposed NL models can effectively generalize to unseen\nattributes, a new ability enabled by the NL interface, as well as unseen\nattribute combinations. Interestingly, we discover that the simple conditional\ngeneration approach, enhanced with our proposed NL interface, is a strong\nbaseline in those challenging settings.",
    "descriptor": "",
    "authors": [
      "Jingyu Zhang",
      "James Glass",
      "Tianxing He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07431"
  },
  {
    "id": "arXiv:2210.07432",
    "title": "Monte Carlo Augmented Actor-Critic for Sparse Reward Deep Reinforcement  Learning from Suboptimal Demonstrations",
    "abstract": "Providing densely shaped reward functions for RL algorithms is often\nexceedingly challenging, motivating the development of RL algorithms that can\nlearn from easier-to-specify sparse reward functions. This sparsity poses new\nexploration challenges. One common way to address this problem is using\ndemonstrations to provide initial signal about regions of the state space with\nhigh rewards. However, prior RL from demonstrations algorithms introduce\nsignificant complexity and many hyperparameters, making them hard to implement\nand tune. We introduce Monte Carlo Augmented Actor Critic (MCAC), a parameter\nfree modification to standard actor-critic algorithms which initializes the\nreplay buffer with demonstrations and computes a modified $Q$-value by taking\nthe maximum of the standard temporal distance (TD) target and a Monte Carlo\nestimate of the reward-to-go. This encourages exploration in the neighborhood\nof high-performing trajectories by encouraging high $Q$-values in corresponding\nregions of the state space. Experiments across $5$ continuous control domains\nsuggest that MCAC can be used to significantly increase learning efficiency\nacross $6$ commonly used RL and RL-from-demonstrations algorithms. See\nhttps://sites.google.com/view/mcac-rl for code and supplementary material.",
    "descriptor": "\nComments: To be published in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 19 pages. 11 figures\n",
    "authors": [
      "Albert Wilcox",
      "Ashwin Balakrishna",
      "Jules Dedieu",
      "Wyame Benslimane",
      "Daniel Brown",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07432"
  },
  {
    "id": "arXiv:2210.07435",
    "title": "NOCaL: Calibration-Free Semi-Supervised Learning of Odometry and Camera  Intrinsics",
    "abstract": "There are a multitude of emerging imaging technologies that could benefit\nrobotics. However the need for bespoke models, calibration and low-level\nprocessing represents a key barrier to their adoption. In this work we present\nNOCaL, Neural odometry and Calibration using Light fields, a semi-supervised\nlearning architecture capable of interpreting previously unseen cameras without\ncalibration. NOCaL learns to estimate camera parameters, relative pose, and\nscene appearance. It employs a scene-rendering hypernetwork pretrained on a\nlarge number of existing cameras and scenes, and adapts to previously unseen\ncameras using a small supervised training set to enforce metric scale. We\ndemonstrate NOCaL on rendered and captured imagery using conventional cameras,\ndemonstrating calibration-free odometry and novel view synthesis. This work\nrepresents a key step toward automating the interpretation of general camera\ngeometries and emerging imaging technologies.",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables, for associated project page, see this https URL\n",
    "authors": [
      "Ryan Griffiths",
      "Jack Naylor",
      "Donald G. Dansereau"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07435"
  },
  {
    "id": "arXiv:2210.07436",
    "title": "Smart Headset, Computer Vision and Machine Learning for Efficient Prawn  Farm Management",
    "abstract": "Understanding the growth and distribution of the prawns is critical for\noptimising the feed and harvest strategies. An inadequate understanding of\nprawn growth can lead to reduced financial gain, for example, crops are\nharvested too early. The key to maintaining a good understanding of prawn\ngrowth is frequent sampling. However, the most commonly adopted sampling\npractice, the cast net approach, is unable to sample the prawns at a high\nfrequency as it is expensive and laborious. An alternative approach is to\nsample prawns from feed trays that farm workers inspect each day. This will\nallow growth data collection at a high frequency (each day). But measuring\nprawns manually each day is a laborious task. In this article, we propose a new\napproach that utilises smart glasses, depth camera, computer vision and machine\nlearning to detect prawn distribution and growth from feed trays. A smart\nheadset was built to allow farmers to collect prawn data while performing daily\nfeed tray checks. A computer vision + machine learning pipeline was developed\nand demonstrated to detect the growth trends of prawns in 4 prawn ponds over a\ngrowing season.",
    "descriptor": "\nComments: Submitted to Elsevier Aquacultural Engineering\n",
    "authors": [
      "Mingze Xi",
      "Ashfaqur Rahman",
      "Chuong Nguyen",
      "Stuart Arnold",
      "John McCulloch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07436"
  },
  {
    "id": "arXiv:2210.07437",
    "title": "Upper bounds on the Rate of Uniformly-Random Codes for the Deletion  Channel",
    "abstract": "We consider the maximum coding rate achievable by uniformly-random codes for\nthe deletion channel. We prove an upper bound that's within 0.1 of the best\nknown lower bounds for all values of the deletion probability $d,$ and much\ncloser for small and large $d.$ We give simulation results which suggest that\nour upper bound is within 0.05 of the exact value for all $d$, and within\n$0.01$ for $d>0.75$. Despite our upper bounds, based on simulations, we\nconjecture that a positive rate is achievable with uniformly-random codes for\nall deletion probabilities less than 1. Our results imply impossibility results\nfor the (equivalent) problem of compression of i.i.d. sources correlated via\nthe deletion channel, a relevant model for DNA storage.",
    "descriptor": "",
    "authors": [
      "Berivan Isik",
      "Francisco Pernice",
      "Tsachy Weissman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07437"
  },
  {
    "id": "arXiv:2210.07439",
    "title": "Risk-Awareness in Learning Neural Controllers for Temporal Logic  Objectives",
    "abstract": "In this paper, we consider the problem of synthesizing a controller in the\npresence of uncertainty such that the resulting closed-loop system satisfies\ncertain hard constraints while optimizing certain (soft) performance\nobjectives. We assume that the hard constraints encoding safety or\nmission-critical task objectives are expressed using Signal Temporal Logic\n(STL), while performance is quantified using standard cost functions on system\ntrajectories. In order to prioritize the satisfaction of the hard STL\nconstraints, we utilize the framework of control barrier functions (CBFs) and\nalgorithmically obtain CBFs for STL objectives. We assume that the controllers\nare modeled using neural networks (NNs) and provide an optimization algorithm\nto learn the optimal parameters for the NN controller that optimize the\nperformance at a user-specified robustness margin for the safety\nspecifications. We use the formalism of risk measures to evaluate the risk\nincurred by the trade-off between robustness margin of the system and its\nperformance. We demonstrate the efficacy of our approach on well-known\ndifficult examples for nonlinear control such as a quad-rotor and a unicycle,\nwhere the mission objectives for each system include hard timing constraints\nand safety objectives.",
    "descriptor": "",
    "authors": [
      "Navid Hashemi",
      "Xin Qin",
      "Jyotirmoy V. Deshmukh",
      "Georgios Fainekos",
      "Bardh Hoxha",
      "Danil Prokhorov",
      "Tomoya Yamaguchi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.07439"
  },
  {
    "id": "arXiv:2210.07440",
    "title": "InterFair: Debiasing with Natural Language Feedback for Fair  Interpretable Predictions",
    "abstract": "Debiasing methods in NLP models traditionally focus on isolating information\nrelated to a sensitive attribute (like gender or race). We instead argue that a\nfavorable debiasing method should use sensitive information 'fairly,' with\nexplanations, rather than blindly eliminating it. This fair balance is often\nsubjective and can be challenging to achieve algorithmically. We show that an\ninteractive setup with users enabled to provide feedback can achieve a better\nand fair balance between task performance and bias mitigation, supported by\nfaithful explanations.",
    "descriptor": "",
    "authors": [
      "Bodhisattwa Prasad Majumder",
      "Zexue He",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07440"
  },
  {
    "id": "arXiv:2210.07441",
    "title": "Characterizing the Influence of Graph Elements",
    "abstract": "Influence function, a method from robust statistics, measures the changes of\nmodel parameters or some functions about model parameters concerning the\nremoval or modification of training instances. It is an efficient and useful\npost-hoc method for studying the interpretability of machine learning models\nwithout the need for expensive model re-training. Recently, graph convolution\nnetworks (GCNs), which operate on graph data, have attracted a great deal of\nattention. However, there is no preceding research on the influence functions\nof GCNs to shed light on the effects of removing training nodes/edges from an\ninput graph. Since the nodes/edges in a graph are interdependent in GCNs, it is\nchallenging to derive influence functions for GCNs. To fill this gap, we\nstarted with the simple graph convolution (SGC) model that operates on an\nattributed graph and formulated an influence function to approximate the\nchanges in model parameters when a node or an edge is removed from an\nattributed graph. Moreover, we theoretically analyzed the error bound of the\nestimated influence of removing an edge. We experimentally validated the\naccuracy and effectiveness of our influence estimation function. In addition,\nwe showed that the influence function of an SGC model could be used to estimate\nthe impact of removing training nodes/edges on the test performance of the SGC\nwithout re-training the model. Finally, we demonstrated how to use influence\nfunctions to guide the adversarial attacks on GCNs effectively.",
    "descriptor": "",
    "authors": [
      "Zizhang Chen",
      "Peizhao Li",
      "Hongfu Liu",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07441"
  },
  {
    "id": "arXiv:2210.07442",
    "title": "Frame Mining: a Free Lunch for Learning Robotic Manipulation from 3D  Point Clouds",
    "abstract": "We study how choices of input point cloud coordinate frames impact learning\nof manipulation skills from 3D point clouds. There exist a variety of\ncoordinate frame choices to normalize captured robot-object-interaction point\nclouds. We find that different frames have a profound effect on agent learning\nperformance, and the trend is similar across 3D backbone networks. In\nparticular, the end-effector frame and the target-part frame achieve higher\ntraining efficiency than the commonly used world frame and robot-base frame in\nmany tasks, intuitively because they provide helpful alignments among point\nclouds across time steps and thus can simplify visual module learning.\nMoreover, the well-performing frames vary across tasks, and some tasks may\nbenefit from multiple frame candidates. We thus propose FrameMiners to\nadaptively select candidate frames and fuse their merits in a task-agnostic\nmanner. Experimentally, FrameMiners achieves on-par or significantly higher\nperformance than the best single-frame version on five fully physical\nmanipulation tasks adapted from ManiSkill and OCRTOC. Without changing existing\ncamera placements or adding extra cameras, point cloud frame mining can serve\nas a free lunch to improve 3D manipulation learning.",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022; Project Website: this https URL\n",
    "authors": [
      "Minghua Liu",
      "Xuanlin Li",
      "Zhan Ling",
      "Yangyan Li",
      "Hao Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07442"
  },
  {
    "id": "arXiv:2210.07443",
    "title": "MEGCF: Multimodal Entity Graph Collaborative Filtering for Personalized  Recommendation",
    "abstract": "In most E-commerce platforms, whether the displayed items trigger the user's\ninterest largely depends on their most eye-catching multimodal content.\nConsequently, increasing efforts focus on modeling multimodal user preference,\nand the pressing paradigm is to incorporate complete multimodal deep features\nof the items into the recommendation module. However, the existing studies\nignore the mismatch problem between multimodal feature extraction (MFE) and\nuser interest modeling (UIM). That is, MFE and UIM have different emphases.\nSpecifically, MFE is migrated from and adapted to upstream tasks such as image\nclassification. In addition, it is mainly a content-oriented and\nnon-personalized process, while UIM, with its greater focus on understanding\nuser interaction, is essentially a user-oriented and personalized process.\nTherefore, the direct incorporation of MFE into UIM for purely user-oriented\ntasks, tends to introduce a large number of preference-independent multimodal\nnoise and contaminate the embedding representations in UIM.\nThis paper aims at solving the mismatch problem between MFE and UIM, so as to\ngenerate high-quality embedding representations and better model multimodal\nuser preferences. Towards this end, we develop a novel model, MEGCF. The UIM of\nthe proposed model captures the semantic correlation between interactions and\nthe features obtained from MFE, thus making a better match between MFE and UIM.\nMore precisely, semantic-rich entities are first extracted from the multimodal\ndata, since they are more relevant to user preferences than other multimodal\ninformation. These entities are then integrated into the user-item interaction\ngraph. Afterwards, a symmetric linear Graph Convolution Network (GCN) module is\nconstructed to perform message propagation over the graph, in order to capture\nboth high-order semantic correlation and collaborative filtering signals.",
    "descriptor": "",
    "authors": [
      "Kang Liu",
      "Feng Xue",
      "Dan Guo",
      "Le Wu",
      "Shujie Li",
      "Richang Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.07443"
  },
  {
    "id": "arXiv:2210.07447",
    "title": "Multilingual Word Sense Disambiguation with Unified Sense Representation",
    "abstract": "As a key natural language processing (NLP) task, word sense disambiguation\n(WSD) evaluates how well NLP models can understand the lexical semantics of\nwords under specific contexts. Benefited from the large-scale annotation,\ncurrent WSD systems have achieved impressive performances in English by\ncombining supervised learning with lexical knowledge. However, such success is\nhard to be replicated in other languages, where we only have limited\nannotations.In this paper, based on the multilingual lexicon BabelNet\ndescribing the same set of concepts across languages, we propose building\nknowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD)\nsystems. We build unified sense representations for multiple languages and\naddress the annotation scarcity problem for MWSD by transferring annotations\nfrom rich-sourced languages to poorer ones. With the unified sense\nrepresentations, annotations from multiple languages can be jointly trained to\nbenefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets\ndemonstrate the effectiveness of our methodology.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ying Su",
      "Hongming Zhang",
      "Yangqiu Song",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07447"
  },
  {
    "id": "arXiv:2210.07448",
    "title": "Evaluating Out-of-Distribution Performance on Document Image Classifiers",
    "abstract": "The ability of a document classifier to handle inputs that are drawn from a\ndistribution different from the training distribution is crucial for robust\ndeployment and generalizability. The RVL-CDIP corpus is the de facto standard\nbenchmark for document classification, yet to our knowledge all studies that\nuse this corpus do not include evaluation on out-of-distribution documents. In\nthis paper, we curate and release a new out-of-distribution benchmark for\nevaluating out-of-distribution performance for document classifiers. Our new\nout-of-distribution benchmark consists of two types of documents: those that\nare not part of any of the 16 in-domain RVL-CDIP categories (RVL-CDIP-O), and\nthose that are one of the 16 in-domain categories yet are drawn from a\ndistribution different from that of the original RVL-CDIP dataset (RVL-CDIP-N).\nWhile prior work on document classification for in-domain RVL-CDIP documents\nreports high accuracy scores, we find that these models exhibit accuracy drops\nof between roughly 15-30% on our new out-of-domain RVL-CDIP-N benchmark, and\nfurther struggle to distinguish between in-domain RVL-CDIP-N and out-of-domain\nRVL-CDIP-O inputs. Our new benchmark provides researchers with a valuable new\nresource for analyzing out-of-distribution performance on document classifiers.\nOur new out-of-distribution data can be found at https://tinyurl.com/4he6my23.",
    "descriptor": "\nComments: NeurIPS D&B 2022\n",
    "authors": [
      "Stefan Larson",
      "Gordon Lim",
      "Yutong Ai",
      "David Kuang",
      "Kevin Leach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07448"
  },
  {
    "id": "arXiv:2210.07449",
    "title": "G2A2: An Automated Graph Generator with Attributes and Anomalies",
    "abstract": "Many data-mining applications use dynamic attributed graphs to represent\nrelational information; but due to security and privacy concerns, there is a\ndearth of available datasets that can be represented as dynamic attributed\ngraphs. Even when such datasets are available, they do not have ground truth\nthat can be used to train deep-learning models. Thus, we present G2A2, an\nautomated graph generator with attributes and anomalies, which encompasses (1)\nprobabilistic models to generate a dynamic bipartite graph, representing\ntime-evolving connections between two independent sets of entities, (2)\nrealistic injection of anomalies using a novel algorithm that captures the\ngeneral properties of graph anomalies across domains, and (3) a deep generative\nmodel to produce realistic attributes, learned from an existing real-world\ndataset. Using the maximum mean discrepancy (MMD) metric to evaluate the\nrealism of a G2A2-generated graph against three real-world graphs, G2A2\noutperforms Kronecker graph generation by reducing the MMD distance by up to\nsix-fold (6x).",
    "descriptor": "",
    "authors": [
      "Saikat Dey",
      "Sonal Jha",
      "Wu-chun Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07449"
  },
  {
    "id": "arXiv:2210.07450",
    "title": "ExAug: Robot-Conditioned Navigation Policies via Geometric Experience  Augmentation",
    "abstract": "Machine learning techniques rely on large and diverse datasets for\ngeneralization. Computer vision, natural language processing, and other\napplications can often reuse public datasets to train many different models.\nHowever, due to differences in physical configurations, it is challenging to\nleverage public datasets for training robotic control policies on new robot\nplatforms or for new tasks. In this work, we propose a novel framework, ExAug\nto augment the experiences of different robot platforms from multiple datasets\nin diverse environments. ExAug leverages a simple principle: by extracting 3D\ninformation in the form of a point cloud, we can create much more complex and\nstructured augmentations, utilizing both generating synthetic images and\ngeometric-aware penalization that would have been suitable in the same\nsituation for a different robot, with different size, turning radius, and\ncamera placement. The trained policy is evaluated on two new robot platforms\nwith three different cameras in indoor and outdoor environments with obstacles.",
    "descriptor": "\nComments: 10 pages, 9 figures, 2 tables\n",
    "authors": [
      "Noriaki Hirose",
      "Dhruv Shah",
      "Ajay Sridhar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07450"
  },
  {
    "id": "arXiv:2210.07451",
    "title": "Neural Network Compression by Joint Sparsity Promotion and Redundancy  Reduction",
    "abstract": "Compression of convolutional neural network models has recently been\ndominated by pruning approaches. A class of previous works focuses solely on\npruning the unimportant filters to achieve network compression. Another\nimportant direction is the design of sparsity-inducing constraints which has\nalso been explored in isolation. This paper presents a novel training scheme\nbased on composite constraints that prune redundant filters and minimize their\neffect on overall network learning via sparsity promotion. Also, as opposed to\nprior works that employ pseudo-norm-based sparsity-inducing constraints, we\npropose a sparse scheme based on gradient counting in our framework. Our tests\non several pixel-wise segmentation benchmarks show that the number of neurons\nand the memory footprint of networks in the test phase are significantly\nreduced without affecting performance. MobileNetV3 and UNet, two well-known\narchitectures, are used to test the proposed scheme. Our network compression\nmethod not only results in reduced parameters but also achieves improved\nperformance compared to MobileNetv3, which is an already optimized\narchitecture.",
    "descriptor": "",
    "authors": [
      "Tariq M. Khan",
      "Syed S. Naqvi",
      "Antonio Robles-Kelly",
      "Erik Meijering"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07451"
  },
  {
    "id": "arXiv:2210.07453",
    "title": "Using Graph Algorithms to Pretrain Graph Completion Transformers",
    "abstract": "Recent work on Graph Neural Networks has demonstrated that self-supervised\npretraining can further enhance performance on downstream graph, link, and node\nclassification tasks. However, the efficacy of pretraining tasks has not been\nfully investigated for downstream large knowledge graph completion tasks. Using\na contextualized knowledge graph embedding approach, we investigate five\ndifferent pretraining signals, constructed using several graph algorithms and\nno external data, as well as their combination. We leverage the versatility of\nour Transformer-based model to explore graph structure generation pretraining\ntasks, typically inapplicable to most graph embedding methods. We further\npropose a new path-finding algorithm guided by information gain and find that\nit is the best-performing pretraining task across three downstream knowledge\ngraph completion datasets. In a multitask setting that combines all pretraining\ntasks, our method surpasses some of the latest and strong performing knowledge\ngraph embedding methods on all metrics for FB15K-237, on MRR and Hit@1 for\nWN18RR and on MRR and hit@10 for JF17K (a knowledge hypergraph dataset).",
    "descriptor": "",
    "authors": [
      "Jonathan Pilault",
      "Michael Galkin",
      "Bahare Fatemi",
      "Perouz Taslakian",
      "David Vasquez",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07453"
  },
  {
    "id": "arXiv:2210.07454",
    "title": "Communication-Efficient Adam-Type Algorithms for Distributed Data Mining",
    "abstract": "Distributed data mining is an emerging research topic to effectively and\nefficiently address hard data mining tasks using big data, which are\npartitioned and computed on different worker nodes, instead of one centralized\nserver. Nevertheless, distributed learning methods often suffer from the\ncommunication bottleneck when the network bandwidth is limited or the size of\nmodel is large. To solve this critical issue, many gradient compression methods\nhave been proposed recently to reduce the communication cost for multiple\noptimization algorithms. However, the current applications of gradient\ncompression to adaptive gradient method, which is widely adopted because of its\nexcellent performance to train DNNs, do not achieve the same ideal compression\nrate or convergence rate as Sketched-SGD. To address this limitation, in this\npaper, we propose a class of novel distributed Adam-type algorithms\n(\\emph{i.e.}, SketchedAMSGrad) utilizing sketching, which is a promising\ncompression technique that reduces the communication cost from $O(d)$ to\n$O(\\log(d))$ where $d$ is the parameter dimension. In our theoretical analysis,\nwe prove that our new algorithm achieves a fast convergence rate of\n$O(\\frac{1}{\\sqrt{nT}} + \\frac{1}{(k/d)^2 T})$ with the communication cost of\n$O(k \\log(d))$ at each iteration. Compared with single-machine AMSGrad, our\nalgorithm can achieve the linear speedup with respect to the number of workers\n$n$. The experimental results on training various DNNs in distributed paradigm\nvalidate the efficiency of our algorithms.",
    "descriptor": "",
    "authors": [
      "Wenhan Xian",
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07454"
  },
  {
    "id": "arXiv:2210.07455",
    "title": "Controlling Bias Exposure for Fair Interpretable Predictions",
    "abstract": "Recent work on reducing bias in NLP models usually focuses on protecting or\nisolating information related to a sensitive attribute (like gender or race).\nHowever, when sensitive information is semantically entangled with the task\ninformation of the input, e.g., the gender information is predictive for a\nprofession, a fair trade-off between task performance and bias mitigation is\ndifficult to achieve. Existing approaches perform this trade-off by eliminating\nbias information from the latent space, lacking control over how much bias is\nnecessarily required to be removed. We argue that a favorable debiasing method\nshould use sensitive information 'fairly' rather than blindly eliminating it\n(Caliskan et al., 2017; Sun et al., 2019). In this work, we provide a novel\ndebiasing algorithm by adjusting the predictive model's belief to (1) ignore\nthe sensitive information if it is not useful for the task; (2) use sensitive\ninformation minimally as necessary for the prediction (while also incurring a\npenalty). Experimental results on two text classification tasks (influenced by\ngender) and an open-ended generation task (influenced by race) indicate that\nour model achieves a desirable trade-off between debiasing and task performance\nalong with producing debiased rationales as evidence.",
    "descriptor": "\nComments: To appear at EMNLP2022 as Findings\n",
    "authors": [
      "Zexue He",
      "Yu Wang",
      "Julian McAuley",
      "Bodhisattwa Prasad Majumder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07455"
  },
  {
    "id": "arXiv:2210.07461",
    "title": "Distributed Computation for the Non-metric Data Placement Problem using  Glauber Dynamics and Auctions",
    "abstract": "We consider the non-metric data placement problem and develop distributed\nalgorithms for computing or approximating its optimal integral solution. We\nfirst show that the non-metric data placement problem is inapproximable up to a\nlogarithmic factor. We then provide a game-theoretic decomposition of the\nobjective function and show that natural Glauber dynamics in which players\nupdate their resources with probability proportional to the utility they\nreceive from caching those resources will converge to an optimal global\nsolution for a sufficiently large noise parameter. In particular, we establish\nthe polynomial mixing time of the Glauber dynamics for a certain range of noise\nparameters. Finally, we provide another auction-based distributed algorithm,\nwhich allows us to approximate the optimal global solution with a performance\nguarantee that depends on the ratio of the revenue vs. social welfare obtained\nfrom the underlying auction. Our results provide the first distributed\ncomputation algorithms for the non-metric data placement problem.",
    "descriptor": "",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.07461"
  },
  {
    "id": "arXiv:2210.07463",
    "title": "Polycentric Clustering and Structural Regularization for Source-free  Unsupervised Domain Adaptation",
    "abstract": "Source-Free Domain Adaptation (SFDA) aims to solve the domain adaptation\nproblem by transferring the knowledge learned from a pre-trained source model\nto an unseen target domain. Most existing methods assign pseudo-labels to the\ntarget data by generating feature prototypes. However, due to the discrepancy\nin the data distribution between the source domain and the target domain and\ncategory imbalance in the target domain, there are severe class biases in the\ngenerated feature prototypes and noisy pseudo-labels. Besides, the data\nstructure of the target domain is often ignored, which is crucial for\nclustering. In this paper, a novel framework named PCSR is proposed to tackle\nSFDA via a novel intra-class Polycentric Clustering and Structural\nRegularization strategy. Firstly, an inter-class balanced sampling strategy is\nproposed to generate representative feature prototypes for each class.\nFurthermore, k-means clustering is introduced to generate multiple clustering\ncenters for each class in the target domain to obtain robust pseudo-labels.\nFinally, to enhance the model's generalization, structural regularization is\nintroduced for the target domain. Extensive experiments on three UDA benchmark\ndatasets show that our method performs better or similarly against the other\nstate of the art methods, demonstrating our approach's superiority for visual\ndomain adaptation problems.",
    "descriptor": "\nComments: BMVC2022, codes this https URL\n",
    "authors": [
      "Xinyu Guan",
      "Han Sun",
      "Ningzhong Liu",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07463"
  },
  {
    "id": "arXiv:2210.07465",
    "title": "Learning Algorithms in Static Analysis of Web Applications",
    "abstract": "Web applications are distributed applications, they are programs that run on\nmore than one computer and communicate through a network or server. This very\ndistributed nature of web applications, combined with the scale and sheer\ncomplexity of modern software systems complicate manual security auditing,\nwhile also creating a huge attack surface of potential hackers. These factors\nare making automated analysis a necessity. Static Application Security Testing\n(SAST) is a method devised to automatically analyze application source code of\nlarge code bases without compiling it, and design conditions that are\nindicative of security vulnerabilities. However, the problem lies in the fact\nthat the most widely used Static Application Security Testing Tools often yield\nunreliable results, owing to the false positive classification of\nvulnerabilities grossly outnumbering the classification of true positive\nvulnerabilities. This is one of the biggest hindrances to the proliferation of\nSAST testing, which leaves the user to review hundreds, if not thousands, of\npotential warnings, and classify them as either actionable or spurious. We try\nto minimize the problem of false positives by introducing a technique to filter\nthe output of SAST tools. The aim of the project is to apply learning\nalgorithms to the output by analyzing the true and false positives classified\nby OWASP Benchmark, and eliminate, or reduce the number of false positives\npresented to the user of the SAST Tool.",
    "descriptor": "\nComments: This paper was originally written in 2019\n",
    "authors": [
      "Akash Nagaraj",
      "Bishesh Sinha",
      "Mukund Sood",
      "Yash Mathur",
      "Sanchika Gupta",
      "Dinkar Sitaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07465"
  },
  {
    "id": "arXiv:2210.07466",
    "title": "Synthetic-to-real Composite Semantic Segmentation in Additive  Manufacturing",
    "abstract": "The application of computer vision and machine learning methods in the field\nof additive manufacturing (AM) for semantic segmentation of the structural\nelements of 3-D printed products will improve real-time failure analysis\nsystems and can potentially reduce the number of defects by enabling in situ\ncorrections. This work demonstrates the possibilities of using physics-based\nrendering for labeled image dataset generation, as well as image-to-image\ntranslation capabilities to improve the accuracy of real image segmentation for\nAM systems. Multi-class semantic segmentation experiments were carried out\nbased on the U-Net model and cycle generative adversarial network. The test\nresults demonstrated the capacity of detecting such structural elements of 3-D\nprinted parts as a top layer, infill, shell, and support. A basis for further\nsegmentation system enhancement by utilizing image-to-image style transfer and\ndomain adaptation technologies was also developed. The results indicate that\nusing style transfer as a precursor to domain adaptation can significantly\nimprove real 3-D printing image segmentation in situations where a model\ntrained on synthetic data is the only tool available. The mean intersection\nover union (mIoU) scores for synthetic test datasets included 94.90% for the\nentire 3-D printed part, 73.33% for the top layer, 78.93% for the infill,\n55.31% for the shell, and 69.45% for supports.",
    "descriptor": "",
    "authors": [
      "Aliaksei Petsiuk",
      "Harnoor Singh",
      "Himanshu Dadhwal",
      "Joshua M. Pearce"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.07466"
  },
  {
    "id": "arXiv:2210.07467",
    "title": "Adaptable Claim Rewriting with Offline Reinforcement Learning for  Effective Misinformation Discovery",
    "abstract": "We propose a novel system to help fact-checkers formulate search queries for\nknown misinformation claims and effectively search across multiple social media\nplatforms. We introduce an adaptable rewriting strategy, where editing actions\n(e.g., swap a word with its synonym; change verb tense into present simple) for\nqueries containing claims are automatically learned through offline\nreinforcement learning. Specifically, we use a decision transformer to learn a\nsequence of editing actions that maximize query retrieval metrics such as mean\naverage precision. Through several experiments, we show that our approach can\nincrease the effectiveness of the queries by up to 42\\% relatively, while\nproducing editing action sequences that are human readable, thus making the\nsystem easy to use and explain.",
    "descriptor": "",
    "authors": [
      "Ashkan Kazemi",
      "Artem Abzaliev",
      "Naihao Deng",
      "Rui Hou",
      "Davis Liang",
      "Scott A. Hale",
      "Ver\u00f3nica P\u00e9rez-Rosas",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07467"
  },
  {
    "id": "arXiv:2210.07468",
    "title": "Transparency Helps Reveal When Language Models Learn Meaning",
    "abstract": "Many current NLP systems are built from language models trained to optimize\nunsupervised objectives on large amounts of raw text. Under what conditions\nmight such a procedure acquire meaning? Our systematic experiments with\nsynthetic data reveal that, with languages where all expressions have\ncontext-independent denotations (i.e., languages with strong transparency),\nboth autoregressive and masked language models successfully learn to emulate\nsemantic relations between expressions. However, when denotations are changed\nto be context-dependent with the language otherwise unmodified, this ability\ndegrades. Turning to natural language, our experiments with a specific\nphenomenon -- referential opacity -- add to the growing body of evidence that\ncurrent language models do not well-represent natural language semantics. We\nshow this failure relates to the context-dependent nature of natural language\nform-meaning mappings.",
    "descriptor": "",
    "authors": [
      "Zhaofeng Wu",
      "William Merrill",
      "Hao Peng",
      "Iz Beltagy",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07468"
  },
  {
    "id": "arXiv:2210.07469",
    "title": "StyLEx: Explaining Styles with Lexicon-Based Human Perception",
    "abstract": "Style plays a significant role in how humans express themselves and\ncommunicate with others. Large pre-trained language models produce impressive\nresults on various style classification tasks. However, they often learn\nspurious domain-specific words to make predictions. This incorrect word\nimportance learned by the model often leads to ambiguous token-level\nexplanations which do not align with human perception of linguistic styles. To\ntackle this challenge, we introduce StyLEx, a model that learns annotated human\nperceptions of stylistic lexica and uses these stylistic words as additional\ninformation for predicting the style of a sentence. Our experiments show that\nStyLEx can provide human-like stylistic lexical explanations without\nsacrificing the performance of sentence-level style prediction on both original\nand out-of-domain datasets. Explanations from StyLEx show higher sufficiency,\nand plausibility when compared to human annotations, and are also more\nunderstandable by human judges compared to the existing widely-used saliency\nbaseline.",
    "descriptor": "",
    "authors": [
      "Shirley Anugrah Hayati",
      "Kyumin Park",
      "Dheeraj Rajagopal",
      "Lyle Ungar",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07469"
  },
  {
    "id": "arXiv:2210.07471",
    "title": "\"John is 50 years old, can his son be 65?\" Evaluating NLP Models'  Understanding of Feasibility",
    "abstract": "In current NLP research, large-scale language models and their abilities are\nwidely being discussed. Some recent works have also found notable failures of\nthese models. Often these failure examples involve complex reasoning abilities.\nThis work focuses on a simple commonsense ability, reasoning about when an\naction (or its effect) is feasible. We introduce FeasibilityQA, a\nquestion-answering dataset involving binary classification (BCQ) and\nmulti-choice multi-correct questions (MCQ) that test understanding of\nfeasibility. We show that even state-of-the-art models such as GPT-3 struggle\nto answer the feasibility questions correctly. Specifically, on (MCQ, BCQ)\nquestions, GPT-3 achieves accuracy of just (19%, 62%) and (25%, 64%) in\nzero-shot and few-shot settings, respectively. We also evaluate models by\nproviding relevant knowledge statements required to answer the question and\nfind that the additional knowledge leads to a 7% gain in performance, but the\noverall performance still remains low. These results make one wonder how much\ncommonsense knowledge about action feasibility is encoded in GPT-3 and how well\nthe model can reason about it.",
    "descriptor": "\nComments: 4 pages + 5 pages in Appendix\n",
    "authors": [
      "Himanshu Gupta",
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Kuntal Kumar Pal",
      "Saurabh Arjun Sawant",
      "Kevin Scaria",
      "Siddharth Goyal",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07471"
  },
  {
    "id": "arXiv:2210.07472",
    "title": "Robust Candidate Generation for Entity Linking on Short Social Media  Texts",
    "abstract": "Entity Linking (EL) is the gateway into Knowledge Bases. Recent advances in\nEL utilize dense retrieval approaches for Candidate Generation, which addresses\nsome of the shortcomings of the Lookup based approach of matching NER mentions\nagainst pre-computed dictionaries. In this work, we show that in the domain of\nTweets, such methods suffer as users often include informal spelling, limited\ncontext, and lack of specificity, among other issues. We investigate these\nchallenges on a large and recent Tweets benchmark for EL, empirically evaluate\nlookup and dense retrieval approaches, and demonstrate a hybrid solution using\nlong contextual representation from Wikipedia is necessary to achieve\nconsiderable gains over previous work, achieving 0.93 recall.",
    "descriptor": "\nComments: 7 pages, 2 figures. Accepted to Proceedings of the Eighth Workshop on Noisy User-generated Text (W-NUT 2022). URL: this https URL\n",
    "authors": [
      "Liam Hebert",
      "Raheleh Makki",
      "Shubhanshu Mishra",
      "Hamidreza Saghir",
      "Anusha Kamath",
      "Yuval Merhav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07472"
  },
  {
    "id": "arXiv:2210.07474",
    "title": "SQA3D: Situated Question Answering in 3D Scenes",
    "abstract": "We propose a new task to benchmark scene understanding of embodied agents:\nSituated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g.,\n3D scan), SQA3D requires the tested agent to first understand its situation\n(position, orientation, etc.) in the 3D scene as described by text, then reason\nabout its surrounding environment and answer a question under that situation.\nBased upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k\nunique situations, along with 20.4k descriptions and 33.4k diverse reasoning\nquestions for these situations. These questions examine a wide spectrum of\nreasoning capabilities for an intelligent agent, ranging from spatial relation\ncomprehension to commonsense understanding, navigation, and multi-hop\nreasoning. SQA3D imposes a significant challenge to current multi-modal\nespecially 3D reasoning models. We evaluate various state-of-the-art approaches\nand find that the best one only achieves an overall score of 47.20%, while\namateur human participants can reach 90.06%. We believe SQA3D could facilitate\nfuture embodied AI research with stronger situation understanding and reasoning\ncapability.",
    "descriptor": "",
    "authors": [
      "Xiaojian Ma",
      "Silong Yong",
      "Zilong Zheng",
      "Qing Li",
      "Yitao Liang",
      "Song-Chun Zhu",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07474"
  },
  {
    "id": "arXiv:2210.07475",
    "title": "Latent Temporal Flows for Multivariate Analysis of Wearables Data",
    "abstract": "Increased use of sensor signals from wearable devices as rich sources of\nphysiological data has sparked growing interest in developing health monitoring\nsystems to identify changes in an individual's health profile. Indeed, machine\nlearning models for sensor signals have enabled a diverse range of healthcare\nrelated applications including early detection of abnormalities, fertility\ntracking, and adverse drug effect prediction. However, these models can fail to\naccount for the dependent high-dimensional nature of the underlying sensor\nsignals. In this paper, we introduce Latent Temporal Flows, a method for\nmultivariate time-series modeling tailored to this setting. We assume that a\nset of sequences is generated from a multivariate probabilistic model of an\nunobserved time-varying low-dimensional latent vector. Latent Temporal Flows\nsimultaneously recovers a transformation of the observed sequences into\nlower-dimensional latent representations via deep autoencoder mappings, and\nestimates a temporally-conditioned probabilistic model via normalizing flows.\nUsing data from the Apple Heart and Movement Study (AH&MS), we illustrate\npromising forecasting performance on these challenging signals. Additionally,\nby analyzing two and three dimensional representations learned by our model, we\nshow that we can identify participants' $\\text{VO}_2\\text{max}$, a main\nindicator and summary of cardio-respiratory fitness, using only lower-level\nsignals. Finally, we show that the proposed method consistently outperforms the\nstate-of-the-art in multi-step forecasting benchmarks (achieving at least a\n$10\\%$ performance improvement) on several real-world datasets, while enjoying\nincreased computational efficiency.",
    "descriptor": "",
    "authors": [
      "Magda Amiridi",
      "Gregory Darnell",
      "Sean Jewell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.07475"
  },
  {
    "id": "arXiv:2210.07476",
    "title": "An interpretation of TRiSK-type schemes from a discrete exterior  calculus perspective",
    "abstract": "TRiSK-type numerical schemes are widely used in both atmospheric and oceanic\ndynamical cores, due to their discrete analogues of important properties such\nas energy conservation and steady geostrophic modes. In this work, we show that\nthese numerical methods are best understood as a discrete exterior calculus\n(DEC) scheme applied to a Hamiltonian formulation of the rotating shallow water\nequations based on split exterior calculus. This comprehensive description of\nthe differential geometric underpinnings of TRiSK-type schemes completes the\none started in \\cite{Thuburn2012,Eldred2017}, and provides a new understanding\nof certain operators in TRiSK-type schemes as discrete wedge products and\ntopological pairings from split exterior calculus. All known TRiSK-type schemes\nin the literature are shown to fit inside this general framework, by\nidentifying the (implicit) choices made for various DEC operators by the\ndifferent schemes. In doing so, unexplored choices and combinations are\nidentified that might offer the possibility of fixing known issues with\nTRiSK-type schemes such as operator accuracy and Hollingsworth instability.",
    "descriptor": "\nComments: 40 pages, 3 figures\n",
    "authors": [
      "Christopher Eldred",
      "Werner Bauer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07476"
  },
  {
    "id": "arXiv:2210.07480",
    "title": "Real-time computational powered landing guidance using convex  optimization and neural networks",
    "abstract": "Computational guidance is an emerging and accelerating trend in aerospace\nguidance and control. Combining machine learning and convex optimization, this\npaper presents a real-time computational guidance method for the\n6-degrees-of-freedom powered landing guidance problem. The powered landing\nguidance problem is formulated as an optimal control problem, which is then\ntransformed into a convex optimization problem. Instead of brutally using the\nneural networks as the controller, we use neural networks to improve the\nstate-of-the-art sequential convex programming (SCP) algorithm. Based on the\ndeep neural network, an initial trajectory generator is designed to provide a\nsatisfactory initial guess for the SCP algorithm. Benefitting from designing\nthe initial trajectory generator as a sequence model predictor, the proposed\ndata-driven SCP architecture is capable of improving the performance of any\nstate-of-the-art SCP algorithm in various applications, not just powered\nlanding guidance. The simulation results show that the proposed method can\nprecisely guide the vehicle to the landing site. Moreover, through Monte Carlo\ntests, the proposed method can averagely save 40.8% of the computation time\ncompared with the SCP method, while ensuring higher terminal states accuracy.\nThe proposed computational guidance scheme is suitable for real-time\napplications.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Zhipeng Shen",
      "Shiyu Zhou",
      "Jianglong Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07480"
  },
  {
    "id": "arXiv:2210.07481",
    "title": "InFIP: An Explainable DNN Intellectual Property Protection Method based  on Intrinsic Features",
    "abstract": "Intellectual property (IP) protection for Deep Neural Networks (DNNs) has\nraised serious concerns in recent years. Most existing works embed watermarks\nin the DNN model for IP protection, which need to modify the model and lack of\ninterpretability. In this paper, for the first time, we propose an\ninterpretable intellectual property protection method for DNN based on\nexplainable artificial intelligence. Compared with existing works, the proposed\nmethod does not modify the DNN model, and the decision of the ownership\nverification is interpretable. We extract the intrinsic features of the DNN\nmodel by using Deep Taylor Decomposition. Since the intrinsic feature is\ncomposed of unique interpretation of the model's decision, the intrinsic\nfeature can be regarded as fingerprint of the model. If the fingerprint of a\nsuspected model is the same as the original model, the suspected model is\nconsidered as a pirated model. Experimental results demonstrate that the\nfingerprints can be successfully used to verify the ownership of the model and\nthe test accuracy of the model is not affected. Furthermore, the proposed\nmethod is robust to fine-tuning attack, pruning attack, watermark overwriting\nattack, and adaptive attack.",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Xin Wang",
      "Yinghao Wu",
      "Shifeng Ni",
      "Yushu Zhang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07481"
  },
  {
    "id": "arXiv:2210.07482",
    "title": "Cargo Ecosystem Dependency-Vulnerability Knowledge Graph Construction  and Vulnerability Propagation Study",
    "abstract": "Currently, little is known about the structure of the Cargo ecosystem and the\npotential for vulnerability propagation. Many empirical studies generalize\nthird-party dependency governance strategies from a single software ecosystem\nto other ecosystems but ignore the differences in the technical structures of\ndifferent software ecosystems, making it difficult to directly generalize\nsecurity governance strategies from other ecosystems to the Cargo ecosystem. To\nfill the gap in this area, this paper constructs a knowledge graph of\ndependency vulnerabilities for the Cargo ecosystem using techniques related to\nknowledge graphs to address this challenge. This paper is the first large-scale\nempirical study in a related research area to address vulnerability propagation\nin the Cargo ecosystem. This paper proposes a dependency-vulnerability\nknowledge graph parsing algorithm to determine the vulnerability propagation\npath and propagation range and empirically studies the characteristics of\nvulnerabilities in the Cargo ecosystem, the propagation range, and the factors\nthat cause vulnerability propagation. Our research has found that the Cargo\necosystem's security vulnerabilities are primarily memory-related. 18% of the\nlibraries affected by the vulnerability is still affected by the vulnerability\nin the latest version of the library. The number of versions affected by the\npropagation of the vulnerabilities is 19.78% in the entire Cargo ecosystem.\nThis paper looks at the characteristics and propagation factors triggering\nvulnerabilities in the Cargo ecosystem. It provides some practical resolution\nstrategies for administrators of the Cargo community, developers who use Cargo\nto manage third-party libraries, and library owners. This paper provides new\nideas for improving the overall security of the Cargo ecosystem.",
    "descriptor": "",
    "authors": [
      "Peiyang Jia",
      "Chengwei Liu",
      "Hongyu Sun",
      "Chengyi Sun",
      "Mianxue Gu",
      "Yang Liu",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.07482"
  },
  {
    "id": "arXiv:2210.07484",
    "title": "Mutual Information Regularized Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) aims at learning an effective policy from\noffline datasets without active interactions with the environment. The major\nchallenge of offline RL is the distribution shift that appears when\nout-of-distribution actions are queried, which makes the policy improvement\ndirection biased by extrapolation errors. Most existing methods address this\nproblem by penalizing the policy for deviating from the behavior policy during\npolicy improvement or making conservative updates for value functions during\npolicy evaluation. In this work, we propose a novel MISA framework to approach\noffline RL from the perspective of Mutual Information between States and\nActions in the dataset by directly constraining the policy improvement\ndirection. Intuitively, mutual information measures the mutual dependence of\nactions and states, which reflects how a behavior agent reacts to certain\nenvironment states during data collection. To effectively utilize this\ninformation to facilitate policy learning, MISA constructs lower bounds of\nmutual information parameterized by the policy and Q-values. We show that\noptimizing this lower bound is equivalent to maximizing the likelihood of a\none-step improved policy on the offline dataset. In this way, we constrain the\npolicy improvement direction to lie in the data manifold. The resulting\nalgorithm simultaneously augments the policy evaluation and improvement by\nadding a mutual information regularization. MISA is a general offline RL\nframework that unifies conservative Q-learning (CQL) and behavior\nregularization methods (e.g., TD3+BC) as special cases. Our experiments show\nthat MISA performs significantly better than existing methods and achieves new\nstate-of-the-art on various tasks of the D4RL benchmark.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Xiao Ma",
      "Bingyi Kang",
      "Zhongwen Xu",
      "Min Lin",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07484"
  },
  {
    "id": "arXiv:2210.07485",
    "title": "Holistic Sentence Embeddings for Better Out-of-Distribution Detection",
    "abstract": "Detecting out-of-distribution (OOD) instances is significant for the safe\ndeployment of NLP models. Among recent textual OOD detection works based on\npretrained language models (PLMs), distance-based methods have shown superior\nperformance. However, they estimate sample distance scores in the last-layer\nCLS embedding space and thus do not make full use of linguistic information\nunderlying in PLMs. To address the issue, we propose to boost OOD detection by\nderiving more holistic sentence embeddings. On the basis of the observations\nthat token averaging and layer combination contribute to improving OOD\ndetection, we propose a simple embedding approach named Avg-Avg, which averages\nall token representations from each intermediate layer as the sentence\nembedding and significantly surpasses the state-of-the-art on a comprehensive\nsuite of benchmarks by a 9.33% FAR95 margin. Furthermore, our analysis\ndemonstrates that it indeed helps preserve general linguistic knowledge in\nfine-tuned PLMs and substantially benefits detecting background shifts. The\nsimple yet effective embedding method can be applied to fine-tuned PLMs with\nnegligible extra costs, providing a free gain in OOD detection. Our code is\navailable at https://github.com/lancopku/Avg-Avg.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Sishuo Chen",
      "Xiaohan Bi",
      "Rundong Gao",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07485"
  },
  {
    "id": "arXiv:2210.07486",
    "title": "AFETM: Adaptive function execution trace monitoring for fault diagnosis",
    "abstract": "The high tracking overhead, the amount of up-front effort required to\nselecting the trace points, and the lack of effective data analysis model are\nthe significant barriers to the adoption of intra-component tracking for fault\ndiagnosis today. This paper introduces a novel method for fault diagnosis by\ncombining adaptive function level dynamic tracking, target fault injection, and\ngraph convolutional network. In order to implement this method, we introduce\ntechniques for (i) selecting function level trace points, (ii) constructing\napproximate function call tree of program when using adaptive tracking, and\n(iii) constructing graph convolutional network with fault injection campaign.\nWe evaluate our method using a web service benchmark composed of Redis, Nginx,\nHttpd, and SQlite. The experimental results show that this method outperforms\nlog based method, full tracking method, and Gaussian influence method in the\naccuracy of fault diagnosis, overhead, and performance impact on the diagnosis\ntarget.",
    "descriptor": "",
    "authors": [
      "Wei Zhang",
      "Yuxi Hu",
      "Bolong Tan",
      "Xiaohai Shi",
      "Jianhui Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.07486"
  },
  {
    "id": "arXiv:2210.07487",
    "title": "A Scalable Finite Difference Method for Deep Reinforcement Learning",
    "abstract": "Several low-bandwidth distributable black-box optimization algorithms have\nrecently been shown to perform nearly as well as more refined modern methods in\nsome Deep Reinforcement Learning domains. In this work we investigate a core\nproblem with the use of distributed workers in such systems. Further, we\ninvestigate the dramatic differences in performance between the popular Adam\ngradient descent algorithm and the simplest form of stochastic gradient\ndescent. These investigations produce a stable, low-bandwidth learning\nalgorithm that achieves 100\\% usage of all connected CPUs under typical\nconditions.",
    "descriptor": "",
    "authors": [
      "Matthew Allen",
      "John Raisbeck",
      "Hakho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07487"
  },
  {
    "id": "arXiv:2210.07488",
    "title": "MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous  Information Networks",
    "abstract": "Heterogeneous Information Network (HIN) is essential to study complicated\nnetworks containing multiple edge types and node types. Meta-path, a sequence\nof node types and edge types, is the core technique to embed HINs. Since\nmanually curating meta-paths is time-consuming, there is a pressing need to\ndevelop automated meta-path generation approaches. Existing meta-path\ngeneration approaches cannot fully exploit the rich textual information in\nHINs, such as node names and edge type names. To address this problem, we\npropose MetaFill, a text-infilling-based approach for meta-path generation. The\nkey idea of MetaFill is to formulate meta-path identification problem as a word\nsequence infilling problem, which can be advanced by Pretrained Language Models\n(PLMs). We observed the superior performance of MetaFill against existing\nmeta-path generation methods and graph embedding methods that do not leverage\nmeta-paths in both link prediction and node classification on two real-world\nHIN datasets. We further demonstrated how MetaFill can accurately classify\nedges in the zero-shot setting, where existing approaches cannot generate any\nmeta-paths. MetaFill exploits PLMs to generate meta-paths for graph embedding,\nopening up new avenues for language model applications in graph analysis.",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2022\n",
    "authors": [
      "Zequn Liu",
      "Kefei Duan",
      "Junwei Yang",
      "Hanwen Xu",
      "Ming Zhang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07488"
  },
  {
    "id": "arXiv:2210.07489",
    "title": "The Surprisingly Straightforward Scene Text Removal Method With Gated  Attention and Region of Interest Generation: A Comprehensive Prominent Model  Analysis",
    "abstract": "Scene text removal (STR), a task of erasing text from natural scene images,\nhas recently attracted attention as an important component of editing text or\nconcealing private information such as ID, telephone, and license plate\nnumbers. While there are a variety of different methods for STR actively being\nresearched, it is difficult to evaluate superiority because previously proposed\nmethods do not use the same standardized training/evaluation dataset. We use\nthe same standardized training/testing dataset to evaluate the performance of\nseveral previous methods after standardized re-implementation. We also\nintroduce a simple yet extremely effective Gated Attention (GA) and\nRegion-of-Interest Generation (RoIG) methodology in this paper. GA uses\nattention to focus on the text stroke as well as the textures and colors of the\nsurrounding regions to remove text from the input image much more precisely.\nRoIG is applied to focus on only the region with text instead of the entire\nimage to train the model more efficiently. Experimental results on the\nbenchmark dataset show that our method significantly outperforms existing\nstate-of-the-art methods in almost all metrics with remarkably higher-quality\nresults. Furthermore, because our model does not generate a text stroke mask\nexplicitly, there is no need for additional refinement steps or sub-models,\nmaking our model extremely fast with fewer parameters. The dataset and code are\navailable at this https://github.com/naver/garnet.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Hyeonsu Lee",
      "Chankyu Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07489"
  },
  {
    "id": "arXiv:2210.07493",
    "title": "Psychology-guided Controllable Story Generation",
    "abstract": "Controllable story generation is a challenging task in the field of NLP,\nwhich has attracted increasing research interest in recent years. However, most\nexisting works generate a whole story conditioned on the appointed keywords or\nemotions, ignoring the psychological changes of the protagonist. Inspired by\npsychology theories, we introduce global psychological state chains, which\ninclude the needs and emotions of the protagonists, to help a story generation\nsystem create more controllable and well-planned stories. In this paper, we\npropose a Psychology-guIded Controllable Story Generation System (PICS) to\ngenerate stories that adhere to the given leading context and desired\npsychological state chains for the protagonist. Specifically, psychological\nstate trackers are employed to memorize the protagonist's local psychological\nstates to capture their inner temporal relationships. In addition,\npsychological state planners are adopted to gain the protagonist's global\npsychological states for story planning. Eventually, a psychology controller is\ndesigned to integrate the local and global psychological states into the story\ncontext representation for composing psychology-guided stories. Automatic and\nmanual evaluations demonstrate that PICS outperforms baselines, and each part\nof PICS shows effectiveness for writing stories with more consistent\npsychological changes.",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Yuqiang Xie",
      "Yue Hu",
      "Yunpeng Li",
      "Guanqun Bi",
      "Luxi Xing",
      "Wei Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07493"
  },
  {
    "id": "arXiv:2210.07494",
    "title": "A Comprehensive Study on Large-Scale Graph Training: Benchmarking and  Rethinking",
    "abstract": "Large-scale graph training is a notoriously challenging problem for graph\nneural networks (GNNs). Due to the nature of evolving graph structures into the\ntraining process, vanilla GNNs usually fail to scale up, limited by the GPU\nmemory space. Up to now, though numerous scalable GNN architectures have been\nproposed, we still lack a comprehensive survey and fair benchmark of this\nreservoir to find the rationale for designing scalable GNNs. To this end, we\nfirst systematically formulate the representative methods of large-scale graph\ntraining into several branches and further establish a fair and consistent\nbenchmark for them by a greedy hyperparameter searching. In addition, regarding\nefficiency, we theoretically evaluate the time and space complexity of various\nbranches and empirically compare them w.r.t GPU memory usage, throughput, and\nconvergence. Furthermore, We analyze the pros and cons for various branches of\nscalable GNNs and then present a new ensembling training manner, named EnGCN,\nto address the existing issues. Remarkably, our proposed method has achieved\nnew state-of-the-art (SOTA) performance on large-scale datasets. Our code is\navailable at https://github.com/VITA-Group/Large_Scale_GCN_Benchmarking.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Dataset and Benchmark Track\n",
    "authors": [
      "Keyu Duan",
      "Zirui Liu",
      "Peihao Wang",
      "Wenqing Zheng",
      "Kaixiong Zhou",
      "Tianlong Chen",
      "Xia Hu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07494"
  },
  {
    "id": "arXiv:2210.07497",
    "title": "Distributed Emergency Frequency Control Considering Transient Stability  Constraints in Multi-Infeed Hybrid AC-DC System",
    "abstract": "Due to possible emergency faults and frequency regulation reserve shortage in\nthe multi-infeed hybrid AC-DC (MIDC) system, the emergency frequency control\n(EFC) with LCC-HVDC systems participating is important for system frequency\nstability. Nevertheless, the existing decentralized EFC strategies cannot\nguarantee the transient stability constraints of lines and cannot meet the\nfrequency restoration requirement. To fill this gap, this paper proposes a\ncomplementary distributed EFC strategy. By selecting the semi-distributed or\nfully-distributed control law according to the state of AC system control\ncenter, the proposed distributed EFC can improve the control performance with a\nnormal control center and enhance the control reliability in case of control\ncenter failure. Then, to derive the semi-distributed and fully-distributed\ncontrol laws, a general design method is proposed by formulating an optimal EFC\nproblem. Both of these two control laws can guarantee transient stability\nconstraints, restore system frequency and achieve the defined optimal control\nobjective. Moreover, the optimality of the closed-loop equilibrium is proven,\nand a Lyapunov analysis shows the asymptotic stability of the closed-loop\nsystem with the discontinuous control dynamics. A case study verifies the\neffectiveness of the proposed distributed EFC strategy.",
    "descriptor": "",
    "authors": [
      "Ye Liu",
      "Chen Shen",
      "Zhaojian Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07497"
  },
  {
    "id": "arXiv:2210.07499",
    "title": "Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks",
    "abstract": "Sequence-to-Sequence (seq2seq) tasks transcribe the input sequence to a\ntarget sequence. The Connectionist Temporal Classification (CTC) criterion is\nwidely used in multiple seq2seq tasks. Besides predicting the target sequence,\na side product of CTC is to predict the alignment, which is the most probable\ninput-long sequence that specifies a hard aligning relationship between the\ninput and target units. As there are multiple potential aligning sequences\n(called paths) that are equally considered in CTC formulation, the choice of\nwhich path will be most probable and become the predicted alignment is always\nuncertain. In addition, it is usually observed that the alignment predicted by\nvanilla CTC will drift compared with its reference and rarely provides\npractical functionalities. Thus, the motivation of this work is to make the CTC\nalignment prediction controllable and thus equip CTC with extra\nfunctionalities. The Bayes risk CTC (BRCTC) criterion is then proposed in this\nwork, in which a customizable Bayes risk function is adopted to enforce the\ndesired characteristics of the predicted alignment. With the risk function, the\nBRCTC is a general framework to adopt some customizable preference over the\npaths in order to concentrate the posterior into a particular subset of the\npaths. In applications, we explore one particular preference which yields\nmodels with the down-sampling ability and reduced inference costs. By using\nBRCTC with another preference for early emissions, we obtain an improved\nperformance-latency trade-off for online models. Experimentally, the proposed\nBRCTC reduces the inference cost of offline models by up to 47% without\nperformance degradation and cuts down the overall latency of online systems to\nan unseen level.",
    "descriptor": "",
    "authors": [
      "Jinchuan Tian",
      "Brian Yan",
      "Jianwei Yu",
      "Chao Weng",
      "Dong Yu",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07499"
  },
  {
    "id": "arXiv:2210.07500",
    "title": "ToupleGDD: A Fine-Designed Solution of Influence Maximization by Deep  Reinforcement Learning",
    "abstract": "Online social platforms have become more and more popular, and the\ndissemination of information on social networks has attracted wide attention of\nthe industries and academia. Aiming at selecting a small subset of nodes with\nmaximum influence on networks, the Influence Maximization (IM) problem has been\nextensively studied. Since it is #P-hard to compute the influence spread given\na seed set, the state-of-art methods, including heuristic and approximation\nalgorithms, faced with great difficulties such as theoretical guarantee, time\nefficiency, generalization, etc. This makes it unable to adapt to large-scale\nnetworks and more complex applications. With the latest achievements of Deep\nReinforcement Learning (DRL) in artificial intelligence and other fields, a lot\nof works has focused on exploiting DRL to solve the combinatorial optimization\nproblems. Inspired by this, we propose a novel end-to-end DRL framework,\nToupleGDD, to address the IM problem in this paper, which incorporates three\ncoupled graph neural networks for network embedding and double deep Q-networks\nfor parameters learning. Previous efforts to solve the IM problem with DRL\ntrained their models on the subgraph of the whole network, and then tested\ntheir performance on the whole graph, which makes the performance of their\nmodels unstable among different networks. However, our model is trained on\nseveral small randomly generated graphs and tested on completely different\nnetworks, and can obtain results that are very close to the state-of-the-art\nmethods. In addition, our model is trained with a small budget, and it can\nperform well under various large budgets in the test, showing strong\ngeneralization ability. Finally, we conduct entensive experiments on synthetic\nand realistic datasets, and the experimental results prove the effectiveness\nand superiority of our model.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Tiantian Chen",
      "Siwen Yan",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07500"
  },
  {
    "id": "arXiv:2210.07502",
    "title": "Liquid Welfare guarantees for No-Regret Learning in Sequential Budgeted  Auctions",
    "abstract": "We study the liquid welfare in repeated first-price auctions with budget\nlimited buyers. We use a behavioral model for the buyers, assuming a learning\nstyle guarantee on the utility each achieves. We focus on first-price auctions,\nwhich are increasingly commonly used in many settings, and consider liquid\nwelfare, a natural and well-studied generalization of social welfare for the\ncase of budget-constrained buyers. We show a $\\gamma+O(\\sqrt{\\gamma})$ price of\nanarchy for liquid welfare assuming buyers have additive valuations and the\nutility of each buyer is within a $\\gamma$ factor of the utility achievable by\nshading her value with the same factor each iteration. This positive result is\nin stark contrast to repeated second-price auctions, where even with\n$\\gamma=1$, the resulting liquid welfare can be arbitrarily smaller than the\noptimal one. We prove a lower bound of $\\gamma$ on the liquid welfare loss\nunder the above assumption, making our bound asymptotically tight. For the case\nwhen $\\gamma = 1$ our theorem proves a price of anarchy upper bound that is\nabout $3.18$; we prove a lower bound of $2$ for that case.\nWe also offer a learning algorithm that achieves utility of at least a\n$\\gamma = O(\\log T)$ fraction of the optimal utility even when a buyer's values\nand the bids of the other buyers are chosen adversarially, offering a possible\nalgorithm they can use to achieve the guarantee needed for our liquid welfare\nresult.\nFinally, we extend our liquid welfare results for the case where buyers have\nsubmodular valuations with a slightly worse constant in the big $O(.)$ of the\nguarantee for the linear case.",
    "descriptor": "",
    "authors": [
      "Giannis Fikioris",
      "\u00c9va Tardos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07502"
  },
  {
    "id": "arXiv:2210.07503",
    "title": "STAR-Transformer: A Spatio-temporal Cross Attention Transformer for  Human Action Recognition",
    "abstract": "In action recognition, although the combination of spatio-temporal videos and\nskeleton features can improve the recognition performance, a separate model and\nbalancing feature representation for cross-modal data are required. To solve\nthese problems, we propose Spatio-TemporAl cRoss (STAR)-transformer, which can\neffectively represent two cross-modal features as a recognizable vector. First,\nfrom the input video and skeleton sequence, video frames are output as global\ngrid tokens and skeletons are output as joint map tokens, respectively. These\ntokens are then aggregated into multi-class tokens and input into\nSTAR-transformer. The STAR-transformer encoder layer consists of a full\nself-attention (FAttn) module and a proposed zigzag spatio-temporal attention\n(ZAttn) module. Similarly, the continuous decoder consists of a FAttn module\nand a proposed binary spatio-temporal attention (BAttn) module.\nSTAR-transformer learns an efficient multi-feature representation of the\nspatio-temporal features by properly arranging pairings of the FAttn, ZAttn,\nand BAttn modules. Experimental results on the Penn-Action, NTU RGB+D 60, and\n120 datasets show that the proposed method achieves a promising improvement in\nperformance in comparison to previous state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by WACV 2023\n",
    "authors": [
      "Dasom Ahn",
      "Sangwon Kim",
      "Hyunsu Hong",
      "Byoung Chul Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07503"
  },
  {
    "id": "arXiv:2210.07505",
    "title": "Learning Active Camera for Multi-Object Navigation",
    "abstract": "Getting robots to navigate to multiple objects autonomously is essential yet\ndifficult in robot applications. One of the key challenges is how to explore\nenvironments efficiently with camera sensors only. Existing navigation methods\nmainly focus on fixed cameras and few attempts have been made to navigate with\nactive cameras. As a result, the agent may take a very long time to perceive\nthe environment due to limited camera scope. In contrast, humans typically gain\na larger field of view by looking around for a better perception of the\nenvironment. How to make robots perceive the environment as efficiently as\nhumans is a fundamental problem in robotics. In this paper, we consider\nnavigating to multiple objects more efficiently with active cameras.\nSpecifically, we cast moving camera to a Markov Decision Process and\nreformulate the active camera problem as a reinforcement learning problem.\nHowever, we have to address two new challenges: 1) how to learn a good camera\npolicy in complex environments and 2) how to coordinate it with the navigation\npolicy. To address these, we carefully design a reward function to encourage\nthe agent to explore more areas by moving camera actively. Moreover, we exploit\nhuman experience to infer a rule-based camera action to guide the learning\nprocess. Last, to better coordinate two kinds of policies, the camera policy\ntakes navigation actions into account when making camera moving decisions.\nExperimental results show our camera policy consistently improves the\nperformance of multi-object navigation over four baselines on two datasets.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Peihao Chen",
      "Dongyu Ji",
      "Kunyang Lin",
      "Weiwen Hu",
      "Wenbing Huang",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07505"
  },
  {
    "id": "arXiv:2210.07506",
    "title": "Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language  Navigation",
    "abstract": "We address a practical yet challenging problem of training robot agents to\nnavigate in an environment following a path described by some language\ninstructions. The instructions often contain descriptions of objects in the\nenvironment. To achieve accurate and efficient navigation, it is critical to\nbuild a map that accurately represents both spatial location and the semantic\ninformation of the environment objects. However, enabling a robot to build a\nmap that well represents the environment is extremely challenging as the\nenvironment often involves diverse objects with various attributes. In this\npaper, we propose a multi-granularity map, which contains both object\nfine-grained details (e.g., color, texture) and semantic classes, to represent\nobjects more comprehensively. Moreover, we propose a weakly-supervised\nauxiliary task, which requires the agent to localize instruction-relevant\nobjects on the map. Through this task, the agent not only learns to localize\nthe instruction-relevant objects for navigation but also is encouraged to learn\na better map representation that reveals object information. We then feed the\nlearned map and instruction to a waypoint predictor to determine the next\nnavigation goal. Experimental results show our method outperforms the\nstate-of-the-art by 4.0% and 4.6% w.r.t. success rate both in seen and unseen\nenvironments, respectively on VLN-CE dataset. Code is available at\nhttps://github.com/PeihaoChen/WS-MGMap.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Peihao Chen",
      "Dongyu Ji",
      "Kunyang Lin",
      "Runhao Zeng",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07506"
  },
  {
    "id": "arXiv:2210.07508",
    "title": "Hierarchical Diffusion Models for Singing Voice Neural Vocoder",
    "abstract": "Recent progress in deep generative models has improved the quality of neural\nvocoders in speech domain. However, it remains challenging to generate\nhigh-quality singing voice due to a wider variety of musical expressions in\npitch, loudness, and pronunciations. In this work, we propose a hierarchical\ndiffusion model for singing voice neural vocoders. The proposed method consists\nof multiple diffusion models operating in different sampling rates; the model\nat the lowest sampling rate focuses on generating accurate low frequency\ncomponents such as pitch, and other models progressively generate the waveform\nat the higher sampling rates based on the data at the lower sampling rate and\nacoustic features. Experimental results show that the proposed method produces\nhigh-quality singing voice for multiple singers, outperforming state-of-the-art\nneural vocoders with a similar range of computational costs.",
    "descriptor": "",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar",
      "Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07508"
  },
  {
    "id": "arXiv:2210.07509",
    "title": "Boosting Performance of a Baseline Visual Place Recognition Technique by  Predicting the Maximally Complementary Technique",
    "abstract": "One recent promising approach to the Visual Place Recognition (VPR) problem\nhas been to fuse the place recognition estimates of multiple complementary VPR\ntechniques using methods such as SRAL and multi-process fusion. These\napproaches come with a substantial practical limitation: they require all\npotential VPR methods to be brute-force run before they are selectively fused.\nThe obvious solution to this limitation is to predict the viable subset of\nmethods ahead of time, but this is challenging because it requires a predictive\nsignal within the imagery itself that is indicative of high performance\nmethods. Here we propose an alternative approach that instead starts with a\nknown single base VPR technique, and learns to predict the most complementary\nadditional VPR technique to fuse with it, that results in the largest\nimprovement in performance. The key innovation here is to use a dimensionally\nreduced difference vector between the query image and the top-retrieved\nreference image using this baseline technique as the predictive signal of the\nmost complementary additional technique, both during training and inference. We\ndemonstrate that our approach can train a single network to select performant,\ncomplementary technique pairs across datasets which span multiple modes of\ntransportation (train, car, walking) as well as to generalise to unseen\ndatasets, outperforming multiple baseline strategies for manually selecting the\nbest technique pairs based on the same training data.",
    "descriptor": "\nComments: 7 pages, 5 figures. arXiv admin note: text overlap with arXiv:2112.04701\n",
    "authors": [
      "Connor Malone",
      "Stephen Hausler",
      "Tobias Fischer",
      "Michael Milford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07509"
  },
  {
    "id": "arXiv:2210.07514",
    "title": "Decentralized Coverage Path Planning with Reinforcement Learning and  Dual Guidance",
    "abstract": "Planning coverage path for multiple robots in a decentralized way enhances\nrobustness to coverage tasks handling uncertain malfunctions. To achieve high\nefficiency in a distributed manner for each single robot, a comprehensive\nunderstanding of both the complicated environments and cooperative agents\nintent is crucial. Unfortunately, existing works commonly consider only part of\nthese factors, resulting in imbalanced subareas or unnecessary overlaps. To\ntackle this issue, we introduce a Decentralized reinforcement learning\nframework with dual guidance to train each agent to solve the decentralized\nmultiple coverage path planning problem straightly through the environment\nstates. As distributed robots require others intentions to perform better\ncoverage efficiency, we utilize two guidance methods, artificial potential\nfields and heuristic guidance, to include and integrate others intentions into\nobservations for each robot. With our constructed framework, results have shown\nour agents successfully learn to determine their own subareas while achieving\nfull coverage, balanced subareas and low overlap rates. We then implement\nspanning tree cover within those subareas to construct actual routes for each\nrobot and complete given coverage tasks. Our performance is also compared with\nthe state of the art decentralized method showing at most 10 percent lower\noverlap rates while performing high efficiency in similar environments.",
    "descriptor": "",
    "authors": [
      "Yongkai Liu",
      "Jiawei Hu",
      "Wei Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07514"
  },
  {
    "id": "arXiv:2210.07518",
    "title": "Counterfactual Neural Temporal Point Process for Estimating Causal  Influence of Misinformation on Social Media",
    "abstract": "Recent years have witnessed the rise of misinformation campaigns that spread\nspecific narratives on social media to manipulate public opinions on different\nareas, such as politics and healthcare. Consequently, an effective and\nefficient automatic methodology to estimate the influence of the misinformation\non user beliefs and activities is needed. However, existing works on\nmisinformation impact estimation either rely on small-scale psychological\nexperiments or can only discover the correlation between user behaviour and\nmisinformation. To address these issues, in this paper, we build up a causal\nframework that model the causal effect of misinformation from the perspective\nof temporal point process. To adapt the large-scale data, we design an\nefficient yet precise way to estimate the Individual Treatment Effect(ITE) via\nneural temporal point process and gaussian mixture models. Extensive\nexperiments on synthetic dataset verify the effectiveness and efficiency of our\nmodel. We further apply our model on a real-world dataset of social media posts\nand engagements about COVID-19 vaccines. The experimental results indicate that\nour model recognized identifiable causal effect of misinformation that hurts\npeople's subjective emotions toward the vaccines.",
    "descriptor": "\nComments: 19 pages, 8 figures, already accepted by NeurIPS 2022\n",
    "authors": [
      "Yizhou Zhang",
      "Defu Cao",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07518"
  },
  {
    "id": "arXiv:2210.07519",
    "title": "Can Language Representation Models Think in Bets?",
    "abstract": "In recent years, transformer-based language representation models (LRMs) have\nachieved state-of-the-art results on difficult natural language understanding\nproblems, such as question answering and text summarization. As these models\nare integrated into real-world applications, evaluating their ability to make\nrational decisions is an important research agenda, with practical\nramifications. This article investigates LRMs' rational decision-making ability\nthrough a carefully designed set of decision-making benchmarks and experiments.\nInspired by classic work in cognitive science, we model the decision-making\nproblem as a bet. We then investigate an LRM's ability to choose outcomes that\nhave optimal, or at minimum, positive expected gain. Through a robust body of\nexperiments on four established LRMs, we show that a model is only able to\n`think in bets' if it is first fine-tuned on bet questions with an identical\nstructure. Modifying the bet question's structure, while still retaining its\nfundamental characteristics, decreases an LRM's performance by more than 25\\%,\non average, although absolute performance remains well above random. LRMs are\nalso found to be more rational when selecting outcomes with non-negative\nexpected gain, rather than optimal or strictly positive expected gain. Our\nresults suggest that LRMs could potentially be applied to tasks that rely on\ncognitive decision-making skills, but that more research is necessary before\nthey can robustly make rational decisions.",
    "descriptor": "",
    "authors": [
      "Zhisheng Tang",
      "Mayank Kejriwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07519"
  },
  {
    "id": "arXiv:2210.07522",
    "title": "Spatiotemporal Classification with limited labels using Constrained  Clustering for large datasets",
    "abstract": "Creating separable representations via representation learning and clustering\nis critical in analyzing large unstructured datasets with only a few labels.\nSeparable representations can lead to supervised models with better\nclassification capabilities and additionally aid in generating new labeled\nsamples. Most unsupervised and semisupervised methods to analyze large datasets\ndo not leverage the existing small amounts of labels to get better\nrepresentations. In this paper, we propose a spatiotemporal clustering paradigm\nthat uses spatial and temporal features combined with a constrained loss to\nproduce separable representations. We show the working of this method on the\nnewly published dataset ReaLSAT, a dataset of surface water dynamics for over\n680,000 lakes across the world, making it an essential dataset in terms of\necology and sustainability. Using this large unlabelled dataset, we first show\nhow a spatiotemporal representation is better compared to just spatial or\ntemporal representation. We then show how we can learn even better\nrepresentation using a constrained loss with few labels. We conclude by showing\nhow our method, using few labels, can pick out new labeled samples from the\nunlabeled data, which can be used to augment supervised methods leading to\nbetter classification.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Praveen Ravirathinam",
      "Rahul Ghosh",
      "Ke Wang",
      "Keyang Xuan",
      "Ankush Khandelwal",
      "Hilary Dugan",
      "Paul Hanson",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07522"
  },
  {
    "id": "arXiv:2210.07523",
    "title": "Self-Adaptive Named Entity Recognition by Retrieving Unstructured  Knowledge",
    "abstract": "Although named entity recognition (NER) helps us to extract various\ndomain-specific entities from text (e.g., artists in the music domain), it is\ncostly to create a large amount of training data or a structured knowledge base\nto perform accurate NER in the target domain. Here, we propose self-adaptive\nNER, where the model retrieves the external knowledge from unstructured text to\nlearn the usage of entities that has not been learned well. To retrieve useful\nknowledge for NER, we design an effective two-stage model that retrieves\nunstructured knowledge using uncertain entities as queries. Our model first\npredicts the entities in the input and then finds the entities of which the\nprediction is not confident. Then, our model retrieves knowledge by using these\nuncertain entities as queries and concatenates the retrieved text to the\noriginal input to revise the prediction. Experiments on CrossNER datasets\ndemonstrated that our model outperforms the strong NERBERT baseline by 2.45\npoints on average.",
    "descriptor": "",
    "authors": [
      "Kosuke Nishida",
      "Naoki Yoshinaga",
      "Kyosuke Nishida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07523"
  },
  {
    "id": "arXiv:2210.07530",
    "title": "Cut paths and their remainder structure, with applications",
    "abstract": "In a strongly connected graph $G = (V,E)$, a cut arc (also called strong\nbridge) is an arc $e \\in E$ whose removal makes the graph no longer strongly\nconnected. Equivalently, there exist $u,v \\in V$, such that all $u$-$v$ walks\ncontain $e$. Cut arcs are a fundamental graph-theoretic notion, with countless\napplications, especially in reachability problems.\nIn this paper we initiate the study of cut paths, as a generalisation of cut\narcs, which we naturally define as those paths $P$ for which there exist $u,v\n\\in V$, such that all $u$-$v$ walks contain $P$ as subwalk. We first prove\nvarious properties of cut paths and define their remainder structures, which we\nuse to present a simple $O(m)$-time verification algorithm for a cut path ($|V|\n= n$, $|E| = m$).\nSecondly, we apply cut paths and their remainder structures to improve\nseveral reachability problems from bioinformatics. A walk is called safe if it\nis a subwalk of every node-covering closed walk of a strongly connected graph.\nMulti-safety is defined analogously, by considering node-covering sets of\nclosed walks instead. We show that cut paths provide simple $O(m)$-time\nalgorithms verifying if a walk is safe or multi-safe. For multi-safety, we\npresent the first linear time algorithm, while for safety, we present a simple\nalgorithm where the state-of-the-art employed complex data structures. Finally\nwe show that the simultaneous computation of remainder structures of all\nsubwalks of a cut path can be performed in linear time. These properties yield\nan $O(mn)$ algorithm outputting all maximal multi-safe walks, improving over\nthe state-of-the-art algorithm running in time $O(m^2+n^3)$.\nThe results of this paper only scratch the surface in the study of cut paths,\nand we believe a rich structure of a graph can be revealed, considering the\nperspective of a path, instead of just an arc.",
    "descriptor": "",
    "authors": [
      "Massimo Cairo",
      "Shahbaz Khan",
      "Romeo Rizzi",
      "Sebastian Schmidt",
      "Alexandru I. Tomescu",
      "Elia C. Zirondelli"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.07530"
  },
  {
    "id": "arXiv:2210.07531",
    "title": "Let's Talk Through Physics! Covert Cyber-Physical Data Exfiltration on  Air-Gapped Edge Devices",
    "abstract": "Although organizations are continuously making concerted efforts to harden\ntheir systems against network attacks by air-gapping critical systems,\nattackers continuously adapt and uncover covert channels to exfiltrate data\nfrom air-gapped systems. For instance, attackers have demonstrated the\nfeasibility of exfiltrating data from a computer sitting in a Faraday cage by\nexfiltrating data using magnetic fields. Although a large body of work has\nrecently emerged highlighting various physical covert channels, these attacks\nhave mostly targeted open-loop cyber-physical systems where the covert channels\nexist on physical channels that are not being monitored by the victim. Network\narchitectures such as fog computing push sensitive data to cyber-physical edge\ndevices--whose physical side channels are typically monitored via state\nestimation. In this paper, we formalize covert data exfiltration that uses\nexisting cyber-physical models and infrastructure of individual devices to\nexfiltrate data in a stealthy manner, i.e., we propose a method to circumvent\ncyber-physical state estimation intrusion detection techniques while\nexfiltrating sensitive data from the network. We propose a generalized model\nfor encoding and decoding sensitive data within cyber-physical control loops.\nWe evaluate our approach on a distributed IoT network that includes computation\nnodes residing on physical drones as well as on an industrial control system\nfor the control of a robotic arm. Unlike prior works, we formalize the\nconstraints of covert cyber-physical channel exfiltration in the presence of a\ndefender performing state estimation.",
    "descriptor": "",
    "authors": [
      "Matthew Chan",
      "Nathaniel Snyder",
      "Marcus Lucas",
      "Luis Garcia",
      "Oleg Sokolsky",
      "James Weimer",
      "Insup Lee",
      "Paulo Tabuada",
      "Saman Zonouz",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07531"
  },
  {
    "id": "arXiv:2210.07532",
    "title": "Provable Subspace Identification Under Post-Nonlinear Mixtures",
    "abstract": "Unsupervised mixture learning (UML) aims at identifying linearly or\nnonlinearly mixed latent components in a blind manner. UML is known to be\nchallenging: Even learning linear mixtures requires highly nontrivial\nanalytical tools, e.g., independent component analysis or nonnegative matrix\nfactorization. In this work, the post-nonlinear (PNL) mixture model -- where\nunknown element-wise nonlinear functions are imposed onto a linear mixture --\nis revisited. The PNL model is widely employed in different fields ranging from\nbrain signal classification, speech separation, remote sensing, to causal\ndiscovery. To identify and remove the unknown nonlinear functions, existing\nworks often assume different properties on the latent components (e.g.,\nstatistical independence or probability-simplex structures).\nThis work shows that under a carefully designed UML criterion, the existence\nof a nontrivial null space associated with the underlying mixing system\nsuffices to guarantee identification/removal of the unknown nonlinearity.\nCompared to prior works, our finding largely relaxes the conditions of\nattaining PNL identifiability, and thus may benefit applications where no\nstrong structural information on the latent components is known. A\nfinite-sample analysis is offered to characterize the performance of the\nproposed approach under realistic settings. To implement the proposed learning\ncriterion, a block coordinate descent algorithm is proposed. A series of\nnumerical experiments corroborate our theoretical claims.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022, 21 pages, 2 figures\n",
    "authors": [
      "Qi Lyu",
      "Xiao Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07532"
  },
  {
    "id": "arXiv:2210.07533",
    "title": "GazeBaseVR, a large-scale, longitudinal, binocular eye-tracking dataset  collected in virtual reality",
    "abstract": "We present GazeBaseVR, a large-scale, longitudinal, binocular eye-tracking\n(ET) dataset collected at 250 Hz with an ET-enabled virtual-reality (VR)\nheadset. GazeBaseVR comprises 5,020 binocular recordings from a diverse\npopulation of 407 college-aged participants. Participants were recorded up to\nsix times each over a 26-month period, each time performing a series of five\ndifferent ET tasks: (1) a vergence task, (2) a horizontal smooth pursuit task,\n(3) a video-viewing task, (4) a self-paced reading task, and (5) a random\noblique saccade task. Many of these participants have also been recorded for\ntwo previously published datasets with different ET devices, and some\nparticipants were recorded before and after COVID-19 infection and recovery.\nGazeBaseVR is suitable for a wide range of research on ET data in VR devices,\nespecially eye movement biometrics due to its large population and longitudinal\nnature. In addition to ET data, additional participant details are provided to\nenable further research on topics such as fairness.",
    "descriptor": "\nComments: Data publicly available on figshare at this https URL\n",
    "authors": [
      "Dillon Lohr",
      "Samantha Aziz",
      "Lee Friedman",
      "Oleg V Komogortsev"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07533"
  },
  {
    "id": "arXiv:2210.07534",
    "title": "Time-Space Tradeoffs for Element Distinctness and Set Intersection via  Pseudorandomness",
    "abstract": "In the Element Distinctness problem, one is given an array $a_1,\\dots, a_n$\nof integers from $[poly(n)]$ and is tasked to decide if $\\{a_i\\}$ are mutually\ndistinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm\nfor this problem running in space $S(n)$ and time $T(n)$ where $T(n) \\le\n\\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random\naccess to polynomially many random bits). A recent breakthrough by Chen, Jin,\nWilliams and Wu (SODA 2022) showed how to remove the random oracle assumption\nin the regime $S(n) = polylog(n)$ and $T(n) = \\widetilde{O}(n^{3/2})$. They\ndesigned the first truly $polylog(n)$-space, $\\widetilde{O}(n^{3/2})$-time\nalgorithm by constructing a small family of hash functions $\\mathcal{H}\n\\subseteq \\{h | h:[poly(n)]\\to [n]\\}$ with a certain pseudorandom property.\nIn this paper, we give a significantly simplified analysis of the\npseudorandom hash family by Chen et al. Our analysis clearly identifies the key\npseudorandom property required to fool the BCM algorithm, allowing us to\nexplore the full potential of this construction. As our main result, we show a\ntime-space tradeoff for Element Distinctness without random oracle. Namely, for\nevery $S(n),T(n)$ such that $T\\approx \\widetilde{O}(n^{3/2}/S(n)^{1/2})$, our\nalgorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm\nalso works for a related problem Set Intersection, for which this tradeoff is\ntight due to a matching lower bound by Dinur (Eurocrypt 2020). As two\nadditional contributions, we show a more general pseudorandom property of the\nhash family, and slightly improve the seed length to sample the pseudorandom\nhash function.",
    "descriptor": "\nComments: To appear in SODA 2023. Abstract shortened to fit into the requirement of arXiv\n",
    "authors": [
      "Xin Lyu",
      "Weihao Zhu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.07534"
  },
  {
    "id": "arXiv:2210.07535",
    "title": "AutoMoE: Neural Architecture Search for Efficient Sparsely Activated  Transformers",
    "abstract": "Neural architecture search (NAS) has demonstrated promising results on\nidentifying efficient Transformer architectures which outperform manually\ndesigned ones for natural language tasks like neural machine translation (NMT).\nExisting NAS methods operate on a space of dense architectures, where all of\nthe sub-architecture weights are activated for every input. Motivated by the\nrecent advances in sparsely activated models like the Mixture-of-Experts (MoE)\nmodel, we introduce sparse architectures with conditional computation into the\nNAS search space. Given this expressive search space which subsumes prior\ndensely activated architectures, we develop a new framework AutoMoE to search\nfor efficient sparsely activated sub-Transformers. AutoMoE-generated sparse\nmodels obtain (i) 3x FLOPs reduction over manually designed dense Transformers\nand (ii) 23% FLOPs reduction over state-of-the-art NAS-generated dense\nsub-Transformers with parity in BLEU score on benchmark datasets for NMT.\nAutoMoE consists of three training phases: (a) Heterogeneous search space\ndesign with dense and sparsely activated Transformer modules (e.g., how many\nexperts? where to place them? what should be their sizes?); (b) SuperNet\ntraining that jointly trains several subnetworks sampled from the large search\nspace by weight-sharing; (c) Evolutionary search for the architecture with the\noptimal trade-off between task performance and computational constraint like\nFLOPs and latency. AutoMoE code, data and trained models are available at\nhttps://github.com/microsoft/AutoMoE.",
    "descriptor": "",
    "authors": [
      "Ganesh Jawahar",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Young Jin Kim",
      "Muhammad Abdul-Mageed",
      "Laks V. S. Lakshmanan",
      "Ahmed Hassan Awadallah",
      "Sebastien Bubeck",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07535"
  },
  {
    "id": "arXiv:2210.07536",
    "title": "A Reinforcement Learning Approach to Estimating Long-term Treatment  Effects",
    "abstract": "Randomized experiments (a.k.a. A/B tests) are a powerful tool for estimating\ntreatment effects, to inform decisions making in business, healthcare and other\napplications. In many problems, the treatment has a lasting effect that evolves\nover time. A limitation with randomized experiments is that they do not easily\nextend to measure long-term effects, since running long experiments is\ntime-consuming and expensive. In this paper, we take a reinforcement learning\n(RL) approach that estimates the average reward in a Markov process. Motivated\nby real-world scenarios where the observed state transition is nonstationary,\nwe develop a new algorithm for a class of nonstationary problems, and\ndemonstrate promising results in two synthetic datasets and one online store\ndataset.",
    "descriptor": "",
    "authors": [
      "Ziyang Tang",
      "Yiheng Duan",
      "Stephanie Zhang",
      "Lihong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07536"
  },
  {
    "id": "arXiv:2210.07538",
    "title": "The User-Aware Arabic Gender Rewriter",
    "abstract": "We introduce the User-Aware Arabic Gender Rewriter, a user-centric web-based\nsystem for Arabic gender rewriting in contexts involving two users. The system\ntakes either Arabic or English sentences as input, and provides users with the\nability to specify their desired first and/or second person target genders. The\nsystem outputs gender rewritten alternatives of the Arabic input sentences (or\ntheir Arabic translations in case of English input) to match the target users'\ngender preferences.",
    "descriptor": "",
    "authors": [
      "Bashar Alhafni",
      "Ossama Obeid",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07538"
  },
  {
    "id": "arXiv:2210.07539",
    "title": "Superpixel Perception Graph Neural Network for Intelligent Defect  Detection",
    "abstract": "Aero-engine is the core component of aircraft and other spacecraft. The\nhigh-speed rotating blades provide power by sucking in air and fully\ncombusting, and various defects will inevitably occur, threatening the\noperation safety of aero-engine. Therefore, regular inspections are essential\nfor such a complex system. However, existing traditional technology which is\nborescope inspection is labor-intensive, time-consuming, and\nexperience-dependent. To endow this technology with intelligence, a novel\nsuperpixel perception graph neural network (SPGNN) is proposed by utilizing a\nmulti-stage graph convolutional network (MSGCN) for feature extraction and\nsuperpixel perception region proposal network (SPRPN) for region proposal.\nFirst, to capture complex and irregular textures, the images are transformed\ninto a series of patches, to obtain their graph representations. Then, MSGCN\ncomposed of several GCN blocks extracts graph structure features and performs\ngraph information processing at graph level. Last but not least, the SPRPN is\nproposed to generate perceptual bounding boxes by fusing graph representation\nfeatures and superpixel perception features. Therefore, the proposed SPGNN\nalways implements feature extraction and information transmission at the graph\nlevel in the whole SPGNN pipeline, and SPRPN and MSGNN mutually benefit from\neach other. To verify the effectiveness of SPGNN, we meticulously construct a\nsimulated blade dataset with 3000 images. A public aluminum dataset is also\nused to validate the performances of different methods. The experimental\nresults demonstrate that the proposed SPGNN has superior performance compared\nwith the state-of-the-art methods. The source code will be available at\nhttps://github.com/githbshang/SPGNN.",
    "descriptor": "",
    "authors": [
      "Hongbing Shang",
      "Qixiu Yang",
      "Chuang Sun",
      "Xuefeng Chen",
      "Ruqiang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.07539"
  },
  {
    "id": "arXiv:2210.07540",
    "title": "When Adversarial Training Meets Vision Transformers: Recipes from  Training to Architecture",
    "abstract": "Vision Transformers (ViTs) have recently achieved competitive performance in\nbroad vision tasks. Unfortunately, on popular threat models, naturally trained\nViTs are shown to provide no more adversarial robustness than convolutional\nneural networks (CNNs). Adversarial training is still required for ViTs to\ndefend against such adversarial attacks. In this paper, we provide the first\nand comprehensive study on the adversarial training recipe of ViTs via\nextensive evaluation of various training techniques across benchmark datasets.\nWe find that pre-training and SGD optimizer are necessary for ViTs' adversarial\ntraining. Further considering ViT as a new type of model architecture, we\ninvestigate its adversarial robustness from the perspective of its unique\narchitectural components. We find, when randomly masking gradients from some\nattention blocks or masking perturbations on some patches during adversarial\ntraining, the adversarial robustness of ViTs can be remarkably improved, which\nmay potentially open up a line of work to explore the architectural information\ninside the newly designed models like ViTs. Our code is available at\nhttps://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers.",
    "descriptor": "",
    "authors": [
      "Yichuan Mo",
      "Dongxian Wu",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07540"
  },
  {
    "id": "arXiv:2210.07543",
    "title": "Watermarking Pre-trained Language Models with Backdooring",
    "abstract": "Large pre-trained language models (PLMs) have proven to be a crucial\ncomponent of modern natural language processing systems. PLMs typically need to\nbe fine-tuned on task-specific downstream datasets, which makes it hard to\nclaim the ownership of PLMs and protect the developer's intellectual property\ndue to the catastrophic forgetting phenomenon. We show that PLMs can be\nwatermarked with a multi-task learning framework by embedding backdoors\ntriggered by specific inputs defined by the owners, and those watermarks are\nhard to remove even though the watermarked PLMs are fine-tuned on multiple\ndownstream tasks. In addition to using some rare words as triggers, we also\nshow that the combination of common words can be used as backdoor triggers to\navoid them being easily detected. Extensive experiments on multiple datasets\ndemonstrate that the embedded watermarks can be robustly extracted with a high\nsuccess rate and less influenced by the follow-up fine-tuning.",
    "descriptor": "",
    "authors": [
      "Chenxi Gu",
      "Chengsong Huang",
      "Xiaoqing Zheng",
      "Kai-Wei Chang",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07543"
  },
  {
    "id": "arXiv:2210.07544",
    "title": "Legal Case Document Summarization: Extractive and Abstractive Methods  and their Evaluation",
    "abstract": "Summarization of legal case judgement documents is a challenging problem in\nLegal NLP. However, not much analyses exist on how different families of\nsummarization models (e.g., extractive vs. abstractive) perform when applied to\nlegal case documents. This question is particularly important since many recent\ntransformer-based abstractive summarization models have restrictions on the\nnumber of input tokens, and legal documents are known to be very long. Also, it\nis an open question on how best to evaluate legal case document summarization\nsystems. In this paper, we carry out extensive experiments with several\nextractive and abstractive summarization methods (both supervised and\nunsupervised) over three legal summarization datasets that we have developed.\nOur analyses, that includes evaluation by law practitioners, lead to several\ninteresting insights on legal summarization in specific and long document\nsummarization in general.",
    "descriptor": "\nComments: Accepted at The 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (AACL-IJCNLP), 2022\n",
    "authors": [
      "Abhay Shukla",
      "Paheli Bhattacharya",
      "Soham Poddar",
      "Rajdeep Mukherjee",
      "Kripabandhu Ghosh",
      "Pawan Goyal",
      "Saptarshi Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.07544"
  },
  {
    "id": "arXiv:2210.07546",
    "title": "Transformer-Based Speech Synthesizer Attribution in an Open Set Scenario",
    "abstract": "Speech synthesis methods can create realistic-sounding speech, which may be\nused for fraud, spoofing, and misinformation campaigns. Forensic methods that\ndetect synthesized speech are important for protection against such attacks.\nForensic attribution methods provide even more information about the nature of\nsynthesized speech signals because they identify the specific speech synthesis\nmethod (i.e., speech synthesizer) used to create a speech signal. Due to the\nincreasing number of realistic-sounding speech synthesizers, we propose a\nspeech attribution method that generalizes to new synthesizers not seen during\ntraining. To do so, we investigate speech synthesizer attribution in both a\nclosed set scenario and an open set scenario. In other words, we consider some\nspeech synthesizers to be \"known\" synthesizers (i.e., part of the closed set)\nand others to be \"unknown\" synthesizers (i.e., part of the open set). We\nrepresent speech signals as spectrograms and train our proposed method, known\nas compact attribution transformer (CAT), on the closed set for multi-class\nclassification. Then, we extend our analysis to the open set to attribute\nsynthesized speech signals to both known and unknown synthesizers. We utilize a\nt-distributed stochastic neighbor embedding (tSNE) on the latent space of the\ntrained CAT to differentiate between each unknown synthesizer. Additionally, we\nexplore poly-1 loss formulations to improve attribution results. Our proposed\napproach successfully attributes synthesized speech signals to their respective\nspeech synthesizers in both closed and open set scenarios.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Conference on Machine Learning and Applications\n",
    "authors": [
      "Emily R. Bartusiak",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07546"
  },
  {
    "id": "arXiv:2210.07547",
    "title": "Kernel-Whitening: Overcome Dataset Bias with Isotropic Sentence  Embedding",
    "abstract": "Dataset bias has attracted increasing attention recently for its detrimental\neffect on the generalization ability of fine-tuned models. The current\nmainstream solution is designing an additional shallow model to pre-identify\nbiased instances. However, such two-stage methods scale up the computational\ncomplexity of training process and obstruct valid feature information while\nmitigating bias. To address this issue, we utilize the representation\nnormalization method which aims at disentangling the correlations between\nfeatures of encoded sentences. We find it also promising in eliminating the\nbias problem by providing isotropic data distribution. We further propose\nKernel-Whitening, a Nystrom kernel approximation method to achieve more\nthorough debiasing on nonlinear spurious correlations. Our framework is\nend-to-end with similar time consumption to fine-tuning. Experiments show that\nKernel-Whitening significantly improves the performance of BERT on\nout-of-distribution datasets while maintaining in-distribution accuracy.",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Songyang Gao",
      "Shihan Dou",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07547"
  },
  {
    "id": "arXiv:2210.07548",
    "title": "Reconstructed Student-Teacher and Discriminative Networks for Anomaly  Detection",
    "abstract": "Anomaly detection is an important problem in computer vision; however, the\nscarcity of anomalous samples makes this task difficult. Thus, recent anomaly\ndetection methods have used only normal images with no abnormal areas for\ntraining. In this work, a powerful anomaly detection method is proposed based\non student-teacher feature pyramid matching (STPM), which consists of a student\nand teacher network. Generative models are another approach to anomaly\ndetection. They reconstruct normal images from an input and compute the\ndifference between the predicted normal and the input. Unfortunately, STPM does\nnot have the ability to generate normal images. To improve the accuracy of\nSTPM, this work uses a student network, as in generative models, to reconstruct\nnormal features. This improves the accuracy; however, the anomaly maps for\nnormal images are not clean because STPM does not use anomaly images for\ntraining, which decreases the accuracy of the image-level anomaly detection. To\nfurther improve accuracy, a discriminative network trained with\npseudo-anomalies from anomaly maps is used in our method, which consists of two\npairs of student-teacher networks and a discriminative network. The method\ndisplayed high accuracy on the MVTec anomaly detection dataset.",
    "descriptor": "\nComments: 8 pages, 7 figures, accepted IROS2022\n",
    "authors": [
      "Shinji Yamada",
      "Satoshi Kamiya",
      "Kazuhiro Hotta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07548"
  },
  {
    "id": "arXiv:2210.07553",
    "title": "Safe Model-Based Reinforcement Learning with an Uncertainty-Aware  Reachability Certificate",
    "abstract": "Safe reinforcement learning (RL) that solves constraint-satisfactory policies\nprovides a promising way to the broader safety-critical applications of RL in\nreal-world problems such as robotics. Among all safe RL approaches, model-based\nmethods reduce training time violations further due to their high sample\nefficiency. However, lacking safety robustness against the model uncertainties\nremains an issue in safe model-based RL, especially in training time safety. In\nthis paper, we propose a distributional reachability certificate (DRC) and its\nBellman equation to address model uncertainties and characterize robust\npersistently safe states. Furthermore, we build a safe RL framework to resolve\nconstraints required by the DRC and its corresponding shield policy. We also\ndevise a line search method to maintain safety and reach higher returns\nsimultaneously while leveraging the shield policy. Comprehensive experiments on\nclassical benchmarks such as constrained tracking and navigation indicate that\nthe proposed algorithm achieves comparable returns with much fewer constraint\nviolations during training.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Dongjie Yu",
      "Wenjun Zou",
      "Yujie Yang",
      "Haitong Ma",
      "Shengbo Eben Li",
      "Jingliang Duan",
      "Jianyu Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07553"
  },
  {
    "id": "arXiv:2210.07556",
    "title": "A Constructive Prophet Inequality Approach to The Adaptive ProbeMax  Problem",
    "abstract": "In the adaptive ProbeMax problem, given a collection of mutually-independent\nrandom variables $X_1, \\ldots, X_n$, our goal is to design an adaptive probing\npolicy for sequentially sampling at most $k$ of these variables, with the\nobjective of maximizing the expected maximum value sampled. In spite of its\nstylized formulation, this setting captures numerous technical hurdles inherent\nto stochastic optimization, related to both information structure and efficient\ncomputation. For these reasons, adaptive ProbeMax has served as a test bed for\na multitude of algorithmic methods, and concurrently as a popular teaching tool\nin courses and tutorials dedicated to recent trends in optimization under\nuncertainty.\nThe main contribution of this paper consists in proposing a novel method for\nupper-bounding the expected maximum reward of optimal adaptive probing\npolicies, based on a simple min-max problem. Equipped with this method, we\ndevise purely-combinatorial algorithms for deterministically computing feasible\nsets whose vicinity to the adaptive optimum is analyzed through prophet\ninequality ideas. Consequently, this approach allows us to establish improved\nconstructive adaptivity gaps for the ProbeMax problem in its broadest form,\nwhere $X_1, \\ldots, X_n$ are general random variables, making further\nadvancements when $X_1, \\ldots, X_n$ are continuous.",
    "descriptor": "",
    "authors": [
      "Guillermo Gallego",
      "Danny Segev"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07556"
  },
  {
    "id": "arXiv:2210.07558",
    "title": "DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic  Search-Free Low-Rank Adaptation",
    "abstract": "With the ever-growing size of pre-trained models (PMs), fine-tuning them has\nbecome more expensive and resource-hungry. As a remedy, low-rank adapters\n(LoRA) keep the main pre-trained weights of the model frozen and just introduce\nsome learnable truncated SVD modules (so-called LoRA blocks) to the model.\nWhile LoRA blocks are parameter efficient, they suffer from two major problems:\nfirst, the size of these blocks is fixed and cannot be modified after training\n(for example, if we need to change the rank of LoRA blocks, then we need to\nre-train them from scratch); second, optimizing their rank requires an\nexhaustive search and effort. In this work, we introduce a dynamic low-rank\nadaptation (DyLoRA) technique to address these two problems together. Our\nDyLoRA method trains LoRA blocks for a range of ranks instead of a single rank\nby sorting out the representation learned by the adapter module at different\nranks during training. We evaluate our solution on different tasks of the GLUE\nbenchmark using the RoBERTa model. Our results show that we can train dynamic\nsearch-free models with DyLoRA at least $7\\times$ faster than LoRA without\nsignificantly compromising performance. Moreover, our models can perform\nconsistently well on a much larger range of ranks compared to LoRA.",
    "descriptor": "",
    "authors": [
      "Mojtaba Valipour",
      "Mehdi Rezagholizadeh",
      "Ivan Kobyzev",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07558"
  },
  {
    "id": "arXiv:2210.07559",
    "title": "Empirical Study Incorporating Linguistic Knowledge on Filled Pauses for  Personalized Spontaneous Speech Synthesis",
    "abstract": "We present a comprehensive empirical study for personalized spontaneous\nspeech synthesis on the basis of linguistic knowledge. With the advent of voice\ncloning for reading-style speech synthesis, a new voice cloning paradigm for\nhuman-like and spontaneous speech synthesis is required. We, therefore, focus\non personalized spontaneous speech synthesis that can clone both the\nindividual's voice timbre and speech disfluency. Specifically, we deal with\nfilled pauses, a major source of speech disfluency, which is known to play an\nimportant role in speech generation and communication in psychology and\nlinguistics. To comparatively evaluate personalized filled pause insertion and\nnon-personalized filled pause prediction methods, we developed a speech\nsynthesis method with a non-personalized external filled pause predictor\ntrained with a multi-speaker corpus. The results clarify the position-word\nentanglement of filled pauses, i.e., the necessity of precisely predicting\npositions for naturalness and the necessity of precisely predicting words for\nindividuality on the evaluation of synthesized speech.",
    "descriptor": "\nComments: Accepted to APSIPA ASC 2022\n",
    "authors": [
      "Yuta Matsunaga",
      "Takaaki Saeki",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07559"
  },
  {
    "id": "arXiv:2210.07562",
    "title": "TokenMixup: Efficient Attention-guided Token-level Data Augmentation for  Transformers",
    "abstract": "Mixup is a commonly adopted data augmentation technique for image\nclassification. Recent advances in mixup methods primarily focus on mixing\nbased on saliency. However, many saliency detectors require intense computation\nand are especially burdensome for parameter-heavy transformer models. To this\nend, we propose TokenMixup, an efficient attention-guided token-level data\naugmentation method that aims to maximize the saliency of a mixed set of\ntokens. TokenMixup provides x15 faster saliency-aware data augmentation\ncompared to gradient-based methods. Moreover, we introduce a variant of\nTokenMixup which mixes tokens within a single instance, thereby enabling\nmulti-scale feature augmentation. Experiments show that our methods\nsignificantly improve the baseline models' performance on CIFAR and\nImageNet-1K, while being more efficient than previous methods. We also reach\nstate-of-the-art performance on CIFAR-100 among from-scratch transformer\nmodels. Code is available at https://github.com/mlvlab/TokenMixup.",
    "descriptor": "\nComments: Accepted paper at NeurIPS 2022\n",
    "authors": [
      "Hyeong Kyu Choi",
      "Joonmyung Choi",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07562"
  },
  {
    "id": "arXiv:2210.07563",
    "title": "Deep Koopman with Control: Spectral Analysis of Soft Robot Dynamics",
    "abstract": "Soft robots are challenging to model and control as inherent non-linearities\n(e.g., elasticity and deformation), often requires complex explicit\nphysics-based analytical modeling (e.g., a priori geometric definitions). While\nmachine learning can be used to learn non-linear control models in a\ndata-driven approach, these models often lack an intuitive internal physical\ninterpretation and representation, limiting dynamical analysis. To address\nthis, this paper presents an approach using Koopman operator theory and deep\nneural networks to provide a global linear description of the non-linear\ncontrol systems. Specifically, by globally linearising dynamics, the Koopman\noperator is analyzed using spectral decomposition to characterises important\nphysics-based interpretations, such as functional growths and oscillations.\nExperiments in this paper demonstrate this approach for controlling non-linear\nsoft robotics, and shows model outputs are interpretable in the context of\nspectral analysis.",
    "descriptor": "\nComments: 8 pages, accepted by the 2022 61st Annual Conference of the Society of Instrument and Control Engineers (SICE2022)\n",
    "authors": [
      "Naoto Komeno",
      "Brendan Michael",
      "Katharina K\u00fcchler",
      "Edgar Anarossi",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07563"
  },
  {
    "id": "arXiv:2210.07564",
    "title": "Q-TOD: A Query-driven Task-oriented Dialogue System",
    "abstract": "Existing pipelined task-oriented dialogue systems usually have difficulties\nadapting to unseen domains, whereas end-to-end systems are plagued by\nlarge-scale knowledge bases in practice. In this paper, we introduce a novel\nquery-driven task-oriented dialogue system, namely Q-TOD. The essential\ninformation from the dialogue context is extracted into a query, which is\nfurther employed to retrieve relevant knowledge records for response\ngeneration. Firstly, as the query is in the form of natural language and not\nconfined to the schema of the knowledge base, the issue of domain adaption is\nalleviated remarkably in Q-TOD. Secondly, as the query enables the decoupling\nof knowledge retrieval from the generation, Q-TOD gets rid of the issue of\nknowledge base scalability. To evaluate the effectiveness of the proposed\nQ-TOD, we collect query annotations for three publicly available task-oriented\ndialogue datasets. Comprehensive experiments verify that Q-TOD outperforms\nstrong baselines and establishes a new state-of-the-art performance on these\ndatasets.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Xin Tian",
      "Yingzhan Lin",
      "Mengfei Song",
      "Siqi Bao",
      "Fan Wang",
      "Huang He",
      "Shuqi Sun",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07564"
  },
  {
    "id": "arXiv:2210.07565",
    "title": "Multi-Task Pre-Training of Modular Prompt for Few-Shot Learning",
    "abstract": "Prompt tuning is a parameter-efficient approach to adapting pre-trained\nlanguage models to downstream tasks. Although prompt tuning has been shown to\nmatch the performance of full model tuning when training data is sufficient, it\ntends to struggle in few-shot learning settings. In this paper, we present\nMulti-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot\nlearning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.\nOn downstream tasks, the pre-trained prompts are selectively activated and\ncombined, leading to strong compositional generalization to unseen tasks. To\nbridge the gap between pre-training and fine-tuning, we formulate upstream and\ndownstream tasks into a unified machine reading comprehension task. Extensive\nexperiments under two learning paradigms, i.e., gradient descent and black-box\ntuning, show that MP2 significantly outperforms prompt tuning, full model\ntuning, and prior prompt pre-training methods in few-shot settings. In\naddition, we demonstrate that MP2 can achieve surprisingly fast and strong\nadaptation to downstream tasks by merely learning 8 parameters to combine the\npre-trained modular prompts.",
    "descriptor": "",
    "authors": [
      "Tianxiang Sun",
      "Zhengfu He",
      "Qin Zhu",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07565"
  },
  {
    "id": "arXiv:2210.07566",
    "title": "A Survey of Parameters Associated with the Quality of Benchmarks in NLP",
    "abstract": "Several benchmarks have been built with heavy investment in resources to\ntrack our progress in NLP. Thousands of papers published in response to those\nbenchmarks have competed to top leaderboards, with models often surpassing\nhuman performance. However, recent studies have shown that models triumph over\nseveral popular benchmarks just by overfitting on spurious biases, without\ntruly learning the desired task. Despite this finding, benchmarking, while\ntrying to tackle bias, still relies on workarounds, which do not fully utilize\nthe resources invested in benchmark creation, due to the discarding of low\nquality data, and cover limited sets of bias. A potential solution to these\nissues -- a metric quantifying quality -- remains underexplored. Inspired by\nsuccessful quality indices in several domains such as power, food, and water,\nwe take the first step towards a metric by identifying certain language\nproperties that can represent various possible interactions leading to biases\nin a benchmark. We look for bias related parameters which can potentially help\npave our way towards the metric. We survey existing works and identify\nparameters capturing various properties of bias, their origins, types and\nimpact on performance, generalization, and robustness. Our analysis spans over\ndatasets and a hierarchy of tasks ranging from NLI to Summarization, ensuring\nthat our parameters are generic and are not overfitted towards a specific task\nor dataset. We also develop certain parameters in this process.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2005.00816\n",
    "authors": [
      "Swaroop Mishra",
      "Anjana Arunkumar",
      "Chris Bryan",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07566"
  },
  {
    "id": "arXiv:2210.07570",
    "title": "MICO: A Multi-alternative Contrastive Learning Framework for Commonsense  Knowledge Representation",
    "abstract": "Commonsense reasoning tasks such as commonsense knowledge graph completion\nand commonsense question answering require powerful representation learning. In\nthis paper, we propose to learn commonsense knowledge representation by MICO, a\nMulti-alternative contrastve learning framework on COmmonsense knowledge graphs\n(MICO). MICO generates the commonsense knowledge representation by contextual\ninteraction between entity nodes and relations with multi-alternative\ncontrastive learning. In MICO, the head and tail entities in an $(h,r,t)$\nknowledge triple are converted to two relation-aware sequence pairs (a premise\nand an alternative) in the form of natural language. Semantic representations\ngenerated by MICO can benefit the following two tasks by simply comparing the\ndistance score between the representations: 1) zero-shot commonsense question\nanswering task; 2) inductive commonsense knowledge graph completion task.\nExtensive experiments show the effectiveness of our method.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ying Su",
      "Zihao Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Yangqiu Song",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07570"
  },
  {
    "id": "arXiv:2210.07571",
    "title": "Mix and Reason: Reasoning over Semantic Topology with Data Mixing for  Domain Generalization",
    "abstract": "Domain generalization (DG) enables generalizing a learning machine from\nmultiple seen source domains to an unseen target one. The general objective of\nDG methods is to learn semantic representations that are independent of domain\nlabels, which is theoretically sound but empirically challenged due to the\ncomplex mixture of common and domain-specific factors. Although disentangling\nthe representations into two disjoint parts has been gaining momentum in DG,\nthe strong presumption over the data limits its efficacy in many real-world\nscenarios. In this paper, we propose Mix and Reason (\\mire), a new DG framework\nthat learns semantic representations via enforcing the structural invariance of\nsemantic topology. \\mire\\ consists of two key components, namely,\nCategory-aware Data Mixing (CDM) and Adaptive Semantic Topology Refinement\n(ASTR). CDM mixes two images from different domains in virtue of activation\nmaps generated by two complementary classification losses, making the\nclassifier focus on the representations of semantic objects. ASTR introduces\nrelation graphs to represent semantic topology, which is progressively refined\nvia the interactions between local feature aggregation and global cross-domain\nrelational reasoning. Experiments on multiple DG benchmarks validate the\neffectiveness and robustness of the proposed \\mire.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Chaoqi Chen",
      "Luyao Tang",
      "Feng Liu",
      "Gangming Zhao",
      "Yue Huang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07571"
  },
  {
    "id": "arXiv:2210.07572",
    "title": "Cross-Scale Context Extracted Hashing for Fine-Grained Image Binary  Encoding",
    "abstract": "Deep hashing has been widely applied to large-scale image retrieval tasks\nowing to efficient computation and low storage cost by encoding\nhigh-dimensional image data into binary codes. Since binary codes do not\ncontain as much information as float features, the essence of binary encoding\nis preserving the main context to guarantee retrieval quality. However, the\nexisting hashing methods have great limitations on suppressing redundant\nbackground information and accurately encoding from Euclidean space to Hamming\nspace by a simple sign function. In order to solve these problems, a\nCross-Scale Context Extracted Hashing Network (CSCE-Net) is proposed in this\npaper. Firstly, we design a two-branch framework to capture fine-grained local\ninformation while maintaining high-level global semantic information. Besides,\nAttention guided Information Extraction module (AIE) is introduced between two\nbranches, which suppresses areas of low context information cooperated with\nglobal sliding windows. Unlike previous methods, our CSCE-Net learns a\ncontent-related Dynamic Sign Function (DSF) to replace the original simple sign\nfunction. Therefore, the proposed CSCE-Net is context-sensitive and able to\nperform well on accurate image binary encoding. We further demonstrate that our\nCSCE-Net is superior to the existing hashing methods, which improves retrieval\nperformance on standard benchmarks.",
    "descriptor": "\nComments: Accepted by 14th Asian Conference on Machine Learning (ACML2022)\n",
    "authors": [
      "Xuetong Xue",
      "Jiaying Shi",
      "Xinxue He",
      "Shenghui Xu",
      "Zhaoming Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07572"
  },
  {
    "id": "arXiv:2210.07573",
    "title": "Model-based Safe Deep Reinforcement Learning via a Constrained Proximal  Policy Optimization Algorithm",
    "abstract": "During initial iterations of training in most Reinforcement Learning (RL)\nalgorithms, agents perform a significant number of random exploratory steps. In\nthe real world, this can limit the practicality of these algorithms as it can\nlead to potentially dangerous behavior. Hence safe exploration is a critical\nissue in applying RL algorithms in the real world. This problem has been\nrecently well studied under the Constrained Markov Decision Process (CMDP)\nFramework, where in addition to single-stage rewards, an agent receives\nsingle-stage costs or penalties as well depending on the state transitions. The\nprescribed cost functions are responsible for mapping undesirable behavior at\nany given time-step to a scalar value. The goal then is to find a feasible\npolicy that maximizes reward returns while constraining the cost returns to be\nbelow a prescribed threshold during training as well as deployment.\nWe propose an On-policy Model-based Safe Deep RL algorithm in which we learn\nthe transition dynamics of the environment in an online manner as well as find\na feasible optimal policy using the Lagrangian Relaxation-based Proximal Policy\nOptimization. We use an ensemble of neural networks with different\ninitializations to tackle epistemic and aleatoric uncertainty issues faced\nduring environment model learning. We compare our approach with relevant\nmodel-free and model-based approaches in Constrained RL using the challenging\nSafe Reinforcement Learning benchmark - the Open AI Safety Gym. We demonstrate\nthat our algorithm is more sample efficient and results in lower cumulative\nhazard violations as compared to constrained model-free approaches. Further,\nour approach shows better reward performance than other constrained model-based\napproaches in the literature.",
    "descriptor": "\nComments: Proceedings of NeurIPS 2022\n",
    "authors": [
      "Ashish Kumar Jayant",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07573"
  },
  {
    "id": "arXiv:2210.07574",
    "title": "Is synthetic data from generative models ready for image recognition?",
    "abstract": "Recent text-to-image generation models have shown promising results in\ngenerating high-fidelity photo-realistic images. Though the results are\nastonishing to human eyes, how applicable these generated images are for\nrecognition tasks remains under-explored. In this work, we extensively study\nwhether and how synthetic images generated from state-of-the-art text-to-image\ngeneration models can be used for image recognition tasks, and focus on two\nperspectives: synthetic data for improving classification models in data-scarce\nsettings (i.e. zero-shot and few-shot), and synthetic data for large-scale\nmodel pre-training for transfer learning. We showcase the powerfulness and\nshortcomings of synthetic data from existing generative models, and propose\nstrategies for better applying synthetic data for recognition tasks. Code:\nhttps://github.com/CVMI-Lab/SyntheticData.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Ruifei He",
      "Shuyang Sun",
      "Xin Yu",
      "Chuhui Xue",
      "Wenqing Zhang",
      "Philip Torr",
      "Song Bai",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07574"
  },
  {
    "id": "arXiv:2210.07577",
    "title": "MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to  Depth-aware Video Panoptic Segmentation",
    "abstract": "Depth-aware video panoptic segmentation tackles the inverse projection\nproblem of restoring panoptic 3D point clouds from video sequences, where the\n3D points are augmented with semantic classes and temporally consistent\ninstance identifiers. We propose a novel solution with a multi-task network\nthat performs monocular depth estimation and video panoptic segmentation. Since\nacquiring ground truth labels for both depth and image segmentation has a\nrelatively large cost, we leverage the power of unlabeled video sequences with\nself-supervised monocular depth estimation and semi-supervised learning from\npseudo-labels for video panoptic segmentation. To further improve the depth\nprediction, we introduce panoptic-guided depth losses and a novel panoptic\nmasking scheme for moving objects to avoid corrupting the training signal.\nExtensive experiments on the Cityscapes-DVPS and SemKITTI-DVPS datasets\ndemonstrate that our model with the proposed improvements achieves competitive\nresults and fast inference speed.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Andra Petrovai",
      "Sergiu Nedevschi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07577"
  },
  {
    "id": "arXiv:2210.07578",
    "title": "PoolLines: Modeling Carpooling as Ephemeral Lines in GTFS for effective  integration with Public Transit",
    "abstract": "In carpooling systems, a set of drivers owning a private car can accept a\nsmall detour to pick-up and drop-off other riders. However, carpooling is\nwidely used for long-distance trips, where rider-driver matching can be done\ndays ahead. Making carpooling a viable option for daily commute is more\nchallenging, as trips are shorter and, proportionally, the detours tolerated by\ndrivers are more tight. As a consequence, finding riders and drivers sharing\nclose-enough origins, destinations and departure time is less likely, which\nlimits potential matching. In this paper we propose an Integrated System, where\ncarpooling matching is synchronized with Public Transit (PT) schedules, so as\nto serve as a feeder service to PT in the first mile. Driver detours are\nproposed towards PT selected stations, which are used as consolidation points,\nthus increasing matching probability. We present a computationally efficient\nmethod to represent PT schedules and drivers trajectory in a single General\nTransit Feed Specification database, which allows to compute multimodal rider\njourneys using any off the shelf planners. We showcase our approach in the\nmetropolitan area of Portland, Oregon, considering 8k randomly generated trips.\nWe show the benefits of our Integrated System. We find that 10% more riders\nfind a feasible matching with respect to the status quo, where carpooling and\nPT are operated separately. We release our code as open source.",
    "descriptor": "\nComments: 15th ACM SIGSPATIAL International Workshop on Computational Transportation Science (IWCTS 2022)\n",
    "authors": [
      "Youssef Chaabouni",
      "Andrea Araldo",
      "Andr\u00e9 de Palma",
      "Souhila Arib"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2210.07578"
  },
  {
    "id": "arXiv:2210.07580",
    "title": "GriT-DBSCAN: A Spatial Clustering Algorithm for Very Large Databases",
    "abstract": "DBSCAN is a fundamental spatial clustering algorithm with numerous practical\napplications. However, a bottleneck of the algorithm is in the worst case, the\nrun time complexity is $O(n^2)$. To address this limitation, we propose a new\ngrid-based algorithm for exact DBSCAN in Euclidean space called GriT-DBSCAN,\nwhich is based on the following two techniques. First, we introduce a grid tree\nto organize the non-empty grids for the purpose of efficient non-empty\nneighboring grids queries. Second, by utilising the spatial relationships among\npoints, we propose a technique that iteratively prunes unnecessary distance\ncalculations when determining whether the minimum distance between two sets is\nless than or equal to a certain threshold. We theoretically prove that the\ncomplexity of GriT-DBSCAN is linear to the data set size. In addition, we\nobtain two variants of GriT-DBSCAN by incorporating heuristics, or by combining\nthe second technique with an existing algorithm. Experiments are conducted on\nboth synthetic and real-world data sets to evaluate the efficiency of\nGriT-DBSCAN and its variants. The results of our analyses show that our\nalgorithms outperform existing algorithms.",
    "descriptor": "",
    "authors": [
      "Xiaogang Huang",
      "Tiefeng Ma",
      "Conan Liu",
      "Shuangzhe Liu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07580"
  },
  {
    "id": "arXiv:2210.07582",
    "title": "Deep PatchMatch MVS with Learned Patch Coplanarity, Geometric  Consistency and Adaptive Pixel Sampling",
    "abstract": "Recent work in multi-view stereo (MVS) combines learnable photometric scores\nand regularization with PatchMatch-based optimization to achieve robust\npixelwise estimates of depth, normals, and visibility. However, non-learning\nbased methods still outperform for large scenes with sparse views, in part due\nto use of geometric consistency constraints and ability to optimize over many\nviews at high resolution. In this paper, we build on learning-based approaches\nto improve photometric scores by learning patch coplanarity and encourage\ngeometric consistency by learning a scaled photometric cost that can be\ncombined with reprojection error. We also propose an adaptive pixel sampling\nstrategy for candidate propagation that reduces memory to enable training on\nlarger resolution with more views and a larger encoder. These modifications\nlead to 6-15% gains in accuracy and completeness on the challenging ETH3D\nbenchmark, resulting in higher F1 performance than the widely used\nstate-of-the-art non-learning approaches ACMM and ACMP.",
    "descriptor": "",
    "authors": [
      "Jae Yong Lee",
      "Chuhang Zou",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07582"
  },
  {
    "id": "arXiv:2210.07584",
    "title": "Probabilistic Scheduling of Dynamic I/O Requests via Application  Clustering for Burst-Buffer Equipped HPC",
    "abstract": "Burst-Buffering is a promising storage solution that introduces an\nintermediate highthroughput storage buffer layer to mitigate the I/O bottleneck\nproblem that the current High-Performance Computing (HPC) platforms suffer. The\nexisting Markov-Chain based probabilistic I/O scheduling utilizes the load\nstate of Burst-Buffers and the periodical characteristics of applications to\nreduce I/O congestion due to the limited capacity of Burst-Buffers. However,\nthis probabilistic approach requires consistent I/O characteristics of\napplications, including similar I/O duration and long application length, in\norder to obtain an accurate I/O load estimation. These consistency conditions\ndo not often hold in realistic situations.\nIn this paper, we propose a generic framework of dynamic probabilistic I/O\nscheduling based on application clustering (DPSAC) to make applications meet\nthe consistency requirements. According to the I/O phrase length of each\napplication, our scheme first deploys a one-dimensional K-means clustering\nalgorithm to cluster the applications into clusters. Next, it calculates the\nexpected workload of each cluster through the probabilistic model of\napplications and then partitions the Burst-Buffers proportionally. Then, to\nhandle dynamic changes (join and exit) of applications, it updates the clusters\nbased on a heuristic strategy. Finally, it applies the probabilistic I/O\nscheduling, which is based on the distribution of application workload and the\nstate of Burst-Buffers, to schedule I/O for all the concurrent applications to\nmitigate I/O congestion. The simulation results on synthetic data show that our\nDPSAC is effective and efficient.",
    "descriptor": "",
    "authors": [
      "Benbo Zha",
      "Hong Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07584"
  },
  {
    "id": "arXiv:2210.07586",
    "title": "Automatic Creation of Named Entity Recognition Datasets by Querying  Phrase Representations",
    "abstract": "Most weakly supervised named entity recognition (NER) models rely on\ndomain-specific dictionaries provided by experts. This approach is infeasible\nin many domains where dictionaries do not exist. While a phrase retrieval model\nwas used to construct pseudo-dictionaries with entities retrieved from\nWikipedia automatically in a recent study, these dictionaries often have\nlimited coverage because the retriever is likely to retrieve popular entities\nrather than rare ones. In this study, a phrase embedding search to efficiently\ncreate high-coverage dictionaries is presented. Specifically, the reformulation\nof natural language queries into phrase representations allows the retriever to\nsearch a space densely populated with various entities. In addition, we present\na novel framework, HighGEN, that generates NER datasets with high-coverage\ndictionaries obtained using the phrase embedding search. HighGEN generates weak\nlabels based on the distance between the embeddings of a candidate phrase and\ntarget entity type to reduce the noise in high-coverage dictionaries. We\ncompare HighGEN with current weakly supervised NER models on six NER benchmarks\nand demonstrate the superiority of our models.",
    "descriptor": "",
    "authors": [
      "Hyunjae Kim",
      "Jaehyo Yoo",
      "Seunghyun Yoon",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07586"
  },
  {
    "id": "arXiv:2210.07587",
    "title": "ConEntail: An Entailment-based Framework for Universal Zero and Few Shot  Classification with Supervised Contrastive Pretraining",
    "abstract": "A universal classification model aims to generalize to diverse classification\ntasks in both zero and few shot settings. A promising way toward universal\nclassification is to cast heterogeneous data formats into a dataset-agnostic\n\"meta-task\" (e.g., textual entailment, question answering) then pretrain a\nmodel on the combined meta dataset. The existing work is either pretrained on\nspecific subsets of classification tasks, or pretrained on both classification\nand generation data but the model could not fulfill its potential in\nuniversality and reliability. These also leave a massive amount of annotated\ndata under-exploited. To fill these gaps, we propose ConEntail, a new framework\nfor universal zero and few shot classification with supervised contrastive\npretraining. Our unified meta-task for classification is based on nested\nentailment. It can be interpreted as \"Does sentence a entails [sentence b\nentails label c]\". This formulation enables us to make better use of 57\nannotated classification datasets for supervised contrastive pretraining and\nuniversal evaluation. In this way, ConEntail helps the model (1) absorb\nknowledge from different datasets, and (2) gain consistent performance gain\nwith more pretraining data. In experiments, we compare our model with\ndiscriminative and generative models pretrained on the same dataset. The\nresults confirm that our framework effectively exploits existing annotated data\nand consistently outperforms baselines in both zero (9.4% average improvement)\nand few shot settings (3.5% average improvement).",
    "descriptor": "",
    "authors": [
      "Haoran Zhang",
      "Aysa Xuemo Fan",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07587"
  },
  {
    "id": "arXiv:2210.07588",
    "title": "Distributed Distributionally Robust Optimization with Non-Convex  Objectives",
    "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal\ndecision that minimizes the worst case cost over the ambiguity set of\nprobability distribution, has been widely applied in diverse applications,\ne.g., network behavior analysis, risk management, etc. However, existing DRO\ntechniques face three key challenges: 1) how to deal with the asynchronous\nupdating in a distributed environment; 2) how to leverage the prior\ndistribution effectively; 3) how to properly adjust the degree of robustness\naccording to different scenarios. To this end, we propose an asynchronous\ndistributed algorithm, named Asynchronous Single-looP alternatIve gRadient\nprojEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to\ntackle the distributed distributionally robust optimization (DDRO) problem.\nFurthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set,\nis developed to effectively leverage the prior distribution and flexibly\ncontrol the degree of robustness. Finally, our theoretical analysis elucidates\nthat the proposed algorithm is guaranteed to converge and the iteration\ncomplexity is also analyzed. Extensive empirical studies on real-world datasets\ndemonstrate that the proposed method can not only achieve fast convergence, and\nremain robust against data heterogeneity as well as malicious attacks, but also\ntradeoff robustness with performance.",
    "descriptor": "\nComments: Accepted to NeurIPS2022\n",
    "authors": [
      "Yang Jiao",
      "Kai Yang",
      "Dongjin Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07588"
  },
  {
    "id": "arXiv:2210.07589",
    "title": "Inverse Problems for Subdiffusion from Observation at an Unknown  Terminal Time",
    "abstract": "Inverse problems of recovering space-dependent parameters, e.g., initial\ncondition, space-dependent source or potential coefficient, in a subdiffusion\nmodel from the terminal observation have been extensively studied in recent\nyears. However, all existing studies have assumed that the terminal time at\nwhich one takes the observation is exactly known. In this work, we present\nuniqueness and stability results for three canonical inverse problems, e.g.,\nbackward problem, inverse source and inverse potential problems, from the\nterminal observation at an unknown time. The subdiffusive nature of the problem\nindicates that one can simultaneously determine the terminal time and\nspace-dependent parameter. The analysis is based on explicit solution\nrepresentations, asymptotic behavior of the Mittag-Leffler function, and mild\nregularity conditions on the problem data. Further, we present several one- and\ntwo-dimensional numerical experiments to illustrate the feasibility of the\napproach.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Bangti Jin",
      "Yavar Kian",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.07589"
  },
  {
    "id": "arXiv:2210.07590",
    "title": "Stroke-based Rendering and Planning for Robotic Performance of Artistic  Drawing",
    "abstract": "We present a new robotic drawing system based on stroke-based rendering\n(SBR). Our motivation is the artistic quality of the whole performance. Not\nonly should the generated strokes in the final drawing resemble the input\nimage, but the stroke sequence should also exhibit a human artist's planning\nprocess. Thus, when a robot executes the drawing task, both the drawing results\nand the way the robot executes would look artistic.\nOur SBR system is based on image segmentation and depth estimation. It\ngenerates the drawing strokes in an order that allows for the intended shape to\nbe perceived quickly and for its detailed features to be filled in and emerge\ngradually when observed by the human. This ordering represents a stroke plan\nthat the drawing robot should follow to create an artistic rendering of images.\nWe experimentally demonstrate that our SBR-based drawing makes visually\npleasing artistic images, and our robotic system can replicate the result with\nproper sequences of stroke drawing.",
    "descriptor": "\nComments: Submitted to IEEE ICRA 2023\n",
    "authors": [
      "Ivaylo Ilinkin",
      "Daeun Song",
      "Young J. Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07590"
  },
  {
    "id": "arXiv:2210.07592",
    "title": "TSP-Bot: Robotic TSP Pen Art using High-DoF Manipulators",
    "abstract": "With the tremendous growth of digital technologies, digital art has become\none of the largest art fields since the early 1960s. Early pioneers of digital\nart were not only artists but also engineers, computer scientists, and\nmathematicians who challenged traditional art standards with new technologies.\nTypically, most of the work focuses on investigating the production of artistic\nimages in virtual space, which enables a wide variety of expressive and\naesthetic styles using computer algorithms. Traveling Salesman Problem Art,\nabbreviated as TSP art, is one of the representative examples of creating\nartistic work using computer algorithms. It was first invented by mathematician\nRobert Bosh \\cite{kaplan2005tsp}, who wished to engage his students in\noptimization problems. TSP art is an art piece that represents the original\ndigital image with piecewise-continuous line segments. It is obtained by first\nplacing the points that reproduce the tonal quality of the image and then\nfinding line segments (or paths) that visit once and every point by solving\nTSP, one of the most thoroughly studied optimization problems. TSP art involves\nnot only the creative process of computer algorithms but also fits the nature\nof a robotic task, whose fundamental mission is to follow a path accurately and\nefficiently.",
    "descriptor": "\nComments: Submitted to IEEE ICRA 2023\n",
    "authors": [
      "Daeun Song",
      "Eunjung Lim",
      "Jiyoon Park",
      "Minjung Jung",
      "Young J. Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07592"
  },
  {
    "id": "arXiv:2210.07594",
    "title": "See Blue Sky: Deep Image Dehaze Using Paired and Unpaired Training  Images",
    "abstract": "The issue of image haze removal has attracted wide attention in recent years.\nHowever, most existing haze removal methods cannot restore the scene with clear\nblue sky, since the color and texture information of the object in the original\nhaze image is insufficient. To remedy this, we propose a cycle generative\nadversarial network to construct a novel end-to-end image dehaze model. We\nadopt outdoor image datasets to train our model, which includes a set of\nreal-world unpaired image dataset and a set of paired image dataset to ensure\nthat the generated images are close to the real scene. Based on the cycle\nstructure, our model adds four different kinds of loss function to constrain\nthe effect including adversarial loss, cycle consistency loss, photorealism\nloss and paired L1 loss. These four constraints can improve the overall quality\nof such degraded images for better visual appeal and ensure reconstruction of\nimages to keep from distortion. The proposed model could remove the haze of\nimages and also restore the sky of images to be clean and blue (like captured\nin a sunny weather).",
    "descriptor": "",
    "authors": [
      "Xiaoyan Zhang",
      "Gaoyang Tang",
      "Yingying Zhu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.07594"
  },
  {
    "id": "arXiv:2210.07595",
    "title": "The State of Profanity Obfuscation in Natural Language Processing",
    "abstract": "Work on hate speech has made the consideration of rude and harmful examples\nin scientific publications inevitable. This raises various problems, such as\nwhether or not to obscure profanities. While science must accurately disclose\nwhat it does, the unwarranted spread of hate speech is harmful to readers, and\nincreases its internet frequency. While maintaining publications' professional\nappearance, obfuscating profanities makes it challenging to evaluate the\ncontent, especially for non-native speakers. Surveying 150 ACL papers, we\ndiscovered that obfuscation is usually employed for English but not other\nlanguages, and even so quite uneven. We discuss the problems with obfuscation\nand suggest a multilingual community resource called PrOf that has a Python\nmodule to standardize profanity obfuscation processes. We believe PrOf can help\nscientific publication policies to make hate speech work accessible and\ncomparable, irrespective of language.",
    "descriptor": "",
    "authors": [
      "Debora Nozza",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07595"
  },
  {
    "id": "arXiv:2210.07598",
    "title": "Lightweight Stepless Super-Resolution of Remote Sensing Images via  Saliency-Aware Dynamic Routing Strategy",
    "abstract": "Deep learning-based algorithms have greatly improved the performance of\nremote sensing image (RSI) super-resolution (SR). However, increasing network\ndepth and parameters cause a huge burden of computing and storage. Directly\nreducing the depth or width of existing models results in a large performance\ndrop. We observe that the SR difficulty of different regions in an RSI varies\ngreatly, and existing methods use the same deep network to process all regions\nin an image, resulting in a waste of computing resources. In addition, existing\nSR methods generally predefine integer scale factors and cannot perform\nstepless SR, i.e., a single model can deal with any potential scale factor.\nRetraining the model on each scale factor wastes considerable computing\nresources and model storage space. To address the above problems, we propose a\nsaliency-aware dynamic routing network (SalDRN) for lightweight and stepless SR\nof RSIs. First, we introduce visual saliency as an indicator of region-level SR\ndifficulty and integrate a lightweight saliency detector into the SalDRN to\ncapture pixel-level visual characteristics. Then, we devise a saliency-aware\ndynamic routing strategy that employs path selection switches to adaptively\nselect feature extraction paths of appropriate depth according to the SR\ndifficulty of sub-image patches. Finally, we propose a novel lightweight\nstepless upsampling module whose core is an implicit feature function for\nrealizing mapping from low-resolution feature space to high-resolution feature\nspace. Comprehensive experiments verify that the SalDRN can achieve a good\ntrade-off between performance and complexity. The code is available at\n\\url{https://github.com/hanlinwu/SalDRN}.",
    "descriptor": "",
    "authors": [
      "Hanlin Wu",
      "Ning Ni",
      "Libao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07598"
  },
  {
    "id": "arXiv:2210.07599",
    "title": "Online Harassment of Celebrities and Influencers",
    "abstract": "Celebrities and influencers are harassed online on a daily basis. Online\nharassment mentally disturbs celebrities/influencers and negatively affects\nsociety. However, limited studies have been conducted on online harassment\nvictimization of celebrities and influencers, and its effects remain unclear.\nWe surveyed Japanese celebrities and influencers ($N=213$) about online\nharassment victimization, emotional damage, and action against offenders and\nrevealed that various forms of online harassment were prevalent. Some victims\nused the anti-harassment functions provided by weblogs and social media systems\n(e.g., blocking/muting/reporting offender accounts and closing comment forms),\ntalked about their victimization to close people, and contacted relevant\nauthorities for concrete legal actions (talent agencies, legal consultants, and\npolice). By contrast, some victims felt compelled to accept harassment and did\nnot initiate actions for smaller offenses. We proposed several approaches to\nsupport victims, inhibit online harassment, and educate people. Our research\nwould contribute that platforms establish a support system against online\nharassment.",
    "descriptor": "\nComments: 15 pages, 7 figures, 2 tables\n",
    "authors": [
      "Masanori Takano",
      "Fumiaki Taka",
      "Chiki Ogiue",
      "Natsuki Nagata"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.07599"
  },
  {
    "id": "arXiv:2210.07600",
    "title": "Identification of Common Trends in Political Speech in Social Media  using Sentiment Analysis",
    "abstract": "Social Media have been extensively used for commercial and political\ncommunication, besides their initial scope of providing an easy-to-use outlet\nto produce and consume user-generated content. Besides being a popular medium,\nSocial Media have definitely changed the way we express ourselves or where we\nlook for emerging news and commentary, especially during troubled times. In\nthis paper, we examine a corpus assembled from the Twitter accounts of\npoliticians in the United States and annotated with respect to their audience\nand the sentiment they convey with each post. Our purpose is to examine whether\nthere are stylistic differences among representatives of different political\nideologies, directed to different audiences or with dissimilar agendas. Our\nfindings verify existing knowledge from conventional written communication and\ncan be used to evaluate the quality and depth of political expression and\ndialogue, especially during the period leading to an election.",
    "descriptor": "\nComments: Accepted for the 9th International Euro-Mediterranean Conference (EuroMed 2022)\n",
    "authors": [
      "Kostas Karpouzis",
      "Stavros Kaperonis",
      "Yannis Skarpelos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07600"
  },
  {
    "id": "arXiv:2210.07601",
    "title": "MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in  Optical Remote Sensing Images",
    "abstract": "For the task of change detection (CD) in remote sensing images, deep\nconvolution neural networks (CNNs)-based methods have recently aggregated\ntransformer modules to improve the capability of global feature extraction.\nHowever, they suffer degraded CD performance on small changed areas due to the\nsimple single-scale integration of deep CNNs and transformer modules. To\naddress this issue, we propose a hybrid network based on multi-scale\nCNN-transformer structure, termed MCTNet, where the multi-scale global and\nlocal information are exploited to enhance the robustness of the CD performance\non changed areas with different sizes. Especially, we design the ConvTrans\nblock to adaptively aggregate global features from transformer modules and\nlocal features from CNN layers, which provides abundant global-local features\nwith different scales. Experimental results demonstrate that our MCTNet\nachieves better detection performance than existing state-of-the-art CD\nmethods.",
    "descriptor": "",
    "authors": [
      "Weiming Li",
      "Lihui Xue",
      "Xueqian Wang",
      "Gang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07601"
  },
  {
    "id": "arXiv:2210.07602",
    "title": "Mention Annotations Alone Enable Efficient Domain Adaptation for  Coreference Resolution",
    "abstract": "Although, recent advances in neural network models for coreference resolution\nhave led to substantial improvements on benchmark datasets, it remains a\nchallenge to successfully transfer those models to new target domains\ncontaining many out-of-vocabulary spans and requiring differing annotation\nschemes. Typical approaches for domain adaptation involve continued training on\ncoreference annotations in the target domain, but obtaining those annotations\nis costly and time-consuming. In this work, we show that adapting mention\ndetection is the key component to successful domain adaptation of coreference\nmodels, rather than antecedent linking. Through timed annotation experiments,\nwe also show annotating mentions alone is nearly twice as fast as annotating\nfull coreference chains. Based on these insights, we propose a method for\neffectively adapting coreference models that requires only mention annotations\nin the target domain. We use an auxiliary mention detection objective trained\nwith mention examples in the target domain resulting in higher mention\nprecision. We demonstrate that our approach facilitates sample- and\ntime-efficient transfer to new annotation schemes and lexicons in extensive\nevaluation across three English coreference datasets: CoNLL-2012\n(news/conversation), i2b2/VA (medical case notes), and a dataset of child\nwelfare case notes. We show that annotating mentions results in 7-14%\nimprovement in average F1 over annotating coreference over an equivalent amount\nof time.",
    "descriptor": "",
    "authors": [
      "Nupoor Gandhi",
      "Anjalie Field",
      "Emma Strubell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07602"
  },
  {
    "id": "arXiv:2210.07604",
    "title": "High-Order Non-Conforming Discontinuous Galerkin Methods for the  Acoustic Conservation Equations",
    "abstract": "This work compares two Nitsche-type approaches to treat non-conforming\ntriangulations for a high-order discontinuous Galerkin (DG) solver for the\nacoustic conservation equations. The first approach (point-to-point\ninterpolation) uses inexact integration with quadrature points prescribed by a\nprimary element. The second approach uses exact integration (mortaring) by\nchoosing quadratures depending on the intersection between non-conforming\nelements. In literature, some excellent properties regarding performance and\nease of implementation are reported for point-to-point interpolation. However,\nwe show that this approach can not safely be used for DG discretizations of the\nacoustic conservation equations since, in our setting, it yields spurious\noscillations that lead to instabilities. This work presents a test case in that\nwe can observe the instabilities and shows that exact integration is required\nto maintain a stable method. Additionally, we provide a detailed analysis of\nthe method with exact integration. We show optimal spatial convergence rates\nglobally and in each mesh region separately. The method is constructed such\nthat it can natively treat overlaps between elements. Finally, we highlight the\nbenefits of non-conforming discretizations in acoustic computations by a\nnumerical test case with different fluids.",
    "descriptor": "",
    "authors": [
      "Johannes Heinz",
      "Peter Munch",
      "Manfred Kaltenbacher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07604"
  },
  {
    "id": "arXiv:2210.07606",
    "title": "Revisiting Heterophily For Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) extend basic Neural Networks (NNs) by using\ngraph structures based on the relational inductive bias (homophily assumption).\nWhile GNNs have been commonly believed to outperform NNs in real-world tasks,\nrecent work has identified a non-trivial set of datasets where their\nperformance compared to NNs is not satisfactory. Heterophily has been\nconsidered the main cause of this empirical observation and numerous works have\nbeen put forward to address it. In this paper, we first revisit the widely used\nhomophily metrics and point out that their consideration of only graph-label\nconsistency is a shortcoming. Then, we study heterophily from the perspective\nof post-aggregation node similarity and define new homophily metrics, which are\npotentially advantageous compared to existing ones. Based on this\ninvestigation, we prove that some harmful cases of heterophily can be\neffectively addressed by local diversification operation. Then, we propose the\nAdaptive Channel Mixing (ACM), a framework to adaptively exploit aggregation,\ndiversification and identity channels node-wisely to extract richer localized\ninformation for diverse node heterophily situations. ACM is more powerful than\nthe commonly used uni-channel framework for node classification tasks on\nheterophilic graphs and is easy to be implemented in baseline GNN layers. When\nevaluated on 10 benchmark node classification tasks, ACM-augmented baselines\nconsistently achieve significant performance gain, exceeding state-of-the-art\nGNNs on most tasks without incurring significant computational burden.",
    "descriptor": "\nComments: Published at 36th Conference on Neural Information Processing Systems (NeurIPS 2022). arXiv admin note: substantial text overlap with arXiv:2109.05641\n",
    "authors": [
      "Sitao Luan",
      "Chenqing Hua",
      "Qincheng Lu",
      "Jiaqi Zhu",
      "Mingde Zhao",
      "Shuyuan Zhang",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07606"
  },
  {
    "id": "arXiv:2210.07615",
    "title": "FedFM: Anchor-based Feature Matching for Data Heterogeneity in Federated  Learning",
    "abstract": "One of the key challenges in federated learning (FL) is local data\ndistribution heterogeneity across clients, which may cause inconsistent feature\nspaces across clients. To address this issue, we propose a novel method FedFM,\nwhich guides each client's features to match shared category-wise anchors\n(landmarks in feature space). This method attempts to mitigate the negative\neffects of data heterogeneity in FL by aligning each client's feature space.\nBesides, we tackle the challenge of varying objective function and provide\nconvergence guarantee for FedFM. In FedFM, to mitigate the phenomenon of\noverlapping feature spaces across categories and enhance the effectiveness of\nfeature matching, we further propose a more precise and effective feature\nmatching loss called contrastive-guiding (CG), which guides each local feature\nto match with the corresponding anchor while keeping away from\nnon-corresponding anchors. Additionally, to achieve higher efficiency and\nflexibility, we propose a FedFM variant, called FedFM-Lite, where clients\ncommunicate with server with fewer synchronization times and communication\nbandwidth costs. Through extensive experiments, we demonstrate that FedFM with\nCG outperforms several works by quantitative and qualitative comparisons.\nFedFM-Lite can achieve better performance than state-of-the-art methods with\nfive to ten times less communication costs.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Rui Ye",
      "Zhenyang Ni",
      "Chenxin Xu",
      "Jianyu Wang",
      "Siheng Chen",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07615"
  },
  {
    "id": "arXiv:2210.07617",
    "title": "Quantifying Quality of Class-Conditional Generative Models in  Time-Series Domain",
    "abstract": "Generative models are designed to address the data scarcity problem. Even\nwith the exploding amount of data, due to computational advancements, some\napplications (e.g., health care, weather forecast, fault detection) still\nsuffer from data insufficiency, especially in the time-series domain. Thus\ngenerative models are essential and powerful tools, but they still lack a\nconsensual approach for quality assessment. Such deficiency hinders the\nconfident application of modern implicit generative models on time-series data.\nInspired by assessment methods on the image domain, we introduce the\nInceptionTime Score (ITS) and the Frechet InceptionTime Distance (FITD) to\ngauge the qualitative performance of class conditional generative models on the\ntime-series domain. We conduct extensive experiments on 80 different datasets\nto study the discriminative capabilities of proposed metrics alongside two\nexisting evaluation metrics: Train on Synthetic Test on Real (TSTR) and Train\non Real Test on Synthetic (TRTS). Extensive evaluation reveals that the\nproposed assessment method, i.e., ITS and FITD in combination with TSTR, can\naccurately assess class-conditional generative model performance.",
    "descriptor": "",
    "authors": [
      "Alireza Koochali",
      "Maria Walch",
      "Sankrutyayan Thota",
      "Peter Schichtel",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07617"
  },
  {
    "id": "arXiv:2210.07621",
    "title": "Dense-ATOMIC: Construction of Densely-connected and Multi-hop  Commonsense Knowledge Graph upon ATOMIC",
    "abstract": "ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing\neveryday if-then knowledge triplets, i.e., {head event, relation, tail event}.\nThe one-hop annotation manner made ATOMIC a set of independent bipartite\ngraphs, which ignored the numerous missing links between events in different\nbipartite graphs and consequently caused shortcomings in knowledge coverage and\nmulti-hop reasoning. To address these issues, we propose a CSKG completion\napproach by training a relation prediction model based on a set of existing\ntriplets, and infer the missing links on ATOMIC. On this basis, we construct\nDense-ATOMIC, a densely-connected and multi-hop commonsense knowledge graph.\nThe experimental results on an annotated dense subgraph demonstrate the\neffectiveness of our CSKG completion approach upon ATOMIC. The evaluation on a\ndownstream commonsense reasoning task also proves the advantage of Dense-ATOMIC\nagainst conventional ATOMIC.",
    "descriptor": "",
    "authors": [
      "Xiangqing Shen",
      "Siwei Wu",
      "Rui Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07621"
  },
  {
    "id": "arXiv:2210.07626",
    "title": "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for  Text Generation",
    "abstract": "Automatic evaluation metrics are crucial to the development of generative\nsystems. In recent years, pre-trained language model (PLM) based metrics, such\nas BERTScore, have been commonly adopted in various generation tasks. However,\nit has been demonstrated that PLMs encode a range of stereotypical societal\nbiases, leading to a concern on the fairness of PLMs as metrics. To that end,\nthis work presents the first systematic study on the social bias in PLM-based\nmetrics. We demonstrate that popular PLM-based metrics exhibit significantly\nhigher social bias than traditional metrics on 6 sensitive attributes, namely\nrace, gender, religion, physical appearance, age, and socioeconomic status.\nIn-depth analysis suggests that choosing paradigms (matching, regression, or\ngeneration) of the metric has a greater impact on fairness than choosing PLMs.\nIn addition, we develop debiasing adapters that are injected into PLM layers,\nmitigating bias in PLM-based metrics while retaining high performance for\nevaluating text generation.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (main conference). Data and code are available at this https URL\n",
    "authors": [
      "Tianxiang Sun",
      "Junliang He",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07626"
  },
  {
    "id": "arXiv:2210.07630",
    "title": "The Invariant Ground Truth of Affect",
    "abstract": "Affective computing strives to unveil the unknown relationship between affect\nelicitation, manifestation of affect and affect annotations. The ground truth\nof affect, however, is predominately attributed to the affect labels which\ninadvertently include biases inherent to the subjective nature of emotion and\nits labeling. The response to such limitations is usually augmenting the\ndataset with more annotations per data point; however, this is not possible\nwhen we are interested in self-reports via first-person annotation. Moreover,\noutlier detection methods based on inter-annotator agreement only consider the\nannotations themselves and ignore the context and the corresponding affect\nmanifestation. This paper reframes the ways one may obtain a reliable ground\ntruth of affect by transferring aspects of causation theory to affective\ncomputing. In particular, we assume that the ground truth of affect can be\nfound in the causal relationships between elicitation, manifestation and\nannotation that remain \\emph{invariant} across tasks and participants. To test\nour assumption we employ causation inspired methods for detecting outliers in\naffective corpora and building affect models that are robust across\nparticipants and tasks. We validate our methodology within the domain of\ndigital games, with experimental results showing that it can successfully\ndetect outliers and boost the accuracy of affect models. To the best of our\nknowledge, this study presents the first attempt to integrate causation tools\nin affective computing, making a crucial and decisive step towards general\naffect modeling.",
    "descriptor": "\nComments: 8 pages, accepted for publication and presentation at 2022 10th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)\n",
    "authors": [
      "Konstantinos Makantasis",
      "Kosmas Pinitas",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07630"
  },
  {
    "id": "arXiv:2210.07631",
    "title": "Hardness of Samples Need to be Quantified for a Reliable Evaluation  System: Exploring Potential Opportunities with a New Task",
    "abstract": "Evaluation of models on benchmarks is unreliable without knowing the degree\nof sample hardness; this subsequently overestimates the capability of AI\nsystems and limits their adoption in real world applications. We propose a Data\nScoring task that requires assignment of each unannotated sample in a benchmark\na score between 0 to 1, where 0 signifies easy and 1 signifies hard. Use of\nunannotated samples in our task design is inspired from humans who can\ndetermine a question difficulty without knowing its correct answer. This also\nrules out the use of methods involving model based supervision (since they\nrequire sample annotations to get trained), eliminating potential biases\nassociated with models in deciding sample difficulty. We propose a method based\non Semantic Textual Similarity (STS) for this task; we validate our method by\nshowing that existing models are more accurate with respect to the easier\nsample-chunks than with respect to the harder sample-chunks. Finally we\ndemonstrate five novel applications.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.06898\n",
    "authors": [
      "Swaroop Mishra",
      "Anjana Arunkumar",
      "Chris Bryan",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07631"
  },
  {
    "id": "arXiv:2210.07632",
    "title": "Stability of Decentralized Queueing Networks Beyond Complete Bipartite  Cases",
    "abstract": "Gaitonde and Tardos recently studied a model of queueing networks where\nqueues compete for servers and re-send returned packets in future rounds. They\nquantify the amount of additional processing power that guarantees a\ndecentralized system's stability, both when the queues adapt their strategies\nfrom round to round using no-regret learning algorithms, and when they are\npatient and evaluate the utility of a strategy over long periods of time. In\nthis paper, we generalize Gaitonde and Tardos's model and consider scenarios\nwhere not all servers can serve all queues (i.e., the underlying graph is an\nincomplete bipartite graphs) and, further, when packets need to go through more\nthan one layer of servers before their completions (i.e., when the underlying\ngraph is a DAG). For the bipartite case, we obtain bounds comparable to those\nby Gaitonde and Tardos, with the factor slightly worse in the patient queueing\nmodel. For the more general multi-layer systems, we show that straightforward\ngeneralizations of the utility function and servers' priority rules in Gaitonde\nand Tardos's model may lead to unbounded gaps between centralized and\ndecentralized systems when the queues use no regret strategies. We define a new\nutility and a service priority rule that are aware of the queue lengths, and\nshow that these suffice to restore the bounded gap between centralized and\ndecentralized systems observed in bipartite graphs.",
    "descriptor": "\nComments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)\n",
    "authors": [
      "Hu Fu",
      "Qun Hu",
      "Jia'nan Lin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07632"
  },
  {
    "id": "arXiv:2210.07634",
    "title": "Pareto-aware Neural Architecture Generation for Diverse Computational  Budgets",
    "abstract": "Designing feasible and effective architectures under diverse computational\nbudgets, incurred by different applications/devices, is essential for deploying\ndeep models in real-world applications. To achieve this goal, existing methods\noften perform an independent architecture search process for each target\nbudget, which is very inefficient yet unnecessary. More critically, these\nindependent search processes cannot share their learned knowledge (i.e., the\ndistribution of good architectures) with each other and thus often result in\nlimited search results. To address these issues, we propose a Pareto-aware\nNeural Architecture Generator (PNAG) which only needs to be trained once and\ndynamically produces the Pareto optimal architecture for any given budget via\ninference. To train our PNAG, we learn the whole Pareto frontier by jointly\nfinding multiple Pareto optimal architectures under diverse budgets. Such a\njoint search algorithm not only greatly reduces the overall search cost but\nalso improves the search results. Extensive experiments on three hardware\nplatforms (i.e., mobile device, CPU, and GPU) show the superiority of our\nmethod over existing methods.",
    "descriptor": "\nComments: 11 pages, 7 figures, journal version\n",
    "authors": [
      "Yong Guo",
      "Yaofo Chen",
      "Yin Zheng",
      "Qi Chen",
      "Peilin Zhao",
      "Jian Chen",
      "Junzhou Huang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07634"
  },
  {
    "id": "arXiv:2210.07636",
    "title": "Distributional Reward Estimation for Effective Multi-Agent Deep  Reinforcement Learning",
    "abstract": "Multi-agent reinforcement learning has drawn increasing attention in\npractice, e.g., robotics and automatic driving, as it can explore optimal\npolicies using samples generated by interacting with the environment. However,\nhigh reward uncertainty still remains a problem when we want to train a\nsatisfactory model, because obtaining high-quality reward feedback is usually\nexpensive and even infeasible. To handle this issue, previous methods mainly\nfocus on passive reward correction. At the same time, recent active reward\nestimation methods have proven to be a recipe for reducing the effect of reward\nuncertainty. In this paper, we propose a novel Distributional Reward Estimation\nframework for effective Multi-Agent Reinforcement Learning (DRE-MARL). Our main\nidea is to design the multi-action-branch reward estimation and policy-weighted\nreward aggregation for stabilized training. Specifically, we design the\nmulti-action-branch reward estimation to model reward distributions on all\naction branches. Then we utilize reward aggregation to obtain stable updating\nsignals during training. Our intuition is that consideration of all possible\nconsequences of actions could be useful for learning policies. The superiority\nof the DRE-MARL is demonstrated using benchmark multi-agent scenarios, compared\nwith the SOTA baselines in terms of both effectiveness and robustness.",
    "descriptor": "",
    "authors": [
      "Jifeng Hu",
      "Yanchao Sun",
      "Hechang Chen",
      "Sili Huang",
      "haiyin piao",
      "Yi Chang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.07636"
  },
  {
    "id": "arXiv:2210.07639",
    "title": "Parallel solutions for ordinal scheduling with a small number of  machines",
    "abstract": "We study ordinal makespan scheduling on small numbers of identical machines,\nwith respect to two parallel solutions. In ordinal scheduling, it is known that\njobs are sorted by non-increasing sizes, but the specific sizes are not known\nin advance. For problems with two parallel solutions, it is required to design\ntwo solutions, and the performance of algorithm is tested for each input using\nthe best solution of the two. We find tight results for makespan minimization\non two and three machines, and algorithms that have strictly better competitive\nratios than the best possible algorithm with a single solution also for four\nand five machines. To prove upper bounds, we use a new approach of considering\npairs of machines from the two solutions.",
    "descriptor": "",
    "authors": [
      "Leah Epstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.07639"
  },
  {
    "id": "arXiv:2210.07642",
    "title": "Training speech emotion classifier without categorical annotations",
    "abstract": "There are two paradigms of emotion representation, categorical labeling and\ndimensional description in continuous space. Therefore, the emotion recognition\ntask can be treated as a classification or regression. The main aim of this\nstudy is to investigate the relation between these two representations and\npropose a classification pipeline that uses only dimensional annotation. The\nproposed approach contains a regressor model which is trained to predict a\nvector of continuous values in dimensional representation for given speech\naudio. The output of this model can be interpreted as an emotional category\nusing a mapping algorithm. We investigated the performances of a combination of\nthree feature extractors, three neural network architectures, and three mapping\nalgorithms on two different corpora. Our study shows the advantages and\nlimitations of the classification via regression approach.",
    "descriptor": "",
    "authors": [
      "Meysam Shamsi",
      "Marie Tahon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07642"
  },
  {
    "id": "arXiv:2210.07646",
    "title": "Vision Transformer Visualization: What Neurons Tell and How Neurons  Behave?",
    "abstract": "Recently vision transformers (ViT) have been applied successfully for various\ntasks in computer vision. However, important questions such as why they work or\nhow they behave still remain largely unknown. In this paper, we propose an\neffective visualization technique, to assist us in exposing the information\ncarried in neurons and feature embeddings across the ViT's layers. Our approach\ndeparts from the computational process of ViTs with a focus on visualizing the\nlocal and global information in input images and the latent feature embeddings\nat multiple levels. Visualizations at the input and embeddings at level 0\nreveal interesting findings such as providing support as to why ViTs are rather\ngenerally robust to image occlusions and patch shuffling; or unlike CNNs, level\n0 embeddings already carry rich semantic details. Next, we develop a rigorous\nframework to perform effective visualizations across layers, exposing the\neffects of ViTs filters and grouping/clustering behaviors to object patches.\nFinally, we provide comprehensive experiments on real datasets to qualitatively\nand quantitatively demonstrate the merit of our proposed methods as well as our\nfindings. https://github.com/byM1902/ViT_visualization",
    "descriptor": "",
    "authors": [
      "Van-Anh Nguyen",
      "Khanh Pham Dinh",
      "Long Tung Vuong",
      "Thanh-Toan Do",
      "Quan Hung Tran",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07646"
  },
  {
    "id": "arXiv:2210.07648",
    "title": "Machine Learning in Transaction Monitoring: The Prospect of xAI",
    "abstract": "Banks hold a societal responsibility and regulatory requirements to mitigate\nthe risk of financial crimes. Risk mitigation primarily happens through\nmonitoring customer activity through Transaction Monitoring (TM). Recently,\nMachine Learning (ML) has been proposed to identify suspicious customer\nbehavior, which raises complex socio-technical implications around trust and\nexplainability of ML models and their outputs. However, little research is\navailable due to its sensitivity. We aim to fill this gap by presenting\nempirical research exploring how ML supported automation and augmentation\naffects the TM process and stakeholders' requirements for building eXplainable\nArtificial Intelligence (xAI). Our study finds that xAI requirements depend on\nthe liable party in the TM process which changes depending on augmentation or\nautomation of TM. Context-relatable explanations can provide much-needed\nsupport for auditing and may diminish bias in the investigator's judgement.\nThese results suggest a use case-specific approach for xAI to adequately foster\nthe adoption of ML in TM.",
    "descriptor": "\nComments: 10 pages, HICSS56 proceedings\n",
    "authors": [
      "Julie Gerlings",
      "Ioanna Constantiou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07648"
  },
  {
    "id": "arXiv:2210.07650",
    "title": "DART: Articulated Hand Model with Diverse Accessories and Rich Textures",
    "abstract": "Hand, the bearer of human productivity and intelligence, is receiving much\nattention due to the recent fever of digital twins. Among different hand\nmorphable models, MANO has been widely used in vision and graphics community.\nHowever, MANO disregards textures and accessories, which largely limits its\npower to synthesize photorealistic hand data. In this paper, we extend MANO\nwith Diverse Accessories and Rich Textures, namely DART. DART is composed of 50\ndaily 3D accessories which varies in appearance and shape, and 325 hand-crafted\n2D texture maps covers different kinds of blemishes or make-ups. Unity GUI is\nalso provided to generate synthetic hand data with user-defined settings, e.g.,\npose, camera, background, lighting, textures, and accessories. Finally, we\nrelease DARTset, which contains large-scale (800K), high-fidelity synthetic\nhand images, paired with perfect-aligned 3D labels. Experiments demonstrate its\nsuperiority in diversity. As a complement to existing hand datasets, DARTset\nboosts the generalization in both hand pose estimation and mesh recovery tasks.\nRaw ingredients (textures, accessories), Unity GUI, source code and DARTset are\npublicly available at dart2022.github.io",
    "descriptor": "\nComments: Homepage: dart2022.github.io. Accepted by NeurIPS 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Daiheng Gao",
      "Yuliang Xiu",
      "Kailin Li",
      "Lixin Yang",
      "Feng Wang",
      "Peng Zhang",
      "Bang Zhang",
      "Cewu Lu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.07650"
  },
  {
    "id": "arXiv:2210.07651",
    "title": "Decentralized Policy Gradient for Nash Equilibria Learning of  General-sum Stochastic Games",
    "abstract": "We study Nash equilibria learning of a general-sum stochastic game with an\nunknown transition probability density function. Agents take actions at the\ncurrent environment state and their joint action influences the transition of\nthe environment state and their immediate rewards. Each agent only observes the\nenvironment state and its own immediate reward and is unknown about the actions\nor immediate rewards of others. We introduce the concepts of weighted\nasymptotic Nash equilibrium with probability 1 and in probability. For the case\nwith exact pseudo gradients, we design a two-loop algorithm by the equivalence\nof Nash equilibrium and variational inequality problems. In the outer loop, we\nsequentially update a constructed strongly monotone variational inequality by\nupdating a proximal parameter while employing a single-call extra-gradient\nalgorithm in the inner loop for solving the constructed variational inequality.\nWe show that if the associated Minty variational inequality has a solution,\nthen the designed algorithm converges to the k^{1/2}-weighted asymptotic Nash\nequilibrium. Further, for the case with unknown pseudo gradients, we propose a\ndecentralized algorithm, where the G(PO)MDP gradient estimator of the pseudo\ngradient is provided by Monte-Carlo simulations. The convergence to the k^{1/4}\n-weighted asymptotic Nash equilibrium in probability is achieved.",
    "descriptor": "",
    "authors": [
      "Yan Chen",
      "Tao Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.07651"
  },
  {
    "id": "arXiv:2210.07652",
    "title": "Enabling Classifiers to Make Judgements Explicitly Aligned with Human  Values",
    "abstract": "Many NLP classification tasks, such as sexism/racism detection or toxicity\ndetection, are based on human values. Yet, human values can vary under diverse\ncultural conditions. Therefore, we introduce a framework for value-aligned\nclassification that performs prediction based on explicitly written human\nvalues in the command. Along with the task, we propose a practical approach\nthat distills value-aligned knowledge from large-scale language models (LLMs)\nto construct value-aligned classifiers in two steps. First, we generate\nvalue-aligned training data from LLMs by prompt-based few-shot learning. Next,\nwe fine-tune smaller classification models with the generated data for the\ntask. Empirical results show that our VA-Models surpass multiple baselines by\nat least 15.56% on the F1-score, including few-shot learning with OPT-175B and\nexisting text augmentation methods. We suggest that using classifiers with\nexplicit human value input improves both inclusivity & explainability in AI.",
    "descriptor": "",
    "authors": [
      "Yejin Bang",
      "Tiezheng Yu",
      "Andrea Madotto",
      "Zhaojiang Lin",
      "Mona Diab",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07652"
  },
  {
    "id": "arXiv:2210.07653",
    "title": "A Non-iterative Spatio-temporal Multi-task Assignments based  Collision-free Trajectories for Music Playing Robots",
    "abstract": "In this paper, a non-iterative spatio-temporal multi-task assignment approach\nis used for playing the piano music by a team of robots. This paper considers\nthe piano playing problem, in which an algorithm needs to compute the\ntrajectories for a dynamically sized team of robots who will play the musical\nnotes by traveling through the specific locations associated with musical notes\nat their respective specific times. A two-step dynamic resource allocation\nbased on a spatio-temporal multi-task assignment problem (DREAM), has been\nimplemented to assign robots for playing the musical tune. The algorithm\ncomputes the required number of robots to play the music in the first step. In\nthe second step, optimal assignments are computed for the updated team of\nrobots, which minimizes the total distance traveled by the team. Furthermore,\nif robots are operating in Euclidean space, then the solution of DREAM approach\nprovides collision-free trajectories, and the same has been proven. The working\nof DREAM approach has been illustrated with the help of the high fidelity\nsimulations in Gazebo operated using ROS2. The result clearly shows that the\nDREAM approach computes the required number of robots and assigns multiple\ntasks to robots in at most two step. The simulation of the robots playing\nmusic, using computed assignments, is demonstrated in the attached video. video\nlink: \\url{https://youtu.be/XToicNm-CO8}",
    "descriptor": "",
    "authors": [
      "Shridhar Velhal",
      "Krishna Kishore VS",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07653"
  },
  {
    "id": "arXiv:2210.07654",
    "title": "Towards Transformer-based Homogenization of Satellite Imagery for  Landsat-8 and Sentinel-2",
    "abstract": "Landsat-8 (NASA) and Sentinel-2 (ESA) are two prominent multi-spectral\nimaging satellite projects that provide publicly available data. The\nmulti-spectral imaging sensors of the satellites capture images of the earth's\nsurface in the visible and infrared region of the electromagnetic spectrum.\nSince the majority of the earth's surface is constantly covered with clouds,\nwhich are not transparent at these wavelengths, many images do not provide much\ninformation. To increase the temporal availability of cloud-free images of a\ncertain area, one can combine the observations from multiple sources. However,\nthe sensors of satellites might differ in their properties, making the images\nincompatible. This work provides a first glance at the possibility of using a\ntransformer-based model to reduce the spectral and spatial differences between\nobservations from both satellite projects. We compare the results to a model\nbased on a fully convolutional UNet architecture. Somewhat surprisingly, we\nfind that, while deep models outperform classical approaches, the UNet\nsignificantly outperforms the transformer in our experiments.",
    "descriptor": "",
    "authors": [
      "Venkatesh Thirugnana Sambandham",
      "Konstantin Kirchheim",
      "Sayan Mukhopadhaya",
      "Frank Ortmeier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.07654"
  },
  {
    "id": "arXiv:2210.07658",
    "title": "Abstract-to-Executable Trajectory Translation for One-Shot Task  Generalization",
    "abstract": "Training long-horizon robotic policies in complex physical environments is\nessential for many applications, such as robotic manipulation. However,\nlearning a policy that can generalize to unseen tasks is challenging. In this\nwork, we propose to achieve one-shot task generalization by decoupling plan\ngeneration and plan execution. Specifically, our method solves complex\nlong-horizon tasks in three steps: build a paired abstract environment by\nsimplifying geometry and physics, generate abstract trajectories, and solve the\noriginal task by an abstract-to-executable trajectory translator. In the\nabstract environment, complex dynamics such as physical manipulation are\nremoved, making abstract trajectories easier to generate. However, this\nintroduces a large domain gap between abstract trajectories and the actual\nexecuted trajectories as abstract trajectories lack low-level details and are\nnot aligned frame-to-frame with the executed trajectory. In a manner\nreminiscent of language translation, our approach leverages a seq-to-seq model\nto overcome the large domain gap between the abstract and executable\ntrajectories, enabling the low-level policy to follow the abstract trajectory.\nExperimental results on various unseen long-horizon tasks with different robot\nembodiments demonstrate the practicability of our methods to achieve one-shot\ntask generalization.",
    "descriptor": "\nComments: Code and visualizations: this https URL\n",
    "authors": [
      "Stone Tao",
      "Xiaochen Li",
      "Tongzhou Mu",
      "Zhiao Huang",
      "Yuzhe Qin",
      "Hao Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07658"
  },
  {
    "id": "arXiv:2210.07659",
    "title": "Automated dysgraphia detection by deep learning with SensoGrip",
    "abstract": "Dysgraphia, a handwriting learning disability, has a serious negative impact\non children's academic results, daily life and overall wellbeing. Early\ndetection of dysgraphia allows for an early start of a targeted intervention.\nSeveral studies have investigated dysgraphia detection by machine learning\nalgorithms using a digital tablet. However, these studies deployed classical\nmachine learning algorithms with manual feature extraction and selection as\nwell as binary classification: either dysgraphia or no dysgraphia. In this\nwork, we investigated fine grading of handwriting capabilities by predicting\nSEMS score (between 0 and 12) with deep learning. Our approach provide accuracy\nmore than 99% and root mean square error lower than one, with automatic instead\nof manual feature extraction and selection. Furthermore, we used smart pen\ncalled SensoGrip, a pen equipped with sensors to capture handwriting dynamics,\ninstead of a tablet, enabling writing evaluation in more realistic scenarios.",
    "descriptor": "",
    "authors": [
      "Mugdim Bublin",
      "Franz Werner",
      "Andrea Kerschbaumer",
      "Gernot Korak",
      "Sebastian Geyer",
      "Lena Rettinger",
      "Erna Schoenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07659"
  },
  {
    "id": "arXiv:2210.07660",
    "title": "MV-HAN: A Hybrid Attentive Networks based Multi-View Learning Model for  Large-scale Contents Recommendation",
    "abstract": "Industrial recommender systems usually employ multi-source data to improve\nthe recommendation quality, while effectively sharing information between\ndifferent data sources remain a challenge. In this paper, we introduce a novel\nMulti-View Approach with Hybrid Attentive Networks (MV-HAN) for contents\nretrieval at the matching stage of recommender systems. The proposed model\nenables high-order feature interaction from various input features while\neffectively transferring knowledge between different types. By employing a\nwell-placed parameters sharing strategy, the MV-HAN substantially improves the\nretrieval performance in sparse types. The designed MV-HAN inherits the\nefficiency advantages in the online service from the two-tower model, by\nmapping users and contents of different types into the same features space.\nThis enables fast retrieval of similar contents with an approximate nearest\nneighbor algorithm. We conduct offline experiments on several industrial\ndatasets, demonstrating that the proposed MV-HAN significantly outperforms\nbaselines on the content retrieval tasks. Importantly, the MV-HAN is deployed\nin a real-world matching system. Online A/B test results show that the proposed\nmethod can significantly improve the quality of recommendations.",
    "descriptor": "\nComments: accepted by ASE 2022\n",
    "authors": [
      "Ge Fan",
      "Chaoyun Zhang",
      "Kai Wang",
      "Junyang Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.07660"
  },
  {
    "id": "arXiv:2210.07661",
    "title": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
    "abstract": "Transformer has achieved remarkable success in language, image, and speech\nprocessing. Recently, various efficient attention architectures have been\nproposed to improve transformer's efficiency while largely preserving its\nefficacy, especially in modeling long sequences. A widely-used benchmark to\ntest these efficient methods' capability on long-range modeling is Long Range\nArena (LRA). However, LRA only focuses on the standard bidirectional (or\nnoncausal) self attention, and completely ignores cross attentions and\nunidirectional (or causal) attentions, which are equally important to\ndownstream applications. Although designing cross and causal variants of an\nattention method is straightforward for vanilla attention, it is often\nchallenging for efficient attentions with subquadratic time and memory\ncomplexity. In this paper, we propose Comprehensive Attention Benchmark (CAB)\nunder a fine-grained attention taxonomy with four distinguishable attention\npatterns, namely, noncausal self, causal self, noncausal cross, and causal\ncross attentions. CAB collects seven real-world tasks from different research\nareas to evaluate efficient attentions under the four attention patterns. Among\nthese tasks, CAB validates efficient attentions in eight backbone networks to\nshow their generalization across neural architectures. We conduct exhaustive\nexperiments to benchmark the performances of nine widely-used efficient\nattention architectures designed with different philosophies on CAB. Extensive\nexperimental results also shed light on the fundamental problems of efficient\nattentions, such as efficiency length against vanilla attention, performance\nconsistency across attention patterns, the benefit of attention mechanisms, and\ninterpolation/extrapolation on long-context language modeling.",
    "descriptor": "",
    "authors": [
      "Jun Zhang",
      "Shuyang Jiang",
      "Jiangtao Feng",
      "Lin Zheng",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07661"
  },
  {
    "id": "arXiv:2210.07663",
    "title": "Pretrained Transformers Do not Always Improve Robustness",
    "abstract": "Pretrained Transformers (PT) have been shown to improve Out of Distribution\n(OOD) robustness than traditional models such as Bag of Words (BOW), LSTMs,\nConvolutional Neural Networks (CNN) powered by Word2Vec and Glove embeddings.\nHow does the robustness comparison hold in a real world setting where some part\nof the dataset can be noisy? Do PT also provide more robust representation than\ntraditional models on exposure to noisy data? We perform a comparative study on\n10 models and find an empirical evidence that PT provide less robust\nrepresentation than traditional models on exposure to noisy data. We\ninvestigate further and augment PT with an adversarial filtering (AF) mechanism\nthat has been shown to improve OOD generalization. However, increase in\ngeneralization does not necessarily increase robustness, as we find that noisy\ndata fools the AF method powered by PT.",
    "descriptor": "",
    "authors": [
      "Swaroop Mishra",
      "Bhavdeep Singh Sachdeva",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07663"
  },
  {
    "id": "arXiv:2210.07666",
    "title": "A Location-Based Global Authorization Method for Underwater Security",
    "abstract": "National or international maritime authorities are used to handle requests\nfor licenses for all kinds of marine activities. These licenses constitute\nauthorizations limited in time and space, but there is no technical security\nservice to check for the authorization of a wide range of marine assets. We\nhave noted secure AIS solutions suitable for more or less constantly\ninternet-connected assets such as ships with satellite connections. The\nadditional constraints posed by underwater autonomous assets, namely less power\nand connectivity, can be mitigated by using symmetric cryptography. We propose\na security service that allows the automatized check of asset authorization\nstatus based on large symmetric keys. Key generation can take place at a\ncentral authority according to the time and space limitations of a license,\ni.e. timestamped and geocoded. Our solution harnesses the exceptionally large\nkey size of the RC5 cipher and the standardized encoding of geocells in the\nOpen Location Code system. While we developed and described our solution for\noffshore underwater use, aerial and terrestrial environments could also make\nuse of it if they are similarly bandwidth constrained or want to rely on\nquantum-resistant and computationally economic symmetric methods.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "B\u00e1lint Z. T\u00e9gl\u00e1sy",
      "Sokratis Katsikas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07666"
  },
  {
    "id": "arXiv:2210.07667",
    "title": "A $\u03bc$-mode approach for exponential integrators: actions of  $\\varphi$-functions of Kronecker sums",
    "abstract": "We present a novel method for computing actions of the so-called\n$\\varphi$-functions for a Kronecker sum $K$ of $d$ arbitrary matrices $A_\\mu$.\nIt is based on the approximation of the integral representation of the\n$\\varphi$-functions by Gaussian quadrature formulas combined with a scaling and\nsquaring technique. The resulting algorithm, which we call PHIKS, evaluates the\nrequired actions by means of $\\mu$-mode products involving exponentials of the\nsmall sized matrices $A_\\mu$, without using the large sized matrix $K$ itself.\nPHIKS, which profits from the highly efficient level 3 BLAS, is designed to\ncompute different $\\varphi$-functions applied on the same vector or a linear\ncombination of actions of $\\varphi$-functions applied on different vectors. In\naddition, due to the underlying scaling and squaring technique, the desired\nquantities are available simultaneously at suitable time scales. All these\nfeatures allow the effective usage of PHIKS in the exponential integration\ncontext. In particular, we tested our newly designed method on popular\nexponential Runge-Kutta integrators of stiff order from one to four, in\ncomparison with state-of-the-art algorithms for computing actions of\n$\\varphi$-functions. Our numerical experiments with discretized semilinear\nevolutionary 2D or 3D advection-diffusion-reaction, Allen-Cahn, and Brusselator\nequations show the superiority of the $\\mu$-mode approach of PHIKS.",
    "descriptor": "",
    "authors": [
      "Marco Caliari",
      "Fabio Cassini",
      "Franco Zivcovich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07667"
  },
  {
    "id": "arXiv:2210.07670",
    "title": "Multi-View Photometric Stereo Revisited",
    "abstract": "Multi-view photometric stereo (MVPS) is a preferred method for detailed and\nprecise 3D acquisition of an object from images. Although popular methods for\nMVPS can provide outstanding results, they are often complex to execute and\nlimited to isotropic material objects. To address such limitations, we present\na simple, practical approach to MVPS, which works well for isotropic as well as\nother object material types such as anisotropic and glossy. The proposed\napproach in this paper exploits the benefit of uncertainty modeling in a deep\nneural network for a reliable fusion of photometric stereo (PS) and multi-view\nstereo (MVS) network predictions. Yet, contrary to the recently proposed\nstate-of-the-art, we introduce neural volume rendering methodology for a\ntrustworthy fusion of MVS and PS measurements. The advantage of introducing\nneural volume rendering is that it helps in the reliable modeling of objects\nwith diverse material types, where existing MVS methods, PS methods, or both\nmay fail. Furthermore, it allows us to work on neural 3D shape representation,\nwhich has recently shown outstanding results for many geometric processing\ntasks. Our suggested new loss function aims to fits the zero level set of the\nimplicit neural function using the most certain MVS and PS network predictions\ncoupled with weighted neural volume rendering cost. The proposed approach shows\nstate-of-the-art results when tested extensively on several benchmark datasets.",
    "descriptor": "\nComments: Accepted for publication at IEEE/CVF WACV 2023. Draft info: 10 pages, 5 figure, and 3 tables\n",
    "authors": [
      "Berk Kaya",
      "Suryansh Kumar",
      "Carlos Oliveira",
      "Vittorio Ferrari",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07670"
  },
  {
    "id": "arXiv:2210.07675",
    "title": "Learning image representations for anomaly detection: application to  discovery of histological alterations in drug development",
    "abstract": "We present a system for anomaly detection in histopathological images. In\nhistology, normal samples are usually abundant, whereas anomalous\n(pathological) cases are scarce or not available. Under such settings,\none-class classifiers trained on healthy data can detect out-of-distribution\nanomalous samples. Such approaches combined with pre-trained Convolutional\nNeural Network (CNN) representations of images were previously employed for\nanomaly detection (AD). However, pre-trained off-the-shelf CNN representations\nmay not be sensitive to abnormal conditions in tissues, while natural\nvariations of healthy tissue may result in distant representations. To adapt\nrepresentations to relevant details in healthy tissue we propose training a CNN\non an auxiliary task that discriminates healthy tissue of different species,\norgans, and staining reagents. Almost no additional labeling workload is\nrequired, since healthy samples come automatically with aforementioned labels.\nDuring training we enforce compact image representations with a center-loss\nterm, which further improves representations for AD. The proposed system\noutperforms established AD methods on a published dataset of liver anomalies.\nMoreover, it provided comparable results to conventional methods specifically\ntailored for quantification of liver anomalies. We show that our approach can\nbe used for toxicity assessment of candidate drugs at early development stages\nand thereby may reduce expensive late-stage drug attrition.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Igor Zingman",
      "Birgit Stierstorfer",
      "Charlotte Lempp",
      "Fabian Heinemann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07675"
  },
  {
    "id": "arXiv:2210.07681",
    "title": "Quo Vadis: Is Trajectory Forecasting the Key Towards Long-Term  Multi-Object Tracking?",
    "abstract": "Recent developments in monocular multi-object tracking have been very\nsuccessful in tracking visible objects and bridging short occlusion gaps,\nmainly relying on data-driven appearance models. While we have significantly\nadvanced short-term tracking performance, bridging longer occlusion gaps\nremains elusive: state-of-the-art object trackers only bridge less than 10% of\nocclusions longer than three seconds. We suggest that the missing key is\nreasoning about future trajectories over a longer time horizon. Intuitively,\nthe longer the occlusion gap, the larger the search space for possible\nassociations. In this paper, we show that even a small yet diverse set of\ntrajectory predictions for moving agents will significantly reduce this search\nspace and thus improve long-term tracking robustness. Our experiments suggest\nthat the crucial components of our approach are reasoning in a bird's-eye view\nspace and generating a small yet diverse set of forecasts while accounting for\ntheir localization uncertainty. This way, we can advance state-of-the-art\ntrackers on the MOTChallenge dataset and significantly improve their long-term\ntracking performance. This paper's source code and experimental data are\navailable at https://github.com/dendorferpatrick/QuoVadis.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Patrick Dendorfer",
      "Vladimir Yugay",
      "Aljo\u0161a O\u0161ep",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07681"
  },
  {
    "id": "arXiv:2210.07685",
    "title": "Full-Stack Bioacoustics: Field Kit to AI to Action (Workshop report)",
    "abstract": "Acoustic data (sound recordings) are a vital source of evidence for\ndetecting, counting, and distinguishing wildlife. This domain of \"bioacoustics\"\nhas grown in the past decade due to the massive advances in signal processing\nand machine learning, recording devices, and the capacity of data processing\nand storage. Numerous research papers describe the use of Raspberry Pi or\nsimilar devices for acoustic monitoring, and other research papers describe\nautomatic classification of animal sounds by machine learning. But for most\necologists, zoologists, conservationists, the pieces of the puzzle do not come\ntogether: the domain is fragmented. In this Lorentz workshop we bridge this gap\nby bringing together leading exponents of open hardware and open-source\nsoftware for bioacoustic monitoring and machine learning, as well as ecologists\nand other field researchers. We share skills while also building a vision for\nthe future development of \"bioacoustic AI\".\nThis report contains an overview of the workshop aims and structure, as well\nas reports from the six groups.",
    "descriptor": "\nComments: Workshop report: Lorentz Center, Leiden, the Netherlands, 1-5 August 2022\n",
    "authors": [
      "Dan Stowell",
      "Caitlin Black",
      "Florencia Noriega",
      "Sarab S. Sethi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07685"
  },
  {
    "id": "arXiv:2210.07686",
    "title": "Learning Generalizable Models for Vehicle Routing Problems via Knowledge  Distillation",
    "abstract": "Recent neural methods for vehicle routing problems always train and test the\ndeep models on the same instance distribution (i.e., uniform). To tackle the\nconsequent cross-distribution generalization concerns, we bring the knowledge\ndistillation to this field and propose an Adaptive Multi-Distribution Knowledge\nDistillation (AMDKD) scheme for learning more generalizable deep models.\nParticularly, our AMDKD leverages various knowledge from multiple teachers\ntrained on exemplar distributions to yield a light-weight yet generalist\nstudent model. Meanwhile, we equip AMDKD with an adaptive strategy that allows\nthe student to concentrate on difficult distributions, so as to absorb\nhard-to-master knowledge more effectively. Extensive experimental results show\nthat, compared with the baseline neural methods, our AMDKD is able to achieve\ncompetitive results on both unseen in-distribution and out-of-distribution\ninstances, which are either randomly synthesized or adopted from benchmark\ndatasets (i.e., TSPLIB and CVRPLIB). Notably, our AMDKD is generic, and\nconsumes less computational resources for inference.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Jieyi Bi",
      "Yining Ma",
      "Jiahai Wang",
      "Zhiguang Cao",
      "Jinbiao Chen",
      "Yuan Sun",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07686"
  },
  {
    "id": "arXiv:2210.07688",
    "title": "Plausible May Not Be Faithful: Probing Object Hallucination in  Vision-Language Pre-training",
    "abstract": "Large-scale vision-language pre-trained (VLP) models are prone to hallucinate\nnon-existent visual objects when generating text based on visual information.\nIn this paper, we exhaustively probe the object hallucination problem from\nthree aspects. First, we examine various state-of-the-art VLP models, showing\nthat models achieving better scores on standard metrics(e.g., BLEU-4, CIDEr)\ncould hallucinate objects more frequently. Second, we investigate how different\ntypes of visual features in VLP influence hallucination, including\nregion-based, grid-based, and patch-based. Surprisingly, we find that\npatch-based features perform the best and smaller patch resolution yields a\nnon-trivial reduction in object hallucination. Third, we decouple various VLP\nobjectives and demonstrate their effectiveness in alleviating object\nhallucination. Based on that, we propose a new pre-training loss, object masked\nlanguage modeling, to further reduce object hallucination. We evaluate models\non both COCO (in-domain) and NoCaps (out-of-domain) datasets with our improved\nCHAIR metric. Furthermore, we investigate the effects of various text decoding\nstrategies and image augmentation methods on object hallucination.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Wenliang Dai",
      "Zihan Liu",
      "Ziwei Ji",
      "Dan Su",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07688"
  },
  {
    "id": "arXiv:2210.07689",
    "title": "Computational Design of Active Kinesthetic Garments",
    "abstract": "Garments with the ability to provide kinesthetic force-feedback on-demand can\naugment human capabilities in a non-obtrusive way, enabling numerous\napplications in VR haptics, motion assistance, and robotic control. However,\ndesigning such garments is a complex, and often manual task, particularly when\nthe goal is to resist multiple motions with a single design. In this work, we\npropose a computational pipeline for designing connecting structures between\nactive components - one of the central challenges in this context. We focus on\nelectrostatic (ES) clutches that are compliant in their passive state while\nstrongly resisting elongation when activated. Our method automatically computes\noptimized connecting structures that efficiently resist a range of pre-defined\nbody motions on demand. We propose a novel dual-objective optimization approach\nto simultaneously maximize the resistance to motion when clutches are active,\nwhile minimizing resistance when inactive. We demonstrate our method on a set\nof problems involving different body sites and a range of motions. We further\nfabricate and evaluate a subset of our automatically created designs against\nmanually created baselines using mechanical testing and in a VR pointing study.",
    "descriptor": "",
    "authors": [
      "Velko Vechev",
      "Ronan Hinchet",
      "Stelian Coros",
      "Bernhard Thomaszewski",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07689"
  },
  {
    "id": "arXiv:2210.07692",
    "title": "Accelerating RNN-based Speech Enhancement on a Multi-Core MCU with Mixed  FP16-INT8 Post-Training Quantization",
    "abstract": "This paper presents an optimized methodology to design and deploy Speech\nEnhancement (SE) algorithms based on Recurrent Neural Networks (RNNs) on a\nstate-of-the-art MicroController Unit (MCU), with 1+8 general-purpose RISC-V\ncores. To achieve low-latency execution, we propose an optimized software\npipeline interleaving parallel computation of LSTM or GRU recurrent blocks,\nfeaturing vectorized 8-bit integer (INT8) and 16-bit floating-point (FP16)\ncompute units, with manually-managed memory transfers of model parameters. To\nensure minimal accuracy degradation with respect to the full-precision models,\nwe propose a novel FP16-INT8 Mixed-Precision Post-Training Quantization (PTQ)\nscheme that compresses the recurrent layers to 8-bit while the bit precision of\nremaining layers is kept to FP16. Experiments are conducted on multiple LSTM\nand GRU based SE models trained on the Valentini dataset, featuring up to 1.24M\nparameters. Thanks to the proposed approaches, we speed-up the computation by\nup to 4x with respect to the lossless FP16 baselines. Differently from a\nuniform 8-bit quantization that degrades the PESQ score by 0.3 on average, the\nMixed-Precision PTQ scheme leads to a low-degradation of only 0.06, while\nachieving a 1.4-1.7x memory saving. Thanks to this compression, we cut the\npower cost of the external memory by fitting the large models on the limited\non-chip non-volatile memory and we gain a MCU power saving of up to 2.5x by\nreducing the supply voltage from 0.8V to 0.65V while still matching the\nreal-time constraints. Our design results 10x more energy efficient than\nstate-of-the-art SE solutions deployed on single-core MCUs that make use of\nsmaller models and quantization-aware training.",
    "descriptor": "\nComments: Accepted at the ITEM Workshop 2022 (located at ECML-PKDD2022)\n",
    "authors": [
      "Manuele Rusci",
      "Marco Fariselli",
      "Martin Croome",
      "Francesco Paci",
      "Eric Flamand"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07692"
  },
  {
    "id": "arXiv:2210.07693",
    "title": "Designing a general library for convolutions",
    "abstract": "We will discuss our experiences and design decisions obtained from building a\nformal library for the convolution of two functions. Convolution is a\nfundamental concept with applications throughout mathematics. We will focus on\nthe design decisions we made to make the convolution general and easy to use,\nand the incorporation of this development in Lean's mathematical library\nmathlib.",
    "descriptor": "\nComments: 24 pages, submitted to CPP 2023\n",
    "authors": [
      "Floris van Doorn"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Mathematical Software (cs.MS)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.07693"
  },
  {
    "id": "arXiv:2210.07695",
    "title": "Understanding Multi-link Operation in Wi-Fi 7: Performance, Anomalies,  and Solutions",
    "abstract": "Will Wi-Fi 7, conceived to support extremely high throughput, also deliver\nconsistently low delay? The best hope seems to lie in allowing next-generation\ndevices to access multiple channels via multi-link operation (MLO). In this\npaper, we aim to advance the understanding of MLO, placing the spotlight on its\npacket delay performance. We show that MLO devices can take advantage of\nmultiple contention-free links to significantly reduce their transmission time,\nbut also that they can occasionally starve one another and surprisingly incur a\nhigher delay than that of a well planned legacy single link operation. We next\nexamine and explain this anomaly, also putting forth practical workarounds to\ncircumvent it. We conclude by pointing to other disruptive features that, if\nsuccessfully paired with MLO, can usher in exciting and unprecedented\nopportunities for Wi-Fi 8.",
    "descriptor": "",
    "authors": [
      "Marc Carrascosa-Zamacois",
      "Giovanni Geraci",
      "Lorenzo Galati-Giordano",
      "Anders Jonsson",
      "Boris Bellalta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07695"
  },
  {
    "id": "arXiv:2210.07697",
    "title": "Multi-Task Learning based Video Anomaly Detection with Attention",
    "abstract": "Multi-task learning based video anomaly detection methods combine multiple\nproxy tasks in different branches to detect video anomalies in different\nsituations. Most existing methods either do not combine complementary tasks to\neffectively cover all motion patterns, or the class of the objects is not\nexplicitly considered. To address the aforementioned shortcomings, we propose a\nnovel multi-task learning based method that combines complementary proxy tasks\nto better consider the motion and appearance features. We combine the semantic\nsegmentation and future frame prediction tasks in a single branch to learn the\nobject class and consistent motion patterns, and to detect respective anomalies\nsimultaneously. In the second branch, we added several attention mechanisms to\ndetect motion anomalies with attention to object parts, the direction of\nmotion, and the distance of the objects from the camera. Our qualitative\nresults show that the proposed method considers the object class effectively\nand learns motion with attention to the aforementioned important factors which\nresults in a precise motion modeling and a better motion anomaly detection.\nAdditionally, quantitative results show the superiority of our method compared\nwith state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Mohammad Baradaran",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07697"
  },
  {
    "id": "arXiv:2210.07699",
    "title": "s-Club Cluster Vertex Deletion on Interval and Well-Partitioned Chordal  Graphs",
    "abstract": "In this paper, we study the computational complexity of \\textsc{$s$-Club\nCluster Vertex Deletion}. Given a graph, \\textsc{$s$-Club Cluster Vertex\nDeletion ($s$-CVD)} aims to delete the minimum number of vertices from the\ngraph so that each connected component of the resulting graph has a diameter at\nmost $s$. When $s=1$, the corresponding problem is popularly known as \\sloppy\n\\textsc{Cluster Vertex Deletion (CVD)}. We provide a faster algorithm for\n\\textsc{$s$-CVD} on \\emph{interval graphs}. For each $s\\geq 1$, we give an\n$O(n(n+m))$-time algorithm for \\textsc{$s$-CVD} on interval graphs with $n$\nvertices and $m$ edges. In the case of $s=1$, our algorithm is a slight\nimprovement over the $O(n^3)$-time algorithm of Cao \\etal (Theor. Comput. Sci.,\n2018) and for $s \\geq 2$, it significantly improves the state-of-the-art\nrunning time $\\left(O\\left(n^4\\right)\\right)$.\nWe also give a polynomial-time algorithm to solve \\textsc{CVD} on\n\\emph{well-partitioned chordal graphs}, a graph class introduced by Ahn \\etal\n(\\textsc{WG 2020}) as a tool for narrowing down complexity gaps for problems\nthat are hard on chordal graphs, and easy on split graphs. Our algorithm relies\non a characterisation of the optimal solution and on solving polynomially many\ninstances of the \\textsc{Weighted Bipartite Vertex Cover}. This generalises a\nresult of Cao \\etal (Theor. Comput. Sci., 2018) on split graphs.\nWe also show that for any even integer $s\\geq 2$, \\textsc{$s$-CVD} is NP-hard\non well-partitioned chordal graphs.",
    "descriptor": "",
    "authors": [
      "Dibyayan Chakraborty",
      "L. Sunil Chandran",
      "Sajith Padinhatteeri",
      "Raji. R. Pillai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.07699"
  },
  {
    "id": "arXiv:2210.07700",
    "title": "Language Generation Models Can Cause Harm: So What Can We Do About It?  An Actionable Survey",
    "abstract": "Recent advances in the capacity of large language models to generate\nhuman-like text have resulted in their increased adoption in user-facing\nsettings. In parallel, these improvements have prompted a heated discourse\naround the risks of societal harms they introduce, whether inadvertent or\nmalicious. Several studies have identified potential causes of these harms and\ncalled for their mitigation via development of safer and fairer models. Going\nbeyond enumerating the risks of harms, this work provides a survey of practical\nmethods for addressing potential threats and societal harms from language\ngeneration models. We draw on several prior works' taxonomies of language model\nrisks to present a structured overview of strategies for detecting and\nameliorating different kinds of risks/harms of language generators. Bridging\ndiverse strands of research, this survey aims to serve as a practical guide for\nboth LM researchers and practitioners with explanations of motivations behind\ndifferent mitigation strategies, their limitations, and open problems for\nfuture research.",
    "descriptor": "",
    "authors": [
      "Sachin Kumar",
      "Vidhisha Balachandran",
      "Lucille Njoo",
      "Antonios Anastasopoulos",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07700"
  },
  {
    "id": "arXiv:2210.07702",
    "title": "Theory and Approximate Solvers for Branched Optimal Transport with  Multiple Sources",
    "abstract": "Branched Optimal Transport (BOT) is a generalization of optimal transport in\nwhich transportation costs along an edge are subadditive. This subadditivity\nmodels an increase in transport efficiency when shipping mass along the same\nroute, favoring branched transportation networks. We here study the NP-hard\noptimization of BOT networks connecting a finite number of sources and sinks in\n$\\mathbb{R}^2$. First, we show how to efficiently find the best geometry of a\nBOT network for many sources and sinks, given a topology. Second, we argue that\na topology with more than three edges meeting at a branching point is never\noptimal. Third, we show that the results obtained for the Euclidean plane\ngeneralize directly to optimal transportation networks on two-dimensional\nRiemannian manifolds. Finally, we present a simple but effective approximate\nBOT solver combining geometric optimization with a combinatorial optimization\nof the network topology.",
    "descriptor": "\nComments: To be published in proceedings of NeurIPS 2022\n",
    "authors": [
      "Peter Lippmann",
      "Enrique Fita Sanmart\u00edn",
      "Fred A. Hamprecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.07702"
  },
  {
    "id": "arXiv:2210.07703",
    "title": "Hybrid Decentralized Optimization: First- and Zeroth-Order Optimizers  Can Be Jointly Leveraged For Faster Convergence",
    "abstract": "Distributed optimization has become one of the standard ways of speeding up\nmachine learning training, and most of the research in the area focuses on\ndistributed first-order, gradient-based methods. Yet, there are settings where\nsome computationally-bounded nodes may not be able to implement first-order,\ngradient-based optimization, while they could still contribute to joint\noptimization tasks. In this paper, we initiate the study of hybrid\ndecentralized optimization, studying settings where nodes with zeroth-order and\nfirst-order optimization capabilities co-exist in a distributed system, and\nattempt to jointly solve an optimization task over some data distribution. We\nessentially show that, under reasonable parameter settings, such a system can\nnot only withstand noisier zeroth-order agents but can even benefit from\nintegrating such agents into the optimization process, rather than ignoring\ntheir information. At the core of our approach is a new analysis of distributed\noptimization with noisy and possibly-biased gradient estimators, which may be\nof independent interest. Experimental results on standard optimization tasks\nconfirm our analysis, showing that hybrid first-zeroth order optimization can\nbe practical.",
    "descriptor": "",
    "authors": [
      "Shayan Talaei",
      "Giorgi Nadiradze",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07703"
  },
  {
    "id": "arXiv:2210.07707",
    "title": "Generative Adversarial Learning for Trusted and Secure Clustering in  Industrial Wireless Sensor Networks",
    "abstract": "Traditional machine learning techniques have been widely used to establish\nthe trust management systems. However, the scale of training dataset can\nsignificantly affect the security performances of the systems, while it is a\ngreat challenge to detect malicious nodes due to the absence of labeled data\nregarding novel attacks. To address this issue, this paper presents a\ngenerative adversarial network (GAN) based trust management mechanism for\nIndustrial Wireless Sensor Networks (IWSNs). First, type-2 fuzzy logic is\nadopted to evaluate the reputation of sensor nodes while alleviating the\nuncertainty problem. Then, trust vectors are collected to train a GAN-based\ncodec structure, which is used for further malicious node detection. Moreover,\nto avoid normal nodes being isolated from the network permanently due to error\ndetections, a GAN-based trust redemption model is constructed to enhance the\nresilience of trust management. Based on the latest detection results, a trust\nmodel update method is developed to adapt to the dynamic industrial\nenvironment. The proposed trust management mechanism is finally applied to\nsecure clustering for reliable and real-time data transmission, and simulation\nresults show that it achieves a high detection rate up to 96%, as well as a low\nfalse positive rate below 8%.",
    "descriptor": "",
    "authors": [
      "Liu Yang",
      "Simon X. Yang",
      "Yun Li",
      "Yinzhi Lu",
      "Tan Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07707"
  },
  {
    "id": "arXiv:2210.07713",
    "title": "An Empirical Evaluation of Multivariate Time Series Classification with  Input Transformation across Different Dimensions",
    "abstract": "In current research, machine and deep learning solutions for the\nclassification of temporal data are shifting from single-channel datasets\n(univariate) to problems with multiple channels of information (multivariate).\nThe majority of these works are focused on the method novelty and architecture,\nand the format of the input data is often treated implicitly. Particularly,\nmultivariate datasets are often treated as a stack of univariate time series in\nterms of input preprocessing, with scaling methods applied across each channel\nseparately. In this evaluation, we aim to demonstrate that the additional\nchannel dimension is far from trivial and different approaches to scaling can\nlead to significantly different results in the accuracy of a solution. To that\nend, we test seven different data transformation methods on four different\ntemporal dimensions and study their effect on the classification accuracy of\nfive recent methods. We show that, for the large majority of tested datasets,\nthe best transformation-dimension configuration leads to an increase in the\naccuracy compared to the result of each model with the same hyperparameters and\nno scaling, ranging from 0.16 to 76.79 percentage points. We also show that if\nwe keep the transformation method constant, there is a statistically\nsignificant difference in accuracy results when applying it across different\ndimensions, with accuracy differences ranging from 0.23 to 47.79 percentage\npoints. Finally, we explore the relation of the transformation methods and\ndimensions to the classifiers, and we conclude that there is no prominent\ngeneral trend, and the optimal configuration is dataset- and\nclassifier-specific.",
    "descriptor": "",
    "authors": [
      "Leonardos Pantiskas",
      "Kees Verstoep",
      "Mark Hoogendoorn",
      "Henri Bal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07713"
  },
  {
    "id": "arXiv:2210.07714",
    "title": "Close the Gate: Detecting Backdoored Models in Federated Learning based  on Client-Side Deep Layer Output Analysis",
    "abstract": "Federated Learning (FL) is a scheme for collaboratively training Deep Neural\nNetworks (DNNs) with multiple data sources from different clients. Instead of\nsharing the data, each client trains the model locally, resulting in improved\nprivacy. However, recently so-called targeted poisoning attacks have been\nproposed that allow individual clients to inject a backdoor into the trained\nmodel. Existing defenses against these backdoor attacks either rely on\ntechniques like Differential Privacy to mitigate the backdoor, or analyze the\nweights of the individual models and apply outlier detection methods that\nrestricts these defenses to certain data distributions. However, adding noise\nto the models' parameters or excluding benign outliers might also reduce the\naccuracy of the collaboratively trained model. Additionally, allowing the\nserver to inspect the clients' models creates a privacy risk due to existing\nknowledge extraction methods.\nWe propose \\textit{CrowdGuard}, a model filtering defense, that mitigates\nbackdoor attacks by leveraging the clients' data to analyze the individual\nmodels before the aggregation. To prevent data leaks, the server sends the\nindividual models to secure enclaves, running in client-located Trusted\nExecution Environments. To effectively distinguish benign and poisoned models,\neven if the data of different clients are not independently and identically\ndistributed (non-IID), we introduce a novel metric called \\textit{HLBIM} to\nanalyze the outputs of the DNN's hidden layers. We show that the applied\nsignificance-based detection algorithm combined can effectively detect poisoned\nmodels, even in non-IID scenarios.",
    "descriptor": "\nComments: Phillip Rieger and Torsten Krau{\\ss} contributed equally to this contribution. 18 pages, 7 figures, 2 tables, 4 algorithms, 3 equations\n",
    "authors": [
      "Phillip Rieger",
      "Torsten Krau\u00df",
      "Markus Miettinen",
      "Alexandra Dmitrienko",
      "Ahmad-Reza Sadeghi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07714"
  },
  {
    "id": "arXiv:2210.07715",
    "title": "Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning",
    "abstract": "Graph attention networks (GATs) are powerful tools for analyzing graph data\nfrom various real-world scenarios. To learn representations for downstream\ntasks, GATs generally attend to all neighbors of the central node when\naggregating the features. In this paper, we show that a large portion of the\nneighbors are irrelevant to the central nodes in many real-world graphs, and\ncan be excluded from neighbor aggregation. Taking the cue, we present Selective\nAttention (SA) and a series of novel attention mechanisms for graph neural\nnetworks (GNNs). SA leverages diverse forms of learnable node-node\ndissimilarity to acquire the scope of attention for each node, from which\nirrelevant neighbors are excluded. We further propose Graph selective attention\nnetworks (SATs) to learn representations from the highly correlated node\nfeatures identified and investigated by different SA mechanisms. Lastly,\ntheoretical analysis on the expressive power of the proposed SATs and a\ncomprehensive empirical study of the SATs on challenging real-world datasets\nagainst state-of-the-art GNNs are presented to demonstrate the effectiveness of\nSATs.",
    "descriptor": "",
    "authors": [
      "Tiantian He",
      "Haicang Zhou",
      "Yew-Soon Ong",
      "Gao Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07715"
  },
  {
    "id": "arXiv:2210.07719",
    "title": "A Lightweight Moving Target Defense Framework for Multi-purpose Malware  Affecting IoT Devices",
    "abstract": "Malware affecting Internet of Things (IoT) devices is rapidly growing due to\nthe relevance of this paradigm in real-world scenarios. Specialized literature\nhas also detected a trend towards multi-purpose malware able to execute\ndifferent malicious actions such as remote control, data leakage, encryption,\nor code hiding, among others. Protecting IoT devices against this kind of\nmalware is challenging due to their well-known vulnerabilities and limitation\nin terms of CPU, memory, and storage. To improve it, the moving target defense\n(MTD) paradigm was proposed a decade ago and has shown promising results, but\nthere is a lack of IoT MTD solutions dealing with multi-purpose malware. Thus,\nthis work proposes four MTD mechanisms changing IoT devices' network, data, and\nruntime environment to mitigate multi-purpose malware. Furthermore, it presents\na lightweight and IoT-oriented MTD framework to decide what, when, and how the\nMTD mechanisms are deployed. Finally, the efficiency and effectiveness of the\nframework and MTD mechanisms are evaluated in a real-world scenario with one\nIoT spectrum sensor affected by multi-purpose malware.",
    "descriptor": "",
    "authors": [
      "Jan von der Assen",
      "Alberto Huertas Celdr\u00e1n",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Jordan Cede\u00f1o",
      "G\u00e9r\u00f4me Bovet",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07719"
  },
  {
    "id": "arXiv:2210.07721",
    "title": "Mechanical features based object recognition",
    "abstract": "Current robotic haptic object recognition relies on statistical measures\nderived from movement dependent interaction signals such as force, vibration or\nposition. Mechanical properties that can be identified from these signals are\nintrinsic object properties that may yield a more robust object representation.\nTherefore, this paper proposes an object recognition framework using multiple\nrepresentative mechanical properties: the coefficient of restitution,\nstiffness, viscosity and friction coefficient. These mechanical properties are\nidentified in real-time using a dual Kalman filter, then used to classify\nobjects. The proposed framework was tested with a robot identifying 20 objects\nthrough haptic exploration. The results demonstrate the technique's\neffectiveness and efficiency, and that all four mechanical properties are\nrequired for best recognition yielding a rate of 98.18 $\\pm$ 0.424 %.\nClustering with Gaussian mixture models further shows that using these\nmechanical properties results in superior recognition as compared to using\nstatistical parameters of the interaction signals.",
    "descriptor": "\nComments: 9 pages, journal paper\n",
    "authors": [
      "Pakorn Uttayopas",
      "Xiaoxiao Cheng",
      "Jonathan Eden",
      "Etienne Burdet"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07721"
  },
  {
    "id": "arXiv:2210.07722",
    "title": "(1,1)-Cluster Editing is Polynomial-time Solvable",
    "abstract": "A graph $H$ is a clique graph if $H$ is a vertex-disjoin union of cliques.\nAbu-Khzam (2017) introduced the $(a,d)$-{Cluster Editing} problem, where for\nfixed natural numbers $a,d$, given a graph $G$ and vertex-weights $a^*:\\\nV(G)\\rightarrow \\{0,1,\\dots, a\\}$ and $d^*{}:\\ V(G)\\rightarrow \\{0,1,\\dots,\nd\\}$, we are to decide whether $G$ can be turned into a cluster graph by\ndeleting at most $d^*(v)$ edges incident to every $v\\in V(G)$ and adding at\nmost $a^*(v)$ edges incident to every $v\\in V(G)$. Results by Komusiewicz and\nUhlmann (2012) and Abu-Khzam (2017) provided a dichotomy of complexity (in P or\nNP-complete) of $(a,d)$-{Cluster Editing} for all pairs $a,d$ apart from\n$a=d=1.$ Abu-Khzam (2017) conjectured that $(1,1)$-{Cluster Editing} is in P.\nWe resolve Abu-Khzam's conjecture in affirmative by (i) providing a serious of\nfive polynomial-time reductions to $C_3$-free and $C_4$-free graphs of maximum\ndegree at most 3, and (ii) designing a polynomial-time algorithm for solving\n$(1,1)$-{Cluster Editing} on $C_3$-free and $C_4$-free graphs of maximum degree\nat most 3.",
    "descriptor": "",
    "authors": [
      "Gregory Gutin",
      "Anders Yeo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.07722"
  },
  {
    "id": "arXiv:2210.07724",
    "title": "Automatic Differentiation for ML-family languages: correctness via  logical relations",
    "abstract": "We give a simple, direct and reusable logical relations technique for\nlanguages with recursive features and partially defined differentiable\nfunctions. We do so by working out the case of Automatic Differentiation (AD)\ncorrectness: namely, we present a proof of the dual numbers style AD macro\ncorrectness for realistic functional languages in the ML-family. We also show\nhow this macro provides us with correct forward- and reverse-mode AD.\nThe starting point was to interpret a functional programming language in a\nsuitable freely generated categorical structure. In this setting, by the\nuniversal property of the syntactic categorical structure, the dual numbers AD\nmacro and the basic $\\omega$-cpo-semantics arise as structure preserving\nfunctors. The proof follows, then, by a novel logical relations argument.\nThe key to much of our contribution is a powerful monadic logical relations\ntechnique for term recursion and recursive types. It provides us with a\nsemantic correctness proof based on a simple approach for denotational\nsemantics, making use only of the very basic concrete model of $\\omega$-cpos.",
    "descriptor": "",
    "authors": [
      "Fernando Lucatelli Nunes",
      "Matthijs V\u00e1k\u00e1r"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.07724"
  },
  {
    "id": "arXiv:2210.07729",
    "title": "Model-Based Imitation Learning for Urban Driving",
    "abstract": "An accurate model of the environment and the dynamic agents acting in it\noffers great potential for improving motion planning. We present MILE: a\nModel-based Imitation LEarning approach to jointly learn a model of the world\nand a policy for autonomous driving. Our method leverages 3D geometry as an\ninductive bias and learns a highly compact latent space directly from\nhigh-resolution videos of expert demonstrations. Our model is trained on an\noffline corpus of urban driving data, without any online interaction with the\nenvironment. MILE improves upon prior state-of-the-art by 35% in driving score\non the CARLA simulator when deployed in a completely new town and new weather\nconditions. Our model can predict diverse and plausible states and actions,\nthat can be interpretably decoded to bird's-eye view semantic segmentation.\nFurther, we demonstrate that it can execute complex driving manoeuvres from\nplans entirely predicted in imagination. Our approach is the first camera-only\nmethod that models static scene, dynamic scene, and ego-behaviour in an urban\ndriving environment. The code and model weights are available at\nhttps://github.com/wayveai/mile.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Anthony Hu",
      "Gianluca Corrado",
      "Nicolas Griffiths",
      "Zak Murez",
      "Corina Gurau",
      "Hudson Yeo",
      "Alex Kendall",
      "Roberto Cipolla",
      "Jamie Shotton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07729"
  },
  {
    "id": "arXiv:2210.07730",
    "title": "DroneARchery: Human-Drone Interaction through Augmented Reality with  Haptic Feedback and Multi-UAV Collision Avoidance Driven by Deep  Reinforcement Learning",
    "abstract": "We propose a novel concept of augmented reality (AR) human-drone interaction\ndriven by RL-based swarm behavior to achieve intuitive and immersive control of\na swarm formation of unmanned aerial vehicles. The DroneARchery system\ndeveloped by us allows the user to quickly deploy a swarm of drones, generating\nflight paths simulating archery. The haptic interface LinkGlide delivers a\ntactile stimulus of the bowstring tension to the forearm to increase the\nprecision of aiming. The swarm of released drones dynamically avoids collisions\nbetween each other, the drone following the user, and external obstacles with\nbehavior control based on deep reinforcement learning.\nThe developed concept was tested in the scenario with a human, where the user\nshoots from a virtual bow with a real drone to hit the target. The human\noperator observes the ballistic trajectory of the drone in an AR and achieves a\nrealistic and highly recognizable experience of the bowstring tension through\nthe haptic display.\nThe experimental results revealed that the system improves trajectory\nprediction accuracy by 63.3% through applying AR technology and conveying\nhaptic feedback of pulling force. DroneARchery users highlighted the\nnaturalness (4.3 out of 5 point Likert scale) and increased confidence (4.7 out\nof 5) when controlling the drone. We have designed the tactile patterns to\npresent four sliding distances (tension) and three applied force levels\n(stiffness) of the haptic display. Users demonstrated the ability to\ndistinguish tactile patterns produced by the haptic display representing\nvarying bowstring tension(average recognition rate is of 72.8%) and stiffness\n(average recognition rate is of 94.2%).\nThe novelty of the research is the development of an AR-based approach for\ndrone control that does not require special skills and training from the\noperator.",
    "descriptor": "\nComments: Accepted to the IEEE Int. Symp. on Mixed and Augmented Reality (ISMAR 2022). Copyright 20XX IEEE. Personal use of this material is permitted\n",
    "authors": [
      "Ekaterina Dorzhieva",
      "Ahmed Baza",
      "Ayush Gupta",
      "Aleksey Fedoseev",
      "Miguel Altamirano Cabrera",
      "Ekaterina Karmanova",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07730"
  },
  {
    "id": "arXiv:2210.07733",
    "title": "Fine-grained Category Discovery under Coarse-grained supervision with  Hierarchical Weighted Self-contrastive Learning",
    "abstract": "Novel category discovery aims at adapting models trained on known categories\nto novel categories. Previous works only focus on the scenario where known and\nnovel categories are of the same granularity. In this paper, we investigate a\nnew practical scenario called Fine-grained Category Discovery under\nCoarse-grained supervision (FCDC). FCDC aims at discovering fine-grained\ncategories with only coarse-grained labeled data, which can adapt models to\ncategories of different granularity from known ones and reduce significant\nlabeling cost. It is also a challenging task since supervised training on\ncoarse-grained categories tends to focus on inter-class distance (distance\nbetween coarse-grained classes) but ignore intra-class distance (distance\nbetween fine-grained sub-classes) which is essential for separating\nfine-grained categories. Considering most current methods cannot transfer\nknowledge from coarse-grained level to fine-grained level, we propose a\nhierarchical weighted self-contrastive network by building a novel weighted\nself-contrastive module and combining it with supervised learning in a\nhierarchical manner. Extensive experiments on public datasets show both\neffectiveness and efficiency of our model over compared methods. Code and data\nare available at https://github.com/Lackel/Hierarchical_Weighted_SCL.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Ping Chen",
      "Siliang Tang",
      "Qinghua Zheng",
      "QianYing Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07733"
  },
  {
    "id": "arXiv:2210.07737",
    "title": "On Benefits and Challenges of Conditional Interframe Video Coding in  Light of Information Theory",
    "abstract": "The rise of variational autoencoders for image and video compression has\nopened the door to many elaborate coding techniques. One example here is the\npossibility of conditional interframe coding. Here, instead of transmitting the\nresidual between the original frame and the predicted frame (often obtained by\nmotion compensation), the current frame is transmitted under the condition of\nknowing the prediction signal. In practice, conditional coding can be\nstraightforwardly implemented using a conditional autoencoder, which has also\nshown good results in recent works. In this paper, we provide an information\ntheoretical analysis of conditional coding for inter frames and show in which\ncases gains compared to traditional residual coding can be expected. We also\nshow the effect of information bottlenecks which can occur in practical video\ncoders in the prediction signal path due to the network structure, as a\nconsequence of the data-processing theorem or due to quantization. We\ndemonstrate that conditional coding has theoretical benefits over residual\ncoding but that there are cases in which the benefits are quickly canceled by\nsmall information bottlenecks of the prediction signal.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted to be presented at PCS 2022. arXiv admin note: text overlap with arXiv:2112.08011\n",
    "authors": [
      "Fabian Brand",
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.07737"
  },
  {
    "id": "arXiv:2210.07738",
    "title": "When programs have to watch paint dry",
    "abstract": "We explore type systems and programming abstractions for the safe use of\nresources. In particular, we investigate how to use types to modularly specify\nand check when programs are allowed to use their resources, e.g., when\nprogramming a robot arm on a production line, it is crucial that painted parts\nare given enough time to dry before assembly. We capture such temporal\nresources using a time-graded variant of Fitch-style modal type systems,\ndevelop a corresponding modally typed, effectful core calculus, and equip it\nwith a graded-monadic denotational semantics illustrated by a concrete presheaf\nmodel. Our calculus also includes temporally-aware graded algebraic effects and\neffect handlers. The former are given a novel temporal treatment, where\noperations' specifications include their execution times, and their\ncontinuations know that an operation's worth of additional time has passed\nbefore they start executing, making it possible to safely access further\ntemporal resources in them, and where effect handlers have to respect this\ntemporal discipline.",
    "descriptor": "\nComments: FoSSaCS 2023 submission\n",
    "authors": [
      "Danel Ahman"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.07738"
  },
  {
    "id": "arXiv:2210.07741",
    "title": "E-Resource Management and Management Issues and Challenges",
    "abstract": "E-resources are inevitable, technology has grown and libraries are also\nadopting the technologies although adopting have many challenges to the library\nprofessionals. Whenever something new comes they need to update themselves. A\nstudy investigated E-Resources management and management issues of Indian\nlibrary professional perspectives. For this study, data was collected from\nvarious academic institutes/university libraries in India. It includes\ninstitutes of national importance, central, state, deemed and private\nuniversities. The study finds that the majority of the libraries subscribed to\nE-journals and E-books, administration related challenges faced by LIS\nprofessionals. The t-test results revealed a lack of professional skills is the\nreason for issues and challenges of Library management.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Ammaji Rajitha",
      "Mohd Amin Dar",
      "Natarajan R"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07741"
  },
  {
    "id": "arXiv:2210.07745",
    "title": "Confidence estimation of classification based on the distribution of the  neural network output layer",
    "abstract": "One of the most common problems preventing the application of prediction\nmodels in the real world is lack of generalization: The accuracy of models,\nmeasured in the benchmark does repeat itself on future data, e.g. in the\nsettings of real business. There is relatively little methods exist that\nestimate the confidence of prediction models. In this paper, we propose novel\nmethods that, given a neural network classification model, estimate uncertainty\nof particular predictions generated by this model. Furthermore, we propose a\nmethod that, given a model and a confidence level, calculates a threshold that\nseparates prediction generated by this model into two subsets, one of them\nmeets the given confidence level. In contrast to other methods, the proposed\nmethods do not require any changes on existing neural networks, because they\nsimply build on the output logit layer of a common neural network. In\nparticular, the methods infer the confidence of a particular prediction based\non the distribution of the logit values corresponding to this prediction. The\nproposed methods constitute a tool that is recommended for filtering\npredictions in the process of knowledge extraction, e.g. based on web\nscrapping, where predictions subsets are identified that maximize the precision\non cost of the recall, which is less important due to the availability of data.\nThe method has been tested on different tasks including relation extraction,\nnamed entity recognition and image classification to show the significant\nincrease of accuracy achieved.",
    "descriptor": "\nComments: Draft\n",
    "authors": [
      "Abdel Aziz Taha",
      "Leonhard Hennig",
      "Petr Knoth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07745"
  },
  {
    "id": "arXiv:2210.07746",
    "title": "Formalising the $h$-principle and sphere eversion",
    "abstract": "In differential topology and geometry, the h-principle is a property enjoyed\nby certain construction problems. Roughly speaking, it states that the only\nobstructions to the existence of a solution come from algebraic topology.\nWe describe a formalisation in Lean of the local h-principle for first-order,\nopen, ample partial differential relations. This is a significant result in\ndifferential topology, originally proven by Gromov in 1973 as part of his\nsweeping effort which greatly generalised many previous flexibility results in\ntopology and geometry. In particular it reproves Smale's celebrated sphere\neversion theorem, a visually striking and counter-intuitive construction. Our\nformalisation uses Theilli\\`ere's implementation of convex integration from\n2018.\nThis paper is the first part of the sphere eversion project, aiming to\nformalise the global version of the h-principle for open and ample first order\ndifferential relations, for maps between smooth manifolds. Our current local\nversion for vector spaces is the main ingredient of this proof, and is\nsufficient to prove the titular corollary of the project. From a broader\nperspective, the goal of this project is to show that one can formalise\nadvanced mathematics with a strongly geometric flavour and not only\nalgebraically-flavoured",
    "descriptor": "\nComments: 30 pages, submitted to CPP 2023\n",
    "authors": [
      "Patrick Massot",
      "Floris van Doorn",
      "Oliver Nash"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07746"
  },
  {
    "id": "arXiv:2210.07747",
    "title": "Online Learning of Caching and Recommendation Policies in a Multi-BS  Cellular Networks",
    "abstract": "Mobile edge computing is a key technology for the future wireless networks\nand hence, the efficiency of a cache-placement algorithm is important to seek\nthe cache content which satisfies the maximum user demands. Since\nrecommendations personalizes an individual's choices, it is responsible for a\nsignificant percentage of user requests, and hence recommendation can be\nutilized to maximize the overall cache hit rate. Hence, in this work, joint\noptimization of both recommendation and caching is proposed. The influence of\nrecommendation on the popularity of a file is modelled using a conditional\nprobability distribution. To this end, the concept of probability matrix is\nintroduced and a Bayesian based model, specifically Dirichlet distribution is\nused to predict and estimate the content request probability and hence the\naverage cache hit is derived. Joint recommendation and caching algorithm is\npresented to maximize the average cache hits. Subsequently, theoretical\nguarantees are provided on the performance of the algorithm. Also, a\nheterogeneous network consisting of M small base stations and one macro base\nstation is also presented. Finally, simulation results confirm the efficiency\nof the proposed algorithms in terms of average cache hit rate, delay and\nthroughput.",
    "descriptor": "\nComments: 31 pages, 7 figures\n",
    "authors": [
      "S. Krishnendu",
      "B. N. Bharath",
      "Vimal Bhatia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07747"
  },
  {
    "id": "arXiv:2210.07750",
    "title": "Bandwidth-efficient distributed neural network architectures with  application to body sensor networks",
    "abstract": "In this paper, we describe a conceptual design methodology to design\ndistributed neural network architectures that can perform efficient inference\nwithin sensor networks with communication bandwidth constraints. The different\nsensor channels are distributed across multiple sensor devices, which have to\nexchange data over bandwidth-limited communication channels to solve, e.g., a\nclassification task. Our design methodology starts from a user-defined\ncentralized neural network and transforms it into a distributed architecture in\nwhich the channels are distributed over different nodes. The distributed\nnetwork consists of two parallel branches of which the outputs are fused at the\nfusion center. The first branch collects classification results from local,\nnode-specific classifiers while the second branch compresses each node's signal\nand then reconstructs the multi-channel time series for classification at the\nfusion center. We further improve bandwidth gains by dynamically activating the\ncompression path when the local classifications do not suffice. We validate\nthis method on a motor execution task in an emulated EEG sensor network and\nanalyze the resulting bandwidth-accuracy trade-offs. Our experiments show that\nthe proposed framework enables up to a factor 20 in bandwidth reduction with\nminimal loss (up to 2%) in classification accuracy compared to the centralized\nbaseline on the demonstrated motor execution task. The proposed method offers a\nway to smoothly transform a centralized architecture to a distributed,\nbandwidth-efficient network amenable for low-power sensor networks. While the\napplication focus of this paper is on wearable brain-computer interfaces, the\nproposed methodology can be applied in other sensor network-like applications\nas well.",
    "descriptor": "",
    "authors": [
      "Thomas Strypsteen",
      "Alexander Bertrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.07750"
  },
  {
    "id": "arXiv:2210.07754",
    "title": "Zero-Rate Thresholds and New Capacity Bounds for List-Decoding and  List-Recovery",
    "abstract": "In this work we consider the list-decodability and list-recoverability of\narbitrary $q$-ary codes, for all integer values of $q\\geq 2$. A code is called\n$(p,L)_q$-list-decodable if every radius $pn$ Hamming ball contains less than\n$L$ codewords; $(p,\\ell,L)_q$-list-recoverability is a generalization where we\nplace radius $pn$ Hamming balls on every point of a combinatorial rectangle\nwith side length $\\ell$ and again stipulate that there be less than $L$\ncodewords.\nOur main contribution is to precisely calculate the maximum value of $p$ for\nwhich there exist infinite families of positive rate\n$(p,\\ell,L)_q$-list-recoverable codes, the quantity we call the zero-rate\nthreshold. Denoting this value by $p_*$, we in fact show that codes correcting\na $p_*+\\varepsilon$ fraction of errors must have size $O_{\\varepsilon}(1)$,\ni.e., independent of $n$. Such a result is typically referred to as a ``Plotkin\nbound.'' To complement this, a standard random code with expurgation\nconstruction shows that there exist positive rate codes correcting a\n$p_*-\\varepsilon$ fraction of errors. We also follow a classical proof template\n(typically attributed to Elias and Bassalygo) to derive from the zero-rate\nthreshold other tradeoffs between rate and decoding radius for list-decoding\nand list-recovery.\nTechnically, proving the Plotkin bound boils down to demonstrating the Schur\nconvexity of a certain function defined on the $q$-simplex as well as the\nconvexity of a univariate function derived from it. We remark that an earlier\nargument claimed similar results for $q$-ary list-decoding; however, we point\nout that this earlier proof is flawed.",
    "descriptor": "",
    "authors": [
      "Nicolas Resch",
      "Chen Yuan",
      "Yihan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.07754"
  },
  {
    "id": "arXiv:2210.07755",
    "title": "Simpson's Paradox in Recommender Fairness: Reconciling differences  between per-user and aggregated evaluations",
    "abstract": "There has been a flurry of research in recent years on notions of fairness in\nranking and recommender systems, particularly on how to evaluate if a\nrecommender allocates exposure equally across groups of relevant items (also\nknown as provider fairness). While this research has laid an important\nfoundation, it gave rise to different approaches depending on whether relevant\nitems are compared per-user/per-query or aggregated across users. Despite both\nbeing established and intuitive, we discover that these two notions can lead to\nopposite conclusions, a form of Simpson's Paradox. We reconcile these notions\nand show that the tension is due to differences in distributions of users where\nitems are relevant, and break down the important factors of the user's\nrecommendations. Based on this new understanding, practitioners might be\ninterested in either notions, but might face challenges with the per-user\nmetric due to partial observability of the relevance and user satisfaction,\ntypical in real-world recommenders. We describe a technique based on\ndistribution matching to estimate it in such a scenario. We demonstrate on\nsimulated and real-world recommender data the effectiveness and usefulness of\nsuch an approach.",
    "descriptor": "",
    "authors": [
      "Flavien Prost",
      "Ben Packer",
      "Jilin Chen",
      "Li Wei",
      "Pierre Kremp",
      "Nicholas Blumm",
      "Susan Wang",
      "Tulsee Doshi",
      "Tonia Osadebe",
      "Lukasz Heldt",
      "Ed H. Chi",
      "Alex Beutel"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07755"
  },
  {
    "id": "arXiv:2210.07756",
    "title": "National-scale bi-directional EV fleet control for ancillary service  provision",
    "abstract": "Deploying real-time control on large-scale fleets of electric vehicles (EVs)\nis becoming pivotal as the share of EVs over internal combustion engine\nvehicles increases. In this paper, we present a Vehicle-to-Grid (V2G) algorithm\nto simultaneously schedule thousands of EVs charging and discharging\noperations, that can be used to provide ancillary services. To achieve\nscalability, the monolithic problem is decomposed using the alternating\ndirection method of multipliers (ADMM). Furthermore, we propose a method to\nhandle bilinear constraints of the original problem inside the ADMM iterations,\nwhich changes the problem class from Mixed-Integer Quadratic Program (MIQP) to\nQuadratic Program (QP), allowing for a substantial computational speed up. We\ntest the algorithm using real data from the largest carsharing company in\nSwitzerland and show how our formulation can be used to retrieve flexibility\nboundaries for the EV fleet. Our work thus enables fleet operators to make\ninformed bids on ancillary services provision, thereby facilitating the\nintegration of electric vehicles.",
    "descriptor": "",
    "authors": [
      "Lorenzo Nespoli",
      "Nina Wiedemann",
      "Esra Suel",
      "Yanan Xin",
      "Martin Raubal",
      "Vasco Medici"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07756"
  },
  {
    "id": "arXiv:2210.07758",
    "title": "A Study and Analysis of Manuscript Publications in the Open Access  Journals",
    "abstract": "The purpose of this study is to analyze the research article publishing with\nspecial reference to preparing to publish and peer reviewing. Peer reviewing is\nthe process required for standardizing any publications. Manuscript writing is\nan art. Though it appears to be simple there is a lot of effort required. Peer\nreviewing is the process that eliminates articles that do not meet the standard\nof the journals and the scope of the journals. The study investigated authors\nviews on manuscript submissions to the publishing process. There are 375\nsamples selected for this study who have experienced publishing journals listed\nin refereed journals. For the selection of the sample 50 ScimagoJR Library and\nInformation Science open access journals between 2019 to 2021 are verified by\nthe authors.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan",
      "Supriya Pradhan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07758"
  },
  {
    "id": "arXiv:2210.07760",
    "title": "Lightweight Alpha Matting Network Using Distillation-Based Channel  Pruning",
    "abstract": "Recently, alpha matting has received a lot of attention because of its\nusefulness in mobile applications such as selfies. Therefore, there has been a\ndemand for a lightweight alpha matting model due to the limited computational\nresources of commercial portable devices. To this end, we suggest a\ndistillation-based channel pruning method for the alpha matting networks. In\nthe pruning step, we remove channels of a student network having fewer impacts\non mimicking the knowledge of a teacher network. Then, the pruned lightweight\nstudent network is trained by the same distillation loss. A lightweight alpha\nmatting model from the proposed method outperforms existing lightweight\nmethods. To show superiority of our algorithm, we provide various quantitative\nand qualitative experiments with in-depth analyses. Furthermore, we demonstrate\nthe versatility of the proposed distillation-based channel pruning method by\napplying it to semantic segmentation.",
    "descriptor": "\nComments: Accepted by ACCV2022\n",
    "authors": [
      "Donggeun Yoon",
      "Jinsun Park",
      "Donghyeon Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07760"
  },
  {
    "id": "arXiv:2210.07762",
    "title": "Controllable Style Transfer via Test-time Training of Implicit Neural  Representation",
    "abstract": "We propose a controllable style transfer framework based on Implicit Neural\nRepresentation (INR) that pixel-wisely controls the stylized output via\ntest-time training. Unlike traditional image optimization methods that often\nsuffer from unstable convergence and learning-based methods that require\nintensive training and have limited generalization ability, we present a model\noptimization framework that optimizes the neural networks during test-time with\nexplicit loss functions for style transfer. After being test-time trained once,\nthanks to the flexibility of the INR-based model,our framework can precisely\ncontrol the stylized images in a pixel-wise manner and freely adjust image\nresolution without further optimization or training.",
    "descriptor": "\nComments: Project Page: [this https URL](this https URL)\n",
    "authors": [
      "Sunwoo Kim",
      "Youngjo Min",
      "Younghun Jung",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07762"
  },
  {
    "id": "arXiv:2210.07763",
    "title": "Extracting Cultural Commonsense Knowledge at Scale",
    "abstract": "Structured knowledge is important for many AI applications. Commonsense\nknowledge, which is crucial for robust human-centric AI, is covered by a small\nnumber of structured knowledge projects. However, they lack knowledge about\nhuman traits and behaviors conditioned on socio-cultural contexts, which is\ncrucial for situative AI. This paper presents CANDLE, an end-to-end methodology\nfor extracting high-quality cultural commonsense knowledge (CCSK) at scale.\nCANDLE extracts CCSK assertions from a huge web corpus and organizes them into\ncoherent clusters, for 3 domains of subjects (geography, religion, occupation)\nand several cultural facets (food, drinks, clothing, traditions, rituals,\nbehaviors). CANDLE includes judicious techniques for classification-based\nfiltering and scoring of interestingness. Experimental evaluations show the\nsuperiority of the CANDLE CCSK collection over prior works, and an extrinsic\nuse case demonstrates the benefits of CCSK for the GPT-3 language model. Code\nand data can be accessed at https://cultural-csk.herokuapp.com/.",
    "descriptor": "\nComments: 12 pages, 6 figures, 9 tables\n",
    "authors": [
      "Tuan-Phong Nguyen",
      "Simon Razniewski",
      "Aparna Varde",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07763"
  },
  {
    "id": "arXiv:2210.07764",
    "title": "Intel Labs at Ego4D Challenge 2022: A Better Baseline for Audio-Visual  Diarization",
    "abstract": "This report describes our approach for the Audio-Visual Diarization (AVD)\ntask of the Ego4D Challenge 2022. Specifically, we present multiple technical\nimprovements over the official baselines. First, we improve the detection\nperformance of the camera wearer's voice activity by modifying the training\nscheme of its model. Second, we discover that an off-the-shelf voice activity\ndetection model can effectively remove false positives when it is applied\nsolely to the camera wearer's voice activities. Lastly, we show that better\nactive speaker detection leads to a better AVD outcome. Our final method\nobtains 65.9% DER on the test set of Ego4D, which significantly outperforms all\nthe baselines. Our submission achieved 1st place in the Ego4D Challenge 2022.",
    "descriptor": "\nComments: Validation report for the Ego4D challenge at ECCV 2022\n",
    "authors": [
      "Kyle Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07764"
  },
  {
    "id": "arXiv:2210.07765",
    "title": "HGARN: Hierarchical Graph Attention Recurrent Network for Human Mobility  Prediction",
    "abstract": "Human mobility prediction is a fundamental task essential for various\napplications, including urban planning, transportation services, and location\nrecommendation. Existing approaches often ignore activity information crucial\nfor reasoning human preferences and routines, or adopt a simplified\nrepresentation of the dependencies between time, activities and locations. To\naddress these issues, we present Hierarchical Graph Attention Recurrent Network\n(HGARN) for human mobility prediction. Specifically, we construct a\nhierarchical graph based on all users' history mobility records and employ a\nHierarchical Graph Attention Module to capture complex time-activity-location\ndependencies. This way, HGARN can learn representations with rich contextual\nsemantics to model user preferences at the global level. We also propose a\nmodel-agnostic history-enhanced confidence (MaHec) label to focus our model on\neach user's individual-level preferences. Finally, we introduce a Recurrent\nEncoder-Decoder Module, which employs recurrent structures to jointly predict\nusers' next activities (as an auxiliary task) and locations. For model\nevaluation, we test the performances of our Hgarn against existing SOTAs in\nrecurring and explorative settings. The recurring setting focuses more on\nassessing models' capabilities to capture users' individual-level preferences.\nIn contrast, the results in the explorative setting tend to reflect the power\nof different models to learn users' global-level preferences. Overall, our\nmodel outperforms other baselines significantly in the main, recurring, and\nexplorative settings based on two real-world human mobility data benchmarks.\nSource codes of HGARN are available at https://github.com/YihongT/HGARN.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yihong Tang",
      "Junlin He",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07765"
  },
  {
    "id": "arXiv:2210.07768",
    "title": "FeatureBox: Feature Engineering on GPUs for Massive-Scale Ads Systems",
    "abstract": "Deep learning has been widely deployed for online ads systems to predict\nClick-Through Rate (CTR). Machine learning researchers and practitioners\nfrequently retrain CTR models to test their new extracted features. However,\nthe CTR model training often relies on a large number of raw input data logs.\nHence, the feature extraction can take a significant proportion of the training\ntime for an industrial-level CTR model. In this paper, we propose FeatureBox, a\nnovel end-to-end training framework that pipelines the feature extraction and\nthe training on GPU servers to save the intermediate I/O of the feature\nextraction. We rewrite computation-intensive feature extraction operators as\nGPU operators and leave the memory-intensive operator on CPUs. We introduce a\nlayer-wise operator scheduling algorithm to schedule these heterogeneous\noperators. We present a light-weight GPU memory management algorithm that\nsupports dynamic GPU memory allocation with minimal overhead. We experimentally\nevaluate FeatureBox and compare it with the previous in-production feature\nextraction framework on two real-world ads applications. The results confirm\nthe effectiveness of our proposed method.",
    "descriptor": "",
    "authors": [
      "Weijie Zhao",
      "Xuewu Jiao",
      "Xinsheng Luo",
      "Jingxue Li",
      "Belhal Karimi",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07768"
  },
  {
    "id": "arXiv:2210.07769",
    "title": "Flattened Graph Convolutional Networks For Recommendation",
    "abstract": "Graph Convolutional Networks (GCNs) and their variants have achieved\nsignificant performances on various recommendation tasks. However, many\nexisting GCN models tend to perform recursive aggregations among all related\nnodes, which can arise severe computational burden to hinder their application\nto large-scale recommendation tasks. To this end, this paper proposes the\nflattened GCN~(FlatGCN) model, which is able to achieve superior performance\nwith remarkably less complexity compared with existing models. Our main\ncontribution is three-fold. First, we propose a simplified but powerful GCN\narchitecture which aggregates the neighborhood information using one flattened\nGCN layer, instead of recursively. The aggregation step in FlatGCN is\nparameter-free such that it can be pre-computed with parallel computation to\nsave memory and computational cost. Second, we propose an informative\nneighbor-infomax sampling method to select the most valuable neighbors by\nmeasuring the correlation among neighboring nodes based on a principled metric.\nThird, we propose a layer ensemble technique which improves the expressiveness\nof the learned representations by assembling the layer-wise neighborhood\nrepresentations at the final layer. Extensive experiments on three datasets\nverify that our proposed model outperforms existing GCN models considerably and\nyields up to a few orders of magnitude speedup in training efficiency.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.04164\n",
    "authors": [
      "Yue Xu",
      "Hao Chen",
      "Zengde Deng",
      "Yuanchen Bei",
      "Feiran Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07769"
  },
  {
    "id": "arXiv:2210.07770",
    "title": "Towards Trustworthy AI-Empowered Real-Time Bidding for Online  Advertisement Auctioning",
    "abstract": "Artificial intelligence-empowred Real-Time Bidding (AIRTB) is regarded as one\nof the most enabling technologies for online advertising. It has attracted\nsignificant research attention from diverse fields such as pattern recognition,\ngame theory and mechanism design. Despite of its remarkable development and\ndeployment, the AIRTB system can sometimes harm the interest of its\nparticipants (e.g., depleting the advertisers' budget with various kinds of\nfraud). As such, building trustworthy AIRTB auctioning systems has emerged as\nan important direction of research in this field in recent years. Due to the\nhighly interdisciplinary nature of this field and a lack of a comprehensive\nsurvey, it is a challenge for researchers to enter this field and contribute\ntowards building trustworthy AIRTB technologies. This paper bridges this\nimportant gap in trustworthy AIRTB literature. We start by analysing the key\nconcerns of various AIRTB stakeholders and identify three main dimensions of\ntrust building in AIRTB, namely security, robustness and fairness. For each of\nthese dimensions, we propose a unique taxonomy of the state of the art, trace\nthe root causes of possible breakdown of trust, and discuss the necessity of\nthe given dimension. This is followed by a comprehensive review of existing\nstrategies for fulfilling the requirements of each trust dimension. In\naddition, we discuss the promising future directions of research essential\ntowards building trustworthy AIRTB systems to benefit the field of online\nadvertising.",
    "descriptor": "",
    "authors": [
      "Xiaoli Tang",
      "Han Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07770"
  },
  {
    "id": "arXiv:2210.07773",
    "title": "Diversified Recommendations for Agents with Adaptive Preferences",
    "abstract": "When an Agent visits a platform recommending a menu of content to select\nfrom, their choice of item depends not only on fixed preferences, but also on\ntheir prior engagements with the platform. The Recommender's primary objective\nis typically to encourage content consumption which optimizes some reward, such\nas ad revenue, but they often also aim to ensure that a wide variety of content\nis consumed by the Agent over time. We formalize this problem as an adversarial\nbandit task. At each step, the Recommender presents a menu of $k$ (out of $n$)\nitems to the Agent, who selects one item in the menu according to their unknown\npreference model, which maps their history of past items to relative selection\nprobabilities. The Recommender then observes the Agent's chosen item and\nreceives bandit feedback of the item's reward. In addition to optimizing reward\nfrom selected items, the Recommender must also ensure that the total\ndistribution of chosen items has sufficiently high entropy.\nWe define a class of preference models which are locally learnable, i.e.\nbehavior over the entire domain can be estimated by only observing behavior in\na small region; this includes models representable by bounded-degree\npolynomials as well as functions with a sparse Fourier basis. For this class,\nwe give an algorithm for the Recommender which obtains $\\tilde{O}(T^{3/4})$\nregret against all item distributions satisfying two conditions: they are\nsufficiently diversified, and they are instantaneously realizable at any\nhistory by some distribution over menus. We show that these conditions are\nclosely connected: all sufficiently high-entropy distributions are\ninstantaneously realizable at any item history. We also give a set of negative\nresults justifying our assumptions, in the form of a runtime lower bound for\nnon-local learning and linear regret lower bounds for alternate benchmarks.",
    "descriptor": "",
    "authors": [
      "Arpit Agarwal",
      "William Brown"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07773"
  },
  {
    "id": "arXiv:2210.07774",
    "title": "Learning To Rank Diversely",
    "abstract": "Airbnb is a two-sided marketplace, bringing together hosts who own listings\nfor rent, with prospective guests from around the globe. Applying neural\nnetwork-based learning to rank techniques has led to significant improvements\nin matching guests with hosts. These improvements in ranking were driven by a\ncore strategy: order the listings by their estimated booking probabilities,\nthen iterate on techniques to make these booking probability estimates more and\nmore accurate. Embedded implicitly in this strategy was an assumption that the\nbooking probability of a listing could be determined independently of other\nlistings in search results. In this paper we discuss how this assumption,\npervasive throughout the commonly-used learning to rank frameworks, is false.\nWe provide a theoretical foundation correcting this assumption, followed by\nefficient neural network architectures based on the theory. Explicitly\naccounting for possible similarities between listings, and reducing them to\ndiversify the search results generated strong positive impact. We discuss these\nmetric wins as part of the online A/B tests of the theory. Our method provides\na practical way to diversify search results for large-scale production ranking\nsystems.",
    "descriptor": "\nComments: Search ranking, Diversity, e-commerce\n",
    "authors": [
      "Malay Haldar",
      "Mustafa Abdool",
      "Liwei He",
      "Dillon Davis",
      "Huiji Gao",
      "Sanjeev Katariya"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07774"
  },
  {
    "id": "arXiv:2210.07775",
    "title": "PrivMVMF: Privacy-Preserving Multi-View Matrix Factorization for  Recommender Systems",
    "abstract": "With an increasing focus on data privacy, there have been pilot studies on\nrecommender systems in a federated learning (FL) framework, where multiple\nparties collaboratively train a model without sharing their data. Most of these\nstudies assume that the conventional FL framework can fully protect user\nprivacy. However, there are serious privacy risks in matrix factorization in\nfederated recommender systems based on our study. This paper first provides a\nrigorous theoretical analysis of the server reconstruction attack in four\nscenarios in federated recommender systems, followed by comprehensive\nexperiments. The empirical results demonstrate that the FL server could infer\nusers' information with accuracy >80% based on the uploaded gradients from FL\nnodes. The robustness analysis suggests that our reconstruction attack analysis\noutperforms the random guess by >30% under Laplace noises with b no larger than\n0.5 for all scenarios. Then, the paper proposes a new privacy-preserving\nframework based on homomorphic encryption, Privacy-Preserving Multi-View Matrix\nFactorization (PrivMVMF), to enhance user data privacy protection in federated\nrecommender systems. The proposed PrivMVMF is successfully implemented and\ntested thoroughly with the MovieLens dataset.",
    "descriptor": "",
    "authors": [
      "Peihua Mai",
      "Yan Pang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07775"
  },
  {
    "id": "arXiv:2210.07777",
    "title": "LEATHER: A Framework for Learning to Generate Human-like Text in  Dialogue",
    "abstract": "Algorithms for text-generation in dialogue can be misguided. For example, in\ntask-oriented settings, reinforcement learning that optimizes only task-success\ncan lead to abysmal lexical diversity. We hypothesize this is due to poor\ntheoretical understanding of the objectives in text-generation and their\nrelation to the learning process (i.e., model training). To this end, we\npropose a new theoretical framework for learning to generate text in dialogue.\nCompared to existing theories of learning, our framework allows for analysis of\nthe multi-faceted goals inherent to text-generation. We use our framework to\ndevelop theoretical guarantees for learners that adapt to unseen data. As an\nexample, we apply our theory to study data-shift within a cooperative learning\nalgorithm proposed for the GuessWhat?! visual dialogue game. From this insight,\nwe propose a new algorithm, and empirically, we demonstrate our proposal\nimproves both task-success and human-likeness of the generated text. Finally,\nwe show statistics from our theory are empirically predictive of multiple\nqualities of the generated dialogue, suggesting our theory is useful for\nmodel-selection when human evaluations are not available.",
    "descriptor": "",
    "authors": [
      "Anthony Sicilia",
      "Malihe Alikhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07777"
  },
  {
    "id": "arXiv:2210.07780",
    "title": "Federated Best Arm Identification with Heterogeneous Clients",
    "abstract": "We study best arm identification in a federated multi-armed bandit setting\nwith a central server and multiple clients, when each client has access to a\n{\\em subset} of arms and each arm yields independent Gaussian observations. The\n{\\em reward} from an arm at any given time is defined as the average of the\nobservations generated at this time across all the clients that have access to\nthe arm. The end goal is to identify the best arm (the arm with the largest\nmean reward) of each client with the least expected stopping time, subject to\nan upper bound on the error probability (i.e., the {\\em fixed-confidence\nregime}). We provide a lower bound on the growth rate of the expected time to\nfind the best arm of each client. Furthermore, we show that for any algorithm\nwhose upper bound on the expected time to find the best arms matches with the\nlower bound up to a multiplicative constant, the ratio of any two consecutive\ncommunication time instants must be bounded, a result that is of independent\ninterest. We then provide the first-known lower bound on the expected number of\n{\\em communication rounds} required to find the best arms. We propose a novel\nalgorithm based on the well-known {\\em Track-and-Stop} strategy that\ncommunicates only at exponential time instants, and derive asymptotic upper\nbounds on its expected time to find the best arms and the expected number of\ncommunication rounds, where the asymptotics is one of vanishing error\nprobabilities.",
    "descriptor": "",
    "authors": [
      "Zhirui Chen",
      "P. N. Karthik",
      "Vincent Y. F. Tan",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.07780"
  },
  {
    "id": "arXiv:2210.07783",
    "title": "Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong  Learning in Task-Oriented Dialogue",
    "abstract": "Lifelong learning (LL) is vital for advanced task-oriented dialogue (ToD)\nsystems. To address the catastrophic forgetting issue of LL, generative replay\nmethods are widely employed to consolidate past knowledge with generated pseudo\nsamples. However, most existing generative replay methods use only a single\ntask-specific token to control their models. This scheme is usually not strong\nenough to constrain the generative model due to insufficient information\ninvolved. In this paper, we propose a novel method, prompt conditioned VAE for\nlifelong learning (PCLL), to enhance generative replay by incorporating tasks'\nstatistics. PCLL captures task-specific distributions with a conditional\nvariational autoencoder, conditioned on natural language prompts to guide the\npseudo-sample generation. Moreover, it leverages a distillation process to\nfurther consolidate past knowledge by alleviating the noise in pseudo samples.\nExperiments on natural language understanding tasks of ToD systems demonstrate\nthat PCLL significantly outperforms competitive baselines in building LL\nmodels.",
    "descriptor": "\nComments: EMNLP2022 Long Paper (Main Track)\n",
    "authors": [
      "Yingxiu Zhao",
      "Yinhe Zheng",
      "Zhiliang Tian",
      "Chang Gao",
      "Bowen Yu",
      "Haiyang Yu",
      "Yongbin Li",
      "Jian Sun",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07783"
  },
  {
    "id": "arXiv:2210.07784",
    "title": "Towards Immersive Collaborative Sensemaking",
    "abstract": "When collaborating face-to-face, people commonly use the surfaces and spaces\naround them to perform sensemaking tasks, such as spatially organising\ndocuments, notes or images. However, when people collaborate remotely using\ndesktop interfaces they no longer feel like they are sharing the same space.\nThis limitation may be overcome through collaboration in immersive\nenvironments, which simulate the physical in-person experience. In this paper,\nwe report on a between-groups study comparing collaborations on image\norganisation tasks, in an immersive Virtual Reality (VR) environment to more\nconventional desktop conferencing. Collecting data from 40 subjects in groups\nof four, we measured task performance, user behaviours, collaboration\nengagement and awareness. Overall, the VR and desktop interface resulted in\nsimilar speed, accuracy and social presence rating, but we observed more\nconversations and interaction with objects, and more equal contributions to the\ninteraction from participants within groups in VR. We also identified\ndifferences in coordination and collaborative awareness behaviours between VR\nand desktop platforms. We report on a set of systematic measures for assessing\nVR collaborative experience and a new analysis tool that we have developed to\ncapture user behaviours in collaborative setting. Finally, we provide design\nconsiderations and directions for future work.",
    "descriptor": "\nComments: Accepted at ACM ISS 2022\n",
    "authors": [
      "Ying Yang",
      "Tim Dwyer",
      "Michael Wybrow",
      "Benjamin Lee",
      "Maxime Cordeil",
      "Mark Billinghurst",
      "Bruce H. Thomas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07784"
  },
  {
    "id": "arXiv:2210.07789",
    "title": "i13DR: A Real-Time Demand Response Infrastructure for Integrating  Renewable Energy Resources",
    "abstract": "With the ongoing integration of Renewable Energy Sources (RES), the\ncomplexity of power grids is increasing. Due to the fluctuating nature of RES,\nensuring the reliability of power grids can be challenging. One possible\napproach for addressing these challenges is Demand Response (DR) which is\ndescribed as matching the demand for electrical energy according to the changes\nand the availability of supply. However, implementing a DR system to monitor\nand control a broad set of electrical appliances in real-time introduces\nseveral new complications, including ensuring the reliability and financial\nfeasibility of the system. In this work, we address these issues by designing\nand implementing a distributed real-time DR infrastructure for laptops, which\nestimates and controls the power consumption of a network of connected laptops\nin response to the fast, irregular changes of RES. Furthermore, since our\napproach is entirely software-based, we dramatically reduce the initial costs\nof the demand side participants. The result of our field experiments confirms\nthat our system successfully schedules and executes rapid and effective DR\nevents. However, the accuracy of the estimated power consumption of all\nparticipating laptops is relatively low, directly caused by our software-based\napproach.",
    "descriptor": "",
    "authors": [
      "Pezhman Nasirifard",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07789"
  },
  {
    "id": "arXiv:2210.07792",
    "title": "Robust Preference Learning for Storytelling via Contrastive  Reinforcement Learning",
    "abstract": "Controlled automated story generation seeks to generate natural language\nstories satisfying constraints from natural language critiques or preferences.\nExisting methods to control for story preference utilize prompt engineering\nwhich is labor intensive and often inconsistent. They may also use\nlogit-manipulation methods which require annotated datasets to exist for the\ndesired attributes. To address these issues, we first train a contrastive\nbi-encoder model to align stories with corresponding human critiques, named\nCARP, building a general purpose preference model. This is subsequently used as\na reward function to fine-tune a generative language model via reinforcement\nlearning. However, simply fine-tuning a generative language model with a\ncontrastive reward model does not always reliably result in a story generation\nsystem capable of generating stories that meet user preferences. To increase\nstory generation robustness we further fine-tune the contrastive reward model\nusing a prompt-learning technique. A human participant study is then conducted\ncomparing generations from our full system, ablations, and two baselines. We\nshow that the full fine-tuning pipeline results in a story generator preferred\nover a LLM 20x as large as well as logit-based methods. This motivates the use\nof contrastive learning for general purpose human preference modeling.",
    "descriptor": "",
    "authors": [
      "Louis Castricato",
      "Alexander Havrilla",
      "Shahbuland Matiana",
      "Michael Pieler",
      "Anbang Ye",
      "Ian Yang",
      "Spencer Frazier",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07792"
  },
  {
    "id": "arXiv:2210.07793",
    "title": "Greedy Transaction Fee Mechanisms for (Non-)myopic Miners",
    "abstract": "Decentralized cryptocurrencies are payment systems that rely on aligning the\nincentives of users and miners to operate correctly and offer a high quality of\nservice to their users. Recent literature studies the mechanism design problem\nof the auction serving as the transaction fee mechanism (TFM). We show that\nwhile the protocol that requires a user to ``pay as bid'' and greedily chooses\namong available transactions based on their fees is not dominant strategy\nincentive-compatible (DSIC) for users, it has a Bayesian-Nash equilibrium (BNE)\nwhere bids are slightly shaded. Relaxing this incentive compatibility\nrequirement circumvents the impossibility result of [16] and allows for an\napproximately revenue and welfare optimal, myopic miners\nincentive-compatibility (MMIC), and off-chain-agreement (OCA)-proof mechanism.\nWe prove its guarantees using different benchmarks, and in particular, show it\nis the revenue optimal Bayesian incentive-compatible (BIC), MMIC and\n1-OCA-proof mechanism among a large class of mechanisms. We move beyond the\nmyopic model to a model where users offer transaction fees for their\ntransaction to be accepted, as well as report their urgency level by specifying\nthe time to live (TTL) of the transaction, after which it expires. We show\nguarantees provided by the greedy allocation rule, as well as a\nbetter-performing non-myopic rule. The above analysis is stated in terms of a\ncryptocurrency TFM, but applies to other settings, such as cloud computing and\ndecentralized ``gig'' economy, as well.",
    "descriptor": "",
    "authors": [
      "Yotam Gafni",
      "Aviv Yaish"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.07793"
  },
  {
    "id": "arXiv:2210.07795",
    "title": "EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge  Distillation and Modal-adaptive Pruning",
    "abstract": "Pre-trained vision-language models (VLMs) have achieved impressive results in\na range of vision-language tasks. However, popular VLMs usually consist of\nhundreds of millions of parameters which brings challenges for fine-tuning and\ndeployment in real-world applications due to space, memory, and latency\nconstraints. In this work, we introduce a distilling then pruning framework to\ncompress large vision-language models into smaller, faster, and more accurate\nones. We first shrink the size of a pre-trained large VLM and apply knowledge\ndistillation in the vision-language pre-training stage to obtain a\ntask-agnostic compact VLM. Then we propose a modal-adaptive pruning algorithm\nto automatically infer the importance of vision and language modalities for\ndifferent downstream tasks and adaptively remove redundant structures and\nneurons in different encoders with controllable target sparsity. We apply our\nframework to train EfficientVLM, a fast and accurate vision-language model\nconsisting of 6 vision layers, 3 text layers, and 3 cross-modal fusion layers,\naccounting for only 93 million parameters in total, which is 44.3% of the\nteacher model. EfficientVLM retains 98.4% performance of the teacher model and\naccelerates its inference speed by 2.2x. EfficientVLM achieves a large absolute\nimprovement over previous SoTA efficient VLMs of similar sizes by a large\nmargin on various vision-language tasks, including VQAv2 (+4.9%), NLVR2\n(+5.6%), ITR (R@1 on TR +17.2%, on IR + 15.6% ) and COCO caption generation\n(CIDEr +6.5), demonstrating a large potential on training lightweight VLMs.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Tiannan Wang",
      "Wangchunshu Zhou",
      "Yan Zeng",
      "Xinsong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07795"
  },
  {
    "id": "arXiv:2210.07796",
    "title": "Nobody Wants to Work Anymore: An Analysis of r/antiwork and the  Interplay between Social and Mainstream Media during the Great Resignation",
    "abstract": "r/antiwork is a Reddit community that focuses on the discussion of worker\nexploitation, labour rights and related left-wing political ideas (e.g.\nuniversal basic income). In late 2021, r/antiwork became the fastest growing\ncommunity on Reddit, coinciding with what the mainstream media began referring\nto as the Great Resignation. This same media coverage was attributed with\npopularising the subreddit and, therefore, accelerating its growth. In this\narticle, we explore how the r/antiwork community was affected by the\nexponential increase in subscribers and the media coverage that chronicled its\nrise. We investigate how subreddit activity changed over time, the behaviour of\nheavy and light users, and how the topical nature of the discourse evolved with\nthe influx of new subscribers. We report that, despite the continuing rise of\nsubscribers well into 2022, activity on the subreddit collapsed after January\n25th 2022, when a moderator's Fox news interview was widely criticised. While\nmany users never commented again, longer running trends of users' posting and\ncommenting behaviour did not change. Finally, while many users expressed their\ndiscontent at the changing nature of the subreddit as it became more popular,\nwe found no evidence of major shifts in the topical content of discussion over\nthe period studied, with the exception of the introduction of topics related to\nseasonal events (e.g. holidays, such as Thanksgiving) and ongoing developments\nin the news (e.g. working from home and the curtailing of reproductive rights\nin the United States).",
    "descriptor": "",
    "authors": [
      "Alan Medlar",
      "Yang Liu",
      "Dorota Glowacka"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.07796"
  },
  {
    "id": "arXiv:2210.07798",
    "title": "A Formal-Methods Approach to Provide Evidence in Automated-Driving  Safety Cases",
    "abstract": "The safety of automated driving systems must be justified by convincing\narguments and supported by compelling evidence to persuade certification\nagencies, regulatory entities, and the general public to allow the systems on\npublic roads. This persuasion is typically facilitated by compiling the\narguments and the compelling evidence into a safety case. Reviews and testing,\ntwo common approaches to ensure correctness of automotive systems cannot\nexplore the typically infinite set of possible behaviours. In contrast, formal\nmethods are exhaustive methods that can provide mathematical proofs of\ncorrectness of models, and they can be used to prove that formalizations of\nfunctional safety requirements are fulfilled by formal models of system\ncomponents. This paper shows how formal methods can provide evidence for the\ncorrect break-down of the functional safety requirements onto the components\nthat are part of feedback loops, and how this evidence fits into the argument\nof the safety case. If a proof is obtained, the formal models are used as\nrequirements on the components. This structure of the safety argumentation can\nbe used to alleviate the need for reviews and tests to ensure that the\nbreak-down is correct, thereby saving effort both in data collection and\nverification time.",
    "descriptor": "\nComments: 8 pages, 3 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jonas Krook",
      "Yuvaraj Selvaraj",
      "Wolfgang Ahrendt",
      "Martin Fabian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07798"
  },
  {
    "id": "arXiv:2210.07800",
    "title": "Multiple Choice Hard Thresholding Pursuit (MCHTP) for Simultaneous  Sparse Recovery and Sparsity Order Estimation",
    "abstract": "We address the problem of sparse recovery using greedy compressed sensing\nrecovery algorithms, without explicit knowledge of the sparsity. Estimating the\nsparsity order is a crucial problem in many practical scenarios, e.g., wireless\ncommunications, where exact value of the sparsity order of the unknown channel\nmay be unavailable a priori. In this paper we have proposed a new greedy\nalgorithm, referred to as the Multiple Choice Hard Thresholding Pursuit\n(MCHTP), which modifies the popular hard thresholding pursuit (HTP) suitably to\niteratively recover the unknown sparse vector along with the sparsity order of\nthe unknown vector. We provide provable performance guarantees which ensures\nthat MCHTP can estimate the sparsity order exactly, along with recovering the\nunknown sparse vector exactly with noiseless measurements. The simulation\nresults corroborate the theoretical findings, demonstrating that even without\nexact sparsity knowledge, with only the knowledge of a loose upper bound of the\nsparsity, MCHTP exhibits outstanding recovery performance, which is almost\nidentical to that of the conventional HTP with exact sparsity knowledge.\nFurthermore, simulation results demonstrate much lower computational complexity\nof MCHTP compared to other state-of-the-art techniques like MSP.",
    "descriptor": "",
    "authors": [
      "Samrat Mukhopadhyay",
      "Himanshu Bhusan Mishra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07800"
  },
  {
    "id": "arXiv:2210.07802",
    "title": "Object-Category Aware Reinforcement Learning",
    "abstract": "Object-oriented reinforcement learning (OORL) is a promising way to improve\nthe sample efficiency and generalization ability over standard RL. Recent works\nthat try to solve OORL tasks without additional feature engineering mainly\nfocus on learning the object representations and then solving tasks via\nreasoning based on these object representations. However, none of these works\ntries to explicitly model the inherent similarity between different object\ninstances of the same category. Objects of the same category should share\nsimilar functionalities; therefore, the category is the most critical property\nof an object. Following this insight, we propose a novel framework named\nObject-Category Aware Reinforcement Learning (OCARL), which utilizes the\ncategory information of objects to facilitate both perception and reasoning.\nOCARL consists of three parts: (1) Category-Aware Unsupervised Object Discovery\n(UOD), which discovers the objects as well as their corresponding categories;\n(2) Object-Category Aware Perception, which encodes the category information\nand is also robust to the incompleteness of (1) at the same time; (3)\nObject-Centric Modular Reasoning, which adopts multiple independent and\nobject-category-specific networks when reasoning based on objects. Our\nexperiments show that OCARL can improve both the sample efficiency and\ngeneralization in the OORL domain.",
    "descriptor": "\nComments: This paper is to be published on NeurIPS 2022\n",
    "authors": [
      "Qi Yi",
      "Rui Zhang",
      "Shaohui Peng",
      "Jiaming Guo",
      "Xing Hu",
      "Zidong Du",
      "Xishan Zhang",
      "Qi Guo",
      "Yunji Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07802"
  },
  {
    "id": "arXiv:2210.07805",
    "title": "Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set  Active Learning",
    "abstract": "Unlabeled data examples awaiting annotations contain open-set noise\ninevitably. A few active learning studies have attempted to deal with this\nopen-set noise for sample selection by filtering out the noisy examples.\nHowever, because focusing on the purity of examples in a query set leads to\noverlooking the informativeness of the examples, the best balancing of purity\nand informativeness remains an important question. In this paper, to solve this\npurity-informativeness dilemma in open-set active learning, we propose a novel\nMeta-Query-Net,(MQ-Net) that adaptively finds the best balancing between the\ntwo factors. Specifically, by leveraging the multi-round property of active\nlearning, we train MQ-Net using a query set without an additional validation\nset. Furthermore, a clear dominance relationship between unlabeled examples is\neffectively captured by MQ-Net through a novel skyline regularization.\nExtensive experiments on multiple open-set active learning scenarios\ndemonstrate that the proposed MQ-Net achieves 20.14% improvement in terms of\naccuracy, compared with the state-of-the-art methods.",
    "descriptor": "\nComments: to be published in NeurIPS 2022\n",
    "authors": [
      "Dongmin Park",
      "Yooju Shin",
      "Jihwan Bang",
      "Youngjun Lee",
      "Hwanjun Song",
      "Jae-Gil Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07805"
  },
  {
    "id": "arXiv:2210.07806",
    "title": "Comparison of different automatic solutions for resection cavity  segmentation in postoperative MRI volumes including longitudinal acquisitions",
    "abstract": "In this work, we compare five deep learning solutions to automatically\nsegment the resection cavity in postoperative MRI. The proposed methods are\nbased on the same 3D U-Net architecture. We use a dataset of postoperative MRI\nvolumes, each including four MRI sequences and the ground truth of the\ncorresponding resection cavity. Four solutions are trained with a different MRI\nsequence. Besides, a method designed with all the available sequences is also\npresented. Our experiments show that the method trained only with the T1\nweighted contrast-enhanced MRI sequence achieves the best results, with a\nmedian DICE index of 0.81.",
    "descriptor": "",
    "authors": [
      "Luca Canalini",
      "Jan Klein",
      "Nuno Pedrosa de Barros",
      "Diana Maria Sima",
      "Dorothea Miller",
      "Horst Hahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07806"
  },
  {
    "id": "arXiv:2210.07807",
    "title": "Does personality impact requirements engineering Activities?",
    "abstract": "Context: Requirements engineering (RE) is an important part of Software\nEngineering (SE), consisting of various human-centric activities that require\nfrequent collaboration of a variety of roles. Prior research has shown that\npersonality is one such human aspect that has a huge impact on the success of a\nsoftware project. However, a limited number of empirical studies exist focusing\non the impact of personality on RE activities. Objective: The objective of this\nstudy is to explore and identify the impact of personality on RE activities,\nprovide a better understanding of these impacts, and to provide guidance on how\nto better handle these impacts in RE. Method: We used a mixed-methods approach,\nincluding a personality test-based survey (50 participants) and an in-depth\ninterview study (15 participants) with software practitioners from around the\nworld involved in RE activities. Results: Through personality profiles, we\nfound a majority of the practitioners scored as statistically significant\n(high-scored) on agreeableness and conscientiousness traits and average on\nextraversion and neuroticism traits. Through analysis of the interviews, we\nfound a range of impacts related to the personality traits of software\npractitioners, their team members, and external stakeholders. These impacts can\nbe positive or negative, depending on the RE activities, the overall software\ndevelopment process, and the people involved in these activities. Moreover, we\nfound a set of strategies that can be applied to mitigate the negative impact\nof personality on RE activities. Conclusion: Our identified impacts of\npersonality on RE activities and mitigation strategies serve to provide\nguidance to software practitioners on handling such possible personality\nimpacts on RE activities and for researchers to investigate these impacts in\ngreater depth in future.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Software Engineering (TSE), 19 pages, 6 figures, 4 tables\n",
    "authors": [
      "Dulaji Hidellaarachchi",
      "John Grundy",
      "Rashina Hoda",
      "Ingo Mueller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.07807"
  },
  {
    "id": "arXiv:2210.07809",
    "title": "Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks",
    "abstract": "Watermarking has been widely adopted for protecting the intellectual property\n(IP) of Deep Neural Networks (DNN) to defend the unauthorized distribution.\nUnfortunately, the popular data-poisoning DNN watermarking scheme relies on\ntarget model fine-tuning to embed watermarks, which limits its practical\napplications in tackling real-world tasks. Specifically, the learning of\nwatermarks via tedious model fine-tuning on a poisoned dataset\n(carefully-crafted sample-label pairs) is not efficient in tackling the tasks\non challenging datasets and production-level DNN model protection. To address\nthe aforementioned limitations, in this paper, we propose a plug-and-play\nwatermarking scheme for DNN models by injecting an independent proprietary\nmodel into the target model to serve the watermark embedding and ownership\nverification. In contrast to the prior studies, our proposed method by\nincorporating a proprietary model is free of target model fine-tuning without\ninvolving any parameters update of the target model, thus the fidelity is well\npreserved. Our research findings reveal that model fine-tuning with poisoned\ndata is not prepared for the IP protection of DNN models deployed in real-world\ntasks and poses a new research direction toward a more thorough understanding\nand investigation of adopting the proprietary model for DNN watermarking. The\nsource code and models are available at\nhttps://github.com/AntigoneRandy/PTYNet.",
    "descriptor": "",
    "authors": [
      "Run Wang",
      "Jixing Ren",
      "Boheng Li",
      "Tianyi She",
      "Chehao Lin",
      "Liming Fang",
      "Jing Chen",
      "Chao Shen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07809"
  },
  {
    "id": "arXiv:2210.07811",
    "title": "SAILOR: Scaling Anchors via Insights into Latent Object",
    "abstract": "LiDAR 3D object detection models are inevitably biased towards their training\ndataset. The detector clearly exhibits this bias when employed on a target\ndataset, particularly towards object sizes. However, object sizes vary heavily\nbetween domains due to, for instance, different labeling policies or\ngeographical locations. State-of-the-art unsupervised domain adaptation\napproaches outsource methods to overcome the object size bias. Mainstream size\nadaptation approaches exploit target domain statistics, contradicting the\noriginal unsupervised assumption. Our novel unsupervised anchor calibration\nmethod addresses this limitation. Given a model trained on the source data, we\nestimate the optimal target anchors in a completely unsupervised manner. The\nmain idea stems from an intuitive observation: by varying the anchor sizes for\nthe target domain, we inevitably introduce noise or even remove valuable object\ncues. The latent object representation, perturbed by the anchor size, is\nclosest to the learned source features only under the optimal target anchors.\nWe leverage this observation for anchor size optimization. Our experimental\nresults show that, without any retraining, we achieve competitive results even\ncompared to state-of-the-art weakly-supervised size adaptation approaches. In\naddition, our anchor calibration can be combined with such existing methods,\nmaking them completely unsupervised.",
    "descriptor": "\nComments: WACV 2023; code is available at this https URL\n",
    "authors": [
      "Du\u0161an Mali\u0107",
      "Christian Fruhwirth-Reisinger",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07811"
  },
  {
    "id": "arXiv:2210.07812",
    "title": "Surface abnormality detection in medical and inspection systems using  energy variations in co-occurrence matrixes",
    "abstract": "Detection of surface defects is one of the most important issues in the field\nof image processing and machine vision. In this article, a method for detecting\nsurface defects based on energy changes in co-occurrence matrices is presented.\nThe presented method consists of two stages of training and testing. In the\ntraining phase, the co-occurrence matrix operator is first applied on healthy\nimages and then the amount of output energy is calculated. In the following,\naccording to the changes in the amount of energy, a suitable feature vector is\ndefined, and with the help of it, a suitable threshold for the health of the\nimages is obtained. Then, in the test phase, with the help of the calculated\nquorum, the defective parts are distinguished from the healthy ones. In the\nresults section, the mentioned method has been applied on stone and ceramic\nimages and its detection accuracy has been calculated and compared with some\nprevious methods. Among the advantages of the presented method, we can mention\nhigh accuracy, low calculations and compatibility with all types of levels due\nto the use of the training stage. The proposed approach can be used in medical\napplications to detect abnormalities such as diseases. So, the performance is\nevaluated on 2d-hela dataset to classify cell phenotypes. The proposed approach\nprovides about 89.56 percent accuracy on 2d-hela.",
    "descriptor": "",
    "authors": [
      "Nandara K. Krishnand",
      "Akshakhi Kumar Pritoonka",
      "Faeze Kiani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07812"
  },
  {
    "id": "arXiv:2210.07814",
    "title": "A Sequence-Aware Recommendation Method Based on Complex Networks",
    "abstract": "Online stores and service providers rely heavily on recommendation softwares\nto guide users through the vast amount of available products. Consequently, the\nfield of recommender systems has attracted increased attention from the\nindustry and academia alike, but despite this joint effort, the field still\nfaces several challenges. For instance, most existing work models the\nrecommendation problem as a matrix completion problem to predict the user\npreference for an item. This abstraction prevents the system from utilizing the\nrich information from the ordered sequence of user actions logged in online\nsessions. To address this limitation, researchers have recently developed a\npromising new breed of algorithms called sequence-aware recommender systems to\npredict the user's next action by utilizing the time series composed of the\nsequence of actions in an ongoing user session. This paper proposes a novel\nsequence-aware recommendation approach based on a complex network generated by\nthe hidden metric space model, which combines node similarity and popularity to\ngenerate links. We build a network model from data and then use it to predict\nthe user's subsequent actions. The network model provides an additional source\nof information that improves the accuracy of the recommendations. The proposed\nmethod is implemented and tested experimentally on a large dataset. The results\nprove that the proposed approach performs better than state-of-the-art\nrecommendation methods.",
    "descriptor": "",
    "authors": [
      "Abdullah Alhadlaq",
      "Said Kerrache",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07814"
  },
  {
    "id": "arXiv:2210.07815",
    "title": "Intra-session Context-aware Feed Recommendation in Live Systems",
    "abstract": "Feed recommendation allows users to constantly browse items until feel\nuninterested and leave the session, which differs from traditional\nrecommendation scenarios. Within a session, user's decision to continue\nbrowsing or not substantially affects occurrences of later clicks. However,\nsuch type of exposure bias is generally ignored or not explicitly modeled in\nmost feed recommendation studies. In this paper, we model this effect as part\nof intra-session context, and propose a novel intra-session Context-aware Feed\nRecommendation (INSCAFER) framework to maximize the total views and total\nclicks simultaneously. User click and browsing decisions are jointly learned by\na multi-task setting, and the intra-session context is encoded by the\nsession-wise exposed item sequence. We deploy our model on Alipay with all key\nbusiness benchmarks improved. Our method sheds some lights on feed\nrecommendation studies which aim to optimize session-level click and view\nmetrics.",
    "descriptor": "\nComments: 5 pages, 4 figures, CIKM 2022 short paper\n",
    "authors": [
      "Luo Ji",
      "Gao Liu",
      "Mingyang Yin",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07815"
  },
  {
    "id": "arXiv:2210.07816",
    "title": "A Recommendation Approach based on Similarity-Popularity Models of  Complex Networks",
    "abstract": "Recommender systems have become an essential tool for providers and users of\nonline services and goods, especially with the increased use of the Internet to\naccess information and purchase products and services. This work proposes a\nnovel recommendation method based on complex networks generated by a\nsimilarity-popularity model to predict ones. We first construct a model of a\nnetwork having users and items as nodes from observed ratings and then use it\nto predict unseen ratings. The prospect of producing accurate rating\npredictions using a similarity-popularity model with hidden metric spaces and\ndot-product similarity is explored. The proposed approach is implemented and\nexperimentally compared against baseline and state-of-the-art recommendation\nmethods on 21 datasets from various domains. The experimental results\ndemonstrate that the proposed method produces accurate predictions and\noutperforms existing methods. We also show that the proposed approach produces\nsuperior results in low dimensions, proving its effectiveness for data\nvisualization and exploration.",
    "descriptor": "",
    "authors": [
      "Abdullah Alhadlaq",
      "Said Kerrache",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07816"
  },
  {
    "id": "arXiv:2210.07817",
    "title": "Discussion about Attacks and Defenses for Fair and Robust Recommendation  System Design",
    "abstract": "Information has exploded on the Internet and mobile with the advent of the\nbig data era. In particular, recommendation systems are widely used to help\nconsumers who struggle to select the best products among such a large amount of\ninformation. However, recommendation systems are vulnerable to malicious user\nbiases, such as fake reviews to promote or demote specific products, as well as\nattacks that steal personal information. Such biases and attacks compromise the\nfairness of the recommendation model and infringe the privacy of users and\nsystems by distorting data.Recently, deep-learning collaborative filtering\nrecommendation systems have shown to be more vulnerable to this bias. In this\nposition paper, we examine the effects of bias that cause various ethical and\nsocial issues, and discuss the need for designing the robust recommendation\nsystem for fairness and stability.",
    "descriptor": "",
    "authors": [
      "Mirae Kim",
      "Simon Woo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07817"
  },
  {
    "id": "arXiv:2210.07822",
    "title": "Shadfa 0.1: The Iranian Movie Knowledge Graph and Graph-Embedding-Based  Recommender System",
    "abstract": "Movies are a great source of entertainment. However, the problem arises when\none is trying to find the desired content within this vast amount of data which\nis significantly increasing every year. Recommender systems can provide\nappropriate algorithms to solve this problem. The content_based technique has\nfound popularity due to the lack of available user data in most cases.\nContent_based recommender systems are based on the similarity of items'\ndemographic information; Term Frequency _ Inverse Document Frequency (TF_IDF)\nand Knowledge Graph Embedding (KGE) are two approaches used to vectorize data\nto calculate these similarities. In this paper, we propose a weighted\ncontent_based movie RS by combining TF_IDF which is an appropriate approach for\nembedding textual data such as plot/description, and KGE which is used to embed\nnamed entities such as the director's name. The weights between features are\ndetermined using a Genetic algorithm. Additionally, the Iranian movies dataset\nis created by scraping data from movie_related websites. This dataset and the\nstructure of the FarsBase KG are used to create the MovieFarsBase KG which is a\ncomponent in the implementation process of the proposed content_based RS. Using\nprecision, recall, and F1 score metrics, this study shows that the proposed\napproach outperforms the conventional approach that uses TF_IDF for embedding\nall attributes.",
    "descriptor": "\nComments: 7 pages and 6 figures\n",
    "authors": [
      "Rayhane Pouyan",
      "Hadi Kalamati",
      "Hannane Ebrahimian",
      "Mohammad Karrabi",
      "Mohammad-R. Akbarzadeh-T"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07822"
  },
  {
    "id": "arXiv:2210.07826",
    "title": "Low-power In-pixel Computing with Current-modulated Switched Capacitors",
    "abstract": "We present a scalable in-pixel processing architecture that can reduce the\ndata throughput by 10X and consume less than 30 mW per megapixel at the imager\nfrontend. Unlike the state-of-the-art (SOA) analog process-in-pixel (PIP) that\nmodulates the exposure time of photosensors when performing matrix-vector\nmultiplications, we use switched capacitors and pulse width modulation (PWM).\nThis non-destructive approach decouples the sensor exposure and computing,\nproviding processing parallelism and high data fidelity. Our design minimizes\nthe computational complexity and chip density by leveraging the patch-based\nfeature extraction that can perform as well as the CNN. We further reduce data\nusing partial observation of the attended objects, which performs closely to\nthe full frame observations. We have been studying the reduction of output\nfeatures as a function of accuracy, chip density and power consumption from a\ntransformer-based backend model for object classification and detection.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "David Zhang",
      "Gooitzen van der Wal",
      "Saurabh Farkya",
      "Thomas Senko",
      "Aswin Raghavan",
      "Michael Isnardi",
      "Michael Piacentino"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.07826"
  },
  {
    "id": "arXiv:2210.07827",
    "title": "Stabilized exponential time differencing schemes for the convective  Allen-Cahn equation",
    "abstract": "The convective Allen-Cahn equation has been widely used to simulate\nmulti-phase flows in many phase-field models. As a generalized form of the\nclassic Allen-Cahn equation, the convective Allen-Cahn equation still preserves\nthe maximum bound principle (MBP) in the sense that the time-dependent solution\nof the equation with appropriate initial and boundary conditions preserves for\nall time a uniform pointwise bound in absolute value. In this paper, we develop\nefficient first- and second-order exponential time differencing (ETD) schemes\ncombined with the linear stabilizing technique to preserve the MBP\nunconditionally in the discrete setting. The space discretization is done using\nthe upwind difference scheme for the convective term and the central difference\nscheme for the diffusion term, and both the mobility and nonlinear terms are\napproximated through the linear convex interpolation. The unconditional\npreservation of the MBP of the proposed schemes is proven, and their\nconvergence analysis is presented. Various numerical experiments in two and\nthree dimensions are also carried out to verify the theoretical results.",
    "descriptor": "",
    "authors": [
      "Yongyong Cai",
      "Lili Ju",
      "Rihui Lan",
      "Jingwei Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07827"
  },
  {
    "id": "arXiv:2210.07828",
    "title": "Parameter-Free Average Attention Improves Convolutional Neural Network  Performance (Almost) Free of Charge",
    "abstract": "Visual perception is driven by the focus on relevant aspects in the\nsurrounding world. To transfer this observation to the digital information\nprocessing of computers, attention mechanisms have been introduced to highlight\nsalient image regions. Here, we introduce a parameter-free attention mechanism\ncalled PfAAM, that is a simple yet effective module. It can be plugged into\nvarious convolutional neural network architectures with a little computational\noverhead and without affecting model size. PfAAM was tested on multiple\narchitectures for classification and segmentic segmentation leading to improved\nmodel performance for all tested cases. This demonstrates its wide\napplicability as a general easy-to-use module for computer vision tasks. The\nimplementation of PfAAM can be found on https://github.com/nkoerb/pfaam.",
    "descriptor": "",
    "authors": [
      "Nils K\u00f6rber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07828"
  },
  {
    "id": "arXiv:2210.07829",
    "title": "Asymmetric Student-Teacher Networks for Industrial Anomaly Detection",
    "abstract": "Industrial defect detection is commonly addressed with anomaly detection (AD)\nmethods where no or only incomplete data of potentially occurring defects is\navailable. This work discovers previously unknown problems of student-teacher\napproaches for AD and proposes a solution, where two neural networks are\ntrained to produce the same output for the defect-free training examples. The\ncore assumption of student-teacher networks is that the distance between the\noutputs of both networks is larger for anomalies since they are absent in\ntraining. However, previous methods suffer from the similarity of student and\nteacher architecture, such that the distance is undesirably small for\nanomalies. For this reason, we propose asymmetric student-teacher networks\n(AST). We train a normalizing flow for density estimation as a teacher and a\nconventional feed-forward network as a student to trigger large distances for\nanomalies: The bijectivity of the normalizing flow enforces a divergence of\nteacher outputs for anomalies compared to normal data. Outside the training\ndistribution the student cannot imitate this divergence due to its\nfundamentally different architecture. Our AST network compensates for wrongly\nestimated likelihoods by a normalizing flow, which was alternatively used for\nanomaly detection in previous work. We show that our method produces\nstate-of-the-art results on the two currently most relevant defect detection\ndatasets MVTec AD and MVTec 3D-AD regarding image-level anomaly detection on\nRGB and 3D data.",
    "descriptor": "\nComments: accepted to WACV 2023\n",
    "authors": [
      "Marco Rudolph",
      "Tom Wehrbein",
      "Bodo Rosenhahn",
      "Bastian Wandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07829"
  },
  {
    "id": "arXiv:2210.07832",
    "title": "Awareness and usage of SWAYAM course among library and information  science students a survey",
    "abstract": "The Government of India initiated SWAYAM (Study Webs of Active-learning for\nYoung Aspiring Minds), where the objective of the programme is to take the best\nteaching and learning resources to all with no costs. To find out the awareness\nand usage of SWAYAM courses among Library and Information science students,\nsurvey method of research used. To collect data from selective Universities\nstudents a structured questionnaire was prepared. The results show that most of\nthe responses received from Annamalai University, majority respondents are\naware of SWAYAM course. Respondents are aware of these courses through their\nteachers. 74.73 percent of respondents replied that their University providing\norientation programme on SWAYAM. Half of the respondents prefer Word file\nformat for submitting their assignment. More than 82 percent of respondents are\nspending 1 to 3 hours for SWAYAM course. Half of the respondents are agreed\nSWAYAM courses help to gain new knowledge and supports life-long learning.\nFurther, the result reveals that the numbers of students continue their\nenrolled courses and only less number were discontinued due to some reasons",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Fakrudhin Ali Ahamed"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.07832"
  },
  {
    "id": "arXiv:2210.07834",
    "title": "An atom's worth of anonymity",
    "abstract": "Anonymity has gained notoriety in modern times as data about our actions and\nchoices accumulates in the internet partly unbeknownst to us and partly by our\nown choice. Usually people wish some data about themselves were private while\nsome other date may be public or is even wanted to be public for publicity\nreasons. There are different criteria which characterize the degree of\nanonymity of data. Given data can also be anonymized by different techniques in\norder to increase its degree of anonymity. In this paper we take a very simple\n\"atomic\" degree of anonymity as our starting place. We axiomatize these atoms\nand propose the investigation of first order logic based on these atoms.\nConsidering the vast literature and the huge importance of anonymity our\ninvestigation may seem quite modest. However, it is about the logic of\nanonymity, not about how to secure, create or break anonymity.",
    "descriptor": "",
    "authors": [
      "Jouko V\u00e4\u00e4n\u00e4nen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07834"
  },
  {
    "id": "arXiv:2210.07836",
    "title": "A real-time GP based MPC for quadcopters with unknown disturbances",
    "abstract": "Gaussian Process (GP) regressions have proven to be a valuable tool to\npredict disturbances and model mismatches and incorporate this information into\na Model Predictive Control (MPC) prediction. Unfortunately, the computational\ncomplexity of inference and learning on classical GPs scales cubically, which\nis intractable for real-time applications. Thus GPs are commonly trained\noffline, which is not suited for learning disturbances as their dynamics may\nvary with time. Recently, state-space formulation of GPs has been introduced,\nallowing inference and learning with linear computational complexity. This\npaper presents a framework that enables online learning of disturbance dynamics\non quadcopters, which can be executed within milliseconds using a state-space\nformulation of GPs. The obtained disturbance predictions are combined with MPC\nleading to a significant performance increase in simulations with jMAVSim. The\ncomputational burden is evaluated on a Raspberry Pi 4 B to prove the real-time\napplicability.",
    "descriptor": "\nComments: Published at American Control Conference (ACC 2022), Atlanta, GA, USA, June 8 to 10, 2022\n",
    "authors": [
      "Niklas Schmid",
      "Jonas Gruner",
      "Hossam S. Abbas",
      "Philipp Rostalski"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07836"
  },
  {
    "id": "arXiv:2210.07838",
    "title": "Fields2Cover: An open-source coverage path planning library for unmanned  agricultural vehicles",
    "abstract": "This paper describes Fields2Cover, a novel open source library for coverage\npath planning (CPP) for agricultural vehicles. While there are several CPP\nsolutions nowadays, there have been limited efforts to unify them into an open\nsource library and provide benchmarking tools to compare their performance.\nFields2Cover provides a framework for planning coverage paths, developing novel\ntechniques, and benchmarking state-of-the-art algorithms. The library features\na modular and extensible architecture that supports various vehicles and can be\nused for a variety of applications, including farms. Its core modules are: a\nheadland generator, a swath generator, a route planner and a path planner. An\ninterface to the Robot Operating System (ROS) is also supplied as an add-on. In\nthis paper, the functionalities of the library for planning a coverage path in\nagriculture are demonstrated using 8 state-of-the-art methods and 7 objective\nfunctions in simulation and field experiments.",
    "descriptor": "\nComments: 7 pages, 5 figures, 2 tables\n",
    "authors": [
      "Gonzalo Mier",
      "Jo\u00e3o Valente",
      "Sytze de Bruin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.07838"
  },
  {
    "id": "arXiv:2210.07839",
    "title": "Contrastive Audio-Visual Masked Autoencoder",
    "abstract": "In this paper, we first extend the recent Masked Auto-Encoder (MAE) model\nfrom a single modality to audio-visual multi-modalities. Subsequently, we\npropose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining\ncontrastive learning and masked data modeling, two major self-supervised\nlearning frameworks, to learn a joint and coordinated audio-visual\nrepresentation. Our experiments show that the contrastive audio-visual\ncorrespondence learning objective not only enables the model to perform\naudio-visual retrieval tasks, but also helps the model learn a better joint\nrepresentation. As a result, our fully self-supervised pretrained CAV-MAE\nachieves a new SOTA accuracy of 65.9% on VGGSound, and is comparable with the\nprevious best supervised pretrained model on AudioSet in the audio-visual event\nclassification task.",
    "descriptor": "",
    "authors": [
      "Yuan Gong",
      "Andrew Rouditchenko",
      "Alexander H. Liu",
      "David Harwath",
      "Leonid Karlinsky",
      "Hilde Kuehne",
      "James Glass"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07839"
  },
  {
    "id": "arXiv:2210.07842",
    "title": "ENTS: An Edge-native Task Scheduling System for Collaborative Edge  Computing",
    "abstract": "Collaborative edge computing (CEC) is an emerging paradigm enabling sharing\nof the coupled data, computation, and networking resources among heterogeneous\ngeo-distributed edge nodes. Recently, there has been a trend to orchestrate and\nschedule containerized application workloads in CEC, while Kubernetes has\nbecome the de-facto standard broadly adopted by the industry and academia.\nHowever, Kubernetes is not preferable for CEC because its design is not\ndedicated to edge computing and neglects the unique features of edge\nnativeness. More specifically, Kubernetes primarily ensures resource provision\nof workloads while neglecting the performance requirements of edge-native\napplications, such as throughput and latency. Furthermore, Kubernetes neglects\nthe inner dependencies of edge-native applications and fails to consider data\nlocality and networking resources, leading to inferior performance. In this\nwork, we design and develop ENTS, the first edge-native task scheduling system,\nto manage the distributed edge resources and facilitate efficient task\nscheduling to optimize the performance of edge-native applications. ENTS\nextends Kubernetes with the unique ability to collaboratively schedule\ncomputation and networking resources by comprehensively considering job profile\nand resource status. We showcase the superior efficacy of ENTS with a case\nstudy on data streaming applications. We mathematically formulate a joint task\nallocation and flow scheduling problem that maximizes the job throughput. We\ndesign two novel online scheduling algorithms to optimally decide the task\nallocation, bandwidth allocation, and flow routing policies. The extensive\nexperiments on a real-world edge video analytics application show that ENTS\nachieves 43\\%-220\\% higher average job throughput compared with the\nstate-of-the-art.",
    "descriptor": "\nComments: The Seventh ACM/IEEE Symposium on Edge Computing (SEC), 2022\n",
    "authors": [
      "Mingjin Zhang",
      "Jiannong Cao",
      "Lei Yang",
      "Liang Zhang",
      "Yuvraj Sahni",
      "Shan Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07842"
  },
  {
    "id": "arXiv:2210.07845",
    "title": "Realizing Flame State Monitoring with Very Few Visual or Infrared Images  via Few-Shot Learning",
    "abstract": "The success of current machine learning on image-based combustion monitoring\nis based on massive data, which is costly even impossible for industrial\napplications. To address this conflict, we introduce few-shot learning to\ncombustion monitoring for the first time. Two algorithms, Siamese Network\ncoupled with k Nearest Neighbors (SN-kNN) and Prototypical Network (PN), are\nattempted. Besides, rather than purely utilizing visual images as previous\nstudies, we also attempt Infrared (IR) images. In this work, we analyze the\ntraining process, test performance and inference speed of two algorithms on\nboth image formats, and also use t-SNE to visualize learned features. The\nresults demonstrate that both SN-kNN and PN are capable to distinguish flame\nstates from learning with 20 images per flame state. The worst performance,\nwhich is realized by combination of PN and IR images, still possesses\nprecision, accuracy, recall, and F1-score all above 0.95. Through observing\nimages and visualizing features, we realize that visual images have more\ndramatic differences between classes and have more consistent patterns inside\nthe class, which makes the training speed and model performance on visual\nimages is better. In contrast, the relatively \"low-quality\" IR images makes PN\nhard to extract distinguishable prototypes, which causes the relative weak\nperformance, but with the whole training set to support classification, SN-kNN\ncooperates well with IR images. On the other hand, benefited from the\narchitecture design, PN has a much faster speed in training and inference than\nSN-kNN. The work here analyzes the characteristics of both algorithms and image\nformats for the first time, which provides the guidance for further utilizing\nthem in combustion monitoring tasks.",
    "descriptor": "\nComments: 15 pages, 12 figures, four tables\n",
    "authors": [
      "Ruiyuan Kang",
      "Panos Liatsis",
      "Dimitrios C. Kyritsis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07845"
  },
  {
    "id": "arXiv:2210.07848",
    "title": "Convolutional Neural Networks: Basic Concepts and Applications in  Manufacturing",
    "abstract": "We discuss basic concepts of convolutional neural networks (CNNs) and outline\nuses in manufacturing. We begin by discussing how different types of data\nobjects commonly encountered in manufacturing (e.g., time series, images,\nmicrographs, videos, spectra, molecular structures) can be represented in a\nflexible manner using tensors and graphs. We then discuss how CNNs use\nconvolution operations to extract informative features (e.g., geometric\npatterns and textures) from the such representations to predict emergent\nproperties and phenomena and/or to identify anomalies. We also discuss how CNNs\ncan exploit color as a key source of information, which enables the use of\nmodern computer vision hardware (e.g., infrared, thermal, and hyperspectral\ncameras). We illustrate the concepts using diverse case studies arising in\nspectral analysis, molecule design, sensor design, image-based control, and\nmultivariate process monitoring.",
    "descriptor": "",
    "authors": [
      "Shengli Jiang",
      "Shiyi Qin",
      "Joshua L. Pulsipher",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07848"
  },
  {
    "id": "arXiv:2210.07851",
    "title": "Learning to Autonomously Reach Objects with NICO and Grow-When-Required  Networks",
    "abstract": "The act of reaching for an object is a fundamental yet complex skill for a\nrobotic agent, requiring a high degree of visuomotor control and coordination.\nIn consideration of dynamic environments, a robot capable of autonomously\nadapting to novel situations is desired. In this paper, a developmental\nrobotics approach is used to autonomously learn visuomotor coordination on the\nNICO (Neuro-Inspired COmpanion) platform, for the task of object reaching. The\nrobot interacts with its environment and learns associations between motor\ncommands and temporally correlated sensory perceptions based on Hebbian\nlearning. Multiple Grow-When-Required (GWR) networks are used to learn\nincreasingly more complex motoric behaviors, by first learning how to direct\nthe gaze towards a visual stimulus, followed by learning motor control of the\narm, and finally learning how to reach for an object using eye-hand\ncoordination. We demonstrate that the model is able to deal with an unforeseen\nmechanical change in the NICO's body, showing the adaptability of the proposed\napproach. In evaluations of our approach, we show that the humanoid robot NICO\nis able to reach objects with a 76% success rate.",
    "descriptor": "\nComments: Accepted at the 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022)\n",
    "authors": [
      "Nima Rahrakhshan",
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Nicolas Duczek",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07851"
  },
  {
    "id": "arXiv:2210.07852",
    "title": "Bringing NURC/SP to Digital Life: the Role of Open-source Automatic  Speech Recognition Models",
    "abstract": "The NURC Project that started in 1969 to study the cultured linguistic urban\nnorm spoken in five Brazilian capitals, was responsible for compiling a large\ncorpus for each capital. The digitized NURC/SP comprises 375 inquiries in 334\nhours of recordings taken in S\\~ao Paulo capital. Although 47 inquiries have\ntranscripts, there was no alignment between the audio-transcription, and 328\ninquiries were not transcribed. This article presents an evaluation and error\nanalysis of three automatic speech recognition models trained with spontaneous\nspeech in Portuguese and one model trained with prepared speech. The evaluation\nallowed us to choose the best model, using WER and CER metrics, in a manually\naligned sample of NURC/SP, to automatically transcribe 284 hours.",
    "descriptor": "",
    "authors": [
      "Lucas Rafael Stefanel Gris",
      "Arnaldo Candido Junior",
      "Vin\u00edcius G. dos Santos",
      "Bruno A. Papa Dias",
      "Marli Quadros Leite",
      "Flaviane Romani Fernandes Svartman",
      "Sandra Alu\u00edsio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07852"
  },
  {
    "id": "arXiv:2210.07860",
    "title": "Super-localization of spatial network models",
    "abstract": "Spatial network models are used as a simplified discrete representation in a\nwide range of applications, e.g., flow in blood vessels, elasticity of fiber\nbased materials, and pore network models of porous materials. Nevertheless, the\nresulting linear systems are typically large and poorly conditioned and their\nnumerical solution is challenging.\nThis paper proposes a numerical homogenization technique for spatial network\nmodels which is based on the Super Localized Orthogonal Decomposition (SLOD),\nrecently introduced for elliptic multiscale partial differential equations. It\nprovides accurate coarse solution spaces with approximation properties\nindependent of the smoothness of the material data. A unique selling point of\nthe SLOD is that it constructs an almost local basis of these coarse spaces,\nrequiring less computations on the fine scale and achieving improved sparsity\non the coarse scale compared to other state-of-the-art methods. We provide an\na-posteriori analysis of the proposed method and numerically confirm the\nmethod's unique localization properties. In addition, we show its applicability\nalso for high-contrast channeled material data.",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Moritz Hauck",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07860"
  },
  {
    "id": "arXiv:2210.07861",
    "title": "A compatible finite element discretisation for the nonhydrostatic  vertical slice equations",
    "abstract": "We present a compatible finite element discretisation for the vertical slice\ncompressible Euler equations, at next-to-lowest order (i.e., the pressure space\nis bilinear discontinuous functions. The equations are numerically integrated\nin time using a fully implicit timestepping scheme which is solved using\nmonolithic GMRES preconditioned by a linesmoother. This is implemented using\nFiredrake, and the additive Schwarz preconditioner framework of PETSc. We\ndemonstrate the robustness of the scheme using a standard set of testcases that\nmay be compared with other approaches.",
    "descriptor": "",
    "authors": [
      "C. J. Cotter",
      "J. Shipton"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07861"
  },
  {
    "id": "arXiv:2210.07862",
    "title": "Unsupervised Dense Nuclei Detection and Segmentation with Prior  Self-activation Map For Histology Images",
    "abstract": "The success of supervised deep learning models in medical image segmentation\nrelies on detailed annotations. However, labor-intensive manual labeling is\ncostly and inefficient, especially in dense object segmentation. To this end,\nwe propose a self-supervised learning based approach with a Prior\nSelf-activation Module (PSM) that generates self-activation maps from the input\nimages to avoid labeling costs and further produce pseudo masks for the\ndownstream task. To be specific, we firstly train a neural network using\nself-supervised learning and utilize the gradient information in the shallow\nlayers of the network to generate self-activation maps. Afterwards, a\nsemantic-guided generator is then introduced as a pipeline to transform visual\nrepresentations from PSM to pixel-level semantic pseudo masks for downstream\ntasks. Furthermore, a two-stage training module, consisting of a nuclei\ndetection network and a nuclei segmentation network, is adopted to achieve the\nfinal segmentation. Experimental results show the effectiveness on two public\npathological datasets. Compared with other fully-supervised and\nweakly-supervised methods, our method can achieve competitive performance\nwithout any manual annotations.",
    "descriptor": "",
    "authors": [
      "Pingyi Chen",
      "Chenglu Zhu",
      "Zhongyi Shui",
      "Jiatong Cai",
      "Sunyi Zheng",
      "Shichuan Zhang",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07862"
  },
  {
    "id": "arXiv:2210.07863",
    "title": "Revisiting Optimal Convergence Rate for Smooth and Non-convex Stochastic  Decentralized Optimization",
    "abstract": "Decentralized optimization is effective to save communication in large-scale\nmachine learning. Although numerous algorithms have been proposed with\ntheoretical guarantees and empirical successes, the performance limits in\ndecentralized optimization, especially the influence of network topology and\nits associated weight matrix on the optimal convergence rate, have not been\nfully understood. While (Lu and Sa, 2021) have recently provided an optimal\nrate for non-convex stochastic decentralized optimization with weight matrices\ndefined over linear graphs, the optimal rate with general weight matrices\nremains unclear.\nThis paper revisits non-convex stochastic decentralized optimization and\nestablishes an optimal convergence rate with general weight matrices. In\naddition, we also establish the optimal rate when non-convex loss functions\nfurther satisfy the Polyak-Lojasiewicz (PL) condition. Following existing lines\nof analysis in literature cannot achieve these results. Instead, we leverage\nthe Ring-Lattice graph to admit general weight matrices while maintaining the\noptimal relation between the graph diameter and weight matrix connectivity.\nLastly, we develop a new decentralized algorithm to nearly attain the above two\noptimal rates under additional mild conditions.",
    "descriptor": "",
    "authors": [
      "Kun Yuan",
      "Xinmeng Huang",
      "Yiming Chen",
      "Xiaohan Zhang",
      "Yingya Zhang",
      "Pan Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.07863"
  },
  {
    "id": "arXiv:2210.07864",
    "title": "Unwarranted Gender Disparity in Online P2P Lending: Evidence of  Affirmative Action",
    "abstract": "Closing the gender gap in financial access is important. Most research tends\nto empirically uncover the direct effect of gender on decisions. Yet, this view\noverlooks other indirect channels of gender discrimination, leading to systemic\nbias in identifying the overall discrimination effect. In this work, by\ncollaborating with one of the largest online P2P lending platforms in China, we\nestimate a broadened discrimination notion called unwarranted gender disparity\n(UGD). UGD recognizes any disparate lending decisions that do not commensurate\nwith the loan's return rate, encompassing direct, indirect, and proxy\ndiscrimination. We develop a two-stage predictor substitution (2SPS) approach\nto estimate UGD. Somewhat surprisingly, we find significant female favoritism\nat almost all return rate levels. On average, female borrowers are 3.97% more\nlikely to be funded than male borrowers with identical return rates. We further\ndecompose and find at least 37.1% of UGD is indeed indirect or proxy\ndiscrimination. However, we also identify the observed UGD favoring female can\nbe completely attributed to \\emph{accurate statistical distribution}, which is\nrationalized by women being less likely to default on their P2P loans. Our\nresults suggest that online P2P lending can complement traditional bank lending\nin closing the gender gap, by providing an alternative credit market where the\naffirmative action to support women can arise naturally from the rational\ncrowd.",
    "descriptor": "\nComments: preprint, under review\n",
    "authors": [
      "Xudong Shen",
      "Tianhui Tan",
      "Tuan Q. Phan",
      "Jussi Keppo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.07864"
  },
  {
    "id": "arXiv:2210.07869",
    "title": "Witnessed Symmetric Choice and Interpretations in Fixed-Point Logic with  Counting",
    "abstract": "At the core of the quest for a logic for PTime is a mismatch between\nalgorithms making arbitrary choices and isomorphism-invariant logics. One\napproach to overcome this problem is witnessed symmetric choice. It allows for\nchoices from definable orbits which are certified by definable witnessing\nautomorphisms.\nWe consider the extension of fixed-point logic with counting (IFPC) with\nwitnessed symmetric choice (IFPC+WSC) and a further extension with an\ninterpretation operator (IFP+WSC+I). The latter operator evaluates a subformula\nin the structure defined by an interpretation. This structure possibly has\nother automorphisms exploitable by the WSC-operator. For similar extensions of\npure fixed-point logic (IFP) it is known that IFP+WSC+I simulates counting\nwhich IFP+WSC fails to do. For IFPC it is unknown whether the interpretation\noperator increases expressiveness and thus allows studying the relation between\nWSC and interpretations beyond counting.\nIn this paper, we prove that if IFPC+WSC+I canonizes a particular class of\nbase graphs, then it also canonizes the corresponding CFI graphs. This differs\nfrom various other logics, where CFI graphs provide difficult instances. To\ncanonize CFI graphs, we nest WSC and interpretation operators. We show that for\nCFI graphs this deeper nesting is indeed necessary. Lastly, we separate\nIFPC+WSC from IFPC+WSC+I, so for IFPC the interpretation operator increases\nexpressiveness, too. In particular, IFPC+WSC is not closed under FO-reductions.",
    "descriptor": "",
    "authors": [
      "Moritz Lichter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07869"
  },
  {
    "id": "arXiv:2210.07871",
    "title": "One Graph to Rule them All: Using NLP and Graph Neural Networks to  analyse Tolkien's Legendarium",
    "abstract": "Natural Language Processing and Machine Learning have considerably advanced\nComputational Literary Studies. Similarly, the construction of co-occurrence\nnetworks of literary characters, and their analysis using methods from social\nnetwork analysis and network science, have provided insights into the micro-\nand macro-level structure of literary texts. Combining these perspectives, in\nthis work we study character networks extracted from a text corpus of J.R.R.\nTolkien's Legendarium. We show that this perspective helps us to analyse and\nvisualise the narrative style that characterises Tolkien's works. Addressing\ncharacter classification, embedding and co-occurrence prediction, we further\ninvestigate the advantages of state-of-the-art Graph Neural Networks over a\npopular word embedding method. Our results highlight the large potential of\ngraph learning in Computational Literary Studies.",
    "descriptor": "",
    "authors": [
      "Vincenzo Perri",
      "Lisi Qarkaxhija",
      "Albin Zehe",
      "Andreas Hotho",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07871"
  },
  {
    "id": "arXiv:2210.07873",
    "title": "A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing",
    "abstract": "Foundational Hebrew NLP tasks such as segmentation, tagging and parsing, have\nrelied to date on various versions of the Hebrew Treebank (HTB, Sima'an et al.\n2001). However, the data in HTB, a single-source newswire corpus, is now over\n30 years old, and does not cover many aspects of contemporary Hebrew on the\nweb. This paper presents a new, freely available UD treebank of Hebrew\nstratified from a range of topics selected from Hebrew Wikipedia. In addition\nto introducing the corpus and evaluating the quality of its annotations, we\ndeploy automatic validation tools based on grew (Guillaume, 2021), and conduct\nthe first cross domain parsing experiments in Hebrew. We obtain new\nstate-of-the-art (SOTA) results on UD NLP tasks, using a combination of the\nlatest language modelling and some incremental improvements to existing\ntransformer based approaches. We also release a new version of the UD HTB\nmatching annotation scheme updates from our new corpus.",
    "descriptor": "\nComments: Proceedings of EMNLP 2022\n",
    "authors": [
      "Amir Zeldes",
      "Nick Howell",
      "Noam Ordan",
      "Yifat Ben Moshe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07873"
  },
  {
    "id": "arXiv:2210.07876",
    "title": "Control, Confidentiality, and the Right to be Forgotten",
    "abstract": "Recent digital rights frameworks stipulate an ability (e.g., the ``right to\nbe forgotten'' embodied in the GDPR and CCPA) to request that a \\textit{data\ncontroller} -- roughly, any system that stores and manipulates personal\ninformation -- \\emph{delete} one's data. We ask how deletion should be\nformalized in complex systems that interact with many parties and store\nderivative information. There are two broad principles at work in existing\napproaches to formalizing deletion: \\emph{confidentiality} and \\emph{control}.\nWe build a unified formalism for deletion that encompasses previous approaches\nas special cases. We argue that existing work on deletion-as-control (in\nparticular, ``machine unlearning'') can be reframed in the language of\n(adaptive) history independence, for which we provide a general definition. We\nalso show classes of controllers, such as those that publish differentially\nprivate statistics without later updating them, that satisfy intuitive notions\nof deletion and our formal definition, but which fall outside the scope of\nprevious approaches.",
    "descriptor": "",
    "authors": [
      "Aloni Cohen",
      "Adam Smith",
      "Marika Swanberg",
      "Prashant Nalini Vasudevan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.07876"
  },
  {
    "id": "arXiv:2210.07879",
    "title": "Hierarchical Approach for Joint Semantic, Plant Instance, and Leaf  Instance Segmentation in the Agricultural Domain",
    "abstract": "Plant phenotyping is a central task in agriculture, as it describes plants'\ngrowth stage, development, and other relevant quantities. Robots can help\nautomate this process by accurately estimating plant traits such as the number\nof leaves, leaf area, and the plant size. In this paper, we address the problem\nof joint semantic, plant instance, and leaf instance segmentation of crop\nfields from RGB data. We propose a single convolutional neural network that\naddresses the three tasks simultaneously, exploiting their underlying\nhierarchical structure. We introduce task-specific skip connections, which our\nexperimental evaluation proves to be more beneficial than the usual schemes. We\nalso propose a novel automatic post-processing, which explicitly addresses the\nproblem of spatially close instances, common in the agricultural domain because\nof overlapping leaves. Our architecture simultaneously tackles these problems\njointly in the agricultural context. Previous works either focus on plant or\nleaf segmentation, or do not optimise for semantic segmentation. Results show\nthat our system has superior performance to state-of-the-art approaches, while\nhaving a reduced number of parameters and is operating at camera frame rate.",
    "descriptor": "\nComments: 6+1 pages, submitted to the IEEE International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Gianmarco Roggiolani",
      "Matteo Sodano",
      "Tiziano Guadagnino",
      "Federico Magistri",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07879"
  },
  {
    "id": "arXiv:2210.07883",
    "title": "One Model to Edit Them All: Free-Form Text-Driven Image Manipulation  with Semantic Modulations",
    "abstract": "Free-form text prompts allow users to describe their intentions during image\nmanipulation conveniently. Based on the visual latent space of StyleGAN[21] and\ntext embedding space of CLIP[34], studies focus on how to map these two latent\nspaces for text-driven attribute manipulations. Currently, the latent mapping\nbetween these two spaces is empirically designed and confines that each\nmanipulation model can only handle one fixed text prompt. In this paper, we\npropose a method named Free-Form CLIP (FFCLIP), aiming to establish an\nautomatic latent mapping so that one manipulation model handles free-form text\nprompts. Our FFCLIP has a cross-modality semantic modulation module containing\nsemantic alignment and injection. The semantic alignment performs the automatic\nlatent mapping via linear transformations with a cross attention mechanism.\nAfter alignment, we inject semantics from text prompt embeddings to the\nStyleGAN latent space. For one type of image (e.g., `human portrait'), one\nFFCLIP model can be learned to handle free-form text prompts. Meanwhile, we\nobserve that although each training text prompt only contains a single semantic\nmeaning, FFCLIP can leverage text prompts with multiple semantic meanings for\nimage manipulation. In the experiments, we evaluate FFCLIP on three types of\nimages (i.e., `human portraits', `cars', and `churches'). Both visual and\nnumerical results show that FFCLIP effectively produces semantically accurate\nand visually realistic images. Project page:\nhttps://github.com/KumapowerLIU/FFCLIP.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yiming Zhu",
      "Hongyu Liu",
      "Yibing Song",
      "iyang Yuan",
      "Xintong Han",
      "Chun Yuan",
      "Qifeng Chen",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07883"
  },
  {
    "id": "arXiv:2210.07884",
    "title": "SealClub: Computer-aided Paper Document Authentication",
    "abstract": "Digital authentication is a mature field, offering a range of solutions with\nrigorous mathematical guarantees. Nevertheless, paper documents, where\ncryptographic techniques are not directly applicable, are still widely utilized\ndue to usability and legal reasons. We propose a novel approach to\nauthenticating paper documents using smartphones by taking short videos of\nthem. Our solution combines cryptographic and image comparison techniques to\ndetect and highlight subtle semantic-changing attacks on rich documents,\ncontaining text and graphics, that could go unnoticed by humans. We rigorously\nanalyze our approach, proving that it is secure against strong adversaries\ncapable of compromising different system components. We also measure its\naccuracy empirically on a set of 128 videos of paper documents, half containing\nsubtle forgeries. Our algorithm finds all forgeries accurately (no false\nalarms) after analyzing 5.13 frames on average (corresponding to 1.28 seconds\nof video). Highlighted regions are large enough to be visible to users, but\nsmall enough to precisely locate forgeries. Thus, our approach provides a\npromising way for users to authenticate paper documents using conventional\nsmartphones under realistic conditions.",
    "descriptor": "",
    "authors": [
      "Mart\u00edn Ochoa",
      "Jorge Toro-Pozo",
      "David Basin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07884"
  },
  {
    "id": "arXiv:2210.07886",
    "title": "PedFormer: Pedestrian Behavior Prediction via Cross-Modal Attention  Modulation and Gated Multitask Learning",
    "abstract": "Predicting pedestrian behavior is a crucial task for intelligent driving\nsystems. Accurate predictions require a deep understanding of various\ncontextual elements that potentially impact the way pedestrians behave. To\naddress this challenge, we propose a novel framework that relies on different\ndata modalities to predict future trajectories and crossing actions of\npedestrians from an ego-centric perspective. Specifically, our model utilizes a\ncross-modal Transformer architecture to capture dependencies between different\ndata types. The output of the Transformer is augmented with representations of\ninteractions between pedestrians and other traffic agents conditioned on the\npedestrian and ego-vehicle dynamics that are generated via a semantic attentive\ninteraction module. Lastly, the context encodings are fed into a multi-stream\ndecoder framework using a gated-shared network. We evaluate our algorithm on\npublic pedestrian behavior benchmarks, PIE and JAAD, and show that our model\nimproves state-of-the-art in trajectory and action prediction by up to 22% and\n13% respectively on various metrics. The advantages brought by components of\nour model are investigated via extensive ablation studies.",
    "descriptor": "\nComments: 8 pages, 3 Figures\n",
    "authors": [
      "Amir Rasouli",
      "Iuliia Kotseruba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07886"
  },
  {
    "id": "arXiv:2210.07887",
    "title": "E2R: a Hierarchical-Learning inspired Novelty-Search method to generate  diverse repertoires of grasping trajectories",
    "abstract": "Robotics grasping refers to the task of making a robotic system pick an\nobject by applying forces and torques on its surface. Despite the recent\nadvances in data-driven approaches, grasping remains an unsolved problem. Most\nof the works on this task are relying on priors and heavy constraints to avoid\nthe exploration problem. Novelty Search (NS) refers to evolutionary algorithms\nthat replace selection of best performing individuals with selection of the\nmost novel ones. Such methods have already shown promising results on hard\nexploration problems. In this work, we introduce a new NS-based method that can\ngenerate large datasets of grasping trajectories in a platform-agnostic manner.\nInspired by the hierarchical learning paradigm, our method decouples approach\nand prehension to make the behavioral space smoother. Experiments conducted on\n3 different robot-gripper setups and on several standard objects shows that our\nmethod outperforms state-of-the-art for generating diverse repertoire of\ngrasping trajectories, getting a higher successful run ratio, as well as a\nbetter diversity for both approach and prehension. Some of the generated\nsolutions have been successfully deployed on a real robot, showing the\nexploitability of the obtained repertoires.",
    "descriptor": "\nComments: 7 pages, 6 figures. Preprint version\n",
    "authors": [
      "Johann Huber",
      "Oumar Sane",
      "Alex Coninx",
      "Faiz Ben Amar",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07887"
  },
  {
    "id": "arXiv:2210.07888",
    "title": "Guessing Random Additive Noise Decoding of Network Coded Data  Transmitted over Burst Error Channels",
    "abstract": "We consider a transmitter that encodes data packets using network coding and\nbroadcasts coded packets. A receiver employing network decoding recovers the\ndata packets if a sufficient number of error-free coded packets are gathered.\nThe receiver does not abandon its efforts to recover the data packets if\nnetwork decoding is unsuccessful; instead, it employs syndrome decoding (SD) in\nan effort to repair erroneously received coded packets, and then reattempts\nnetwork decoding. Most decoding techniques, including SD, assume that errors\nare independently and identically distributed within received coded packets.\nMotivated by the guessing random additive noise decoding (GRAND) framework, we\npropose transversal GRAND (T-GRAND): an algorithm that exploits statistical\ndependence in the occurrence of errors, complements network decoding and\nrecovers all data packets with a higher probability than SD. T-GRAND examines\nerror vectors in order of their likelihood of occurring and altering the\ntransmitted packets. Calculation and sorting of the likelihood values of all\nerror vectors is a simple but computationally expensive process. To reduce the\ncomplexity of T-GRAND, we take advantage of the properties of the likelihood\nfunction and develop an efficient method, which identifies the most likely\nerror vectors without computing and ordering their likelihoods.",
    "descriptor": "\nComments: 28 pages, 7 figures, 1 table, extended version of paper presented in the 2022 International Symposium on Information Theory. arXiv admin note: text overlap with arXiv:2112.05854\n",
    "authors": [
      "Ioannis Chatzigeorgiou",
      "Dmitry Savostyanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07888"
  },
  {
    "id": "arXiv:2210.07889",
    "title": "Semi-supervised Learning with Network Embedding on Ambient RF Signals  for Geofencing Services",
    "abstract": "In applications such as elderly care, dementia anti-wandering and pandemic\ncontrol, it is important to ensure that people are within a predefined area for\ntheir safety and well-being. We propose GEM, a practical, semi-supervised\ngeofencing system with network embedding, which is based only on ambient radio\nfrequency (RF) signals. GEM models measured RF signal records as a weighted\nbipartite graph. With APs on one side and signal records on the other, it is\nable to precisely capture the relationships between signal records. GEM then\nlearns node embeddings from the graph via a novel bipartite network embedding\nalgorithm called BiSAGE, based on a graph neural network with a novel bi-level\naggregation mechanism and non-uniform neighborhood sampling. Using the learned\nembeddings, GEM finally builds a one-class classification model via an enhanced\nhistogram-based algorithm for in-out detection, i.e., to detect whether the\nuser is inside the area or not. This model also keeps on improving with newly\ncollected signal records. We demonstrate through extensive experiments in\ndiverse environments that GEM shows state-of-the-art performance with up to 34%\nimprovement in F-score. BiSAGE in GEM leads to a 54% improvement in F-score, as\ncompared to the one without BiSAGE.",
    "descriptor": "",
    "authors": [
      "Weipeng Zhuo",
      "Ka Ho Chiu",
      "Jierun Chen",
      "Jiajie Tan",
      "Edmund Sumpena",
      "S.-H. Gary Chan",
      "Sangtae Ha",
      "Chul-Ho Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.07889"
  },
  {
    "id": "arXiv:2210.07890",
    "title": "Hierarchical Policy Blending as Inference for Reactive Robot Control",
    "abstract": "Motion generation in cluttered, dense, and dynamic environments is a central\ntopic in robotics, rendered as a multi-objective decision-making problem.\nCurrent approaches trade-off between safety and performance. On the one hand,\nreactive policies guarantee fast response to environmental changes at the risk\nof suboptimal behavior. On the other hand, planning-based motion generation\nprovides feasible trajectories, but the high computational cost may limit the\ncontrol frequency and thus safety. To combine the benefits of reactive policies\nand planning, we propose a hierarchical motion generation method. Moreover, we\nadopt probabilistic inference methods to formalize the hierarchical model and\nstochastic optimization. We realize this approach as a weighted product of\nstochastic, reactive expert policies, where planning is used to adaptively\ncompute the optimal weights over the task horizon. This stochastic optimization\navoids local optima and proposes feasible reactive plans that find paths in\ncluttered and dense environments. Our extensive experimental study in planar\nnavigation and 6DoF manipulation shows that our proposed hierarchical motion\ngeneration method outperforms both myopic reactive controllers and online\nre-planning methods.",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table, submitted to ICRA 2023\n",
    "authors": [
      "Kay Hansel",
      "Julen Urain",
      "Jan Peters",
      "Georgia Chalvatzaki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07890"
  },
  {
    "id": "arXiv:2210.07895",
    "title": "GRAFICS: Graph Embedding-based Floor Identification Using Crowdsourced  RF Signals",
    "abstract": "We study the problem of floor identification for radiofrequency (RF) signal\nsamples obtained in a crowdsourced manner, where the signal samples are highly\nheterogeneous and most samples lack their floor labels. We propose GRAFICS, a\ngraph embedding-based floor identification system. GRAFICS first builds a\nhighly versatile bipartite graph model, having APs on one side and signal\nsamples on the other. GRAFICS then learns the low-dimensional embeddings of\nsignal samples via a novel graph embedding algorithm named E-LINE. GRAFICS\nfinally clusters the node embeddings along with the embeddings of a few labeled\nsamples through a proximity-based hierarchical clustering, which eases the\nfloor identification of every new sample. We validate the effectiveness of\nGRAFICS based on two large-scale datasets that contain RF signal records from\n204 buildings in Hangzhou, China, and five buildings in Hong Kong. Our\nexperiment results show that GRAFICS achieves highly accurate prediction\nperformance with only a few labeled samples (96% in both micro- and macro-F\nscores) and significantly outperforms several state-of-the-art algorithms (by\nabout 45% improvement in micro-F score and 53% in macro-F score).",
    "descriptor": "\nComments: Accepted by IEEE ICDCS 2022\n",
    "authors": [
      "Weipeng Zhuo",
      "Ziqi Zhao",
      "Ka Ho Chiu",
      "Shiju Li",
      "Sangtae Ha",
      "Chul-Ho Lee",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.07895"
  },
  {
    "id": "arXiv:2210.07897",
    "title": "A Serverless Publish/Subscribe System",
    "abstract": "Operating a scalable and reliable server application, such as\npublish/subscribe (pub/sub) systems, requires tremendous development efforts\nand resources. The emerging serverless paradigm simplifies the development and\ndeployment of highly available applications by delegating most operational\nconcerns to the cloud providers. The serverless paradigm describes a\nprogramming model where the developers break the application downs into smaller\nmicroservices that run on the cloud in response to events. This paper proposes\ndesigning a serverless pub/sub system based on the IBM Bluemix cloud platform.\nOur pub/sub system performs topic-based, content-based, and function-based\nmatchings. The function-based matching is a novel matching approach where the\nsubscribers can define a highly customizable subscription function that the\nbroker applies to the publications in the cloud. The evaluations of the\ndesigned system verify the practicality of the designed system. However, the\nvendor-specific constraints of the IBM Bluemix resources are a bottleneck to\nthe scalability of the broker.",
    "descriptor": "",
    "authors": [
      "Pezhman Nasirifard",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07897"
  },
  {
    "id": "arXiv:2210.07898",
    "title": "An IMEX-DG solver for atmospheric dynamics simulations with adaptive  mesh refinement",
    "abstract": "We present an accurate and efficient solver for atmospheric dynamics\nsimulations that allows for non-conforming mesh refinement. The model equations\nare the conservative Euler equations for compressible flows. The numerical\nmethod is based on an $h-$adaptive Discontinuous Galerkin spatial\ndiscretization and on a second order Additive Runge Kutta IMEX method for time\ndiscretization, especially designed for low Mach regimes. The solver is\nimplemented in the framework of the $deal.II$ library, whose mesh refinement\ncapabilities are employed to enhance efficiency. A number of numerical\nexperiments based on classical benchmarks for atmosphere dynamics demonstrate\nthe properties and advantages of the proposed method.",
    "descriptor": "",
    "authors": [
      "Giuseppe Orlando",
      "Tommaso Benacchio",
      "Luca Bonaventura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07898"
  },
  {
    "id": "arXiv:2210.07903",
    "title": "Text Detection Forgot About Document OCR",
    "abstract": "Detection and recognition of text from scans and other images, commonly\ndenoted as Optical Character Recognition (OCR), is a widely used form of\nautomated document processing with a number of methods available. Advances in\nmachine learning enabled even more challenging scenarios of text detection and\nrecognition \"in-the-wild\" - such as detecting text on objects from photographs\nof complex scenes. While the state-of-the-art methods for in-the-wild text\nrecognition are typically evaluated on complex scenes, their performance in the\ndomain of documents has not been published. This paper compares several methods\ndesigned for in-the-wild text recognition and for document text recognition,\nand provides their evaluation on the domain of structured documents. The\nresults suggest that state-of-the-art methods originally proposed for\nin-the-wild text detection also achieve excellent results on document text\ndetection, outperforming available OCR methods. We argue that the application\nof document OCR should not be omitted in evaluation of text detection and\nrecognition methods.",
    "descriptor": "",
    "authors": [
      "Krzysztof Olejniczak",
      "Milan \u0160ulc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07903"
  },
  {
    "id": "arXiv:2210.07904",
    "title": "HashFormers: Towards Vocabulary-independent Pre-trained Transformers",
    "abstract": "Transformer-based pre-trained language models are vocabulary-dependent,\nmapping by default each token to its corresponding embedding. This one-to-one\nmapping results into embedding matrices that occupy a lot of memory (i.e.\nmillions of parameters) and grow linearly with the size of the vocabulary.\nPrevious work on on-device transformers dynamically generate token embeddings\non-the-fly without embedding matrices using locality-sensitive hashing over\nmorphological information. These embeddings are subsequently fed into\ntransformer layers for text classification. However, these methods are not\npre-trained. Inspired by this line of work, we propose HashFormers, a new\nfamily of vocabulary-independent pre-trained transformers that support an\nunlimited vocabulary (i.e. all possible tokens in a corpus) given a\nsubstantially smaller fixed-sized embedding matrix. We achieve this by first\nintroducing computationally cheap hashing functions that bucket together\nindividual tokens to embeddings. We also propose three variants that do not\nrequire an embedding matrix at all, further reducing the memory requirements.\nWe empirically demonstrate that HashFormers are more memory efficient compared\nto standard pre-trained transformers while achieving comparable predictive\nperformance when fine-tuned on multiple text classification tasks. For example,\nour most efficient HashFormer variant has a negligible performance degradation\n(0.4\\% on GLUE) using only 99.1K parameters for representing the embeddings\ncompared to 12.3-38M parameters of state-of-the-art models.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Huiyin Xue",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07904"
  },
  {
    "id": "arXiv:2210.07906",
    "title": "Post-Training Quantization for Energy Efficient Realization of Deep  Neural Networks",
    "abstract": "The biggest challenge for the deployment of Deep Neural Networks (DNNs) close\nto the generated data on edge devices is their size, i.e., memory footprint and\ncomputational complexity. Both are significantly reduced with quantization.\nWith the resulting lower word-length, the energy efficiency of DNNs increases\nproportionally. However, lower word-length typically causes accuracy\ndegradation. To counteract this effect, the quantized DNN is retrained.\nUnfortunately, training costs up to 5000x more energy than the inference of the\nquantized DNN. To address this issue, we propose a post-training quantization\nflow without the need for retraining. For this, we investigated different\nquantization options. Furthermore, our analysis systematically assesses the\nimpact of reduced word-lengths of weights and activations revealing a clear\ntrend for the choice of word-length. Both aspects have not been systematically\ninvestigated so far. Our results are independent of the depth of the DNNs and\napply to uniform quantization, allowing fast quantization of a given\npre-trained DNN. We excel state-of-the-art for 6 bit by 2.2% Top-1 accuracy for\nImageNet. Without retraining, our quantization to 8 bit surpasses\nfloating-point accuracy.",
    "descriptor": "\nComments: memory footprint, MSE, residuals, scale computation, channelwise, layerwise, word-length, bit-width\n",
    "authors": [
      "Cecilia Latotzke",
      "Batuhan Balim",
      "Tobias Gemmeke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07906"
  },
  {
    "id": "arXiv:2210.07907",
    "title": "Expose Backdoors on the Way: A Feature-Based Efficient Defense against  Textual Backdoor Attacks",
    "abstract": "Natural language processing (NLP) models are known to be vulnerable to\nbackdoor attacks, which poses a newly arisen threat to NLP models. Prior online\nbackdoor defense methods for NLP models only focus on the anomalies at either\nthe input or output level, still suffering from fragility to adaptive attacks\nand high computational cost. In this work, we take the first step to\ninvestigate the unconcealment of textual poisoned samples at the\nintermediate-feature level and propose a feature-based efficient online defense\nmethod. Through extensive experiments on existing attacking methods, we find\nthat the poisoned samples are far away from clean samples in the intermediate\nfeature space of a poisoned NLP model. Motivated by this observation, we devise\na distance-based anomaly score (DAN) to distinguish poisoned samples from clean\nsamples at the feature level. Experiments on sentiment analysis and offense\ndetection tasks demonstrate the superiority of DAN, as it substantially\nsurpasses existing online defense methods in terms of defending performance and\nenjoys lower inference costs. Moreover, we show that DAN is also resistant to\nadaptive attacks based on feature-level regularization. Our code is available\nat https://github.com/lancopku/DAN.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Sishuo Chen",
      "Wenkai Yang",
      "Zhiyuan Zhang",
      "Xiaohan Bi",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07907"
  },
  {
    "id": "arXiv:2210.07908",
    "title": "Superconvergence and accuracy enhancement of discontinuous Galerkin  solutions for Vlasov-Maxwell equations",
    "abstract": "This paper considers the discontinuous Galerkin (DG) methods for solving the\nVlasov-Maxwell (VM) system, a fundamental model for collisionless magnetized\nplasma. The DG methods provide accurate numerical description with conservation\nand stability properties. However, to resolve the high dimensional probability\ndistribution function, the computational cost is the main bottleneck even for\nmodern-day supercomputers. This work studies the applicability of a\npost-processing technique to the DG solution to enhance its accuracy and\nresolution for the VM system. In particular, we prove the superconvergence of\norder $(2k+\\frac{1}{2})$ in the negative order norm for the probability\ndistribution function and the electromagnetic fields when piecewise polynomial\ndegree $k$ is used. Numerical tests including Landau damping, two-stream\ninstability and streaming Weibel instabilities are considered showing the\nperformance of the post-processor.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Galindo-Olarte",
      "Juntao Huang",
      "Jennifer K. Ryan",
      "Yingda Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07908"
  },
  {
    "id": "arXiv:2210.07911",
    "title": "Popularity on the Roommate Diversity Problem",
    "abstract": "A recently introduced restricted variant of the multidimensional stable\nroommate problem is the roommate diversity problem: each agent belongs to one\nof two types (e.g., red and blue), and the agents' preferences over the\ncoalitions solely depend on the fraction of agents of their own type among\ntheir roommates.\nThere are various notions of stability that defines an optimal partitioning\nof agents. The notion of popularity has received a lot of attention recently. A\npartitioning of agents is popular if there does not exist another partitioning\nin which more agents are better off than worse off. Computing a popular\npartition in a stable roommate game can be done in polynomial time. When we\nallow ties the stable roommate problem becomes NP-complete. Determining the\nexistence of a popular solution in the multidimensional stable roommate problem\nalso NP-hard.\nWe show that in the roommate diversity problem with the room size fixed to\ntwo, the problem becomes tractable. Particularly, a popular partitioning of\nagents is guaranteed to exist and can be computed in polynomial time.\nAdditionally a mixed popular partitioning of agents is always guaranteed to\nexist in any roommate diversity game. By contrast, when there are no\nrestrictions on the coalition size of a roommate diversity game, a popular\npartitioning may fail to exist and the problem becomes intractable. Our results\nintractability results are summarized as follows:\n* Determining the existence of a popular partitioning is co-NP-hard, even if\nthe agents' preferences are trichotomous.\n* Determining the existence of a strictly popular partitioning is co-NP-hard,\neven if the agents' preferences are dichotomous.\n* Computing a mixed popular partitioning of agents in polynomial time is\nimpossible unless P=NP, even if the agents' preferences are dichotomous.",
    "descriptor": "\nComments: 30 pages, submitted to STACS 2023\n",
    "authors": [
      "Steven Ge",
      "Toshiya Itoh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07911"
  },
  {
    "id": "arXiv:2210.07913",
    "title": "Efficiently Controlling Multiple Risks with Pareto Testing",
    "abstract": "Machine learning applications frequently come with multiple diverse\nobjectives and constraints that can change over time. Accordingly, trained\nmodels can be tuned with sets of hyper-parameters that affect their predictive\nbehavior (e.g., their run-time efficiency versus error rate). As the number of\nconstraints and hyper-parameter dimensions grow, naively selected settings may\nlead to sub-optimal and/or unreliable results. We develop an efficient method\nfor calibrating models such that their predictions provably satisfy multiple\nexplicit and simultaneous statistical guarantees (e.g., upper-bounded error\nrates), while also optimizing any number of additional, unconstrained\nobjectives (e.g., total run-time cost). Building on recent results in\ndistribution-free, finite-sample risk control for general losses, we propose\nPareto Testing: a two-stage process which combines multi-objective optimization\nwith multiple hypothesis testing. The optimization stage constructs a set of\npromising combinations on the Pareto frontier. We then apply statistical\ntesting to this frontier only to identify configurations that have (i) high\nutility with respect to our objectives, and (ii) guaranteed risk levels with\nrespect to our constraints, with specifiable high probability. We demonstrate\nthe effectiveness of our approach to reliably accelerate the execution of\nlarge-scale Transformer models in natural language processing (NLP)\napplications. In particular, we show how Pareto Testing can be used to\ndynamically configure multiple inter-dependent model attributes -- including\nthe number of layers computed before exiting, number of attention heads pruned,\nor number of text tokens considered -- to simultaneously control and optimize\nvarious accuracy and cost metrics.",
    "descriptor": "",
    "authors": [
      "Bracha Laufer-Goldshtein",
      "Adam Fisch",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07913"
  },
  {
    "id": "arXiv:2210.07914",
    "title": "Model-checking lock-sharing systems against regular constraints",
    "abstract": "We study the verification of distributed systems where processes are finite\nautomata with access to a shared pool of locks. We consider objectives that are\nboolean combinations of local regular constraints. We show that the problem,\nPSPACE-complete in general, falls in NP with the right assumptions on the\nsystem. We use restrictions on the number of locks a process can access and the\norder in which locks can be released. We provide tight complexity bounds, as\nwell as a subcase of interest that can be solved in PTIME.",
    "descriptor": "",
    "authors": [
      "Corto Mascle"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07914"
  },
  {
    "id": "arXiv:2210.07916",
    "title": "Style Transfer as Data Augmentation: A Case Study on Named Entity  Recognition",
    "abstract": "In this work, we take the named entity recognition task in the English\nlanguage as a case study and explore style transfer as a data augmentation\nmethod to increase the size and diversity of training data in low-resource\nscenarios. We propose a new method to effectively transform the text from a\nhigh-resource domain to a low-resource domain by changing its style-related\nattributes to generate synthetic data for training. Moreover, we design a\nconstrained decoding algorithm along with a set of key ingredients for data\nselection to guarantee the generation of valid and coherent data. Experiments\nand analysis on five different domain pairs under different data regimes\ndemonstrate that our approach can significantly improve results compared to\ncurrent state-of-the-art data augmentation methods. Our approach is a practical\nsolution to data scarcity, and we expect it to be applicable to other NLP\ntasks.",
    "descriptor": "\nComments: To appear at EMNLP 2022 main conference\n",
    "authors": [
      "Shuguang Chen",
      "Leonardo Neves",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07916"
  },
  {
    "id": "arXiv:2210.07918",
    "title": "A Hybrid Partitioning Strategy for Backward Reachability of Neural  Feedback Loops",
    "abstract": "As neural networks become more integrated into the systems that we depend on\nfor transportation, medicine, and security, it becomes increasingly important\nthat we develop methods to analyze their behavior to ensure that they are safe\nto use within these contexts. The methods used in this paper seek to certify\nsafety for closed-loop systems with neural network controllers, i.e., neural\nfeedback loops, using backward reachability analysis. Namely, we calculate\nbackprojection (BP) set over-approximations (BPOAs), i.e., sets of states that\nlead to a given target set that bounds dangerous regions of the state space.\nThe system's safety can then be certified by checking its current state against\nthe BPOAs. While over-approximating BPs is significantly faster than\ncalculating exact BP sets, solving the relaxed problem leads to\nconservativeness. To combat conservativeness, partitioning strategies can be\nused to split the problem into a set of sub-problems, each less conservative\nthan the unpartitioned problem. We introduce a hybrid partitioning method that\nuses both target set partitioning (TSP) and backreachable set partitioning\n(BRSP) to overcome a lower bound on estimation error that is present when using\nBRSP. Numerical results demonstrate a near order-of-magnitude reduction in\nestimation error compared to BRSP or TSP given the same computation time.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Nicholas Rober",
      "Michael Everett",
      "Songan Zhang",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07918"
  },
  {
    "id": "arXiv:2210.07920",
    "title": "MOVE: Unsupervised Movable Object Segmentation and Detection",
    "abstract": "We introduce MOVE, a novel method to segment objects without any form of\nsupervision. MOVE exploits the fact that foreground objects can be shifted\nlocally relative to their initial position and result in realistic\n(undistorted) new images. This property allows us to train a segmentation model\non a dataset of images without annotation and to achieve state of the art\n(SotA) performance on several evaluation datasets for unsupervised salient\nobject detection and segmentation. In unsupervised single object discovery,\nMOVE gives an average CorLoc improvement of 7.2% over the SotA, and in\nunsupervised class-agnostic object detection it gives a relative AP improvement\nof 53% on average. Our approach is built on top of self-supervised features\n(e.g. from DINO or MAE), an inpainting network (based on the Masked\nAutoEncoder) and adversarial training.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Adam Bielski",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07920"
  },
  {
    "id": "arXiv:2210.07924",
    "title": "A Note on Fourier-Motzkin Elimination with Three Eliminating Variables",
    "abstract": "In this note, we show how difficult the brute-force Fourier-Motzkin\nelimination is, even in a simple case with three eliminating variables.\nSpecifically, we first give a theorem, which plays quite an important role in\nthe study of information-theoretic security for a multiple access wiretap\n(MAC-WT) channel, and then prove it for the case with three users by directly\nusing the Fourier-Motzkin procedure. It is shown that large amounts of\ninequalities are generated in the elimination procedure while most of them are\nredundant. Actually, the number of generated inequalities grows doubly\nexponentially with the number of users or eliminating variables. It thus\nbecomes unmanageable to directly prove the theorem in this brute-force way.\nBesides the great complexity, another disadvantage of the direct strategy is\nthat it works only if the number of users is given. Obviously, this makes the\nstrategy inappropriate for the proof of the theorem since it is a general\nresult for any number of users. It is thus urgent and challenging to generally\nprove the theorem.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Hao Xu",
      "Kai-Kit Wong",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07924"
  },
  {
    "id": "arXiv:2210.07932",
    "title": "Neural Routing in Meta Learning",
    "abstract": "Meta-learning often referred to as learning-to-learn is a promising notion\nraised to mimic human learning by exploiting the knowledge of prior tasks but\nbeing able to adapt quickly to novel tasks. A plethora of models has emerged in\nthis context and improved the learning efficiency, robustness, etc. The\nquestion that arises here is can we emulate other aspects of human learning and\nincorporate them into the existing meta learning algorithms? Inspired by the\nwidely recognized finding in neuroscience that distinct parts of the brain are\nhighly specialized for different types of tasks, we aim to improve the model\nperformance of the current meta learning algorithms by selectively using only\nparts of the model conditioned on the input tasks. In this work, we describe an\napproach that investigates task-dependent dynamic neuron selection in deep\nconvolutional neural networks (CNNs) by leveraging the scaling factor in the\nbatch normalization (BN) layer associated with each convolutional layer. The\nproblem is intriguing because the idea of helping different parts of the model\nto learn from different types of tasks may help us train better filters in\nCNNs, and improve the model generalization performance. We find that the\nproposed approach, neural routing in meta learning (NRML), outperforms one of\nthe well-known existing meta learning baselines on few-shot classification\ntasks on the most widely used benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Jicang Cai",
      "Saeed Vahidian",
      "Weijia Wang",
      "Mohsen Joneidi",
      "Bill Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07932"
  },
  {
    "id": "arXiv:2210.07934",
    "title": "Codes, Patterns and Shapes of Contemporary Online Antisemitism and  Conspiracy Narratives -- an Annotation Guide and Labeled German-Language  Dataset in the Context of COVID-19",
    "abstract": "Over the course of the COVID-19 pandemic, existing conspiracy theories were\nrefreshed and new ones were created, often interwoven with antisemitic\nnarratives, stereotypes and codes. The sheer volume of antisemitic and\nconspiracy theory content on the Internet makes data-driven algorithmic\napproaches essential for anti-discrimination organizations and researchers\nalike. However, the manifestation and dissemination of these two interrelated\nphenomena is still quite under-researched in scholarly empirical research of\nlarge text corpora. Algorithmic approaches for the detection and classification\nof specific contents usually require labeled datasets, annotated based on\nconceptually sound guidelines. While there is a growing number of datasets for\nthe more general phenomenon of hate speech, the development of corpora and\nannotation guidelines for antisemitic and conspiracy content is still in its\ninfancy, especially for languages other than English. We contribute to closing\nthis gap by developing an annotation guide for antisemitic and conspiracy\ntheory online content in the context of the COVID-19 pandemic. We provide\nworking definitions, including specific forms of antisemitism such as encoded\nand post-Holocaust antisemitism. We use these to annotate a German-language\ndataset consisting of ~3,700 Telegram messages sent between 03/2020 and\n12/2021.",
    "descriptor": "\nComments: Link to the data sheet of the dataset: this https URL\n",
    "authors": [
      "Elisabeth Steffen",
      "Helena Mihaljevi\u0107",
      "Milena Pustet",
      "Nyco Bischoff",
      "Mar\u00eda do Mar Castro Varela",
      "Yener Bayramo\u011flu",
      "Bahar Oghalai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07934"
  },
  {
    "id": "arXiv:2210.07940",
    "title": "AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments",
    "abstract": "Recent years have seen embodied visual navigation advance in two distinct\ndirections: (i) in equipping the AI agent to follow natural language\ninstructions, and (ii) in making the navigable world multimodal, e.g.,\naudio-visual navigation. However, the real world is not only multimodal, but\nalso often complex, and thus in spite of these advances, agents still need to\nunderstand the uncertainty in their actions and seek instructions to navigate.\nTo this end, we present AVLEN~ -- an interactive agent for\nAudio-Visual-Language Embodied Navigation. Similar to audio-visual navigation\ntasks, the goal of our embodied agent is to localize an audio event via\nnavigating the 3D visual world; however, the agent may also seek help from a\nhuman (oracle), where the assistance is provided in free-form natural language.\nTo realize these abilities, AVLEN uses a multimodal hierarchical reinforcement\nlearning backbone that learns: (a) high-level policies to choose either\naudio-cues for navigation or to query the oracle, and (b) lower-level policies\nto select navigation actions based on its audio-visual and language inputs. The\npolicies are trained via rewarding for the success on the navigation task while\nminimizing the number of queries to the oracle. To empirically evaluate AVLEN,\nwe present experiments on the SoundSpaces framework for semantic audio-visual\nnavigation tasks. Our results show that equipping the agent to ask for help\nleads to a clear improvement in performance, especially in challenging cases,\ne.g., when the sound is unheard during training or in the presence of\ndistractor sounds.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Sudipta Paul",
      "Amit K. Roy-Chowdhury",
      "Anoop Cherian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07940"
  },
  {
    "id": "arXiv:2210.07963",
    "title": "Rate and Detection-Error Exponent Tradeoff for Joint Communication and  Sensing of Fixed Channel States",
    "abstract": "We study the information-theoretic limits of joint communication and sensing\nwhen the sensing task is modeled as the estimation of a discrete channel state\nfixed during the transmission of an entire codeword. This setting captures\nscenarios in which the time scale over which sensing happens is significantly\nslower than the time scale over which symbol transmission occurs. The tradeoff\nbetween communication and sensing then takes the form of a tradeoff region\nbetween the rate of reliable communication and the state detection-error\nexponent. We investigate such tradeoffs for both mono-static and bi-static\nscenarios, in which the sensing task is performed at the transmitter or\nreceiver, respectively. In the mono-static case, we develop an exact\ncharacterization of the tradeoff in open-loop, when the sensing is not used to\nassist the communication. We also show the strict improvement brought by a\nclosed-loop operation, in which the sensing informs the communication. In the\nbi-static case, we develop an achievable tradeoff region that highlights the\nfundamentally different nature of the bi-static scenario. Specifically, the\nrate of communication plays a key role in the characterization of the tradeoff\nand we show how joint strategies, which simultaneously estimate message and\nstate, outperform sequential strategies, which only estimate the state after\ndecoding the transmitted message.",
    "descriptor": "\nComments: 33 pages, 5 figures, submitted to JSAIT\n",
    "authors": [
      "Meng-Che Chang",
      "Shi-Yuan Wang",
      "Tuna Erdo\u011fan",
      "Matthieu R. Bloch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.07963"
  },
  {
    "id": "arXiv:2210.07970",
    "title": "Market Interventions in a Large-Scale Virtual Economy",
    "abstract": "Massively multiplayer online role-playing games often contain sophisticated\nin-game economies. Many important real-world economic phenomena, such as\ninflation, economic growth, and business cycles, are also present in these\nvirtual economies. One major difference between real-world and virtual\neconomies is the ease and frequency by which a policymaker, in this case, a\ngame developer, can introduce economic shocks. These economic shocks, typically\nimplemented with game updates or signaled through community channels, provide\nfertile ground to study the effects of economic interventions on markets. In\nthis work, we study the effect of in-game economic market interventions,\nnamely, a transaction tax and an item sink, in Old School RuneScape. Using\ncausal inference methods, we find that the tax did not meaningfully affect the\ntrading volume of items at the tax boundaries and that the item sink\ncontributed to the inflation of luxury good prices, without reducing trade\nvolume. Furthermore, we find evidence that the illicit gold trading market was\nrelatively unaffected by the implemented market interventions. Our findings\nyield useful insights not only into the effect of market interventions in\nvirtual economies but also for real-world markets.",
    "descriptor": "",
    "authors": [
      "Senan Hogan-Hennessy",
      "Peter Xenopoulos",
      "Claudio Silva"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.07970"
  },
  {
    "id": "arXiv:2210.07973",
    "title": "Wild Animal Classifier Using CNN",
    "abstract": "Classification and identification of wild animals for tracking and protection\npurposes has become increasingly important with the deterioration of the\nenvironment, and technology is the agent of change which augments this process\nwith novel solutions. Computer vision is one such technology which uses the\nabilities of artificial intelligence and machine learning models on visual\ninputs. Convolution neural networks (CNNs) have multiple layers which have\ndifferent weights for the purpose of prediction of a particular input. The\nprecedent for classification, however, is set by the image processing\ntechniques which provide nearly ideal input images that produce optimal\nresults. Image segmentation is one such widely used image processing method\nwhich provides a clear demarcation of the areas of interest in the image, be it\nregions or objects. The Efficiency of CNN can be related to the preprocessing\ndone before training. Further, it is a well-established fact that heterogeneity\nin image sources is detrimental to the performance of CNNs. Thus, the added\nfunctionality of heterogeneity elimination is performed by the image processing\ntechniques, introducing a level of consistency that sets the tone for the\nexcellent feature extraction and eventually in classification.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Sahil Faizal",
      "Sanjay Sundaresan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07973"
  },
  {
    "id": "arXiv:2210.07974",
    "title": "Point-Normal Subdivision Curves and Surfaces",
    "abstract": "This paper proposes to generalize linear subdivision schemes to nonlinear\nsubdivision schemes for curve and surface modeling by refining vertex positions\ntogether with refinement of unit control normals at the vertices. For each\nround of subdivision, new control normals are obtained by projections of\nlinearly subdivided normals onto unit circle or sphere while new vertex\npositions are obtained by updating linearly subdivided vertices along the\ndirections of the newly subdivided normals. Particularly, the new position of\neach linearly subdivided vertex is computed by weighted averages of end points\nof circular or helical arcs that interpolate the positions and normals at the\nold vertices at one ends and the newly subdivided normal at the other ends.\nThe main features of the proposed subdivision schemes are three folds:\n(1) The point-normal (PN) subdivision schemes can reproduce circles, circular\ncylinders and spheres using control points and control normals;\n(2) PN subdivision schemes generalized from convergent linear subdivision\nschemes converge and can have the same smoothness orders as the linear schemes;\n(3) PN $C^2$ subdivision schemes generalizing linear subdivision schemes that\ngenerate $C^2$ subdivision surfaces with flat extraordinary points can generate\nvisually $C^2$ subdivision surfaces with non-flat extraordinary points.\nExperimental examples have been given to show the effectiveness of the\nproposed techniques for curve and surface modeling.",
    "descriptor": "\nComments: 30 pages, 17 figures\n",
    "authors": [
      "Xunnian Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07974"
  },
  {
    "id": "arXiv:2210.07978",
    "title": "Improving generalizability of distilled self-supervised speech  processing models under distorted settings",
    "abstract": "Self-supervised learned (SSL) speech pre-trained models perform well across\nvarious speech processing tasks. Distilled versions of SSL models have been\ndeveloped to match the needs of on-device speech applications. Though having\nsimilar performance as original SSL models, distilled counterparts suffer from\nperformance degradation even more than their original versions in distorted\nenvironments. This paper proposes to apply Cross-Distortion Mapping and Domain\nAdversarial Training to SSL models during knowledge distillation to alleviate\nthe performance gap caused by the domain mismatch problem. Results show\nconsistent performance improvements under both in- and out-of-domain distorted\nsetups for different downstream tasks while keeping efficient model size.",
    "descriptor": "\nComments: Accepted by IEEE SLT2022\n",
    "authors": [
      "Kuan-Po Huang",
      "Yu-Kuan Fu",
      "Tsu-Yuan Hsu",
      "Fabian Ritter Gutierrez",
      "Fan-Lin Wang",
      "Liang-Hsuan Tseng",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07978"
  },
  {
    "id": "arXiv:2210.07979",
    "title": "Space-Efficient STR-IC-LCS Computation",
    "abstract": "One of the most fundamental method for comparing two given strings $A$ and\n$B$ is the longest common subsequence (LCS), where the task is to find (the\nlength) of the longest common subsequence. In this paper, we address the\nSTR-IC-LCS problem which is one of the constrained LCS problems proposed by\nChen and Chao [J. Comb. Optim, 2011]. A string $Z$ is said to be an STR-IC-LCS\nof three given strings $A$, $B$, and $P$, if $Z$ is one of the longest common\nsubsequences of $A$ and $B$ that contains $P$ as a substring. We present a\nspace efficient solution for the STR-IC-LCS problem. Our algorithm computes the\nlength of an STR-IC-LCS in $O(n^2)$ time and $O((\\ell+1)(n-\\ell+1))$ space\nwhere $\\ell$ is the length of a longest common subsequence of $A$ and $B$ of\nlength $n$. When $\\ell = O(1)$ or $n-\\ell = O(1)$, then our algorithm uses only\nlinear $O(n)$ space.",
    "descriptor": "",
    "authors": [
      "Yuuki Yonemoto",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Hideo Bannai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07979"
  },
  {
    "id": "arXiv:2210.07983",
    "title": "Trailers12k: Evaluating Transfer Learning for Movie Trailer Genre  Classification",
    "abstract": "Transfer learning is a cornerstone for a wide range of computer vision\nproblems.It has been broadly studied for image analysis tasks. However,\nliterature for video analysis is scarce and has been mainly focused on\ntransferring representations learned from ImageNet to human action recognition\ntasks. In this paper, we study transfer learning for Multi-label Movie Trailer\nGenre Classification (MTGC). In particular, we introduce Trailers12k}, a new\nmanually-curated movie trailer dataset and evaluate the transferability of\nspatial and spatio-temporal representations learned from ImageNet and/or\nKinetics to Trailers12k MTGC. In order to reduce the spatio-temporal structure\ngap between the source and target tasks and improve transferability, we propose\na method that performs shot detection so as to segment the trailer into highly\ncorrelated clips. We study different aspects that influence transferability,\nsuch as segmentation strategy, frame rate, input video extension, and\nspatio-temporal modeling. Our results demonstrate that representations learned\non either ImageNet or Kinetics are comparatively transferable to Trailers12k,\nalthough they provide complementary information that can be combined to improve\nclassification performance. Having a similar number of parameters and FLOPS,\nTransformers provide a better transferability base than ConvNets. Nevertheless,\ncompetitive performance can be achieved using lightweight ConvNets, becoming an\nattractive option for low-resource environments.",
    "descriptor": "",
    "authors": [
      "Ricardo Montalvo-Lezama",
      "Berenice Montalvo-Lezama",
      "Gibran Fuentes-Pineda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07983"
  },
  {
    "id": "arXiv:2210.07984",
    "title": "$\u03b1$QBoost: An Iteratively Weighted Adiabatic Trained Classifier",
    "abstract": "A new implementation of an adiabatically-trained ensemble model is derived\nthat shows significant improvements over classical methods. In particular,\nempirical results of this new algorithm show that it offers not just higher\nperformance, but also more stability with less classifiers, an attribute that\nis critically important in areas like explainability and speed-of-inference. In\nall, the empirical analysis displays that the algorithm can provide an increase\nin performance on unseen data by strengthening stability of the statistical\nmodel through further minimizing and balancing variance and bias, while\ndecreasing the time to convergence over its predecessors.",
    "descriptor": "",
    "authors": [
      "Salvatore Certo",
      "Andrew Vlasic",
      "Daniel Beaulieu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07984"
  },
  {
    "id": "arXiv:2210.07988",
    "title": "PseudoReasoner: Leveraging Pseudo Labels for Commonsense Knowledge Base  Population",
    "abstract": "Commonsense Knowledge Base (CSKB) Population aims at reasoning over unseen\nentities and assertions on CSKBs, and is an important yet hard commonsense\nreasoning task. One challenge is that it requires out-of-domain generalization\nability as the source CSKB for training is of a relatively smaller scale (1M)\nwhile the whole candidate space for population is way larger (200M). We propose\nPseudoReasoner, a semi-supervised learning framework for CSKB population that\nuses a teacher model pre-trained on CSKBs to provide pseudo labels on the\nunlabeled candidate dataset for a student model to learn from. The teacher can\nbe a generative model rather than restricted to discriminative models as\nprevious works. In addition, we design a new filtering procedure for pseudo\nlabels based on influence function and the student model's prediction to\nfurther improve the performance. The framework can improve the backbone model\nKG-BERT (RoBERTa-large) by 3.3 points on the overall performance and\nespecially, 5.3 points on the out-of-domain performance, and achieves the\nstate-of-the-art. Codes and data are available at\nhttps://github.com/HKUST-KnowComp/PseudoReasoner.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tianqing Fang",
      "Quyet V. Do",
      "Hongming Zhang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07988"
  },
  {
    "id": "arXiv:2210.07990",
    "title": "Metaverse: Survey, Applications, Security, and Opportunities",
    "abstract": "As a fusion of various emerging digital technologies, the Metaverse aims to\nbuild a virtual shared digital space. It is closely related to extended\nreality, digital twin, blockchain, and other technologies. Its goal is to build\na digital space based on the real world, form a virtual economic system, and\nexpand the space of human activities, which injects new vitality into the\nsocial, economic, and other fields. In this article, we make the following\ncontributions. We first introduce the basic concepts such as the development\nprocess, definition, and characteristics of the Metaverse. After that, we\nanalyze the overall framework and supporting technologies of the Metaverse and\nsummarize the status of common fields. Finally, we focus on the security and\nprivacy issues that exist in the Metaverse, and give corresponding solutions or\ndirections. We also discuss the challenges and possible research directions of\nthe Metaverse. We believe this comprehensive review can provide an overview of\nthe Metaverse and research directions for some multidisciplinary studies.",
    "descriptor": "\nComments: Preprint. 5 figures, 4 tables\n",
    "authors": [
      "Jiayi Sun",
      "Wensheng Gan",
      "Han-Chieh Chao",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07990"
  },
  {
    "id": "arXiv:2210.07991",
    "title": "Novel 3D Scene Understanding Applications From Recurrence in a Single  Image",
    "abstract": "We demonstrate the utility of recurring pattern discovery from a single image\nfor spatial understanding of a 3D scene in terms of (1) vanishing point\ndetection, (2) hypothesizing 3D translation symmetry and (3) counting the\nnumber of RP instances in the image.\nFurthermore, we illustrate the feasibility of leveraging RP discovery output\nto form a more precise, quantitative text description of the scene. Our\nquantitative evaluations on a new 1K+ Recurring Pattern (RP) benchmark with\ndiverse variations show that visual perception of recurrence from one single\nview leads to scene understanding outcomes that are as good as or better than\nexisting supervised methods and/or unsupervised methods that use millions of\nimages.",
    "descriptor": "",
    "authors": [
      "Shimian Zhang",
      "Skanda Bharadwaj",
      "Keaton Kraiger",
      "Yashasvi Asthana",
      "Hong Zhang",
      "Robert Collins",
      "Yanxi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07991"
  },
  {
    "id": "arXiv:2210.07993",
    "title": "MiQA: A Benchmark for Inference on Metaphorical Questions",
    "abstract": "We propose a benchmark to assess the capability of large language models to\nreason with conventional metaphors. Our benchmark combines the previously\nisolated topics of metaphor detection and commonsense reasoning into a single\ntask that requires a model to make inferences by accurately selecting between\nthe literal and metaphorical register. We examine the performance of\nstate-of-the-art pre-trained models on binary-choice tasks and find a large\ndiscrepancy between the performance of small and very large models, going from\nchance to near-human level. We also analyse the largest model in a generative\nsetting and find that although human performance is approached, careful\nmultiple-shot prompting is required.",
    "descriptor": "\nComments: AACL-IJCNLP 2022 conference paper\n",
    "authors": [
      "Iulia-Maria Comsa",
      "Julian Martin Eisenschlos",
      "Srini Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07993"
  },
  {
    "id": "arXiv:2210.07994",
    "title": "Will Emerging Millimeter-Wave Cellular Networks Cause Harmful  Interference to Weather Satellites?",
    "abstract": "We study whether realistic 5G mm-wave cellular networks would cause harmful\nout-of-band interference to weather satellites sensing in the 23.8 GHz band. We\nestimate uplink and downlink interference from a single interferer and a\nnetwork of interferers in New York City, using real 3D building data and\nrealistic antenna patterns. We perform detailed ray-tracing propagation\nsimulations, for locations of the MetOp-B weather satellite and its scanning\norientations and ground interferer antenna orientations for representative\nurban cell sites. In addition to the ITU-R threshold of -136 dBm/200 MHz, we\npropose an alternative set of harmful interference thresholds directly related\nto the sensitivity of the satellite sensor. Our results show that the 3GPP\npower leakage limits are sufficient to ensure that interference from a single\n5G device is not harmful if considering the ITU-R threshold, but not if the\nweather prediction software can tolerate only very low interference levels.\nImportantly, aggregate interference resulting in practice from a 5G network\nwith realistic network densities is often harmful, even considering the least\nconservative ITU-R threshold. Overall, our comprehensive coexistence study thus\nstrongly suggests that additional engineering and/or regulatory solutions will\nbe necessary to protect weather satellite passive sensing from mm-wave cellular\nnetwork interference.",
    "descriptor": "",
    "authors": [
      "Andreea Palade",
      "Andra M. Voicu",
      "Petri M\u00e4h\u00f6nen",
      "Ljiljana Simi\u0107"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.07994"
  },
  {
    "id": "arXiv:2210.07996",
    "title": "Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions",
    "abstract": "We study the classical Network Revenue Management (NRM) problem with\naccept/reject decisions and $T$ IID arrivals. We consider a distributional form\nwhere each arrival must fall under a finite number of possible categories, each\nwith a deterministic resource consumption vector, but a random value\ndistributed continuously over an interval. We develop an online algorithm that\nachieves $O(\\log^2 T)$ regret under this model, with no further assumptions. We\ndevelop another online algorithm that achieves an improved $O(\\log T)$ regret,\nwith only a second-order growth assumption. To our knowledge, these are the\nfirst results achieving logarithmic-level regret in a continuous-distribution\nNRM model without further ``non-degeneracy'' assumptions. Our results are\nachieved via new techniques including: a new method of bounding myopic regret,\na ``semi-fluid'' relaxation of the offline allocation, and an improved bound on\nthe ``dual convergence''.",
    "descriptor": "",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.07996"
  },
  {
    "id": "arXiv:2210.07998",
    "title": "$\u039b$-DARTS: Mitigating Performance Collapse by Harmonizing  Operation Selection among Cells",
    "abstract": "Differentiable neural architecture search (DARTS) is a popular method for\nneural architecture search (NAS), which performs cell-search and utilizes\ncontinuous relaxation to improve the search efficiency via gradient-based\noptimization. The main shortcoming of DARTS is performance collapse, where the\ndiscovered architecture suffers from a pattern of declining quality during\nsearch. Performance collapse has become an important topic of research, with\nmany methods trying to solve the issue through either regularization or\nfundamental changes to DARTS. However, the weight-sharing framework used for\ncell-search in DARTS and the convergence of architecture parameters has not\nbeen analyzed yet. In this paper, we provide a thorough and novel theoretical\nand empirical analysis on DARTS and its point of convergence. We show that\nDARTS suffers from a specific structural flaw due to its weight-sharing\nframework that limits the convergence of DARTS to saturation points of the\nsoftmax function. This point of convergence gives an unfair advantage to layers\ncloser to the output in choosing the optimal architecture, causing performance\ncollapse. We then propose two new regularization terms that aim to prevent\nperformance collapse by harmonizing operation selection via aligning gradients\nof layers. Experimental results on six different search spaces and three\ndifferent datasets show that our method ($\\Lambda$-DARTS) does indeed prevent\nperformance collapse, providing justification for our theoretical analysis and\nthe proposed remedy.",
    "descriptor": "",
    "authors": [
      "Sajad Movahedi",
      "Melika Adabinejad",
      "Ayyoob Imani",
      "Arezou Keshavarz",
      "Mostafa Dehghani",
      "Azadeh Shakery",
      "Babak N. Araabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07998"
  },
  {
    "id": "arXiv:2210.08001",
    "title": "Learnable Polyphase Sampling for Shift Invariant and Equivariant  Convolutional Networks",
    "abstract": "We propose learnable polyphase sampling (LPS), a pair of learnable\ndown/upsampling layers that enable truly shift-invariant and equivariant\nconvolutional networks. LPS can be trained end-to-end from data and generalizes\nexisting handcrafted downsampling layers. It is widely applicable as it can be\nintegrated into any convolutional network by replacing down/upsampling layers.\nWe evaluate LPS on image classification and semantic segmentation. Experiments\nshow that LPS is on-par with or outperforms existing methods in both\nperformance and shift consistency. For the first time, we achieve true\nshift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift\nconsistency, outperforming baselines by an absolute 3.3%.",
    "descriptor": "\nComments: Accepted at the Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Teck-Yian Lim",
      "Alexander G. Schwing",
      "Minh N. Do",
      "Raymond A. Yeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08001"
  },
  {
    "id": "arXiv:2210.07278",
    "title": "Meta-Uncertainty in Bayesian Model Comparison",
    "abstract": "Bayesian model comparison (BMC) offers a principled probabilistic approach to\nstudy and rank competing models. In standard BMC, we construct a discrete\nprobability distribution over the set of possible models, conditional on the\nobserved data of interest. These posterior model probabilities (PMPs) are\nmeasures of uncertainty, but, when derived from a finite number of\nobservations, are also uncertain themselves. In this paper, we conceptualize\ndistinct levels of uncertainty which arise in BMC. We explore a fully\nprobabilistic framework for quantifying meta-uncertainty, resulting in an\napplied method to enhance any BMC workflow. Drawing on both Bayesian and\nfrequentist techniques, we represent the uncertainty over the uncertain PMPs\nvia meta-models which combine simulated and observed data into a predictive\ndistribution for PMPs on new data. We demonstrate the utility of the proposed\nmethod in the context of conjugate Bayesian regression, likelihood-based\ninference with Markov chain Monte Carlo, and simulation-based inference with\nneural networks.",
    "descriptor": "",
    "authors": [
      "Marvin Schmitt",
      "Stefan T. Radev",
      "Paul-Christian B\u00fcrkner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07278"
  },
  {
    "id": "arXiv:2210.07322",
    "title": "Human Behavioral Models Using Utility Theory and Prospect Theory",
    "abstract": "Several examples of Cyber-physical human systems (CPHS) include real-time\ndecisions from humans as a necessary building block for the successful\nperformance of the overall system. Many of these decision-making problems\nnecessitate an appropriate model of human behavior. Tools from Utility Theory\nhave been used successfully in several problems in transportation for resource\nallocation and balance of supply and demand \\citep{ben1985discrete}. More\nrecently, Prospect Theory has been demonstrated as a useful tool in behavioral\neconomics and cognitive psychology for deriving human behavioral models that\ncharacterize their subjective decision-making in the presence of stochastic\nuncertainties and risks, as an alternative to conventional Utility Theory\n\\citep{kahneman_prospect_2012}. These models will be described in this article.\nTheoretical implications of Prospect Theory are also discussed. Examples will\nbe drawn from transportation use cases such as shared mobility to illustrate\nthese models as well as the distinctions between Utility Theory and Prospect\nTheory.",
    "descriptor": "\nComments: 26 pages, submitted chapter to upcoming Wiley book on Cyber-Physical Human Systems (CPHS). arXiv admin note: text overlap with arXiv:1904.04824\n",
    "authors": [
      "Anuradha M. Annaswamy",
      "Vineet Jagadeesan Nair"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.07322"
  },
  {
    "id": "arXiv:2210.07326",
    "title": "Characterizing matrices with eigenvalues in an LMI region: A  dissipative-Hamiltonian approach",
    "abstract": "In this paper, we provide a dissipative Hamiltonian (DH) characterization for\nthe set of matrices whose eigenvalues belong to a given LMI region. This\ncharacterization is a generalization of that of Choudhary et al. (Numer. Linear\nAlgebra Appl., 2020) to any LMI region. It can be used in various contexts,\nwhich we illustrate on the nearest $\\Omega$-stable matrix problem: given an LMI\nregion $\\Omega \\subseteq \\mathbb{C}$ and a matrix $A \\in \\mathbb{C}^{n,n}$,\nfind the nearest matrix to $A$ whose eigenvalues belong to $\\Omega$. Finally,\nwe generalize our characterization to more general regions that can be\nexpressed using LMIs involving complex matrices.",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Neelam Choudhary",
      "Nicolas Gillis",
      "Punit Sharma"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07326"
  },
  {
    "id": "arXiv:2210.07339",
    "title": "Nash Equilibria for Exchangeable Team against Team Games and their Mean  Field Limit",
    "abstract": "We study stochastic mean-field games among finite number of teams with large\nfinite as well as infinite number of decision makers. For this class of games\nwithin static and dynamic settings, we establish the existence of a Nash\nequilibrium, and show that a Nash equilibrium exhibits exchangeability in the\nfinite decision maker regime and symmetry in the infinite one. To arrive at\nthese existence and structural theorems, we endow the set of randomized\npolicies with a suitable topology under various decentralized information\nstructures, which leads to the desired convexity and compactness of the set of\nrandomized policies. Then, we establish the existence of a randomized Nash\nequilibrium that is exchangeable (not necessarily symmetric) among decision\nmakers within each team for a general class of exchangeable stochastic games.\nAs the number of decision makers within each team goes to infinity (that is for\nthe mean-field game among teams), using a de Finetti representation theorem, we\nshow the existence of a randomized Nash equilibrium that is symmetric (i.e.,\nidentical) among decision makers within each team and also independently\nrandomized. Finally, we establish that a Nash equilibrium for a class of\nmean-field games among teams (which is symmetric) constitutes an approximate\nNash equilibrium for the corresponding pre-limit (exchangeable) game among\nteams with large but finite number of decision makers.",
    "descriptor": "",
    "authors": [
      "Sina Sanjari",
      "Naci Saldi",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07339"
  },
  {
    "id": "arXiv:2210.07361",
    "title": "On the ergodicity assumption in Performance-Based Engineering",
    "abstract": "In the Performance-Based Engineering (PBE) framework, uncertainties in system\nparameters, or modelling uncertainties, have been shown to have significant\neffects on capacity fragilities and annual collapse rates of buildings. Yet,\nsince modelling uncertainties are non-ergodic variables, their consideration in\nfailure rate calculations offends the Poisson assumption of independent\ncrossings. This problem has been addressed in the literature, and errors found\nnegligible for small annual collapse failure rates. However, the errors could\nbe significant for serviceability limit states, and when failure rates are\nintegrated in time, to provide lifetime failure probabilities. Herein, we\npresent a novel formulation to fully avoid the error in integration of\nnon-ergodic variables. The proposed product-of-lognormals formulation is fully\ncompatible with popular fragility modelling approaches in PBE context.\nMoreover, we address collapse limit states of realistic reinforced concrete\nbuildings, and find errors of the order of 5 to 8% for 50-year lifetimes, up to\n14% for 100 years. Computation of accurate lifetime failure probabilities in a\nPBE context is clearly important, as it allows comparison with lifetime target\nreliability values for other structural analysis formulations.",
    "descriptor": "",
    "authors": [
      "Andre T. Beck",
      "Rubia M. Bosse",
      "Isabela D. Rodrigues"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.07361"
  },
  {
    "id": "arXiv:2210.07383",
    "title": "Notes on CSPs and Polymorphisms",
    "abstract": "These are notes from a multi-year learning seminar on the algebraic approach\nto Constraint Satisfaction Problems (CSPs). The main topics covered are the\ntheory of algebraic structures with few subpowers, the theory of absorbing\nsubalgebras and its applications to studying CSP templates which can be solved\nby local consistency methods, and the dichotomy theorem for conservative CSP\ntemplates. Subsections and appendices cover supplementary material.",
    "descriptor": "\nComments: 407 pages\n",
    "authors": [
      "Zarathustra Brady"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07383"
  },
  {
    "id": "arXiv:2210.07410",
    "title": "Quantification of entanglement with Siamese convolutional neural  networks",
    "abstract": "Quantum entanglement is a fundamental property commonly used in various\nquantum information protocols and algorithms. Nonetheless, the problem of\nquantifying entanglement has still not reached general solution for systems\nlarger than two qubits. In this paper, we investigate the possibility of\ndetecting entanglement with the use of the supervised machine learning method,\nnamely the deep convolutional neural networks. We build a model consisting of\nconvolutional layers, which is able to recognize and predict the presence of\nentanglement for any bipartition of the given multi-qubit system. We\ndemonstrate that training our model on synthetically generated datasets\ncollecting random density matrices, which either include or exclude challenging\npositive-under-partial-transposition entangled states (PPTES), leads to the\ndifferent accuracy of the model and its possibility to detect such states.\nMoreover, it is shown that enforcing entanglement-preserving symmetry\noperations (local operations on qubit or permutations of qubits) by using\ntriple Siamese network, can significantly increase the model performance and\nability to generalize on types of states not seen during the training stage. We\nperform numerical calculations for 3,4 and 5-qubit systems, therefore proving\nthe scalability of the proposed approach.",
    "descriptor": "\nComments: 17 pages, 9 figures, 5 tables\n",
    "authors": [
      "Jaros\u0142aw Paw\u0142owski",
      "Mateusz Krawczyk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07410"
  },
  {
    "id": "arXiv:2210.07413",
    "title": "Invariance-adapted decomposition and Lasso-type contrastive learning",
    "abstract": "Recent years have witnessed the effectiveness of contrastive learning in\nobtaining the representation of dataset that is useful in interpretation and\ndownstream tasks. However, the mechanism that describes this effectiveness have\nnot been thoroughly analyzed, and many studies have been conducted to\ninvestigate the data structures captured by contrastive learning. In\nparticular, the recent study of \\citet{content_isolate} has shown that\ncontrastive learning is capable of decomposing the data space into the space\nthat is invariant to all augmentations and its complement. In this paper, we\nintroduce the notion of invariance-adapted latent space that decomposes the\ndata space into the intersections of the invariant spaces of each augmentation\nand their complements. This decomposition generalizes the one introduced in\n\\citet{content_isolate}, and describes a structure that is analogous to the\nfrequencies in the harmonic analysis of a group. We experimentally show that\ncontrastive learning with lasso-type metric can be used to find an\ninvariance-adapted latent space, thereby suggesting a new potential for the\ncontrastive learning. We also investigate when such a latent space can be\nidentified up to mixings within each component.",
    "descriptor": "",
    "authors": [
      "Masanori Koyama",
      "Takeru Miyato",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07413"
  },
  {
    "id": "arXiv:2210.07430",
    "title": "CaloDVAE : Discrete Variational Autoencoders for Fast Calorimeter Shower  Simulation",
    "abstract": "Calorimeter simulation is the most computationally expensive part of Monte\nCarlo generation of samples necessary for analysis of experimental data at the\nLarge Hadron Collider (LHC). The High-Luminosity upgrade of the LHC would\nrequire an even larger amount of such samples. We present a technique based on\nDiscrete Variational Autoencoders (DVAEs) to simulate particle showers in\nElectromagnetic Calorimeters. We discuss how this work paves the way towards\nexploration of quantum annealing processors as sampling devices for generation\nof simulated High Energy Physics datasets.",
    "descriptor": "\nComments: 11 pages, 4 figures, 5 tables, Accepted version at NeurIPS Workshop on Machine Learning and the Physical Sciences (ML4PS) 2021\n",
    "authors": [
      "Abhishek Abhishek",
      "Eric Drechsler",
      "Wojciech Fedorko",
      "Bernd Stelzer"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07430"
  },
  {
    "id": "arXiv:2210.07490",
    "title": "Exploring Vanilla U-Net for Lesion Segmentation from Whole-body  FDG-PET/CT Scans",
    "abstract": "Tumor lesion segmentation is one of the most important tasks in medical image\nanalysis. In clinical practice, Fluorodeoxyglucose Positron-Emission\nTomography~(FDG-PET) is a widely used technique to identify and quantify\nmetabolically active tumors. However, since FDG-PET scans only provide\nmetabolic information, healthy tissue or benign disease with irregular glucose\nconsumption may be mistaken for cancer. To handle this challenge, PET is\ncommonly combined with Computed Tomography~(CT), with the CT used to obtain the\nanatomic structure of the patient. The combination of PET-based metabolic and\nCT-based anatomic information can contribute to better tumor segmentation\nresults. %Computed tomography~(CT) is a popular modality to illustrate the\nanatomic structure of the patient. The combination of PET and CT is promising\nto handle this challenge by utilizing metabolic and anatomic information. In\nthis paper, we explore the potential of U-Net for lesion segmentation in\nwhole-body FDG-PET/CT scans from three aspects, including network architecture,\ndata preprocessing, and data augmentation. The experimental results demonstrate\nthat the vanilla U-Net with proper input shape can achieve satisfactory\nperformance. Specifically, our method achieves first place in both preliminary\nand final leaderboards of the autoPET 2022 challenge. Our code is available at\nhttps://github.com/Yejin0111/autoPET2022_Blackbean.",
    "descriptor": "\nComments: autoPET 2022, MICCAI 2022 challenge, champion\n",
    "authors": [
      "Jin Ye",
      "Haoyu Wang",
      "Ziyan Huang",
      "Zhongying Deng",
      "Yanzhou Su",
      "Can Tu",
      "Qian Wu",
      "Yuncheng Yang",
      "Meng Wei",
      "Jingqi Niu",
      "Junjun He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07490"
  },
  {
    "id": "arXiv:2210.07513",
    "title": "Continuous-in-time Limit for Bayesian Bandits",
    "abstract": "This paper revisits the bandit problem in the Bayesian setting. The Bayesian\napproach formulates the bandit problem as an optimization problem, and the goal\nis to find the optimal policy which minimizes the Bayesian regret. One of the\nmain challenges facing the Bayesian approach is that computation of the optimal\npolicy is often intractable, especially when the length of the problem horizon\nor the number of arms is large. In this paper, we first show that under a\nsuitable rescaling, the Bayesian bandit problem converges to a continuous\nHamilton-Jacobi-Bellman (HJB) equation. The optimal policy for the limiting HJB\nequation can be explicitly obtained for several common bandit problems, and we\ngive numerical methods to solve the HJB equation when an explicit solution is\nnot available. Based on these results, we propose an approximate Bayes-optimal\npolicy for solving Bayesian bandit problems with large horizons. Our method has\nthe added benefit that its computational cost does not increase as the horizon\nincreases.",
    "descriptor": "",
    "authors": [
      "Yuhua Zhu",
      "Zach Izzo",
      "Lexing Ying"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07513"
  },
  {
    "id": "arXiv:2210.07545",
    "title": "Hypergraphs for multiscale cycles in structured data",
    "abstract": "Scientific data has been growing in both size and complexity across the\nmodern physical, engineering, life and social sciences. Spatial structure, for\nexample, is a hallmark of many of the most important real-world complex\nsystems, but its analysis is fraught with statistical challenges. Topological\ndata analysis can provide a powerful computational window on complex systems.\nHere we present a framework to extend and interpret persistent homology\nsummaries to analyse spatial data across multiple scales. We introduce\nhyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global\n(e.g. Euclidean) metrics without losing spatial information, even in the\npresence of noise. Homology generators offer an elegant and flexible\ndescription of spatial structures and can capture the information computed by\npersistent homology in an interpretable way. Here the information computed by\npersistent homology is transformed into a weighted hypergraph, where hyperedges\ncorrespond to homology generators. We consider different choices of generators\n(e.g. matroid or minimal) and find that centrality and community detection are\nrobust to either choice. We compare hyperTDA to existing geometric measures and\nvalidate its robustness to noise. We demonstrate the power of computing\nhigher-order topological structures on spatial curves arising frequently in\necology, biophysics, and biology, but also in high-dimensional financial\ndatasets. We find that hyperTDA can select between synthetic trajectories from\nthe landmark 2020 AnDi challenge and quantifies movements of different animal\nspecies, even when data is limited.",
    "descriptor": "\nComments: 6 Figures, 15 pages and Supplementary Information (including figures) as an Appendix. Associated GitHub repositories: github.com/degnbol/hyperTDA and github.com/irishryoon/minimal_generators_curves\n",
    "authors": [
      "Agnese Barbensi",
      "Hee Rhang Yoon",
      "Christian Degnbol Madsen",
      "Deborah O. Ajayi",
      "Michael P.H. Stumpf",
      "Heather A. Harrington"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.07545"
  },
  {
    "id": "arXiv:2210.07550",
    "title": "Codes on Subgroups of Weighted Projective Tori",
    "abstract": "We obtain certain algebraic invariants relevant to study codes on subgroups\nof weighted projective tori inside an $n$-dimensional weighted projective\nspace. As application, we compute all the main parameters of generalized toric\ncodes on these subgroups of tori lying inside a weighted projective plane of\nthe form $\\Pp(1,1,a)$.",
    "descriptor": "\nComments: supported by TUBITAK Project No:119F177\n",
    "authors": [
      "Mesut \u015eahin",
      "O\u011fuz Yayla"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.07550"
  },
  {
    "id": "arXiv:2210.07611",
    "title": "Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion",
    "abstract": "Deep Learning-based 2D/3D registration enables fast, robust, and accurate\nX-ray to CT image fusion when large annotated paired datasets are available for\ntraining. However, the need for paired CT volume and X-ray images with ground\ntruth registration limits the applicability in interventional scenarios. An\nalternative is to use simulated X-ray projections from CT volumes, thus\nremoving the need for paired annotated datasets. Deep Neural Networks trained\nexclusively on simulated X-ray projections can perform significantly worse on\nreal X-ray images due to the domain gap. We propose a self-supervised 2D/3D\nregistration framework combining simulated training with unsupervised feature\nand pixel space domain adaptation to overcome the domain gap and eliminate the\nneed for paired annotated datasets. Our framework achieves a registration\naccuracy of 1.83$\\pm$1.16 mm with a high success ratio of 90.1% on real X-ray\nimages showing a 23.9% increase in success ratio compared to reference\nannotation-free algorithms.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Srikrishna Jaganathan",
      "Maximilian Kukla",
      "Jian Wang",
      "Karthik Shetty",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07611"
  },
  {
    "id": "arXiv:2210.07612",
    "title": "Monotonicity and Double Descent in Uncertainty Estimation with Gaussian  Processes",
    "abstract": "The quality of many modern machine learning models improves as model\ncomplexity increases, an effect that has been quantified, for predictive\nperformance, with the non-monotonic double descent learning curve. Here, we\naddress the overarching question: is there an analogous theory of double\ndescent for models which estimate uncertainty? We provide a partially\naffirmative and partially negative answer in the setting of Gaussian processes\n(GP). Under standard assumptions, we prove that higher model quality for\noptimally-tuned GPs (including uncertainty prediction) under marginal\nlikelihood is realized for larger input dimensions, and therefore exhibits a\nmonotone error curve. After showing that marginal likelihood does not naturally\nexhibit double descent in the input dimension, we highlight related forms of\nposterior predictive loss that do exhibit non-monotonicity. Finally, we verify\nempirically that our results hold for real data, beyond our considered\nassumptions, and we explore consequences involving synthetic covariates.",
    "descriptor": "\nComments: 40 pages, 20 figures\n",
    "authors": [
      "Liam Hodgkinson",
      "Chris van der Heide",
      "Fred Roosta",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07612"
  },
  {
    "id": "arXiv:2210.07677",
    "title": "TransFusion: Transcribing Speech with Multinomial Diffusion",
    "abstract": "Diffusion models have shown exceptional scaling properties in the image\nsynthesis domain, and initial attempts have shown similar benefits for applying\ndiffusion to unconditional text synthesis. Denoising diffusion models attempt\nto iteratively refine a sampled noise signal until it resembles a coherent\nsignal (such as an image or written sentence). In this work we aim to see\nwhether the benefits of diffusion models can also be realized for speech\nrecognition. To this end, we propose a new way to perform speech recognition\nusing a diffusion model conditioned on pretrained speech features.\nSpecifically, we propose TransFusion: a transcribing diffusion model which\niteratively denoises a random character sequence into coherent text\ncorresponding to the transcript of a conditioning utterance. We demonstrate\ncomparable performance to existing high-performing contrastive models on the\nLibriSpeech speech recognition benchmark. To the best of our knowledge, we are\nthe first to apply denoising diffusion to speech recognition. We also propose\nnew techniques for effectively sampling and decoding multinomial diffusion\nmodels. These are required because traditional methods of sampling from\nacoustic models are not possible with our new discrete diffusion approach. Code\nand trained models are available: https://github.com/RF5/transfusion-asr",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table. Accepted at SACAIR 2022\n",
    "authors": [
      "Matthew Baas",
      "Kevin Eloff",
      "Herman Kamper"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.07677"
  },
  {
    "id": "arXiv:2210.07717",
    "title": "Motion-related Artefact Classification Using Patch-based Ensemble and  Transfer Learning in Cardiac MRI",
    "abstract": "Cardiac Magnetic Resonance Imaging (MRI) plays an important role in the\nanalysis of cardiac function. However, the acquisition is often accompanied by\nmotion artefacts because of the difficulty of breath-hold, especially for acute\nsymptoms patients. Therefore, it is essential to assess the quality of cardiac\nMRI for further analysis. Time-consuming manual-based classification is not\nconducive to the construction of an end-to-end computer aided diagnostic\nsystem. To overcome this problem, an automatic cardiac MRI quality estimation\nframework using ensemble and transfer learning is proposed in this work.\nMultiple pre-trained models were initialised and fine-tuned on 2-dimensional\nimage patches sampled from the training data. In the model inference process,\ndecisions from these models are aggregated to make a final prediction. The\nframework has been evaluated on CMRxMotion grand challenge (MICCAI 2022)\ndataset which is small, multi-class, and imbalanced. It achieved a\nclassification accuracy of 78.8% and 70.0% on the training set (5-fold\ncross-validation) and a validation set, respectively. The final trained model\nwas also evaluated on an independent test set by the CMRxMotion organisers,\nwhich achieved the classification accuracy of 72.5% and Cohen's Kappa of 0.6309\n(ranked top 1 in this grand challenge). Our code is available on Github:\nhttps://github.com/ruizhe-l/CMRxMotion.",
    "descriptor": "\nComments: Accepted for CMRxMotion challenge at STACOM 2022 workshop, MICCAI 2022\n",
    "authors": [
      "Ruizhe Li",
      "Xin Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07717"
  },
  {
    "id": "arXiv:2210.07723",
    "title": "Privacy-Preserving and Lossless Distributed Estimation of  High-Dimensional Generalized Additive Mixed Models",
    "abstract": "Various privacy-preserving frameworks that respect the individual's privacy\nin the analysis of data have been developed in recent years. However, available\nmodel classes such as simple statistics or generalized linear models lack the\nflexibility required for a good approximation of the underlying data-generating\nprocess in practice. In this paper, we propose an algorithm for a distributed,\nprivacy-preserving, and lossless estimation of generalized additive mixed\nmodels (GAMM) using component-wise gradient boosting (CWB). Making use of CWB\nallows us to reframe the GAMM estimation as a distributed fitting of base\nlearners using the $L_2$-loss. In order to account for the heterogeneity of\ndifferent data location sites, we propose a distributed version of a row-wise\ntensor product that allows the computation of site-specific (smooth) effects.\nOur adaption of CWB preserves all the important properties of the original\nalgorithm, such as an unbiased feature selection and the feasibility to fit\nmodels in high-dimensional feature spaces, and yields equivalent model\nestimates as CWB on pooled data. Next to a derivation of the equivalence of\nboth algorithms, we also showcase the efficacy of our algorithm on a\ndistributed heart disease data set and compare it with state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Daniel Schalk",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07723"
  },
  {
    "id": "arXiv:2210.07749",
    "title": "LeVoice ASR Systems for the ISCSLP 2022 Intelligent Cockpit Speech  Recognition Challenge",
    "abstract": "This paper describes LeVoice automatic speech recognition systems to track2\nof intelligent cockpit speech recognition challenge 2022. Track2 is a speech\nrecognition task without limits on the scope of model size. Our main points\ninclude deep learning based speech enhancement, text-to-speech based speech\ngeneration, training data augmentation via various techniques and speech\nrecognition model fusion. We compared and fused the hybrid architecture and two\nkinds of end-to-end architecture. For end-to-end modeling, we used models based\non connectionist temporal classification/attention-based encoder-decoder\narchitecture and recurrent neural network transducer/attention-based\nencoder-decoder architecture. The performance of these models is evaluated with\nan additional language model to improve word error rates. As a result, our\nsystem achieved 10.2\\% character error rate on the challenge test set data and\nranked third place among the submitted systems in the challenge.",
    "descriptor": "",
    "authors": [
      "Yan Jia",
      "Mi Hong",
      "Jingyu Hou",
      "Kailong Ren",
      "Sifan Ma",
      "Jin Wang",
      "Fangzhen Peng",
      "Yinglin Ji",
      "Lin Yang",
      "Junjie Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.07749"
  },
  {
    "id": "arXiv:2210.07751",
    "title": "Blind Super-Resolution for Remote Sensing Images via Conditional  Stochastic Normalizing Flows",
    "abstract": "Remote sensing images (RSIs) in real scenes may be disturbed by multiple\nfactors such as optical blur, undersampling, and additional noise, resulting in\ncomplex and diverse degradation models. At present, the mainstream SR\nalgorithms only consider a single and fixed degradation (such as bicubic\ninterpolation) and cannot flexibly handle complex degradations in real scenes.\nTherefore, designing a super-resolution (SR) model that can cope with various\ndegradations is gradually attracting the attention of researchers. Some studies\nfirst estimate the degradation kernels and then perform degradation-adaptive SR\nbut face the problems of estimation error amplification and insufficient\nhigh-frequency details in the results. Although blind SR algorithms based on\ngenerative adversarial networks (GAN) have greatly improved visual quality,\nthey still suffer from pseudo-texture, mode collapse, and poor training\nstability. In this article, we propose a novel blind SR framework based on the\nstochastic normalizing flow (BlindSRSNF) to address the above problems.\nBlindSRSNF learns the conditional probability distribution over the\nhigh-resolution image space given a low-resolution (LR) image by explicitly\noptimizing the variational bound on the likelihood. BlindSRSNF is easy to train\nand can generate photo-realistic SR results that outperform GAN-based models.\nBesides, we introduce a degradation representation strategy based on\ncontrastive learning to avoid the error amplification problem caused by the\nexplicit degradation estimation. Comprehensive experiments show that the\nproposed algorithm can obtain SR results with excellent visual perception\nquality on both simulated LR and real-world RSIs.",
    "descriptor": "",
    "authors": [
      "Hanlin Wu",
      "Ning Ni",
      "Shan Wang",
      "Libao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07751"
  },
  {
    "id": "arXiv:2210.07761",
    "title": "Improved automated lesion segmentation in whole-body FDG/PET-CT via  Test-Time Augmentation",
    "abstract": "Numerous oncology indications have extensively quantified metabolically\nactive tumors using positron emission tomography (PET) and computed tomography\n(CT). F-fluorodeoxyglucose-positron emission tomography (FDG-PET) is frequently\nutilized in clinical practice and clinical drug research to detect and measure\nmetabolically active malignancies. The assessment of tumor burden using manual\nor computer-assisted tumor segmentation in FDG-PET images is widespread. Deep\nlearning algorithms have also produced effective solutions in this area.\nHowever, there may be a need to improve the performance of a pre-trained deep\nlearning network without the opportunity to modify this network. We investigate\nthe potential benefits of test-time augmentation for segmenting tumors from\nPET-CT pairings. We applied a new framework of multilevel and multimodal tumor\nsegmentation techniques that can simultaneously consider PET and CT data. In\nthis study, we improve the network using a learnable composition of test time\naugmentations. We trained U-Net and Swin U-Netr on the training database to\ndetermine how different test time augmentation improved segmentation\nperformance. We also developed an algorithm that finds an optimal test time\naugmentation contribution coefficient set. Using the newly trained U-Net and\nSwin U-Netr results, we defined an optimal set of coefficients for test-time\naugmentation and utilized them in combination with a pre-trained fixed nnU-Net.\nThe ultimate idea is to improve performance at the time of testing when the\nmodel is fixed. Averaging the predictions with varying ratios on the augmented\ndata can improve prediction accuracy. Our code will be available at\n\\url{https://github.com/sepidehamiri/pet\\_seg\\_unet}",
    "descriptor": "",
    "authors": [
      "Sepideh Amiri",
      "Bulat Ibragimov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07761"
  },
  {
    "id": "arXiv:2210.07771",
    "title": "Learning to Jointly Transcribe and Subtitle for End-to-End Spontaneous  Speech Recognition",
    "abstract": "TV subtitles are a rich source of transcriptions of many types of speech,\nranging from read speech in news reports to conversational and spontaneous\nspeech in talk shows and soaps. However, subtitles are not verbatim (i.e.\nexact) transcriptions of speech, so they cannot be used directly to improve an\nAutomatic Speech Recognition (ASR) model. We propose a multitask dual-decoder\nTransformer model that jointly performs ASR and automatic subtitling. The ASR\ndecoder (possibly pre-trained) predicts the verbatim output and the subtitle\ndecoder generates a subtitle, while sharing the encoder. The two decoders can\nbe independent or connected. The model is trained to perform both tasks\njointly, and is able to effectively use subtitle data. We show improvements on\nregular ASR and on spontaneous and conversational ASR by incorporating the\nadditional subtitle decoder. The method does not require preprocessing\n(aligning, filtering, pseudo-labeling, ...) of the subtitles.",
    "descriptor": "\nComments: Accepted at SLT 2022\n",
    "authors": [
      "Jakob Poncelet",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.07771"
  },
  {
    "id": "arXiv:2210.07803",
    "title": "An Efficient FPGA Accelerator for Point Cloud",
    "abstract": "Deep learning-based point cloud processing plays an important role in various\nvision tasks, such as autonomous driving, virtual reality (VR), and augmented\nreality (AR). The submanifold sparse convolutional network (SSCN) has been\nwidely used for the point cloud due to its unique advantages in terms of visual\nresults. However, existing convolutional neural network accelerators suffer\nfrom non-trivial performance degradation when employed to accelerate SSCN\nbecause of the extreme and unstructured sparsity, and the complex computational\ndependency between the sparsity of the central activation and the neighborhood\nones. In this paper, we propose a high performance FPGA-based accelerator for\nSSCN. Firstly, we develop a zero removing strategy to remove the coarse-grained\nredundant regions, thus significantly improving computational efficiency.\nSecondly, we propose a concise encoding scheme to obtain the matching\ninformation for efficient point-wise multiplications. Thirdly, we develop a\nsparse data matching unit and a computing core based on the proposed encoding\nscheme, which can convert the irregular sparse operations into regular\nmultiply-accumulate operations. Finally, an efficient hardware architecture for\nthe submanifold sparse convolutional layer is developed and implemented on the\nXilinx ZCU102 field-programmable gate array board, where the 3D submanifold\nsparse U-Net is taken as the benchmark. The experimental results demonstrate\nthat our design drastically improves computational efficiency, and can\ndramatically improve the power efficiency by 51 times compared to GPU.",
    "descriptor": "\nComments: 6 pages, 10 figures, accepted by 2022 IEEE INTERNATIONAL SYSTEM-ON-CHIP conference\n",
    "authors": [
      "Zilun Wang",
      "Wendong Mao",
      "Peixiang Yang",
      "Zhongfeng Wang",
      "Jun Lin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.07803"
  },
  {
    "id": "arXiv:2210.07808",
    "title": "Optimal AdaBoost Converges",
    "abstract": "The following work is a preprint collection of formal proofs regarding the\nconvergence properties of the AdaBoost machine learning algorithm's classifier\nand margins. Various math and computer science papers have been written\nregarding conjectures and special cases of these convergence properties.\nFurthermore, the margins of AdaBoost feature prominently in the research\nsurrounding the algorithm. At the zenith of this paper we present how\nAdaBoost's classifier and margins converge on a value that agrees with decades\nof research. After this, we show how various quantities associated with the\ncombined classifier converge.",
    "descriptor": "",
    "authors": [
      "Conor Snedeker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07808"
  },
  {
    "id": "arXiv:2210.07810",
    "title": "A Consistent and Differentiable Lp Canonical Calibration Error Estimator",
    "abstract": "Calibrated probabilistic classifiers are models whose predicted probabilities\ncan directly be interpreted as uncertainty estimates. It has been shown\nrecently that deep neural networks are poorly calibrated and tend to output\noverconfident predictions. As a remedy, we propose a low-bias, trainable\ncalibration error estimator based on Dirichlet kernel density estimates, which\nasymptotically converges to the true $L_p$ calibration error. This novel\nestimator enables us to tackle the strongest notion of multiclass calibration,\ncalled canonical (or distribution) calibration, while other common calibration\nmethods are tractable only for top-label and marginal calibration. The\ncomputational complexity of our estimator is $\\mathcal{O}(n^2)$, the\nconvergence rate is $\\mathcal{O}(n^{-1/2})$, and it is unbiased up to\n$\\mathcal{O}(n^{-2})$, achieved by a geometric series debiasing scheme. In\npractice, this means that the estimator can be applied to small subsets of\ndata, enabling efficient estimation and mini-batch updates. The proposed method\nhas a natural choice of kernel, and can be used to generate consistent\nestimates of other quantities based on conditional expectation, such as the\nsharpness of a probabilistic classifier. Empirical results validate the\ncorrectness of our estimator, and demonstrate its utility in canonical\ncalibration error estimation and calibration error regularized risk\nminimization.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Teodora Popordanoska",
      "Raphael Sayer",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07810"
  },
  {
    "id": "arXiv:2210.07818",
    "title": "ISTA-Inspired Network for Image Super-Resolution",
    "abstract": "Deep learning for image super-resolution (SR) has been investigated by\nnumerous researchers in recent years. Most of the works concentrate on\neffective block designs and improve the network representation but lack\ninterpretation. There are also iterative optimization-inspired networks for\nimage SR, which take the solution step as a whole without giving an explicit\noptimization step. This paper proposes an unfolding iterative shrinkage\nthresholding algorithm (ISTA) inspired network for interpretable image SR.\nSpecifically, we analyze the problem of image SR and propose a solution based\non the ISTA method. Inspired by the mathematical analysis, the ISTA block is\ndeveloped to conduct the optimization in an end-to-end manner. To make the\nexploration more effective, a multi-scale exploitation block and multi-scale\nattention mechanism are devised to build the ISTA block. Experimental results\nshow the proposed ISTA-inspired restoration network (ISTAR) achieves\ncompetitive or better performances than other optimization-inspired works with\nfewer parameters and lower computation complexity.",
    "descriptor": "",
    "authors": [
      "Yuqing Liu",
      "Wei Zhang",
      "Weifeng Sun",
      "Zhikai Yu",
      "Jianfeng Wei",
      "Shengquan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07818"
  },
  {
    "id": "arXiv:2210.07856",
    "title": "Description and analysis of novelties introduced in DCASE Task 4 2022 on  the baseline system",
    "abstract": "The aim of the Detection and Classification of Acoustic Scenes and Events\nChallenge Task 4 is to evaluate systems for the detection of sound events in\ndomestic environments using an heterogeneous dataset. The systems need to be\nable to correctly detect the sound events present in a recorded audio clip, as\nwell as localize the events in time. This year's task is a follow-up of DCASE\n2021 Task 4, with some important novelties. The goal of this paper is to\ndescribe and motivate these new additions, and report an analysis of their\nimpact on the baseline system. We introduced three main novelties: the use of\nexternal datasets, including recently released strongly annotated clips from\nAudioset, the possibility of leveraging pre-trained models, and a new energy\nconsumption metric to raise awareness about the ecological impact of training\nsound events detectors. The results on the baseline system show that leveraging\nopen-source pretrained on AudioSet improves the results significantly in terms\nof event classification but not in terms of event segmentation.",
    "descriptor": "",
    "authors": [
      "Francesca Ronchini",
      "Samuele Cornell",
      "Romain Serizel",
      "Nicolas Turpault",
      "Eduardo Fonseca",
      "Daniel P. W. Ellis"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.07856"
  },
  {
    "id": "arXiv:2210.07857",
    "title": "Commutativity and Disentanglement from the Manifold Perspective",
    "abstract": "In this paper, we interpret disentanglement from the manifold perspective and\ntrace how it naturally leads to a necessary and sufficient condition for\ndisentanglement: the disentangled factors must commute with each other. Along\nthe way, we show how some technical results have consequences for the\ncompression and disentanglement of generative models, and we also discuss the\npractical and theoretical implications of commutativity. Finally, we conclude\nwith a discussion of related approaches to disentanglement and how they relate\nto our view of disentanglement from the manifold perspective.",
    "descriptor": "",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07857"
  },
  {
    "id": "arXiv:2210.07880",
    "title": "Tunable Complexity Benchmarks for Evaluating Physics-Informed Neural  Networks on Coupled Ordinary Differential Equations",
    "abstract": "In this work, we assess the ability of physics-informed neural networks\n(PINNs) to solve increasingly-complex coupled ordinary differential equations\n(ODEs). We focus on a pair of benchmarks: discretized partial differential\nequations and harmonic oscillators, each of which has a tunable parameter that\ncontrols its complexity. Even by varying network architecture and applying a\nstate-of-the-art training method that accounts for \"difficult\" training\nregions, we show that PINNs eventually fail to produce correct solutions to\nthese benchmarks as their complexity -- the number of equations and the size of\ntime domain -- increases. We identify several reasons why this may be the case,\nincluding insufficient network capacity, poor conditioning of the ODEs, and\nhigh local curvature, as measured by the Laplacian of the PINN loss.",
    "descriptor": "\nComments: Accepted at KGML-AAAI-22: this https URL\n",
    "authors": [
      "Alexander New",
      "Benjamin Eng",
      "Andrea C. Timm",
      "Andrew S. Gearhart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07880"
  },
  {
    "id": "arXiv:2210.07881",
    "title": "Communication-Efficient Topologies for Decentralized Learning with  $O(1)$ Consensus Rate",
    "abstract": "Decentralized optimization is an emerging paradigm in distributed learning in\nwhich agents achieve network-wide solutions by peer-to-peer communication\nwithout the central server. Since communication tends to be slower than\ncomputation, when each agent communicates with only a few neighboring agents\nper iteration, they can complete iterations faster than with more agents or a\ncentral server. However, the total number of iterations to reach a network-wide\nsolution is affected by the speed at which the agents' information is ``mixed''\nby communication. We found that popular communication topologies either have\nlarge maximum degrees (such as stars and complete graphs) or are ineffective at\nmixing information (such as rings and grids). To address this problem, we\npropose a new family of topologies, EquiTopo, which has an (almost) constant\ndegree and a network-size-independent consensus rate that is used to measure\nthe mixing efficiency.\nIn the proposed family, EquiStatic has a degree of $\\Theta(\\ln(n))$, where\n$n$ is the network size, and a series of time-dependent one-peer topologies,\nEquiDyn, has a constant degree of 1. We generate EquiDyn through a certain\nrandom sampling procedure. Both of them achieve an $n$-independent consensus\nrate. We apply them to decentralized SGD and decentralized gradient tracking\nand obtain faster communication and better convergence, theoretically and\nempirically. Our code is implemented through BlueFog and available at\n\\url{https://github.com/kexinjinnn/EquiTopo}",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhuoqing Song",
      "Weijian Li",
      "Kexin Jin",
      "Lei Shi",
      "Ming Yan",
      "Wotao Yin",
      "Kun Yuan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07881"
  },
  {
    "id": "arXiv:2210.07893",
    "title": "Numerically Stable Sparse Gaussian Processes via Minimum Separation  using Cover Trees",
    "abstract": "As Gaussian processes mature, they are increasingly being deployed as part of\nlarger machine learning and decision-making systems, for instance in geospatial\nmodeling, Bayesian optimization, or in latent Gaussian models. Within a system,\nthe Gaussian process model needs to perform in a stable and reliable manner to\nensure it interacts correctly with other parts the system. In this work, we\nstudy the numerical stability of scalable sparse approximations based on\ninducing points. We derive sufficient and in certain cases necessary conditions\non the inducing points for the computations performed to be numerically stable.\nFor low-dimensional tasks such as geospatial modeling, we propose an automated\nmethod for computing inducing points satisfying these conditions. This is done\nvia a modification of the cover tree data structure, which is of independent\ninterest. We additionally propose an alternative sparse approximation for\nregression with a Gaussian likelihood which trades off a small amount of\nperformance to further improve stability. We evaluate the proposed techniques\non a number of examples, showing that, in geospatial settings, sparse\napproximations with guaranteed numerical stability often perform comparably to\nthose without.",
    "descriptor": "",
    "authors": [
      "Alexander Terenin",
      "David R. Burt",
      "Artem Artemev",
      "Seth Flaxman",
      "Mark van der Wilk",
      "Carl Edward Rasmussen",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07893"
  },
  {
    "id": "arXiv:2210.07929",
    "title": "Object Storage, Persistent Memory, and Data Infrastructure for HPC  Materials Informatics",
    "abstract": "Speculation is provided on how infrastructure choices fit into the materials\ndata ecosystem. Special attention is paid to object storage, the Intel DAOS\nAPI, storage-class memory (SCM), and the prospect of non-von Neumann computing.\nLastly, the hypothesized implications of data infrastructure choices on a\nsample materials informatics problem is discussed: computational materials\ndiscovery of phase-change materials with properties tailored for phase-change\nmemory (PCM). The motivation for selecting PCM as a sample materials\ninformatics case study comes from its relevance to emerging SCM hardware.",
    "descriptor": "\nComments: 27 pages, 51 figures\n",
    "authors": [
      "Stephanie R Taylor"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.07929"
  },
  {
    "id": "arXiv:2210.07930",
    "title": "Machine learning frontier orbital energies of nanodiamonds",
    "abstract": "Nanodiamonds have a wide range of applications including catalysis, sensing,\ntribology and biomedicine. To leverage nanodiamond design via machine learning,\nwe introduce the new dataset ND5k, consisting of 5,089 diamondoid and\nnanodiamond structures and their frontier orbital energies. ND5k structures are\noptimized via tight-binding density functional theory (DFTB) and their frontier\norbital energies are computed using density functional theory (DFT) with the\nPBE0 hybrid functional. We also compare recent machine learning models for\npredicting frontier orbital energies for similar structures as they have been\ntrained on (interpolation on ND5k), and we test their abilities to extrapolate\npredictions to larger structures. For both the interpolation and extrapolation\ntask, we find best performance using the equivariant graph neural network\nPaiNN. The second best results are achieved with a message passing neural\nnetwork using a tailored set of atomic descriptors proposed here.",
    "descriptor": "",
    "authors": [
      "Thorren Kirschbaum",
      "B\u00f6rries von Seggern",
      "Joachim Dzubiella",
      "Annika Bande",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07930"
  },
  {
    "id": "arXiv:2210.07931",
    "title": "Sequential Learning Of Neural Networks for Prequential MDL",
    "abstract": "Minimum Description Length (MDL) provides a framework and an objective for\nprincipled model evaluation. It formalizes Occam's Razor and can be applied to\ndata from non-stationary sources. In the prequential formulation of MDL, the\nobjective is to minimize the cumulative next-step log-loss when sequentially\ngoing through the data and using previous observations for parameter\nestimation. It thus closely resembles a continual- or online-learning problem.\nIn this study, we evaluate approaches for computing prequential description\nlengths for image classification datasets with neural networks. Considering the\ncomputational cost, we find that online-learning with rehearsal has favorable\nperformance compared to the previously widely used block-wise estimation. We\npropose forward-calibration to better align the models predictions with the\nempirical observations and introduce replay-streams, a minibatch incremental\ntraining technique to efficiently implement approximate random replay while\navoiding large in-memory replay buffers. As a result, we present description\nlengths for a suite of image classification datasets that improve upon\npreviously reported results by large margins.",
    "descriptor": "",
    "authors": [
      "Jorg Bornschein",
      "Yazhe Li",
      "Marcus Hutter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07931"
  },
  {
    "id": "arXiv:2210.07936",
    "title": "Data-Limited Tissue Segmentation using Inpainting-Based Self-Supervised  Learning",
    "abstract": "Although supervised learning has enabled high performance for image\nsegmentation, it requires a large amount of labeled training data, which can be\ndifficult to obtain in the medical imaging field. Self-supervised learning\n(SSL) methods involving pretext tasks have shown promise in overcoming this\nrequirement by first pretraining models using unlabeled data. In this work, we\nevaluate the efficacy of two SSL methods (inpainting-based pretext tasks of\ncontext prediction and context restoration) for CT and MRI image segmentation\nin label-limited scenarios, and investigate the effect of implementation design\nchoices for SSL on downstream segmentation performance. We demonstrate that\noptimally trained and easy-to-implement inpainting-based SSL segmentation\nmodels can outperform classically supervised methods for MRI and CT tissue\nsegmentation in label-limited scenarios, for both clinically-relevant metrics\nand the traditional Dice score.",
    "descriptor": "\nComments: Submitted to Radiology: Artificial Intelligence\n",
    "authors": [
      "Jeffrey Dominic",
      "Nandita Bhaskhar",
      "Arjun D. Desai",
      "Andrew Schmidt",
      "Elka Rubin",
      "Beliz Gunel",
      "Garry E. Gold",
      "Brian A. Hargreaves",
      "Leon Lenchik",
      "Robert Boutin",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07936"
  },
  {
    "id": "arXiv:2210.07976",
    "title": "Wide Range MRI Artifact Removal with Transformers",
    "abstract": "Artifacts on magnetic resonance scans are a serious challenge for both\nradiologists and computer-aided diagnosis systems. Most commonly, artifacts are\ncaused by motion of the patients, but can also arise from device-specific\nabnormalities such as noise patterns. Irrespective of the source, artifacts can\nnot only render a scan useless, but can potentially induce misdiagnoses if left\nunnoticed. For instance, an artifact may masquerade as a tumor or other\nabnormality. Retrospective artifact correction (RAC) is concerned with removing\nartifacts after the scan has already been taken. In this work, we propose a\nmethod capable of retrospectively removing eight common artifacts found in\nnative-resolution MR imagery. Knowledge of the presence or location of a\nspecific artifact is not assumed and the system is, by design, capable of\nundoing interactions of multiple artifacts. Our method is realized through the\ndesign of a novel volumetric transformer-based neural network that generalizes\na \\emph{window-centered} approach popularized by the Swin transformer. Unlike\nSwin, our method is (i) natively volumetric, (ii) geared towards dense\nprediction tasks instead of classification, and (iii), uses a novel and more\nglobal mechanism to enable information exchange between windows. Our\nexperiments show that our reconstructions are considerably better than those\nattained by ResNet, V-Net, MobileNet-v2, DenseNet, CycleGAN and BicycleGAN.\nMoreover, we show that the reconstructed images from our model improves the\naccuracy of FSL BET, a standard skull-stripping method typically applied in\ndiagnostic workflows.",
    "descriptor": "\nComments: BMVC22\n",
    "authors": [
      "Lennart Alexander Van der Goten",
      "Kevin Smith"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07976"
  },
  {
    "id": "arXiv:2210.07980",
    "title": "Representation Theory for Geometric Quantum Machine Learning",
    "abstract": "Recent advances in classical machine learning have shown that creating models\nwith inductive biases encoding the symmetries of a problem can greatly improve\nperformance. Importation of these ideas, combined with an existing rich body of\nwork at the nexus of quantum theory and symmetry, has given rise to the field\nof Geometric Quantum Machine Learning (GQML). Following the success of its\nclassical counterpart, it is reasonable to expect that GQML will play a crucial\nrole in developing problem-specific and quantum-aware models capable of\nachieving a computational advantage. Despite the simplicity of the main idea of\nGQML -- create architectures respecting the symmetries of the data -- its\npractical implementation requires a significant amount of knowledge of group\nrepresentation theory. We present an introduction to representation theory\ntools from the optics of quantum learning, driven by key examples involving\ndiscrete and continuous groups. These examples are sewn together by an\nexposition outlining the formal capture of GQML symmetries via \"label\ninvariance under the action of a group representation\", a brief (but rigorous)\ntour through finite and compact Lie group representation theory, a\nreexamination of ubiquitous tools like Haar integration and twirling, and an\noverview of some successful strategies for detecting symmetries.",
    "descriptor": "\nComments: 43 pages, 10 figures\n",
    "authors": [
      "Michael Ragone",
      "Paolo Braccia",
      "Quynh T. Nguyen",
      "Louis Schatzki",
      "Patrick J. Coles",
      "Frederic Sauvage",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07980"
  },
  {
    "id": "arXiv:2210.07992",
    "title": "A Variational Perspective on Generative Flow Networks",
    "abstract": "Generative flow networks (GFNs) are a class of models for sequential sampling\nof composite objects, which approximate a target distribution that is defined\nin terms of an energy function or a reward. GFNs are typically trained using a\nflow matching or trajectory balance objective, which matches forward and\nbackward transition models over trajectories. In this work, we define\nvariational objectives for GFNs in terms of the Kullback-Leibler (KL)\ndivergences between the forward and backward distribution. We show that\nvariational inference in GFNs is equivalent to minimizing the trajectory\nbalance objective when sampling trajectories from the forward model. We\ngeneralize this approach by optimizing a convex combination of the reverse- and\nforward KL divergence. This insight suggests variational inference methods can\nserve as a means to define a more general family of objectives for training\ngenerative flow networks, for example by incorporating control variates, which\nare commonly used in variational inference, to reduce the variance of the\ngradients of the trajectory balance objective. We evaluate our findings and the\nperformance of the proposed variational objective numerically by comparing it\nto the trajectory balance objective on two synthetic tasks.",
    "descriptor": "",
    "authors": [
      "Heiko Zimmermann",
      "Fredrik Lindsten",
      "Jan-Willem van de Meent",
      "Christian A. Naesseth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07992"
  },
  {
    "id": "arXiv:1709.03146",
    "title": "Stable super-resolution limit and smallest singular value of restricted  Fourier matrices",
    "abstract": "Comments: fixed some typos; 40 pages, 5 figures; Applied and Computational Harmonic Analysis 2021",
    "descriptor": "\nComments: fixed some typos; 40 pages, 5 figures; Applied and Computational Harmonic Analysis 2021\n",
    "authors": [
      "Weilin Li",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1709.03146"
  },
  {
    "id": "arXiv:1904.03015",
    "title": "A faster algorithm for the limited-capacity many-to-many point matching  in one dimension",
    "abstract": "Comments: 24 pages, 7 figures. arXiv admin note: text overlap with arXiv:1702.01083",
    "descriptor": "\nComments: 24 pages, 7 figures. arXiv admin note: text overlap with arXiv:1702.01083\n",
    "authors": [
      "Fatemeh Rajabi-Alni",
      "Alireza Bagheri"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1904.03015"
  },
  {
    "id": "arXiv:1904.03139",
    "title": "Parameter estimation for integer-valued Gibbs distributions",
    "abstract": "Comments: Superseded by arXiv:2007.10824",
    "descriptor": "\nComments: Superseded by arXiv:2007.10824\n",
    "authors": [
      "David G. Harris",
      "Vladimir Kolmogorov"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1904.03139"
  },
  {
    "id": "arXiv:1908.07414",
    "title": "Sarcasm Detection using Hybrid Neural Network",
    "abstract": "Sarcasm Detection using Hybrid Neural Network",
    "descriptor": "",
    "authors": [
      "Rishabh Misra",
      "Prahal Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.07414"
  },
  {
    "id": "arXiv:1910.02008",
    "title": "Nonasymptotic estimates for Stochastic Gradient Langevin Dynamics under  local conditions in nonconvex optimization",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Ying Zhang",
      "\u00d6mer Deniz Akyildiz",
      "Theodoros Damoulas",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.02008"
  },
  {
    "id": "arXiv:1911.04227",
    "title": "Cumulo: A Dataset for Learning Cloud Classes",
    "abstract": "Cumulo: A Dataset for Learning Cloud Classes",
    "descriptor": "",
    "authors": [
      "Valentina Zantedeschi",
      "Fabrizio Falasca",
      "Alyson Douglas",
      "Richard Strange",
      "Matt J. Kusner",
      "Duncan Watson-Parris"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.04227"
  },
  {
    "id": "arXiv:2001.01125",
    "title": "Discovering and Certifying Lower Bounds for the Online Bin Stretching  Problem",
    "abstract": "Discovering and Certifying Lower Bounds for the Online Bin Stretching  Problem",
    "descriptor": "",
    "authors": [
      "Martin B\u00f6hm",
      "Bertrand Simon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2001.01125"
  },
  {
    "id": "arXiv:2002.12251",
    "title": "The Complexity of Finding Tangles",
    "abstract": "Comments: Appears in the Proceedings of the 48th International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM 2023)",
    "descriptor": "\nComments: Appears in the Proceedings of the 48th International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM 2023)\n",
    "authors": [
      "Oksana Firman",
      "Philipp Kindermann",
      "Boris Klemz",
      "Alexander Ravsky",
      "Alexander Wolff",
      "Johannes Zink"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2002.12251"
  },
  {
    "id": "arXiv:2003.12659",
    "title": "Semiparametric Inference For Causal Effects In Graphical Models With  Hidden Variables",
    "abstract": "Comments: 76 pages",
    "descriptor": "\nComments: 76 pages\n",
    "authors": [
      "Rohit Bhattacharya",
      "Razieh Nabi",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.12659"
  },
  {
    "id": "arXiv:2101.01611",
    "title": "Look Twice: A Generalist Computational Model Predicts Return Fixations  across Tasks and Species",
    "abstract": "Comments: 9 main figs and 24 supp figs, accepted in PLOS Computational Biology",
    "descriptor": "\nComments: 9 main figs and 24 supp figs, accepted in PLOS Computational Biology\n",
    "authors": [
      "Mengmi Zhang",
      "Marcelo Armendariz",
      "Will Xiao",
      "Olivia Rose",
      "Katarina Bendtz",
      "Margaret Livingstone",
      "Carlos Ponce",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.01611"
  },
  {
    "id": "arXiv:2101.08732",
    "title": "Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning",
    "abstract": "Comments: Accepted at T-PAMI. Journal version of arXiv:2002.10319 [cs.LG] (NeurIPS2020). 22 pages, 15 figures, 13 tables",
    "descriptor": "\nComments: Accepted at T-PAMI. Journal version of arXiv:2002.10319 [cs.LG] (NeurIPS2020). 22 pages, 15 figures, 13 tables\n",
    "authors": [
      "Lang Huang",
      "Chao Zhang",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08732"
  },
  {
    "id": "arXiv:2102.04217",
    "title": "The Fault in the Stars: Understanding Underground Incentivized Review  Services",
    "abstract": "Comments: This work is in submission to USENIX 2023",
    "descriptor": "\nComments: This work is in submission to USENIX 2023\n",
    "authors": [
      "Rajvardhan Oak",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.04217"
  },
  {
    "id": "arXiv:2105.02322",
    "title": "Reconstructing shared dynamics with a deep neural network",
    "abstract": "Reconstructing shared dynamics with a deep neural network",
    "descriptor": "",
    "authors": [
      "Zsigmond Benk\u0151",
      "Zolt\u00e1n Somogyv\u00e1ri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.02322"
  },
  {
    "id": "arXiv:2105.02611",
    "title": "A Bit of Nondeterminism Makes Pushdown Automata Expressive and Succinct",
    "abstract": "A Bit of Nondeterminism Makes Pushdown Automata Expressive and Succinct",
    "descriptor": "",
    "authors": [
      "Shibashis Guha",
      "Isma\u00ebl Jecker",
      "Karoliina Lehtinen",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.02611"
  },
  {
    "id": "arXiv:2106.09245",
    "title": "An improved Material Mask Overlay Strategy for the desired discreteness  of pressure-loaded optimized topologies",
    "abstract": "Comments: 25 pages, 19 figures",
    "descriptor": "\nComments: 25 pages, 19 figures\n",
    "authors": [
      "Prabhat Kumar",
      "Anupam Saxena"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.09245"
  },
  {
    "id": "arXiv:2107.00462",
    "title": "Deep Hierarchical Super Resolution for Scientific Data",
    "abstract": "Comments: Accepted by IEEE Transactions on Visualization and Computer Graphics (TVCG) 2022",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Visualization and Computer Graphics (TVCG) 2022\n",
    "authors": [
      "Skylar W. Wurster",
      "Hanqi Guo",
      "Han-Wei Shen",
      "Thomas Peterka",
      "Jiayi Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00462"
  },
  {
    "id": "arXiv:2107.03032",
    "title": "A Review of Beamforming Technologies for Ultra-Massive MIMO in Terahertz  Communications",
    "abstract": "A Review of Beamforming Technologies for Ultra-Massive MIMO in Terahertz  Communications",
    "descriptor": "",
    "authors": [
      "Boyu Ning",
      "Zhongbao Tian",
      "Zhi Chen",
      "Chong Han",
      "Shaoqian Li",
      "Jinhong Yuan",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.03032"
  },
  {
    "id": "arXiv:2107.08392",
    "title": "Dynamic Convolution for 3D Point Cloud Instance Segmentation",
    "abstract": "Comments: Accepted to IEEE Trans. Pattern Analysis and Machine Intelligence. Extended version of arXiv:2011.13328",
    "descriptor": "\nComments: Accepted to IEEE Trans. Pattern Analysis and Machine Intelligence. Extended version of arXiv:2011.13328\n",
    "authors": [
      "Tong He",
      "Chunhua Shen",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08392"
  },
  {
    "id": "arXiv:2108.03362",
    "title": "On Measures of Biases and Harms in NLP",
    "abstract": "On Measures of Biases and Harms in NLP",
    "descriptor": "",
    "authors": [
      "Sunipa Dev",
      "Emily Sheng",
      "Jieyu Zhao",
      "Aubrie Amstutz",
      "Jiao Sun",
      "Yu Hou",
      "Mattie Sanseverino",
      "Jiin Kim",
      "Akihiro Nishi",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.03362"
  },
  {
    "id": "arXiv:2109.04286",
    "title": "NTS-NOTEARS: Learning Nonparametric DBNs With Prior Knowledge",
    "abstract": "NTS-NOTEARS: Learning Nonparametric DBNs With Prior Knowledge",
    "descriptor": "",
    "authors": [
      "Xiangyu Sun",
      "Oliver Schulte",
      "Guiliang Liu",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04286"
  },
  {
    "id": "arXiv:2109.07606",
    "title": "Graph skeletonization of high-dimensional point cloud data via  topological method",
    "abstract": "Graph skeletonization of high-dimensional point cloud data via  topological method",
    "descriptor": "",
    "authors": [
      "Lucas Magee",
      "Yusu Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.07606"
  },
  {
    "id": "arXiv:2110.04093",
    "title": "How to Do Things without Words: Modeling Semantic Drift of Emoji",
    "abstract": "Comments: To be published at EMNLP 2022",
    "descriptor": "\nComments: To be published at EMNLP 2022\n",
    "authors": [
      "Eyal Arviv",
      "Oren Tsur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04093"
  },
  {
    "id": "arXiv:2110.15108",
    "title": "Generalized Anomaly Detection",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Suresh Singh",
      "Minwei Luo",
      "Yu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15108"
  },
  {
    "id": "arXiv:2111.00539",
    "title": "Template Filling for Controllable Commonsense Reasoning",
    "abstract": "Template Filling for Controllable Commonsense Reasoning",
    "descriptor": "",
    "authors": [
      "Dheeraj Rajagopal",
      "Vivek Khetan",
      "Bogdan Sacaleanu",
      "Anatole Gershman",
      "Andrew Fano",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00539"
  },
  {
    "id": "arXiv:2111.02644",
    "title": "A Concentration Bound for LSPE($\u03bb$)",
    "abstract": "Comments: 18 pages, submitted to Elsevier System & Control Letters",
    "descriptor": "\nComments: 18 pages, submitted to Elsevier System & Control Letters\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S. Borkar",
      "Harsh Dolhare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02644"
  },
  {
    "id": "arXiv:2111.03117",
    "title": "Sound approximate and asymptotic probabilistic bisimulations for PCTL",
    "abstract": "Sound approximate and asymptotic probabilistic bisimulations for PCTL",
    "descriptor": "",
    "authors": [
      "Massimo Bartoletti",
      "Maurizio Murgia",
      "Roberto Zunino"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.03117"
  },
  {
    "id": "arXiv:2111.04658",
    "title": "Consistent Sufficient Explanations and Minimal Local Rules for  explaining regression and classification models",
    "abstract": "Comments: Accepted at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Salim I. Amoukou",
      "Nicolas J.B Brunel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04658"
  },
  {
    "id": "arXiv:2111.10899",
    "title": "Identification of Low Rank Vector Processes",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2012.05004",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.05004\n",
    "authors": [
      "Wenqi Cao",
      "Giorgio Picci",
      "Anders Lindquist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10899"
  },
  {
    "id": "arXiv:2112.00646",
    "title": "Reliability Assessment and Safety Arguments for Machine Learning  Components in System Assurance",
    "abstract": "Comments: Preprint Accepted by ACM Transactions on Embedded Computing Systems",
    "descriptor": "\nComments: Preprint Accepted by ACM Transactions on Embedded Computing Systems\n",
    "authors": [
      "Yi Dong",
      "Wei Huang",
      "Vibhav Bharti",
      "Victoria Cox",
      "Alec Banks",
      "Sen Wang",
      "Xingyu Zhao",
      "Sven Schewe",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00646"
  },
  {
    "id": "arXiv:2112.02624",
    "title": "Dynamic Token Normalization Improves Vision Transformers",
    "abstract": "Comments: Published at ICLR'22; 18 pages, 12 Tables, 9 Figures",
    "descriptor": "\nComments: Published at ICLR'22; 18 pages, 12 Tables, 9 Figures\n",
    "authors": [
      "Wenqi Shao",
      "Yixiao Ge",
      "Zhaoyang Zhang",
      "Xuyuan Xu",
      "Xiaogang Wang",
      "Ying Shan",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02624"
  },
  {
    "id": "arXiv:2112.07441",
    "title": "An Interpretive Constrained Linear Model for ResNet and MgNet",
    "abstract": "Comments: 29 pages, 2 figures and 11 tables. arXiv admin note: text overlap with arXiv:1911.10428",
    "descriptor": "\nComments: 29 pages, 2 figures and 11 tables. arXiv admin note: text overlap with arXiv:1911.10428\n",
    "authors": [
      "Juncai He",
      "Jinchao Xu",
      "Lian Zhang",
      "Jianqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07441"
  },
  {
    "id": "arXiv:2112.08125",
    "title": "Exponential Convergence of Deep Operator Networks for Elliptic Partial  Differential Equations",
    "abstract": "Exponential Convergence of Deep Operator Networks for Elliptic Partial  Differential Equations",
    "descriptor": "",
    "authors": [
      "Carlo Marcati",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08125"
  },
  {
    "id": "arXiv:2112.08884",
    "title": "Skeleton Abstraction for Universal Temporal Properties",
    "abstract": "Skeleton Abstraction for Universal Temporal Properties",
    "descriptor": "",
    "authors": [
      "Sophie Wallner",
      "Karsten Wolf"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08884"
  },
  {
    "id": "arXiv:2112.14382",
    "title": "Self-Supervised Robustifying Guidance for Monocular 3D Face  Reconstruction",
    "abstract": "Comments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022",
    "descriptor": "\nComments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Hitika Tiwari",
      "Min-Hung Chen",
      "Yi-Min Tsai",
      "Hsien-Kai Kuo",
      "Hung-Jen Chen",
      "Kevin Jou",
      "K. S. Venkatesh",
      "Yong-Sheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14382"
  },
  {
    "id": "arXiv:2201.01222",
    "title": "The cluster structure function",
    "abstract": "The cluster structure function",
    "descriptor": "",
    "authors": [
      "Andrew R. Cohen",
      "Paul M.B. Vit\u00e1nyi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.01222"
  },
  {
    "id": "arXiv:2201.03169",
    "title": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks",
    "abstract": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Zhenyuan Zhang",
      "Tao Shen",
      "Jie Zhang",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.03169"
  },
  {
    "id": "arXiv:2201.03522",
    "title": "When is Offline Two-Player Zero-Sum Markov Game Solvable?",
    "abstract": "Comments: 30 pages; accepted by NeurIPS 2022",
    "descriptor": "\nComments: 30 pages; accepted by NeurIPS 2022\n",
    "authors": [
      "Qiwen Cui",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.03522"
  },
  {
    "id": "arXiv:2201.05077",
    "title": "Black-box Safety Analysis and Retraining of DNNs based on Feature  Extraction and Clustering",
    "abstract": "Comments: 41 pages, 12 figures, 15 tables",
    "descriptor": "\nComments: 41 pages, 12 figures, 15 tables\n",
    "authors": [
      "Mohammed Oualid Attaoui",
      "Hazem Fahmy",
      "Fabrizio Pastore",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05077"
  },
  {
    "id": "arXiv:2201.05129",
    "title": "Rewriting with Acyclic Queries: Mind Your Head",
    "abstract": "Comments: submission for LMCS special issue",
    "descriptor": "\nComments: submission for LMCS special issue\n",
    "authors": [
      "Gaetano Geck",
      "Jens Keppeler",
      "Thomas Schwentick",
      "Christopher Spinrath"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.05129"
  },
  {
    "id": "arXiv:2201.05819",
    "title": "Interpretable and Effective Reinforcement Learning for Attacking against  Graph-based Rumor Detection",
    "abstract": "Interpretable and Effective Reinforcement Learning for Attacking against  Graph-based Rumor Detection",
    "descriptor": "",
    "authors": [
      "Yuefei Lyu",
      "Xiaoyu Yang",
      "Jiaxin Liu",
      "Philip S. Yu",
      "Sihong Xie",
      "Xi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.05819"
  },
  {
    "id": "arXiv:2201.12787",
    "title": "GRPE: Relative Positional Encoding for Graph Transformer",
    "abstract": "GRPE: Relative Positional Encoding for Graph Transformer",
    "descriptor": "",
    "authors": [
      "Wonpyo Park",
      "Woonggi Chang",
      "Donggeon Lee",
      "Juntae Kim",
      "Seung-won Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12787"
  },
  {
    "id": "arXiv:2201.12803",
    "title": "Similarity and Generalization: From Noise to Corruption",
    "abstract": "Comments: v2: references added, discussion extended, CIFAR10 experiments added, training evolution and learning rate comparison included in appendix, results unchanged",
    "descriptor": "\nComments: v2: references added, discussion extended, CIFAR10 experiments added, training evolution and learning rate comparison included in appendix, results unchanged\n",
    "authors": [
      "Nayara Fonseca",
      "Veronica Guidetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12803"
  },
  {
    "id": "arXiv:2201.13320",
    "title": "BEER: Fast $O(1/T)$ Rate for Decentralized Nonconvex Optimization with  Communication Compression",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Haoyu Zhao",
      "Boyue Li",
      "Zhize Li",
      "Peter Richt\u00e1rik",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13320"
  },
  {
    "id": "arXiv:2202.00348",
    "title": "Learning entanglement breakdown as a phase transition by confusion",
    "abstract": "Comments: 14 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 14 pages, 9 figures, 4 tables\n",
    "authors": [
      "M.A. Gavreev",
      "A.S. Mastiukova",
      "E.O. Kiktenko",
      "A.K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00348"
  },
  {
    "id": "arXiv:2202.01628",
    "title": "Feasible Wrench Set Computation for Legged Robots",
    "abstract": "Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Ander Vallinas Prieto",
      "Arvid Q.L. Keemink",
      "Edwin H.F. van Asseldonk",
      "Herman van der Kooij"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01628"
  },
  {
    "id": "arXiv:2202.04206",
    "title": "Covariate-informed Representation Learning to Prevent Posterior Collapse  of iVAE",
    "abstract": "Covariate-informed Representation Learning to Prevent Posterior Collapse  of iVAE",
    "descriptor": "",
    "authors": [
      "Young-geun Kim",
      "Ying Liu",
      "Xuexin Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04206"
  },
  {
    "id": "arXiv:2202.04487",
    "title": "Finding Optimal Arms in Non-stochastic Combinatorial Bandits with  Semi-bandit Feedback and Finite Budget",
    "abstract": "Finding Optimal Arms in Non-stochastic Combinatorial Bandits with  Semi-bandit Feedback and Finite Budget",
    "descriptor": "",
    "authors": [
      "Jasmin Brandt",
      "Viktor Bengs",
      "Bj\u00f6rn Haddenhorst",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04487"
  },
  {
    "id": "arXiv:2202.04798",
    "title": "Augmenting Neural Networks with Priors on Function Values",
    "abstract": "Augmenting Neural Networks with Priors on Function Values",
    "descriptor": "",
    "authors": [
      "Hunter Nisonoff",
      "Yixin Wang",
      "Jennifer Listgarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04798"
  },
  {
    "id": "arXiv:2202.07615",
    "title": "P4E: Few-Shot Event Detection as Prompt-Guided Identification and  Localization",
    "abstract": "Comments: 13 pages, updated baselines and additional experiments",
    "descriptor": "\nComments: 13 pages, updated baselines and additional experiments\n",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07615"
  },
  {
    "id": "arXiv:2202.09368",
    "title": "Mixture-of-Experts with Expert Choice Routing",
    "abstract": "Mixture-of-Experts with Expert Choice Routing",
    "descriptor": "",
    "authors": [
      "Yanqi Zhou",
      "Tao Lei",
      "Hanxiao Liu",
      "Nan Du",
      "Yanping Huang",
      "Vincent Zhao",
      "Andrew Dai",
      "Zhifeng Chen",
      "Quoc Le",
      "James Laudon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09368"
  },
  {
    "id": "arXiv:2202.10115",
    "title": "An Efficient Smoothing and Thresholding Image Segmentation Framework  with Weighted Anisotropic-Isotropic Total Variation",
    "abstract": "Comments: expanded numerical experiments",
    "descriptor": "\nComments: expanded numerical experiments\n",
    "authors": [
      "Kevin Bui",
      "Yifei Lou",
      "Fredrick Park",
      "Jack Xin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10115"
  },
  {
    "id": "arXiv:2202.11705",
    "title": "COLD Decoding: Energy-based Constrained Text Generation with Langevin  Dynamics",
    "abstract": "Comments: NeurIPS 2022. code: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. code: this https URL\n",
    "authors": [
      "Lianhui Qin",
      "Sean Welleck",
      "Daniel Khashabi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11705"
  },
  {
    "id": "arXiv:2203.00007",
    "title": "Spatial-Temporal Attention Fusion Network for short-term passenger flow  prediction on holidays in urban rail transit systems",
    "abstract": "Comments: 26 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 26 pages, 10 figures, 5 tables\n",
    "authors": [
      "Shuxin Zhang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Jiateng Yin",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00007"
  },
  {
    "id": "arXiv:2203.00241",
    "title": "Pond: CXL-Based Memory Pooling Systems for Cloud Platforms",
    "abstract": "Comments: Preprint for ASPLOS'23 Camera Ready",
    "descriptor": "\nComments: Preprint for ASPLOS'23 Camera Ready\n",
    "authors": [
      "Huaicheng Li",
      "Daniel S. Berger",
      "Stanko Novakovic",
      "Lisa Hsu",
      "Dan Ernst",
      "Pantea Zardoshti",
      "Monish Shah",
      "Samir Rajadnya",
      "Scott Lee",
      "Ishwar Agarwal",
      "Mark D. Hill",
      "Marcus Fontoura",
      "Ricardo Bianchini"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.00241"
  },
  {
    "id": "arXiv:2203.01161",
    "title": "Discrete Optimal Transport with Independent Marginals is #P-Hard",
    "abstract": "Discrete Optimal Transport with Independent Marginals is #P-Hard",
    "descriptor": "",
    "authors": [
      "Bahar Ta\u015fkesen",
      "Soroosh Shafieezadeh-Abadeh",
      "Daniel Kuhn",
      "Karthik Natarajan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01161"
  },
  {
    "id": "arXiv:2203.01681",
    "title": "Quantity over Quality: Training an AV Motion Planner with Large Scale  Commodity Vision Data",
    "abstract": "Quantity over Quality: Training an AV Motion Planner with Large Scale  Commodity Vision Data",
    "descriptor": "",
    "authors": [
      "Lukas Platinsky",
      "Tayyab Naseer",
      "Hui Chen",
      "Ben Haines",
      "Haoyue Zhu",
      "Hugo Grimmett",
      "Luca Del Pero"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01681"
  },
  {
    "id": "arXiv:2203.03885",
    "title": "Incentivizing Data Contribution in Cross-Silo Federated Learning",
    "abstract": "Incentivizing Data Contribution in Cross-Silo Federated Learning",
    "descriptor": "",
    "authors": [
      "Chao Huang",
      "Shuqi Ke",
      "Charles Kamhoua",
      "Prasant Mohapatra",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.03885"
  },
  {
    "id": "arXiv:2203.05483",
    "title": "projUNN: efficient method for training deep networks with unitary  matrices",
    "abstract": "projUNN: efficient method for training deep networks with unitary  matrices",
    "descriptor": "",
    "authors": [
      "Bobak Kiani",
      "Randall Balestriero",
      "Yann LeCun",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.05483"
  },
  {
    "id": "arXiv:2203.07648",
    "title": "Contrastive Learning of Sociopragmatic Meaning in Social Media",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07648"
  },
  {
    "id": "arXiv:2203.08299",
    "title": "FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric",
    "abstract": "Comments: 21 pages, 13 figures, 4 tables. code available at this https URL",
    "descriptor": "\nComments: 21 pages, 13 figures, 4 tables. code available at this https URL\n",
    "authors": [
      "Maximillian Chen",
      "Caitlyn Chen",
      "Xiao Yu",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08299"
  },
  {
    "id": "arXiv:2203.09065",
    "title": "STPLS3D: A Large-Scale Synthetic and Real Aerial Photogrammetry 3D Point  Cloud Dataset",
    "abstract": "STPLS3D: A Large-Scale Synthetic and Real Aerial Photogrammetry 3D Point  Cloud Dataset",
    "descriptor": "",
    "authors": [
      "Meida Chen",
      "Qingyong Hu",
      "Zifan Yu",
      "Hugues Thomas",
      "Andrew Feng",
      "Yu Hou",
      "Kyle McCullough",
      "Fengbo Ren",
      "Lucio Soibelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09065"
  },
  {
    "id": "arXiv:2203.10358",
    "title": "Multi-Domain Multi-Definition Landmark Localization for Small Datasets",
    "abstract": "Comments: European Conference on Computer Vision, 2022",
    "descriptor": "\nComments: European Conference on Computer Vision, 2022\n",
    "authors": [
      "David Ferman",
      "Gaurav Bharaj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10358"
  },
  {
    "id": "arXiv:2203.10363",
    "title": "Towards Device Efficient Conditional Image Generation",
    "abstract": "Comments: British Machine Vision Conference 2022",
    "descriptor": "\nComments: British Machine Vision Conference 2022\n",
    "authors": [
      "Nisarg A. Shah",
      "Gaurav Bharaj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.10363"
  },
  {
    "id": "arXiv:2203.10774",
    "title": "Fictitious Play with Maximin Initialization",
    "abstract": "Fictitious Play with Maximin Initialization",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.10774"
  },
  {
    "id": "arXiv:2203.12215",
    "title": "Physics-Driven Deep Learning for Computational Magnetic Resonance  Imaging",
    "abstract": "Comments: To appear in IEEE Signal Processing Magazine",
    "descriptor": "\nComments: To appear in IEEE Signal Processing Magazine\n",
    "authors": [
      "Kerstin Hammernik",
      "Thomas K\u00fcstner",
      "Burhaneddin Yaman",
      "Zhengnan Huang",
      "Daniel Rueckert",
      "Florian Knoll",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.12215"
  },
  {
    "id": "arXiv:2203.16915",
    "title": "A Dataset of Images of Public Streetlights with Operational Monitoring  using Computer Vision Techniques",
    "abstract": "Comments: Data in Brief Journal",
    "descriptor": "\nComments: Data in Brief Journal\n",
    "authors": [
      "Ioannis Mavromatis",
      "Aleksandar Stanoev",
      "Pietro Carnelli",
      "Yichao Jin",
      "Mahesh Sooriyabandara",
      "Aftab Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16915"
  },
  {
    "id": "arXiv:2204.05460",
    "title": "CorrectSpeech: A Fully Automated System for Speech Correction and Accent  Reduction",
    "abstract": "Comments: Accepted by ISCSLP 2022",
    "descriptor": "\nComments: Accepted by ISCSLP 2022\n",
    "authors": [
      "Daxin Tan",
      "Liqun Deng",
      "Nianzu Zheng",
      "Yu Ting Yeung",
      "Xin Jiang",
      "Xiao Chen",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.05460"
  },
  {
    "id": "arXiv:2204.06452",
    "title": "Building Markovian Generative Architectures over Pretrained LM Backbones  for Efficient Task-Oriented Dialog Systems",
    "abstract": "Comments: Accepted by SLT 2022",
    "descriptor": "\nComments: Accepted by SLT 2022\n",
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.06452"
  },
  {
    "id": "arXiv:2204.07537",
    "title": "Unconditional Image-Text Pair Generation with Multimodal Cross Quantizer",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Hyungyung Lee",
      "Sungjin Park",
      "Joonseok Lee",
      "Edward Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07537"
  },
  {
    "id": "arXiv:2204.08786",
    "title": "Decentralized non-convex optimization via bi-level SQP and ADMM",
    "abstract": "Decentralized non-convex optimization via bi-level SQP and ADMM",
    "descriptor": "",
    "authors": [
      "G\u00f6sta Stomberg",
      "Alexander Engelmann",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08786"
  },
  {
    "id": "arXiv:2204.14030",
    "title": "Neural Implicit Representations for Physical Parameter Inference from a  Single Video",
    "abstract": "Comments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Florian Hofherr",
      "Lukas Koestler",
      "Florian Bernard",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.14030"
  },
  {
    "id": "arXiv:2205.04009",
    "title": "Posterior Collapse of a Linear Latent Variable Model",
    "abstract": "Comments: NeurIPS 2022; 25 pages, 5 figures, 1 Table",
    "descriptor": "\nComments: NeurIPS 2022; 25 pages, 5 figures, 1 Table\n",
    "authors": [
      "Zihao Wang",
      "Liu Ziyin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.04009"
  },
  {
    "id": "arXiv:2205.05398",
    "title": "Scalable Stochastic Parametric Verification with Stochastic Variational  Smoothed Model Checking",
    "abstract": "Scalable Stochastic Parametric Verification with Stochastic Variational  Smoothed Model Checking",
    "descriptor": "",
    "authors": [
      "Luca Bortolussi",
      "Francesca Cairoli",
      "Ginevra Carbone",
      "Paolo Pulcini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05398"
  },
  {
    "id": "arXiv:2205.05570",
    "title": "Review on Panoramic Imaging and Its Applications in Scene Understanding",
    "abstract": "Comments: Accepted to IEEE Transactions on Instrumentation and Measurement. 34 pages, 15 figures, 420 references",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Instrumentation and Measurement. 34 pages, 15 figures, 420 references\n",
    "authors": [
      "Shaohua Gao",
      "Kailun Yang",
      "Hao Shi",
      "Kaiwei Wang",
      "Jian Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.05570"
  },
  {
    "id": "arXiv:2205.06262",
    "title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue",
    "abstract": "Comments: EMNLP 2022. benchmark available at this https URL",
    "descriptor": "\nComments: EMNLP 2022. benchmark available at this https URL\n",
    "authors": [
      "Alon Albalak",
      "Yi-Lin Tuan",
      "Pegah Jandaghi",
      "Connor Pryor",
      "Luke Yoffe",
      "Deepak Ramachandran",
      "Lise Getoor",
      "Jay Pujara",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.06262"
  },
  {
    "id": "arXiv:2205.07384",
    "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit  Composite Kernel",
    "abstract": "Comments: 21 pages, 12 figures, 3 tables, 2 algorithms, submitted to the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)",
    "descriptor": "\nComments: 21 pages, 12 figures, 3 tables, 2 algorithms, submitted to the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
    "authors": [
      "Ziyang Jiang",
      "Tongshu Zheng",
      "Yiling Liu",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07384"
  },
  {
    "id": "arXiv:2205.07475",
    "title": "Ergodic variational flows",
    "abstract": "Ergodic variational flows",
    "descriptor": "",
    "authors": [
      "Zuheng Xu",
      "Naitong Chen",
      "Trevor Campbell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.07475"
  },
  {
    "id": "arXiv:2205.07844",
    "title": "Guess What Moves: Unsupervised Video and Image Segmentation by  Anticipating Motion",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Subhabrata Choudhury",
      "Laurynas Karazija",
      "Iro Laina",
      "Andrea Vedaldi",
      "Christian Rupprecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07844"
  },
  {
    "id": "arXiv:2205.08356",
    "title": "DouFu: A Double Fusion Joint Learning Method For Driving Trajectory  Representation",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Han Wang",
      "Zhou Huang",
      "Xiao Zhou",
      "Ganmin Yin",
      "Yi Bao",
      "Yi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.08356"
  },
  {
    "id": "arXiv:2205.09067",
    "title": "Automatic Rule Induction for Interpretable Semi-Supervised Learning",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Reid Pryzant",
      "Ziyi Yang",
      "Yichong Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09067"
  },
  {
    "id": "arXiv:2205.09548",
    "title": "ODBO: Bayesian Optimization with Search Space Prescreening for Directed  Protein Evolution",
    "abstract": "Comments: 27 pages, 13 figures",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Lixue Cheng",
      "Ziyi Yang",
      "Benben Liao",
      "Changyu Hsieh",
      "Shengyu Zhang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.09548"
  },
  {
    "id": "arXiv:2205.09824",
    "title": "Deep Learning Methods for Proximal Inference via Maximum Moment  Restriction",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Benjamin Kompa",
      "David R. Bellamy",
      "Thomas Kolokotrones",
      "James M. Robins",
      "Andrew L. Beam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09824"
  },
  {
    "id": "arXiv:2205.10337",
    "title": "UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes",
    "abstract": "Comments: 22 pages. Accepted at NeurIPS 2022",
    "descriptor": "\nComments: 22 pages. Accepted at NeurIPS 2022\n",
    "authors": [
      "Alexander Kolesnikov",
      "Andr\u00e9 Susano Pinto",
      "Lucas Beyer",
      "Xiaohua Zhai",
      "Jeremiah Harmsen",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10337"
  },
  {
    "id": "arXiv:2205.10343",
    "title": "Towards Understanding Grokking: An Effective Theory of Representation  Learning",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Ziming Liu",
      "Ouail Kitouni",
      "Niklas Nolte",
      "Eric J. Michaud",
      "Max Tegmark",
      "Mike Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.10343"
  },
  {
    "id": "arXiv:2205.11200",
    "title": "BBTv2: Towards a Gradient-Free Future with Large Language Models",
    "abstract": "Comments: Accepted to EMNLP 2022 (main conference). Code is available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (main conference). Code is available at this https URL\n",
    "authors": [
      "Tianxiang Sun",
      "Zhengfu He",
      "Hong Qian",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11200"
  },
  {
    "id": "arXiv:2205.11443",
    "title": "Unsupervised Tokenization Learning",
    "abstract": "Comments: 16 pages, 9 figures; Paper accepted to the EMNLP 2022 conference",
    "descriptor": "\nComments: 16 pages, 9 figures; Paper accepted to the EMNLP 2022 conference\n",
    "authors": [
      "Anton Kolonin",
      "Vignav Ramesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.11443"
  },
  {
    "id": "arXiv:2205.11459",
    "title": "CELEST: Federated Learning for Globally Coordinated Threat Detection",
    "abstract": "CELEST: Federated Learning for Globally Coordinated Threat Detection",
    "descriptor": "",
    "authors": [
      "Talha Ongun",
      "Simona Boboila",
      "Alina Oprea",
      "Tina Eliassi-Rad",
      "Jason Hiser",
      "Jack Davidson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11459"
  },
  {
    "id": "arXiv:2205.12550",
    "title": "Recognition Models to Learn Dynamics from Partial Observations with  Neural ODEs",
    "abstract": "Recognition Models to Learn Dynamics from Partial Observations with  Neural ODEs",
    "descriptor": "",
    "authors": [
      "Mona Buisson-Fenet",
      "Valery Morgenthaler",
      "Sebastian Trimpe",
      "Florent Di Meglio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12550"
  },
  {
    "id": "arXiv:2205.12644",
    "title": "LingMess: Linguistically Informed Multi Expert Scorers for Coreference  Resolution",
    "abstract": "LingMess: Linguistically Informed Multi Expert Scorers for Coreference  Resolution",
    "descriptor": "",
    "authors": [
      "Shon Otmazgin",
      "Arie Cattan",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12644"
  },
  {
    "id": "arXiv:2205.13038",
    "title": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "abstract": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "descriptor": "",
    "authors": [
      "Yili Shen",
      "Xiao Liu",
      "Cheng-Wei Ju",
      "Jiaxu Yan",
      "Jun Yi",
      "Zhou Lin",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13038"
  },
  {
    "id": "arXiv:2205.13320",
    "title": "Towards Learning Universal Hyperparameter Optimizers with Transformers",
    "abstract": "Comments: Published as a conference paper in Neural Information Processing Systems (NeurIPS) 2022. Code can be found in this https URL and Google AI Blog can be found in this https URL",
    "descriptor": "\nComments: Published as a conference paper in Neural Information Processing Systems (NeurIPS) 2022. Code can be found in this https URL and Google AI Blog can be found in this https URL\n",
    "authors": [
      "Yutian Chen",
      "Xingyou Song",
      "Chansoo Lee",
      "Zi Wang",
      "Qiuyi Zhang",
      "David Dohan",
      "Kazuya Kawakami",
      "Greg Kochanski",
      "Arnaud Doucet",
      "Marc'aurelio Ranzato",
      "Sagi Perel",
      "Nando de Freitas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13320"
  },
  {
    "id": "arXiv:2205.13515",
    "title": "Green Hierarchical Vision Transformer for Masked Image Modeling",
    "abstract": "Comments: Accepted at NeurIPS 2022. 18 pages, 7 figures, 6 tables, and 3 algorithms",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. 18 pages, 7 figures, 6 tables, and 3 algorithms\n",
    "authors": [
      "Lang Huang",
      "Shan You",
      "Mingkai Zheng",
      "Fei Wang",
      "Chen Qian",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13515"
  },
  {
    "id": "arXiv:2205.13863",
    "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of  Expressive Power",
    "abstract": "Comments: 25 pages; to appear in NeurIPS 2022",
    "descriptor": "\nComments: 25 pages; to appear in NeurIPS 2022\n",
    "authors": [
      "Binghui Li",
      "Jikai Jin",
      "Han Zhong",
      "John E. Hopcroft",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13863"
  },
  {
    "id": "arXiv:2205.14401",
    "title": "Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud  Pre-training",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Renrui Zhang",
      "Ziyu Guo",
      "Rongyao Fang",
      "Bin Zhao",
      "Dong Wang",
      "Yu Qiao",
      "Hongsheng Li",
      "Peng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14401"
  },
  {
    "id": "arXiv:2205.14690",
    "title": "CoNT: Contrastive Neural Text Generation",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Chenxin An",
      "Jiangtao Feng",
      "Kai Lv",
      "Lingpeng Kong",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14690"
  },
  {
    "id": "arXiv:2205.14987",
    "title": "A Continuous Time Framework for Discrete Denoising Models",
    "abstract": "Comments: 44 pages, 15 figures; NeurIPS 2022",
    "descriptor": "\nComments: 44 pages, 15 figures; NeurIPS 2022\n",
    "authors": [
      "Andrew Campbell",
      "Joe Benton",
      "Valentin De Bortoli",
      "Tom Rainforth",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14987"
  },
  {
    "id": "arXiv:2205.15156",
    "title": "Towards Efficient 3D Object Detection with Knowledge Distillation",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jihan Yang",
      "Shaoshuai Shi",
      "Runyu Ding",
      "Zhe Wang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15156"
  },
  {
    "id": "arXiv:2205.15581",
    "title": "Comparing interpretation methods in mental state decoding analyses with  deep learning models",
    "abstract": "Comments: 27 pages, 5 main figures",
    "descriptor": "\nComments: 27 pages, 5 main figures\n",
    "authors": [
      "Armin W. Thomas",
      "Christopher R\u00e9",
      "Russell A. Poldrack"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15581"
  },
  {
    "id": "arXiv:2205.15809",
    "title": "Feature Learning in $L_{2}$-regularized DNNs: Attraction/Repulsion and  Sparsity",
    "abstract": "Feature Learning in $L_{2}$-regularized DNNs: Attraction/Repulsion and  Sparsity",
    "descriptor": "",
    "authors": [
      "Arthur Jacot",
      "Eugene Golikov",
      "Cl\u00e9ment Hongler",
      "Franck Gabriel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15809"
  },
  {
    "id": "arXiv:2206.00159",
    "title": "Provably Efficient Offline Multi-agent Reinforcement Learning via  Strategy-wise Bonus",
    "abstract": "Comments: 34 pages; accepted by NeurIPS 2022",
    "descriptor": "\nComments: 34 pages; accepted by NeurIPS 2022\n",
    "authors": [
      "Qiwen Cui",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.00159"
  },
  {
    "id": "arXiv:2206.00619",
    "title": "Graph Machine Learning for Design of High-Octane Fuels",
    "abstract": "Comments: manuscript (26 pages, 9 figures, 2 tables), supporting information (12 pages, 8 figures, 1 table)",
    "descriptor": "\nComments: manuscript (26 pages, 9 figures, 2 tables), supporting information (12 pages, 8 figures, 1 table)\n",
    "authors": [
      "Jan G. Rittig",
      "Martin Ritzert",
      "Artur M. Schweidtmann",
      "Stefanie Winkler",
      "Jana M. Weber",
      "Philipp Morsch",
      "K. Alexander Heufer",
      "Martin Grohe",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00619"
  },
  {
    "id": "arXiv:2206.00743",
    "title": "Nest Your Adaptive Algorithm for Parameter-Agnostic Nonconvex Minimax  Optimization",
    "abstract": "Comments: v2: fixed typos and improved Theorem 3.4",
    "descriptor": "\nComments: v2: fixed typos and improved Theorem 3.4\n",
    "authors": [
      "Junchi Yang",
      "Xiang Li",
      "Niao He"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00743"
  },
  {
    "id": "arXiv:2206.00927",
    "title": "DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling  in Around 10 Steps",
    "abstract": "Comments: Accepted in Neurips 2022",
    "descriptor": "\nComments: Accepted in Neurips 2022\n",
    "authors": [
      "Cheng Lu",
      "Yuhao Zhou",
      "Fan Bao",
      "Jianfei Chen",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00927"
  },
  {
    "id": "arXiv:2206.00975",
    "title": "A Fast Randomized Algorithm for computing the Null Space",
    "abstract": "Comments: 19 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 19 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yuji Nakatsukasa",
      "Taejun Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00975"
  },
  {
    "id": "arXiv:2206.01451",
    "title": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game",
    "abstract": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01451"
  },
  {
    "id": "arXiv:2206.01454",
    "title": "Indirect Active Learning",
    "abstract": "Indirect Active Learning",
    "descriptor": "",
    "authors": [
      "Shashank Singh"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01454"
  },
  {
    "id": "arXiv:2206.01649",
    "title": "Neural Differential Equations for Learning to Program Neural Nets  Through Continuous Learning Rules",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Kazuki Irie",
      "Francesco Faccio",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01649"
  },
  {
    "id": "arXiv:2206.01880",
    "title": "Learning in Congestion Games with Bandit Feedback",
    "abstract": "Comments: 34 pages, Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 34 pages, Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Qiwen Cui",
      "Zhihan Xiong",
      "Maryam Fazel",
      "Simon S. Du"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01880"
  },
  {
    "id": "arXiv:2206.02721",
    "title": "Revisiting Realistic Test-Time Training: Sequential Inference and  Adaptation by Anchored Clustering",
    "abstract": "Comments: NeurIPS 2022 accepted paper",
    "descriptor": "\nComments: NeurIPS 2022 accepted paper\n",
    "authors": [
      "Yongyi Su",
      "Xun Xu",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02721"
  },
  {
    "id": "arXiv:2206.02743",
    "title": "A Neural Corpus Indexer for Document Retrieval",
    "abstract": "Comments: 19 pages, 6 figures, accepted by NeurIPS 2022",
    "descriptor": "\nComments: 19 pages, 6 figures, accepted by NeurIPS 2022\n",
    "authors": [
      "Yujing Wang",
      "Yingyan Hou",
      "Haonan Wang",
      "Ziming Miao",
      "Shibin Wu",
      "Hao Sun",
      "Qi Chen",
      "Yuqing Xia",
      "Chengmin Chi",
      "Guoshuai Zhao",
      "Zheng Liu",
      "Xing Xie",
      "Hao Allen Sun",
      "Weiwei Deng",
      "Qi Zhang",
      "Mao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02743"
  },
  {
    "id": "arXiv:2206.02929",
    "title": "$\\mathcal{L}_2$-optimal Reduced-order Modeling Using Parameter-separable  Forms",
    "abstract": "Comments: 22 pages, 10 figures",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Petar Mlinari\u0107",
      "Serkan Gugercin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02929"
  },
  {
    "id": "arXiv:2206.03693",
    "title": "Autoregressive Perturbations for Data Poisoning",
    "abstract": "Comments: Accepted to NeurIPS 2022. Code available at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Code available at this https URL\n",
    "authors": [
      "Pedro Sandoval-Segura",
      "Vasu Singla",
      "Jonas Geiping",
      "Micah Goldblum",
      "Tom Goldstein",
      "David W. Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03693"
  },
  {
    "id": "arXiv:2206.03858",
    "title": "Rotation-Equivariant Conditional Spherical Neural Fields for Learning a  Natural Illumination Prior",
    "abstract": "Comments: NeurIPS 2022 - Project Website: jadgardner.github.io/RENI",
    "descriptor": "\nComments: NeurIPS 2022 - Project Website: jadgardner.github.io/RENI\n",
    "authors": [
      "James A. D. Gardner",
      "Bernhard Egger",
      "William A. P. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03858"
  },
  {
    "id": "arXiv:2206.04055",
    "title": "Gradient Obfuscation Gives a False Sense of Security in Federated  Learning",
    "abstract": "Comments: Accepted by USENIX Security 2023",
    "descriptor": "\nComments: Accepted by USENIX Security 2023\n",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Chau-Wai Wong",
      "Dror Baron",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04055"
  },
  {
    "id": "arXiv:2206.06295",
    "title": "Markov Chain Score Ascent: A Unifying Framework of Variational Inference  with Markovian Gradients",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Kyurae Kim",
      "Jisu Oh",
      "Jacob R. Gardner",
      "Adji Bousso Dieng",
      "Hongseok Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06295"
  },
  {
    "id": "arXiv:2206.07578",
    "title": "E2V-SDE: From Asynchronous Events to Fast and Continuous Video  Reconstruction via Neural Stochastic Differential Equations",
    "abstract": "Comments: arXiv admin note: This submission has been withdrawn by arXiv administrators due to inappropriate text overlap with external sources. Additional information at this https URL",
    "descriptor": "\nComments: arXiv admin note: This submission has been withdrawn by arXiv administrators due to inappropriate text overlap with external sources. Additional information at this https URL\n",
    "authors": [
      "Jongwan Kim",
      "DongJin Lee",
      "Byunggook Na",
      "Seongsik Park",
      "Jeonghee Jo",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.07578"
  },
  {
    "id": "arXiv:2206.07912",
    "title": "Double Sampling Randomized Smoothing",
    "abstract": "Comments: ICML 2022; minor typos fixed",
    "descriptor": "\nComments: ICML 2022; minor typos fixed\n",
    "authors": [
      "Linyi Li",
      "Jiawei Zhang",
      "Tao Xie",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.07912"
  },
  {
    "id": "arXiv:2206.08199",
    "title": "MAGIC: Microlensing Analysis Guided by Intelligent Computation",
    "abstract": "Comments: 23 pages, 19 figures, accepted version. Code available at this https URL . An earlier version of this work is accepted to the ICML 2022 Workshop on Machine Learning for Astrophysics at this https URL",
    "descriptor": "\nComments: 23 pages, 19 figures, accepted version. Code available at this https URL . An earlier version of this work is accepted to the ICML 2022 Workshop on Machine Learning for Astrophysics at this https URL\n",
    "authors": [
      "Haimeng Zhao",
      "Wei Zhu"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.08199"
  },
  {
    "id": "arXiv:2206.08321",
    "title": "Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for  End-to-End Visual Robotic Manipulation Learning",
    "abstract": "Comments: 30 pages, 10 figures, under review as a conference paper",
    "descriptor": "\nComments: 30 pages, 10 figures, under review as a conference paper\n",
    "authors": [
      "Hyunwoo Ryu",
      "Hong-in Lee",
      "Jeong-Hoon Lee",
      "Jongeun Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08321"
  },
  {
    "id": "arXiv:2206.09106",
    "title": "Embodied Scene-aware Human Pose Estimation",
    "abstract": "Comments: NeurIPS 2022. Project website: this https URL Zhengyi Luo and Shun Iwase contributed equally",
    "descriptor": "\nComments: NeurIPS 2022. Project website: this https URL Zhengyi Luo and Shun Iwase contributed equally\n",
    "authors": [
      "Zhengyi Luo",
      "Shun Iwase",
      "Ye Yuan",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09106"
  },
  {
    "id": "arXiv:2206.09144",
    "title": "Beyond Real-world Benchmark Datasets: An Empirical Study of Node  Classification with GNNs",
    "abstract": "Comments: Accepted to NeurIPS 2022 Datasets and Benchmarks Track. 20 pages, 15 figures",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Datasets and Benchmarks Track. 20 pages, 15 figures\n",
    "authors": [
      "Seiji Maekawa",
      "Koki Noda",
      "Yuya Sasaki",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09144"
  },
  {
    "id": "arXiv:2206.09642",
    "title": "Beyond IID: data-driven decision-making in heterogeneous environments",
    "abstract": "Beyond IID: data-driven decision-making in heterogeneous environments",
    "descriptor": "",
    "authors": [
      "Omar Besbes",
      "Will Ma",
      "Omar Mouchtaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09642"
  },
  {
    "id": "arXiv:2206.10075",
    "title": "Counting Varying Density Crowds Through Density Guided Adaptive  Selection CNN and Transformer Estimation",
    "abstract": "Counting Varying Density Crowds Through Density Guided Adaptive  Selection CNN and Transformer Estimation",
    "descriptor": "",
    "authors": [
      "Yuehai Chen",
      "Jing Yang",
      "Badong Chen",
      "Shaoyi Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10075"
  },
  {
    "id": "arXiv:2206.11140",
    "title": "Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries",
    "abstract": "Comments: NeurIPS 2022, Camera Ready; 48 pages, 7 figures",
    "descriptor": "\nComments: NeurIPS 2022, Camera Ready; 48 pages, 7 figures\n",
    "authors": [
      "Fabrizio Frasca",
      "Beatrice Bevilacqua",
      "Michael M. Bronstein",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11140"
  },
  {
    "id": "arXiv:2206.13673",
    "title": "How Many Events do You Need? Event-based Visual Place Recognition Using  Sparse But Varying Pixels",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Tobias Fischer",
      "Michael Milford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13673"
  },
  {
    "id": "arXiv:2206.13839",
    "title": "On the Calculation of the Variance of Algebraic Variables in Power  System Dynamic Models with Stochastic Processes",
    "abstract": "On the Calculation of the Variance of Algebraic Variables in Power  System Dynamic Models with Stochastic Processes",
    "descriptor": "",
    "authors": [
      "Muhammad Adeen",
      "Federico Bizzarri",
      "Davide del Giudice",
      "Samuele Grillo",
      "Daniele Linaro",
      "Angelo Brambilla",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13839"
  },
  {
    "id": "arXiv:2206.14331",
    "title": "Spherical Channels for Modeling Atomic Interactions",
    "abstract": "Comments: 19 pages, accepted NeurIPS 2022",
    "descriptor": "\nComments: 19 pages, accepted NeurIPS 2022\n",
    "authors": [
      "C. Lawrence Zitnick",
      "Abhishek Das",
      "Adeesh Kolluru",
      "Janice Lan",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Zachary Ulissi",
      "Brandon Wood"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.14331"
  },
  {
    "id": "arXiv:2206.15258",
    "title": "Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D  Camera",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Hongrui Cai",
      "Wanquan Feng",
      "Xuetao Feng",
      "Yan Wang",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.15258"
  },
  {
    "id": "arXiv:2207.01927",
    "title": "Drone Detection and Tracking in Real-Time by Fusion of Different Sensing  Modalities",
    "abstract": "Comments: Under consideration at Drones",
    "descriptor": "\nComments: Under consideration at Drones\n",
    "authors": [
      "Fredrik Svanstr\u00f6m",
      "Fernando Alonso-Fernandez",
      "Cristofer Englund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01927"
  },
  {
    "id": "arXiv:2207.02422",
    "title": "Adaptive Identification with Guaranteed Performance Under  Saturated-Observation and Non-Persistent Excitation",
    "abstract": "Comments: 11pages, 2 figures",
    "descriptor": "\nComments: 11pages, 2 figures\n",
    "authors": [
      "Lantian Zhang",
      "Lei Guo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.02422"
  },
  {
    "id": "arXiv:2207.02440",
    "title": "PAC Prediction Sets for Meta-Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Sangdon Park",
      "Edgar Dobriban",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.02440"
  },
  {
    "id": "arXiv:2207.03327",
    "title": "Exploring the sequence length bottleneck in the Transformer for Image  Captioning",
    "abstract": "Exploring the sequence length bottleneck in the Transformer for Image  Captioning",
    "descriptor": "",
    "authors": [
      "Jia Cheng Hu",
      "Roberto Cavicchioli",
      "Alessandro Capotondi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.03327"
  },
  {
    "id": "arXiv:2207.04397",
    "title": "2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds",
    "abstract": "Comments: ECCV2022",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Xu Yan",
      "Jiantao Gao",
      "Chaoda Zheng",
      "Chao Zheng",
      "Ruimao Zhang",
      "Shenghui Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04397"
  },
  {
    "id": "arXiv:2207.05736",
    "title": "Vision Transformer for NeRF-Based View Synthesis from a Single Input  Image",
    "abstract": "Comments: WACV 2023 Project website: this https URL",
    "descriptor": "\nComments: WACV 2023 Project website: this https URL\n",
    "authors": [
      "Kai-En Lin",
      "Lin Yen-Chen",
      "Wei-Sheng Lai",
      "Tsung-Yi Lin",
      "Yi-Chang Shih",
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.05736"
  },
  {
    "id": "arXiv:2207.06205",
    "title": "Trans4Map: Revisiting Holistic Bird's-Eye-View Mapping from Egocentric  Images to Allocentric Semantics with Vision Transformers",
    "abstract": "Comments: Accepted to WACV 2023. Code is publicly available at this https URL",
    "descriptor": "\nComments: Accepted to WACV 2023. Code is publicly available at this https URL\n",
    "authors": [
      "Chang Chen",
      "Jiaming Zhang",
      "Kailun Yang",
      "Kunyu Peng",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.06205"
  },
  {
    "id": "arXiv:2207.06635",
    "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "abstract": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "descriptor": "",
    "authors": [
      "Min Zhao",
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06635"
  },
  {
    "id": "arXiv:2207.06764",
    "title": "Finite strain porohyperelasticity: An asymptotic multiscale ALE-FSI  approach supported by ANNs",
    "abstract": "Finite strain porohyperelasticity: An asymptotic multiscale ALE-FSI  approach supported by ANNs",
    "descriptor": "",
    "authors": [
      "Hamidreza Dehghani",
      "Andreas Zilian"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2207.06764"
  },
  {
    "id": "arXiv:2207.06950",
    "title": "Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA  Models",
    "abstract": "Comments: 25 pages plus appendix",
    "descriptor": "\nComments: 25 pages plus appendix\n",
    "authors": [
      "Linwei Hu",
      "Jie Chen",
      "Vijayan N. Nair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06950"
  },
  {
    "id": "arXiv:2207.08275",
    "title": "Inverse Matrix Games with Unique Quantal Response Equilibrium",
    "abstract": "Inverse Matrix Games with Unique Quantal Response Equilibrium",
    "descriptor": "",
    "authors": [
      "Yue Yu",
      "Jonathan Salfity",
      "David Fridovich-Keil",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.08275"
  },
  {
    "id": "arXiv:2207.08803",
    "title": "Adversarial Pixel Restoration as a Pretext Task for Transferable  Perturbations",
    "abstract": "Comments: Accepted at BMVC'22 (Oral)",
    "descriptor": "\nComments: Accepted at BMVC'22 (Oral)\n",
    "authors": [
      "Hashmat Shadab Malik",
      "Shahina K Kunhimon",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08803"
  },
  {
    "id": "arXiv:2207.09397",
    "title": "Composition Theorems for Interactive Differential Privacy",
    "abstract": "Comments: To appear in NeurIPS 2022; Revised according to reviewers' feedback; Mentioned a concurrent and independent work",
    "descriptor": "\nComments: To appear in NeurIPS 2022; Revised according to reviewers' feedback; Mentioned a concurrent and independent work\n",
    "authors": [
      "Xin Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.09397"
  },
  {
    "id": "arXiv:2207.09944",
    "title": "Probable Domain Generalization via Quantile Risk Minimization",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Cian Eastwood",
      "Alexander Robey",
      "Shashank Singh",
      "Julius von K\u00fcgelgen",
      "Hamed Hassani",
      "George J. Pappas",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09944"
  },
  {
    "id": "arXiv:2208.01215",
    "title": "PAN: Pulse Ansatz on NISQ Machines",
    "abstract": "Comments: 13 pages, 13 figures",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Zhiding Liang",
      "Jinglei Cheng",
      "Hang Ren",
      "Hanrui Wang",
      "Fei Hua",
      "Yongshan Ding",
      "Fred Chong",
      "Song Han",
      "Yiyu Shi",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01215"
  },
  {
    "id": "arXiv:2208.01695",
    "title": "PolarFly: A Cost-Effective and Flexible Low-Diameter Topology",
    "abstract": "Comments: To appear at The International Conference for High Performance Computing, Networking, Storage, and Analysis (SC) 2022",
    "descriptor": "\nComments: To appear at The International Conference for High Performance Computing, Networking, Storage, and Analysis (SC) 2022\n",
    "authors": [
      "Kartik Lakhotia",
      "Maciej Besta",
      "Laura Monroe",
      "Kelly Isham",
      "Patrick Iff",
      "Torsten Hoefler",
      "Fabrizio Petrini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.01695"
  },
  {
    "id": "arXiv:2208.02836",
    "title": "Modeling community standards for metadata as templates makes data FAIR",
    "abstract": "Comments: 20 pages, 1 table, 5 figures",
    "descriptor": "\nComments: 20 pages, 1 table, 5 figures\n",
    "authors": [
      "Mark A. Musen",
      "Martin J. O'Connor",
      "Erik Schultes",
      "Marcos Martinez-Romero",
      "Josef Hardi",
      "John Graybeal"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2208.02836"
  },
  {
    "id": "arXiv:2208.03113",
    "title": "On the non-universality of deep learning: quantifying the cost of  symmetry",
    "abstract": "Comments: Improved exposition, to appear in NeurIPS'22",
    "descriptor": "\nComments: Improved exposition, to appear in NeurIPS'22\n",
    "authors": [
      "Emmanuel Abbe",
      "Enric Boix-Adsera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03113"
  },
  {
    "id": "arXiv:2208.03491",
    "title": "Parameterized Algorithms for Locally Minimal Defensive Alliance",
    "abstract": "Parameterized Algorithms for Locally Minimal Defensive Alliance",
    "descriptor": "",
    "authors": [
      "Ajinkya Gaikwad",
      "Soumen Maity",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.03491"
  },
  {
    "id": "arXiv:2208.05516",
    "title": "Quality Not Quantity: On the Interaction between Dataset Design and  Robustness of CLIP",
    "abstract": "Comments: Added GitHub link",
    "descriptor": "\nComments: Added GitHub link\n",
    "authors": [
      "Thao Nguyen",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Sewoong Oh",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05516"
  },
  {
    "id": "arXiv:2208.06287",
    "title": "Towards 6G-V2X: Aggregated RF-VLC for Ultra-Reliable and Low-Latency  Autonomous Driving Under Meteorological Impact",
    "abstract": "Towards 6G-V2X: Aggregated RF-VLC for Ultra-Reliable and Low-Latency  Autonomous Driving Under Meteorological Impact",
    "descriptor": "",
    "authors": [
      "Gurinder Singh",
      "Anand Srivastava",
      "Vivek Ashok Bohara",
      "Md Noor-A-Rahim",
      "Zilong Liu",
      "Dirk Pesch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.06287"
  },
  {
    "id": "arXiv:2208.07204",
    "title": "USB: A Unified Semi-supervised Learning Benchmark for Classification",
    "abstract": "Comments: Accepted by NeurIPS'22 dataset and benchmark track; code at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS'22 dataset and benchmark track; code at this https URL\n",
    "authors": [
      "Yidong Wang",
      "Hao Chen",
      "Yue Fan",
      "Wang Sun",
      "Ran Tao",
      "Wenxin Hou",
      "Renjie Wang",
      "Linyi Yang",
      "Zhi Zhou",
      "Lan-Zhe Guo",
      "Heli Qi",
      "Zhen Wu",
      "Yu-Feng Li",
      "Satoshi Nakamura",
      "Wei Ye",
      "Marios Savvides",
      "Bhiksha Raj",
      "Takahiro Shinozaki",
      "Bernt Schiele",
      "Jindong Wang",
      "Xing Xie",
      "Yue Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07204"
  },
  {
    "id": "arXiv:2208.07968",
    "title": "Blind Users Accessing Their Training Images in Teachable Object  Recognizers",
    "abstract": "Blind Users Accessing Their Training Images in Teachable Object  Recognizers",
    "descriptor": "",
    "authors": [
      "Jonggi Hong",
      "Jaina Gandhi",
      "Ernest Essuah Mensah",
      "Farnaz Zamiri Zeraati",
      "Ebrima Haddy Jarjue",
      "Kyungjun Lee",
      "Hernisa Kacorri"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07968"
  },
  {
    "id": "arXiv:2208.08165",
    "title": "Towards Open-vocabulary Scene Graph Generation with Prompt-based  Finetuning",
    "abstract": "Towards Open-vocabulary Scene Graph Generation with Prompt-based  Finetuning",
    "descriptor": "",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08165"
  },
  {
    "id": "arXiv:2208.08561",
    "title": "Geometric Scattering on Measure Spaces",
    "abstract": "Geometric Scattering on Measure Spaces",
    "descriptor": "",
    "authors": [
      "Joyce Chew",
      "Matthew Hirn",
      "Smita Krishnaswamy",
      "Deanna Needell",
      "Michael Perlmutter",
      "Holly Steach",
      "Siddharth Viswanath",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08561"
  },
  {
    "id": "arXiv:2208.11299",
    "title": "Spectral Telescope: Convergence Rate Bounds for Random-Scan Gibbs  Samplers Based on a Hierarchical Structure",
    "abstract": "Spectral Telescope: Convergence Rate Bounds for Random-Scan Gibbs  Samplers Based on a Hierarchical Structure",
    "descriptor": "",
    "authors": [
      "Qian Qin",
      "Guanyang Wang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.11299"
  },
  {
    "id": "arXiv:2208.12814",
    "title": "Interpretable (not just posthoc-explainable) medical claims modeling for  discharge placement to prevent avoidable all-cause readmissions or death",
    "abstract": "Comments: In review",
    "descriptor": "\nComments: In review\n",
    "authors": [
      "Joshua C. Chang",
      "Ted L. Chang",
      "Carson C. Chow",
      "Rohit Mahajan",
      "Sonya Mahajan",
      "Joe Maisog",
      "Shashaank Vattikuti",
      "Hongjing Xia"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2208.12814"
  },
  {
    "id": "arXiv:2208.13364",
    "title": "Improving the Efficiency of OpenCL Kernels through Pipes",
    "abstract": "Improving the Efficiency of OpenCL Kernels through Pipes",
    "descriptor": "",
    "authors": [
      "Mostafa Eghbali Zarch",
      "Michela Becchi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.13364"
  },
  {
    "id": "arXiv:2208.14590",
    "title": "Multitask kernel-learning parameter prediction method for solving  time-dependent linear systems",
    "abstract": "Multitask kernel-learning parameter prediction method for solving  time-dependent linear systems",
    "descriptor": "",
    "authors": [
      "Kai Jiang",
      "Juan Zhang",
      "Qi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.14590"
  },
  {
    "id": "arXiv:2209.00343",
    "title": "B\u00e9zier Gaussian Processes for Tall and Wide Data",
    "abstract": "B\u00e9zier Gaussian Processes for Tall and Wide Data",
    "descriptor": "",
    "authors": [
      "Martin J\u00f8rgensen",
      "Michael A. Osborne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.00343"
  },
  {
    "id": "arXiv:2209.01112",
    "title": "AutoPET Challenge: Combining nn-Unet with Swin UNETR Augmented by  Maximum Intensity Projection Classifier",
    "abstract": "Comments: 11 pages, 2 figures",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Lars Heiliger",
      "Zdravko Marinov",
      "Max Hasin",
      "Andr\u00e9 Ferreira",
      "Jana Fragemann",
      "Kelsey Pomykala",
      "Jacob Murray",
      "David Kersting",
      "Victor Alves",
      "Rainer Stiefelhagen",
      "Jan Egger",
      "Jens Kleesiek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.01112"
  },
  {
    "id": "arXiv:2209.01126",
    "title": "MaxWeight With Discounted UCB: A Provably Stable Scheduling Policy for  Nonstationary Multi-Server Systems With Unknown Statistics",
    "abstract": "MaxWeight With Discounted UCB: A Provably Stable Scheduling Policy for  Nonstationary Multi-Server Systems With Unknown Statistics",
    "descriptor": "",
    "authors": [
      "Zixian Yang",
      "R. Srikant",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.01126"
  },
  {
    "id": "arXiv:2209.01825",
    "title": "Detecting Unjustified Assumptions in Subclasses via Elegant Objects  Representation",
    "abstract": "Detecting Unjustified Assumptions in Subclasses via Elegant Objects  Representation",
    "descriptor": "",
    "authors": [
      "Vitaliy Korbashov",
      "Nikolai Kudasov",
      "Mikhail Olokin",
      "Violetta Sim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.01825"
  },
  {
    "id": "arXiv:2209.03665",
    "title": "Generalized One-shot Domain Adaptation of Generative Adversarial  Networks",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zicheng Zhang",
      "Yinglu Liu",
      "Congying Han",
      "Tiande Guo",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03665"
  },
  {
    "id": "arXiv:2209.07238",
    "title": "Generalization Properties of NAS under Activation and Skip Connection  Search",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07238"
  },
  {
    "id": "arXiv:2209.07263",
    "title": "Robustness in deep learning: The good (width), the bad (depth), and the  ugly (initialization)",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07263"
  },
  {
    "id": "arXiv:2209.07533",
    "title": "Not As Easy As You Think -- Experiences and Lessons Learnt from Trying  to Create a Bottom-Up Visualization Image Typology",
    "abstract": "Not As Easy As You Think -- Experiences and Lessons Learnt from Trying  to Create a Bottom-Up Visualization Image Typology",
    "descriptor": "",
    "authors": [
      "Jian Chen",
      "Petra Isenberg",
      "Robert S. Laramee",
      "Tobias Isenberg",
      "Michael Sedlmair",
      "Torsten Moeller",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.07533"
  },
  {
    "id": "arXiv:2209.08183",
    "title": "Optimal Scaling for Locally Balanced Proposals in Discrete Spaces",
    "abstract": "Optimal Scaling for Locally Balanced Proposals in Discrete Spaces",
    "descriptor": "",
    "authors": [
      "Haoran Sun",
      "Hanjun Dai",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08183"
  },
  {
    "id": "arXiv:2209.08769",
    "title": "Walk-and-Relate: A Random-Walk-based Algorithm for Representation  Learning on Sparse Knowledge Graphs",
    "abstract": "Walk-and-Relate: A Random-Walk-based Algorithm for Representation  Learning on Sparse Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Saurav Manchanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.08769"
  },
  {
    "id": "arXiv:2209.09004",
    "title": "EcoFormer: Energy-Saving Attention with Linear Complexity",
    "abstract": "Comments: NeurIPS 2022 camera ready; First two authors contributed equally",
    "descriptor": "\nComments: NeurIPS 2022 camera ready; First two authors contributed equally\n",
    "authors": [
      "Jing Liu",
      "Zizheng Pan",
      "Haoyu He",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.09004"
  },
  {
    "id": "arXiv:2209.09070",
    "title": "SOCRATES: A Stereo Camera Trap for Monitoring of Biodiversity",
    "abstract": "SOCRATES: A Stereo Camera Trap for Monitoring of Biodiversity",
    "descriptor": "",
    "authors": [
      "Timm Haucke",
      "Hjalmar S. K\u00fchl",
      "Volker Steinhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.09070"
  },
  {
    "id": "arXiv:2209.09478",
    "title": "Guiding vector fields for the distributed motion coordination of mobile  robots",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2103.12372",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.12372\n",
    "authors": [
      "Weijia Yao",
      "Hector Garcia de Marina",
      "Zhiyong Sun",
      "Ming Cao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.09478"
  },
  {
    "id": "arXiv:2209.09646",
    "title": "Active Particle Filter Networks: Efficient Active Localization in  Continuous Action Spaces and Large Maps",
    "abstract": "Active Particle Filter Networks: Efficient Active Localization in  Continuous Action Spaces and Large Maps",
    "descriptor": "",
    "authors": [
      "Daniel Honerkamp",
      "Suresh Guttikonda",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.09646"
  },
  {
    "id": "arXiv:2209.10267",
    "title": "Clustering Without Knowing How To: Application and Evaluation",
    "abstract": "Comments: accepted at HCOMP 2022 Works-in-Progress and Demonstration Track",
    "descriptor": "\nComments: accepted at HCOMP 2022 Works-in-Progress and Demonstration Track\n",
    "authors": [
      "Daniil Likhobaba",
      "Daniil Fedulov",
      "Dmitry Ustalov"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.10267"
  },
  {
    "id": "arXiv:2209.11178",
    "title": "Poisson Flow Generative Models",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yilun Xu",
      "Ziming Liu",
      "Max Tegmark",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11178"
  },
  {
    "id": "arXiv:2209.12519",
    "title": "On the Parameterized Intractability of Determinant Maximization",
    "abstract": "Comments: 30 pages. Accepted to the 33rd International Symposium on Algorithms and Computation (ISAAC 2022). Added the references due to Al-Thani and Lee",
    "descriptor": "\nComments: 30 pages. Accepted to the 33rd International Symposium on Algorithms and Computation (ISAAC 2022). Added the references due to Al-Thani and Lee\n",
    "authors": [
      "Naoto Ohsaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.12519"
  },
  {
    "id": "arXiv:2209.13325",
    "title": "Outlier Suppression: Pushing the Limit of Low-bit Transformer Language  Models",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Xiuying Wei",
      "Yunchen Zhang",
      "Xiangguo Zhang",
      "Ruihao Gong",
      "Shanghang Zhang",
      "Qi Zhang",
      "Fengwei Yu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13325"
  },
  {
    "id": "arXiv:2209.14086",
    "title": "Momentum Gradient Descent Federated Learning with Local Differential  Privacy",
    "abstract": "Comments: There is a crucial definition error of local differential privacy",
    "descriptor": "\nComments: There is a crucial definition error of local differential privacy\n",
    "authors": [
      "Mengde Han",
      "Tianqing Zhu",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14086"
  },
  {
    "id": "arXiv:2209.14878",
    "title": "Enumerating Regular Languages in Constant Delay",
    "abstract": "Comments: 46 pages. Submitted",
    "descriptor": "\nComments: 46 pages. Submitted\n",
    "authors": [
      "Antoine Amarilli",
      "Mika\u00ebl Monet"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.14878"
  },
  {
    "id": "arXiv:2209.15055",
    "title": "Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear  Functions",
    "abstract": "Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear  Functions",
    "descriptor": "",
    "authors": [
      "Arthur Jacot"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15055"
  },
  {
    "id": "arXiv:2210.00392",
    "title": "Physical computation and compositionality",
    "abstract": "Physical computation and compositionality",
    "descriptor": "",
    "authors": [
      "Nima Dehghani",
      "Gianluca Caterina"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computational Physics (physics.comp-ph)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.00392"
  },
  {
    "id": "arXiv:2210.00563",
    "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social  Science",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Julia Balla",
      "Sihao Huang",
      "Owen Dugan",
      "Rumen Dangovski",
      "Marin Soljacic"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2210.00563"
  },
  {
    "id": "arXiv:2210.00752",
    "title": "From Face to Natural Image: Learning Real Degradation for Blind Image  Super-Resolution",
    "abstract": "Comments: In ECCV 2022. Code is available at this https URL",
    "descriptor": "\nComments: In ECCV 2022. Code is available at this https URL\n",
    "authors": [
      "Xiaoming Li",
      "Chaofeng Chen",
      "Xianhui Lin",
      "Wangmeng Zuo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00752"
  },
  {
    "id": "arXiv:2210.00901",
    "title": "On the Salient Limitations of the Methods of Assembly Theory and their  Classification of Molecular Biosignatures",
    "abstract": "Comments: 32 pages with the appendix, 3 figures",
    "descriptor": "\nComments: 32 pages with the appendix, 3 figures\n",
    "authors": [
      "Abicumaran Uthamacumaran",
      "Felipe S. Abrah\u00e3o",
      "Narsis A. Kiani",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00901"
  },
  {
    "id": "arXiv:2210.01078",
    "title": "Unsupervised Model Selection for Time-series Anomaly Detection",
    "abstract": "Comments: Updated affiliations. Under review",
    "descriptor": "\nComments: Updated affiliations. Under review\n",
    "authors": [
      "Mononito Goswami",
      "Cristian Challu",
      "Laurent Callot",
      "Lenon Minorics",
      "Andrey Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01078"
  },
  {
    "id": "arXiv:2210.01642",
    "title": "Opinion-Driven Robot Navigation: Human-Robot Corridor Passing",
    "abstract": "Comments: 7 pages, 6 figures; typos corrected",
    "descriptor": "\nComments: 7 pages, 6 figures; typos corrected\n",
    "authors": [
      "Charlotte Cathcart",
      "Mar\u00eda Santos",
      "Shinkyu Park",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01642"
  },
  {
    "id": "arXiv:2210.01963",
    "title": "COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge  and Inheritance in Pre-trained Language Models",
    "abstract": "Comments: WIP to be submitted to [REDACTED]; now also contains Acknowledgments",
    "descriptor": "\nComments: WIP to be submitted to [REDACTED]; now also contains Acknowledgments\n",
    "authors": [
      "Kanishka Misra",
      "Julia Taylor Rayz",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01963"
  },
  {
    "id": "arXiv:2210.02015",
    "title": "Conformalized Fairness via Quantile Regression",
    "abstract": "Comments: 18 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 18 pages, 5 figures, 2 tables\n",
    "authors": [
      "Meichen Liu",
      "Lei Ding",
      "Dengdeng Yu",
      "Wulong Liu",
      "Linglong Kong",
      "Bei Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02015"
  },
  {
    "id": "arXiv:2210.02523",
    "title": "Dual-Domain Cross-Iteration Squeeze-Excitation Network for Sparse  Reconstruction of Brain MRI",
    "abstract": "Comments: 4 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 4 pages, 5 figures, 2 tables\n",
    "authors": [
      "Xiongchao Chen",
      "Yoshihisa Shinagawa",
      "Zhigang Peng",
      "Gerardo Hermosillo Valadez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02523"
  },
  {
    "id": "arXiv:2210.03166",
    "title": "The Power of Greedy for Online Minimum Cost Matching on the Line",
    "abstract": "The Power of Greedy for Online Minimum Cost Matching on the Line",
    "descriptor": "",
    "authors": [
      "Eric Balkanski",
      "Yuri Faenza",
      "Noemie Perivier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03166"
  },
  {
    "id": "arXiv:2210.03256",
    "title": "Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal  Negation",
    "abstract": "Comments: AACL-ICJNLP 2022",
    "descriptor": "\nComments: AACL-ICJNLP 2022\n",
    "authors": [
      "Thinh Hung Truong",
      "Yulia Otmakhova",
      "Timothy Baldwin",
      "Trevor Cohn",
      "Jey Han Lau",
      "Karin Verspoor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03256"
  },
  {
    "id": "arXiv:2210.03372",
    "title": "Pre-trained Adversarial Perturbations",
    "abstract": "Pre-trained Adversarial Perturbations",
    "descriptor": "",
    "authors": [
      "Yuanhao Ban",
      "Yinpeng Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03372"
  },
  {
    "id": "arXiv:2210.03662",
    "title": "GoalsEye: Learning High Speed Precision Table Tennis on a Physical Robot",
    "abstract": "GoalsEye: Learning High Speed Precision Table Tennis on a Physical Robot",
    "descriptor": "",
    "authors": [
      "Tianli Ding",
      "Laura Graesser",
      "Saminda Abeyruwan",
      "David B. D'Ambrosio",
      "Anish Shankar",
      "Pierre Sermanet",
      "Pannag R. Sanketi",
      "Corey Lynch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03662"
  },
  {
    "id": "arXiv:2210.03956",
    "title": "Robust Graph Structure Learning over Images via Multiple Statistical  Tests",
    "abstract": "Comments: Accepted by the NeurIPS 2022. Homepage: this https URL",
    "descriptor": "\nComments: Accepted by the NeurIPS 2022. Homepage: this https URL\n",
    "authors": [
      "Yaohua Wang",
      "FangYi Zhang",
      "Ming Lin",
      "Senzhang Wang",
      "Xiuyu Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03956"
  },
  {
    "id": "arXiv:2210.04556",
    "title": "Common Randomness Generation from Sources with Countable Alphabet",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2201.11078",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.11078\n",
    "authors": [
      "Wafa Labidi",
      "Rami Ezzine",
      "Christian Deppe",
      "Moritz Wiese",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04556"
  },
  {
    "id": "arXiv:2210.04695",
    "title": "Language Models Are Poor Learners of Directional Inference",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tianyi Li",
      "Mohammad Javad Hosseini",
      "Sabine Weber",
      "Mark Steedman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04695"
  },
  {
    "id": "arXiv:2210.04714",
    "title": "Uncertainty Quantification with Pre-trained Language Models: A  Large-Scale Empirical Analysis",
    "abstract": "Comments: Accepted by EMNLP 2022 (Findings)",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (Findings)\n",
    "authors": [
      "Yuxin Xiao",
      "Paul Pu Liang",
      "Umang Bhatt",
      "Willie Neiswanger",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04714"
  },
  {
    "id": "arXiv:2210.04868",
    "title": "Deep object detection for waterbird monitoring using aerial imagery",
    "abstract": "Comments: Longer version of accepted short paper at 21st IEEE International Conference on Machine Learning and Applications (ICMLA'22). 7 pages, 5 figures",
    "descriptor": "\nComments: Longer version of accepted short paper at 21st IEEE International Conference on Machine Learning and Applications (ICMLA'22). 7 pages, 5 figures\n",
    "authors": [
      "Krish Kabra",
      "Alexander Xiong",
      "Wenbin Li",
      "Minxuan Luo",
      "William Lu",
      "Raul Garcia",
      "Dhananjay Vijay",
      "Jiahui Yu",
      "Maojie Tang",
      "Tianjiao Yu",
      "Hank Arnold",
      "Anna Vallery",
      "Richard Gibbons",
      "Arko Barman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04868"
  },
  {
    "id": "arXiv:2210.04987",
    "title": "Loop Unrolled Shallow Equilibrium Regularizer (LUSER) -- A  Memory-Efficient Inverse Problem Solver",
    "abstract": "Loop Unrolled Shallow Equilibrium Regularizer (LUSER) -- A  Memory-Efficient Inverse Problem Solver",
    "descriptor": "",
    "authors": [
      "Peimeng Guan",
      "Jihui Jin",
      "Justin Romberg",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04987"
  },
  {
    "id": "arXiv:2210.05164",
    "title": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "abstract": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "descriptor": "",
    "authors": [
      "Xiaojun Chen",
      "Yifan He",
      "Zaikun Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.05164"
  },
  {
    "id": "arXiv:2210.05196",
    "title": "DIGAT: Modeling News Recommendation with Dual-Graph Interaction",
    "abstract": "Comments: Findings of EMNLP 2022. This paper was first submitted to ARR 2021 November (this https URL)",
    "descriptor": "\nComments: Findings of EMNLP 2022. This paper was first submitted to ARR 2021 November (this https URL)\n",
    "authors": [
      "Zhiming Mao",
      "Jian Li",
      "Hongru Wang",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.05196"
  },
  {
    "id": "arXiv:2210.05225",
    "title": "A Formalisation of a Fast Fourier Transform",
    "abstract": "A Formalisation of a Fast Fourier Transform",
    "descriptor": "",
    "authors": [
      "Laurent Th\u00e9ry"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.05225"
  },
  {
    "id": "arXiv:2210.05470",
    "title": "Block Format Error Bounds and Optimal Block Size Selection",
    "abstract": "Block Format Error Bounds and Optimal Block Size Selection",
    "descriptor": "",
    "authors": [
      "Ilya Soloveychik",
      "Ilya Lyubomirsky",
      "Xin Wang",
      "Sudeep Bhoja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.05470"
  },
  {
    "id": "arXiv:2210.05479",
    "title": "Frequency-Aware Self-Supervised Monocular Depth Estimation",
    "abstract": "Comments: 8 pages, 5 figures, published to WACV2023",
    "descriptor": "\nComments: 8 pages, 5 figures, published to WACV2023\n",
    "authors": [
      "Xingyu Chen",
      "Thomas H. Li",
      "Ruonan Zhang",
      "Ge Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05479"
  },
  {
    "id": "arXiv:2210.05552",
    "title": "Multi-Agent Distributed and Decentralized Geometric Task Allocation",
    "abstract": "Multi-Agent Distributed and Decentralized Geometric Task Allocation",
    "descriptor": "",
    "authors": [
      "Michael Amir",
      "Yigal Koifman",
      "Yakov Bloch",
      "Ariel Barel",
      "Alfred M. Bruckstein"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.05552"
  },
  {
    "id": "arXiv:2210.05561",
    "title": "Schedule-Robust Online Continual Learning",
    "abstract": "Schedule-Robust Online Continual Learning",
    "descriptor": "",
    "authors": [
      "Ruohan Wang",
      "Marco Ciccone",
      "Giulia Luise",
      "Andrew Yapp",
      "Massimiliano Pontil",
      "Carlo Ciliberto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05561"
  },
  {
    "id": "arXiv:2210.05602",
    "title": "On Monotonicities of Interval Valued Functions",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Ana Shirley Monteiro",
      "Regivan Santiago",
      "Martin Papco",
      "Radko Mesiar",
      "Humberto Bustince"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.05602"
  },
  {
    "id": "arXiv:2210.05614",
    "title": "An Experimental Study on Private Aggregation of Teacher Ensemble  Learning for End-to-End Speech Recognition",
    "abstract": "Comments: 5 pages. Accepted to IEEE SLT 2022. A first version draft was finished in Aug 2021",
    "descriptor": "\nComments: 5 pages. Accepted to IEEE SLT 2022. A first version draft was finished in Aug 2021\n",
    "authors": [
      "Chao-Han Huck Yang",
      "I-Fan Chen",
      "Andreas Stolcke",
      "Sabato Marco Siniscalchi",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.05614"
  },
  {
    "id": "arXiv:2210.05635",
    "title": "Oflib: Facilitating Operations with and on Optical Flow Fields in Python",
    "abstract": "Comments: \"What is Motion for?\" - ECCV 2022 Workshop Submission",
    "descriptor": "\nComments: \"What is Motion for?\" - ECCV 2022 Workshop Submission\n",
    "authors": [
      "Claudio Ravasio",
      "Lyndon Da Cruz",
      "Christos Bergeles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05635"
  },
  {
    "id": "arXiv:2210.05816",
    "title": "Finding and Listing Front-door Adjustment Sets",
    "abstract": "Comments: Pages: 18 (main paper 10, references 2, appendix 6), Figures: 9 (main paper 7, appendix 2), to be published in Proceedings of the 36th Annual Conference on Neural Information Processing Systems",
    "descriptor": "\nComments: Pages: 18 (main paper 10, references 2, appendix 6), Figures: 9 (main paper 7, appendix 2), to be published in Proceedings of the 36th Annual Conference on Neural Information Processing Systems\n",
    "authors": [
      "Hyunchai Jeong",
      "Jin Tian",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05816"
  },
  {
    "id": "arXiv:2210.05888",
    "title": "Calibration and Uncertainty Characterization for Ultra-Wideband  Two-Way-Ranging Measurements",
    "abstract": "Comments: 7 pages, 7 figures, submitted to 2023 International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 7 pages, 7 figures, submitted to 2023 International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Mohammed Ayman Shalaby",
      "Charles Champagne Cossette",
      "James Richard Forbes",
      "Jerome Le Ny"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.05888"
  },
  {
    "id": "arXiv:2210.06110",
    "title": "Uplift and Upsample: Efficient 3D Human Pose Estimation with Uplifting  Transformers",
    "abstract": "Comments: Accepted at IEEE/CVF WACV 2023",
    "descriptor": "\nComments: Accepted at IEEE/CVF WACV 2023\n",
    "authors": [
      "Moritz Einfalt",
      "Katja Ludwig",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06110"
  },
  {
    "id": "arXiv:2210.06155",
    "title": "ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich  Document Understanding",
    "abstract": "Comments: Accepted to EMNLP 2022 (Findings)",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (Findings)\n",
    "authors": [
      "Qiming Peng",
      "Yinxu Pan",
      "Wenjin Wang",
      "Bin Luo",
      "Zhenyu Zhang",
      "Zhengjie Huang",
      "Teng Hu",
      "Weichong Yin",
      "Yongfeng Chen",
      "Yin Zhang",
      "Shikun Feng",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06155"
  },
  {
    "id": "arXiv:2210.06323",
    "title": "AISFormer: Amodal Instance Segmentation with Transformer",
    "abstract": "Comments: Accepted to BMVC2022",
    "descriptor": "\nComments: Accepted to BMVC2022\n",
    "authors": [
      "Minh Tran",
      "Khoa Vo",
      "Kashu Yamazaki",
      "Arthur Fernandes",
      "Michael Kidd",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06323"
  },
  {
    "id": "arXiv:2210.06432",
    "title": "InfoCSE: Information-aggregated Contrastive Learning of Sentence  Embeddings",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Xing Wu",
      "Chaochen Gao",
      "Zijia Lin",
      "Jizhong Han",
      "Zhongyuan Wang",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06432"
  },
  {
    "id": "arXiv:2210.06583",
    "title": "S4ND: Modeling Images and Videos as Multidimensional Signals Using State  Spaces",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Eric Nguyen",
      "Karan Goel",
      "Albert Gu",
      "Gordon W. Downs",
      "Preey Shah",
      "Tri Dao",
      "Stephen A. Baccus",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.06583"
  },
  {
    "id": "arXiv:2210.06586",
    "title": "Automatic Real-time Vehicle Classification by Image Colour Component  Based Template Matching",
    "abstract": "Automatic Real-time Vehicle Classification by Image Colour Component  Based Template Matching",
    "descriptor": "",
    "authors": [
      "Ahmet Orun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06586"
  },
  {
    "id": "arXiv:2210.06587",
    "title": "BLADERUNNER: Rapid Countermeasure for Synthetic (AI-Generated) StyleGAN  Faces",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Adam Dorian Wong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06587"
  },
  {
    "id": "arXiv:2210.06618",
    "title": "QMRNet: Quality Metric Regression for EO Image Quality Assessment and  Super-Resolution",
    "abstract": "Comments: 29 pages, 13 figures, 9 tables",
    "descriptor": "\nComments: 29 pages, 13 figures, 9 tables\n",
    "authors": [
      "David Berga",
      "Pau Gall\u00e9s",
      "Katalin Tak\u00e1ts",
      "Eva Mohedano",
      "Laura Riordan-Chen",
      "Clara Garcia-Moll",
      "David Vilaseca",
      "Javier Mar\u00edn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.06618"
  },
  {
    "id": "arXiv:2210.06663",
    "title": "A Logical Framework with Higher-Order Rational (Circular) Terms",
    "abstract": "A Logical Framework with Higher-Order Rational (Circular) Terms",
    "descriptor": "",
    "authors": [
      "Zhibo Chen",
      "Frank Pfenning"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.06663"
  },
  {
    "id": "arXiv:2210.06784",
    "title": "Efficient circuit implementation for coined quantum walks on binary  trees and application to reinforcement learning",
    "abstract": "Efficient circuit implementation for coined quantum walks on binary  trees and application to reinforcement learning",
    "descriptor": "",
    "authors": [
      "Thomas Mullor",
      "David Vigouroux",
      "Louis Bethune"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.06784"
  },
  {
    "id": "arXiv:2210.06824",
    "title": "An Empirical Study on Finding Spans",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Weiwei Gu",
      "Boyuan Zheng",
      "Yunmo Chen",
      "Tongfei Chen",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06824"
  },
  {
    "id": "arXiv:2210.07002",
    "title": "Anonymizing Speech with Generative Adversarial Networks to Preserve  Speaker Privacy",
    "abstract": "Comments: IEEE Spoken Language Technology Workshop 2022",
    "descriptor": "\nComments: IEEE Spoken Language Technology Workshop 2022\n",
    "authors": [
      "Sarina Meyer",
      "Pascal Tilli",
      "Pavel Denisov",
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07002"
  },
  {
    "id": "arXiv:2210.07074",
    "title": "CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing",
    "abstract": "Comments: Accepted to AACL-IJCNLP 2022: The 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, November 20-23, 2022. See this https URL",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022: The 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, November 20-23, 2022. See this https URL\n",
    "authors": [
      "Andy Rosenbaum",
      "Saleh Soltan",
      "Wael Hamza",
      "Amir Saffari",
      "Marco Damonte",
      "Isabel Groves"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07074"
  },
  {
    "id": "arXiv:2210.07147",
    "title": "Global Explainability of GNNs via Logic Combination of Learned Concepts",
    "abstract": "Global Explainability of GNNs via Logic Combination of Learned Concepts",
    "descriptor": "",
    "authors": [
      "Steve Azzolin",
      "Antonio Longa",
      "Pietro Barbiero",
      "Pietro Li\u00f2",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07147"
  },
  {
    "id": "arXiv:2210.07189",
    "title": "On Compressing Sequences for Self-Supervised Speech Models",
    "abstract": "Comments: Accepted to IEEE SLT 2022",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Yen Meng",
      "Hsuan-Jui Chen",
      "Jiatong Shi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07189"
  }
]
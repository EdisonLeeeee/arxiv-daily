[
  {
    "id": "arXiv:2210.10048",
    "title": "AnalogVNN: A fully modular framework for modeling and optimizing  photonic neural networks",
    "abstract": "In this paper, we present AnalogVNN, a simulation framework built on PyTorch\nwhich can simulate the effects of optoelectronic noise, limited precision, and\nsignal normalization present in photonic neural network accelerators. We use\nthis framework to train and optimize linear and convolutional neural networks\nwith up to 9 layers and ~1.7 million parameters, while gaining insights into\nhow normalization, activation function, reduced precision, and noise influence\naccuracy in analog photonic neural networks. By following the same layer\nstructure design present in PyTorch, the AnalogVNN framework allows users to\nconvert most digital neural network models to their analog counterparts with\njust a few lines of code, taking full advantage of the open-source\noptimization, deep learning, and GPU acceleration libraries available through\nPyTorch.",
    "descriptor": "",
    "authors": [
      "Vivswan Shah",
      "Nathan Youngblood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2210.10048"
  },
  {
    "id": "arXiv:2210.10049",
    "title": "Alibaba-Translate China's Submission for WMT 2022 Quality Estimation  Shared Task",
    "abstract": "In this paper, we present our submission to the sentence-level MQM benchmark\nat Quality Estimation Shared Task, named UniTE (Unified Translation\nEvaluation). Specifically, our systems employ the framework of UniTE, which\ncombined three types of input formats during training with a pre-trained\nlanguage model. First, we apply the pseudo-labeled data examples for the\ncontinuously pre-training phase. Notably, to reduce the gap between\npre-training and fine-tuning, we use data pruning and a ranking-based score\nnormalization strategy. For the fine-tuning phase, we use both Direct\nAssessment (DA) and Multidimensional Quality Metrics (MQM) data from past\nyears' WMT competitions. Finally, we collect the source-only evaluation\nresults, and ensemble the predictions generated by two UniTE models, whose\nbackbones are XLM-R and InfoXLM, respectively. Results show that our models\nreach 1st overall ranking in the Multilingual and English-Russian settings, and\n2nd overall ranking in English-German and Chinese-English settings, showing\nrelatively strong performances in this year's quality estimation competition.",
    "descriptor": "\nComments: WMT 2022 QE Shared Task. arXiv admin note: text overlap with arXiv:2210.09683\n",
    "authors": [
      "Keqin Bao",
      "Yu Wan",
      "Dayiheng Liu",
      "Baosong Yang",
      "Wenqiang Lei",
      "Xiangnan He",
      "Derek F.Wong",
      "Jun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10049"
  },
  {
    "id": "arXiv:2210.10073",
    "title": "Detecting and analyzing missing citations to published scientific  entities",
    "abstract": "Proper citation is of great importance in academic writing for it enables\nknowledge accumulation and maintains academic integrity. However, citing\nproperly is not an easy task. For published scientific entities, the\never-growing academic publications and over-familiarity of terms easily lead to\nmissing citations. To deal with this situation, we design a special method\nCitation Recommendation for Published Scientific Entity (CRPSE) based on the\ncooccurrences between published scientific entities and in-text citations in\nthe same sentences from previous researchers. Experimental outcomes show the\neffectiveness of our method in recommending the source papers for published\nscientific entities. We further conduct a statistical analysis on missing\ncitations among papers published in prestigious computer science conferences in\n2020. In the 12,278 papers collected, 475 published scientific entities of\ncomputer science and mathematics are found to have missing citations. Many\nentities mentioned without citations are found to be well-accepted research\nresults. On a median basis, the papers proposing these published scientific\nentities with missing citations were published 8 years ago, which can be\nconsidered the time frame for a published scientific entity to develop into a\nwell-accepted concept. For published scientific entities, we appeal for\naccurate and full citation of their source papers as required by academic\nstandards.",
    "descriptor": "\nComments: Please cite the version of Scientometrics\n",
    "authors": [
      "Jialiang Lin",
      "Yao Yu",
      "Jiaxin Song",
      "Xiaodong Shi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10073"
  },
  {
    "id": "arXiv:2210.10077",
    "title": "Deterministic vs. Non Deterministic Finite Automata in Automata  Processing",
    "abstract": "Linear-time pattern matching engines have seen promising results using Finite\nAutomata (FA) as their computation model. Among different FA variants,\ndeterministic (DFA) and non-deterministic (NFA) are the most commonly used\ncomputation models for FA-based pattern matching engines. Moreover, NFA is the\nprevalent model in pattern matching engines on spatial architectures. The\nreasons are: i) DFA size, as in #states, can be exponential compared to\nequivalent NFA, ii) DFA cannot exploit the massive parallelism available on\nspatial architectures. This paper performs an empirical study on the #state of\nminimized DFA and optimized NFA across a diverse set of real-world benchmarks\nand shows that if distinct DFAs are generated for distinct patterns, #states of\nminimized DFA are typically equal to their equivalent optimized NFA. However,\nNFA is more robust in maintaining the low #states for some benchmarks. Thus,\nthe choice of NFA vs. DFA for spatial architecture is less important than the\nneed to generate distinct DFAs for each pattern and support these distinct\nDFAs' parallel processing. Finally, this paper presents a throughput study for\nvon Neumann's architecture-based (CPU) vs. spatial architecture-based (FPGA)\nautomata processing engines. The study shows that, based on the workload,\nneither CPU-based automata processing engine nor FPGA-based automata processing\nengine is the clear winner. If #patterns matched per workload increases, the\nCPU-based automata processing engine's throughput decreases. On the other hand,\nthe FPGA-based automata processing engine lacks the memory spilling option;\nhence, it fails to accommodate an entire automata if it does not fit into\nFPGA's logic fabric. In the best-case scenario, the CPU has a 4.5x speedup over\nthe FPGA, while for some benchmarks, the FPGA has a 32,530x speedup over the\nCPU.",
    "descriptor": "",
    "authors": [
      "Farzana Ahmed Siddique",
      "Tommy James Tracy II",
      "Nathan Brunelle",
      "Kevin Skadron"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Hardware Architecture (cs.AR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.10077"
  },
  {
    "id": "arXiv:2210.10081",
    "title": "Why do people judge humans differently from machines? The role of agency  and experience",
    "abstract": "People are known to judge artificial intelligence using a utilitarian moral\nphilosophy and humans using a moral philosophy emphasizing perceived\nintentions. But why do people judge humans and machines differently? Psychology\nsuggests that people may have different mind perception models for humans and\nmachines, and thus, will treat human-like robots more similarly to the way they\ntreat humans. Here we present a randomized experiment where we manipulated\npeople's perception of machines to explore whether people judge more human-like\nmachines more similarly to the way they judge humans. We find that people's\njudgments of machines become more similar to that of humans when they perceive\nmachines as having more agency (e.g. ability to plan, act), but not more\nexperience (e.g. ability to feel). Our findings indicate that people's use of\ndifferent moral philosophies to judge humans and machines can be explained by a\nprogression of mind perception models where the perception of agency plays a\nprominent role. These findings add to the body of evidence suggesting that\npeople's judgment of machines becomes more similar to that of humans motivating\nfurther work on differences in the judgment of human and machine actions.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Jingling Zhang",
      "Jane Conway",
      "C\u00e9sar A. Hidalgo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.10081"
  },
  {
    "id": "arXiv:2210.10084",
    "title": "On History-Deterministic One-Counter Nets",
    "abstract": "We consider the model of history-deterministic one-counter nets (OCNs).\nHistory-determinism is a property of transition systems that allows for a\nlimited kind of non-determinism which can be resolved 'on-the-fly'. Token\ngames, which have been used to characterise history-determinism over various\nmodels, also characterise history-determinism over OCNs. By reducing 1-token\ngames to simulation games, we are able to show that checking for\nhistory-determinism of OCNs is decidable. Moreover, we prove that this problem\nis PSPACE-complete for a unary encoding of transitions, and EXPSPACE-complete\nfor a binary encoding.\nWe then study the language properties of history-deterministic OCNs. We show\nthat the resolvers of non-determinism for history-deterministic OCNs are\neventually periodic. As a consequence, for a given history-deterministic OCN,\nwe construct a language equivalent deterministic one-counter automaton. We also\nshow the decidability of comparing languages of history-deterministic OCNs,\nsuch as language inclusion and language universality.",
    "descriptor": "",
    "authors": [
      "Aditya Prakash",
      "K.S. Thejaswini"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.10084"
  },
  {
    "id": "arXiv:2210.10085",
    "title": "Auditing YouTube's Recommendation Algorithm for Misinformation Filter  Bubbles",
    "abstract": "In this paper, we present results of an auditing study performed over YouTube\naimed at investigating how fast a user can get into a misinformation filter\nbubble, but also what it takes to \"burst the bubble\", i.e., revert the bubble\nenclosure. We employ a sock puppet audit methodology, in which pre-programmed\nagents (acting as YouTube users) delve into misinformation filter bubbles by\nwatching misinformation promoting content. Then they try to burst the bubbles\nand reach more balanced recommendations by watching misinformation debunking\ncontent. We record search results, home page results, and recommendations for\nthe watched videos. Overall, we recorded 17,405 unique videos, out of which we\nmanually annotated 2,914 for the presence of misinformation. The labeled data\nwas used to train a machine learning model classifying videos into three\nclasses (promoting, debunking, neutral) with the accuracy of 0.82. We use the\ntrained model to classify the remaining videos that would not be feasible to\nannotate manually.\nUsing both the manually and automatically annotated data, we observe the\nmisinformation bubble dynamics for a range of audited topics. Our key finding\nis that even though filter bubbles do not appear in some situations, when they\ndo, it is possible to burst them by watching misinformation debunking content\n(albeit it manifests differently from topic to topic). We also observe a sudden\ndecrease of misinformation filter bubble effect when misinformation debunking\nvideos are watched after misinformation promoting videos, suggesting a strong\ncontextuality of recommendations. Finally, when comparing our results with a\nprevious similar study, we do not observe significant improvements in the\noverall quantity of recommended misinformation content.",
    "descriptor": "\nComments: Just accepted to ACM Transactions on Recommender Systems (ACM TORS). arXiv admin note: substantial text overlap with arXiv:2203.13769\n",
    "authors": [
      "Ivan Srba",
      "Robert Moro",
      "Matus Tomlein",
      "Branislav Pecher",
      "Jakub Simko",
      "Elena Stefancova",
      "Michal Kompan",
      "Andrea Hrckova",
      "Juraj Podrouzek",
      "Adrian Gavornik",
      "Maria Bielikova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10085"
  },
  {
    "id": "arXiv:2210.10090",
    "title": "How to Boost Face Recognition with StyleGAN?",
    "abstract": "State-of-the-art face recognition systems require huge amounts of labeled\ntraining data. Given the priority of privacy in face recognition applications,\nthe data is limited to celebrity web crawls, which have issues such as skewed\ndistributions of ethnicities and limited numbers of identities. On the other\nhand, the self-supervised revolution in the industry motivates research on\nadaptation of the related techniques to facial recognition. One of the most\npopular practical tricks is to augment the dataset by the samples drawn from\nthe high-resolution high-fidelity models (e.g. StyleGAN-like), while preserving\nthe identity. We show that a simple approach based on fine-tuning an encoder\nfor StyleGAN allows to improve upon the state-of-the-art facial recognition and\nperforms better compared to training on synthetic face identities. We also\ncollect large-scale unlabeled datasets with controllable ethnic constitution --\nAfricanFaceSet-5M (5 million images of different people) and AsianFaceSet-3M (3\nmillion images of different people) and we show that pretraining on each of\nthem improves recognition of the respective ethnicities (as well as also\nothers), while combining all unlabeled datasets results in the biggest\nperformance increase. Our self-supervised strategy is the most useful with\nlimited amounts of labeled training data, which can be beneficial for more\ntailored face recognition tasks and when facing privacy concerns. Evaluation is\nprovided based on a standard RFW dataset and a new large-scale RB-WebFace\nbenchmark.",
    "descriptor": "",
    "authors": [
      "Artem Sevastopolsky",
      "Yury Malkov",
      "Nikita Durasov",
      "Luisa Verdoliva",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10090"
  },
  {
    "id": "arXiv:2210.10091",
    "title": "Understanding the Knowledge Sharing Behaviors of Library Professionals  in South Asia",
    "abstract": "The present study aim is to know the information professionals-library\nprofessionals knowledge sharing behaviours and attitudes among the institutes.\nThis study investigated six countries' library professionals: Bangladesh,\nBhutan, India, Nepal, Pakistan, and Sri Lanka. The study discussed knowledge\nsharing behaviour, technological equipment used for knowledge management and\ndisseminating the sources of knowledge; academic social networking sites used\nfor sharing the information and knowledge as well as challenges in knowledge\nmanagement faced by the librarians examined in detail. The implication of the\nstudy highlighted the various areas of knowledge management such as training,\nbudget, lack of staff and reward.",
    "descriptor": "",
    "authors": [
      "Abinash Deka",
      "Subaveerapandiyan A"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.10091"
  },
  {
    "id": "arXiv:2210.10092",
    "title": "Awareness of Predatory Journals in Library and Information Science  Faculties in India",
    "abstract": "Predatory journals that pretended to resemble refereed journals but are used\nfor money-making purposes. Predatory publishers produce less quality scientific\nand research papers; it is a severe academic threat in scientific publications.\nResearchers are ensuring the quality of the journal and peer-reviewing process\nbefore submitting the manuscript. This paper aims to know the Indian Library\nand Information Science faculties awareness and knowledge about Predatory\njournals.",
    "descriptor": "",
    "authors": [
      "Madhuri Kumari",
      "Subaveerapandiyan A"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10092"
  },
  {
    "id": "arXiv:2210.10093",
    "title": "Digital Literacy and Reading Habits of the Central University of Tamil  Nadu Students: A Survey Study",
    "abstract": "The study attempted to understand the University students' digital reading\nhabits and their related skills. It also has a view of students' preferred\nsources of reading, whether physical or digital resources. For this study, we\nconducted a survey study with students and research scholars of the Central\nUniversity of Tamil Nadu, India. The instrument was a structured questionnaire\ndistributed with various modes. The result found that the majority of the\nstudents are well known about digital tools and usage, most of the students are\nexcellent in digital literacy skills and other findings is however they are\ngood in digital literacy even though they like to read print books is their\nmost favorable preference. The results conclude that whatever technological\ndevices are developed and students have also grown their technical knowledge.\nThe result finds out, in education especially reading-wise, students or\nreaders' first wish is printed resources; digital books are secondary to them.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Priyanka Sinha"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10093"
  },
  {
    "id": "arXiv:2210.10094",
    "title": "Partitioned Persist Ordering",
    "abstract": "Persistent Memory (PM) technologies enable program recovery to a consistent\nstate in case of failure. To ensure this crash-consistent behavior, programs\nneed to enforce persist ordering by employing mechanisms, such as logging and\ncheckpointing, which introduce additional data movement.The emerging near-data\nprocessing (NDP) architectures can effectively reduce this data movement\noverhead by partitioning the persistent programs and executing the crash\nconsistency mechanisms in the NDP-enabled PM. However, a significant challenge\nlies in maintaining the persist ordering when execution has been partitioned\nbetween the host CPU and NDP-enabled PM. In this work, we first propose\nPartitioned Persist Ordering (PPO) that ensures a correct persist ordering\nbetween CPU and NDP devices, as well as among multiple NDP devices. PPO\nguarantees high efficiency by reducing unnecessary synchronization among CPU\nand NDP devices. Based on PPO, we prototype an NDP system, NearPM, on an FPGA\nplatform. NearPM executes data-intensive operations in crash consistency\nmechanisms with correct ordering guarantees while the rest of the program runs\non the CPU. We evaluate nine PM workloads, where each workload supports three\ncrash consistency mechanisms - logging, checkpointing, and shadow paging.\nOverall, NearPM achieves 4.3-9.8X speedup in the NDP-offloaded operations and\n1.22-1.35X speedup in end-to-end execution.",
    "descriptor": "",
    "authors": [
      "Yasas Seneviratne",
      "Korakit Seemakhupt",
      "Sihang Liu",
      "Samira Khan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10094"
  },
  {
    "id": "arXiv:2210.10101",
    "title": "Optimisation & Generalisation in Networks of Neurons",
    "abstract": "The goal of this thesis is to develop the optimisation and generalisation\ntheoretic foundations of learning in artificial neural networks. On\noptimisation, a new theoretical framework is proposed for deriving\narchitecture-dependent first-order optimisation algorithms. The approach works\nby combining a \"functional majorisation\" of the loss function with\n\"architectural perturbation bounds\" that encode an explicit dependence on\nneural architecture. The framework yields optimisation methods that transfer\nhyperparameters across learning problems. On generalisation, a new\ncorrespondence is proposed between ensembles of networks and individual\nnetworks. It is argued that, as network width and normalised margin are taken\nlarge, the space of networks that interpolate a particular training set\nconcentrates on an aggregated Bayesian method known as a \"Bayes point machine\".\nThis correspondence provides a route for transferring PAC-Bayesian\ngeneralisation theorems over to individual networks. More broadly, the\ncorrespondence presents a fresh perspective on the role of regularisation in\nnetworks with vastly more parameters than data.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Jeremy Bernstein"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10101"
  },
  {
    "id": "arXiv:2210.10104",
    "title": "Guiding Data-Driven Design Ideation by Knowledge Distance",
    "abstract": "Data-driven conceptual design methods and tools aim to inspire human ideation\nfor new design concepts by providing external inspirational stimuli. In prior\nstudies, the stimuli have been limited in terms of coverage, granularity, and\nretrieval guidance. Here, we present a knowledge based expert system that\nprovides design stimuli across the semantic, document and field levels\nsimultaneously from all fields of engineering and technology and that follows\ncreativity theories to guide the retrieval and use of stimuli according to the\nknowledge distance. The system is centered on the use of a network of all\ntechnology fields in the patent classification system, to store and organize\nthe world's cumulative data on the technological knowledge, concepts, and\nsolutions in the total patent database according to statistically estimated\nknowledge distance between technology fields. In turn, knowledge distance\nguides the network-based exploration and retrieval of inspirational stimuli for\ninferences across near and far fields to generate new design ideas by analogy\nand combination. With two case studies, we showcase the effectiveness of using\nthe system to explore and retrieve multilevel inspirational stimuli and\ngenerate new design ideas for both problem solving and open ended innovation.\nThese case studies also demonstrate the computer aided ideation process, which\nis data-driven, computationally augmented, theoretically grounded, visually\ninspiring, and rapid.",
    "descriptor": "",
    "authors": [
      "Jianxi Luo",
      "Serhad Sarica",
      "Kristin Wood"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10104"
  },
  {
    "id": "arXiv:2210.10105",
    "title": "ELASTIC: Numerical Reasoning with Adaptive Symbolic Compiler",
    "abstract": "Numerical reasoning over text is a challenging task of Artificial\nIntelligence (AI), requiring reading comprehension and numerical reasoning\nabilities. Previous approaches use numerical reasoning programs to represent\nthe reasoning process. However, most works do not separate the generation of\noperators and operands, which are key components of a numerical reasoning\nprogram, thus limiting their ability to generate such programs for complicated\ntasks. In this paper, we introduce the numEricaL reASoning with adapTive\nsymbolIc Compiler (ELASTIC) model, which is constituted of the RoBERTa as the\nEncoder and a Compiler with four modules: Reasoning Manager, Operator\nGenerator, Operands Generator, and Memory Register. ELASTIC is robust when\nconducting complicated reasoning. Also, it is domain agnostic by supporting the\nexpansion of diverse operators without caring about the number of operands it\ncontains. Experiments show that ELASTIC achieves 68.96 and 65.21 of execution\naccuracy and program accuracy on the FinQA dataset and 83.00 program accuracy\non the MathQA dataset, outperforming previous state-of-the-art models\nsignificantly.",
    "descriptor": "",
    "authors": [
      "Jiaxin Zhang",
      "Yashar Moshfeghi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10105"
  },
  {
    "id": "arXiv:2210.10108",
    "title": "Parallel Inversion of Neural Radiance Fields for Robust Pose Estimation",
    "abstract": "We present a parallelized optimization method based on fast Neural Radiance\nFields (NeRF) for estimating 6-DoF target poses. Given a single observed RGB\nimage of the target, we can predict the translation and rotation of the camera\nby minimizing the residual between pixels rendered from a fast NeRF model and\npixels in the observed image. We integrate a momentum-based camera extrinsic\noptimization procedure into Instant Neural Graphics Primitives, a recent\nexceptionally fast NeRF implementation. By introducing parallel Monte Carlo\nsampling into the pose estimation task, our method overcomes local minima and\nimproves efficiency in a more extensive search space. We also show the\nimportance of adopting a more robust pixel-based loss function to reduce error.\nExperiments demonstrate that our method can achieve improved generalization and\nrobustness on both synthetic and real-world benchmarks.",
    "descriptor": "\nComments: Submitted to ICRA 2023. Project page at this https URL\n",
    "authors": [
      "Yunzhi Lin",
      "Thomas M\u00fcller",
      "Jonathan Tremblay",
      "Bowen Wen",
      "Stephen Tyree",
      "Alex Evans",
      "Patricio A. Vela",
      "Stan Birchfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10108"
  },
  {
    "id": "arXiv:2210.10109",
    "title": "A Survey of Active Learning for Natural Language Processing",
    "abstract": "In this work, we provide a survey of active learning (AL) for its\napplications in natural language processing (NLP). In addition to a\nfine-grained categorization of query strategies, we also investigate several\nother important aspects of applying AL to NLP problems. These include AL for\nstructured prediction tasks, annotation cost, model learning (especially with\ndeep neural models), and starting and stopping AL. Finally, we conclude with a\ndiscussion of related topics and future directions.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhisong Zhang",
      "Emma Strubell",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10109"
  },
  {
    "id": "arXiv:2210.10110",
    "title": "Trixi the Librarian",
    "abstract": "In this work, we present a three-part system that automatically sorts books\non a shelf using the PR- 2 platform. The paper describes a methodology to\nsufficiently detect and recognize books using a multistep vision pipeline based\non deep learning models as well as conventional computer vision. Furthermore,\nthe difficulties of relocating books using a bi-manual robot along with\nsolutions based on MoveIt and BioIK are being addressed. Experiments show that\nthe performance is overall good enough to repeatedly sort three books on a\nshelf. Nevertheless, further improvements are being discussed, potentially\nleading to a more robust book recognition and more versatile manipulation\ntechniques.",
    "descriptor": "",
    "authors": [
      "Fabian Wieczorek",
      "Shang-Ching Liu",
      "Bj\u00f6rn Sygo",
      "Mykhailo Koshil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10110"
  },
  {
    "id": "arXiv:2210.10114",
    "title": "Transferable Unlearnable Examples",
    "abstract": "With more people publishing their personal data online, unauthorized data\nusage has become a serious concern. The unlearnable strategies have been\nintroduced to prevent third parties from training on the data without\npermission. They add perturbations to the users' data before publishing, which\naims to make the models trained on the perturbed published dataset invalidated.\nThese perturbations have been generated for a specific training setting and a\ntarget dataset. However, their unlearnable effects significantly decrease when\nused in other training settings and datasets. To tackle this issue, we propose\na novel unlearnable strategy based on Classwise Separability Discriminant\n(CSD), which aims to better transfer the unlearnable effects to other training\nsettings and datasets by enhancing the linear separability. Extensive\nexperiments demonstrate the transferability of the proposed unlearnable\nexamples across training settings and datasets.",
    "descriptor": "",
    "authors": [
      "Jie Ren",
      "Han Xu",
      "Yuxuan Wan",
      "Xingjun Ma",
      "Lichao Sun",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10114"
  },
  {
    "id": "arXiv:2210.10123",
    "title": "Interpolated SelectionConv for Spherical Images and Surfaces",
    "abstract": "We present a new and general framework for convolutional neural network\noperations on spherical (or omnidirectional) images. Our approach represents\nthe surface as a graph of connected points that doesn't rely on a particular\nsampling strategy. Additionally, by using an interpolated version of\nSelectionConv, we can operate on the sphere while using existing 2D CNNs and\ntheir weights. Since our method leverages existing graph implementations, it is\nalso fast and can be fine-tuned efficiently. Our method is also general enough\nto be applied to any surface type, even those that are topologically\nnon-simple. We demonstrate the effectiveness of our technique on the tasks of\nstyle transfer and segmentation for spheres as well as stylization for 3D\nmeshes. We provide a thorough ablation study of the performance of various\nspherical sampling strategies.",
    "descriptor": "\nComments: To be presented at WACV 2023\n",
    "authors": [
      "David Hart",
      "Michael Whitney",
      "Bryan Morse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10123"
  },
  {
    "id": "arXiv:2210.10125",
    "title": "Proximal Learning With Opponent-Learning Awareness",
    "abstract": "Learning With Opponent-Learning Awareness (LOLA) (Foerster et al. [2018a]) is\na multi-agent reinforcement learning algorithm that typically learns\nreciprocity-based cooperation in partially competitive environments. However,\nLOLA often fails to learn such behaviour on more complex policy spaces\nparameterized by neural networks, partly because the update rule is sensitive\nto the policy parameterization. This problem is especially pronounced in the\nopponent modeling setting, where the opponent's policy is unknown and must be\ninferred from observations; in such settings, LOLA is ill-specified because\nbehaviorally equivalent opponent policies can result in non-equivalent updates.\nTo address this shortcoming, we reinterpret LOLA as approximating a proximal\noperator, and then derive a new algorithm, proximal LOLA (POLA), which uses the\nproximal formulation directly. Unlike LOLA, the POLA updates are\nparameterization invariant, in the sense that when the proximal objective has a\nunique optimum, behaviorally equivalent policies result in behaviorally\nequivalent updates. We then present practical approximations to the ideal POLA\nupdate, which we evaluate in several partially competitive environments with\nfunction approximation and opponent modeling. This empirically demonstrates\nthat POLA achieves reciprocity-based cooperation more reliably than LOLA.",
    "descriptor": "\nComments: 24 pages (10 pages main paper), 5 figures, to be published in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Stephen Zhao",
      "Chris Lu",
      "Roger Baker Grosse",
      "Jakob Nicolaus Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.10125"
  },
  {
    "id": "arXiv:2210.10127",
    "title": "Output Feedback Tube MPC-Guided Data Augmentation for Robust, Efficient  Sensorimotor Policy Learning",
    "abstract": "Imitation learning (IL) can generate computationally efficient sensorimotor\npolicies from demonstrations provided by computationally expensive model-based\nsensing and control algorithms. However, commonly employed IL methods are often\ndata-inefficient, requiring the collection of a large number of demonstrations\nand producing policies with limited robustness to uncertainties. In this work,\nwe combine IL with an output feedback robust tube model predictive controller\n(RTMPC) to co-generate demonstrations and a data augmentation strategy to\nefficiently learn neural network-based sensorimotor policies. Thanks to the\naugmented data, we reduce the computation time and the number of demonstrations\nneeded by IL, while providing robustness to sensing and process uncertainty. We\ntailor our approach to the task of learning a trajectory tracking visuomotor\npolicy for an aerial robot, leveraging a 3D mesh of the environment as part of\nthe data augmentation process. We numerically demonstrate that our method can\nlearn a robust visuomotor policy from a single demonstration--a two-orders of\nmagnitude improvement in demonstration efficiency compared to existing IL\nmethods.",
    "descriptor": "\nComments: Accepted to IROS 22\n",
    "authors": [
      "Andrea Tagliabue",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10127"
  },
  {
    "id": "arXiv:2210.10128",
    "title": "Distributed MPC for Self-Organized Cooperation of Multi-Agent Systems",
    "abstract": "We present a sequential distributed model predictive control (MPC) scheme\nsuitable for cooperative control of multi-agent systems with dynamically\ndecoupled heterogeneous nonlinear agents subject to individual constraints. We\nshow that the cooperative goal is asymptotically fulfilled if a corresponding\nset and a suitable cost for cooperation are used, leading to a self-organized\nsolution. Each agent solves an individual optimization problem for an\nartificial reference and an input that tracks it, only needing artificial\nreferences of its neighbors. The cost for cooperation couples these artificial\nreferences such that they are incrementally moved towards the cooperative goal.\nSince only artificial references are exchanged, communication is kept to a\nminimum. Furthermore, the scheme is easily extended to open systems, i.e.,\nagents joining or leaving the multi-agent system. Finally, we apply the scheme\nto consensus and formation control in two examples.",
    "descriptor": "",
    "authors": [
      "Matthias K\u00f6hler",
      "Matthias A. M\u00fcller",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10128"
  },
  {
    "id": "arXiv:2210.10130",
    "title": "PERI: Part Aware Emotion Recognition In The Wild",
    "abstract": "Emotion recognition aims to interpret the emotional states of a person based\non various inputs including audio, visual, and textual cues. This paper focuses\non emotion recognition using visual features. To leverage the correlation\nbetween facial expression and the emotional state of a person, pioneering\nmethods rely primarily on facial features. However, facial features are often\nunreliable in natural unconstrained scenarios, such as in crowded scenes, as\nthe face lacks pixel resolution and contains artifacts due to occlusion and\nblur. To address this, in the wild emotion recognition exploits full-body\nperson crops as well as the surrounding scene context. In a bid to use body\npose for emotion recognition, such methods fail to realize the potential that\nfacial expressions, when available, offer. Thus, the aim of this paper is\ntwo-fold. First, we demonstrate our method, PERI, to leverage both body pose\nand facial landmarks. We create part aware spatial (PAS) images by extracting\nkey regions from the input image using a mask generated from both body pose and\nfacial landmarks. This allows us to exploit body pose in addition to facial\ncontext whenever available. Second, to reason from the PAS images, we introduce\ncontext infusion (Cont-In) blocks. These blocks attend to part-specific\ninformation, and pass them onto the intermediate features of an emotion\nrecognition network. Our approach is conceptually simple and can be applied to\nany existing emotion recognition method. We provide our results on the publicly\navailable in the wild EMOTIC dataset. Compared to existing methods, PERI\nachieves superior performance and leads to significant improvements in the mAP\nof emotion categories, while decreasing Valence, Arousal and Dominance errors.\nImportantly, we observe that our method improves performance in both images\nwith fully visible faces as well as in images with occluded or blurred faces.",
    "descriptor": "\nComments: Accepted at ECCVW 2022\n",
    "authors": [
      "Akshita Mittel",
      "Shashank Tripathi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10130"
  },
  {
    "id": "arXiv:2210.10133",
    "title": "STAMP: Lightweight TEE-Assisted MPC for Efficient Privacy-Preserving  Machine Learning",
    "abstract": "In this paper, we propose STAMP, an end-to-end 3-party MPC protocol for\nefficient privacy-preserving machine learning inference assisted by a\nlightweight TEE (LTEE), which will be far easier to secure and deploy than\ntoday's large TEEs. STAMP provides three main advantages over the\nstate-of-the-art; (i) STAMP achieves significant performance improvements\ncompared to state-of-the-art MPC protocols, with only a small \\LTEE that is\ncomparable to a discrete security chip such as the Trusted Platform Module\n(TPM) or on-chip security subsystems in SoCs similar to the Apple enclave\nprocessor. In a semi-honest setting with WAN/GPU, STAMP is 4$\\times$-63$\\times$\nfaster than Falcon (PoPETs'21) and AriaNN (PoPETs'22) and\n3.8$\\times$-12$\\times$ more communication efficient. We achieve even higher\nperformance improvements in a malicious setting. (ii) STAMP guarantees security\nwith abort against malicious adversaries under honest majority assumption.\n(iii) STAMP is not limited by the size of secure memory in a TEE and can\nsupport high-capacity modern neural networks like ResNet18 and Transformer.",
    "descriptor": "\nComments: USENIX'23 submitted\n",
    "authors": [
      "Pengzhi Huang",
      "Thang Hoang",
      "Yueying Li",
      "Elaine Shi",
      "G. Edward Suh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10133"
  },
  {
    "id": "arXiv:2210.10136",
    "title": "Discipline Reputation Evaluation Based on PhD Exchange Network",
    "abstract": "When reputation evaluation indicators become targets, existing indicators\nwill lose the role of indicating the true quality; At present, the evaluation\nof discipline reputation mostly focuses on subjective evaluation based on\nobjective data, and there is a dispute about reliability and validity; Due to\ndifferent indicators and weight settings, it is difficult to make horizontal\ncomparison among disciplines; The evaluation also has a certain time lag. In\norder to solve the above four problems, this study explores a new method of\ndiscipline reputation evaluation. Taking the business administration discipline\nas an example, it collects data of 5848 doctoral graduates who first entered\nteaching posts, establishes a directed adjacency matrix from the employment\nunit to the doctoral degree awarding unit, and uses the theory and method of\nsocial network analysis to conduct quantitative analysis on the doctoral mutual\nemployment network. The results show that: (1) PhD exchange network can explain\ndiscipline reputation and is a new indicator to measure discipline reputation;\n(2) From the perspective of employment behavior among colleges and\nuniversities, there is horizontal flow and downward flow between the head\ncolleges and universities, and downward flow is mainly among the middle and\nlower colleges. There is a time lag between college talent recruitment and\nacademic achievement output. Therefore, the mining of the structural\ncharacteristics and network evolution trend of the PhD exchange network based\non the \"foot voting\" of doctoral graduates is faster than the discipline\nranking based on the follow-up achievement indicators to reflect the changes in\nthe discipline quality, which can be used to warn the changes in the discipline\nquality.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Shudong Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10136"
  },
  {
    "id": "arXiv:2210.10138",
    "title": "Class-Level Confidence Based 3D Semi-Supervised Learning",
    "abstract": "Recent state-of-the-art method FlexMatch firstly demonstrated that correctly\nestimating learning status is crucial for semi-supervised learning (SSL).\nHowever, the estimation method proposed by FlexMatch does not take into account\nimbalanced data, which is the common case for 3D semi-supervised learning. To\naddress this problem, we practically demonstrate that unlabeled data\nclass-level confidence can represent the learning status in the 3D imbalanced\ndataset. Based on this finding, we present a novel class-level confidence based\n3D SSL method. Firstly, a dynamic thresholding strategy is proposed to utilize\nmore unlabeled data, especially for low learning status classes. Then, a\nre-sampling strategy is designed to avoid biasing toward high learning status\nclasses, which dynamically changes the sampling probability of each class. To\nshow the effectiveness of our method in 3D SSL tasks, we conduct extensive\nexperiments on 3D SSL classification and detection tasks. Our method\nsignificantly outperforms state-of-the-art counterparts for both 3D SSL\nclassification and detection tasks in all datasets.",
    "descriptor": "",
    "authors": [
      "Zhimin Chen",
      "Longlong Jing",
      "Liang Yang",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10138"
  },
  {
    "id": "arXiv:2210.10142",
    "title": "Graph Attention Networks Unveil Determinants of Intra- and Inter-city  Health Disparity",
    "abstract": "Understanding the determinants underlying variations in urban health status\nis important for informing urban design and planning, as well as public health\npolicies. Multiple heterogeneous urban features could modulate the prevalence\nof diseases across different neighborhoods in cities and across different\ncities. This study examines heterogeneous features related to\nsocio-demographics, population activity, mobility, and the built environment\nand their non-linear interactions to examine intra- and inter-city disparity in\nprevalence of four disease types: obesity, diabetes, cancer, and heart disease.\nFeatures related to population activity, mobility, and facility density are\nobtained from large-scale anonymized mobility data. These features are used in\ntraining and testing graph attention network (GAT) models to capture non-linear\nfeature interactions as well as spatial interdependence among neighborhoods. We\ntested the models in five U.S. cities across the four disease types. The\nresults show that the GAT model can predict the health status of people in\nneighborhoods based on the top five determinant features. The findings unveil\nthat population activity and built-environment features along with\nsocio-demographic features differentiate the health status of neighborhoods to\nsuch a great extent that a GAT model could predict the health status using\nthese features with high accuracy. The results also show that the model trained\non one city can predict health status in another city with high accuracy,\nallowing us to quantify the inter-city similarity and discrepancy in health\nstatus. The model and findings provide novel approaches and insights for urban\ndesigners, planners, and public health officials to better understand and\nimprove health disparities in cities by considering the significant determinant\nfeatures and their interactions.",
    "descriptor": "",
    "authors": [
      "Chenyue Liu",
      "Chao Fan",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10142"
  },
  {
    "id": "arXiv:2210.10144",
    "title": "Cross-Domain Aspect Extraction using Transformers Augmented with  Knowledge Graphs",
    "abstract": "The extraction of aspect terms is a critical step in fine-grained sentiment\nanalysis of text. Existing approaches for this task have yielded impressive\nresults when the training and testing data are from the same domain. However,\nthese methods show a drastic decrease in performance when applied to\ncross-domain settings where the domain of the testing data differs from that of\nthe training data. To address this lack of extensibility and robustness, we\npropose a novel approach for automatically constructing domain-specific\nknowledge graphs that contain information relevant to the identification of\naspect terms. We introduce a methodology for injecting information from these\nknowledge graphs into Transformer models, including two alternative mechanisms\nfor knowledge insertion: via query enrichment and via manipulation of attention\npatterns. We demonstrate state-of-the-art performance on benchmark datasets for\ncross-domain aspect term extraction using our approach and investigate how the\namount of external knowledge available to the Transformer impacts model\nperformance.",
    "descriptor": "",
    "authors": [
      "Phillip Howard",
      "Arden Ma",
      "Vasudev Lal",
      "Ana Paula Simoes",
      "Daniel Korat",
      "Oren Pereg",
      "Moshe Wasserblat",
      "Gadi Singer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10144"
  },
  {
    "id": "arXiv:2210.10147",
    "title": "TEFL: Turbo Explainable Federated Learning for 6G Trustworthy Zero-Touch  Network Slicing",
    "abstract": "Sixth-generation (6G) networks anticipate intelligently supporting a massive\nnumber of coexisting and heterogeneous slices associated with various vertical\nuse cases. Such a context urges the adoption of artificial intelligence\n(AI)-driven zero-touch management and orchestration (MANO) of the end-to-end\n(E2E) slices under stringent service level agreements (SLAs). Specifically, the\ntrustworthiness of the AI black-boxes in real deployment can be achieved by\nexplainable AI (XAI) tools to build transparency between the interacting actors\nin the slicing ecosystem, such as tenants, infrastructure providers and\noperators. Inspired by the turbo principle, this paper presents a novel\niterative explainable federated learning (FL) approach where a constrained\nresource allocation model and an \\emph{explainer} exchange -- in a closed loop\n(CL) fashion -- soft attributions of the features as well as inference\npredictions to achieve a transparent and SLA-aware zero-touch service\nmanagement (ZSM) of 6G network slices at RAN-Edge setup under non-independent\nidentically distributed (non-IID) datasets. In particular, we quantitatively\nvalidate the faithfulness of the explanations via the so-called\nattribution-based \\emph{confidence metric} that is included as a constraint in\nthe run-time FL optimization task. In this respect, Integrated-Gradient (IG) as\nwell as Input $\\times$ Gradient and SHAP are used to generate the attributions\nfor the turbo explainable FL (TEFL), wherefore simulation results under\ndifferent methods confirm its superiority over an unconstrained\nIntegrated-Gradient \\emph{post-hoc} FL baseline.",
    "descriptor": "",
    "authors": [
      "Swastika Roy",
      "Hatim Chergui",
      "Christos Verikoukis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10147"
  },
  {
    "id": "arXiv:2210.10148",
    "title": "Bidiagonal Decompositions of Vandermonde-Type Matrices of Arbitrary Rank",
    "abstract": "We present a method to derive new explicit expressions for bidiagonal\ndecompositions of Vandermonde and related matrices such as the (q-, h-)\nBernstein-Vandermonde ones, among others. These results generalize the existing\nexpressions for nonsingular matrices to matrices of arbitrary rank. For totally\nnonnegative matrices of the above classes, the new decompositions can be\ncomputed efficiently and to high relative accuracy componentwise in floating\npoint arithmetic. In turn, matrix computations (e.g., eigenvalue computation)\ncan also be performed efficiently and to high relative accuracy.",
    "descriptor": "",
    "authors": [
      "Jorge Delgado",
      "Plamen Koev",
      "Ana Marco",
      "Jose-Javier Martinez",
      "Juan Manuel Pena",
      "Per-Olof Persson",
      "Steven Spasov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10148"
  },
  {
    "id": "arXiv:2210.10151",
    "title": "Dialogue system with humanoid robot",
    "abstract": "Today, as seen in smart speakers, spoken dialogue technology is rapidly\nadvancing to enable human-like interaction. However, current dialogue systems\ncannot pay attention not only to the content of speech, but also to the way of\nspeaking and eye contact and facial expressions, while watching the facial\nexpressions of the person with whom one is speaking. Therefore, this study\nparticipated in a Japanese competition called the \"Dialogue Robot Competition\"\nand attempted to develop a dialogue system that includes control of not only\nthe content of speech but also the robot's facial expressions and gaze in order\nto realize a humanoid robot that can naturally interact with humans.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition2022\n",
    "authors": [
      "Koki Inoue",
      "Shuichiro Ogake",
      "Hayato Kawamura",
      "Naoki Igo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2210.10151"
  },
  {
    "id": "arXiv:2210.10160",
    "title": "Uncertainty in Extreme Multi-label Classification",
    "abstract": "Uncertainty quantification is one of the most crucial tasks to obtain\ntrustworthy and reliable machine learning models for decision making. However,\nmost research in this domain has only focused on problems with small label\nspaces and ignored eXtreme Multi-label Classification (XMC), which is an\nessential task in the era of big data for web-scale machine learning\napplications. Moreover, enormous label spaces could also lead to noisy\nretrieval results and intractable computational challenges for uncertainty\nquantification. In this paper, we aim to investigate general uncertainty\nquantification approaches for tree-based XMC models with a probabilistic\nensemble-based framework. In particular, we analyze label-level and\ninstance-level uncertainty in XMC, and propose a general approximation\nframework based on beam search to efficiently estimate the uncertainty with a\ntheoretical guarantee under long-tail XMC predictions. Empirical studies on six\nlarge-scale real-world datasets show that our framework not only outperforms\nsingle models in predictive performance, but also can serve as strong\nuncertainty-based baselines for label misclassification and out-of-distribution\ndetection, with significant speedup. Besides, our framework can further yield\nbetter state-of-the-art results based on deep XMC models with uncertainty\nquantification.",
    "descriptor": "\nComments: 14 pages, 1 figure, 8 tables\n",
    "authors": [
      "Jyun-Yu Jiang",
      "Wei-Cheng Chang",
      "Jiong Zhong",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10160"
  },
  {
    "id": "arXiv:2210.10163",
    "title": "MedCLIP: Contrastive Learning from Unpaired Medical Images and Text",
    "abstract": "Existing vision-text contrastive learning like CLIP aims to match the paired\nimage and caption embeddings while pushing others apart, which improves\nrepresentation transferability and supports zero-shot prediction. However,\nmedical image-text datasets are orders of magnitude below the general images\nand captions from the internet. Moreover, previous methods encounter many false\nnegatives, i.e., images and reports from separate patients probably carry the\nsame semantics but are wrongly treated as negatives. In this paper, we decouple\nimages and texts for multimodal contrastive learning thus scaling the usable\ntraining data in a combinatorial magnitude with low cost. We also propose to\nreplace the InfoNCE loss with semantic matching loss based on medical knowledge\nto eliminate false negatives in contrastive learning. We prove that MedCLIP is\na simple yet effective framework: it outperforms state-of-the-art methods on\nzero-shot prediction, supervised classification, and image-text retrieval.\nSurprisingly, we observe that with only 20K pre-training data, MedCLIP wins\nover the state-of-the-art method (using around 200K data). Our code is\navailable at https://github.com/RyanWangZf/MedCLIP.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zifeng Wang",
      "Zhenbang Wu",
      "Dinesh Agarwal",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10163"
  },
  {
    "id": "arXiv:2210.10168",
    "title": "Granger causal inference on DAGs identifies genomic loci regulating  transcription",
    "abstract": "When a dynamical system can be modeled as a sequence of observations, Granger\ncausality is a powerful approach for detecting predictive interactions between\nits variables. However, traditional Granger causal inference has limited\nutility in domains where the dynamics need to be represented as directed\nacyclic graphs (DAGs) rather than as a linear sequence, such as with cell\ndifferentiation trajectories. Here, we present GrID-Net, a framework based on\ngraph neural networks with lagged message passing for Granger causal inference\non DAG-structured systems. Our motivating application is the analysis of\nsingle-cell multimodal data to identify genomic loci that mediate the\nregulation of specific genes. To our knowledge, GrID-Net is the first\nsingle-cell analysis tool that accounts for the temporal lag between a genomic\nlocus becoming accessible and its downstream effect on a target gene's\nexpression. We applied GrID-Net on multimodal single-cell assays that profile\nchromatin accessibility (ATAC-seq) and gene expression (RNA-seq) in the same\ncell and show that it dramatically outperforms existing methods for inferring\nregulatory locus-gene links, achieving up to 71% greater agreement with\nindependent population genetics-based estimates. By extending Granger causality\nto DAG-structured dynamical systems, our work unlocks new domains for causal\nanalyses and, more specifically, opens a path towards elucidating gene\nregulatory interactions relevant to cellular differentiation and complex human\ndiseases at unprecedented scale and resolution.",
    "descriptor": "\nComments: Presented at the International Conference on Learning Representations 2022\n",
    "authors": [
      "Rohit Singh",
      "Alexander P. Wu",
      "Bonnie Berger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.10168"
  },
  {
    "id": "arXiv:2210.10172",
    "title": "Simplex Range Searching Revisited: How to Shave Logs in Multi-Level Data  Structures",
    "abstract": "We revisit the classic problem of simplex range searching and related\nproblems in computational geometry. We present a collection of new results\nwhich improve previous bounds by multiple logarithmic factors that were caused\nby the use of multi-level data structures. Highlights include the following:\n\\begin{itemize} \\item For a set of $n$ points in a constant dimension $d$, we\ngive data structures with $O(n^d)$ (or slightly better) space that can answer\nsimplex range counting queries in optimal $O(\\log n)$ time and simplex range\nreporting queries in optimal $O(\\log n + k)$ time, where $k$ denotes the output\nsize. For semigroup range searching, we obtain $O(\\log n)$ query time with\n$O(n^d\\mathop{\\rm polylog}n)$ space. Previous data structures with similar\nspace bounds by Matou\\v{s}ek from nearly three decades ago had $O(\\log^{d+1}n)$\nor $O(\\log^{d+1}n + k)$ query time. \\item For a set of $n$ simplices in a\nconstant dimension $d$, we give data structures with $O(n)$ space that can\nanswer stabbing counting queries (counting the number of simplices containing a\nquery point) in $O(n^{1-1/d})$ time, and stabbing reporting queries in\n$O(n^{1-1/d}+k)$ time. Previous data structures had extra $\\log^d n$ factors in\nspace and query time. \\item For a set of $n$ (possibly intersecting) line\nsegments in 2D, we give a data structure with $O(n)$ space that can answer ray\nshooting queries in $O(\\sqrt{n})$ time. This improves Wang's recent data\nstructure [SoCG'20] with $O(n\\log n)$ space and $O(\\sqrt{n}\\log n)$ query time.",
    "descriptor": "\nComments: Accepted in SODA'23\n",
    "authors": [
      "Timothy M. Chan",
      "Da Wei Zheng"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10172"
  },
  {
    "id": "arXiv:2210.10173",
    "title": "Faster Matrix Multiplication via Asymmetric Hashing",
    "abstract": "Fast matrix multiplication is one of the most fundamental problems in\nalgorithm research. The exponent of the optimal time complexity of matrix\nmultiplication is usually denoted by $\\omega$. This paper discusses new ideas\nfor improving the laser method for fast matrix multiplication. We observe that\nthe analysis of higher powers of the Coppersmith-Winograd tensor [Coppersmith &\nWinograd 1990] incurs a \"combination loss\", and we partially compensate it by\nusing an asymmetric version of CW's hashing method. By analyzing the 8th power\nof the CW tensor, we give a new bound of $\\omega<2.37188$, which improves the\nprevious best bound of $\\omega<2.37286$ [Alman & V.Williams 2020]. Our result\nbreaks the lower bound of $2.3725$ in [Ambainis et al. 2014] because of the new\nmethod for analyzing component (constituent) tensors.",
    "descriptor": "\nComments: 67 pages\n",
    "authors": [
      "Ran Duan",
      "Hongxun Wu",
      "Renfei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10173"
  },
  {
    "id": "arXiv:2210.10175",
    "title": "Intra-Source Style Augmentation for Improved Domain Generalization",
    "abstract": "The generalization with respect to domain shifts, as they frequently appear\nin applications such as autonomous driving, is one of the remaining big\nchallenges for deep learning models. Therefore, we propose an intra-source\nstyle augmentation (ISSA) method to improve domain generalization in semantic\nsegmentation. Our method is based on a novel masked noise encoder for StyleGAN2\ninversion. The model learns to faithfully reconstruct the image preserving its\nsemantic layout through noise prediction. Random masking of the estimated noise\nenables the style mixing capability of our model, i.e. it allows to alter the\nglobal appearance without affecting the semantic layout of an image. Using the\nproposed masked noise encoder to randomize style and content combinations in\nthe training set, ISSA effectively increases the diversity of training data and\nreduces spurious correlation. As a result, we achieve up to $12.4\\%$ mIoU\nimprovements on driving-scene semantic segmentation under different types of\ndata shifts, i.e., changing geographic locations, adverse weather conditions,\nand day to night. ISSA is model-agnostic and straightforwardly applicable with\nCNNs and Transformers. It is also complementary to other domain generalization\ntechniques, e.g., it improves the recent state-of-the-art solution RobustNet by\n$3\\%$ mIoU in Cityscapes to Dark Z\\\"urich.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Yumeng Li",
      "Dan Zhang",
      "Margret Keuper",
      "Anna Khoreva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10175"
  },
  {
    "id": "arXiv:2210.10176",
    "title": "Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual  Question Answering",
    "abstract": "Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a\ntwo-stage framework that first retrieves external knowledge given the visual\nquestion and then predicts the answer based on the retrieved content. However,\nthe retrieved knowledge is often inadequate. Retrievals are frequently too\ngeneral and fail to cover specific knowledge needed to answer the question.\nAlso, the naturally available supervision (whether the passage contains the\ncorrect answer) is weak and does not guarantee question relevancy. To address\nthese issues, we propose an Entity-Focused Retrieval (EnFoRe) model that\nprovides stronger supervision during training and recognizes question-relevant\nentities to help retrieve more specific knowledge. Experiments show that our\nEnFoRe model achieves superior retrieval performance on OK-VQA, the currently\nlargest outside-knowledge VQA dataset. We also combine the retrieved knowledge\nwith state-of-the-art VQA models, and achieve a new state-of-the-art\nperformance on OK-VQA.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Jialin Wu",
      "Raymond J. Mooney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10176"
  },
  {
    "id": "arXiv:2210.10180",
    "title": "Domain Adaptation in 3D Object Detection with Gradual Batch Alternation  Training",
    "abstract": "We consider the problem of domain adaptation in LiDAR-based 3D object\ndetection. Towards this, we propose a simple yet effective training strategy\ncalled Gradual Batch Alternation that can adapt from a large labeled source\ndomain to an insufficiently labeled target domain. The idea is to initiate the\ntraining with the batch of samples from the source and target domain data in an\nalternate fashion, but then gradually reduce the amount of the source domain\ndata over time as the training progresses. This way the model slowly shifts\ntowards the target domain and eventually better adapt to it. The domain\nadaptation experiments for 3D object detection on four benchmark autonomous\ndriving datasets, namely ONCE, PandaSet, Waymo, and nuScenes, demonstrate\nsignificant performance gains over prior arts and strong baselines.",
    "descriptor": "",
    "authors": [
      "Mrigank Rochan",
      "Xingxin Chen",
      "Alaap Grandhi",
      "Eduardo R. Corral-Soto",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10180"
  },
  {
    "id": "arXiv:2210.10181",
    "title": "Comparing Embedded Graphs Using Average Branching Distance",
    "abstract": "Graphs drawn in the plane are ubiquitous, arising from data sets through a\nvariety of methods ranging from GIS analysis to image classification to shape\nanalysis. A fundamental problem in this type of data is comparison: given a set\nof such graphs, can we rank how similar they are, in such a way that we capture\ntheir geometric \"shape\" in the plane? In this paper we explore a method to\ncompare two such embedded graphs, via a simplified combinatorial representation\ncalled a tail-less merge tree which encodes the structure based on a fixed\ndirection. First, we examine the properties of a distance designed to compare\nmerge trees called the branching distance, and show that the distance as\ndefined in previous work fails to satisfy some of the requirements of a metric.\nWe incorporate this into a new distance function called average branching\ndistance to compare graphs by looking at the branching distance for merge trees\ndefined over many directions. Despite the theoretical issues, we show that the\ndefinition is still quite useful in practice by using our open-source code to\ncluster data sets of embedded graphs.",
    "descriptor": "",
    "authors": [
      "Levent Batakci",
      "Abigail Branson",
      "Bryan Castillo",
      "Candace Todd",
      "Erin Wolf Chambers",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.10181"
  },
  {
    "id": "arXiv:2210.10182",
    "title": "Landmark Enforcement and Style Manipulation for Generative Morphing",
    "abstract": "Morph images threaten Facial Recognition Systems (FRS) by presenting as\nmultiple individuals, allowing an adversary to swap identities with another\nsubject. Morph generation using generative adversarial networks (GANs) results\nin high-quality morphs unaffected by the spatial artifacts caused by\nlandmark-based methods, but there is an apparent loss in identity with standard\nGAN-based morphing methods. In this paper, we propose a novel StyleGAN morph\ngeneration technique by introducing a landmark enforcement method to resolve\nthis issue. Considering this method, we aim to enforce the landmarks of the\nmorph image to represent the spatial average of the landmarks of the bona fide\nfaces and subsequently the morph images to inherit the geometric identity of\nboth bona fide faces. Exploration of the latent space of our model is conducted\nusing Principal Component Analysis (PCA) to accentuate the effect of both the\nbona fide faces on the morphed latent representation and address the identity\nloss issue with latent domain averaging. Additionally, to improve high\nfrequency reconstruction in the morphs, we study the train-ability of the noise\ninput for the StyleGAN2 model.",
    "descriptor": "",
    "authors": [
      "Samuel Price",
      "Sobhan Soleymani",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10182"
  },
  {
    "id": "arXiv:2210.10184",
    "title": "High-Dimensional Performance Modeling via Tensor Completion",
    "abstract": "Performance tuning, software/hardware co-design, and job scheduling are among\nthe many tasks that rely on models to predict application performance. We\npropose and evaluate low rank tensor decomposition for modeling application\nperformance. We use tensors to represent regular grids that discretize the\ninput and configuration domain of an application. Application execution times\nmapped within grid-cells are averaged and represented by tensor elements. We\nshow that low-rank canonical-polyadic (CP) tensor decomposition is effective in\napproximating these tensors. We then employ tensor completion to optimize a CP\ndecomposition given a sparse set of observed runtimes. We consider alternative\npiecewise/grid-based (P/G) and supervised learning models for six applications\nand demonstrate that P/G models are significantly more accurate relative to\nmodel size. Among P/G models, CP decomposition of regular grids (CPR) offers\nhigher accuracy and memory-efficiency, faster optimization, and superior\nextensibility via user-selected loss functions and domain partitioning. CPR\nmodels achieve a 2.18x geometric mean decrease in mean prediction error\nrelative to the most accurate alternative models of size $\\le$10 kilobytes.",
    "descriptor": "",
    "authors": [
      "Edward Hutter",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10184"
  },
  {
    "id": "arXiv:2210.10191",
    "title": "Simple and Effective Unsupervised Speech Translation",
    "abstract": "The amount of labeled data to train models for speech tasks is limited for\nmost languages, however, the data scarcity is exacerbated for speech\ntranslation which requires labeled data covering two different languages. To\naddress this issue, we study a simple and effective approach to build speech\ntranslation systems without labeled data by leveraging recent advances in\nunsupervised speech recognition, machine translation and speech synthesis,\neither in a pipeline approach, or to generate pseudo-labels for training\nend-to-end speech translation models. Furthermore, we present an unsupervised\ndomain adaptation technique for pre-trained speech models which improves the\nperformance of downstream unsupervised speech recognition, especially for\nlow-resource settings. Experiments show that unsupervised speech-to-text\ntranslation outperforms the previous unsupervised state of the art by 3.2 BLEU\non the Libri-Trans benchmark, on CoVoST 2, our best systems outperform the best\nsupervised end-to-end models (without pre-training) from only two years ago by\nan average of 5.0 BLEU over five X-En directions. We also report competitive\nresults on MuST-C and CVSS benchmarks.",
    "descriptor": "",
    "authors": [
      "Changhan Wang",
      "Hirofumi Inaguma",
      "Peng-Jen Chen",
      "Ilia Kulikov",
      "Yun Tang",
      "Wei-Ning Hsu",
      "Michael Auli",
      "Juan Pino"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10191"
  },
  {
    "id": "arXiv:2210.10192",
    "title": "Mixed Isogeometric Methods for Linear Elasticity with Weakly Imposed  Symmetry",
    "abstract": "We consider and discretize a mixed formulation for linear elasticity with\nweakly imposed symmetry in two and three dimensions. Whereas existing methods\nmainly deal with simplicial or polygonal meshes, we take advantage of\nisogeometric analysis (IGA) and consequently allow for shapes with curved\nboundaries. To introduce the discrete spaces we use isogeometric discrete\ndifferential forms defined by proper B-spline spaces. For the proposed schemes\na proof of well-posedness and an error estimate are given. Further we discuss\nour ansatz by means of different numerical examples.",
    "descriptor": "",
    "authors": [
      "Jeremias Arf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10192"
  },
  {
    "id": "arXiv:2210.10193",
    "title": "$\u03bb$-MIMO: Massive MIMO via Modulo Sampling",
    "abstract": "Massive multiple-input multiple-output (M-MIMO) architecture is the workhorse\nof modern communication systems. Currently, two fundamental bottlenecks,\nnamely, power consumption and receiver saturation, limit the full potential\nachievement of this technology. These bottlenecks are intricately linked with\nthe analog-to-digital converter (ADC) used in each radio frequency (RF) chain.\nThe power consumption in MIMO systems grows exponentially with the ADC's bit\nbudget while ADC saturation causes permanent loss of information. This\nmotivates the need for a solution that can simultaneously tackle the\nabove-mentioned bottlenecks while offering advantages over existing\nalternatives such as low-resolution ADCs. Taking a radically different approach\nto this problem, we propose $\\lambda$-MIMO architecture which uses modulo ADCs\n($M_\\lambda$-ADC) instead of a conventional ADC. Our work is inspired by the\nUnlimited Sampling Framework. $M_\\lambda$-ADC in the RF chain folds high\ndynamic range signals into low dynamic range modulo samples, thus alleviating\nthe ADC saturation problem. At the same time, digitization of modulo signal\nresults in high resolution quantization. In the novel $\\lambda$-MIMO context,\nwe discuss baseband signal reconstruction, detection and uplink achievable\nsum-rate performance. The key takeaways of our work include, (a) leveraging\nhigher signal-to-quantization noise ratio (SQNR), (b) detection and average\nuplink sum-rate performances comparable to a conventional, infinite-resolution\nADC when using a $1$-$2$ bit $M_\\lambda$-ADC. This enables higher order\nmodulation schemes e.g. $1024$ QAM that seemed previously impossible, (c)\nsuperior trade-off between energy efficiency and bit budget, thus resulting in\nhigher power efficiency. Numerical simulations and modulo ADC based hardware\nexperiments corroborate our theory and reinforce the clear benefits of\n$\\lambda$-MIMO approach.",
    "descriptor": "\nComments: 33 pages, 18 figures, manuscript under submission\n",
    "authors": [
      "Ziang Liu",
      "Ayush Bhandari",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10193"
  },
  {
    "id": "arXiv:2210.10194",
    "title": "Rethinking Prototypical Contrastive Learning through Alignment,  Uniformity and Correlation",
    "abstract": "Contrastive self-supervised learning (CSL) with a prototypical regularization\nhas been introduced in learning meaningful representations for downstream tasks\nthat require strong semantic information. However, to optimize CSL with a loss\nthat performs the prototypical regularization aggressively, e.g., the ProtoNCE\nloss, might cause the \"coagulation\" of examples in the embedding space. That\nis, the intra-prototype diversity of samples collapses to trivial solutions for\ntheir prototype being well-separated from others. Motivated by previous works,\nwe propose to mitigate this phenomenon by learning Prototypical representation\nthrough Alignment, Uniformity and Correlation (PAUC). Specifically, the\nordinary ProtoNCE loss is revised with: (1) an alignment loss that pulls\nembeddings from positive prototypes together; (2) a uniformity loss that\ndistributes the prototypical level features uniformly; (3) a correlation loss\nthat increases the diversity and discriminability between prototypical level\nfeatures. We conduct extensive experiments on various benchmarks where the\nresults demonstrate the effectiveness of our method in improving the quality of\nprototypical contrastive representations. Particularly, in the classification\ndown-stream tasks with linear probes, our proposed method outperforms the\nstate-of-the-art instance-wise and prototypical contrastive learning methods on\nthe ImageNet-100 dataset by 2.96% and the ImageNet-1K dataset by 2.46% under\nthe same settings of batch size and epochs.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Shentong Mo",
      "Zhun Sun",
      "Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10194"
  },
  {
    "id": "arXiv:2210.10195",
    "title": "Curriculum Reinforcement Learning using Optimal Transport via Gradual  Domain Adaptation",
    "abstract": "Curriculum Reinforcement Learning (CRL) aims to create a sequence of tasks,\nstarting from easy ones and gradually learning towards difficult tasks. In this\nwork, we focus on the idea of framing CRL as interpolations between a source\n(auxiliary) and a target task distribution. Although existing studies have\nshown the great potential of this idea, it remains unclear how to formally\nquantify and generate the movement between task distributions. Inspired by the\ninsights from gradual domain adaptation in semi-supervised learning, we create\na natural curriculum by breaking down the potentially large task distributional\nshift in CRL into smaller shifts. We propose GRADIENT, which formulates CRL as\nan optimal transport problem with a tailored distance metric between tasks.\nSpecifically, we generate a sequence of task distributions as a geodesic\ninterpolation (i.e., Wasserstein barycenter) between the source and target\ndistributions. Different from many existing methods, our algorithm considers a\ntask-dependent contextual distance metric and is capable of handling\nnonparametric distributions in both continuous and discrete context settings.\nIn addition, we theoretically show that GRADIENT enables smooth transfer\nbetween subsequent stages in the curriculum under certain conditions. We\nconduct extensive experiments in locomotion and manipulation tasks and show\nthat our proposed GRADIENT achieves higher performance than baselines in terms\nof learning efficiency and asymptotic performance.",
    "descriptor": "",
    "authors": [
      "Peide Huang",
      "Mengdi Xu",
      "Jiacheng Zhu",
      "Laixi Shi",
      "Fei Fang",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10195"
  },
  {
    "id": "arXiv:2210.10196",
    "title": "BirdSoundsDenoising: Deep Visual Audio Denoising for Bird Sounds",
    "abstract": "Audio denoising has been explored for decades using both traditional and deep\nlearning-based methods. However, these methods are still limited to either\nmanually added artificial noise or lower denoised audio quality. To overcome\nthese challenges, we collect a large-scale natural noise bird sound dataset. We\nare the first to transfer the audio denoising problem into an image\nsegmentation problem and propose a deep visual audio denoising (DVAD) model.\nWith a total of 14,120 audio images, we develop an audio ImageMask tool and\npropose to use a few-shot generalization strategy to label these images.\nExtensive experimental results demonstrate that the proposed model achieves\nstate-of-the-art performance. We also show that our method can be easily\ngeneralized to speech denoising, audio separation, audio enhancement, and noise\nestimation.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Youshan Zhang",
      "Jialu Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10196"
  },
  {
    "id": "arXiv:2210.10199",
    "title": "Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic  Reparameterization",
    "abstract": "Optimizing expensive-to-evaluate black-box functions of discrete (and\npotentially continuous) design parameters is a ubiquitous problem in scientific\nand engineering applications. Bayesian optimization (BO) is a popular,\nsample-efficient method that leverages a probabilistic surrogate model and an\nacquisition function (AF) to select promising designs to evaluate. However,\nmaximizing the AF over mixed or high-cardinality discrete search spaces is\nchallenging standard gradient-based methods cannot be used directly or\nevaluating the AF at every point in the search space would be computationally\nprohibitive. To address this issue, we propose using probabilistic\nreparameterization (PR). Instead of directly optimizing the AF over the search\nspace containing discrete parameters, we instead maximize the expectation of\nthe AF over a probability distribution defined by continuous parameters. We\nprove that under suitable reparameterizations, the BO policy that maximizes the\nprobabilistic objective is the same as that which maximizes the AF, and\ntherefore, PR enjoys the same regret bounds as the original BO policy using the\nunderlying AF. Moreover, our approach provably converges to a stationary point\nof the probabilistic objective under gradient ascent using scalable, unbiased\nestimators of both the probabilistic objective and its gradient. Therefore, as\nthe number of starting points and gradient steps increase, our approach will\nrecover of a maximizer of the AF (an often-neglected requisite for commonly\nused BO regret bounds). We validate our approach empirically and demonstrate\nstate-of-the-art optimization performance on a wide range of real-world\napplications. PR is complementary to (and benefits) recent work and naturally\ngeneralizes to settings with multiple objectives and black-box constraints.",
    "descriptor": "\nComments: To appear in Advances in Neural Information Processing Systems 35, 2022. Code available at: this https URL\n",
    "authors": [
      "Samuel Daulton",
      "Xingchen Wan",
      "David Eriksson",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10199"
  },
  {
    "id": "arXiv:2210.10200",
    "title": "Helpful Neighbors: Leveraging Neighbors in Geographic Feature  Pronunciation",
    "abstract": "If one sees the place name Houston Mercer Dog Run in New York, how does one\nknow how to pronounce it? Assuming one knows that Houston in New York is\npronounced \"how-ston\" and not like the Texas city, then one can probably guess\nthat \"how-ston\" is also used in the name of the dog park. We present a novel\narchitecture that learns to use the pronunciations of neighboring names in\norder to guess the pronunciation of a given target feature. Applied to Japanese\nplace names, we demonstrate the utility of the model to finding and proposing\ncorrections for errors in Google Maps.\nTo demonstrate the utility of this approach to structurally similar problems,\nwe also report on an application to a totally different task: Cognate reflex\nprediction in comparative historical linguistics. A version of the code has\nbeen open-sourced\n(https://github.com/google-research/google-research/tree/master/cognate_inpaint_neighbors).",
    "descriptor": "\nComments: 16 pages, to appear Transactions of the Association for Computational Linguistics\n",
    "authors": [
      "Llion Jones",
      "Richard Sproat",
      "Haruko Ishikawa",
      "Alexander Gutkin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10200"
  },
  {
    "id": "arXiv:2210.10202",
    "title": "Planning with SiMBA: Motion Planning under Uncertainty for Temporal  Goals using Simplified Belief Guides",
    "abstract": "This paper presents a new multi-layered algorithm for motion planning under\nmotion and sensing uncertainties for Linear Temporal Logic specifications. We\npropose a technique to guide a sampling-based search tree in the combined task\nand belief space using trajectories from a simplified model of the system, to\nmake the problem computationally tractable. Our method eliminates the need to\nconstruct fine and accurate finite abstractions. We prove correctness and\nprobabilistic completeness of our algorithm, and illustrate the benefits of our\napproach on several case studies. Our results show that guidance with a\nsimplified belief space model allows for significant speed-up in planning for\ncomplex specifications.",
    "descriptor": "\nComments: 8 pages, submitted to IEEE International Conference on Robotics and Automation (ICRA), 2023\n",
    "authors": [
      "Qi Heng Ho",
      "Zachary N. Sunberg",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10202"
  },
  {
    "id": "arXiv:2210.10203",
    "title": "From Model-Based to Model-Free: Learning Building Control for Demand  Response",
    "abstract": "Grid-interactive building control is a challenging and important problem for\nreducing carbon emissions, increasing energy efficiency, and supporting the\nelectric power grid. Currently researchers and practitioners are confronted\nwith a choice of control strategies ranging from model-free (purely\ndata-driven) to model-based (directly incorporating physical knowledge) to\nhybrid methods that combine data and models. In this work, we identify\nstate-of-the-art methods that span this methodological spectrum and evaluate\ntheir performance for multi-zone building HVAC control in the context of three\ndemand response programs. We demonstrate, in this context, that hybrid methods\noffer many benefits over both purely model-free and model-based methods as long\nas certain requirements are met. In particular, hybrid controllers are\nrelatively sample efficient, fast online, and high accuracy so long as the test\ncase falls within the distribution of training data. Like all data-driven\nmethods, hybrid controllers are still subject to generalization errors when\napplied to out-of-sample scenarios. Key takeaways for control strategies are\nsummarized and the developed software framework is open-sourced.",
    "descriptor": "",
    "authors": [
      "David Biagioni",
      "Xiangyu Zhang",
      "Christiane Adcock",
      "Michael Sinner",
      "Peter Graf",
      "Jennifer King"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10203"
  },
  {
    "id": "arXiv:2210.10205",
    "title": "Optimizing Hierarchical Image VAEs for Sample Quality",
    "abstract": "While hierarchical variational autoencoders (VAEs) have achieved great\ndensity estimation on image modeling tasks, samples from their prior tend to\nlook less convincing than models with similar log-likelihood. We attribute this\nto learned representations that over-emphasize compressing imperceptible\ndetails of the image. To address this, we introduce a KL-reweighting strategy\nto control the amount of infor mation in each latent group, and employ a\nGaussian output layer to reduce sharpness in the learning objective. To trade\noff image diversity for fidelity, we additionally introduce a classifier-free\nguidance strategy for hierarchical VAEs. We demonstrate the effectiveness of\nthese techniques in our experiments. Code is available at\nhttps://github.com/tcl9876/visual-vae.",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Eric Luhman",
      "Troy Luhman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10205"
  },
  {
    "id": "arXiv:2210.10207",
    "title": "Exploitability Minimization in Games and Beyond",
    "abstract": "Pseudo-games are a natural and well-known generalization of normal-form\ngames, in which the actions taken by each player affect not only the other\nplayers' payoffs, as in games, but also the other players' strategy sets. The\nsolution concept par excellence for pseudo-games is the generalized Nash\nequilibrium (GNE), i.e., a strategy profile at which each player's strategy is\nfeasible and no player can improve their payoffs by unilaterally deviating to\nanother strategy in the strategy set determined by the other players'\nstrategies. The computation of GNE in pseudo-games has long been a problem of\ninterest, due to applications in a wide variety of fields, from environmental\nprotection to logistics to telecommunications. Although computing GNE is\nPPAD-hard in general, it is still of interest to try to compute them in\nrestricted classes of pseudo-games. One approach is to search for a strategy\nprofile that minimizes exploitability, i.e., the sum of the regrets across all\nplayers. As exploitability is nondifferentiable in general, developing\nefficient first-order methods that minimize it might not seem possible at first\nglance. We observe, however, that the exploitability-minimization problem can\nbe recast as a min-max optimization problem, and thereby obtain polynomial-time\nfirst-order methods to compute a refinement of GNE, namely the variational\nequilibria (VE), in convex-concave cumulative regret pseudo-games with jointly\nconvex constraints. More generally, we also show that our methods find the\nstationary points of the exploitability in polynomial time in Lipschitz-smooth\npseudo-games with jointly convex constraints. Finally, we demonstrate in\nexperiments that our methods not only outperform known algorithms, but that\neven in pseudo-games where they are not guaranteed to converge to a GNE, they\nmay do so nonetheless, with proper initialization.",
    "descriptor": "",
    "authors": [
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10207"
  },
  {
    "id": "arXiv:2210.10209",
    "title": "Exclusive Supermask Subnetwork Training for Continual Learning",
    "abstract": "Continual Learning (CL) methods mainly focus on avoiding catastrophic\nforgetting and learning representations that are transferable to new tasks.\nRecently, Wortsman et al. (2020) proposed a CL method, SupSup, which uses a\nrandomly initialized, fixed base network (model) and finds a supermask for each\nnew task that selectively keeps or removes each weight to produce a subnetwork.\nThey prevent forgetting as the network weights are not being updated. Although\nthere is no forgetting, the performance of the supermask is sub-optimal because\nfixed weights restrict its representational power. Furthermore, there is no\naccumulation or transfer of knowledge inside the model when new tasks are\nlearned. Hence, we propose ExSSNeT (Exclusive Supermask SubNEtwork Training),\nwhich performs exclusive and non-overlapping subnetwork weight training. This\navoids conflicting updates to the shared weights by subsequent tasks to improve\nperformance while still preventing forgetting. Furthermore, we propose a novel\nKNN-based Knowledge Transfer (KKT) module that dynamically initializes a new\ntask's mask based on previous tasks for improving knowledge transfer. We\ndemonstrate that ExSSNeT outperforms SupSup and other strong previous methods\non both text classification and vision tasks while preventing forgetting.\nMoreover, ExSSNeT is particularly advantageous for sparse masks that activate\n2-10% of the model parameters, resulting in an average improvement of 8.3% over\nSupSup. Additionally, ExSSNeT scales to a large number of tasks (100), and our\nKKT module helps to learn new tasks faster while improving overall performance.\nOur code is available at https://github.com/prateeky2806/exessnet",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Prateek Yadav",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10209"
  },
  {
    "id": "arXiv:2210.10211",
    "title": "A Catch-22 of Reservoir Computing",
    "abstract": "Reservoir Computing (RC) is a simple and efficient model-free framework for\ndata-driven predictions of nonlinear dynamical systems. Recently, Next\nGeneration Reservoir Computing (NGRC) has emerged as an especially attractive\nvariant of RC. By shifting the nonlinearity from the reservoir to the readout\nlayer, NGRC requires less data and has fewer hyperparameters to optimize,\nmaking it suitable for challenging tasks such as predicting basins of\nattraction. Here, using paradigmatic multistable systems including magnetic\npendulums and coupled Kuramoto oscillators, we show that the performance of\nNGRC models can be extremely sensitive to the choice of readout nonlinearity.\nIn particular, by incorporating the exact nonlinearity from the original\nequations, NGRC trained on a single trajectory can predict pseudo-fractal\nbasins with almost perfect accuracy. However, even a small uncertainty on the\nexact nonlinearity can completely break NGRC, rendering the prediction accuracy\nno better than chance. This creates a catch-22 for NGRC since it may not be\nable to make useful predictions unless a key part of the system being predicted\n(i.e., its nonlinearity) is already known. Our results highlight the challenges\nfaced by data-driven methods in learning complex dynamical systems.",
    "descriptor": "\nComments: Comments welcome. Our code can be found at this https URL\n",
    "authors": [
      "Yuanzhao Zhang",
      "Sean P. Cornelius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2210.10211"
  },
  {
    "id": "arXiv:2210.10221",
    "title": "Non-iterative optimization of pseudo-labeling thresholds for training  object detection models from multiple datasets",
    "abstract": "We propose a non-iterative method to optimize pseudo-labeling thresholds for\nlearning object detection from a collection of low-cost datasets, each of which\nis annotated for only a subset of all the object classes. A popular approach to\nthis problem is first to train teacher models and then to use their confident\npredictions as pseudo ground-truth labels when training a student model. To\nobtain the best result, however, thresholds for prediction confidence must be\nadjusted. This process typically involves iterative search and repeated\ntraining of student models and is time-consuming. Therefore, we develop a\nmethod to optimize the thresholds without iterative optimization by maximizing\nthe $F_\\beta$-score on a validation dataset, which measures the quality of\npseudo labels and can be measured without training a student model. We\nexperimentally demonstrate that our proposed method achieves an mAP comparable\nto that of grid search on the COCO and VOC datasets.",
    "descriptor": "\nComments: ICIP2022\n",
    "authors": [
      "Yuki Tanaka",
      "Shuhei M. Yoshida",
      "Makoto Terao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10221"
  },
  {
    "id": "arXiv:2210.10223",
    "title": "Identifying the Impact of User Reviews on App Updates: An Exploratory  Study on App Release Notes",
    "abstract": "Release planning for mobile apps has recently become an area of active\nresearch. Prior research concentrated on app analysis based on app release\nnotes in App Store, or tracking user reviews to support app evolution with\nissue trackers. However, as a platform for development teams to communicate\nwith users, Apple Store has not been studied for detecting the relevance\nbetween release notes and user reviews. In this paper, we introduce\nRoseMatcher, an automatic approach to match relevant user reviews with app\nrelease notes, and identify matched pairs with high confidence. We collected\n944 release notes and 1,046,862 user reviews from 5 mobile apps in the Apple\nApp Store as research data, and evaluated the effectiveness and accuracy of\nRoseMatcher. Our evaluation shows that RoseMatcher can reach a hit ratio of\n0.718 for identifying relevant matched pairs. We further conducted manual\nlabelling and content analysis on 984 relevant matched pairs, and defined 8\nroles user reviews play in app update according to the relationship between\nrelease notes and user reviews in the relevant matched pairs. The study results\nshow that release notes tend to respond and solve feature requests, bug\nreports, and complaints raised in user reviews, while user reviews also tend to\ngive positive, negative, and constructive feedback on app updates.\nAdditionally, in the time dimension, the relevant reviews of release notes tend\nto be posed in a small period of time before and after the release of release\nnotes. In the matched pairs, the time interval between the post time of release\nnotes and user reviews reaches a maximum of three years and an average of one\nyear. These findings indicate that the development teams do adopt user reviews\nwhen updating apps, and users show their interest in app release notes.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Tianyang Liu",
      "Chong Wang",
      "Kun Huang",
      "Peng Liang",
      "Beiqi Zhang",
      "Maya Daneva"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.10223"
  },
  {
    "id": "arXiv:2210.10225",
    "title": "Model Predictive Vehicle Yaw Stability Control via Integrated Active  Front Wheel Steering and Individual Braking",
    "abstract": "Vehicle stability control systems are important components of active safety\nsystems for road transport. The problem of vehicle lateral stability control is\naddressed in this paper using active front wheel steering and individual\nbraking. Vehicle lateral stability control means keeping the vehicle yaw rate\nand the vehicle side slip angle in desired values. For this reason, a\nmodel-based controller is designed. The desired yaw rate is obtained from the\nsingle track vehicle model and the desired side slip angle is chosen as zero.\nController design consists of two parts, lower and upper controller parts.\nUpper controller is designed based on Model Predictive Control (MPC) method.\nThis upper controller changes front wheel steering angles utilizing\nsteer-by-wire system and also it generates the required control moment for\nstabilizing the yaw motion of the vehicle. Lower controller is an individual\nbraking algorithm. It determines the individual braking wheel. In this way, the\ncontrol moment can be applied to the vehicle. The designed controller is tested\nusing the nonlinear single track vehicle model and the higher fidelity CarMaker\nvehicle model.",
    "descriptor": "",
    "authors": [
      "Mumin Tolga Emirler",
      "Bilin Aksun Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10225"
  },
  {
    "id": "arXiv:2210.10226",
    "title": "A Real-Time Wrong-Way Vehicle Detection Based on YOLO and Centroid  Tracking",
    "abstract": "Wrong-way driving is one of the main causes of road accidents and traffic jam\nall over the world. By detecting wrong-way vehicles, the number of accidents\ncan be minimized and traffic jam can be reduced. With the increasing popularity\nof real-time traffic management systems and due to the availability of cheaper\ncameras, the surveillance video has become a big source of data. In this paper,\nwe propose an automatic wrong-way vehicle detection system from on-road\nsurveillance camera footage. Our system works in three stages: the detection of\nvehicles from the video frame by using the You Only Look Once (YOLO) algorithm,\ntrack each vehicle in a specified region of interest using centroid tracking\nalgorithm and detect the wrong-way driving vehicles. YOLO is very accurate in\nobject detection and the centroid tracking algorithm can track any moving\nobject efficiently. Experiment with some traffic videos shows that our proposed\nsystem can detect and identify any wrong-way vehicle in different light and\nweather conditions. The system is very simple and easy to implement.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Zillur Rahman",
      "Amit Mazumder Ami",
      "Muhammad Ahsan Ullah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10226"
  },
  {
    "id": "arXiv:2210.10227",
    "title": "Explainable Slot Type Attentions to Improve Joint Intent Detection and  Slot Filling",
    "abstract": "Joint intent detection and slot filling is a key research topic in natural\nlanguage understanding (NLU). Existing joint intent and slot filling systems\nanalyze and compute features collectively for all slot types, and importantly,\nhave no way to explain the slot filling model decisions. In this work, we\npropose a novel approach that: (i) learns to generate additional slot type\nspecific features in order to improve accuracy and (ii) provides explanations\nfor slot filling decisions for the first time in a joint NLU model. We perform\nan additional constrained supervision using a set of binary classifiers for the\nslot type specific feature learning, thus ensuring appropriate attention\nweights are learned in the process to explain slot filling decisions for\nutterances. Our model is inherently explainable and does not need any post-hoc\nprocessing. We evaluate our approach on two widely used datasets and show\naccuracy improvements. Moreover, a detailed analysis is also provided for the\nexclusive slot explainability.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Kalpa Gunaratna",
      "Vijay Srinivasan",
      "Akhila Yerukola",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10227"
  },
  {
    "id": "arXiv:2210.10231",
    "title": "Speaker- and Age-Invariant Training for Child Acoustic Modeling Using  Adversarial Multi-Task Learning",
    "abstract": "One of the major challenges in acoustic modelling of child speech is the\nrapid changes that occur in the children's articulators as they grow up, their\ndiffering growth rates and the subsequent high variability in the same age\ngroup. These high acoustic variations along with the scarcity of child speech\ncorpora have impeded the development of a reliable speech recognition system\nfor children. In this paper, a speaker- and age-invariant training approach\nbased on adversarial multi-task learning is proposed. The system consists of\none generator shared network that learns to generate speaker- and age-invariant\nfeatures connected to three discrimination networks, for phoneme, age, and\nspeaker. The generator network is trained to minimize the\nphoneme-discrimination loss and maximize the speaker- and age-discrimination\nlosses in an adversarial multi-task learning fashion. The generator network is\na Time Delay Neural Network (TDNN) architecture while the three discriminators\nare feed-forward networks. The system was applied to the OGI speech corpora and\nachieved a 13% reduction in the WER of the ASR.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Mostafa Shahin",
      "Beena Ahmed",
      "Julien Epps"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10231"
  },
  {
    "id": "arXiv:2210.10232",
    "title": "Application of Decision Tree Classifier in Detection of Specific Denial  of Service Attacks with Genetic Algorithm Based Feature Selection on NSL-KDD",
    "abstract": "Using a Genetic Algorithm and Decision Tree Classifier, the features of the\nNSL-KDD dataset are reduced using combinatorial optimization to determine the\nminimum features required to accurately classify Denial of Service attacks\nwithin the NSL-KDD dataset.",
    "descriptor": "\nComments: 6 pages, 1 figure, 10 tables\n",
    "authors": [
      "Deanna Wilborne"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.10232"
  },
  {
    "id": "arXiv:2210.10233",
    "title": "Vision-Based Lane Detection and Tracking under Different Challenging  Environmental Conditions",
    "abstract": "Driving is very challenging when the visibility of a road lane marking is\nlow, obscured or often invisible due to abrupt environmental change which may\nlead to severe vehicle clash. A large volume of research has been done on lane\nmarking detection. Most of the lane detection methods suffer from four types of\nmajor problems: (i) abrupt illumination change due to change in time (day,\nnight), weather, road, etc.; (ii) lane markings get obscured partially or fully\nwhen they are colored, eroded or occluded; (iii) blurred view created by\nadverse weather like rain or snow; and (iv) incorrect lane detection due to\npresence of other lookalike lines e.g. guardrails, pavement marking, road\ndivider, vehicle lines, the shadow of trees, etc. In this paper, we proposed a\nrobust lane detection and tracking method to detect lane marking considering\nthe abovementioned challenging conditions. In this method, we introduced three\nkey technologies. First, the bilateral filter is applied to smooth and preserve\nthe edges and we introduced an optimized intensity threshold range (OITR) to\nimprove the performance of the canny operator which detects the edges of low\nintensity (colored, eroded, or blurred) lane markings. Second, we proposed a\nrobust lane verification technique, the angle and length-based geometric\nconstraint (ALGC) algorithm followed by Hough Transform, to verify the\ncharacteristics of lane marking and to prevent incorrect lane detection.\nFinally, a novel lane tracking technique, the horizontally adjustable lane\nrepositioning range (HALRR) algorithm is proposed, which can keep track of the\nlane position. To evaluate the performance of the proposed method we used the\nDSDLDE dataset with 1080x1920 resolutions at 24 frames/sec. Experimental\nresults show that the average detection rate is 97.36%, and the average\ndetection time is 29.06msec per frame, which outperformed the state-of-the-art\nmethod.",
    "descriptor": "\nComments: 19 pages, 10 figures, submitted to Remote Sensing(Journal)\n",
    "authors": [
      "Samia Sultana",
      "Boshir Ahmed",
      "Manoranjan Paul",
      "Muhammad Rafiqul Islam",
      "Shamim Ahmad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10233"
  },
  {
    "id": "arXiv:2210.10238",
    "title": "Towards Exact Interaction Force Control for Underactuated Quadrupedal  Systems with Orthogonal Projection and Quadratic Programming",
    "abstract": "Projected Inverse Dynamics Control (PIDC) is commonly used in robots subject\nto contact, especially in quadrupedal systems. Many methods based on such\ndynamics have been developed for quadrupedal locomotion tasks, and only a few\nworks studied simple interactions between the robot and environment, such as\npressing an E-stop button. To facilitate the interaction requiring exact force\ncontrol for safety, we propose a novel interaction force control scheme for\nunderactuated quadrupedal systems relying on projection techniques and\nQuadratic Programming (QP). This algorithm allows the robot to apply a desired\ninteraction force to the environment without using force sensors while\nsatisfying physical constraints and inducing minimal base motion. Unlike\nprevious projection-based methods, the QP design uses two selection matrices in\nits hierarchical structure, facilitating the decoupling between force and\nmotion control. The proposed algorithm is verified with a quadrupedal robot in\na high-fidelity simulator. Compared to the QP designs without the strategy of\nusing two selection matrices and the PIDC method for contact force control, our\nmethod provided more accurate contact force tracking performance with minimal\nbase movement, paving the way to approach the exact interaction force control\nfor underactuated quadrupedal systems.",
    "descriptor": "\nComments: 7 pages, 4 figures, submitted to 2023 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Shengzhi Wang",
      "Xiangyu Chu",
      "K. W. Samuel Au"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10238"
  },
  {
    "id": "arXiv:2210.10239",
    "title": "GSV-Cities: Toward Appropriate Supervised Visual Place Recognition",
    "abstract": "This paper aims to investigate representation learning for large scale visual\nplace recognition, which consists of determining the location depicted in a\nquery image by referring to a database of reference images. This is a\nchallenging task due to the large-scale environmental changes that can occur\nover time (i.e., weather, illumination, season, traffic, occlusion). Progress\nis currently challenged by the lack of large databases with accurate ground\ntruth. To address this challenge, we introduce GSV-Cities, a new image dataset\nproviding the widest geographic coverage to date with highly accurate ground\ntruth, covering more than 40 cities across all continents over a 14-year\nperiod. We subsequently explore the full potential of recent advances in deep\nmetric learning to train networks specifically for place recognition, and\nevaluate how different loss functions influence performance. In addition, we\nshow that performance of existing methods substantially improves when trained\non GSV-Cities. Finally, we introduce a new fully convolutional aggregation\nlayer that outperforms existing techniques, including GeM, NetVLAD and\nCosPlace, and establish a new state-of-the-art on large-scale benchmarks, such\nas Pittsburgh, Mapillary-SLS, SPED and Nordland. The dataset and code are\navailable for research purposes at https://github.com/amaralibey/gsv-cities.",
    "descriptor": "\nComments: Neurocomputing 2022\n",
    "authors": [
      "Amar Ali-bey",
      "Brahim Chaib-draa",
      "Philippe Gigu\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10239"
  },
  {
    "id": "arXiv:2210.10240",
    "title": "Type-supervised sequence labeling based on the heterogeneous star graph  for named entity recognition",
    "abstract": "Named entity recognition is a fundamental task in natural language\nprocessing, identifying the span and category of entities in unstructured\ntexts. The traditional sequence labeling methodology ignores the nested\nentities, i.e. entities included in other entity mentions. Many approaches\nattempt to address this scenario, most of which rely on complex structures or\nhave high computation complexity. The representation learning of the\nheterogeneous star graph containing text nodes and type nodes is investigated\nin this paper. In addition, we revise the graph attention mechanism into a\nhybrid form to address its unreasonableness in specific topologies. The model\nperforms the type-supervised sequence labeling after updating nodes in the\ngraph. The annotation scheme is an extension of the single-layer sequence\nlabeling and is able to cope with the vast majority of nested entities.\nExtensive experiments on public NER datasets reveal the effectiveness of our\nmodel in extracting both flat and nested entities. The method achieved\nstate-of-the-art performance on both flat and nested datasets. The significant\nimprovement in accuracy reflects the superiority of the multi-layer labeling\nstrategy.",
    "descriptor": "",
    "authors": [
      "Xueru Wen",
      "Changjiang Zhou",
      "Haotian Tang",
      "Luguang Liang",
      "Yu Jiang",
      "Hong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10240"
  },
  {
    "id": "arXiv:2210.10241",
    "title": "Delay Alignment Modulation for Multi-IRS Aided Wideband Communication",
    "abstract": "Delay alignment modulation (DAM) is a promising technology to achieve\nISI-free wideband communication, by leveraging delay compensation and\npath-based beamforming, rather than the conventional channel equalization or\nmulti-carrier transmission. In particular, when there exist a few strong\ntime-dispersive channel paths, DAM can effectively align different propagation\ndelays and achieve their constructive superposition, thus especially appealing\nfor intelligent reflecting surfaces (IRSs)-aided communications with\ncontrollable multi-paths. In this paper, we apply DAM to multi-IRS aided\nwideband communication and study its practical design and achievable\nperformance. We first provide an asymptotic analysis showing that when the\nnumber of base station (BS) antennas is much larger than that of IRSs, an\nISI-free channel can be established with appropriate delay pre-compensation and\nthe simple path-based MRT beamforming. We then consider the general system\nsetup and study the problem of joint path-based beamforming and phase shifts\ndesign for DAM transmission, by considering the three classical beamforming\ntechniques on a per-path basis, namely the low-complexity path-based MRT\nbeamforming, the path-based ZF beamforming for ISI-free DAM communication, and\nthe optimal path-based MMSE beamforming. As a comparison, OFDM-based multi-IRS\naided communication is considered. Simulation results demonstrate that DAM\noutperforms OFDM in terms of spectral efficiency, BER, and PAPR.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Haiquan Lu",
      "Yong Zeng",
      "Shi Jin",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10241"
  },
  {
    "id": "arXiv:2210.10243",
    "title": "CLUTR: Curriculum Learning via Unsupervised Task Representation Learning",
    "abstract": "Reinforcement Learning (RL) algorithms are often known for sample\ninefficiency and difficult generalization. Recently, Unsupervised Environment\nDesign (UED) emerged as a new paradigm for zero-shot generalization by\nsimultaneously learning a task distribution and agent policies on the sampled\ntasks. This is a non-stationary process where the task distribution evolves\nalong with agent policies, creating an instability over time. While past works\ndemonstrated the potential of such approaches, sampling effectively from the\ntask space remains an open challenge, bottlenecking these approaches. To this\nend, we introduce CLUTR: a novel curriculum learning algorithm that decouples\ntask representation and curriculum learning into a two-stage optimization. It\nfirst trains a recurrent variational autoencoder on randomly generated tasks to\nlearn a latent task manifold. Next, a teacher agent creates a curriculum by\nmaximizing a minimax REGRET-based objective on a set of latent tasks sampled\nfrom this manifold. By keeping the task manifold fixed, we show that CLUTR\nsuccessfully overcomes the non-stationarity problem and improves stability. Our\nexperimental results show CLUTR outperforms PAIRED, a principled and popular\nUED method, in terms of generalization and sample efficiency in the challenging\nCarRacing and navigation environments: showing an 18x improvement on the F1\nCarRacing benchmark. CLUTR also performs comparably to the non-UED\nstate-of-the-art for CarRacing, outperforming it in nine of the 20 tracks.\nCLUTR also achieves a 33% higher solved rate than PAIRED on a set of 18\nout-of-distribution navigation tasks.",
    "descriptor": "\nComments: Preprint, Currently Under Review\n",
    "authors": [
      "Abdus Salam Azad",
      "Izzeddin Gur",
      "Aleksandra Faust",
      "Pieter Abbeel",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10243"
  },
  {
    "id": "arXiv:2210.10244",
    "title": "Prove You Owned Me: One Step beyond RFID Tag/Mutual Authentication",
    "abstract": "Radio Frequency Identification (RFID) is a key technology used in many\napplications. In the past decades, plenty of secure and privacy-preserving RFID\ntag/mutual authentication protocols as well as formal frameworks for evaluating\nthem have been proposed. However, we notice that a property, namely proof of\npossession (PoP), has not been rigorously studied till now, despite it has\nsignificant value in many RFID applications. For example, in RFID-enabled\nsupply chains, PoP helps prevent dis-honest parties from publishing information\nabout products/tags that they actually have never processed.\nWe propose the first formal framework for RFID tag/mutual authentication with\nPoP after correcting deficiencies of some existing RFID formal frameworks. We\nprovide a generic construction to transform an RFID tag/mutual authentication\nprotocol to one that supports PoP using a cryptographic hash function, a\npseudorandom function (PRF) and a signature scheme. We prove that the\nconstructed protocol is secure and privacy-preserving under our framework if\nall the building blocks possess desired security properties. Finally, we show\nan RFID mutual authentication protocol with PoP. Arming tag/mutual\nauthentication protocols with PoP is an important step to strengthen\nRFID-enabled systems as it bridges the security gap between physical layer and\ndata layer, and reduces the misuses of RFID-related data.",
    "descriptor": "",
    "authors": [
      "Shaoying Cai",
      "Yingjiu Li",
      "Changshe Ma",
      "Sherman S. M. Chow",
      "Robert H. Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10244"
  },
  {
    "id": "arXiv:2210.10246",
    "title": "Tempo: Accelerating Transformer-Based Model Training through Memory  Footprint Reduction",
    "abstract": "Training deep learning models can be computationally expensive. Prior works\nhave shown that increasing the batch size can potentially lead to better\noverall throughput. However, the batch size is frequently limited by the\naccelerator memory capacity due to the activations/feature maps stored for the\ntraining backward pass, as larger batch sizes require larger feature maps to be\nstored. Transformer-based models, which have recently seen a surge in\npopularity due to their good performance and applicability to a variety of\ntasks, have a similar problem. To remedy this issue, we propose Tempo, a new\napproach to efficiently use accelerator (e.g., GPU) memory resources for\ntraining Transformer-based models. Our approach provides drop-in replacements\nfor the GELU, LayerNorm, and Attention layers, reducing the memory usage and\nultimately leading to more efficient training. We implement Tempo and evaluate\nthe throughput, memory usage, and accuracy/loss on the BERT Large pre-training\ntask. We demonstrate that Tempo enables up to 2x higher batch sizes and 16%\nhigher training throughput over the state-of-the-art baseline. We also evaluate\nTempo on GPT2 and RoBERTa models, showing 19% and 26% speedup over the\nbaseline.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Muralidhar Andoorveedu",
      "Zhanda Zhu",
      "Bojian Zheng",
      "Gennady Pekhimenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.10246"
  },
  {
    "id": "arXiv:2210.10247",
    "title": "Performance of different machine learning methods on activity  recognition and pose estimation datasets",
    "abstract": "With advancements in computer vision taking place day by day, recently a lot\nof light is being shed on activity recognition. With the range for real-world\napplications utilizing this field of study increasing across a multitude of\nindustries such as security and healthcare, it becomes crucial for businesses\nto distinguish which machine learning methods perform better than others in the\narea. This paper strives to aid in this predicament i.e. building upon previous\nrelated work, it employs both classical and ensemble approaches on rich pose\nestimation (OpenPose) and HAR datasets. Making use of appropriate metrics to\nevaluate the performance for each model, the results show that overall, random\nforest yields the highest accuracy in classifying ADLs. Relatively all the\nmodels have excellent performance across both datasets, except for logistic\nregression and AdaBoost perform poorly in the HAR one. With the limitations of\nthis paper also discussed in the end, the scope for further research is vast,\nwhich can use this paper as a base in aims of producing better results.",
    "descriptor": "\nComments: 14\n",
    "authors": [
      "Love Trivedi",
      "Raviit Vij"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10247"
  },
  {
    "id": "arXiv:2210.10249",
    "title": "Discovering Limitations of Image Quality Assessments with Noised Deep  Learning Image Sets",
    "abstract": "Image quality is important, and it can affect overall performance in image\nprocessing and computer vision as well as for numerous other reasons. Image\nquality assessment (IQA) is consequently a vital task in different applications\nfrom aerial photography interpretation to object detection to medical image\nanalysis. In previous research, the BRISQUE algorithm and the PSNR algorithm\nwere evaluated with high resolution ( 512*384 pixels per image), but relatively\nsmall image sets (4,744 images). However, scientists have not evaluated IQA\nalgorithms on low resolution (32*32 pixels per image), multi-perturbation, big\nimage sets (for example, 60,000 different images not counting their\nperturbations). This study explores these two IQA algorithms through\nexperimental investigation. We first chose two deep learning image sets,\nCIFAR-10 and MNIST. Then, we added 68 perturbations that add noise to the\nimages in specific sequences and noise intensities. In addition, we tracked the\nperformance outputs of the two IQA algorithms with singly and multiply noised\nimages. After quantitatively analyzing experimental results, we report the\nlimitations of the two IQAs with these noised CIFAR-10 and MNIST image sets. We\nalso explain three potential root causes for performance degradation. These\nfindings point out weaknesses of the two IQA algorithms. The research results\nprovide guidance to scientists and engineers developing accurate, robust IQA\nalgorithms. In addition to supporting future scientific research and industrial\nprojects, all source codes are shared on the website:\nhttps://github.com/caperock/imagequality",
    "descriptor": "\nComments: 10 pages, 11 figures, 10 tables\n",
    "authors": [
      "Wei Dai",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10249"
  },
  {
    "id": "arXiv:2210.10250",
    "title": "Aging Channel Modeling and Transmission Block Size Optimization for  Massive MIMO Vehicular Networks in Non-Isotropic Scattering Environment",
    "abstract": "We investigate the effect of channel aging on multi-cell massive\nmultiple-input multiple-output (MIMO) vehicular networks in a generic\nnon-isotropic scattering environment. Based on the single cluster scattering\nassumption and the von Mises distribution assumptions of the scatterers'\nangles, an aging channel model is established to capture the joint effect of\nspatial and temporal correlations resulting from different angular spread\nconditions in various application scenarios. Expressions of the user uplink\ntransmission spectral efficiency (SE) are derived for maximum ratio (MR) and\nminimum mean square error (MMSE) combining. Through numerical studies, the area\nspectral efficiency (ASE) performance of the network is evaluated in freeway\nand urban Manhattan road grid scenarios, and easy-to-use empirical models for\nthe optimal transmission block size for ASE maximization are obtained for the\nevaluated scenarios.",
    "descriptor": "",
    "authors": [
      "Huafu Li",
      "Liqin Ding",
      "Yang Wang",
      "Zhenyong Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10250"
  },
  {
    "id": "arXiv:2210.10251",
    "title": "NDN-TR70 -- Utilizing NDN-DPDK for Kubernetes Genomics Data Lake",
    "abstract": "As the growth of genomics samples rapidly expands due to increased access to\nhigh resolution DNA sequencing technology, the need for a scalable platform to\naggregate dispersed datasets enable easy access to the vast wealth of DNA\nsequences available is paramount. In this work, we introduce and demonstrate a\nnovel way to use Named Data Networking (NDN) in conjunction with a Kubernetes\ncluster to design a flexible and scalable genomics Data Lake in the cloud. In\naddition, the use of the NDN Data Plane Development Kit (DPDK) provides an\nefficient and accessible distribution of the datasets to researchers anywhere.\nThis report will explain the need to deploy a Data Lake for genomics data, what\nis necessary to deploy successfully, and detailed instructions to replicate the\nproposed design. Finally, this technical report outlines future enhancement\noptions for further improvements.",
    "descriptor": "",
    "authors": [
      "Sankalpa Timilsina",
      "Justin Presley",
      "David Reddick",
      "Susmit Shannigrahi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.10251"
  },
  {
    "id": "arXiv:2210.10252",
    "title": "A Data-Driven Investigation of Noise-Adaptive Utterance Generation with  Linguistic Modification",
    "abstract": "In noisy environments, speech can be hard to understand for humans. Spoken\ndialog systems can help to enhance the intelligibility of their output, either\nby modifying the speech synthesis (e.g., imitate Lombard speech) or by\noptimizing the language generation. We here focus on the second type of\napproach, by which an intended message is realized with words that are more\nintelligible in a specific noisy environment. By conducting a speech perception\nexperiment, we created a dataset of 900 paraphrases in babble noise, perceived\nby native English speakers with normal hearing. We find that careful selection\nof paraphrases can improve intelligibility by 33% at SNR -5 dB. Our analysis of\nthe data shows that the intelligibility differences between paraphrases are\nmainly driven by noise-robust acoustic cues. Furthermore, we propose an\nintelligibility-aware paraphrase ranking model, which outperforms baseline\nmodels with a relative improvement of 31.37% at SNR -5 dB.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Anupama Chingacham",
      "Vera Demberg",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10252"
  },
  {
    "id": "arXiv:2210.10253",
    "title": "On the Adversarial Robustness of Mixture of Experts",
    "abstract": "Adversarial robustness is a key desirable property of neural networks. It has\nbeen empirically shown to be affected by their sizes, with larger networks\nbeing typically more robust. Recently, Bubeck and Sellke proved a lower bound\non the Lipschitz constant of functions that fit the training data in terms of\ntheir number of parameters. This raises an interesting open question, do -- and\ncan -- functions with more parameters, but not necessarily more computational\ncost, have better robustness? We study this question for sparse Mixture of\nExpert models (MoEs), that make it possible to scale up the model size for a\nroughly constant computational cost. We theoretically show that under certain\nconditions on the routing and the structure of the data, MoEs can have\nsignificantly smaller Lipschitz constants than their dense counterparts. The\nrobustness of MoEs can suffer when the highest weighted experts for an input\nimplement sufficiently different functions. We next empirically evaluate the\nrobustness of MoEs on ImageNet using adversarial attacks and show they are\nindeed more robust than dense models with the same computational cost. We make\nkey observations showing the robustness of MoEs to the choice of experts,\nhighlighting the redundancy of experts in models trained in practice.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Joan Puigcerver",
      "Rodolphe Jenatton",
      "Carlos Riquelme",
      "Pranjal Awasthi",
      "Srinadh Bhojanapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10253"
  },
  {
    "id": "arXiv:2210.10254",
    "title": "Safe Planning in Dynamic Environments using Conformal Prediction",
    "abstract": "We propose a framework for planning in unknown dynamic environments with\nprobabilistic safety guarantees using conformal prediction. Particularly, we\ndesign a model predictive controller (MPC) that uses i) trajectory predictions\nof the dynamic environment, and ii) prediction regions quantifying the\nuncertainty of the predictions. To obtain prediction regions, we use conformal\nprediction, a statistical tool for uncertainty quantification, that requires\navailability of offline trajectory data - a reasonable assumption in many\napplications such as autonomous driving. The prediction regions are valid,\ni.e., they hold with a user-defined probability, so that the MPC is provably\nsafe. We illustrate the results in the self-driving car simulator CARLA at a\npedestrian-filled intersection. The strength of our approach is compatibility\nwith state of the art trajectory predictors, e.g., RNNs and LSTMs, while making\nno assumptions on the underlying trajectory-generating distribution. To the\nbest of our knowledge, these are the first results that provide valid safety\nguarantees in such a setting.",
    "descriptor": "",
    "authors": [
      "Lars Lindemann",
      "Matthew Cleaveland",
      "Gihyun Shim",
      "George J. Pappas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10254"
  },
  {
    "id": "arXiv:2210.10256",
    "title": "Causal Structure Learning with Recommendation System",
    "abstract": "A fundamental challenge of recommendation systems (RS) is understanding the\ncausal dynamics underlying users' decision making. Most existing literature\naddresses this problem by using causal structures inferred from domain\nknowledge. However, there are numerous phenomenons where domain knowledge is\ninsufficient, and the causal mechanisms must be learnt from the feedback data.\nDiscovering the causal mechanism from RS feedback data is both novel and\nchallenging, since RS itself is a source of intervention that can influence\nboth the users' exposure and their willingness to interact. Also for this\nreason, most existing solutions become inappropriate since they require data\ncollected free from any RS. In this paper, we first formulate the underlying\ncausal mechanism as a causal structural model and describe a general causal\nstructure learning framework grounded in the real-world working mechanism of\nRS. The essence of our approach is to acknowledge the unknown nature of RS\nintervention. We then derive the learning objective from our framework and\npropose an augmented Lagrangian solver for efficient optimization. We conduct\nboth simulation and real-world experiments to demonstrate how our approach\ncompares favorably to existing solutions, together with the empirical analysis\nfrom sensitivity and ablation studies.",
    "descriptor": "",
    "authors": [
      "Shuyuan Xu",
      "Da Xu",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Stephen Guo",
      "Kannan Achan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10256"
  },
  {
    "id": "arXiv:2210.10258",
    "title": "Continued Pretraining for Better Zero- and Few-Shot Promptability",
    "abstract": "Recently introduced language model prompting methods can achieve high\naccuracy in zero- and few-shot settings while requiring few to no learned\ntask-specific parameters. Nevertheless, these methods still often trail behind\nfull model finetuning. In this work, we investigate if a dedicated continued\npretraining stage could improve \"promptability\", i.e., zero-shot performance\nwith natural language prompts or few-shot performance with prompt tuning. We\nreveal settings where existing continued pretraining methods lack\npromptability. We also identify current methodological gaps, which we fill with\nthorough large-scale experiments. We demonstrate that a simple recipe,\ncontinued pretraining that incorporates a trainable prompt during multi-task\nlearning, leads to improved promptability in both zero- and few-shot settings\ncompared to existing methods, up to 31% relative. On the other hand, we find\nthat continued pretraining using MAML-style meta-learning, a method that\ndirectly optimizes few-shot promptability, yields subpar performance. We\nvalidate our findings with two prompt tuning methods, and, based on our\nresults, we provide concrete recommendations to optimize promptability for\ndifferent use cases.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhaofeng Wu",
      "Robert L. Logan IV",
      "Pete Walsh",
      "Akshita Bhagia",
      "Dirk Groeneveld",
      "Sameer Singh",
      "Iz Beltagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10258"
  },
  {
    "id": "arXiv:2210.10260",
    "title": "End-to-End Entity Detection with Proposer and Regressor",
    "abstract": "Named entity recognition is a traditional task in natural language\nprocessing. In particular, nested entity recognition receives extensive\nattention for the widespread existence of the nesting scenario. The latest\nresearch migrates the well-established paradigm of set prediction in object\ndetection to cope with entity nesting. However, the manual creation of query\nvectors, which fail to adapt to the rich semantic information in the context,\nlimits these approaches. An end-to-end entity detection approach with proposer\nand regressor is presented in this paper to tackle the issues. First, the\nproposer utilizes the feature pyramid network to generate high-quality entity\nproposals. Then, the regressor refines the proposals for generating the final\nprediction. The model adopts encoder-only architecture and thus obtains the\nadvantages of the richness of query semantics, high precision of entity\nlocalization, and easiness for model training. Moreover, we introduce the novel\nspatially modulated attention and progressive refinement for further\nimprovement. Extensive experiments demonstrate that our model achieves advanced\nperformance in flat and nested NER, achieving a new state-of-the-art F1 score\nof 80.74 on the GENIA dataset and 72.38 on the WeiboNER dataset.",
    "descriptor": "",
    "authors": [
      "Xueru Wen",
      "Changjiang Zhou",
      "Haotian Tang",
      "Luguang Liang",
      "Yu Jiang",
      "Hong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10260"
  },
  {
    "id": "arXiv:2210.10263",
    "title": "Time and Cost-Efficient Bathymetric Mapping System using Sparse Point  Cloud Generation and Automatic Object Detection",
    "abstract": "Generating 3D point cloud (PC) data from noisy sonar measurements is a\nproblem that has potential applications for bathymetry mapping, artificial\nobject inspection, mapping of aquatic plants and fauna as well as underwater\nnavigation and localization of vehicles such as submarines. Side-scan sonar\nsensors are available in inexpensive cost ranges, especially in fish-finders,\nwhere the transducers are usually mounted to the bottom of a boat and can\napproach shallower depths than the ones attached to an Uncrewed Underwater\nVehicle (UUV) can. However, extracting 3D information from side-scan sonar\nimagery is a difficult task because of its low signal-to-noise ratio and\nmissing angle and depth information in the imagery. Since most algorithms that\ngenerate a 3D point cloud from side-scan sonar imagery use Shape from Shading\n(SFS) techniques, extracting 3D information is especially difficult when the\nseafloor is smooth, is slowly changing in depth, or does not have identifiable\nobjects that make acoustic shadows. This paper introduces an efficient\nalgorithm that generates a sparse 3D point cloud from side-scan sonar images.\nThis computation is done in a computationally efficient manner by leveraging\nthe geometry of the first sonar return combined with known positions provided\nby GPS and down-scan sonar depth measurement at each data point. Additionally,\nthis paper implements another algorithm that uses a Convolutional Neural\nNetwork (CNN) using transfer learning to perform object detection on side-scan\nsonar images collected in real life and generated with a simulation. The\nalgorithm was tested on both real and synthetic images to show reasonably\naccurate anomaly detection and classification.",
    "descriptor": "\nComments: Submitted to OCEANS 2022\n",
    "authors": [
      "Andres Pulido",
      "Ruoyao Qin",
      "Antonio Diaz",
      "Andrew Ortega",
      "Peter Ifju",
      "Jaejeong Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10263"
  },
  {
    "id": "arXiv:2210.10264",
    "title": "A new activation for neural networks and its approximation",
    "abstract": "Deep learning with deep neural networks (DNNs) has attracted tremendous\nattention from various fields of science and technology recently. Activation\nfunctions for a DNN define the output of a neuron given an input or set of\ninputs. They are essential and inevitable in learning non-linear\ntransformations and performing diverse computations among successive neuron\nlayers. Thus, the design of activation functions is still an important topic in\ndeep learning research. Meanwhile, theoretical studies on the approximation\nability of DNNs with activation functions have been investigated within the\nlast few years. In this paper, we propose a new activation function, named as\n\"DLU\", and investigate its approximation ability for functions with various\nsmoothness and structures. Our theoretical results show that DLU networks can\nprocess competitive approximation performance with rational and ReLU networks,\nand have some advantages. Numerical experiments are conducted comparing DLU\nwith the existing activations-ReLU, Leaky ReLU, and ELU, which illustrate the\ngood practical performance of DLU.",
    "descriptor": "",
    "authors": [
      "Jianfei Li",
      "Han Feng",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Image and Video Processing (eess.IV)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.10264"
  },
  {
    "id": "arXiv:2210.10266",
    "title": "Corrected Evaluation Results of the NTCIR WWW-2, WWW-3, and WWW-4  English Subtasks",
    "abstract": "Unfortunately, the official English (sub)task results reported in the\nNTCIR-14 WWW-2, NTCIR-15 WWW-3, and NTCIR-16 WWW-4 overview papers are\nincorrect due to noise in the official qrels files; this paper reports results\nbased on the corrected qrels files. The noise is due to a fatal bug in the\nbackend of our relevance assessment interface. More specifically, at WWW-2,\nWWW-3, and WWW-4, two versions of pool files were created for each English\ntopic: a PRI (\"prioritised\") file, which uses the NTCIRPOOL script to\nprioritise likely relevant documents, and a RND (\"randomised\") file, which\nrandomises the pooled documents. This was done for the purpose of studying the\neffect of document ordering for relevance assessors. However, the programmer\nwho wrote the interface backend assumed that a combination of a topic ID and a\ndocument rank in the pool file uniquely determines a document ID; this is\nobviously incorrect as we have two versions of pool files. The outcome is that\nall the PRI-based relevance labels for the WWW-2 test collection are incorrect\n(while all the RND-based relevance labels are correct), and all the RND-based\nrelevance labels for the WWW-3 and WWW-4 test collections are incorrect (while\nall the PRI-based relevance labels are correct). This bug was finally\ndiscovered at the NTCIR-16 WWW-4 task when the first seven authors of this\npaper served as Gold assessors (i.e., topic creators who define what is\nrelevant) and closely examined the disagreements with Bronze assessors (i.e.,\nnon-topic-creators; non-experts). We would like to apologise to the WWW\nparticipants and the NTCIR chairs for the inconvenience and confusion caused\ndue to this bug.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Tetsuya Sakai",
      "Sijie Tao",
      "Maria Maistro",
      "Zhumin Chu",
      "Yujing Li",
      "Nuo Chen",
      "Nicola Ferro",
      "Junjie Wang",
      "Ian Soboroff",
      "Yiqun Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10266"
  },
  {
    "id": "arXiv:2210.10267",
    "title": "Synthetic Sonar Image Simulation with Various Seabed Conditions for  Automatic Target Recognition",
    "abstract": "We propose a novel method to generate underwater object imagery that is\nacoustically compliant with that generated by side-scan sonar using the Unreal\nEngine. We describe the process to develop, tune, and generate imagery to\nprovide representative images for use in training automated target recognition\n(ATR) and machine learning algorithms. The methods provide visual\napproximations for acoustic effects such as back-scatter noise and acoustic\nshadow, while allowing fast rendering with C++ actor in UE for maximizing the\nsize of potential ATR training datasets. Additionally, we provide analysis of\nits utility as a replacement for actual sonar imagery or physics-based sonar\ndata.",
    "descriptor": "\nComments: Submitted to OCEANS 2022\n",
    "authors": [
      "Jaejeong Shin",
      "Shi Chang",
      "Matthew Bays",
      "Joshua Weaver",
      "Tom Wettergren",
      "Silvia Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10267"
  },
  {
    "id": "arXiv:2210.10272",
    "title": "Training set cleansing of backdoor poisoning by self-supervised  representation learning",
    "abstract": "A backdoor or Trojan attack is an important type of data poisoning attack\nagainst deep neural network (DNN) classifiers, wherein the training dataset is\npoisoned with a small number of samples that each possess the backdoor pattern\n(usually a pattern that is either imperceptible or innocuous) and which are\nmislabeled to the attacker's target class. When trained on a backdoor-poisoned\ndataset, a DNN behaves normally on most benign test samples but makes incorrect\npredictions to the target class when the test sample has the backdoor pattern\nincorporated (i.e., contains a backdoor trigger). Here we focus on image\nclassification tasks and show that supervised training may build stronger\nassociation between the backdoor pattern and the associated target class than\nthat between normal features and the true class of origin. By contrast,\nself-supervised representation learning ignores the labels of samples and\nlearns a feature embedding based on images' semantic content. %We thus propose\nto use unsupervised representation learning to avoid emphasising\nbackdoor-poisoned training samples and learn a similar feature embedding for\nsamples of the same class. Using a feature embedding found by self-supervised\nrepresentation learning, a data cleansing method, which combines sample\nfiltering and re-labeling, is developed. Experiments on CIFAR-10 benchmark\ndatasets show that our method achieves state-of-the-art performance in\nmitigating backdoor attacks.",
    "descriptor": "",
    "authors": [
      "H. Wang",
      "S. Karami",
      "O. Dia",
      "H. Ritter",
      "E. Emamjomeh-Zadeh",
      "J. Chen",
      "Z. Xiang",
      "D.J. Miller",
      "G. Kesidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10272"
  },
  {
    "id": "arXiv:2210.10275",
    "title": "Towards Explaining Distribution Shifts",
    "abstract": "A distribution shift can have fundamental consequences such as signaling a\nchange in the operating environment or significantly reducing the accuracy of\ndownstream models. Thus, understanding distribution shifts is critical for\nexamining and hopefully mitigating the effect of such a shift. Most prior work\nhas focused on merely detecting if a shift has occurred and assumes any\ndetected shift can be understood and handled appropriately by a human operator.\nWe hope to aid in these manual mitigation tasks by explaining the distribution\nshift using interpretable transportation maps from the original distribution to\nthe shifted one. We derive our interpretable mappings from a relaxation of the\noptimal transport problem, where the candidate mappings are restricted to a set\nof interpretable mappings. We then use quintessential examples of distribution\nshift in simulated and real-world cases to showcase how our explanatory\nmappings provide a better balance between detail and interpretability than the\nde facto standard mean shift explanation by both visual inspection and our\nPercentExplained metric.",
    "descriptor": "",
    "authors": [
      "Sean Kulinski",
      "David I. Inouye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10275"
  },
  {
    "id": "arXiv:2210.10276",
    "title": "CLIP-Driven Fine-grained Text-Image Person Re-identification",
    "abstract": "TIReID aims to retrieve the image corresponding to the given text query from\na pool of candidate images. Existing methods employ prior knowledge from\nsingle-modality pre-training to facilitate learning, but lack multi-modal\ncorrespondences. Besides, due to the substantial gap between modalities,\nexisting methods embed the original modal features into the same latent space\nfor cross-modal alignment. However, feature embedding may lead to intra-modal\ninformation distortion. Recently, CLIP has attracted extensive attention from\nresearchers due to its powerful semantic concept learning capacity and rich\nmulti-modal knowledge, which can help us solve the above problems. Accordingly,\nin the paper, we propose a CLIP-driven Fine-grained information excavation\nframework (CFine) to fully utilize the powerful knowledge of CLIP for TIReID.\nTo transfer the multi-modal knowledge effectively, we perform fine-grained\ninformation excavation to mine intra-modal discriminative clues and inter-modal\ncorrespondences. Specifically, we first design a multi-grained global feature\nlearning module to fully mine intra-modal discriminative local information,\nwhich can emphasize identity-related discriminative clues by enhancing the\ninteractions between global image (text) and informative local patches (words).\nSecondly, cross-grained feature refinement (CFR) and fine-grained\ncorrespondence discovery (FCD) modules are proposed to establish the\ncross-grained and fine-grained interactions between modalities, which can\nfilter out non-modality-shared image patches/words and mine cross-modal\ncorrespondences from coarse to fine. CFR and FCD are removed during inference\nto save computational costs. Note that the above process is performed in the\noriginal modality space without further feature embedding. Extensive\nexperiments on multiple benchmarks demonstrate the superior performance of our\nmethod on TIReID.",
    "descriptor": "",
    "authors": [
      "Shuanglin Yan",
      "Neng Dong",
      "Liyan Zhang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10276"
  },
  {
    "id": "arXiv:2210.10278",
    "title": "A Reinforcement Learning Approach in Multi-Phase Second-Price Auction  Design",
    "abstract": "We study reserve price optimization in multi-phase second price auctions,\nwhere seller's prior actions affect the bidders' later valuations through a\nMarkov Decision Process (MDP). Compared to the bandit setting in existing\nworks, the setting in ours involves three challenges. First, from the seller's\nperspective, we need to efficiently explore the environment in the presence of\npotentially nontruthful bidders who aim to manipulates seller's policy. Second,\nwe want to minimize the seller's revenue regret when the market noise\ndistribution is unknown. Third, the seller's per-step revenue is unknown,\nnonlinear, and cannot even be directly observed from the environment.\nWe propose a mechanism addressing all three challenges. To address the first\nchallenge, we use a combination of a new technique named \"buffer periods\" and\ninspirations from Reinforcement Learning (RL) with low switching cost to limit\nbidders' surplus from untruthful bidding, thereby incentivizing approximately\ntruthful bidding. The second one is tackled by a novel algorithm that removes\nthe need for pure exploration when the market noise distribution is unknown.\nThe third challenge is resolved by an extension of LSVI-UCB, where we use the\nauction's underlying structure to control the uncertainty of the revenue\nfunction. The three techniques culminate in the $\\underline{\\rm\nC}$ontextual-$\\underline{\\rm L}$SVI-$\\underline{\\rm U}$CB-$\\underline{\\rm\nB}$uffer (CLUB) algorithm which achieves $\\tilde{\n\\mathcal{O}}(H^{5/2}\\sqrt{K})$ revenue regret when the market noise is known\nand $\\tilde{ \\mathcal{O}}(H^{3}\\sqrt{K})$ revenue regret when the noise is\nunknown with no assumptions on bidders' truthfulness.",
    "descriptor": "",
    "authors": [
      "Rui Ai",
      "Boxiang Lyu",
      "Zhaoran Wang",
      "Zhuoran Yang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10278"
  },
  {
    "id": "arXiv:2210.10289",
    "title": "Language Model Decomposition: Quantifying the Dependency and Correlation  of Language Models",
    "abstract": "Pre-trained language models (LMs), such as BERT (Devlin et al., 2018) and its\nvariants, have led to significant improvements on various NLP tasks in past\nyears. However, a theoretical framework for studying their relationships is\nstill missing. In this paper, we fill this gap by investigating the linear\ndependency between pre-trained LMs. The linear dependency of LMs is defined\nanalogously to the linear dependency of vectors. We propose Language Model\nDecomposition (LMD) to represent a LM using a linear combination of other LMs\nas basis, and derive the closed-form solution. A goodness-of-fit metric for LMD\nsimilar to the coefficient of determination is defined and used to measure the\nlinear dependency of a set of LMs. In experiments, we find that BERT and eleven\n(11) BERT-like LMs are 91% linearly dependent. This observation suggests that\ncurrent state-of-the-art (SOTA) LMs are highly \"correlated\". To further advance\nSOTA we need more diverse and novel LMs that are less dependent on existing\nLMs.",
    "descriptor": "\nComments: accepted by EMNLP 2022\n",
    "authors": [
      "Hao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10289"
  },
  {
    "id": "arXiv:2210.10290",
    "title": "Differentiable Self-Adaptive Learning Rate",
    "abstract": "Learning rate adaptation is a popular topic in machine learning. Gradient\nDescent trains neural nerwork with a fixed learning rate. Learning rate\nadaptation is proposed to accelerate the training process through adjusting the\nstep size in the training session. Famous works include Momentum, Adam and\nHypergradient. Hypergradient is the most special one. Hypergradient achieved\nadaptation by calculating the derivative of learning rate with respect to cost\nfunction and utilizing gradient descent for learning rate. However,\nHypergradient is still not perfect. In practice, Hypergradient fail to decrease\ntraining loss after learning rate adaptation with a large probability. Apart\nfrom that, evidence has been found that Hypergradient are not suitable for\ndealing with large datesets in the form of minibatch training. Most\nunfortunately, Hypergradient always fails to get a good accuracy on the\nvalidation dataset although it could reduce training loss to a very tiny value.\nTo solve Hypergradient's problems, we propose a novel adaptation algorithm,\nwhere learning rate is parameter specific and internal structured. We conduct\nextensive experiments on multiple network models and datasets compared with\nvarious benchmark optimizers. It is shown that our algorithm can achieve faster\nand higher qualified convergence than those state-of-art optimizers.",
    "descriptor": "",
    "authors": [
      "Bozhou Chen",
      "Hongzhi Wang",
      "Chenmin Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10290"
  },
  {
    "id": "arXiv:2210.10291",
    "title": "Improving Aspect Sentiment Quad Prediction via Template-Order Data  Augmentation",
    "abstract": "Recently, aspect sentiment quad prediction (ASQP) has become a popular task\nin the field of aspect-level sentiment analysis. Previous work utilizes a\npredefined template to paraphrase the original sentence into a structure target\nsequence, which can be easily decoded as quadruplets of the form (aspect\ncategory, aspect term, opinion term, sentiment polarity). The template involves\nthe four elements in a fixed order. However, we observe that this solution\ncontradicts with the order-free property of the ASQP task, since there is no\nneed to fix the template order as long as the quadruplet is extracted\ncorrectly. Inspired by the observation, we study the effects of template orders\nand find that some orders help the generative model achieve better performance.\nIt is hypothesized that different orders provide various views of the\nquadruplet. Therefore, we propose a simple but effective method to identify the\nmost proper orders, and further combine multiple proper templates as data\naugmentation to improve the ASQP task. Specifically, we use the pre-trained\nlanguage model to select the orders with minimal entropy. By fine-tuning the\npre-trained language model with these template orders, our approach improves\nthe performance of quad prediction, and outperforms state-of-the-art methods\nsignificantly in low-resource settings.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Mengting Hu",
      "Yike Wu",
      "Hang Gao",
      "Yinhao Bai",
      "Shiwan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10291"
  },
  {
    "id": "arXiv:2210.10292",
    "title": "Comparing Spectroscopy Measurements in the Prediction of in Vitro  Dissolution Profile using Artificial Neural Networks",
    "abstract": "Dissolution testing is part of the target product quality that is essential\nin approving new products in the pharmaceutical industry. The prediction of the\ndissolution profile based on spectroscopic data is an alternative to the\ncurrent destructive and time-consuming method. Raman and near-infrared (NIR)\nspectroscopies are two fast and complementary methods that provide information\non the tablets' physical and chemical properties and can help predict their\ndissolution profiles. This work aims to compare the information collected by\nthese spectroscopy methods to support the decision of which measurements should\nbe used so that the accuracy requirement of the industry is met. Artificial\nneural network models were created, in which the spectroscopy data and the\nmeasured compression curves were used as an input individually and in different\ncombinations in order to estimate the dissolution profiles. Results showed that\nusing only the NIR transmission method along with the compression force data or\nthe Raman and NIR reflection methods, the dissolution profile was estimated\nwithin the acceptance limits of the f2 similarity factor. Adding further\nspectroscopy measurements increased the prediction accuracy.",
    "descriptor": "\nComments: 11 pagee, 5 figures, 3rd International Conference on Data Science and Machine Learning (DSML 2022)\n",
    "authors": [
      "Mohamed Azouz Mrad",
      "Krist\u00f3f Csorba",
      "Dori\u00e1n L\u00e1szl\u00f3 Galata",
      "Zsombor Krist\u00f3f Nagy",
      "Brigitta Nagy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2210.10292"
  },
  {
    "id": "arXiv:2210.10293",
    "title": "Forging Multiple Training Objectives for Pre-trained Language Models via  Meta-Learning",
    "abstract": "Multiple pre-training objectives fill the vacancy of the understanding\ncapability of single-objective language modeling, which serves the ultimate\npurpose of pre-trained language models (PrLMs), generalizing well on a mass of\nscenarios. However, learning multiple training objectives in a single model is\nchallenging due to the unknown relative significance as well as the potential\ncontrariety between them. Empirical studies have shown that the current\nobjective sampling in an ad-hoc manual setting makes the learned language\nrepresentation barely converge to the desired optimum. Thus, we propose\n\\textit{MOMETAS}, a novel adaptive sampler based on meta-learning, which learns\nthe latent sampling pattern on arbitrary pre-training objectives. Such a design\nis lightweight with negligible additional training overhead. To validate our\napproach, we adopt five objectives and conduct continual pre-training with\nBERT-base and BERT-large models, where MOMETAS demonstrates universal\nperformance gain over other rule-based sampling strategies on 14 natural\nlanguage processing tasks.",
    "descriptor": "\nComments: EMNLP 2022 (findings)\n",
    "authors": [
      "Hongqiu Wu",
      "Ruixue Ding",
      "Hai Zhao",
      "Boli Chen",
      "Pengjun Xie",
      "Fei Huang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10293"
  },
  {
    "id": "arXiv:2210.10294",
    "title": "Secure and Efficient Multi-Signature Schemes for Fabric: An Enterprise  Blockchain Platform",
    "abstract": "Digital signature is a major component of transactions on Blockchain\nplatforms, especially in enterprise Blockchain platforms, where multiple\nsignatures from a set of peers need to be produced to endorse a transaction.\nHowever, such process is often complex and time-consuming. Multi-signature,\nwhich can improve transaction efficiency by having a set of signers cooperate\nto produce a joint signature, has attracted extensive attentions. In this work,\nwe propose two multi-signature schemes, GMS and AGMS, which are proved to be\nmore secure and efficient than state-of-the-art multi-signature schemes.\nBesides, we implement the proposed schemes in a real Enterprise Blockchain\nplatform, Fabric. Experiment results show that the proposed AGMS scheme helps\nachieve the goal of high transaction efficiency, low storage complexity, as\nwell as high robustness against rogue-key attacks and k-sum problem attacks.",
    "descriptor": "",
    "authors": [
      "Yue Xiao",
      "Peng Zhang",
      "Yuhong Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10294"
  },
  {
    "id": "arXiv:2210.10297",
    "title": "Backward error analysis of the Lanczos bidiagonalization with  reorthogonalization",
    "abstract": "The $k$-step Lanczos bidiagonalization reduces a matrix\n$A\\in\\mathbb{R}^{m\\times n}$ into a bidiagonal form\n$B_k\\in\\mathbb{R}^{(k+1)\\times k}$ while generates two orthonormal matrices\n$U_{k+1}\\in\\mathbb{R}^{m\\times (k+1)}$ and $V_{k+1}\\in\\mathbb{R}^{n\\times\n{(k+1)}}$. However, any practical implementation of the algorithm suffers from\nloss of orthogonality of $U_{k+1}$ and $V_{k+1}$ due to the presence of\nrounding errors, and several reorthogonalization strategies are proposed to\nmaintain some level of orthogonality. In this paper, by writing various\nreorthogonalization strategies in a general form we make a backward error\nanalysis of the Lanczos bidiagonalization with reorthogonalization (LBRO). Our\nresults show that the computed $B_k$ by the $k$-step LBRO of $A$ with starting\nvector $b$ is the exact one generated by the $k$-step Lanczos bidiagonalization\nof $A+E$ with starting vector $b+\\delta_{b}$ (denoted by\nLB($A+E,b+\\delta_{b}$)), where the 2-norm of perturbation vector/matrix\n$\\delta_{b}$ and $E$ depend on the roundoff unit and orthogonality levels of\n$U_{k+1}$ and $V_{k+1}$. The results also show that the 2-norm of\n$U_{k+1}-\\bar{U}_{k+1}$ and $V_{k+1}-\\bar{V}_{k+1}$ are controlled by the\northogonality levels of $U_{k+1}$ and $V_{k+1}$, respectively, where\n$\\bar{U}_{k+1}$ and $\\bar{V}_{k+1}$ are the two orthonormal matrices generated\nby the $k$-step LB($A+E,b+\\delta_{b}$) in exact arithmetic. Thus the $k$-step\nLBRO is mixed forward-backward stable as long as the orthogonality of $U_{k+1}$\nand $V_{k+1}$ are good enough. We use this result to investigate the backward\nstability of LBRO based SVD computation algorithm and LSQR algorithm. Numerical\nexperiments are made to confirm our results.",
    "descriptor": "",
    "authors": [
      "Haibo Li",
      "Guangming Tan",
      "Tong Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10297"
  },
  {
    "id": "arXiv:2210.10298",
    "title": "Evaluation Metrics for Object Detection for Autonomous Systems",
    "abstract": "This paper studies the evaluation of learning-based object detection models\nin conjunction with model-checking of formal specifications defined on an\nabstract model of an autonomous system and its environment. In particular, we\ndefine two metrics -- \\emph{proposition-labeled} and \\emph{class-labeled}\nconfusion matrices -- for evaluating object detection, and we incorporate these\nmetrics to compute the satisfaction probability of system-level safety\nrequirements. While confusion matrices have been effective for comparative\nevaluation of classification and object detection models, our framework fills\ntwo key gaps. First, we relate the performance of object detection to formal\nrequirements defined over downstream high-level planning tasks. In particular,\nwe provide empirical results that show that the choice of a good object\ndetection algorithm, with respect to formal requirements on the overall system,\nsignificantly depends on the downstream planning and control design. Secondly,\nunlike the traditional confusion matrix, our metrics account for variations in\nperformance with respect to the distance between the ego and the object being\ndetected. We demonstrate this framework on a car-pedestrian example by\ncomputing the satisfaction probabilities for safety requirements formalized in\nLinear Temporal Logic (LTL).",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Apurva Badithela",
      "Tichakorn Wongpiromsarn",
      "Richard M. Murray"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10298"
  },
  {
    "id": "arXiv:2210.10300",
    "title": "Dense but Efficient VideoQA for Intricate Compositional Reasoning",
    "abstract": "It is well known that most of the conventional video question answering\n(VideoQA) datasets consist of easy questions requiring simple reasoning\nprocesses. However, long videos inevitably contain complex and compositional\nsemantic structures along with the spatio-temporal axis, which requires a model\nto understand the compositional structures inherent in the videos. In this\npaper, we suggest a new compositional VideoQA method based on transformer\narchitecture with a deformable attention mechanism to address the complex\nVideoQA tasks. The deformable attentions are introduced to sample a subset of\ninformative visual features from the dense visual feature map to cover a\ntemporally long range of frames efficiently. Furthermore, the dependency\nstructure within the complex question sentences is also combined with the\nlanguage embeddings to readily understand the relations among question words.\nExtensive experiments and ablation studies show that the suggested dense but\nefficient model outperforms other baselines.",
    "descriptor": "\nComments: Accepted to WACV'23\n",
    "authors": [
      "Jihyeon Lee",
      "Wooyoung Kang",
      "Eun-Sol Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10300"
  },
  {
    "id": "arXiv:2210.10302",
    "title": "CFAR based NOMP for Line Spectral Estimation and Detection",
    "abstract": "The line spectrum estimation problem is considered in this paper. We propose\na CFAR-based Newtonized OMP (NOMP-CFAR) method which can maintain a desired\nfalse alarm rate without the knowledge of the noise variance. The NOMP-CFAR\nconsists of two steps, namely, an initialization step and a detection step. In\nthe initialization step, NOMP is employed to obtain candidate sinusoidal\ncomponents. In the detection step, CFAR detector is applied to detect each\ncandidate frequency, and remove the most unlikely frequency component. Then,\nthe Newton refinements are used to refine the remaining parameters. The\nrelationship between the false alarm rate and the required threshold is\nestablished. By comparing with the NOMP, NOMP-CFAR has only $1$ dB performance\nloss in additive white Gaussian noise scenario with false alarm probability\n$10^{-2}$ and detection probability $0.8$ without knowledge of noise variance.\nFor varied noise variance scenario, NOMP-CFAR still preserves its CFAR\nproperty, while NOMP violates the CFAR. Besides, real experiments are also\nconducted to demonstrate the detection performance of NOMP-CFAR, compared to\nCFAR and NOMP.",
    "descriptor": "",
    "authors": [
      "Menghuai Xu",
      "Jiang Zhu",
      "Jun Fang",
      "Ning Zhang",
      "Zhiwei Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10302"
  },
  {
    "id": "arXiv:2210.10304",
    "title": "Synthesizing Reactive Test Environments for Autonomous Systems: Testing  Reach-Avoid Specifications with Multi-Commodity Flows",
    "abstract": "We study automated test generation for verifying discrete decision-making\nmodules in autonomous systems. We utilize linear temporal logic to encode the\nrequirements on the system under test in the system specification and the\nbehavior that we want to observe during the test is given as the test\nspecification which is unknown to the system. First, we use the specifications\nand their corresponding non-deterministic B\\\"uchi automata to generate the\nspecification product automaton. Second, a virtual product graph representing\nthe high-level interaction between the system and the test environment is\nconstructed modeling the product automaton encoding the system, the test\nenvironment, and specifications. The main result of this paper is an\noptimization problem, framed as a multi-commodity network flow problem, that\nsolves for constraints on the virtual product graph which can then be projected\nto the test environment. Therefore, the result of the optimization problem is\nreactive test synthesis that ensures that the system meets the test\nspecifications along with satisfying the system specifications. This framework\nis illustrated in simulation on grid world examples, and demonstrated on\nhardware with the Unitree A1 quadruped, wherein dynamic locomotion behaviors\nare verified in the context of reactive test environments.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Apurva Badithela",
      "Josefine B. Graebener",
      "Wyatt Ubellacker",
      "Eric V. Mazumdar",
      "Aaron D. Ames",
      "Richard M. Murray"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10304"
  },
  {
    "id": "arXiv:2210.10305",
    "title": "A Unified Neural Network Model for Readability Assessment with Feature  Projection and Length-Balanced Loss",
    "abstract": "For readability assessment, traditional methods mainly employ machine\nlearning classifiers with hundreds of linguistic features. Although the deep\nlearning model has become the prominent approach for almost all NLP tasks, it\nis less explored for readability assessment. In this paper, we propose a\nBERT-based model with feature projection and length-balanced loss (BERT-FP-LBL)\nfor readability assessment. Specially, we present a new difficulty knowledge\nguided semi-supervised method to extract topic features to complement the\ntraditional linguistic features. From the linguistic features, we employ\nprojection filtering to extract orthogonal features to supplement BERT\nrepresentations. Furthermore, we design a new length-balanced loss to handle\nthe greatly varying length distribution of data. Our model achieves\nstate-of-the-art performances on two English benchmark datasets and one dataset\nof Chinese textbooks, and also achieves the near-perfect accuracy of 99\\% on\none English dataset. Moreover, our proposed model obtains comparable results\nwith human experts in consistency test.",
    "descriptor": "",
    "authors": [
      "Wenbiao Li",
      "Ziyang Wang",
      "Yunfang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10305"
  },
  {
    "id": "arXiv:2210.10306",
    "title": "Fries: Fast and Consistent Runtime Reconfiguration in Dataflow Systems  with Transactional Guarantees (Extended Version)",
    "abstract": "A computing job in a big data system can take a long time to run, especially\nfor pipelined executions on data streams. Developers often need to change the\ncomputing logic of the job such as fixing a loophole in an operator or changing\nthe machine learning model in an operator with a cheaper model to handle a\nsudden increase of the data-ingestion rate. Recently many systems have started\nsupporting runtime reconfigurations to allow this type of change on the fly\nwithout killing and restarting the execution. While the delay in\nreconfiguration is critical to performance, existing systems use epochs to do\nruntime reconfigurations, which can cause a long delay. In this paper we\ndevelop a new technique called Fries that leverages the emerging availability\nof fast control messages in many systems, since these messages can be sent\nwithout being blocked by data messages. We formally define consistency in\nruntime reconfigurations, and develop a Fries scheduler with consistency\nguarantees. The technique not only works for different classes of dataflows,\nbut also works for parallel executions and supports fault tolerance. Our\nextensive experimental evaluation on clusters show the advantages of this\ntechnique compared to epoch-based schedulers.",
    "descriptor": "",
    "authors": [
      "Zuozhi Wang",
      "Shengquan Ni",
      "Avinash Kumar",
      "Chen Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.10306"
  },
  {
    "id": "arXiv:2210.10309",
    "title": "Multi-Objective Recommender Systems: Survey and Challenges",
    "abstract": "Recommender systems can be characterized as software solutions that provide\nusers convenient access to relevant content. Traditionally, recommender systems\nresearch predominantly focuses on developing machine learning algorithms that\naim to predict which content is relevant for individual users. In real-world\napplications, however, optimizing the accuracy of such relevance predictions as\na single objective in many cases is not sufficient. Instead, multiple and often\ncompeting objectives have to be considered, leading to a need for more research\nin multi-objective recommender systems. We can differentiate between several\ntypes of such competing goals, including (i) competing recommendation quality\nobjectives at the individual and aggregate level, (ii) competing objectives of\ndifferent involved stakeholders, (iii) long-term vs. short-term objectives,\n(iv) objectives at the user interface level, and (v) system level objectives.\nIn this paper we review these types of multi-objective recommendation settings\nand outline open challenges in this area.",
    "descriptor": "\nComments: In: Proceedings of the 2nd Workshop on Multi-Objective Recommender Systems (MORS) held in conjunction with the 16th ACM Conference on Recommender Systems (RecSys), 2022, Seattle, USA\n",
    "authors": [
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10309"
  },
  {
    "id": "arXiv:2210.10311",
    "title": "Latency Aware Semi-synchronous Client Selection and Model Aggregation  for Wireless Federated Learning",
    "abstract": "Federated learning (FL) is a collaborative machine learning framework that\nrequires different clients (e.g., Internet of Things devices) to participate in\nthe machine learning model training process by training and uploading their\nlocal models to an FL server in each global iteration. Upon receiving the local\nmodels from all the clients, the FL server generates a global model by\naggregating the received local models. This traditional FL process may suffer\nfrom the straggler problem in heterogeneous client settings, where the FL\nserver has to wait for slow clients to upload their local models in each global\niteration, thus increasing the overall training time. One of the solutions is\nto set up a deadline and only the clients that can upload their local models\nbefore the deadline would be selected in the FL process. This solution may lead\nto a slow convergence rate and global model overfitting issues due to the\nlimited client selection. In this paper, we propose the Latency awarE\nSemi-synchronous client Selection and mOdel aggregation for federated learNing\n(LESSON) method that allows all the clients to participate in the whole FL\nprocess but with different frequencies. That is, faster clients would be\nscheduled to upload their models more frequently than slow clients, thus\nresolving the straggler problem and accelerating the convergence speed, while\navoiding model overfitting. Also, LESSON is capable of adjusting the tradeoff\nbetween the model accuracy and convergence rate by varying the deadline.\nExtensive simulations have been conducted to compare the performance of LESSON\nwith the other two baseline methods, i.e., FedAvg and FedCS. The simulation\nresults demonstrate that LESSON achieves faster convergence speed than FedAvg\nand FedCS, and higher model accuracy than FedCS.",
    "descriptor": "",
    "authors": [
      "Liangkun Yu",
      "Xiang Sun",
      "Rana Albelaihi",
      "Chen Yi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10311"
  },
  {
    "id": "arXiv:2210.10314",
    "title": "Two-stage training method for Japanese electrolaryngeal speech  enhancement based on sequence-to-sequence voice conversion",
    "abstract": "Sequence-to-sequence (seq2seq) voice conversion (VC) models have greater\npotential in converting electrolaryngeal (EL) speech to normal speech (EL2SP)\ncompared to conventional VC models. However, EL2SP based on seq2seq VC requires\na sufficiently large amount of parallel data for the model training and it\nsuffers from significant performance degradation when the amount of training\ndata is insufficient. To address this issue, we suggest a novel, two-stage\nstrategy to optimize the performance on EL2SP based on seq2seq VC when a small\namount of the parallel dataset is available. In contrast to utilizing\nhigh-quality data augmentations in previous studies, we first combine a large\namount of imperfect synthetic parallel data of EL and normal speech, with the\noriginal dataset into VC training. Then, a second stage training is conducted\nwith the original parallel dataset only. The results show that the proposed\nmethod progressively improves the performance of EL2SP based on seq2seq VC.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Ding Ma",
      "Lester Phillip Violeta",
      "Kazuhiro Kobayashi",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10314"
  },
  {
    "id": "arXiv:2210.10317",
    "title": "LAVA: Label-efficient Visual Learning and Adaptation",
    "abstract": "We present LAVA, a simple yet effective method for multi-domain visual\ntransfer learning with limited data. LAVA builds on a few recent innovations to\nenable adapting to partially labelled datasets with class and domain shifts.\nFirst, LAVA learns self-supervised visual representations on the source dataset\nand ground them using class label semantics to overcome transfer collapse\nproblems associated with supervised pretraining. Secondly, LAVA maximises the\ngains from unlabelled target data via a novel method which uses multi-crop\naugmentations to obtain highly robust pseudo-labels. By combining these\ningredients, LAVA achieves a new state-of-the-art on ImageNet semi-supervised\nprotocol, as well as on 7 out of 10 datasets in multi-domain few-shot learning\non the Meta-dataset. Code and models are made available.",
    "descriptor": "\nComments: Accepted in WACV2023\n",
    "authors": [
      "Islam Nassar",
      "Munawar Hayat",
      "Ehsan Abbasnejad",
      "Hamid Rezatofighi",
      "Mehrtash Harandi",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10317"
  },
  {
    "id": "arXiv:2210.10318",
    "title": "Gaussian-Bernoulli RBMs Without Tears",
    "abstract": "We revisit the challenging problem of training Gaussian-Bernoulli restricted\nBoltzmann machines (GRBMs), introducing two innovations. We propose a novel\nGibbs-Langevin sampling algorithm that outperforms existing methods like Gibbs\nsampling. We propose a modified contrastive divergence (CD) algorithm so that\none can generate images with GRBMs starting from noise. This enables direct\ncomparison of GRBMs with deep generative models, improving evaluation protocols\nin the RBM literature. Moreover, we show that modified CD and gradient clipping\nare enough to robustly train GRBMs with large learning rates, thus removing the\nnecessity of various tricks in the literature. Experiments on Gaussian\nMixtures, MNIST, FashionMNIST, and CelebA show GRBMs can generate good samples,\ndespite their single-hidden-layer architecture. Our code is released at:\n\\url{https://github.com/lrjconan/GRBM}.",
    "descriptor": "",
    "authors": [
      "Renjie Liao",
      "Simon Kornblith",
      "Mengye Ren",
      "David J. Fleet",
      "Geoffrey Hinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10318"
  },
  {
    "id": "arXiv:2210.10320",
    "title": "Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning  for Chinese Spell Checking",
    "abstract": "Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling\nerrors. Recent researches start from the pretrained knowledge of language\nmodels and take multimodal information into CSC models to improve the\nperformance. However, they overlook the rich knowledge in the dictionary, the\nreference book where one can learn how one character should be pronounced,\nwritten, and used. In this paper, we propose the LEAD framework, which renders\nthe CSC model to learn heterogeneous knowledge from the dictionary in terms of\nphonetics, vision, and meaning. LEAD first constructs positive and negative\nsamples according to the knowledge of character phonetics, glyphs, and\ndefinitions in the dictionary. Then a unified contrastive learning-based\ntraining scheme is employed to refine the representations of the CSC models.\nExtensive experiments and detailed analyses on the SIGHAN benchmark datasets\ndemonstrate the effectiveness of our proposed methods.",
    "descriptor": "\nComments: Long paper, accepted at the Findings of EMNLP 2022\n",
    "authors": [
      "Yinghui Li",
      "Shirong Ma",
      "Qingyu Zhou",
      "Zhongli Li",
      "Li Yangning",
      "Shulin Huang",
      "Ruiyang Liu",
      "Chao Li",
      "Yunbo Cao",
      "Haitao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10320"
  },
  {
    "id": "arXiv:2210.10321",
    "title": "Quick Graph Conversion for Robust Recommendation",
    "abstract": "Implicit feedback plays a huge role in recommender systems, but its high\nnoise characteristic seriously reduces its effect. To denoise implicit\nfeedback, some efforts have been devoted to graph data augmentation (GDA)\nmethods. Although the bi-level optimization thought of GDA guarantees better\nrecommendation performance theoretically, it also leads to expensive time costs\nand severe space explosion problems. Specifically, bi-level optimization\ninvolves repeated traversal of all positive and negative instances after each\noptimization of the recommendation model. In this paper, we propose a new\ndenoising paradigm, i.e., Quick Graph Conversion (QGrace), to effectively\ntransform the original interaction graph into a purified (for positive\ninstances) and densified (for negative instances) interest graph during the\nrecommendation model training process. In QGrace, we leverage the gradient\nmatching scheme based on elaborated generative models to fulfill the conversion\nand generation of an interest graph, elegantly overcoming the high time and\nspace cost problems. To enable recommendation models to run on interest graphs\nthat lack implicit feedback data, we provide a fine-grained objective function\nfrom the perspective of alignment and uniformity. The experimental results on\nthree benchmark datasets demonstrate that the QGrace outperforms the\nstate-of-the-art GDA methods and recommendation models in effectiveness and\nrobustness.",
    "descriptor": "\nComments: 13pages, 6 figures, 5 tables\n",
    "authors": [
      "Zongwei Wang",
      "Min Gao",
      "Wentao Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10321"
  },
  {
    "id": "arXiv:2210.10325",
    "title": "Improving Stability of Fine-Tuning Pretrained Language Models via  Component-Wise Gradient Norm Clipping",
    "abstract": "Fine-tuning over large pretrained language models (PLMs) has established many\nstate-of-the-art results. Despite its superior performance, such fine-tuning\ncan be unstable, resulting in significant variance in performance and potential\nrisks for practical applications. Previous works have attributed such\ninstability to the catastrophic forgetting problem in the top layers of PLMs,\nwhich indicates iteratively that fine-tuning layers in a top-down manner is a\npromising solution. In this paper, we first point out that this method does not\nalways work out due to the different convergence speeds of different\nlayers/modules. Inspired by this observation, we propose a simple\ncomponent-wise gradient norm clipping method to adjust the convergence speed\nfor different components. Experiment results demonstrate that our method\nachieves consistent improvements in terms of generalization performance,\nconvergence speed, and training stability. The codebase can be found at\nhttps://github.com/yangalan123/FineTuningStability.",
    "descriptor": "\nComments: EMNLP 2022 Camera Ready\n",
    "authors": [
      "Chenghao Yang",
      "Xuezhe Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10325"
  },
  {
    "id": "arXiv:2210.10329",
    "title": "Language Detoxification with Attribute-Discriminative Latent Space",
    "abstract": "Transformer-based Language Models (LMs) achieve remarkable performances on a\nvariety of NLU tasks, but are also prone to generating toxic texts such as\ninsults, threats, and profanities which limit their adaptations to the\nreal-world applications. To overcome this issue, a few text generation\napproaches aim to detoxify toxic texts with additional LMs or perturbations.\nHowever, previous methods require excessive memory, computations, and time\nwhich are serious bottlenecks in their real-world application. To address such\nlimitations, we propose an effective yet efficient method for language\ndetoxification using an attribute-discriminative latent space. Specifically, we\nproject the latent space of an original Transformer LM to a discriminative\nlatent space on which the texts are well-separated by their attributes, with\nthe help of a projection block and a discriminator. This allows the LM to\ncontrol the text generation to be non-toxic with minimal memory and computation\noverhead. We validate our model, Attribute-Discriminative Language Model (ADLM)\non detoxified language and dialogue generation tasks, on which our method\nsignificantly outperforms baselines both in performance and efficiency.",
    "descriptor": "",
    "authors": [
      "Jin Myung Kwak",
      "Minseon Kim",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10329"
  },
  {
    "id": "arXiv:2210.10330",
    "title": "Content-adaptive Encoder Preset Prediction for Adaptive Live Streaming",
    "abstract": "In live streaming applications, a fixed set of bitrate-resolution pairs\n(known as bitrate ladder) is generally used to avoid additional pre-processing\nrun-time to analyze the complexity of every video content and determine the\noptimized bitrate ladder. Furthermore, live encoders use the fastest available\npreset for encoding to ensure the minimum possible latency in streaming. For\nlive encoders, it is expected that the encoding speed is equal to the video\nframerate. An optimized encoding preset may result in (i) increased Quality of\nExperience (QoE) and (ii) improved CPU utilization while encoding. In this\nlight, this paper introduces a Content-Adaptive encoder Preset prediction\nScheme (CAPS) for adaptive live video streaming applications. In this scheme,\nthe encoder preset is determined using Discrete Cosine Transform\n(DCT)-energy-based low-complexity spatial and temporal features for every video\nsegment, the number of CPU threads allocated for each encoding instance, and\nthe target encoding speed. Experimental results show that CAPS yields an\noverall quality improvement of 0.83 dB PSNR and 3.81 VMAF with the same\nbitrate, compared to the fastest preset encoding of the HTTP Live Streaming\n(HLS) bitrate ladder using x265 HEVC open-source encoder. This is achieved by\nmaintaining the desired encoding speed and reducing CPU idle time.",
    "descriptor": "\nComments: Accepted in PCS2022\n",
    "authors": [
      "Vignesh V Menon",
      "Hadi Amirpour",
      "Prajit T Rajendran",
      "Mohammad Ghanbari",
      "Christian Timmerer"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.10330"
  },
  {
    "id": "arXiv:2210.10331",
    "title": "Performance Evaluation of Serverless Edge Computing for Machine Learning  Applications",
    "abstract": "Next generation technologies such as smart healthcare, self-driving cars, and\nsmart cities require new approaches to deal with the network traffic generated\nby the Internet of Things (IoT) devices, as well as efficient programming\nmodels to deploy machine learning techniques. Serverless edge computing is an\nemerging computing paradigm from the integration of two recent technologies,\nedge computing and serverless computing, that can possibly address these\nchallenges. However, there is little work to explore the capability and\nperformance of such a technology. In this paper, a comprehensive performance\nanalysis of a serverless edge computing system using popular open-source\nframeworks, namely, Kubeless, OpenFaaS, Fission, and funcX is presented. The\nexperiments considered different programming languages, workloads, and the\nnumber of concurrent users. The machine learning workloads have been used to\nevaluate the performance of the system under different working conditions to\nprovide insights into the best practices. The evaluation results revealed some\nof the current challenges in serverless edge computing and open research\nopportunities in this emerging technology for machine learning applications.",
    "descriptor": "",
    "authors": [
      "Quoc Lap Trieu",
      "Bahman Javadi",
      "Jim Basilakis",
      "Adel N. Toosi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.10331"
  },
  {
    "id": "arXiv:2210.10332",
    "title": "Revision Transformers: Getting RiT of No-Nos",
    "abstract": "Current transformer language models (LM) are large-scale models with billions\nof parameters. They have been shown to provide high performances on a variety\nof tasks but are also prone to shortcut learning and bias. Addressing such\nincorrect model behavior via parameter adjustments is very costly. This is\nparticularly problematic for updating dynamic concepts, such as moral values,\nwhich vary culturally or interpersonally. In this work, we question the current\ncommon practice of storing all information in the model parameters and propose\nthe Revision Transformer (RiT) employing information retrieval to facilitate\neasy model updating. The specific combination of a large-scale pre-trained LM\nthat inherently but also diffusely encodes world knowledge with a\nclear-structured revision engine makes it possible to update the model's\nknowledge with little effort and the help of user interaction. We exemplify RiT\non a moral dataset and simulate user feedback demonstrating strong performance\nin model revision even with small data. This way, users can easily design a\nmodel regarding their preferences, paving the way for more transparent and\npersonalized AI models.",
    "descriptor": "",
    "authors": [
      "Felix Friedrich",
      "Wolfgang Stammer",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.10332"
  },
  {
    "id": "arXiv:2210.10335",
    "title": "WebtoonMe: A Data-Centric Approach for Full-Body Portrait Stylization",
    "abstract": "Full-body portrait stylization, which aims to translate portrait photography\ninto a cartoon style, has drawn attention recently. However, most methods have\nfocused only on converting face regions, restraining the feasibility of use in\nreal-world applications. A recently proposed two-stage method expands the\nrendering area to full bodies, but the outputs are less plausible and fail to\nachieve quality robustness of non-face regions. Furthermore, they cannot\nreflect diverse skin tones. In this study, we propose a data-centric solution\nto build a production-level full-body portrait stylization system. Based on the\ntwo-stage scheme, we construct a novel and advanced dataset preparation\nparadigm that can effectively resolve the aforementioned problems. Experiments\nreveal that with our pipeline, high-quality portrait stylization can be\nachieved without additional losses or architectural changes.",
    "descriptor": "\nComments: SIGGRAPH Asia 2022 Technical Communications\n",
    "authors": [
      "Jihye Back",
      "Seungkwon Kim",
      "Namhyuk Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10335"
  },
  {
    "id": "arXiv:2210.10338",
    "title": "Comparison of Varied 2D Mapping Approaches by Using Practice-Oriented  Evaluation Criteria",
    "abstract": "A key aspect of the precision of a mobile robots localization is the quality\nand aptness of the map it is using. A variety of mapping approaches are\navailable that can be employed to create such maps with varying degrees of\neffort, hardware requirements and quality of the resulting maps. To create a\nbetter understanding of the applicability of these different approaches to\nspecific applications, this paper evaluates and compares three different\nmapping approaches based on simultaneous localization and mapping, terrestrial\nlaser scanning as well as publicly accessible building contours.",
    "descriptor": "",
    "authors": [
      "Justin Ziegenbein",
      "Manuel Schrick",
      "Marko Thiel",
      "Johannes Hinckeldeyn",
      "Jochen Kreutzfeldt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10338"
  },
  {
    "id": "arXiv:2210.10340",
    "title": "The Devil in Linear Transformer",
    "abstract": "Linear transformers aim to reduce the quadratic space-time complexity of\nvanilla transformers. However, they usually suffer from degraded performances\non various tasks and corpus. In this paper, we examine existing kernel-based\nlinear transformers and identify two key issues that lead to such performance\ngaps: 1) unbounded gradients in the attention computation adversely impact the\nconvergence of linear transformer models; 2) attention dilution which trivially\ndistributes attention scores over long sequences while neglecting neighbouring\nstructures. To address these issues, we first identify that the scaling of\nattention matrices is the devil in unbounded gradients, which turns out\nunnecessary in linear attention as we show theoretically and empirically. To\nthis end, we propose a new linear attention that replaces the scaling operation\nwith a normalization to stabilize gradients. For the issue of attention\ndilution, we leverage a diagonal attention to confine attention to only\nneighbouring tokens in early layers. Benefiting from the stable gradients and\nimproved attention, our new linear transformer model, transNormer, demonstrates\nsuperior performance on text classification and language modeling tasks, as\nwell as on the challenging Long-Range Arena benchmark, surpassing vanilla\ntransformer and existing linear variants by a clear margin while being\nsignificantly more space-time efficient. The code is available at\nhttps://github.com/OpenNLPLab/Transnormer .",
    "descriptor": "\nComments: accepted to EMNLP2022\n",
    "authors": [
      "Zhen Qin",
      "XiaoDong Han",
      "Weixuan Sun",
      "Dongxu Li",
      "Lingpeng Kong",
      "Nick Barnes",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10340"
  },
  {
    "id": "arXiv:2210.10341",
    "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text  Generation and Mining",
    "abstract": "Pre-trained language models have attracted increasing attention in the\nbiomedical domain, inspired by their great success in the general natural\nlanguage domain. Among the two main branches of pre-trained language models in\nthe general language domain, i.e., BERT (and its variants) and GPT (and its\nvariants), the first one has been extensively studied in the biomedical domain,\nsuch as BioBERT and PubMedBERT. While they have achieved great success on a\nvariety of discriminative downstream biomedical tasks, the lack of generation\nability constrains their application scope. In this paper, we propose BioGPT, a\ndomain-specific generative Transformer language model pre-trained on large\nscale biomedical literature. We evaluate BioGPT on six biomedical NLP tasks and\ndemonstrate that our model outperforms previous models on most tasks.\nEspecially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI\nend-to-end relation extraction tasks respectively, and 78.2% accuracy on\nPubMedQA, creating a new record. Our case study on text generation further\ndemonstrates the advantage of BioGPT on biomedical literature to generate\nfluent descriptions for biomedical terms. Code is available at\nhttps://github.com/microsoft/BioGPT.",
    "descriptor": "\nComments: Published at Briefings in Bioinformatics. Code is available at this https URL\n",
    "authors": [
      "Renqian Luo",
      "Liai Sun",
      "Yingce Xia",
      "Tao Qin",
      "Sheng Zhang",
      "Hoifung Poon",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10341"
  },
  {
    "id": "arXiv:2210.10343",
    "title": "EnTDA: Entity-to-Text based Data Augmentation Approach for Named Entity  Recognition Tasks",
    "abstract": "Data augmentation techniques have been used to improve the generalization\ncapability of models in the named entity recognition (NER) tasks. Existing\naugmentation methods either manipulate the words in the original text that\nrequire hand-crafted in-domain knowledge, or leverage generative models which\nsolicit dependency order among entities. To alleviate the excessive reliance on\nthe dependency order among entities in existing augmentation paradigms, we\ndevelop an entity-to-text instead of text-to-entity based data augmentation\nmethod named: EnTDA to decouple the dependencies between entities by adding,\ndeleting, replacing and swapping entities, and adopt these augmented data to\nbootstrap the generalization ability of the NER model. Furthermore, we\nintroduce a diversity beam search to increase the diversity of the augmented\ndata. Experiments on thirteen NER datasets across three tasks (flat NER, nested\nNER, and discontinuous NER) and two settings (full data NER and low resource\nNER) show that EnTDA could consistently outperform the baselines.",
    "descriptor": "\nComments: 13 pages, 4 figures, 9 tables\n",
    "authors": [
      "Xuming Hu",
      "Yong Jiang",
      "Aiwei Liu",
      "Zhongqiang Huang",
      "Pengjun Xie",
      "Fei Huang",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10343"
  },
  {
    "id": "arXiv:2210.10349",
    "title": "Museformer: Transformer with Fine- and Coarse-Grained Attention for  Music Generation",
    "abstract": "Symbolic music generation aims to generate music scores automatically. A\nrecent trend is to use Transformer or its variants in music generation, which\nis, however, suboptimal, because the full attention cannot efficiently model\nthe typically long music sequences (e.g., over 10,000 tokens), and the existing\nmodels have shortcomings in generating musical repetition structures. In this\npaper, we propose Museformer, a Transformer with a novel fine- and\ncoarse-grained attention for music generation. Specifically, with the\nfine-grained attention, a token of a specific bar directly attends to all the\ntokens of the bars that are most relevant to music structures (e.g., the\nprevious 1st, 2nd, 4th and 8th bars, selected via similarity statistics); with\nthe coarse-grained attention, a token only attends to the summarization of the\nother bars rather than each token of them so as to reduce the computational\ncost. The advantages are two-fold. First, it can capture both music\nstructure-related correlations via the fine-grained attention, and other\ncontextual information via the coarse-grained attention. Second, it is\nefficient and can model over 3X longer music sequences compared to its\nfull-attention counterpart. Both objective and subjective experimental results\ndemonstrate its ability to generate long music sequences with high quality and\nbetter structures.",
    "descriptor": "\nComments: Accepted by the Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Botao Yu",
      "Peiling Lu",
      "Rui Wang",
      "Wei Hu",
      "Xu Tan",
      "Wei Ye",
      "Shikun Zhang",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10349"
  },
  {
    "id": "arXiv:2210.10350",
    "title": "MuGER$^2$: Multi-Granularity Evidence Retrieval and Reasoning for Hybrid  Question Answering",
    "abstract": "Hybrid question answering (HQA) aims to answer questions over heterogeneous\ndata, including tables and passages linked to table cells. The heterogeneous\ndata can provide different granularity evidence to HQA models, e.t., column,\nrow, cell, and link. Conventional HQA models usually retrieve coarse- or\nfine-grained evidence to reason the answer. Through comparison, we find that\ncoarse-grained evidence is easier to retrieve but contributes less to the\nreasoner, while fine-grained evidence is the opposite. To preserve the\nadvantage and eliminate the disadvantage of different granularity evidence, we\npropose MuGER$^2$, a Multi-Granularity Evidence Retrieval and Reasoning\napproach. In evidence retrieval, a unified retriever is designed to learn the\nmulti-granularity evidence from the heterogeneous data. In answer reasoning, an\nevidence selector is proposed to navigate the fine-grained evidence for the\nanswer reader based on the learned multi-granularity evidence. Experiment\nresults on the HybridQA dataset show that MuGER$^2$ significantly boosts the\nHQA performance. Further ablation analysis verifies the effectiveness of both\nthe retrieval and reasoning designs.",
    "descriptor": "\nComments: Accepted to EMNLP(Findings) 2022\n",
    "authors": [
      "Yingyao Wang",
      "Junwei Bao",
      "Chaoqun Duan",
      "Youzheng Wu",
      "Xiaodong He",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10350"
  },
  {
    "id": "arXiv:2210.10351",
    "title": "Using deep convolutional neural networks to classify poisonous and  edible mushrooms found in China",
    "abstract": "Because of their abundance of amino acids, polysaccharides, and many other\nnutrients that benefit human beings, mushrooms are deservedly popular as\ndietary cuisine both worldwide and in China. However, if people eat poisonous\nfungi by mistake, they may suffer from nausea, vomiting, mental disorder, acute\nanemia, or even death. Each year in China, there are around 8000 people became\nsick, and 70 died as a result of eating toxic mushrooms by mistake. It is\ncounted that there are thousands of kinds of mushrooms among which only around\n900 types are edible, thus without specialized knowledge, the probability of\neating toxic mushrooms by mistake is very high. Most people deem that the only\ncharacteristic of poisonous mushrooms is a bright colour, however, some kinds\nof them do not correspond to this trait. In order to prevent people from eating\nthese poisonous mushrooms, we propose to use deep learning methods to indicate\nwhether a mushroom is toxic through analyzing hundreds of edible and toxic\nmushrooms smartphone pictures. We crowdsource a mushroom image dataset that\ncontains 250 images of poisonous mushrooms and 200 images of edible mushrooms.\nThe Convolutional Neural Network (CNN) is a specialized type of artificial\nneural networks that use a mathematical operation called convolution in place\nof general matrix multiplication in at least one of their layers, which can\ngenerate a relatively precise result by analyzing a huge amount of images, and\nthus is very suitable for our research. The experimental results demonstrate\nthat the proposed model has high credibility and can provide a decision-making\nbasis for the selection of edible fungi, so as to reduce the morbidity and\nmortality caused by eating poisonous mushrooms. We also open source our hand\ncollected mushroom image dataset so that peer researchers can also deploy their\nown model to advance poisonous mushroom identification.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Baiming Zhang",
      "Ying Zhao",
      "Zhixiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10351"
  },
  {
    "id": "arXiv:2210.10352",
    "title": "Temporal Action Segmentation: An Analysis of Modern Technique",
    "abstract": "Temporal action segmentation from videos aims at the dense labeling of video\nframes with multiple action classes in minutes-long videos. Categorized as a\nlong-range video understanding task, researchers have proposed an extended\ncollection of methods and examined their performance using various benchmarks.\nDespite the rapid development of action segmentation techniques in recent\nyears, there has been no systematic survey in such fields. To this end, in this\nsurvey, we analyze and summarize the main contributions and trends for this\ntask. Specifically, we first examine the task definition, common benchmarks,\ntypes of supervision, and popular evaluation measures. Furthermore, we\nsystematically investigate two fundamental aspects of this topic, i.e., frame\nrepresentation and temporal modeling, which are widely and extensively studied\nin the literature. We then comprehensively review existing temporal action\nsegmentation works, each categorized by their form of supervision. Finally, we\nconclude our survey by highlighting and identifying several open topics for\nresearch. In addition, we supplement our survey with a curated list of temporal\naction segmentation resources, which is available at\nhttps://github.com/atlas-eccv22/awesome-temporal-action-segmentation.",
    "descriptor": "\nComments: 26 pages, 10 figures, 9 tables\n",
    "authors": [
      "Guodong Ding",
      "Fadime Sener",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10352"
  },
  {
    "id": "arXiv:2210.10354",
    "title": "Stating Comparison Score Uncertainty and Verification Decision  Confidence Towards Transparent Face Recognition",
    "abstract": "Face Recognition (FR) is increasingly used in critical verification decisions\nand thus, there is a need for assessing the trustworthiness of such decisions.\nThe confidence of a decision is often based on the overall performance of the\nmodel or on the image quality. We propose to propagate model uncertainties to\nscores and decisions in an effort to increase the transparency of verification\ndecisions. This work presents two contributions. First, we propose an approach\nto estimate the uncertainty of face comparison scores. Second, we introduce a\nconfidence measure of the system's decision to provide insights into the\nverification decision. The suitability of the comparison scores uncertainties\nand the verification decision confidences have been experimentally proven on\nthree face recognition models on two datasets.",
    "descriptor": "\nComments: Accepted at British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Marco Huber",
      "Philipp Terh\u00f6rst",
      "Florian Kirchbuchner",
      "Naser Damer",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10354"
  },
  {
    "id": "arXiv:2210.10358",
    "title": "Leveraging a New Spanish Corpus for Multilingual and Crosslingual  Metaphor Detection",
    "abstract": "The lack of wide coverage datasets annotated with everyday metaphorical\nexpressions for languages other than English is striking. This means that most\nresearch on supervised metaphor detection has been published only for that\nlanguage. In order to address this issue, this work presents the first corpus\nannotated with naturally occurring metaphors in Spanish large enough to develop\nsystems to perform metaphor detection. The presented dataset, CoMeta, includes\ntexts from various domains, namely, news, political discourse, Wikipedia and\nreviews. In order to label CoMeta, we apply the MIPVU method, the guidelines\nmost commonly used to systematically annotate metaphor on real data. We use our\nnewly created dataset to provide competitive baselines by fine-tuning several\nmultilingual and monolingual state-of-the-art large language models.\nFurthermore, by leveraging the existing VUAM English data in addition to\nCoMeta, we present the, to the best of our knowledge, first cross-lingual\nexperiments on supervised metaphor detection. Finally, we perform a detailed\nerror analysis that explores the seemingly high transfer of everyday metaphor\nacross these two languages and datasets.",
    "descriptor": "",
    "authors": [
      "Elisa Sanchez-Bayona",
      "Rodrigo Agerri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10358"
  },
  {
    "id": "arXiv:2210.10360",
    "title": "Adaptive Neural Network Ensemble Using Frequency Distribution",
    "abstract": "Neural network (NN) ensembles can reduce large prediction variance of NN and\nimprove prediction accuracy. For highly nonlinear problems with insufficient\ndata set, the prediction accuracy of NN models becomes unstable, resulting in a\ndecrease in the accuracy of ensembles. Therefore, this study proposes a\nfrequency distribution-based ensemble that identifies core prediction values,\nwhich are expected to be concentrated near the true prediction value. The\nfrequency distribution-based ensemble classifies core prediction values\nsupported by multiple prediction values by conducting statistical analysis with\na frequency distribution, which is based on various prediction values obtained\nfrom a given prediction point. The frequency distribution-based ensemble can\nimprove predictive performance by excluding prediction values with low accuracy\nand coping with the uncertainty of the most frequent value. An adaptive\nsampling strategy that sequentially adds samples based on the core prediction\nvariance calculated as the variance of the core prediction values is proposed\nto improve the predictive performance of the frequency distribution-based\nensemble efficiently. Results of various case studies show that the prediction\naccuracy of the frequency distribution-based ensemble is higher than that of\nKriging and other existing ensemble methods. In addition, the proposed adaptive\nsampling strategy effectively improves the predictive performance of the\nfrequency distribution-based ensemble compared with the previously developed\nspace-filling and prediction variance-based strategies.",
    "descriptor": "",
    "authors": [
      "Ungki Lee",
      "Namwoo Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10360"
  },
  {
    "id": "arXiv:2210.10362",
    "title": "CPL: Counterfactual Prompt Learning for Vision and Language Models",
    "abstract": "Prompt tuning is a new few-shot transfer learning technique that only tunes\nthe learnable prompt for pre-trained vision and language models such as CLIP.\nHowever, existing prompt tuning methods tend to learn spurious or entangled\nrepresentations, which leads to poor generalization to unseen concepts. Towards\nnon-spurious and efficient prompt learning from limited examples, this paper\npresents a novel \\underline{\\textbf{C}}ounterfactual\n\\underline{\\textbf{P}}rompt \\underline{\\textbf{L}}earning (CPL) method for\nvision and language models, which simultaneously employs counterfactual\ngeneration and contrastive learning in a joint optimization framework.\nParticularly, CPL constructs counterfactual by identifying minimal non-spurious\nfeature change between semantically-similar positive and negative samples that\ncauses concept change, and learns more generalizable prompt representation from\nboth factual and counterfactual examples via contrastive learning. Extensive\nexperiments demonstrate that CPL can obtain superior few-shot performance on\ndifferent vision and language tasks than previous prompt tuning methods on\nCLIP. On image classification, we achieve 3.55\\% average relative improvement\non unseen classes across seven datasets; on image-text retrieval and visual\nquestion answering, we gain up to 4.09\\% and 25.08\\% relative improvements\nacross three few-shot scenarios on unseen test sets respectively.",
    "descriptor": "",
    "authors": [
      "Xuehai He",
      "Diji Yang",
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Arjun Akula",
      "Varun Jampani",
      "Pradyumna Narayana",
      "Sugato Basu",
      "William Yang Wang",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10362"
  },
  {
    "id": "arXiv:2210.10365",
    "title": "A sensor-to-pattern calibration framework for multi-modal industrial  collaborative cells",
    "abstract": "Collaborative robotic industrial cells are workspaces where robots\ncollaborate with human operators. In this context, safety is paramount, and for\nthat a complete perception of the space where the collaborative robot is\ninserted is necessary. To ensure this, collaborative cells are equipped with a\nlarge set of sensors of multiple modalities, covering the entire work volume.\nHowever, the fusion of information from all these sensors requires an accurate\nextrinsic calibration. The calibration of such complex systems is challenging,\ndue to the number of sensors and modalities, and also due to the small\noverlapping fields of view between the sensors, which are positioned to capture\ndifferent viewpoints of the cell. This paper proposes a sensor to pattern\nmethodology that can calibrate a complex system such as a collaborative cell in\na single optimization procedure. Our methodology can tackle RGB and Depth\ncameras, as well as LiDARs. Results show that our methodology is able to\naccurately calibrate a collaborative cell containing three RGB cameras, a depth\ncamera and three 3D LiDARs.",
    "descriptor": "\nComments: Journal of Manufacturing Systems\n",
    "authors": [
      "Daniela Rato",
      "Miguel Oliveira",
      "V\u00edtor Santos",
      "Manuel Gomes",
      "Angel Sappa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10365"
  },
  {
    "id": "arXiv:2210.10369",
    "title": "Group is better than individual: Exploiting Label Topologies and Label  Relations for Joint Multiple Intent Detection and Slot Filling",
    "abstract": "Recent joint multiple intent detection and slot filling models employ label\nembeddings to achieve the semantics-label interactions. However, they treat all\nlabels and label embeddings as uncorrelated individuals, ignoring the\ndependencies among them. Besides, they conduct the decoding for the two tasks\nindependently, without leveraging the correlations between them. Therefore, in\nthis paper, we first construct a Heterogeneous Label Graph (HLG) containing two\nkinds of topologies: (1) statistical dependencies based on labels'\nco-occurrence patterns and hierarchies in slot labels; (2) rich relations among\nthe label nodes. Then we propose a novel model termed ReLa-Net. It can capture\nbeneficial correlations among the labels from HLG. The label correlations are\nleveraged to enhance semantic-label interactions. Moreover, we also propose the\nlabel-aware inter-dependent decoding mechanism to further exploit the label\ncorrelations for decoding. Experiment results show that our ReLa-Net\nsignificantly outperforms previous models. Remarkably, ReLa-Net surpasses the\nprevious best model by over 20\\% in terms of overall accuracy on MixATIS\ndataset.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Main Conference\n",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10369"
  },
  {
    "id": "arXiv:2210.10370",
    "title": "On the Perturbation Function of Ranking and Balance for Weighted Online  Bipartite Matching",
    "abstract": "Ranking and Balance are arguably the two most important algorithms in the\nonline matching literature. They achieve the same optimal competitive ratio of\n$1-1/e$ for the integral version and fractional version of online bipartite\nmatching by Karp, Vazirani, and Vazirani (STOC 1990) respectively. The two\nalgorithms have been generalized to weighted online bipartite matching\nproblems, including vertex-weighted online bipartite matching and AdWords, by\nutilizing a perturbation function. The canonical choice of the perturbation\nfunction is $f(x)=1-e^{x-1}$ as it leads to the optimal competitive ratio of\n$1-1/e$ in both settings.\nWe advance the understanding of the weighted generalizations of Ranking and\nBalance in this paper, with a focus on studying the effect of different\nperturbation functions. First, we prove that the canonical perturbation\nfunction is the \\emph{unique} optimal perturbation function for vertex-weighted\nonline bipartite matching. In stark contrast, all perturbation functions\nachieve the optimal competitive ratio of $1-1/e$ in the unweighted setting.\nSecond, we prove that the generalization of Ranking to AdWords with unknown\nbudgets using the canonical perturbation function is at most $0.624$\ncompetitive, refuting a conjecture of Vazirani (2021). More generally, as an\napplication of the first result, we prove that no perturbation function leads\nto the prominent competitive ratio of $1-1/e$ by establishing an upper bound of\n$1-1/e-0.0003$.\nFinally, we propose the online budget-additive welfare maximization problem\nthat is intermediate between AdWords and AdWords with unknown budgets, and we\ndesign an optimal $1-1/e$ competitive algorithm by generalizing Balance.",
    "descriptor": "\nComments: 16 pages, 2 figures, 9 pages appendix\n",
    "authors": [
      "Jingxun Liang",
      "Zhihao Gavin Tang",
      "Yixuan Xu",
      "Yuhao Zhang",
      "Renfei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10370"
  },
  {
    "id": "arXiv:2210.10372",
    "title": "A Study of Obstacles in Plagiarism Software Subscribing by Colleges in  Tamil Nadu",
    "abstract": "This article attempts to comprehend the current issues and hurdles that\nIndian colleges affiliated with Tamil Nadu State Universities encounter when\ntrying to subscribe to a software that detects plagiarism. The study goals are\nto determine whether colleges employ anti-plagiarism software, whether they\nensure that their student-given assignments are free of copyright infringement,\nwhether tutors teach about academic misconduct, and what people seem to think\nof anti-plagiarism software. We surveyed for this study and distributed the\nquestionnaires among college administrators, principals, and librarians.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Sakthivel N"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10372"
  },
  {
    "id": "arXiv:2210.10373",
    "title": "Virtual learning environment is pleasure or pressure",
    "abstract": "The primary aim of this study intends the perception of students towards\nonline learning in the covid-19 pandemic period. The pandemic has changed the\ntraditional concepts of the education system and broken the functions of the\neducational institutions. But, they give it an opportunity to change pedagogy.\nThe research paper discussed the students opinions on online learning and\nvirtual classroom learning. This study applied a qualitative approach and\nprepared a systematic questionnaire for data collection. The researcher\ncollected the data from 258 students from different places in India and also,\nthe disproportionate sampling used for data collection. The research mainly\nfocused on the students perception, the comfort and discomfort of e-learning,\nusing electronic devices for communication, the virtual learning is a pleasure\nor pressure to the students, the digital skills of the students and their\nactive performance. The study revealed that over 50 percent of the students are\nhaving excellent knowledge of digital skills. The students are attending online\nclasses through their personal computers or laptops and phones. The teachers\nare allowing the students to ask questions and clear the doubt of the students.\nThe study found that the students are losing social interaction with teachers,\nfriends and cannot access the library because of online classes. Finally, the\nstudents felt that online learning is a pressure instead of pleasure.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Ammaji Rajitha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10373"
  },
  {
    "id": "arXiv:2210.10374",
    "title": "Learning Universe Model for Partial Matching Networks over Multiple  Graphs",
    "abstract": "We consider the general setting for partial matching of two or multiple\ngraphs, in the sense that not necessarily all the nodes in one graph can find\ntheir correspondences in another graph and vice versa. We take a universe\nmatching perspective to this ubiquitous problem, whereby each node is either\nmatched into an anchor in a virtual universe graph or regarded as an outlier.\nSuch a universe matching scheme enjoys a few important merits, which have not\nbeen adopted in existing learning-based graph matching (GM) literature. First,\nthe subtle logic for inlier matching and outlier detection can be clearly\nmodeled, which is otherwise less convenient to handle in the pairwise matching\nscheme. Second, it enables end-to-end learning especially for universe level\naffinity metric learning for inliers matching, and loss design for gathering\noutliers together. Third, the resulting matching model can easily handle new\narriving graphs under online matching, or even the graphs coming from different\ncategories of the training set. To our best knowledge, this is the first deep\nlearning network that can cope with two-graph matching, multiple-graph\nmatching, online matching, and mixture graph matching simultaneously. Extensive\nexperimental results show the state-of-the-art performance of our method in\nthese settings.",
    "descriptor": "\nComments: 17 pages, 16 figures\n",
    "authors": [
      "Zetian Jiang",
      "Jiaxin Lu",
      "Tianzhe Wang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10374"
  },
  {
    "id": "arXiv:2210.10375",
    "title": "Co-guiding Net: Achieving Mutual Guidances between Multiple Intent  Detection and Slot Filling via Heterogeneous Semantics-Label Graphs",
    "abstract": "Recent graph-based models for joint multiple intent detection and slot\nfilling have obtained promising results through modeling the guidance from the\nprediction of intents to the decoding of slot filling. However, existing\nmethods (1) only model the \\textit{unidirectional guidance} from intent to\nslot; (2) adopt \\textit{homogeneous graphs} to model the interactions between\nthe slot semantics nodes and intent label nodes, which limit the performance.\nIn this paper, we propose a novel model termed Co-guiding Net, which implements\na two-stage framework achieving the \\textit{mutual guidances} between the two\ntasks. In the first stage, the initial estimated labels of both tasks are\nproduced, and then they are leveraged in the second stage to model the mutual\nguidances. Specifically, we propose two \\textit{heterogeneous graph attention\nnetworks} working on the proposed two \\textit{heterogeneous semantics-label\ngraphs}, which effectively represent the relations among the semantics nodes\nand label nodes. Experiment results show that our model outperforms existing\nmodels by a large margin, obtaining a relative improvement of 19.3\\% over the\nprevious best model on MixATIS dataset in overall accuracy.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Main Conference\n",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10375"
  },
  {
    "id": "arXiv:2210.10378",
    "title": "Variational Model Perturbation for Source-Free Domain Adaptation",
    "abstract": "We aim for source-free domain adaptation, where the task is to deploy a model\npre-trained on source domains to target domains. The challenges stem from the\ndistribution shift from the source to the target domain, coupled with the\nunavailability of any source data and labeled target data for optimization.\nRather than fine-tuning the model by updating the parameters, we propose to\nperturb the source model to achieve adaptation to target domains. We introduce\nperturbations into the model parameters by variational Bayesian inference in a\nprobabilistic framework. By doing so, we can effectively adapt the model to the\ntarget domain while largely preserving the discriminative ability. Importantly,\nwe demonstrate the theoretical connection to learning Bayesian neural networks,\nwhich proves the generalizability of the perturbed model to target domains. To\nenable more efficient optimization, we further employ a parameter sharing\nstrategy, which substantially reduces the learnable parameters compared to a\nfully Bayesian neural network. Our model perturbation provides a new\nprobabilistic way for domain adaptation which enables efficient adaptation to\ntarget domains while maximally preserving knowledge in source models.\nExperiments on several source-free benchmarks under three different evaluation\nsettings verify the effectiveness of the proposed variational model\nperturbation for source-free domain adaptation.",
    "descriptor": "",
    "authors": [
      "Mengmeng Jing",
      "Xiantong Zhen",
      "Jingjing Li",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10378"
  },
  {
    "id": "arXiv:2210.10386",
    "title": "Virtual Screening on FPGA: Performance and Energy versus Effort",
    "abstract": "With their widespread availability, FPGA-based accelerators cards have become\nan alternative to GPUs and CPUs to accelerate computing in applications with\ncertain requirements (like energy efficiency) or properties (like fixed-point\ncomputations). In this paper we show results and experiences from mapping an\nindustrial application used for drug discovery on several types of\naccelerators. We especially highlight the effort versus benefit of FPGAs\ncompared to CPUs and GPUs in terms of performance and energy efficiency. For\nthis application, even with extensive use of FPGA-specific features, and\nperforming different optimizations, results on GPUs are still better, both in\nterms of energy and performance.",
    "descriptor": "\nComments: To be published at H2RC 2022 - this https URL\n",
    "authors": [
      "Tom Vander Aa",
      "Tom Haber",
      "Thomas J. Ashby",
      "Roel Wuyts",
      "Wilfried Verachtert"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.10386"
  },
  {
    "id": "arXiv:2210.10390",
    "title": "On the differential spectrum of a class of APN power functions over odd  characteristic finite fields and their $c$-differential properties",
    "abstract": "Only three classes of Almost Perfect Nonlinear (for short, APN) power\nfunctions over odd characteristic finite fields have been investigated in the\nliterature, and their differential spectra were determined. The differential\nuniformity of the power function $F(x)=x^{\\frac{p^{n}-3}{2}}$ over the finite\nfield $F_{p^n}$ of order $p^n$ (where $p$ is an odd prime), was studied by\nHelleseth and Sandberg in 1997, where $p^n\\equiv3\\pmod{4}$ is an odd prime\npower with $p^n>7$. It was shown that $F$ is PN when $p^n=27$, APN when $5$ is\na nonsquare in $F_{p^n}$, and differentially $3$-uniform when $5$ is a square\nin $F_{p^n}$. In this paper, by investigating some equation systems and certain\ncharacter sums over $F_{p^n}$, the differential spectrum of $F$ is completely\ndetermined. We focusing on the power functions $x^d$ with even $d$ over\n$F_{p^n}$ ($p$ odd), the power functions $F$ we consider are APN which are of\nthe lowest differential uniformity and the nontrivial differential spectrum.\nMoreover, we examine the extension of the so-called $c$-differential uniformity\nby investigating the $c$-differential properties of $F$. Specifically, an upper\nbound of the $c$-differential uniformity of $F$ is given, and its\n$c$-differential spectrum is considered in the case where $c=-1$. Finally, we\nemphasize that, throughout our study of the differential spectrum of the\nconsidered power functions, we provide methods for evaluating sums of specific\ncharacters with connections to elliptic curves and for determining the number\nof solutions of specific systems of equations over finite fields.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.09822\n",
    "authors": [
      "Haode Yan",
      "Sihem Mesnager",
      "Xiantong Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10390"
  },
  {
    "id": "arXiv:2210.10392",
    "title": "Spatio-channel Attention Blocks for Cross-modal Crowd Counting",
    "abstract": "Crowd counting research has made significant advancements in real-world\napplications, but it remains a formidable challenge in cross-modal settings.\nMost existing methods rely solely on the optical features of RGB images,\nignoring the feasibility of other modalities such as thermal and depth images.\nThe inherently significant differences between the different modalities and the\ndiversity of design choices for model architectures make cross-modal crowd\ncounting more challenging. In this paper, we propose Cross-modal Spatio-Channel\nAttention (CSCA) blocks, which can be easily integrated into any\nmodality-specific architecture. The CSCA blocks first spatially capture global\nfunctional correlations among multi-modality with less overhead through\nspatial-wise cross-modal attention. Cross-modal features with spatial attention\nare subsequently refined through adaptive channel-wise feature aggregation. In\nour experiments, the proposed block consistently shows significant performance\nimprovement across various backbone networks, resulting in state-of-the-art\nresults in RGB-T and RGB-D crowd counting.",
    "descriptor": "",
    "authors": [
      "Youjia Zhang",
      "Soyun Choi",
      "Sungeun Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10392"
  },
  {
    "id": "arXiv:2210.10394",
    "title": "Near-optimal Coresets for Robust Clustering",
    "abstract": "We consider robust clustering problems in $\\mathbb{R}^d$, specifically\n$k$-clustering problems (e.g., $k$-Median and $k$-Means with $m$ outliers,\nwhere the cost for a given center set $C \\subset \\mathbb{R}^d$ aggregates the\ndistances from $C$ to all but the furthest $m$ data points, instead of all\npoints as in classical clustering. We focus on the $\\epsilon$-coreset for\nrobust clustering, a small proxy of the dataset that preserves the clustering\ncost within $\\epsilon$-relative error for all center sets. Our main result is\nan $\\epsilon$-coreset of size $O(m + \\mathrm{poly}(k \\epsilon^{-1}))$ that can\nbe constructed in near-linear time. This significantly improves previous\nresults, which either suffers an exponential dependence on $(m + k)$ [Feldman\nand Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al.,\nFOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and\nthe fact that it is isolated from other factors may be crucial for dealing with\nlarge number of outliers. We construct our coresets by adapting to the outlier\nsetting a recent framework [Braverman et al., FOCS'22] which was designed for\ncapacity-constrained clustering, overcoming a new challenge that the\nparticipating terms in the cost, particularly the excluded $m$ outlier points,\nare dependent on the center set $C$. We validate our coresets on various\ndatasets, and we observe a superior size-accuracy tradeoff compared with\npopular baselines including uniform sampling and sensitivity sampling. We also\nachieve a significant speedup of existing approximation algorithms for robust\nclustering using our coresets.",
    "descriptor": "",
    "authors": [
      "Lingxiao Huang",
      "Shaofeng H.-C. Jiang",
      "Jianing Lou",
      "Xuan Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10394"
  },
  {
    "id": "arXiv:2210.10400",
    "title": "Tourist Guidance Robot Based on HyperCLOVA",
    "abstract": "This paper describes our system submitted to Dialogue Robot Competition 2022.\nOur proposed system is a combined model of rule-based and generation-based\ndialog systems. The system utilizes HyperCLOVA, a Japanese foundation model,\nnot only to generate responses but also summarization, search information, etc.\nWe also used our original speech recognition system, which was fine-tuned for\nthis dialog task. As a result, our system ranked second in the preliminary\nround and moved on to the finals.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Takato Yamazaki",
      "Katsumasa Yoshikawa",
      "Toshiki Kawamoto",
      "Masaya Ohagi",
      "Tomoya Mizumoto",
      "Shuta Ichimura",
      "Yusuke Kida",
      "Toshinori Sato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10400"
  },
  {
    "id": "arXiv:2210.10401",
    "title": "Asynchronous RIS-assisted Localization: A Comprehensive Analysis of  Fundamental Limits",
    "abstract": "The reconfigurable intelligent surface (RIS) has drawn considerable attention\nfor its ability to enhance the performance of not only the wireless\ncommunication but also the indoor localization with low-cost. This paper\ninvestigates the performance limits of the RIS-based near-field localization in\nthe asynchronous scenario, and analyzes the impact of each part of the cascaded\nchannel on the localization performance. The Fisher information matrix (FIM)\nand the position error bound (PEB) are derived. Besides, we also derive the\nequivalent Fisher information (EFI) for the position-related intermediate\nparameters. Enabled by the derived EFI, we show that the information for both\nthe distance and the direction of the user can be obtained when the near-field\nspherical wavefront is considered for the RIS-User equipment (UE) part of the\nchannel, while only the direction of the UE can be inferred in the far-field\nscenario. For the base station (BS)-RIS part of the channel, we reveal that\nthis part of the channel determines the type of the gain provided by the BS\nantenna array. We also show that the well-known focusing control scheme for\nRIS, which maximizes the received SNR, is not always a good choice and may\ndegrade the localization performance in the asynchronous scenario. The\nsimulation results validate the analytic work. The impact of the focusing\ncontrol scheme on the PEB performances under synchronous and asynchronous\nconditions is also investigated.",
    "descriptor": "",
    "authors": [
      "Ziyi Gong",
      "Liang Wu",
      "Zaichen Zhang",
      "Jian Dang",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10401"
  },
  {
    "id": "arXiv:2210.10403",
    "title": "Segmentation-free Direct Iris Localization Networks",
    "abstract": "This paper proposes an efficient iris localization method without using iris\nsegmentation and circle fitting. Conventional iris localization methods first\nextract iris regions by using semantic segmentation methods such as U-Net.\nAfterward, the inner and outer iris circles are localized using the traditional\ncircle fitting algorithm. However, this approach requires high-resolution\nencoder-decoder networks for iris segmentation, so it causes computational\ncosts to be high. In addition, traditional circle fitting tends to be sensitive\nto noise in input images and fitting parameters, causing the iris recognition\nperformance to be poor. To solve these problems, we propose an iris\nlocalization network (ILN), that can directly localize pupil and iris circles\nwith eyelid points from a low-resolution iris image. We also introduce a pupil\nrefinement network (PRN) to improve the accuracy of pupil localization.\nExperimental results show that the combination of ILN and PRN works in 34.5 ms\nfor one iris image on a CPU, and its localization performance outperforms\nconventional iris segmentation methods. In addition, generalized evaluation\nresults show that the proposed method has higher robustness for datasets in\ndifferent domain than other segmentation methods. Furthermore, we also confirm\nthat the proposed ILN and PRN improve the iris recognition accuracy.",
    "descriptor": "\nComments: Accepted by WACV 2023\n",
    "authors": [
      "Takahiro Toizumi",
      "Koichi Takahashi",
      "Masato Tsukada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10403"
  },
  {
    "id": "arXiv:2210.10406",
    "title": "Effective Capacity of URLLC over Parallel Fading Channels with Imperfect  Channel State Information",
    "abstract": "This paper investigates the effective capacity of a point-to-point\nultra-reliable low latency communication (URLLC) transmission over multiple\nparallel sub-channels at finite blocklength (FBL) with imperfect channel state\ninformation (CSI). Based on reasonable assumptions and approximations, we\nderive the effective capacity as a function of the pilot length, decoding error\nprobability, transmit power and the sub-channel number. Then we reveal\nsignificant impact of the above parameters on the effective capacity. A\nclosed-form lower bound of the effective capacity is derived and an alternating\noptimization based algorithm is proposed to find the optimal pilot length and\ndecoding error probability. Simulation results validate our theoretical\nanalysis and show that the closed-form lower bound is very tight. In addition,\nthrough the simulations of the optimized effective capacity, insights for pilot\nlength and decoding error probability optimization are provided to evaluate the\noptimal parameters in realistic systems.",
    "descriptor": "\nComments: 30 pages, 7 figures.Accepted by China Communication\n",
    "authors": [
      "Hongsen Peng",
      "Meixia Tao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10406"
  },
  {
    "id": "arXiv:2210.10409",
    "title": "Domain generalization Person Re-identification on Attention-aware  multi-operation strategery",
    "abstract": "Domain generalization person re-identification (DG Re-ID) aims to directly\ndeploy a model trained on the source domain to the unseen target domain with\ngood generalization, which is a challenging problem and has practical value in\na real-world deployment. In the existing DG Re-ID methods, invariant operations\nare effective in extracting domain generalization features, and Instance\nNormalization (IN) or Batch Normalization (BN) is used to alleviate the bias to\nunseen domains. Due to domain-specific information being used to capture\ndiscriminability of the individual source domain, the generalized ability for\nunseen domains is unsatisfactory. To address this problem, an Attention-aware\nMulti-operation Strategery (AMS) for DG Re-ID is proposed to extract more\ngeneralized features. We investigate invariant operations and construct a\nmulti-operation module based on IN and group whitening (GW) to extract\ndomain-invariant feature representations. Furthermore, we analyze different\ndomain-invariant characteristics, and apply spatial attention to the IN\noperation and channel attention to the GW operation to enhance the\ndomain-invariant features. The proposed AMS module can be used as a\nplug-and-play module to incorporate into existing network architectures.\nExtensive experimental results show that AMS can effectively enhance the\nmodel's generalization ability to unseen domains and significantly improves the\nrecognition performance in DG Re-ID on three protocols with ten datasets.",
    "descriptor": "",
    "authors": [
      "Yingchun Guo",
      "Huan He",
      "Ye Zhu",
      "Yang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10409"
  },
  {
    "id": "arXiv:2210.10411",
    "title": "Shape calculus for fitted and unfitted discretizations: domain  transformations vs. boundary-face dilations",
    "abstract": "Shape calculus concerns the calculation of directional derivatives of some\nquantity of interest, typically expressed as an integral. This article\nintroduces a type of shape calculus based on localized dilation of boundary\nfaces through perturbations of a level-set function. The calculus is tailored\nfor shape optimization problems where a partial differential equation is\nnumerically solved using a fictitious-domain method. That is, the boundary of a\ndomain is allowed to cut arbitrarily through a computational mesh, which is\nheld fixed throughout the computations. Directional derivatives of a volume or\nsurface integral using the new shape calculus yields purely boundary-supported\nexpressions, and the involved integrands are only required to be element-wise\nsmooth. However, due to this low regularity, only one-sided differentiability\ncan be guaranteed in general. The dilation concept introduced here differs from\nthe standard approach to shape calculus, which is based on domain\ntransformations. The use of domain transformations is closely linked the the\nuse of traditional body-fitted discretization approaches, where the\ncomputational mesh is deformed to conform to the changing domain shape. The\ndirectional derivatives coming out of a shape calculus using deforming meshes\nunder domain transformations are different then the ones from the\nboundary-dilation approach using fixed meshes; the former are not purely\nboundary supported but contain information also from the interior.",
    "descriptor": "",
    "authors": [
      "Martin Berggren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10411"
  },
  {
    "id": "arXiv:2210.10413",
    "title": "Real Image Super-Resolution using GAN through modeling of LR and HR  process",
    "abstract": "The current existing deep image super-resolution methods usually assume that\na Low Resolution (LR) image is bicubicly downscaled of a High Resolution (HR)\nimage. However, such an ideal bicubic downsampling process is different from\nthe real LR degradations, which usually come from complicated combinations of\ndifferent degradation processes, such as camera blur, sensor noise, sharpening\nartifacts, JPEG compression, and further image editing, and several times image\ntransmission over the internet and unpredictable noises. It leads to the highly\nill-posed nature of the inverse upscaling problem. To address these issues, we\npropose a GAN-based SR approach with learnable adaptive sinusoidal\nnonlinearities incorporated in LR and SR models by directly learn degradation\ndistributions and then synthesize paired LR/HR training data to train the\ngeneralized SR model to real image degradations. We demonstrate the\neffectiveness of our proposed approach in quantitative and qualitative\nexperiments.",
    "descriptor": "\nComments: Accepted in 18th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2022. arXiv admin note: text overlap with arXiv:2009.03693, arXiv:2005.00953\n",
    "authors": [
      "Rao Muhammad Umer",
      "Christian Micheloni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10413"
  },
  {
    "id": "arXiv:2210.10414",
    "title": "High-Resolution Depth Estimation for 360-degree Panoramas through  Perspective and Panoramic Depth Images Registration",
    "abstract": "We propose a novel approach to compute high-resolution (2048x1024 and higher)\ndepths for panoramas that is significantly faster and qualitatively and\nqualitatively more accurate than the current state-of-the-art method\n(360MonoDepth). As traditional neural network-based methods have limitations in\nthe output image sizes (up to 1024x512) due to GPU memory constraints, both\n360MonoDepth and our method rely on stitching multiple perspective disparity or\ndepth images to come out a unified panoramic depth map. However, to achieve\nglobally consistent stitching, [23] relied on solving extensive disparity map\nalignment and Poisson-based blending problems, leading to high computation\ntime. Instead, we propose to use an existing panoramic depth map (computed in\nreal-time by any panorama-based method) as the common target for the individual\nperspective depth maps to register to. This key idea made producing globally\nconsistent stitching results from a straightforward task. Our experiments show\nthat our method generates qualitatively better results than existing\npanorama-based methods, and further outperforms them quantitatively on datasets\nunseen by these methods.",
    "descriptor": "\nComments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023, to appear\n",
    "authors": [
      "Chi-Han Peng",
      "Jiayao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10414"
  },
  {
    "id": "arXiv:2210.10415",
    "title": "Optimal computational costs of AFEM with optimal local $hp$-robust  multigrid solver",
    "abstract": "In this work, a fully adaptive finite element algorithm for symmetric\nsecond-order elliptic diffusion problems with inexact solver is developed. The\ndiscrete systems are treated by a local higher-order geometric multigrid method\nextending the approach of [Mira\\c{c}i, Pape\\v{z}, Vohral\\'{i}k, SIAM J. Sci.\nComput. (2021)]. We show that the iterative solver contracts the algebraic\nerror robustly with respect to the polynomial degree $p \\ge 1$ and the (local)\nmesh size $h$. We further prove that the built-in algebraic error estimator is\n$h$- and $p$-robustly equivalent to the algebraic error. The proofs rely on\nsuitably chosen robust stable decompositions and a strengthened Cauchy-Schwarz\ninequality on bisection-generated meshes. Together, this yields that the\nproposed adaptive algorithm has optimal computational cost. Numerical\nexperiments confirm the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Michael Innerberger",
      "Ani Mira\u00e7i",
      "Dirk Praetorius",
      "Julian Streitberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10415"
  },
  {
    "id": "arXiv:2210.10416",
    "title": "Hybrid-Regressive Neural Machine Translation",
    "abstract": "In this work, we empirically confirm that non-autoregressive translation with\nan iterative refinement mechanism (IR-NAT) suffers from poor acceleration\nrobustness because it is more sensitive to decoding batch size and computing\ndevice setting than autoregressive translation (AT). Inspired by it, we attempt\nto investigate how to combine the strengths of autoregressive and\nnon-autoregressive translation paradigms better. To this end, we demonstrate\nthrough synthetic experiments that prompting a small number of AT's predictions\ncan promote one-shot non-autoregressive translation to achieve the equivalent\nperformance of IR-NAT. Following this line, we propose a new two-stage\ntranslation prototype called hybrid-regressive translation (HRT). Specifically,\nHRT first generates discontinuous sequences via autoregression (e.g., make a\nprediction every k tokens, k>1) and then fills in all previously skipped tokens\nat once in a non-autoregressive manner. We also propose a bag of techniques to\neffectively and efficiently train HRT without adding any model parameters. HRT\nachieves the state-of-the-art BLEU score of 28.49 on the WMT En-De task and is\nat least 1.5x faster than AT, regardless of batch size and device. In addition,\nanother bonus of HRT is that it successfully inherits the good characteristics\nof AT in the deep-encoder-shallow-decoder architecture. Concretely, compared to\nthe vanilla HRT with a 6-layer encoder and 6-layer decoder, the inference speed\nof HRT with a 12-layer encoder and 1-layer decoder is further doubled on both\nGPU and CPU without BLEU loss.",
    "descriptor": "\nComments: Submitted to ICLR 2023\n",
    "authors": [
      "Qiang Wang",
      "Xinhui Hu",
      "Ming Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10416"
  },
  {
    "id": "arXiv:2210.10418",
    "title": "p$^3$VAE: a physics-integrated generative model. Application to the  semantic segmentation of optical remote sensing images",
    "abstract": "The combination of machine learning models with physical models is a recent\nresearch path to learn robust data representations. In this paper, we introduce\np$^3$VAE, a generative model that integrates a perfect physical model which\npartially explains the true underlying factors of variation in the data. To\nfully leverage our hybrid design, we propose a semi-supervised optimization\nprocedure and an inference scheme that comes along meaningful uncertainty\nestimates. We apply p$^3$VAE to the semantic segmentation of high-resolution\nhyperspectral remote sensing images. Our experiments on a simulated data set\ndemonstrated the benefits of our hybrid model against conventional machine\nlearning models in terms of extrapolation capabilities and interpretability. In\nparticular, we show that p$^3$VAE naturally has high disentanglement\ncapabilities. Our code and data have been made publicly available at\nhttps://github.com/Romain3Ch216/p3VAE.",
    "descriptor": "\nComments: 21 pages, 11 figures, submitted to the International Journal of Computer Vision\n",
    "authors": [
      "Romain Thoreau",
      "Laurent Risser",
      "V\u00e9ronique Achard",
      "B\u00e9atrice Berthelot",
      "Xavier Briottet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10418"
  },
  {
    "id": "arXiv:2210.10420",
    "title": "Modeling the impact of external influence on green behaviour spreading  in multilayer financial networks",
    "abstract": "Growing awareness of the impact of business activity on the environment\nincreases the pressure on governing bodies to address this issue. One\npossibility is to encourage or force the market into green behaviours. However,\nit is often hard to predict how different actions affect the market. Thus, to\nhelp with that, in this paper, we have proposed the green behaviour spreading\nmodel in the bank-company multilayer network. This model allows assessing how\nvarious elements like the duration of external influence, targeted market\nsegment, or intensity of action affect the outcome regarding market greening\nlevel. The model evaluation results indicate that governing bodies, depending\non the market \"openness\" to green activities, can adjust the duration and\nintensity of the proposed action. The strength of the impact can be changed by\nthe public or private authority with the use of obligatory or voluntary rules\nand the proportion of influenced banks. This research may be helpful in the\nprocess of creating the optimal setups and increasing the performance of\ngreening policies implementation.",
    "descriptor": "\nComments: IEEE DSAA 2022 The 9th IEEE International Conference on Data Science and Advanced Analytics\n",
    "authors": [
      "Magdalena Zio\u0142o",
      "Piotr Br\u00f3dka",
      "Anna Spoz",
      "Jaros\u0142aw Jankowski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.10420"
  },
  {
    "id": "arXiv:2210.10421",
    "title": "Multi-view Gait Recognition based on Siamese Vision Transformer",
    "abstract": "While the Vision Transformer has been used in gait recognition, its\napplication in multi-view gait recognition is still limited. Different views\nsignificantly affect the extraction and identification accuracy of the\ncharacteristics of gait contour. To address this, this paper proposes a Siamese\nMobile Vision Transformer (SMViT). This model not only focuses on the local\ncharacteristics of the human gait space but also considers the characteristics\nof long-distance attention associations, which can extract multi-dimensional\nstep status characteristics. In addition, it describes how different\nperspectives affect gait characteristics and generate reliable perspective\nfeature relationship factors. The average recognition rate of SMViT on the\nCASIA B data set reached 96.4%. The experimental results show that SMViT can\nattain state-of-the-art performance compared to advanced step recognition\nmodels such as GaitGAN, Multi_view GAN, Posegait and other gait recognition\nmodels.",
    "descriptor": "\nComments: 13 pages,9 figures,1 table\n",
    "authors": [
      "Yanchen Yang",
      "Lijun Yun",
      "Ruoyu Li",
      "Feiyan Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10421"
  },
  {
    "id": "arXiv:2210.10424",
    "title": "SR-LIO: LiDAR-Inertial Odometry with Sweep Reconstruction",
    "abstract": "This paper proposes a novel LiDAR-inertial odometry (LIO), named SR-LIO,\nbased on an improved bundle adjustment (BA) framework. The core of our SR-LIO\nis a novel sweep reconstruction method, which segments and reconstructs raw\ninput sweeps from spinning LiDAR to obtain reconstructed sweeps with higher\nfrequency. Such method can effectively reduce the time interval for each IMU\npre-integration, reducing the IMU pre-integration error and enabling the usage\nof BA based LIO optimization. In order to make all the states during the period\nof a reconstructed sweep can be equally optimized, we further propose\nmulti-segment joint LIO optimization, which allows the state of each sweep\nsegment to be constrained from both LiDAR and IMU. Experimental results on\nthree public datasets demonstrate that our SR-LIO outperforms all existing\nstate-of-the-art methods on accuracy, and reducing the IMU pre-integration\nerror via the proposed sweep reconstruction is very importance for the success\nof a BA based LIO framework. The source code of SR-LIO is publicly available\nfor the development of the community.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Robotics\n",
    "authors": [
      "Zikang Yuan",
      "Fengtian Lang",
      "Xin Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10424"
  },
  {
    "id": "arXiv:2210.10426",
    "title": "Pseudo-Label Noise Suppression Techniques for Semi-Supervised Semantic  Segmentation",
    "abstract": "Semi-supervised learning (SSL) can reduce the need for large labelled\ndatasets by incorporating unlabelled data into the training. This is\nparticularly interesting for semantic segmentation, where labelling data is\nvery costly and time-consuming. Current SSL approaches use an initially\nsupervised trained model to generate predictions for unlabelled images, called\npseudo-labels, which are subsequently used for training a new model from\nscratch. Since the predictions usually do not come from an error-free neural\nnetwork, they are naturally full of errors. However, training with partially\nincorrect labels often reduce the final model performance. Thus, it is crucial\nto manage errors/noise of pseudo-labels wisely. In this work, we use three\nmechanisms to control pseudo-label noise and errors: (1) We construct a solid\nbase framework by mixing images with cow-patterns on unlabelled images to\nreduce the negative impact of wrong pseudo-labels. Nevertheless, wrong\npseudo-labels still have a negative impact on the performance. Therefore, (2)\nwe propose a simple and effective loss weighting scheme for pseudo-labels\ndefined by the feedback of the model trained on these pseudo-labels. This\nallows us to soft-weight the pseudo-label training examples based on their\ndetermined confidence score during training. (3) We also study the common\npractice to ignore pseudo-labels with low confidence and empirically analyse\nthe influence and effect of pseudo-labels with different confidence ranges on\nSSL and the contribution of pseudo-label filtering to the achievable\nperformance gains. We show that our method performs superior to state\nof-the-art alternatives on various datasets. Furthermore, we show that our\nfindings also transfer to other tasks such as human pose estimation. Our code\nis available at https://github.com/ChristmasFan/SSL_Denoising_Segmentation.",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Sebastian Scherer",
      "Robin Sch\u00f6n",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10426"
  },
  {
    "id": "arXiv:2210.10428",
    "title": "MC-hands-1M: A glove-wearing hand dataset for pose estimation",
    "abstract": "Nowadays, the need for large amounts of carefully and complexly annotated\ndata for the training of computer vision modules continues to grow.\nFurthermore, although the research community presents state of the art\nsolutions to many problems, there exist special cases, such as the pose\nestimation and tracking of a glove-wearing hand, where the general approaches\ntend to be unable to provide an accurate solution or fail completely. In this\nwork, we are presenting a synthetic dataset1 for 3D pose estimation of\nglove-wearing hands, in order to depict the value of data synthesis in computer\nvision. The dataset is used to fine-tune a public hand joint detection model,\nachieving significant performance in both synthetic and real images of\nglove-wearing hands.",
    "descriptor": "",
    "authors": [
      "Prodromos Boutis",
      "Zisis Batzos",
      "Konstantinos Konstantoudakis",
      "Anastasios Dimou",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10428"
  },
  {
    "id": "arXiv:2210.10431",
    "title": "Hierarchical Reinforcement Learning for Furniture Layout in Virtual  Indoor Scenes",
    "abstract": "In real life, the decoration of 3D indoor scenes through designing furniture\nlayout provides a rich experience for people. In this paper, we explore the\nfurniture layout task as a Markov decision process (MDP) in virtual reality,\nwhich is solved by hierarchical reinforcement learning (HRL). The goal is to\nproduce a proper two-furniture layout in the virtual reality of the indoor\nscenes. In particular, we first design a simulation environment and introduce\nthe HRL formulation for a two-furniture layout. We then apply a hierarchical\nactor-critic algorithm with curriculum learning to solve the MDP. We conduct\nour experiments on a large-scale real-world interior layout dataset that\ncontains industrial designs from professional designers. Our numerical results\ndemonstrate that the proposed model yields higher-quality layouts as compared\nwith the state-of-art models.",
    "descriptor": "\nComments: Accepted by Reinforcement Learning for Real Life Workshop @ NeurIPS 2022\n",
    "authors": [
      "Xinhan Di",
      "Pengqian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10431"
  },
  {
    "id": "arXiv:2210.10433",
    "title": "Multi-antenna Coded Caching at Finite-SNR: Breaking Down the Gain  Structure",
    "abstract": "Multi-antenna coded caching (CC) techniques are considered viable options for\nachieving higher data rates in future networks, especially for the prominent\nuse case of multimedia-driven applications. However, despite their\ninformation-theoretic analyses, which are thoroughly studied in the literature,\nthe research on the finite-SNR performance of multi-antenna CC techniques is\nnot yet mature. In this paper, we try bridging this gap by breaking down,\ncategorizing, and studying the effect of six crucial parameters affecting the\nfinite-SNR performance of multi-antenna CC schemes. We also investigate the\ninteraction of different parameters and clarify how they could affect the\nimplementation complexity in terms of the necessary computation and\nsubpacketization. Theoretical discussions are followed and verified by\nnumerical analysis.",
    "descriptor": "",
    "authors": [
      "MohammadJavad Salehi",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10433"
  },
  {
    "id": "arXiv:2210.10434",
    "title": "A Linguistic Investigation of Machine Learning based Contradiction  Detection Models: An Empirical Analysis and Future Perspectives",
    "abstract": "We analyze two Natural Language Inference data sets with respect to their\nlinguistic features. The goal is to identify those syntactic and semantic\nproperties that are particularly hard to comprehend for a machine learning\nmodel. To this end, we also investigate the differences between a\ncrowd-sourced, machine-translated data set (SNLI) and a collection of text\npairs from internet sources. Our main findings are, that the model has\ndifficulty recognizing the semantic importance of prepositions and verbs,\nemphasizing the importance of linguistically aware pre-training tasks.\nFurthermore, it often does not comprehend antonyms and homonyms, especially if\nthose are depending on the context. Incomplete sentences are another problem,\nas well as longer paragraphs and rare words or phrases. The study shows that\nautomated language understanding requires a more informed approach, utilizing\nas much external knowledge as possible throughout the training process.",
    "descriptor": "\nComments: Accepted at ICMLA 2022, 5 pages, 2 tables\n",
    "authors": [
      "Maren Pielka",
      "Felix Rode",
      "Lisa Pucknat",
      "Tobias Deu\u00dfer",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10434"
  },
  {
    "id": "arXiv:2210.10436",
    "title": "LightEA: A Scalable, Robust, and Interpretable Entity Alignment  Framework via Three-view Label Propagation",
    "abstract": "Entity Alignment (EA) aims to find equivalent entity pairs between KGs, which\nis the core step of bridging and integrating multi-source KGs. In this paper,\nwe argue that existing GNN-based EA methods inherit the inborn defects from\ntheir neural network lineage: weak scalability and poor interpretability.\nInspired by recent studies, we reinvent the Label Propagation algorithm to\neffectively run on KGs and propose a non-neural EA framework -- LightEA,\nconsisting of three efficient components: (i) Random Orthogonal Label\nGeneration, (ii) Three-view Label Propagation, and (iii) Sparse Sinkhorn\nIteration. According to the extensive experiments on public datasets, LightEA\nhas impressive scalability, robustness, and interpretability. With a mere tenth\nof time consumption, LightEA achieves comparable results to state-of-the-art\nmethods across all datasets and even surpasses them on many.",
    "descriptor": "\nComments: 15 pages; Accepted by EMNLP2022 (Main Conf)\n",
    "authors": [
      "Xin Mao",
      "Wenting Wang",
      "Yuanbin Wu",
      "Man Lan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10436"
  },
  {
    "id": "arXiv:2210.10441",
    "title": "Efficient delivery of Robotics Programming educational content using  Cloud Robotics",
    "abstract": "In this paper, we report on our use of cloud-robotics solutions to teach a\nRobotics Applications Programming course at Zurich University of Applied\nSciences (ZHAW). The usage of Kubernetes based cloud computing environment\ncombined with real robots -- turtlebots and Niryo arms -- allowed us to: 1)\nminimize the set up times required to provide a Robotic Operating System (ROS)\nsimulation and development environment to all students independently of their\nlaptop architecture and OS; 2) provide a seamless \"simulation to real\"\nexperience preserving the exciting experience of writing software interacting\nwith the physical world; and 3) sharing GPUs across multiple student groups,\nthus using resources efficiently.\nWe describe our requirements, solution design, experience working with the\nsolution in the educational context and areas where it can be further improved.\nThis may be of interest to other educators who may want to replicate our\nexperience.",
    "descriptor": "\nComments: 7th International Conference on Robotics and Automation Engineering, ICRAE, 2022. arXiv admin note: text overlap with arXiv:2210.03936\n",
    "authors": [
      "Sean Murphy",
      "Leonardo Militano",
      "Giovanni Toffetti",
      "Remo Maurer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10441"
  },
  {
    "id": "arXiv:2210.10442",
    "title": "Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical  Error Correction",
    "abstract": "Chinese Grammatical Error Correction (CGEC) is both a challenging NLP task\nand a common application in human daily life. Recently, many data-driven\napproaches are proposed for the development of CGEC research. However, there\nare two major limitations in the CGEC field: First, the lack of high-quality\nannotated training corpora prevents the performance of existing CGEC models\nfrom being significantly improved. Second, the grammatical errors in widely\nused test sets are not made by native Chinese speakers, resulting in a\nsignificant gap between the CGEC models and the real application. In this\npaper, we propose a linguistic rules-based approach to construct large-scale\nCGEC training corpora with automatically generated grammatical errors.\nAdditionally, we present a challenging CGEC benchmark derived entirely from\nerrors made by native Chinese speakers in real-world scenarios. Extensive\nexperiments and detailed analyses not only demonstrate that the training data\nconstructed by our method effectively improves the performance of CGEC models,\nbut also reflect that our benchmark is an excellent resource for further\ndevelopment of the CGEC field.",
    "descriptor": "\nComments: Long paper, accepted at the Findings of EMNLP 2022\n",
    "authors": [
      "Shirong Ma",
      "Yinghui Li",
      "Rongyi Sun",
      "Qingyu Zhou",
      "Shulin Huang",
      "Ding Zhang",
      "Li Yangning",
      "Ruiyang Liu",
      "Zhongli Li",
      "Yunbo Cao",
      "Haitao Zheng",
      "Ying Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10442"
  },
  {
    "id": "arXiv:2210.10446",
    "title": "EGG-GAE: scalable graph neural networks for tabular data imputation",
    "abstract": "Missing data imputation (MDI) is crucial when dealing with tabular datasets\nacross various domains. Autoencoders can be trained to reconstruct missing\nvalues, and graph autoencoders (GAE) can additionally consider similar patterns\nin the dataset when imputing new values for a given instance. However,\npreviously proposed GAEs suffer from scalability issues, requiring the user to\ndefine a similarity metric among patterns to build the graph connectivity\nbeforehand. In this paper, we leverage recent progress in latent graph\nimputation to propose a novel EdGe Generation Graph AutoEncoder (EGG-GAE) for\nmissing data imputation that overcomes these two drawbacks. EGG-GAE works on\nrandomly sampled mini-batches of the input data (hence scaling to larger\ndatasets), and it automatically infers the best connectivity across the\nmini-batch for each architecture layer. We also experiment with several\nextensions, including an ensemble strategy for inference and the inclusion of\nwhat we call prototype nodes, obtaining significant improvements, both in terms\nof imputation error and final downstream accuracy, across multiple benchmarks\nand baselines.",
    "descriptor": "",
    "authors": [
      "Lev Telyatnikov",
      "Simone Scardapane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10446"
  },
  {
    "id": "arXiv:2210.10447",
    "title": "A New Communication Protocol with Self Error Correction",
    "abstract": "Communication in poor network environment is always a difficult problem,\nsince troubles such as bit errors and packet loss may often occur. It is\ngenerally believed that it is impossible to transmit data both accurately and\nefficiently in this case. However, this paper provides a method to transmit\ndata efficiently on the line where bit error may occur by utilizing Hamming\ncode principle. If the sender adds a small amount of redundant data to the data\nto be sent, the receiver can self-correct them when an error is detected. This\napproach takes advantage of the value of packets with errors, which should have\nbeen discarded, reduce the number of re-transmissions and improve transmission\nefficiency. Based on this method, this paper designs a custom protocol which\nworks in the data link layer and network layer. Finally, this paper verifies\nthe protocol through mathematical simulation.",
    "descriptor": "",
    "authors": [
      "Ye Tianyi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.10447"
  },
  {
    "id": "arXiv:2210.10449",
    "title": "GCDT: A Chinese RST Treebank for Multigenre and Multilingual Discourse  Parsing",
    "abstract": "A lack of large-scale human-annotated data has hampered the hierarchical\ndiscourse parsing of Chinese. In this paper, we present GCDT, the largest\nhierarchical discourse treebank for Mandarin Chinese in the framework of\nRhetorical Structure Theory (RST). GCDT covers over 60K tokens across five\ngenres of freely available text, using the same relation inventory as\ncontemporary RST treebanks for English. We also report on this dataset's\nparsing experiments, including state-of-the-art (SOTA) scores for Chinese RST\nparsing and RST parsing on the English GUM dataset, using cross-lingual\ntraining in Chinese and English with multilingual embeddings.",
    "descriptor": "\nComments: Accepted at AACL 2022\n",
    "authors": [
      "Siyao Peng",
      "Yang Janet Liu",
      "Amir Zeldes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10449"
  },
  {
    "id": "arXiv:2210.10451",
    "title": "An Empirical Analysis of SMS Scam Detection Systems",
    "abstract": "The short message service (SMS) was introduced a generation ago to the mobile\nphone users. They make up the world's oldest large-scale network, with billions\nof users and therefore attracts a lot of fraud. Due to the convergence of\nmobile network with internet, SMS based scams can potentially compromise the\nsecurity of internet services as well. In this study, we present a new SMS scam\ndataset consisting of 153,551 SMSes. This dataset that we will release publicly\nfor research purposes represents the largest publicly-available SMS scam\ndataset. We evaluate and compare the performance achieved by several\nestablished machine learning methods on the new dataset, ranging from shallow\nmachine learning approaches to deep neural networks to syntactic and semantic\nfeature models. We then study the existing models from an adversarial viewpoint\nby assessing its robustness against different level of adversarial\nmanipulation. This perspective consolidates the current state of the art in SMS\nSpam filtering, highlights the limitations and the opportunities to improve the\nexisting approaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.00953 by other authors\n",
    "authors": [
      "Muhammad Salman",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10451"
  },
  {
    "id": "arXiv:2210.10453",
    "title": "Two-layer adaptive signal control framework for large-scale  dynamically-congested networks: Combining efficient Max Pressure with  Perimeter Control",
    "abstract": "Traffic-responsive signal control is a cost-effective and easy-to-implement\nnetwork management strategy with high potential in improving performance in\ncongested networks with dynamic characteristics. Max Pressure (MP) distributed\ncontroller gained significant popularity due to its theoretically proven\nability of queue stabilization and throughput maximization under specific\nassumptions. However, its effectiveness under saturated conditions is\nquestionable, while network-wide application is limited due to high\ninstrumentation cost. Perimeter control (PC) based on the concept of the\nMacroscopic Fundamental Diagram (MFD) is a state-of-the-art aggregated strategy\nthat regulates exchange flows between regions, in order to maintain maximum\nregional travel production and prevent over-saturation. Yet, homogeneity\nassumption is hardly realistic in congested states, thus compromising PC\nefficiency. In this paper, the effectiveness of network-wide, parallel\napplication of PC and MP embedded in a two-layer control framework is assessed\nwith mesoscopic simulation. Aiming at reducing implementation cost of MP\nwithout significant performance loss, we propose a method to identify critical\nnodes for partial MP deployment. A modified version of Store-and-forward\nparadigm incorporating finite queue and spill-back consideration is used to\ntest different configurations of the proposed framework, for a real large-scale\nnetwork, in moderately and highly congested scenarios. Results show that: (i)\ncombined control of MP and PC outperforms separate MP and PC applications in\nboth demand scenarios; (ii) MP control in reduced critical node sets leads to\nsimilar or even better performance compared to full-network implementation,\nthus allowing for significant cost reduction; iii) the proposed control schemes\nimprove system performance even under demand fluctuations of up to 20% of mean.",
    "descriptor": "\nComments: Submitted to Transportation Research Part C: Emerging Technologies\n",
    "authors": [
      "Dimitrios Tsitsokas",
      "Anastasios Kouvelas",
      "Nikolas Geroliminis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10453"
  },
  {
    "id": "arXiv:2210.10454",
    "title": "Automated Content Moderation Increases Adherence to Community Guidelines",
    "abstract": "Online social media platforms use automated moderation systems to remove or\nreduce the visibility of rule-breaking content. While previous work has\ndocumented the importance of manual content moderation, the effects of\nautomated content moderation remain largely unknown, in part due to the\ntechnical and ethical challenges in assessing their impact using randomized\nexperiments. Here, in a large study of Facebook comments ($n=412$M), we used a\nfuzzy regression discontinuity design to measure the impact of automated\ncontent moderation on subsequent rule-breaking behavior (number of comments\nhidden or deleted) and engagement (number of additional comments posted). We\nfound that comment deletion decreased subsequent rule-breaking behavior in\nshorter threads (20 or fewer comments), even among other participants,\nsuggesting that the intervention prevented conversations from derailing.\nFurther, the effect of deletion on the affected user's subsequent rule-breaking\nbehavior was longer-lived than its effect on reducing commenting in general,\nsuggesting that users were deterred from rule-breaking but not from continuing\nto comment. However, hiding (rather than deleting) content had small and\nstatistically insignificant effects. Overall, our results suggest that\nautomated content moderation can increase adherence to community guidelines.",
    "descriptor": "",
    "authors": [
      "Manoel Horta Ribeiro",
      "Justin Cheng",
      "Robert West"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10454"
  },
  {
    "id": "arXiv:2210.10456",
    "title": "Group Fairness in Prediction-Based Decision Making: From Moral  Assessment to Implementation",
    "abstract": "Ensuring fairness of prediction-based decision making is based on statistical\ngroup fairness criteria. Which one of these criteria is the morally most\nappropriate one depends on the context, and its choice requires an ethical\nanalysis. In this paper, we present a step-by-step procedure integrating three\nelements: (a) a framework for the moral assessment of what fairness means in a\ngiven context, based on the recently proposed general principle of \"Fair\nequality of chances\" (FEC) (b) a mapping of the assessment's results to\nestablished statistical group fairness criteria, and (c) a method for\nintegrating the thus-defined fairness into optimal decision making. As a second\ncontribution, we show new applications of the FEC principle and show that, with\nthis extension, the FEC framework covers all types of group fairness criteria:\nindependence, separation, and sufficiency. Third, we introduce an extended\nversion of the FEC principle, which additionally allows accounting for morally\nirrelevant elements of the fairness assessment and links to well-known\nrelaxations of the fairness criteria. This paper presents a framework to\ndevelop fair decision systems in a conceptually sound way, combining the moral\nand the computational elements of fair prediction-based decision-making in an\nintegrated approach. Data and code to reproduce our results are available at\nhttps://github.com/joebaumann/fair-prediction-based-decision-making.",
    "descriptor": "\nComments: Accepted full paper at SDS2022, the 9th Swiss Conference on Data Science, code available on GitHub: this https URL\n",
    "authors": [
      "Joachim Baumann",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10456"
  },
  {
    "id": "arXiv:2210.10459",
    "title": "Estimating the coverage in 3d reconstructions of the colon from  colonoscopy videos",
    "abstract": "Colonoscopy is the most common procedure for early detection and removal of\npolyps, a critical component of colorectal cancer prevention. Insufficient\nvisual coverage of the colon surface during the procedure often results in\nmissed polyps. To mitigate this issue, reconstructing the 3D surfaces of the\ncolon in order to visualize the missing regions has been proposed. However,\nrobustly estimating the local and global coverage from such a reconstruction\nhas not been thoroughly investigated until now. In this work, we present a new\nmethod to estimate the coverage from a reconstructed colon pointcloud. Our\nmethod splits a reconstructed colon into segments and estimates the coverage of\neach segment by estimating the area of the missing surfaces. We achieve a mean\nabsolute coverage error of 3-6\\% on colon segments generated from synthetic\ncolonoscopy data and real colonography CT scans. In addition, we show good\nqualitative results on colon segments reconstructed from real colonoscopy\nvideos.",
    "descriptor": "\nComments: Accepted at Imaging Systems for GI Endoscopy workshop, the 25th International Conference on Medical Image Computing and Computer Assisted Intervention - MICCAI 2022 ISGIE\n",
    "authors": [
      "Emmanuelle Muhlethaler",
      "Erez Posner",
      "Moshe Bouhnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10459"
  },
  {
    "id": "arXiv:2210.10460",
    "title": "Antifragile Control Systems: The case of an oscillator-based network  model of urban road traffic dynamics",
    "abstract": "Urban road traffic continuously evolves under uncertainty. Existing traffic\ncontrol systems only possess a local perspective over the multiple scales of\ntraffic evolution, namely the intersection level, the corridor level, and the\nregion level respectively. Capturing uncertainty under complex traffic\nspatio-temporal interactions is a very difficult problem and we often\nexperience how fragile such systems are in reality. But luckily, despite its\ncomplex mechanics, traffic is described by various periodic phenomena. Workday\nflow distributions in the morning and evening commuting times can be exploited\nto make traffic adaptive and robust to disruptions. Additionally, controlling\ntraffic is also based on a periodic process, choosing the phase of green time\nto allocate to opposite directions right of the pass and complementary red time\nphase for adjacent directions. In our work, we consider a novel system for road\ntraffic control based on a network of interacting oscillators. Such a model has\nthe advantage to capture temporal and spatial interactions of traffic light\nphasing as well as the network-level evolution of the traffic macroscopic\nfeatures (i.e. flow, density). In this study, we propose a new realization of\nthe antifragile control framework to control a network of interacting\noscillator-based traffic light models to achieve region-level flow\noptimization. We demonstrate that antifragile control can capture the\nvolatility of the urban road environment and the uncertainty about the\ndistribution of the disruptions that can occur. We complement our\ncontrol-theoretic design and analysis with experiments on a real-world setup\ncomparatively discussing the benefits of an antifragile design for traffic\ncontrol.",
    "descriptor": "",
    "authors": [
      "Cristian Axenie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.10460"
  },
  {
    "id": "arXiv:2210.10462",
    "title": "Self-supervised Heterogeneous Graph Pre-training Based on Structural  Clustering",
    "abstract": "Recent self-supervised pre-training methods on Heterogeneous Information\nNetworks (HINs) have shown promising competitiveness over traditional\nsemi-supervised Heterogeneous Graph Neural Networks (HGNNs). Unfortunately,\ntheir performance heavily depends on careful customization of various\nstrategies for generating high-quality positive examples and negative examples,\nwhich notably limits their flexibility and generalization ability. In this\nwork, we present SHGP, a novel Self-supervised Heterogeneous Graph Pre-training\napproach, which does not need to generate any positive examples or negative\nexamples. It consists of two modules that share the same attention-aggregation\nscheme. In each iteration, the Att-LPA module produces pseudo-labels through\nstructural clustering, which serve as the self-supervision signals to guide the\nAtt-HGNN module to learn object embeddings and attention coefficients. The two\nmodules can effectively utilize and enhance each other, promoting the model to\nlearn discriminative embeddings. Extensive experiments on four real-world\ndatasets demonstrate the superior effectiveness of SHGP against\nstate-of-the-art unsupervised baselines and even semi-supervised baselines. We\nrelease our source code at: https://github.com/kepsail/SHGP.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yaming Yang",
      "Ziyu Guan",
      "Zhe Wang",
      "Wei Zhao",
      "Cai Xu",
      "Weigang Lu",
      "Jianbin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10462"
  },
  {
    "id": "arXiv:2210.10464",
    "title": "On the Power of Pre-training for Generalization in RL: Provable Benefits  and Hardness",
    "abstract": "Generalization in Reinforcement Learning (RL) aims to learn an agent during\ntraining that generalizes to the target environment. This paper studies RL\ngeneralization from a theoretical aspect: how much can we expect pre-training\nover training environments to be helpful? When the interaction with the target\nenvironment is not allowed, we certify that the best we can obtain is a\nnear-optimal policy in an average sense, and we design an algorithm that\nachieves this goal. Furthermore, when the agent is allowed to interact with the\ntarget environment, we give a surprising result showing that asymptotically,\nthe improvement from pre-training is at most a constant factor. On the other\nhand, in the non-asymptotic regime, we design an efficient algorithm and prove\na distribution-based regret bound in the target environment that is independent\nof the state-action space.",
    "descriptor": "",
    "authors": [
      "Haotian Ye",
      "Xiaoyu Chen",
      "Liwei Wang",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10464"
  },
  {
    "id": "arXiv:2210.10469",
    "title": "Robust Offline Reinforcement Learning with Gradient Penalty and  Constraint Relaxation",
    "abstract": "A promising paradigm for offline reinforcement learning (RL) is to constrain\nthe learned policy to stay close to the dataset behaviors, known as policy\nconstraint offline RL. However, existing works heavily rely on the purity of\nthe data, exhibiting performance degradation or even catastrophic failure when\nlearning from contaminated datasets containing impure trajectories of diverse\nlevels. e.g., expert level, medium level, etc., while offline contaminated data\nlogs exist commonly in the real world. To mitigate this, we first introduce\ngradient penalty over the learned value function to tackle the exploding\nQ-functions. We then relax the closeness constraints towards non-optimal\nactions with critic weighted constraint relaxation. Experimental results show\nthat the proposed techniques effectively tame the non-optimal trajectories for\npolicy constraint offline RL methods, evaluated on a set of contaminated D4RL\nMujoco and Adroit datasets.",
    "descriptor": "\nComments: 9 pages, under review\n",
    "authors": [
      "Chengqian Gao",
      "Ke Xu",
      "Liu Liu",
      "Deheng Ye",
      "Peilin Zhao",
      "Zhiqiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10469"
  },
  {
    "id": "arXiv:2210.10473",
    "title": "FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping",
    "abstract": "In this work, we present a new single-stage method for subject agnostic face\nswapping and identity transfer, named FaceDancer. We have two major\ncontributions: Adaptive Feature Fusion Attention (AFFA) and Interpreted Feature\nSimilarity Regularization (IFSR). The AFFA module is embedded in the decoder\nand adaptively learns to fuse attribute features and features conditioned on\nidentity information without requiring any additional facial segmentation\nprocess. In IFSR, we leverage the intermediate features in an identity encoder\nto preserve important attributes such as head pose, facial expression,\nlighting, and occlusion in the target face, while still transferring the\nidentity of the source face with high fidelity. We conduct extensive\nquantitative and qualitative experiments on various datasets and show that the\nproposed FaceDancer outperforms other state-of-the-art networks in terms of\nidentityn transfer, while having significantly better pose preservation than\nmost of the previous methods.",
    "descriptor": "",
    "authors": [
      "Felix Rosberg",
      "Eren Erdal Aksoy",
      "Fernando Alonso-Fernandez",
      "Cristofer Englund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10473"
  },
  {
    "id": "arXiv:2210.10477",
    "title": "RLM-Tracking: Online Multi-Pedestrian Tracking Supported by Relative  Location Mapping",
    "abstract": "The problem of multi-object tracking is a fundamental computer vision\nresearch focus, widely used in public safety, transport, autonomous vehicles,\nrobotics, and other regions involving artificial intelligence. Because of the\ncomplexity of natural scenes, object occlusion and semi-occlusion usually occur\nin fundamental tracking tasks. These can easily lead to ID switching, object\nloss, detect errors, and misaligned limitation boxes. These conditions have a\nsignificant impact on the precision of multi-object tracking. In this paper, we\ndesign a new multi-object tracker for the above issues that contains an object\n\\textbf{Relative Location Mapping} (RLM) model and \\textbf{Target Region\nDensity} (TRD) model. The new tracker is more sensitive to the differences in\nposition relationships between objects. It can introduce low-score detection\nframes into different regions in real-time according to the density of object\nregions in the video. This improves the accuracy of object tracking without\nconsuming extensive arithmetic resources. Our study shows that the proposed\nmodel has considerably enhanced the HOTA and DF1 measurements on the MOT17 and\nMOT20 data sets when applied to the advanced MOT method.",
    "descriptor": "",
    "authors": [
      "Kai Ren",
      "Chuanping Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10477"
  },
  {
    "id": "arXiv:2210.10480",
    "title": "Comparative plausibility in neighbourhood models: axiom systems and  sequent calculi",
    "abstract": "We introduce a family of comparative plausibility logics over neighbourhood\nmodels, generalising Lewis' comparative plausibility operator over sphere\nmodels. We provide axiom systems for the logics, and prove their soundness and\ncompleteness with respect to the semantics. Then, we introduce two kinds of\nanalytic proof systems for several logics in the family: a multi-premisses\nsequent calculus in the style of Lellmann and Pattinson, for which we prove cut\nadmissibility, and a hypersequent calculus based on structured calculi for\nconditional logics by Girlando et al., tailored for countermodel construction\nover failed proof search. Our results constitute the first steps in the\ndefinition of a unified proof theoretical framework for logics equipped with a\ncomparative plausibility operator.",
    "descriptor": "\nComments: To appear in: David Fern\\'andez-Duque, Alessandra Palmigiano and Sophie Pinchinat (eds), Advances in Modal Logic 14, College Publications, 2022\n",
    "authors": [
      "Tiziano Dalmonte",
      "Marianna Girlando"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.10480"
  },
  {
    "id": "arXiv:2210.10481",
    "title": "Virtual Sensor Middleware: Managing IoT Data for the Fog-Cloud Platform",
    "abstract": "This paper introduces the Virtual Sensor Middleware (VSM), which facilitates\ndistributed sensor data processing on multiple fog nodes. VSM uses a Virtual\nSensor as the core component of the middleware. The virtual sensor concept is\nredesigned to support functionality beyond sensor/device virtualization, such\nas deploying a set of virtual sensors to represent an IoT application and\ndistributed sensor data processing across multiple fog nodes. Furthermore, the\nvirtual sensor deals with the heterogeneous nature of IoT devices and the\nvarious communication protocols using different adapters to communicate with\nthe IoT devices and the underlying protocol. VSM uses the publish-subscribe\ndesign pattern to allow virtual sensors to receive data from other virtual\nsensors for seamless sensor data consumption without tight integration among\nvirtual sensors, which reduces application development efforts. Furthermore,\nVSM enhances the design of virtual sensors with additional components that\nsupport sharing of data in dynamic environments where data receivers may change\nover time, data aggregation is required, and dealing with missing data is\nessential for the applications.",
    "descriptor": "",
    "authors": [
      "Fadi AlMahamid",
      "Hanan Lutfiyya",
      "Katarina Grolinger"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.10481"
  },
  {
    "id": "arXiv:2210.10482",
    "title": "Targeted Adversarial Self-Supervised Learning",
    "abstract": "Recently, unsupervised adversarial training (AT) has been extensively studied\nto attain robustness with the models trained upon unlabeled data. To this end,\nprevious studies have applied existing supervised adversarial training\ntechniques to self-supervised learning (SSL) frameworks. However, all have\nresorted to untargeted adversarial learning as obtaining targeted adversarial\nexamples is unclear in the SSL setting lacking of label information. In this\npaper, we propose a novel targeted adversarial training method for the SSL\nframeworks. Specifically, we propose a target selection algorithm for the\nadversarial SSL frameworks; it is designed to select the most confusing sample\nfor each given instance based on similarity and entropy, and perturb the given\ninstance toward the selected target sample. Our method significantly enhances\nthe robustness of an SSL model without requiring large batches of images or\nadditional models, unlike existing works aimed at achieving the same goal.\nMoreover, our method is readily applicable to general SSL frameworks that only\nuses positive pairs. We validate our method on benchmark datasets, on which it\nobtains superior robust accuracies, outperforming existing unsupervised\nadversarial training methods.",
    "descriptor": "",
    "authors": [
      "Minseon Kim",
      "Hyeonjeong Ha",
      "Sooel Son",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10482"
  },
  {
    "id": "arXiv:2210.10483",
    "title": "O Problema do Roteamento de Interliga\u00e7\u00f5es El\u00e9tricas em Circuitos  Integrados",
    "abstract": "Integrated circuit design automation tools are essential for the feasibility\nof complex designs with millions of transistors. One of the steps performed\nwithin the process is the routing of interconnections between components of a\ncircuit. This problem, which also aims to optimize the utilization of\nconnection resources, has been shown to be NP-Complete and requires heuristic\nalgorithms to look for the best achievable solutions. In this work, we present\na definition of this problem in context with a brief review of existing\nsolutions in the literature. Then, we propose a methodology for the development\nof an original algorithm, which aims to differentiate itself, in certain\ndomains, from the solutions already proposed.",
    "descriptor": "\nComments: in Portuguese language\n",
    "authors": [
      "Tiago Matos Santos"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2210.10483"
  },
  {
    "id": "arXiv:2210.10485",
    "title": "Few-shot Transferable Robust Representation Learning via Bilevel Attacks",
    "abstract": "Existing adversarial learning methods for enhancing the robustness of deep\nneural networks assume the availability of a large amount of data from which we\ncan generate adversarial examples. However, in an adversarial meta-learning\nsetting, the model needs to train with only a few adversarial examples to learn\na robust model for unseen tasks, which is a very difficult goal to achieve.\nFurther, learning transferable robust representations for unseen domains is a\ndifficult problem even with a large amount of data. To tackle such a challenge,\nwe propose a novel adversarial self-supervised meta-learning framework with\nbilevel attacks which aims to learn robust representations that can generalize\nacross tasks and domains. Specifically, in the inner loop, we update the\nparameters of the given encoder by taking inner gradient steps using two\ndifferent sets of augmented samples, and generate adversarial examples for each\nview by maximizing the instance classification loss. Then, in the outer loop,\nwe meta-learn the encoder parameter to maximize the agreement between the two\nadversarial examples, which enables it to learn robust representations. We\nexperimentally validate the effectiveness of our approach on unseen domain\nadaptation tasks, on which it achieves impressive performance. Specifically,\nour method significantly outperforms the state-of-the-art meta-adversarial\nlearning methods on few-shot learning tasks, as well as self-supervised\nlearning baselines in standard learning settings with large-scale datasets.",
    "descriptor": "\nComments: *Equal contribution. Author ordering determined by coin flip\n",
    "authors": [
      "Minseon Kim",
      "Hyeonjeong Ha",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10485"
  },
  {
    "id": "arXiv:2210.10486",
    "title": "Cross-Modal Fusion Distillation for Fine-Grained Sketch-Based Image  Retrieval",
    "abstract": "Representation learning for sketch-based image retrieval has mostly been\ntackled by learning embeddings that discard modality-specific information. As\ninstances from different modalities can often provide complementary information\ndescribing the underlying concept, we propose a cross-attention framework for\nVision Transformers (XModalViT) that fuses modality-specific information\ninstead of discarding them. Our framework first maps paired datapoints from the\nindividual photo and sketch modalities to fused representations that unify\ninformation from both modalities. We then decouple the input space of the\naforementioned modality fusion network into independent encoders of the\nindividual modalities via contrastive and relational cross-modal knowledge\ndistillation. Such encoders can then be applied to downstream tasks like\ncross-modal retrieval. We demonstrate the expressive capacity of the learned\nrepresentations by performing a wide range of experiments and achieving\nstate-of-the-art results on three fine-grained sketch-based image retrieval\nbenchmarks: Shoe-V2, Chair-V2 and Sketchy. Implementation is available at\nhttps://github.com/abhrac/xmodal-vit.",
    "descriptor": "\nComments: British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Abhra Chaudhuri",
      "Massimiliano Mancini",
      "Yanbei Chen",
      "Zeynep Akata",
      "Anjan Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10486"
  },
  {
    "id": "arXiv:2210.10487",
    "title": "Estimating the Contamination Factor's Distribution in Unsupervised  Anomaly Detection",
    "abstract": "Anomaly detection methods identify examples that do not follow the expected\nbehaviour, typically in an unsupervised fashion, by assigning real-valued\nanomaly scores to the examples based on various heuristics. These scores need\nto be transformed into actual predictions by thresholding, so that the\nproportion of examples marked as anomalies equals the expected proportion of\nanomalies, called contamination factor. Unfortunately, there are no good\nmethods for estimating the contamination factor itself. We address this need\nfrom a Bayesian perspective, introducing a method for estimating the posterior\ndistribution of the contamination factor of a given unlabeled dataset. We\nleverage on outputs of several anomaly detectors as a representation that\nalready captures the basic notion of anomalousness and estimate the\ncontamination using a specific mixture formulation. Empirically on 22 datasets,\nwe show that the estimated distribution is well-calibrated and that setting the\nthreshold using the posterior mean improves the anomaly detectors' performance\nover several alternative methods. All code is publicly available for full\nreproducibility.",
    "descriptor": "",
    "authors": [
      "Lorenzo Perini",
      "Paul Buerkner",
      "Arto Klami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10487"
  },
  {
    "id": "arXiv:2210.10488",
    "title": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "abstract": "Two interlocking research questions of growing interest and importance in\nprivacy research are Authorship Attribution (AA) and Authorship Obfuscation\n(AO). Given an artifact, especially a text t in question, an AA solution aims\nto accurately attribute t to its true author out of many candidate authors\nwhile an AO solution aims to modify t to hide its true authorship.\nTraditionally, the notion of authorship and its accompanying privacy concern is\nonly toward human authors. However, in recent years, due to the explosive\nadvancements in Neural Text Generation (NTG) techniques in NLP, capable of\nsynthesizing human-quality open-ended texts (so-called \"neural texts\"), one has\nto now consider authorships by humans, machines, or their combination. Due to\nthe implications and potential threats of neural texts when used maliciously,\nit has become critical to understand the limitations of traditional AA/AO\nsolutions and develop novel AA/AO solutions in dealing with neural texts. In\nthis survey, therefore, we make a comprehensive review of recent literature on\nthe attribution and obfuscation of neural text authorship from a Data Mining\nperspective, and share our view on their limitations and promising research\ndirections.",
    "descriptor": "",
    "authors": [
      "Adaku Uchendu",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10488"
  },
  {
    "id": "arXiv:2210.10489",
    "title": "A Robust Pedestrian Detection Approach for Autonomous Vehicles",
    "abstract": "Nowadays, utilizing Advanced Driver-Assistance Systems (ADAS) has absorbed a\nhuge interest as a potential solution for reducing road traffic issues. Despite\nrecent technological advances in such systems, there are still many inquiries\nthat need to be overcome. For instance, ADAS requires accurate and real-time\ndetection of pedestrians in various driving scenarios. To solve the mentioned\nproblem, this paper aims to fine-tune the YOLOv5s framework for handling\npedestrian detection challenges on the real-world instances of Caltech\npedestrian dataset. We also introduce a developed toolbox for preparing\ntraining and test data and annotations of Caltech pedestrian dataset into the\nformat recognizable by YOLOv5. Experimental results of utilizing our approach\nshow that the mean Average Precision (mAP) of our fine-tuned model for\npedestrian detection task is more than 91 percent when performing at the\nhighest rate of 70 FPS. Moreover, the experiments on the Caltech pedestrian\ndataset samples have verified that our proposed approach is an effective and\naccurate method for pedestrian detection and can outperform other existing\nmethodologies.",
    "descriptor": "\nComments: 6 pages, 5 figures, one table\n",
    "authors": [
      "Bahareh Ghari",
      "Ali Tourani",
      "Asadollah Shahbahrami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10489"
  },
  {
    "id": "arXiv:2210.10491",
    "title": "Visual SLAM: What are the Current Trends and What to Expect?",
    "abstract": "Vision-based sensors have shown significant performance, accuracy, and\nefficiency gain in Simultaneous Localization and Mapping (SLAM) systems in\nrecent years. In this regard, Visual Simultaneous Localization and Mapping\n(VSLAM) methods refer to the SLAM approaches that employ cameras for pose\nestimation and map generation. We can see many research works that demonstrated\nVSLAMs can outperform traditional methods, which rely only on a particular\nsensor, such as a Lidar, even with lower costs. VSLAM approaches utilize\ndifferent camera types (e.g., monocular, stereo, and RGB-D), have been tested\non various datasets (e.g., KITTI, TUM RGB-D, and EuRoC) and in dissimilar\nenvironments (e.g., indoors and outdoors), and employ multiple algorithms and\nmethodologies to have a better understanding of the environment. The mentioned\nvariations have made this topic popular for researchers and resulted in a wide\nrange of VSLAMs methodologies. In this regard, the primary intent of this\nsurvey is to present the recent advances in VSLAM systems, along with\ndiscussing the existing challenges and trends. We have given an in-depth\nliterature survey of forty-five impactful papers published in the domain of\nVSLAMs. We have classified these manuscripts by different characteristics,\nincluding the novelty domain, objectives, employed algorithms, and semantic\nlevel. We also discuss the current trends and future directions that may help\nresearchers investigate them.",
    "descriptor": "\nComments: 18 pages, 4 figures, 1 table\n",
    "authors": [
      "Ali Tourani",
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Holger Voos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10491"
  },
  {
    "id": "arXiv:2210.10492",
    "title": "Efficient, probabilistic analysis of combinatorial neural codes",
    "abstract": "Artificial and biological neural networks (ANNs and BNNs) can encode inputs\nin the form of combinations of individual neurons' activities. These\ncombinatorial neural codes present a computational challenge for direct and\nefficient analysis due to their high dimensionality and often large volumes of\ndata. Here we improve the computational complexity -- from factorial to\nquadratic time -- of direct algebraic methods previously applied to small\nexamples and apply them to large neural codes generated by experiments. These\nmethods provide a novel and efficient way of probing algebraic, geometric, and\ntopological characteristics of combinatorial neural codes and provide insights\ninto how such characteristics are related to learning and experience in neural\nnetworks. We introduce a procedure to perform hypothesis testing on the\nintrinsic features of neural codes using information geometry. We then apply\nthese methods to neural activities from an ANN for image classification and a\nBNN for 2D navigation to, without observing any inputs or outputs, estimate the\nstructure and dimensionality of the stimulus or task space. Additionally, we\ndemonstrate how an ANN varies its internal representations across network depth\nand during learning.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Thomas F Burns",
      "Irwansyah"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.10492"
  },
  {
    "id": "arXiv:2210.10495",
    "title": "Asymmetric Distillation Post-Segmentation Method for Image Anomaly  Detection",
    "abstract": "Knowledge distillation-based anomaly detection methods generate same outputs\nfor unknown classes due to the symmetric form of the input and ignore the\npowerful semantic information of the output of the teacher network since it is\nonly used as a \"reference standard\". Towards this end, this work proposes a\nnovel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively\nexplore the asymmetric structure of the input and the discriminative features\nof the teacher network. Specifically, a simple yet effective asymmetric input\napproach is proposed to make different data flows through the teacher and\nstudent networks. The student network enables to have different inductive and\nexpressive abilities, which can generate different outputs in anomalous\nregions. Besides, to further explore the semantic information of the teacher\nnetwork and obtain effective discriminative boundaries, the Weight Mask Block\n(WMB) and the post-segmentation module are proposede. WMB leverages a weighted\nstrategy by exploring teacher-student feature maps to highlight anomalous\nfeatures. The post-segmentation module further learns the anomalous features\nand obtains valid discriminative boundaries. Experimental results on three\nbenchmark datasets demonstrate that the proposed ADPS achieves state-of-the-art\nanomaly segmentation results.",
    "descriptor": "",
    "authors": [
      "Peng Xing",
      "Zechao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10495"
  },
  {
    "id": "arXiv:2210.10506",
    "title": "Audio Tampering Detection Based on Shallow and Deep Feature  Representation Learning",
    "abstract": "Digital audio tampering detection can be used to verify the authenticity of\ndigital audio. However, most current methods use standard electronic network\nfrequency (ENF) databases for visual comparison analysis of ENF continuity of\ndigital audio or perform feature extraction for classification by machine\nlearning methods. ENF databases are usually tricky to obtain, visual methods\nhave weak feature representation, and machine learning methods have more\ninformation loss in features, resulting in low detection accuracy. This paper\nproposes a fusion method of shallow and deep features to fully use ENF\ninformation by exploiting the complementary nature of features at different\nlevels to more accurately describe the changes in inconsistency produced by\ntampering operations to raw digital audio. The method achieves 97.03% accuracy\non three classic databases: Carioca 1, Carioca 2, and New Spanish. In addition,\nwe have achieved an accuracy of 88.31% on the newly constructed database\nGAUDI-DI. Experimental results show that the proposed method is superior to the\nstate-of-the-art method.",
    "descriptor": "\nComments: Audio tampering detection, 21 pages, 4 figures\n",
    "authors": [
      "Zhifeng Wang",
      "Yao Yang",
      "Chunyan Zeng",
      "Shuai Kong",
      "Shixiong Feng",
      "Nan Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10506"
  },
  {
    "id": "arXiv:2210.10512",
    "title": "Miners in the Cloud: Measuring and Analyzing Cryptocurrency Mining in  Public Clouds",
    "abstract": "Cryptocurrencies, arguably the most prominent application of blockchains,\nhave been on the rise with a wide mainstream acceptance. A central concept in\ncryptocurrencies is \"mining pools\", groups of cooperating cryptocurrency miners\nwho agree to share block rewards in proportion to their contributed mining\npower. Despite many promised benefits of cryptocurrencies, they are equally\nutilized for malicious activities; e.g., ransomware payments, stealthy command,\ncontrol, etc. Thus, understanding the interplay between cryptocurrencies,\nparticularly the mining pools, and other essential infrastructure for profiling\nand modeling is important.\nIn this paper, we study the interplay between mining pools and public clouds\nby analyzing their communication association through passive domain name system\n(pDNS) traces. We observe that 24 cloud providers have some association with\nmining pools as observed from the pDNS query traces, where popular public cloud\nproviders, namely Amazon and Google, have almost 48% of such an association.\nMoreover, we found that the cloud provider presence and cloud\nprovider-to-mining pool association both exhibit a heavy-tailed distribution,\nemphasizing an intrinsic preferential attachment model with both mining pools\nand cloud providers. We measure the security risk and exposure of the cloud\nproviders, as that might aid in understanding the intent of the mining: among\nthe top two cloud providers, we found almost 35% and 30% of their associated\nendpoints are positively detected to be associated with malicious activities,\nper the virustotal.com scan. Finally, we found that the mining pools presented\nin our dataset are predominantly used for mining Metaverse currencies,\nhighlighting a shift in cryptocurrency use, and demonstrating the prevalence of\nmining using public clouds.",
    "descriptor": "\nComments: 6 pages, 6 tables\n",
    "authors": [
      "Ayodeji Adeniran",
      "David Mohaisen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10512"
  },
  {
    "id": "arXiv:2210.10514",
    "title": "The Future of Consumer Edge-AI Computing",
    "abstract": "Deep Learning has proliferated dramatically across consumer devices in less\nthan a decade, but has been largely powered through the hardware acceleration\nwithin isolated devices. Nonetheless, clear signals exist that the next decade\nof consumer intelligence will require levels of resources, a mixing of\nmodalities and a collaboration of devices that will demand a significant pivot\nbeyond hardware alone. To accomplish this, we believe a new Edge-AI paradigm\nwill be necessary for this transition to be possible in a sustainable manner,\nwithout trespassing user-privacy or hurting quality of experience.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Stefanos Laskaridis",
      "Stylianos I. Venieris",
      "Alexandros Kouris",
      "Rui Li",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10514"
  },
  {
    "id": "arXiv:2210.10515",
    "title": "A Segment-Wise Gaussian Process-Based Ground Segmentation With Local  Smoothness Estimation",
    "abstract": "Both in terrestrial and extraterrestrial environments, the precise and\ninformative model of the ground and the surface ahead is crucial for navigation\nand obstacle avoidance. The ground surface is not always flat and it may be\nsloped, bumpy and rough specially in off-road terrestrial scenes. In bumpy and\nrough scenes the functional relationship of the surface-related features may\nvary in different areas of the ground, as the structure of the ground surface\nmay vary suddenly and further the measured point cloud of the ground does not\nbear smoothness. Thus, the ground-related features must be obtained based on\nlocal estimates or even point estimates. To tackle this problem, the\nsegment-wise GP-based ground segmentation method with local smoothness\nestimation is proposed. This method is an extension to our previous method in\nwhich a realistic measurement of the length-scale values were provided for the\ncovariance kernel in each line-segment to give precise estimation of the ground\nfor sloped terrains. In this extension, the value of the length-scale is\nestimated locally for each data point which makes it much more precise for the\nrough scenes while being not computationally complex and more robust to\nunder-segmentation, sparsity and under-represent-ability. The segment-wise task\nis performed to estimate a partial continuous model of the ground for each\nradial range segment. Simulation results show the effectiveness of the proposed\nmethod to give a continuous and precise estimation of the ground surface in\nrough and bumpy scenes while being fast enough for real-world applications.",
    "descriptor": "",
    "authors": [
      "Pouria Mehrabi",
      "Hamid D. Taghirad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10515"
  },
  {
    "id": "arXiv:2210.10517",
    "title": "Automated Perceived Gender Bias Pipeline in YouTube",
    "abstract": "Students are increasingly using online materials to learn new subjects or to\nsupplement their learning process in educational institutions. Issues regarding\ngender bias have been raised in the context of formal education and some\nmeasures have been proposed to mitigate them. However, online educational\nmaterials in terms of possible gender bias and stereotypes which may appear in\ndifferent forms are yet to be investigated in the context of search bias in a\nwidely-used search platform. As a first step towards measuring possible gender\nbias in online platforms, we have investigated YouTube educational videos in\nterms of the perceived gender of their narrators. We adopted bias measures for\nranked search results to evaluate educational videos returned by YouTube in\nresponse to queries related to STEM (Science, Technology, Engineering, and\nMathematics) and NON-STEM fields of education. For this, we propose automated\npipeline to annotate narrators' perceived gender in YouTube videos for\nanalysing perceived gender bias in online education.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.09987\n",
    "authors": [
      "Gizem Gezici"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10517"
  },
  {
    "id": "arXiv:2210.10522",
    "title": "Potentials of Electric Vehicles for the Provision of Active and Reactive  Power Flexibilities as Ancillary Services at Vertical Power System  Interconnections",
    "abstract": "This paper extends the research regarding the determination of the feasible\noperation region under the impact of electric vehicles. Thereby, the active and\nreactive power flexibility potentials of EV for alternating current and direct\ncurrent bidirectional charging are limited in first instance by regulatory\nguidelines. In this paper German regulatory guidelines are applied to depicture\nthe current state of the art for EV charging components. Under assumption of\nbidirectional charging for EV, the corresponding flexibility polygon in the PQ\nplane is derived. The impact on the FOR is then evaluated within the Cigr\\'e\nEuropean medium voltage benchmark system. In a first step, the flexibility\npotential of the system is determined for a load case as basis for the\ncomparison with different, realistic penetration levels of EV. DER are\nconsidered to depict additional existing power flexibilities. In a second step,\nthe FOR and the corresponding limitations within the system are analyzed. Under\nvariation of the rated line current, the limiting utility constraints are\npointed out. The obtained results are the basis for more detailed\ninvestigations regarding the potentials of bidirectional charging for an\nintensified system operators cooperation. The used method presents a promising\napproach to be used by the lower system operator as tool in the grid planning\nprocess to estimate the possible power flexibilities that can be provided to a\nhigher system. Continuing, the potential for ancillary services provided by EV\nis discussed, resulting in the derivation of future research aspects. Because\nthe accumulation of EV leads to higher grid utilization, which results in\nquadratically increasing grid losses the closer the grid is operating to the\ngrid constraints, a cost curve for the EVs active power flexibility is\nintroduced, whereas probability zones are indicated.",
    "descriptor": "",
    "authors": [
      "Manuel Wingenfelder",
      "Marcel Sarstedt",
      "Lutz Hofmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10522"
  },
  {
    "id": "arXiv:2210.10523",
    "title": "Hope of Delivery: Extracting User Locations From Mobile Instant  Messengers",
    "abstract": "Mobile instant messengers such as WhatsApp use delivery status notifications\nin order to inform users if a sent message has successfully reached its\ndestination. This is useful and important information for the sender due to the\noften asynchronous use of the messenger service. However, as we demonstrate in\nthis paper, this standard feature opens up a timing side channel with\nunexpected consequences for user location privacy. We investigate this threat\nconceptually and experimentally for three widely spread instant messengers. We\nvalidate that this information leak even exists in privacy-friendly messengers\nsuch as Signal and Threema.\nOur results show that, after a training phase, a messenger user can\ndistinguish different locations of the message receiver. Our analyses involving\nmultiple rounds of measurements and evaluations show that the timing side\nchannel persists independent of distances between receiver locations -- the\nattack works both for receivers in different countries as well as at small\nscale in one city. For instance, out of three locations within the same city,\nthe sender can determine the correct one with more than 80% accuracy. Thus,\nmessenger users can secretly spy on each others' whereabouts when sending\ninstant messages. As our countermeasure evaluation shows, messenger providers\ncould effectively disable the timing side channel by randomly delaying delivery\nconfirmations within the range of a few seconds. For users themselves, the\nthreat is harder to prevent since there is no option to turn off delivery\nconfirmations.",
    "descriptor": "\nComments: 33 pages, 23 figures, 9 tables, NDSS 2023\n",
    "authors": [
      "Theodor Schnitzler",
      "Katharina Kohls",
      "Evangelos Bitsikas",
      "Christina P\u00f6pper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10523"
  },
  {
    "id": "arXiv:2210.10526",
    "title": "Propagating Variational Model Uncertainty for Bioacoustic Call Label  Smoothing",
    "abstract": "We focus on using the predictive uncertainty signal calculated by Bayesian\nneural networks to guide learning in the self-same task the model is being\ntrained on. Not opting for costly Monte Carlo sampling of weights, we propagate\nthe approximate hidden variance in an end-to-end manner, throughout a\nvariational Bayesian adaptation of a ResNet with attention and\nsqueeze-and-excitation blocks, in order to identify data samples that should\ncontribute less into the loss value calculation. We, thus, propose\nuncertainty-aware, data-specific label smoothing, where the smoothing\nprobability is dependent on this epistemic uncertainty. We show that, through\nthe explicit usage of the epistemic uncertainty in the loss calculation, the\nvariational model is led to improved predictive and calibration performance.\nThis core machine learning methodology is exemplified at wildlife call\ndetection, from audio recordings made via passive acoustic monitoring equipment\nin the animals' natural habitats, with the future goal of automating large\nscale annotation in a trustworthy manner.",
    "descriptor": "",
    "authors": [
      "Georgios Rizos",
      "Jenna Lawson",
      "Simon Mitchell",
      "Pranay Shah",
      "Xin Wen",
      "Cristina Banks-Leite",
      "Robert Ewers",
      "Bjoern W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10526"
  },
  {
    "id": "arXiv:2210.10527",
    "title": "Spectral methods for solving elliptic PDEs on unknown manifolds",
    "abstract": "In this paper, we propose a mesh-free numerical method for solving elliptic\nPDEs on unknown manifolds, identified with randomly sampled point cloud data.\nThe PDE solver is formulated as a spectral method where the test function space\nis the span of the leading eigenfunctions of the Laplacian operator, which are\napproximated from the point cloud data. While the framework is flexible for any\ntest functional space, we will consider the eigensolutions of a weighted\nLaplacian obtained from a symmetric Radial Basis Function (RBF) method induced\nby a weak approximation of a weighted Laplacian on an appropriate Hilbert\nspace. Especially, we consider a test function space that encodes the geometry\nof the data yet does not require us to identify and use the sampling density of\nthe point cloud. To attain a more accurate approximation of the expansion\ncoefficients, we adopt a second-order tangent space estimation method to\nimprove the RBF interpolation accuracy in estimating the tangential\nderivatives. This spectral framework allows us to efficiently solve the PDE\nmany times subjected to different parameters, which reduces the computational\ncost in the related inverse problem applications. In a well-posed elliptic PDE\nsetting with randomly sampled point cloud data, we provide a theoretical\nanalysis to demonstrate the convergent of the proposed solver as the sample\nsize increases. We also report some numerical studies that show the convergence\nof the spectral solver on simple manifolds and unknown, rough surfaces. Our\nnumerical results suggest that the proposed method is more accurate than a\ngraph Laplacian-based solver on smooth manifolds. On rough manifolds, these two\napproaches are comparable. Due to the flexibility of the framework, we\nempirically found improved accuracies in both smoothed and unsmoothed Stanford\nbunny domains by blending the graph Laplacian eigensolutions and RBF\ninterpolator.",
    "descriptor": "\nComments: 7 figures\n",
    "authors": [
      "Qile Yan",
      "Shixiao Jiang",
      "John Harlim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10527"
  },
  {
    "id": "arXiv:2210.10530",
    "title": "Adversarial De-confounding in Individualised Treatment Effects  Estimation",
    "abstract": "Observational studies have recently received significant attention from the\nmachine learning community due to the increasingly available non-experimental\nobservational data and the limitations of the experimental studies, such as\nconsiderable cost, impracticality, small and less representative sample sizes,\netc. In observational studies, de-confounding is a fundamental problem of\nindividualised treatment effects (ITE) estimation. This paper proposes\ndisentangled representations with adversarial training to selectively balance\nthe confounders in the binary treatment setting for the ITE estimation. The\nadversarial training of treatment policy selectively encourages\ntreatment-agnostic balanced representations for the confounders and helps to\nestimate the ITE in the observational studies via counterfactual inference.\nEmpirical results on synthetic and real-world datasets, with varying degrees of\nconfounding, prove that our proposed approach improves the state-of-the-art\nmethods in achieving lower error in the ITE estimation.",
    "descriptor": "\nComments: (under review)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Soheila Molaei",
      "Marzia Hoque Tania",
      "Anshul Thakur",
      "Tingting Zhu",
      "David Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.10530"
  },
  {
    "id": "arXiv:2210.10535",
    "title": "Stability of Entropic Wasserstein Barycenters and application to random  geometric graphs",
    "abstract": "As interest in graph data has grown in recent years, the computation of\nvarious geometric tools has become essential. In some area such as mesh\nprocessing, they often rely on the computation of geodesics and shortest paths\nin discretized manifolds. A recent example of such a tool is the computation of\nWasserstein barycenters (WB), a very general notion of barycenters derived from\nthe theory of Optimal Transport, and their entropic-regularized variant. In\nthis paper, we examine how WBs on discretized meshes relate to the geometry of\nthe underlying manifold. We first provide a generic stability result with\nrespect to the input cost matrices. We then apply this result to random\ngeometric graphs on manifolds, whose shortest paths converge to geodesics,\nhence proving the consistency of WBs computed on discretized shapes.",
    "descriptor": "",
    "authors": [
      "Marc Theveneau",
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.10535"
  },
  {
    "id": "arXiv:2210.10537",
    "title": "Online LiDAR-Camera Extrinsic Parameters Self-checking",
    "abstract": "With the development of neural networks and the increasing popularity of\nautomatic driving, the calibration of the LiDAR and the camera has attracted\nmore and more attention. This calibration task is multi-modal, where the rich\ncolor and texture information captured by the camera and the accurate\nthree-dimensional spatial information from the LiDAR is incredibly significant\nfor downstream tasks. Current research interests mainly focus on obtaining\naccurate calibration results through information fusion. However, they seldom\nanalyze whether the calibrated results are correct or not, which could be of\nsignificant importance in real-world applications. For example, in large-scale\nproduction, the LiDARs and the cameras of each smart car have to get\nwell-calibrated as the car leaves the production line, while in the rest of the\ncar life period, the poses of the LiDARs and cameras should also get\ncontinually supervised to ensure the security. To this end, this paper proposes\na self-checking algorithm to judge whether the extrinsic parameters are\nwell-calibrated by introducing a binary classification network based on the\nfused information from the camera and the LiDAR. Moreover, since there is no\nsuch dataset for the task in this work, we further generate a new dataset\nbranch from the KITTI dataset tailored for the task. Our experiments on the\nproposed dataset branch demonstrate the performance of our method. To the best\nof our knowledge, this is the first work to address the significance of\ncontinually checking the calibrated extrinsic parameters for autonomous\ndriving. The code is open-sourced on the Github website at\nhttps://github.com/OpenCalib/LiDAR2camera_self-check.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Pengjin Wei",
      "Guohang Yan",
      "Yikang Li",
      "Kun Fang",
      "Jie Yang",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10537"
  },
  {
    "id": "arXiv:2210.10540",
    "title": "Design and Modeling of a PVDF-TrFe Flexible Wind Energy Harvester",
    "abstract": "This study presents the simulation, experimentation, and design\nconsiderations of a Poly(vinylidene fluoride co-trifluoroethylene)/\nPolyethylene Terephthalate (PVDF-TrFe / PET), laser-cut, flexible piezoelectric\nenergy harvester. It is possible to obtain energy from the environment around\nautonomous sensor systems, which can then be used to power various equipment.\nThis article investigates the actuation means of ambient vibration, which is a\ngood candidate for using piezoelectric energy harvester (PEH) devices. The\noutput voltage characteristics were analyzed in a wind test apparatus. Finite\nelement modeling (FEM) was done for von Mises stress and modal analysis.\nResonance frequency sweeps, quality factors, and damping ratios of the circular\nplate were given numerically. For a PVDF-TrFe piezoelectric layer thickness of\n18 $\\mu$m and 1.5 mm radius, a damping ratio of 0.117 and a quality factor of\n4.284 was calculated. $V_{max}$ was calculated as 984 mV from the wind setup\nand compared with the FEM outputs.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Berkay Kullukcu",
      "Levent Beker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10540"
  },
  {
    "id": "arXiv:2210.10542",
    "title": "PoseGPT: Quantization-based 3D Human Motion Generation and Forecasting",
    "abstract": "We address the problem of action-conditioned generation of human motion\nsequences. Existing work falls into two categories: forecast models conditioned\non observed past motions, or generative models conditioned on action labels and\nduration only. In contrast, we generate motion conditioned on observations of\narbitrary length, including none. To solve this generalized problem, we propose\nPoseGPT, an auto-regressive transformer-based approach which internally\ncompresses human motion into quantized latent sequences. An auto-encoder first\nmaps human motion to latent index sequences in a discrete space, and\nvice-versa. Inspired by the Generative Pretrained Transformer (GPT), we propose\nto train a GPT-like model for next-index prediction in that space; this allows\nPoseGPT to output distributions on possible futures, with or without\nconditioning on past motion. The discrete and compressed nature of the latent\nspace allows the GPT-like model to focus on long-range signal, as it removes\nlow-level redundancy in the input signal. Predicting discrete indices also\nalleviates the common pitfall of predicting averaged poses, a typical failure\ncase when regressing continuous values, as the average of discrete targets is\nnot a target itself. Our experimental results show that our proposed approach\nachieves state-of-the-art results on HumanAct12, a standard but small scale\ndataset, as well as on BABEL, a recent large scale MoCap dataset, and on GRAB,\na human-object interactions dataset.",
    "descriptor": "\nComments: ECCV'22 Conference paper\n",
    "authors": [
      "Thomas Lucas",
      "Fabien Baradel",
      "Philippe Weinzaepfel",
      "Gr\u00e9gory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10542"
  },
  {
    "id": "arXiv:2210.10543",
    "title": "Towards a neural architecture of language: Deep learning versus  logistics of access in neural architectures for compositional processing",
    "abstract": "Recently, a number of articles have argued that deep learning models such as\nGPT could also capture key aspects of language processing in the human mind and\nbrain. However, I will argue that these models are not suitable as neural\nmodels of human language. Firstly, because they fail on fundamental boundary\nconditions, such as the amount of learning they require. This would in fact\nimply that the mechanisms of GPT and brain language processing are\nfundamentally different. Secondly, because they do not possess the logistics of\naccess needed for compositional and productive human language processing.\nNeural architectures could possess logistics of access based on small-world\nlike network structures, in which processing does not consist of symbol\nmanipulation but of controlling the flow of activation. In this view, two\ncomplementary approaches would be needed to investigate the relation between\nbrain and cognition. Investigating learning methods could reveal how 'learned\ncognition' as found in deep learning could develop in the brain. However,\nneural architectures with logistics of access should also be developed to\naccount for 'productive cognition' as required for natural or artificial human\nlanguage processing. Later on, these approaches could perhaps be combined to\nsee how such architectures could develop by learning and development from a\nsimpler basis.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Frank van der Velde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.10543"
  },
  {
    "id": "arXiv:2210.10547",
    "title": "Hierarchical Multi-Interest Co-Network For Coarse-Grained Ranking",
    "abstract": "In this era of information explosion, a personalized recommendation system is\nconvenient for users to get information they are interested in. To deal with\nbillions of users and items, large-scale online recommendation services usually\nconsist of three stages: candidate generation, coarse-grained ranking, and\nfine-grained ranking. The success of each stage depends on whether the model\naccurately captures the interests of users, which are usually hidden in users'\nbehavior data. Previous research shows that users' interests are diverse, and\none vector is not sufficient to capture users' different preferences.\nTherefore, many methods use multiple vectors to encode users' interests.\nHowever, there are two unsolved problems: (1) The similarity of different\nvectors in existing methods is too high, with too much redundant information.\nConsequently, the interests of users are not fully represented. (2) Existing\nmethods model the long-term and short-term behaviors together, ignoring the\ndifferences between them. This paper proposes a Hierarchical Multi-Interest\nCo-Network (HCN) to capture users' diverse interests in the coarse-grained\nranking stage. Specifically, we design a hierarchical multi-interest extraction\nlayer to update users' diverse interest centers iteratively. The multiple\nembedded vectors obtained in this way contain more information and represent\nthe interests of users better in various aspects. Furthermore, we develop a\nCo-Interest Network to integrate users' long-term and short-term interests.\nExperiments on several real-world datasets and one large-scale industrial\ndataset show that HCN effectively outperforms the state-of-the-art methods. We\ndeploy HCN into a large-scale real world E-commerce system and achieve extra\n2.5\\% improvements on GMV (Gross Merchandise Value).",
    "descriptor": "",
    "authors": [
      "Xu Yuan",
      "Chen Xu",
      "Qiwei Chen",
      "Tao Zhuang",
      "Hongjie Chen",
      "Chao Li",
      "Junfeng Ge"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10547"
  },
  {
    "id": "arXiv:2210.10549",
    "title": "Visual Servoing with Geometrically Interpretable Neural Perception",
    "abstract": "An increasing number of nonspecialist robotic users demand easy-to-use\nmachines. In the context of visual servoing, the removal of explicit image\nprocessing is becoming a trend, allowing an easy application of this technique.\nThis work presents a deep learning approach for solving the perception problem\nwithin the visual servoing scheme. An artificial neural network is trained\nusing the supervision coming from the knowledge of the controller and the\nvisual features motion model. In this way, it is possible to give a geometrical\ninterpretation to the estimated visual features, which can be used in the\nanalytical law of the visual servoing. The approach keeps perception and\ncontrol decoupled, conferring flexibility and interpretability on the whole\nframework. Simulated and real experiments with a robotic manipulator validate\nour approach.",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022\n",
    "authors": [
      "Antonio Paolillo",
      "Mirko Nava",
      "Dario Piga",
      "Alessandro Giusti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10549"
  },
  {
    "id": "arXiv:2210.10550",
    "title": "Unconditional stability and error estimates of FEMs for the  electro-osmotic flow in micro-channels",
    "abstract": "In this paper, we will provide the the finite element method for the\nelectro-osmotic flow in micro-channels, in which a convection-diffusion type\nequation is given for the charge density $\\rho^e$. A time-discrete method based\non the backward Euler method is designed. The theoretical analysis shows that\nthe numerical algorithm is unconditionally stable and has optimal convergence\nrates. To show the effectiveness of the proposed model, some numerical results\nfor the electro-osmotic flow in the T-junction micro-channels and in rough\nmicro-channels are provided. Numerical results indicate that the proposed\nnumerical method is suitable for simulating electro-osmotic flows.",
    "descriptor": "",
    "authors": [
      "Zhiyong Si",
      "Dongdong He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10550"
  },
  {
    "id": "arXiv:2210.10555",
    "title": "Data-Augmented Counterfactual Learning for Bundle Recommendation",
    "abstract": "Bundle Recommendation (BR) aims at recommending bundled items on online\ncontent or e-commerce platform, such as song lists on a music platform or book\nlists on a reading website. Several graph based models have achieved\nstate-of-the-art performance on BR task. But their performance is still\nsub-optimal, since the data sparsity problem tends to be more severe in real\nbundle recommendation scenarios, which limits graph-based models from more\nsufficient learning. In this paper, we propose a novel graph learning paradigm\ncalled Counterfactual Learning for Bundle Recommendation (CLBR) to mitigate the\nimpact of data sparsity problem and improve bundle recommendation. Our paradigm\nconsists of two main parts: counterfactual data augmentation and counterfactual\nconstraint. The main idea of our paradigm lies in answering the counterfactual\nquestions: \"What would a user interact with if his/her interaction history\nchanges?\" \"What would a user interact with if the bundle-item affiliation\nrelations change?\" In counterfactual data augmentation, we design a heuristic\nsampler to generate counterfactual graph views for graph-based models, which\nhas better noise controlling than the stochastic sampler. We further propose\ncounterfactual loss to constrain model learning for mitigating the effects of\nresidual noise in augmented data and achieving more sufficient model\noptimization. Further theoretical analysis demonstrates the rationality of our\ndesign. Extensive experiments of BR models applied with our paradigm on two\nreal-world datasets are conducted to verify the effectiveness of the paradigm",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Shixuan Zhu",
      "Qi Shen",
      "Yiming Zhang",
      "Yitong Pang",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10555"
  },
  {
    "id": "arXiv:2210.10561",
    "title": "Illuminating Large-Scale IPv6 Scanning in the Internet",
    "abstract": "While scans of the IPv4 space are ubiquitous, today little is known about\nscanning activity in the IPv6 Internet. In this work, we present a longitudinal\nand detailed empirical study on large-scale IPv6 scanning behavior in the\nInternet, based on firewall logs captured at some 230,000 hosts of a major\nContent Distribution Network (CDN). We develop methods to identify IPv6 scans,\nassess current and past levels of IPv6 scanning activity, and study dominant\ncharacteristics of scans, including scanner origins, targeted services, and\ninsights on how scanners find target IPv6 addresses. Where possible, we compare\nour findings to what can be assessed from publicly available traces. Our work\nidentifies and highlights new challenges to detect scanning activity in the\nIPv6 Internet, and uncovers that today's scans of the IPv6 space show widely\ndifferent characteristics when compared to the more well-known IPv4 scans.",
    "descriptor": "",
    "authors": [
      "Philipp Richter",
      "Oliver Gasser",
      "Arthur Berger"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.10561"
  },
  {
    "id": "arXiv:2210.10562",
    "title": "Research on Hermitian self-dual codes, GRS codes and EGRS codes",
    "abstract": "MDS self-dual codes have nice algebraic structures, theoretical significance\nand practical implications. In this paper, we present three classes of the\nHermitian self-dual (extended) generalized Reed-Solomon codes with different\nlocators. Furthermore, we showed that when $n\\geq 2q$, $q^2$-ary Hermitian\nself-dual GRS codes of length $n$ does not exist. And when $n\\geq 2q-1$,\n$q^2$-ary Hermitian self-dual EGRS codes of length $n+1$ does not exist.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ruhao Wan",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10562"
  },
  {
    "id": "arXiv:2210.10563",
    "title": "Geometric Deep Learning for the Assessment of Thrombosis Risk in the  Left Atrial Appendage",
    "abstract": "The assessment of left atrial appendage (LAA) thrombogenesis has experienced\nmajor advances with the adoption of patient-specific computational fluid\ndynamics (CFD) simulations. Nonetheless, due to the vast computational\nresources and long execution times required by fluid dynamics solvers, there is\nan ever-growing body of work aiming to develop surrogate models of fluid flow\nsimulations based on neural networks. The present study builds on this\nfoundation by developing a deep learning (DL) framework capable of predicting\nthe endothelial cell activation potential (ECAP), linked to the risk of\nthrombosis, solely from the patient-specific LAA geometry. To this end, we\nleveraged recent advancements in Geometric DL, which seamlessly extend the\nunparalleled potential of convolutional neural networks (CNN), to non-Euclidean\ndata such as meshes. The model was trained with a dataset combining 202\nsynthetic and 54 real LAA, predicting the ECAP distributions instantaneously,\nwith an average mean absolute error of 0.563. Moreover, the resulting framework\nmanages to predict the anatomical features related to higher ECAP values even\nwhen trained exclusively on synthetic cases.",
    "descriptor": "",
    "authors": [
      "Xabier Morales",
      "Jordi Mill",
      "Guillem Simeon",
      "Kristine A. Juhl",
      "Ole De Backer",
      "Rasmus R. Paulsen",
      "Oscar Camara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10563"
  },
  {
    "id": "arXiv:2210.10565",
    "title": "NET-TEN: a silicon neuromorphic network for low-latency detection of  seizures in local field potentials",
    "abstract": "Therapeutic intervention in neurological disorders still relies heavily on\npharmacological solutions, while the treatment of patients with drug resistance\nremains an open challenge. This is particularly true for patients with\nepilepsy, 30% of whom are refractory to medications. Implantable devices for\nchronic recording and electrical modulation of brain activity have proved a\nviable alternative in such cases. To operate, the device should detect the\nrelevant electrographic biomarkers from Local Field Potentials (LFPs) and\ndetermine the right time for stimulation. To enable timely interventions, the\nideal device should attain biomarker detection with low latency while operating\nunder low power consumption to prolong the battery life. Neuromorphic networks\nhave progressively gained reputation as low-latency low-power computing\nsystems, which makes them a promising candidate as processing core of\nnext-generation implantable neural interfaces. Here we introduce a fully-analog\nneuromorphic device implemented in CMOS technology for analyzing LFP signals in\nan in vitro model of acute ictogenesis. We show that the system can detect\nictal and interictal events with ms-latency and with high precision, consuming\non average 3.50 nW during the task. Our work paves the way to a new generation\nof brain implantable devices for personalized closed-loop stimulation for\nepilepsy treatment.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Margherita Ronchini",
      "Yasser Rezaeiyan",
      "Milad Zamani",
      "Gabriella Panuccio",
      "Farshad Moradi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.10565"
  },
  {
    "id": "arXiv:2210.10568",
    "title": "What matters in the new field of machine learning and satellite  imagery-based poverty predictions? A review with relevance for potential  downstream applications and development research",
    "abstract": "This paper reviews the state of the art in satellite and machine learning\nbased poverty estimates and finds some interesting results. The most important\nfactors correlated to the predictive power of welfare in the reviewed studies\nare the number of pre-processing steps employed, the number of datasets used,\nthe type of welfare indicator targeted, and the choice of AI model. As\nexpected, studies that used hard indicators as targets achieved better\nperformance in predicting welfare than those that targeted soft ones. Also\nexpected was the number of pre-processing steps and datasets used having a\npositive and statistically significant relationship with welfare estimation\nperformance. Even more important, we find that the combination of ML and DL\nsignificantly increases predictive power by as much as 15 percentage points\ncompared to using either alone. Surprisingly, we find that the spatial\nresolution of the satellite imagery used is important but not critical to the\nperformance as the relationship is positive but not statistically significant.\nThe finding of no evidence indicating that predictive performance of a\nstatistically significant effect occurs over time was also unexpected. These\nfindings have important implications for future research in this domain. For\nexample, the level of effort and resources devoted to acquiring more expensive,\nhigher resolution SI will have to be reconsidered given that medium resolutions\nones seem to achieve similar results. The increasingly popular approach of\ncombining ML, DL, and TL, either in a concurrent or iterative manner, might\nbecome a standard approach to achieving better results.",
    "descriptor": "",
    "authors": [
      "Olan Hall",
      "Francis Dompae",
      "Ibrahim Wahab",
      "Fred Mawunyo Dzanku"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10568"
  },
  {
    "id": "arXiv:2210.10572",
    "title": "Distributed Ledger Technologies for Managing Heterogenous Computing  Systems at the Edge",
    "abstract": "The increased use of Internet of Things (IoT) devices -- from basic sensors\nto robust embedded computers -- has boosted the demand for information\nprocessing and storing solutions closer to these devices. Edge computing has\nbeen established as a standard architecture for developing IoT solutions, since\nit can optimize the workload and capacity of systems that depend on cloud\nservices by deploying necessary computing power close to where the information\nis being produced and consumed. However, as the network scale in size, reaching\nconsensus becomes an increasingly challenging task. Distributed ledger\ntechnologies (DLTs), which can be described as a network of distributed\ndatabases that incorporate cryptography, can be leveraged to achieve consensus\namong participants. In recent years DLTs have gained traction due to the\npopularity of blockchains, the most-well known type of implementation. The\nreliability and trust that can be achieved through transparent and traceable\ntransactions are other key concepts that bring IoT and DLT together. We present\nthe design, development and conducted experiments of a proof-of-concept system\nthat uses DLT smart contracts for efficiently selecting edge nodes for\noffloading computational tasks. In particular, we integrate network performance\nindicators in smart contracts with a Hyperledger Blockchain to optimize the\noffloading on computation under dynamic connectivity solutions. The proposed\nmethod can be applied to networks with varied topologies and different means of\nconnectivity. Our results show the applicability of blockchain smart contracts\nto a variety of industrial use cases.",
    "descriptor": "\nComments: 8 pages, 8 figures, 5 tables and 2 algorithms\n",
    "authors": [
      "Daniel Montero Hern\u00e1ndez",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.10572"
  },
  {
    "id": "arXiv:2210.10573",
    "title": "A fully implicit method using nodal radial basis functions to solve the  linear advection equation",
    "abstract": "Radial basis functions are typically used when discretization sche-mes\nrequire inhomogeneous node distributions. While spawning from a desire to\ninterpolate functions on a random set of nodes, they have found successful\napplications in solving many types of differential equations. However, the\nweights of the interpolated solution, used in the linear superposition of basis\nfunctions to interpolate the solution, and the actual value of the solution are\ncompletely different. In fact, these weights mix the value of the solution with\nthe geometrical location of the nodes used to discretize the equation. In this\npaper, we used nodal radial basis functions, which are interpolants of the\nimpulse function at each node inside the domain. This transformation allows to\nsolve a linear hyperbolic partial differential equation using series expansion\nrather than the explicit computation of a matrix inverse. This transformation\neffectively yields an implicit solver which only requires the multiplication of\nvectors with matrices. Because the solver requires neither matrix inverse nor\nmatrix-matrix products, this approach is numerically more stable and reduces\nthe error by at least two orders of magnitude, compared to other solvers using\nradial basis functions directly. Further, boundary conditions are integrated\ndirectly inside the solver, at no extra cost. The method is naturally\nconservative, keeping the error virtually constant throughout the computation.",
    "descriptor": "",
    "authors": [
      "P.-A. Gourdain",
      "M. B. Adams",
      "M. Evans",
      "H. R. Hasson",
      "J. R. Young",
      "I. West-Abdallah"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10573"
  },
  {
    "id": "arXiv:2210.10574",
    "title": "On Bisimulation in Absence of Restriction",
    "abstract": "We revisit the standard bisimulation equalities in process models free of the\nrestriction operator. As is well-known, in general the weak bisimilarity is\ncoarser than the strong bisimilarity because it abstracts from internal\nactions. In absence of restriction, those internal actions become somewhat\nvisible, so one might wonder if the weak bisimilarity is still 'weak'. We show\nthat in both CCScore (i.e., Milner's standard CCS without $\\tau$-prefix,\nsummation and relabelling) and its higher-order variant (named HOCCScore), the\nweak bisimilarity indeed remains weak, i.e., still strictly coarser than the\nstrong bisimilarity, even without the restriction operator. These results can\nbe extended to other first-order or higher-order process models. Essentially,\nthis is due to the direct or indirect existence of the replication operation,\nwhich can keep a process retaining its state (i.e., capacity of interaction).\nBy virtue of these observations, we examine a variant of the weak bisimilarity,\ncalled quasi-strong bisimilarity. This quasi-strong bisimilarity requires the\nmatching of internal actions to be conducted in the strong manner, as for the\nstrong bisimilarity, and the matching of visible actions to have no trailing\ninternal actions. We exhibit that in CCScore without the restriction operator,\nthe weak bisimilarity exactly collapses onto this quasi-strong bisimilarity,\nwhich is moreover shown to coincide with the branching bisimilarity. These\nresults reveal that in absence of the restriction operation, some ingredient of\nthe weak bisimilarity indeed turns into strong, particularly the matching of\ninternal actions.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Xian Xu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.10574"
  },
  {
    "id": "arXiv:2210.10578",
    "title": "Language Does More Than Describe: On The Lack Of Figurative Speech in  Text-To-Image Models",
    "abstract": "The impressive capacity shown by recent text-to-image diffusion models to\ngenerate high-quality pictures from textual input prompts has leveraged the\ndebate about the very definition of art. Nonetheless, these models have been\ntrained using text data collected from content-based labelling protocols that\nfocus on describing the items and actions in an image but neglect any\nsubjective appraisal. Consequently, these automatic systems need rigorous\ndescriptions of the elements and the pictorial style of the image to be\ngenerated, otherwise failing to deliver. As potential indicators of the actual\nartistic capabilities of current generative models, we characterise the\nsentimentality, objectiveness and degree of abstraction of publicly available\ntext data used to train current text-to-image diffusion models. Considering the\nsharp difference observed between their language style and that typically\nemployed in artistic contexts, we suggest generative models should incorporate\nadditional sources of subjective information in their training in order to\novercome (or at least to alleviate) some of their current limitations, thus\neffectively unleashing a truly artistic and creative generation.",
    "descriptor": "\nComments: NeurIPS 2022 Machine Learning for Creativity and Design Workshop\n",
    "authors": [
      "Ricardo Kleinlein",
      "Cristina Luna-Jim\u00e9nez",
      "Fernando Fern\u00e1ndez-Mart\u00ednez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10578"
  },
  {
    "id": "arXiv:2210.10581",
    "title": "CEntRE: A paragraph-level Chinese dataset for Relation Extraction among  Enterprises",
    "abstract": "Enterprise relation extraction aims to detect pairs of enterprise entities\nand identify the business relations between them from unstructured or\nsemi-structured text data, and it is crucial for several real-world\napplications such as risk analysis, rating research and supply chain security.\nHowever, previous work mainly focuses on getting attribute information about\nenterprises like personnel and corporate business, and pays little attention to\nenterprise relation extraction. To encourage further progress in the research,\nwe introduce the CEntRE, a new dataset constructed from publicly available\nbusiness news data with careful human annotation and intelligent data\nprocessing. Extensive experiments on CEntRE with six excellent models\ndemonstrate the challenges of our proposed dataset.",
    "descriptor": "",
    "authors": [
      "Peipei Liu",
      "Hong Li",
      "Zhiyu Wang",
      "Yimo Ren",
      "Jie Liu",
      "Fei Lyu",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10581"
  },
  {
    "id": "arXiv:2210.10583",
    "title": "Community detection in edge-labeled graphs",
    "abstract": "Finding dense communities in networks is a widely-used tool for analysis in\ngraph mining. A popular choice for finding such communities is to find\nsubgraphs with a high average degree. While useful, interpreting such subgraphs\nmay be difficult. On the other hand, many real-world networks have additional\ninformation, and we are specifically interested in networks that have labels on\nedges. In this paper, we study finding dense subgraphs that can be explained\nwith the labels on edges. More specifically, we are looking for a set of labels\nso that the induced subgraph has a high average degree. There are many ways to\ninduce a subgraph from a set of labels, and we study two cases: First, we study\nconjunctive-induced dense subgraphs, where the subgraph edges need to have all\nlabels. Secondly, we study disjunctive-induced dense subgraphs, where the\nsubgraph edges need to have at least one label. We show that both problems are\n$\\textbf{NP}$-hard. Because of the hardness, we resort to greedy heuristics. We\nshow that we can implement the greedy search efficiently: the respective\nrunning times for finding conjunctive-induced and disjunctive-induced dense\nsubgraphs are in $\\mathcal{O}(p \\log k)$ and $\\mathcal{O}(p \\log^2 k)$, where\n$p$ is the number of edge-label pairs and $k$ is the number of labels. Our\nexperimental evaluation demonstrates that we can find the ground truth in\nsynthetic graphs and that we can find interpretable subgraphs from real-world\nnetworks.",
    "descriptor": "",
    "authors": [
      "Iiro Kumpulainen",
      "Nikolaj Tatti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10583"
  },
  {
    "id": "arXiv:2210.10584",
    "title": "Enhanced vectors for top-k document retrieval in Question Answering",
    "abstract": "Modern day applications, especially information retrieval webapps that\ninvolve \"search\" as their use cases are gradually moving towards \"answering\"\nmodules. Conversational chatbots which have been proved to be more engaging to\nusers, use Question Answering as their core. Since, precise answering is\ncomputationally expensive, several approaches have been developed to prefetch\nthe most relevant documents/passages from the database that contain the answer.\nWe propose a different approach that retrieves the evidence documents\nefficiently and accurately, making sure that the relevant document for a given\nuser query is not missed. We do so by assigning each document (or passage in\nour case), a unique identifier and using them to create dense vectors which can\nbe efficiently indexed. More precisely, we use the identifier to predict\nrandomly sampled context window words of the relevant question corresponding to\nthe passage along with the words of passage itself. This naturally embeds the\npassage identifier into the vector space in such a way that the embedding is\ncloser to the question without compromising he information content. This\napproach enables efficient creation of real-time query vectors in ~4\nmilliseconds.",
    "descriptor": "\nComments: Year-2019\n",
    "authors": [
      "Mohammed Hammad"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10584"
  },
  {
    "id": "arXiv:2210.10586",
    "title": "Active Learning for Imbalanced Civil Infrastructure Data",
    "abstract": "Aging civil infrastructures are closely monitored by engineers for damage and\ncritical defects. As the manual inspection of such large structures is costly\nand time-consuming, we are working towards fully automating the visual\ninspections to support the prioritization of maintenance activities. To that\nend we combine recent advances in drone technology and deep learning.\nUnfortunately, annotation costs are incredibly high as our proprietary civil\nengineering dataset must be annotated by highly trained engineers. Active\nlearning is, therefore, a valuable tool to optimize the trade-off between model\nperformance and annotation costs. Our use-case differs from the classical\nactive learning setting as our dataset suffers from heavy class imbalance and\nconsists of a much larger already labeled data pool than other active learning\nresearch. We present a novel method capable of operating in this challenging\nsetting by replacing the traditional active learning acquisition function with\nan auxiliary binary discriminator. We experimentally show that our novel method\noutperforms the best-performing traditional active learning method (BALD) by 5%\nand 38% accuracy on CIFAR-10 and our proprietary dataset respectively.",
    "descriptor": "",
    "authors": [
      "Thomas Frick",
      "Diego Antognini",
      "Mattia Rigotti",
      "Ioana Giurgiu",
      "Benjamin Grewe",
      "Cristiano Malossi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10586"
  },
  {
    "id": "arXiv:2210.10592",
    "title": "DyTed: Disentangling Temporal Invariance and Fluctuations in Dynamic  Graph Representation Learning",
    "abstract": "Unsupervised representation learning for dynamic graphs has attracted a lot\nof research attention in recent years. Compared with static graphs, dynamic\ngraphs are the integrative reflection of both the temporal-invariant or stable\ncharacteristics of nodes and the dynamic-fluctuate preference changing with\ntime. However, existing dynamic graph representation learning methods generally\nconfound these two types of information into a shared representation space,\nwhich may lead to poor explanation, less robustness, and a limited ability when\napplied to different downstream tasks. Taking the real dynamic graphs of daily\ncapital transactions on Tencent as an example, the learned representation of\nthe state-of-the-art method achieves only 32% accuracy in predicting\ntemporal-invariant characteristics of users like annual income. In this paper,\nwe introduce a novel temporal invariance-fluctuation disentangled\nrepresentation learning framework for dynamic graphs, namely DyTed. In\nparticular, we propose a temporal-invariant representation generator and a\ndynamic-fluctuate representation generator with carefully designed pretext\ntasks to identify the two types of representations in dynamic graphs. To\nfurther enhance the disentanglement or separation, we propose a\ndisentanglement-aware discriminator under an adversarial learning framework.\nExtensive experiments on Tencent and five commonly used public datasets\ndemonstrate that the different parts of our disentangled representation can\nachieve state-of-the-art performance on various downstream tasks, as well as be\nmore robust against noise, and is a general framework that can further improve\nexisting methods.",
    "descriptor": "",
    "authors": [
      "Kaike Zhang",
      "Qi Cao",
      "Gaolin Fang",
      "Bingbing Xu",
      "Hongjian Zou",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10592"
  },
  {
    "id": "arXiv:2210.10594",
    "title": "Motion-Based Weak Supervision for Video Parsing with Application to  Colonoscopy",
    "abstract": "We propose a two-stage unsupervised approach for parsing videos into phases.\nWe use motion cues to divide the video into coarse segments. Noisy segment\nlabels are then used to weakly supervise an appearance-based classifier. We\nshow the effectiveness of the method for phase detection in colonoscopy videos.",
    "descriptor": "",
    "authors": [
      "Ori Kelner",
      "Or Weinstein",
      "Ehud Rivlin",
      "Roman Goldenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10594"
  },
  {
    "id": "arXiv:2210.10595",
    "title": "DIAMBRA Arena: a New Reinforcement Learning Platform for Research and  Experimentation",
    "abstract": "The recent advances in reinforcement learning have led to effective methods\nable to obtain above human-level performances in very complex environments.\nHowever, once solved, these environments become less valuable, and new\nchallenges with different or more complex scenarios are needed to support\nresearch advances. This work presents DIAMBRA Arena, a new platform for\nreinforcement learning research and experimentation, featuring a collection of\nhigh-quality environments exposing a Python API fully compliant with OpenAI Gym\nstandard. They are episodic tasks with discrete actions and observations\ncomposed by raw pixels plus additional numerical values, all supporting both\nsingle player and two players mode, allowing to work on standard reinforcement\nlearning, competitive multi-agent, human-agent competition, self-play,\nhuman-in-the-loop training and imitation learning. Software capabilities are\ndemonstrated by successfully training multiple deep reinforcement learning\nagents with proximal policy optimization obtaining human-like behavior. Results\nconfirm the utility of DIAMBRA Arena as a reinforcement learning research tool,\nproviding environments designed to study some of the most challenging topics in\nthe field.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Alessandro Palmas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10595"
  },
  {
    "id": "arXiv:2210.10599",
    "title": "Self-supervised Graph Masking Pre-training for Graph-to-Text Generation",
    "abstract": "Large-scale pre-trained language models (PLMs) have advanced Graph-to-Text\n(G2T) generation by processing the linearised version of a graph. However, the\nlinearisation is known to ignore the structural information. Additionally, PLMs\nare typically pre-trained on free text which introduces domain mismatch between\npre-training and downstream G2T generation tasks. To address these\nshortcomings, we propose graph masking pre-training strategies that neither\nrequire supervision signals nor adjust the architecture of the underlying\npre-trained encoder-decoder model. When used with a pre-trained T5, our\napproach achieves new state-of-the-art results on WebNLG+2020 and\nEventNarrative G2T generation datasets. Our method also shows to be very\neffective in the low-resource setting.",
    "descriptor": "\nComments: EMNLP 2022; code is available at this https URL\n",
    "authors": [
      "Jiuzhou Han",
      "Ehsan Shareghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10599"
  },
  {
    "id": "arXiv:2210.10601",
    "title": "Diamonds are Forever, Loss-Versus-Rebalancing is Not",
    "abstract": "The always-available liquidity of automated market makers (AMMs) has been one\nof the most important catalysts in early cryptocurrency adoption. However, it\nhas become increasingly evident that AMMs in their current form are not viable\ninvestment options for passive liquidity providers. This is because of the cost\nincurred by AMMs providing stale prices to arbitrageurs against external market\nprices, formalized as loss-versus-rebalancing (LVR) [Milionis et al., 2022].\nIn this paper, we present Diamond, an automated market making protocol that\naligns the incentives of liquidity providers and block producers in the\nprotocol-level retention of LVR. In Diamond, block producers effectively\nauction the right to capture any arbitrage that exists between the external\nmarket price of a Diamond pool, and the price of the pool itself. The proceeds\nof these auctions are shared by the Diamond pool and block producer in a way\nthat is proven to remain incentive compatible for the block producer. Given the\nparticipation of competing arbitrageurs, LVR is effectively prevented in\nDiamond.\nWe formally prove this result, and detail an implementation of Diamond. We\nalso provide comparative simulations of Diamond to relevant benchmarks, further\nevidencing the LVR-protection capabilities of Diamond.\nWith this new protection, passive liquidity provision on blockchains becomes\nrationally viable, beckoning a new age for decentralized finance.",
    "descriptor": "",
    "authors": [
      "Conor McMenamin",
      "Vanesa Daza",
      "Bruno Mazorra"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10601"
  },
  {
    "id": "arXiv:2210.10602",
    "title": "NGEP: A Graph-based Event Planning Framework for Story Generation",
    "abstract": "To improve the performance of long text generation, recent studies have\nleveraged automatically planned event structures (i.e. storylines) to guide\nstory generation. Such prior works mostly employ end-to-end neural generation\nmodels to predict event sequences for a story. However, such generation models\nstruggle to guarantee the narrative coherence of separate events due to the\nhallucination problem, and additionally the generated event sequences are often\nhard to control due to the end-to-end nature of the models. To address these\nchallenges, we propose NGEP, an novel event planning framework which generates\nan event sequence by performing inference on an automatically constructed event\ngraph and enhances generalisation ability through a neural event advisor. We\nconduct a range of experiments on multiple criteria, and the results\ndemonstrate that our graph-based neural framework outperforms the\nstate-of-the-art (SOTA) event planning approaches, considering both the\nperformance of event sequence generation and the effectiveness on the\ndownstream task of story generation.",
    "descriptor": "",
    "authors": [
      "Chen Tang",
      "Zhihao Zhang",
      "Tyler Loakman",
      "Chenghua Lin",
      "Frank Guerin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10602"
  },
  {
    "id": "arXiv:2210.10605",
    "title": "Provably Convergent Plug & Play Linearized ADMM, applied to Deblurring  Spatially Varying Kernels",
    "abstract": "Plug & Play methods combine proximal algorithms with denoiser priors to solve\ninverse problems. These methods rely on the computability of the proximal\noperator of the data fidelity term. In this paper, we propose a Plug & Play\nframework based on linearized ADMM that allows us to bypass the computation of\nintractable proximal operators. We demonstrate the convergence of the algorithm\nand provide results on restoration tasks such as super-resolution and\ndeblurring with non-uniform blur.",
    "descriptor": "",
    "authors": [
      "Charles Laroche",
      "Andr\u00e9s Almansa",
      "Eva Coupet\u00e9",
      "Matias Tassano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.10605"
  },
  {
    "id": "arXiv:2210.10606",
    "title": "DALLE-2 is Seeing Double: Flaws in Word-to-Concept Mapping in Text2Image  Models",
    "abstract": "We study the way DALLE-2 maps symbols (words) in the prompt to their\nreferences (entities or properties of entities in the generated image). We show\nthat in stark contrast to the way human process language, DALLE-2 does not\nfollow the constraint that each word has a single role in the interpretation,\nand sometimes re-use the same symbol for different purposes. We collect a set\nof stimuli that reflect the phenomenon: we show that DALLE-2 depicts both\nsenses of nouns with multiple senses at once; and that a given word can modify\nthe properties of two distinct entities in the image, or can be depicted as one\nobject and also modify the properties of another object, creating a semantic\nleakage of properties between entities. Taken together, our study highlights\nthe differences between DALLE-2 and human language processing and opens an\navenue for future study on the inductive biases of text-to-image models.",
    "descriptor": "\nComments: 5 pages, BlackboxNLP @ EMNLP 2022\n",
    "authors": [
      "Royi Rassin",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10606"
  },
  {
    "id": "arXiv:2210.10613",
    "title": "Integrated Decision and Control for High-Level Automated Vehicles by  Mixed Policy Gradient and Its Experiment Verification",
    "abstract": "Self-evolution is indispensable to realize full autonomous driving. This\npaper presents a self-evolving decision-making system based on the Integrated\nDecision and Control (IDC), an advanced framework built on reinforcement\nlearning (RL). First, an RL algorithm called constrained mixed policy gradient\n(CMPG) is proposed to consistently upgrade the driving policy of the IDC. It\nadapts the MPG under the penalty method so that it can solve constrained\noptimization problems using both the data and model. Second, an attention-based\nencoding (ABE) method is designed to tackle the state representation issue. It\nintroduces an embedding network for feature extraction and a weighting network\nfor feature fusion, fulfilling order-insensitive encoding and importance\ndistinguishing of road users. Finally, by fusing CMPG and ABE, we develop the\nfirst data-driven decision and control system under the IDC architecture, and\ndeploy the system on a fully-functional self-driving vehicle running in daily\noperation. Experiment results show that boosting by data, the system can\nachieve better driving ability over model-based methods. It also demonstrates\nsafe, efficient and smart driving behavior in various complex scenes at a\nsignalized intersection with real mixed traffic flow.",
    "descriptor": "",
    "authors": [
      "Yang Guan",
      "Liye Tang",
      "Chuanxiao Li",
      "Shengbo Eben Li",
      "Yangang Ren",
      "Junqing Wei",
      "Bo Zhang",
      "Keqiang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10613"
  },
  {
    "id": "arXiv:2210.10615",
    "title": "A Unified View of Masked Image Modeling",
    "abstract": "Masked image modeling has demonstrated great potential to eliminate the\nlabel-hungry problem of training large-scale vision Transformers, achieving\nimpressive performance on various downstream tasks. In this work, we propose a\nunified view of masked image modeling after revisiting existing methods. Under\nthe unified view, we introduce a simple yet effective method, termed as\nMaskDistill, which reconstructs normalized semantic features from teacher\nmodels at the masked positions, conditioning on corrupted input images.\nExperimental results on image classification and semantic segmentation show\nthat MaskDistill achieves comparable or superior performance than\nstate-of-the-art methods. When using the huge vision Transformer and\npretraining 300 epochs, MaskDistill obtains 88.3% fine-tuning top-1 accuracy on\nImageNet-1k (224 size) and 58.8% semantic segmentation mIoU metric on ADE20k\n(512 size). The code and pretrained models will be available at\nhttps://aka.ms/unimim.",
    "descriptor": "",
    "authors": [
      "Zhiliang Peng",
      "Li Dong",
      "Hangbo Bao",
      "Qixiang Ye",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10615"
  },
  {
    "id": "arXiv:2210.10618",
    "title": "Improving Chinese Story Generation via Awareness of Syntactic  Dependencies and Semantics",
    "abstract": "Story generation aims to generate a long narrative conditioned on a given\ninput. In spite of the success of prior works with the application of\npre-trained models, current neural models for Chinese stories still struggle to\ngenerate high-quality long text narratives. We hypothesise that this stems from\nambiguity in syntactically parsing the Chinese language, which does not have\nexplicit delimiters for word segmentation. Consequently, neural models suffer\nfrom the inefficient capturing of features in Chinese narratives. In this\npaper, we present a new generation framework that enhances the feature\ncapturing mechanism by informing the generation model of dependencies between\nwords and additionally augmenting the semantic representation learning through\nsynonym denoising training. We conduct a range of experiments, and the results\ndemonstrate that our framework outperforms the state-of-the-art Chinese\ngeneration models on all evaluation metrics, demonstrating the benefits of\nenhanced dependency and semantic representation learning.",
    "descriptor": "",
    "authors": [
      "Henglin Huang",
      "Chen Tang",
      "Tyler Loakman",
      "Frank Guerin",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10618"
  },
  {
    "id": "arXiv:2210.10619",
    "title": "ResBeMF: Improving Prediction Coverage of Classification based  Collaborative Filtering",
    "abstract": "Reliability measures associated to machine learning model predictions are\ncritical to reinforcing user confidence in artificial intelligence. Therefore,\nthose models that are able to provide not only predictions, but also\nreliability enjoy greater popularity. In the field of recommender systems,\nreliability is crucial, since users tend to prefer those recommendations that\nare sure to interest them, i.e.\\ high predictions with high reliabilities. In\nthis paper we present ResBeMF, a new recommender system based on collaborative\nfiltering that provides reliabilities associated with its predictions.\nExperimental results show that ResBeMF offers greater customization than other\nmodels, allowing to adjust the balance between prediction quality and\nprediction reliability.",
    "descriptor": "",
    "authors": [
      "\u00c1ngel Gonz\u00e1lez-Prieto",
      "Abraham Gutierrez",
      "Fernando Ortega",
      "Ra\u00fal Lara-Cabrera"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10619"
  },
  {
    "id": "arXiv:2210.10620",
    "title": "Active Image Indexing",
    "abstract": "Image copy detection and retrieval from large databases leverage two\ncomponents. First, a neural network maps an image to a vector representation,\nthat is relatively robust to various transformations of the image. Second, an\nefficient but approximate similarity search algorithm trades scalability (size\nand speed) against quality of the search, thereby introducing a source of\nerror. This paper improves the robustness of image copy detection with active\nindexing, that optimizes the interplay of these two components. We reduce the\nquantization loss of a given image representation by making imperceptible\nchanges to the image before its release. The loss is back-propagated through\nthe deep neural network back to the image, under perceptual constraints. These\nmodifications make the image more retrievable. Our experiments show that the\nretrieval and copy detection of activated images is significantly improved. For\ninstance, activation improves by $+40\\%$ the Recall1@1 on various image\ntransformations, and for several popular indexing structures based on product\nquantization and locality sensitivity hashing.",
    "descriptor": "",
    "authors": [
      "Pierre Fernandez",
      "Matthijs Douze",
      "Herv\u00e9 J\u00e9gou",
      "Teddy Furon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10620"
  },
  {
    "id": "arXiv:2210.10621",
    "title": "CLEAR: Causal Explanations from Attention in Neural Recommenders",
    "abstract": "We present CLEAR, a method for learning session-specific causal graphs, in\nthe possible presence of latent confounders, from attention in pre-trained\nattention-based recommenders. These causal graphs describe user behavior,\nwithin the context captured by attention, and can provide a counterfactual\nexplanation for a recommendation. In essence, these causal graphs allow\nanswering \"why\" questions uniquely for any specific session. Using empirical\nevaluations we show that, compared to naively using attention weights to\nexplain input-output relations, counterfactual explanations found by CLEAR are\nshorter and an alternative recommendation is ranked higher in the original\ntop-k recommendations.",
    "descriptor": "\nComments: Causality, Counterfactuals and Sequential Decision-Making for Recommender Systems (CONSEQUENCES) workshop at RecSys 2022, Seattle, WA, USA\n",
    "authors": [
      "Shami Nisimov",
      "Raanan Y. Rohekar",
      "Yaniv Gurwicz",
      "Guy Koren",
      "Gal Novik"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10621"
  },
  {
    "id": "arXiv:2210.10625",
    "title": "HyperMiner: Topic Taxonomy Mining with Hyperbolic Embedding",
    "abstract": "Embedded topic models are able to learn interpretable topics even with large\nand heavy-tailed vocabularies. However, they generally hold the Euclidean\nembedding space assumption, leading to a basic limitation in capturing\nhierarchical relations. To this end, we present a novel framework that\nintroduces hyperbolic embeddings to represent words and topics. With the\ntree-likeness property of hyperbolic space, the underlying semantic hierarchy\namong words and topics can be better exploited to mine more interpretable\ntopics. Furthermore, due to the superiority of hyperbolic geometry in\nrepresenting hierarchical data, tree-structure knowledge can also be naturally\ninjected to guide the learning of a topic hierarchy. Therefore, we further\ndevelop a regularization term based on the idea of contrastive learning to\ninject prior structural knowledge efficiently. Experiments on both topic\ntaxonomy discovery and document representation demonstrate that the proposed\nframework achieves improved performance against existing embedded topic models.",
    "descriptor": "",
    "authors": [
      "Yishi Xu",
      "Dongsheng Wang",
      "Bo Chen",
      "Ruiying Lu",
      "Zhibin Duan",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10625"
  },
  {
    "id": "arXiv:2210.10626",
    "title": "HAVANA: Hard negAtiVe sAmples aware self-supervised coNtrastive leArning  for Airborne laser scanning point clouds semantic segmentation",
    "abstract": "Deep Neural Network (DNN) based point cloud semantic segmentation has\npresented significant achievements on large-scale labeled aerial laser point\ncloud datasets. However, annotating such large-scaled point clouds is\ntime-consuming. Due to density variations and spatial heterogeneity of the\nAirborne Laser Scanning (ALS) point clouds, DNNs lack generalization capability\nand thus lead to unpromising semantic segmentation, as the DNN trained in one\nregion underperform when directly utilized in other regions. However,\nSelf-Supervised Learning (SSL) is a promising way to solve this problem by\npre-training a DNN model utilizing unlabeled samples followed by a fine-tuned\ndownstream task involving very limited labels. Hence, this work proposes a\nhard-negative sample aware self-supervised contrastive learning method to\npre-train the model for semantic segmentation. The traditional contrastive\nlearning for point clouds selects the hardest negative samples by solely\nrelying on the distance between the embedded features derived from the learning\nprocess, potentially evolving some negative samples from the same classes to\nreduce the contrastive learning effectiveness. Therefore, we design an AbsPAN\n(Absolute Positive And Negative samples) strategy based on k-means clustering\nto filter the possible false-negative samples. Experiments on two typical ALS\nbenchmark datasets demonstrate that the proposed method is more appealing than\nsupervised training schemes without pre-training. Especially when the labels\nare severely inadequate (10% of the ISPRS training set), the results obtained\nby the proposed HAVANA method still exceed 94% of the supervised paradigm\nperformance with full training set.",
    "descriptor": "",
    "authors": [
      "Yunsheng Zhang",
      "Jianguo Yao",
      "Ruixiang Zhang",
      "Siyang Chen",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10626"
  },
  {
    "id": "arXiv:2210.10628",
    "title": "RecipeMind: Guiding Ingredient Choices from Food Pairing to Recipe  Completion using Cascaded Set Transformer",
    "abstract": "We propose a computational approach for recipe ideation, a downstream task\nthat helps users select and gather ingredients for creating dishes. To perform\nthis task, we developed RecipeMind, a food affinity score prediction model that\nquantifies the suitability of adding an ingredient to set of other ingredients.\nWe constructed a large-scale dataset containing ingredient co-occurrence based\nscores to train and evaluate RecipeMind on food affinity score prediction.\nDeployed in recipe ideation, RecipeMind helps the user expand an initial set of\ningredients by suggesting additional ingredients. Experiments and qualitative\nanalysis show RecipeMind's potential in fulfilling its assistive role in\ncuisine domain.",
    "descriptor": "\nComments: Accepted and to be appeared in CIKM-2022\n",
    "authors": [
      "Mogan Gim",
      "Donghee Choi",
      "Kana Maruyama",
      "Jihun Choi",
      "Hajung Kim",
      "Donghyeon Park",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10628"
  },
  {
    "id": "arXiv:2210.10629",
    "title": "Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender  Systems",
    "abstract": "Existing benchmark datasets for recommender systems (RS) either are created\nat a small scale or involve very limited forms of user feedback. RS models\nevaluated on such datasets often lack practical values for large-scale\nreal-world applications. In this paper, we describe Tenrec, a novel and\npublicly available data collection for RS that records various user feedback\nfrom four different recommendation scenarios. To be specific, Tenrec has the\nfollowing five characteristics: (1) it is large-scale, containing around 5\nmillion users and 140 million interactions; (2) it has not only positive user\nfeedback, but also true negative feedback (vs. one-class recommendation); (3)\nit contains overlapped users and items across four different scenarios; (4) it\ncontains various types of user positive feedback, in forms of clicks, likes,\nshares, and follows, etc; (5) it contains additional features beyond the user\nIDs and item IDs. We verify Tenrec on ten diverse recommendation tasks by\nrunning several classical baseline models per task. Tenrec has the potential to\nbecome a useful benchmark dataset for a majority of popular recommendation\ntasks.",
    "descriptor": "",
    "authors": [
      "Guanghu Yuan",
      "Fajie Yuan",
      "Yudong Li",
      "Beibei Kong",
      "Shujie Li",
      "Lei Chen",
      "Min Yang",
      "Chenyun YU",
      "Bo Hu",
      "Zang Li",
      "Yu Xu",
      "Xiaohu Qie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10629"
  },
  {
    "id": "arXiv:2210.10630",
    "title": "Irregularly-Sampled Time Series Modeling with Spline Networks",
    "abstract": "Observations made in continuous time are often irregular and contain the\nmissing values across different channels. One approach to handle the missing\ndata is imputing it using splines, by fitting the piecewise polynomials to the\nobserved values. We propose using the splines as an input to a neural network,\nin particular, applying the transformations on the interpolating function\ndirectly, instead of sampling the points on a grid. To do that, we design the\nlayers that can operate on splines and which are analogous to their discrete\ncounterparts. This allows us to represent the irregular sequence compactly and\nuse this representation in the downstream tasks such as classification and\nforecasting. Our model offers competitive performance compared to the existing\nmethods both in terms of the accuracy and computation efficiency.",
    "descriptor": "\nComments: ICML Continuous Time Methods for Machine Learning Workshop (2022)\n",
    "authors": [
      "Marin Bilo\u0161",
      "Emanuel Ramneantu",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10630"
  },
  {
    "id": "arXiv:2210.10631",
    "title": "Simulated Contextual Bandits for Personalization Tasks from  Recommendation Datasets",
    "abstract": "We propose a method for generating simulated contextual bandit environments\nfor personalization tasks from recommendation datasets like MovieLens, Netflix,\nLast.fm, Million Song, etc. This allows for personalization environments to be\ndeveloped based on real-life data to reflect the nuanced nature of real-world\nuser interactions. The obtained environments can be used to develop methods for\nsolving personalization tasks, algorithm benchmarking, model simulation, and\nmore. We demonstrate our approach with numerical examples on MovieLens and IMDb\ndatasets.",
    "descriptor": "",
    "authors": [
      "Anton Dereventsov",
      "Anton Bibin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10631"
  },
  {
    "id": "arXiv:2210.10633",
    "title": "Depth Contrast: Self-Supervised Pretraining on 3DPM Images for Mining  Material Classification",
    "abstract": "This work presents a novel self-supervised representation learning method to\nlearn efficient representations without labels on images from a 3DPM sensor\n(3-Dimensional Particle Measurement; estimates the particle size distribution\nof material) utilizing RGB images and depth maps of mining material on the\nconveyor belt. Human annotations for material categories on sensor-generated\ndata are scarce and cost-intensive. Currently, representation learning without\nhuman annotations remains unexplored for mining materials and does not leverage\non utilization of sensor-generated data. The proposed method, Depth Contrast,\nenables self-supervised learning of representations without labels on the 3DPM\ndataset by exploiting depth maps and inductive transfer. The proposed method\noutperforms material classification over ImageNet transfer learning performance\nin fully supervised learning settings and achieves an F1 score of 0.73.\nFurther, The proposed method yields an F1 score of 0.65 with an 11% improvement\nover ImageNet transfer learning performance in a semi-supervised setting when\nonly 20% of labels are used in fine-tuning. Finally, the Proposed method\nshowcases improved performance generalization on linear evaluation. The\nimplementation of proposed method is available on GitHub.",
    "descriptor": "\nComments: Accepted to CVF European Conference on Computer Vision Workshop(ECCVW 2022)\n",
    "authors": [
      "Prakash Chandra Chhipa",
      "Richa Upadhyay",
      "Rajkumar Saini",
      "Lars Lindqvist",
      "Richard Nordenskjold",
      "Seiichi Uchida",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10633"
  },
  {
    "id": "arXiv:2210.10634",
    "title": "RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses",
    "abstract": "Recently, substantial progress has been made in text ranking based on\npretrained language models such as BERT. However, there are limited studies on\nhow to leverage more powerful sequence-to-sequence models such as T5. Existing\nattempts usually formulate text ranking as classification and rely on\npostprocessing to obtain a ranked list. In this paper, we propose RankT5 and\nstudy two T5-based ranking model structures, an encoder-decoder and an\nencoder-only one, so that they not only can directly output ranking scores for\neach query-document pair, but also can be fine-tuned with \"pairwise\" or\n\"listwise\" ranking losses to optimize ranking performances. Our experiments\nshow that the proposed models with ranking losses can achieve substantial\nranking performance gains on different public text ranking data sets. Moreover,\nwhen fine-tuned with listwise ranking losses, the ranking model appears to have\nbetter zero-shot ranking performance on out-of-domain data sets compared to the\nmodel fine-tuned with classification losses.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Honglei Zhuang",
      "Zhen Qin",
      "Rolf Jagerman",
      "Kai Hui",
      "Ji Ma",
      "Jing Lu",
      "Jianmo Ni",
      "Xuanhui Wang",
      "Michael Bendersky"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10634"
  },
  {
    "id": "arXiv:2210.10636",
    "title": "Using Interventions to Improve Out-of-Distribution Generalization of  Text-Matching Recommendation Systems",
    "abstract": "Given a user's input text, text-matching recommender systems output relevant\nitems by comparing the input text to available items' description, such as\nproduct-to-product recommendation on e-commerce platforms. As users' interests\nand item inventory are expected to change, it is important for a text-matching\nsystem to generalize to data shifts, a task known as out-of-distribution (OOD)\ngeneralization. However, we find that the popular approach of fine-tuning a\nlarge, base language model on paired item relevance data (e.g., user clicks)\ncan be counter-productive for OOD generalization. For a product recommendation\ntask, fine-tuning obtains worse accuracy than the base model when recommending\nitems in a new category or for a future time period. To explain this\ngeneralization failure, we consider an intervention-based importance metric,\nwhich shows that a fine-tuned model captures spurious correlations and fails to\nlearn the causal features that determine the relevance between any two text\ninputs. Moreover, standard methods for causal regularization do not apply in\nthis setting, because unlike in images, there exist no universally spurious\nfeatures in a text-matching task (the same token may be spurious or causal\ndepending on the text it is being matched to). For OOD generalization on text\ninputs, therefore, we highlight a different goal: avoiding high importance\nscores for certain features. We do so using an intervention-based regularizer\nthat constraints the causal effect of any token on the model's relevance score\nto be similar to the base model. Results on Amazon product and 3 question\nrecommendation datasets show that our proposed regularizer improves\ngeneralization for both in-distribution and OOD evaluation, especially in\ndifficult scenarios when the base model is not accurate.",
    "descriptor": "",
    "authors": [
      "Parikshit Bansal",
      "Yashoteja Prabhu",
      "Emre Kiciman",
      "Amit Sharma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10636"
  },
  {
    "id": "arXiv:2210.10637",
    "title": "Digital Asset Valuation: A Study on Domain Names, Email Addresses, and  NFTs",
    "abstract": "Existing works on valuing digital assets on the Internet typically focus on a\nsingle asset class. To promote the development of automated valuation\ntechniques, preferably those that are generally applicable to multiple asset\nclasses, we construct DASH, the first Digital Asset Sales History dataset that\nfeatures multiple digital asset classes spanning from classical to\nblockchain-based ones. Consisting of 280K transactions of domain names\n(DASH_DN), email addresses (DASH_EA), and non-fungible token (NFT)-based\nidentifiers (DASH_NFT), such as Ethereum Name Service names, DASH advances the\nfield in several aspects: the subsets DASH_DN, DASH_EA, and DASH_NFT are the\nlargest freely accessible domain name transaction dataset, the only publicly\navailable email address transaction dataset, and the first NFT transaction\ndataset that focuses on identifiers, respectively.\nWe build strong conventional feature-based models as the baselines for DASH.\nWe next explore deep learning models based on fine-tuning pre-trained language\nmodels, which have not yet been explored for digital asset valuation in the\nprevious literature. We find that the vanilla fine-tuned model already performs\nreasonably well, outperforming all but the best-performing baselines. We\nfurther propose improvements to make the model more aware of the time\nsensitivity of transactions and the popularity of assets. Experimental results\nshow that our improved model consistently outperforms all the other models\nacross all asset classes on DASH.",
    "descriptor": "",
    "authors": [
      "Kai Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10637"
  },
  {
    "id": "arXiv:2210.10638",
    "title": "Digital Human Interactive Recommendation Decision-Making Based on  Reinforcement Learning",
    "abstract": "Digital human recommendation system has been developed to help customers to\nfind their favorite products and is playing an active role in various\nrecommendation contexts. How to catch and learn the preferences of the\ncustomers at the right time and meet the exact requirements of the customer\nbecome crucial in the digital human recommendation. We design a novel practical\ndigital human interactive recommendation agent framework based on reinforcement\nlearning to improve the efficiency of interactive recommendation\ndecision-making by leveraging both the digital human features and the\nsuperiority of reinforcement learning. The proposed framework learns through\nimmediate interactions among the digital human and customers dynamically\nthrough stat-of-art reinforcement learning algorithms and embedding with\nmultimodal and graph embedding to improve the accuracy of the personalization\nand thus enable the digital human agent to actively catch the attention of a\ncustomer timely. Experiments on real business data show that this framework can\nprovide better-personalized customer engagement and better customer experiences\netc.",
    "descriptor": "\nComments: Preprint Under Review: NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL\n",
    "authors": [
      "Junwu Xiong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10638"
  },
  {
    "id": "arXiv:2210.10639",
    "title": "Robot Navigation with Reinforcement Learned Path Generation and  Fine-Tuned Motion Control",
    "abstract": "In this paper, we propose a novel reinforcement learning (RL) based path\ngeneration (RL-PG) approach for mobile robot navigation without a prior\nexploration of an unknown environment. Multiple predictive path points are\ndynamically generated by a deep Markov model optimized using RL approach for\nrobot to track. To ensure the safety when tracking the predictive points, the\nrobot's motion is fine-tuned by a motion fine-tuning module. Such an approach,\nusing the deep Markov model with RL algorithm for planning, focuses on the\nrelationship between adjacent path points. We analyze the benefits that our\nproposed approach are more effective and are with higher success rate than\nRL-Based approach DWA-RL and a traditional navigation approach APF. We deploy\nour model on both simulation and physical platforms and demonstrate our model\nperforms robot navigation effectively and safely.",
    "descriptor": "",
    "authors": [
      "Longyuan Zhang",
      "Ziyue Hou",
      "Ji Wang",
      "Ziang Liu",
      "Wei Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10639"
  },
  {
    "id": "arXiv:2210.10643",
    "title": "Towards Accurate Subgraph Similarity Computation via Neural Graph  Pruning",
    "abstract": "Subgraph similarity search, one of the core problems in graph search,\nconcerns whether a target graph approximately contains a query graph. The\nproblem is recently touched by neural methods. However, current neural methods\ndo not consider pruning the target graph, though pruning is critically\nimportant in traditional calculations of subgraph similarities. One obstacle to\napplying pruning in neural methods is {the discrete property of pruning}. In\nthis work, we convert graph pruning to a problem of node relabeling and then\nrelax it to a differentiable problem. Based on this idea, we further design a\nnovel neural network to approximate a type of subgraph distance: the subgraph\nedit distance (SED). {In particular, we construct the pruning component using a\nneural structure, and the entire model can be optimized end-to-end.} In the\ndesign of the model, we propose an attention mechanism to leverage the\ninformation about the query graph and guide the pruning of the target graph.\nMoreover, we develop a multi-head pruning strategy such that the model can\nbetter explore multiple ways of pruning the target graph. The proposed model\nestablishes new state-of-the-art results across seven benchmark datasets.\nExtensive analysis of the model indicates that the proposed model can\nreasonably prune the target graph for SED computation. The implementation of\nour algorithm is released at our Github repo:\nhttps://github.com/tufts-ml/Prune4SED.",
    "descriptor": "",
    "authors": [
      "Linfeng Liu",
      "Xu Han",
      "Dawei Zhou",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10643"
  },
  {
    "id": "arXiv:2210.10646",
    "title": "Robust Regression with Highly Corrupted Data via Physics Informed Neural  Networks",
    "abstract": "Physics-informed neural networks (PINNs) have been proposed to solve two main\nclasses of problems: data-driven solutions and data-driven discovery of partial\ndifferential equations. This task becomes prohibitive when such data is highly\ncorrupted due to the possible sensor mechanism failing. We propose the Least\nAbsolute Deviation based PINN (LAD-PINN) to reconstruct the solution and\nrecover unknown parameters in PDEs - even if spurious data or outliers corrupt\na large percentage of the observations. To further improve the accuracy of\nrecovering hidden physics, the two-stage Median Absolute Deviation based PINN\n(MAD-PINN) is proposed, where LAD-PINN is employed as an outlier detector\nfollowed by MAD screening out the highly corrupted data. Then the vanilla PINN\nor its variants can be subsequently applied to exploit the remaining normal\ndata. Through several examples, including Poisson's equation, wave equation,\nand steady or unsteady Navier-Stokes equations, we illustrate the\ngeneralizability, accuracy and efficiency of the proposed algorithms for\nrecovering governing equations from noisy and highly corrupted measurement\ndata.",
    "descriptor": "",
    "authors": [
      "Wei Peng",
      "Wen Yao",
      "Weien Zhou",
      "Xiaoya Zhang",
      "Weijie Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10646"
  },
  {
    "id": "arXiv:2210.10648",
    "title": "Preliminary Analysis of Channel Capacity in Air to ground LoS MIMO  Communication Based on A Cloud Modeling Method",
    "abstract": "Since the orthogonality of the line-of-sight multiple input multiple output\n(LoS MIMO) channel is only available within the Rayleigh distance, coverage of\ncommunication systems is restricted due to the finite implementation spacing of\nantennas. However, media with different permittivity in the transmission path\nare likely to loosen the requirement for antenna spacing. Such a conclusion\ncould be enlightening in an air-to-ground LoS MIMO scenario considering the\nexistence of clouds in the troposphere. To analyze the random phase variations\nin the presence of a single-layer cloud, we propose and modify a new cloud\nmodeling method fit for LoS MIMO scene based on real-measurement data. Then,\nthe preliminary analysis of channel capacity is conducted based on the\nsimulation result.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Ning Wei",
      "Shuangqing Tang",
      "Zeyuan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10648"
  },
  {
    "id": "arXiv:2210.10651",
    "title": "Fant\u00f4mas: Evaluating Reversibility of Face Anonymizations Using a  General Deep Learning Attacker",
    "abstract": "Biometric data is a rich source of information that can be used to identify\nindividuals and infer private information about them. To mitigate this privacy\nrisk, anonymization techniques employ transformations on clear data to\nobfuscate sensitive information, all while retaining some utility of the data.\nAlbeit published with impressive claims, they sometimes are not evaluated with\nconvincing methodology. We hence are interested to which extent recently\nsuggested anonymization techniques for obfuscating facial images are effective.\nMore specifically, we test how easily they can be automatically reverted, to\nestimate the privacy they can provide. Our approach is agnostic to the\nanonymization technique as we learn a machine learning model on the clear and\ncorresponding anonymized data. We find that 10 out of 14 tested face\nanonymization techniques are at least partially reversible, and six of them are\nat least highly reversible.",
    "descriptor": "",
    "authors": [
      "Julian Todt",
      "Simon Hanisch",
      "Thorsten Strufe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10651"
  },
  {
    "id": "arXiv:2210.10652",
    "title": "Multi-Modal Recommendation System with Auxiliary Information",
    "abstract": "Context-aware recommendation systems improve upon classical recommender\nsystems by including, in the modelling, a user's behaviour. Research into\ncontext-aware recommendation systems has previously only considered the\nsequential ordering of items as contextual information. However, there is a\nwealth of unexploited additional multi-modal information available in auxiliary\nknowledge related to items. This study extends the existing research by\nevaluating a multi-modal recommendation system that exploits the inclusion of\ncomprehensive auxiliary knowledge related to an item. The empirical results\nexplore extracting vector representations (embeddings) from unstructured and\nstructured data using data2vec. The fused embeddings are then used to train\nseveral state-of-the-art transformer architectures for sequential user-item\nrepresentations. The analysis of the experimental results shows a statistically\nsignificant improvement in prediction accuracy, which confirms the\neffectiveness of including auxiliary information in a context-aware\nrecommendation system. We report a 4% and 11% increase in the NDCG score for\nlong and short user sequence datasets, respectively.",
    "descriptor": "\nComments: 15 pages, 3 figures, 3 tables, to be published in the SACAIR CCIS Springer proceedings volume\n",
    "authors": [
      "Mufhumudzi Muthivhi",
      "Terence L. van Zyl",
      "Hairong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.10652"
  },
  {
    "id": "arXiv:2210.10654",
    "title": "POGD: Gradient Descent with New Stochastic Rules",
    "abstract": "There introduce Particle Optimized Gradient Descent (POGD), an algorithm\nbased on the gradient descent but integrates the particle swarm optimization\n(PSO) principle to achieve the iteration. From the experiments, this algorithm\nhas adaptive learning ability. The experiments in this paper mainly focus on\nthe training speed to reach the target value and the ability to prevent the\nlocal minimum. The experiments in this paper are achieved by the convolutional\nneural network (CNN) image classification on the MNIST and cifar-10 datasets.",
    "descriptor": "",
    "authors": [
      "Feihu Han",
      "Sida Xing",
      "Sui Yang Khoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10654"
  },
  {
    "id": "arXiv:2210.10655",
    "title": "Controlling Travel Path of Original Cobra",
    "abstract": "In this paper we propose a kernel based COBRA which is a direct approximation\nof the original COBRA. We propose a novel tuning procedure for original COBRA\nparameters based on this kernel approximation. We show that our proposed\nalgorithm provides much better accuracy than other COBRAs and faster than usual\nGridsearch COBRA. We use two datasets to illustrate our proposed methodology\nover existing COBRAs.",
    "descriptor": "\nComments: 9 pages; 2 figures\n",
    "authors": [
      "Mriganka Basu RoyChowdhury",
      "Arabin K Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.10655"
  },
  {
    "id": "arXiv:2210.10657",
    "title": "A Framework for Undergraduate Data Collection Strategies for Student  Support Recommendation Systems in Higher Education",
    "abstract": "Understanding which student support strategies mitigate dropout and improve\nstudent retention is an important part of modern higher educational research.\nOne of the largest challenges institutions of higher learning currently face is\nthe scalability of student support. Part of this is due to the shortage of\nstaff addressing the needs of students, and the subsequent referral pathways\nassociated to provide timeous student support strategies. This is further\ncomplicated by the difficulty of these referrals, especially as students are\noften faced with a combination of administrative, academic, social, and\nsocio-economic challenges. A possible solution to this problem can be a\ncombination of student outcome predictions and applying algorithmic recommender\nsystems within the context of higher education. While much effort and detail\nhas gone into the expansion of explaining algorithmic decision making in this\ncontext, there is still a need to develop data collection strategies Therefore,\nthe purpose of this paper is to outline a data collection framework specific to\nrecommender systems within this context in order to reduce collection biases,\nunderstand student characteristics, and find an ideal way to infer optimal\ninfluences on the student journey. If confirmation biases, challenges in data\nsparsity and the type of information to collect from students are not\naddressed, it will have detrimental effects on attempts to assess and evaluate\nthe effects of these systems within higher education.",
    "descriptor": "\nComments: 14 pages, 4 figures, Proceedings of the 2020 SACAIR Conference\n",
    "authors": [
      "Herkulaas MvE Combrink",
      "Vukosi Marivate",
      "Benjamin Rosman"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10657"
  },
  {
    "id": "arXiv:2210.10659",
    "title": "Review of the state of the art in autonomous artificial intelligence",
    "abstract": "This article presents a new design for autonomous artificial intelligence\n(AI), based on the state-of-the-art algorithms, and describes a new autonomous\nAI system called AutoAI. The methodology is used to assemble the design founded\non self-improved algorithms that use new and emerging sources of data (NEFD).\nThe objective of the article is to conceptualise the design of a novel AutoAI\nalgorithm. The conceptual approach is used to advance into building new and\nimproved algorithms. The article integrates and consolidates the findings from\nexisting literature and advances the AutoAI design into (1) using new and\nemerging sources of data for teaching and training AI algorithms and (2)\nenabling AI algorithms to use automated tools for training new and improved\nalgorithms. This approach is going beyond the state-of-the-art in AI algorithms\nand suggests a design that enables autonomous algorithms to self-optimise and\nself-adapt, and on a higher level, be capable to self-procreate.",
    "descriptor": "\nComments: AI Ethics (2022)\n",
    "authors": [
      "Petar Radanliev",
      "David De Roure"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10659"
  },
  {
    "id": "arXiv:2210.10660",
    "title": "Binary Orthogonal Non-negative Matrix Factorization",
    "abstract": "We propose a method for computing binary orthogonal non-negative matrix\nfactorization (BONMF) for clustering and classification. The method is tested\non several representative real-world data sets. The numerical results confirm\nthat the method has improved accuracy compared to the related techniques. The\nproposed method is fast for training and classification and space efficient.",
    "descriptor": "",
    "authors": [
      "S. Fathi Hafshejani",
      "D. Gaur",
      "S. Hossain",
      "R. Benkoczi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10660"
  },
  {
    "id": "arXiv:2210.10662",
    "title": "Towards Practical Explainability with Cluster Descriptors",
    "abstract": "With the rapid development of machine learning, improving its explainability\nhas become a crucial research goal. We study the problem of making the clusters\nmore explainable by investigating the cluster descriptors. Given a set of\nobjects $S$, a clustering of these objects $\\pi$, and a set of tags $T$ that\nhave not participated in the clustering algorithm. Each object in $S$ is\nassociated with a subset of $T$. The goal is to find a representative set of\ntags for each cluster, referred to as the cluster descriptors, with the\nconstraint that these descriptors we find are pairwise disjoint, and the total\nsize of all the descriptors is minimized. In general, this problem is NP-hard.\nWe propose a novel explainability model that reinforces the previous models in\nsuch a way that tags that do not contribute to explainability and do not\nsufficiently distinguish between clusters are not added to the optimal\ndescriptors. The proposed model is formulated as a quadratic unconstrained\nbinary optimization problem which makes it suitable for solving on modern\noptimization hardware accelerators. We experimentally demonstrate how a\nproposed explainability model can be solved on specialized hardware for\naccelerating combinatorial optimization, the Fujitsu Digital Annealer, and use\nreal-life Twitter and PubMed datasets for use cases.",
    "descriptor": "",
    "authors": [
      "Xiaoyuan Liu",
      "Ilya Tyagin",
      "Hayato Ushijima-Mwesigwa",
      "Indradeep Ghosh",
      "Ilya Safro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10662"
  },
  {
    "id": "arXiv:2210.10664",
    "title": "Deep Multi-Representation Model for Click-Through Rate Prediction",
    "abstract": "Click-Through Rate prediction (CTR) is a crucial task in recommender systems,\nand it gained considerable attention in the past few years. The primary purpose\nof recent research emphasizes obtaining meaningful and powerful representations\nthrough mining low and high feature interactions using various components such\nas Deep Neural Networks (DNN), CrossNets, or transformer blocks. In this work,\nwe propose the Deep Multi-Representation model (DeepMR) that jointly trains a\nmixture of two powerful feature representation learning components, namely DNNs\nand multi-head self-attentions. Furthermore, DeepMR integrates the novel\nresidual with zero initialization (ReZero) connections to the DNN and the\nmulti-head self-attention components for learning superior input\nrepresentations. Experiments on three real-world datasets show that the\nproposed model significantly outperforms all state-of-the-art models in the\ntask of click-through rate prediction.",
    "descriptor": "",
    "authors": [
      "Shereen Elsayed",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10664"
  },
  {
    "id": "arXiv:2210.10665",
    "title": "Soil moisture estimation from Sentinel-1 interferometric observations  over arid regions",
    "abstract": "We present a methodology based on interferometric synthetic aperture radar\n(InSAR) time series analysis that can provide surface (top 5 cm) soil moisture\n(SSM) estimations. The InSAR time series analysis consists of five processing\nsteps. A co-registered Single Look Complex (SLC) SAR stack as well as\nmeteorological information are required as input of the proposed workflow. In\nthe first step, ice/snow-free and zero-precipitation SAR images are identified\nusing meteorological data. In the second step, construction and phase\nextraction of distributed scatterers (DSs) (over bare land) is performed. In\nthe third step, for each DS the ordering of surface soil moisture (SSM) levels\nof SAR acquisitions based on interferometric coherence is calculated. In the\nfourth step, for each DS the coherence due to SSM variations is calculated. In\nthe fifth step, SSM is estimated by a constrained inversion of an analytical\ninterferometric model using coherence and phase closure information. The\nimplementation of the proposed approach is provided as an open-source software\ntoolbox (INSAR4SM) available at www.github.com/kleok/INSAR4SM.\nA case study over an arid region in California/Arizona is presented. The\nproposed workflow was applied in Sentinel- 1 (C-band) VV-polarized InSAR\nobservations. The estimated SSM results were assessed with independent SSM\nobservations from a station of the International Soil Moisture Network (ISMN)\n(RMSE: 0.027 $m^3/m^3$ R: 0.88) and ERA5-Land reanalysis model data (RMSE:\n0.035 $m^3/m^3$ R: 0.71). The proposed methodology was able to provide accurate\nSSM estimations at high spatial resolution (~250 m). A discussion of the\nbenefits and the limitations of the proposed methodology highlighted the\npotential of interferometric observables for SSM estimation over arid regions.",
    "descriptor": "",
    "authors": [
      "Kleanthis Karamvasis",
      "Vassilia Karathanassi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10665"
  },
  {
    "id": "arXiv:2210.10667",
    "title": "Analysis of Master Vein Attacks on Finger Vein Recognition Systems",
    "abstract": "Finger vein recognition (FVR) systems have been commercially used, especially\nin ATMs, for customer verification. Thus, it is essential to measure their\nrobustness against various attack methods, especially when a hand-crafted FVR\nsystem is used without any countermeasure methods. In this paper, we are the\nfirst in the literature to introduce master vein attacks in which we craft a\nvein-looking image so that it can falsely match with as many identities as\npossible by the FVR systems. We present two methods for generating master veins\nfor use in attacking these systems. The first uses an adaptation of the latent\nvariable evolution algorithm with a proposed generative model (a multi-stage\ncombination of beta-VAE and WGAN-GP models). The second uses an adversarial\nmachine learning attack method to attack a strong surrogate CNN-based\nrecognition system. The two methods can be easily combined to boost their\nattack ability. Experimental results demonstrated that the proposed methods\nalone and together achieved false acceptance rates up to 73.29% and 88.79%,\nrespectively, against Miura's hand-crafted FVR system. We also point out that\nMiura's system is easily compromised by non-vein-looking samples generated by a\nWGAN-GP model with false acceptance rates up to 94.21%. The results raise the\nalarm about the robustness of such systems and suggest that master vein attacks\nshould be considered an important security measure.",
    "descriptor": "\nComments: Accepted to be Published in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Huy H. Nguyen",
      "Trung-Nghia Le",
      "Junichi Yamagishi",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10667"
  },
  {
    "id": "arXiv:2210.10668",
    "title": "N-Best Hypotheses Reranking for Text-To-SQL Systems",
    "abstract": "Text-to-SQL task maps natural language utterances to structured queries that\ncan be issued to a database. State-of-the-art (SOTA) systems rely on finetuning\nlarge, pre-trained language models in conjunction with constrained decoding\napplying a SQL parser. On the well established Spider dataset, we begin with\nOracle studies: specifically, choosing an Oracle hypothesis from a SOTA model's\n10-best list, yields a $7.7\\%$ absolute improvement in both exact match (EM)\nand execution (EX) accuracy, showing significant potential improvements with\nreranking. Identifying coherence and correctness as reranking approaches, we\ndesign a model generating a query plan and propose a heuristic schema linking\nalgorithm. Combining both approaches, with T5-Large, we obtain a consistent\n$1\\% $ improvement in EM accuracy, and a $~2.5\\%$ improvement in EX,\nestablishing a new SOTA for this task. Our comprehensive error studies on DEV\ndata show the underlying difficulty in making progress on this task.",
    "descriptor": "\nComments: Accepted for publication at IEEE SLT'22\n",
    "authors": [
      "Lu Zeng",
      "Sree Hari Krishnan Parthasarathi",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10668"
  },
  {
    "id": "arXiv:2210.10669",
    "title": "Weakly Supervised Learning for Analyzing Political Campaigns on Facebook",
    "abstract": "Social media platforms are currently the main channel for political\nmessaging, allowing politicians to target specific demographics and adapt based\non their reactions. However, making this communication transparent is\nchallenging, as the messaging is tightly coupled with its intended audience and\noften echoed by multiple stakeholders interested in advancing specific\npolicies. Our goal in this paper is to take a first step towards understanding\nthese highly decentralized settings. We propose a weakly supervised approach to\nidentify the stance and issue of political ads on Facebook and analyze how\npolitical campaigns use some kind of demographic targeting by location, gender,\nor age. Furthermore, we analyze the temporal dynamics of the political ads on\nelection polls.",
    "descriptor": "\nComments: accepted at 17th International AAAI Conference on Web and Social Media (ICWSM-2023), 12 pages\n",
    "authors": [
      "Tunazzina Islam",
      "Shamik Roy",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10669"
  },
  {
    "id": "arXiv:2210.10670",
    "title": "Attaining Class-level Forgetting in Pretrained Model using Few Samples",
    "abstract": "In order to address real-world problems, deep learning models are jointly\ntrained on many classes. However, in the future, some classes may become\nrestricted due to privacy/ethical concerns, and the restricted class knowledge\nhas to be removed from the models that have been trained on them. The available\ndata may also be limited due to privacy/ethical concerns, and re-training the\nmodel will not be possible. We propose a novel approach to address this problem\nwithout affecting the model's prediction power for the remaining classes. Our\napproach identifies the model parameters that are highly relevant to the\nrestricted classes and removes the knowledge regarding the restricted classes\nfrom them using the limited available training data. Our approach is\nsignificantly faster and performs similar to the model re-trained on the\ncomplete data of the remaining classes.",
    "descriptor": "\nComments: Accepted in ECCV 2022\n",
    "authors": [
      "Pravendra Singh",
      "Pratik Mazumder",
      "Mohammed Asad Karim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10670"
  },
  {
    "id": "arXiv:2210.10672",
    "title": "Arabic Word-level Readability Visualization for Assisted Text  Simplification",
    "abstract": "This demo paper presents a Google Docs add-on for automatic Arabic word-level\nreadability visualization. The add-on includes a lemmatization component that\nis connected to a five-level readability lexicon and Arabic WordNet-based\nsubstitution suggestions. The add-on can be used for assessing the reading\ndifficulty of a text and identifying difficult words as part of the task of\nmanual text simplification. We make our add-on and its code publicly available.",
    "descriptor": "",
    "authors": [
      "Reem Hazim",
      "Hind Saddiki",
      "Bashar Alhafni",
      "Muhamed Al Khalil",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10672"
  },
  {
    "id": "arXiv:2210.10676",
    "title": "Kirin: Hitting the Internet with Millions of Distributed IPv6  Announcements",
    "abstract": "The Internet is a critical resource in the day-to-day life of billions of\nusers. To support the growing number of users and their increasing demands,\noperators have to continuously scale their network footprint -- e.g., by\njoining Internet Exchange Points -- and adopt relevant technologies -- such as\nIPv6. IPv6, however, has a vastly larger address space compared to its\npredecessor, which allows for new kinds of attacks on the Internet routing\ninfrastructure.\nIn this paper, we present Kirin: a BGP attack that sources millions of IPv6\nroutes and distributes them via thousands of sessions across various IXPs to\noverflow the memory of border routers within thousands of remote ASes. Kirin's\nhighly distributed nature allows it to bypass traditional route-flooding\ndefense mechanisms, such as per-session prefix limits or route flap damping. We\nanalyze the theoretical feasibility of the attack by formulating it as a\nInteger Linear Programming problem, test for practical hurdles by deploying the\ninfrastructure required to perform a small-scale Kirin attack using 4 IXPs, and\nvalidate our assumptions via BGP data analysis, real-world measurements, and\nrouter testbed experiments. Despite its low deployment cost, we find Kirin\ncapable of injecting lethal amounts of IPv6 routes in the routers of thousands\nof ASes.",
    "descriptor": "",
    "authors": [
      "Lars Prehn",
      "Pawel Foremski",
      "Oliver Gasser"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.10676"
  },
  {
    "id": "arXiv:2210.10677",
    "title": "List homomorphisms by deleting edges and vertices: tight complexity  bounds for bounded-treewidth graphs",
    "abstract": "The goal of this paper is to investigate a family of optimization problems\narising from list homomorphisms, and to understand what the best possible\nalgorithms are if we restrict the problem to bounded-treewidth graphs. For a\nfixed $H$, the input of the optimization problem LHomVD($H$) is a graph $G$\nwith lists $L(v)$, and the task is to find a set $X$ of vertices having minimum\nsize such that $(G-X,L)$ has a list homomorphism to $H$. We define analogously\nthe edge-deletion variant LHomED($H$). This expressive family of problems\nincludes members that are essentially equivalent to fundamental problems such\nas Vertex Cover, Max Cut, Odd Cycle Transversal, and Edge/Vertex Multiway Cut.\nFor both variants, we first characterize those graphs $H$ that make the\nproblem polynomial-time solvable and show that the problem is NP-hard for every\nother fixed $H$. Second, as our main result, we determine for every graph $H$\nfor which the problem is NP-hard, the smallest possible constant $c_H$ such\nthat the problem can be solved in time $c^t_H\\cdot n^{O(1)}$ if a tree\ndecomposition of $G$ having width $t$ is given in the input, assuming the SETH.\nLet $i(H)$ be the maximum size of a set of vertices in $H$ that have pairwise\nincomparable neighborhoods. For the vertex-deletion variant LHomVD($H$), we\nshow that the smallest possible constant is $i(H)+1$ for every $H$.\nThe situation is more complex for the edge-deletion version. For every $H$,\none can solve LHomED($H$) in time $i(H)^t\\cdot n^{O(1)}$ if a tree\ndecomposition of width $t$ is given. However, the existence of a specific type\nof decomposition of $H$ shows that there are graphs $H$ where LHomED($H$) can\nbe solved significantly more efficiently and the best possible constant can be\narbitrarily smaller than $i(H)$. Nevertheless, we determine this best possible\nconstant and (assuming the SETH) prove tight bounds for every fixed $H$.",
    "descriptor": "",
    "authors": [
      "Bar\u0131\u015f Can Esmer",
      "Jacob Focke",
      "D\u00e1niel Marx",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10677"
  },
  {
    "id": "arXiv:2210.10678",
    "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with  Empirical Baseline Study",
    "abstract": "This paper presents an empirical study to build relation extraction systems\nin low-resource settings. Based upon recent pre-trained language models, we\ncomprehensively investigate three schemes to evaluate the performance in\nlow-resource settings: (i) different types of prompt-based methods with\nfew-shot labeled data; (ii) diverse balancing methods to address the\nlong-tailed distribution issue; (iii) data augmentation technologies and\nself-training to generate more labeled in-domain data. We create a benchmark\nwith 8 relation extraction (RE) datasets covering different languages, domains\nand contexts and perform extensive comparisons over the proposed schemes with\ncombinations. Our experiments illustrate: (i) Though prompt-based tuning is\nbeneficial in low-resource RE, there is still much potential for improvement,\nespecially in extracting relations from cross-sentence contexts with multiple\nrelational triples; (ii) Balancing methods are not always helpful for RE with\nlong-tailed distribution; (iii) Data augmentation complements existing\nbaselines and can bring much performance gain, while self-training may not\nconsistently achieve advancement to low-resource RE. Code and datasets are in\nhttps://github.com/zjunlp/LREBench.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (Findings)\n",
    "authors": [
      "Xin Xu",
      "Xiang Chen",
      "Ningyu Zhang",
      "Xin Xie",
      "Xi Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10678"
  },
  {
    "id": "arXiv:2210.10683",
    "title": "Why Should Adversarial Perturbations be Imperceptible? Rethink the  Research Paradigm in Adversarial NLP",
    "abstract": "Textual adversarial samples play important roles in multiple subfields of NLP\nresearch, including security, evaluation, explainability, and data\naugmentation. However, most work mixes all these roles, obscuring the problem\ndefinitions and research goals of the security role that aims to reveal the\npractical concerns of NLP models. In this paper, we rethink the research\nparadigm of textual adversarial samples in security scenarios. We discuss the\ndeficiencies in previous work and propose our suggestions that the research on\nthe Security-oriented adversarial NLP (SoadNLP) should: (1) evaluate their\nmethods on security tasks to demonstrate the real-world concerns; (2) consider\nreal-world attackers' goals, instead of developing impractical methods. To this\nend, we first collect, process, and release a security datasets collection\nAdvbench. Then, we reformalize the task and adjust the emphasis on different\ngoals in SoadNLP. Next, we propose a simple method based on heuristic rules\nthat can easily fulfill the actual adversarial goals to simulate real-world\nattack methods. We conduct experiments on both the attack and the defense sides\non Advbench. Experimental results show that our method has higher practical\nvalue, indicating that the research paradigm in SoadNLP may start from our new\nbenchmark. All the code and data of Advbench can be obtained at\n\\url{https://github.com/thunlp/Advbench}.",
    "descriptor": "\nComments: Accepted to EMNLP 2022, main conference\n",
    "authors": [
      "Yangyi Chen",
      "Hongcheng Gao",
      "Ganqu Cui",
      "Fanchao Qi",
      "Longtao Huang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10683"
  },
  {
    "id": "arXiv:2210.10684",
    "title": "Language Models Understand Us, Poorly",
    "abstract": "Some claim language models understand us. Others won't hear it. To clarify, I\ninvestigate three views of human language understanding: as-mapping,\nas-reliability and as-representation. I argue that while behavioral reliability\nis necessary for understanding, internal representations are sufficient; they\nclimb the right hill. I review state-of-the-art language and multi-modal\nmodels: they are pragmatically challenged by under-specification of form. I\nquestion the Scaling Paradigm: limits on resources may prohibit scaled-up\nmodels from approaching understanding. Last, I describe how as-representation\nadvances a science of understanding. We need work which probes model internals,\nadds more of human language, and measures what models can learn.",
    "descriptor": "\nComments: 5 pages, 1 figure, to be published in Findings of EMNLP 2022\n",
    "authors": [
      "Jared Moore"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10684"
  },
  {
    "id": "arXiv:2210.10687",
    "title": "Unboxing Trustworthiness through Quantum Internet",
    "abstract": "The broad adoption of the Internet of Things during the last decade has\nwidened the application horizons of distributed sensor networks, ranging from\nsmart home appliances to automation, including remote sensing. Typically, these\ndistributed systems are composed of several nodes attached to sensing devices\nlinked by a heterogeneous communication network. The unreliable nature of these\nsystems (e.g., devices might run out of energy or communications might become\nunavailable) drives practitioners to implement heavyweight fault tolerance\nmechanisms to identify those untrustworthy nodes that are misbehaving\nerratically and, thus, ensure that the sensed data from the IoT domain are\ncorrect. The overhead in the communication network degrades the overall system,\nespecially in scenarios with limited available bandwidth that are exposed to\nseverely harsh conditions. Quantum Internet might be a promising alternative to\nminimize traffic congestion and avoid worsening reliability due to the link\nsaturation effect by using a quantum consensus layer. In this regard, the\npurpose of this paper is to explore and simulate the usage of quantum consensus\narchitecture in one of the most challenging natural environments in the world\nwhere researchers need a responsive sensor network: the remote sensing of\npermafrost in Antarctica. More specifically, this paper 1) describes the use\ncase of permafrost remote sensing in Antarctica, 2) proposes the usage of a\nquantum consensus management plane to reduce the traffic overhead associated\nwith fault tolerance protocols, and 3) discusses, by means of simulation,\npossible improvements to increase the trustworthiness of a holistic telemetry\nsystem by exploiting the complexity reduction offered by the quantum\nparallelism. Collected insights from this research can be generalized to\ncurrent and forthcoming IoT environments.",
    "descriptor": "\nComments: 32 pages, 14 figures, 5 tables. arXiv admin note: text overlap with arXiv:1908.10758 by other authors\n",
    "authors": [
      "Agustin Zaballos",
      "Adria Mallorqui",
      "Joan Navarro"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10687"
  },
  {
    "id": "arXiv:2210.10689",
    "title": "Towards Procedural Fairness: Uncovering Biases in How a Toxic Language  Classifier Uses Sentiment Information",
    "abstract": "Previous works on the fairness of toxic language classifiers compare the\noutput of models with different identity terms as input features but do not\nconsider the impact of other important concepts present in the context. Here,\nbesides identity terms, we take into account high-level latent features learned\nby the classifier and investigate the interaction between these features and\nidentity terms. For a multi-class toxic language classifier, we leverage a\nconcept-based explanation framework to calculate the sensitivity of the model\nto the concept of sentiment, which has been used before as a salient feature\nfor toxic language detection. Our results show that although for some classes,\nthe classifier has learned the sentiment information as expected, this\ninformation is outweighed by the influence of identity terms as input features.\nThis work is a step towards evaluating procedural fairness, where unfair\nprocesses lead to unfair outcomes. The produced knowledge can guide debiasing\ntechniques to ensure that important concepts besides identity terms are\nwell-represented in training datasets.",
    "descriptor": "\nComments: 13 pages, 2 figures, accepted at the fifth edition of BlackBoxNLP collocated with EMNLP2022\n",
    "authors": [
      "Isar Nejadgholi",
      "Esma Balk\u0131r",
      "Kathleen C. Fraser",
      "Svetlana Kiritchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10689"
  },
  {
    "id": "arXiv:2210.10691",
    "title": "Provably Safe Reinforcement Learning via Action Projection using  Reachability Analysis and Polynomial Zonotopes",
    "abstract": "While reinforcement learning produces very promising results for many\napplications, its main disadvantage is the lack of safety guarantees, which\nprevents its use in safety-critical systems. In this work, we address this\nissue by a safety shield for nonlinear continuous systems that solve\nreach-avoid tasks. Our safety shield prevents applying potentially unsafe\nactions from a reinforcement learning agent by projecting the proposed action\nto the closest safe action. This approach is called action projection and is\nimplemented via mixed-integer optimization. The safety constraints for action\nprojection are obtained by applying parameterized reachability analysis using\npolynomial zonotopes, which enables to accurately capture the nonlinear effects\nof the actions on the system. In contrast to other state of the art approaches\nfor action projection, our safety shield can efficiently handle input\nconstraints and dynamic obstacles, eases incorporation of the spatial robot\ndimensions into the safety constraints, guarantees robust safety despite\nprocess noise and measurement errors, and is well suited for high-dimensional\nsystems, as we demonstrate on several challenging benchmark systems.",
    "descriptor": "",
    "authors": [
      "Niklas Kochdumper",
      "Hanna Krasowski",
      "Xiao Wang",
      "Stanley Bak",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10691"
  },
  {
    "id": "arXiv:2210.10692",
    "title": "Separating Grains from the Chaff: Using Data Filtering to Improve  Multilingual Translation for Low-Resourced African Languages",
    "abstract": "We participated in the WMT 2022 Large-Scale Machine Translation Evaluation\nfor the African Languages Shared Task. This work describes our approach, which\nis based on filtering the given noisy data using a sentence-pair classifier\nthat was built by fine-tuning a pre-trained language model. To train the\nclassifier, we obtain positive samples (i.e. high-quality parallel sentences)\nfrom a gold-standard curated dataset and extract negative samples (i.e.\nlow-quality parallel sentences) from automatically aligned parallel data by\nchoosing sentences with low alignment scores. Our final machine translation\nmodel was then trained on filtered data, instead of the entire noisy dataset.\nWe empirically validate our approach by evaluating on two common datasets and\nshow that data filtering generally improves overall translation quality, in\nsome cases even significantly.",
    "descriptor": "\nComments: Accepted at the Seventh Conference on Machine Translation (WMT22)\n",
    "authors": [
      "Idris Abdulmumin",
      "Michael Beukman",
      "Jesujoba O. Alabi",
      "Chris Emezue",
      "Everlyn Asiko",
      "Tosin Adewumi",
      "Shamsuddeen Hassan Muhammad",
      "Mofetoluwa Adeyemi",
      "Oreen Yousuf",
      "Sahib Singh",
      "Tajuddeen Rabiu Gwadabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10692"
  },
  {
    "id": "arXiv:2210.10693",
    "title": "Robustness of Demonstration-based Learning Under Limited Data Scenario",
    "abstract": "Demonstration-based learning has shown great potential in stimulating\npretrained language models' ability under limited data scenario. Simply\naugmenting the input with some demonstrations can significantly improve\nperformance on few-shot NER. However, why such demonstrations are beneficial\nfor the learning process remains unclear since there is no explicit alignment\nbetween the demonstrations and the predictions. In this paper, we design\npathological demonstrations by gradually removing intuitively useful\ninformation from the standard ones to take a deep dive of the robustness of\ndemonstration-based sequence labeling and show that (1) demonstrations composed\nof random tokens still make the model a better few-shot learner; (2) the length\nof random demonstrations and the relevance of random tokens are the main\nfactors affecting the performance; (3) demonstrations increase the confidence\nof model predictions on captured superficial patterns. We have publicly\nreleased our code at https://github.com/SALT-NLP/RobustDemo.",
    "descriptor": "\nComments: 14 pages, EMNLP 2022 Main Conference\n",
    "authors": [
      "Hongxin Zhang",
      "Yanzhe Zhang",
      "Ruiyi Zhang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10693"
  },
  {
    "id": "arXiv:2210.10694",
    "title": "Verification of the Socio-Technical Aspects of Voting: The Case of the  Polish Postal Vote 2020",
    "abstract": "Voting procedures are designed and implemented by people, for people, and\nwith significant human involvement. Thus, one should take into account the\nhuman factors in order to comprehensively analyze properties of an election and\ndetect threats. In particular, it is essential to assess how actions and\nstrategies of the involved agents (voters, municipal office employees, mail\nclerks) can influence the outcome of other agents' actions as well as the\noverall outcome of the election. In this paper, we present our first attempt to\ncapture those aspects in a formal multi-agent model of the Polish presidential\nelection 2020. The election marked the first time when postal vote was\nuniversally available in Poland. Unfortunately, the voting scheme was prepared\nunder time pressure and political pressure, and without the involvement of\nexperts. This might have opened up possibilities for various kinds of ballot\nfraud, in-house coercion, etc. We propose a preliminary scalable model of the\nprocedure in the form of a Multi-Agent Graph, and formalize selected integrity\nand security properties by formulas of agent logics. Then, we transform the\nmodels and formulas so that they can be input to the state-of-art model checker\nUppaal. The first series of experiments demonstrates that verification scales\nrather badly due to the state-space explosion. However, we show that a recently\ndeveloped technique of user-friendly model reduction by variable abstraction\nallows us to verify more complex scenarios.",
    "descriptor": "",
    "authors": [
      "Wojciech Jamroga",
      "Peter Y.A. Ryan",
      "Yan Kim"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.10694"
  },
  {
    "id": "arXiv:2210.10695",
    "title": "Incorporating Relevance Feedback for Information-Seeking Retrieval using  Few-Shot Document Re-Ranking",
    "abstract": "Pairing a lexical retriever with a neural re-ranking model has set\nstate-of-the-art performance on large-scale information retrieval datasets.\nThis pipeline covers scenarios like question answering or navigational queries,\nhowever, for information-seeking scenarios, users often provide information on\nwhether a document is relevant to their query in form of clicks or explicit\nfeedback. Therefore, in this work, we explore how relevance feedback can be\ndirectly integrated into neural re-ranking models by adopting few-shot and\nparameter-efficient learning techniques. Specifically, we introduce a kNN\napproach that re-ranks documents based on their similarity with the query and\nthe documents the user considers relevant. Further, we explore Cross-Encoder\nmodels that we pre-train using meta-learning and subsequently fine-tune for\neach query, training only on the feedback documents. To evaluate our different\nintegration strategies, we transform four existing information retrieval\ndatasets into the relevance feedback scenario. Extensive experiments\ndemonstrate that integrating relevance feedback directly in neural re-ranking\nmodels improves their performance, and fusing lexical ranking with our best\nperforming neural re-ranker outperforms all other methods by 5.2 nDCG@20.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Tim Baumg\u00e4rtner",
      "Leonardo F. R. Ribeiro",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10695"
  },
  {
    "id": "arXiv:2210.10698",
    "title": "RoleSeer: Understanding Informal Social Role Changes in MMORPGs via  Visual Analytics",
    "abstract": "Massively multiplayer online role-playing games create virtual communities\nthat support heterogeneous \"social roles\" determined by gameplay interaction\nbehaviors under a specific social context. For all social roles, formal roles\nare pre-defined, obvious, and explicitly ascribed to the people holding the\nroles, whereas informal roles are not well-defined and unspoken. Identifying\nthe informal roles and understanding their subtle changes are critical to\ndesigning sociability mechanisms. However, it is nontrivial to understand the\nexistence and evolution of such roles due to their loosely defined,\ninterconvertible, and dynamic characteristics. We propose a visual analytics\nsystem, RoleSeer, to investigate informal roles from the perspectives of\nbehavioral interactions and depict their dynamic interconversions and\ntransitions. Two cases, experts' feedback, and a user study suggest that\nRoleSeer helps interpret the identified informal roles and explore the patterns\nbehind role changes. We see our approach's potential in investigating informal\nroles in a broader range of social games.",
    "descriptor": "\nComments: CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA\n",
    "authors": [
      "Laixin Xie",
      "Ziming Wu",
      "Peng Xu",
      "Wei Li",
      "Xiaojuan Ma",
      "Quan Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.10698"
  },
  {
    "id": "arXiv:2210.10703",
    "title": "AUC-based Selective Classification",
    "abstract": "Selective classification (or classification with a reject option) pairs a\nclassifier with a selection function to determine whether or not a prediction\nshould be accepted. This framework trades off coverage (probability of\naccepting a prediction) with predictive performance, typically measured by\ndistributive loss functions. In many application scenarios, such as credit\nscoring, performance is instead measured by ranking metrics, such as the Area\nUnder the ROC Curve (AUC). We propose a model-agnostic approach to associate a\nselection function to a given probabilistic binary classifier. The approach is\nspecifically targeted at optimizing the AUC. We provide both theoretical\njustifications and a novel algorithm, called $AUCross$, to achieve such a goal.\nExperiments show that $AUCross$ succeeds in trading-off coverage for AUC,\nimproving over existing selective classification methods targeted at optimizing\naccuracy.",
    "descriptor": "",
    "authors": [
      "Andrea Pugnana",
      "Salvatore Ruggieri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10703"
  },
  {
    "id": "arXiv:2210.10709",
    "title": "Schema-aware Reference as Prompt Improves Data-Efficient Relational  Triple and Event Extraction",
    "abstract": "Information Extraction, which aims to extract structural relational triple or\nevent from unstructured texts, often suffers from data scarcity issues. With\nthe development of pre-trained language models, many prompt-based approaches to\ndata-efficient information extraction have been proposed and achieved\nimpressive performance. However, existing prompt learning methods for\ninformation extraction are still susceptible to several potential limitations:\n(i) semantic gap between natural language and output structure knowledge with\npre-defined schema; (ii) representation learning with locally individual\ninstances limits the performance given the insufficient features. In this\npaper, we propose a novel approach of schema-aware Reference As Prompt (RAP),\nwhich dynamically leverage schema and knowledge inherited from global\n(few-shot) training data for each sample. Specifically, we propose a\nschema-aware reference store, which unifies symbolic schema and relevant\ntextual instances. Then, we employ a dynamic reference integration module to\nretrieve pertinent knowledge from the datastore as prompts during training and\ninference. Experimental results demonstrate that RAP can be plugged into\nvarious existing models and outperforms baselines in low-resource settings on\nfive datasets of relational triple extraction and event extraction. In\naddition, we provide comprehensive empirical ablations and case analysis\nregarding different types and scales of knowledge in order to better understand\nthe mechanisms of RAP. Code is available in https://github.com/zjunlp/RAP.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Yunzhi Yao",
      "Shengyu Mao",
      "Xiang Chen",
      "Ningyu Zhang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10709"
  },
  {
    "id": "arXiv:2210.10715",
    "title": "Autoregressive Generative Modeling with Noise Conditional Maximum  Likelihood Estimation",
    "abstract": "We introduce a simple modification to the standard maximum likelihood\nestimation (MLE) framework. Rather than maximizing a single unconditional\nlikelihood of the data under the model, we maximize a family of \\textit{noise\nconditional} likelihoods consisting of the data perturbed by a continuum of\nnoise levels. We find that models trained this way are more robust to noise,\nobtain higher test likelihoods, and generate higher quality images. They can\nalso be sampled from via a novel score-based sampling scheme which combats the\nclassical \\textit{covariate shift} problem that occurs during sample generation\nin autoregressive models. Applying this augmentation to autoregressive image\nmodels, we obtain 3.32 bits per dimension on the ImageNet 64x64 dataset, and\nsubstantially improve the quality of generated samples in terms of the Frechet\nInception distance (FID) -- from 37.50 to 12.09 on the CIFAR-10 dataset.",
    "descriptor": "\nComments: 18 pages, 10 figures, 2 tables\n",
    "authors": [
      "Henry Li",
      "Yuval Kluger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10715"
  },
  {
    "id": "arXiv:2210.10716",
    "title": "CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View  Completion",
    "abstract": "Masked Image Modeling (MIM) has recently been established as a potent\npre-training paradigm. A pretext task is constructed by masking patches in an\ninput image, and this masked content is then predicted by a neural network\nusing visible patches as sole input. This pre-training leads to\nstate-of-the-art performance when finetuned for high-level semantic tasks, e.g.\nimage classification and object detection. In this paper we instead seek to\nlearn representations that transfer well to a wide variety of 3D vision and\nlower-level geometric downstream tasks, such as depth prediction or optical\nflow estimation. Inspired by MIM, we propose an unsupervised representation\nlearning task trained from pairs of images showing the same scene from\ndifferent viewpoints. More precisely, we propose the pretext task of cross-view\ncompletion where the first input image is partially masked, and this masked\ncontent has to be reconstructed from the visible content and the second image.\nIn single-view MIM, the masked content often cannot be inferred precisely from\nthe visible portion only, so the model learns to act as a prior influenced by\nhigh-level semantics. In contrast, this ambiguity can be resolved with\ncross-view completion from the second unmasked image, on the condition that the\nmodel is able to understand the spatial relationship between the two images.\nOur experiments show that our pretext task leads to significantly improved\nperformance for monocular 3D vision downstream tasks such as depth estimation.\nIn addition, our model can be directly applied to binocular downstream tasks\nlike optical flow or relative camera pose estimation, for which we obtain\ncompetitive results without bells and whistles, i.e., using a generic\narchitecture without any task-specific design.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Philippe Weinzaepfel",
      "Vincent Leroy",
      "Thomas Lucas",
      "Romain Br\u00e9gier",
      "Yohann Cabon",
      "Vaibhav Arora",
      "Leonid Antsfeld",
      "Boris Chidlovskii",
      "Gabriela Csurka",
      "J\u00e9r\u00f4me Revaud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10716"
  },
  {
    "id": "arXiv:2210.10718",
    "title": "Whole Page Unbiased Learning to Rank",
    "abstract": "The page presentation biases in the information retrieval system, especially\non the click behavior, is a well-known challenge that hinders improving ranking\nmodels' performance with implicit user feedback. Unbiased Learning to\nRank~(ULTR) algorithms are then proposed to learn an unbiased ranking model\nwith biased click data. However, most existing algorithms are specifically\ndesigned to mitigate position-related bias, e.g., trust bias, without\nconsidering biases induced by other features in search result page\npresentation(SERP). For example, the multimedia type may generate attractive\nbias. Unfortunately, those biases widely exist in industrial systems and may\nlead to an unsatisfactory search experience. Therefore, we introduce a new\nproblem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle\nbiases induced by whole-page SERP features simultaneously. It presents\ntremendous challenges. For example, a suitable user behavior model (user\nbehavior hypothesis) can be hard to find; and complex biases cannot be handled\nby existing algorithms. To address the above challenges, we propose a Bias\nAgnostic whole-page unbiased Learning to rank algorithm, BAL, to automatically\ndiscover and mitigate the biases from multiple SERP features with no specific\ndesign. Experimental results on a real-world dataset verify the effectiveness\nof the BAL.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Haitao Mao",
      "Lixin Zou",
      "Yujia Zheng",
      "Jiliang Tang",
      "Xiaokai Chu",
      "Jiashu Zhao",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10718"
  },
  {
    "id": "arXiv:2210.10719",
    "title": "Dodona: learn to code with a virtual co-teacher that supports active  learning",
    "abstract": "Dodona (dodona.ugent.be) is an intelligent tutoring system for computer\nprogramming. It bridges the gap between assessment and learning by providing\nreal-time data and feedback to help students learn better, teachers teach\nbetter and educational technology become more effective. We demonstrate how\nDodona can be used as a virtual co-teacher to stimulate active learning and\nsupport challenge-based education in open and collaborative learning\nenvironments. We also highlight some of the opportunities (automated feedback,\nlearning analytics, educational data mining) and challenges (scalable feedback,\nopen internet exams, plagiarism) we faced in practice. Dodona is free for use\nand has more than 36 thousand registered users across many educational and\nresearch institutes, of which 15 thousand new users registered last year.\nLowering the barriers for such a broad adoption was achieved by following best\npractices and extensible approaches for software development, authentication,\ncontent management, assessment, security and interoperability, and by adopting\na holistic view on computer-assisted learning and teaching that spans all\naspects of managing courses that involve programming assignments. The source\ncode of Dodona is available on GitHub under the permissive MIT open-source\nlicense.",
    "descriptor": "",
    "authors": [
      "Charlotte Van Petegem",
      "Rien Maertens",
      "Niko Strijbol",
      "Jorg Van Renterghem",
      "Felix Van der Jeugt",
      "Bram De Wever",
      "Peter Dawyndt",
      "Bart Mesuere"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10719"
  },
  {
    "id": "arXiv:2210.10722",
    "title": "UniNL: Aligning Representation Learning with Scoring Function for OOD  Detection via Unified Neighborhood Learning",
    "abstract": "Detecting out-of-domain (OOD) intents from user queries is essential for\navoiding wrong operations in task-oriented dialogue systems. The key challenge\nis how to distinguish in-domain (IND) and OOD intents. Previous methods ignore\nthe alignment between representation learning and scoring function, limiting\nthe OOD detection performance. In this paper, we propose a unified neighborhood\nlearning framework (UniNL) to detect OOD intents. Specifically, we design a\nK-nearest neighbor contrastive learning (KNCL) objective for representation\nlearning and introduce a KNN-based scoring function for OOD detection. We aim\nto align representation learning with scoring function. Experiments and\nanalysis on two benchmark datasets show the effectiveness of our method.",
    "descriptor": "\nComments: Accepted at EMNLP2022 main conference\n",
    "authors": [
      "Yutao Mou",
      "Pei Wang",
      "Keqing He",
      "Yanan Wu",
      "Jingang Wang",
      "Wei Wu",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10722"
  },
  {
    "id": "arXiv:2210.10723",
    "title": "TabLLM: Few-shot Classification of Tabular Data with Large Language  Models",
    "abstract": "We study the application of large language models to zero-shot and few-shot\nclassification of tabular data. We prompt the large language model with a\nserialization of the tabular data to a natural-language string, together with a\nshort description of the classification problem. In the few-shot setting, we\nfine-tune the large language model using some labeled examples. We evaluate\nseveral serialization methods including templates, table-to-text models, and\nlarge language models. Despite its simplicity, we find that this technique\noutperforms prior deep-learning-based tabular classification methods on several\nbenchmark datasets. In most cases, even zero-shot classification obtains\nnon-trivial performance, illustrating the method's ability to exploit prior\nknowledge encoded in large language models. Unlike many deep learning methods\nfor tabular datasets, this approach is also competitive with strong traditional\nbaselines like gradient-boosted trees, especially in the very-few-shot setting.",
    "descriptor": "",
    "authors": [
      "Stefan Hegselmann",
      "Alejandro Buendia",
      "Hunter Lang",
      "Monica Agrawal",
      "Xiaoyi Jiang",
      "David Sontag"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10723"
  },
  {
    "id": "arXiv:2210.10725",
    "title": "SML:Enhance the Network Smoothness with Skip Meta Logit for CTR  Prediction",
    "abstract": "In light of the smoothness property brought by skip connections in ResNet,\nthis paper proposed the Skip Logit to introduce the skip connection mechanism\nthat fits arbitrary DNN dimensions and embraces similar properties to ResNet.\nMeta Tanh Normalization (MTN) is designed to learn variance information and\nstabilize the training process. With these delicate designs, our Skip Meta\nLogit (SML) brought incremental boosts to the performance of extensive SOTA ctr\nprediction models on two real-world datasets. In the meantime, we prove that\nthe optimization landscape of arbitrarily deep skip logit networks has no\nspurious local optima. Finally, SML can be easily added to building blocks and\nhas delivered offline accuracy and online business metrics gains on app ads\nlearning to rank systems at TikTok.",
    "descriptor": "",
    "authors": [
      "Wenlong Deng",
      "Lang Lang",
      "Zhen Liu",
      "Bin Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10725"
  },
  {
    "id": "arXiv:2210.10726",
    "title": "DL based analysis of movie reviews",
    "abstract": "Undoubtedly, social media are brainstormed by a tremendous volume of stories,\nfeedback, reviews, and reactions expressed in various languages and idioms,\neven though some are factually incorrect. These motifs make assessing such data\nchallenging, time-consuming, and vulnerable to misinterpretation. This paper\ndescribes a classification model for movie reviews founded on deep learning\napproaches. Almost 500KB pairs of balanced data from the IMDb movie review\ndatabases are employed to train the model. People's perspectives regarding\nmovies were classified using both the long short-term memory (LSTM) and\nconvolutional neural network (CNN) strategies. According to the findings, the\nCNN algorithm's prediction accuracy rate would be almost 97.4%. Furthermore,\nthe model trained by LSTM resulted in accuracies of around and applying 99.2%\nwithin the Keras library. The model is investigated more by modification of\nmodel parameters. According to the outcomes, LTSM outperforms CNN in assessing\nIMDb movie reviews and is computationally less costly than LSTM.",
    "descriptor": "",
    "authors": [
      "Mary Pa",
      "Amin Kazemi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10726"
  },
  {
    "id": "arXiv:2210.10732",
    "title": "OpenEarthMap: A Benchmark Dataset for Global High-Resolution Land Cover  Mapping",
    "abstract": "We introduce OpenEarthMap, a benchmark dataset, for global high-resolution\nland cover mapping. OpenEarthMap consists of 2.2 million segments of 5000\naerial and satellite images covering 97 regions from 44 countries across 6\ncontinents, with manually annotated 8-class land cover labels at a 0.25--0.5m\nground sampling distance. Semantic segmentation models trained on the\nOpenEarthMap generalize worldwide and can be used as off-the-shelf models in a\nvariety of applications. We evaluate the performance of state-of-the-art\nmethods for unsupervised domain adaptation and present challenging problem\nsettings suitable for further technical development. We also investigate\nlightweight models using automated neural architecture search for limited\ncomputational resources and fast mapping. The dataset is available at\nhttps://open-earth-map.org.",
    "descriptor": "\nComments: Accepted by WACV 2023\n",
    "authors": [
      "Junshi Xia",
      "Naoto Yokoya",
      "Bruno Adriano",
      "Clifford Broni-Bediako"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10732"
  },
  {
    "id": "arXiv:2210.10737",
    "title": "RSC: Accelerating Graph Neural Networks Training via Randomized Sparse  Computations",
    "abstract": "The training of graph neural networks (GNNs) is extremely time consuming\nbecause sparse graph-based operations are hard to be accelerated by hardware.\nPrior art explores trading off the computational precision to reduce the time\ncomplexity via sampling-based approximation. Based on the idea, previous works\nsuccessfully accelerate the dense matrix based operations (e.g., convolution\nand linear) with negligible accuracy drop. However, unlike dense matrices,\nsparse matrices are stored in the irregular data format such that each\nrow/column may have different number of non-zero entries. Thus, compared to the\ndense counterpart, approximating sparse operations has two unique challenges\n(1) we cannot directly control the efficiency of approximated sparse operation\nsince the computation is only executed on non-zero entries; (2) sub-sampling\nsparse matrices is much more inefficient due to the irregular data format. To\naddress the issues, our key idea is to control the accuracy-efficiency trade\noff by optimizing computation resource allocation layer-wisely and\nepoch-wisely. Specifically, for the first challenge, we customize the\ncomputation resource to different sparse operations, while limit the total used\nresource below a certain budget. For the second challenge, we cache previous\nsampled sparse matrices to reduce the epoch-wise sampling overhead. Finally, we\npropose a switching mechanisms to improve the generalization of GNNs trained\nwith approximated operations. To this end, we propose Randomized Sparse\nComputation, which for the first time demonstrate the potential of training\nGNNs with approximated operations. In practice, rsc can achieve up to\n$11.6\\times$ speedup for a single sparse operation and a $1.6\\times$ end-to-end\nwall-clock time speedup with negligible accuracy drop.",
    "descriptor": "",
    "authors": [
      "Zirui Liu",
      "Shengyuan Chen",
      "Kaixiong Zhou",
      "Daochen Zha",
      "Xiao Huang",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10737"
  },
  {
    "id": "arXiv:2210.10742",
    "title": "End-to-End Integration of Speech Recognition, Dereverberation,  Beamforming, and Self-Supervised Learning Representation",
    "abstract": "Self-supervised learning representation (SSLR) has demonstrated its\nsignificant effectiveness in automatic speech recognition (ASR), mainly with\nclean speech. Recent work pointed out the strength of integrating SSLR with\nsingle-channel speech enhancement for ASR in noisy environments. This paper\nfurther advances this integration by dealing with multi-channel input. We\npropose a novel end-to-end architecture by integrating dereverberation,\nbeamforming, SSLR, and ASR within a single neural network. Our system achieves\nthe best performance reported in the literature on the CHiME-4 6-channel track\nwith a word error rate (WER) of 1.77%. While the WavLM-based strong SSLR\ndemonstrates promising results by itself, the end-to-end integration with the\nweighted power minimization distortionless response beamformer, which\nsimultaneously performs dereverberation and denoising, improves WER\nsignificantly. Its effectiveness is also validated on the REVERB dataset.",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Yoshiki Masuyama",
      "Xuankai Chang",
      "Samuele Cornell",
      "Shinji Watanabe",
      "Nobutaka Ono"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10742"
  },
  {
    "id": "arXiv:2210.10747",
    "title": "Lumped-Parameter Modeling and Control for Robotic High-Viscosity Fluid  Dispensing in Additive Manufacturing",
    "abstract": "In this paper, we present a novel flow model and compensation strategy for\nhigh-viscosity fluid deposition that yields high quality parts in the face of\nlarge transient delays and nonlinearity. Robotic high-viscosity fluid\ndeposition is an essential process for a broad range of manufacturing\napplications including additive manufacturing, adhesive and sealant dispensing,\nand soft robotics. However, high-viscosity fluid deposition without\ncompensation can lead to poor part quality and defects due to large transient\ndelays and complex fluid dynamics. Our computationally efficient model is\nwell-suited to real-time control and can be quickly calibrated and our\ncompensation strategy leverages an iterative Linear-Quadratic Regulator to\ncompute compensated deposition paths that can be deployed on most dispensing\nsystems, without additional hardware. We demonstrate the improvements provided\nby our method when 3D printing using a robotic manipulator.",
    "descriptor": "\nComments: 6 pages, 10 figures, conference\n",
    "authors": [
      "William van den Bogert",
      "James Lorenz",
      "Xili Yi",
      "Nima Fazeli",
      "Albert J. Shih"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10747"
  },
  {
    "id": "arXiv:2210.10749",
    "title": "Transformers Learn Shortcuts to Automata",
    "abstract": "Algorithmic reasoning requires capabilities which are most naturally\nunderstood through recurrent models of computation, like the Turing machine.\nHowever, Transformer models, while lacking recurrence, are able to perform such\nreasoning using far fewer layers than the number of reasoning steps. This\nraises the question: what solutions are these shallow and non-recurrent models\nfinding? We investigate this question in the setting of learning automata,\ndiscrete dynamical systems naturally suited to recurrent modeling and\nexpressing algorithmic tasks. Our theoretical results completely characterize\nshortcut solutions, whereby a shallow Transformer with only $o(T)$ layers can\nexactly replicate the computation of an automaton on an input sequence of\nlength $T$. By representing automata using the algebraic structure of their\nunderlying transformation semigroups, we obtain $O(\\log T)$-depth simulators\nfor all automata and $O(1)$-depth simulators for all automata whose associated\ngroups are solvable. Empirically, we perform synthetic experiments by training\nTransformers to simulate a wide variety of automata, and show that shortcut\nsolutions can be learned via standard training. We further investigate the\nbrittleness of these solutions and propose potential mitigations.",
    "descriptor": "",
    "authors": [
      "Bingbin Liu",
      "Jordan T. Ash",
      "Surbhi Goel",
      "Akshay Krishnamurthy",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10749"
  },
  {
    "id": "arXiv:2210.10750",
    "title": "Canary in a Coalmine: Better Membership Inference with Ensembled  Adversarial Queries",
    "abstract": "As industrial applications are increasingly automated by machine learning\nmodels, enforcing personal data ownership and intellectual property rights\nrequires tracing training data back to their rightful owners. Membership\ninference algorithms approach this problem by using statistical techniques to\ndiscern whether a target sample was included in a model's training set.\nHowever, existing methods only utilize the unaltered target sample or simple\naugmentations of the target to compute statistics. Such a sparse sampling of\nthe model's behavior carries little information, leading to poor inference\ncapabilities. In this work, we use adversarial tools to directly optimize for\nqueries that are discriminative and diverse. Our improvements achieve\nsignificantly more accurate membership inference than existing methods,\nespecially in offline scenarios and in the low false-positive regime which is\ncritical in legal settings. Code is available at\nhttps://github.com/YuxinWenRick/canary-in-a-coalmine.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Yuxin Wen",
      "Arpit Bansal",
      "Hamid Kazemi",
      "Eitan Borgnia",
      "Micah Goldblum",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10750"
  },
  {
    "id": "arXiv:2210.10756",
    "title": "Two-level Data Augmentation for Calibrated Multi-view Detection",
    "abstract": "Data augmentation has proven its usefulness to improve model generalization\nand performance. While it is commonly applied in computer vision application\nwhen it comes to multi-view systems, it is rarely used. Indeed geometric data\naugmentation can break the alignment among views. This is problematic since\nmulti-view data tend to be scarce and it is expensive to annotate. In this work\nwe propose to solve this issue by introducing a new multi-view data\naugmentation pipeline that preserves alignment among views. Additionally to\ntraditional augmentation of the input image we also propose a second level of\naugmentation applied directly at the scene level. When combined with our simple\nmulti-view detection model, our two-level augmentation pipeline outperforms all\nexisting baselines by a significant margin on the two main multi-view\nmulti-person detection datasets WILDTRACK and MultiviewX.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Martin Engilberge",
      "Haixin Shi",
      "Zhiye Wang",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10756"
  },
  {
    "id": "arXiv:2210.10758",
    "title": "GraphCSPN: Geometry-Aware Depth Completion via Dynamic GCNs",
    "abstract": "Image guided depth completion aims to recover per-pixel dense depth maps from\nsparse depth measurements with the help of aligned color images, which has a\nwide range of applications from robotics to autonomous driving. However, the 3D\nnature of sparse-to-dense depth completion has not been fully explored by\nprevious methods. In this work, we propose a Graph Convolution based Spatial\nPropagation Network (GraphCSPN) as a general approach for depth completion.\nFirst, unlike previous methods, we leverage convolution neural networks as well\nas graph neural networks in a complementary way for geometric representation\nlearning. In addition, the proposed networks explicitly incorporate learnable\ngeometric constraints to regularize the propagation process performed in\nthree-dimensional space rather than in two-dimensional plane. Furthermore, we\nconstruct the graph utilizing sequences of feature patches, and update it\ndynamically with an edge attention module during propagation, so as to better\ncapture both the local neighboring features and global relationships over long\ndistance. Extensive experiments on both indoor NYU-Depth-v2 and outdoor KITTI\ndatasets demonstrate that our method achieves the state-of-the-art performance,\nespecially when compared in the case of using only a few propagation steps.\nCode and models are available at the project page.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Xin Liu",
      "Xiaofei Shao",
      "Bo Wang",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10758"
  },
  {
    "id": "arXiv:2210.10759",
    "title": "On Representing Mixed-Integer Linear Programs by Graph Neural Networks",
    "abstract": "While Mixed-integer linear programming (MILP) is NP-hard in general,\npractical MILP has received roughly 100--fold speedup in the past twenty years.\nStill, many classes of MILPs quickly become unsolvable as their sizes increase,\nmotivating researchers to seek new acceleration techniques for MILPs. With deep\nlearning, they have obtained strong empirical results, and many results were\nobtained by applying graph neural networks (GNNs) to making decisions in\nvarious stages of MILP solution processes. This work discovers a fundamental\nlimitation: there exist feasible and infeasible MILPs that all GNNs will,\nhowever, treat equally, indicating GNN's lacking power to express general\nMILPs. Then, we show that, by restricting the MILPs to unfoldable ones or by\nadding random features, there exist GNNs that can reliably predict MILP\nfeasibility, optimal objective values, and optimal solutions up to prescribed\nprecision. We conducted small-scale numerical experiments to validate our\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Ziang Chen",
      "Jialin Liu",
      "Xinshang Wang",
      "Jianfeng Lu",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10759"
  },
  {
    "id": "arXiv:2210.10760",
    "title": "Scaling Laws for Reward Model Overoptimization",
    "abstract": "In reinforcement learning from human feedback, it is common to optimize\nagainst a reward model trained to predict human preferences. Because the reward\nmodel is an imperfect proxy, optimizing its value too much can hinder ground\ntruth performance, in accordance with Goodhart's law. This effect has been\nfrequently observed, but not carefully measured due to the expense of\ncollecting human preference data. In this work, we use a synthetic setup in\nwhich a fixed \"gold-standard\" reward model plays the role of humans, providing\nlabels used to train a proxy reward model. We study how the gold reward model\nscore changes as we optimize against the proxy reward model using either\nreinforcement learning or best-of-$n$ sampling. We find that this relationship\nfollows a different functional form depending on the method of optimization,\nand that in both cases its coefficients scale smoothly with the number of\nreward model parameters. We also study the effect on this relationship of the\nsize of the reward model dataset, the number of reward model and policy\nparameters, and the coefficient of the KL penalty added to the reward in the\nreinforcement learning setup. We explore the implications of these empirical\nresults for theoretical considerations in AI alignment.",
    "descriptor": "",
    "authors": [
      "Leo Gao",
      "John Schulman",
      "Jacob Hilton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10760"
  },
  {
    "id": "arXiv:2210.10763",
    "title": "On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement  Learning",
    "abstract": "Reinforcement Learning (RL) algorithms can solve challenging control problems\ndirectly from image observations, but they often require millions of\nenvironment interactions to do so. Recently, model-based RL algorithms have\ngreatly improved sample-efficiency by concurrently learning an internal model\nof the world, and supplementing real environment interactions with imagined\nrollouts for policy improvement. However, learning an effective model of the\nworld from scratch is challenging, and in stark contrast to humans that rely\nheavily on world understanding and visual cues for learning new skills. In this\nwork, we investigate whether internal models learned by modern model-based RL\nalgorithms can be leveraged to solve new, distinctly different tasks faster. We\npropose Model-Based Cross-Task Transfer (XTRA), a framework for\nsample-efficient online RL with scalable pretraining and finetuning of learned\nworld models. By offline multi-task pretraining and online cross-task\nfinetuning, we achieve substantial improvements on the Atari100k benchmark over\na baseline trained from scratch; we improve mean performance of model-based\nalgorithm EfficientZero by 23%, and by as much as 71% in some instances.\nProject page: https://nicklashansen.github.io/xtra.",
    "descriptor": "\nComments: Webpage with code: this https URL\n",
    "authors": [
      "Yifan Xu",
      "Nicklas Hansen",
      "Zirui Wang",
      "Yung-Chieh Chan",
      "Hao Su",
      "Zhuowen Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10763"
  },
  {
    "id": "arXiv:2210.10765",
    "title": "When to Ask for Help: Proactive Interventions in Autonomous  Reinforcement Learning",
    "abstract": "A long-term goal of reinforcement learning is to design agents that can\nautonomously interact and learn in the world. A critical challenge to such\nautonomy is the presence of irreversible states which require external\nassistance to recover from, such as when a robot arm has pushed an object off\nof a table. While standard agents require constant monitoring to decide when to\nintervene, we aim to design proactive agents that can request human\nintervention only when needed. To this end, we propose an algorithm that\nefficiently learns to detect and avoid states that are irreversible, and\nproactively asks for help in case the agent does enter them. On a suite of\ncontinuous control environments with unknown irreversible states, we find that\nour algorithm exhibits better sample- and intervention-efficiency compared to\nexisting methods. Our code is publicly available at\nhttps://sites.google.com/view/proactive-interventions",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Annie Xie",
      "Fahim Tajwar",
      "Archit Sharma",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10765"
  },
  {
    "id": "arXiv:2210.10769",
    "title": "\"Why did the Model Fail?\": Attributing Model Performance Changes to  Distribution Shifts",
    "abstract": "Performance of machine learning models may differ between training and\ndeployment for many reasons. For instance, model performance can change between\nenvironments due to changes in data quality, observing a different population\nthan the one in training, or changes in the relationship between labels and\nfeatures. These manifest as changes to the underlying data generating\nmechanisms, and thereby result in distribution shifts across environments.\nAttributing performance changes to specific shifts, such as covariate or\nconcept shifts, is critical for identifying sources of model failures, and for\ntaking mitigating actions that ensure robust models. In this work, we introduce\nthe problem of attributing performance differences between environments to\nshifts in the underlying data generating mechanisms. We formulate the problem\nas a cooperative game and derive an importance weighting method for computing\nthe value of a coalition (or a set) of distributions. The contribution of each\ndistribution to the total performance change is then quantified as its Shapley\nvalue. We demonstrate the correctness and utility of our method on two\nsynthetic datasets and two real-world case studies, showing its effectiveness\nin attributing performance changes to a wide range of distribution shifts.",
    "descriptor": "",
    "authors": [
      "Haoran Zhang",
      "Harvineet Singh",
      "Marzyeh Ghassemi",
      "Shalmali Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10769"
  },
  {
    "id": "arXiv:2210.10770",
    "title": "LaMAR: Benchmarking Localization and Mapping for Augmented Reality",
    "abstract": "Localization and mapping is the foundational technology for augmented reality\n(AR) that enables sharing and persistence of digital content in the real world.\nWhile significant progress has been made, researchers are still mostly driven\nby unrealistic benchmarks not representative of real-world AR scenarios. These\nbenchmarks are often based on small-scale datasets with low scene diversity,\ncaptured from stationary cameras, and lack other sensor inputs like inertial,\nradio, or depth data. Furthermore, their ground-truth (GT) accuracy is mostly\ninsufficient to satisfy AR requirements. To close this gap, we introduce LaMAR,\na new benchmark with a comprehensive capture and GT pipeline that co-registers\nrealistic trajectories and sensor streams captured by heterogeneous AR devices\nin large, unconstrained scenes. To establish an accurate GT, our pipeline\nrobustly aligns the trajectories against laser scans in a fully automated\nmanner. As a result, we publish a benchmark dataset of diverse and large-scale\nscenes recorded with head-mounted and hand-held AR devices. We extend several\nstate-of-the-art methods to take advantage of the AR-specific setup and\nevaluate them on our benchmark. The results offer new insights on current\nresearch and reveal promising avenues for future work in the field of\nlocalization and mapping for AR.",
    "descriptor": "\nComments: Accepted at ECCV 2022, website at this https URL\n",
    "authors": [
      "Paul-Edouard Sarlin",
      "Mihai Dusmanu",
      "Johannes L. Sch\u00f6nberger",
      "Pablo Speciale",
      "Lukas Gruber",
      "Viktor Larsson",
      "Ondrej Miksik",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10770"
  },
  {
    "id": "arXiv:2210.10771",
    "title": "Multi-view Tracking Using Weakly Supervised Human Motion Prediction",
    "abstract": "Multi-view approaches to people-tracking have the potential to better handle\nocclusions than single-view ones in crowded scenes. They often rely on the\ntracking-by-detection paradigm, which involves detecting people first and then\nconnecting the detections. In this paper, we argue that an even more effective\napproach is to predict people motion over time and infer people's presence in\nindividual frames from these. This enables to enforce consistency both over\ntime and across views of a single temporal frame. We validate our approach on\nthe PETS2009 and WILDTRACK datasets and demonstrate that it outperforms\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Martin Engilberge",
      "Weizhe Liu",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10771"
  },
  {
    "id": "arXiv:2210.10773",
    "title": "Anomaly Detection Requires Better Representations",
    "abstract": "Anomaly detection seeks to identify unusual phenomena, a central task in\nscience and industry. The task is inherently unsupervised as anomalies are\nunexpected and unknown during training. Recent advances in self-supervised\nrepresentation learning have directly driven improvements in anomaly detection.\nIn this position paper, we first explain how self-supervised representations\ncan be easily used to achieve state-of-the-art performance in commonly reported\nanomaly detection benchmarks. We then argue that tackling the next generation\nof anomaly detection tasks requires new technical and conceptual improvements\nin representation learning.",
    "descriptor": "\nComments: Accepted to ECCV SSLWIN Workshop (2022)\n",
    "authors": [
      "Tal Reiss",
      "Niv Cohen",
      "Eliahu Horwitz",
      "Ron Abutbul",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10773"
  },
  {
    "id": "arXiv:2210.10774",
    "title": "Learning to Discover and Detect Objects",
    "abstract": "We tackle the problem of novel class discovery, detection, and localization\n(NCDL). In this setting, we assume a source dataset with labels for objects of\ncommonly observed classes. Instances of other classes need to be discovered,\nclassified, and localized automatically based on visual similarity, without\nhuman supervision. To this end, we propose a two-stage object detection network\nRegion-based NCDL (RNCDL), that uses a region proposal network to localize\nobject candidates and is trained to classify each candidate, either as one of\nthe known classes, seen in the source dataset, or one of the extended set of\nnovel classes, with a long-tail distribution constraint on the class\nassignments, reflecting the natural frequency of classes in the real world. By\ntraining our detection network with this objective in an end-to-end manner, it\nlearns to classify all region proposals for a large variety of classes,\nincluding those that are not part of the labeled object class vocabulary. Our\nexperiments conducted using COCO and LVIS datasets reveal that our method is\nsignificantly more effective compared to multi-stage pipelines that rely on\ntraditional clustering algorithms or use pre-extracted crops. Furthermore, we\ndemonstrate the generality of our approach by applying our method to a\nlarge-scale Visual Genome dataset, where our network successfully learns to\ndetect various semantic classes without explicit supervision.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022, Homepage: this https URL\n",
    "authors": [
      "Vladimir Fomenko",
      "Ismail Elezi",
      "Deva Ramanan",
      "Laura Leal-Taix\u00e9",
      "Aljo\u0161a O\u0161ep"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10774"
  },
  {
    "id": "arXiv:2210.10775",
    "title": "TOIST: Task Oriented Instance Segmentation Transformer with Noun-Pronoun  Distillation",
    "abstract": "Current referring expression comprehension algorithms can effectively detect\nor segment objects indicated by nouns, but how to understand verb reference is\nstill under-explored. As such, we study the challenging problem of task\noriented detection, which aims to find objects that best afford an action\nindicated by verbs like sit comfortably on. Towards a finer localization that\nbetter serves downstream applications like robot interaction, we extend the\nproblem into task oriented instance segmentation. A unique requirement of this\ntask is to select preferred candidates among possible alternatives. Thus we\nresort to the transformer architecture which naturally models pair-wise query\nrelationships with attention, leading to the TOIST method. In order to leverage\npre-trained noun referring expression comprehension models and the fact that we\ncan access privileged noun ground truth during training, a novel noun-pronoun\ndistillation framework is proposed. Noun prototypes are generated in an\nunsupervised manner and contextual pronoun features are trained to select\nprototypes. As such, the network remains noun-agnostic during inference. We\nevaluate TOIST on the large-scale task oriented dataset COCO-Tasks and achieve\n+10.9% higher $\\rm{mAP^{box}}$ than the best-reported results. The proposed\nnoun-pronoun distillation can boost $\\rm{mAP^{box}}$ and $\\rm{mAP^{mask}}$ by\n+2.8% and +3.8%. Codes and models are publicly available at\nhttps://github.com/AIR-DISCOVER/TOIST.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Codes are available at this https URL\n",
    "authors": [
      "Pengfei Li",
      "Beiwen Tian",
      "Yongliang Shi",
      "Xiaoxue Chen",
      "Hao Zhao",
      "Guyue Zhou",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10775"
  },
  {
    "id": "arXiv:2201.11787",
    "title": "A New Perspective on Impartial and Unbiased Apportionment",
    "abstract": "How to fairly apportion congressional seats to states has been debated for\ncenturies. We present an alternative perspective on apportionment, centered not\non states but \"families\" of state, sets of states with \"divisor-method\" quotas\nwith the same integer part. We develop ``impartial\" and ``unbiased\"\napportionment methods. Impartial methods apportion the same number of seats to\nfamilies of states containing the same total population, whether a family\nconsists of many small-population states or a few large-population states.\nUnbiased methods apportion seats so that if states are drawn repeatedly from\nthe same distribution, the expected number of seats apportioned to each family\nequals the expected divisor-method quota for that family.",
    "descriptor": "\nComments: 23 pages, 2 figures, accepted for publication in the American Mathematical Monthly\n",
    "authors": [
      "Ross Hyman",
      "Nicolaus Tideman"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computer Science and Game Theory (cs.GT)",
      "General Mathematics (math.GM)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.11787"
  },
  {
    "id": "arXiv:2210.10050",
    "title": "Explainable bilevel optimization: an application to the Helsinki deblur  challenge",
    "abstract": "In this paper we present a bilevel optimization scheme for the solution of a\ngeneral image deblurring problem, in which a parametric variational-like\napproach is encapsulated within a machine learning scheme to provide a high\nquality reconstructed image with automatically learned parameters. The\ningredients of the variational lower level and the machine learning upper one\nare specifically chosen for the Helsinki Deblur Challenge 2021, in which\nsequences of letters are asked to be recovered from out-of-focus photographs\nwith increasing levels of blur. Our proposed procedure for the reconstructed\nimage consists in a fixed number of FISTA iterations applied to the\nminimization of an edge preserving and binarization enforcing regularized\nleast-squares functional. The parameters defining the variational model and the\noptimization steps, which, unlike most deep learning approaches, all have a\nprecise and interpretable meaning, are learned via either a similarity index or\na support vector machine strategy. Numerical experiments on the test images\nprovided by the challenge authors show significant gains with respect to a\nstandard variational approach and performances comparable with those of some of\nthe proposed deep learning based algorithms which require the optimization of\nmillions of parameters.",
    "descriptor": "",
    "authors": [
      "Silvia Bonettini",
      "Giorgia Franchini",
      "Danilo Pezzi",
      "Marco Prato"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10050"
  },
  {
    "id": "arXiv:2210.10051",
    "title": "Combination of Raman spectroscopy and chemometrics: A review of recent  studies published in the Spectrochimica Acta, Part A: Molecular and  Biomolecular Spectroscopy Journal",
    "abstract": "Raman spectroscopy is a promising technique used for noninvasive analysis of\nsamples in various fields of application due to its ability for fingerprint\nprobing of samples at the molecular level. Chemometrics methods are widely used\nnowadays for better understanding of the recorded spectral fingerprints of\nsamples and differences in their chemical composition. This review considers a\nnumber of manuscripts published in the Spectrochimica Acta, Part A: Molecular\nand Biomolecular Spectroscopy Journal that presented findings regarding the\napplication of Raman spectroscopy in combination with chemometrics to study\nsamples and their changes caused by different factors. In 57 reviewed\nmanuscripts, we analyzed application of chemometrics algorithms, statistical\nmodeling parameters, utilization of cross validation, sample sizes, as well as\nthe performance of the proposed classification and regression model. We\nsummarized the best strategies for creating classification models and\nhighlighted some common drawbacks when it comes to the application of\nchemometrics techniques. According to our estimations, about 70% of the papers\nare likely to contain unsupported or invalid data due to insufficient\ndescription of the utilized methods or drawbacks of the proposed classification\nmodels. These drawbacks include: (1) insufficient experimental sample size for\nclassification/regression to achieve significant and reliable results, (2) lack\nof cross validation (or a test set) for verification of the\nclassifier/regression performance, (3) incorrect division of the spectral data\ninto the training and the test/validation sets; (4) improper selection of the\nPC number to reduce the analyzed spectral data dimension.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Yulia Khristoforova",
      "Lyudmila Bratchenko",
      "Ivan Bratchenko"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10051"
  },
  {
    "id": "arXiv:2210.10120",
    "title": "Initial Orbit Determination from Only Heading Measurements",
    "abstract": "This work introduces the problem of initial orbit determination (IOD) from\nonly heading measurements. Such a problem occurs in practice when estimating\nthe orbit of a spacecraft using visual odometry measurements from an optical\ncamera. After reviewing the problem geometry, a simple solution is developed in\nthe form of an iterative scheme on the parameters describing the orbital\nhodograph. Numerical results are presented for an example spacecraft in low\nlunar orbit. The principal intent of this brief study is to communicate the\nexistence of a new class of IOD problem to the community and to encourage the\nbroader study of hodographs and heading-only IOD.",
    "descriptor": "",
    "authors": [
      "John A. Christian"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10120"
  },
  {
    "id": "arXiv:2210.10143",
    "title": "Lattice-Based Quantum Advantage from Rotated Measurements",
    "abstract": "Trapdoor claw-free functions (TCFs) are immensely valuable in cryptographic\ninteractions between a classical client and a quantum server. Typically, a\nprotocol has the quantum server prepare a superposition of two-bit strings of a\nclaw and then measure it using Pauli-$X$ or $Z$ measurements. In this paper, we\ndemonstrate a new technique that uses the entire range of qubit measurements\nfrom the $XY$-plane. We show the advantage of this approach in two\napplications. First, building on (Brakerski et al. 2018, Kalai et al. 2022), we\nshow an optimized two-round proof of quantumness whose security can be\nexpressed directly in terms of the hardness of the LWE (learning with errors)\nproblem. Second, we construct a one-round protocol for blind remote preparation\nof an arbitrary state on the $XY$-plane up to a Pauli-$Z$ correction.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Yusuf Alnawakhtha",
      "Atul Mantri",
      "Carl A. Miller",
      "Daochen Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.10143"
  },
  {
    "id": "arXiv:2210.10161",
    "title": "Nonparametric Quantile Regression: Non-Crossing Constraints and  Conformal Prediction",
    "abstract": "We propose a nonparametric quantile regression method using deep neural\nnetworks with a rectified linear unit penalty function to avoid quantile\ncrossing. This penalty function is computationally feasible for enforcing\nnon-crossing constraints in multi-dimensional nonparametric quantile\nregression. We establish non-asymptotic upper bounds for the excess risk of the\nproposed nonparametric quantile regression function estimators. Our error\nbounds achieve optimal minimax rate of convergence for the Holder class, and\nthe prefactors of the error bounds depend polynomially on the dimension of the\npredictor, instead of exponentially. Based on the proposed non-crossing\npenalized deep quantile regression, we construct conformal prediction intervals\nthat are fully adaptive to heterogeneity. The proposed prediction interval is\nshown to have good properties in terms of validity and accuracy under\nreasonable conditions. We also derive non-asymptotic upper bounds for the\ndifference of the lengths between the proposed non-crossing conformal\nprediction interval and the theoretically oracle prediction interval. Numerical\nexperiments including simulation studies and a real data example are conducted\nto demonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: 8 figures, 3 tables\n",
    "authors": [
      "Wenlu Tang",
      "Guohao Shen",
      "Yuanyuan Lin",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.10161"
  },
  {
    "id": "arXiv:2210.10162",
    "title": "Computational pathology in renal disease: a comprehensive perspective",
    "abstract": "Computational pathology is a field that has complemented various\nsubspecialties of diagnostic pathology over the last few years. In this article\na brief analyzis the different applications in nephrology is developed. To\nbegin, an overview of the different forms of image production is provided. To\ncontinue, the most frequent applications of computer vision models, the salient\nfeatures of the different clinical applications, and the data protection\nconsiderations encountered are described. To finish the development, I delve\ninto the interpretability of these applications, expanding in depth on the\nthree dimensions of this area.",
    "descriptor": "\nComments: 10 pages, 7 figures and 3 tables\n",
    "authors": [
      "Manuel Cossio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10162"
  },
  {
    "id": "arXiv:2210.10164",
    "title": "Optimized Telecloning Circuits: Theory and Practice of Nine NISQ Clones",
    "abstract": "Although perfect copying of an unknown quantum state is not possible,\napproximate cloning is possible in quantum mechanics. Quantum telecloning is a\nvariant of approximate quantum cloning which uses quantum teleportation to\nallow for the use of classical communication to create physically separate\nclones of a quantum state. We present results of a of $1 \\rightarrow 9$\nuniversal, symmetric, optimal quantum telecloning implementation on a cloud\naccessible quantum computer - the Quantinuum H1-1 device. The H1-1 device\nallows direct creation of the telecloning protocol due to real time classical\nif-statements that are conditional on the mid-circuit measurement outcome of a\nBell measurement. In this implementation, we also provide an improvement over\nprevious work for the circuit model description of quantum telecloning, which\nreduces the required gate depth and gate count for an all-to-all connectivity.\nThe demonstration of creating $9$ approximate clones on a quantum processor is\nthe largest number of clones that has been generated, telecloning or otherwise.",
    "descriptor": "",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10164"
  },
  {
    "id": "arXiv:2210.10179",
    "title": "Inference in conditioned dynamics through causality restoration",
    "abstract": "Computing observables from conditioned dynamics is typically computationally\nhard, because, although obtaining independent samples efficiently from the\nunconditioned dynamics is usually feasible, generally most of the samples must\nbe discarded (in a form of importance sampling) because they do not satisfy the\nimposed conditions. Sampling directly from the conditioned distribution is\nnon-trivial, as conditioning breaks the causal properties of the dynamics which\nultimately renders the sampling procedure efficient. One standard way of\nachieving it is through a Metropolis Monte-Carlo procedure, but this procedure\nis normally slow and a very large number of Monte-Carlo steps is needed to\nobtain a small number of statistically independent samples. In this work, we\npropose an alternative method to produce independent samples from a conditioned\ndistribution. The method learns the parameters of a generalized dynamical model\nthat optimally describe the conditioned distribution in a variational sense.\nThe outcome is an effective, unconditioned, dynamical model, from which one can\ntrivially obtain independent samples, effectively restoring causality of the\nconditioned distribution. The consequences are twofold: on the one hand, it\nallows us to efficiently compute observables from the conditioned dynamics by\nsimply averaging over independent samples. On the other hand, the method gives\nan effective unconditioned distribution which is easier to interpret. The\nmethod is flexible and can be applied virtually to any dynamics. We discuss an\nimportant application of the method, namely the problem of epidemic risk\nassessment from (imperfect) clinical tests, for a large family of\ntime-continuous epidemic models endowed with a Gillespie-like sampler. We show\nthat the method compares favorably against the state of the art, including the\nsoft-margin approach and mean-field methods.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Alfredo Braunstein",
      "Giovanni Catania",
      "Luca Dall'Asta",
      "Matteo Mariani",
      "Anna Paola Muntoni"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2210.10179"
  },
  {
    "id": "arXiv:2210.10188",
    "title": "On Hitting Times for General Quantum Markov Processes",
    "abstract": "Random walks (or Markov chains) are models extensively used in theoretical\ncomputer science. Several tools, including analysis of quantities such as\nhitting and mixing times, are helpful for devising randomized algorithms. A\nnotable example is Sch\\\"oning's algorithm for the satisfiability (SAT) problem.\nIn this work, we use the density-matrix formalism to define a quantum Markov\nchain model which directly generalizes classical walks, and we show that a\ncommon tools such as hitting times can be computed with a similar formula as\nthe one found in the classical theory, which we then apply to known quantum\nsettings such as Grover's algorithm.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Lorenzo Laneve",
      "Francesco Tacchino",
      "Ivano Tavernelli"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.10188"
  },
  {
    "id": "arXiv:2210.10208",
    "title": "Optimizing Temporal Resolution Of Convolutional Recurrent Neural  Networks For Sound Event Detection",
    "abstract": "In this technical report, the systems we submitted for subtask 4 of the DCASE\n2021 challenge, regarding sound event detection, are described in detail. These\nmodels are closely related to the baseline provided for this problem, as they\nare essentially convolutional recurrent neural networks trained in a mean\nteacher setting to deal with the heterogeneous annotation of the supplied data.\nHowever, the time resolution of the predictions was adapted to deal with the\nfact that these systems are evaluated using two intersection-based metrics\ninvolving different needs in terms of temporal localization. This was done by\noptimizing the pooling operations.\nFor the first of the defined evaluation scenarios, imposing relatively strict\nrequirements on the temporal localization accuracy, our best model achieved a\nPSDS score of 0.3609 on the validation data. This is only marginally better\nthan the performance obtained by the baseline system (0.342): The amount of\npooling in the baseline network already turned out to be optimal, and thus, no\nsubstantial changes were made, explaining this result.\nFor the second evaluation scenario, imposing relatively lax restrictions on\nthe localization accuracy, our best-performing system achieved a PSDS score of\n0.7312 on the validation data. This is significantly better than the\nperformance obtained by the baseline model (0.527), which can effectively be\nattributed to the changes that were applied to the pooling operations of the\nnetwork.",
    "descriptor": "\nComments: Technical report of submission to DCASE 2021 Challenge Task 4\n",
    "authors": [
      "Wim Boes",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.10208"
  },
  {
    "id": "arXiv:2210.10210",
    "title": "Equispaced Fourier representations for efficient Gaussian process  regression from a billion data points",
    "abstract": "We introduce a Fourier-based fast algorithm for Gaussian process regression.\nIt approximates a translationally-invariant covariance kernel by complex\nexponentials on an equispaced Cartesian frequency grid of $M$ nodes. This\nresults in a weight-space $M\\times M$ system matrix with Toeplitz structure,\nwhich can thus be applied to a vector in ${\\mathcal O}(M \\log{M})$ operations\nvia the fast Fourier transform (FFT), independent of the number of data points\n$N$. The linear system can be set up in ${\\mathcal O}(N + M \\log{M})$\noperations using nonuniform FFTs. This enables efficient massive-scale\nregression via an iterative solver, even for kernels with fat-tailed spectral\ndensities (large $M$). We include a rigorous error analysis of the kernel\napproximation, the resulting accuracy (relative to \"exact\" GP regression), and\nthe condition number. Numerical experiments for squared-exponential and\nMat\\'ern kernels in one, two and three dimensions often show 1-2 orders of\nmagnitude acceleration over state-of-the-art rank-structured solvers at\ncomparable accuracy. Our method allows 2D Mat\\'ern-${\\small \\frac{3}{2}}$\nregression from $N=10^9$ data points to be performed in 2 minutes on a standard\ndesktop, with posterior mean accuracy $10^{-3}$. This opens up spatial\nstatistics applications 100 times larger than previously possible.",
    "descriptor": "",
    "authors": [
      "Philip Greengard",
      "Manas Rachh",
      "Alex Barnett"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10210"
  },
  {
    "id": "arXiv:2210.10212",
    "title": "Multi-Source Transformer Architectures for Audiovisual Scene  Classification",
    "abstract": "In this technical report, the systems we submitted for subtask 1B of the\nDCASE 2021 challenge, regarding audiovisual scene classification, are described\nin detail. They are essentially multi-source transformers employing a\ncombination of auditory and visual features to make predictions. These models\nare evaluated utilizing the macro-averaged multi-class cross-entropy and\naccuracy metrics.\nIn terms of the macro-averaged multi-class cross-entropy, our best model\nachieved a score of 0.620 on the validation data. This is slightly better than\nthe performance of the baseline system (0.658).\nWith regard to the accuracy measure, our best model achieved a score of\n77.1\\% on the validation data, which is about the same as the performance\nobtained by the baseline system (77.0\\%).",
    "descriptor": "\nComments: Technical report of submission to DCASE 2021 Challenge Task 1B\n",
    "authors": [
      "Wim Boes",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10212"
  },
  {
    "id": "arXiv:2210.10262",
    "title": "Free energy model of emotional valence in dual-process perceptions",
    "abstract": "An appropriate level of arousal induces positive emotions, and a high arousal\npotential may provoke negative emotions. To explain the effect of arousal on\nemotional valence, we propose a novel mathematical framework of arousal\npotential variations in the dual process of human cognition: automatic and\ncontrolled process. Although models have been proposed to explain the emotions\nin the dual process, a suitable mathematical formulation is largely\nundiscovered. Our model associates free energy with arousal potential and its\nvariations to explain emotional valence. Decreasing and increasing free energy\nconsequently induces positive and negative emotions, respectively. We formalize\na transition from the automatic to controlled process in the dual process as a\nchange of Bayesian prior. We model emotion valence using free-energy increase\n(FI) when one tries to change one's Bayesian prior and its reduction (FR) when\none succeeds to recognize the same stimuli with a changed prior and define\nthree emotions: \"interest,\" \"confusion,\" and \"boredom\" using the variations.\nThe mathematical analysis comparing between varied Gaussian model parameters\nsuggests that: 1) prediction error (PR) increases FR when the first prior\nvariance is greater than the second prior variance, 2) PR always increases FR,\nand 3) the distance between priors' means always increases FR. We discuss the\nassociation of the outcomes with emotions in the controlled process. The\nmathematical model provides a general framework for predicting and controlling\nemotional valence in the dual process that varies with viewpoint and stimuli,\nas well as for understanding the contradictions in the effects of arousal on\nthe valence.",
    "descriptor": "",
    "authors": [
      "Hideyoshi Yanagisawa",
      "Xiaoxiang Wu",
      "Kazutaka Ueda",
      "Takeo Kato"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.10262"
  },
  {
    "id": "arXiv:2210.10265",
    "title": "Deep Learning Based Two-dimensional Speaker Localization With Large  Ad-hoc Microphone Arrays",
    "abstract": "Deep learning based speaker localization has shown its advantage in\nreverberant scenarios. However, it mostly focuses on the direction-of-arrival\n(DOA) estimation subtask of speaker localization, where the DOA instead of the\n2-dimensional (2D) coordinates is obtained only. To obtain the 2D coordinates\nof multiple speakers with random positions, this paper proposes a\ndeep-learning-based 2D speaker localization method with large ad-hoc microphone\narrays, where an ad-hoc microphone array is a set of randomly-distributed\nmicrophone nodes with each node set to a traditional microphone array, e.g. a\nlinear array. Specifically, a convolutional neural network is applied to each\nnode to get the direction-of-arrival (DOA) estimation of speech sources. Then,\na triangulation and clustering method integrates the DOA estimations of the\nnodes for estimating the 2D positions of the speech sources. To further improve\nthe estimation accuracy, we propose a softmax-based node selection algorithm.\nExperimental results with large-scale ad-hoc microphone arrays show that the\nproposed method achieves significantly better performance than conventional\nmethods in both simulated and real-world environments. The softmax-based node\nselection further improves the performance.",
    "descriptor": "",
    "authors": [
      "Shupei Liu",
      "Yijun Gong",
      "Xiao-Lei Zhang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.10265"
  },
  {
    "id": "arXiv:2210.10268",
    "title": "Fast Approximation of the Generalized Sliced-Wasserstein Distance",
    "abstract": "Generalized sliced Wasserstein distance is a variant of sliced Wasserstein\ndistance that exploits the power of non-linear projection through a given\ndefining function to better capture the complex structures of the probability\ndistributions. Similar to sliced Wasserstein distance, generalized sliced\nWasserstein is defined as an expectation over random projections which can be\napproximated by the Monte Carlo method. However, the complexity of that\napproximation can be expensive in high-dimensional settings. To that end, we\npropose to form deterministic and fast approximations of the generalized sliced\nWasserstein distance by using the concentration of random projections when the\ndefining functions are polynomial function, circular function, and neural\nnetwork type function. Our approximations hinge upon an important result that\none-dimensional projections of a high-dimensional random vector are\napproximately Gaussian.",
    "descriptor": "\nComments: 22 pages, 2 figures. Dung Le, Huy Nguyen and Khai Nguyen contributed equally to this work\n",
    "authors": [
      "Dung Le",
      "Huy Nguyen",
      "Khai Nguyen",
      "Trang Nguyen",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10268"
  },
  {
    "id": "arXiv:2210.10336",
    "title": "A Non-Interior-Point Continuation Method for the Optimal Control Problem  with Equilibrium Constraints",
    "abstract": "In this study, we propose a numerical solution method for the optimal control\nproblem with equilibrium constraints (OCPEC). OCPEC can be discretized into a\nperturbed finite-dimensional nonlinear programming (NLP) problem and further\nrelaxed to satisfy the fundamental constraint qualifications. Therefore, its\nsolution can be obtained by the continuation method that solves a sequence of\nwell-posed NLP problems. However, numerical difficulties that the interior of\nthe feasible region shrinks toward the disjunctive and empty set, arise when\nthe perturbed parameter is close to zero. Hence, we propose a dedicated NLP\nsolver that maps the Karush--Kuhn--Tucker conditions into a system of\nequations, referred to as the non-interior-point (NIP) method. Compared with\nactive-set methods, the NIP method considers all inequality constraints at each\niteration, which is similar to the interior-point (IP) method and suitable for\nlarge-scale problems. However, it does not enforce all iterates to remain in\nthe feasible interior, leading to a larger stepsize to mitigate the geometrical\ndifficulties of the feasible region. Moreover, we introduce some numerical\ntechniques to improve the solver performance. The local convergence and\nsolution error are analyzed under certain assumptions. Comparisons with an\noff-the-shelf IP solver demonstrate that the proposed method is capable of\nfinding a better solution, less sensitive to the ill-posedness of the feasible\nregion, and requires significantly fewer iterations.",
    "descriptor": "",
    "authors": [
      "Kangyu Lin",
      "Toshiyuki Ohtsuka"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10336"
  },
  {
    "id": "arXiv:2210.10391",
    "title": "Machine Learning for a Sustainable Energy Future",
    "abstract": "Transitioning from fossil fuels to renewable energy sources is a critical\nglobal challenge; it demands advances at the levels of materials, devices, and\nsystems for the efficient harvesting, storage, conversion, and management of\nrenewable energy. Researchers globally have begun incorporating machine\nlearning (ML) techniques with the aim of accelerating these advances. ML\ntechnologies leverage statistical trends in data to build models for prediction\nof material properties, generation of candidate structures, optimization of\nprocesses, among other uses; as a result, they can be incorporated into\ndiscovery and development pipelines to accelerate progress. Here we review\nrecent advances in ML-driven energy research, outline current and future\nchallenges, and describe what is required moving forward to best lever ML\ntechniques. To start, we give an overview of key ML concepts. We then introduce\na set of key performance indicators to help compare the benefits of different\nML-accelerated workflows for energy research. We discuss and evaluate the\nlatest advances in applying ML to the development of energy harvesting\n(photovoltaics), storage (batteries), conversion (electrocatalysis), and\nmanagement (smart grids). Finally, we offer an outlook of potential research\nareas in the energy field that stand to further benefit from the application of\nML.",
    "descriptor": "",
    "authors": [
      "Zhenpeng Yao",
      "Yanwei Lum",
      "Andrew Johnston",
      "Luis Martin Mejia-Mendoza",
      "Xin Zhou",
      "Yonggang Wen",
      "Alan Aspuru-Guzik",
      "Edward H. Sargent",
      "Zhi Wei Seh"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10391"
  },
  {
    "id": "arXiv:2210.10404",
    "title": "On the gain of entrainment in the $n$-dimensional ribosome flow model",
    "abstract": "The ribosome flow model (RFM) is a phenomenological model for the flow of\nparticles along a 1D chain of sites. It has been extensively used to study\nribosome flow along the mRNA molecule during translation. When the transition\nrates along the chain are time-varying and jointly T-periodic the RFM entrains,\ni.e., every trajectory of the RFM converges to a unique T-periodic solution\nthat depends on the transition rates, but not on the initial condition.\nEntrainment to periodic excitations like the 24h solar day or the 50Hz\nfrequency of the electric grid is important in numerous natural and artificial\nsystems. An interesting question, called the gain of entrainment (GOE), is\nwhether proper coordination of the periodic translation rates along the mRNA\ncan lead to a larger average protein production rate. Analyzing the GOE in the\nRFM is non-trivial and partial results exist only for the RFM with dimensions\n$n=1,2$. We use a new approach to derive several results on the GOE in the\ngeneral $n$-dimensional RFM. Perhaps surprisingly, we rigorously characterize\nseveral cases where there is no GOE, so to maximize the average production rate\nin these cases, the best choice is to use constant transition rates along the\nchain.",
    "descriptor": "",
    "authors": [
      "Ron Ofir",
      "Thomas Kriecherbauer",
      "Lars Gr\u00fcne",
      "Michael Margaliot"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10404"
  },
  {
    "id": "arXiv:2210.10430",
    "title": "Convexity Certificates from Hessians",
    "abstract": "The Hessian of a differentiable convex function is positive semidefinite.\nTherefore, checking the Hessian of a given function is a natural approach to\ncertify convexity. However, implementing this approach is not straightforward\nsince it requires a representation of the Hessian that allows its analysis.\nHere, we implement this approach for a class of functions that is rich enough\nto support classical machine learning. For this class of functions, it was\nrecently shown how to compute computational graphs of their Hessians. We show\nhow to check these graphs for positive semidefiniteness. We compare our\nimplementation of the Hessian approach with the well-established disciplined\nconvex programming (DCP) approach and prove that the Hessian approach is at\nleast as powerful as the DCP approach for differentiable functions.\nFurthermore, we show for a state-of-the-art implementation of the DCP approach\nthat, for differentiable functions, the Hessian approach is actually more\npowerful. That is, it can certify the convexity of a larger class of\ndifferentiable functions.",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2022\n",
    "authors": [
      "Julien Klaus",
      "Niklas Merk",
      "Konstantin Wiedom",
      "S\u00f6ren Laue",
      "Joachim Giesen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.10430"
  },
  {
    "id": "arXiv:2210.10439",
    "title": "A scan-specific unsupervised method for parallel MRI reconstruction via  implicit neural representation",
    "abstract": "Parallel imaging is a widely-used technique to accelerate magnetic resonance\nimaging (MRI). However, current methods still perform poorly in reconstructing\nartifact-free MRI images from highly undersampled k-space data. Recently,\nimplicit neural representation (INR) has emerged as a new deep learning\nparadigm for learning the internal continuity of an object. In this study, we\nadopted INR to parallel MRI reconstruction. The MRI image was modeled as a\ncontinuous function of spatial coordinates. This function was parameterized by\na neural network and learned directly from the measured k-space itself without\nadditional fully sampled high-quality training data. Benefitting from the\npowerful continuous representations provided by INR, the proposed method\noutperforms existing methods by suppressing the aliasing artifacts and noise,\nespecially at higher acceleration rates and smaller sizes of the\nauto-calibration signals. The high-quality results and scanning specificity\nmake the proposed method hold the potential for further accelerating the data\nacquisition of parallel MRI.",
    "descriptor": "\nComments: conference\n",
    "authors": [
      "Ruimin Feng",
      "Qing Wu",
      "Yuyao Zhang",
      "Hongjiang Wei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10439"
  },
  {
    "id": "arXiv:2210.10443",
    "title": "Deep neural network expressivity for optimal stopping problems",
    "abstract": "This article studies deep neural network expression rates for optimal\nstopping problems of discrete-time Markov processes on high-dimensional state\nspaces. A general framework is established in which the value function and\ncontinuation value of an optimal stopping problem can be approximated with\nerror at most $\\varepsilon$ by a deep ReLU neural network of size at most\n$\\kappa d^{\\mathfrak{q}} \\varepsilon^{-\\mathfrak{r}}$. The constants\n$\\kappa,\\mathfrak{q},\\mathfrak{r} \\geq 0$ do not depend on the dimension $d$ of\nthe state space or the approximation accuracy $\\varepsilon$. This proves that\ndeep neural networks do not suffer from the curse of dimensionality when\nemployed to solve optimal stopping problems. The framework covers, for example,\nexponential L\\'evy models, discrete diffusion processes and their running\nminima and maxima. These results mathematically justify the use of deep neural\nnetworks for numerically solving optimal stopping problems and pricing American\noptions in high dimensions.",
    "descriptor": "",
    "authors": [
      "Lukas Gonon"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2210.10443"
  },
  {
    "id": "arXiv:2210.10452",
    "title": "Rethinking Sharpness-Aware Minimization as Variational Inference",
    "abstract": "Sharpness-aware minimization (SAM) aims to improve the generalisation of\ngradient-based learning by seeking out flat minima. In this work, we establish\nconnections between SAM and Mean-Field Variational Inference (MFVI) of neural\nnetwork parameters. We show that both these methods have interpretations as\noptimizing notions of flatness, and when using the reparametrisation trick,\nthey both boil down to calculating the gradient at a perturbed version of the\ncurrent mean parameter. This thinking motivates our study of algorithms that\ncombine or interpolate between SAM and MFVI. We evaluate the proposed\nvariational algorithms on several benchmark datasets, and compare their\nperformance to variants of SAM. Taking a broader perspective, our work suggests\nthat SAM-like updates can be used as a drop-in replacement for the\nreparametrisation trick.",
    "descriptor": "",
    "authors": [
      "Szilvia Ujv\u00e1ry",
      "Zsigmond Telek",
      "Anna Kerekes",
      "Anna M\u00e9sz\u00e1ros",
      "Ferenc Husz\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10452"
  },
  {
    "id": "arXiv:2210.10474",
    "title": "Video super-resolution for single-photon LIDAR",
    "abstract": "3D Time-of-Flight (ToF) image sensors are used widely in applications such as\nself-driving cars, Augmented Reality (AR) and robotics. When implemented with\nSingle-Photon Avalanche Diodes (SPADs), compact, array format sensors can be\nmade that offer accurate depth maps over long distances, without the need for\nmechanical scanning. However, array sizes tend to be small, leading to low\nlateral resolution, which combined with low Signal-to-Noise Ratio (SNR) levels\nunder high ambient illumination, may lead to difficulties in scene\ninterpretation. In this paper, we use synthetic depth sequences to train a 3D\nConvolutional Neural Network (CNN) for denoising and upscaling (x4) depth data.\nExperimental results, based on synthetic as well as real ToF data, are used to\ndemonstrate the effectiveness of the scheme. With GPU acceleration, frames are\nprocessed at >30 frames per second, making the approach suitable for\nlow-latency imaging, as required for obstacle avoidance.",
    "descriptor": "\nComments: 18 pages, 10 figures, 3 tables\n",
    "authors": [
      "Germ\u00e1n Mora Mart\u00edn",
      "Stirling Scholes",
      "Alice Ruget",
      "Robert K. Henderson",
      "Jonathan Leach",
      "Istvan Gyongy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2210.10474"
  },
  {
    "id": "arXiv:2210.10494",
    "title": "Spectroscopic data de-noising via training-set-free deep learning method",
    "abstract": "De-noising plays a crucial role in the post-processing of spectra. Machine\nlearning-based methods show good performance in extracting intrinsic\ninformation from noisy data, but often require a high-quality training set that\nis typically inaccessible in real experimental measurements. Here, using\nspectra in angle-resolved photoemission spectroscopy (ARPES) as an example, we\ndevelop a de-noising method for extracting intrinsic spectral information\nwithout the need for a training set. This is possible as our method leverages\nthe self-correlation information of the spectra themselves. It preserves the\nintrinsic energy band features and thus facilitates further analysis and\nprocessing. Moreover, since our method is not limited by specific properties of\nthe training set compared to previous ones, it may well be extended to other\nfields and application scenarios where obtaining high-quality multidimensional\ntraining data is challenging.",
    "descriptor": "",
    "authors": [
      "Dongchen Huang",
      "Junde Liu",
      "Tian Qian",
      "Yi-feng Yang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.10494"
  },
  {
    "id": "arXiv:2210.10503",
    "title": "Reducing Graph Parameters by Contractions and Deletions",
    "abstract": "We consider the following problem: for a given graph $G$ and two integers $k$\nand $d$, can we apply a fixed graph operation at most $k$ times in order to\nreduce a given graph parameter $\\pi$ by at least $d$? We show that this problem\nis NP-hard when the parameter is the independence number and the graph\noperation is vertex deletion or edge contraction, even for fixed $d=1$ and when\nrestricted to chordal graphs. We give a polynomial time algorithm for bipartite\ngraphs when the operation is edge contraction, the parameter is the\nindependence number and $d$ is fixed. Further, we complete the complexity\ndichotomy on $H$-free graphs when the parameter is the clique number and the\noperation is edge contraction by showing that this problem is NP-hard in\n$(C_3+P_1)$-free graphs even for fixed $d=1$. When the operation is edge\ndeletion and the parameter is the chromatic number, we determine the\ncomputational complexity of the associated problem on cographs and complete\nmultipartite graphs. Our results answer several open questions stated in [Diner\net al., Theoretical Computer Science, 746, p. 49-72 (2012)].",
    "descriptor": "\nComments: 26 pages, 4 figures. arXiv admin note: substantial text overlap with arXiv:2202.08574\n",
    "authors": [
      "Felicia Lucke",
      "Felix Mann"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.10503"
  },
  {
    "id": "arXiv:2210.10507",
    "title": "Predicting Oxide Glass Properties with Low Complexity Neural Network and  Physical and Chemical Descriptors",
    "abstract": "Due to their disordered structure, glasses present a unique challenge in\npredicting the composition-property relationships. Recently, several attempts\nhave been made to predict the glass properties using machine learning\ntechniques. However, these techniques have the limitations, namely, (i)\npredictions are limited to the components that are present in the original\ndataset, and (ii) predictions towards the extreme values of the properties,\nimportant regions for new materials discovery, are not very reliable due to the\nsparse datapoints in this region. To address these challenges, here we present\na low complexity neural network (LCNN) that provides improved performance in\npredicting the properties of oxide glasses. In addition, we combine the LCNN\nwith physical and chemical descriptors that allow the development of universal\nmodels that can provide predictions for components beyond the training set. By\ntraining on a large dataset (~50000) of glass components, we show the LCNN\noutperforms state-of-the-art algorithms such as XGBoost. In addition, we\ninterpret the LCNN models using Shapely additive explanations to gain insights\ninto the role played by the descriptors in governing the property. Finally, we\ndemonstrate the universality of the LCNN models by predicting the properties\nfor glasses with new components that were not present in the original training\nset. Altogether, the present approach provides a promising direction towards\naccelerated discovery of novel glass compositions.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Suresh Bishnoi",
      "Skyler Badge",
      "Jayadeva",
      "N. M. Anoop Krishnan"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10507"
  },
  {
    "id": "arXiv:2210.10520",
    "title": "Graph sampling for node embedding",
    "abstract": "Node embedding is a central topic in graph representation learning.\nComputational efficiency and scalability can be challenging to any method that\nrequires full-graph operations. We propose sampling approaches to node\nembedding, with or without explicit modelling of the feature vector, which aim\nto extract useful information from both the eigenvectors related to the graph\nLaplacien and the given values associated with the graph.",
    "descriptor": "",
    "authors": [
      "Li-Chun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10520"
  },
  {
    "id": "arXiv:2210.10524",
    "title": "Over-the-Air Computation: Foundations, Technologies, and Applications",
    "abstract": "The rapid advancement of artificial intelligence technologies has given rise\nto diversified intelligent services, which place unprecedented demands on\nmassive connectivity and gigantic data aggregation. However, the scarce radio\nresources and stringent latency requirement make it challenging to meet these\ndemands. To tackle these challenges, over-the-air computation (AirComp) emerges\nas a potential technology. Specifically, AirComp seamlessly integrates the\ncommunication and computation procedures through the superposition property of\nmultiple-access channels, which yields a revolutionary multiple-access paradigm\nshift from \"compute-after-communicate\" to \"compute-when-communicate\".\nMeanwhile, low-latency and spectral-efficient wireless data aggregation can be\nachieved via AirComp by allowing multiple devices to access the wireless\nchannels non-orthogonally. In this paper, we aim to present the recent\nadvancement of AirComp in terms of foundations, technologies, and applications.\nThe mathematical form and communication design are introduced as the\nfoundations of AirComp, and the critical issues of AirComp over different\nnetwork architectures are then discussed along with the review of existing\nliterature. The technologies employed for the analysis and optimization on\nAirComp are reviewed from the information theory and signal processing\nperspectives. Moreover, we present the existing studies that tackle the\npractical implementation issues in AirComp systems, and elaborate the\napplications of AirComp in Internet of Things and edge intelligent networks.\nFinally, potential research directions are highlighted to motivate the future\ndevelopment of AirComp.",
    "descriptor": "",
    "authors": [
      "Zhibin Wang",
      "Yapeng Zhao",
      "Yong Zhou",
      "Yuanming Shi",
      "Chunxiao Jiang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10524"
  },
  {
    "id": "arXiv:2210.10533",
    "title": "Deep-based quality assessment of medical images through domain  adaptation",
    "abstract": "Predicting the quality of multimedia content is often needed in different\nfields. In some applications, quality metrics are crucial with a high impact,\nand can affect decision making such as diagnosis from medical multimedia. In\nthis paper, we focus on such applications by proposing an efficient and shallow\nmodel for predicting the quality of medical images without reference from a\nsmall amount of annotated data. Our model is based on convolution\nself-attention that aims to model complex representation from relevant local\ncharacteristics of images, which itself slide over the image to interpolate the\nglobal quality score. We also apply domain adaptation learning in unsupervised\nand semi-supervised manner. The proposed model is evaluated through a dataset\ncomposed of several images and their corresponding subjective scores. The\nobtained results showed the efficiency of the proposed method, but also, the\nrelevance of the applying domain adaptation to generalize over different\nmultimedia domains regarding the downstream task of perceptual quality\nprediction. \\footnote{Funded by the TIC-ART project, Regional fund (Region\nCentre-Val de Loire)}",
    "descriptor": "\nComments: ICIP 2022\n",
    "authors": [
      "Marouane Tliba",
      "Aymen Sekhri",
      "Mohamed Amine Kerkouri",
      "Aladine Chetouani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10533"
  },
  {
    "id": "arXiv:2210.10541",
    "title": "The phase unwrapping of under-sampled interferograms using radial basis  function neural networks",
    "abstract": "Interferometry can measure the shape or the material density of a system that\ncould not be measured otherwise by recording the difference between the phase\nchange of a signal and a reference phase. This difference is always between\n$-\\pi$ and $\\pi$ while it is the absolute phase that is required to get a true\nmeasurement. There is a long history of methods designed to recover accurately\nthis phase from the phase \"wrapped\" inside $]-\\pi,\\pi]$. However, noise and\nunder-sampling limit the effectiveness of most techniques and require highly\nsophisticated algorithms that can process imperfect measurements. Ultimately,\nanalysing successfully an interferogram amounts to pattern recognition, a task\nwhere radial basis function neural networks truly excel at. The proposed neural\nnetwork is designed to unwrap the phase from two-dimensional interferograms,\nwhere aliasing, stemming from under-resolved regions, and noise levels are\nsignificant. The neural network can be trained in parallel and in three stages,\nusing gradient-based supervised learning. Parallelism allows to handle\nrelatively large data sets, but requires a supplemental step to synchronized\nthe fully unwrapped phase across the different networks.",
    "descriptor": "",
    "authors": [
      "Pierre-Alexandre Gourdain",
      "Aidan Bachmann"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10541"
  },
  {
    "id": "arXiv:2210.10544",
    "title": "Subtractive random forests",
    "abstract": "Motivated by online recommendation systems, we study a family of random\nforests. The vertices of the forest are labeled by integers. Each non-positive\ninteger $i\\le 0$ is the root of a tree. Vertices labeled by positive integers\n$n \\ge 1$ are attached sequentially such that the parent of vertex $n$ is\n$n-Z_n$, where the $Z_n$ are i.i.d.\\ random variables taking values in $\\mathbb\nN$. We study several characteristics of the resulting random forest. In\nparticular, we establish bounds for the expected tree sizes, the number of\ntrees in the forest, the number of leaves, the maximum degree, and the height\nof the forest. We show that for all distributions of the $Z_n$, the forest\ncontains at most one infinite tree, almost surely. If ${\\mathbb E} Z_n <\n\\infty$, then there is a unique infinite tree and the total size of the\nremaining trees is finite, with finite expected value if ${\\mathbb E}Z_n^2 <\n\\infty$. If ${\\mathbb E} Z_n = \\infty$ then almost surely all trees are finite.",
    "descriptor": "",
    "authors": [
      "Nicolas Broutin",
      "Luc Devroye",
      "Gabor Lugosi",
      "Roberto Imbuzeiro Oliveira"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.10544"
  },
  {
    "id": "arXiv:2210.10545",
    "title": "Improved lung segmentation based on U-Net architecture and morphological  operations",
    "abstract": "An essential stage in computer aided diagnosis of chest X rays is automated\nlung segmentation. Due to rib cages and the unique modalities of each persons\nlungs, it is essential to construct an effective automated lung segmentation\nmodel. This paper presents a reliable model for the segmentation of lungs in\nchest radiographs. Our model overcomes the challenges by learning to ignore\nunimportant areas in the source Chest Radiograph and emphasize important\nfeatures for lung segmentation. We evaluate our model on public datasets,\nMontgomery and Shenzhen. The proposed model has a DICE coefficient of 98.1\npercent which demonstrates the reliability of our model.",
    "descriptor": "\nComments: 8 pages, 5 figures, conference\n",
    "authors": [
      "S Ali John Naqvi",
      "Abdullah Tauqeer",
      "Rohaib Bhatti",
      "S Bazil Ali"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10545"
  },
  {
    "id": "arXiv:2210.10551",
    "title": "Distributed Coordination Based on Quantum Entanglement",
    "abstract": "This paper demonstrates and proves that the coordination of actions in a\ndistributed swarm can be enhanced by using quantum entanglement. In particular,\nwe focus on\n- Global and local simultaneous random walks, using entangled qubits that\ncollapse into the same (or opposite) direction, either random direction or\ntotally controlled simultaneous movements.\n- Identifying eavesdropping from malicious eavesdroppers aimed at disturbing\nthe simultaneous random walks by using entangled qubits that were sent at\nrandom or with predefined bases.\n- Identifying Byzantine robots or malicious robots that are trying to gain\nsecret information or are attacking the system using entangled qubits.\n- The use of Pseudo Telepathy to coordinate robots' actions.",
    "descriptor": "",
    "authors": [
      "Yotam Ashkenazi",
      "Shlomi Dolev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10551"
  },
  {
    "id": "arXiv:2210.10567",
    "title": "Margin Optimal Classification Trees",
    "abstract": "In recent years there has been growing attention to interpretable machine\nlearning models which can give explanatory insights on their behavior. Thanks\nto their interpretability, decision trees have been intensively studied for\nclassification tasks, and due to the remarkable advances in mixed-integer\nprogramming (MIP), various approaches have been proposed to formulate the\nproblem of training an Optimal Classification Tree (OCT) as a MIP model. We\npresent a novel mixed-integer quadratic formulation for the OCT problem, which\nexploits the generalization capabilities of Support Vector Machines for binary\nclassification. Our model, denoted as Margin Optimal Classification Tree\n(MARGOT), encompasses the use of maximum margin multivariate hyperplanes nested\nin a binary tree structure. To enhance the interpretability of our approach, we\nanalyse two alternative versions of MARGOT, which include feature selection\nconstraints inducing local sparsity of the hyperplanes. First, MARGOT has been\ntested on non-linearly separable synthetic datasets in 2-dimensional feature\nspace to provide a graphical representation of the maximum margin approach.\nFinally, the proposed models have been tested on benchmark datasets from the\nUCI repository. The MARGOT formulation turns out to be easier to solve than\nother OCT approaches, and the generated tree better generalizes on new\nobservations. The two interpretable versions are effective in selecting the\nmost relevant features and maintaining good prediction quality.",
    "descriptor": "",
    "authors": [
      "Federico D'Onofrio",
      "Giorgio Grani",
      "Marta Monaci",
      "Laura Palagi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10567"
  },
  {
    "id": "arXiv:2210.10570",
    "title": "Spoofed training data for speech spoofing countermeasure can be  efficiently created using neural vocoders",
    "abstract": "A good training set for speech spoofing countermeasures requires diverse TTS\nand VC spoofing attacks, but generating TTS and VC spoofed trials for a target\nspeaker may be technically demanding. Instead of using full-fledged TTS and VC\nsystems, this study uses neural-network-based vocoders to do copy-synthesis on\nbona fide utterances. The output data can be used as spoofed data. To make\nbetter use of pairs of bona fide and spoofed data, this study introduces a\ncontrastive feature loss that can be plugged into the standard training\ncriterion. On the basis of the bona fide trials from the ASVspoof 2019 logical\naccess training set, this study empirically compared a few training sets\ncreated in the proposed manner using a few neural non-autoregressive vocoders.\nResults on multiple test sets suggest good practices such as fine-tuning neural\nvocoders using bona fide data from the target domain. The results also\ndemonstrated the effectiveness of the contrastive feature loss. Combining the\nbest practices, the trained CM achieved overall competitive performance. Its\nEERs on the ASVspoof 2021 hidden subsets also outperformed the top-1 challenge\nsubmissions.",
    "descriptor": "\nComments: ICASSP 2023 submission\n",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.10570"
  },
  {
    "id": "arXiv:2210.10585",
    "title": "The Minimum Wage as an Anchor: Effects on Determinations of Fairness by  Humans and AI",
    "abstract": "I study the role of the minimum wage as an anchor for perceptions of the\nfairness of wages by both human subjects and AI. Through surveys on human\nsubjects enrolled in the crowdsourcing platform Prolific.co and queries\nsubmitted to the large language model GPT-3, I test whether the numerical\nresponse for what wage is deemed fair for a particular job description changes\nwhen respondents and GPT-3 are prompted with information regarding the minimum\nwage. I find that the minimum wage influences the distribution of responses for\nthe wage considered fair by shifting the mean towards the minimum wage, thus\nestablishing the minimum wage's role as an anchor for judgements of fairness.\nThe anchor exerts a similar effect on the AI bot, but with differences\nincluding a systematic shift downward of the wage perceived as fair. In\naddition, I test the AI bot for variability with respect to gender and race\ncues in the prompt and find anomalies in the distribution of responses.",
    "descriptor": "",
    "authors": [
      "Dario G. Soatto"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10585"
  },
  {
    "id": "arXiv:2210.10610",
    "title": "Extending Graph Transformers with Quantum Computed Aggregation",
    "abstract": "Recently, efforts have been made in the community to design new Graph Neural\nNetworks (GNN), as limitations of Message Passing Neural Networks became more\napparent. This led to the appearance of Graph Transformers using global graph\nfeatures such as Laplacian Eigenmaps. In our paper, we introduce a GNN\narchitecture where the aggregation weights are computed using the long-range\ncorrelations of a quantum system. These correlations are generated by\ntranslating the graph topology into the interactions of a set of qubits in a\nquantum computer. This work was inspired by the recent development of quantum\nprocessing units which enables the computation of a new family of global graph\nfeatures that would be otherwise out of reach for classical hardware. We give\nsome theoretical insights about the potential benefits of this approach, and\nbenchmark our algorithm on standard datasets. Although not being adapted to all\ndatasets, our model performs similarly to standard GNN architectures, and paves\na promising future for quantum enhanced GNNs.",
    "descriptor": "",
    "authors": [
      "Slimane Thabet",
      "Romain Fouilland",
      "Loic Henriet"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10610"
  },
  {
    "id": "arXiv:2210.10641",
    "title": "Comparative analysis of deep learning approaches for AgNOR-stained  cytology samples interpretation",
    "abstract": "Cervical cancer is a public health problem, where the treatment has a better\nchance of success if detected early. The analysis is a manual process which is\nsubject to a human error, so this paper provides a way to analyze argyrophilic\nnucleolar organizer regions (AgNOR) stained slide using deep learning\napproaches. Also, this paper compares models for instance and semantic\ndetection approaches. Our results show that the semantic segmentation using\nU-Net with ResNet-18 or ResNet-34 as the backbone have similar results, and the\nbest model shows an IoU for nucleus, cluster, and satellites of 0.83, 0.92, and\n0.99 respectively. For instance segmentation, the Mask R-CNN using ResNet-50\nperforms better in the visual inspection and has a 0.61 of the IoU metric. We\nconclude that the instance segmentation and semantic segmentation models can be\nused in combination to make a cascade model able to select a nucleus and\nsubsequently segment the nucleus and its respective nucleolar organizer regions\n(NORs).",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Gustavo Atkinson Amorim",
      "Andr\u00e9 Vict\u00f3ria Matias",
      "Allan Cerentini",
      "Luiz Antonio Buschetto Macarini",
      "Alexandre Sherlley Onofre",
      "Fabiana Botelho Onofre",
      "Aldo von Wangenheim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.10641"
  },
  {
    "id": "arXiv:2210.10653",
    "title": "Agile Systems Engineering for sub-CubeSat scale spacecraft",
    "abstract": "Space systems miniaturization has been increasingly popular for the past\ndecades, with over 1600 CubeSats and 300 sub-CubeSat sized spacecraft estimated\nto have been launched since 1998. This trend towards decreasing size enables\nthe execution of unprecedented missions in terms of quantity, cost and\ndevelopment time, allowing for massively distributed satellite networks, and\nrapid prototyping of space equipment. Pocket-sized spacecraft can be designed\nin-house in less than a year and can reach weights of less than 10g, reducing\nthe considerable effort typically associated with orbital flight. However,\nwhile Systems Engineering methodologies have been proposed for missions down to\nCubeSat size, there is still a gap regarding design approaches for\npicosatellites and smaller spacecraft, which can exploit their potential for\niterative and accelerated development. In this paper, we propose a Systems\nEngineering methodology that abstains from the classic waterfall-like approach\nin favor of agile practices, focusing on available capabilities, delivery of\nfeatures and design \"sprints\". Our method, originating from the software\nengineering disciplines, allows quick adaptation to imposed constraints,\nchanges to requirements and unexpected events (e.g. chip shortages or delays),\nby making the design flexible to well-defined modifications. Two femtosatellite\nmissions, currently under development and due to be launched in 2023, are used\nas case studies for our approach, showing how miniature spacecraft can be\ndesigned, developed and qualified from scratch in 6 months or less. We claim\nthat the proposed method can simultaneously increase confidence in the design\nand decrease turnaround time for extremely small satellites, allowing\nunprecedented missions to take shape without the overhead traditionally\nassociated with sending cutting-edge hardware to space.",
    "descriptor": "\nComments: 15 pages, 6 figures, 3 tables, presented in the 73rd International Astronautical Congress\n",
    "authors": [
      "Konstantinos Kanavouras",
      "Andreas Makoto Hein",
      "Maanasa Sachidanand"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Other Computer Science (cs.OH)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10653"
  },
  {
    "id": "arXiv:2210.10729",
    "title": "Ruminations on Matrix Convexity and the Strong Subadditivity of Quantum  Entropy",
    "abstract": "The familiar second derivative test for convexity is shown to yield a useful\ntool also in the context of matrix-valued functions. We demonstrate its\napplicability on a number of theorems in this field. These include convexity\nprinciples which play an essential role in the Lieb-Ruskai proof of the strong\nsubadditivity of quantum entropy.",
    "descriptor": "\nComments: 12 pages, no figures\n",
    "authors": [
      "Michael Aizenman",
      "Giorgio Cipolloni"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10729"
  },
  {
    "id": "arXiv:2210.10741",
    "title": "A kernel Stein test of goodness of fit for sequential models",
    "abstract": "We propose a goodness-of-fit measure for probability densities modelling\nobservations with varying dimensionality, such as text documents of differing\nlengths or variable-length sequences. The proposed measure is an instance of\nthe kernel Stein discrepancy (KSD), which has been used to construct\ngoodness-of-fit tests for unnormalised densities. Existing KSDs require the\nmodel to be defined on a fixed-dimension space. As our major contributions, we\nextend the KSD to the variable dimension setting by identifying appropriate\nStein operators, and propose a novel KSD goodness-of-fit test. As with the\nprevious variants, the proposed KSD does not require the density to be\nnormalised, allowing the evaluation of a large class of models. Our test is\nshown to perform well in practice on discrete sequential data benchmarks.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Jerome Baum",
      "Heishiro Kanagawa",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.10741"
  },
  {
    "id": "arXiv:2210.10768",
    "title": "Anytime-valid off-policy inference for contextual bandits",
    "abstract": "Contextual bandits are a modern staple tool for active sequential\nexperimentation in the tech industry. They involve online learning algorithms\nthat adaptively (over time) learn policies to map observed contexts $X_t$ to\nactions $A_t$ in an attempt to maximize stochastic rewards $R_t$. This\nadaptivity raises interesting but hard statistical inference questions,\nespecially counterfactual ones: for example, it is often of interest to\nestimate the properties of a hypothetical policy that is different from the\nlogging policy that was used to collect the data -- a problem known as\n\"off-policy evaluation\" (OPE). Using modern martingale techniques, we present a\ncomprehensive framework for OPE inference that relax many unnecessary\nassumptions made in past work, significantly improving on them theoretically\nand empirically. Our methods remain valid in very general settings, and can be\nemployed while the original experiment is still running (that is, not\nnecessarily post-hoc), when the logging policy may be itself changing (due to\nlearning), and even if the context distributions are drifting over time. More\nconcretely, we derive confidence sequences for various functionals of interest\nin OPE. These include doubly robust ones for time-varying off-policy mean\nreward values, but also confidence bands for the entire CDF of the off-policy\nreward distribution. All of our methods (a) are valid at arbitrary stopping\ntimes (b) only make nonparametric assumptions, and (c) do not require known\nbounds on the maximal importance weights, and (d) adapt to the empirical\nvariance of the reward and weight distributions. In summary, our methods enable\nanytime-valid off-policy inference using adaptively collected contextual bandit\ndata.",
    "descriptor": "",
    "authors": [
      "Ian Waudby-Smith",
      "Lili Wu",
      "Aaditya Ramdas",
      "Nikos Karampatziakis",
      "Paul Mineiro"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10768"
  },
  {
    "id": "arXiv:1604.02509",
    "title": "Towards an Indexical Model of Situated Language Comprehension for  Cognitive Agents in Physical Worlds",
    "abstract": "Towards an Indexical Model of Situated Language Comprehension for  Cognitive Agents in Physical Worlds",
    "descriptor": "",
    "authors": [
      "Shiwali Mohan",
      "Aaron Mininger",
      "John Laird"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1604.02509"
  },
  {
    "id": "arXiv:1809.09910",
    "title": "Generalization Properties of hyper-RKHS and its Applications",
    "abstract": "Comments: Published on JMLR",
    "descriptor": "\nComments: Published on JMLR\n",
    "authors": [
      "Fanghui Liu",
      "Lei Shi",
      "Xiaolin Huang",
      "Jie Yang",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1809.09910"
  },
  {
    "id": "arXiv:1903.03825",
    "title": "Interpolation Consistency Training for Semi-Supervised Learning",
    "abstract": "Comments: This is the latest version, which is published in the Journal, \"Neural Networks\", in 2022. All the previous results are unchanged. Keyword: Deep Learning, Semi-supervised Learning, Mixup",
    "descriptor": "\nComments: This is the latest version, which is published in the Journal, \"Neural Networks\", in 2022. All the previous results are unchanged. Keyword: Deep Learning, Semi-supervised Learning, Mixup\n",
    "authors": [
      "Vikas Verma",
      "Kenji Kawaguchi",
      "Alex Lamb",
      "Juho Kannala",
      "Arno Solin",
      "Yoshua Bengio",
      "David Lopez-Paz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.03825"
  },
  {
    "id": "arXiv:1910.03365",
    "title": "A Penalized Inequality-Constrained Approach for Robust Beamforming with  DoF Limitation",
    "abstract": "Comments: Accepted by Signal Processing",
    "descriptor": "\nComments: Accepted by Signal Processing\n",
    "authors": [
      "Wenqiang Pu",
      "Jinjun Xiao",
      "Tao Zhang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1910.03365"
  },
  {
    "id": "arXiv:2012.01511",
    "title": "Temporal Representation Learning on Monocular Videos for 3D Human Pose  Estimation",
    "abstract": "Comments: Accepted in \"IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\"",
    "descriptor": "\nComments: Accepted in \"IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\"\n",
    "authors": [
      "Sina Honari",
      "Victor Constantin",
      "Helge Rhodin",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01511"
  },
  {
    "id": "arXiv:2012.02909",
    "title": "What Makes a \"Good\" Data Augmentation in Knowledge Distillation -- A  Statistical Perspective",
    "abstract": "Comments: Accepted by NeurIPS 2022. Project: this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Project: this https URL\n",
    "authors": [
      "Huan Wang",
      "Suhas Lohit",
      "Mike Jones",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.02909"
  },
  {
    "id": "arXiv:2012.03902",
    "title": "Generative Adversarial User Privacy in Lossy Single-Server Information  Retrieval",
    "abstract": "Comments: Accepted for Publication in IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY (TIFS)",
    "descriptor": "\nComments: Accepted for Publication in IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY (TIFS)\n",
    "authors": [
      "Chung-Wei Weng",
      "Yauhen Yakimenka",
      "Hsuan-Yin Lin",
      "Eirik Rosnes",
      "Joerg Kliewer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.03902"
  },
  {
    "id": "arXiv:2012.08626",
    "title": "Computation Against a Neighbour: Addressing Large-Scale Distribution and  Adaptivity with Functional Programming and Scala",
    "abstract": "Comments: 59 pages, 17 figures, 1 table",
    "descriptor": "\nComments: 59 pages, 17 figures, 1 table\n",
    "authors": [
      "Giorgio Audrito",
      "Roberto Casadei",
      "Ferruccio Damiani",
      "Mirko Viroli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2012.08626"
  },
  {
    "id": "arXiv:2101.07413",
    "title": "Dynamic Privacy Budget Allocation Improves Data Efficiency of  Differentially Private Gradient Descent",
    "abstract": "Comments: Accepted to FAccT'22; Updated abstract",
    "descriptor": "\nComments: Accepted to FAccT'22; Updated abstract\n",
    "authors": [
      "Junyuan Hong",
      "Zhangyang Wang",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.07413"
  },
  {
    "id": "arXiv:2101.08367",
    "title": "Influence Estimation for Generative Adversarial Networks",
    "abstract": "Comments: Published as a conference paper at ICLR 2021 (Spotlight)",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2021 (Spotlight)\n",
    "authors": [
      "Naoyuki Terashita",
      "Hiroki Ohashi",
      "Yuichi Nonaka",
      "Takashi Kanemaru"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08367"
  },
  {
    "id": "arXiv:2102.02804",
    "title": "A Deeper Look into Convolutions via Eigenvalue-based Pruning",
    "abstract": "Comments: The codes are available at this https URL",
    "descriptor": "\nComments: The codes are available at this https URL\n",
    "authors": [
      "Ilke Cugu",
      "Emre Akbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.02804"
  },
  {
    "id": "arXiv:2103.05134",
    "title": "Constrained Learning with Non-Convex Losses",
    "abstract": "Comments: IEEE Transactions on Information Theory",
    "descriptor": "\nComments: IEEE Transactions on Information Theory\n",
    "authors": [
      "Luiz F. O. Chamon",
      "Santiago Paternain",
      "Miguel Calvo-Fullana",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05134"
  },
  {
    "id": "arXiv:2104.10481",
    "title": "SKID: Self-Supervised Learning for Knee Injury Diagnosis from MRI Data",
    "abstract": "SKID: Self-Supervised Learning for Knee Injury Diagnosis from MRI Data",
    "descriptor": "",
    "authors": [
      "Siladittya Manna",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10481"
  },
  {
    "id": "arXiv:2106.15734",
    "title": "UAV-assisted Online Machine Learning over Multi-Tiered Networks: A  Hierarchical Nested Personalized Federated Learning Approach",
    "abstract": "Comments: To be published in IEEE Transactions on Network and Service Management",
    "descriptor": "\nComments: To be published in IEEE Transactions on Network and Service Management\n",
    "authors": [
      "Su Wang",
      "Seyyedali Hosseinalipour",
      "Maria Gorlatova",
      "Christopher G. Brinton",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15734"
  },
  {
    "id": "arXiv:2108.09306",
    "title": "D-DARTS: Distributed Differentiable Architecture Search",
    "abstract": "D-DARTS: Distributed Differentiable Architecture Search",
    "descriptor": "",
    "authors": [
      "Alexandre Heuillet",
      "Hedi Tabia",
      "Hichem Arioui",
      "Kamal Youcef-Toumi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09306"
  },
  {
    "id": "arXiv:2109.05126",
    "title": "D-REX: Dialogue Relation Extraction with Explanations",
    "abstract": "Comments: NLP4CONVAI, code at this https URL",
    "descriptor": "\nComments: NLP4CONVAI, code at this https URL\n",
    "authors": [
      "Alon Albalak",
      "Varun Embar",
      "Yi-Lin Tuan",
      "Lise Getoor",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05126"
  },
  {
    "id": "arXiv:2109.09519",
    "title": "PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation",
    "abstract": "Comments: Findings of AACL-IJCNLP 2022. First four authors contributed equally to this work",
    "descriptor": "\nComments: Findings of AACL-IJCNLP 2022. First four authors contributed equally to this work\n",
    "authors": [
      "Siqi Bao",
      "Huang He",
      "Fan Wang",
      "Hua Wu",
      "Haifeng Wang",
      "Wenquan Wu",
      "Zhihua Wu",
      "Zhen Guo",
      "Hua Lu",
      "Xinxian Huang",
      "Xin Tian",
      "Xinchao Xu",
      "Yingzhan Lin",
      "Zheng-Yu Niu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.09519"
  },
  {
    "id": "arXiv:2109.13016",
    "title": "Semi-Supervised Adversarial Discriminative Domain Adaptation",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Thai-Vu Nguyen",
      "Anh Nguyen",
      "Nghia Le",
      "Bac Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13016"
  },
  {
    "id": "arXiv:2110.05631",
    "title": "Reeb Graph Metrics from the Ground Up",
    "abstract": "Comments: 71 pages, 35 figures",
    "descriptor": "\nComments: 71 pages, 35 figures\n",
    "authors": [
      "Brian Bollen",
      "Erin Chambers",
      "Joshua A. Levine",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.05631"
  },
  {
    "id": "arXiv:2110.07511",
    "title": "Contrastive Proposal Extension with LSTM Network for Weakly Supervised  Object Detection",
    "abstract": "Comments: 15 pages,12 figures, accepted to IEEE Transactions on Image Processing",
    "descriptor": "\nComments: 15 pages,12 figures, accepted to IEEE Transactions on Image Processing\n",
    "authors": [
      "Pei Lv",
      "Suqi Hu",
      "Tianran Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07511"
  },
  {
    "id": "arXiv:2110.08247",
    "title": "Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks",
    "abstract": "Comments: Accepted to EMNLP 2022, main conference",
    "descriptor": "\nComments: Accepted to EMNLP 2022, main conference\n",
    "authors": [
      "Yangyi Chen",
      "Fanchao Qi",
      "Hongcheng Gao",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08247"
  },
  {
    "id": "arXiv:2110.12087",
    "title": "Gaussian Process Sampling and Optimization with Approximate Upper and  Lower Bounds",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Vu Nguyen",
      "Marc Peter Deisenroth",
      "Michael A. Osborne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12087"
  },
  {
    "id": "arXiv:2111.10962",
    "title": "Enhancing Multilingual Language Model with Massive Multilingual  Knowledge Triples",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Linlin Liu",
      "Xin Li",
      "Ruidan He",
      "Lidong Bing",
      "Shafiq Joty",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10962"
  },
  {
    "id": "arXiv:2111.11821",
    "title": "Learning Representation for Clustering via Prototype Scattering and  Positive Sampling",
    "abstract": "Comments: Accepted by TPAMI 2022",
    "descriptor": "\nComments: Accepted by TPAMI 2022\n",
    "authors": [
      "Zhizhong Huang",
      "Jie Chen",
      "Junping Zhang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11821"
  },
  {
    "id": "arXiv:2111.13839",
    "title": "Towards Principled Disentanglement for Domain Generalization",
    "abstract": "Comments: CVPR 2022 Oral",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Hanlin Zhang",
      "Yi-Fan Zhang",
      "Weiyang Liu",
      "Adrian Weller",
      "Bernhard Sch\u00f6lkopf",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13839"
  },
  {
    "id": "arXiv:2112.04195",
    "title": "VIRT: Improving Representation-based Models for Text Matching through  Virtual Interaction",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Dan Li",
      "Yang Yang",
      "Hongyin Tang",
      "Jingang Wang",
      "Tong Xu",
      "Wei Wu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04195"
  },
  {
    "id": "arXiv:2112.09828",
    "title": "Exploiting Long-Term Dependencies for Generating Dynamic Scene Graphs",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Shengyu Feng",
      "Subarna Tripathi",
      "Hesham Mostafa",
      "Marcel Nassar",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09828"
  },
  {
    "id": "arXiv:2201.00122",
    "title": "A Relaxed Energy Function Based Analog Neural Network Approach to Target  Localization in Distributed MIMO Radar",
    "abstract": "A Relaxed Energy Function Based Analog Neural Network Approach to Target  Localization in Distributed MIMO Radar",
    "descriptor": "",
    "authors": [
      "Xiaoyu Zhao",
      "Jun Li",
      "Qinghua Guo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.00122"
  },
  {
    "id": "arXiv:2201.02494",
    "title": "Progressive Video Summarization via Multimodal Self-supervised Learning",
    "abstract": "Progressive Video Summarization via Multimodal Self-supervised Learning",
    "descriptor": "",
    "authors": [
      "Li Haopeng",
      "Ke Qiuhong",
      "Gong Mingming",
      "Tom Drummond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.02494"
  },
  {
    "id": "arXiv:2201.04429",
    "title": "Constraint Learning to Define Trust Regions in Predictive-Model Embedded  Optimization",
    "abstract": "Constraint Learning to Define Trust Regions in Predictive-Model Embedded  Optimization",
    "descriptor": "",
    "authors": [
      "Chenbo Shi",
      "Mohsen Emadikhiav",
      "Leonardo Lozano",
      "David Bergman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.04429"
  },
  {
    "id": "arXiv:2201.04968",
    "title": "A Graph-based Methodology for the Sensorless Estimation of Road Traffic  Profiles",
    "abstract": "Comments: 16 pages, 7 figures, 2 tables. Submitted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: 16 pages, 7 figures, 2 tables. Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Eric L. Manibardo",
      "Ibai La\u00f1a",
      "Esther Villar",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.04968"
  },
  {
    "id": "arXiv:2201.05465",
    "title": "Covering Many (or Few) Edges with k Vertices in Sparse Graphs",
    "abstract": "Comments: Extended abstract appeared in STACS '22",
    "descriptor": "\nComments: Extended abstract appeared in STACS '22\n",
    "authors": [
      "Tomohiro Koana",
      "Christian Komusiewicz",
      "Andr\u00e9 Nichterlein",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.05465"
  },
  {
    "id": "arXiv:2201.06025",
    "title": "COLD: A Benchmark for Chinese Offensive Language Detection",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Jiawen Deng",
      "Jingyan Zhou",
      "Hao Sun",
      "Chujie Zheng",
      "Fei Mi",
      "Helen Meng",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06025"
  },
  {
    "id": "arXiv:2201.07434",
    "title": "Interpreting Arabic Transformer Models",
    "abstract": "Comments: A new version of the paper was uploaded under a different reference: arXiv:2201.07434",
    "descriptor": "\nComments: A new version of the paper was uploaded under a different reference: arXiv:2201.07434\n",
    "authors": [
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Fahim Dalvi",
      "Hassan Sajjad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.07434"
  },
  {
    "id": "arXiv:2201.08520",
    "title": "Learning Two-Step Hybrid Policy for Graph-Based Interpretable  Reinforcement Learning",
    "abstract": "Comments: Transactions on Machine Learning Research (TMLR)",
    "descriptor": "\nComments: Transactions on Machine Learning Research (TMLR)\n",
    "authors": [
      "Tongzhou Mu",
      "Kaixiang Lin",
      "Feiyang Niu",
      "Govind Thattai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08520"
  },
  {
    "id": "arXiv:2201.10072",
    "title": "A Regularity Theory for Static Schr\u00f6dinger Equations on $\\mathbb{R}^d$  in Spectral Barron Spaces",
    "abstract": "A Regularity Theory for Static Schr\u00f6dinger Equations on $\\mathbb{R}^d$  in Spectral Barron Spaces",
    "descriptor": "",
    "authors": [
      "Ziang Chen",
      "Jianfeng Lu",
      "Yulong Lu",
      "Shengxuan Zhou"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10072"
  },
  {
    "id": "arXiv:2201.10154",
    "title": "Neural Information Squeezer for Causal Emergence",
    "abstract": "Comments: 33 pages, 9 figures",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "Jiang Zhang",
      "Kaiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.10154"
  },
  {
    "id": "arXiv:2201.10206",
    "title": "A fully adaptive explicit stabilized integrator for  advection-diffusion-reaction problems",
    "abstract": "A fully adaptive explicit stabilized integrator for  advection-diffusion-reaction problems",
    "descriptor": "",
    "authors": [
      "Ibrahim Almuslimani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.10206"
  },
  {
    "id": "arXiv:2201.10866",
    "title": "CodeRetriever: Unimodal and Bimodal Contrastive Learning for Code Search",
    "abstract": "Comments: Accepted to EMNLP 2022 (main conference)",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (main conference)\n",
    "authors": [
      "Xiaonan Li",
      "Yeyun Gong",
      "Yelong Shen",
      "Xipeng Qiu",
      "Hang Zhang",
      "Bolun Yao",
      "Weizhen Qi",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.10866"
  },
  {
    "id": "arXiv:2201.11079",
    "title": "Orienteering with one endomorphism",
    "abstract": "Comments: 40 pages, 1 figure; 3rd revision implements small corrections and expositional improvements",
    "descriptor": "\nComments: 40 pages, 1 figure; 3rd revision implements small corrections and expositional improvements\n",
    "authors": [
      "Sarah Arpin",
      "Mingjie Chen",
      "Kristin E. Lauter",
      "Renate Scheidler",
      "Katherine E. Stange",
      "Ha T. N. Tran"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11079"
  },
  {
    "id": "arXiv:2201.11706",
    "title": "A Systematic Study of Bias Amplification",
    "abstract": "A Systematic Study of Bias Amplification",
    "descriptor": "",
    "authors": [
      "Melissa Hall",
      "Laurens van der Maaten",
      "Laura Gustafson",
      "Maxwell Jones",
      "Aaron Adcock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11706"
  },
  {
    "id": "arXiv:2201.12093",
    "title": "PCL: Peer-Contrastive Learning with Diverse Augmentations for  Unsupervised Sentence Embeddings",
    "abstract": "Comments: To appear at EMNLP 2022",
    "descriptor": "\nComments: To appear at EMNLP 2022\n",
    "authors": [
      "Qiyu Wu",
      "Chongyang Tao",
      "Tao Shen",
      "Can Xu",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12093"
  },
  {
    "id": "arXiv:2201.12543",
    "title": "Fast Differentiable Matrix Square Root and Inverse Square Root",
    "abstract": "Comments: T-PAMI 2022. arXiv admin note: substantial text overlap with arXiv:2201.08663",
    "descriptor": "\nComments: T-PAMI 2022. arXiv admin note: substantial text overlap with arXiv:2201.08663\n",
    "authors": [
      "Yue Song",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12543"
  },
  {
    "id": "arXiv:2201.13027",
    "title": "BOAT: Bilateral Local Attention Vision Transformer",
    "abstract": "Comments: BMVC2022 oral",
    "descriptor": "\nComments: BMVC2022 oral\n",
    "authors": [
      "Tan Yu",
      "Gangming Zhao",
      "Ping Li",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13027"
  },
  {
    "id": "arXiv:2202.04428",
    "title": "Adapting to Mixing Time in Stochastic Optimization with Markovian Data",
    "abstract": "Comments: ICML 2022. Code: this https URL",
    "descriptor": "\nComments: ICML 2022. Code: this https URL\n",
    "authors": [
      "Ron Dorfman",
      "Kfir Y. Levy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04428"
  },
  {
    "id": "arXiv:2202.04982",
    "title": "A Robust Version of Heged\u0171s's Lemma, with Applications",
    "abstract": "Comments: Published in STOC 2020. Changed affiliation in v2. v3: Revised in accordance with comments from referees for TheoretiCS",
    "descriptor": "\nComments: Published in STOC 2020. Changed affiliation in v2. v3: Revised in accordance with comments from referees for TheoretiCS\n",
    "authors": [
      "Srikanth Srinivasan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04982"
  },
  {
    "id": "arXiv:2202.06671",
    "title": "Neighborhood Contrastive Learning for Scientific Document  Representations with Citation Embeddings",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Malte Ostendorff",
      "Nils Rethmeier",
      "Isabelle Augenstein",
      "Bela Gipp",
      "Georg Rehm"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06671"
  },
  {
    "id": "arXiv:2202.06881",
    "title": "Active Surrogate Estimators: An Active Learning Approach to  Label-Efficient Model Evaluation",
    "abstract": "Comments: Accepted for publication at NeurIPS 2022",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2022\n",
    "authors": [
      "Jannik Kossen",
      "Sebastian Farquhar",
      "Yarin Gal",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06881"
  },
  {
    "id": "arXiv:2202.07280",
    "title": "Saving Dense Retriever from Shortcut Dependency in Conversational Search",
    "abstract": "Comments: Accepted to EMNLP 2022 main conference",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Sungdong Kim",
      "Gangwoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07280"
  },
  {
    "id": "arXiv:2202.07530",
    "title": "Optimal Algorithms for Stochastic Multi-Level Compositional Optimization",
    "abstract": "Optimal Algorithms for Stochastic Multi-Level Compositional Optimization",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Bokun Wang",
      "Yibo Wang",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07530"
  },
  {
    "id": "arXiv:2202.08827",
    "title": "LAMP: Extracting Text from Gradients with Language Model Priors",
    "abstract": "LAMP: Extracting Text from Gradients with Language Model Priors",
    "descriptor": "",
    "authors": [
      "Mislav Balunovi\u0107",
      "Dimitar I. Dimitrov",
      "Nikola Jovanovi\u0107",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08827"
  },
  {
    "id": "arXiv:2202.11701",
    "title": "Super-resolution GANs of randomly-seeded fields",
    "abstract": "Super-resolution GANs of randomly-seeded fields",
    "descriptor": "",
    "authors": [
      "Alejandro G\u00fcemes",
      "Carlos Sanmiguel Vila",
      "Stefano Discetti"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.11701"
  },
  {
    "id": "arXiv:2202.12832",
    "title": "Morphology Without Borders: Clause-Level Morphology",
    "abstract": "Comments: To appear on TACL",
    "descriptor": "\nComments: To appear on TACL\n",
    "authors": [
      "Omer Goldman",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12832"
  },
  {
    "id": "arXiv:2203.00830",
    "title": "Fast Object Inertial Parameter Identification for Collaborative Robots",
    "abstract": "Comments: In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA'22), Philadelphia, USA, May 23-27, 2022",
    "descriptor": "\nComments: In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA'22), Philadelphia, USA, May 23-27, 2022\n",
    "authors": [
      "Philippe Nadeau",
      "Matthew Giamou",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00830"
  },
  {
    "id": "arXiv:2203.01069",
    "title": "Enhanced Decentralized Autonomous Aerial Robot Teams with Group Planning",
    "abstract": "Comments: RAL with IROS2022",
    "descriptor": "\nComments: RAL with IROS2022\n",
    "authors": [
      "Jialiang Hou",
      "Xin Zhou",
      "Zhongxue Gan",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01069"
  },
  {
    "id": "arXiv:2203.01902",
    "title": "Instance Segmentation for Autonomous Log Grasping in Forestry Operations",
    "abstract": "Comments: 8 pages, 6 figures, accepted at IROS 2022",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted at IROS 2022\n",
    "authors": [
      "Jean-Michel Fortin",
      "Olivier Gamache",
      "Vincent Grondin",
      "Fran\u00e7ois Pomerleau",
      "Philippe Gigu\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01902"
  },
  {
    "id": "arXiv:2203.03404",
    "title": "Weak Muller Conditions Make Delay Games Hard",
    "abstract": "Weak Muller Conditions Make Delay Games Hard",
    "descriptor": "",
    "authors": [
      "Sarah Winter",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.03404"
  },
  {
    "id": "arXiv:2203.03716",
    "title": "Open-Ended Knowledge Tracing",
    "abstract": "Comments: This paper is accepted at EMNLP 2022",
    "descriptor": "\nComments: This paper is accepted at EMNLP 2022\n",
    "authors": [
      "Naiming Liu",
      "Zichao Wang",
      "Richard G. Baraniuk",
      "Andrew Lan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03716"
  },
  {
    "id": "arXiv:2203.03897",
    "title": "Geodesic Multi-Modal Mixup for Robust Fine-Tuning",
    "abstract": "Geodesic Multi-Modal Mixup for Robust Fine-Tuning",
    "descriptor": "",
    "authors": [
      "Junhyuk So",
      "Changdae Oh",
      "Yongtaek Lim",
      "Hoyoon Byun",
      "Minchul Shin",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03897"
  },
  {
    "id": "arXiv:2203.04176",
    "title": "Variational methods for simulation-based inference",
    "abstract": "Variational methods for simulation-based inference",
    "descriptor": "",
    "authors": [
      "Manuel Gl\u00f6ckler",
      "Michael Deistler",
      "Jakob H. Macke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04176"
  },
  {
    "id": "arXiv:2203.05096",
    "title": "Heterogeneous Sparse Matrix-Vector Multiplication via Compressed Sparse  Row Format",
    "abstract": "Comments: 14 pages, intended for submission to the Journal of Parallel Computing, 17 figures, 4 listings, 2 tables",
    "descriptor": "\nComments: 14 pages, intended for submission to the Journal of Parallel Computing, 17 figures, 4 listings, 2 tables\n",
    "authors": [
      "Phillip Allen Lane",
      "Joshua Dennis Booth"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.05096"
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave",
    "abstract": "Theory of Network Wave",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05241"
  },
  {
    "id": "arXiv:2203.05285",
    "title": "Breaking the Curse of Dimensionality in Multiagent State Space: A  Unified Agent Permutation Framework",
    "abstract": "Breaking the Curse of Dimensionality in Multiagent State Space: A  Unified Agent Permutation Framework",
    "descriptor": "",
    "authors": [
      "Xiaotian Hao",
      "Hangyu Mao",
      "Weixun Wang",
      "Yaodong Yang",
      "Dong Li",
      "Yan Zheng",
      "Zhen Wang",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.05285"
  },
  {
    "id": "arXiv:2203.08060",
    "title": "Seeking Commonness and Inconsistencies: A Jointly Smoothed Approach to  Multi-view Subspace Clustering",
    "abstract": "Comments: To appear in Information Fusion",
    "descriptor": "\nComments: To appear in Information Fusion\n",
    "authors": [
      "Xiaosha Cai",
      "Dong Huang",
      "Guang-Yu Zhang",
      "Chang-Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08060"
  },
  {
    "id": "arXiv:2203.10206",
    "title": "Incentive Compatibility in Two-Stage Repeated Stochastic Games",
    "abstract": "Incentive Compatibility in Two-Stage Repeated Stochastic Games",
    "descriptor": "",
    "authors": [
      "Bharadwaj Satchidanandan",
      "Munther A. Dahleh"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.10206"
  },
  {
    "id": "arXiv:2203.10794",
    "title": "Human-Centric Artificial Intelligence Architecture for Industry 5.0  Applications",
    "abstract": "Human-Centric Artificial Intelligence Architecture for Industry 5.0  Applications",
    "descriptor": "",
    "authors": [
      "Jo\u017ee M. Ro\u017eanec",
      "Inna Novalija",
      "Patrik Zajec",
      "Klemen Kenda",
      "Hooman Tavakoli",
      "Sungho Suh",
      "Entso Veliou",
      "Dimitrios Papamartzivanos",
      "Thanassis Giannetsos",
      "Sofia Anna Menesidou",
      "Ruben Alonso",
      "Nino Cauli",
      "Antonello Meloni",
      "Diego Reforgiato Recupero",
      "Dimosthenis Kyriazis",
      "Georgios Sofianidis",
      "Spyros Theodoropoulos",
      "Bla\u017e Fortuna",
      "Dunja Mladeni\u0107",
      "John Soldatos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10794"
  },
  {
    "id": "arXiv:2203.11752",
    "title": "COSTARICA estimator for rollback-less systems handling in iterative  co-simulation algorithms",
    "abstract": "COSTARICA estimator for rollback-less systems handling in iterative  co-simulation algorithms",
    "descriptor": "",
    "authors": [
      "Yohan Eguillon",
      "Bruno Lacabanne",
      "Damien Tromeur-Dervout"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11752"
  },
  {
    "id": "arXiv:2203.15191",
    "title": "Idea and Theory of Particle Access",
    "abstract": "Idea and Theory of Particle Access",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Ke Sun",
      "Zhongjiang Yan",
      "Mao Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15191"
  },
  {
    "id": "arXiv:2203.15335",
    "title": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "abstract": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "descriptor": "",
    "authors": [
      "Danial Ebrat",
      "Farzad Didehvar",
      "Milad Dadgar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15335"
  },
  {
    "id": "arXiv:2204.01084",
    "title": "On Polynomially Solvable Constrained Input Selections for Fixed and  Switched Linear Structured Systems",
    "abstract": "Comments: Extended version of an IEEE CDC 2022 paper",
    "descriptor": "\nComments: Extended version of an IEEE CDC 2022 paper\n",
    "authors": [
      "Yuan Zhang",
      "Yuanqing Xia",
      "Shenyu Liu",
      "Zhongqi Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.01084"
  },
  {
    "id": "arXiv:2204.04392",
    "title": "Contrastive Demonstration Tuning for Pre-trained Language Models",
    "abstract": "Comments: Accepted to EMNLP 2022(Findings)",
    "descriptor": "\nComments: Accepted to EMNLP 2022(Findings)\n",
    "authors": [
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Siyuan Cheng",
      "Zhenru Zhang",
      "Chuanqi Tan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04392"
  },
  {
    "id": "arXiv:2204.04656",
    "title": "Video K-Net: A Simple, Strong, and Unified Baseline for Video  Segmentation",
    "abstract": "Comments: Accepted by CVPR-2022(oral); Add more experiments. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by CVPR-2022(oral); Add more experiments. Code is available at this https URL\n",
    "authors": [
      "Xiangtai Li",
      "Wenwei Zhang",
      "Jiangmiao Pang",
      "Kai Chen",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04656"
  },
  {
    "id": "arXiv:2204.06607",
    "title": "Towards Metrical Reconstruction of Human Faces",
    "abstract": "Comments: Video: this https URL Website: this https URL Accepted to ECCV 2022",
    "descriptor": "\nComments: Video: this https URL Website: this https URL Accepted to ECCV 2022\n",
    "authors": [
      "Wojciech Zielonka",
      "Timo Bolkart",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06607"
  },
  {
    "id": "arXiv:2204.08140",
    "title": "Pricing Real-time Stochastic Storage Operations",
    "abstract": "Comments: 8 pages, 4 figures, 2022 Power Systems Computation Conference (PSCC)",
    "descriptor": "\nComments: 8 pages, 4 figures, 2022 Power Systems Computation Conference (PSCC)\n",
    "authors": [
      "Cong Chen",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08140"
  },
  {
    "id": "arXiv:2204.09162",
    "title": "Computational Adaptation of XR Interfaces Through Interaction Simulation",
    "abstract": "Comments: 5 pages, 1 figure, 1 table. CHI 2022 Workshop on Computational Approaches for Understanding, Generating, and Adapting User Interfaces",
    "descriptor": "\nComments: 5 pages, 1 figure, 1 table. CHI 2022 Workshop on Computational Approaches for Understanding, Generating, and Adapting User Interfaces\n",
    "authors": [
      "Kashyap Todi",
      "Ben Lafreniere",
      "Tanya Jonker"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09162"
  },
  {
    "id": "arXiv:2204.10293",
    "title": "A Hierarchical N-Gram Framework for Zero-Shot Link Prediction",
    "abstract": "Comments: Published as a conference paper at EMNLP Findings 2022",
    "descriptor": "\nComments: Published as a conference paper at EMNLP Findings 2022\n",
    "authors": [
      "Mingchen Li",
      "Junfan Chen",
      "Samuel Mensah",
      "Nikolaos Aletras",
      "Xiulong Yang",
      "Yang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10293"
  },
  {
    "id": "arXiv:2204.10414",
    "title": "A Deep Top-Down Approach to Hierarchically Coherent Probabilistic  Forecasting",
    "abstract": "A Deep Top-Down Approach to Hierarchically Coherent Probabilistic  Forecasting",
    "descriptor": "",
    "authors": [
      "Abhimanyu Das",
      "Weihao Kong",
      "Biswajit Paria",
      "Rajat Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.10414"
  },
  {
    "id": "arXiv:2204.13103",
    "title": "FlowGNN: A Dataflow Architecture for Real-Time Workload-Agnostic Graph  Neural Network Inference",
    "abstract": "Comments: 13 pages, 10 figures. Accepted at HPCA 2023",
    "descriptor": "\nComments: 13 pages, 10 figures. Accepted at HPCA 2023\n",
    "authors": [
      "Rishov Sarkar",
      "Stefan Abi-Karam",
      "Yuqi He",
      "Lakshmi Sathidevi",
      "Cong Hao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13103"
  },
  {
    "id": "arXiv:2204.13692",
    "title": "NMTScore: A Multilingual Analysis of Translation-based Text Similarity  Measures",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Jannis Vamvas",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.13692"
  },
  {
    "id": "arXiv:2205.00135",
    "title": "Failing to hash into supersingular isogeny graphs",
    "abstract": "Comments: 33 pages, 7 figures",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Jeremy Booher",
      "Ross Bowden",
      "Javad Doliskani",
      "Tako Boris Fouotsa",
      "Steven D. Galbraith",
      "Sabrina Kunzweiler",
      "Simon-Philipp Merz",
      "Christophe Petit",
      "Benjamin Smith",
      "Katherine E. Stange",
      "Yan Bo Ti",
      "Christelle Vincent",
      "Jos\u00e9 Felipe Voloch",
      "Charlotte Weitk\u00e4mper",
      "Lukas Zobernig"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.00135"
  },
  {
    "id": "arXiv:2205.01620",
    "title": "Unifying the Convergences in Multilingual Neural Machine Translation",
    "abstract": "Comments: EMNLP2022",
    "descriptor": "\nComments: EMNLP2022\n",
    "authors": [
      "Yichong Huang",
      "Xiaocheng Feng",
      "Xinwei Geng",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01620"
  },
  {
    "id": "arXiv:2205.05835",
    "title": "Assessment of an energy-based surface tension model for simulation of  two-phase flows using second-order phase field methods",
    "abstract": "Comments: 13 pages, 5 figures, Revision submitted to Journal of Computational Physics",
    "descriptor": "\nComments: 13 pages, 5 figures, Revision submitted to Journal of Computational Physics\n",
    "authors": [
      "Shahab Mirjalili",
      "Makrand A Khanwale",
      "Ali Mani"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.05835"
  },
  {
    "id": "arXiv:2205.11380",
    "title": "Outliers Dimensions that Disrupt Transformers Are Driven by Frequency",
    "abstract": "Comments: To appear in Findings of EMNLP 2022",
    "descriptor": "\nComments: To appear in Findings of EMNLP 2022\n",
    "authors": [
      "Giovanni Puccetti",
      "Anna Rogers",
      "Aleksandr Drozd",
      "Felice Dell'Orletta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11380"
  },
  {
    "id": "arXiv:2205.12101",
    "title": "Empirical Phase Diagram for Three-layer Neural Networks with Infinite  Width",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2007.07497",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.07497\n",
    "authors": [
      "Hanxu Zhou",
      "Qixuan Zhou",
      "Zhenyuan Jin",
      "Tao Luo",
      "Yaoyu Zhang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12101"
  },
  {
    "id": "arXiv:2205.12393",
    "title": "Fine-tuned Language Models are Continual Learners",
    "abstract": "Fine-tuned Language Models are Continual Learners",
    "descriptor": "",
    "authors": [
      "Thomas Scialom",
      "Tuhin Chakrabarty",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12393"
  },
  {
    "id": "arXiv:2205.12986",
    "title": "Transcormer: Transformer for Sentence Scoring with Sliding Language  Modeling",
    "abstract": "Transcormer: Transformer for Sentence Scoring with Sliding Language  Modeling",
    "descriptor": "",
    "authors": [
      "Kaitao Song",
      "Yichong Leng",
      "Xu Tan",
      "Yicheng Zou",
      "Tao Qin",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12986"
  },
  {
    "id": "arXiv:2205.13623",
    "title": "Hybrid Neural Autoencoders for Stimulus Encoding in Visual and Other  Sensory Neuroprostheses",
    "abstract": "Comments: NeurIPS 2022 camera ready revision",
    "descriptor": "\nComments: NeurIPS 2022 camera ready revision\n",
    "authors": [
      "Jacob Granley",
      "Lucas Relic",
      "Michael Beyeler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13623"
  },
  {
    "id": "arXiv:2205.14108",
    "title": "Scalable Interpretability via Polynomials",
    "abstract": "Comments: 26 pages including appendix. v2 includes source code link at this https URL, v3 fixes to baseline results in Table 1, v4 update for NeurIPS camera ready",
    "descriptor": "\nComments: 26 pages including appendix. v2 includes source code link at this https URL, v3 fixes to baseline results in Table 1, v4 update for NeurIPS camera ready\n",
    "authors": [
      "Abhimanyu Dubey",
      "Filip Radenovic",
      "Dhruv Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14108"
  },
  {
    "id": "arXiv:2205.14120",
    "title": "Neural Basis Models for Interpretability",
    "abstract": "Comments: 17 pages including appendix. v2 includes link to source code available at this https URL v3 includes updates to baseline results, v4 updated for NeurIPS camera ready",
    "descriptor": "\nComments: 17 pages including appendix. v2 includes link to source code available at this https URL v3 includes updates to baseline results, v4 updated for NeurIPS camera ready\n",
    "authors": [
      "Filip Radenovic",
      "Abhimanyu Dubey",
      "Dhruv Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14120"
  },
  {
    "id": "arXiv:2205.15759",
    "title": "Hierarchically Constrained Adaptive Ad Exposure in Feeds",
    "abstract": "Comments: In Proceedings of the 31st ACM International Conference on Information and Knowledge Management (CIKM '22)",
    "descriptor": "\nComments: In Proceedings of the 31st ACM International Conference on Information and Knowledge Management (CIKM '22)\n",
    "authors": [
      "Dagui Chen",
      "Qi Yan",
      "Chunjie Chen",
      "Zhenzhe Zheng",
      "Yangsu Liu",
      "Zhenjia Ma",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.15759"
  },
  {
    "id": "arXiv:2206.00363",
    "title": "Bring Your Own Algorithm for Optimal Differentially Private Stochastic  Minimax Optimization",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Liang Zhang",
      "Kiran Koshy Thekumparampil",
      "Sewoong Oh",
      "Niao He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00363"
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "Comments: I should have updated 2102.08581 instead of 2206.00518, but I made a mistake",
    "descriptor": "\nComments: I should have updated 2102.08581 instead of 2206.00518, but I made a mistake\n",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00518"
  },
  {
    "id": "arXiv:2206.00626",
    "title": "Regular Convergence and Finite Element Methods for Eigenvalue Problems",
    "abstract": "Regular Convergence and Finite Element Methods for Eigenvalue Problems",
    "descriptor": "",
    "authors": [
      "Bo Gong",
      "Jiguang Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00626"
  },
  {
    "id": "arXiv:2206.02845",
    "title": "On Efficient Approximate Queries over Machine Learning Models",
    "abstract": "Comments: Submitted to VLDB 2023, 16 pages, 15 figures; Under Revision",
    "descriptor": "\nComments: Submitted to VLDB 2023, 16 pages, 15 figures; Under Revision\n",
    "authors": [
      "Dujian Ding",
      "Sihem Amer-Yahia",
      "Laks VS Lakshmanan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02845"
  },
  {
    "id": "arXiv:2206.03907",
    "title": "A Unified Convergence Theorem for Stochastic Optimization Methods",
    "abstract": "Comments: Accepted in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Xiao Li",
      "Andre Milzarek"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03907"
  },
  {
    "id": "arXiv:2206.04426",
    "title": "Biologically Inspired Dynamic Thresholds for Spiking Neural Networks",
    "abstract": "Biologically Inspired Dynamic Thresholds for Spiking Neural Networks",
    "descriptor": "",
    "authors": [
      "Jianchuan Ding",
      "Bo Dong",
      "Felix Heide",
      "Yufei Ding",
      "Yunduo Zhou",
      "Baocai Yin",
      "Xin Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04426"
  },
  {
    "id": "arXiv:2206.07647",
    "title": "Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a  Scalable Hyper-Ensemble Solution",
    "abstract": "Comments: 19 pages, The code is available at: this https URL",
    "descriptor": "\nComments: 19 pages, The code is available at: this https URL\n",
    "authors": [
      "Xueying Ding",
      "Lingxiao Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.07647"
  },
  {
    "id": "arXiv:2206.08091",
    "title": "Unsupervised Space Partitioning for Nearest Neighbor Search",
    "abstract": "Comments: To be published in Proceedings of the 26th International Conference on Extending Database Technology (EDBT), 28th March-31st March, 2023",
    "descriptor": "\nComments: To be published in Proceedings of the 26th International Conference on Extending Database Technology (EDBT), 28th March-31st March, 2023\n",
    "authors": [
      "Abrar Fahim",
      "Mohammed Eunus Ali",
      "Muhammad Aamir Cheema"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08091"
  },
  {
    "id": "arXiv:2206.10044",
    "title": "Identifiability of deep generative models without auxiliary information",
    "abstract": "Comments: 34 pages, 9 figures, to appear in NeurIPS 2022",
    "descriptor": "\nComments: 34 pages, 9 figures, to appear in NeurIPS 2022\n",
    "authors": [
      "Bohdan Kivva",
      "Goutham Rajendran",
      "Pradeep Ravikumar",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10044"
  },
  {
    "id": "arXiv:2206.11699",
    "title": "The SJTU X-LANCE Lab System for CNSRC 2022",
    "abstract": "The SJTU X-LANCE Lab System for CNSRC 2022",
    "descriptor": "",
    "authors": [
      "Zhengyang Chen",
      "Bei Liu",
      "Bing Han",
      "Leying Zhang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.11699"
  },
  {
    "id": "arXiv:2206.12654",
    "title": "BackdoorBench: A Comprehensive Benchmark of Backdoor Learning",
    "abstract": "Comments: Accepted at NeurIPS 2022 Datasets and Benchmarks Track; 44 pages; 8 backdoor attacks; 9 backdoor defenses; 8,000 pairs of attack-defense evaluations; several analysis and 5 analysis tools",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Datasets and Benchmarks Track; 44 pages; 8 backdoor attacks; 9 backdoor defenses; 8,000 pairs of attack-defense evaluations; several analysis and 5 analysis tools\n",
    "authors": [
      "Baoyuan Wu",
      "Hongrui Chen",
      "Mingda Zhang",
      "Zihao Zhu",
      "Shaokui Wei",
      "Danni Yuan",
      "Chao Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12654"
  },
  {
    "id": "arXiv:2206.13974",
    "title": "Joint Generator-Ranker Learning for Natural Language Generation",
    "abstract": "Comments: In progress",
    "descriptor": "\nComments: In progress\n",
    "authors": [
      "Weizhou Shen",
      "Yeyun Gong",
      "Yelong Shen",
      "Song Wang",
      "Xiaojun Quan",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13974"
  },
  {
    "id": "arXiv:2207.00182",
    "title": "Recovering Detail in 3D Shapes Using Disparity Maps",
    "abstract": "Recovering Detail in 3D Shapes Using Disparity Maps",
    "descriptor": "",
    "authors": [
      "Marissa Ramirez de Chanlatte",
      "Matheus Gadelha",
      "Thibault Groueix",
      "Radomir Mech"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00182"
  },
  {
    "id": "arXiv:2207.02556",
    "title": "Deep Learning Approaches to Grasp Synthesis: A Review",
    "abstract": "Comments: 21 pages. Submitted to T-RO",
    "descriptor": "\nComments: 21 pages. Submitted to T-RO\n",
    "authors": [
      "Rhys Newbury",
      "Morris Gu",
      "Lachlan Chumbley",
      "Arsalan Mousavian",
      "Clemens Eppner",
      "J\u00fcrgen Leitner",
      "Jeannette Bohg",
      "Antonio Morales",
      "Tamim Asfour",
      "Danica Kragic",
      "Dieter Fox",
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.02556"
  },
  {
    "id": "arXiv:2207.04044",
    "title": "k-means Mask Transformer",
    "abstract": "Comments: ECCV 2022. arXiv v2: add results on ADE20K. Codes and models are available at this https URL",
    "descriptor": "\nComments: ECCV 2022. arXiv v2: add results on ADE20K. Codes and models are available at this https URL\n",
    "authors": [
      "Qihang Yu",
      "Huiyu Wang",
      "Siyuan Qiao",
      "Maxwell Collins",
      "Yukun Zhu",
      "Hartwig Adam",
      "Alan Yuille",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04044"
  },
  {
    "id": "arXiv:2207.04394",
    "title": "Radiomics-Guided Global-Local Transformer for Weakly Supervised  Pathology Localization in Chest X-Rays",
    "abstract": "Radiomics-Guided Global-Local Transformer for Weakly Supervised  Pathology Localization in Chest X-Rays",
    "descriptor": "",
    "authors": [
      "Yan Han",
      "Gregory Holste",
      "Ying Ding",
      "Ahmed Tewfik",
      "Yifan Peng",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04394"
  },
  {
    "id": "arXiv:2207.05549",
    "title": "PoeticTTS -- Controllable Poetry Reading for Literary Studies",
    "abstract": "Comments: Presented at Interspeech 2022",
    "descriptor": "\nComments: Presented at Interspeech 2022\n",
    "authors": [
      "Julia Koch",
      "Florian Lux",
      "Nadja Schauffler",
      "Toni Bernhart",
      "Felix Dieterle",
      "Jonas Kuhn",
      "Sandra Richter",
      "Gabriel Viehhauser",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.05549"
  },
  {
    "id": "arXiv:2207.05843",
    "title": "A new hope for network model generalization",
    "abstract": "Comments: 6 pages (without references)",
    "descriptor": "\nComments: 6 pages (without references)\n",
    "authors": [
      "Alexander Dietm\u00fcller",
      "Siddhant Ray",
      "Romain Jacob",
      "Laurent Vanbever"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05843"
  },
  {
    "id": "arXiv:2207.08540",
    "title": "Multi-block-Single-probe Variance Reduced Estimator for Coupled  Compositional Optimization",
    "abstract": "Multi-block-Single-probe Variance Reduced Estimator for Coupled  Compositional Optimization",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Gang Li",
      "Yibo Wang",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.08540"
  },
  {
    "id": "arXiv:2207.10896",
    "title": "Privacy and Transparency in Graph Machine Learning: A Unified  Perspective",
    "abstract": "Comments: In Advances in Interpretable Machine Learning and Artificial Intelligence (AIMLAI) at International Conference on Information and Knowledge Management (CIKM'22)",
    "descriptor": "\nComments: In Advances in Interpretable Machine Learning and Artificial Intelligence (AIMLAI) at International Conference on Information and Knowledge Management (CIKM'22)\n",
    "authors": [
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10896"
  },
  {
    "id": "arXiv:2207.12043",
    "title": "Representational Ethical Model Calibration",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Robert Carruthers",
      "Isabel Straw",
      "James K Ruffle",
      "Daniel Herron",
      "Amy Nelson",
      "Danilo Bzdok",
      "Delmiro Fernandez-Reyes",
      "Geraint Rees",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.12043"
  },
  {
    "id": "arXiv:2208.00116",
    "title": "Adaptive Feature Fusion for Cooperative Perception using LiDAR Point  Clouds",
    "abstract": "Comments: Accepted by WACV2022",
    "descriptor": "\nComments: Accepted by WACV2022\n",
    "authors": [
      "Donghao Qiao",
      "Farhana Zulkernine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.00116"
  },
  {
    "id": "arXiv:2208.01685",
    "title": "Differentiable Subdivision Surface Fitting",
    "abstract": "Differentiable Subdivision Surface Fitting",
    "descriptor": "",
    "authors": [
      "Tianhao Xie"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.01685"
  },
  {
    "id": "arXiv:2208.03309",
    "title": "Lethal Dose Conjecture on Data Poisoning",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Wenxiao Wang",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.03309"
  },
  {
    "id": "arXiv:2208.03605",
    "title": "An FPGA framework for Interferometric Vision-Based Navigation (iVisNav)",
    "abstract": "Comments: Replacement comments: 1. added information on timing and latency, 2. corrected error percentages in results, 3. corrected typos, 4. Plots and results unchanged",
    "descriptor": "\nComments: Replacement comments: 1. added information on timing and latency, 2. corrected error percentages in results, 3. corrected typos, 4. Plots and results unchanged\n",
    "authors": [
      "Ramchander Rao Bhaskara",
      "Kookjin Sung",
      "Manoranjan Majji"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.03605"
  },
  {
    "id": "arXiv:2208.04593",
    "title": "Robust Output Feedback Control Design in the Presence of Sporadic  Measurements",
    "abstract": "Comments: Extended version of the paper accepted for publication in the IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Extended version of the paper accepted for publication in the IEEE Transactions on Automatic Control\n",
    "authors": [
      "Roberto Merco",
      "Francesco Ferrante",
      "Ricardo G. Sanfelice",
      "Pierluigi Pisu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.04593"
  },
  {
    "id": "arXiv:2208.07369",
    "title": "Cellular liberality is measurable as Lempel-Ziv complexity of fastq  files",
    "abstract": "Comments: 6 pages, single table, 4 figures",
    "descriptor": "\nComments: 6 pages, single table, 4 figures\n",
    "authors": [
      "Norichika Ogata",
      "Aoi Hosaka"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.07369"
  },
  {
    "id": "arXiv:2208.07903",
    "title": "Casual Indoor HDR Radiance Capture from Omnidirectional Images",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Pulkit Gera",
      "Mohammad Reza Karimi Dastjerdi",
      "Charles Renaud",
      "P. J. Narayanan",
      "Jean-Fran\u00e7ois Lalonde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07903"
  },
  {
    "id": "arXiv:2208.08701",
    "title": "Improved Distributed Algorithms for the Lov\u00e1sz Local Lemma and Edge  Coloring",
    "abstract": "Comments: Accepted at SODA 2023",
    "descriptor": "\nComments: Accepted at SODA 2023\n",
    "authors": [
      "Peter Davies"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.08701"
  },
  {
    "id": "arXiv:2208.10211",
    "title": "PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling",
    "abstract": "Comments: Accepted to TPAMI 2022",
    "descriptor": "\nComments: Accepted to TPAMI 2022\n",
    "authors": [
      "Fabien Baradel",
      "Romain Br\u00e9gier",
      "Thibault Groueix",
      "Philippe Weinzaepfel",
      "Yannis Kalantidis",
      "Gr\u00e9gory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10211"
  },
  {
    "id": "arXiv:2208.11474",
    "title": "Physics-Infused Reduced Order Modeling of Aerothermal Loads for  Hypersonic Aerothermoelastic Analysis",
    "abstract": "Physics-Infused Reduced Order Modeling of Aerothermal Loads for  Hypersonic Aerothermoelastic Analysis",
    "descriptor": "",
    "authors": [
      "Carlos Vargas Venegas",
      "Daning Huang"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.11474"
  },
  {
    "id": "arXiv:2208.11556",
    "title": "Knowledge-based and Data-driven Reasoning and Learning for Ad Hoc  Teamwork",
    "abstract": "Comments: Presented at the AI-HRI Symposium at AAAI Fall Symposium Series(FSS), 2022 (arXiv:cs/2209.14292)",
    "descriptor": "\nComments: Presented at the AI-HRI Symposium at AAAI Fall Symposium Series(FSS), 2022 (arXiv:cs/2209.14292)\n",
    "authors": [
      "Hasra Dodampegama",
      "Mohan Sridharan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.11556"
  },
  {
    "id": "arXiv:2208.12386",
    "title": "Swarm Analytics: Designing Information Markers to Characterise Swarm  Systems in Shepherding Contexts",
    "abstract": "Comments: 28 pages, 15 tables, 13 figures",
    "descriptor": "\nComments: 28 pages, 15 tables, 13 figures\n",
    "authors": [
      "Adam Hepworth",
      "Aya Hussein",
      "Darryn Reid",
      "Hussein Abbass"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.12386"
  },
  {
    "id": "arXiv:2208.14054",
    "title": "A greedy MOR method for the tracking of eigensolutions to parametric  elliptic PDEs",
    "abstract": "A greedy MOR method for the tracking of eigensolutions to parametric  elliptic PDEs",
    "descriptor": "",
    "authors": [
      "Moataz M. Alghamdi",
      "Daniele Boffi",
      "Francesca Bonizzoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.14054"
  },
  {
    "id": "arXiv:2209.00853",
    "title": "TarGF: Learning Target Gradient Field for Object Rearrangement",
    "abstract": "TarGF: Learning Target Gradient Field for Object Rearrangement",
    "descriptor": "",
    "authors": [
      "Mingdong Wu",
      "Fangwei Zhong",
      "Yulong Xia",
      "Hao Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.00853"
  },
  {
    "id": "arXiv:2209.01498",
    "title": "StreamNet: A WAE for White Matter Streamline Analysis",
    "abstract": "StreamNet: A WAE for White Matter Streamline Analysis",
    "descriptor": "",
    "authors": [
      "Andrew Lizarraga",
      "Katherine L. Narr",
      "Kirsten A. Donald",
      "Shantanu H. Joshi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.01498"
  },
  {
    "id": "arXiv:2209.03138",
    "title": "Treating Motion as Option to Reduce Motion Dependency in Unsupervised  Video Object Segmentation",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Chaewon Park",
      "Donghyeong Kim",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03138"
  },
  {
    "id": "arXiv:2209.04049",
    "title": "Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept  Statistics",
    "abstract": "Comments: 12 pages of main contents, 9 pages of appendix. It could also serve as an accompanying material for Latplan paper arXiv:2107.00110 v2: rewrote the general ELBO derivation without Prolog",
    "descriptor": "\nComments: 12 pages of main contents, 9 pages of appendix. It could also serve as an accompanying material for Latplan paper arXiv:2107.00110 v2: rewrote the general ELBO derivation without Prolog\n",
    "authors": [
      "Masataro Asai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04049"
  },
  {
    "id": "arXiv:2209.04477",
    "title": "Mixed $\\mathcal{H}_2/\\mathcal{H}_\\infty$ LQ Games for Robust Policy  Optimization Under Unknown Dynamics",
    "abstract": "Mixed $\\mathcal{H}_2/\\mathcal{H}_\\infty$ LQ Games for Robust Policy  Optimization Under Unknown Dynamics",
    "descriptor": "",
    "authors": [
      "Leilei Cui",
      "Lekan Molu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.04477"
  },
  {
    "id": "arXiv:2209.04610",
    "title": "Cache Refinement Type for Side-Channel Detection of Cryptographic  Software",
    "abstract": "Comments: Accepted by the 29th ACM Conference on Computer and Communications Security (CCS), 2022",
    "descriptor": "\nComments: Accepted by the 29th ACM Conference on Computer and Communications Security (CCS), 2022\n",
    "authors": [
      "Ke Jiang",
      "Yuyan Bao",
      "Shuai Wang",
      "Zhibo Liu",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.04610"
  },
  {
    "id": "arXiv:2209.04761",
    "title": "Testing Pre-trained Language Models' Understanding of Distributivity via  Causal Mediation Analysis",
    "abstract": "Comments: Accepted at BlackboxNLP 2022",
    "descriptor": "\nComments: Accepted at BlackboxNLP 2022\n",
    "authors": [
      "Pangbo Ban",
      "Yifan Jiang",
      "Tianran Liu",
      "Shane Steinert-Threlkeld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04761"
  },
  {
    "id": "arXiv:2209.05227",
    "title": "DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation  Framework for Efficient Device Model Generalization",
    "abstract": "DUET: A Tuning-Free Device-Cloud Collaborative Parameters Generation  Framework for Efficient Device Model Generalization",
    "descriptor": "",
    "authors": [
      "Zheqi Lv",
      "Wenqiao Zhang",
      "Shengyu Zhang",
      "Kun Kuang",
      "Feng Wang",
      "Yongwei Wang",
      "Zhengyu Chen",
      "Tao Shen",
      "Hongxia Yang",
      "Bengchin Ooi",
      "Fei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.05227"
  },
  {
    "id": "arXiv:2209.07921",
    "title": "ImDrug: A Benchmark for Deep Imbalanced Learning in AI-aided Drug  Discovery",
    "abstract": "Comments: 29 pages, 7 figures, 8 tables, a machine learning benchmark submission",
    "descriptor": "\nComments: 29 pages, 7 figures, 8 tables, a machine learning benchmark submission\n",
    "authors": [
      "Lanqing Li",
      "Liang Zeng",
      "Ziqi Gao",
      "Shen Yuan",
      "Yatao Bian",
      "Bingzhe Wu",
      "Hengtong Zhang",
      "Yang Yu",
      "Chan Lu",
      "Zhipeng Zhou",
      "Hongteng Xu",
      "Jia Li",
      "Peilin Zhao",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.07921"
  },
  {
    "id": "arXiv:2209.08465",
    "title": "Active Metric-Semantic Mapping by Multiple Aerial Robots",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Xu Liu",
      "Ankit Prabhu",
      "Fernando Cladera",
      "Ian D. Miller",
      "Lifeng Zhou",
      "Camillo J. Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.08465"
  },
  {
    "id": "arXiv:2209.09341",
    "title": "A Simple and Powerful Global Optimization for Unsupervised Video Object  Segmentation",
    "abstract": "Comments: Accepted to the IEEE Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Accepted to the IEEE Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Georgy Ponimatkin",
      "Nermin Samet",
      "Yang Xiao",
      "Yuming Du",
      "Renaud Marlet",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09341"
  },
  {
    "id": "arXiv:2209.10428",
    "title": "An NWDAF Approach to 5G Core Network Signaling Traffic: Analysis and  Characterization",
    "abstract": "Comments: Accepted in IEEE GlobeCom 2022",
    "descriptor": "\nComments: Accepted in IEEE GlobeCom 2022\n",
    "authors": [
      "Dimitrios Michael Manias",
      "Ali Chouman",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10428"
  },
  {
    "id": "arXiv:2209.10833",
    "title": "Physical Interaction: Reconstructing Hand-object Interactions with  Physics",
    "abstract": "Comments: Accepted to SIGGRAPH Asia 2022, Conference Track",
    "descriptor": "\nComments: Accepted to SIGGRAPH Asia 2022, Conference Track\n",
    "authors": [
      "Haoyu Hu",
      "Xinyu Yi",
      "Hao Zhang",
      "Jun-Hai Yong",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10833"
  },
  {
    "id": "arXiv:2209.14292",
    "title": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2022",
    "abstract": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2022",
    "descriptor": "",
    "authors": [
      "Zhao Han",
      "Emmanuel Senft",
      "Muneeb I. Ahmad",
      "Shelly Bagchi",
      "Amir Yazdani",
      "Jason R. Wilson",
      "Boyoung Kim",
      "Ruchen Wen",
      "Justin W. Hart",
      "Daniel Hern\u00e1ndez Garc\u00eda",
      "Matteo Leonetti",
      "Ross Mead",
      "Reuth Mirsky",
      "Ahalya Prabhakar",
      "Megan L. Zimmerman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.14292"
  },
  {
    "id": "arXiv:2209.15589",
    "title": "Where Should I Spend My FLOPS? Efficiency Evaluations of Visual  Pre-training Methods",
    "abstract": "Comments: 11 pages. 36th Conference on Neural Information Processing Systems, Workshop on Self-Supervised Learning (2022)",
    "descriptor": "\nComments: 11 pages. 36th Conference on Neural Information Processing Systems, Workshop on Self-Supervised Learning (2022)\n",
    "authors": [
      "Skanda Koppula",
      "Yazhe Li",
      "Evan Shelhamer",
      "Andrew Jaegle",
      "Nikhil Parthasarathy",
      "Relja Arandjelovic",
      "Jo\u00e3o Carreira",
      "Olivier H\u00e9naff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15589"
  },
  {
    "id": "arXiv:2210.00215",
    "title": "Differentiable Parsing and Visual Grounding of Verbal Instructions for  Object Placement",
    "abstract": "Comments: Submitted to ICRA 2023",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Zirui Zhao",
      "Wee Sun Lee",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00215"
  },
  {
    "id": "arXiv:2210.00301",
    "title": "Learning Globally Smooth Functions on Manifolds",
    "abstract": "Learning Globally Smooth Functions on Manifolds",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luiz F. O. Chamon",
      "Benjamin D. Haeffele",
      "Rene Vidal",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00301"
  },
  {
    "id": "arXiv:2210.00489",
    "title": "Unsupervised Multi-View Object Segmentation Using Radiance Field  Propagation",
    "abstract": "Comments: 23 pages, 14 figures, NeurIPS 2022",
    "descriptor": "\nComments: 23 pages, 14 figures, NeurIPS 2022\n",
    "authors": [
      "Xinhang Liu",
      "Jiaben Chen",
      "Huai Yu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00489"
  },
  {
    "id": "arXiv:2210.02541",
    "title": "Inserting or Stretching Points in Finite Difference Discretizations",
    "abstract": "Inserting or Stretching Points in Finite Difference Discretizations",
    "descriptor": "",
    "authors": [
      "Jherek Healy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.02541"
  },
  {
    "id": "arXiv:2210.02889",
    "title": "A Distributional Lens for Multi-Aspect Controllable Text Generation",
    "abstract": "Comments: 21pages, 21figures, EMNLP2022",
    "descriptor": "\nComments: 21pages, 21figures, EMNLP2022\n",
    "authors": [
      "Yuxuan Gu",
      "Xiaocheng Feng",
      "Sicheng Ma",
      "Lingyuan Zhang",
      "Heng Gong",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02889"
  },
  {
    "id": "arXiv:2210.03008",
    "title": "Residual-based error correction for neural operator accelerated  infinite-dimensional Bayesian inverse problems",
    "abstract": "Residual-based error correction for neural operator accelerated  infinite-dimensional Bayesian inverse problems",
    "descriptor": "",
    "authors": [
      "Lianghao Cao",
      "Thomas O'Leary-Roseberry",
      "Prashant K. Jha",
      "J. Tinsley Oden",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03008"
  },
  {
    "id": "arXiv:2210.03299",
    "title": "Topology-Preserving Segmentation Network",
    "abstract": "Topology-Preserving Segmentation Network",
    "descriptor": "",
    "authors": [
      "Han Zhang",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03299"
  },
  {
    "id": "arXiv:2210.03392",
    "title": "Latent Matrices for Tensor Network Decomposition and to Tensor  Completion",
    "abstract": "Latent Matrices for Tensor Network Decomposition and to Tensor  Completion",
    "descriptor": "",
    "authors": [
      "Peilin Yang",
      "Weijun Sun",
      "Qibin Zhao",
      "Guoxu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03392"
  },
  {
    "id": "arXiv:2210.04490",
    "title": "Semantic Framework based Query Generation for Temporal Question  Answering over Knowledge Graphs",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Weantao Ding",
      "Hao Chen",
      "Huayu Li",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04490"
  },
  {
    "id": "arXiv:2210.05298",
    "title": "Weakly-Supervised Optical Flow Estimation for Time-of-Flight",
    "abstract": "Comments: accepted at WACV 2023. The code, dataset and pretrained weights available at this https URL",
    "descriptor": "\nComments: accepted at WACV 2023. The code, dataset and pretrained weights available at this https URL\n",
    "authors": [
      "Michael Schelling",
      "Pedro Hermosilla",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.05298"
  },
  {
    "id": "arXiv:2210.05499",
    "title": "Capturing Global Structural Information in Long Document Question  Answering with Compressive Graph Selector Network",
    "abstract": "Comments: Accepted to the main conference of EMNLP 2022",
    "descriptor": "\nComments: Accepted to the main conference of EMNLP 2022\n",
    "authors": [
      "Yuxiang Nie",
      "Heyan Huang",
      "Wei Wei",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.05499"
  },
  {
    "id": "arXiv:2210.05610",
    "title": "MTet: Multi-domain Translation for English and Vietnamese",
    "abstract": "MTet: Multi-domain Translation for English and Vietnamese",
    "descriptor": "",
    "authors": [
      "Chinh Ngo",
      "Trieu H. Trinh",
      "Long Phan",
      "Hieu Tran",
      "Tai Dang",
      "Hieu Nguyen",
      "Minh Nguyen",
      "Minh-Thang Luong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.05610"
  },
  {
    "id": "arXiv:2210.05801",
    "title": "Linkless Link Prediction via Relational Distillation",
    "abstract": "Linkless Link Prediction via Relational Distillation",
    "descriptor": "",
    "authors": [
      "Zhichun Guo",
      "William Shiao",
      "Shichang Zhang",
      "Yozen Liu",
      "Nitesh Chawla",
      "Neil Shah",
      "Tong Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05801"
  },
  {
    "id": "arXiv:2210.06206",
    "title": "Parallel efficiency of monolithic and fixed-strain solution strategies  for poroelasticity problems",
    "abstract": "Parallel efficiency of monolithic and fixed-strain solution strategies  for poroelasticity problems",
    "descriptor": "",
    "authors": [
      "Denis Anuprienko"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.06206"
  },
  {
    "id": "arXiv:2210.06361",
    "title": "MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection",
    "abstract": "Comments: In Proceedings of the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)",
    "descriptor": "\nComments: In Proceedings of the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Dehua Zheng",
      "Xiaochen Zheng",
      "Laurence T. Yang",
      "Yuan Gao",
      "Chenlu Zhu",
      "Yiheng Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06361"
  },
  {
    "id": "arXiv:2210.06423",
    "title": "Foundation Transformers",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Hongyu Wang",
      "Shuming Ma",
      "Shaohan Huang",
      "Li Dong",
      "Wenhui Wang",
      "Zhiliang Peng",
      "Yu Wu",
      "Payal Bajaj",
      "Saksham Singhal",
      "Alon Benhaim",
      "Barun Patra",
      "Zhun Liu",
      "Vishrav Chaudhary",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06423"
  },
  {
    "id": "arXiv:2210.06659",
    "title": "Structural Pruning via Latency-Saliency Knapsack",
    "abstract": "Comments: Accepted by NeurIPS 2022. arXiv admin note: substantial text overlap with arXiv:2110.10811",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. arXiv admin note: substantial text overlap with arXiv:2110.10811\n",
    "authors": [
      "Maying Shen",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Lei Mao",
      "Jianna Liu",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06659"
  },
  {
    "id": "arXiv:2210.06694",
    "title": "SubeventWriter: Iterative Sub-event Sequence Generation with Coherence  Controller",
    "abstract": "Comments: Accepted to the main conference of EMNLP 2022",
    "descriptor": "\nComments: Accepted to the main conference of EMNLP 2022\n",
    "authors": [
      "Zhaowei Wang",
      "Hongming Zhang",
      "Tianqing Fang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06694"
  },
  {
    "id": "arXiv:2210.06884",
    "title": "Algorithms for Weighted Pushdown Automata",
    "abstract": "Comments: 12 pages, 7 figures. Submitted to EMNLP 2022",
    "descriptor": "\nComments: 12 pages, 7 figures. Submitted to EMNLP 2022\n",
    "authors": [
      "Alexandra Butoi",
      "Brian DuSell",
      "Tim Vieira",
      "Ryan Cotterell",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06884"
  },
  {
    "id": "arXiv:2210.07363",
    "title": "The Power of Multi-Step Vizing Chains",
    "abstract": "Comments: 31 pages, 3 figures",
    "descriptor": "\nComments: 31 pages, 3 figures\n",
    "authors": [
      "Aleksander B G Christiansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07363"
  },
  {
    "id": "arXiv:2210.07661",
    "title": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
    "abstract": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling",
    "descriptor": "",
    "authors": [
      "Jun Zhang",
      "Shuyang Jiang",
      "Jiangtao Feng",
      "Lin Zheng",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07661"
  },
  {
    "id": "arXiv:2210.07793",
    "title": "Greedy Transaction Fee Mechanisms for (Non-)myopic Miners",
    "abstract": "Greedy Transaction Fee Mechanisms for (Non-)myopic Miners",
    "descriptor": "",
    "authors": [
      "Yotam Gafni",
      "Aviv Yaish"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.07793"
  },
  {
    "id": "arXiv:2210.08031",
    "title": "Neural Attentive Circuits",
    "abstract": "Comments: To appear at NeurIPS 2022",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Nasim Rahaman",
      "Martin Weiss",
      "Francesco Locatello",
      "Chris Pal",
      "Yoshua Bengio",
      "Bernhard Sch\u00f6lkopf",
      "Li Erran Li",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08031"
  },
  {
    "id": "arXiv:2210.08291",
    "title": "Bidirectional Semi-supervised Dual-branch CNN for Robust 3D  Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel  Supervisions",
    "abstract": "Comments: 12 pages, submitted to Medical Image Analysis",
    "descriptor": "\nComments: 12 pages, submitted to Medical Image Analysis\n",
    "authors": [
      "Hongkuan Shi",
      "Zhiwei Wang",
      "Ying Zhou",
      "Dun Li",
      "Xin Yang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08291"
  },
  {
    "id": "arXiv:2210.08342",
    "title": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "abstract": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "descriptor": "",
    "authors": [
      "Philipp Scholl",
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08342"
  },
  {
    "id": "arXiv:2210.08465",
    "title": "Character-Centric Story Visualization via Visual Planning and Token  Alignment",
    "abstract": "Comments: accepted by EMNLP2022",
    "descriptor": "\nComments: accepted by EMNLP2022\n",
    "authors": [
      "Hong Chen",
      "Rujun Han",
      "Te-Lin Wu",
      "Hideki Nakayama",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08465"
  },
  {
    "id": "arXiv:2210.08713",
    "title": "Supervised Prototypical Contrastive Learning for Emotion Recognition in  Conversation",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Xiaohui Song",
      "Longtao Huang",
      "Hui Xue",
      "Songlin Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08713"
  },
  {
    "id": "arXiv:2210.08735",
    "title": "2nd Place Solution to Google Universal Image Embedding",
    "abstract": "Comments: 3 pages, 1 figures, Instance-Level Recognition Workshop at ECCV 2022, Google Universal Image Embedding, 2nd place solution",
    "descriptor": "\nComments: 3 pages, 1 figures, Instance-Level Recognition Workshop at ECCV 2022, Google Universal Image Embedding, 2nd place solution\n",
    "authors": [
      "Xiaolong Huang",
      "Qiankun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08735"
  },
  {
    "id": "arXiv:2210.08753",
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "abstract": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "descriptor": "",
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08753"
  },
  {
    "id": "arXiv:2210.08906",
    "title": "A.I. Robustness: a Human-Centered Perspective on Technological  Challenges and Opportunities",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Andrea Tocchetti",
      "Lorenzo Corti",
      "Agathe Balayn",
      "Mireia Yurrita",
      "Philip Lippmann",
      "Marco Brambilla",
      "Jie Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08906"
  },
  {
    "id": "arXiv:2210.09012",
    "title": "SAICL: Student Modelling with Interaction-level Auxiliary Contrastive  Tasks for Knowledge Tracing and Dropout Prediction",
    "abstract": "Comments: preprint, under review",
    "descriptor": "\nComments: preprint, under review\n",
    "authors": [
      "Jungbae Park",
      "Jinyoung Kim",
      "Soonwoo Kwon",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09012"
  },
  {
    "id": "arXiv:2210.09151",
    "title": "Symbol Guided Hindsight Priors for Reward Learning from Human  Preferences",
    "abstract": "Symbol Guided Hindsight Priors for Reward Learning from Human  Preferences",
    "descriptor": "",
    "authors": [
      "Mudit Verma",
      "Katherine Metcalf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09151"
  },
  {
    "id": "arXiv:2210.09153",
    "title": "Face Pasting Attack",
    "abstract": "Face Pasting Attack",
    "descriptor": "",
    "authors": [
      "Niklas Bunzel",
      "Lukas Graner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09153"
  },
  {
    "id": "arXiv:2210.09186",
    "title": "Implicit models, latent compression, intrinsic biases, and cheap lunches  in community detection",
    "abstract": "Comments: 24 pages, 18 figures",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Tiago P. Peixoto",
      "Alec Kirkley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09186"
  },
  {
    "id": "arXiv:2210.09338",
    "title": "Deep Bidirectional Language-Knowledge Graph Pretraining",
    "abstract": "Comments: Published at NeurIPS 2022. Code, data, and trained models are available at this https URL",
    "descriptor": "\nComments: Published at NeurIPS 2022. Code, data, and trained models are available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Antoine Bosselut",
      "Hongyu Ren",
      "Xikun Zhang",
      "Christopher D Manning",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09338"
  },
  {
    "id": "arXiv:2210.09404",
    "title": "Measures of Information Reflect Memorization Patterns",
    "abstract": "Comments: 22 pages; NeurIPS 2022. Code and data at this https URL",
    "descriptor": "\nComments: 22 pages; NeurIPS 2022. Code and data at this https URL\n",
    "authors": [
      "Rachit Bansal",
      "Danish Pruthi",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09404"
  },
  {
    "id": "arXiv:2210.09472",
    "title": "Multi-granularity Argument Mining in Legal Texts",
    "abstract": "Multi-granularity Argument Mining in Legal Texts",
    "descriptor": "",
    "authors": [
      "Huihui Xu",
      "Kevin Ashley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09472"
  },
  {
    "id": "arXiv:2210.09477",
    "title": "UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation  Model on a Single Image",
    "abstract": "UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation  Model on a Single Image",
    "descriptor": "",
    "authors": [
      "Dani Valevski",
      "Matan Kalman",
      "Yossi Matias",
      "Yaniv Leviathan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09477"
  },
  {
    "id": "arXiv:2210.09604",
    "title": "Perceptual Multi-Exposure Fusion",
    "abstract": "Comments: The current version is our previous work rejected by IEEE TMM. I'm very sorry and I want to withdraw this submitted version. I will resubmit it when I improve it in the future. The version involves some ideas we are doing",
    "descriptor": "\nComments: The current version is our previous work rejected by IEEE TMM. I'm very sorry and I want to withdraw this submitted version. I will resubmit it when I improve it in the future. The version involves some ideas we are doing\n",
    "authors": [
      "Xiaoning Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09604"
  },
  {
    "id": "arXiv:2210.09630",
    "title": "Completeness of Tableau Calculi for Two-Dimensional Hybrid Logics",
    "abstract": "Comments: Version 2. 27 pages. 5 figures. This is a preprint",
    "descriptor": "\nComments: Version 2. 27 pages. 5 figures. This is a preprint\n",
    "authors": [
      "Yuki Nishimura"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09630"
  },
  {
    "id": "arXiv:2210.09634",
    "title": "DPIS: An Enhanced Mechanism for Differentially Private SGD with  Importance Sampling",
    "abstract": "Comments: A short version of this paper will appear in CCS 2022",
    "descriptor": "\nComments: A short version of this paper will appear in CCS 2022\n",
    "authors": [
      "Jianxin Wei",
      "Ergute Bao",
      "Xiaokui Xiao",
      "Yin Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09634"
  },
  {
    "id": "arXiv:2210.09695",
    "title": "Consistent Multiclass Algorithms for Complex Metrics and Constraints",
    "abstract": "Consistent Multiclass Algorithms for Complex Metrics and Constraints",
    "descriptor": "",
    "authors": [
      "Harikrishna Narasimhan",
      "Harish G. Ramaswamy",
      "Shiv Kumar Tavker",
      "Drona Khurana",
      "Praneeth Netrapalli",
      "Shivani Agarwal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09695"
  },
  {
    "id": "arXiv:2210.09782",
    "title": "Decoupling Features in Hierarchical Propagation for Video Object  Segmentation",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Zongxin Yang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09782"
  },
  {
    "id": "arXiv:2210.09787",
    "title": "CPS-MEBR: Click Feedback-Aware Web Page Summarization for  Multi-Embedding-Based Retrieval",
    "abstract": "Comments: Not all co authors have agreed",
    "descriptor": "\nComments: Not all co authors have agreed\n",
    "authors": [
      "Wenbiao Li",
      "Pan Tang",
      "Zhengfan Wu",
      "Weixue Lu",
      "Minghua Zhang",
      "Zhenlei Tian",
      "Daiting Shi",
      "Yu Sun",
      "Simiu Gu",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09787"
  },
  {
    "id": "arXiv:2210.09803",
    "title": "Sentiment-Aware Word and Sentence Level Pre-training for Sentiment  Analysis",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Shuai Fan",
      "Chen Lin",
      "Haonan Li",
      "Zhenghao Lin",
      "Jinsong Su",
      "Hang Zhang",
      "Yeyun Gong",
      "Jian Guo",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09803"
  },
  {
    "id": "arXiv:2210.09822",
    "title": "Two low differentially uniform power permutations over odd  characteristic finite fields: APN and differentially $4$-uniform functions",
    "abstract": "Two low differentially uniform power permutations over odd  characteristic finite fields: APN and differentially $4$-uniform functions",
    "descriptor": "",
    "authors": [
      "Haode Yan",
      "Sihem Mesnager",
      "Xiantong Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09822"
  },
  {
    "id": "arXiv:2210.09837",
    "title": "Deep Scattering Spectrum germaneness to Fault Detection and Diagnosis  for Component-level Prognostics and Health Management (PHM)",
    "abstract": "Comments: need changes",
    "descriptor": "\nComments: need changes\n",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09837"
  },
  {
    "id": "arXiv:2210.09871",
    "title": "Sequence and Circle: Exploring the Relationship Between Patches",
    "abstract": "Comments: 7 pages, 1 figure",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Zhengyang Yu",
      "Jochen Triesch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09871"
  },
  {
    "id": "arXiv:2210.10041",
    "title": "Hidden State Variability of Pretrained Language Models Can Guide  Computation Reduction for Transfer Learning",
    "abstract": "Comments: EMNLP 2022 camera-ready",
    "descriptor": "\nComments: EMNLP 2022 camera-ready\n",
    "authors": [
      "Shuo Xie",
      "Jiahao Qiu",
      "Ankita Pasad",
      "Li Du",
      "Qing Qu",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10041"
  },
  {
    "id": "arXiv:2210.10047",
    "title": "From Play to Policy: Conditional Behavior Generation from Uncurated  Robot Data",
    "abstract": "Comments: Code and data available at: this https URL; (fixed metadata author name format)",
    "descriptor": "\nComments: Code and data available at: this https URL; (fixed metadata author name format)\n",
    "authors": [
      "Zichen Jeff Cui",
      "Yibin Wang",
      "Nur Muhammad Mahi Shafiullah",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10047"
  }
]
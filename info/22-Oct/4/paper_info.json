[
  {
    "id": "arXiv:2210.00001",
    "title": "Geometrically exact isogeometric Bernoulli-Euler beam based on the  Frenet-Serret frame",
    "abstract": "A novel geometrically exact model of the spatially curved Bernoulli-Euler\nbeam is developed. The formulation utilizes the Frenet-Serret frame as the\nreference for updating the orientation of a cross section. The weak form is\nconsistently derived and linearized, including the contributions from kinematic\nconstraints and configuration-dependent load. The nonlinear terms with respect\nto the cross-sectional coordinates are strictly considered, and the obtained\nconstitutive model is scrutinized. The main features of the formulation are\ninvariance with respect to the rigid-body motion, path-independence, and\nimproved accuracy for strongly curved beams. A new reduced beam model is\nconceived as a special case, by omitting the rotational DOF. Although\nrotation-free, the reduced model includes the part of the torsional stiffness\nthat is related to the torsion of the beam axis. This allows simulation of\nexamples where the angle between material axes and Frenet-Serret frame is\nsmall. The applicability of the obtained isogeometric finite element is\nverified via a set of standard academic benchmark examples. The formulation is\nable to accurately model strongly curved Bernoulli-Euler beams that have\nwell-defined Frenet-Serret frames.",
    "descriptor": "",
    "authors": [
      "A. Borkovi\u0107",
      "M. H. Gfrerer",
      "B. Marussig"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.00001"
  },
  {
    "id": "arXiv:2210.00002",
    "title": "Evaluation of physics constrained data-driven methods for turbulence  model uncertainty quantification",
    "abstract": "In order to achieve a virtual certification process and robust designs for\nturbomachinery, the uncertainty bounds for computational fluid dynamics have to\nbe known. The formulation of turbulence closure models implies a major source\nof the overall uncertainty of Reynold-averaged Navier Stokes simulations. We\ndiscuss the common practice of applying a physics constrained eigenspace\nperturbation of the Reynolds stress tensor in order to account for the model\nform uncertainty of turbulence models. Since the basic methodology often leads\nto generous uncertainty estimates, we extend a recent approach of adding a\nmachine learning strategy. The application of a data-driven method is motivated\nby striving for the detection of flow regions, which are prone to suffer from a\nlack of turbulence model prediction accuracy. In this way any user input\nrelated to choosing the degree of uncertainty is supposed to become obsolete.\nThis work especially investigates an approach, which tries to determine an a\npriori estimation of prediction confidence, when there is no accurate data\navailable to judge the prediction. The flow around the NACA 4412 airfoil at\nnear-stall conditions serves to demonstrate the successful application of the\ndata-driven eigenspace perturbation framework. We especially highlight the\nobjectives and limitations of the underlying methodology finally.",
    "descriptor": "",
    "authors": [
      "Marcel Matha",
      "Karsten Kucharczyk",
      "Christian Morsbach"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.00002"
  },
  {
    "id": "arXiv:2210.00003",
    "title": "Architecting materials for extremal stiffness, yield and buckling  strength",
    "abstract": "This paper proposes a methodology for architecting microstructures with\nextremal stiffness, yield, and buckling strength using topology optimization.\nThe optimized microstructures reveal an interesting transition from simple\nlattice like structures for yield-dominated situations to hierarchical lattice\nstructures for buckling-dominated situations. The transition from simple to\nhierarchical is governed by the relative yield strength of the constituent base\nmaterial as well as the volume fraction. The overall performances of the\nproposed microstructures indicate that optimal strength is determined by the\nbuckling strength at low volume fractions and yield strength at high volume\nfractions, regardless of the base material's relative yield strength.",
    "descriptor": "",
    "authors": [
      "Fengwen Wang",
      "Ole Sigmund"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00003"
  },
  {
    "id": "arXiv:2210.00008",
    "title": "Adversarial Attacks on Transformers-Based Malware Detectors",
    "abstract": "Signature-based malware detectors have proven to be insufficient as even a\nsmall change in malignant executable code can bypass these signature-based\ndetectors. Many machine learning-based models have been proposed to efficiently\ndetect a wide variety of malware. Many of these models are found to be\nsusceptible to adversarial attacks - attacks that work by generating\nintentionally designed inputs that can force these models to misclassify. Our\nwork aims to explore vulnerabilities in the current state of the art malware\ndetectors to adversarial attacks. We train a Transformers-based malware\ndetector, carry out adversarial attacks resulting in a misclassification rate\nof 23.9% and propose defenses that reduce this misclassification rate to half.\nAn implementation of our work can be found at\nhttps://github.com/yashjakhotiya/Adversarial-Attacks-On-Transformers.",
    "descriptor": "",
    "authors": [
      "Yash Jakhotiya",
      "Heramb Patil",
      "Jugal Rawlani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00008"
  },
  {
    "id": "arXiv:2210.00022",
    "title": "A high-order fast direct solver for surface PDEs",
    "abstract": "We introduce a fast direct solver for variable-coefficient elliptic partial\ndifferential equations on surfaces based on the hierarchical Poincar\\'e-Steklov\nmethod. The method takes as input an unstructured, high-order quadrilateral\nmesh of a surface and discretizes surface differential operators on each\nelement using a high-order spectral collocation scheme. Elemental solution\noperators and Dirichlet-to-Neumann maps tangent to the surface are precomputed\nand merged in a pairwise fashion to yield a hierarchy of solution operators\nthat may be applied in $\\mathcal{O}(N \\log N)$ operations for a mesh with $N$\nelements. The resulting fast direct solver may be used to accelerate high-order\nimplicit time-stepping schemes, as the precomputed operators can be reused for\nfast elliptic solves on surfaces. On a standard laptop, precomputation for a\n12th-order surface mesh with over 1 million degrees of freedom takes 17\nseconds, while subsequent solves take only 0.25 seconds. We apply the method to\na range of problems on both smooth surfaces and surfaces with sharp corners and\nedges, including the static Laplace-Beltrami problem, the Hodge decomposition\nof a tangential vector field, and some time-dependent nonlinear\nreaction-diffusion systems.",
    "descriptor": "",
    "authors": [
      "Daniel Fortunato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00022"
  },
  {
    "id": "arXiv:2210.00025",
    "title": "Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in  Bandits",
    "abstract": "While standard bandit algorithms sometimes incur high regret, their\nperformance can be greatly improved by \"warm starting\" with historical data.\nUnfortunately, how best to incorporate historical data is unclear: naively\ninitializing reward estimates using all historical samples can suffer from\nspurious data and imbalanced data coverage, leading to computational and\nstorage issues - particularly in continuous action spaces. We address these two\nchallenges by proposing Artificial Replay, a meta-algorithm for incorporating\nhistorical data into any arbitrary base bandit algorithm. Artificial Replay\nuses only a subset of the historical data as needed to reduce computation and\nstorage. We show that for a broad class of base algorithms that satisfy\nindependence of irrelevant data (IIData), a novel property that we introduce,\nour method achieves equal regret as a full warm-start approach while\npotentially using only a fraction of the historical data. We complement these\ntheoretical results with a case study of $K$-armed and continuous combinatorial\nbandit algorithms, including on a green security domain using real poaching\ndata, to show the practical benefits of Artificial Replay in achieving optimal\nregret alongside low computational and storage costs.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Siddhartha Banerjee",
      "Sean R. Sinclair",
      "Milind Tambe",
      "Lily Xu",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00025"
  },
  {
    "id": "arXiv:2210.00026",
    "title": "CRC-Aided Short Convolutional Codes and RCU Bounds for Orthogonal  Signaling",
    "abstract": "We extend earlier work on the design of convolutional code-specific CRC codes\nto $Q$-ary alphabets, with an eye toward $Q$-ary orthogonal signaling. Starting\nwith distance-spectrum optimal, zero-terminated, $Q$-ary convolutional codes,\nwe design $Q$-ary CRC codes so that the CRC/convolutional concatenation is\ndistance-spectrum optimal. The $Q$-ary code symbols are mapped to a $Q$-ary\northogonal signal set and sent over an AWGN channel with noncoherent reception.\nWe focus on $Q = 4$, rate-1/2 convolutional codes in our designs. The random\ncoding union bound and normal approximation are used in earlier works as\nbenchmarks for performance for distance-spectrum optimal convolutional codes.\nWe derive a saddlepoint approximation of the random coding union bound for the\ncoded noncoherent signaling channel, as well as a normal approximation for this\nchannel, and compare the performance of our codes to these limits. Our best\ndesign is within $0.6$ dB of the RCU bound at a frame error rate of $10^{-4}$.",
    "descriptor": "\nComments: GLOBECOM 2022 camera-ready version\n",
    "authors": [
      "Jacob King",
      "William Ryan",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00026"
  },
  {
    "id": "arXiv:2210.00030",
    "title": "VIP: Towards Universal Visual Reward and Representation via  Value-Implicit Pre-Training",
    "abstract": "Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Yecheng Jason Ma",
      "Shagun Sodhani",
      "Dinesh Jayaraman",
      "Osbert Bastani",
      "Vikash Kumar",
      "Amy Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00030"
  },
  {
    "id": "arXiv:2210.00032",
    "title": "Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs",
    "abstract": "Temporal networks model a variety of important phenomena involving timed\ninteractions between entities. Existing methods for machine learning on\ntemporal networks generally exhibit at least one of two limitations. First,\ntime is assumed to be discretized, so if the time data is continuous, the user\nmust determine the discretization and discard precise time information. Second,\nedge representations can only be calculated indirectly from the nodes, which\nmay be suboptimal for tasks like edge classification. We present a simple\nmethod that avoids both shortcomings: construct the line graph of the network,\nwhich includes a node for each interaction, and weigh the edges of this graph\nbased on the difference in time between interactions. From this derived graph,\nedge representations for the original network can be computed with efficient\nclassical methods. The simplicity of this approach facilitates explicit\ntheoretical analysis: we can constructively show the effectiveness of our\nmethod's representations for a natural synthetic model of temporal networks.\nEmpirical results on real-world networks demonstrate our method's efficacy and\nefficiency on both edge classification and temporal link prediction.",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Ryan A. Rossi",
      "Sungchul Kim",
      "Tong Yu",
      "Jane Hoffswell",
      "Nedim Lipka",
      "Shunan Guo",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.00032"
  },
  {
    "id": "arXiv:2210.00034",
    "title": "Offset-value coding in database query processing",
    "abstract": "Recent work measures how much offset-value coding speeds up database query\noperations. It speeds up not only sorting but also duplicate removal, grouping\n(aggregation) in sorted streams, order-preserving exchange (shuffle), and merge\njoin. It already saves thousands of CPUs in Google's Napa and F1~Query systems,\ne.g., in grouping algorithms and in log-structured merge-forests.\nIn order to achieve the full benefits of interesting orderings, however,\nquery execution algorithms must not only consume and exploit offset-value codes\nbut also provide offset-value codes to the next operation in the pipeline. This\nshort paper describes in detail how order-preserving algorithms (from filter to\nmerge join and even shuffle) can compute offset-value codes for their outputs.\nThese calculations are surprisingly simple and very efficient.",
    "descriptor": "",
    "authors": [
      "Goetz Graefe",
      "Thanh Do"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.00034"
  },
  {
    "id": "arXiv:2210.00035",
    "title": "Neural Causal Models for Counterfactual Identification and Estimation",
    "abstract": "Evaluating hypothetical statements about how the world would be had a\ndifferent course of action been taken is arguably one key capability expected\nfrom modern AI systems. Counterfactual reasoning underpins discussions in\nfairness, the determination of blame and responsibility, credit assignment, and\nregret. In this paper, we study the evaluation of counterfactual statements\nthrough neural models. Specifically, we tackle two causal problems required to\nmake such evaluations, i.e., counterfactual identification and estimation from\nan arbitrary combination of observational and experimental data. First, we show\nthat neural causal models (NCMs) are expressive enough and encode the\nstructural constraints necessary for performing counterfactual reasoning.\nSecond, we develop an algorithm for simultaneously identifying and estimating\ncounterfactual distributions. We show that this algorithm is sound and complete\nfor deciding counterfactual identification in general settings. Third,\nconsidering the practical implications of these results, we introduce a new\nstrategy for modeling NCMs using generative adversarial networks. Simulations\ncorroborate with the proposed methodology.",
    "descriptor": "\nComments: 10 pages main body, 57 pages total, 23 figures\n",
    "authors": [
      "Kevin Xia",
      "Yushu Pan",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00035"
  },
  {
    "id": "arXiv:2210.00036",
    "title": "Differentially Private Bias-Term only Fine-tuning of Foundation Models",
    "abstract": "We study the problem of differentially private (DP) fine-tuning of large\npre-trained models -- a recent privacy-preserving approach suitable for solving\ndownstream tasks with sensitive data. Existing work has demonstrated that high\naccuracy is possible under strong privacy constraint, yet requires significant\ncomputational overhead or modifications to the network architecture.\nWe propose differentially private bias-term fine-tuning (DP-BiTFiT), which\nmatches the state-of-the-art accuracy for DP algorithms and the efficiency of\nthe standard BiTFiT. DP-BiTFiT is model agnostic (not modifying the network\narchitecture), parameter efficient (only training about $0.1\\%$ of the\nparameters), and computation efficient (almost removing the overhead caused by\nDP, in both the time and space complexity). On a wide range of tasks, DP-BiTFiT\nis $2\\sim 30\\times$ faster and uses $2\\sim 8\\times$ less memory than DP full\nfine-tuning, even faster than the standard full fine-tuning. This amazing\nefficiency enables us to conduct DP fine-tuning on language and vision tasks\nwith long-sequence texts and high-resolution images, which were computationally\ndifficult using existing methods.",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu",
      "Yu-Xiang Wang",
      "Sheng Zha",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00036"
  },
  {
    "id": "arXiv:2210.00037",
    "title": "A Complete Set of Connectivity-aware Local Topology Manipulation  Operations for Robot Swarms",
    "abstract": "The topology of a robotic swarm affects the convergence speed of consensus\nand the mobility of the robots. In this paper, we prove the existence of a\ncomplete set of local topology manipulation operations that allow the\ntransformation of a swarm topology. The set is complete in the sense that any\nother possible set of manipulation operations can be performed by a sequence of\noperations from our set. The operations are local as they depend only on the\nfirst and second hop neighbors' information to transform any initial spanning\ntree of the network's graph to any other connected tree with the same number of\nnodes. The flexibility provided by our method is similar to global methods that\nrequire full knowledge of the swarm network. We prove the existence of a\nsequence of transformations for any tree-to-tree transformation, and derive\nsequences of operations to form a line or star from any initial spanning tree.\nOur work provides a theoretical and practical framework for topological control\nof a swarm, establishing global properties using only local information.",
    "descriptor": "",
    "authors": [
      "Karthik Soma",
      "Koresh Khateri",
      "Mahdi Pourgholi",
      "Mohsen Montazeri",
      "Lorenzo Sabattini",
      "Giovanni Beltrame"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00037"
  },
  {
    "id": "arXiv:2210.00038",
    "title": "Differentially Private Optimization on Large Model at Small Cost",
    "abstract": "Differentially private (DP) optimization is the standard paradigm to learn\nlarge neural networks that are accurate and privacy-preserving. The\ncomputational cost for DP deep learning, however, is notoriously heavy due to\nthe per-sample gradient clipping. Existing DP implementations are\n$2-1000\\times$ more costly in time and space complexity than the standard\n(non-private) training. In this work, we develop a novel Book-Keeping (BK)\ntechnique that implements existing DP optimizers (thus achieving the same\naccuracy), with a substantial improvement on the computational cost.\nSpecifically, BK enables DP training on large models and high dimensional data\nto be roughly as efficient as the standard training, whereas previous DP\nalgorithms can be inefficient or incapable of training due to memory error. The\ncomputational advantage of BK is supported by the complexity analysis as well\nas extensive experiments on vision and language tasks. Our implementation\nachieves state-of-the-art (SOTA) accuracy with very small extra cost: on GPT2\nand at the same memory cost, BK has 1.0$\\times$ the time complexity of the\nstandard training (0.75$\\times$ training speed in practice), and 0.6$\\times$\nthe time complexity of the most efficient DP implementation (1.24$\\times$\ntraining speed in practice). We will open-source the codebase for the BK\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu",
      "Yu-Xiang Wang",
      "Sheng Zha",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00038"
  },
  {
    "id": "arXiv:2210.00040",
    "title": "Utility of the Koopman operator in output regulation of disturbed  nonlinear systems",
    "abstract": "This paper studies the problem of output regulation for a class of nonlinear\nsystems experiencing matched input disturbances. The disturbance signal is\ngenerated by an external autonomous dynamical system. Using the Koopman\noperator, the nonlinear dynamical system is represented as a bilinear dynamical\nsystem. Inspired by the linear output regulation problem, a linear dynamic\nerror feedback controller is designed for the system. Subsequently, a\nLyapunov-based stability analysis method is used to characterize a set of\ninitial conditions for which output regulation is achieved. Numerical results\nare provided to validate the analysis.",
    "descriptor": "",
    "authors": [
      "Bart Kieboom",
      "Matin Jafarian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00040"
  },
  {
    "id": "arXiv:2210.00041",
    "title": "Communication-Enabled Multi-Agent Decentralised Deep Reinforcement  Learning to Optimise Energy-Efficiency in UAV-Assisted Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed to provide wireless\nconnectivity to static and mobile ground users in situations of increased\nnetwork demand or points-of-failure in existing terrestrial cellular\ninfrastructure. However, UAVs are energy-constrained and may experience\ninterference from nearby UAV cells sharing the same frequency spectrum, thereby\nimpacting the system's energy efficiency (EE). We aim to address research gaps\nthat focus on optimising the system's EE using a 2D trajectory optimisation of\nUAVs serving only static ground users, and neglect the impact of interference\nfrom nearby UAV cells. Unlike previous work that assume global spatial\nknowledge of ground users' location via a central controller that periodically\nscans the network perimeter and provides real-time updates to the UAVs for\ndecision making, we focus on a realistic decentralised approach suitable in\nemergencies. Thus, we apply a decentralised Multi-Agent Reinforcement Learning\n(MARL) approach that maximizes the system's EE by jointly optimising each UAV's\n3D trajectory, number of connected static and mobile users, and the energy\nconsumed, while taking into account the impact of interference and the UAVs'\ncoordination on the system's EE in a dynamic network environment. To address\nthis, we propose a direct collaborative Communication-enabled Multi-Agent\nDecentralised Double Deep Q-Network (CMAD-DDQN) approach. The CMAD-DDQN is a\ncollaborative algorithm that allows UAVs to explicitly share knowledge by\ncommunicating with its nearest neighbours based on existing 3GPP guidelines.\nOur approach is able to maximise the system's EE without degrading the coverage\nperformance in the network. Simulation results show that the proposed approach\noutperforms existing baselines in term of maximising the systems' EE by about\n15% - 85%.",
    "descriptor": "\nComments: 12 pages, 14 figures, Under-review. arXiv admin note: substantial text overlap with arXiv:2204.01597\n",
    "authors": [
      "Babatunji Omoniwa",
      "Boris Galkin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00041"
  },
  {
    "id": "arXiv:2210.00044",
    "title": "Task Formulation Matters When Learning Continually: A Case Study in  Visual Question Answering",
    "abstract": "Continual learning aims to train a model incrementally on a sequence of tasks\nwithout forgetting previous knowledge. Although continual learning has been\nwidely studied in computer vision, its application to Vision+Language tasks is\nnot that straightforward, as settings can be parameterized in multiple ways\naccording to their input modalities. In this paper, we present a detailed study\nof how different settings affect performance for Visual Question Answering. We\nfirst propose three plausible task formulations and demonstrate their impact on\nthe performance of continual learning algorithms. We break down several factors\nof task similarity, showing that performance and sensitivity to task order\nhighly depend on the shift of the output distribution. We also investigate the\npotential of pretrained models and compare the robustness of transformer models\nwith different visual embeddings. Finally, we provide an analysis interpreting\nmodel representations and their impact on forgetting. Our results highlight the\nimportance of stabilizing visual representations in deeper layers.",
    "descriptor": "",
    "authors": [
      "Mavina Nikandrou",
      "Lu Yu",
      "Alessandro Suglia",
      "Ioannis Konstas",
      "Verena Rieser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00044"
  },
  {
    "id": "arXiv:2210.00045",
    "title": "Calibrating Sequence likelihood Improves Conditional Language Generation",
    "abstract": "Conditional language models are predominantly trained with maximum likelihood\nestimation (MLE), giving probability mass to sparsely observed target\nsequences. While MLE trained models assign high probability to plausible\nsequences given the context, the model probabilities often do not accurately\nrank-order generated sequences by quality. This has been empirically observed\nin beam search decoding as output quality degrading with large beam sizes, and\ndecoding strategies benefiting from heuristics such as length normalization and\nrepetition-blocking. In this work, we introduce sequence likelihood calibration\n(SLiC) where the likelihood of model generated sequences are calibrated to\nbetter align with reference sequences in the model's latent space. With SLiC,\ndecoding heuristics become unnecessary and decoding candidates' quality\nsignificantly improves regardless of the decoding method. Furthermore, SLiC\nshows no sign of diminishing returns with model scale, and presents alternative\nways to improve quality with limited training and inference budgets. With SLiC,\nwe exceed or match SOTA results on a wide range of generation tasks spanning\nabstractive summarization, question generation, abstractive question answering\nand data-to-text generation, even with modest-sized models.",
    "descriptor": "",
    "authors": [
      "Yao Zhao",
      "Misha Khalman",
      "Rishabh Joshi",
      "Shashi Narayan",
      "Mohammad Saleh",
      "Peter J. Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00045"
  },
  {
    "id": "arXiv:2210.00048",
    "title": "Axioms for Constant Function AMMs",
    "abstract": "We study axiomatic foundations for different classes of constant function\nautomated market makers (AMMs). We focus particularly on independence,\nhomogeneity and convexity properties and give axiomatic characterizations of a\nnatural generalization of constant product AMMs that has not been considered so\nfar in the decentralized finance context. Our results add to a formal analysis\nof mechanisms that are currently used for decentralized exchanges and\nintroduces tools of decision theory to the topic.",
    "descriptor": "",
    "authors": [
      "Jan Christoph Schlegel",
      "Akaki Mamageishvili"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.00048"
  },
  {
    "id": "arXiv:2210.00051",
    "title": "Force/Torque Sensing for Soft Grippers using an External Camera",
    "abstract": "Robotic manipulation can benefit from wrist-mounted force/torque (F/T)\nsensors, but conventional F/T sensors can be expensive, difficult to install,\nand damaged by high loads. We present Visual Force/Torque Sensing (VFTS), a\nmethod that visually estimates the 6-axis F/T measurement that would be\nreported by a conventional F/T sensor. In contrast to approaches that sense\nloads using internal cameras placed behind soft exterior surfaces, our approach\nuses an external camera with a fisheye lens that observes a soft gripper. VFTS\nincludes a deep learning model that takes a single RGB image as input and\noutputs a 6-axis F/T estimate. We trained the model with sensor data collected\nwhile teleoperating a robot (Stretch RE1 from Hello Robot Inc.) to perform\nmanipulation tasks. VFTS outperformed F/T estimates based on motor currents,\ngeneralized to a novel home environment, and supported three autonomous tasks\nrelevant to healthcare: grasping a blanket, pulling a blanket over a manikin,\nand cleaning a manikin's limbs. VFTS also performed well with a manually\noperated pneumatic gripper. Overall, our results suggest that an external\ncamera observing a soft gripper can perform useful visual force/torque sensing\nfor a variety of manipulation tasks.",
    "descriptor": "",
    "authors": [
      "Jeremy A. Collins",
      "Patrick Grady",
      "Charles C. Kemp"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00051"
  },
  {
    "id": "arXiv:2210.00053",
    "title": "Kernel Normalized Convolutional Networks for Privacy-Preserving Machine  Learning",
    "abstract": "Normalization is an important but understudied challenge in privacy-related\napplication domains such as federated learning (FL) and differential privacy\n(DP). While the unsuitability of batch normalization for FL and DP has already\nbeen shown, the impact of the other normalization methods on the performance of\nfederated or differentially private models is not well-known. To address this,\nwe draw a performance comparison among layer normalization (LayerNorm), group\nnormalization (GroupNorm), and the recently proposed kernel normalization\n(KernelNorm) in FL and DP settings. Our results indicate LayerNorm and\nGroupNorm provide no performance gain compared to the baseline (i.e. no\nnormalization) for shallow models, but they considerably enhance performance of\ndeeper models. KernelNorm, on the other hand, significantly outperforms its\ncompetitors in terms of accuracy and convergence rate (or communication\nefficiency) for both shallow and deeper models. Given these key observations,\nwe propose a kernel normalized ResNet architecture called KNResNet-13 for\ndifferentially private learning environments. Using the proposed architecture,\nwe provide new state-of-the-art accuracy values on the CIFAR-10 and Imagenette\ndatasets.",
    "descriptor": "",
    "authors": [
      "Reza Nasirigerdeh",
      "Javad Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00053"
  },
  {
    "id": "arXiv:2210.00055",
    "title": "$MaskTune$: Mitigating Spurious Correlations by Forcing to Explore",
    "abstract": "A fundamental challenge of over-parameterized deep learning models is\nlearning meaningful data representations that yield good performance on a\ndownstream task without over-fitting spurious input features. This work\nproposes MaskTune, a masking strategy that prevents over-reliance on spurious\n(or a limited number of) features. MaskTune forces the trained model to explore\nnew features during a single epoch finetuning by masking previously discovered\nfeatures. MaskTune, unlike earlier approaches for mitigating shortcut learning,\ndoes not require any supervision, such as annotating spurious features or\nlabels for subgroup samples in a dataset. Our empirical results on biased\nMNIST, CelebA, Waterbirds, and ImagenNet-9L datasets show that MaskTune is\neffective on tasks that often suffer from the existence of spurious\ncorrelations. Finally, we show that MaskTune outperforms or achieves similar\nperformance to the competing methods when applied to the selective\nclassification (classification with rejection option) task. Code for MaskTune\nis available at https://github.com/aliasgharkhani/Masktune.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Saeid Asgari Taghanaki",
      "Aliasghar Khani",
      "Fereshte Khani",
      "Ali Gholami",
      "Linh Tran",
      "Ali Mahdavi-Amiri",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00055"
  },
  {
    "id": "arXiv:2210.00058",
    "title": "Hardware Trojan Threats to Cache Coherence in Modern 2.5D Chiplet  Systems",
    "abstract": "As industry moves toward chiplet-based designs, the insertion of hardware\nTrojans poses a significant threat to the security of these systems. These\nsystems rely heavily on cache coherence for coherent data communication, making\ncoherence an attractive target. Critically, unlike prior work, which focuses\nonly on malicious packet modifications, a Trojan attack that exploits coherence\ncan modify data in memory that was never touched and is not owned by the\nchiplet which contains the Trojan. Further, the Trojan need not even be\nphysically between the victim and the memory controller to attack the victim's\nmemory transactions. Here, we explore the fundamental attack vectors possible\nin chiplet-based systems and provide an example Trojan implementation capable\nof directly modifying victim data in memory. This work aims to highlight the\nneed for developing mechanisms that can protect and secure the coherence scheme\nfrom these forms of attacks.",
    "descriptor": "",
    "authors": [
      "Gino A. Chacon",
      "Charles Williams",
      "Johann Knechtel",
      "Ozgur Sinanoglu",
      "Paul V. Gratz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.00058"
  },
  {
    "id": "arXiv:2210.00060",
    "title": "FedTrees: A Novel Computation-Communication Efficient Federated Learning  Framework Investigated in Smart Grids",
    "abstract": "Smart energy performance monitoring and optimisation at the supplier and\nconsumer levels is essential to realising smart cities. In order to implement a\nmore sustainable energy management plan, it is crucial to conduct a better\nenergy forecast. The next-generation smart meters can also be used to measure,\nrecord, and report energy consumption data, which can be used to train machine\nlearning (ML) models for predicting energy needs. However, sharing fine-grained\nenergy data and performing centralised learning may compromise users' privacy\nand leave them vulnerable to several attacks. This study addresses this issue\nby utilising federated learning (FL), an emerging technique that performs ML\nmodel training at the user level, where data resides. We introduce FedTrees, a\nnew, lightweight FL framework that benefits from the outstanding features of\nensemble learning. Furthermore, we developed a delta-based early stopping\nalgorithm to monitor FL training and stop it when it does not need to continue.\nThe simulation results demonstrate that FedTrees outperforms the most popular\nfederated averaging (FedAvg) framework and the baseline Persistence model for\nproviding accurate energy forecasting patterns while taking only 2% of the\ncomputation time and 13% of the communication rounds compared to FedAvg, saving\nconsiderable amounts of computation and communication resources.",
    "descriptor": "",
    "authors": [
      "Mohammad Al-Quraan",
      "Ahsan Khan",
      "Anthony Centeno",
      "Ahmed Zoha",
      "Muhammad Ali Imran",
      "Lina Mohjazi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00060"
  },
  {
    "id": "arXiv:2210.00062",
    "title": "Learning Robust Kernel Ensembles with Kernel Average Pooling",
    "abstract": "Model ensembles have long been used in machine learning to reduce the\nvariance in individual model predictions, making them more robust to input\nperturbations. Pseudo-ensemble methods like dropout have also been commonly\nused in deep learning models to improve generalization. However, the\napplication of these techniques to improve neural networks' robustness against\ninput perturbations remains underexplored. We introduce Kernel Average Pool\n(KAP), a new neural network building block that applies the mean filter along\nthe kernel dimension of the layer activation tensor. We show that ensembles of\nkernels with similar functionality naturally emerge in convolutional neural\nnetworks equipped with KAP and trained with backpropagation. Moreover, we show\nthat when combined with activation noise, KAP models are remarkably robust\nagainst various forms of adversarial attacks. Empirical evaluations on CIFAR10,\nCIFAR100, TinyImagenet, and Imagenet datasets show substantial improvements in\nrobustness against strong adversarial attacks such as AutoAttack that are on\npar with adversarially trained networks but are importantly obtained without\ntraining on any adversarial examples.",
    "descriptor": "",
    "authors": [
      "Pouya Bashivan",
      "Adam Ibrahim",
      "Amirozhan Dehghani",
      "Yifei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.00062"
  },
  {
    "id": "arXiv:2210.00063",
    "title": "DecAF: Joint Decoding of Answers and Logical Forms for Question  Answering over Knowledge Bases",
    "abstract": "Question answering over knowledge bases (KBs) aims to answer natural language\nquestions with factual information such as entities and relations in KBs.\nPrevious methods either generate logical forms that can be executed over KBs to\nobtain final answers or predict answers directly. Empirical results show that\nthe former often produces more accurate answers, but it suffers from\nnon-execution issues due to potential syntactic and semantic errors in the\ngenerated logical forms. In this work, we propose a novel framework DecAF that\njointly generates both logical forms and direct answers, and then combines the\nmerits of them to get the final answers. Moreover, different from most of the\nprevious methods, DecAF is based on simple free-text retrieval without relying\non any entity linking tools -- this simplification eases its adaptation to\ndifferent datasets. DecAF achieves new state-of-the-art accuracy on WebQSP,\nFreebaseQA, and GrailQA benchmarks, while getting competitive results on the\nComplexWebQuestions benchmark.",
    "descriptor": "",
    "authors": [
      "Donghan Yu",
      "Sheng Zhang",
      "Patrick Ng",
      "Henghui Zhu",
      "Alexander Hanbo Li",
      "Jun Wang",
      "Yiqun Hu",
      "William Wang",
      "Zhiguo Wang",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00063"
  },
  {
    "id": "arXiv:2210.00064",
    "title": "CEREAL: Few-Sample Clustering Evaluation",
    "abstract": "Evaluating clustering quality with reliable evaluation metrics like\nnormalized mutual information (NMI) requires labeled data that can be expensive\nto annotate. We focus on the underexplored problem of estimating clustering\nquality with limited labels. We adapt existing approaches from the few-sample\nmodel evaluation literature to actively sub-sample, with a learned surrogate\nmodel, the most informative data points for annotation to estimate the\nevaluation metric. However, we find that their estimation can be biased and\nonly relies on the labeled data. To that end, we introduce CEREAL, a\ncomprehensive framework for few-sample clustering evaluation that extends\nactive sampling approaches in three key ways. First, we propose novel NMI-based\nacquisition functions that account for the distinctive properties of clustering\nand uncertainties from a learned surrogate model. Next, we use ideas from\nsemi-supervised learning and train the surrogate model with both the labeled\nand unlabeled data. Finally, we pseudo-label the unlabeled data with the\nsurrogate model. We run experiments to estimate NMI in an active sampling\npipeline on three datasets across vision and language. Our results show that\nCEREAL reduces the area under the absolute error curve by up to 57% compared to\nthe best sampling baseline. We perform an extensive ablation study to show that\nour framework is agnostic to the choice of clustering algorithm and evaluation\nmetric. We also extend CEREAL from clusterwise annotations to pairwise\nannotations. Overall, CEREAL can efficiently evaluate clustering with limited\nhuman annotations.",
    "descriptor": "",
    "authors": [
      "Nihal V. Nayak",
      "Ethan R. Elenberg",
      "Clemens Rosenbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00064"
  },
  {
    "id": "arXiv:2210.00065",
    "title": "Application of Deep Q Learning with Stimulation Results for Elevator  Optimization",
    "abstract": "This paper presents a methodology for combining programming and mathematics\nto optimize elevator wait times. Based on simulated user data generated\naccording to the canonical three-peak model of elevator traffic, we first\ndevelop a naive model from an intuitive understanding of the logic behind\nelevators. We take into consideration a general array of features including\ncapacity, acceleration, and maximum wait time thresholds to adequately model\nrealistic circumstances. Using the same evaluation framework, we proceed to\ndevelop a Deep Q Learning model in an attempt to match the hard-coded naive\napproach for elevator control. Throughout the majority of the paper, we work\nunder a Markov Decision Process (MDP) schema, but later explore how the\nassumption fails to characterize the highly stochastic overall Elevator Group\nControl System (EGCS).",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Zheng Cao",
      "Raymond Guo",
      "Caesar M. Tuguinay",
      "Mark Pock",
      "Jiayi Gao",
      "Ziyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00065"
  },
  {
    "id": "arXiv:2210.00066",
    "title": "Improving Policy Learning via Language Dynamics Distillation",
    "abstract": "Recent work has shown that augmenting environments with language descriptions\nimproves policy learning. However, for environments with complex language\nabstractions, learning how to ground language to observations is difficult due\nto sparse, delayed rewards. We propose Language Dynamics Distillation (LDD),\nwhich pretrains a model to predict environment dynamics given demonstrations\nwith language descriptions, and then fine-tunes these language-aware pretrained\nrepresentations via reinforcement learning (RL). In this way, the model is\ntrained to both maximize expected reward and retain knowledge about how\nlanguage relates to environment dynamics. On SILG, a benchmark of five tasks\nwith language descriptions that evaluate distinct generalization challenges on\nunseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD\noutperforms tabula-rasa RL, VAE pretraining, and methods that learn from\nunlabeled demonstrations in inverse RL and reward shaping with pretrained\nexperts. In our analyses, we show that language descriptions in demonstrations\nimprove sample-efficiency and generalization across environments, and that\ndynamics modelling with expert demonstrations is more effective than with\nnon-experts.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. 16 pages, 12 figures\n",
    "authors": [
      "Victor Zhong",
      "Jesse Mu",
      "Luke Zettlemoyer",
      "Edward Grefenstette",
      "Tim Rockt\u00e4schel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00066"
  },
  {
    "id": "arXiv:2210.00068",
    "title": "Multi-Task Option Learning and Discovery for Stochastic Path Planning",
    "abstract": "This paper addresses the problem of reliably and efficiently solving broad\nclasses of long-horizon stochastic path planning problems. Starting with a\nvanilla RL formulation with a stochastic dynamics simulator and an occupancy\nmatrix of the environment, our approach computes useful options with policies\nas well as high-level paths that compose the discovered options.\nOur main contributions are (1) data-driven methods for creating abstract\nstates that serve as endpoints for helpful options, (2) methods for computing\noption policies using auto-generated option guides in the form of dense\npseudo-reward functions, and (3) an overarching algorithm for composing the\ncomputed options. We show that this approach yields strong guarantees of\nexecutability and solvability: under fairly general conditions, the computed\noption guides lead to composable option policies and consequently ensure\ndownward refinability. Empirical evaluation on a range of robots, environments,\nand tasks shows that this approach effectively transfers knowledge across\nrelated tasks and that it outperforms existing approaches by a significant\nmargin.",
    "descriptor": "",
    "authors": [
      "Naman Shah",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00068"
  },
  {
    "id": "arXiv:2210.00069",
    "title": "TOAST: Topological Algorithm for Singularity Tracking",
    "abstract": "The manifold hypothesis, which assumes that data lie on or close to an\nunknown manifold of low intrinsic dimensionality, is a staple of modern machine\nlearning research. However, recent work has shown that real-world data exhibit\ndistinct non-manifold structures, which result in singularities that can lead\nto erroneous conclusions about the data. Detecting such singularities is\ntherefore crucial as a precursor to interpolation and inference tasks. We\naddress detecting singularities by developing (i) persistent local homology, a\nnew topology-driven framework for quantifying the intrinsic dimension of a data\nset locally, and (ii) Euclidicity, a topology-based multi-scale measure for\nassessing the 'manifoldness' of individual points. We show that our approach\ncan reliably identify singularities of complex spaces, while also capturing\nsingular structures in real-world data sets.",
    "descriptor": "",
    "authors": [
      "Julius von Rohrscheidt",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00069"
  },
  {
    "id": "arXiv:2210.00073",
    "title": "Digital Twin and Artificial Intelligence Incorporated With Surrogate  Modeling for Hybrid and Sustainable Energy Systems",
    "abstract": "Surrogate modeling has brought about a revolution in computation in the\nbranches of science and engineering. Backed by Artificial Intelligence, a\nsurrogate model can present highly accurate results with a significant\nreduction in computation time than computer simulation of actual models.\nSurrogate modeling techniques have found their use in numerous branches of\nscience and engineering, energy system modeling being one of them. Since the\nidea of hybrid and sustainable energy systems is spreading rapidly in the\nmodern world for the paradigm of the smart energy shift, researchers are\nexploring the future application of artificial intelligence-based surrogate\nmodeling in analyzing and optimizing hybrid energy systems. One of the\npromising technologies for assessing applicability for the energy system is the\ndigital twin, which can leverage surrogate modeling. This work presents a\ncomprehensive framework/review on Artificial Intelligence-driven surrogate\nmodeling and its applications with a focus on the digital twin framework and\nenergy systems. The role of machine learning and artificial intelligence in\nconstructing an effective surrogate model is explained. After that, different\nsurrogate models developed for different sustainable energy sources are\npresented. Finally, digital twin surrogate models and associated uncertainties\nare described.",
    "descriptor": "",
    "authors": [
      "Abid Hossain Khan",
      "Salauddin Omar",
      "Nadia Mushtary",
      "Richa Verma",
      "Dinesh Kumar",
      "Syed Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00073"
  },
  {
    "id": "arXiv:2210.00074",
    "title": "Leveraging Industry 4.0 -- Deep Learning, Surrogate Model and Transfer  Learning with Uncertainty Quantification Incorporated into Digital Twin for  Nuclear System",
    "abstract": "Industry 4.0 targets the conversion of the traditional industries into\nintelligent ones through technological revolution. This revolution is only\npossible through innovation, optimization, interconnection, and rapid\ndecision-making capability. Numerical models are believed to be the key\ncomponents of Industry 4.0, facilitating quick decision-making through\nsimulations instead of costly experiments. However, numerical investigation of\nprecise, high-fidelity models for optimization or decision-making is usually\ntime-consuming and computationally expensive. In such instances, data-driven\nsurrogate models are excellent substitutes for fast computational analysis and\nthe probabilistic prediction of the output parameter for new input parameters.\nThe emergence of Internet of Things (IoT) and Machine Learning (ML) has made\nthe concept of surrogate modeling even more viable. However, these surrogate\nmodels contain intrinsic uncertainties, originate from modeling defects, or\nboth. These uncertainties, if not quantified and minimized, can produce a\nskewed result. Therefore, proper implementation of uncertainty quantification\ntechniques is crucial during optimization, cost reduction, or safety\nenhancement processes analysis. This chapter begins with a brief overview of\nthe concept of surrogate modeling, transfer learning, IoT and digital twins.\nAfter that, a detailed overview of uncertainties, uncertainty quantification\nframeworks, and specifics of uncertainty quantification methodologies for a\nsurrogate model linked to a digital twin is presented. Finally, the use of\nuncertainty quantification approaches in the nuclear industry has been\naddressed.",
    "descriptor": "",
    "authors": [
      "M. Rahman",
      "Abid Khan",
      "Sayeed Anowar",
      "Md Al-Imran",
      "Richa Verma",
      "Dinesh Kumar",
      "Kazuma Kobayashi",
      "Syed Alam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.00074"
  },
  {
    "id": "arXiv:2210.00075",
    "title": "Mixed-Reality Robot Behavior Replay: A System Implementation",
    "abstract": "As robots become increasingly complex, they must explain their behaviors to\ngain trust and acceptance. However, it may be difficult through verbal\nexplanation alone to fully convey information about past behavior, especially\nregarding objects no longer present due to robots' or humans' actions. Humans\noften try to physically mimic past movements to accompany verbal explanations.\nInspired by this human-human interaction, we describe the technical\nimplementation of a system for past behavior replay for robots in this tool\npaper. Specifically, we used Behavior Trees to encode and separate robot\nbehaviors, and schemaless MongoDB to structurally store and query the\nunderlying sensor data and joint control messages for future replay. Our\napproach generalizes to different types of replays, including both manipulation\nand navigation replay, and visual (i.e., augmented reality (AR)) and auditory\nreplay. Additionally, we briefly summarize a user study to further provide\nempirical evidence of its effectiveness and efficiency. Sample code and\ninstructions are available on GitHub at\nhttps://github.com/umhan35/robot-behavior-replay.",
    "descriptor": "\nComments: 6 pages, 5 figures, the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022\n",
    "authors": [
      "Zhao Han",
      "Tom Williams",
      "Holly A. Yanco"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00075"
  },
  {
    "id": "arXiv:2210.00081",
    "title": "Distributed Implementation of Minimax Adaptive Controller For Finite Set  of Linear Systems",
    "abstract": "This paper deals with a distributed implementation of minimax adaptive\ncontrol algorithm for networked dynamical systems modeled by a finite set of\nlinear models. To hedge against the uncertainty arising out of finite number of\npossible dynamics in each node in the network, it collects only the historical\ndata of its neighboring nodes to decide its control action along its edges.\nThis makes our proposed distributed approach scalable. Numerical simulations\ndemonstrate that once each node has sufficiently estimated the uncertain\nparameters, the distributed minimax adaptive controller behaves like the\noptimal distributed H-infinity controller in hindsight.",
    "descriptor": "",
    "authors": [
      "Venkatraman Renganathan",
      "Anders Rantzer",
      "Olle Kjellqvist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00081"
  },
  {
    "id": "arXiv:2210.00084",
    "title": "Contrastive Graph Few-Shot Learning",
    "abstract": "Prevailing deep graph learning models often suffer from label sparsity issue.\nAlthough many graph few-shot learning (GFL) methods have been developed to\navoid performance degradation in face of limited annotated data, they\nexcessively rely on labeled data, where the distribution shift in the test\nphase might result in impaired generalization ability. Additionally, they lack\na general purpose as their designs are coupled with task or data-specific\ncharacteristics. To this end, we propose a general and effective Contrastive\nGraph Few-shot Learning framework (CGFL). CGFL leverages a self-distilled\ncontrastive learning procedure to boost GFL. Specifically, our model firstly\npre-trains a graph encoder with contrastive learning using unlabeled data.\nLater, the trained encoder is frozen as a teacher model to distill a student\nmodel with a contrastive loss. The distilled model is finally fed to GFL. CGFL\nlearns data representation in a self-supervised manner, thus mitigating the\ndistribution shift impact for better generalization and making model task and\ndata-independent for a general graph mining purpose. Furthermore, we introduce\nan information-based method to quantitatively measure the capability of CGFL.\nComprehensive experiments demonstrate that CGFL outperforms state-of-the-art\nbaselines on several graph mining tasks in the few-shot scenario. We also\nprovide quantitative measurement of CGFL's success.",
    "descriptor": "",
    "authors": [
      "Chunhui Zhang",
      "Hongfu Liu",
      "Jundong Li",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00084"
  },
  {
    "id": "arXiv:2210.00087",
    "title": "D-Align: Dual Query Co-attention Network for 3D Object Detection Based  on Multi-frame Point Cloud Sequence",
    "abstract": "LiDAR sensors are widely used for 3D object detection in various mobile\nrobotics applications. LiDAR sensors continuously generate point cloud data in\nreal-time. Conventional 3D object detectors detect objects using a set of\npoints acquired over a fixed duration. However, recent studies have shown that\nthe performance of object detection can be further enhanced by utilizing\nspatio-temporal information obtained from point cloud sequences. In this paper,\nwe propose a new 3D object detector, named D-Align, which can effectively\nproduce strong bird's-eye-view (BEV) features by aligning and aggregating the\nfeatures obtained from a sequence of point sets. The proposed method includes a\nnovel dual-query co-attention network that uses two types of queries, including\ntarget query set (T-QS) and support query set (S-QS), to update the features of\ntarget and support frames, respectively. D-Align aligns S-QS to T-QS based on\nthe temporal context features extracted from the adjacent feature maps and then\naggregates S-QS with T-QS using a gated attention mechanism. The dual queries\nare updated through multiple attention layers to progressively enhance the\ntarget frame features used to produce the detection results. Our experiments on\nthe nuScenes dataset show that the proposed D-Align method greatly improved the\nperformance of a single frame-based baseline method and significantly\noutperformed the latest 3D object detectors.",
    "descriptor": "",
    "authors": [
      "Junhyung Lee",
      "Junho Koh",
      "Youngwoo Lee",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00087"
  },
  {
    "id": "arXiv:2210.00089",
    "title": "A Multi-label Time Series Classification Approach for Non-intrusive  Water End-Use Monitoring",
    "abstract": "Numerous real-world problems from a diverse set of application areas exist\nthat exhibit temporal dependencies. We focus on a specific type of time series\nclassification which we refer to as aggregated time series classification. We\nconsider an aggregated sequence of a multi-variate time series, and propose a\nmethodology to make predictions based solely on the aggregated information. As\na case study, we apply our methodology to the challenging problem of household\nwater end-use dissagregation when using non-intrusive water monitoring. Our\nmethodology does not require a-priori identification of events, and to our\nknowledge, it is considered for the first time. We conduct an extensive\nexperimental study using a residential water-use simulator, involving different\nmachine learning classifiers, multi-label classification methods, and\nsuccessfully demonstrate the effectiveness of our methodology.",
    "descriptor": "\nComments: 18th International Conference on Artificial Intelligence Applications and Innovations (AIAI), 2022\n",
    "authors": [
      "Dimitris Papatheodoulou",
      "Pavlos Pavlou",
      "Stelios G. Vrachimis",
      "Kleanthis Malialis",
      "Demetrios G. Eliades",
      "Theocharis Theocharides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00089"
  },
  {
    "id": "arXiv:2210.00090",
    "title": "Data-driven discovery of non-Newtonian astronomy via learning  non-Euclidean Hamiltonian",
    "abstract": "Incorporating the Hamiltonian structure of physical dynamics into deep\nlearning models provides a powerful way to improve the interpretability and\nprediction accuracy. While previous works are mostly limited to the Euclidean\nspaces, their extension to the Lie group manifold is needed when rotations form\na key component of the dynamics, such as the higher-order physics beyond simple\npoint-mass dynamics for N-body celestial interactions. Moreover, the multiscale\nnature of these processes presents a challenge to existing methods as a long\ntime horizon is required. By leveraging a symplectic Lie-group manifold\npreserving integrator, we present a method for data-driven discovery of\nnon-Newtonian astronomy. Preliminary results show the importance of both these\nproperties in training stability and prediction accuracy.",
    "descriptor": "",
    "authors": [
      "Oswin So",
      "Gongjie Li",
      "Evangelos A. Theodorou",
      "Molei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00090"
  },
  {
    "id": "arXiv:2210.00092",
    "title": "Federated Training of Dual Encoding Models on Small Non-IID Client  Datasets",
    "abstract": "Dual encoding models that encode a pair of inputs are widely used for\nrepresentation learning. Many approaches train dual encoding models by\nmaximizing agreement between pairs of encodings on centralized training data.\nHowever, in many scenarios, datasets are inherently decentralized across many\nclients (user devices or organizations) due to privacy concerns, motivating\nfederated learning. In this work, we focus on federated training of dual\nencoding models on decentralized data composed of many small, non-IID\n(independent and identically distributed) client datasets. We show that\nexisting approaches that work well in centralized settings perform poorly when\nnaively adapted to this setting using federated averaging. We observe that, we\ncan simulate large-batch loss computation on individual clients for loss\nfunctions that are based on encoding statistics. Based on this insight, we\npropose a novel federated training approach, Distributed Cross Correlation\nOptimization (DCCO), which trains dual encoding models using encoding\nstatistics aggregated across clients, without sharing individual data samples.\nOur experimental results on two datasets demonstrate that the proposed DCCO\napproach outperforms federated variants of existing approaches by a large\nmargin.",
    "descriptor": "",
    "authors": [
      "Raviteja Vemulapalli",
      "Warren Richard Morningstar",
      "Philip Andrew Mansfield",
      "Hubert Eichner",
      "Karan Singhal",
      "Arash Afkanpour",
      "Bradley Green"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00092"
  },
  {
    "id": "arXiv:2210.00093",
    "title": "Shockwave: Fair and Efficient Cluster Scheduling for Dynamic Adaptation  in Machine Learning",
    "abstract": "Dynamic adaptation has become an essential technique in accelerating\ndistributed machine learning (ML) training. Recent studies have shown that\ndynamically adjusting model structure (e.g., lottery ticket hypothesis) or\nhyperparameters (e.g., batch size) can significantly accelerate training\nwithout sacrificing accuracy. However, existing ML cluster schedulers are not\ndesigned to handle dynamic adaptation. We show that existing schemes fail to\nprovide fairness and degrade system efficiency when the training throughput\nchanges over time under dynamic adaptation. We design Shockwave, a scheduler\nwith future planning that builds on two key ideas. First, Shockwave extends\nclassic market theory from static settings to dynamic settings to co-optimize\nefficiency and fairness. Second, Shockwave utilizes stochastic dynamic\nprogramming to handle dynamic changes. We build a system for Shockwave and\nvalidate its performance with both trace-driven simulation and cluster\nexperiments. Results show that for traces of ML jobs with dynamic adaptation,\nShockwave improves makespan by 1.3X and fairness by 2X when compared with\nexisting fair scheduling schemes.",
    "descriptor": "\nComments: Accepted at the 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI '23)\n",
    "authors": [
      "Pengfei Zheng",
      "Rui Pan",
      "Tarannum Khan",
      "Shivaram Venkataraman",
      "Aditya Akella"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00093"
  },
  {
    "id": "arXiv:2210.00094",
    "title": "Adaptive Weight Decay: On The Fly Weight Decay Tuning for Improving  Robustness",
    "abstract": "We introduce adaptive weight decay, which automatically tunes the\nhyper-parameter for weight decay during each training iteration. For\nclassification problems, we propose changing the value of the weight decay\nhyper-parameter on the fly based on the strength of updates from the\nclassification loss (i.e., gradient of cross-entropy), and the regularization\nloss (i.e., $\\ell_2$-norm of the weights). We show that this simple\nmodification can result in large improvements in adversarial robustness -- an\narea which suffers from robust overfitting -- without requiring extra data.\nSpecifically, our reformulation results in 20% relative robustness improvement\nfor CIFAR-100, and 10% relative robustness improvement on CIFAR-10 comparing to\ntraditional weight decay. In addition, this method has other desirable\nproperties, such as less sensitivity to learning rate, and smaller weight\nnorms, which the latter contributes to robustness to overfitting to label\nnoise, and pruning.",
    "descriptor": "",
    "authors": [
      "Amin Ghiasi",
      "Ali Shafahi",
      "Reza Ardekani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00094"
  },
  {
    "id": "arXiv:2210.00095",
    "title": "Safety-Critical Adaptation in Self-Adaptive Systems",
    "abstract": "Modern systems are designed to operate in increasingly variable and uncertain\nenvironments. Not only are these environments complex, in the sense that they\ncontain a tremendous number of variables, but they also change over time.\nSystems must be able to adjust their behaviour at run-time to manage these\nuncertainties. These self-adaptive systems have been studied extensively. This\npaper proposes a definition of a safety-critical self-adaptive system and then\ndescribes a taxonomy for classifying adaptations into different types based on\ntheir impact on the system's safety and the system's safety case. The taxonomy\nexpresses criteria for classification and then describes specific criteria that\nthe safety case for a self-adaptive system must satisfy, depending on the type\nof adaptations performed. Each type in the taxonomy is illustrated using the\nexample of a safety-critical self-adaptive water heating system.",
    "descriptor": "\nComments: Submitted to The 1st IEEE International Workshop on Assured Autonomy, Artificial Intelligence and Machine Learning (WAAM) 2022\n",
    "authors": [
      "Simon Diemert",
      "Jens H. Weber"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00095"
  },
  {
    "id": "arXiv:2210.00100",
    "title": "Image-Based Detection of Modifications in Gas Pump PCBs with Deep  Convolutional Autoencoders",
    "abstract": "In this paper, we introduce an approach for detecting modifications in\nassembled printed circuit boards based on photographs taken without tight\ncontrol over perspective and illumination conditions. One instance of this\nproblem is the visual inspection of gas pumps PCBs, which can be modified by\nfraudsters wishing to deceive costumers or evade taxes. Given the uncontrolled\nenvironment and the huge number of possible modifications, we address the\nproblem as a case of anomaly detection, proposing an approach that is directed\ntowards the characteristics of that scenario, while being well-suited for other\nsimilar applications. The proposed approach employs a deep convolutional\nautoencoder trained to reconstruct images of an unmodified board, but which\nremains unable to do the same for images showing modifications. By comparing\nthe input image with its reconstruction, it is possible to segment anomalies\nand modifications in a pixel-wise manner. Experiments performed on a dataset\nbuilt to represent real-world situations (and which we will make publicly\navailable) show that our approach outperforms other state-of-the-art approaches\nfor anomaly segmentation in the considered scenario, while producing comparable\nresults on the popular MVTec-AD dataset for a more general object anomaly\ndetection task.",
    "descriptor": "",
    "authors": [
      "Diulhio Candido de Oliveira",
      "Bogdan Tomoyuki Nassu",
      "Marco Aurelio Wehrmeister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00100"
  },
  {
    "id": "arXiv:2210.00102",
    "title": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP  Initialization",
    "abstract": "Training graph neural networks (GNNs) on large graphs is complex and\nextremely time consuming. This is attributed to overheads caused by sparse\nmatrix multiplication, which are sidestepped when training multi-layer\nperceptrons (MLPs) with only node features. MLPs, by ignoring graph context,\nare simple and faster for graph data, however they usually sacrifice prediction\naccuracy, limiting their applications for graph data. We observe that for most\nmessage passing-based GNNs, we can trivially derive an analog MLP (we call this\na PeerMLP) whose weights can be made identical, making us curious about how do\nGNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find\nthat GNNs initialized with such weights significantly outperform their PeerMLPs\nfor graph data, motivating us to use PeerMLP training as a precursor,\ninitialization step to GNN training. To this end, we propose an embarrassingly\nsimple, yet hugely effective initialization method for GNN training\nacceleration, called MLPInit. Our extensive experiments on multiple large-scale\ngraph datasets with diverse GNN architectures validate that MLPInit can\naccelerate the training of GNNs (up to 33X speedup on OGB-products) and often\nimprove prediction performance (e.g., up to 7.97% improvement for GraphSAGE\nacross 7 datasets for node classification, and up to 17.81% improvement across\n4 datasets for link prediction on metric Hits@10). Most importantly, MLPInit is\nextremely simple to implement and can be flexibly used as a plug-and-play\ninitialization method for message passing-based GNNs.",
    "descriptor": "",
    "authors": [
      "Xiaotian Han",
      "Tong Zhao",
      "Yozen Liu",
      "Xia Hu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.00102"
  },
  {
    "id": "arXiv:2210.00105",
    "title": "A Decade of Knowledge Graphs in Natural Language Processing: A Survey",
    "abstract": "In pace with developments in the research field of artificial intelligence,\nknowledge graphs (KGs) have attracted a surge of interest from both academia\nand industry. As a representation of semantic relations between entities, KGs\nhave proven to be particularly relevant for natural language processing (NLP),\nexperiencing a rapid spread and wide adoption within recent years. Given the\nincreasing amount of research work in this area, several KG-related approaches\nhave been surveyed in the NLP research community. However, a comprehensive\nstudy that categorizes established topics and reviews the maturity of\nindividual research streams remains absent to this day. Contributing to closing\nthis gap, we systematically analyzed 507 papers from the literature on KGs in\nNLP. Our survey encompasses a multifaceted review of tasks, research types, and\ncontributions. As a result, we present a structured overview of the research\nlandscape, provide a taxonomy of tasks, summarize our findings, and highlight\ndirections for future work.",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Phillip Schneider",
      "Tim Schopf",
      "Juraj Vladika",
      "Mikhail Galkin",
      "Elena Simperl",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00105"
  },
  {
    "id": "arXiv:2210.00107",
    "title": "Contrastive Corpus Attribution for Explaining Representations",
    "abstract": "Despite the widespread use of unsupervised models, very few methods are\ndesigned to explain them. Most explanation methods explain a scalar model\noutput. However, unsupervised models output representation vectors, the\nelements of which are not good candidates to explain because they lack semantic\nmeaning. To bridge this gap, recent works defined a scalar explanation output:\na dot product-based similarity in the representation space to the sample being\nexplained (i.e., an explicand). Although this enabled explanations of\nunsupervised models, the interpretation of this approach can still be opaque\nbecause similarity to the explicand's representation may not be meaningful to\nhumans. To address this, we propose contrastive corpus similarity, a novel and\nsemantically meaningful scalar explanation output based on a reference corpus\nand a contrasting foil set of samples. We demonstrate that contrastive corpus\nsimilarity is compatible with many post-hoc feature attribution methods to\ngenerate COntrastive COrpus Attributions (COCOA) and quantitatively verify that\nfeatures important to the corpus are identified. We showcase the utility of\nCOCOA in two ways: (i) we draw insights by explaining augmentations of the same\nimage in a contrastive learning setting (SimCLR); and (ii) we perform zero-shot\nobject localization by explaining the similarity of image representations to\njointly learned text representations (CLIP).",
    "descriptor": "",
    "authors": [
      "Chris Lin",
      "Hugh Chen",
      "Chanwoo Kim",
      "Su-In Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00107"
  },
  {
    "id": "arXiv:2210.00108",
    "title": "ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled  neural networks",
    "abstract": "Early backdoor attacks against machine learning set off an arms race in\nattack and defence development. Defences have since appeared demonstrating some\nability to detect backdoors in models or even remove them. These defences work\nby inspecting the training data, the model, or the integrity of the training\nprocedure. In this work, we show that backdoors can be added during\ncompilation, circumventing any safeguards in the data preparation and model\ntraining stages. As an illustration, the attacker can insert weight-based\nbackdoors during the hardware compilation step that will not be detected by any\ntraining or data-preparation process. Next, we demonstrate that some backdoors,\nsuch as ImpNet, can only be reliably detected at the stage where they are\ninserted and removing them anywhere else presents a significant challenge. We\nconclude that machine-learning model security requires assurance of provenance\nalong the entire technical pipeline, including the data, model architecture,\ncompiler, and hardware specification.",
    "descriptor": "\nComments: 10 pages, 6 figures. For website see this https URL . For source code, see this https URL\n",
    "authors": [
      "Tim Clifford",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Ross Anderson",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00108"
  },
  {
    "id": "arXiv:2210.00113",
    "title": "Institutional Foundations of Adaptive Planning: Exploration of Flood  Planning in the Lower Rio Grande Valley, Texas, USA",
    "abstract": "Adaptive planning is ideally suited for the deep uncertainties presented by\nclimate change. While there is a robust scholarship on the theory and methods\nof adaptive planning, this has largely neglected how adaptive planning is\naffected by existing planning institutions and how to move forward within the\nconstraints of traditional planning organizations. This study asks: How do\nexisting traditional planning institutions support adaptive planning? We\nexplore this for flood planning in the Lower Rio Grande Valley of Texas, United\nStates. We draw on county hazard plan and regional flood plan documents as well\nas transcripts of regional flood planning meetings to explore the emergent\ntopics of these institutional outputs. Using Natural Language Processing to\nanalyze this large amount of text, we find that hazard plans and discussions\ndeveloping these plans are largely lacking an adaptive approach.",
    "descriptor": "",
    "authors": [
      "Ashley D. Ross",
      "Ali Nejat",
      "Virgie Greb"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.00113"
  },
  {
    "id": "arXiv:2210.00116",
    "title": "Predicting Cellular Responses with Variational Causal Inference and  Refined Relational Information",
    "abstract": "Predicting the responses of a cell under perturbations may bring important\nbenefits to drug discovery and personalized therapeutics. In this work, we\npropose a novel graph variational Bayesian causal inference framework to\npredict a cell's gene expressions under counterfactual perturbations\n(perturbations that this cell did not factually receive), leveraging\ninformation representing biological knowledge in the form of gene regulatory\nnetworks (GRNs) to aid individualized cellular response predictions. Aiming at\na data-adaptive GRN, we also developed an adjacency matrix updating technique\nfor graph convolutional networks and used it to refine GRNs during\npre-training, which generated more insights on gene relations and enhanced\nmodel performance. Additionally, we propose a robust estimator within our\nframework for the asymptotically efficient estimation of marginal perturbation\neffect, which is yet to be carried out in previous works. With extensive\nexperiments, we exhibited the advantage of our approach over state-of-the-art\ndeep learning models for individual response prediction.",
    "descriptor": "",
    "authors": [
      "Yulun Wu",
      "Robert A. Barton",
      "Zichen Wang",
      "Vassilis N. Ioannidis",
      "Carlo De Donno",
      "Layne C. Price",
      "Luis F. Voloch",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00116"
  },
  {
    "id": "arXiv:2210.00120",
    "title": "NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning",
    "abstract": "Neural Motion Planners (NMPs) have emerged as a promising tool for solving\nrobot navigation tasks in complex environments. However, these methods often\nrequire expert data for learning, which limits their application to scenarios\nwhere data generation is time-consuming. Recent developments have also led to\nphysics-informed deep neural models capable of representing complex dynamical\nPartial Differential Equations (PDEs). Inspired by these developments, we\npropose Neural Time Fields (NTFields) for robot motion planning in cluttered\nscenarios. Our framework represents a wave propagation model generating\ncontinuous arrival time to find path solutions informed by a nonlinear\nfirst-order PDE called Eikonal Equation. We evaluate our method in various\ncluttered 3D environments, including the Gibson dataset, and demonstrate its\nability to solve motion planning problems for 4-DOF and 6-DOF robot\nmanipulators where the traditional grid-based Eikonal planners often face the\ncurse of dimensionality. Furthermore, the results show that our method exhibits\nhigh success rates and significantly lower computational times than the\nstate-of-the-art methods, including NMPs that require training data from\nclassical planners.",
    "descriptor": "",
    "authors": [
      "Ruiqi Ni",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00120"
  },
  {
    "id": "arXiv:2210.00121",
    "title": "Visuo-Tactile Transformers for Manipulation",
    "abstract": "Learning representations in the joint domain of vision and touch can improve\nmanipulation dexterity, robustness, and sample-complexity by exploiting mutual\ninformation and complementary cues. Here, we present Visuo-Tactile Transformers\n(VTTs), a novel multimodal representation learning approach suited for\nmodel-based reinforcement learning and planning. Our approach extends the\nVisual Transformer \\cite{dosovitskiy2021image} to handle visuo-tactile\nfeedback. Specifically, VTT uses tactile feedback together with self and\ncross-modal attention to build latent heatmap representations that focus\nattention on important task features in the visual domain. We demonstrate the\nefficacy of VTT for representation learning with a comparative evaluation\nagainst baselines on four simulated robot tasks and one real world block\npushing task. We conduct an ablation study over the components of VTT to\nhighlight the importance of cross-modality in representation learning.",
    "descriptor": "\nComments: Accepted to CoRL 2022\n",
    "authors": [
      "Yizhou Chen",
      "Andrea Sipos",
      "Mark Van der Merwe",
      "Nima Fazeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00121"
  },
  {
    "id": "arXiv:2210.00122",
    "title": "Adversarial Robustness of Representation Learning for Knowledge Graphs",
    "abstract": "Knowledge graphs represent factual knowledge about the world as relationships\nbetween concepts and are critical for intelligent decision making in enterprise\napplications. New knowledge is inferred from the existing facts in the\nknowledge graphs by encoding the concepts and relations into low-dimensional\nfeature vector representations. The most effective representations for this\ntask, called Knowledge Graph Embeddings (KGE), are learned through neural\nnetwork architectures. Due to their impressive predictive performance, they are\nincreasingly used in high-impact domains like healthcare, finance and\neducation. However, are the black-box KGE models adversarially robust for use\nin domains with high stakes? This thesis argues that state-of-the-art KGE\nmodels are vulnerable to data poisoning attacks, that is, their predictive\nperformance can be degraded by systematically crafted perturbations to the\ntraining knowledge graph. To support this argument, two novel data poisoning\nattacks are proposed that craft input deletions or additions at training time\nto subvert the learned model's performance at inference time. These adversarial\nattacks target the task of predicting the missing facts in knowledge graphs\nusing KGE models, and the evaluation shows that the simpler attacks are\ncompetitive with or outperform the computationally expensive ones. The thesis\ncontributions not only highlight and provide an opportunity to fix the security\nvulnerabilities of KGE models, but also help to understand the black-box\npredictive behaviour of KGE models.",
    "descriptor": "\nComments: PhD Thesis at Trinity College Dublin, Ireland\n",
    "authors": [
      "Peru Bhardwaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00122"
  },
  {
    "id": "arXiv:2210.00123",
    "title": "Multi-Robot Motion Planning for Unit Discs with Revolving Areas",
    "abstract": "We study the problem of motion planning for a collection of $n$ labeled unit\ndisc robots in a polygonal environment. We assume that the robots have\n\\emph{revolving areas} around their start and final positions: that each start\nand each final is contained in a radius $2$ disc lying in the free space, not\nnecessarily concentric with the start or final position, which is free from\nother start or final positions. This assumption allows a \\emph{weakly-monotone}\nmotion plan, in which robots move according to an ordering as follows: during\nthe turn of a robot $R$ in the ordering, it moves fully from its start to final\nposition, while other robots do not leave their revolving areas. As $R$ passes\nthrough a revolving area, a robot $R'$ that is inside this area may move within\nthe revolving area to avoid a collision. Notwithstanding the existence of a\nmotion plan, we show that minimizing the total traveled distance in this\nsetting, specifically even when the motion plan is restricted to be\nweakly-monotone, is APX-hard, ruling out any polynomial-time\n$(1+\\epsilon)$-approximation algorithm.\nOn the positive side, we present the first constant-factor approximation\nalgorithm for computing a feasible weakly-monotone motion plan. The total\ndistance traveled by the robots is within an $O(1)$ factor of that of the\noptimal motion plan, which need not be weakly monotone. Our algorithm extends\nto an online setting in which the polygonal environment is fixed but the\ninitial and final positions of robots are specified in an online manner.\nFinally, we observe that the overhead in the overall cost that we add while\nediting the paths to avoid robot-robot collision can vary significantly\ndepending on the ordering we chose. Finding the best ordering in this respect\nis known to be NP-hard, and we provide a polynomial time $O(\\log n \\log \\log\nn)$-approximation algorithm for this problem.",
    "descriptor": "",
    "authors": [
      "Pankaj K. Agarwal",
      "Tzvika Geft",
      "Dan Halperin",
      "Erin Taylor"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00123"
  },
  {
    "id": "arXiv:2210.00124",
    "title": "Implicit Neural Spatial Representations for Time-dependent PDEs",
    "abstract": "Numerically solving partial differential equations (PDEs) often entails\nspatial and temporal discretizations. Traditional methods (e.g., finite\ndifference, finite element, smoothed-particle hydrodynamics) frequently adopt\nexplicit spatial discretizations, such as grids, meshes, and point clouds,\nwhere each degree-of-freedom corresponds to a location in space. While these\nexplicit spatial correspondences are intuitive to model and understand, these\nrepresentations are not necessarily optimal for accuracy, memory-usage, or\nadaptivity. In this work, we explore implicit neural representation as an\nalternative spatial discretization, where spatial information is implicitly\nstored in the neural network weights. With implicit neural spatial\nrepresentation, PDE-constrained time-stepping translates into updating neural\nnetwork weights, which naturally integrates with commonly adopted optimization\ntime integrators. We validate our approach on a variety of classic PDEs with\nexamples involving large elastic deformations, turbulent fluids, and multiscale\nphenomena. While slower to compute than traditional representations, our\napproach exhibits higher accuracy, lower memory consumption, and dynamically\nadaptive allocation of degrees of freedom without complex remeshing.",
    "descriptor": "",
    "authors": [
      "Honglin Chen",
      "Rundi Wu",
      "Eitan Grinspun",
      "Changxi Zheng",
      "Peter Yichen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00124"
  },
  {
    "id": "arXiv:2210.00125",
    "title": "A Taxonomy of Semantic Information in Robot-Assisted Disaster Response",
    "abstract": "This paper proposes a taxonomy of semantic information in robot-assisted\ndisaster response. Robots are increasingly being used in hazardous environment\nindustries and emergency response teams to perform various tasks. Operational\ndecision-making in such applications requires a complex semantic understanding\nof environments that are remote from the human operator. Low-level sensory data\nfrom the robot is transformed into perception and informative cognition.\nCurrently, such cognition is predominantly performed by a human expert, who\nmonitors remote sensor data such as robot video feeds. This engenders a need\nfor AI-generated semantic understanding capabilities on the robot itself.\nCurrent work on semantics and AI lies towards the relatively academic end of\nthe research spectrum, hence relatively removed from the practical realities of\nfirst responder teams. We aim for this paper to be a step towards bridging this\ndivide. We first review common robot tasks in disaster response and the types\nof information such robots must collect. We then organize the types of semantic\nfeatures and understanding that may be useful in disaster operations into a\ntaxonomy of semantic information. We also briefly review the current\nstate-of-the-art semantic understanding techniques. We highlight potential\nsynergies, but we also identify gaps that need to be bridged to apply these\nideas. We aim to stimulate the research that is needed to adapt, robustify, and\nimplement state-of-the-art AI semantics methods in the challenging conditions\nof disasters and first responder scenarios.",
    "descriptor": "",
    "authors": [
      "Tianshu Ruan",
      "Hao Wang",
      "Rustam Stolkin",
      "Manolis Chiou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00125"
  },
  {
    "id": "arXiv:2210.00127",
    "title": "Robust Person Identification: A WiFi Vision-based Approach",
    "abstract": "Person re-identification (Re-ID) has become increasingly important as it\nsupports a wide range of security applications. Traditional person Re-ID mainly\nrelies on optical camera-based systems, which incur several limitations due to\nthe changes in the appearance of people, occlusions, and human poses. In this\nwork, we propose a WiFi vision-based system, 3D-ID, for person Re-ID in 3D\nspace. Our system leverages the advances of WiFi and deep learning to help WiFi\ndevices see, identify, and recognize people. In particular, we leverage\nmultiple antennas on next-generation WiFi devices and 2D AoA estimation of the\nsignal reflections to enable WiFi to visualize a person in the physical\nenvironment. We then leverage deep learning to digitize the visualization of\nthe person into 3D body representation and extract both the static body shape\nand dynamic walking patterns for person Re-ID. Our evaluation results under\nvarious indoor environments show that the 3D-ID system achieves an overall\nrank-1 accuracy of 85.3%. Results also show that our system is resistant to\nvarious attacks. The proposed 3D-ID is thus very promising as it could augment\nor complement camera-based systems.",
    "descriptor": "\nComments: 18 pages, USENIX Security '23\n",
    "authors": [
      "Yili Ren",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00127"
  },
  {
    "id": "arXiv:2210.00128",
    "title": "Equity Scores for Public Transit Lines from Open-Data and Accessibility  Measures",
    "abstract": "Current transit suffers from an evident inequity: the level of service of\ntransit in suburbs is much less satisfying than in city centers. As a\nconsequence, private cars are still the dominant transportation mode for\nsuburban people, which results in congestion and pollution. To achieve\nsustainability goals and reduce car-dependency, transit should be (re)designed\naround equity. To this aim, it is necessary to (i) quantify the \"level of\nequity\" of the transit system and (ii) provide an indicator that scores the\ntransit lines that contribute the most to keep transit equitable. This\nindicator could suggest on which lines the transit operator must invest to\nincrease the service level (frequency or coverage) in order to reduce inequity\nin the system.\nTo the best of our knowledge, this paper is the first to tackle (ii). To this\naim, we propose efficient scoring methods that rely solely on open data, which\nallows us to perform the analysis on multiple cities (7 in this paper). Our\nmethod can be used to guide large-scale iterative optimization algorithms to\nimprove accessibility equity.",
    "descriptor": "",
    "authors": [
      "Amirhesam Badeanlou",
      "Andrea Araldo",
      "Marco Diana",
      "Vincent Gauthier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.00128"
  },
  {
    "id": "arXiv:2210.00129",
    "title": "An In-depth Study of Stochastic Backpropagation",
    "abstract": "In this paper, we provide an in-depth study of Stochastic Backpropagation\n(SBP) when training deep neural networks for standard image classification and\nobject detection tasks. During backward propagation, SBP calculates the\ngradients by only using a subset of feature maps to save the GPU memory and\ncomputational cost. We interpret SBP as an efficient way to implement\nstochastic gradient decent by performing backpropagation dropout, which leads\nto considerable memory saving and training process speedup, with a minimal\nimpact on the overall model accuracy. We offer some good practices to apply SBP\nin training image recognition models, which can be adopted in learning a wide\nrange of deep neural networks. Experiments on image classification and object\ndetection show that SBP can save up to 40% of GPU memory with less than 1%\naccuracy degradation.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jun Fang",
      "Mingze Xu",
      "Hao Chen",
      "Bing Shuai",
      "Zhuowen Tu",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00129"
  },
  {
    "id": "arXiv:2210.00130",
    "title": "Midas: A Multi-Joint Robotics Simulator with Intersection-Free  Frictional Contact",
    "abstract": "We introduce Midas, a robotics simulation framework based on the Incremental\nPotential Contact (IPC) model. Our simulator guarantees intersection-free,\nstable, and accurate resolution of frictional contact. We demonstrate the\nefficacy of our framework with experimental validations on high-precision tasks\nand through comparisons with Bullet physics. A reinforcement learning pipeline\nusing Midas is also developed and tested to perform intersection-free\npeg-in-hole tasks.",
    "descriptor": "",
    "authors": [
      "Yunuo Chen",
      "Minchen Li",
      "Wenlong Lu",
      "Chuyuan Fu",
      "Chenfanfu Jiang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00130"
  },
  {
    "id": "arXiv:2210.00131",
    "title": "Exploiting Selection Bias on Underspecified Tasks in Large Language  Models",
    "abstract": "In this paper we motivate the causal mechanisms behind sample selection\ninduced collider bias (selection collider bias) that can cause Large Language\nModels (LLMs) to learn unconditional dependence between entities that are\nunconditionally independent in the real world. We show that selection collider\nbias can become amplified in underspecified learning tasks, and although\ndifficult to overcome, we describe a method to exploit the resulting spurious\ncorrelations for determination of when a model may be uncertain about its\nprediction. We demonstrate an uncertainty metric that matches human uncertainty\nin tasks with gender pronoun underspecification on an extended version of the\nWinogender Schemas evaluation set, and we provide online demos where users can\nevaluate spurious correlations and apply our uncertainty metric to their own\ntexts and models. Finally, we generalize our approach to address a wider range\nof prediction tasks.",
    "descriptor": "\nComments: 15 pages, 20 figures. arXiv admin note: substantial text overlap with arXiv:2208.10063\n",
    "authors": [
      "Emily McMilin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00131"
  },
  {
    "id": "arXiv:2210.00132",
    "title": "Alignment-guided Temporal Attention for Video Action Recognition",
    "abstract": "Temporal modeling is crucial for various video learning tasks. Most recent\napproaches employ either factorized (2D+1D) or joint (3D) spatial-temporal\noperations to extract temporal contexts from the input frames. While the former\nis more efficient in computation, the latter often obtains better performance.\nIn this paper, we attribute this to a dilemma between the sufficiency and the\nefficiency of interactions among various positions in different frames. These\ninteractions affect the extraction of task-relevant information shared among\nframes. To resolve this issue, we prove that frame-by-frame alignments have the\npotential to increase the mutual information between frame representations,\nthereby including more task-relevant information to boost effectiveness. Then\nwe propose Alignment-guided Temporal Attention (ATA) to extend 1-dimensional\ntemporal attention with parameter-free patch-level alignments between\nneighboring frames. It can act as a general plug-in for image backbones to\nconduct the action recognition task without any model-specific design.\nExtensive experiments on multiple benchmarks demonstrate the superiority and\ngenerality of our module.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yizhou Zhao",
      "Zhenyang Li",
      "Xun Guo",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00132"
  },
  {
    "id": "arXiv:2210.00134",
    "title": "Towards Implementing ML-Based Failure Detectors",
    "abstract": "Most existing failure detection algorithms rely on statistical methods, and\nvery few use machine learning (ML). This paper explores the viability of ML in\nthe field of failure detection: is it possible to implement an ML-based\ndetector that achieves a satisfactory quality of service? We implement a\nprototype that uses a basic long short-term memory neural network algorithm,\nand study its behavior with real traces. Although ML model has comparatively\nlonger computing time, our prototype performs well in terms of accuracy and\ndetection time.",
    "descriptor": "\nComments: 4 pages, 3 figures Editor: Ib\\'eria Medeiros. 18th European Dependable Computing Conference (EDCC 2022), September 12-15, 2022, Zaragoza, Spain. Student Forum Proceedings - EDCC 2022\n",
    "authors": [
      "Xiaonan Li",
      "Olivier Marin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00134"
  },
  {
    "id": "arXiv:2210.00135",
    "title": "Deep Learning Classification of Touch Gestures Using Distributed Normal  and Shear Force",
    "abstract": "When humans socially interact with another agent (e.g., human, pet, or robot)\nthrough touch, they do so by applying varying amounts of force with different\ndirections, locations, contact areas, and durations. While previous work on\ntouch gesture recognition has focused on the spatio-temporal distribution of\nnormal forces, we hypothesize that the addition of shear forces will permit\nmore reliable classification. We present a soft, flexible skin with an array of\ntri-axial tactile sensors for the arm of a person or robot. We use it to\ncollect data on 13 touch gesture classes through user studies and train a\nConvolutional Neural Network (CNN) to learn spatio-temporal features from the\nrecorded data. The network achieved a recognition accuracy of 74% with normal\nand shear data, compared to 66% using only normal force data. Adding\ndistributed shear data improved classification accuracy for 11 out of 13 touch\ngesture classes.",
    "descriptor": "",
    "authors": [
      "Hojung Choi",
      "Dane Brouwer",
      "Michael A. Lin",
      "Kyle T. Yoshida",
      "Carine Rognon",
      "Benjamin Stephens-Fripp",
      "Allison M. Okamura",
      "Mark R. Cutkosky"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00135"
  },
  {
    "id": "arXiv:2210.00136",
    "title": "IMB-NAS: Neural Architecture Search for Imbalanced Datasets",
    "abstract": "Class imbalance is a ubiquitous phenomenon occurring in real world data\ndistributions. To overcome its detrimental effect on training accurate\nclassifiers, existing work follows three major directions: class re-balancing,\ninformation transfer, and representation learning. In this paper, we propose a\nnew and complementary direction for improving performance on long tailed\ndatasets - optimizing the backbone architecture through neural architecture\nsearch (NAS). We find that an architecture's accuracy obtained on a balanced\ndataset is not indicative of good performance on imbalanced ones. This poses\nthe need for a full NAS run on long tailed datasets which can quickly become\nprohibitively compute intensive. To alleviate this compute burden, we aim to\nefficiently adapt a NAS super-network from a balanced source dataset to an\nimbalanced target one. Among several adaptation strategies, we find that the\nmost effective one is to retrain the linear classification head with reweighted\nloss, while freezing the backbone NAS super-network trained on a balanced\nsource dataset. We perform extensive experiments on multiple datasets and\nprovide concrete insights to optimize architectures for long tailed datasets.",
    "descriptor": "",
    "authors": [
      "Rahul Duggal",
      "Shengyun Peng",
      "Hao Zhou",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00136"
  },
  {
    "id": "arXiv:2210.00137",
    "title": "Going In Blind: Object Motion Classification using Distributed Tactile  Sensing for Safe Reaching in Clutter",
    "abstract": "Robotic manipulators navigating cluttered shelves or cabinets may find it\nchallenging to avoid contact with obstacles. Indeed, rearranging obstacles may\nbe necessary to access a target. Rather than planning explicit motions that\nplace obstacles into a desired pose, we suggest allowing incidental contacts to\nrearrange obstacles while monitoring contacts for safety. Bypassing object\nidentification, we present a method for categorizing object motions from\ntactile data collected from incidental contacts with a capacitive tactile skin\non an Allegro Hand. We formalize tactile cues associated with categories of\nobject motion, demonstrating that they can determine with $>90$% accuracy\nwhether an object is movable and whether a contact is causing the object to\nslide stably (safe contact) or tip (unsafe).",
    "descriptor": "\nComments: This paper has been accepted to be presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Rachel Thomasson",
      "Etienne Roberge",
      "Mark R. Cutkosky",
      "Jean-Philippe Roberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00137"
  },
  {
    "id": "arXiv:2210.00139",
    "title": "Code Reviews in Open Source Projects : How Do Gender Biases Affect  Participation and Outcomes?",
    "abstract": "Context: Contemporary software development organizations lack diversity and\nthe ratios of women in Free and open-source software (FOSS) communities are\neven lower than the industry average. Although the results of recent studies\nhint the existence of biases against women, it is unclear to what extent such\nbiases influence the outcomes of various software development tasks.\nAim: We aim to identify whether the outcomes of or participation in code\nreviews (or pull requests) are influenced by the gender of a developer..\nApproach: With this goal, this study includes a total 1010 FOSS projects. We\ndeveloped six regression models for each of the 14 dataset (i.e., 10 Gerrit\nbased and four Github) to identify if code acceptance, review intervals, and\ncode review participation differ based on the gender and gender neutral profile\nof a developer.\nKey findings: Our results find significant gender biases during code\nacceptance among 13 out of the 14 datasets, with seven seven favoring men and\nthe remaining six favoring women. We also found significant differences between\nmen and women in terms of code review intervals, with women encountering longer\ndelays in three cases and the opposite in seven. Our results indicate reviewer\nselection as one of the most gender biased aspects among most of the projects,\nwith women having significantly lower code review participation among 11 out of\nthe 14 cases. Since most of the review assignments are based on invitations,\nthis result suggests possible affinity biases among the developers.\nConclusion: Though gender bias exists among many projects, direction and\namplitude of bias varies based on project size, community and culture. Similar\nbias mitigation strategies may not work across all communities, as\ncharacteristics of biases and their underlying causes differ.",
    "descriptor": "",
    "authors": [
      "Sayma Sultana",
      "Asif Kamal Turzo",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.00139"
  },
  {
    "id": "arXiv:2210.00140",
    "title": "Efficiently Learning Small Policies for Locomotion and Manipulation",
    "abstract": "Neural control of memory-constrained, agile robots requires small, yet highly\nperformant models. We leverage graph hyper networks to learn graph hyper\npolicies trained with off-policy reinforcement learning resulting in networks\nthat are two orders of magnitude smaller than commonly used networks yet encode\npolicies comparable to those encoded by much larger networks trained on the\nsame task. We show that our method can be appended to any off-policy\nreinforcement learning algorithm, without any change in hyperparameters, by\nshowing results across locomotion and manipulation tasks. Further, we obtain an\narray of working policies, with differing numbers of parameters, allowing us to\npick an optimal network for the memory constraints of a system. Training\nmultiple policies with our method is as sample efficient as training a single\npolicy. Finally, we provide a method to select the best architecture, given a\nconstraint on the number of parameters. Project website:\nhttps://sites.google.com/usc.edu/graphhyperpolicy",
    "descriptor": "",
    "authors": [
      "Shashank Hegde",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00140"
  },
  {
    "id": "arXiv:2210.00142",
    "title": "Tunable Magnets: modeling and validation for dynamic and precision  applications",
    "abstract": "Actuator self-heating limits the achievable force and can cause unwanted\nstructural deformations. This is especially apparent in quasi-static actuation\nsystems that require the actuator to maintain a stable position over an\nextended period. As a solution, we use the concept of a Tunable Magnet. Tunable\nmagnets rely on in-situ magnetization state tuning of AlNico to create an\ninfinitely adjustable magnetic flux. They consist of an AlNiCo low coercivity\npermanent magnet together with a magnetizing coil. After tuning, the AlNiCo\nretains its magnetic field without further energy input, which eliminates the\nstatic heat dissipation. To enable implementation in actuation systems, the\nAlNiCo needs to be robustly tunable in the presence of a varying system\nair-gap. We achieve this by implementing a magnetization state tuning method,\nbased on a magnetic circuit model of the actuator, measured AlNiCo BH data and\nair-gap flux feedback control. The proposed tuning method consists of 2 main\nsteps. The prediction step, during which the required magnet operating point is\ndetermined, and the demagnetization step, where a feedback controller drives a\ndemagnetization current to approach this operating point. With this method\nimplemented for an AlNiCo 5 tunable magnet in a reluctance actuator\nconfiguration, we achieve tuning with a maximum error of 15.86 \"mT\" and a\nminimum precision of 0.67 \"mT\" over an air-gap range of 200 \"{\\mu}m\". With this\ntuning accuracy, actuator heating during static periods is almost eliminated.\nOnly a small bias current is needed to compensate for the tuning error.",
    "descriptor": "",
    "authors": [
      "Silvan G. Vi\u00ebtor",
      "Jo W. Spronck",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00142"
  },
  {
    "id": "arXiv:2210.00145",
    "title": "Coalitional Game-Theoretical Approach to Coinvestment with Application  to Edge Computing",
    "abstract": "We propose in this paper a coinvestment plan between several stakeholders of\ndifferent types, namely a physical network owner, operating network nodes, e.g.\na network operator or a tower company, and a set of service providers willing\nto use these resources to provide services as video streaming, augmented\nreality, autonomous driving assistance, etc. One such scenario is that of\ndeployment of Edge Computing resources.\nIndeed, although the latter technology is ready, the high Capital Expenditure\n(CAPEX) cost of such resources is the barrier to its deployment. For this\nreason, a solid economical framework to guide the investment and the returns of\nthe stakeholders is key to solve this issue. We formalize the coinvestment\nframework using coalitional game theory. We provide a solution to calculate how\nto divide the profits and costs among the stakeholders, taking into account\ntheir characteristics: traffic load, revenues, utility function. We prove that\nit is always possible to form the grand coalition composed of all the\nstakeholders, by showing that our game is convex. We derive the payoff of the\nstakeholders using the Shapley value concept, and elaborate on some properties\nof our game. We show our solution in simulation.",
    "descriptor": "",
    "authors": [
      "Rosario Patan\u00e8",
      "Andrea Araldo",
      "Tijani Chahed",
      "Diego Kiedanski",
      "Daniel Kofman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.00145"
  },
  {
    "id": "arXiv:2210.00146",
    "title": "FAST-LIO, Then Bayesian ICP, then GTSFM",
    "abstract": "For the Hilti Challenge 2022, we created two systems, one building upon the\nother. The first system is FL2BIPS which utilizes the iEKF algorithm FAST-LIO2\nand Bayesian ICP PoseSLAM, whereas the second system is GTSFM, a structure from\nmotion pipeline with factor graph backend optimization powered by GTSAM",
    "descriptor": "",
    "authors": [
      "Jerred Chen",
      "Xiangcheng Hu",
      "Shicong Ma",
      "Jianhao Jiao",
      "Ming Liu",
      "Frank Dellaert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00146"
  },
  {
    "id": "arXiv:2210.00153",
    "title": "Probabilistic Traversability Model for Risk-Aware Motion Planning in  Off-Road Environments",
    "abstract": "A key challenge in off-road navigation is that even visually similar or\nsemantically identical terrain may have substantially different traction\nproperties. Existing work typically assumes a nominal or expected robot\ndynamical model for planning, which can lead to degraded performance if the\nassumed models are not realizable given the terrain properties. In contrast,\nthis work introduces a new probabilistic representation of traversability as a\ndistribution of parameters in the robot's dynamical model that are conditioned\non the terrain characteristics. This model is learned in a self-supervised\nmanner by fitting a probability distribution over the parameters identified\nonline, encoded as a neural network that takes terrain features as input. This\nwork then presents two risk-aware planning algorithms that leverage the learned\ntraversability model to plan risk-aware trajectories. Finally, a method for\ndetecting unfamiliar terrain with respect to the training data is introduced\nbased on a Gaussian Mixture Model fit to the latent space of the trained model.\nExperiments demonstrate that the proposed approach outperforms existing work\nthat assumes nominal or expected robot dynamics in both success rate and\ncompletion time for representative navigation tasks. Furthermore, when the\nproposed approach is deployed in an unseen environment, excluding unfamiliar\nterrains during planning leads to improved success rate.",
    "descriptor": "\nComments: 7 pages submitted to ICRA 2023. Video and code: this https URL\n",
    "authors": [
      "Xiaoyi Cai",
      "Michael Everett",
      "Lakshay Sharma",
      "Philip R. Osteen",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00153"
  },
  {
    "id": "arXiv:2210.00155",
    "title": "A Novel Data Segmentation Based Approach for Meter Topology  Identification using Smart Meter Voltage and Power Measurements",
    "abstract": "This paper presents a data segmentation based approach to improve\nidentification accuracy and reduce false-positives in meter topology\nidentification problems, such as meter phase identification and\ntransformer-meter pairing identification. Using smart meter data as inputs,\nvoltage correlations between meters are calculated to determine which phase a\nmeter is on and which transformer it is supplied by. The underlying assumption\nis that voltage profiles of meters supplied by the same distribution\ntransformer or on the same phase are strongly correlated. In this paper, we\nfirst derive that i) when two customers consume at different power levels, the\nvoltage drops on the secondary circuits that connect the customers to the\ntransformer can be significant, and ii) large secondary circuit voltage drops\ncan significantly weaken the voltage correlation between meters on the same\nphase or supplied by the same transformer. Based on this discovery, we proposed\na data segmentation based approach that uses power bands for highly correlated\nvoltage segment selection in order to minimize correlation deterioration. Thus,\ninstead of using the entire voltage waveforms, we use an ensemble of voltage\nsegments for voltage correlation calculation. The proposed methods are\ndeveloped and tested on both synthetic and real feeder data sets for two\nalgorithms: meter phase and transformer-meter pairing identification.\nSimulation results show that the proposed algorithm outperforms the\nstate-of-the-art methods in both accuracy and robustness.",
    "descriptor": "\nComments: 10 pages, IEEE Transactions on Smart Grid. arXiv admin note: text overlap with arXiv:2111.10500\n",
    "authors": [
      "Han Pyo Lee",
      "PJ Rehm",
      "Matthew Makdad",
      "Edmond Miller",
      "Ning Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00155"
  },
  {
    "id": "arXiv:2210.00160",
    "title": "Explaining Website Reliability by Visualizing Hyperlink Connectivity",
    "abstract": "As the information on the Internet continues growing exponentially,\nunderstanding and assessing the reliability of a website is becoming\nincreasingly important. Misinformation has far-ranging repercussions, from\nsowing mistrust in media to undermining democratic elections. While some\nresearch investigates how to alert people to misinformation on the web, much\nless research has been conducted on explaining how websites engage in spreading\nfalse information. To fill the research gap, we present MisVis, a web-based\ninteractive visualization tool that helps users assess a website's reliability\nby understanding how it engages in spreading false information on the World\nWide Web. MisVis visualizes the hyperlink connectivity of the website and\nsummarizes key characteristics of the Twitter accounts that mention the site. A\nlarge-scale user study with 139 participants demonstrates that MisVis\nfacilitates users to assess and understand false information on the web and\nnode-link diagrams can be used to communicate with non-experts. MisVis is\navailable at the public demo link: https://poloclub.github.io/MisVis.",
    "descriptor": "\nComments: Accepted at IEEE VIS 2022, 5 pages, 4 figures, For a live demo, visit this https URL\n",
    "authors": [
      "Seongmin Lee",
      "Sadia Afroz",
      "Haekyu Park",
      "Zijie J. Wang",
      "Omar Shaikh",
      "Vibhor Sehgal",
      "Ankit Peshin",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00160"
  },
  {
    "id": "arXiv:2210.00162",
    "title": "Diving into Unified Data-Model Sparsity for Class-Imbalanced Graph  Representation Learning",
    "abstract": "Even pruned by the state-of-the-art network compression methods, Graph Neural\nNetworks (GNNs) training upon non-Euclidean graph data often encounters\nrelatively higher time costs, due to its irregular and nasty density\nproperties, compared with data in the regular Euclidean space. Another natural\nproperty concomitantly with graph is class-imbalance which cannot be alleviated\nby the massive graph data while hindering GNNs' generalization. To fully tackle\nthese unpleasant properties, (i) theoretically, we introduce a hypothesis about\nwhat extent a subset of the training data can approximate the full dataset's\nlearning effectiveness. The effectiveness is further guaranteed and proved by\nthe gradients' distance between the subset and the full set; (ii) empirically,\nwe discover that during the learning process of a GNN, some samples in the\ntraining dataset are informative for providing gradients to update model\nparameters. Moreover, the informative subset is not fixed during training\nprocess. Samples that are informative in the current training epoch may not be\nso in the next one. We also notice that sparse subnets pruned from a\nwell-trained GNN sometimes forget the information provided by the informative\nsubset, reflected in their poor performances upon the subset. Based on these\nfindings, we develop a unified data-model dynamic sparsity framework named\nGraph Decantation (GraphDec) to address challenges brought by training upon a\nmassive class-imbalanced graph data. The key idea of GraphDec is to identify\nthe informative subset dynamically during the training process by adopting\nsparse graph contrastive learning. Extensive experiments on benchmark datasets\ndemonstrate that GraphDec outperforms baselines for graph and node tasks, with\nrespect to classification accuracy and data usage efficiency.",
    "descriptor": "",
    "authors": [
      "Chunhui Zhang",
      "Chao Huang",
      "Yijun Tian",
      "Qianlong Wen",
      "Zhongyu Ouyang",
      "Youhuan Li",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00162"
  },
  {
    "id": "arXiv:2210.00167",
    "title": "Weighted MMSE Precoding for Constructive Interference Region",
    "abstract": "In this paper, we propose a symbol-level precoding (SLP) design that aims to\nminimize the weighted mean square error between the received signal and the\nconstellation point located in the constructive interference region (CIR).\nUnlike most existing SLP schemes that rely on channel state information (CSI)\nonly, the proposed scheme exploits both CSI and the distribution information of\nthe noise to achieve improved performance. We firstly propose a simple generic\ndescription of CIR that facilitates the subsequent SLP design. Such an\nobjective can further be formulated as a nonnegative least squares (NNLS)\nproblem, which can be solved efficiently by the active-set algorithm.\nFurthermore, the weighted minimum mean square error (WMMSE) precoding and the\nexisting SLP can be easily verified as special cases of the proposed scheme.\nFinally, simulation results show that the proposed precoding outperforms the\nstate-of-the-art SLP schemes in full signal-to-noise ratio ranges in both\nuncoded and coded systems without additional complexity over conventional SLP.",
    "descriptor": "",
    "authors": [
      "Yafei Wang",
      "Wenjin Wang",
      "Li You",
      "Christos G. Tsinos",
      "Shi Jin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00167"
  },
  {
    "id": "arXiv:2210.00169",
    "title": "Multi-stage Progressive Compression of Conformer Transducer for  On-device Speech Recognition",
    "abstract": "The smaller memory bandwidth in smart devices prompts development of smaller\nAutomatic Speech Recognition (ASR) models. To obtain a smaller model, one can\nemploy the model compression techniques. Knowledge distillation (KD) is a\npopular model compression approach that has shown to achieve smaller model size\nwith relatively lesser degradation in the model performance. In this approach,\nknowledge is distilled from a trained large size teacher model to a smaller\nsize student model. Also, the transducer based models have recently shown to\nperform well for on-device streaming ASR task, while the conformer models are\nefficient in handling long term dependencies. Hence in this work we employ a\nstreaming transducer architecture with conformer as the encoder. We propose a\nmulti-stage progressive approach to compress the conformer transducer model\nusing KD. We progressively update our teacher model with the distilled student\nmodel in a multi-stage setup. On standard LibriSpeech dataset, our experimental\nresults have successfully achieved compression rates greater than 60% without\nsignificant degradation in the performance compared to the larger teacher\nmodel.",
    "descriptor": "\nComments: Published in INTERSPEECH 2022\n",
    "authors": [
      "Jash Rathod",
      "Nauman Dawalatabad",
      "Shatrughan Singh",
      "Dhananjaya Gowda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.00169"
  },
  {
    "id": "arXiv:2210.00171",
    "title": "PORTAL: Portal Widget for Remote Target Acquisition and Control in  Immersive Virtual Environments",
    "abstract": "This paper introduces PORTAL (POrtal widget for Remote Target Acquisition and\ncontroL) that allows the user to interact with out-of-reach objects in a\nvirtual environment. We describe the PORTAL interaction technique for placing a\nportal widget and interacting with target objects through the portal. We\nconduct two formal user studies to evaluate PORTAL for selection and\nmanipulation functionalities. The results show PORTAL supports participants to\ninteract with remote objects successfully and precisely. Following that, we\ndiscuss its potential and limitations, and future works.",
    "descriptor": "",
    "authors": [
      "Dongyun Han",
      "Donghoon Kim",
      "Isaac Cho"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00171"
  },
  {
    "id": "arXiv:2210.00173",
    "title": "Predictive Inference with Feature Conformal Prediction",
    "abstract": "Conformal prediction is a distribution-free technique for establishing valid\nprediction intervals. Although conventionally people conduct conformal\nprediction in the output space, this is not the only possibility. In this\npaper, we propose feature conformal prediction, which extends the scope of\nconformal prediction to semantic feature spaces by leveraging the inductive\nbias of deep representation learning. From a theoretical perspective, we\ndemonstrate that feature conformal prediction provably outperforms regular\nconformal prediction under mild assumptions. Our approach could be combined\nwith not only vanilla conformal prediction, but also other adaptive conformal\nprediction methods. Experiments on various predictive inference tasks\ncorroborate the efficacy of our method.",
    "descriptor": "",
    "authors": [
      "Jiaye Teng",
      "Chuan Wen",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Yang Gao",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00173"
  },
  {
    "id": "arXiv:2210.00174",
    "title": "Improving ProtoNet for Few-Shot Video Object Recognition: Winner of  ORBIT Challenge 2022",
    "abstract": "In this work, we present the winning solution for ORBIT Few-Shot Video Object\nRecognition Challenge 2022. Built upon the ProtoNet baseline, the performance\nof our method is improved with three effective techniques. These techniques\ninclude the embedding adaptation, the uniform video clip sampler and the\ninvalid frame detection. In addition, we re-factor and re-implement the\nofficial codebase to encourage modularity, compatibility and improved\nperformance. Our implementation accelerates the data loading in both training\nand testing.",
    "descriptor": "\nComments: Winner of ORBIT Challenge 2022\n",
    "authors": [
      "Li Gu",
      "Zhixiang Chi",
      "Huan Liu",
      "Yuanhao Yu",
      "Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00174"
  },
  {
    "id": "arXiv:2210.00175",
    "title": "Technical Report-IoT Devices Proximity Authentication In Ad Hoc Network  Environment",
    "abstract": "Internet of Things (IoT) is a distributed communication technology system\nthat offers the possibility for physical devices (e.g. vehicles home appliances\nsensors actuators etc.) known as Things to connect and exchange data more\nimportantly without human interaction. Since IoT plays a significant role in\nour daily lives we must secure the IoT environment to work effectively. Among\nthe various security requirements authentication to the IoT devices is\nessential as it is the first step in preventing any negative impact of possible\nattackers. Using the current IEEE 802.11 infrastructure this paper implements\nan IoT devices authentication scheme based on something that is in the IoT\ndevices environment (i.e. ambient access points). Data from the broadcast\nmessages (i.e. beacon frame characteristics) are utilized to implement the\nauthentication factor that confirms proximity between two devices in an ad hoc\nIoT network.",
    "descriptor": "",
    "authors": [
      "Ali Abdullah S. AlQahtani",
      "Hosam Alamleh",
      "Baker Al Smadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00175"
  },
  {
    "id": "arXiv:2210.00176",
    "title": "A Combinatorial Perspective on the Optimization of Shallow ReLU Networks",
    "abstract": "The NP-hard problem of optimizing a shallow ReLU network can be characterized\nas a combinatorial search over each training example's activation pattern\nfollowed by a constrained convex problem given a fixed set of activation\npatterns. We explore the implications of this combinatorial aspect of ReLU\noptimization in this work. We show that it can be naturally modeled via a\ngeometric and combinatoric object known as a zonotope with its vertex set\nisomorphic to the set of feasible activation patterns. This assists in analysis\nand provides a foundation for further research. We demonstrate its usefulness\nwhen we explore the sensitivity of the optimal loss to perturbations of the\ntraining data. Later we discuss methods of zonotope vertex selection and its\nrelevance to optimization. Overparameterization assists in training by making a\nrandomly chosen vertex more likely to contain a good solution. We then\nintroduce a novel polynomial-time vertex selection procedure that provably\npicks a vertex containing the global optimum using only double the minimum\nnumber of parameters required to fit the data. We further introduce a local\ngreedy search heuristic over zonotope vertices and demonstrate that it\noutperforms gradient descent on underparameterized problems.",
    "descriptor": "",
    "authors": [
      "Michael Matena",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00176"
  },
  {
    "id": "arXiv:2210.00178",
    "title": "On the tightness of linear relaxation based robustness certification  methods",
    "abstract": "There has been a rapid development and interest in adversarial training and\ndefenses in the machine learning community in the recent years. One line of\nresearch focuses on improving the performance and efficiency of adversarial\nrobustness certificates for neural networks \\cite{gowal:19, wong_zico:18,\nraghunathan:18, WengTowardsFC:18, wong:scalable:18, singh:convex_barrier:19,\nHuang_etal:19, single-neuron-relax:20, Zhang2020TowardsSA}. While each\nproviding a certification to lower (or upper) bound the true distortion under\nadversarial attacks via relaxation, less studied was the tightness of\nrelaxation. In this paper, we analyze a family of linear outer approximation\nbased certificate methods via a meta algorithm, IBP-Lin. The aforementioned\nworks often lack quantitative analysis to answer questions such as how does the\nperformance of the certificate method depend on the network configuration and\nthe choice of approximation parameters. Under our framework, we make a first\nattempt at answering these questions, which reveals that the tightness of\nlinear approximation based certification can depend heavily on the\nconfiguration of the trained networks.",
    "descriptor": "",
    "authors": [
      "Cheng Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00178"
  },
  {
    "id": "arXiv:2210.00181",
    "title": "EAPruning: Evolutionary Pruning for Vision Transformers and CNNs",
    "abstract": "Structured pruning greatly eases the deployment of large neural networks in\nresource-constrained environments. However, current methods either involve\nstrong domain expertise, require extra hyperparameter tuning, or are restricted\nonly to a specific type of network, which prevents pervasive industrial\napplications. In this paper, we undertake a simple and effective approach that\ncan be easily applied to both vision transformers and convolutional neural\nnetworks. Specifically, we consider pruning as an evolution process of\nsub-network structures that inherit weights through reconstruction techniques.\nWe achieve a 50% FLOPS reduction for ResNet50 and MobileNetV1, leading to 1.37x\nand 1.34x speedup respectively. For DeiT-Base, we reach nearly 40% FLOPs\nreduction and 1.4x speedup. Our code will be made available.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Qingyuan Li",
      "Bo Zhang",
      "Xiangxiang Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00181"
  },
  {
    "id": "arXiv:2210.00182",
    "title": "Configuration Tracking Control of a Multi-Segment Soft Robotic Arm Using  a Cosserat Rod Model",
    "abstract": "Controlling soft continuum robotic arms is challenging due to their\nhyper-redundancy and dexterity. In this paper we demonstrate, for the first\ntime, closed-loop control of the configuration space variables of a soft\nrobotic arm, composed of independently controllable segments, using a Cosserat\nrod model of the robot and the distributed sensing and actuation capabilities\nof the segments. Our controller solves the inverse dynamic problem by\nsimulating the Cosserat rod model in MATLAB using a computationally efficient\nnumerical solution scheme, and it applies the computed control output to the\nactual robot in real time. The position and orientation of the tip of each\nsegment are measured in real time, while the remaining unknown variables that\nare needed to solve the inverse dynamics are estimated simultaneously in the\nsimulation. We implement the controller on a multi-segment silicone robotic arm\nwith pneumatic actuation, using a motion capture system to measure the\nsegments' positions and orientations. The controller is used to reshape the arm\ninto configurations that are achieved through different combinations of bending\nand extension deformations in 3D space. The resulting tracking performance\nindicates the effectiveness of the controller and the accuracy of the simulated\nCosserat rod model that is used to estimate the unmeasured variables.",
    "descriptor": "",
    "authors": [
      "Azadeh Doroudchi",
      "Zhi Qiao",
      "Wenlong Zhang",
      "Spring Berman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00182"
  },
  {
    "id": "arXiv:2210.00183",
    "title": "Structure-Aware NeRF without Posed Camera via Epipolar Constraint",
    "abstract": "The neural radiance field (NeRF) for realistic novel view synthesis requires\ncamera poses to be pre-acquired by a structure-from-motion (SfM) approach. This\ntwo-stage strategy is not convenient to use and degrades the performance\nbecause the error in the pose extraction can propagate to the view synthesis.\nWe integrate the pose extraction and view synthesis into a single end-to-end\nprocedure so they can benefit from each other. For training NeRF models, only\nRGB images are given, without pre-known camera poses. The camera poses are\nobtained by the epipolar constraint in which the identical feature in different\nviews has the same world coordinates transformed from the local camera\ncoordinates according to the extracted poses. The epipolar constraint is\njointly optimized with pixel color constraint. The poses are represented by a\nCNN-based deep network, whose input is the related frames. This joint\noptimization enables NeRF to be aware of the scene's structure that has an\nimproved generalization performance. Extensive experiments on a variety of\nscenes demonstrate the effectiveness of the proposed approach. Code is\navailable at https://github.com/XTU-PR-LAB/SaNerf.",
    "descriptor": "",
    "authors": [
      "Shu Chen",
      "Yang Zhang",
      "Yaxin Xu",
      "Beiji Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00183"
  },
  {
    "id": "arXiv:2210.00185",
    "title": "Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple  Tasks",
    "abstract": "Although large language models have achieved impressive zero-shot ability,\nthe huge model size generally incurs high cost. Recently, semi-parametric\nlanguage models, which augment a smaller language model with an external\nretriever, have demonstrated promising language modeling capabilities. However,\nit remains unclear whether such semi-parametric language models can perform\ncompetitively well as their fully-parametric counterparts on zero-shot\ngeneralization to downstream tasks. In this work, we introduce $\\text{Zemi}$, a\nzero-shot semi-parametric language model. To our best knowledge, this is the\nfirst semi-parametric language model that can demonstrate strong zero-shot\nperformance on a wide range of held-out unseen tasks. We train $\\text{Zemi}$\nwith a novel semi-parametric multitask prompted training paradigm, which shows\nsignificant improvement compared with the parametric multitask training as\nproposed by T0. Specifically, we augment the multitask training and zero-shot\nevaluation with retrieval from a large-scale task-agnostic unlabeled corpus. In\norder to incorporate multiple potentially noisy retrieved augmentations, we\nfurther propose a novel $\\text{augmentation fusion}$ module leveraging\nperceiver resampler and gated cross-attention. Notably, our proposed\n$\\text{Zemi}_\\text{LARGE}$ outperforms T0-3B by 16% on all seven evaluation\ntasks while being 3.9x smaller in model size.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zhenhailong Wang",
      "Xiaoman Pan",
      "Dian Yu",
      "Dong Yu",
      "Jianshu Chen",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00185"
  },
  {
    "id": "arXiv:2210.00187",
    "title": "Design of Economical Fuzzy Logic Controller for Washing Machine",
    "abstract": "Things are becoming more advanced as technology advances, and machines now\nperform the majority of the manual work. The most often used home appliance is\nthe washing machine for cloths. Modification and research in this field is\nessential since it pertains to the amount of time, water, and electricity\nrequired for washing. In this work, a Fuzzy Logic Controller has been developed\nfor smart washing machines. The objective of this paper is to optimize the\nconsumption of electricity, water, and detergent for washing machines. The type\nof dirt, volume of clothes, and type of cloth play a vital role in saving\nwater, electricity, and detergent. However, none of the work on the Fuzzy Logic\nController provided a design procedure endowed with the specified inputs and\noutputs implemented in Python. In this paper, we used the Mamdani approach and\ncreated an algorithm based on multi-input multi-output. The algorithm is\nimplemented in Python. The results of this simulation show that the washing\nmachine provides better execution at a low computation cost.",
    "descriptor": "\nComments: Submitted to Journal\n",
    "authors": [
      "Kriti Dheerawat",
      "Umme Salma M Pirzada",
      "H.R. Kataria"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00187"
  },
  {
    "id": "arXiv:2210.00189",
    "title": "Pitfalls of Gaussians as a noise distribution in NCE",
    "abstract": "Noise Contrastive Estimation (NCE) is a popular approach for learning\nprobability density functions parameterized up to a constant of\nproportionality. The main idea is to design a classification problem for\ndistinguishing training data from samples from an easy-to-sample noise\ndistribution $q$, in a manner that avoids having to calculate a partition\nfunction. It is well-known that the choice of $q$ can severely impact the\ncomputational and statistical efficiency of NCE. In practice, a common choice\nfor $q$ is a Gaussian which matches the mean and covariance of the data.\nIn this paper, we show that such a choice can result in an exponentially bad\n(in the ambient dimension) conditioning of the Hessian of the loss, even for\nvery simple data distributions. As a consequence, both the statistical and\nalgorithmic complexity for such a choice of $q$ will be problematic in\npractice, suggesting that more complex noise distributions are essential to the\nsuccess of NCE.",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Holden Lee",
      "Chirag Pabbaraju",
      "Anish Sevekari",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00189"
  },
  {
    "id": "arXiv:2210.00190",
    "title": "A high performance globally exponentially stable sensorless observer for  the IPMSM: Theoretical and experimental results",
    "abstract": "In a recent paper [18] the authors proposed the first solution to the problem\nof designing a {\\em globally exponentially stable} (GES) flux observer for the\ninterior permanent magnet synchronous motor. However, the establishment of the\nstability proof relies on the assumption that the adaptation gain is\nsufficiently {\\em small} -- a condition that may degrade the quality of the\ntransient behavior. In this paper we propose a new GES flux observer that\novercomes this limitation ensuring a high performance behavior. The design\nrelies on the use of a novel theoretical tool -- the generation of a {\\em\n``virtual\" invariant manifold} -- that allows the use of the more advanced\nKreisselmeier's regression extension estimator, instead of a simple gradient\ndescent one. We illustrate its superior transient behavior via extensive\nsimulations and {\\em experiments}.",
    "descriptor": "",
    "authors": [
      "Bowen Yi",
      "Romeo Ortega",
      "Jongwon Choi",
      "Kwanghee Nam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00190"
  },
  {
    "id": "arXiv:2210.00191",
    "title": "Cut-Paste Consistency Learning for Semi-Supervised Lesion Segmentation",
    "abstract": "Semi-supervised learning has the potential to improve the data-efficiency of\ntraining data-hungry deep neural networks, which is especially important for\nmedical image analysis tasks where labeled data is scarce. In this work, we\npresent a simple semi-supervised learning method for lesion segmentation tasks\nbased on the ideas of cut-paste augmentation and consistency regularization. By\nexploiting the mask information available in the labeled data, we synthesize\npartially labeled samples from the unlabeled images so that the usual\nsupervised learning objective (e.g., binary cross entropy) can be applied.\nAdditionally, we introduce a background consistency term to regularize the\ntraining on the unlabeled background regions of the synthetic images. We\nempirically verify the effectiveness of the proposed method on two public\nlesion segmentation datasets, including an eye fundus photograph dataset and a\nbrain CT scan dataset. The experiment results indicate that our method achieves\nconsistent and superior performance over other self-training and\nconsistency-based methods without introducing sophisticated network components.",
    "descriptor": "\nComments: Accepted to appear in WACV 2023\n",
    "authors": [
      "Boon Peng Yap",
      "Beng Koon Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00191"
  },
  {
    "id": "arXiv:2210.00192",
    "title": "RDA: An Accelerated Collision-free Motion Planner for Autonomous  Navigation in Cluttered Environments",
    "abstract": "Motion planning is challenging for autonomous systems in multi-obstacle\nenvironments due to nonconvex collision avoidance constraints. Directly\napplying numerical solvers to these nonconvex formulations fails to exploit the\nconstraint structures, resulting in excessive computation time. In this paper,\nwe present an accelerated collision-free motion planner, namely regularized\ndual alternating direction method of multipliers (RDADMM or RDA for short), for\nthe model predictive control (MPC) based motion planning problem. The proposed\nRDA addresses nonconvex motion planning via solving a smooth biconvex\nreformulation via duality and allows the collision avoidance constraints to be\ncomputed in parallel for each obstacle to reduce computation time\nsignificantly. We validate the performance of the RDA planner through\npath-tracking experiments with car-like robots in simulation and real world\nsetting. Experimental results show that the proposed methods can generate\nsmooth collision-free trajectories with less computation time compared with\nother benchmarks and perform robustly in cluttered environments.",
    "descriptor": "",
    "authors": [
      "Ruihua Han",
      "Shuai Wang",
      "Shuaijun Wang",
      "Zeqing Zhang",
      "Qianru Zhang",
      "Yonina C. Eldar",
      "Qi Hao",
      "Jia Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00192"
  },
  {
    "id": "arXiv:2210.00193",
    "title": "FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation",
    "abstract": "We present FRMT, a new dataset and evaluation benchmark for Few-shot\nRegion-aware Machine Translation, a type of style-targeted translation. The\ndataset consists of professional translations from English into two regional\nvariants each of Portuguese and Mandarin Chinese. Source documents are selected\nto enable detailed analysis of phenomena of interest, including lexically\ndistinct terms and distractor terms. We explore automatic evaluation metrics\nfor FRMT and validate their correlation with expert human evaluation across\nboth region-matched and mismatched rating scenarios. Finally, we present a\nnumber of baseline models for this task, and offer guidelines for how\nresearchers can train, evaluate, and compare their own models. Our dataset and\nevaluation code are publicly available: https://bit.ly/frmt-task",
    "descriptor": "",
    "authors": [
      "Parker Riley",
      "Timothy Dozat",
      "Jan A. Botha",
      "Xavier Garcia",
      "Dan Garrette",
      "Jason Riesa",
      "Orhan Firat",
      "Noah Constant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00193"
  },
  {
    "id": "arXiv:2210.00198",
    "title": "Closed cap condition under the cap construction algorithm",
    "abstract": "Every polygon $P$ can be companioned by a cap polygon $\\hat P$ such that $P$\nand $\\hat P$ serve as two parts of the boundary surface of a polyhedron $V$.\nPairs of vertices on $P$ and $\\hat P$ are identified successively to become\nvertices of $V$. In this paper, we study the cap construction that asserts\nequal angular defects at these pairings. We exhibit a linear relation that\narises from the cap construction algorithm, which in turn demonstrates an\nabundance of polygons that satisfy the closed cap condition, that is, those\nthat can successfully undergo the cap construction process.",
    "descriptor": "\nComments: 17 pages, 9 figures, submitted to Involve\n",
    "authors": [
      "Mercedes Sandu",
      "Shuyi Weng",
      "Jade Zhang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00198"
  },
  {
    "id": "arXiv:2210.00201",
    "title": "Integrating Conventional Headway Control with Reinforcement Learning to  Avoid Bus Bunching",
    "abstract": "Bus bunching is a natural-occurring phenomenon that undermines the efficiency\nand stability of the public transportation system. The mainstream solutions\ncontrol the bus to intentionally stay longer at certain stations. Existing\ncontrol methods include conventional methods that provide a formula to\ncalculate the control time and reinforcement learning (RL) methods that\ndetermine the control policy through repeated interactions with the system. In\nthis paper, we propose an integrated proximal policy optimization model with\ndual-headway (IPPO-DH). IPPO-DH integrates the conventional headway control\nwith reinforcement learning, so that it acquires the advantages of both\nalgorithms -- it is more efficient in normal environments and more stable in\nharsh ones. To demonstrate such an advantage, we design a bus simulation\nenvironment and compare IPPO-DH with RL and several conventional methods. The\nresults show that the proposed model maintains the application value of the\nconventional method by avoiding the instability of the RL method in certain\nenvironments, and improves the efficiency compared with the conventional\ncontrol, shedding new light on real-world bus transit system optimization.",
    "descriptor": "\nComments: 12 pages,8 figures\n",
    "authors": [
      "Xiheng Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00201"
  },
  {
    "id": "arXiv:2210.00203",
    "title": "Digital Library Initiatives in North East India: A Survey",
    "abstract": "This is a survey of digital library initiative of North East India. The\nrecent initiative by the government of India towards the digitization is\nreflected in various digitation programs. The secondary sources of data are\nused to map the 16 digital library initiatives in eight north east state of\nIndia. The study has observed that digital library in true sense is perhaps\nlacking. Many of the digital libraries are not accessible from the outside and\nlack regular maintenance. In this context, a national level policy initiative\nis the need of the hour including various stakeholders from the academics,\nlibrary professionals etc. The study also comes up with various important\nobservations and policy suggestions which may be helpful for scholar,\nlibrarians, policy and decision makers in the government.",
    "descriptor": "\nComments: 14 pages, 2 tables\n",
    "authors": [
      "Sankhayan Mukherjee",
      "Swapan Kumar Patra"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.00203"
  },
  {
    "id": "arXiv:2210.00204",
    "title": "Learning-Based Adaptive Optimal Control of Linear Time-Delay Systems: A  Policy Iteration Approach",
    "abstract": "This paper studies the adaptive optimal control problem for a class of linear\ntime-delay systems described by delay differential equations (DDEs). A crucial\nstrategy is to take advantage of recent developments in reinforcement learning\nand adaptive dynamic programming and develop novel methods to learn adaptive\noptimal controllers from finite samples of input and state data. In this paper,\nthe data-driven policy iteration (PI) is proposed to solve the\ninfinite-dimensional algebraic Riccati equation (ARE) iteratively in the\nabsence of exact model knowledge. Interestingly, the proposed recursive PI\nalgorithm is new in the present context of continuous-time time-delay systems,\neven when the model knowledge is assumed known. The efficacy of the proposed\nlearning-based control methods is validated by means of practical applications\narising from metal cutting and autonomous driving.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Leilei Cui",
      "Bo Pang",
      "Zhong-Ping Jiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00204"
  },
  {
    "id": "arXiv:2210.00211",
    "title": "Boosting Exploration in Actor-Critic Algorithms by Incentivizing  Plausible Novel States",
    "abstract": "Actor-critic (AC) algorithms are a class of model-free deep reinforcement\nlearning algorithms, which have proven their efficacy in diverse domains,\nespecially in solving continuous control problems. Improvement of exploration\n(action entropy) and exploitation (expected return) using more efficient\nsamples is a critical issue in AC algorithms. A basic strategy of a learning\nalgorithm is to facilitate indiscriminately exploring all of the environment\nstate space, as well as to encourage exploring rarely visited states rather\nthan frequently visited one. Under this strategy, we propose a new method to\nboost exploration through an intrinsic reward, based on measurement of a\nstate's novelty and the associated benefit of exploring the state (with regards\nto policy optimization), altogether called plausible novelty. With incentivized\nexploration of plausible novel states, an AC algorithm is able to improve its\nsample efficiency and hence training performance. The new method is verified by\nextensive simulations of continuous control tasks of MuJoCo environments on a\nvariety of prominent off-policy AC algorithms.",
    "descriptor": "",
    "authors": [
      "Chayan Banerjee",
      "Zhiyong Chen",
      "Nasimul Noman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00211"
  },
  {
    "id": "arXiv:2210.00213",
    "title": "HyperHawkes: Hypernetwork based Neural Temporal Point Process",
    "abstract": "Temporal point process serves as an essential tool for modeling time-to-event\ndata in continuous time space. Despite having massive amounts of event sequence\ndata from various domains like social media, healthcare etc., real world\napplication of temporal point process faces two major challenges: 1) it is not\ngeneralizable to predict events from unseen sequences in dynamic environment 2)\nthey are not capable of thriving in continually evolving environment with\nminimal supervision while retaining previously learnt knowledge. To tackle\nthese issues, we propose \\textit{HyperHawkes}, a hypernetwork based temporal\npoint process framework which is capable of modeling time of occurrence of\nevents for unseen sequences. Thereby, we solve the problem of zero-shot\nlearning for time-to-event modeling. We also develop a hypernetwork based\ncontinually learning temporal point process for continuous modeling of\ntime-to-event sequences with minimal forgetting. In this way,\n\\textit{HyperHawkes} augments the temporal point process with zero-shot\nmodeling and continual learning capabilities. We demonstrate the application of\nthe proposed framework through our experiments on two real-world datasets. Our\nresults show the efficacy of the proposed approach in terms of predicting\nfuture events under zero-shot regime for unseen event sequences. We also show\nthat the proposed model is able to predict sequences continually while\nretaining information from previous event sequences, hence mitigating\ncatastrophic forgetting for time-to-event data.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Manisha Dubey",
      "P.K. Srijith",
      "Maunendra Sankar Desarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00213"
  },
  {
    "id": "arXiv:2210.00215",
    "title": "Differentiable Parsing and Visual Grounding of Verbal Instructions for  Object Placement",
    "abstract": "Grounding spatial relations in natural language for object placing could have\nambiguity and compositionality issues. To address the issues, we introduce\nParaGon, a PARsing And visual GrOuNding framework for language-conditioned\nobject placement. It parses language instructions into relations between\nobjects and grounds those objects in visual scenes. A particle-based GNN then\nconducts relational reasoning between grounded objects for placement\ngeneration. ParaGon encodes all of those procedures into neural networks for\nend-to-end training, which avoids annotating parsing and object reference\ngrounding labels. Our approach inherently integrates parsing-based methods into\na probabilistic, data-driven framework. It is data-efficient and generalizable\nfor learning compositional instructions, robust to noisy language inputs, and\nadapts to the uncertainty of ambiguous instructions.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Zirui Zhao",
      "Wee Sun Lee",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00215"
  },
  {
    "id": "arXiv:2210.00216",
    "title": "Nested Search versus Limited Discrepancy Search",
    "abstract": "Limited Discrepancy Search (LDS) is a popular algorithm to search a state\nspace with a heuristic to order the possible actions. Nested Search (NS) is\nanother algorithm to search a state space with the same heuristic. NS spends\nmore time on the move associated to the best heuristic playout while LDS spends\nmore time on the best heuristic move. They both use similar times for the same\nlevel of search. We advocate in this paper that it is often better to follow\nthe best heuristic playout as in NS than to follow the heuristic as in LDS.",
    "descriptor": "",
    "authors": [
      "Tristan Cazenave"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00216"
  },
  {
    "id": "arXiv:2210.00220",
    "title": "A Dual-Attention Learning Network with Word and Sentence Embedding for  Medical Visual Question Answering",
    "abstract": "Research in medical visual question answering (MVQA) can contribute to the\ndevelopment of computeraided diagnosis. MVQA is a task that aims to predict\naccurate and convincing answers based on given medical images and associated\nnatural language questions. This task requires extracting medical\nknowledge-rich feature content and making fine-grained understandings of them.\nTherefore, constructing an effective feature extraction and understanding\nscheme are keys to modeling. Existing MVQA question extraction schemes mainly\nfocus on word information, ignoring medical information in the text. Meanwhile,\nsome visual and textual feature understanding schemes cannot effectively\ncapture the correlation between regions and keywords for reasonable visual\nreasoning. In this study, a dual-attention learning network with word and\nsentence embedding (WSDAN) is proposed. We design a module, transformer with\nsentence embedding (TSE), to extract a double embedding representation of\nquestions containing keywords and medical information. A dualattention learning\n(DAL) module consisting of self-attention and guided attention is proposed to\nmodel intensive intramodal and intermodal interactions. With multiple DAL\nmodules (DALs), learning visual and textual co-attention can increase the\ngranularity of understanding and improve visual reasoning. Experimental results\non the ImageCLEF 2019 VQA-MED (VQA-MED 2019) and VQA-RAD datasets demonstrate\nthat our proposed method outperforms previous state-of-the-art methods.\nAccording to the ablation studies and Grad-CAM maps, WSDAN can extract rich\ntextual information and has strong visual reasoning ability.",
    "descriptor": "",
    "authors": [
      "Xiaofei Huang",
      "Hongfang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00220"
  },
  {
    "id": "arXiv:2210.00221",
    "title": "Motion-inductive Self-supervised Object Discovery in Videos",
    "abstract": "In this paper, we consider the task of unsupervised object discovery in\nvideos. Previous works have shown promising results via processing optical\nflows to segment objects. However, taking flow as input brings about two\ndrawbacks. First, flow cannot capture sufficient cues when objects remain\nstatic or partially occluded. Second, it is challenging to establish temporal\ncoherency from flow-only input, due to the missing texture information. To\ntackle these limitations, we propose a model for directly processing\nconsecutive RGB frames, and infer the optical flow between any pair of frames\nusing a layered representation, with the opacity channels being treated as the\nsegmentation. Additionally, to enforce object permanence, we apply temporal\nconsistency loss on the inferred masks from randomly-paired frames, which refer\nto the motions at different paces, and encourage the model to segment the\nobjects even if they may not move at the current time point. Experimentally, we\ndemonstrate superior performance over previous state-of-the-art methods on\nthree public video segmentation datasets (DAVIS2016, SegTrackv2, and FBMS-59),\nwhile being computationally efficient by avoiding the overhead of computing\noptical flow as input.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Shuangrui Ding",
      "Weidi Xie",
      "Yabo Chen",
      "Rui Qian",
      "Xiaopeng Zhang",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00221"
  },
  {
    "id": "arXiv:2210.00222",
    "title": "Solving practical multi-body dynamics problems using a single neural  operator",
    "abstract": "As a fundamental design tool in many engineering disciplines, multi-body\ndynamics (MBD) models a complex structure with a differential equation group\ncontaining multiple physical quantities. Engineers must constantly adjust\nstructures at the design stage, which requires a highly efficient solver. The\nrise of deep learning technologies has offered new perspectives on MBD.\nUnfortunately, existing black-box models suffer from poor accuracy and\nrobustness, while the advanced methodologies of single-output operator\nregression cannot deal with multiple quantities simultaneously. To address\nthese challenges, we propose PINO-MBD, a deep learning framework for solving\npractical MBD problems based on the theory of physics-informed neural operator\n(PINO). PINO-MBD uses a single network for all quantities in a multi-body\nsystem, instead of training dozens, or even hundreds of networks as in the\nexisting literature. We demonstrate the flexibility and feasibility of PINO-MBD\nfor one toy example and two practical applications: vehicle-track coupled\ndynamics (VTCD) and reliability analysis of a four-storey building. The\nperformance of VTCD indicates that our framework outperforms existing software\nand machine learning-based methods in terms of efficiency and precision,\nrespectively. For the reliability analysis, PINO-MBD can provide\nhigher-resolution results in less than a quarter of the time incurred when\nusing the probability density evolution method (PDEM). This framework\nintegrates mechanics and deep learning technologies and may reveal a new\nconcept for MBD and probabilistic engineering.",
    "descriptor": "",
    "authors": [
      "Wenhao Ding",
      "Qing He",
      "Hanghang Tong",
      "Qingjing Wang",
      "Ping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00222"
  },
  {
    "id": "arXiv:2210.00223",
    "title": "Contour-Aware Equipotential Learning for Semantic Segmentation",
    "abstract": "With increasing demands for high-quality semantic segmentation in the\nindustry, hard-distinguishing semantic boundaries have posed a significant\nthreat to existing solutions. Inspired by real-life experience, i.e., combining\nvaried observations contributes to higher visual recognition confidence, we\npresent the equipotential learning (EPL) method. This novel module transfers\nthe predicted/ground-truth semantic labels to a self-defined potential domain\nto learn and infer decision boundaries along customized directions. The\nconversion to the potential domain is implemented via a lightweight\ndifferentiable anisotropic convolution without incurring any parameter\noverhead. Besides, the designed two loss functions, the point loss and the\nequipotential line loss implement anisotropic field regression and\ncategory-level contour learning, respectively, enhancing prediction\nconsistencies in the inter/intra-class boundary areas. More importantly, EPL is\nagnostic to network architectures, and thus it can be plugged into most\nexisting segmentation models. This paper is the first attempt to address the\nboundary segmentation problem with field regression and contour learning.\nMeaningful performance improvements on Pascal Voc 2012 and Cityscapes\ndemonstrate that the proposed EPL module can benefit the off-the-shelf fully\nconvolutional network models when recognizing semantic boundary areas. Besides,\nintensive comparisons and analysis show the favorable merits of EPL for\ndistinguishing semantically-similar and irregular-shaped categories.",
    "descriptor": "",
    "authors": [
      "Xu Yin",
      "Dongbo Min",
      "Yuchi Huo",
      "Sung-Eui Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00223"
  },
  {
    "id": "arXiv:2210.00226",
    "title": "Towards Understanding and Mitigating Dimensional Collapse in  Heterogeneous Federated Learning",
    "abstract": "Federated learning aims to train models collaboratively across different\nclients without the sharing of data for privacy considerations. However, one\nmajor challenge for this learning paradigm is the {\\em data heterogeneity}\nproblem, which refers to the discrepancies between the local data distributions\namong various clients. To tackle this problem, we first study how data\nheterogeneity affects the representations of the globally aggregated models.\nInterestingly, we find that heterogeneous data results in the global model\nsuffering from severe {\\em dimensional collapse}, in which representations tend\nto reside in a lower-dimensional space instead of the ambient space. Moreover,\nwe observe a similar phenomenon on models locally trained on each client and\ndeduce that the dimensional collapse on the global model is inherited from\nlocal models. In addition, we theoretically analyze the gradient flow dynamics\nto shed light on how data heterogeneity result in dimensional collapse for\nlocal models. To remedy this problem caused by the data heterogeneity, we\npropose {\\sc FedDecorr}, a novel method that can effectively mitigate\ndimensional collapse in federated learning. Specifically, {\\sc FedDecorr}\napplies a regularization term during local training that encourages different\ndimensions of representations to be uncorrelated. {\\sc FedDecorr}, which is\nimplementation-friendly and computationally-efficient, yields consistent\nimprovements over baselines on standard benchmark datasets. Code will be\nreleased.",
    "descriptor": "",
    "authors": [
      "Yujun Shi",
      "Jian Liang",
      "Wenqing Zhang",
      "Vincent Y. F. Tan",
      "Song Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00226"
  },
  {
    "id": "arXiv:2210.00229",
    "title": "Stability analysis of the perfectly matched layer for the elastic wave  equation in layered media",
    "abstract": "In this paper, we present the stability analysis of the perfectly matched\nlayer (PML) in two-space dimensional layered elastic media. Using normal mode\nanalysis we prove that all interface wave modes present at a planar interface\nof bi-material elastic solids are dissipated by the PML. Numerical experiments\nin two-layer and multi-layer elastic solids corroborate the theoretical\nanalysis.",
    "descriptor": "",
    "authors": [
      "Kenneth Duru",
      "Siyang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00229"
  },
  {
    "id": "arXiv:2210.00232",
    "title": "Learnable Distribution Calibration for Few-Shot Class-Incremental  Learning",
    "abstract": "Few-shot class-incremental learning (FSCIL) faces challenges of memorizing\nold class distributions and estimating new class distributions given few\ntraining samples. In this study, we propose a learnable distribution\ncalibration (LDC) approach, with the aim to systematically solve these two\nchallenges using a unified framework. LDC is built upon a parameterized\ncalibration unit (PCU), which initializes biased distributions for all classes\nbased on classifier vectors (memory-free) and a single covariance matrix. The\ncovariance matrix is shared by all classes, so that the memory costs are fixed.\nDuring base training, PCU is endowed with the ability to calibrate biased\ndistributions by recurrently updating sampled features under the supervision of\nreal distributions. During incremental learning, PCU recovers distributions for\nold classes to avoid `forgetting', as well as estimating distributions and\naugmenting samples for new classes to alleviate `over-fitting' caused by the\nbiased distributions of few-shot samples. LDC is theoretically plausible by\nformatting a variational inference procedure. It improves FSCIL's flexibility\nas the training procedure requires no class similarity priori. Experiments on\nCUB200, CIFAR100, and mini-ImageNet datasets show that LDC outperforms the\nstate-of-the-arts by 4.64%, 1.98%, and 3.97%, respectively. LDC's effectiveness\nis also validated on few-shot learning scenarios.",
    "descriptor": "",
    "authors": [
      "Binghao Liu",
      "Boyu Yang",
      "Lingxi Xie",
      "Ren Wang",
      "Qi Tian",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00232"
  },
  {
    "id": "arXiv:2210.00235",
    "title": "The maximum length of shortest accepted strings for  direction-determinate two-way finite automata",
    "abstract": "It is shown that, for every $n \\geqslant 2$, the maximum length of the\nshortest string accepted by an $n$-state direction-determinate two-way finite\nautomaton is exactly $\\binom{n}{\\lfloor\\frac{n}{2}\\rfloor}-1$\n(direction-determinate automata are those that always remember in the current\nstate whether the last move was to the left or to the right). For two-way\nfinite automata of the general form, a family of $n$-state automata with\nshortest accepted strings of length $\\frac{3}{4} \\cdot 2^n - 1$ is constructed.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Olga Martynova",
      "Alexander Okhotin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.00235"
  },
  {
    "id": "arXiv:2210.00236",
    "title": "Software system rationalisation: How to get better outcomes through  stronger user engagement",
    "abstract": "As businesses get more sizable and more mature they now, inevitably accrete\nmore and more software systems. This estate expansion leads not only to greater\ncomplexity and expense for the enterprise, but also to fragmentation,\ninconsistency and siloing of business processes. Because platform\nrationalisation and system decommissioning never happens spontaneously, a\nperennial problem for the enterprise then becomes how to simplify their\ncorporate software platforms. Recently, Curlew Research personnel were involved\nin a software rationalisation program within a large global life sciences\ncompany and this paper describes an approach to decommissioning which we\ndeveloped as part of that project, and which we feel could be of use more\nwidely to help with objective more user-centric system rationalisation. The\nmethod derives from a model developed by Noriaki Kano et al to help with\ndetermining customer satisfaction and loyalty, and the prioritisation of new,\nadditional functionality, features or \"products\", for example when looking to\nenhance software applications. Using a blueprint process for rationalisation,\nthe Curlew-Kano method enables each application to be placed efficiently and\nobjectively into one of four categories - Retain; Review; Remove; Research -\nthus allowing the enterprise to identify and prioritise quickly those systems\nwhich warrant further investigation as part of a decommissioning activity. The\nkey difference of the Curlew-Kano method compared to other application\nrationalisation methodologies is the fundamental involvement of users in the\nidentification of systems more suitable for rationalisation and possible\ndecommissioning. In our view involving users more fully in system\nrationalisation leads to better outcomes for the enterprise.",
    "descriptor": "\nComments: 12 pages, 5 figures, 3 tables, 10 references\n",
    "authors": [
      "Richard Shute",
      "Nick Lynch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2210.00236"
  },
  {
    "id": "arXiv:2210.00240",
    "title": "Executable First-Order Queries in the Logic of Information Flows",
    "abstract": "The logic of information flows (LIF) has recently been proposed as a general\nframework in the field of knowledge representation. In this framework, tasks of\na procedural nature can still be modeled in a declarative, logic-based fashion.\nIn this paper, we focus on the task of query processing under limited access\npatterns, a well-studied problem in the database literature. We show that LIF\nis well-suited for modeling this task. Toward this goal, we introduce a variant\nof LIF called \"forward\" LIF, in a first-order setting. We define FLIFio, a\nsyntactical fragment of forward LIF, and show that it corresponds exactly to\nthe \"executable\" fragment of first-order logic defined by Nash and Lud\\\"ascher.\nMoreover, we show that general FLIF expressions can also be put into\nio-disjoint form. The definition of FLIFio involves a classification of the\nfree variables of an expression into \"input\" and \"output\" variables. Our result\nhinges on inertia and determinacy laws for forward LIF expressions, which are\ninteresting in their own right. These laws are formulated in terms of the input\nand output variables.",
    "descriptor": "\nComments: This paper is the extended version of the two papers presented at ICDT 2020 and ICDT 2021\n",
    "authors": [
      "Heba Aamer",
      "Bart Bogaerts",
      "Dimitri Surinx",
      "Eugenia Ternovska",
      "Jan Van den Bussche"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00240"
  },
  {
    "id": "arXiv:2210.00243",
    "title": "An experimental study of algorithms for obtaining a singly connected  subgraph",
    "abstract": "\\begin{abstract}\n\\normalsize{\\noindent A directed graph $G = (V,E)$ is singly connected if for\nany two vertices $v,u \\in V$, the directed graph $G$ contains at most one\nsimple path from $v$ to $u$. In this paper, we study different algorithms to\nfind a feasible but necessarily optimal solution to the following problem.\nGiven a directed acyclic graph $G=(V,E)$, find a subset $H \\subseteq E$ of\nminimum size such that the subgraph $(V,E \\setminus H)$ is singly connected.\nMoreover, we prove that this problem can be solved in polynomial time for a\nspecial kind of directed graphs.}\n\\end{abstract}",
    "descriptor": "",
    "authors": [
      "Ahmed Zahloote",
      "Al-hasan Saleh",
      "Ayman Ghanem",
      "Hiba Hasan",
      "Asem Dreibaty",
      "Ali Abodaraa",
      "Nermeen Suleiman",
      "Nour Naameh",
      "Ali Ibrahim",
      "Zeinab mahfoud"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.00243"
  },
  {
    "id": "arXiv:2210.00244",
    "title": "On The Relative Error of Random Fourier Features for Preserving Kernel  Distance",
    "abstract": "The method of random Fourier features (RFF), proposed in a seminal paper by\nRahimi and Recht (NIPS'07), is a powerful technique to find approximate\nlow-dimensional representations of points in (high-dimensional) kernel space,\nfor shift-invariant kernels. While RFF has been analyzed under various notions\nof error guarantee, the ability to preserve the kernel distance with\n\\emph{relative} error is less understood. We show that for a significant range\nof kernels, including the well-known Laplacian kernels, RFF cannot approximate\nthe kernel distance with small relative error using low dimensions. We\ncomplement this by showing as long as the shift-invariant kernel is analytic,\nRFF with $\\mathrm{poly}(\\epsilon^{-1} \\log n)$ dimensions achieves\n$\\epsilon$-relative error for pairwise kernel distance of $n$ points, and the\ndimension bound is improved to $\\mathrm{poly}(\\epsilon^{-1}\\log k)$ for the\nspecific application of kernel $k$-means. Finally, going beyond RFF, we make\nthe first step towards data-oblivious dimension-reduction for general\nshift-invariant kernels, and we obtain a similar $\\mathrm{poly}(\\epsilon^{-1}\n\\log n)$ dimension bound for Laplacian kernels. We also validate the\ndimension-error tradeoff of our methods on simulated datasets, and they\ndemonstrate superior performance compared with other popular methods including\nrandom-projection and Nystr\\\"{o}m methods.",
    "descriptor": "",
    "authors": [
      "Kuan Cheng",
      "Shaofeng H.-C. Jiang",
      "Luojian Wei",
      "Zhide Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.00244"
  },
  {
    "id": "arXiv:2210.00248",
    "title": "Heterogeneous Graph Contrastive Multi-view Learning",
    "abstract": "Inspired by the success of contrastive learning (CL) in computer vision and\nnatural language processing, graph contrastive learning (GCL) has been\ndeveloped to learn discriminative node representations on graph datasets.\nHowever, the development of GCL on Heterogeneous Information Networks (HINs) is\nstill in the infant stage. For example, it is unclear how to augment the HINs\nwithout substantially altering the underlying semantics, and how to design the\ncontrastive objective to fully capture the rich semantics. Moreover, early\ninvestigations demonstrate that CL suffers from sampling bias, whereas\nconventional debiasing techniques are empirically shown to be inadequate for\nGCL. How to mitigate the sampling bias for heterogeneous GCL is another\nimportant problem. To address the aforementioned challenges, we propose a novel\nHeterogeneous Graph Contrastive Multi-view Learning (HGCML) model. In\nparticular, we use metapaths as the augmentation to generate multiple subgraphs\nas multi-views, and propose a contrastive objective to maximize the mutual\ninformation between any pairs of metapath-induced views. To alleviate the\nsampling bias, we further propose a positive sampling strategy to explicitly\nselect positives for each node via jointly considering semantic and structural\ninformation preserved on each metapath view. Extensive experiments demonstrate\nHGCML consistently outperforms state-of-the-art baselines on five real-world\nbenchmark datasets.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zehong Wang",
      "Qi Li",
      "Donghua Yu",
      "Xiaolong Han",
      "Xiao-Zhi Gao",
      "Shigen Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00248"
  },
  {
    "id": "arXiv:2210.00252",
    "title": "Blindly Deconvolving Super-noisy Blurry Image Sequences",
    "abstract": "Image blur and image noise are imaging artifacts intrinsically arising in\nimage acquisition. In this paper, we consider multi-frame blind deconvolution\n(MFBD), where image blur is described by the convolution of an unobservable,\nundeteriorated image and an unknown filter, and the objective is to recover the\nundeteriorated image from a sequence of its blurry and noisy observations. We\npresent two new methods for MFBD, which, in contrast to previous work, do not\nrequire the estimation of the unknown filters. The first method is based on\nlikelihood maximization and requires careful initialization to cope with the\nnon-convexity of the loss function. The second method circumvents this\nrequirement and exploits that the solution of likelihood maximization emerges\nas an eigenvector of a specifically constructed matrix, if the signal subspace\nspanned by the observations has a sufficiently large dimension. We describe a\npre-processing step, which increases the dimension of the signal subspace by\nartificially generating additional observations. We also propose an extension\nof the eigenvector method, which copes with insufficient dimensions of the\nsignal subspace by estimating a footprint of the unknown filters (that is a\nvector of the size of the filters, only one is required for the whole image\nsequence). We have applied the eigenvector method to synthetically generated\nimage sequences and performed a quantitative comparison with a previous method,\nobtaining strongly improved results.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Leonid Kostrykin",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00252"
  },
  {
    "id": "arXiv:2210.00258",
    "title": "Primal-dual regression approach for Markov decision processes with  general state and action space",
    "abstract": "We develop a regression based primal-dual martingale approach for solving\nfinite time horizon MDPs with general state and action space. As a result, our\nmethod allows for the construction of tight upper and lower biased\napproximations of the value functions, and, provides tight approximations to\nthe optimal policy. In particular, we prove tight error bounds for the\nestimated duality gap featuring polynomial dependence on the time horizon, and\nsublinear dependence on the cardinality/dimension of the possibly infinite\nstate and action space.From a computational point of view the proposed method\nis efficient since, in contrast to usual duality-based methods for optimal\ncontrol problems in the literature, the Monte Carlo procedures here involved do\nnot require nested simulations.",
    "descriptor": "",
    "authors": [
      "Denis Belomestny",
      "John Schoenmakers"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00258"
  },
  {
    "id": "arXiv:2210.00260",
    "title": "A new numerical treatment of soil heterogeneity for modeling unsaturated  flow",
    "abstract": "We develop a new approach to solve the Richardson-Richards equation for\nmodeling unsaturated flow through heterogeneous porous media. The main idea of\nthe proposed techniques is the use of the Kirchhoff transformation, the Brooks\nand Corey model for the capillary pressure function and a power-law relation in\nsaturation for the relative permeability function. The new approach allows us\nto avoid the technical issues encountered in the Kirchhoff transformation due\nto soil heterogeneity. This transformation is applied to reduce the\nnonlinearity of the model which is solved using a numerical scheme based on a\nlocal radial basis function method (RBF). To validate the developed approach\nfor predicting the dynamics of unsaturated flow in porous media, numerical\nexperiments are performed in one, two, and three-dimensional soils. The\nnumerical results demonstrate the efficiency and accuracy of the proposed\ntechniques for modeling infiltration through heterogeneous soils.",
    "descriptor": "",
    "authors": [
      "Mohamed Boujoudar",
      "Abdelaziz Beljadid",
      "Ahmed Taik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00260"
  },
  {
    "id": "arXiv:2210.00262",
    "title": "Frequency Estimation of Evolving Data Under Local Differential Privacy",
    "abstract": "Collecting and analyzing evolving longitudinal data has become a common\npractice. One possible approach to protect the users' privacy in this context\nis to use local differential privacy (LDP) protocols, which ensure the privacy\nprotection of all users even in the case of a breach or data misuse. Existing\nLDP data collection protocols such as Google's RAPPOR and Microsoft's\ndBitFlipPM have longitudinal privacy linear to the domain size k, which can be\nexcessive for large domains, such as Internet domains. To solve this issue, in\nthis paper we introduce a new LDP data collection protocol for longitudinal\nfrequency monitoring named LOngitudinal LOcal HAshing (LOLOHA) with formal\nprivacy guarantees. In addition, the privacy-utility trade-off of our protocol\nis only linear with respect to a reduced domain size 2<=g<<k. LOLOHA combines a\ndomain reduction approach via local hashing with double randomization to\nminimize the privacy leakage incurred by data updates. As demonstrated by our\ntheoretical analysis as well as our experimental evaluation, LOLOHA achieves a\nutility competitive to current state-of-the-art protocols, while substantially\nminimizing the longitudinal privacy budget consumption by up to k/g orders of\nmagnitude.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Carlos Pinz\u00f3n",
      "Catuscia Palamidessi",
      "S\u00e9bastien Gambs"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00262"
  },
  {
    "id": "arXiv:2210.00264",
    "title": "zkBridge: Trustless Cross-chain Bridges Made Practical",
    "abstract": "Blockchains have seen growing traction with cryptocurrencies reaching a\nmarket cap of over 1 trillion dollars, major institution investors taking\ninterests, and global impacts on governments, businesses, and individuals. Also\ngrowing significantly is the heterogeneity of the ecosystem where a variety of\nblockchains co-exist. Cross-chain bridge is a necessary building block in this\nmulti-chain ecosystem. Existing solutions, however, either suffer from\nperformance issues or rely on trust assumptions of committees that\nsignificantly lower the security. Recurring attacks against bridges have cost\nusers more than 1.5 billion USD. In this paper, we introduce zkBridge, an\nefficient cross-chain bridge that guarantees strong security without external\ntrust assumptions. With succinct proofs, zkBridge not only guarantees\ncorrectness, but also significantly reduces on-chain verification cost. We\npropose novel succinct proof protocols that are orders-of-magnitude faster than\nexisting solutions for workload in zkBridge. With a modular design, zkBridge\nenables a broad spectrum of use cases and capabilities, including message\npassing, token transferring, and other computational logic operating on state\nchanges from different chains. To demonstrate the practicality of zkBridge, we\nimplemented a prototype bridge from Cosmos to Ethereum, a particularly\nchallenging direction that involves large proof circuits that existing systems\ncannot efficiently handle. Our evaluation shows that zkBridge achieves\npractical performance: proof generation takes less than 20 seconds, while\nverifying proofs on-chain costs less than 230K gas. For completeness, we also\nimplemented and evaluated the direction from Ethereum to other EVM-compatible\nchains (such as BSC) which involves smaller circuits and incurs much less\noverhead.",
    "descriptor": "\nComments: An extended version of the paper to appear in ACM CCS 2022\n",
    "authors": [
      "Tiancheng Xie",
      "Jiaheng Zhang",
      "Zerui Cheng",
      "Fan Zhang",
      "Yupeng Zhang",
      "Yongzheng Jia",
      "Dan Boneh",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00264"
  },
  {
    "id": "arXiv:2210.00266",
    "title": "Long-Tailed Class Incremental Learning",
    "abstract": "In class incremental learning (CIL) a model must learn new classes in a\nsequential manner without forgetting old ones. However, conventional CIL\nmethods consider a balanced distribution for each new task, which ignores the\nprevalence of long-tailed distributions in the real world. In this work we\npropose two long-tailed CIL scenarios, which we term ordered and shuffled\nLT-CIL. Ordered LT-CIL considers the scenario where we learn from head classes\ncollected with more samples than tail classes which have few. Shuffled LT-CIL,\non the other hand, assumes a completely random long-tailed distribution for\neach task. We systematically evaluate existing methods in both LT-CIL scenarios\nand demonstrate very different behaviors compared to conventional CIL\nscenarios. Additionally, we propose a two-stage learning baseline with a\nlearnable weight scaling layer for reducing the bias caused by long-tailed\ndistribution in LT-CIL and which in turn also improves the performance of\nconventional CIL due to the limited exemplars. Our results demonstrate the\nsuperior performance (up to 6.44 points in average incremental accuracy) of our\napproach on CIFAR-100 and ImageNet-Subset. The code is available at\nhttps://github.com/xialeiliu/Long-Tailed-CIL",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Xialei Liu",
      "Yu-Song Hu",
      "Xu-Sheng Cao",
      "Andrew D. Bagdanov",
      "Ke Li",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00266"
  },
  {
    "id": "arXiv:2210.00267",
    "title": "RIS Design to Optimize the CRB for Source Localization",
    "abstract": "Reconfigurable Intelligent Surface (RIS) plays a pivotal role in enhancing\nsource localization accuracy. Based on the information inequality of Fisher\ninformation analyses, the Cram\\'{e}r-Rao Bound (CRB) of the localization error\ncan be used to evaluate the localization accuracy for a given set of RIS\ncoefficients. However, there is a lack of research in optimizing these RIS\ncoefficients to decrease the CRB under the constraint imposed by the RIS\nhardware. In this paper, we adopt the manifold optimization method to derive\nthe locally optimal CRB of the localization error, where the RIS coefficients\nare restricted to lie on the complex circle manifold. Specifically, the\nWirtinger derivatives are calculated in the gradient descent part, and the\nRiemannian nonlinear acceleration technique is employed to speed up the\nconvergence rate. Simulation results show that the proposed method can yield\nthe locally optimal RIS coefficients and can significantly decrease the CRB of\nlocalization error. Moreover, the iteration number can be reduced by the\nacceleration technique.",
    "descriptor": "",
    "authors": [
      "Yuhua Jiang",
      "Feifei Gao",
      "Wanm"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00267"
  },
  {
    "id": "arXiv:2210.00268",
    "title": "Joint Mobility Control and MEC Offloading for Hybrid  Satellite-Terrestrial-Network-Enabled Robots",
    "abstract": "Benefiting from the fusion of communication and intelligent technologies,\nnetwork-enabled robots have become important to support future machine-assisted\nand unmanned applications. To provide high-quality services for robots in wide\nareas, hybrid satellite-terrestrial networks are a key technology. Through\nhybrid networks, computation-intensive and latency-sensitive tasks can be\noffloaded to mobile edge computing (MEC) servers. However, due to the mobility\nof mobile robots and unreliable wireless network environments, excessive local\ncomputations and frequent service migrations may significantly increase the\nservice delay. To address this issue, this paper aims to minimize the average\ntask completion time for MEC-based offloading initiated by\nsatellite-terrestrial-network-enabled robots. Different from conventional\nmobility-aware schemes, the proposed scheme makes the offloading decision by\njointly considering the mobility control of robots. A joint optimization\nproblem of task offloading and velocity control is formulated. Using Lyapunov\noptimization, the original optimization is decomposed into a velocity control\nsubproblem and a task offloading subproblem. Then, based on the Markov decision\nprocess (MDP), a dual-agent reinforcement learning (RL) algorithm is proposed.\nTheoretical analysis proves the convergence of the improved RL algorithm, and\nthe simulation results show that the proposed scheme can effectively reduce the\noffloading delay.",
    "descriptor": "\nComments: 14 pages, 16 figures\n",
    "authors": [
      "Peng Wei",
      "Wei Feng",
      "Yunfei Chen",
      "Ning Ge",
      "Cheng-Xiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00268"
  },
  {
    "id": "arXiv:2210.00269",
    "title": "Solar Power Time Series Forecasting Utilising Wavelet Coefficients",
    "abstract": "Accurate and reliable prediction of Photovoltaic (PV) power output is\ncritical to electricity grid stability and power dispatching capabilities.\nHowever, Photovoltaic (PV) power generation is highly volatile and unstable due\nto different reasons. The Wavelet Transform (WT) has been utilised in time\nseries applications, such as Photovoltaic (PV) power prediction, to model the\nstochastic volatility and reduce prediction errors. Yet the existing Wavelet\nTransform (WT) approach has a limitation in terms of time complexity. It\nrequires reconstructing the decomposed components and modelling them separately\nand thus needs more time for reconstruction, model configuration and training.\nThe aim of this study is to improve the efficiency of applying Wavelet\nTransform (WT) by proposing a new method that uses a single simplified model.\nGiven a time series and its Wavelet Transform (WT) coefficients, it trains one\nmodel with the coefficients as features and the original time series as labels.\nThis eliminates the need for component reconstruction and training numerous\nmodels. This work contributes to the day-ahead aggregated solar Photovoltaic\n(PV) power time series prediction problem by proposing and comprehensively\nevaluating a new approach of employing WT. The proposed approach is evaluated\nusing 17 months of aggregated solar Photovoltaic (PV) power data from two\nreal-world datasets. The evaluation includes the use of a variety of prediction\nmodels, including Linear Regression, Random Forest, Support Vector Regression,\nand Convolutional Neural Networks. The results indicate that using a\ncoefficients-based strategy can give predictions that are comparable to those\nobtained using the components-based approach while requiring fewer models and\nless computational time.",
    "descriptor": "",
    "authors": [
      "Sarah Almaghrabi",
      "Mashud Rana",
      "Margaret Hamilton",
      "Mohammad Saiedur Rahaman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00269"
  },
  {
    "id": "arXiv:2210.00270",
    "title": "ML for Location Prediction Using RSSI On WiFi 2.4 GHZ Frequency Band",
    "abstract": "For decades, the determination of an objects location has been implemented\nutilizing different technologies. Despite GPS (Global Positioning System)\nprovides a scalable efficient and cost effective location services however the\nsatellite emitted signals cannot be exploited indoor to effectively determine\nthe location. In contrast to GPS which is a cost effective localization\ntechnology for outdoor locations several technologies have been studied for\nindoor localization. These include Wireless Fidelity (Wi-Fi) Bluetooth Low\nEnergy (BLE) and Received Signal Strength Indicator (RSSI) etc. This paper\npresents an enhanced method of using RSSI as a mean to determine an objects\nlocation by applying some Machine Learning (ML) concepts. The binary\nclassification is defined by considering the adjacency of the coordinates\ndenoting objects locations. The proposed features were tested empirically via\nmultiple classifiers that achieved a maximum of 96 percent accuracy.",
    "descriptor": "",
    "authors": [
      "Ali Abdullah S. AlQahtani",
      "Nazim Choudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00270"
  },
  {
    "id": "arXiv:2210.00272",
    "title": "FINDE: Neural Differential Equations for Finding and Preserving  Invariant Quantities",
    "abstract": "Many real-world dynamical systems are associated with first integrals (a.k.a.\ninvariant quantities), which are quantities that remain unchanged over time.\nThe discovery and understanding of first integrals are fundamental and\nimportant topics both in the natural sciences and in industrial applications.\nFirst integrals arise from the conservation laws of system energy, momentum,\nand mass, and from constraints on states; these are typically related to\nspecific geometric structures of the governing equations. Existing neural\nnetworks designed to ensure such first integrals have shown excellent accuracy\nin modeling from data. However, these models incorporate the underlying\nstructures, and in most situations where neural networks learn unknown systems,\nthese structures are also unknown. This limitation needs to be overcome for\nscientific discovery and modeling of unknown systems. To this end, we propose\nfirst integral-preserving neural differential equation (FINDE). By leveraging\nthe projection method and the discrete gradient method, FINDE finds and\npreserves first integrals from data, even in the absence of prior knowledge\nabout underlying structures. Experimental results demonstrate that FINDE can\npredict future states of target systems much longer and find various quantities\nconsistent with well-known first integrals in a unified manner.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Takashi Matsubara",
      "Takaharu Yaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00272"
  },
  {
    "id": "arXiv:2210.00275",
    "title": "Offline Handwritten Amharic Character Recognition Using Few-shot  Learning",
    "abstract": "Few-shot learning is an important, but challenging problem of machine\nlearning aimed at learning from only fewer labeled training examples. It has\nbecome an active area of research due to deep learning requiring huge amounts\nof labeled dataset, which is not feasible in the real world. Learning from a\nfew examples is also an important attempt towards learning like humans.\nFew-shot learning has proven a very good promise in different areas of machine\nlearning applications, particularly in image classification. As it is a recent\ntechnique, most researchers focus on understanding and solving the issues\nrelated to its concept by focusing only on common image datasets like\nMini-ImageNet and Omniglot. Few-shot learning also opens an opportunity to\naddress low resource languages like Amharic. In this study, offline handwritten\nAmharic character recognition using few-shot learning is addressed.\nParticularly, prototypical networks, the popular and simpler type of few-shot\nlearning, is implemented as a baseline. Using the opportunities explored in the\nnature of Amharic alphabet having row-wise and column-wise similarities, a\nnovel way of augmenting the training episodes is proposed. The experimental\nresults show that the proposed method outperformed the baseline method. This\nstudy has implemented few-shot learning for Amharic characters for the first\ntime. More importantly, the findings of the study open new ways of examining\nthe influence of training episodes in few-shot learning, which is one of the\nimportant issues that needs exploration. The datasets used for this study are\ncollected from native Amharic language writers using an Android App developed\nas a part of this study.",
    "descriptor": "\nComments: PanAfriCon AI 2022 virtual conference paper\n",
    "authors": [
      "Mesay Samuel",
      "Lars Schmidt-Thieme",
      "DP Sharma",
      "Abiot Sinamo",
      "Abey Bruck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00275"
  },
  {
    "id": "arXiv:2210.00276",
    "title": "Electromagnetic Channel Model for Near Field MIMO Systems in The Half  Space",
    "abstract": "In most multiple-input multiple-output (MIMO) communication systems, the\namount of information that can be transmitted reliably depends on the effective\ndegrees of freedom (EDoF) of the wireless channel. Conventionally, one can\nmodel the channel matrix and study the EDoF, based on an electromagnetic (EM)\nchannel model that is built with the free space Green's function. However, the\nEDoF of free-space channel model may not fit the practical scenario when EM\nwaves only transmit above the ground. In this paper, we analyze the EDoF for\nboth discrete and continuous aperture MIMO systems in the half space. We also\npropose an approach to quickly calculate the Green function in the half space\nfrom the Sommerfeld identity. Simulation results show that the difference\nbetween the EDoF in the half space and that in the free space is non-negligible\nfor the near field communications, which indicates that the ground exerts\nnoticeable influence on EDoF. The proposed study establishes a fundamental\nelectromagnetic framework for MIMO wireless communication in the half space.",
    "descriptor": "",
    "authors": [
      "Yuhua Jiang",
      "Feifei Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00276"
  },
  {
    "id": "arXiv:2210.00278",
    "title": "Det-SLAM: A semantic visual SLAM for highly dynamic scenes using  Detectron2",
    "abstract": "According to experts, Simultaneous Localization and Mapping (SLAM) is an\nintrinsic part of autonomous robotic systems. Several SLAM systems with\nimpressive performance have been invented and used during the last several\ndecades. However, there are still unresolved issues, such as how to deal with\nmoving objects in dynamic situations. Classic SLAM systems depend on the\nassumption of a static environment, which becomes unworkable in highly dynamic\nsituations. Several methods have been presented to tackle this issue in recent\nyears, but each has its limitations. This research combines the visual SLAM\nsystems ORB-SLAM3 and Detectron2 to present the Det-SLAM system, which employs\ndepth information and semantic segmentation to identify and eradicate dynamic\nspots to accomplish semantic SLAM for dynamic situations. Evaluation of public\nTUM datasets indicates that Det-SLAM is more resilient than previous dynamic\nSLAM systems and can lower the estimated error of camera posture in dynamic\nindoor scenarios.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Ali Eslamian",
      "Mohammad R. Ahmadzadeh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00278"
  },
  {
    "id": "arXiv:2210.00279",
    "title": "Failure-informed adaptive sampling for PINNs",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as an effective\ntechnique for solving PDEs in a wide range of domains. Recent research has\ndemonstrated, however, that the performance of PINNs can vary dramatically with\ndifferent sampling procedures, and that using a fixed set of training points\ncan be detrimental to the convergence of PINNs to the correct solution. In this\npaper, we present an adaptive approach termed failure-informed PINNs(FI-PINNs),\nwhich is inspired by the viewpoint of reliability analysis. The basic idea is\nto define a failure probability by using the residual, which represents the\nreliability of the PINNs. With the aim of placing more samples in the failure\nregion and fewer samples in the safe region, FI-PINNs employs a\nfailure-informed enrichment technique to incrementally add new collocation\npoints to the training set adaptively. Using the new collocation points, the\naccuracy of the PINNs model is then improved. The failure probability, similar\nto classical adaptive finite element methods, acts as an error indicator that\nguides the refinement of the training set. When compared to the conventional\nPINNs method and the residual-based adaptive refinement method, the developed\nalgorithm can significantly improve accuracy, especially for low regularity and\nhigh-dimensional problems. We prove rigorous bounds on the error incurred by\nthe proposed FI-PINNs and illustrate its performance through several problems.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Zhiwei Gao",
      "Liang Yan",
      "Tao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00279"
  },
  {
    "id": "arXiv:2210.00282",
    "title": "Construction and Evaluation of a Self-Attention Model for Semantic  Understanding of Sentence-Final Particles",
    "abstract": "Sentence-final particles serve an essential role in spoken Japanese because\nthey express the speaker's mental attitudes toward a proposition and/or an\ninterlocutor. They are acquired at early ages and occur very frequently in\neveryday conversation. However, there has been little proposal for a\ncomputational model of acquiring sentence-final particles. This paper proposes\nSubjective BERT, a self-attention model that takes various subjective senses in\naddition to language and images as input and learns the relationship between\nwords and subjective senses. An evaluation experiment revealed that the model\nunderstands the usage of \"yo\", which expresses the speaker's intention to\ncommunicate new information, and that of \"ne\", which denotes the speaker's\ndesire to confirm that some information is shared.",
    "descriptor": "\nComments: 4 pages, 1 figure. Published in the Program and Abstract Booklet of Workshop on Constructive Approaches to Co-Creative Communication in Joint Conference on Language Evolution, 2022\n",
    "authors": [
      "Shuhei Mandokoro",
      "Natsuki Oka",
      "Akane Matsushima",
      "Chie Fukada",
      "Yuko Yoshimura",
      "Koji Kawahara",
      "Kazuaki Tanaka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.00282"
  },
  {
    "id": "arXiv:2210.00283",
    "title": "Swift Markov Logic for Probabilistic Reasoning on Knowledge Graphs",
    "abstract": "We provide a framework for probabilistic reasoning in Vadalog-based Knowledge\nGraphs (KGs), satisfying the requirements of ontological reasoning: full\nrecursion, powerful existential quantification, expression of inductive\ndefinitions. Vadalog is a Knowledge Representation and Reasoning (KRR) language\nbased on Warded Datalog+/-, a logical core language of existential rules, with\na good balance between computational complexity and expressive power. Handling\nuncertainty is essential for reasoning with KGs. Yet Vadalog and Warded\nDatalog+/- are not covered by the existing probabilistic logic programming and\nstatistical relational learning approaches for several reasons, including\ninsufficient support for recursion with existential quantification, and the\nimpossibility to express inductive definitions. In this work, we introduce Soft\nVadalog, a probabilistic extension to Vadalog, satisfying these desiderata. A\nSoft Vadalog program induces what we call a Probabilistic Knowledge Graph\n(PKG), which consists of a probability distribution on a network of chase\ninstances, structures obtained by grounding the rules over a database using the\nchase procedure. We exploit PKGs for probabilistic marginal inference. We\ndiscuss the theory and present MCMC-chase, a Monte Carlo method to use Soft\nVadalog in practice. We apply our framework to solve data management and\nindustrial problems, and experimentally evaluate it in the Vadalog system.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Luigi Bellomarini",
      "Eleonora Laurenza",
      "Emanuel Sallinger",
      "Evgeny Sherkhonov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00283"
  },
  {
    "id": "arXiv:2210.00286",
    "title": "NeuroEvo: A Cloud-based Platform for Automated Design and Training of  Neural Networks using Evolutionary and Particle Swarm Algorithms",
    "abstract": "Evolutionary algorithms (EAs) provide unique advantages for optimizing neural\nnetworks in complex search spaces. This paper introduces a new web platform,\nNeuroEvo (neuroevo.io), that allows users to interactively design and train\nneural network classifiers using evolutionary and particle swarm algorithms.\nThe classification problem and training data are provided by the user and, upon\ncompletion of the training process, the best classifier is made available to\ndownload and implement in Python, Java, and JavaScript. NeuroEvo is a\ncloud-based application that leverages GPU parallelization to improve the speed\nwith which the independent evolutionary steps, such as mutation, crossover, and\nfitness evaluation, are executed across the population. This paper outlines the\ntraining algorithms and opportunities for users to specify design decisions and\nhyperparameter settings. The algorithms described in this paper are also made\navailable as a Python package, neuroevo (PyPI:\nhttps://pypi.org/project/neuroevo/).",
    "descriptor": "",
    "authors": [
      "Philip Schroeder"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00286"
  },
  {
    "id": "arXiv:2210.00289",
    "title": "Robust Power Allocation and Linear Precoding for Cell-Free and  Multi-Cell Massive MIMO Systems",
    "abstract": "Multi-Cell (MC) systems are present in mobile network operations from the\nfirst generation to the fifth generation of wireless networks, and considers\nthe signals of all users to a base station (BS) centered in a cell. Cell-Free\n(CF) systems works with a large number of distributed antennas serving users at\nthe same time. In this context, Multiple-input multiple-output (MIMO)\ntechniques are used in both topologies and result in performance gains and\ninterference reduction. In order to achieve the benefits mentioned, proper\nprecoder design and power allocation techniques are required in the downlink\n(DL). In general, DL schemes assume perfect channel state information at the\ntransmitter (CSIT), which is not realistic. This paper studies MC and CF with\nMIMO systems equipped with linear precoders in the DL and proposes an adaptive\nalgorithm to allocate power in the presence of imperfect CSIT. The proposed\nrobust adaptive power allocation outperforms standard adaptive and uniform\npower allocation. Simulations also compare the performance of both systems\nframeworks using minimum mean-square error (MMSE) precoders with robust\nadaptive power allocation and adaptive power allocation.",
    "descriptor": "\nComments: 6 figures, 8 pages\n",
    "authors": [
      "E. F. de Almeida",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00289"
  },
  {
    "id": "arXiv:2210.00292",
    "title": "DeltaBound Attack: Efficient decision-based attack in low queries regime",
    "abstract": "Deep neural networks and other machine learning systems, despite being\nextremely powerful and able to make predictions with high accuracy, are\nvulnerable to adversarial attacks. We proposed the DeltaBound attack: a novel,\npowerful attack in the hard-label setting with $\\ell_2$ norm bounded\nperturbations. In this scenario, the attacker has only access to the top-1\npredicted label of the model and can be therefore applied to real-world\nsettings such as remote API. This is a complex problem since the attacker has\nvery little information about the model. Consequently, most of the other\ntechniques present in the literature require a massive amount of queries for\nattacking a single example. Oppositely, this work mainly focuses on the\nevaluation of attack's power in the low queries regime $\\leq 1000$ queries)\nwith $\\ell_2$ norm in the hard-label settings. We find that the DeltaBound\nattack performs as well and sometimes better than current state-of-the-art\nattacks while remaining competitive across different kinds of models. Moreover,\nwe evaluate our method against not only deep neural networks, but also non-deep\nlearning models, such as Gradient Boosting Decision Trees and Multinomial Naive\nBayes.",
    "descriptor": "",
    "authors": [
      "Lorenzo Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00292"
  },
  {
    "id": "arXiv:2210.00293",
    "title": "Deep Intrinsically Motivated Exploration in Continuous Control",
    "abstract": "In continuous control, exploration is often performed through undirected\nstrategies in which parameters of the networks or selected actions are\nperturbed by random noise. Although the deep setting of undirected exploration\nhas been shown to improve the performance of on-policy methods, they introduce\nan excessive computational complexity and are known to fail in the off-policy\nsetting. The intrinsically motivated exploration is an effective alternative to\nthe undirected strategies, but they are usually studied for discrete action\ndomains. In this paper, we investigate how intrinsic motivation can effectively\nbe combined with deep reinforcement learning in the control of continuous\nsystems to obtain a directed exploratory behavior. We adapt the existing\ntheories on animal motivational systems into the reinforcement learning\nparadigm and introduce a novel and scalable directed exploration strategy. The\nintroduced approach, motivated by the maximization of the value function's\nerror, can benefit from a collected set of experiences by extracting useful\ninformation and unify the intrinsic exploration motivations in the literature\nunder a single exploration objective. An extensive set of empirical studies\ndemonstrate that our framework extends to larger and more diverse state spaces,\ndramatically improves the baselines, and outperforms the undirected strategies\nsignificantly.",
    "descriptor": "",
    "authors": [
      "Baturay Saglam",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00293"
  },
  {
    "id": "arXiv:2210.00294",
    "title": "Gait-based Age Group Classification with Adaptive Graph Neural Network",
    "abstract": "Deep learning techniques have recently been utilized for model-free\nage-associated gait feature extraction. However, acquiring model-free gait\ndemands accurate pre-processing such as background subtraction, which is\nnon-trivial in unconstrained environments. On the other hand, model-based gait\ncan be obtained without background subtraction and is less affected by\ncovariates. For model-based gait-based age group classification problems,\npresent works rely solely on handcrafted features, where feature extraction is\ntedious and requires domain expertise. This paper proposes a deep learning\napproach to extract age-associated features from model-based gait for age group\nclassification. Specifically, we first develop an unconstrained gait dataset\ncalled Multimedia University Gait Age and Gender dataset (MMU GAG). Next, the\nbody joint coordinates are determined via pose estimation algorithms and\nrepresented as compact gait graphs via a novel part aggregation scheme. Then, a\nPart-AdaptIve Residual Graph Convolutional Neural Network (PairGCN) is designed\nfor age-associated feature learning. Experiments suggest that PairGCN features\nare far more informative than handcrafted features, yielding up to 99% accuracy\nfor classifying subjects as a child, adult, or senior in the MMU GAG dataset.",
    "descriptor": "",
    "authors": [
      "Timilehin B. Aderinola",
      "Tee Connie",
      "Thian Song Ong",
      "Andrew Beng Jin Teoh",
      "Michael Kah Ong Goh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00294"
  },
  {
    "id": "arXiv:2210.00298",
    "title": "An Ensemble of Convolutional Neural Networks to Detect Foliar Diseases  in Apple Plants",
    "abstract": "Apple diseases, if not diagnosed early, can lead to massive resource loss and\npose a serious threat to humans and animals who consume the infected apples.\nHence, it is critical to diagnose these diseases early in order to manage plant\nhealth and minimize the risks associated with them. However, the conventional\napproach of monitoring plant diseases entails manual scouting and analyzing the\nfeatures, texture, color, and shape of the plant leaves, resulting in delayed\ndiagnosis and misjudgments. Our work proposes an ensembled system of Xception,\nInceptionResNet, and MobileNet architectures to detect 5 different types of\napple plant diseases. The model has been trained on the publicly available\nPlant Pathology 2021 dataset and can classify multiple diseases in a given\nplant leaf. The system has achieved outstanding results in multi-class and\nmulti-label classification and can be used in a real-time setting to monitor\nlarge apple plantations to aid the farmers manage their yields effectively.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Kush Vora",
      "Dishant Padalia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00298"
  },
  {
    "id": "arXiv:2210.00299",
    "title": "Federated Representation Learning via Maximal Coding Rate Reduction",
    "abstract": "We propose a federated methodology to learn low-dimensional representations\nfrom a dataset that is distributed among several clients. In particular, we\nmove away from the commonly-used cross-entropy loss in federated learning, and\nseek to learn shared low-dimensional representations of the data in a\ndecentralized manner via the principle of maximal coding rate reduction (MCR2).\nOur proposed method, which we refer to as FLOW, utilizes MCR2 as the objective\nof choice, hence resulting in representations that are both between-class\ndiscriminative and within-class compressible. We theoretically show that our\ndistributed algorithm achieves a first-order stationary point. Moreover, we\ndemonstrate, via numerical experiments, the utility of the learned\nlow-dimensional representations.",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00299"
  },
  {
    "id": "arXiv:2210.00301",
    "title": "Learning Globally Smooth Functions on Manifolds",
    "abstract": "Smoothness and low dimensional structures play central roles in improving\ngeneralization and stability in learning and statistics. The combination of\nthese properties has led to many advances in semi-supervised learning,\ngenerative modeling, and control of dynamical systems. However, learning smooth\nfunctions is generally challenging, except in simple cases such as learning\nlinear or kernel models. Typical methods are either too conservative, relying\non crude upper bounds such as spectral normalization, too lax, penalizing\nsmoothness on average, or too computationally intensive, requiring the solution\nof large-scale semi-definite programs. These issues are only exacerbated when\ntrying to simultaneously exploit low dimensionality using, e.g., manifolds.\nThis work proposes to overcome these obstacles by combining techniques from\nsemi-infinite constrained learning and manifold regularization. To do so, it\nshows that, under typical conditions, the problem of learning a Lipschitz\ncontinuous function on a manifold is equivalent to a dynamically weighted\nmanifold regularization problem. This observation leads to a practical\nalgorithm based on a weighted Laplacian penalty whose weights are adapted using\nstochastic gradient techniques. We prove that, under mild conditions, this\nmethod estimates the Lipschitz constant of the solution, learning a globally\nsmooth solution as a byproduct. Numerical examples illustrate the advantages of\nusing this method to impose global smoothness on manifolds as opposed to\nimposing smoothness on average.",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luiz Chamon",
      "Benjamin D. Haeffele",
      "Rene Vidal",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00301"
  },
  {
    "id": "arXiv:2210.00305",
    "title": "PromptKG: A Prompt Learning Framework for Knowledge Graph Representation  Learning and Application",
    "abstract": "Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. KG representation models\nshould consider graph structures and text semantics, but no comprehensive\nopen-sourced framework is mainly designed for KG regarding informative text\ndescription. In this paper, we present PromptKG, a prompt learning framework\nfor KG representation learning and application that equips the cutting-edge\ntext-based methods, integrates a new prompt learning model and supports various\ntasks (e.g., knowledge graph completion, question answering, recommendation,\nand knowledge probing). PromptKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG with long-term technical support.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xin Xie",
      "Zhoubo Li",
      "Xiaohan Wang",
      "Shumin Deng",
      "Feiyu Xiong",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00305"
  },
  {
    "id": "arXiv:2210.00310",
    "title": "Clustering for directed graphs using parametrized random walk diffusion  kernels",
    "abstract": "Clustering based on the random walk operator has been proven effective for\nundirected graphs, but its generalization to directed graphs (digraphs) is much\nmore challenging. Although the random walk operator is well-defined for\ndigraphs, in most cases such graphs are not strongly connected, and hence the\nassociated random walks are not irreducible, which is a crucial property for\nclustering that exists naturally in the undirected setting. To remedy this, the\nusual workaround is to either naively symmetrize the adjacency matrix or to\nreplace the natural random walk operator by the teleporting random walk\noperator, but this can lead to the loss of valuable information carried by edge\ndirectionality. In this paper, we introduce a new clustering framework, the\nParametrized Random Walk Diffusion Kernel Clustering (P-RWDKC), which is\nsuitable for handling both directed and undirected graphs. Our framework is\nbased on the diffusion geometry and the generalized spectral clustering\nframework. Accordingly, we propose an algorithm that automatically reveals the\ncluster structure at a given scale, by considering the random walk dynamics\nassociated with a parametrized kernel operator, and by estimating its critical\ndiffusion time. Experiments on $K$-NN graphs constructed from real-world\ndatasets and real-world graphs show that our clustering approach performs well\nin all tested cases, and outperforms existing approaches in most of them.",
    "descriptor": "",
    "authors": [
      "Harry Sevi",
      "Matthieu Jonckheere",
      "Argyris Kalogeratos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00310"
  },
  {
    "id": "arXiv:2210.00312",
    "title": "Multimodal Analogical Reasoning over Knowledge Graphs",
    "abstract": "Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ningyu Zhang",
      "Lei Li",
      "Xiang Chen",
      "Xiaozhuan Liang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00312"
  },
  {
    "id": "arXiv:2210.00313",
    "title": "CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family",
    "abstract": "Polar codes are widely used state-of-the-art codes for reliable communication\nthat have recently been included in the 5th generation wireless standards (5G).\nHowever, there remains room for the design of polar decoders that are both\nefficient and reliable in the short blocklength regime. Motivated by recent\nsuccesses of data-driven channel decoders, we introduce a novel\n$\\textbf{C}$ur$\\textbf{RI}$culum based $\\textbf{S}$equential neural decoder for\n$\\textbf{P}$olar codes (CRISP). We design a principled curriculum, guided by\ninformation-theoretic insights, to train CRISP and show that it outperforms the\nsuccessive-cancellation (SC) decoder and attains near-optimal reliability\nperformance on the Polar(16,32) and Polar(22, 64) codes. The choice of the\nproposed curriculum is critical in achieving the accuracy gains of CRISP, as we\nshow by comparing against other curricula. More notably, CRISP can be readily\nextended to Polarization-Adjusted-Convolutional (PAC) codes, where existing SC\ndecoders are significantly less reliable. To the best of our knowledge, CRISP\nconstructs the first data-driven decoder for PAC codes and attains near-optimal\nperformance on the PAC(16, 32) code.",
    "descriptor": "\nComments: 24 pages, 23 figures\n",
    "authors": [
      "S Ashwin Hebbar",
      "Viraj Nadkarni",
      "Ashok Vardhan Makkuva",
      "Suma Bhat",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00313"
  },
  {
    "id": "arXiv:2210.00314",
    "title": "Concurrent Recognition and Segmentation with Adaptive Segment Tokens",
    "abstract": "Recognizing an image and segmenting it into coherent regions are often\ntreated as separate tasks. Human vision, however, has a general sense of\nsegmentation hierarchy before recognition occurs. We are thus inspired to learn\nimage recognition with hierarchical image segmentation based entirely on\nunlabeled images. Our insight is to learn fine-to-coarse features concurrently\nat superpixels, segments, and full image levels, enforcing consistency and\ngoodness of feature induced segmentations while maximizing discrimination among\nimage instances.\nOur model innovates vision transformers on three aspects. 1) We use adaptive\nsegment tokens instead of fixed-shape patch tokens. 2) We create a token\nhierarchy by inserting graph pooling between transformer blocks, naturally\nproducing consistent multi-scale segmentations while increasing the segment\nsize and reducing the number of tokens. 3) We produce hierarchical image\nsegmentation for free while training for recognition by maximizing image-wise\ndiscrimination.\nOur work delivers the first concurrent recognition and hierarchical\nsegmentation model without any supervision. Validated on ImageNet and PASCAL\nVOC, it achieves better recognition and segmentation with higher computational\nefficiency.",
    "descriptor": "",
    "authors": [
      "Tsung-Wei Ke",
      "Jyh-Jing Hwang",
      "Stella X. Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00314"
  },
  {
    "id": "arXiv:2210.00315",
    "title": "Using Argumentation Schemes to Model Legal Reasoning",
    "abstract": "We present argumentation schemes to model reasoning with legal cases. We\nprovide schemes for each of the three stages that take place after the facts\nare established: factor ascription, issue resolution and outcome determination.\nThe schemes are illustrated with examples from a specific legal domain, US\nTrade Secrets law, and the wider applicability of these schemes is discussed.",
    "descriptor": "",
    "authors": [
      "Trevor Bench-Capon",
      "Katie Atkinson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00315"
  },
  {
    "id": "arXiv:2210.00317",
    "title": "Implementation of a Three-class Classification LS-SVM Model for the  Hybrid Antenna Array with Bowtie Elements in the Adaptive Beamforming  Application",
    "abstract": "To address three significant challenges of massive wireless communications\nincluding propagation loss, long-distance transmission, and channel fading, we\naim at establishing the hybrid antenna array with bowtie elements in a compact\nsize for beamforming applications. In this work we rigorously demonstrate that\nbowtie elements allow for a significant improvement in the beamforming\nperformance of the hybrid antenna array compared to not only other available\nantenna arrays, but also its geometrical counterpart with dipole elements. We\nhave achieved a greater than 15 dB increase in SINR values, a greater than 20%\nimprovement in the antenna efficiency, a significant enhancement in the DoA\nestimation, and 20 increments in the directivity for the hybrid antenna array\nwith bowtie elements, compared to its geometrical counterpart, by performing a\nthree-class classification LS-SVM (LeastSquares Support Vector Machine)\noptimization method. The proposed hybrid antenna array has shown a 3D uniform\ndirectivity, which is accompanied by its superior performance in the 3D uniform\nbeam-scanning capability. The directivities remain almost constant at 40.83 dBi\nwith the variation of angle {\\theta}, and 41.21 dBi with the variation of angle\n{\\phi}. The unrivaled functionality and performance of the hybrid antenna array\nwith bowtie elements makes it a potential candidate for beamforming\napplications in massive wireless communications.",
    "descriptor": "",
    "authors": [
      "Somayeh Komeylian",
      "Christopher Paolini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00317"
  },
  {
    "id": "arXiv:2210.00319",
    "title": "PathFinder: Discovering Decision Pathways in Deep Neural Networks",
    "abstract": "Explainability is becoming an increasingly important topic for deep neural\nnetworks. Though the operation in convolutional layers is easier to understand,\nprocessing becomes opaque in fully-connected layers. The basic idea in our work\nis that each instance, as it flows through the layers, causes a different\nactivation pattern in the hidden layers and in our Paths methodology, we\ncluster these activation vectors for each hidden layer and then see how the\nclusters in successive layers connect to one another as activation flows from\nthe input layer to the output. We find that instances of the same class follow\na small number of cluster sequences over the layers, which we name ``decision\npaths.\" Such paths explain how classification decisions are typically made, and\nalso help us determine outliers that follow unusual paths. We also propose\nusing the Sankey diagram to visualize such pathways. We validate our method\nwith experiments on two feed-forward networks trained on MNIST and CELEB data\nsets, and one recurrent network trained on PenDigits.",
    "descriptor": "",
    "authors": [
      "Ozan \u0130rsoy",
      "Ethem Alpayd\u0131n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00319"
  },
  {
    "id": "arXiv:2210.00320",
    "title": "MALM: Mixing Augmented Language Modeling for Zero-Shot Machine  Translation",
    "abstract": "Large pre-trained language models have brought remarkable progress in NLP.\nPre-training and Fine-tuning have given state-of-art performance across tasks\nin text processing. Data Augmentation techniques have also helped build\nstate-of-art models on low or zero resource tasks. Many works in the past have\nattempted at learning a single massively-multilingual machine translation model\nfor zero-shot translation. Although those translation models are producing\ncorrect translations, the main challenge is those models are producing the\nwrong languages for zero-shot translation. This work and its results indicate\nthat prompt conditioned large models do not suffer from off-target language\nerrors i.e. errors arising due to translation to wrong languages. We\nempirically demonstrate the effectiveness of self-supervised pre-training and\ndata augmentation for zero-shot multi-lingual machine translation.",
    "descriptor": "\nComments: Published in 2nd Workshop on Natural Language Processing for Digital Humanities (NLP4DH 2022) which was organized with AACL 2022\n",
    "authors": [
      "Kshitij Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00320"
  },
  {
    "id": "arXiv:2210.00325",
    "title": "Privacy-preserving Decentralized Federated Learning over Time-varying  Communication Graph",
    "abstract": "Establishing how a set of learners can provide privacy-preserving federated\nlearning in a fully decentralized (peer-to-peer, no coordinator) manner is an\nopen problem. We propose the first privacy-preserving consensus-based algorithm\nfor the distributed learners to achieve decentralized global model aggregation\nin an environment of high mobility, where the communication graph between the\nlearners may vary between successive rounds of model aggregation. In\nparticular, in each round of global model aggregation, the Metropolis-Hastings\nmethod is applied to update the weighted adjacency matrix based on the current\ncommunication topology. In addition, the Shamir's secret sharing scheme is\nintegrated to facilitate privacy in reaching consensus of the global model. The\npaper establishes the correctness and privacy properties of the proposed\nalgorithm. The computational efficiency is evaluated by a simulation built on a\nfederated learning framework with a real-word dataset.",
    "descriptor": "",
    "authors": [
      "Yang Lu",
      "Zhengxin Yu",
      "Neeraj Suri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00325"
  },
  {
    "id": "arXiv:2210.00327",
    "title": "Deep Recurrent Q-learning for Energy-constrained Coverage with a Mobile  Robot",
    "abstract": "In this paper, we study the problem of coverage of an environment with an\nenergy-constrained robot in the presence of multiple charging stations. As the\nrobot's on-board power supply is limited, it might not have enough energy to\ncover all the points in the environment with a single charge. Instead, it will\nneed to stop at one or more charging stations to recharge its battery\nintermittently. The robot cannot violate the energy constraint, i.e., visit a\nlocation with negative available energy. To solve this problem, we propose a\ndeep Q-learning framework that produces a policy to maximize the coverage and\nminimize the budget violations. Our proposed framework also leverages the\nmemory of a recurrent neural network (RNN) to better suit this multi-objective\noptimization problem. We have tested the presented framework within a 16 x 16\ngrid environment having charging stations and various obstacle configurations.\nResults show that our proposed method finds feasible solutions and outperforms\na comparable existing technique.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Aaron Zellner",
      "Ayan Dutta",
      "Iliya Kulbaka",
      "Gokarna Sharma"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.00327"
  },
  {
    "id": "arXiv:2210.00328",
    "title": "CodeDSI: Differentiable Code Search",
    "abstract": "Reimplementing solutions to previously solved software engineering problems\nis not only inefficient but also introduces inadequate and error-prone code.\nMany existing methods achieve impressive performance on this issue by using\nautoregressive text-generation models trained on code. However, these methods\nare not without their flaws. The generated code from these models can be buggy,\nlack documentation, and introduce vulnerabilities that may go unnoticed by\ndevelopers. An alternative to code generation -- neural code search -- is a\nfield of machine learning where a model takes natural language queries as input\nand, in turn, relevant code samples from a database are returned. Due to the\nnature of this pre-existing database, code samples can be documented, tested,\nlicensed, and checked for vulnerabilities before being used by developers in\nproduction. In this work, we present CodeDSI, an end-to-end unified approach to\ncode search. CodeDSI is trained to directly map natural language queries to\ntheir respective code samples, which can be retrieved later. In an effort to\nimprove the performance of code search, we have investigated docid\nrepresentation strategies, impact of tokenization on docid structure, and\ndataset sizes on overall code search performance. Our results demonstrate\nCodeDSI strong performance, exceeding conventional robust baselines by 2-6%\nacross varying dataset sizes.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Usama Nadeem",
      "Noah Ziems",
      "Shaoen Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.00328"
  },
  {
    "id": "arXiv:2210.00330",
    "title": "Social VR and multi-party holographic communications: Opportunities,  Challenges and Impact in the Education and Training Sectors",
    "abstract": "Technological advances can bring many benefits to our daily lives, and this\nincludes the education and training sectors. In the last years, online\neducation, teaching and training models are becoming increasingly adopted, in\npart influenced by major circumstances like the pandemic. The use of\nvideoconferencing tools in such sectors has become fundamental, but recent\nresearch has shown their multiple limitations in terms of relevant aspects,\nlike comfort, interaction quality, situational awareness, (co-)presence, etc.\nThis study elaborates on a new communication, interaction and collaboration\nmedium that becomes a promising candidate to overcome such limitations, by\nadopting immersive technologies: Social Virtual Reality (VR). First, this\narticle provides a comprehensive review of studies having provided initial\nevidence on (potential) benefits provided by Social VR in relevant use cases\nrelated to education, such as online classes, training and co-design\nactivities, virtual conferences and interactive visits to virtual spaces, many\nof them including comparisons with classical tools like 2D conferencing.\nLikewise, the potential benefits of integrating realistic and volumetric users'\nrepresentations to enable multi-party holographic communications in Social VR\nis also discussed. Next, this article identifies and elaborates on key\nlimitations of existing studies in this field, including both technological and\nmethodological aspects. Finally, it discusses key remaining challenges to be\naddressed to fully exploit the potential of Social VR in the education sector.",
    "descriptor": "",
    "authors": [
      "Mario Montagud",
      "Gianluca Cernigliaro",
      "Miguel Arevalillo-Herr\u00e1ez",
      "Miguel Garc\u00eda-Pineda",
      "Jaume Segura-Garcia",
      "Sergi Fern\u00e1ndez"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.00330"
  },
  {
    "id": "arXiv:2210.00339",
    "title": "Longitudinal Sentiment Analyses for Radicalization Research:  Intertemporal Dynamics on Social Media Platforms and their Implications",
    "abstract": "This discussion paper demonstrates how longitudinal sentiment analyses can\ndepict intertemporal dynamics on social media platforms, what challenges are\ninherent and how further research could benefit from a longitudinal\nperspective. Furthermore and since tools for sentiment analyses shall simplify\nand accelerate the analytical process regarding qualitative data at acceptable\ninter-rater reliability, their applicability in the context of radicalization\nresearch will be examined regarding the Tweets collected on January 6th 2021,\nthe day of the storming of the U.S. Capitol in Washington. Therefore, a total\nof 49,350 Tweets will be analyzed evenly distributed within three different\nsequences: before, during and after the U.S. Capitol in Washington was stormed.\nThese sequences highlight the intertemporal dynamics within comments on social\nmedia platforms as well as the possible benefits of a longitudinal perspective\nwhen using conditional means and conditional variances. Limitations regarding\nthe identification of supporters of such events and associated hate speech as\nwell as common application errors will be demonstrated as well. As a result,\nonly under certain conditions a longitudinal sentiment analysis can increase\nthe accuracy of evidence based predictions in the context of radicalization\nresearch.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Dennis Klinkhammer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.00339"
  },
  {
    "id": "arXiv:2210.00340",
    "title": "Speed Up the Cold-Start Learning in Two-Sided Bandits with Many Arms",
    "abstract": "Multi-armed bandit (MAB) algorithms are efficient approaches to reduce the\nopportunity cost of online experimentation and are used by companies to find\nthe best product from periodically refreshed product catalogs. However, these\nalgorithms face the so-called cold-start at the onset of the experiment due to\na lack of knowledge of customer preferences for new products, requiring an\ninitial data collection phase known as the burning period. During this period,\nMAB algorithms operate like randomized experiments, incurring large burning\ncosts which scale with the large number of products. We attempt to reduce the\nburning by identifying that many products can be cast into two-sided products,\nand then naturally model the rewards of the products with a matrix, whose rows\nand columns represent the two sides respectively. Next, we design two-phase\nbandit algorithms that first use subsampling and low-rank matrix estimation to\nobtain a substantially smaller targeted set of products and then apply a UCB\nprocedure on the target products to find the best one. We theoretically show\nthat the proposed algorithms lower costs and expedite the experiment in cases\nwhen there is limited experimentation time along with a large product set. Our\nanalysis also reveals three regimes of long, short, and ultra-short horizon\nexperiments, depending on dimensions of the matrix. Empirical evidence from\nboth synthetic data and a real-world dataset on music streaming services\nvalidates this superior performance.",
    "descriptor": "",
    "authors": [
      "Mohsen Bayati",
      "Junyu Cao",
      "Wanning Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00340"
  },
  {
    "id": "arXiv:2210.00346",
    "title": "Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis  Function Decomposition",
    "abstract": "This work analyzes the solution trajectory of gradient-based algorithms via a\nnovel basis function decomposition. We show that, although solution\ntrajectories of gradient-based algorithms may vary depending on the learning\ntask, they behave almost monotonically when projected onto an appropriate\northonormal function basis. Such projection gives rise to a basis function\ndecomposition of the solution trajectory. Theoretically, we use our proposed\nbasis function decomposition to establish the convergence of gradient descent\n(GD) on several representative learning tasks. In particular, we improve the\nconvergence of GD on symmetric matrix factorization and provide a completely\nnew convergence result for the orthogonal symmetric tensor decomposition.\nEmpirically, we illustrate the promise of our proposed framework on realistic\ndeep neural networks (DNNs) across different architectures, gradient-based\nsolvers, and datasets. Our key finding is that gradient-based algorithms\nmonotonically learn the coefficients of a particular orthonormal function basis\nof DNNs defined as the eigenvectors of the conjugate kernel after training. Our\ncode is available at https://github.com/jianhaoma/function-basis-decomposition.",
    "descriptor": "",
    "authors": [
      "Jianhao Ma",
      "Lingjun Gun",
      "Salar Fattahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00346"
  },
  {
    "id": "arXiv:2210.00350",
    "title": "Zero-Shot Policy Transfer with Disentangled Task Representation of  Meta-Reinforcement Learning",
    "abstract": "Humans are capable of abstracting various tasks as different combinations of\nmultiple attributes. This perspective of compositionality is vital for human\nrapid learning and adaption since previous experiences from related tasks can\nbe combined to generalize across novel compositional settings. In this work, we\naim to achieve zero-shot policy generalization of Reinforcement Learning (RL)\nagents by leveraging the task compositionality. Our proposed method is a meta-\nRL algorithm with disentangled task representation, explicitly encoding\ndifferent aspects of the tasks. Policy generalization is then performed by\ninferring unseen compositional task representations via the obtained\ndisentanglement without extra exploration. The evaluation is conducted on three\nsimulated tasks and a challenging real-world robotic insertion task.\nExperimental results demonstrate that our proposed method achieves policy\ngeneralization to unseen compositional tasks in a zero-shot manner.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Zheng Wu",
      "Yichen Xie",
      "Wenzhao Lian",
      "Changhao Wang",
      "Yanjiang Guo",
      "Jianyu Chen",
      "Stefan Schaal",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00350"
  },
  {
    "id": "arXiv:2210.00356",
    "title": "Social and environmental impact of recent developments in machine  learning on biology and chemistry research",
    "abstract": "Potential societal and environmental effects such as the rapidly increasing\nresource use and the associated environmental impact, reproducibility issues,\nand exclusivity, the privatization of ML research leading to a public research\nbrain-drain, a narrowing of the research effort caused by a focus on deep\nlearning, and the introduction of biases through a lack of sociodemographic\ndiversity in data and personnel caused by recent developments in machine\nlearning are a current topic of discussion and scientific publications.\nHowever, these discussions and publications focus mainly on computer\nscience-adjacent fields, including computer vision and natural language\nprocessing or basic ML research. Using bibliometric analysis of the complete\nand full-text analysis of the open-access literature, we show that the same\nobservations can be made for applied machine learning in chemistry and biology.\nThese developments can potentially affect basic and applied research, such as\ndrug discovery and development, beyond the known issue of biased data sets.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Daniel Probst"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00356"
  },
  {
    "id": "arXiv:2210.00358",
    "title": "Differentially Private Timeseries Forecasts for Networked Control",
    "abstract": "We study how a controller relying on a timeseries forecast can minimize its\ncontrol cost given imperfect future forecasts. Forecasts are imperfect because\nrandom perturbations are added to protect the private input data of forecasting\nmodels, thereby leading to additional control costs. We analyze a scenario\nwhere the controller is able to pay the forecasting models an economic\nincentive, such as money, to lower their noise. Thus, the forecasting models\nare paid based on their contributions to reducing control costs. A trade-off\narises for forecasting models to receive incentives or protect their privacy.\nWe then study how a controller can allocate economic currency to forecasting\nmodels and combine resulting forecasts to minimize its cost while preserving\ndata privacy. We use the linear quadratic regulator as an example of this\nscenario, and solve a biconvex optimization problem with guaranteed local\noptimality. We demonstrate our method on a synthetic ARIMA timeseries and a\nreal-world demand forecast from the ride sharing service Uber. Our method\nreduces control costs compared to a scheme that allocates incentives and\ncombines forecasts uniformly by 2.5 and 2.7 times for the synthetic ARIMA\ntimeseries and the Uber demand forecast, respectively.",
    "descriptor": "\nComments: Submission to ACC 2023\n",
    "authors": [
      "Po-han Li",
      "Sandeep P. Chinchali",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00358"
  },
  {
    "id": "arXiv:2210.00361",
    "title": "Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection",
    "abstract": "Thanks to the remarkable advances in generative adversarial networks (GANs),\nit is becoming increasingly easy to generate/manipulate images. The existing\nworks have mainly focused on deepfake in face images and videos. However, we\nare currently witnessing the emergence of fake satellite images, which can be\nmisleading or even threatening to national security. Consequently, there is an\nurgent need to develop detection methods capable of distinguishing between real\nand fake satellite images. To advance the field, in this paper, we explore the\nsuitability of several convolutional neural network (CNN) architectures for\nfake satellite image detection. Specifically, we benchmark four CNN models by\nconducting extensive experiments to evaluate their performance and robustness\nagainst various image distortions. This work allows the establishment of new\nbaselines and may be useful for the development of CNN-based methods for fake\nsatellite image detection.",
    "descriptor": "\nComments: IEEE International Workshop on Multimedia Signal Processing (MMSP'2022)\n",
    "authors": [
      "Sid Ahmed Fezza",
      "Mohammed Yasser Ouis",
      "Bachir Kaddar",
      "Wassim Hamidouche",
      "Abdenour Hadid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00361"
  },
  {
    "id": "arXiv:2210.00364",
    "title": "DCI-ES: An Extended Disentanglement Framework with Connections to  Identifiability",
    "abstract": "In representation learning, a common approach is to seek representations\nwhich disentangle the underlying factors of variation. Eastwood & Williams\n(2018) proposed three metrics for quantifying the quality of such disentangled\nrepresentations: disentanglement (D), completeness (C) and informativeness (I).\nIn this work, we first connect this DCI framework to two common notions of\nlinear and nonlinear identifiability, thus establishing a formal link between\ndisentanglement and the closely-related field of independent component\nanalysis. We then propose an extended DCI-ES framework with two new measures of\nrepresentation quality - explicitness (E) and size (S) - and point out how D\nand C can be computed for black-box predictors. Our main idea is that the\nfunctional capacity required to use a representation is an important but\nthus-far neglected aspect of representation quality, which we quantify using\nexplicitness or ease-of-use (E). We illustrate the relevance of our extensions\non the MPI3D and Cars3D datasets.",
    "descriptor": "",
    "authors": [
      "Cian Eastwood",
      "Andrei Liviu Nicolicioiu",
      "Julius von K\u00fcgelgen",
      "Armin Keki\u0107",
      "Frederik Tr\u00e4uble",
      "Andrea Dittadi",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00364"
  },
  {
    "id": "arXiv:2210.00368",
    "title": "Parameter-varying neural ordinary differential equations with  partition-of-unity networks",
    "abstract": "In this study, we propose parameter-varying neural ordinary differential\nequations (NODEs) where the evolution of model parameters is represented by\npartition-of-unity networks (POUNets), a mixture of experts architecture. The\nproposed variant of NODEs, synthesized with POUNets, learn a meshfree partition\nof space and represent the evolution of ODE parameters using sets of\npolynomials associated to each partition. We demonstrate the effectiveness of\nthe proposed method for three important tasks: data-driven dynamics modeling of\n(1) hybrid systems, (2) switching linear dynamical systems, and (3) latent\ndynamics for dynamical systems with varying external forcing.",
    "descriptor": "",
    "authors": [
      "Kookjin Lee",
      "Nathaniel Trask"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00368"
  },
  {
    "id": "arXiv:2210.00377",
    "title": "CHARTOPOLIS: A Small-Scale Labor-art-ory for Research and Reflection on  Autonomous Vehicles, Human-Robot Interaction, and Sociotechnical Imaginaries",
    "abstract": "CHARTOPOLIS is a multi-faceted sociotechnical testbed meant to aid in\nbuilding connections among engineers, psychologists, anthropologists,\nethicists, and artists. Superficially, it is an urban autonomous-vehicle\ntestbed that includes both a physical environment for small-scale robotic\nvehicles as well as a high-fidelity virtual replica that provides extra\nflexibility by way of computer simulation. However, both environments have been\ndeveloped to allow for participatory simulation with human drivers as well.\nEach physical vehicle can be remotely operated by human drivers that have a\ndriver-seat point of view that immerses them within the small-scale testbed,\nand those same drivers can also pilot high-fidelity models of those vehicles in\na virtual replica of the environment. Juxtaposing human driving performance\nacross these two contexts will help identify to what extent human driving\nbehaviors are sensorimotor responses or involve psychological engagement with a\nsystem that has physical, not virtual, side effects and consequences.\nFurthermore, through collaboration with artists, we have designed the physical\ntestbed to make tangible the reality that technological advancement causes the\nhistory of a city to fork into multiple, parallel timelines that take place\nwithin populations whose increasing isolation effectively creates multiple\nindependent cities in one. Ultimately, CHARTOPOLIS is meant to challenge\nengineers to take a more holistic view when designing autonomous systems, while\nalso enabling them to gather novel data that will assist them in making these\nsystems more trustworthy.",
    "descriptor": "\nComments: Submission to 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022) Workshop on Miniature Robot Platforms for Full Scale Autonomous Vehicle Research\n",
    "authors": [
      "Sangeet Sankaramangalam Ulhas",
      "Aditya Ravichander",
      "Kathryn A. Johnson",
      "Theodore P. Pavlic",
      "Lance Gharavi",
      "Spring Berman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00377"
  },
  {
    "id": "arXiv:2210.00379",
    "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review",
    "abstract": "Neural Radiance Field (NeRF), a new novel view synthesis with implicit scene\nrepresentation has taken the field of Computer Vision by storm. As a novel view\nsynthesis and 3D reconstruction method, NeRF models find applications in\nrobotics, urban mapping, autonomous navigation, virtual reality/augmented\nreality, and more. Since the original paper by Mildenhall et al., more than 250\npreprints were published, with more than 100 eventually being accepted in tier\none Computer Vision Conferences. Given NeRF popularity and the current interest\nin this research area, we believe it necessary to compile a comprehensive\nsurvey of NeRF papers from the past two years, which we organized into both\narchitecture, and application based taxonomies. We also provide an introduction\nto the theory of NeRF based novel view synthesis, and a benchmark comparison of\nthe performance and speed of key NeRF models. By creating this survey, we hope\nto introduce new researchers to NeRF, provide a helpful reference for\ninfluential works in this field, as well as motivate future research directions\nwith our discussion section.",
    "descriptor": "",
    "authors": [
      "Kyle Gao",
      "Yina Gao",
      "Hongjie He",
      "Denning Lu",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00379"
  },
  {
    "id": "arXiv:2210.00380",
    "title": "Causal Knowledge Transfer from Task Affinity",
    "abstract": "Recent developments in deep representation models through counterfactual\nbalancing have led to a promising framework for estimating Individual Treatment\nEffects (ITEs) that are essential to causal inference in the Neyman-Rubin\npotential outcomes framework. While Randomized Control Trials are vital to\nunderstanding causal effects, they are sometimes infeasible, costly, or\nunethical to conduct. Motivated by these potential obstacles to data\nacquisition, we focus on transferring the causal knowledge acquired in prior\nexperiments to new scenarios for which only limited data is available. To this\nend, we first observe that the absolute values of ITEs are invariant under the\naction of the symmetric group on the labels of treatments. Given this\ninvariance, we propose a symmetrized task distance for calculating the\nsimilarity of a target scenario with those encountered before. The\naforementioned task distance is then used to transfer causal knowledge from the\nclosest of all the available previously learned tasks to the target scenario.\nWe provide upper bounds on the counterfactual loss and ITE error of the target\ntask indicating the transferability of causal knowledge. Empirical studies are\nprovided for various real-world, semi-synthetic, and synthetic datasets\ndemonstrating that the proposed symmetrized task distance is strongly related\nto the estimation of the counterfactual loss. Numerical results indicate that\ntransferring causal knowledge reduces the amount of required data by up to 95%\nwhen compared to training from scratch. These results reveal the promise of our\nmethod when applied to important albeit challenging real-world scenarios such\nas transferring the knowledge of treatment effects (e.g., medicine, social\npolicy, personal training, etc.) studied on a population to other groups absent\nin the study.",
    "descriptor": "",
    "authors": [
      "Ahmed Aloui",
      "Juncheng Dong",
      "Cat P. Le",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00380"
  },
  {
    "id": "arXiv:2210.00389",
    "title": "A Novel Parallel Triangle Counting Algorithm with Reduced Communication",
    "abstract": "Counting and finding triangles in graphs is often used in real-world\nanalytics for characterizing the cohesiveness and identifying communities in\ngraphs. In this paper, we present novel sequential and parallel triangle\ncounting algorithms based on identifying horizontal-edges in a breadth-first\nsearch (BFS) traversal of the graph. The BFS allows our algorithm to\ndrastically reduce the number of edges examined for set intersections. Our new\napproach is the first communication-optimal parallel algorithm that\nasymptotically reduces the communication on massive graphs such as from real\nsocial networks and synthetic graphs from the Graph500 Benchmark. In our\nestimate from massive-scale Graph500 graphs, our new algorithms reduces the\ncommunication by 21x on a scale 36 and by 176x on a scale 42. Because\ncommunication is known to be the dominant cost of parallel triangle counting,\nour new parallel algorithm, to our knowledge, is now the fastest method for\ncounting triangles in large graphs.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "David A. Bader",
      "Fuhuan Li",
      "Anya Ganeshan",
      "Ahmet Gundogdu",
      "Jason Lew",
      "Oliver Alvarado Rodriguez",
      "Zhihui Du"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.00389"
  },
  {
    "id": "arXiv:2210.00390",
    "title": "An adaptive superconvergent finite element method based on local  residual minimization",
    "abstract": "We introduce an adaptive superconvergent finite element method for a class of\nmixed formulations to solve partial differential equations involving a\ndiffusion term. It combines a superconvergent postprocessing technique for the\nprimal variable with an adaptive finite element method via residual\nminimization. Such a residual minimization procedure is performed on a local\npostprocessing scheme, commonly used in the context of mixed finite element\nmethods. Given the local nature of that approach, the underlying saddle point\nproblems associated with residual minimizations can be solved with minimal\ncomputational effort. We propose and study a posteriori error estimators,\nincluding the built-in residual representative associated with residual\nminimization schemes; and an improved estimator which adds, on the one hand, a\nresidual term quantifying the mismatch between discrete fluxes and, on the\nother hand, the interelement jumps of the postprocessed solution. We present\nnumerical experiments in two dimensions using Brezzi-Douglas-Marini elements as\ninput for our methodology. The experiments perfectly fit our key theoretical\nfindings and suggest that our estimates are sharp.",
    "descriptor": "",
    "authors": [
      "Ignacio Muga",
      "Sergio Rojas",
      "Patrick Vega"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00390"
  },
  {
    "id": "arXiv:2210.00391",
    "title": "Online Revenue Maximization with Unknown Concave Utilities",
    "abstract": "We study an online revenue maximization problem where the consumers arrive\ni.i.d from some unknown distribution and purchase a bundle of products from the\nsellers. The classical approach generally assumes complete knowledge of the\nconsumer utility functions, while recent works have been devoted to unknown\nlinear utility functions. This paper focuses on the online posted-price model\nwith unknown consumer distribution and unknown consumer utilities, given they\nare concave. Hence, the two questions to ask are i) when is the seller's online\nmaximization problem concave, and ii) how to find the optimal pricing strategy\nfor non-linear utilities. We answer the first question by imposing a\nthird-order smoothness condition on the utilities. The second question is\naddressed by two algorithms, which we prove to exhibit the sub-linear regrets\nof $O(T^{\\frac{2}{3}} (\\log T)^{\\frac{1}{3}})$ and $O(T^{\\frac{1}{2}} (\\log\nT)^{\\frac{1}{2}})$ respectively.",
    "descriptor": "",
    "authors": [
      "Owen Shen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00391"
  },
  {
    "id": "arXiv:2210.00393",
    "title": "(Non)-Coherent MU-MIMO Block Fading Channels with Finite Blocklength and  Linear Processing",
    "abstract": "This paper studies the coherent and non-coherent multiuser multiple-input\nmultiple-output (MU-MIMO) uplink system in the finite blocklength regime. The\ni.i.d. Gaussian codebook is assumed for each user. To be more specific, the BS\nfirst uses two popular linear processing schemes to combine the signals\ntransmitted from all users, namely, MRC and ZF. Following it, the matched\nmaximum-likelihood (ML) and mismatched nearest-neighbour (NN) decoding metric\nfor the coherent and non-coherent cases are respectively employed at the BS.\nUnder these conditions, the refined third-order achievable coding rate,\nexpressed as a function of the blocklength, average error probability, and the\nthird-order term of the information density (called as the channel\nperturbation), is derived. With this result in hand, a detailed performance\nanalysis is then pursued, through which, we derive the asymptotic results of\nthe channel perturbation, achievable coding rate, channel capacity, and the\nchannel dispersion. These theoretical results enable us to obtain a number of\ninteresting insights related to the impact of the finite blocklength: i) in our\nsystem setting, massive MIMO helps to reduce the channel perturbation of the\nachievable coding rate, which can even be discarded without affecting the\nperformance with just a small-to-moderate number of BS antennas and number of\nblocks; ii) under the non-coherent case, even with massive MIMO, the channel\nestimation errors cannot be eliminated unless the transmit powers in both the\nchannel estimation and data transmission phases for each user are made\ninversely proportional to the square root of the number of BS antennas; iii) in\nthe non-coherent case and for fixed total blocklength, the scenarios with\nlonger coherence intervals and smaller number of blocks offer higher achievable\ncoding rate.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Junjuan Feng",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00393"
  },
  {
    "id": "arXiv:2210.00394",
    "title": "CGELBank: CGEL as a Framework for English Syntax Annotation",
    "abstract": "We introduce the syntactic formalism of the \\textit{Cambridge Grammar of the\nEnglish Language} (CGEL) to the world of treebanking through the CGELBank\nproject. We discuss some issues in linguistic analysis that arose in adapting\nthe formalism to corpus annotation, followed by quantitative and qualitative\ncomparisons with parallel UD and PTB treebanks. We argue that CGEL provides a\ngood tradeoff between comprehensiveness of analysis and usability for\nannotation, which motivates expanding the treebank with automatic conversion in\nthe future.",
    "descriptor": "\nComments: 11 pages (8 main text)\n",
    "authors": [
      "Brett Reynolds",
      "Aryaman Arora",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00394"
  },
  {
    "id": "arXiv:2210.00396",
    "title": "Re-Routing Strategy of Connected and Automated Vehicles Considering  Coordination at Intersections",
    "abstract": "In this paper, we propose a re-routing strategy for connected and automated\nvehicles (CAVs), considering coordination and control of all the CAVs in the\nnetwork. The objective for each CAV is to find the route that minimizes the\ntotal travel time of all CAVs. We coordinate CAVs at signal-free intersections\nto accurately predict the travel time for the routing problem. While it is\npossible to find a system-optimal solution by comparing all the possible\ncombinations of the routes, this may impose a computational burden. Thus, we\ninstead find a person-by-person optimal solution to reduce computational time\nwhile still deriving a better solution than selfish routing. We validate our\nframework through simulations in a grid network.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Heeseung Bang",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00396"
  },
  {
    "id": "arXiv:2210.00400",
    "title": "Systematic Generalization and Emergent Structures in Transformers  Trained on Structured Tasks",
    "abstract": "Transformer networks have seen great success in natural language processing\nand machine vision, where task objectives such as next word prediction and\nimage classification benefit from nuanced context sensitivity across\nhigh-dimensional inputs. However, there is an ongoing debate about how and when\ntransformers can acquire highly structured behavior and achieve systematic\ngeneralization. Here, we explore how well a causal transformer can perform a\nset of algorithmic tasks, including copying, sorting, and hierarchical\ncompositions of these operations. We demonstrate strong generalization to\nsequences longer than those used in training by replacing the standard\npositional encoding typically used in transformers with labels arbitrarily\npaired with items in the sequence. By finding the layer and head configuration\nsufficient to solve the task, then performing ablation experiments and\nrepresentation analysis, we show that two-layer transformers learn\ngeneralizable solutions to multi-level problems and develop signs of systematic\ntask decomposition. They also exploit shared computation across related tasks.\nThese results provide key insights into how transformer models may be capable\nof decomposing complex decisions into reusable, multi-level policies in tasks\nrequiring structured behavior.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Yuxuan Li",
      "James L. McClelland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00400"
  },
  {
    "id": "arXiv:2210.00405",
    "title": "Basic Binary Convolution Unit for Binarized Image Restoration Network",
    "abstract": "Lighter and faster image restoration (IR) models are crucial for the\ndeployment on resource-limited devices. Binary neural network (BNN), one of the\nmost promising model compression methods, can dramatically reduce the\ncomputations and parameters of full-precision convolutional neural networks\n(CNN). However, there are different properties between BNN and full-precision\nCNN, and we can hardly use the experience of designing CNN to develop BNN. In\nthis study, we reconsider components in binary convolution, such as residual\nconnection, BatchNorm, activation function, and structure, for IR tasks. We\nconduct systematic analyses to explain each component's role in binary\nconvolution and discuss the pitfalls. Specifically, we find that residual\nconnection can reduce the information loss caused by binarization; BatchNorm\ncan solve the value range gap between residual connection and binary\nconvolution; The position of the activation function dramatically affects the\nperformance of BNN. Based on our findings and analyses, we design a simple yet\nefficient basic binary convolution unit (BBCU). Furthermore, we divide IR\nnetworks into four parts and specially design variants of BBCU for each part to\nexplore the benefit of binarizing these parts. We conduct experiments on\ndifferent IR tasks, and our BBCU significantly outperforms other BNNs and\nlightweight models, which shows that BBCU can serve as a basic unit for\nbinarized IR networks. All codes and models will be released.",
    "descriptor": "",
    "authors": [
      "Bin Xia",
      "Yulun Zhang",
      "Yitong Wang",
      "Yapeng Tian",
      "Wenming Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.00405"
  },
  {
    "id": "arXiv:2210.00411",
    "title": "Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening  Problem",
    "abstract": "Self-supervised monocular depth estimation (MDE) models universally suffer\nfrom the notorious edge-fattening issue. Triplet loss, popular for metric\nlearning, has made a great success in many computer vision tasks. In this\npaper, we redesign the patch-based triplet loss in MDE to alleviate the\nubiquitous edge-fattening issue. We show two drawbacks of the raw triplet loss\nin MDE and demonstrate our problem-driven redesigns. First, we present a min.\noperator based strategy applied to all negative samples, to prevent\nwell-performing negatives sheltering the error of edge-fattening negatives.\nSecond, we split the anchor-positive distance and anchor-negative distance from\nwithin the original triplet, which directly optimizes the positives without any\nmutual effect with the negatives. Extensive experiments show the combination of\nthese two small redesigns can achieve unprecedented results: Our powerful and\nversatile triplet loss not only makes our model outperform all previous SoTA by\na large margin, but also provides substantial performance boosts to a large\nnumber of existing models, while introducing no extra inference computation at\nall.",
    "descriptor": "\nComments: 8 pages, 7 figures, published to WACV2023\n",
    "authors": [
      "Xingyu Chen",
      "Ruonan Zhang",
      "Ji Jiang",
      "Yan Wang",
      "Ge Li",
      "Thomas H. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00411"
  },
  {
    "id": "arXiv:2210.00412",
    "title": "Observer-based Event-triggered Boundary Control of the One-phase Stefan  Problem",
    "abstract": "The Stefan problem models liquid-solid phase change phenomena as the time\nevolution of a temperature profile in a liquid-solid material and its moving\ninterface. This paper provides an observer-based event-triggered boundary\ncontrol strategy for the one-phase Stefan problem using the position and\nvelocity measurements of the moving interface. The infinite-dimensional\nbackstepping approach is used to design the underlying observer and controller.\nFor the event-triggered implementation of the continuous-time observer-based\ncontroller, a dynamic event triggering condition is proposed. The triggering\ncondition determines the times at which the control input needs to be updated.\nIn between events, the control input is applied in a \\textit{Zero-Order-Hold}\nfashion. It is shown that the dwell-time between two triggering instances is\nuniformly bounded below. Due to the existence of a minimal dwell-time, the\nclosed-loop system is free from the so-called \\textit{Zeno behavior}. Under the\nproposed event-triggered boundary control approach, the well-posedness of the\nclosed-loop system along with certain model validity conditions is proved.\nFurther, using Lyapunov approach, the global exponential convergence of the\nclosed-loop system to the setpoint is proved. A simulation example is provided\nto illustrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Bhathiya Rathnayake",
      "Mamadou Diagne"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00412"
  },
  {
    "id": "arXiv:2210.00413",
    "title": "Unsupervised Vision and Vision-motion Calibration Strategies for  PointGoal Navigation in Indoor Environment",
    "abstract": "PointGoal navigation in indoor environment is a fundamental task for personal\nrobots to navigate to a specified point.\nRecent studies solved this PointGoal navigation task with near-perfect\nsuccess rate in photo-realistically simulated environments,\nunder the assumptions with noiseless actuation and most importantly, perfect\nlocalization with GPS and compass sensors.\nHowever, accurate GPS signal can not be obtained in real indoor environment.\nTo improve the pointgoal navigation accuracy in real indoor,\nwe proposed novel vision and vision-motion calibration strategies to train\nvisual and motion path integration in unsupervised manner.\nSepecifically, visual calibration computes the relative pose of the agent\nfrom the re-projection error of two adjacent frames, and then\nreplaces the accurate GPS signal with the path integration.\nThis pseudo position is also used to calibrate self-motion integration\nwhich assists agent to update their internal perception of location and helps\nimprove the success rate of navigation.\nThe training and inference process only use RGB, depth, collision as well as\nself-action information.\nThe experiments show that the proposed system achieves satisfactory results\nand\noutperforms the partially supervised learning algorithms on the popular\nGibson dataset.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Yijun Cao",
      "Xianshi Zhang",
      "Fuya Luo",
      "Yongjie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00413"
  },
  {
    "id": "arXiv:2210.00415",
    "title": "Metric Distribution to Vector: Constructing Data Representation via  Broad-Scale Discrepancies",
    "abstract": "Graph embedding provides a feasible methodology to conduct pattern\nclassification for graph-structured data by mapping each data into the\nvectorial space. Various pioneering works are essentially coding method that\nconcentrates on a vectorial representation about the inner properties of a\ngraph in terms of the topological constitution, node attributions, link\nrelations, etc. However, the classification for each targeted data is a\nqualitative issue based on understanding the overall discrepancies within the\ndataset scale. From the statistical point of view, these discrepancies manifest\na metric distribution over the dataset scale if the distance metric is adopted\nto measure the pairwise similarity or dissimilarity. Therefore, we present a\nnovel embedding strategy named $\\mathbf{MetricDistribution2vec}$ to extract\nsuch distribution characteristics into the vectorial representation for each\ndata. We demonstrate the application and effectiveness of our representation\nmethod in the supervised prediction tasks on extensive real-world structural\ngraph datasets. The results have gained some unexpected increases compared with\na surge of baselines on all the datasets, even if we take the lightweight\nmodels as classifiers. Moreover, the proposed methods also conducted\nexperiments in Few-Shot classification scenarios, and the results still show\nattractive discrimination in rare training samples based inference.",
    "descriptor": "",
    "authors": [
      "Xue Liu",
      "Dan Sun",
      "Xiaobo Cao",
      "Hao Ye",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00415"
  },
  {
    "id": "arXiv:2210.00418",
    "title": "Subspace Learning for Feature Selection via Rank Revealing QR  Factorization: Unsupervised and Hybrid Approaches with Non-negative Matrix  Factorization and Evolutionary Algorithm",
    "abstract": "The selection of most informative and discriminative features from\nhigh-dimensional data has been noticed as an important topic in machine\nlearning and data engineering. Using matrix factorization-based techniques such\nas nonnegative matrix factorization for feature selection has emerged as a hot\ntopic in feature selection. The main goal of feature selection using matrix\nfactorization is to extract a subspace which approximates the original space\nbut in a lower dimension. In this study, rank revealing QR (RRQR)\nfactorization, which is computationally cheaper than singular value\ndecomposition (SVD), is leveraged in obtaining the most informative features as\na novel unsupervised feature selection technique. This technique uses the\npermutation matrix of QR for feature selection which is a unique property to\nthis factorization method. Moreover, QR factorization is embedded into\nnon-negative matrix factorization (NMF) objective function as a new\nunsupervised feature selection method. Lastly, a hybrid feature selection\nalgorithm is proposed by coupling RRQR, as a filter-based technique, and a\nGenetic algorithm as a wrapper-based technique. In this method, redundant\nfeatures are removed using RRQR factorization and the most discriminative\nsubset of features are selected using the Genetic algorithm. The proposed\nalgorithm shows to be dependable and robust when compared against\nstate-of-the-art feature selection algorithms in supervised, unsupervised, and\nsemi-supervised settings. All methods are tested on seven available microarray\ndatasets using KNN, SVM and C4.5 classifiers. In terms of evaluation metrics,\nthe experimental results shows that the proposed method is comparable with the\nstate-of-the-art feature selection.",
    "descriptor": "\nComments: 34 pages, 10 figures, 4 tables\n",
    "authors": [
      "Amir Moslemi",
      "Arash Ahmadian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.00418"
  },
  {
    "id": "arXiv:2210.00421",
    "title": "Multiple Access Channel in Massive Multi-User MIMO Using Group Testing",
    "abstract": "The number of wireless devices (e.g., cellular phones, IoT, laptops)\nconnected to Wireless Local Area Networks (WLAN) grows each year exponentially.\nThe orchestration of the connected devices becomes infeasible, especially when\nthe number of resources available at the single access point (e.g., Base\nStation, Wireless Access Points) is limited. On the other hand, the number of\nantennas at each device grows too. We leverage the large number of antennas to\nsuggest a massive multiple-user multiple-input-multiple-output (MU-MIMO) scheme\nusing sparse coding based on Group Testing (GT) principles, which reduces\noverhead and complexity. We show that it is possible to jointly identify and\ndecode up to $K$ messages simultaneously out of $N\\cdot C$ messages (where $N$\nis the number of users and $C$ is the number of messages per user) without any\nscheduling overhead or prior knowledge of the identity of the transmitting\ndevices.\nOur scheme is order-optimal in the number of users and messages, utilizing\nminimal knowledge of channel state and an efficient (in both run-time and\nspace) decoding algorithm requiring $O(K\\log NC)$ antennas. We derive\nsufficient conditions for vanishing error probability and bound the minimal\nnumber of antennas necessary for our scheme.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "George Vershinin",
      "Asaf Cohen",
      "Omer Gurewitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00421"
  },
  {
    "id": "arXiv:2210.00423",
    "title": "Improved Algorithms for Neural Active Learning",
    "abstract": "We improve the theoretical and empirical performance of\nneural-network(NN)-based active learning algorithms for the non-parametric\nstreaming setting. In particular, we introduce two regret metrics by minimizing\nthe population loss that are more suitable in active learning than the one used\nin state-of-the-art (SOTA) related work. Then, the proposed algorithm leverages\nthe powerful representation of NNs for both exploitation and exploration, has\nthe query decision-maker tailored for $k$-class classification problems with\nthe performance guarantee, utilizes the full feedback, and updates parameters\nin a more practical and efficient manner. These careful designs lead to a\nbetter regret upper bound, improving by a multiplicative factor $O(\\log T)$ and\nremoving the curse of both input dimensionality and the complexity of the\nfunction to be learned. Furthermore, we show that the algorithm can achieve the\nsame performance as the Bayes-optimal classifier in the long run under the\nhard-margin setting in classification problems. In the end, we use extensive\nexperiments to evaluate the proposed algorithm and SOTA baselines, to show the\nimproved empirical performance.",
    "descriptor": "",
    "authors": [
      "Yikun Ban",
      "Yuheng Zhang",
      "Hanghang Tong",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00423"
  },
  {
    "id": "arXiv:2210.00429",
    "title": "ROSIA: Rotation-Search-Based Star Identification Algorithm",
    "abstract": "Solving the star identification (Star-ID) problem with a\nrotation-search-based approach eliminates the conventional heuristics in the\nestablished paradigms, i.e., the subgraph-isomorphic-based and\npattern-recognition-based methods. However, it is not trivial to execute such\nan approach efficiently. Here, we present ROSIA, which seeks the optimal\nrotation alignment that maximally matches the input and catalog stars in their\nrespective coordinates. ROSIA searches the rotation space systematically with\nthe Branch-and-Bound (BnB) method. Crucially affecting the runtime feasibility\nof ROSIA is the upper bound function that prioritizes the search space. In this\npaper, we make a theoretical contribution by proposing a tight (provable) upper\nbound function that allows a 400x speed up compared to an existing formulation.\nCoupling the bounding function with an efficient evaluation scheme that\nleverages stereographic projection and the R-tree data structure, ROSIA\nachieves real-time operational speed with state-of-the-art performances under\ndifferent sources of noise.",
    "descriptor": "\nComments: 13 pages, 9 figures, Submitted to IEEE Transactions on Aerospace and Electronic Systems\n",
    "authors": [
      "Chee-Kheng Chng",
      "Alvaro Parra Bustos",
      "Benjamin McCarthy",
      "Tat-Jun Chin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00429"
  },
  {
    "id": "arXiv:2210.00430",
    "title": "Understanding Adversarial Robustness Against On-manifold Adversarial  Examples",
    "abstract": "Deep neural networks (DNNs) are shown to be vulnerable to adversarial\nexamples. A well-trained model can be easily attacked by adding small\nperturbations to the original data. One of the hypotheses of the existence of\nthe adversarial examples is the off-manifold assumption: adversarial examples\nlie off the data manifold. However, recent research showed that on-manifold\nadversarial examples also exist. In this paper, we revisit the off-manifold\nassumption and want to study a question: at what level is the poor performance\nof neural networks against adversarial attacks due to on-manifold adversarial\nexamples? Since the true data manifold is unknown in practice, we consider two\napproximated on-manifold adversarial examples on both real and synthesis\ndatasets. On real datasets, we show that on-manifold adversarial examples have\ngreater attack rates than off-manifold adversarial examples on both\nstandard-trained and adversarially-trained models. On synthetic datasets,\ntheoretically, We prove that on-manifold adversarial examples are powerful, yet\nadversarial training focuses on off-manifold directions and ignores the\non-manifold adversarial examples. Furthermore, we provide analysis to show that\nthe properties derived theoretically can also be observed in practice. Our\nanalysis suggests that on-manifold adversarial examples are important, and we\nshould pay more attention to on-manifold adversarial examples for training\nrobust models.",
    "descriptor": "",
    "authors": [
      "Jiancong Xiao",
      "Liusha Yang",
      "Yanbo Fan",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00430"
  },
  {
    "id": "arXiv:2210.00433",
    "title": "Open Framework for Analyzing Public Parliaments Data",
    "abstract": "Open information of government organizations is a subject that should\ninterest all citizens who care about the functionality of their governments.\nLarge-scale open governmental data open the door to new opportunities for\ncitizens and researchers to monitor their government's activities and to\nimprove its transparency. Over the years, various projects and systems have\nbeen processing and analyzing governmental data using open government\ninformation. Here, we present the Collecting and Analyzing Parliament Data\n(CAPD) framework. This novel generic open framework enables the collection and\nanalysis of large-scale public governmental data from multiple sources. We used\nthe framework to collect over 64,000 parliaments' protocols from over 90\ncommittees from three countries. Then, we parsed the collected data and\ncalculated structured features from it. Next, using the calculated features, we\nutilized anomaly detection and time series analysis to uncover various insights\ninto the committees' activities. We demonstrate that the CAPD framework can be\nused to identify anomalous meetings and detect dates of events that affect the\nparliaments' functionality, and help to monitor their activities.",
    "descriptor": "",
    "authors": [
      "Shai Berkovitz",
      "Amit Mazuz",
      "Michael Fire"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.00433"
  },
  {
    "id": "arXiv:2210.00438",
    "title": "Design of Artificial Noise for Physical Layer Security in Visible Light  Systems with Clipping",
    "abstract": "Though visible light communication (VLC) systems are contained to a given\nroom, ensuring their security amongst users in a room is essential. In this\npaper, the design of artificial noise (AN) to enhance physical layer security\nin VLC systems is studied in the context of input signals with no explicit\namplitude constraint (such as multicarrier systems). In such systems, clipping\nis needed to constrain the input signals within the limited linear ranges of\nthe LEDs. However, this clipping process gives rise to non-linear clipping\ndistortion, which must be incorporated into the AN design. To facilitate the\nsolution of this problem, a sub-optimal design approach is presented using the\nCharnes-Cooper transformation and the convex-concave procedure (CCP). Numerical\nresults show that the clipping distortion significantly reduces the secrecy\nlevel, and using AN is advantageous over the no-AN scheme in improving the\nsecrecy performance.",
    "descriptor": "",
    "authors": [
      "Thanh V. Pham",
      "Steve Hranilovic",
      "Susumu Ishihara"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00438"
  },
  {
    "id": "arXiv:2210.00440",
    "title": "Grouped self-attention mechanism for a memory-efficient Transformer",
    "abstract": "Time-series data analysis is important because numerous real-world tasks such\nas forecasting weather, electricity consumption, and stock market involve\npredicting data that vary over time. Time-series data are generally recorded\nover a long period of observation with long sequences owing to their periodic\ncharacteristics and long-range dependencies over time. Thus, capturing\nlong-range dependency is an important factor in time-series data forecasting.\nTo solve these problems, we proposed two novel modules, Grouped Self-Attention\n(GSA) and Compressed Cross-Attention (CCA). With both modules, we achieved a\ncomputational space and time complexity of order $O(l)$ with a sequence length\n$l$ under small hyperparameter limitations, and can capture locality while\nconsidering global information. The results of experiments conducted on\ntime-series datasets show that our proposed model efficiently exhibited reduced\ncomputational complexity and performance comparable to or better than existing\nmethods.",
    "descriptor": "\nComments: 10 pages, 3 figures, under review as a conference paper at ICLR 2023\n",
    "authors": [
      "Bumjun Jung",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00440"
  },
  {
    "id": "arXiv:2210.00442",
    "title": "Modified-operator method for the calculation of band diagrams of  crystalline materials",
    "abstract": "In solid state physics, electronic properties of crystalline materials are\noften inferred from the spectrum of periodic Schr\\\"odinger operators. As a\nconsequence of Bloch's theorem, the numerical computation of electronic\nquantities of interest involves computing derivatives or integrals over the\nBrillouin zone of so-called energy bands, which are piecewise smooth, Lipschitz\ncontinuous periodic functions obtained by solving a parametrized elliptic\neigenvalue problem on a Hilbert space of periodic functions. Classical\ndiscretization strategies for resolving these eigenvalue problems produce\napproximate energy bands that are either non-periodic or discontinuous, both of\nwhich cause difficulty when computing numerical derivatives or employing\nnumerical quadrature. In this article, we study an alternative discretization\nstrategy based on an ad hoc operator modification approach. While specific\ninstances of this approach have been proposed in the physics literature, we\nintroduce here a systematic formulation of this operator modification approach.\nWe derive a priori error estimates for the resulting energy bands and we show\nthat these bands are periodic and can be made arbitrarily smooth (away from\nband crossings) by adjusting suitable parameters in the operator modification\napproach. Numerical experiments involving a toy model in 1D, graphene in 2D,\nand silicon in 3D validate our theoretical results and showcase the efficiency\nof the operator modification approach.",
    "descriptor": "\nComments: 40 pages, 12 figures\n",
    "authors": [
      "Eric Canc\u00e8s",
      "Muhammad Hassan",
      "Laurent Vidal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2210.00442"
  },
  {
    "id": "arXiv:2210.00443",
    "title": "ReAct: A Review Comment Dataset for Actionability (and more)",
    "abstract": "Review comments play an important role in the evolution of documents. For a\nlarge document, the number of review comments may become large, making it\ndifficult for the authors to quickly grasp what the comments are about. It is\nimportant to identify the nature of the comments to identify which comments\nrequire some action on the part of document authors, along with identifying the\ntypes of these comments. In this paper, we introduce an annotated review\ncomment dataset ReAct. The review comments are sourced from OpenReview site. We\ncrowd-source annotations for these reviews for actionability and type of\ncomments. We analyze the properties of the dataset and validate the quality of\nannotations. We release the dataset (https://github.com/gtmdotme/ReAct) to the\nresearch community as a major contribution. We also benchmark our data with\nstandard baselines for classification tasks and analyze their performance.",
    "descriptor": "\nComments: Published at WISE 2021\n",
    "authors": [
      "Gautam Choudhary",
      "Natwar Modani",
      "Nitish Maurya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00443"
  },
  {
    "id": "arXiv:2210.00445",
    "title": "ManiCLIP: Multi-Attribute Face Manipulation from Text",
    "abstract": "In this paper we present a novel multi-attribute face manipulation method\nbased on textual descriptions. Previous text-based image editing methods either\nrequire test-time optimization for each individual image or are restricted to\nsingle attribute editing. Extending these methods to multi-attribute face image\nediting scenarios will introduce undesired excessive attribute change, e.g.,\ntext-relevant attributes are overly manipulated and text-irrelevant attributes\nare also changed. In order to address these challenges and achieve natural\nediting over multiple face attributes, we propose a new decoupling training\nscheme where we use group sampling to get text segments from same attribute\ncategories, instead of whole complex sentences. Further, to preserve other\nexisting face attributes, we encourage the model to edit the latent code of\neach attribute separately via a entropy constraint. During the inference phase,\nour model is able to edit new face images without any test-time optimization,\neven from complex textual prompts. We show extensive experiments and analysis\nto demonstrate the efficacy of our method, which generates natural manipulated\nfaces with minimal text-irrelevant attribute editing. Code and pre-trained\nmodel will be released.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Ana Garc\u00eda del Molino",
      "Anran Wang",
      "Zehuan Yuan",
      "Chunyan Miao",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00445"
  },
  {
    "id": "arXiv:2210.00448",
    "title": "A Smart Recycling Bin Using Waste Image Classification At The Edge",
    "abstract": "Rapid economic growth gives rise to the urgent demand for a more efficient\nwaste recycling system. This work thereby developed an innovative recycling bin\nthat automatically separates urban waste to increase the recycling rate. We\ncollected 1800 recycling waste images and combined them with an existing public\ndataset to train classification models for two embedded systems, Jetson Nano\nand K210, targeting different markets. The model reached an accuracy of 95.98%\non Jetson Nano and 96.64% on K210. A bin program was designed to collect\nfeedback from users. On Jetson Nano, the overall power consumption of the\napplication was reduced by 30% from the previous work to 4.7 W, while the\nsecond system, K210, only needed 0.89 W of power to operate. In summary, our\nwork demonstrated a fully functional prototype of an energy-saving,\nhigh-accuracy smart recycling bin, which can be commercialized in the future to\nimprove urban waste recycling.",
    "descriptor": "",
    "authors": [
      "Xueying Li",
      "Ryan Grammenos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00448"
  },
  {
    "id": "arXiv:2210.00450",
    "title": "Citation Trajectory Prediction via Publication Influence Representation  Using Temporal Knowledge Graph",
    "abstract": "Predicting the impact of publications in science and technology has become an\nimportant research area, which is useful in various real world scenarios such\nas technology investment, research direction selection, and technology\npolicymaking. Citation trajectory prediction is one of the most popular tasks\nin this area. Existing approaches mainly rely on mining temporal and graph data\nfrom academic articles. Some recent methods are capable of handling cold-start\nprediction by aggregating metadata features of new publications. However, the\nimplicit factors causing citations and the richer information from handling\ntemporal and attribute features still need to be explored. In this paper, we\npropose CTPIR, a new citation trajectory prediction framework that is able to\nrepresent the influence (the momentum of citation) of either new or existing\npublications using the history information of all their attributes. Our\nframework is composed of three modules: difference-preserved graph embedding,\nfine-grained influence representation, and learning-based trajectory\ncalculation. To test the effectiveness of our framework in more situations, we\ncollect and construct a new temporal knowledge graph dataset from the real\nworld, named AIPatent, which stems from global patents in the field of\nartificial intelligence. Experiments are conducted on both the APS academic\ndataset and our contributed AIPatent dataset. The results demonstrate the\nstrengths of our approach in the citation trajectory prediction task.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Chang Zong",
      "Yueting Zhuang",
      "Weiming Lu",
      "Jian Shao",
      "Siliang Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.00450"
  },
  {
    "id": "arXiv:2210.00451",
    "title": "Asynchronous Activity Detection for Cell-Free Massive MIMO: From  Centralized to Distributed Algorithms",
    "abstract": "Device activity detection in the emerging cell-free massive multiple-input\nmultiple-output (MIMO) systems has been recognized as a crucial task in\nmachine-type communications, in which multiple access points (APs) jointly\nidentify the active devices from a large number of potential devices based on\nthe received signals. Most of the existing works addressing this problem rely\non the impractical assumption that different active devices transmit signals\nsynchronously. However, in practice, synchronization cannot be guaranteed due\nto the low-cost oscillators, which brings additional discontinuous and\nnonconvex constraints to the detection problem. To address this challenge, this\npaper reveals an equivalent reformulation to the asynchronous activity\ndetection problem, which facilitates the development of a centralized algorithm\nand a distributed algorithm that satisfy the highly nonconvex constraints in a\ngentle fashion as the iteration number increases, so that the sequence\ngenerated by the proposed algorithms can get around bad stationary points. To\nreduce the capacity requirements of the fronthauls, we further design a\ncommunication-efficient accelerated distributed algorithm. Simulation results\ndemonstrate that the proposed centralized and distributed algorithms outperform\nstate-of-the-art approaches, and the proposed accelerated distributed algorithm\nachieves a close detection performance to that of the centralized algorithm but\nwith a much smaller number of bits to be transmitted on the fronthaul links.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Qingfeng Lin",
      "Ya-Feng Liu",
      "Bo Ai",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00451"
  },
  {
    "id": "arXiv:2210.00453",
    "title": "Neural Graphical Models",
    "abstract": "Graphs are ubiquitous and are often used to understand the dynamics of a\nsystem. Probabilistic Graphical Models comprising Bayesian and Markov networks,\nand Conditional Independence graphs are some of the popular graph\nrepresentation techniques. They can model relationships between features\n(nodes) together with the underlying distribution. Although theoretically these\nmodels can represent very complex dependency functions, in practice often\nsimplifying assumptions are made due to computational limitations associated\nwith graph operations. This work introduces Neural Graphical Models (NGMs)\nwhich attempt to represent complex feature dependencies with reasonable\ncomputational costs. Specifically, given a graph of feature relationships and\ncorresponding samples, we capture the dependency structure between the features\nalong with their complex function representations by using neural networks as a\nmulti-task learning framework. We provide efficient learning, inference and\nsampling algorithms for NGMs. Moreover, NGMs can fit generic graph structures\nincluding directed, undirected and mixed-edge graphs as well as support mixed\ninput data types. We present empirical studies that show NGMs' capability to\nrepresent Gaussian graphical models, inference analysis of a lung cancer data\nand extract insights from a real world infant mortality data provided by CDC.",
    "descriptor": "",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00453"
  },
  {
    "id": "arXiv:2210.00457",
    "title": "Towards a Complete Direct Mapping From Relational Databases To Property  Graphs",
    "abstract": "It is increasingly common to find complex data represented through the graph\nmodel. Contrary to relational models, graphs offer a high capacity for\nexecuting analytical tasks on complex data. Since a huge amount of data is\nstill presented in terms of relational tables, it is necessary to understand\nhow to translate this data into graphs. This paper proposes a complete mapping\nprocess that allows transforming any relational database (schema and instance)\ninto a property graph database (schema and instance). Contrary to existing\nmappings, our solution preserves the three fundamental mapping properties,\nnamely: information preservation, semantic preservation and query preservation.\nMoreover, we study mapping any SQL query into an equivalent Cypher query, which\nmakes our solution practical. Existing solutions are either incomplete or based\non non-practical query language. Thus, this work is the first complete and\npractical solution for mapping relations to graphs.",
    "descriptor": "",
    "authors": [
      "Abdelkrim Boudaoud",
      "Houari Mahfoud",
      "Azeddine Chikh"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.00457"
  },
  {
    "id": "arXiv:2210.00462",
    "title": "Improved Stein Variational Gradient Descent with Importance Weights",
    "abstract": "Stein Variational Gradient Descent~(\\algname{SVGD}) is a popular sampling\nalgorithm used in various machine learning tasks. It is well known that\n\\algname{SVGD} arises from a discretization of the kernelized gradient flow of\nthe Kullback-Leibler divergence $D_{KL}\\left(\\cdot\\mid\\pi\\right)$, where $\\pi$\nis the target distribution. In this work, we propose to enhance \\algname{SVGD}\nvia the introduction of {\\em importance weights}, which leads to a new method\nfor which we coin the name \\algname{$\\beta$-SVGD}. In the continuous time and\ninfinite particles regime, the time for this flow to converge to the\nequilibrium distribution $\\pi$, quantified by the Stein Fisher information,\ndepends on $\\rho_0$ and $\\pi$ very weakly. This is very different from the\nkernelized gradient flow of Kullback-Leibler divergence, whose time complexity\ndepends on $D_{KL}\\left(\\rho_0\\mid\\pi\\right)$. Under certain assumptions, we\nprovide a descent lemma for the population limit \\algname{$\\beta$-SVGD}, which\ncovers the descent lemma for the population limit \\algname{SVGD} when $\\beta\\to\n0$. We also illustrate the advantages of \\algname{$\\beta$-SVGD} over\n\\algname{SVGD} by simple experiments.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Lukang Sun",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.00462"
  },
  {
    "id": "arXiv:2210.00465",
    "title": "Assessing the impact of contextual information in hate speech detection",
    "abstract": "In recent years, hate speech has gained great relevance in social networks\nand other virtual media because of its intensity and its relationship with\nviolent acts against members of protected groups. Due to the great amount of\ncontent generated by users, great effort has been made in the research and\ndevelopment of automatic tools to aid the analysis and moderation of this\nspeech, at least in its most threatening forms. One of the limitations of\ncurrent approaches to automatic hate speech detection is the lack of context.\nMost studies and resources are performed on data without context; that is,\nisolated messages without any type of conversational context or the topic being\ndiscussed. This restricts the available information to define if a post on a\nsocial network is hateful or not. In this work, we provide a novel corpus for\ncontextualized hate speech detection based on user responses to news posts from\nmedia outlets on Twitter. This corpus was collected in the Rioplatense\ndialectal variety of Spanish and focuses on hate speech associated with the\nCOVID-19 pandemic. Classification experiments using state-of-the-art techniques\nshow evidence that adding contextual information improves hate speech detection\nperformance for two proposed tasks (binary and multi-label prediction). We make\nour code, models, and corpus available for further research.",
    "descriptor": "",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Franco Luque",
      "Demian Zayat",
      "Mart\u00edn Kondratzky",
      "Agust\u00edn Moro",
      "Pablo Serrati",
      "Joaqu\u00edn Zajac",
      "Paula Miguel",
      "Natalia Debandi",
      "Agust\u00edn Gravano",
      "Viviana Cotik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00465"
  },
  {
    "id": "arXiv:2210.00467",
    "title": "Numerical analysis for coagulation-fragmentation equations with singular  rates",
    "abstract": "This article deals with the convergence of finite volume scheme (FVS) for\nsolving coagulation and multiple fragmentation equations having locally bounded\ncoagulation kernel but singularity near the origin due to fragmentation rates.\nThanks to the Dunford-Pettis and De La Vall$\\acute{e}$e-Poussin theorems which\nallow us to have the convergence of numerically truncated solution towards a\nweak solution of the continuous model using a weak $L^1$ compactness argument.\nA suitable stable condition on time step is taken to achieve the result.\nFurthermore, when kernels are in $W^{1,\\infty}_{loc}$ space, first order error\napproximation is demonstrated for a uniform mesh. It is numerically validated\nby attempting several test problems.",
    "descriptor": "",
    "authors": [
      "Sanjiv Kumar Bariwal",
      "Prasanta Kumar Barik",
      "Ankik Kumar Giri",
      "Rajesh Kumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.00467"
  },
  {
    "id": "arXiv:2210.00471",
    "title": "OCD: Learning to Overfit with Conditional Diffusion Models",
    "abstract": "We present a dynamic model in which the weights are conditioned on an input\nsample x and are learned to match those that would be obtained by finetuning a\nbase model on x and its label y. This mapping between an input sample and\nnetwork weights is shown to be approximated by a linear transformation of the\nsample distribution, which suggests that a denoising diffusion model can be\nsuitable for this task. The diffusion model we therefore employ focuses on\nmodifying a single layer of the base model and is conditioned on the input,\nactivations, and output of this layer. Our experiments demonstrate the wide\napplicability of the method for image classification, 3D reconstruction,\ntabular data, and speech separation. Our code is available at\nhttps://github.com/ShaharLutatiPersonal/OCD.",
    "descriptor": "",
    "authors": [
      "Shahar Shlomo Lutati",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00471"
  },
  {
    "id": "arXiv:2210.00472",
    "title": "VFLens: Co-design the Modeling Process for Efficient Vertical Federated  Learning via Visualization",
    "abstract": "As a decentralized training approach, federated learning enables multiple\norganizations to jointly train a model without exposing their private data.\nThis work investigates vertical federated learning (VFL) to address scenarios\nwhere collaborating organizations have the same set of users but with different\nfeatures, and only one party holds the labels. While VFL shows good\nperformance, practitioners often face uncertainty when preparing\nnon-transparent, internal/external features and samples for the VFL training\nphase. Moreover, to balance the prediction accuracy and the resource\nconsumption of model inference, practitioners require to know which subset of\nprediction instances is genuinely needed to invoke the VFL model for inference.\nTo this end, we co-design the VFL modeling process by proposing an interactive\nreal-time visualization system, VFLens, to help practitioners with feature\nengineering, sample selection, and inference. A usage scenario, a quantitative\nexperiment, and expert feedback suggest that VFLens helps practitioners boost\nVFL efficiency at a lower cost with sufficient confidence.",
    "descriptor": "\nComments: The Tenth International Symposium of Chinese CHI (Chinese CHI 2022), October 22--23, 2022, Guangzhou, China and Online, China\n",
    "authors": [
      "Yun Tian",
      "He Wang",
      "Laixin Xie",
      "Xiaojuan Ma",
      "Quan Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00472"
  },
  {
    "id": "arXiv:2210.00474",
    "title": "Saving the Limping: Fault-tolerant Quadruped Locomotion via  Reinforcement Learning",
    "abstract": "Quadruped locomotion now has acquired the skill to traverse or even sprint on\nuneven terrains in remote uncontrolled environment. However, surviving in the\nwild requires not only the maneuverability, but also the ability to handle\nunexpected hardware failures. We present the first deep reinforcement learning\nbased methodology to train fault-tolerant controllers, which can bring an\ninjured quadruped back home safely and speedily. We adopt the teacher-student\nframework to train the controller with close-to-reality joint-locking failure\nin the simulation, which can be zero-shot transferred to the physical robot\nwithout any fine-tuning. Extensive simulation and real-world experiments\ndemonstrate that our fault-tolerant controller can efficiently lead a quadruped\nstably when it faces joint failure during locomotion.",
    "descriptor": "\nComments: Submitted to ICRA2023\n",
    "authors": [
      "Dikai Liu",
      "Tianwei Zhang",
      "Jianxiong Yin",
      "Simon See"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00474"
  },
  {
    "id": "arXiv:2210.00476",
    "title": "Robust Bayesian optimization with reinforcement learned acquisition  functions",
    "abstract": "In Bayesian optimization (BO) for expensive black-box optimization tasks,\nacquisition function (AF) guides sequential sampling and plays a pivotal role\nfor efficient convergence to better optima. Prevailing AFs usually rely on\nartificial experiences in terms of preferences for exploration or exploitation,\nwhich runs a risk of a computational waste or traps in local optima and\nresultant re-optimization. To address the crux, the idea of data-driven AF\nselection is proposed, and the sequential AF selection task is further\nformalized as a Markov decision process (MDP) and resort to powerful\nreinforcement learning (RL) technologies. Appropriate selection policy for AFs\nis learned from superior BO trajectories to balance between exploration and\nexploitation in real time, which is called reinforcement-learning-assisted\nBayesian optimization (RLABO). Competitive and robust BO evaluations on five\nbenchmark problems demonstrate RL's recognition of the implicit AF selection\npattern and imply the proposal's potential practicality for intelligent AF\nselection as well as efficient optimization in expensive black-box problems.",
    "descriptor": "",
    "authors": [
      "Zijing Liu",
      "Xiyao Qu",
      "Xuejun Liu",
      "Hongqiang Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00476"
  },
  {
    "id": "arXiv:2210.00479",
    "title": "Fast OT for Latent Domain Adaptation",
    "abstract": "In this paper, we address the problem of unsupervised Domain Adaptation. The\nneed for such an adaptation arises when the distribution of the target data\ndiffers from that which is used to develop the model and the ground truth\ninformation of the target data is unknown. We propose an algorithm that uses\noptimal transport theory with a verifiably efficient and implementable solution\nto learn the best latent feature representation. This is achieved by minimizing\nthe cost of transporting the samples from the target domain to the distribution\nof the source domain.",
    "descriptor": "\nComments: 6 PAGES\n",
    "authors": [
      "Siddharth Roheda",
      "Ashkan Panahi",
      "Hamid Krim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00479"
  },
  {
    "id": "arXiv:2210.00482",
    "title": "Compositional Generalization in Unsupervised Compositional  Representation Learning: A Study on Disentanglement and Emergent Language",
    "abstract": "Deep learning models struggle with compositional generalization, i.e. the\nability to recognize or generate novel combinations of observed elementary\nconcepts. In hopes of enabling compositional generalization, various\nunsupervised learning algorithms have been proposed with inductive biases that\naim to induce compositional structure in learned representations (e.g.\ndisentangled representation and emergent language learning). In this work, we\nevaluate these unsupervised learning algorithms in terms of how well they\nenable compositional generalization. Specifically, our evaluation protocol\nfocuses on whether or not it is easy to train a simple model on top of the\nlearned representation that generalizes to new combinations of compositional\nfactors. We systematically study three unsupervised representation learning\nalgorithms -- $\\beta$-VAE, $\\beta$-TCVAE, and emergent language (EL)\nautoencoders -- on two datasets that allow directly testing compositional\ngeneralization. We find that directly using the bottleneck representation with\nsimple models and few labels may lead to worse generalization than using\nrepresentations from layers before or after the learned representation itself.\nIn addition, we find that the previously proposed metrics for evaluating the\nlevels of compositionality are not correlated with actual compositional\ngeneralization in our framework. Surprisingly, we find that increasing pressure\nto produce a disentangled representation produces representations with worse\ngeneralization, while representations from EL models show strong compositional\ngeneralization. Taken together, our results shed new light on the compositional\ngeneralization behavior of different unsupervised learning algorithms with a\nnew setting to rigorously test this behavior, and suggest the potential\nbenefits of delevoping EL learning algorithms for more generalizable\nrepresentations.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhenlin Xu",
      "Marc Niethamme",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00482"
  },
  {
    "id": "arXiv:2210.00483",
    "title": "Learning Algorithm Generalization Error Bounds via Auxiliary  Distributions",
    "abstract": "Generalization error boundaries are essential for comprehending how well\nmachine learning models work. In this work, we suggest a creative method, i.e.,\nthe Auxiliary Distribution Method, that derives new upper bounds on\ngeneralization errors that are appropriate for supervised learning scenarios.\nWe show that our general upper bounds can be specialized under some conditions\nto new bounds involving the generalized $\\alpha$-Jensen-Shannon,\n$\\alpha$-R\\'enyi ($0< \\alpha < 1$) information between random variable modeling\nthe set of training samples and another random variable modeling the set of\nhypotheses. Our upper bounds based on generalized $\\alpha$-Jensen-Shannon\ninformation are also finite. Additionally, we demonstrate how our auxiliary\ndistribution method can be used to derive the upper bounds on generalization\nerror under the distribution mismatch scenario in supervised learning\nalgorithms, where the distributional mismatch is modeled as\n$\\alpha$-Jensen-Shannon or $\\alpha$-R\\'enyi ($0< \\alpha < 1$) between the\ndistribution of test and training data samples. We also outline the\ncircumstances in which our proposed upper bounds might be tighter than other\nearlier upper bounds.",
    "descriptor": "",
    "authors": [
      "Gholamali Aminian",
      "Saeed Masiha",
      "Laura Toni",
      "Miguel R. D. Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00483"
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": "In order to perform machine learning among multiple parties while protecting\nthe privacy of raw data, privacy-preserving machine learning based on secure\nmulti-party computation (MPL for short) has been a hot spot in recent. The\nconfiguration of MPL usually follows the peer-to-peer architecture, where each\nparty has the same chance to reveal the output result. However, typical\nbusiness scenarios often follow a hierarchical architecture where a powerful,\nusually \\textit{privileged party}, leads the tasks of machine learning. Only\nthe \\textit{privileged party} can reveal the final model even if other\n\\textit{assistant parties} collude with each other. It is even required to\navoid the abort of machine learning to ensure the scheduled deadlines and/or\nsave used computing resources when part of \\textit{assistant parties} drop out.\nMotivated by the above scenarios, we propose \\pmpl, a robust MPL framework\nwith a \\textit{privileged party}. \\pmpl supports three-party training in the\nsemi-honest setting. By setting alternate shares for the \\textit{privileged\nparty}, \\pmpl is robust to tolerate one of the rest two parties dropping out\nduring the training. With the above settings, we design a series of efficient\nprotocols based on vector space secret sharing for \\pmpl to bridge the gap\nbetween vector space secret sharing and machine learning. Finally, the\nexperimental results show that the performance of \\pmpl is promising when we\ncompare it with the state-of-the-art MPL frameworks. Especially, in the LAN\nsetting, \\pmpl is around $16\\times$ and $5\\times$ faster than\n\\texttt{TF-encrypted} (with \\texttt{ABY3} as the back-end framework) for the\nlinear regression, and logistic regression, respectively. Besides, the accuracy\nof trained models of linear regression, logistic regression, and BP neural\nnetworks can reach around 97\\%, 99\\%, and 96\\% on MNIST dataset respectively.",
    "descriptor": "\nComments: This paper is the full version of a paper to appear in CCS 2022\n",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00486"
  },
  {
    "id": "arXiv:2210.00489",
    "title": "Unsupervised Multi-View Object Segmentation Using Radiance Field  Propagation",
    "abstract": "We present radiance field propagation (RFP), a novel approach to segmenting\nobjects in 3D during reconstruction given only unlabeled multi-view images of a\nscene. RFP is derived from emerging neural radiance field-based techniques,\nwhich jointly encodes semantics with appearance and geometry. The core of our\nmethod is a novel propagation strategy for individual objects' radiance fields\nwith a bidirectional photometric loss, enabling an unsupervised partitioning of\na scene into salient or meaningful regions corresponding to different object\ninstances. To better handle complex scenes with multiple objects and\nocclusions, we further propose an iterative expectation-maximization algorithm\nto refine object masks. To the best of our knowledge, RFP is the first\nunsupervised approach for tackling 3D scene object segmentation for neural\nradiance field (NeRF) without any supervision, annotations, or other cues such\nas 3D bounding boxes and prior knowledge of object class. Experiments\ndemonstrate that RFP achieves feasible segmentation results that are more\naccurate than previous unsupervised image/scene segmentation approaches, and\nare comparable to existing supervised NeRF-based methods. The segmented object\nrepresentations enable individual 3D object editing operations.",
    "descriptor": "\nComments: 23 pages, 14 figures, NeurIPS 2022\n",
    "authors": [
      "Xinhang Liu",
      "Jiaben Chen",
      "Huai Yu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00489"
  },
  {
    "id": "arXiv:2210.00490",
    "title": "Incentive Mechanism and Path Planning for UAV Hitching over Traffic  Networks",
    "abstract": "Package delivery via the UAVs is a promising transport mode to provide\nefficient and green logistic services, especially in urban areas or complicated\ntopography. However, the energy storage limit of the UAV makes it difficult to\nperform long-distance delivery tasks. In this paper, we propose a novel\nmultimodal logistics framework, in which the UAVs can call on ground vehicles\nto provide hitch services to save their own energy and extend their delivery\ndistance. This multimodal logistics framework is formulated as a two-stage\nmodel to jointly consider the incentive mechanism design for ground vehicles\nand path planning for UAVs. In Stage I, to deal with the motivations for ground\nvehicles to assist UAV delivery, a dynamic pricing scheme is proposed to best\nbalance the vehicle response time and payments to ground vehicles. It shows\nthat a higher price should be decided if the vehicle response time is long to\nencourage more vehicles to offer a ride. In Stage II, the task allocation and\npath planning of the UAVs over traffic network is studied based on the vehicle\nresponse time obtained in Stage I. To address pathfinding with restrictions and\nthe performance degradation of the pathfinding algorithm due to the rising\nnumber of conflicts in multi-agent pathfinding, we propose the suboptimal\nconflict avoidance-based path search (CABPS) algorithm, which has polynomial\ntime complexity. Finally, we validate our results via simulations. It is shown\nthat our approach is able to increase the success rate of UAV package delivery.\nMoreover, we estimate the delivery time of the UAV in a pessimistic case, it is\nstill twice as fast as the delivery time of the ground vehicle only.",
    "descriptor": "",
    "authors": [
      "Ziyi Lu",
      "Na Yu",
      "Xuehe Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00490"
  },
  {
    "id": "arXiv:2210.00495",
    "title": "On convergence of an unconditional stable numerical scheme for Q-tensor  flow based on invariant quardratization method",
    "abstract": "We present convergence analysis towards a numerical scheme designed for\nQ-tensor flows of nematic liquid crystals. This scheme is based on the\nInvariant Energy Quadratization method, which introduces an auxiliary variable\nto replace the original energy functional. In this work, we have shown that\ngiven an initial value with $H^2$ regularity, we can obtain a uniform $H^2$\nestimate on the numerical solutions for Q-tensor flows and then deduce the\nconvergence to a strong solution of the parabolic-type Q-tensor equation. We\nhave also shown that the limit of the auxiliary variable is equivalent to the\noriginal energy functional term in the strong sense.",
    "descriptor": "",
    "authors": [
      "Yukun Yue"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00495"
  },
  {
    "id": "arXiv:2210.00497",
    "title": "Approximate Computing and the Efficient Machine Learning Expedition",
    "abstract": "Approximate computing (AxC) has been long accepted as a design alternative\nfor efficient system implementation at the cost of relaxed accuracy\nrequirements. Despite the AxC research activities in various application\ndomains, AxC thrived the past decade when it was applied in Machine Learning\n(ML). The by definition approximate notion of ML models but also the increased\ncomputational overheads associated with ML applications-that were effectively\nmitigated by corresponding approximations-led to a perfect matching and a\nfruitful synergy. AxC for AI/ML has transcended beyond academic prototypes. In\nthis work, we enlighten the synergistic nature of AxC and ML and elucidate the\nimpact of AxC in designing efficient ML systems. To that end, we present an\noverview and taxonomy of AxC for ML and use two descriptive application\nscenarios to demonstrate how AxC boosts the efficiency of ML systems.",
    "descriptor": "\nComments: Accepted for publication at the International Conference on Computer-Aided Design (ICCAD) 2022\n",
    "authors": [
      "J\u00f6rg Henkel",
      "Hai Li",
      "Anand Raghunathan",
      "Mehdi B. Tahoori",
      "Swagath Venkataramani",
      "Xiaoxuan Yang",
      "Georgios Zervakis"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00497"
  },
  {
    "id": "arXiv:2210.00498",
    "title": "EUCLID: Towards Efficient Unsupervised Reinforcement Learning with  Multi-choice Dynamics Model",
    "abstract": "Unsupervised reinforcement learning (URL) poses a promising paradigm to learn\nuseful behaviors in a task-agnostic environment without the guidance of\nextrinsic rewards to facilitate the fast adaptation of various downstream\ntasks. Previous works focused on the pre-training in a model-free manner while\nlacking the study of transition dynamics modeling that leaves a large space for\nthe improvement of sample efficiency in downstream tasks. To this end, we\npropose an Efficient Unsupervised Reinforcement Learning Framework with\nMulti-choice Dynamics model (EUCLID), which introduces a novel model-fused\nparadigm to jointly pre-train the dynamics model and unsupervised exploration\npolicy in the pre-training phase, thus better leveraging the environmental\nsamples and improving the downstream task sampling efficiency. However,\nconstructing a generalizable model which captures the local dynamics under\ndifferent behaviors remains a challenging problem. We introduce the\nmulti-choice dynamics model that covers different local dynamics under\ndifferent behaviors concurrently, which uses different heads to learn the state\ntransition under different behaviors during unsupervised pre-training and\nselects the most appropriate head for prediction in the downstream task.\nExperimental results in the manipulation and locomotion domains demonstrate\nthat EUCLID achieves state-of-the-art performance with high sample efficiency,\nbasically solving the state-based URLB benchmark and reaching a mean normalized\nscore of 104.0$\\pm$1.2$\\%$ in downstream tasks with 100k fine-tuning steps,\nwhich is equivalent to DDPG's performance at 2M interactive steps with 20x more\ndata.",
    "descriptor": "\nComments: 10 pages, 8 figures; 6 pages appendix (2 additional figures)\n",
    "authors": [
      "Yifu Yuan",
      "Jianye Hao",
      "Fei Ni",
      "Yao Mu",
      "Yan Zheng",
      "Yujing Hu",
      "Jinyi Liu",
      "Yingfeng Chen",
      "Changjie Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00498"
  },
  {
    "id": "arXiv:2210.00500",
    "title": "Cognitive modelling with multilayer networks: Insights, advancements and  future challenges",
    "abstract": "The mental lexicon is a complex cognitive system representing information\nabout the words/concepts that one knows. Decades of psychological experiments\nhave shown that conceptual associations across multiple, interactive cognitive\nlevels can greatly influence word acquisition, storage, and processing. How can\nsemantic, phonological, syntactic, and other types of conceptual associations\nbe mapped within a coherent mathematical framework to study how the mental\nlexicon works? We here review cognitive multilayer networks as a promising\nquantitative and interpretative framework for investigating the mental lexicon.\nCognitive multilayer networks can map multiple types of information at once,\nthus capturing how different layers of associations might co-exist within the\nmental lexicon and influence cognitive processing. This review starts with a\ngentle introduction to the structure and formalism of multilayer networks. We\nthen discuss quantitative mechanisms of psychological phenomena that could not\nbe observed in single-layer networks and were only unveiled by combining\nmultiple layers of the lexicon: (i) multiplex viability highlights language\nkernels and facilitative effects of knowledge processing in healthy and\nclinical populations; (ii) multilayer community detection enables contextual\nmeaning reconstruction depending on psycholinguistic features; (iii) layer\nanalysis can mediate latent interactions of mediation, suppression and\nfacilitation for lexical access. By outlining novel quantitative perspectives\nwhere multilayer networks can shed light on cognitive knowledge\nrepresentations, also in next-generation brain/mind models, we discuss key\nlimitations and promising directions for cutting-edge future research.",
    "descriptor": "",
    "authors": [
      "Massimo Stella",
      "Salvatore Citraro",
      "Giulio Rossetti",
      "Daniele Marinazzo",
      "Yoed N. Kenett",
      "Michael S. Vitevitch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.00500"
  },
  {
    "id": "arXiv:2210.00502",
    "title": "Self-Tuning Tube-based Model Predictive Control",
    "abstract": "We present Self-Tuning Tube-based Model Predictive Control (STT-MPC), an\nadaptive robust control algorithm for uncertain linear systems with additive\ndisturbances based on the least-squares estimator and polytopic tubes. Our\nalgorithm leverages concentration results to bound the system uncertainty set\nwith prescribed confidence, and guarantees robust constraint satisfaction for\nthis set, along with recursive feasibility and input-to-state stability.\nPersistence of excitation is ensured without compromising the algorithm's\nasymptotic performance or increasing its computational complexity. We\ndemonstrate the performance of our algorithm using numerical experiments.",
    "descriptor": "",
    "authors": [
      "Damianos Tranos",
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00502"
  },
  {
    "id": "arXiv:2210.00503",
    "title": "DARE: A large-scale handwritten date recognition system",
    "abstract": "Handwritten text recognition for historical documents is an important task\nbut it remains difficult due to a lack of sufficient training data in\ncombination with a large variability of writing styles and degradation of\nhistorical documents. While recurrent neural network architectures are commonly\nused for handwritten text recognition, they are often computationally expensive\nto train and the benefit of recurrence drastically differs by task. For these\nreasons, it is important to consider non-recurrent architectures. In the\ncontext of handwritten date recognition, we propose an architecture based on\nthe EfficientNetV2 class of models that is fast to train, robust to parameter\nchoices, and accurately transcribes handwritten dates from a number of sources.\nFor training, we introduce a database containing almost 10 million tokens,\noriginating from more than 2.2 million handwritten dates which are segmented\nfrom different historical documents. As dates are some of the most common\ninformation on historical documents, and with historical archives containing\nmillions of such documents, the efficient and automatic transcription of dates\nhas the potential to lead to significant cost-savings over manual\ntranscription. We show that training on handwritten text with high variability\nin writing styles result in robust models for general handwritten text\nrecognition and that transfer learning from the DARE system increases\ntranscription accuracy substantially, allowing one to obtain high accuracy even\nwhen using a relatively small training sample.",
    "descriptor": "",
    "authors": [
      "Christian M. Dahl",
      "Torben S. D. Johansen",
      "Emil N. S\u00f8rensen",
      "Christian E. Westermann",
      "Simon F. Wittrock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00503"
  },
  {
    "id": "arXiv:2210.00507",
    "title": "Fast and Robust Video-Based Exercise Classification via Body Pose  Tracking and Scalable Multivariate Time Series Classifiers",
    "abstract": "Technological advancements have spurred the usage of machine learning based\napplications in sports science. Physiotherapists, sports coaches and athletes\nactively look to incorporate the latest technologies in order to further\nimprove performance and avoid injuries. While wearable sensors are very\npopular, their use is hindered by constraints on battery power and sensor\ncalibration, especially for use cases which require multiple sensors to be\nplaced on the body. Hence, there is renewed interest in video-based data\ncapture and analysis for sports science. In this paper, we present the\napplication of classifying S\\&C exercises using video. We focus on the popular\nMilitary Press exercise, where the execution is captured with a video-camera\nusing a mobile device, such as a mobile phone, and the goal is to classify the\nexecution into different types. Since video recordings need a lot of storage\nand computation, this use case requires data reduction, while preserving the\nclassification accuracy and enabling fast prediction. To this end, we propose\nan approach named BodyMTS to turn video into time series by employing body pose\ntracking, followed by training and prediction using multivariate time series\nclassifiers. We analyze the accuracy and robustness of BodyMTS and show that it\nis robust to different types of noise caused by either video quality or pose\nestimation factors. We compare BodyMTS to state-of-the-art deep learning\nmethods which classify human activity directly from videos and show that\nBodyMTS achieves similar accuracy, but with reduced running time and model\nengineering effort. Finally, we discuss some of the practical aspects of\nemploying BodyMTS in this application in terms of accuracy and robustness under\nreduced data quality and size. We show that BodyMTS achieves an average\naccuracy of 87\\%, which is significantly higher than the accuracy of human\ndomain experts.",
    "descriptor": "",
    "authors": [
      "Ashish Singh",
      "Antonio Bevilacqua",
      "Thach Le Nguyen",
      "Feiyan Hu",
      "Kevin McGuinness",
      "Martin OReilly",
      "Darragh Whelan",
      "Brian Caulfield",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00507"
  },
  {
    "id": "arXiv:2210.00513",
    "title": "Gradient Gating for Deep Multi-Rate Learning on Graphs",
    "abstract": "We present Gradient Gating (G$^2$), a novel framework for improving the\nperformance of Graph Neural Networks (GNNs). Our framework is based on gating\nthe output of GNN layers with a mechanism for multi-rate flow of message\npassing information across nodes of the underlying graph. Local gradients are\nharnessed to further modulate message passing updates. Our framework flexibly\nallows one to use any basic GNN layer as a wrapper around which the multi-rate\ngradient gating mechanism is built. We rigorously prove that G$^2$ alleviates\nthe oversmoothing problem and allows the design of deep GNNs. Empirical results\nare presented to demonstrate that the proposed framework achieves\nstate-of-the-art performance on a variety of graph learning tasks, including on\nlarge-scale heterophilic graphs.",
    "descriptor": "",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "Michael W. Mahoney",
      "Michael M. Bronstein",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00513"
  },
  {
    "id": "arXiv:2210.00518",
    "title": "High Precision Differentiation Techniques for Data-Driven Solution of  Nonlinear PDEs by Physics-Informed Neural Networks",
    "abstract": "Time-dependent Partial Differential Equations with given initial conditions\nare considered in this paper. New differentiation techniques of the unknown\nsolution with respect to time variable are proposed. It is shown that the\nproposed techniques allow to generate accurate higher order derivatives\nsimultaneously for a set of spatial points. The calculated derivatives can then\nbe used for data-driven solution in different ways. An application for Physics\nInformed Neural Networks by the well-known DeepXDE software solution in Python\nunder Tensorflow background framework has been presented for three real-life\nPDEs: Burgers', Allen-Cahn and Schrodinger equations.",
    "descriptor": "\nComments: 23 pages, 4 figures, 2 tables\n",
    "authors": [
      "Marat S. Mukhametzhanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00518"
  },
  {
    "id": "arXiv:2210.00519",
    "title": "Exploiting More Information in Sparse Point Cloud for 3D Single Object  Tracking",
    "abstract": "3D single object tracking is a key task in 3D computer vision. However, the\nsparsity of point clouds makes it difficult to compute the similarity and\nlocate the object, posing big challenges to the 3D tracker. Previous works\ntried to solve the problem and improved the tracking performance in some common\nscenarios, but they usually failed in some extreme sparse scenarios, such as\nfor tracking objects at long distances or partially occluded. To address the\nabove problems, in this letter, we propose a sparse-to-dense and\ntransformer-based framework for 3D single object tracking. First, we transform\nthe 3D sparse points into 3D pillars and then compress them into 2D BEV\nfeatures to have a dense representation. Then, we propose an attention-based\nencoder to achieve global similarity computation between template and search\nbranches, which could alleviate the influence of sparsity. Meanwhile, the\nencoder applies the attention on multi-scale features to compensate for the\nlack of information caused by the sparsity of point cloud and the single scale\nof features. Finally, we use set-prediction to track the object through a\ntwo-stage decoder which also utilizes attention. Extensive experiments show\nthat our method achieves very promising results on the KITTI and NuScenes\ndatasets.",
    "descriptor": "\nComments: Accepted for publication at IEEE Robotics and Automation Letters (RAL)\n",
    "authors": [
      "Yubo Cui",
      "Jiayao Shan",
      "Zuoxu Gu",
      "Zhiheng Li",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00519"
  },
  {
    "id": "arXiv:2210.00521",
    "title": "Leveraging unsupervised data and domain adaptation for deep regression  in low-cost sensor calibration",
    "abstract": "Air quality monitoring is becoming an essential task with rising awareness\nabout air quality. Low cost air quality sensors are easy to deploy but are not\nas reliable as the costly and bulky reference monitors. The low quality sensors\ncan be calibrated against the reference monitors with the help of deep\nlearning. In this paper, we translate the task of sensor calibration into a\nsemi-supervised domain adaptation problem and propose a novel solution for the\nsame. The problem is challenging because it is a regression problem with\ncovariate shift and label gap. We use histogram loss instead of mean squared or\nmean absolute error, which is commonly used for regression, and find it useful\nagainst covariate shift. To handle the label gap, we propose weighting of\nsamples for adversarial entropy optimization. In experimental evaluations, the\nproposed scheme outperforms many competitive baselines, which are based on\nsemi-supervised and supervised domain adaptation, in terms of R2 score and mean\nabsolute error. Ablation studies show the relevance of each proposed component\nin the entire scheme.",
    "descriptor": "\nComments: submitted to IEEE Trans. on Neural Networks and Learning Systems as a regular article\n",
    "authors": [
      "Swapnil Dey",
      "Vipul Arora",
      "Sachchida Nand Tripathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00521"
  },
  {
    "id": "arXiv:2210.00527",
    "title": "Comparison of Data Representations and Machine Learning Architectures  for User Identification on Arbitrary Motion Sequences",
    "abstract": "Reliable and robust user identification and authentication are important and\noften necessary requirements for many digital services. It becomes paramount in\nsocial virtual reality (VR) to ensure trust, specifically in digital encounters\nwith lifelike realistic-looking avatars as faithful replications of real\npersons. Recent research has shown great interest in providing new solutions\nthat verify the identity of extended reality (XR) systems. This paper compares\ndifferent machine learning approaches to identify users based on arbitrary\nsequences of head and hand movements, a data stream provided by the majority of\ntoday's XR systems. We compare three different potential representations of the\nmotion data from heads and hands (scene-relative, body-relative, and\nbody-relative velocities), and by comparing the performances of five different\nmachine learning architectures (random forest, multilayer perceptron, fully\nrecurrent neural network, long-short term memory, gated recurrent unit). We use\nthe publicly available dataset \"Talking with Hands\" and publish all our code to\nallow reproducibility and to provide baselines for future work. After\nhyperparameter optimization, the combination of a long-short term memory\narchitecture and body-relative data outperformed competing combinations: the\nmodel correctly identifies any of the 34 subjects with an accuracy of 100\\%\nwithin 150 seconds. The code for models, training and evaluation is made\npublicly available. Altogether, our approach provides an effective foundation\nfor behaviometric-based identification and authentication to guide researchers\nand practitioners.",
    "descriptor": "\nComments: manuscript submitted for publication\n",
    "authors": [
      "Christian Schell",
      "Andreas Hotho",
      "Marc Erich Latoschik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00527"
  },
  {
    "id": "arXiv:2210.00533",
    "title": "Strategic Communication via Cascade Multiple Description Network",
    "abstract": "In decentralized decision-making problems, agents choose their actions based\non locally available information and knowledge about decision rules or\nstrategies of other agents. We consider a three-node cascade network with an\nencoder, a relay and a decoder, having distinct objectives captured by cost\nfunctions. In such a cascade network, agents choose their respective strategies\nsequentially, as a response to the former agent's strategy and in a way to\ninfluence the decision of the latter agent in the network. We assume the\nencoder commits to a strategy before the communication takes place. Upon\nrevelation of the encoding strategy, the relay commits to a strategy and\nreveals it. The communication starts, the source sequence is drawn and\nprocessed by the encoder and relay. Then, the decoder observes a sequences of\nsymbols, updates its Bayesian posterior beliefs accordingly, and takes the\noptimal action. This is an extension of the Bayesian persuasion problem in the\nGame Theory literature. In this work, we provide an information-theoretic\napproach to study the fundamental limit of the strategic communication via\nthree-node cascade network. Our goal is to characterize the optimal strategies\nof the encoder, the relay and the decoder, and study the asymptotic behavior of\nthe encoder's minimal long-run cost function.",
    "descriptor": "",
    "authors": [
      "Rony Bou Rouphael",
      "Ma\u00ebl Le trust"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00533"
  },
  {
    "id": "arXiv:2210.00538",
    "title": "Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation",
    "abstract": "Social networks are considered to be heterogeneous graph neural networks\n(HGNNs) with deep learning technological advances. HGNNs, compared to\nhomogeneous data, absorb various aspects of information about individuals in\nthe training stage. That means more information has been covered in the\nlearning result, especially sensitive information. However, the\nprivacy-preserving methods on homogeneous graphs only preserve the same type of\nnode attributes or relationships, which cannot effectively work on\nheterogeneous graphs due to the complexity. To address this issue, we propose a\nnovel heterogeneous graph neural network privacy-preserving method based on a\ndifferential privacy mechanism named HeteDP, which provides a double guarantee\non graph features and topology. In particular, we first define a new attack\nscheme to reveal privacy leakage in the heterogeneous graphs. Specifically, we\ndesign a two-stage pipeline framework, which includes the privacy-preserving\nfeature encoder and the heterogeneous link reconstructor with gradients\nperturbation based on differential privacy to tolerate data diversity and\nagainst the attack. To better control the noise and promote model performance,\nwe utilize a bi-level optimization pattern to allocate a suitable privacy\nbudget for the above two modules. Our experiments on four public benchmarks\nshow that the HeteDP method is equipped to resist heterogeneous graph privacy\nleakage with admirable model generalization.",
    "descriptor": "",
    "authors": [
      "Yuecen Wei",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Jia Wu",
      "Jinyan Wang",
      "Xianxian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00538"
  },
  {
    "id": "arXiv:2210.00541",
    "title": "Semi-autonomous Prosthesis Control Using Minimal Depth Information and  Vibrotactile Feedback",
    "abstract": "A semi-autonomous prosthesis control based on computer vision can be used to\nimprove performance while decreasing the cognitive burden, especially when\nusing advanced systems with multiple functions. However, a drawback of this\napproach is that it relies on the complex processing of a significant amount of\ndata (e.g., a point cloud provided by a depth sensor), which can be a challenge\nwhen deploying such a system onto an embedded prosthesis controller. In the\npresent study, therefore, we propose a novel method to reconstruct the shape of\nthe target object using minimal data. Specifically, four concurrent laser\nscanner lines provide partial contours of the object cross-section. Simple\ngeometry is then used to reconstruct the dimensions and orientation of\nspherical, cylindrical and cuboid objects. The prototype system was implemented\nusing depth sensor to simulate the scan lines and vibrotactile feedback to aid\nthe user during aiming of the laser towards the target object. The prototype\nwas tested on ten able-bodied volunteers who used the semi-autonomous\nprosthesis to grasp a set of ten objects of different shape, size and\norientation. The novel prototype was compared against the benchmark system,\nwhich used the full depth data. The results showed that novel system could be\nused to successfully handle all the objects, and that the performance improved\nwith training, although it was still somewhat worse compared to the benchmark.\nThe present study is therefore an important step towards building a compact\nsystem for embedded depth sensing specialized for prosthesis grasping.",
    "descriptor": "",
    "authors": [
      "Miguel Nobre Castro",
      "Strahinja Dosen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00541"
  },
  {
    "id": "arXiv:2210.00543",
    "title": "Fine-grained Contrastive Learning for Definition Generation",
    "abstract": "Recently, pre-trained transformer-based models have achieved great success in\nthe task of definition generation (DG). However, previous encoder-decoder\nmodels lack effective representation learning to contain full semantic\ncomponents of the given word, which leads to generating under-specific\ndefinitions. To address this problem, we propose a novel contrastive learning\nmethod, encouraging the model to capture more detailed semantic representations\nfrom the definition sequence encoding. According to both automatic and manual\nevaluation, the experimental results on three mainstream benchmarks demonstrate\nthat the proposed method could generate more specific and high-quality\ndefinitions compared with several state-of-the-art models.",
    "descriptor": "\nComments: Accepted by AACL-IJCNLP Main Conference 2022\n",
    "authors": [
      "Hengyuan Zhang",
      "Dawei Li",
      "Shiping Yang",
      "Yanran Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00543"
  },
  {
    "id": "arXiv:2210.00545",
    "title": "Seeing Through The Noisy Dark: Toward Real-world Low-Light Image  Enhancement and Denoising",
    "abstract": "Images collected in real-world low-light environment usually suffer from\nlower visibility and heavier noise, due to the insufficient light or hardware\nlimitation. While existing low-light image enhancement (LLIE) methods basically\nignored the noise interference and mainly focus on refining the illumination of\nthe low-light images based on benchmarked noise-negligible datasets. Such\noperations will make them inept for the real-world LLIE (RLLIE) with heavy\nnoise, and result in speckle noise and blur in the enhanced images. Although\nseveral LLIE methods considered the noise in low-light image, they are trained\non the raw data and hence cannot be used for sRGB images, since the domains of\ndata are different and lack of expertise or unknown protocols. In this paper,\nwe clearly consider the task of seeing through the noisy dark in sRGB color\nspace, and propose a novel end-to-end method termed Real-world Low-light\nEnhancement & Denoising Network (RLED-Net). Since natural images can usually be\ncharacterized by low-rank subspaces in which the redundant information and\nnoise can be removed, we design a Latent Subspace Reconstruction Block (LSRB)\nfor feature extraction and denoising. To reduce the loss of global feature\n(e.g., color/shape information) and extract more accurate local features (e.g.,\nedge/texture information), we also present a basic layer with two branches,\ncalled Cross-channel & Shift-window Transformer (CST). Based on the CST, we\nfurther present a new backbone to design a U-structure Network (CSTNet) for\ndeep feature recovery, and also design a Feature Refine Block (FRB) to refine\nthe final features. Extensive experiments on real noisy images and public\ndatabases verified the effectiveness of our RLED-Net for both RLLIE and\ndenoising.",
    "descriptor": "",
    "authors": [
      "Jiahuan Ren",
      "Zhao Zhang",
      "Richang Hong",
      "Mingliang Xu",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00545"
  },
  {
    "id": "arXiv:2210.00546",
    "title": "Siamese-NAS: Using Trained Samples Efficiently to Find Lightweight  Neural Architecture by Prior Knowledge",
    "abstract": "In the past decade, many architectures of convolution neural networks were\ndesigned by handcraft, such as Vgg16, ResNet, DenseNet, etc. They all achieve\nstate-of-the-art level on different tasks in their time. However, it still\nrelies on human intuition and experience, and it also takes so much time\nconsumption for trial and error. Neural Architecture Search (NAS) focused on\nthis issue. In recent works, the Neural Predictor has significantly improved\nwith few training architectures as training samples. However, the sampling\nefficiency is already considerable. In this paper, our proposed\nSiamese-Predictor is inspired by past works of predictor-based NAS. It is\nconstructed with the proposed Estimation Code, which is the prior knowledge\nabout the training procedure. The proposed Siamese-Predictor gets significant\nbenefits from this idea. This idea causes it to surpass the current SOTA\npredictor on NASBench-201. In order to explore the impact of the Estimation\nCode, we analyze the relationship between it and accuracy. We also propose the\nsearch space Tiny-NanoBench for lightweight CNN architecture. This\nwell-designed search space is easier to find better architecture with few FLOPs\nthan NASBench-201. In summary, the proposed Siamese-Predictor is a\npredictor-based NAS. It achieves the SOTA level, especially with limited\ncomputation budgets. It applied to the proposed Tiny-NanoBench can just use a\nfew trained samples to find extremely lightweight CNN architecture.",
    "descriptor": "",
    "authors": [
      "Yu-Ming Zhang",
      "Jun-Wei Hsieh",
      "Chun-Chieh Lee",
      "Kuo-Chin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00546"
  },
  {
    "id": "arXiv:2210.00549",
    "title": "Error estimates of Kaczmarz and randomized Kaczmarz methods",
    "abstract": "The Kaczmarz method is an iterative projection scheme for solving con-sistent\nsystem $Ax = b$. It is later extended to the inconsistent and ill-posed linear\nproblems. But the classical Kaczmarz method is sensitive to the correlation of\nthe adjacent equations. In order to reduce the impact of correlation on the\nconvergence rate, the randomized Kaczmarz method and randomized block Kaczmarz\nmethod are proposed, respectively. In the current literature, the error\nestimate results of these methods are established based on the error\n$\\|x_k-x_*\\|_2$, where $x_*$ is the solution of linear system $Ax=b$. In this\npaper, we extend the present error estimates of the Kaczmarz and randomized\nKaczmarz methods on the basis of the convergence theorem of Kunio Tanabe, and\nobtain some general results about the error $\\|x_k-P_{N(A)}x_0-x^\\dagger\\|_2$.",
    "descriptor": "",
    "authors": [
      "Chuan-gang Kang",
      "Heng Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00549"
  },
  {
    "id": "arXiv:2210.00552",
    "title": "Occlusion-Aware Crowd Navigation Using People as Sensors",
    "abstract": "Autonomous navigation in crowded spaces poses a challenge for mobile robots\ndue to the highly dynamic, partially observable environment. Occlusions are\nhighly prevalent in such settings due to a limited sensor field of view and\nobstructing human agents. Previous work has shown that observed interactive\nbehaviors of human agents can be used to estimate potential obstacles despite\nocclusions. We propose integrating such social inference techniques into the\nplanning pipeline. We use a variational autoencoder with a specially designed\nloss function to learn representations that are meaningful for occlusion\ninference. This work adopts a deep reinforcement learning approach to\nincorporate the learned representation for occlusion-aware planning. In\nsimulation, our occlusion-aware policy achieves comparable collision avoidance\nperformance to fully observable navigation by estimating agents in occluded\nspaces. We demonstrate successful policy transfer from simulation to the\nreal-world Turtlebot 2i. To the best of our knowledge, this work is the first\nto use social occlusion inference for crowd navigation.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Ye-Ji Mun",
      "Masha Itkina",
      "Shuijing Liu",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00552"
  },
  {
    "id": "arXiv:2210.00553",
    "title": "ALT: A software for readability analysis of Portuguese-language texts",
    "abstract": "In the initial stage of human life, communication, seen as a process of\nsocial interaction, was always the best way to reach consensus between the\nparties. Understanding and credibility in this process are essential for the\nmutual agreement to be validated. But, how to do it so that this communication\nreaches the great mass? This is the main challenge when what is sought is the\ndissemination of information and its approval. In this context, this study\npresents the ALT software, developed from original readability metrics adapted\nto the Portuguese language, available on the web, to reduce communication\ndifficulties. The development of the software was motivated by the theory of\ncommunicative action of Habermas, which uses a multidisciplinary style to\nmeasure the credibility of the discourse in the communication channels used to\nbuild and maintain a safe and healthy relationship with the public.",
    "descriptor": "\nComments: 21 pages, 13 figures, see software in this https URL\n",
    "authors": [
      "Gleice Carvalho de Lima Moreno",
      "Marco P. M. de Souza",
      "Nelson Hein",
      "Adriana Kroenke Hein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00553"
  },
  {
    "id": "arXiv:2210.00557",
    "title": "Adaptive Smoothness-weighted Adversarial Training for Multiple  Perturbations with Its Stability Analysis",
    "abstract": "Adversarial Training (AT) has been demonstrated as one of the most effective\nmethods against adversarial examples. While most existing works focus on AT\nwith a single type of perturbation e.g., the $\\ell_\\infty$ attacks), DNNs are\nfacing threats from different types of adversarial examples. Therefore,\nadversarial training for multiple perturbations (ATMP) is proposed to\ngeneralize the adversarial robustness over different perturbation types (in\n$\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ norm-bounded perturbations). However, the\nresulting model exhibits trade-off between different attacks. Meanwhile, there\nis no theoretical analysis of ATMP, limiting its further development. In this\npaper, we first provide the smoothness analysis of ATMP and show that $\\ell_1$,\n$\\ell_2$, and $\\ell_\\infty$ adversaries give different contributions to the\nsmoothness of the loss function of ATMP. Based on this, we develop the\nstability-based excess risk bounds and propose adaptive smoothness-weighted\nadversarial training for multiple perturbations. Theoretically, our algorithm\nyields better bounds. Empirically, our experiments on CIFAR10 and CIFAR100\nachieve the state-of-the-art performance against the mixture of multiple\nperturbations attacks.",
    "descriptor": "",
    "authors": [
      "Jiancong Xiao",
      "Zeyu Qin",
      "Yanbo Fan",
      "Baoyuan Wu",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00557"
  },
  {
    "id": "arXiv:2210.00562",
    "title": "RISC-V Toolchain and Agile Development based Open-source Neuromorphic  Processor",
    "abstract": "In recent decades, neuromorphic computing aiming to imitate brains' behaviors\nhas been developed in various fields of computer science. The Artificial Neural\nNetwork (ANN) is an important concept in Artificial Intelligence (AI). It is\nutilized in recognition and classification. To explore a better way to simulate\nobtained brain behaviors, which is fast and energy-efficient, on hardware,\nresearchers need an advanced method such as neuromorphic computing. In this\ncase, Spiking Neural Network (SNN) becomes an optimal choice in hardware\nimplementation. Recent works are focusing on accelerating SNN computing.\nHowever, most accelerator solutions are based on CPU-accelerator architecture\nwhich is energy-inefficient due to the complex control flows in this structure.\nThis paper proposes Wenquxing 22A, a low-power neuromorphic processor that\ncombines general-purpose CPU functions and SNN to efficiently compute it with\nRISC-V SNN extension instructions. The main idea of Wenquxing 22A is to\nintegrate the SNN calculation unit into the pipeline of a general-purpose CPU\nto achieve low-power computing with customized RISC-V SNN instructions version\n1.0 (RV-SNN V1.0), Streamlined Leaky Integrate-and-Fire (LIF) model, and the\nbinary stochastic Spike-timing-dependent-plasticity (STDP). The source code of\nWenquxing 22A is released online on Gitee and GitHub. We apply Wenquxing 22A to\nthe recognition of the MNIST dataset to make a comparison with other SNN\nsystems. Our experiment results show that Wenquxing 22A improves the energy\nexpenses by 5.13 times over the accelerator solution, ODIN, with approximately\nclassification accuracy, 85.00% for 3-bit ODIN online learning, and 91.91% for\n1-bit Wenquxing 22A.",
    "descriptor": "\nComments: 6 pages, 5 figures, conference or other essential info\n",
    "authors": [
      "Jiulong Wang",
      "Ruopu Wu",
      "Guokai Chen",
      "Xuhao Chen",
      "Zhijie Jia",
      "Boran Liu",
      "Jixiang Zong",
      "Di Zhao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00562"
  },
  {
    "id": "arXiv:2210.00563",
    "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social  Science",
    "abstract": "In social science, formal and quantitative models, such as ones describing\neconomic growth and collective action, are used to formulate mechanistic\nexplanations, provide predictions, and uncover questions about observed\nphenomena. Here, we demonstrate the use of a machine learning system to aid the\ndiscovery of symbolic models that capture nonlinear and dynamical relationships\nin social science datasets. By extending neuro-symbolic methods to find compact\nfunctions and differential equations in noisy and longitudinal data, we show\nthat our system can be used to discover interpretable models from real-world\ndata in economics and sociology. Augmenting existing workflows with symbolic\nregression can help uncover novel relationships and explore counterfactual\nmodels during the scientific process. We propose that this AI-assisted\nframework can bridge parametric and non-parametric models commonly employed in\nsocial science research by systematically exploring the space of nonlinear\nmodels and enabling fine-grained control over expressivity and\ninterpretability.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Julia Balla",
      "Sihao Huang",
      "Owen Dugan",
      "Rumen Dangovski",
      "Marin Soljacic"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2210.00563"
  },
  {
    "id": "arXiv:2210.00567",
    "title": "Two teams of oblivious asynchronous robots performing different tasks on  an infinite grid without the knowledge of its team members",
    "abstract": "Two fundamental problems of distributed computing are Gathering and Arbitrary\npattern formation (\\textsc{Apf}). These two tasks are different in nature as in\ngathering robots meet at a point but in \\textsc{Apf} robots form a fixed\npattern in distinct positions.\nIn most of the current literature on swarm robot algorithms, it is assumed\nthat all robots in the system perform one single task together. Two teams of\noblivious robots deployed in the same system and different teams of robots\nperforming two different works simultaneously where no robot knows the team of\nanother robot is a new concept in the literature introduced by Bhagat et al.\n[ICDCN'2020].\nIn this work, a swarm of silent and oblivious robots are deployed on an\ninfinite grid under an asynchronous scheduler. The robots do not have access to\nany global coordinates. Some of the robots are given input of an arbitrary but\nunique pattern. The set of robots with the given pattern is assigned with the\ntask of forming the given pattern on the grid. The remaining robots are\nassigned with the task of gathering to a vertex of the grid (not fixed from\nearlier and not any point where a robot that is forming a pattern terminates).\nEach robot knows to which team it belongs, but can not recognize the team of\nanother robot. Considering weak multiplicity detection, a distributed algorithm\nis presented in this paper which leads the robots with the input pattern into\nforming it and other robots into gathering on a vertex of the grid on which no\nother robot forming the pattern, terminates.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.13870\n",
    "authors": [
      "Satakshi Ghosh",
      "Avisek Sharma",
      "Pritam Goswami",
      "Buddhadeb Sau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00567"
  },
  {
    "id": "arXiv:2210.00571",
    "title": "Beyond the Theory of the Reals",
    "abstract": "We show that completeness at higher levels of the theory of the reals is a\nrobust notion (under changing the signature and bounding the domain of the\nquantifiers). This mends recognized gaps in the hierarchy, and leads to\nstronger completeness results for various computational problems. We exhibit\nseveral families of complete problems which can be used for future completeness\nresults in the real hierarchy. As an application we answer an open question by\nJungeblut, Kleist, and Miltzow on the complexity of two semialgebraic sets\nhaving Hausdorff distance $0$, and sharpen some results by Burgisser and\nCucker.",
    "descriptor": "",
    "authors": [
      "Marcus Schaefer",
      "Daniel Stefankovic"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.00571"
  },
  {
    "id": "arXiv:2210.00572",
    "title": "Risk-graded Safety for Handling Medical Queries in Conversational AI",
    "abstract": "Conversational AI systems can engage in unsafe behaviour when handling users'\nmedical queries that can have severe consequences and could even lead to\ndeaths. Systems therefore need to be capable of both recognising the\nseriousness of medical inputs and producing responses with appropriate levels\nof risk. We create a corpus of human written English language medical queries\nand the responses of different types of systems. We label these with both\ncrowdsourced and expert annotations. While individual crowdworkers may be\nunreliable at grading the seriousness of the prompts, their aggregated labels\ntend to agree with professional opinion to a greater extent on identifying the\nmedical queries and recognising the risk types posed by the responses. Results\nof classification experiments suggest that, while these tasks can be automated,\ncaution should be exercised, as errors can potentially be very serious.",
    "descriptor": "\nComments: Accepted for publication at AACL 2022\n",
    "authors": [
      "Gavin Abercrombie",
      "Verena Rieser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00572"
  },
  {
    "id": "arXiv:2210.00573",
    "title": "Natural Gradient Ascent in Evolutionary Games",
    "abstract": "We study evolutionary games with a continuous trait space in which replicator\ndynamics are restricted to the manifold of multidimensional Gaussian\ndistributions. We demonstrate that the replicator equations are natural\ngradient flow for maximization of the mean fitness.\nOur findings extend previous results on information-geometric aspects of\nevolutionary games with a finite strategy set.\nThroughout the paper we exploit the information-geometric approach and the\nrelation between evolutionary dynamics and Natural Evolution Strategies, the\nconcept that has been developed within the framework of black-box optimization.\nThis relation sheds a new light on the replicator dynamics as a compromise\nbetween maximization of the mean fitness and preservation of diversity in the\npopulation.",
    "descriptor": "",
    "authors": [
      "Vladimir Ja\u0107imovi\u0107"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00573"
  },
  {
    "id": "arXiv:2210.00577",
    "title": "Deep Invertible Approximation of Topologically Rich Maps between  Manifolds",
    "abstract": "How can we design neural networks that allow for stable universal\napproximation of maps between topologically interesting manifolds? The answer\nis with a coordinate projection. Neural networks based on topological data\nanalysis (TDA) use tools such as persistent homology to learn topological\nsignatures of data and stabilize training but may not be universal\napproximators or have stable inverses. Other architectures universally\napproximate data distributions on submanifolds but only when the latter are\ngiven by a single chart, making them unable to learn maps that change topology.\nBy exploiting the topological parallels between locally bilipschitz maps,\ncovering spaces, and local homeomorphisms, and by using universal approximation\narguments from machine learning, we find that a novel network of the form\n$\\mathcal{T} \\circ p \\circ \\mathcal{E}$, where $\\mathcal{E}$ is an injective\nnetwork, $p$ a fixed coordinate projection, and $\\mathcal{T}$ a bijective\nnetwork, is a universal approximator of local diffeomorphisms between compact\nsmooth submanifolds embedded in $\\mathbb{R}^n$. We emphasize the case when the\ntarget map changes topology. Further, we find that by constraining the\nprojection $p$, multivalued inversions of our networks can be computed without\nsacrificing universality. As an application, we show that learning a group\ninvariant function with unknown group action naturally reduces to the question\nof learning local diffeomorphisms for finite groups. Our theory permits us to\nrecover orbits of the group action. We also outline possible extensions of our\narchitecture to address molecular imaging of molecules with symmetries.\nFinally, our analysis informs the choice of topologically expressive starting\nspaces in generative problems.",
    "descriptor": "",
    "authors": [
      "Michael Puthawala",
      "Matti Lassas",
      "Ivan Dokmanic",
      "Pekka Pankka",
      "Maarten de Hoop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2210.00577"
  },
  {
    "id": "arXiv:2210.00578",
    "title": "An optimal open-loop strategy for handling a flexible beam with a robot  manipulator",
    "abstract": "Fast and safe manipulation of flexible objects with a robot manipulator\nnecessitates measures to cope with vibrations. Existing approaches either\nincrease the task execution time or require complex models and/or additional\ninstrumentation to measure vibrations. This paper develops a model-based method\nthat overcomes these limitations. It relies on a simple pendulum-like model for\nmodeling the beam, open-loop optimal control for suppressing vibrations, and\ndoes not require any exteroceptive sensors. We experimentally show that the\nproposed method drastically reduces residual vibrations -- at least 90% -- and\noutperforms the commonly used input shaping (IS) for the same execution time.\nBesides, our method can also execute the task faster than IS with a minor\nreduction in vibration suppression performance. The proposed method facilitates\nthe development of new solutions to a wide range of tasks that involve dynamic\nmanipulation of flexible objects.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Shamil Mamedov",
      "Alejandro Astudillo",
      "Daniele Ronzani",
      "Wilm Decr\u00e9",
      "Jean-Philippe No\u00ebl",
      "Jan Swevers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00578"
  },
  {
    "id": "arXiv:2210.00580",
    "title": "GFlowNets and variational inference",
    "abstract": "This paper builds bridges between two families of probabilistic algorithms:\n(hierarchical) variational inference (VI), which is typically used to model\ndistributions over continuous spaces, and generative flow networks (GFlowNets),\nwhich have been used for distributions over discrete structures such as graphs.\nWe demonstrate that, in certain cases, VI algorithms are equivalent to special\ncases of GFlowNets in the sense of equality of expected gradients of their\nlearning objectives. We then point out the differences between the two families\nand show how these differences emerge experimentally. Notably, GFlowNets, which\nborrow ideas from reinforcement learning, are more amenable than VI to\noff-policy training without the cost of high gradient variance induced by\nimportance sampling. We argue that this property of GFlowNets can provide\nadvantages for capturing diversity in multimodal target distributions.",
    "descriptor": "",
    "authors": [
      "Nikolay Malkin",
      "Salem Lahlou",
      "Tristan Deleu",
      "Xu Ji",
      "Edward Hu",
      "Katie Everett",
      "Dinghuai Zhang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00580"
  },
  {
    "id": "arXiv:2210.00581",
    "title": "PrivTrace: Differentially Private Trajectory Synthesis by Adaptive  Markov Model",
    "abstract": "Publishing trajectory data (individual's movement information) is very\nuseful, but it also raises privacy concerns. To handle the privacy concern, in\nthis paper, we apply differential privacy, the standard technique for data\nprivacy, together with Markov chain model, to generate synthetic trajectories.\nWe notice that existing studies all use Markov chain model and thus propose a\nframework to analyze the usage of the Markov chain model in this problem. Based\non the analysis, we come up with an effective algorithm PrivTrace that uses the\nfirst-order and second-order Markov model adaptively. We evaluate PrivTrace and\nexisting methods on synthetic and real-world datasets to demonstrate the\nsuperiority of our method.",
    "descriptor": "\nComments: To Appear in 2023 USENIX Security Symposium, August 9-11, 2023. Please cite our USENIX Security version\n",
    "authors": [
      "Haiming Wang",
      "Zhikun Zhang",
      "Tianhao Wang",
      "Shibo He",
      "Michael Backes",
      "Jiming Chen",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00581"
  },
  {
    "id": "arXiv:2210.00583",
    "title": "The Dynamic of Consensus in Deep Networks and the Identification of  Noisy Labels",
    "abstract": "Deep neural networks have incredible capacity and expressibility, and can\nseemingly memorize any training set. This introduces a problem when training in\nthe presence of noisy labels, as the noisy examples cannot be distinguished\nfrom clean examples by the end of training. Recent research has dealt with this\nchallenge by utilizing the fact that deep networks seem to memorize clean\nexamples much earlier than noisy examples. Here we report a new empirical\nresult: for each example, when looking at the time it has been memorized by\neach model in an ensemble of networks, the diversity seen in noisy examples is\nmuch larger than the clean examples. We use this observation to develop a new\nmethod for noisy labels filtration. The method is based on a statistics of the\ndata, which captures the differences in ensemble learning dynamics between\nclean and noisy data. We test our method on three tasks: (i) noise amount\nestimation; (ii) noise filtration; (iii) supervised classification. We show\nthat our method improves over existing baselines in all three tasks using a\nvariety of datasets, noise models, and noise levels. Aside from its improved\nperformance, our method has two other advantages. (i) Simplicity, which implies\nthat no additional hyperparameters are introduced. (ii) Our method is modular:\nit does not work in an end-to-end fashion, and can therefore be used to clean a\ndataset for any other future usage.",
    "descriptor": "",
    "authors": [
      "Daniel Shwartz",
      "Uri Stern",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00583"
  },
  {
    "id": "arXiv:2210.00584",
    "title": "FLCert: Provably Secure Federated Learning against Poisoning Attacks",
    "abstract": "Due to its distributed nature, federated learning is vulnerable to poisoning\nattacks, in which malicious clients poison the training process via\nmanipulating their local training data and/or local model updates sent to the\ncloud server, such that the poisoned global model misclassifies many\nindiscriminate test inputs or attacker-chosen ones. Existing defenses mainly\nleverage Byzantine-robust federated learning methods or detect malicious\nclients. However, these defenses do not have provable security guarantees\nagainst poisoning attacks and may be vulnerable to more advanced attacks. In\nthis work, we aim to bridge the gap by proposing FLCert, an ensemble federated\nlearning framework, that is provably secure against poisoning attacks with a\nbounded number of malicious clients. Our key idea is to divide the clients into\ngroups, learn a global model for each group of clients using any existing\nfederated learning method, and take a majority vote among the global models to\nclassify a test input. Specifically, we consider two methods to group the\nclients and propose two variants of FLCert correspondingly, i.e., FLCert-P that\nrandomly samples clients in each group, and FLCert-D that divides clients to\ndisjoint groups deterministically. Our extensive experiments on multiple\ndatasets show that the label predicted by our FLCert for a test input is\nprovably unaffected by a bounded number of malicious clients, no matter what\npoisoning attacks they use.",
    "descriptor": "\nComments: To appear in Transactions on Information Forensics and Security. arXiv admin note: text overlap with arXiv:2102.01854\n",
    "authors": [
      "Xiaoyu Cao",
      "Zaixi Zhang",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00584"
  },
  {
    "id": "arXiv:2210.00586",
    "title": "Generated Faces in the Wild: Quantitative Comparison of Stable  Diffusion, Midjourney and DALL-E 2",
    "abstract": "The field of image synthesis has made great strides in the last couple of\nyears. Recent models are capable of generating images with astonishing quality.\nFine-grained evaluation of these models on some interesting categories such as\nfaces is still missing. Here, we conduct a quantitative comparison of three\npopular systems including Stable Diffusion, Midjourney, and DALL-E 2 in their\nability to generate photorealistic faces in the wild. We find that Stable\nDiffusion generates better faces than the other systems, according to the FID\nscore. We also introduce a dataset of generated faces in the wild dubbed GFW,\nincluding a total of 15,076 faces. Furthermore, we hope that our study spurs\nfollow-up research in assessing the generative models and improving them. Data\nand code are available at data and code, respectively.",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00586"
  },
  {
    "id": "arXiv:2210.00588",
    "title": "DFA: Dynamic Feature Aggregation for Efficient Video Object Detection",
    "abstract": "Video object detection is a fundamental yet challenging task in computer\nvision. One practical solution is to take advantage of temporal information\nfrom the video and apply feature aggregation to enhance the object features in\neach frame. Though effective, those existing methods always suffer from low\ninference speeds because they use a fixed number of frames for feature\naggregation regardless of the input frame. Therefore, this paper aims to\nimprove the inference speed of the current feature aggregation-based video\nobject detectors while maintaining their performance. To achieve this goal, we\npropose a vanilla dynamic aggregation module that adaptively selects the frames\nfor feature enhancement. Then, we extend the vanilla dynamic aggregation module\nto a more effective and reconfigurable deformable version. Finally, we\nintroduce inplace distillation loss to improve the representations of objects\naggregated with fewer frames. Extensive experimental results validate the\neffectiveness and efficiency of our proposed methods: On the ImageNet VID\nbenchmark, integrated with our proposed methods, FGFA and SELSA can improve the\ninference speed by 31% and 76% respectively while getting comparable\nperformance on accuracy.",
    "descriptor": "",
    "authors": [
      "Yiming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00588"
  },
  {
    "id": "arXiv:2210.00589",
    "title": "Uncertainty estimations methods for a deep learning model to aid in  clinical decision-making -- a clinician's perspective",
    "abstract": "Prediction uncertainty estimation has clinical significance as it can\npotentially quantify prediction reliability. Clinicians may trust 'blackbox'\nmodels more if robust reliability information is available, which may lead to\nmore models being adopted into clinical practice. There are several deep\nlearning-inspired uncertainty estimation techniques, but few are implemented on\nmedical datasets -- fewer on single institutional datasets/models. We sought to\ncompare dropout variational inference (DO), test-time augmentation (TTA),\nconformal predictions, and single deterministic methods for estimating\nuncertainty using our model trained to predict feeding tube placement for 271\nhead and neck cancer patients treated with radiation. We compared the area\nunder the curve (AUC), sensitivity, specificity, positive predictive value\n(PPV), and negative predictive value (NPV) trends for each method at various\ncutoffs that sought to stratify patients into 'certain' and 'uncertain'\ncohorts. These cutoffs were obtained by calculating the percentile\n\"uncertainty\" within the validation cohort and applied to the testing cohort.\nBroadly, the AUC, sensitivity, and NPV increased as the predictions were more\n'certain' -- i.e., lower uncertainty estimates. However, when a majority vote\n(implementing 2/3 criteria: DO, TTA, conformal predictions) or a stricter\napproach (3/3 criteria) were used, AUC, sensitivity, and NPV improved without a\nnotable loss in specificity or PPV. Especially for smaller, single\ninstitutional datasets, it may be important to evaluate multiple estimations\ntechniques before incorporating a model into clinical practice.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Michael Dohopolski",
      "Kai Wang",
      "Biling Wang",
      "Ti Bai",
      "Dan Nguyen",
      "David Sher",
      "Steve Jiang",
      "Jing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00589"
  },
  {
    "id": "arXiv:2210.00590",
    "title": "Community Learning: Understanding A Community Through NLP for Positive  Impact",
    "abstract": "A post-pandemic world resulted in economic upheaval, particularly for the\ncities' communities. While significant work in NLP4PI focuses on national and\ninternational events, there is a gap in bringing such state-of-the-art methods\ninto the community development field. In order to help with community\ndevelopment, we must learn about the communities we develop. To that end, we\npropose the task of community learning as a computational task of extracting\nnatural language data about the community, transforming and loading it into a\nsuitable knowledge graph structure for further downstream applications. We\nstudy two particular cases of homelessness and education in showing the\nvisualization capabilities of a knowledge graph, and also discuss other\nusefulness such a model can provide.",
    "descriptor": "",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Naveen Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00590"
  },
  {
    "id": "arXiv:2210.00592",
    "title": "Fully discrete finite element methods for nonlinear stochastic elastic  wave equations with multiplicative noise",
    "abstract": "This paper is concerned with fully discrete finite element methods for\napproximating variational solutions of nonlinear stochastic elastic wave\nequations with multiplicative noise. A detailed analysis of the properties of\nthe weak solution is carried out and a fully discrete finite element method is\nproposed. Strong convergence in the energy norm with rate $\\cal{O}(k+h^r)$ is\nproved, where $k$ and $h$ denote respectively the temporal and spatial mesh\nsizes, and $r(\\geq 1)$ is the order of the finite element. Numerical\nexperiments are provided to test the efficiency of proposed numerical methods\nand to validate the theoretical error estimate results.",
    "descriptor": "\nComments: 37 pages, 4 tables, and 16 graphics\n",
    "authors": [
      "Xiaobing Feng",
      "Yukun Li",
      "Yujian Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00592"
  },
  {
    "id": "arXiv:2210.00594",
    "title": "A database of high precision trivial choreographies for the planar  three-body problem",
    "abstract": "Trivial choreographies are special periodic solutions of the planar\nthree-body problem. In this work we use a modified Newton's method based on the\ncontinuous analog of Newton's method and a high precision arithmetic for a\nspecialized numerical search for new trivial choreographies. As a result of the\nsearch we computed a high precision database of 462 such orbits, including 397\nnew ones. The initial conditions and the periods of all found solutions are\ngiven with 180 correct decimal digits. 108 of the choreographies are linearly\nstable, including 99 new ones. The linear stability is tested by a high\nprecision computing of the eigenvalues of the monodromy matrices.",
    "descriptor": "\nComments: 10 pages, 3 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2203.02793\n",
    "authors": [
      "I. Hristov",
      "R. Hristova",
      "I. Puzynin",
      "T. Puzynina",
      "Z. Sharipov",
      "Z. Tukhliev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00594"
  },
  {
    "id": "arXiv:2210.00596",
    "title": "Policy Gradients for Probabilistic Constrained Reinforcement Learning",
    "abstract": "This paper considers the problem of learning safe policies in the context of\nreinforcement learning (RL). In particular, a safe policy or controller is one\nthat, with high probability, maintains the trajectory of the agent in a given\nsafe set. We relate this notion of safety to the notion of average safety often\nconsidered in the literature by providing theoretical bounds in terms of their\nsafety and performance. The challenge of working with the probabilistic notion\nof safety considered in this work is the lack of expressions for their\ngradients. Indeed, policy optimization algorithms rely on gradients of the\nobjective function and the constraints. To the best of our knowledge, this work\nis the first one providing such explicit gradient expressions for probabilistic\nconstraints. It is worth noting that such probabilistic gradients are naturally\nalgorithm independent, which provides possibilities for them to be applied to\nvarious policy-based algorithms. In addition, we consider a continuous\nnavigation problem to empirically illustrate the advantages (in terms of safety\nand performance) of working with probabilistic constraints as compared to\naverage constraints.",
    "descriptor": "",
    "authors": [
      "Weiqin Chen",
      "Dharmashankar Subramanian",
      "Santiago Paternain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00596"
  },
  {
    "id": "arXiv:2210.00597",
    "title": "Composition of Differential Privacy & Privacy Amplification by  Subsampling",
    "abstract": "This chapter is meant to be part of the book ``Differential Privacy for\nArtificial Intelligence Applications.'' We give an introduction to the most\nimportant property of differential privacy -- composition: running multiple\nindependent analyses on the data of a set of people will still be\ndifferentially private as long as each of the analyses is private on its own --\nas well as the related topic of privacy amplification by subsampling. This\nchapter introduces the basic concepts and gives proofs of the key results\nneeded to apply these tools in practice.",
    "descriptor": "",
    "authors": [
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00597"
  },
  {
    "id": "arXiv:2210.00604",
    "title": "Ensembling improves stability and power of feature selection for deep  learning models",
    "abstract": "With the growing adoption of deep learning models in different real-world\ndomains, including computational biology, it is often necessary to understand\nwhich data features are essential for the model's decision. Despite extensive\nrecent efforts to define different feature importance metrics for deep learning\nmodels, we identified that inherent stochasticity in the design and training of\ndeep learning models makes commonly used feature importance scores unstable.\nThis results in varied explanations or selections of different features across\ndifferent runs of the model. We demonstrate how the signal strength of features\nand correlation among features directly contribute to this instability. To\naddress this instability, we explore the ensembling of feature importance\nscores of models across different epochs and find that this simple approach can\nsubstantially address this issue. For example, we consider knockoff inference\nas they allow feature selection with statistical guarantees. We discover\nconsiderable variability in selected features in different epochs of deep\nlearning training, and the best selection of features doesn't necessarily occur\nat the lowest validation loss, the conventional approach to determine the best\nmodel. As such, we present a framework to combine the feature importance of\ntrained models across different hyperparameter settings and epochs, and instead\nof selecting features from one best model, we perform an ensemble of feature\nimportance scores from numerous good models. Across the range of experiments in\nsimulated and various real-world datasets, we demonstrate that the proposed\nframework consistently improves the power of feature selection.",
    "descriptor": "",
    "authors": [
      "Prashnna K Gyawali",
      "Xiaoxia Liu",
      "James Zou",
      "Zihuai He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00604"
  },
  {
    "id": "arXiv:2210.00608",
    "title": "Establishing Meta-Decision-Making for AI: An Ontology of Relevance,  Representation and Reasoning",
    "abstract": "We propose an ontology of building decision-making systems, with the aim of\nestablishing Meta-Decision-Making for Artificial Intelligence (AI), improving\nautonomy, and creating a framework to build metrics and benchmarks upon. To\nthis end, we propose the three parts of Relevance, Representation, and\nReasoning, and discuss their value in ensuring safety and mitigating risk in\nthe context of third wave cognitive systems. Our nomenclature reflects the\nliterature on decision-making, and our ontology allows researchers that adopt\nit to frame their work in relation to one or more of these parts.",
    "descriptor": "\nComments: This version was peer-reviewed, accepted and presented as part of the AAAI 2021 Fall Symposium FSS-21. 2021\n",
    "authors": [
      "Cosmin Badea",
      "Leilani Gilpin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00608"
  },
  {
    "id": "arXiv:2210.00609",
    "title": "Throwing Objects into A Moving Basket While Avoiding Obstacles",
    "abstract": "The capabilities of a robot will be increased significantly by exploiting\nthrowing behavior. In particular, throwing will enable robots to rapidly place\nthe object into the target basket, located outside its feasible kinematic\nspace, without traveling to the desired location. In previous approaches, the\nrobot often learned a parameterized throwing kernel through analytical\napproaches, imitation learning, or hand-coding. There are many situations in\nwhich such approaches do not work/generalize well due to various object shapes,\nheterogeneous mass distribution, and also obstacles that might be presented in\nthe environment. It is obvious that a method is needed to modulate the throwing\nkernel through its meta parameters. In this paper, we tackle object throwing\nproblem through a deep reinforcement learning approach that enables robots to\nprecisely throw objects into moving baskets while there are obstacles\nobstructing the path. To the best of our knowledge, we are the first group that\naddresses throwing objects with obstacle avoidance. Such a throwing skill not\nonly increases the physical reachability of a robot arm but also improves the\nexecution time. In particular, the robot detects the pose of the target object,\nbasket, and obstacle at each time step, predicts the proper grasp configuration\nfor the target object, and then infers appropriate parameters to throw the\nobject into the basket. Due to safety constraints, we develop a simulation\nenvironment in Gazebo to train the robot and then use the learned policy in\nreal-robot directly. To assess the performers of the proposed approach, we\nperform extensive sets of experiments in both simulation and real robots in\nthree scenarios. Experimental results showed that the robot could precisely\nthrow a target object into the basket outside its kinematic range and\ngeneralize well to new locations and objects without colliding with obstacles.",
    "descriptor": "\nComments: The video of our experiments can be found at this https URL\n",
    "authors": [
      "Hamidreza Kasaei",
      "Mohammadreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00609"
  },
  {
    "id": "arXiv:2210.00610",
    "title": "Belief propagation generalizes backpropagation",
    "abstract": "The two most important algorithms in artificial intelligence are\nbackpropagation and belief propagation. In spite of their importance, the\nconnection between them is poorly characterized. We show that when an input to\nbackpropagation is converted into an input to belief propagation so that\n(loopy) belief propagation can be run on it, then the result of belief\npropagation encodes the result of backpropagation; thus backpropagation is\nrecovered as a special case of belief propagation. In other words, we prove for\napparently the first time that belief propagation generalizes backpropagation.\nOur analysis is a theoretical contribution, which we motivate with the\nexpectation that it might reconcile our understandings of each of these\nalgorithms, and serve as a guide to engineering researchers seeking to improve\nthe behavior of systems that use one or the other.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Frederik Eaton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00610"
  },
  {
    "id": "arXiv:2210.00611",
    "title": "SAGDA: Achieving $\\mathcal{O}(\u03b5^{-2})$ Communication Complexity  in Federated Min-Max Learning",
    "abstract": "To lower the communication complexity of federated min-max learning, a\nnatural approach is to utilize the idea of infrequent communications (through\nmultiple local updates) same as in conventional federated learning. However,\ndue to the more complicated inter-outer problem structure in federated min-max\nlearning, theoretical understandings of communication complexity for federated\nmin-max learning with infrequent communications remain very limited in the\nliterature. This is particularly true for settings with non-i.i.d. datasets and\npartial client participation. To address this challenge, in this paper, we\npropose a new algorithmic framework called stochastic sampling averaging\ngradient descent ascent (SAGDA), which i) assembles stochastic gradient\nestimators from randomly sampled clients as control variates and ii) leverages\ntwo learning rates on both server and client sides. We show that SAGDA achieves\na linear speedup in terms of both the number of clients and local update steps,\nwhich yields an $\\mathcal{O}(\\epsilon^{-2})$ communication complexity that is\norders of magnitude lower than the state of the art. Interestingly, by noting\nthat the standard federated stochastic gradient descent ascent (FSGDA) is in\nfact a control-variate-free special version of SAGDA, we immediately arrive at\nan $\\mathcal{O}(\\epsilon^{-2})$ communication complexity result for FSGDA.\nTherefore, through the lens of SAGDA, we also advance the current understanding\non communication complexity of the standard FSGDA method for federated min-max\nlearning.",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Haibo Yang",
      "Zhuqing Liu",
      "Xin Zhang",
      "Jia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00611"
  },
  {
    "id": "arXiv:2210.00612",
    "title": "MultiScale MeshGraphNets",
    "abstract": "In recent years, there has been a growing interest in using machine learning\nto overcome the high cost of numerical simulation, with some learned models\nachieving impressive speed-ups over classical solvers whilst maintaining\naccuracy. However, these methods are usually tested at low-resolution settings,\nand it remains to be seen whether they can scale to the costly high-resolution\nsimulations that we ultimately want to tackle.\nIn this work, we propose two complementary approaches to improve the\nframework from MeshGraphNets, which demonstrated accurate predictions in a\nbroad range of physical systems. MeshGraphNets relies on a message passing\ngraph neural network to propagate information, and this structure becomes a\nlimiting factor for high-resolution simulations, as equally distant points in\nspace become further apart in graph space. First, we demonstrate that it is\npossible to learn accurate surrogate dynamics of a high-resolution system on a\nmuch coarser mesh, both removing the message passing bottleneck and improving\nperformance; and second, we introduce a hierarchical approach (MultiScale\nMeshGraphNets) which passes messages on two different resolutions (fine and\ncoarse), significantly improving the accuracy of MeshGraphNets while requiring\nless computational resources.",
    "descriptor": "",
    "authors": [
      "Meire Fortunato",
      "Tobias Pfaff",
      "Peter Wirnsberger",
      "Alexander Pritzel",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.00612"
  },
  {
    "id": "arXiv:2210.00613",
    "title": "The boundaries of meaning: a case study in neural machine translation",
    "abstract": "The success of deep learning in natural language processing raises intriguing\nquestions about the nature of linguistic meaning and ways in which it can be\nprocessed by natural and artificial systems. One such question has to do with\nsubword segmentation algorithms widely employed in language modeling, machine\ntranslation, and other tasks since 2016. These algorithms often cut words into\nsemantically opaque pieces, such as 'period', 'on', 't', and 'ist' in\n'period|on|t|ist'. The system then represents the resulting segments in a dense\nvector space, which is expected to model grammatical relations among them. This\nrepresentation may in turn be used to map 'period|on|t|ist' (English) to\n'par|od|ont|iste' (French). Thus, instead of being modeled at the lexical\nlevel, translation is reformulated more generally as the task of learning the\nbest bilingual mapping between the sequences of subword segments of two\nlanguages; and sometimes even between pure character sequences:\n'p|e|r|i|o|d|o|n|t|i|s|t' $\\rightarrow$ 'p|a|r|o|d|o|n|t|i|s|t|e'. Such subword\nsegmentations and alignments are at work in highly efficient end-to-end machine\ntranslation systems, despite their allegedly opaque nature. The computational\nvalue of such processes is unquestionable. But do they have any linguistic or\nphilosophical plausibility? I attempt to cast light on this question by\nreviewing the relevant details of the subword segmentation algorithms and by\nrelating them to important philosophical and linguistic debates, in the spirit\nof making artificial intelligence more transparent and explainable.",
    "descriptor": "\nComments: 35 pages, 4 figures, 1 table\n",
    "authors": [
      "Yuri Balashov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00613"
  },
  {
    "id": "arXiv:2210.00615",
    "title": "iCTGAN--An Attack Mitigation Technique for Random-vector Attack on  Accelerometer-based Gait Authentication Systems",
    "abstract": "A recent study showed that commonly (vanilla) studied implementations of\naccelerometer-based gait authentication systems ($v$ABGait) are susceptible to\nrandom-vector attack. The same study proposed a beta noise-assisted\nimplementation ($\\beta$ABGait) to mitigate the attack. In this paper, we assess\nthe effectiveness of the random-vector attack on both $v$ABGait and\n$\\beta$ABGait using three accelerometer-based gait datasets. In addition, we\npropose $i$ABGait, an alternative implementation of ABGait, which uses a\nConditional Tabular Generative Adversarial Network. Then we evaluate\n$i$ABGait's resilience against the traditional zero-effort and random-vector\nattacks. The results show that $i$ABGait mitigates the impact of the\nrandom-vector attack to a reasonable extent and outperforms $\\beta$ABGait in\nmost experimental settings.",
    "descriptor": "\nComments: 9 pages, 5 figures, IEEE International Joint Conference on Biometrics (IJCB 2022)\n",
    "authors": [
      "Jun Hyung Mo",
      "Rajesh Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00615"
  },
  {
    "id": "arXiv:2210.00616",
    "title": "An Efficient Cyclic Entailment Procedure in a Fragment of Separation  Logic",
    "abstract": "An efficient entailment proof system is essential to compositional\nverification using separation logic. Unfortunately, existing decision\nprocedures are either inexpressive or inefficient. For example, Smallfoot is an\nefficient procedure but only works with hardwired lists and trees. Other\nprocedures that can support general inductive predicates run exponentially in\ntime as their proof search requires back-tracking to deal with a disjunction in\nthe consequent.\nThis paper presents a decision procedure to derive cyclic entailment proofs\nfor general inductive predicates in polynomial time. Our procedure is efficient\nand does not require back-tracking; it uses normalisation rules that help avoid\nthe introduction of disjunction in the consequent. Moreover, our decidable\nfragment is sufficiently expressive: It is based on compositional predicates\nand can capture a wide range of data structures, including sorted and nested\nlist segments, skip lists with fast forward pointers, and binary search trees.\nWe have implemented the proposal in a prototype tool and evaluated it over\nchallenging problems taken from a recent separation logic competition. The\nexperimental results confirm the efficiency of the proposed system.",
    "descriptor": "",
    "authors": [
      "Quang Loc Le",
      "Xuan-Bach D. Le"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00616"
  },
  {
    "id": "arXiv:2210.00620",
    "title": "Does Wikidata Support Analogical Reasoning?",
    "abstract": "Analogical reasoning methods have been built over various resources,\nincluding commonsense knowledge bases, lexical resources, language models, or\ntheir combination. While the wide coverage of knowledge about entities and\nevents make Wikidata a promising resource for analogical reasoning across\nsituations and domains, Wikidata has not been employed for this task yet. In\nthis paper, we investigate whether the knowledge in Wikidata supports\nanalogical reasoning. Specifically, we study whether relational knowledge is\nmodeled consistently in Wikidata, observing that relevant relational\ninformation is typically missing or modeled in an inconsistent way. Our further\nexperiments show that Wikidata can be used to create data for analogy\nclassification, but this requires much manual effort. To facilitate future work\nthat can support analogies, we discuss key desiderata, and devise a set of\nmetrics to guide an automatic method for extracting analogies from Wikidata.",
    "descriptor": "",
    "authors": [
      "Filip Ilievski",
      "Jay Pujara",
      "Kartik Shenoy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00620"
  },
  {
    "id": "arXiv:2210.00621",
    "title": "Optimization for Robustness Evaluation beyond $\\ell_p$ Metrics",
    "abstract": "Empirical evaluation of deep learning models against adversarial attacks\nentails solving nontrivial constrained optimization problems. Popular\nalgorithms for solving these constrained problems rely on projected gradient\ndescent (PGD) and require careful tuning of multiple hyperparameters. Moreover,\nPGD can only handle $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ attack models due to\nthe use of analytical projectors. In this paper, we introduce a novel\nalgorithmic framework that blends a general-purpose constrained-optimization\nsolver PyGRANSO, With Constraint-Folding (PWCF), to add reliability and\ngenerality to robustness evaluation. PWCF 1) finds good-quality solutions\nwithout the need of delicate hyperparameter tuning, and 2) can handle general\nattack models, e.g., general $\\ell_p$ ($p \\geq 0$) and perceptual attacks,\nwhich are inaccessible to PGD-based algorithms.",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables, submitted to the 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023) and the 14th International OPT Workshop on Optimization for Machine Learning\n",
    "authors": [
      "Hengyue Liang",
      "Buyun Liang",
      "Ying Cui",
      "Tim Mitchell",
      "Ju Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00621"
  },
  {
    "id": "arXiv:2210.00625",
    "title": "Optimin achieves super-Nash performance",
    "abstract": "Since the 1990s, AI systems have achieved superhuman performance in major\nzero-sum games where \"winning\" has an unambiguous definition. However, most\nsocial interactions are mixed-motive games, where measuring the performance of\nAI systems is a non-trivial task. In this paper, I propose a novel benchmark\ncalled super-Nash performance to assess the performance of AI systems in\nmixed-motive settings. I show that a solution concept called optimin achieves\nsuper-Nash performance in every n-person game, i.e., for every Nash equilibrium\nthere exists an optimin where every player not only receives but also\nguarantees super-Nash payoffs even if the others deviate unilaterally and\nprofitably from the optimin.",
    "descriptor": "",
    "authors": [
      "Mehmet S. Ismail"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.00625"
  },
  {
    "id": "arXiv:2210.00627",
    "title": "MonoNHR: Monocular Neural Human Renderer",
    "abstract": "Existing neural human rendering methods struggle with a single image input\ndue to the lack of information in invisible areas and the depth ambiguity of\npixels in visible areas. In this regard, we propose Monocular Neural Human\nRenderer (MonoNHR), a novel approach that renders robust free-viewpoint images\nof an arbitrary human given only a single image. MonoNHR is the first method\nthat (i) renders human subjects never seen during training in a monocular\nsetup, and (ii) is trained in a weakly-supervised manner without geometry\nsupervision. First, we propose to disentangle 3D geometry and texture features\nand to condition the texture inference on the 3D geometry features. Second, we\nintroduce a Mesh Inpainter module that inpaints the occluded parts exploiting\nhuman structural priors such as symmetry. Experiments on ZJU-MoCap, AIST, and\nHUMBI datasets show that our approach significantly outperforms the recent\nmethods adapted to the monocular case.",
    "descriptor": "\nComments: Hongsuk Choi and Gyeongsik Moon contributed equally, 15 pages including the reference and supplementary material\n",
    "authors": [
      "Hongsuk Choi",
      "Gyeongsik Moon",
      "Matthieu Armando",
      "Vincent Leroy",
      "Kyoung Mu Lee",
      "Gregory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00627"
  },
  {
    "id": "arXiv:2210.00629",
    "title": "Convex synthesis and verification of control-Lyapunov and barrier  functions with input constraints",
    "abstract": "Control Lyapunov functions (CLFs) and control barrier functions (CBFs) are\nwidely used tools for synthesizing controllers subject to stability and safety\nconstraints. Paired with online optimization, they provide stabilizing control\nactions that satisfy input constraints and avoid unsafe regions of state-space.\nDesigning CLFs and CBFs with rigorous performance guarantees is computationally\nchallenging. To certify existence of control actions, current techniques not\nonly design a CLF/CBF, but also a nominal controller. This can make the\nsynthesis task more expensive, and performance estimation more conservative. In\nthis work, we characterize polynomial CLFs/CBFs using sum-of-squares\nconditions, which can be directly certified using convex optimization. This\nyields a CLF and CBF synthesis technique that does not rely on a nominal\ncontroller. We then present algorithms for iteratively enlarging estimates of\nthe stabilizable and safe regions. We demonstrate our algorithms on a 2D toy\nsystem, a pendulum and a quadrotor.",
    "descriptor": "",
    "authors": [
      "Hongkai Dai",
      "Frank Permenter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00629"
  },
  {
    "id": "arXiv:2210.00630",
    "title": "No Selection Lemma for Empty Triangles",
    "abstract": "Let $S$ be a set of $n$ points in general position in the plane. The Second\nSelection Lemma states that for any family of $\\Theta(n^3)$ triangles spanned\nby $S$, there exists a point of the plane that lies in a constant fraction of\nthem. For families of $\\Theta(n^{3-\\alpha})$ triangles, with $0\\le \\alpha \\le\n1$, there might not be a point in more than $\\Theta(n^{3-2\\alpha})$ of those\ntriangles. An empty triangle of $S$ is a triangle spanned by $S$ not containing\nany point of $S$ in its interior. B\\'ar\\'any conjectured that there exist an\nedge spanned by $S$ that is incident to a super constant number of empty\ntriangles of $S$. The number of empty triangles of $S$ might be $O(n^2)$; in\nsuch a case, on average, every edge spanned by $S$ is incident to a constant\nnumber of empty triangles. The conjecture of B\\'ar\\'any suggests that for the\nclass of empty triangles the above upper bound might not hold. In this paper we\nshow that, somewhat surprisingly, the above upper bound does in fact hold for\nempty triangles. Specifically, we show that for any integer $n$ and real number\n$0\\leq \\alpha \\leq 1$ there exists a point set of size $n$ with\n$\\Theta(n^{3-\\alpha})$ empty triangles such that any point of the plane is only\nin $O(n^{3-2\\alpha})$ empty triangles.",
    "descriptor": "\nComments: Some results were presented at EuroComb2022\n",
    "authors": [
      "Ruy Fabila-Monroy",
      "Carlos Hidalgo-Toscano",
      "Daniel Perz",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00630"
  },
  {
    "id": "arXiv:2210.00635",
    "title": "Robust Empirical Risk Minimization with Tolerance",
    "abstract": "Developing simple, sample-efficient learning algorithms for robust\nclassification is a pressing issue in today's tech-dominated world, and current\ntheoretical techniques requiring exponential sample complexity and complicated\nimproper learning rules fall far from answering the need. In this work we study\nthe fundamental paradigm of (robust) $\\textit{empirical risk minimization}$\n(RERM), a simple process in which the learner outputs any hypothesis minimizing\nits training error. RERM famously fails to robustly learn VC classes (Montasser\net al., 2019a), a bound we show extends even to `nice' settings such as\n(bounded) halfspaces. As such, we study a recent relaxation of the robust model\ncalled $\\textit{tolerant}$ robust learning (Ashtiani et al., 2022) where the\noutput classifier is compared to the best achievable error over slightly larger\nperturbation sets. We show that under geometric niceness conditions, a natural\ntolerant variant of RERM is indeed sufficient for $\\gamma$-tolerant robust\nlearning VC classes over $\\mathbb{R}^d$, and requires only $\\tilde{O}\\left(\n\\frac{VC(H)d\\log \\frac{D}{\\gamma\\delta}}{\\epsilon^2}\\right)$ samples for\nrobustness regions of (maximum) diameter $D$.",
    "descriptor": "\nComments: 22 pages, 1 figure\n",
    "authors": [
      "Robi Bhattacharjee",
      "Max Hopkins",
      "Akash Kumar",
      "Hantao Yu",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00635"
  },
  {
    "id": "arXiv:2210.00637",
    "title": "Benign Autoencoders",
    "abstract": "The success of modern machine learning algorithms depends crucially on\nefficient data representation and compression through dimensionality reduction.\nThis practice seemingly contradicts the conventional intuition suggesting that\ndata processing always leads to information loss. We prove that this intuition\nis wrong. For any non-convex problem, there exists an optimal, benign\nauto-encoder (BAE) extracting a lower-dimensional data representation that is\nstrictly beneficial: Compressing model inputs improves model performance. We\nprove that BAE projects data onto a manifold whose dimension is the\ncompressibility dimension of the learning model. We develop and implement an\nefficient algorithm for computing BAE and show that BAE improves model\nperformance in every dataset we consider. Furthermore, by compressing\n\"malignant\" data dimensions, BAE makes learning more stable and robust.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.08884\n",
    "authors": [
      "Semyon Malamud",
      "Andreas Schrimpf",
      "Andrea Xu",
      "Giuseppe Matera",
      "Antoine Didisheim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00637"
  },
  {
    "id": "arXiv:2210.00638",
    "title": "What shapes the loss landscape of self-supervised learning?",
    "abstract": "Prevention of complete and dimensional collapse of representations has\nrecently become a design principle for self-supervised learning (SSL). However,\nquestions remain in our theoretical understanding: When do those collapses\noccur? What are the mechanisms and causes? We provide answers to these\nquestions by thoroughly analyzing SSL loss landscapes for a linear model. We\nderive an analytically tractable theory of SSL landscape and show that it\naccurately captures an array of collapse phenomena and identifies their causes.\nFinally, we leverage the interpretability afforded by the analytical theory to\nunderstand how dimensional collapse can be beneficial and what affects the\nrobustness of SSL against data imbalance.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Liu Ziyin",
      "Ekdeep Singh Lubana",
      "Masahito Ueda",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.00638"
  },
  {
    "id": "arXiv:2210.00640",
    "title": "Wide Attention Is The Way Forward For Transformers",
    "abstract": "The Transformer is an extremely powerful and prominent deep learning\narchitecture. In this work, we challenge the commonly held belief in deep\nlearning that going deeper is better, and show an alternative design approach\nthat is building wider attention Transformers. We demonstrate that wide single\nlayer Transformer models can compete with or outperform deeper ones in a\nvariety of Natural Language Processing (NLP) tasks when both are trained from\nscratch. The impact of changing the model aspect ratio on Transformers is then\nstudied systematically. This ratio balances the number of layers and the number\nof attention heads per layer while keeping the total number of attention heads\nand all other hyperparameters constant. On average, across 4 NLP tasks and 10\nattention types, single layer wide models perform 0.3% better than their deep\ncounterparts. We show an in-depth evaluation and demonstrate how wide models\nrequire a far smaller memory footprint and can run faster on commodity\nhardware, in addition, these wider models are also more interpretable. For\nexample, a single layer Transformer on the IMDb byte level text classification\nhas 3.1x faster inference latency on a CPU than its equally accurate deeper\ncounterpart, and is half the size. Our results suggest that the critical\ndirection for building better Transformers for NLP is their width, and that\ntheir depth is less relevant.",
    "descriptor": "",
    "authors": [
      "Jason Ross Brown",
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert D Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00640"
  },
  {
    "id": "arXiv:2210.00641",
    "title": "DARTFormer: Finding The Best Type Of Attention",
    "abstract": "Given the wide and ever growing range of different efficient Transformer\nattention mechanisms, it is important to identify which attention is most\neffective when given a task. In this work, we are also interested in combining\ndifferent attention types to build heterogeneous Transformers. We first propose\na DARTS-like Neural Architecture Search (NAS) method to find the best attention\nfor a given task, in this setup, all heads use the same attention (homogeneous\nmodels). Our results suggest that NAS is highly effective on this task, and it\nidentifies the best attention mechanisms for IMDb byte level text\nclassification and Listops. We then extend our framework to search for and\nbuild Transformers with multiple different attention types, and call them\nheterogeneous Transformers. We show that whilst these heterogeneous\nTransformers are better than the average homogeneous models, they cannot\noutperform the best. We explore the reasons why heterogeneous attention makes\nsense, and why it ultimately fails.",
    "descriptor": "",
    "authors": [
      "Jason Ross Brown",
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert D Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00641"
  },
  {
    "id": "arXiv:2210.00642",
    "title": "Fron 2G to 4G Mobile Network: Architecture and Key Performance  Indicators",
    "abstract": "The second-generation (2G) mobile systems were developed in response to the\ngrowing demand for a system that met mobile communication demands while also\nproviding greater interoperability with other systems. International\norganizations were crucial in the development of a system that would offer\nbetter services, be more transparent, and be more interoperable with other\nnetworks. The aim of having a single set of standards for networks worldwide\nwas sadly not realized by the 2G network standards. The third generation (3G)\nwas born. It was called the universal terrestrial mobile system (UMTS), which\nis European telecommunications standards institute (ETSI) driven. IMT-2000 is\nthe international telecommunication union-telecommunication standardization\nsector (ITU-T) name for the 3G network. Wide-band code division multiple access\n(WCDMA) is the air interface technology for the UMTS. This platform offers many\nservices that are based on the Internet, along with video calling, imaging,\netc. Further advancements to mobile network technology led to long term\nevolution (LTE), a technology referred to as 4G. The primary goal of LTE was to\nimprove the speed and capacity of mobile networks while lowering latency. As we\nmove to an ALL-IP system, mobile networks' design becomes much simpler. LTE\nuses orthogonal frequency division multiplexing (OFDM) in its air interface.\nThis paper details all mentioned mobile generations, as well as all the\ndifferences between them in terms of hardware and software architectures.",
    "descriptor": "",
    "authors": [
      "Hamza Kheddar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00642"
  },
  {
    "id": "arXiv:2210.00643",
    "title": "Spectral Augmentation for Self-Supervised Learning on Graphs",
    "abstract": "Graph contrastive learning (GCL), as an emerging self-supervised learning\ntechnique on graphs, aims to learn representations via instance discrimination.\nIts performance heavily relies on graph augmentation to reflect invariant\npatterns that are robust to small perturbations; yet it still remains unclear\nabout what graph invariance GCL should capture. Recent studies mainly perform\ntopology augmentations in a uniformly random manner in the spatial domain,\nignoring its influence on the intrinsic structural properties embedded in the\nspectral domain. In this work, we aim to find a principled way for topology\naugmentations by exploring the invariance of graphs from the spectral\nperspective. We develop spectral augmentation which guides topology\naugmentations by maximizing the spectral change. Extensive experiments on both\ngraph and node classification tasks demonstrate the effectiveness of our method\nin self-supervised representation learning. The proposed method also brings\npromising generalization capability in transfer learning, and is equipped with\nintriguing robustness property under adversarial attacks. Our study sheds light\non a general principle for graph topology augmentation.",
    "descriptor": "\nComments: 26 pages, 5 figures, 12 tables\n",
    "authors": [
      "Lu Lin",
      "Jinghui Chen",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00643"
  },
  {
    "id": "arXiv:2210.00645",
    "title": "Economic-Driven Adaptive Traffic Signal Control",
    "abstract": "With the emerging connected-vehicle technologies and smart roads, the need\nfor intelligent adaptive traffic signal controls is more than ever before. This\npaper proposes a novel Economic-driven Adaptive Traffic Signal Control (eATSC)\nmodel with a hyper control variable - interest rate defined in economics for\ntraffic signal control at signalized intersections. The eATSC uses a continuous\ncompounding function that captures both the total number of vehicles and the\naccumulated waiting time of each vehicle to compute penalties for different\ndirections. The computed penalties grow with waiting time and is used for\nsignal control decisions. Each intersection is assigned two intelligent agents\nadjusting interest rate and signal length for different directions according to\nthe traffic patterns, respectively. The problem is formulated as a Markov\nDecision Process (MDP) problem to reduce congestions, and a two-agent Double\nDueling Deep Q Network (DDDQN) is utilized to solve the problem. Under the\noptimal policy, the agents can select the optimal interest rates and signal\ntime to minimize the likelihood of traffic congestion. To evaluate the\nsuperiority of our method, a VISSIM simulation model with classic four-leg\nsignalized intersections is developed. The results indicate that the proposed\nmodel is adequately able to maintain healthy traffic flow at the intersection.",
    "descriptor": "\nComments: 18 pages, 12 figures, presented at the Transportation Research Board (TRB) 100th Annual Meeting, 2021\n",
    "authors": [
      "Shan Jiang",
      "Yufei Huang",
      "Mohsen Jafari",
      "Mohammad Jalayer"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00645"
  },
  {
    "id": "arXiv:2210.00646",
    "title": "Pixel-global Self-supervised Learning with Uncertainty-aware Context  Stabilizer",
    "abstract": "We developed a novel SSL approach to capture global consistency and\npixel-level local consistencies between differently augmented views of the same\nimages to accommodate downstream discriminative and dense predictive tasks. We\nadopted the teacher-student architecture used in previous contrastive SSL\nmethods. In our method, the global consistency is enforced by aggregating the\ncompressed representations of augmented views of the same image. The\npixel-level consistency is enforced by pursuing similar representations for the\nsame pixel in differently augmented views. Importantly, we introduced an\nuncertainty-aware context stabilizer to adaptively preserve the context gap\ncreated by the two views from different augmentations. Moreover, we used Monte\nCarlo dropout in the stabilizer to measure uncertainty and adaptively balance\nthe discrepancy between the representations of the same pixels in different\nviews.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Zhuangzhuang Zhang",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00646"
  },
  {
    "id": "arXiv:2210.00647",
    "title": "IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable  Novel View Synthesis",
    "abstract": "We present intrinsic neural radiance fields, dubbed IntrinsicNeRF, that\nintroduce intrinsic decomposition into the NeRF-based~\\cite{mildenhall2020nerf}\nneural rendering method and can perform editable novel view synthesis in\nroom-scale scenes while existing inverse rendering combined with neural\nrendering methods~\\cite{zhang2021physg, zhang2022modeling} can only work on\nobject-specific scenes. Given that intrinsic decomposition is a fundamentally\nambiguous and under-constrained inverse problem, we propose a novel\ndistance-aware point sampling and adaptive reflectance iterative clustering\noptimization method that enables IntrinsicNeRF with traditional intrinsic\ndecomposition constraints to be trained in an unsupervised manner, resulting in\ntemporally consistent intrinsic decomposition results. To cope with the problem\nof different adjacent instances of similar reflectance in a scene being\nincorrectly clustered together, we further propose a hierarchical clustering\nmethod with coarse-to-fine optimization to obtain a fast hierarchical indexing\nrepresentation. It enables compelling real-time augmented reality applications\nsuch as scene recoloring, material editing, and illumination variation.\nExtensive experiments on Blender Object and Replica Scene demonstrate that we\ncan obtain high-quality, consistent intrinsic decomposition results and\nhigh-fidelity novel view synthesis even for challenging sequences. Code and\ndata are available on the project webpage:\nhttps://zju3dv.github.io/intrinsic_nerf/.",
    "descriptor": "\nComments: Project webpage: this https URL, code: this https URL\n",
    "authors": [
      "Weicai Ye",
      "Shuo Chen",
      "Chong Bao",
      "Hujun Bao",
      "Marc Pollefeys",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.00647"
  },
  {
    "id": "arXiv:2210.00649",
    "title": "Automated Security Analysis of Exposure Notification Systems",
    "abstract": "We present the first formal analysis and comparison of the security of the\ntwo most widely deployed exposure notification systems, ROBERT and the Google\nand Apple Exposure Notification (GAEN) framework. ROBERT is the most popular\ninstalment of the centralised approach to exposure notification, in which the\nrisk score is computed by a central server. GAEN, in contrast, follows the\ndecentralised approach, where the user's phone calculates the risk. The\nrelative merits of centralised and decentralised systems have proven to be a\ncontroversial question. The majority of the previous analyses have focused on\nthe privacy implications of these systems, ours is the first formal analysis to\nevaluate the security of the deployed systems -- the absence of false risk\nalerts. We model the French deployment of ROBERT and the most widely deployed\nGAEN variant, Germany's Corona-Warn-App. We isolate the precise conditions\nunder which these systems prevent false alerts. We determine exactly how an\nadversary can subvert the system via network and Bluetooth sniffing, database\nleakage or the compromise of phones, back-end systems and health authorities.\nWe also investigate the security of the original specification of the DP3T\nprotocol, in order to identify gaps between the proposed scheme and its\nultimate deployment. We find a total of 27 attack patterns, including many that\ndistinguish the centralised from the decentralised approach, as well as attacks\non the authorisation procedure that differentiate all three protocols. Our\nresults suggest that ROBERT's centralised design is more vulnerable against\nboth opportunistic and highly resourced attackers trying to perform\nmass-notification attacks.",
    "descriptor": "\nComments: 23 pages, Full version of the corresponding USENIX Security '23 paper\n",
    "authors": [
      "Kevin Morio",
      "Ilkan Esiyok",
      "Dennis Jackson",
      "Robert K\u00fcnnemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00649"
  },
  {
    "id": "arXiv:2210.00653",
    "title": "Greedy capped nonlinear Kaczmarz methods",
    "abstract": "To solve nonlinear problems, we construct two kinds of greedy capped\nnonlinear Kaczmarz methods by setting a capped threshold and introducing an\neffective probability criterion for selecting a row of the Jacobian matrix. The\ncapped threshold and probability criterion are mainly determined by the maximum\nresidual and maximum distance rules. The block versions of the new methods are\nalso presented. We provide the convergence analysis of these methods and their\nnumerical results behave quite well.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.06082\n",
    "authors": [
      "Yanjun Zhang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00653"
  },
  {
    "id": "arXiv:2210.00654",
    "title": "Relational Models for the Lambek Calculus with Intersection and  Constants",
    "abstract": "We consider relational semantics (R-models) for the Lambek calculus extended\nwith intersection and explicit constants for zero and unit. For its variant\nwithout constants and a restriction which disallows empty antecedents, Andreka\nand Mikulas (1994) prove strong completeness. We show that it fails without\nthis restriction, but, on the other hand, prove weak completeness for\nnon-standard interpretation of constants. For the standard interpretation, even\nweak completeness fails. The weak completeness result extends to an infinitary\nsetting, for so-called iterative divisions (Kleene star under division). We\nalso prove strong completeness results for product-free fragments.",
    "descriptor": "\nComments: This article is an extended version of the conference paper presented at RAMiCS 2021\n",
    "authors": [
      "Stepan L. Kuznetsov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00654"
  },
  {
    "id": "arXiv:2210.00655",
    "title": "Online Pen Testing",
    "abstract": "We study a \"pen testing\" problem, in which we are given $n$ pens with unknown\namounts of ink $X_1, X_2, \\ldots, X_n$, and we want to choose a pen with the\nmaximum amount of remaining ink in it. The challenge is that we cannot access\neach $X_i$ directly; we only get to write with the $i$-th pen until either a\ncertain amount of ink is used, or the pen runs out of ink. In both cases, this\ntesting reduces the remaining ink in the pen and thus the utility of selecting\nit.\nDespite this significant lack of information, we show that it is possible to\napproximately maximize our utility up to an $O(\\log n)$ factor. Formally, we\nconsider two different setups: the \"prophet\" setting, in which each $X_i$ is\nindependently drawn from some distribution $\\mathcal{D}_i$, and the \"secretary\"\nsetting, in which $(X_i)_{i=1}^n$ is a random permutation of arbitrary $a_1,\na_2, \\ldots, a_n$. We derive the optimal competitive ratios in both settings up\nto constant factors. Our algorithms are surprisingly robust: (1) In the prophet\nsetting, we only require one sample from each $\\mathcal{D}_i$, rather than a\nfull description of the distribution; (2) In the secretary setting, the\nalgorithm also succeeds under an arbitrary permutation, if an estimate of the\nmaximum $a_i$ is given.\nOur techniques include a non-trivial online sampling scheme from a sequence\nwith an unknown length, as well as the construction of a hard, non-uniform\ndistribution over permutations. Both might be of independent interest. We also\nhighlight some immediate open problems and discuss several directions for\nfuture research.",
    "descriptor": "",
    "authors": [
      "Mingda Qiao",
      "Gregory Valiant"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.00655"
  },
  {
    "id": "arXiv:2210.00660",
    "title": "A Non-monotonic Self-terminating Language Model",
    "abstract": "Recent large-scale neural autoregressive sequence models have shown\nimpressive performances on a variety of natural language generation tasks.\nHowever, their generated sequences often exhibit degenerate properties such as\nnon-termination, undesirable repetition, and premature termination, when\ngenerated with decoding algorithms such as greedy search, beam search, top-$k$\nsampling, and nucleus sampling. In this paper, we focus on the problem of\nnon-terminating sequences resulting from an incomplete decoding algorithm. We\nfirst define an incomplete probable decoding algorithm which includes greedy\nsearch, top-$k$ sampling, and nucleus sampling, beyond the incomplete decoding\nalgorithm originally put forward by Welleck et al. (2020). We then propose a\nnon-monotonic self-terminating language model, which significantly relaxes the\nconstraint of monotonically increasing termination probability in the\noriginally proposed self-terminating language model by Welleck et al. (2020),\nto address the issue of non-terminating sequences when using incomplete\nprobable decoding algorithms. We prove that our proposed model prevents\nnon-terminating sequences when using not only incomplete probable decoding\nalgorithms but also beam search. We empirically validate our model on sequence\ncompletion tasks with various architectures.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Eugene Choi",
      "Cheolhyoung Lee",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00660"
  },
  {
    "id": "arXiv:2210.00662",
    "title": "Under the Cover Infant Pose Estimation using Multimodal Data",
    "abstract": "Infant pose monitoring during sleep has multiple applications in both\nhealthcare and home settings. In a healthcare setting, pose detection can be\nused for region of interest detection and movement detection for noncontact\nbased monitoring systems. In a home setting, pose detection can be used to\ndetect sleep positions which has shown to have a strong influence on multiple\nhealth factors. However, pose monitoring during sleep is challenging due to\nheavy occlusions from blanket coverings and low lighting. To address this, we\npresent a novel dataset, Simultaneously-collected multimodal Mannequin Lying\npose (SMaL) dataset, for under the cover infant pose estimation. We collect\ndepth and pressure imagery of an infant mannequin in different poses under\nvarious cover conditions. We successfully infer full body pose under the cover\nby training state-of-art pose estimation methods and leveraging existing\nmultimodal adult pose datasets for transfer learning. We demonstrate a\nhierarchical pretraining strategy for transformer-based models to significantly\nimprove performance on our dataset. Our best performing model was able to\ndetect joints under the cover within 25mm 86% of the time with an overall mean\nerror of 16.9mm. Data, code and models publicly available at\nhttps://github.com/DanielKyr/SMaL",
    "descriptor": "",
    "authors": [
      "Daniel G. Kyrollos",
      "Anthony Fuller",
      "Kim Greenwood",
      "JoAnn Harrold",
      "James R. Green"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00662"
  },
  {
    "id": "arXiv:2210.00664",
    "title": "FRIDA: A Collaborative Robot Painter with a Differentiable,  Real2Sim2Real Planning Environment",
    "abstract": "Painting is an artistic process of rendering visual content that achieves the\nhigh-level communication goals of an artist that may change dynamically\nthroughout the creative process. In this paper, we present a Framework and\nRobotics Initiative for Developing Arts (FRIDA) that enables humans to produce\npaintings on canvases by collaborating with a painter robot using simple inputs\nsuch as language descriptions or images. FRIDA introduces several technical\ninnovations for computationally modeling a creative painting process. First, we\ndevelop a fully differentiable simulation environment for painting, adopting\nthe idea of real to simulation to real (real2sim2real). We show that our\nproposed simulated painting environment is higher fidelity to reality than\nexisting simulation environments used for robot painting. Second, to model the\nevolving dynamics of a creative process, we develop a planning approach that\ncan continuously optimize the painting plan based on the evolving canvas with\nrespect to the high-level goals. In contrast to existing approaches where the\ncontent generation process and action planning are performed independently and\nsequentially, FRIDA adapts to the stochastic nature of using paint and a brush\nby continually re-planning and re-assessing its semantic goals based on its\nvisual perception of the painting progress. We describe the details on the\ntechnical approach as well as the system integration.",
    "descriptor": "",
    "authors": [
      "Peter Schaldenbrand",
      "James McCann",
      "Jean Oh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00664"
  },
  {
    "id": "arXiv:2210.00665",
    "title": "$\u03b2$-Stochastic Sign SGD: A Byzantine Resilient and Differentially  Private Gradient Compressor for Federated Learning",
    "abstract": "Federated Learning (FL) is a nascent privacy-preserving learning framework\nunder which the local data of participating clients is kept locally throughout\nmodel training. Scarce communication resources and data heterogeneity are two\ndefining characteristics of FL. Besides, a FL system is often implemented in a\nharsh environment -- leaving the clients vulnerable to Byzantine attacks. To\nthe best of our knowledge, no gradient compressors simultaneously achieve\nquantitative Byzantine resilience and privacy preservation. In this paper, we\nfill this gap via revisiting the stochastic sign SGD \\cite{jin 2020}. We\npropose $\\beta$-stochastic sign SGD, which contains a gradient compressor that\nencodes a client's gradient information in sign bits subject to the privacy\nbudget $\\beta>0$. We show that as long as $\\beta>0$, $\\beta$-stochastic sign\nSGD converges in the presence of partial client participation and mobile\nByzantine faults, showing that it achieves quantifiable Byzantine-resilience\nand differential privacy simultaneously. In sharp contrast, when $\\beta=0$, the\ncompressor is not differentially private. Notably, for the special case when\neach of the stochastic gradients involved is bounded with known bounds, our\ngradient compressor with $\\beta=0$ coincides with the compressor proposed in\n\\cite{jin 2020}. As a byproduct, we show that when the clients report sign\nmessages, the popular information aggregation rules simple mean, trimmed mean,\nmedian and majority vote are identical in terms of the output signs. Our\ntheories are corroborated by experiments on MNIST and CIFAR-10 datasets.",
    "descriptor": "",
    "authors": [
      "Ming Xiang",
      "Lili Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00665"
  },
  {
    "id": "arXiv:2210.00667",
    "title": "Probing of Quantitative Values in Abstractive Summarization Models",
    "abstract": "Abstractive text summarization has recently become a popular approach, but\ndata hallucination remains a serious problem, including with quantitative data.\nWe propose a set of probing tests to evaluate the efficacy of abstract\nsummarization models' modeling of quantitative values found in the input text.\nOur results show that in most cases, the encoders of recent SOTA-performing\nmodels struggle to provide embeddings that adequately represent quantitative\nvalues in the input compared to baselines, and in particular, they outperform\nrandom representations in some, but surprisingly not all, cases. Under our\nassumptions, this suggests that the encoder's performance contributes to the\nquantity hallucination problem. One model type in particular, DistilBART-CDM,\nwas observed to underperform randomly initialized representations for several\nexperiments, and performance versus BERT suggests that standard pretraining and\nfine-tuning approaches for the summarization task may play a role in\nunderperformance for some encoders.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Nathan M. White"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00667"
  },
  {
    "id": "arXiv:2210.00672",
    "title": "Evolution is Still Good: Theoretical Analysis of Evolutionary Algorithms  on General Cover Problems",
    "abstract": "Theoretical studies on evolutionary algorithms have developed vigorously in\nrecent years. Many such algorithms have theoretical guarantees in both running\ntime and approximation ratio. Some approximation mechanism seems to be\ninherently embedded in many evolutionary algorithms. In this paper, we identify\nsuch a relation by proposing a unified analysis framework for a generalized\nsimple multi-objective evolutionary algorithm (GSEMO), and apply it on a\nminimum weight general cover problem. For a wide range of problems (including\nthe the minimum submodular cover problem in which the submodular function is\nreal-valued, and the minimum connected dominating set problem for which the\npotential function is non-submodular), GSEMO yields asymptotically tight\napproximation ratios in expected polynomial time.",
    "descriptor": "",
    "authors": [
      "Yaoyao Zhang",
      "Chaojie Zhu",
      "Shaojie Tang",
      "Ringli Ran",
      "Ding-Zhu Du",
      "Zhao Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.00672"
  },
  {
    "id": "arXiv:2210.00673",
    "title": "Deep Learning for Wireless Networked Systems: a joint  Estimation-Control-Scheduling Approach",
    "abstract": "Wireless networked control system (WNCS) connecting sensors, controllers, and\nactuators via wireless communications is a key enabling technology for highly\nscalable and low-cost deployment of control systems in the Industry 4.0 era.\nDespite the tight interaction of control and communications in WNCSs, most\nexisting works adopt separative design approaches. This is mainly because the\nco-design of control-communication policies requires large and hybrid state and\naction spaces, making the optimal problem mathematically intractable and\ndifficult to be solved effectively by classic algorithms. In this paper, we\nsystematically investigate deep learning (DL)-based estimator-control-scheduler\nco-design for a model-unknown nonlinear WNCS over wireless fading channels. In\nparticular, we propose a co-design framework with the awareness of the sensor's\nage-of-information (AoI) states and dynamic channel states. We propose a novel\ndeep reinforcement learning (DRL)-based algorithm for controller and scheduler\noptimization utilizing both model-free and model-based data. An AoI-based\nimportance sampling algorithm that takes into account the data accuracy is\nproposed for enhancing learning efficiency. We also develop novel schemes for\nenhancing the stability of joint training. Extensive experiments demonstrate\nthat the proposed joint training algorithm can effectively solve the\nestimation-control-scheduling co-design problem in various scenarios and\nprovide significant performance gain compared to separative design and some\nbenchmark policies.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zihuai Zhao",
      "Wanchun Liu",
      "Daniel E. Quevedo",
      "Yonghui Li",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00673"
  },
  {
    "id": "arXiv:2210.00674",
    "title": "Multi-view information fusion using multi-view variational autoencoders  to predict proximal femoral strength",
    "abstract": "Background and aim: Hip fracture can be devastating. The proximal femoral\nstrength can be computed by subject-specific finite element (FE) analysis (FEA)\nusing quantitative CT images. The aim of this paper is to design a deep\nlearning-based model for hip fracture prediction with multi-view information\nfusion. Method: We developed a multi-view variational autoencoder (MMVAE) for\nfeature representation learning and designed the product of expert model (PoE)\nfor multi-view information fusion.We performed genome-wide association studies\n(GWAS) to select the most relevant genetic features with proximal femoral\nstrengths and integrated genetic features with DXA-derived imaging features and\nclinical variables for proximal femoral strength prediction. Results: The\ndesigned model achieved the mean absolute percentage error of 0.2050,0.0739 and\n0.0852 for linear fall, nonlinear fall and nonlinear stance fracture load\nprediction, respectively. For linear fall and nonlinear stance fracture load\nprediction, integrating genetic and DXA-derived imaging features were\nbeneficial; while for nonlinear fall fracture load prediction, integrating\ngenetic features, DXA-derived imaging features as well as clinical variables,\nthe model achieved the best performance. Conclusion: The proposed model is\ncapable of predicting proximal femoral strengths using genetic features,\nDXA-derived imaging features as well as clinical variables. Compared to\nperforming FEA using QCT images to calculate proximal femoral strengths, the\npresented method is time-efficient and cost effective, and radiation dosage is\nlimited. From the technique perspective, the final models can be applied to\nother multi-view information integration tasks.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Chen Zhao",
      "Joyce H Keyak",
      "Xuewei Cao",
      "Qiuying Sha",
      "Li Wu",
      "Zhe Luo",
      "Lanjuan Zhao",
      "Qing Tian",
      "Chuan Qiu",
      "Ray Su",
      "Hui Shen",
      "Hong-Wen Deng",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.00674"
  },
  {
    "id": "arXiv:2210.00685",
    "title": "Two new classes of exponential Runge-Kutta integrators for efficiently  solving stiff systems or highly oscillatory problems",
    "abstract": "We study two new classes of exponential Runge-Kutta (ERK) integrators for\nefficiently solving stiff systems or highly oscillatory problems. We first\npresent a novel class of explicit modified version of exponential Runge-Kutta\n(MVERK) methods based on the order conditions. Furthermore, we consider a class\nof explicit simplified version of exponential Runge-Kutta (SVERK) methods.\nNumerical results demonstrate the high efficiency of the explicit MVERK\nintegrators and SVERK methods derived in this paper compared with the\nwell-known explicit ERK integrators for stiff systems or highly oscillatory\nproblems in the literature.",
    "descriptor": "",
    "authors": [
      "Bin Wang",
      "Xianfa Hu",
      "Xinyuan Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00685"
  },
  {
    "id": "arXiv:2210.00689",
    "title": "Multipod Convolutional Network",
    "abstract": "In this paper, we introduce a convolutional network which we call MultiPodNet\nconsisting of a combination of two or more convolutional networks which process\nthe input image in parallel to achieve the same goal. Output feature maps of\nparallel convolutional networks are fused at the fully connected layer of the\nnetwork. We experimentally observed that three parallel pod networks\n(TripodNet) produce the best results in commonly used object recognition\ndatasets. Baseline pod networks can be of any type. In this paper, we use\nResNets as baseline networks and their inputs are augmented image patches. The\nnumber of parameters of the TripodNet is about three times that of a single\nResNet. We train the TripodNet using the standard backpropagation type\nalgorithms. In each individual ResNet, parameters are initialized with\ndifferent random numbers during training. The TripodNet achieved\nstate-of-the-art performance on CIFAR-10 and ImageNet datasets. For example, it\nimproved the accuracy of a single ResNet from 91.66% to 92.47% under the same\ntraining process on the CIFAR-10 dataset.",
    "descriptor": "",
    "authors": [
      "Hongyi Pan",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00689"
  },
  {
    "id": "arXiv:2210.00690",
    "title": "Taming Fat-Tailed (\"Heavier-Tailed'' with Potentially Infinite Variance)  Noise in Federated Learning",
    "abstract": "A key assumption in most existing works on FL algorithms' convergence\nanalysis is that the noise in stochastic first-order information has a finite\nvariance. Although this assumption covers all light-tailed (i.e.,\nsub-exponential) and some heavy-tailed noise distributions (e.g., log-normal,\nWeibull, and some Pareto distributions), it fails for many fat-tailed noise\ndistributions (i.e., ``heavier-tailed'' with potentially infinite variance)\nthat have been empirically observed in the FL literature. To date, it remains\nunclear whether one can design convergent algorithms for FL systems that\nexperience fat-tailed noise. This motivates us to fill this gap in this paper\nby proposing an algorithmic framework called FAT-Clipping (\\ul{f}ederated\n\\ul{a}veraging with \\ul{t}wo-sided learning rates and \\ul{clipping}), which\ncontains two variants: FAT-Clipping per-round (FAT-Clipping-PR) and\nFAT-Clipping per-iteration (FAT-Clipping-PI). Specifically, for the largest\n$\\alpha \\in (1,2]$ such that the fat-tailed noise in FL still has a bounded\n$\\alpha$-moment, we show that both variants achieve\n$\\mathcal{O}((mT)^{\\frac{2-\\alpha}{\\alpha}})$ and\n$\\mathcal{O}((mT)^{\\frac{1-\\alpha}{3\\alpha-2}})$ convergence rates in the\nstrongly-convex and general non-convex settings, respectively, where $m$ and\n$T$ are the numbers of clients and communication rounds. Moreover, at the\nexpense of more clipping operations compared to FAT-Clipping-PR,\nFAT-Clipping-PI further enjoys a linear speedup effect with respect to the\nnumber of local updates at each client and being lower-bound-matching (i.e.,\norder-optimal). Collectively, our results advance the understanding of\ndesigning efficient algorithms for FL systems that exhibit fat-tailed\nfirst-order oracle information.",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Haibo Yang",
      "Peiwen Qiu",
      "Jia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00690"
  },
  {
    "id": "arXiv:2210.00698",
    "title": "NAS-based Recursive Stage Partial Network (RSPNet) for Light-Weight  Semantic Segmentation",
    "abstract": "Current NAS-based semantic segmentation methods focus on accuracy\nimprovements rather than light-weight design. In this paper, we proposed a\ntwo-stage framework to design our NAS-based RSPNet model for light-weight\nsemantic segmentation. The first architecture search determines the inner cell\nstructure, and the second architecture search considers exponentially growing\npaths to finalize the outer structure of the network. It was shown in the\nliterature that the fusion of high- and low-resolution feature maps produces\nstronger representations. To find the expected macro structure without manual\ndesign, we adopt a new path-attention mechanism to efficiently search for\nsuitable paths to fuse useful information for better segmentation. Our search\nfor repeatable micro-structures from cells leads to a superior network\narchitecture in semantic segmentation. In addition, we propose an RSP\n(recursive Stage Partial) architecture to search a light-weight design for\nNAS-based semantic segmentation. The proposed architecture is very efficient,\nsimple, and effective that both the macro- and micro- structure searches can be\ncompleted in five days of computation on two V100 GPUs. The light-weight NAS\narchitecture with only 1/4 parameter size of SoTA architectures can achieve\nSoTA performance on semantic segmentation on the Cityscapes dataset without\nusing any backbones.",
    "descriptor": "",
    "authors": [
      "Yi-Chun Wang",
      "Jun-Wei Hsieh",
      "Ming-Ching Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00698"
  },
  {
    "id": "arXiv:2210.00700",
    "title": "Optimal Weight Adaptation of Model Predictive Control for Connected and  Automated Vehicles in Mixed Traffic with Bayesian Optimization",
    "abstract": "In this paper, we develop an optimal weight adaptation strategy of model\npredictive control (MPC) for connected and automated vehicles (CAVs) in mixed\ntraffic. Built upon our recent paper, we model the interaction between a CAV\nand a human-driven vehicle (HDV) as a simultaneous game and formulate a\ngame-theoretic MPC problem to find a Nash equilibrium of the game. In the MPC\nproblem, the weights in the HDV's objective function can be learned online\nusing moving horizon inverse reinforcement learning. Using Bayesian\noptimization, we propose a strategy to optimally adapt the weights in the CAV's\nobjective function given the HDV's objective weights so that the expected true\ncost when using MPC in simulations can be minimized. We validate the\neffectiveness of the derived optimal strategy by numerical simulations of a\nvehicle crossing example at an unsignalized intersection.",
    "descriptor": "\nComments: submitted to ACC 2023\n",
    "authors": [
      "Viet-Anh Le",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00700"
  },
  {
    "id": "arXiv:2210.00701",
    "title": "Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning  with Linear Function Approximation",
    "abstract": "We study the problem of deployment efficient reinforcement learning (RL) with\nlinear function approximation under the \\emph{reward-free} exploration setting.\nThis is a well-motivated problem because deploying new policies is costly in\nreal-life RL applications. Under the linear MDP setting with feature dimension\n$d$ and planning horizon $H$, we propose a new algorithm that collects at most\n$\\widetilde{O}(\\frac{d^2H^5}{\\epsilon^2})$ trajectories within $H$ deployments\nto identify $\\epsilon$-optimal policy for any (possibly data-dependent) choice\nof reward functions. To the best of our knowledge, our approach is the first to\nachieve optimal deployment complexity and optimal $d$ dependence in sample\ncomplexity at the same time, even if the reward is known ahead of time. Our\nnovel techniques include an exploration-preserving policy discretization and a\ngeneralized G-optimal experiment design, which could be of independent\ninterest. Lastly, we analyze the related problem of regret minimization in\nlow-adaptive RL and provide information-theoretic lower bounds for switching\ncost and batch complexity.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00701"
  },
  {
    "id": "arXiv:2210.00704",
    "title": "Combined Dynamic Virtual Spatiotemporal Graph Mapping for Traffic  Prediction",
    "abstract": "The continuous expansion of the urban construction scale has recently\ncontributed to the demand for the dynamics of traffic intersections that are\nmanaged, making adaptive modellings become a hot topic. Existing deep learning\nmethods are powerful to fit complex heterogeneous graphs. However, they still\nhave drawbacks, which can be roughly classified into two categories, 1)\nspatiotemporal async-modelling approaches separately consider temporal and\nspatial dependencies, resulting in weak generalization and large instability\nwhile aggregating; 2) spatiotemporal sync-modelling is hard to capture\nlong-term temporal dependencies because of the local receptive field. In order\nto overcome above challenges, a \\textbf{C}ombined \\textbf{D}ynamic\n\\textbf{V}irtual spatiotemporal \\textbf{G}raph \\textbf{M}apping\n\\textbf{(CDVGM)} is proposed in this work. The contributions are the following:\n1) a dynamic virtual graph Laplacian ($DVGL$) is designed, which considers both\nthe spatial signal passing and the temporal features simultaneously; 2) the\nLong-term Temporal Strengthen model ($LT^2S$) for improving the stability of\ntime series forecasting; Extensive experiments demonstrate that CDVGM has\nexcellent performances of fast convergence speed and low resource consumption\nand achieves the current SOTA effect in terms of both accuracy and\ngeneralization. The code is available at\n\\hyperlink{https://github.com/Dandelionym/CDVGM.}{https://github.com/Dandelionym/CDVGM.}",
    "descriptor": "",
    "authors": [
      "Yingming Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00704"
  },
  {
    "id": "arXiv:2210.00705",
    "title": "SpeechCLIP: Integrating Speech with Pre-Trained Vision and Language  Model",
    "abstract": "Data-driven speech processing models usually perform well with a large amount\nof text supervision, but collecting transcribed speech data is costly.\nTherefore, we propose SpeechCLIP, a novel framework bridging speech and text\nthrough images to enhance speech models without transcriptions. We leverage\nstate-of-the-art pre-trained HuBERT and CLIP, aligning them via paired images\nand spoken captions with minimal fine-tuning. SpeechCLIP outperforms prior\nstate-of-the-art on image-speech retrieval and performs zero-shot speech-text\nretrieval without direct supervision from transcriptions. Moreover, SpeechCLIP\ncan directly retrieve semantically related keywords from speech.",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Yi-Jen Shih",
      "Hsuan-Fu Wang",
      "Heng-Jui Chang",
      "Layne Berry",
      "Hung-yi Lee",
      "David Harwath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.00705"
  },
  {
    "id": "arXiv:2210.00706",
    "title": "Information-Theoretic Analysis of Unsupervised Domain Adaptation",
    "abstract": "This paper uses information-theoretic tools to analyze the generalization\nerror in unsupervised domain adaptation (UDA). We present novel upper bounds\nfor two notions of generalization errors. The first notion measures the gap\nbetween the population risk in the target domain and that in the source domain,\nand the second measures the gap between the population risk in the target\ndomain and the empirical risk in the source domain. While our bounds for the\nfirst kind of error are in line with the traditional analysis and give similar\ninsights, our bounds on the second kind of error are algorithm-dependent, which\nalso provide insights into algorithm designs. Specifically, we present two\nsimple techniques for improving generalization in UDA and validate them\nexperimentally.",
    "descriptor": "",
    "authors": [
      "Ziqiao Wang",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00706"
  },
  {
    "id": "arXiv:2210.00707",
    "title": "Theme and Topic: How Qualitative Research and Topic Modeling Can Be  Brought Together",
    "abstract": "Qualitative research is an approach to understanding social phenomenon based\naround human interpretation of data, particularly text. Probabilistic topic\nmodelling is a machine learning approach that is also based around the analysis\nof text and often is used to in order to understand social phenomena. Both of\nthese approaches aim to extract important themes or topics in a textual corpus\nand therefore we may see them as analogous to each other. However there are\nalso considerable differences in how the two approaches function. One is a\nhighly human interpretive process, the other is automated and statistical. In\nthis paper we use this analogy as the basis for our Theme and Topic system, a\ntool for qualitative researchers to conduct textual research that integrates\ntopic modelling into an accessible interface. This is an example of a more\ngeneral approach to the design of interactive machine learning systems in which\nexisting human professional processes can be used as the model for processes\ninvolving machine learning. This has the particular benefit of providing a\nfamiliar approach to existing professionals, that may can make machine learning\nseem less alien and easier to learn. Our design approach has two elements. We\nfirst investigate the steps professionals go through when performing tasks and\ndesign a workflow for Theme and Topic that integrates machine learning. We then\ndesigned interfaces for topic modelling in which familiar concepts from\nqualitative research are mapped onto machine learning concepts. This makes\nthese the machine learning concepts more familiar and easier to learn for\nqualitative researchers.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Marco Gillies",
      "Dhiraj Murthy",
      "Harry Brenton",
      "Rapheal Olaniyan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00707"
  },
  {
    "id": "arXiv:2210.00708",
    "title": "EraseNet: A Recurrent Residual Network for Supervised Document Cleaning",
    "abstract": "Document denoising is considered one of the most challenging tasks in\ncomputer vision. There exist millions of documents that are still to be\ndigitized, but problems like document degradation due to natural and man-made\nfactors make this task very difficult. This paper introduces a supervised\napproach for cleaning dirty documents using a new fully convolutional\nauto-encoder architecture. This paper focuses on restoring documents with\ndiscrepancies like deformities caused due to aging of a document, creases left\non the pages that were xeroxed, random black patches, lightly visible text,\netc., and also improving the quality of the image for better optical character\nrecognition system (OCR) performance. Removing noise from scanned documents is\na very important step before the documents as this noise can severely affect\nthe performance of an OCR system. The experiments in this paper have shown\npromising results as the model is able to learn a variety of ordinary as well\nas unusual noises and rectify them efficiently.",
    "descriptor": "\nComments: 10 pages, 5 figures, attempting for publication in International Journal on Document Analysis and Recognition (IJDAR)\n",
    "authors": [
      "Yashowardhan Shinde",
      "Kishore Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.00708"
  },
  {
    "id": "arXiv:2210.00712",
    "title": "PSENet: Progressive Self-Enhancement Network for Unsupervised  Extreme-Light Image Enhancement",
    "abstract": "The extremes of lighting (e.g. too much or too little light) usually cause\nmany troubles for machine and human vision. Many recent works have mainly\nfocused on under-exposure cases where images are often captured in low-light\nconditions (e.g. nighttime) and achieved promising results for enhancing the\nquality of images. However, they are inferior to handling images under\nover-exposure. To mitigate this limitation, we propose a novel unsupervised\nenhancement framework which is robust against various lighting conditions while\ndoes not require any well-exposed images to serve as the ground-truths. Our\nmain concept is to construct pseudo-ground-truth images synthesized from\nmultiple source images that simulate all potential exposure scenarios to train\nthe enhancement network. Our extensive experiments show that the proposed\napproach consistently outperforms the current state-of-the-art unsupervised\ncounterparts in several public datasets in terms of both quantitative metrics\nand qualitative results. Our code is available at\nhttps://github.com/VinAIResearch/PSENet-Image-Enhancement.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Hue Nguyen",
      "Diep Tran",
      "Khoi Nguyen",
      "Rang Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00712"
  },
  {
    "id": "arXiv:2210.00713",
    "title": "Efficient Meta-Learning for Continual Learning with Taylor Expansion  Approximation",
    "abstract": "Continual learning aims to alleviate catastrophic forgetting when handling\nconsecutive tasks under non-stationary distributions. Gradient-based\nmeta-learning algorithms have shown the capability to implicitly solve the\ntransfer-interference trade-off problem between different examples. However,\nthey still suffer from the catastrophic forgetting problem in the setting of\ncontinual learning, since the past data of previous tasks are no longer\navailable. In this work, we propose a novel efficient meta-learning algorithm\nfor solving the online continual learning problem, where the regularization\nterms and learning rates are adapted to the Taylor approximation of the\nparameter's importance to mitigate forgetting. The proposed method expresses\nthe gradient of the meta-loss in closed-form and thus avoid computing\nsecond-order derivative which is computationally inhibitable. We also use\nProximal Gradient Descent to further improve computational efficiency and\naccuracy. Experiments on diverse benchmarks show that our method achieves\nbetter or on-par performance and much higher efficiency compared to the\nstate-of-the-art approaches.",
    "descriptor": "\nComments: Accepted by the 2022 International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Xiaohan Zou",
      "Tong Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00713"
  },
  {
    "id": "arXiv:2210.00714",
    "title": "It's Time to Replace TCP in the Datacenter",
    "abstract": "In spite of its long and successful history, TCP is a poor transport protocol\nfor modern datacenters. Every significant element of TCP, from its stream\norientation to its expectation of in-order packet delivery, is wrong for the\ndatacenter. It is time to recognize that TCP's problems are too fundamental and\ninterrelated to be fixed; the only way to harness the full performance\npotential of modern networks is to introduce a new transport protocol into the\ndatacenter. Homa demonstrates that it is possible to create a transport\nprotocol that avoids all of TCP's problems. Although Homa is not API-compatible\nwith TCP, it should be possible to bring it into widespread usage by\nintegrating it with RPC frameworks.",
    "descriptor": "",
    "authors": [
      "John Ousterhout"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.00714"
  },
  {
    "id": "arXiv:2210.00715",
    "title": "WorldGen: A Large Scale Generative Simulator",
    "abstract": "In the era of deep learning, data is the critical determining factor in the\nperformance of neural network models. Generating large datasets suffers from\nvarious difficulties such as scalability, cost efficiency and photorealism. To\navoid expensive and strenuous dataset collection and annotations, researchers\nhave inclined towards computer-generated datasets. Although, a lack of\nphotorealism and a limited amount of computer-aided data, has bounded the\naccuracy of network predictions.\nTo this end, we present WorldGen -- an open source framework to autonomously\ngenerate countless structured and unstructured 3D photorealistic scenes such as\ncity view, object collection, and object fragmentation along with its rich\nground truth annotation data. WorldGen being a generative model gives the user\nfull access and control to features such as texture, object structure, motion,\ncamera and lens properties for better generalizability by diminishing the data\nbias in the network. We demonstrate the effectiveness of WorldGen by presenting\nan evaluation on deep optical flow. We hope such a tool can open doors for\nfuture research in a myriad of domains related to robotics and computer vision\nby reducing manual labor and the cost of acquiring rich and high-quality data.",
    "descriptor": "",
    "authors": [
      "Chahat Deep Singh",
      "Riya Kumari",
      "Cornelia Ferm\u00fcller",
      "Nitin J. Sanket",
      "Yiannis Aloimonos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00715"
  },
  {
    "id": "arXiv:2210.00716",
    "title": "Deep Physiological Sensing Toolbox",
    "abstract": "Camera physiological measurement is a fast growing field of computer vision.\nRemote photoplethysmography (rPPG) uses video cameras (imagers) to measure the\nperipheral blood volume pulse (BVP). Simply, this enables heart rate\nmeasurement via webcams, smartphone cameras and many other imaging devices. The\ncurrent state-of-the-art methods are supervised deep neural architectures that\nhave large numbers of parameters and a signal number of hyperparameters.\nReplication of results and benchmarking of new models is critical for\nscientific progress. However, as with many other applications of deep learning,\nreliable codebases are not easy to find. We present a comprehensive toolbox,\nrPPG-Toolbox, containing code for training and evaluating unsupervised and\nsupervised rPPG models: https://github.com/ubicomplab/rPPG-Toolbox",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Xiaoyu Zhang",
      "Girish Narayanswamy",
      "Yuzhe Zhang",
      "Yuntao Wang",
      "Shwetak Patel",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00716"
  },
  {
    "id": "arXiv:2210.00717",
    "title": "Future of industrial assembly: Intelligent Reconfigurable & Repurposable  Adaptive Assembly (IRRAA)",
    "abstract": "Assembly, the process of integrating parts and components into usable\nproducts, is a key industrial process to achieve finished goods. Driven by\nmarket demographics and technological advancements, industrial assembly has\nevolved through several phases i.e. craftmanship, bench assembly, assembly\nlines and flexible assembly cells. Due to the complexity and variety of\nassembly tasks, besides significant advancement of automation technologies in\nother manufacturing activities, humans are still considered vital for assembly\noperations. The rationalization of manufacturing automation has considerably\nremained away from assembly systems. The advancement in assembly has only been\nin terms of better scheduling of work tasks and avoiding of wastes. With smart\nmanufacturing technologies such as collaborative robots, additive\nmanufacturing, and digital twins, the opportunities have arisen for the next\nreshaping of assembly systems. The new paradigm promises a higher degree of\nautomation yet remaining flexible. This may result into a new manufacturing\nparadigm driven by the advancement of new technologies, new customer\nexpectations and by establishing new kinds of manufacturing systems. This study\nexplores the future collaborative assembly cells, presents a generic framework\nto develop them and the basic building blocks.",
    "descriptor": "",
    "authors": [
      "Ali Ahmad Malik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00717"
  },
  {
    "id": "arXiv:2210.00719",
    "title": "To Improve Is to Change: Towards Improving Mood Prediction by Learning  Changes in Emotion",
    "abstract": "Although the terms mood and emotion are closely related and often used\ninterchangeably, they are distinguished based on their duration, intensity and\nattribution. To date, hardly any computational models have (a) examined mood\nrecognition, and (b) modelled the interplay between mood and emotional state in\ntheir analysis. In this paper, as a first step towards mood prediction, we\npropose a framework that utilises both dominant emotion (or mood) labels, and\nemotional change labels on the AFEW-VA database. Experiments evaluating\nunimodal (trained only using mood labels) and multimodal (trained with both\nmood and emotion change labels) convolutional neural networks confirm that\nincorporating emotional change information in the network training process can\nsignificantly improve the mood prediction performance, thus highlighting the\nimportance of modelling emotion and mood simultaneously for improved\nperformance in affective state recognition.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Soujanya Narayana",
      "Ramanathan Subramanian",
      "Ibrahim Radwan",
      "Roland Goecke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00719"
  },
  {
    "id": "arXiv:2210.00720",
    "title": "Complexity-Based Prompting for Multi-Step Reasoning",
    "abstract": "We study the task of prompting large-scale language models to perform\nmulti-step reasoning. Existing work shows that when prompted with a chain of\nthoughts (CoT), sequences of short sentences describing intermediate reasoning\nsteps towards a final answer, large language models can generate new reasoning\nchains and predict answers for new inputs. A central question is which\nreasoning examples make the most effective prompts. In this work, we propose\ncomplexity-based prompting, a simple and effective example selection scheme for\nmulti-step reasoning. We show that prompts with higher reasoning complexity,\ni.e., chains with more reasoning steps, achieve substantially better\nperformance on math word reasoning tasks over strong baselines. We further\nextend our complexity-based criteria from prompting (selecting inputs) to\ndecoding (selecting outputs), where we sample multiple reasoning chains from\nthe model, then choose the majority of generated answers from complex reasoning\nchains (over simple chains). When used to prompt GPT-3, our approach\nsubstantially improves multi-step reasoning accuracy, with an 8.6% absolute\nimprovement on GSM8K, and 6.4% on MathQA. Compared with existing example\nselection schemes like manual tuning or retrieval-based selection, selection\nbased on reasoning complexity is intuitive, easy to implement, and\nannotation-efficient. Further results demonstrate the robustness of our methods\nunder format perturbation and distribution shift.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yao Fu",
      "Hao Peng",
      "Ashish Sabharwal",
      "Peter Clark",
      "Tushar Khot"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00720"
  },
  {
    "id": "arXiv:2210.00721",
    "title": "Efficient acoustic feature transformation in mismatched environments  using a Guided-GAN",
    "abstract": "We propose a new framework to improve automatic speech recognition (ASR)\nsystems in resource-scarce environments using a generative adversarial network\n(GAN) operating on acoustic input features. The GAN is used to enhance the\nfeatures of mismatched data prior to decoding, or can optionally be used to\nfine-tune the acoustic model. We achieve improvements that are comparable to\nmulti-style training (MTR), but at a lower computational cost. With less than\none hour of data, an ASR system trained on good quality data, and evaluated on\nmismatched audio is improved by between 11.5% and 19.7% relative word error\nrate (WER). Experiments demonstrate that the framework can be very useful in\nunder-resourced environments where training data and computational resources\nare limited. The GAN does not require parallel training data, because it\nutilises a baseline acoustic model to provide an additional loss term that\nguides the generator to create acoustic features that are better classified by\nthe baseline.",
    "descriptor": "\nComments: 20 pages, 8 figures, 9 tables\n",
    "authors": [
      "Walter Heymans",
      "Marelie H. Davel",
      "Charl van Heerden"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.00721"
  },
  {
    "id": "arXiv:2210.00722",
    "title": "GenDexGrasp: Generalizable Dexterous Grasping",
    "abstract": "Generating dexterous grasping has been a long-standing and challenging\nrobotic task. Despite recent progress, existing methods primarily suffer from\ntwo issues. First, most prior arts focus on a specific type of robot hand,\nlacking the generalizable capability of handling unseen ones. Second, prior\narts oftentimes fail to rapidly generate diverse grasps with a high success\nrate. To jointly tackle these challenges with a unified solution, we propose\nGenDexGrasp, a novel hand-agnostic grasping algorithm for generalizable\ngrasping. GenDexGrasp is trained on our proposed large-scale multi-hand\ngrasping dataset MultiDex synthesized with force closure optimization. By\nleveraging the contact map as a hand-agnostic intermediate representation,\nGenDexGrasp efficiently generates diverse and plausible grasping poses with a\nhigh success rate and can transfer among diverse multi-fingered robotic hands.\nCompared with previous methods, GenDexGrasp achieves a three-way trade-off\namong success rate, inference speed, and diversity. Code is available at\nhttps://github.com/tengyu-liu/GenDexGrasp.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Puhao Li",
      "Tengyu Liu",
      "Yuyang Li",
      "Yiran Geng",
      "Yixin Zhu",
      "Yaodong Yang",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00722"
  },
  {
    "id": "arXiv:2210.00723",
    "title": "Data-Driven Convex Approach to Off-road Navigation via Linear Transfer  Operators",
    "abstract": "We consider the problem of optimal navigation control design for navigation\non off-road terrain. We use traversability measure to characterize the degree\nof difficulty of navigation on the off-road terrain. The traversability measure\ncaptures the property of terrain essential for navigation, such as elevation\nmap, terrain roughness, slope, and terrain texture. The terrain with the\npresence or absence of obstacles becomes a particular case of the proposed\ntraversability measure. We provide a convex formulation to the off-road\nnavigation problem by lifting the problem to the density space using the linear\nPerron-Frobenius (P-F) operator. The convex formulation leads to an\ninfinite-dimensional optimal navigation problem for control synthesis. The\nfinite-dimensional approximation of the infinite-dimensional convex problem is\nconstructed using data. We use a computational framework involving the Koopman\noperator and the duality between the Koopman and P-F operator for the\ndata-driven approximation. This makes our proposed approach data-driven and can\nbe applied in cases where an explicit system model is unavailable. Finally, we\ndemonstrate the application of the developed framework for the navigation of\nvehicle dynamics with Dubin's car model.",
    "descriptor": "",
    "authors": [
      "Joseph Moyalan",
      "Yongxin Chen",
      "Umesh Vaidya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00723"
  },
  {
    "id": "arXiv:2210.00724",
    "title": "Inattentive in social, active in mind: VR-based design intervention for  imagining desirable possibilities in the public space",
    "abstract": "The metro as a form of public transportation is an important urban\ninfrastructure that takes a large population from place A to B every day. To\nachieve that, it is primarily designed for extreme functionality and\nefficiency. However, in terms of experiential aesthetics, the metro is seldom\npeople s favourite place. When this modern infrastructure succeeds in serving\nurban mobility with high performance and efficiency, passengers seem to want\nmore than the guaranteed functional performance. Recently, with the emergence\nof VR technologies, increasing efforts from design and HCI communities look at\nthe value of VR technology in enhancing commuting experiences, bringing new\npossibilities of interaction and activities, and potentially transforming\nsocial public spaces. This study investigates how and why VR technology could\nbe integrated with a metro ride. We experimented with ten passengers by showing\nthem three 360 videos during their metro ride. The results show the narrative\ndriven scene is most desirable. Despite wearing a VR headset might cause\nanxiety, our findings indicate a high level of acceptance towards VR\nexperiences based on the finding that it does not challenge the normative\nbehaviours of being a passenger inattentive in social, active in mind and\nfurther can enhance the experience. As the takeaway, we propose three\nstrategies of VR content tailored for the metro context in which passengers\nwould find a role participating in the virtual scene and turn the scene to one\ns own story, and at the same time, maintain physically constrained.",
    "descriptor": "\nComments: IASDR conference 2021\n",
    "authors": [
      "Yiying Wu",
      "Miikka J. Lehtonen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00724"
  },
  {
    "id": "arXiv:2210.00725",
    "title": "Unpacking Cultural Perceptions of Future Elder Care through Design  Fiction",
    "abstract": "We present a case using Design Fiction to unpack cultural perceptions of\nfuture elder care rooted in the Asian context of Singapore. We created two\ndesign fictions, addressing the tensions between filial piety and automated\ncare and the controversy of integrating elder care facilities into residential\ncommunities. The design fictions took the visual forms of a shopping web page\nand a petition site and the public were invited to make fictional decisions.\nReceived in total 109 responses, we identify the key tensions and value\nconflicts and illustrate them through visual narratives. Further, we propose\nthe Asian perspective of positioning relationships as the protagonist in\ncreating elder care design fiction.",
    "descriptor": "\nComments: IASDR conference 2021\n",
    "authors": [
      "Tse Pei Ng",
      "Jung-Joo Lee",
      "Yiying Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00725"
  },
  {
    "id": "arXiv:2210.00726",
    "title": "Statistical Efficiency of Score Matching: The View from Isoperimetry",
    "abstract": "Deep generative models parametrized up to a normalizing constant (e.g.\nenergy-based models) are difficult to train by maximizing the likelihood of the\ndata because the likelihood and/or gradients thereof cannot be explicitly or\nefficiently written down. Score matching is a training method, whereby instead\nof fitting the likelihood $\\log p(x)$ for the training data, we instead fit the\nscore function $\\nabla_x \\log p(x)$ -- obviating the need to evaluate the\npartition function. Though this estimator is known to be consistent, its\nunclear whether (and when) its statistical efficiency is comparable to that of\nmaximum likelihood -- which is known to be (asymptotically) optimal. We\ninitiate this line of inquiry in this paper, and show a tight connection\nbetween statistical efficiency of score matching and the isoperimetric\nproperties of the distribution being estimated -- i.e. the Poincar\\'e,\nlog-Sobolev and isoperimetric constant -- quantities which govern the mixing\ntime of Markov processes like Langevin dynamics. Roughly, we show that the\nscore matching estimator is statistically comparable to the maximum likelihood\nwhen the distribution has a small isoperimetric constant. Conversely, if the\ndistribution has a large isoperimetric constant -- even for simple families of\ndistributions like exponential families with rich enough sufficient statistics\n-- score matching will be substantially less efficient than maximum likelihood.\nWe suitably formalize these results both in the finite sample regime, and in\nthe asymptotic regime. Finally, we identify a direct parallel in the discrete\nsetting, where we connect the statistical properties of pseudolikelihood\nestimation with approximate tensorization of entropy and the Glauber dynamics.",
    "descriptor": "",
    "authors": [
      "Frederic Koehler",
      "Alexander Heckett",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00726"
  },
  {
    "id": "arXiv:2210.00728",
    "title": "Learning from the Dark: Boosting Graph Convolutional Neural Networks  with Diverse Negative Samples",
    "abstract": "Graph Convolutional Neural Networks (GCNs) has been generally accepted to be\nan effective tool for node representations learning. An interesting way to\nunderstand GCNs is to think of them as a message passing mechanism where each\nnode updates its representation by accepting information from its neighbours\n(also known as positive samples). However, beyond these neighbouring nodes,\ngraphs have a large, dark, all-but forgotten world in which we find the\nnon-neighbouring nodes (negative samples). In this paper, we show that this\ngreat dark world holds a substantial amount of information that might be useful\nfor representation learning. Most specifically, it can provide negative\ninformation about the node representations. Our overall idea is to select\nappropriate negative samples for each node and incorporate the negative\ninformation contained in these samples into the representation updates.\nMoreover, we show that the process of selecting the negative samples is not\ntrivial. Our theme therefore begins by describing the criteria for a good\nnegative sample, followed by a determinantal point process algorithm for\nefficiently obtaining such samples. A GCN, boosted by diverse negative samples,\nthen jointly considers the positive and negative information when passing\nmessages. Experimental evaluations show that this idea not only improves the\noverall performance of standard representation learning but also significantly\nalleviates over-smoothing problems.",
    "descriptor": "",
    "authors": [
      "Wei Duan",
      "Junyu Xuan",
      "Maoying Qiao",
      "Jie Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00728"
  },
  {
    "id": "arXiv:2210.00729",
    "title": "Deep Spatial Domain Generalization",
    "abstract": "Spatial autocorrelation and spatial heterogeneity widely exist in spatial\ndata, which make the traditional machine learning model perform badly. Spatial\ndomain generalization is a spatial extension of domain generalization, which\ncan generalize to unseen spatial domains in continuous 2D space. Specifically,\nit learns a model under varying data distributions that generalizes to unseen\ndomains. Although tremendous success has been achieved in domain\ngeneralization, there exist very few works on spatial domain generalization.\nThe advancement of this area is challenged by: 1) Difficulty in characterizing\nspatial heterogeneity, and 2) Difficulty in obtaining predictive models for\nunseen locations without training data. To address these challenges, this paper\nproposes a generic framework for spatial domain generalization. Specifically,\nWe develop the spatial interpolation graph neural network that handles spatial\ndata as a graph and learns the spatial embedding on each node and their\nrelationships. The spatial interpolation graph neural network infers the\nspatial embedding of an unseen location during the test phase. Then the spatial\nembedding of the target location is used to decode the parameters of the\ndownstream-task model directly on the target location. Finally, extensive\nexperiments on thirteen real-world datasets demonstrate the proposed method's\nstrength.",
    "descriptor": "",
    "authors": [
      "Dazhou Yu",
      "Guangji Bai",
      "Yun Li",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.00729"
  },
  {
    "id": "arXiv:2210.00733",
    "title": "A Dynamic Model for Bus Arrival Time Estimation based on Spatial  Patterns using Machine Learning",
    "abstract": "The notion of smart cities is being adapted globally to provide a better\nquality of living. A smart city's smart mobility component focuses on providing\nsmooth and safe commuting for its residents and promotes eco-friendly and\nsustainable alternatives such as public transit (bus). Among several smart\napplications, a system that provides up-to-the-minute information like bus\narrival, travel duration, schedule, etc., improves the reliability of public\ntransit services. Still, this application needs live information on traffic\nflow, accidents, events, and the location of the buses. Most cities lack the\ninfrastructure to provide these data. In this context, a bus arrival prediction\nmodel is proposed for forecasting the arrival time using limited data sets. The\nlocation data of public transit buses and spatial characteristics are used for\nthe study. One of the routes of Tumakuru city service, Tumakuru, India, is\nselected and divided into two spatial patterns: sections with intersections and\nsections without intersections. The machine learning model XGBoost is modeled\nfor both spatial patterns individually. A model to dynamically predict bus\narrival time is developed using the preceding trip information and the machine\nlearning model to estimate the arrival time at a downstream bus stop. The\nperformance of models is compared based on the R-squared values of the\npredictions made, and the proposed model established superior results. It is\nsuggested to predict bus arrival in the study area. The proposed model can also\nbe extended to other similar cities with limited traffic-related\ninfrastructure.",
    "descriptor": "",
    "authors": [
      "B. P. Ashwini",
      "R. Sumathi",
      "H. S. Sudhira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00733"
  },
  {
    "id": "arXiv:2210.00735",
    "title": "ScrollTest: Evaluating Scrolling Speed and Accuracy",
    "abstract": "Scrolling is an essential interaction technique enabling users to display\npreviously off-screen content. Existing evaluation models for scrolling are\noften entangled with the selection of content, e.g., when scrolling on the\nphone for reading. Furthermore, some evaluation models overlook whether the\nuser knows the target position. We have developed ScrollTest, a general-purpose\nevaluation tool for scrolling speed and accuracy that avoids the need for\nselection. We tested it across four dimensions: 11 different scrolling\ntechniques/devices, 5 frame heights, 13 scrolling distances, and 2 scrolling\nconditions (i.e., with or without knowing the target position). The results\nshow that flicking and two-finger scrolling are the fastest; flicking is also\nrelatively precise for scrolling to targets already onscreen, but pressing\narrow buttons on the scrollbar is the most accurate for scrolling to nearby\ntargets. Mathematical models of scrolling are highly linear when the target\nposition is unknown but like Fitts' law when known.",
    "descriptor": "",
    "authors": [
      "Chaoran Chen",
      "Brad A. Myers",
      "Cem Ergin",
      "Emily Porat",
      "Sijia Li",
      "Chun Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00735"
  },
  {
    "id": "arXiv:2210.00737",
    "title": "FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients",
    "abstract": "Federated Learning (FL) effectively protects client data privacy. However,\nclient absence or leaving during training can seriously degrade model\nperformances, particularly for unbalanced and non-IID client data. We address\nthis issue by generating data digests from the raw data and using them to guide\ntraining at the FL moderator. The proposed FL framework, called FedDig, can\ntolerate unexpected client absence in cross-silo scenarios while preserving\nclient data privacy because the digests de-identify the raw data by mixing\nencoded features in the features space. We evaluate FedDig using EMNIST,\nCIFAR-10, and CIFAR-100; the results consistently outperform against three\nbaseline algorithms (FedAvg, FedProx, and FedNova) by large margins in various\nclient absence scenarios.",
    "descriptor": "",
    "authors": [
      "Chih-Fan Hsu",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00737"
  },
  {
    "id": "arXiv:2210.00738",
    "title": "A Nontrivial Interplay between Triadic Closure, Preferential, and  Anti-Preferential Attachment: New Insights from Online Data",
    "abstract": "This paper presents an analysis of a temporal network that describes the\nsocial connections of a large-scale (~ 30,000) sample of online social network\nusers, inhabitants of a fixed city. We tested how the main network formation\ndeterminants - transitivity, preferential attachment, and social selection -\ncontribute to network evolution. Among other things, we found that opinion\nsocial selection does affect tie appearing whereas its impact on tie removing\nis rather unclear. We report that transitivity displayed the strongest effect\non network dynamics. Surprisingly, a closer look revealed an intriguing and\ncomplex interplay between the transitivity, preferential attachment, and\nanti-preferential attachment mechanisms. For a given pair of unconnected nodes,\nif they have no mutual connections, then the probability of tie creation goes\nup with the sum of node degrees - that is exactly what the preferential\nattachment mechanism is assumed to do. Instead, if the nodes have at least one\ncommon friend, then the highest probability of tie appearing is achieved if\nboth the nodes have only a few friends - a phenomenon that is called\nanti-preferential attachment. We attempted to explain this finding by appealing\nto the notions of social communities and leaders.",
    "descriptor": "\nComments: 7 figures and 2 tables in the main part of the manuscript, 11 figures and 1 table in appendix\n",
    "authors": [
      "Ivan V. Kozitsin",
      "Eduard R. Sayfulin",
      "Vyacheslav L. Goiko"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00738"
  },
  {
    "id": "arXiv:2210.00740",
    "title": "Heatmap Distribution Matching for Human Pose Estimation",
    "abstract": "For tackling the task of 2D human pose estimation, the great majority of the\nrecent methods regard this task as a heatmap estimation problem, and optimize\nthe heatmap prediction using the Gaussian-smoothed heatmap as the optimization\nobjective and using the pixel-wise loss (e.g. MSE) as the loss function. In\nthis paper, we show that optimizing the heatmap prediction in such a way, the\nmodel performance of body joint localization, which is the intrinsic objective\nof this task, may not be consistently improved during the optimization process\nof the heatmap prediction. To address this problem, from a novel perspective,\nwe propose to formulate the optimization of the heatmap prediction as a\ndistribution matching problem between the predicted heatmap and the dot\nannotation of the body joint directly. By doing so, our proposed method does\nnot need to construct the Gaussian-smoothed heatmap and can achieve a more\nconsistent model performance improvement during the optimization of the heatmap\nprediction. We show the effectiveness of our proposed method through extensive\nexperiments on the COCO dataset and the MPII dataset.v",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Haoxuan Qu",
      "Li Xu",
      "Yujun Cai",
      "Lin Geng Foo",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00740"
  },
  {
    "id": "arXiv:2210.00743",
    "title": "An Embarrassingly Simple Approach for Intellectual Property Rights  Protection on Recurrent Neural Networks",
    "abstract": "Capitalise on deep learning models, offering Natural Language Processing\n(NLP) solutions as a part of the Machine Learning as a Service (MLaaS) has\ngenerated handsome revenues. At the same time, it is known that the creation of\nthese lucrative deep models is non-trivial. Therefore, protecting these\ninventions intellectual property rights (IPR) from being abused, stolen and\nplagiarized is vital. This paper proposes a practical approach for the IPR\nprotection on recurrent neural networks (RNN) without all the bells and\nwhistles of existing IPR solutions. Particularly, we introduce the Gatekeeper\nconcept that resembles the recurrent nature in RNN architecture to embed keys.\nAlso, we design the model training scheme in a way such that the protected RNN\nmodel will retain its original performance iff a genuine key is presented.\nExtensive experiments showed that our protection scheme is robust and effective\nagainst ambiguity and removal attacks in both white-box and black-box\nprotection schemes on different RNN variants. Code is available at\nhttps://github.com/zhiqin1998/RecurrentIPR",
    "descriptor": "\nComments: Accepted at AACL-IJCNLP 2022\n",
    "authors": [
      "Zhi Qin Tan",
      "Hao Shan Wong",
      "Chee Seng Chan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00743"
  },
  {
    "id": "arXiv:2210.00750",
    "title": "Offline Reinforcement Learning with Differentiable Function  Approximation is Provably Efficient",
    "abstract": "Offline reinforcement learning, which aims at optimizing sequential\ndecision-making strategies with historical data, has been extensively applied\nin real-life applications. State-Of-The-Art algorithms usually leverage\npowerful function approximators (e.g. neural networks) to alleviate the sample\ncomplexity hurdle for better empirical performances. Despite the successes, a\nmore systematic understanding of the statistical complexity for function\napproximation remains lacking. Towards bridging the gap, we take a step by\nconsidering offline reinforcement learning with differentiable function class\napproximation (DFA). This function class naturally incorporates a wide range of\nmodels with nonlinear/nonconvex structures. Most importantly, we show offline\nRL with differentiable function approximation is provably efficient by\nanalyzing the pessimistic fitted Q-learning (PFQL) algorithm, and our results\nprovide the theoretical basis for understanding a variety of practical\nheuristics that rely on Fitted Q-Iteration style design. In addition, we\nfurther improve our guarantee with a tighter instance-dependent\ncharacterization. We hope our work could draw interest in studying\nreinforcement learning with differentiable function approximation beyond the\nscope of current research.",
    "descriptor": "",
    "authors": [
      "Ming Yin",
      "Mengdi Wang",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00750"
  },
  {
    "id": "arXiv:2210.00752",
    "title": "From Face to Natural Image: Learning Real Degradation for Blind Image  Super-Resolution",
    "abstract": "Designing proper training pairs is critical for super-resolving the\nreal-world low-quality (LQ) images, yet suffers from the difficulties in either\nacquiring paired ground-truth HQ images or synthesizing photo-realistic\ndegraded observations. Recent works mainly circumvent this by simulating the\ndegradation with handcrafted or estimated degradation parameters. However,\nexisting synthetic degradation models are incapable to model complicated real\ndegradation types, resulting in limited improvement on these scenarios, \\eg,\nold photos. Notably, face images, which have the same degradation process with\nthe natural images, can be robustly restored with photo-realistic textures by\nexploiting their specific structure priors. In this work, we use these\nreal-world LQ face images and their restored HQ counterparts to model the\ncomplex real degradation (namely ReDegNet), and then transfer it to HQ natural\nimages to synthesize their realistic LQ ones. Specifically, we take these\npaired HQ and LQ face images as inputs to explicitly predict the\ndegradation-aware and content-independent representations, which control the\ndegraded image generation. Subsequently, we transfer these real degradation\nrepresentations from face to natural images to synthesize the degraded LQ\nnatural images. Experiments show that our ReDegNet can well learn the real\ndegradation process from face images, and the restoration network trained with\nour synthetic pairs performs favorably against SOTAs. More importantly, our\nmethod provides a new manner to handle the unsynthesizable real-world scenarios\nby learning their degradation representations through face images within them,\nwhich can be used for specifically fine-tuning. The source code is available at\nhttps://github.com/csxmli2016/ReDegNet.",
    "descriptor": "\nComments: In ECCV 2022. Code is available at this https URL\n",
    "authors": [
      "Xiaoming Li",
      "Chaofeng Chen",
      "Xianhui Lin",
      "Wangmeng Zuo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00752"
  },
  {
    "id": "arXiv:2210.00753",
    "title": "Push-Pull: Characterizing the Adversarial Robustness for Audio-Visual  Active Speaker Detection",
    "abstract": "Audio-visual active speaker detection (AVASD) is well-developed, and now is\nan indispensable front-end for several multi-modal applications. However, to\nthe best of our knowledge, the adversarial robustness of AVASD models hasn't\nbeen investigated, not to mention the effective defense against such attacks.\nIn this paper, we are the first to reveal the vulnerability of AVASD models\nunder audio-only, visual-only, and audio-visual adversarial attacks through\nextensive experiments. What's more, we also propose a novel audio-visual\ninteraction loss (AVIL) for making attackers difficult to find feasible\nadversarial examples under an allocated attack budget. The loss aims at pushing\nthe inter-class embeddings to be dispersed, namely non-speech and speech\nclusters, sufficiently disentangled, and pulling the intra-class embeddings as\nclose as possible to keep them compact. Experimental results show the AVIL\noutperforms the adversarial training by 33.14 mAP (%) under multi-modal\nattacks.",
    "descriptor": "\nComments: Accepted by SLT 2022\n",
    "authors": [
      "Xuanjun Chen",
      "Haibin Wu",
      "Helen Meng",
      "Hung-yi Lee",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.00753"
  },
  {
    "id": "arXiv:2210.00754",
    "title": "Lexical semantics enhanced neural word embeddings",
    "abstract": "Current breakthroughs in natural language processing have benefited\ndramatically from neural language models, through which distributional\nsemantics can leverage neural data representations to facilitate downstream\napplications. Since neural embeddings use context prediction on word\nco-occurrences to yield dense vectors, they are inevitably prone to capture\nmore semantic association than semantic similarity. To improve vector space\nmodels in deriving semantic similarity, we post-process neural word embeddings\nthrough deep metric learning, through which we can inject lexical-semantic\nrelations, including syn/antonymy and hypo/hypernymy, into a distributional\nspace. We introduce hierarchy-fitting, a novel semantic specialization approach\nto modelling semantic similarity nuances inherently stored in the IS-A\nhierarchies. Hierarchy-fitting attains state-of-the-art results on the common-\nand rare-word benchmark datasets for deriving semantic similarity from neural\nword embeddings. It also incorporates an asymmetric distance function to\nspecialize hypernymy's directionality explicitly, through which it\nsignificantly improves vanilla embeddings in multiple evaluation tasks of\ndetecting hypernymy and directionality without negative impacts on semantic\nsimilarity judgement. The results demonstrate the efficacy of hierarchy-fitting\nin specializing neural embeddings with semantic relations in late fusion,\npotentially expanding its applicability to aggregating heterogeneous data and\nvarious knowledge resources for learning multimodal semantic spaces.",
    "descriptor": "",
    "authors": [
      "Dongqiang Yang",
      "Ning Li",
      "Li Zou",
      "Hongwei Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00754"
  },
  {
    "id": "arXiv:2210.00755",
    "title": "D\u00e9tection de petites cibles par apprentissage profond et crit\u00e8re a  contrario",
    "abstract": "Small target detection is an essential yet challenging task in defense\napplications, since differentiating low-contrast targets from natural textured\nand noisy environment remains difficult. To better take into account the\ncontextual information, we propose to explore deep learning approaches based on\nattention mechanisms. Specifically, we propose a customized version of\nTransUnet including channel attention, which has shown a significant\nimprovement in performance. Moreover, the lack of annotated data induces weak\ndetection precision, leading to many false alarms. We thus explore a contrario\nmethods in order to select meaningful potential targets detected by a weak deep\nlearning training.\n--\nLa d\\'etection de petites cibles est une probl\\'ematique d\\'elicate mais\nessentielle dans le domaine de la d\\'efense, notamment lorsqu'il s'agit de\ndiff\\'erencier ces cibles d'un fond bruit\\'e ou textur\\'e, ou lorsqu'elles sont\nde faible contraste. Pour mieux prendre en compte les informations\ncontextuelles, nous proposons d'explorer diff\\'erentes approches de\nsegmentation par apprentissage profond, dont certaines bas\\'ees sur les\nm\\'ecanismes d'attention. Nous proposons \\'egalement d'inclure un module\nd'attention par canal au TransUnet, r\\'eseau \\`a l'\\'etat de l'art, ce qui\npermet d'am\\'eliorer significativement les performances. Par ailleurs, le\nmanque de donn\\'ees annot\\'ees induit une perte en pr\\'ecision lors des\nd\\'etections, conduisant \\`a de nombreuses fausses alarmes non pertinentes.\nNous explorons donc des m\\'ethodes a contrario afin de s\\'electionner les\ncibles les plus significatives d\\'etect\\'ees par un r\\'eseau entra\\^in\\'e avec\npeu de donn\\'ees.",
    "descriptor": "\nComments: 4 pages, in French\n",
    "authors": [
      "Alina Ciocarlan",
      "Sylvie Le Hegarat-Mascle",
      "Sidonie Lefebvre",
      "Clara Barbanson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00755"
  },
  {
    "id": "arXiv:2210.00756",
    "title": "CERBERUS: Simple and Effective All-In-One Automotive Perception Model  with Multi Task Learning",
    "abstract": "Perceiving the surrounding environment is essential for enabling autonomous\nor assisted driving functionalities. Common tasks in this domain include\ndetecting road users, as well as determining lane boundaries and classifying\ndriving conditions. Over the last few years, a large variety of powerful Deep\nLearning models have been proposed to address individual tasks of camera-based\nautomotive perception with astonishing performances. However, the limited\ncapabilities of in-vehicle embedded computing platforms cannot cope with the\ncomputational effort required to run a heavy model for each individual task. In\nthis work, we present CERBERUS (CEnteR Based End-to-end peRception Using a\nSingle model), a lightweight model that leverages a multitask-learning approach\nto enable the execution of multiple perception tasks at the cost of a single\ninference. The code will be made publicly available at\nhttps://github.com/cscribano/CERBERUS",
    "descriptor": "\nComments: Presented at IROS 2022 PNARUDE Workshop\n",
    "authors": [
      "Carmelo Scribano",
      "Giorgia Franchini",
      "Ignacio Sa\u00f1udo Olmedo",
      "Marko Bertogna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00756"
  },
  {
    "id": "arXiv:2210.00757",
    "title": "Fully Transformer Network for Change Detection of Remote Sensing Images",
    "abstract": "Recently, change detection (CD) of remote sensing images have achieved great\nprogress with the advances of deep learning. However, current methods generally\ndeliver incomplete CD regions and irregular CD boundaries due to the limited\nrepresentation ability of the extracted visual features. To relieve these\nissues, in this work we propose a novel learning framework named Fully\nTransformer Network (FTN) for remote sensing image CD, which improves the\nfeature extraction from a global view and combines multi-level visual features\nin a pyramid manner. More specifically, the proposed framework first utilizes\nthe advantages of Transformers in long-range dependency modeling. It can help\nto learn more discriminative global-level features and obtain complete CD\nregions. Then, we introduce a pyramid structure to aggregate multi-level visual\nfeatures from Transformers for feature enhancement. The pyramid structure\ngrafted with a Progressive Attention Module (PAM) can improve the feature\nrepresentation ability with additional interdependencies through channel\nattentions. Finally, to better train the framework, we utilize the\ndeeply-supervised learning with multiple boundaryaware loss functions.\nExtensive experiments demonstrate that our proposed method achieves a new\nstate-of-the-art performance on four public CD benchmarks. For model\nreproduction, the source code is released at https://github.com/AI-Zhpp/FTN.",
    "descriptor": "\nComments: 18 pages, 6 figures and 5 tables. This work will appear in ACCV2022 as a poster paper\n",
    "authors": [
      "Tianyu Yan",
      "Zifu Wan",
      "Pingping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.00757"
  },
  {
    "id": "arXiv:2210.00758",
    "title": "Reflections on existential types",
    "abstract": "Existential types are reconstructed in terms of small reflective subuniverses\nand dependent sums. The folklore decomposition detailed here gives rise to a\nparticularly simple account of first-class modules as a mode of use of\ntraditional second-class modules in connection with the modal operator induced\nby a reflective subuniverse, leading to a semantic justification for the rules\nof first-class modules in languages like OCaml and MoscowML. Additionally, we\nexpose several constructions that give rise to semantic models of ML-style\nprogramming languages with both first-class modules and realistic computational\neffects, culminating in a model that accommodates higher-order first-class\nrecursive modules and higher-order store.",
    "descriptor": "",
    "authors": [
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00758"
  },
  {
    "id": "arXiv:2210.00762",
    "title": "Meta-Learning Priors for Safe Bayesian Optimization",
    "abstract": "In robotics, optimizing controller parameters under safety constraints is an\nimportant challenge. Safe Bayesian optimization (BO) quantifies uncertainty in\nthe objective and constraints to safely guide exploration in such settings.\nHand-designing a suitable probabilistic model can be challenging, however. In\nthe presence of unknown safety constraints, it is crucial to choose reliable\nmodel hyper-parameters to avoid safety violations. Here, we propose a\ndata-driven approach to this problem by meta-learning priors for safe BO from\noffline data. We build on a meta-learning algorithm, F-PACOH, capable of\nproviding reliable uncertainty quantification in settings of data scarcity. As\ncore contribution, we develop a novel framework for choosing safety-compliant\npriors in a data-riven manner via empirical uncertainty metrics and a frontier\nsearch algorithm. On benchmark functions and a high-precision motion system, we\ndemonstrate that our meta-learned priors accelerate the convergence of safe BO\napproaches while maintaining safety.",
    "descriptor": "\nComments: Accepted for the Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Jonas Rothfuss",
      "Christopher Koenig",
      "Alisa Rupenyan",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00762"
  },
  {
    "id": "arXiv:2210.00764",
    "title": "Relational program synthesis with numerical reasoning",
    "abstract": "Program synthesis approaches struggle to learn programs with numerical\nvalues. An especially difficult problem is learning continuous values over\nmultiple examples, such as intervals. To overcome this limitation, we introduce\nan inductive logic programming approach which combines relational learning with\nnumerical reasoning. Our approach, which we call NUMSYNTH, uses satisfiability\nmodulo theories solvers to efficiently learn programs with numerical values.\nOur approach can identify numerical values in linear arithmetic fragments, such\nas real difference logic, and from infinite domains, such as real numbers or\nintegers. Our experiments on four diverse domains, including game playing and\nprogram synthesis, show that our approach can (i) learn programs with numerical\nvalues from linear arithmetical reasoning, and (ii) outperform existing\napproaches in terms of predictive accuracies and learning times.",
    "descriptor": "",
    "authors": [
      "C\u00e9line Hocquette",
      "Andrew Cropper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.00764"
  },
  {
    "id": "arXiv:2210.00765",
    "title": "Few-Shot Segmentation via Rich Prototype Generation and Recurrent  Prediction Enhancement",
    "abstract": "Prototype learning and decoder construction are the keys for few-shot\nsegmentation. However, existing methods use only a single prototype generation\nmode, which can not cope with the intractable problem of objects with various\nscales. Moreover, the one-way forward propagation adopted by previous methods\nmay cause information dilution from registered features during the decoding\nprocess. In this research, we propose a rich prototype generation module (RPGM)\nand a recurrent prediction enhancement module (RPEM) to reinforce the prototype\nlearning paradigm and build a unified memory-augmented decoder for few-shot\nsegmentation, respectively. Specifically, the RPGM combines superpixel and\nK-means clustering to generate rich prototype features with complementary scale\nrelationships and adapt the scale gap between support and query images. The\nRPEM utilizes the recurrent mechanism to design a round-way propagation\ndecoder. In this way, registered features can provide object-aware information\ncontinuously. Experiments show that our method consistently outperforms other\ncompetitors on two popular benchmarks PASCAL-${{5}^{i}}$ and COCO-${{20}^{i}}$.",
    "descriptor": "\nComments: Accepted in PRCV 2022\n",
    "authors": [
      "Hongsheng Wang",
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Jinqing Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00765"
  },
  {
    "id": "arXiv:2210.00766",
    "title": "Dual Gradient Descent EMF-Aware MU-MIMO Beamforming in RIS-Aided 6G  Networks",
    "abstract": "Reconfigurable Intelligent Surface (RIS) is one of the key technologies for\nthe upcoming 6th Generation (6G) communications, which can improve the signal\nstrength at the receivers by adding artificial propagation paths. In the\ncontext of Downlink (DL) Multi-User Multiple-Input Multiple-Output (MU-MIMO)\ncommunications, designing an appropriate Beamforming (BF) scheme to take full\nadvantage of this reconfigured propagation environment and improve the network\ncapacity is a major challenge. Due to the spatial dimension provided by MIMO\nsystems, independent data streams can be transmitted to multiple users\nsimultaneously on the same radio resources. It is important to note that\nserving the same subset of users over a period of time may lead to undesired\nareas where the average Electromagnetic Field Exposure (EMFE) exceeds\nregulatory limits. To address this challenge, in this paper, we propose a Dual\nGradient Descent (Dual-GD)-based Electromagnetic Field (EMF)-aware MU-MIMO BF\nscheme that aims to optimize the overall capacity under EMFE constraints in\nRIS-aided 6G cellular networks.",
    "descriptor": "\nComments: 8 pages, 5 figures, published in the SWirNet workshop at the conference WiOpt 2022. arXiv admin note: substantial text overlap with arXiv:2209.14785\n",
    "authors": [
      "Yi Yu",
      "Rita Ibrahim",
      "Dinh-Thuy Phan-Huy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00766"
  },
  {
    "id": "arXiv:2210.00767",
    "title": "Unsupervised Search Algorithm Configuration using Query Performance  Prediction",
    "abstract": "Search engine configuration can be quite difficult for inexpert developers.\nInstead, an auto-configuration approach can be used to speed up development\ntime. Yet, such an automatic process usually requires relevance labels to train\na supervised model. In this work, we suggest a simple solution based on query\nperformance prediction that requires no relevance labels but only a sample of\nqueries in a given domain. Using two example usecases we demonstrate the merits\nof our solution.",
    "descriptor": "",
    "authors": [
      "Haggai Roitman"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00767"
  },
  {
    "id": "arXiv:2210.00770",
    "title": "Accelerate Reinforcement Learning with PID Controllers in the Pendulum  Simulations",
    "abstract": "We propose a Proportional Integral Derivative (PID) controller-based coaching\nscheme to expedite reinforcement learning (RL).",
    "descriptor": "",
    "authors": [
      "Liping Bai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00770"
  },
  {
    "id": "arXiv:2210.00778",
    "title": "On Lattice-Code based Multiple Access: Uplink Architecture and  Algorithms",
    "abstract": "This paper studies a lattice-code based multiple-access (LCMA) framework, and\ndevelops a package of processing techniques that are essential to its practical\nimplementation. In the uplink, $K$ users encode their messages with the same\nring coded modulation of $2^{m}$-PAM signaling. With it, the integer sum of\nmultiple codewords belongs to the $n$-dimension lattice of the base code. Such\nproperty enables efficient \\textit{algebraic binning} for computing linear\ncombinations of $K$ users' messages. For the receiver, we devise two new\nalgorithms, based on linear physical-layer network coding and linear filtering,\nto calculate the symbol-wise a posteriori probabilities (APPs) w.r.t. the $K$\nstreams of linear codeword combinations. The resultant APP streams are\nforwarded to the $q$-ary belief-propagation decoders, which parallelly compute\n$K$ streams of linear message combinations. Finally, by multiplying the inverse\nof the coefficient matrix, all users' messages are recovered. Even with\nsingle-stage parallel processing, LCMA is shown to support a remarkably larger\nnumber of users and exhibits improved frame error rate (FER) relative to\nexisting NOMA systems such as IDMA and SCMA. Further, we propose a new\nmulti-stage LCMA receiver relying on \\emph{generalized matrix inversion}. With\nit, a near-capacity performance is demonstrated for a wide range of system\nloads. Numerical results demonstrate that the number of users that LCMA can\nsupport is no less than 350\\% of the length of the spreading sequence or number\nof receive antennas. Since LCMA relaxes receiver iteration, off-the-shelf\nchannel codes in standards can be directly utilized, avoiding the compatibility\nand convergence issue of channel code and detector in IDMA and SCMA.",
    "descriptor": "\nComments: 30 Pages, 11 figures, submitted to IEEE Trans. Wireless Comm\n",
    "authors": [
      "Tao Yang. Fangtao Yu",
      "Qiuzhuo Chen",
      "Rongke Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00778"
  },
  {
    "id": "arXiv:2210.00785",
    "title": "The Geometry of Reachability in Continuous Vector Addition Systems with  States",
    "abstract": "We study the geometry of reachability sets of continuous vector addition\nsystems with states (VASS). In particular we establish that they are almost\nMinkowski sums of convex cones and zonotopes generated by the vectors labelling\nthe transitions of the VASS. We use the latter to prove that short so-called\nlinear path schemes suffice as witnesses of reachability in continuous VASS of\nfixed dimension. Then, we give new polynomial-time algorithms for the\nreachability problem for linear path schemes. Finally, we also establish that\nenriching the model with zero tests makes the reachability problem intractable\nalready for linear path schemes of dimension two.",
    "descriptor": "",
    "authors": [
      "Shaull Almagor",
      "Arka Ghosh",
      "Tim Leys",
      "Guillermo A. Perez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00785"
  },
  {
    "id": "arXiv:2210.00788",
    "title": "Towards a Unified View on Visual Parameter-Efficient Transfer Learning",
    "abstract": "Since the release of various large-scale natural language processing (NLP)\npre-trained models, parameter efficient transfer learning (PETL) has become a\npopular paradigm capable of achieving impressive performance on various\ndownstream tasks. PETL aims at making good use of the representation knowledge\nin the pre-trained large models by fine-tuning a small number of parameters.\nRecently, it has also attracted increasing attention to developing various PETL\ntechniques for vision tasks. Popular PETL techniques such as Prompt-tuning and\nAdapter have been proposed for high-level visual downstream tasks such as image\nclassification and video recognition. However, Prefix-tuning remains\nunder-explored for vision tasks. In this work, we intend to adapt large\nvideo-based models to downstream tasks with a good parameter-accuracy\ntrade-off. Towards this goal, we propose a framework with a unified view called\nvisual-PETL (V-PETL) to investigate the different aspects affecting the\ntrade-off. Specifically, we analyze the positional importance of trainable\nparameters and differences between NLP and vision tasks in terms of data\nstructures and pre-training mechanisms while implementing various PETL\ntechniques, especially for the under-explored prefix-tuning technique. Based on\na comprehensive understanding of differences between NLP and video data, we\npropose a new variation of prefix-tuning module called parallel attention\n(PATT) for video-based downstream tasks. An extensive empirical analysis on two\nvideo datasets via different frozen backbones has been carried and the findings\nshow that the proposed PATT can effectively contribute to other PETL\ntechniques. An effective scheme Swin-BAPAT derived from the proposed V-PETL\nframework achieves significantly better performance than the state-of-the-art\nAdaptFormer-Swin with slightly more parameters and outperforms full-tuning with\nfar less parameters.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Bruce X.B. Yu",
      "Jianlong Chang",
      "Lingbo Liu",
      "Qi Tian",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00788"
  },
  {
    "id": "arXiv:2210.00789",
    "title": "Nested Sequents for First-Order Modal Logics via Reachability Rules",
    "abstract": "We introduce (cut-free) nested sequent systems for first-order modal logics\nthat admit increasing, decreasing, constant, and empty domains along with\nso-called general path conditions and seriality. We obtain such systems by\nmeans two devices: 'reachability rules' and 'structural refinement.' Regarding\nthe former device, we introduce reachability rules as special logical rules\nparameterized with formal grammars (viz. semi-Thue systems) that operate by\npropagating formulae and/or checking if data exists along certain paths within\na nested sequent, where paths are encoded as strings generated by a\nparameterizing grammar. Regarding the latter device, structural refinement is a\nrelatively new methodology used to extract nested sequent systems from labeled\nsystems (which are ultimately obtained from a semantics) by means of\neliminating structural/relational rules, introducing reachability rules, and\nthen carrying out a notational translation. We therefore demonstrate how this\nmethod can be extended to the setting of first-order modal logics, and expose\nhow reachability rules naturally arise from applying this method.",
    "descriptor": "",
    "authors": [
      "Tim S. Lyon"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00789"
  },
  {
    "id": "arXiv:2210.00795",
    "title": "Hierarchical reinforcement learning for in-hand robotic manipulation  using Davenport chained rotations",
    "abstract": "End-to-end reinforcement learning techniques are among the most successful\nmethods for robotic manipulation tasks. However, the training time required to\nfind a good policy capable of solving complex tasks is prohibitively large.\nTherefore, depending on the computing resources available, it might not be\nfeasible to use such techniques. The use of domain knowledge to decompose\nmanipulation tasks into primitive skills, to be performed in sequence, could\nreduce the overall complexity of the learning problem, and hence reduce the\namount of training required to achieve dexterity. In this paper, we propose the\nuse of Davenport chained rotations to decompose complex 3D rotation goals into\na concatenation of a smaller set of more simple rotation skills.\nState-of-the-art reinforcement-learning-based methods can then be trained using\nless overall simulated experience. We compare its performance with the popular\nHindsight Experience Replay method, trained in an end-to-end fashion using the\nsame amount of experience in a simulated robotic hand environment. Despite a\ngeneral decrease in performance of the primitive skills when being sequentially\nexecuted, we find that decomposing arbitrary 3D rotations into elementary\nrotations is beneficial when computing resources are limited, obtaining\nincreases of success rates of approximately 10% on the most complex 3D\nrotations with respect to the success rates obtained by HER trained in an\nend-to-end fashion, and increases of success rates between 20% and 40% on the\nmost simple rotations.",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables, submitted to AICS 2022\n",
    "authors": [
      "Francisco Roldan Sanchez",
      "Qiang Wang",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Stephen Redmond",
      "Noel O'Connor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00795"
  },
  {
    "id": "arXiv:2210.00798",
    "title": "HPC Storage Service Autotuning Using Variational-Autoencoder-Guided  Asynchronous Bayesian Optimization",
    "abstract": "Distributed data storage services tailored to specific applications have\ngrown popular in the high-performance computing (HPC) community as a way to\naddress I/O and storage challenges. These services offer a variety of specific\ninterfaces, semantics, and data representations. They also expose many tuning\nparameters, making it difficult for their users to find the best configuration\nfor a given workload and platform.\nTo address this issue, we develop a novel variational-autoencoder-guided\nasynchronous Bayesian optimization method to tune HPC storage service\nparameters. Our approach uses transfer learning to leverage prior tuning\nresults and use a dynamically updated surrogate model to explore the large\nparameter search space in a systematic way.\nWe implement our approach within the DeepHyper open-source framework, and\napply it to the autotuning of a high-energy physics workflow on Argonne's Theta\nsupercomputer. We show that our transfer-learning approach enables a more than\n$40\\times$ search speedup over random search, compared with a $2.5\\times$ to\n$10\\times$ speedup when not using transfer learning. Additionally, we show that\nour approach is on par with state-of-the-art autotuning frameworks in speed and\noutperforms them in resource utilization and parallelization capabilities.",
    "descriptor": "\nComments: Accepted at IEEE Cluster 2022\n",
    "authors": [
      "Matthieu Dorier",
      "Romain Egele",
      "Prasanna Balaprakash",
      "Jaehoon Koo",
      "Sandeep Madireddy",
      "Srinivasan Ramesh",
      "Allen D. Malony",
      "Rob Ross"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00798"
  },
  {
    "id": "arXiv:2210.00801",
    "title": "Design of the PID temperature controller for an alkaline electrolysis  system with time delays",
    "abstract": "Electrolysis systems use proportional-integral-derivative (PID) temperature\ncontrollers to maintain stack temperatures around set points. However, heat\ntransfer delays in electrolysis systems cause manual tuning of PID temperature\ncontrollers to be time-consuming, and temperature oscillations often occur.\nThis paper focuses on the design of the PID temperature controller for an\nalkaline electrolysis system to achieve fast and stable temperature control. A\nthermal dynamic model of an electrolysis system is established in the\nfrequency-domain for controller designs. Based on this model, the temperature\nstability is analysed by the root distribution, and the PID parameters are\noptimized considering both the temperature overshoot and the settling time. The\nperformance of the optimal PID controllers is verified through experiments.\nFurthermore, the simulation results show that the before-stack temperature\nshould be used as the feedback variable for small lab-scale systems to suppress\nstack temperature fluctuations, and the after-stack temperature should be used\nfor larger systems to improve the economy. This study is helpful in ensuring\nthe temperature stability and control of electrolysis systems.",
    "descriptor": "",
    "authors": [
      "Ruomei Qi",
      "Jiarong Li",
      "Jin Lin",
      "Yonghua Song",
      "Jiepeng Wang",
      "Qiangqiang Cui",
      "Yiwei Qiu",
      "Ming Tang",
      "Jian Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00801"
  },
  {
    "id": "arXiv:2210.00803",
    "title": "Obstacle Avoidance for Robotic Manipulator in Joint Space via Improved  Proximal Policy Optimization",
    "abstract": "Reaching tasks with random targets and obstacles can still be challenging\nwhen the robotic arm is operating in unstructured environments. In contrast to\ntraditional model-based methods, model-free reinforcement learning methods do\nnot require complex inverse kinematics or dynamics equations to be calculated.\nIn this paper, we train a deep neural network via an improved Proximal Policy\nOptimization (PPO) algorithm, which aims to map from task space to joint space\nfor a 6-DoF manipulator. In particular, we modify the original PPO and design\nan effective representation for environmental inputs and outputs to train the\nrobot faster in a larger workspace. Firstly, a type of action ensemble is\nadopted to improve output efficiency. Secondly, the policy is designed to join\nin value function updates directly. Finally, the distance between obstacles and\nlinks of the manipulator is calculated based on a geometry method as part of\nthe representation of states. Since training such a task in real-robot is\ntime-consuming and strenuous, we develop a simulation environment to train the\nmodel. We choose Gazebo as our first simulation environment since it often\nproduces a smaller Sim-to-Real gap than other simulators. However, the training\nprocess in Gazebo is time-consuming and takes a long time. Therefore, to\naddress this limitation, we propose a Sim-to-Sim method to reduce the training\ntime significantly. The trained model is finally used in a real-robot setup\nwithout fine-tuning. Experimental results showed that using our method, the\nrobot was capable of tracking a single target or reaching multiple targets in\nunstructured environments.",
    "descriptor": "",
    "authors": [
      "Yongliang Wang",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00803"
  },
  {
    "id": "arXiv:2210.00805",
    "title": "Limitations of gradient descent due to numerical instability of  backpropagation",
    "abstract": "We study the training of deep neural networks by gradient descent where\nfloating-point arithmetic is used to compute the gradients. In this framework\nand under realistic assumptions, we demonstrate that it is highly unlikely to\nfind ReLU neural networks that maintain, in the course of training with\ngradient descent, superlinearly many affine pieces with respect to their number\nof layers. In virtually all approximation theoretical arguments which yield\nhigh order polynomial rates of approximation, sequences of ReLU neural networks\nwith exponentially many affine pieces compared to their numbers of layers are\nused. As a consequence, we conclude that approximating sequences of ReLU neural\nnetworks resulting from gradient descent in practice differ substantially from\ntheoretically constructed sequences. The assumptions and the theoretical\nresults are compared to a numerical study, which yields concurring results.",
    "descriptor": "",
    "authors": [
      "Clemens Karner",
      "Vladimir Kazeev",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00805"
  },
  {
    "id": "arXiv:2210.00808",
    "title": "A Multi Camera Unsupervised Domain Adaptation Pipeline for Object  Detection in Cultural Sites through Adversarial Learning and Self-Training",
    "abstract": "Object detection algorithms allow to enable many interesting applications\nwhich can be implemented in different devices, such as smartphones and wearable\ndevices. In the context of a cultural site, implementing these algorithms in a\nwearable device, such as a pair of smart glasses, allow to enable the use of\naugmented reality (AR) to show extra information about the artworks and enrich\nthe visitors' experience during their tour. However, object detection\nalgorithms require to be trained on many well annotated examples to achieve\nreasonable results. This brings a major limitation since the annotation process\nrequires human supervision which makes it expensive in terms of time and costs.\nA possible solution to reduce these costs consist in exploiting tools to\nautomatically generate synthetic labeled images from a 3D model of the site.\nHowever, models trained with synthetic data do not generalize on real images\nacquired in the target scenario in which they are supposed to be used.\nFurthermore, object detectors should be able to work with different wearable\ndevices or different mobile devices, which makes generalization even harder. In\nthis paper, we present a new dataset collected in a cultural site to study the\nproblem of domain adaptation for object detection in the presence of multiple\nunlabeled target domains corresponding to different cameras and a labeled\nsource domain obtained considering synthetic images for training purposes. We\npresent a new domain adaptation method which outperforms current\nstate-of-the-art approaches combining the benefits of aligning the domains at\nthe feature and pixel level with a self-training process. We release the\ndataset at the following link https://iplab.dmi.unict.it/OBJ-MDA/ and the code\nof the proposed architecture at https://github.com/fpv-iplab/STMDA-RetinaNet.",
    "descriptor": "",
    "authors": [
      "Giovanni Pasqualino",
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00808"
  },
  {
    "id": "arXiv:2210.00812",
    "title": "A Benchmark for Multi-Modal Lidar SLAM with Ground Truth in GNSS-Denied  Environments",
    "abstract": "Lidar-based simultaneous localization and mapping (SLAM) approaches have\nobtained considerable success in autonomous robotic systems. This is in part\nowing to the high-accuracy of robust SLAM algorithms and the emergence of new\nand lower-cost lidar products. This study benchmarks current state-of-the-art\nlidar SLAM algorithms with a multi-modal lidar sensor setup showcasing diverse\nscanning modalities (spinning and solid-state) and sensing technologies, and\nlidar cameras, mounted on a mobile sensing and computing platform. We extend\nour previous multi-modal multi-lidar dataset with additional sequences and new\nsources of ground truth data. Specifically, we propose a new multi-modal\nmulti-lidar SLAM-assisted and ICP-based sensor fusion method for generating\nground truth maps. With these maps, we then match real-time pointcloud data\nusing a natural distribution transform (NDT) method to obtain the ground truth\nwith full 6 DOF pose estimation. This novel ground truth data leverages\nhigh-resolution spinning and solid-state lidars. We also include new open road\nsequences with GNSS-RTK data and additional indoor sequences with motion\ncapture (MOCAP) ground truth, complementing the previous forest sequences with\nMOCAP data. We perform an analysis of the positioning accuracy achieved with\nten different SLAM algorithm and lidar combinations. We also report the\nresource utilization in four different computational platforms and a total of\nfive settings (Intel and Jetson ARM CPUs). Our experimental results show that\ncurrent state-of-the-art lidar SLAM algorithms perform very differently for\ndifferent types of sensors. More results, code, and the dataset can be found\nat:\n\\href{https://github.com/TIERS/tiers-lidars-dataset-enhanced}{github.com/TIERS/tiers-lidars-dataset-enhanced.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Ha Sier",
      "Li Qingqing",
      "Yu Xianjia",
      "Jorge Pe\u00f1a Queralta",
      "Zhuo Zou",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00812"
  },
  {
    "id": "arXiv:2210.00821",
    "title": "A high accuracy and low complexity quality control method for image  compression",
    "abstract": "For large-scale still image coding tasks, the processing platform needs to\nensure that the coded images meet the quality requirement. Therefore, the\nquality control algorithms that generate adaptive QP towards a target quality\nlevel for image coding are of significant research value. However, the existing\nquality control methods are limited by low accuracy, excessive computational\ncost, or temporal information dependence. In this paper, we propose a concise\n{\\lambda} domain linear distortion model and an accurate model parameters\nestimation method based on the original data. Since the model parameters are\nobtained from the original data, the proposed method is decoupled from the RDO\nprocess and can be applied to different image encoders. Experiments show that\nthe proposed quality control algorithm achieves the highest control accuracy\nand the lowest delay in the literature at the same time. The application of\nAlibaba's e-commerce platform also shows that the proposed algorithm can\nsignificantly reduce the overall bitrate while greatly reducing the bad case\nratio.",
    "descriptor": "",
    "authors": [
      "Xiao Yan",
      "Zhangxin Gong",
      "Wenqiang Wang",
      "Xiaoyang Zeng",
      "Yibo Fan"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.00821"
  },
  {
    "id": "arXiv:2210.00825",
    "title": "Self-omics: A Self-supervised Learning Framework for Multi-omics Cancer  Data",
    "abstract": "We have gained access to vast amounts of multi-omics data thanks to Next\nGeneration Sequencing. However, it is challenging to analyse this data due to\nits high dimensionality and much of it not being annotated. Lack of annotated\ndata is a significant problem in machine learning, and Self-Supervised Learning\n(SSL) methods are typically used to deal with limited labelled data. However,\nthere is a lack of studies that use SSL methods to exploit inter-omics\nrelationships on unlabelled multi-omics data. In this work, we develop a novel\nand efficient pre-training paradigm that consists of various SSL components,\nincluding but not limited to contrastive alignment, data recovery from\ncorrupted samples, and using one type of omics data to recover other omic\ntypes. Our pre-training paradigm improves performance on downstream tasks with\nlimited labelled data. We show that our approach outperforms the\nstate-of-the-art method in cancer type classification on the TCGA pan-cancer\ndataset in semi-supervised setting. Moreover, we show that the encoders that\nare pre-trained using our approach can be used as powerful feature extractors\neven without fine-tuning. Our ablation study shows that the method is not\noverly dependent on any pretext task component. The network architectures in\nour approach are designed to handle missing omic types and multiple datasets\nfor pre-training and downstream training. Our pre-training paradigm can be\nextended to perform zero-shot classification of rare cancers.",
    "descriptor": "\nComments: Preprint of an article published in Pacific Symposium on Biocomputing $\\copyright$ 2022 World Scientific Publishing Co., Singapore, this http URL\n",
    "authors": [
      "Sayed Hashim",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.00825"
  },
  {
    "id": "arXiv:2210.00826",
    "title": "Federated Learning-Based Interference Modeling for Vehicular Dynamic  Spectrum Access",
    "abstract": "A platoon-based driving is a technology allowing vehicles to follow each\nother at close distances to, e.g., save fuel. However, it requires reliable\nwireless communications to adjust their speeds. Recent studies have shown that\nthe frequency band dedicated for vehicle-to-vehicle communications can be too\nbusy for intra-platoon communications. Thus it is reasonable to use additional\nspectrum resources, of low occupancy, i.e., secondary spectrum channels. The\nchallenge is to model the interference in those channels to enable proper\nchannel selection. In this paper, we propose a two-layered Radio Environment\nMap (REM) that aims at providing platoons with accurate location-dependent\ninterference models by using the Federated Learning approach. Each platoon is\nequipped with a Local REM that is updated on the basis of raw interference\nsamples and previous interference model stored in the Global REM. The model in\nglobal REM is obtained by merging models reported by platoons. The nodes\nexchange only parameters of interference models, reducing the required control\nchannel capacity. Moreover, in the proposed architecture platoon can utilize\nLocal REM to predict channel occupancy, even when the connection to the Global\nREM is temporarily unavailable. The proposed system is validated via computer\nsimulations considering non-trivial interference patterns.",
    "descriptor": "",
    "authors": [
      "Marcin Hoffmann",
      "Pawel Kryszkiewicz",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00826"
  },
  {
    "id": "arXiv:2210.00828",
    "title": "Mastering Spatial Graph Prediction of Road Networks",
    "abstract": "Accurately predicting road networks from satellite images requires a global\nunderstanding of the network topology. We propose to capture such high-level\ninformation by introducing a graph-based framework that simulates the addition\nof sequences of graph edges using a reinforcement learning (RL) approach. In\nparticular, given a partially generated graph associated with a satellite\nimage, an RL agent nominates modifications that maximize a cumulative reward.\nAs opposed to standard supervised techniques that tend to be more restricted to\ncommonly used surrogate losses, these rewards can be based on various complex,\npotentially non-continuous, metrics of interest. This yields more power and\nflexibility to encode problem-dependent knowledge. Empirical results on several\nbenchmark datasets demonstrate enhanced performance and increased high-level\nreasoning about the graph topology when using a tree-based search. We further\nhighlight the superiority of our approach under substantial occlusions by\nintroducing a new synthetic benchmark dataset for this task.",
    "descriptor": "",
    "authors": [
      "Sotiris Anagnostidis",
      "Aurelien Lucchi",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00828"
  },
  {
    "id": "arXiv:2210.00829",
    "title": "Dancing with the Unexpected and Beyond: The Use of AI Assistance in  Design Fiction Creation",
    "abstract": "The creation process of design fiction is going participatory and inclusive\nwith non experts. Recognizing the potential of artificial intelligence in\ncreativity support, we explore the use of AI assistance in creating design\nfiction. This investigation is based on a workshop on future work in 2040 with\nChinese youth. We look into fiction quality, participants experiences with the\nAI agent, and their ways of incorporating those texts into writing. Our\nfindings show that human writers while responding to messy and unexpected\nAI-generated texts, can elevate the richness and creativity in writing and\ninitiate joyful and inspirational interactions. Furthermore, for the design of\nAI assistance in creativity support, we suggest two implications of enhancing\ninteractional quality between human and AI and prompt programming. Our study\nindicates the potential of applying design fiction outside the design context\nusing a more inclusive approach for future speculation with critical reflection\non technology.",
    "descriptor": "\nComments: Chinese CHI conference 2022\n",
    "authors": [
      "Yiying Wu",
      "Yunye Yu",
      "Pengcheng An"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00829"
  },
  {
    "id": "arXiv:2210.00832",
    "title": "Square-root regret bounds for continuous-time episodic Markov decision  processes",
    "abstract": "We study reinforcement learning for continuous-time Markov decision processes\n(MDPs) in the finite-horizon episodic setting. We present a learning algorithm\nbased on the methods of value iteration and upper confidence bound. We derive\nan upper bound on the worst-case expected regret for the proposed algorithm,\nand establish a worst-case lower bound, both bounds are of the order of\nsquare-root on the number of episodes. Finally, we conduct simulation\nexperiments to illustrate the performance of our algorithm.",
    "descriptor": "",
    "authors": [
      "Xuefeng Gao",
      "Xun Yu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00832"
  },
  {
    "id": "arXiv:2210.00833",
    "title": "SafeSoftDR: A Library to Enable Software-based Diverse Redundancy for  Safety-Critical Tasks",
    "abstract": "Applications with safety requirements have become ubiquitous nowadays and can\nbe found in edge devices of all kinds. However, microcontrollers in those\ndevices, despite offering moderate performance by implementing multicores and\ncache hierarchies, may fail to offer adequate support to implement some safety\nmeasures needed for the highest integrity levels, such as lockstepped execution\nto avoid so-called common cause failures (i.e., a fault affecting redundant\ncomponents causing the same error in all of them). To respond to this\nlimitation, an approach based on a software monitor enforcing some sort of\nsoftware-based lockstepped execution across cores has been proposed recently,\nproviding a proof of concept. This paper presents SafeSoftDR, a library\nproviding a standard interface to deploy software-based lockstepped execution\nacross non-natively lockstepped cores relieving end-users from having to manage\nthe burden to create redundant processes, copying input/output data, and\nperforming result comparison. Our library has been tested on x86-based Linux\nand is currently being integrated on top of an open-source RISC-V platform\ntargeting safety-related applications, hence offering a convenient environment\nfor safety-critical applications.",
    "descriptor": "\nComments: FORECAST 2022 Functional Properties and Dependability in Cyber-Physical Systems Workshop (held jointly with HiPEAC Conference)\n",
    "authors": [
      "Fabio Mazzocchetti",
      "Sergi Alcaide",
      "Francisco Bas",
      "Pedro Benedicte",
      "Guillem Cabo",
      "Feng Chang",
      "Francisco Fuentes",
      "Jaume Abella"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.00833"
  },
  {
    "id": "arXiv:2210.00834",
    "title": "Merging Classification Predictions with Sequential Information for  Lightweight Visual Place Recognition in Changing Environments",
    "abstract": "Low-overhead visual place recognition (VPR) is a highly active research\ntopic. Mobile robotics applications often operate under low-end hardware, and\neven more hardware capable systems can still benefit from freeing up onboard\nsystem resources for other navigation tasks. This work addresses lightweight\nVPR by proposing a novel system based on the combination of binary-weighted\nclassifier networks with a one-dimensional convolutional network, dubbed\nmerger. Recent work in fusing multiple VPR techniques has mainly focused on\nincreasing VPR performance, with computational efficiency not being highly\nprioritized. In contrast, we design our technique prioritizing low inference\ntimes, taking inspiration from the machine learning literature where the\nefficient combination of classifiers is a heavily researched topic. Our\nexperiments show that the merger achieves inference times as low as 1\nmillisecond, being significantly faster than other well-established lightweight\nVPR techniques, while achieving comparable or superior VPR performance on\nseveral visual changes such as seasonal variations and viewpoint lateral\nshifts.",
    "descriptor": "",
    "authors": [
      "Bruno Arcanjo",
      "Bruno Ferrarini",
      "Michael Milford",
      "Klaus D. McDonald-Maier",
      "Shoaib Ehsan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00834"
  },
  {
    "id": "arXiv:2210.00841",
    "title": "Smooth image-to-image translations with latent space interpolations",
    "abstract": "Multi-domain image-to-image (I2I) translations can transform a source image\naccording to the style of a target domain. One important, desired\ncharacteristic of these transformations, is their graduality, which corresponds\nto a smooth change between the source and the target image when their\nrespective latent-space representations are linearly interpolated. However,\nstate-of-the-art methods usually perform poorly when evaluated using\ninter-domain interpolations, often producing abrupt changes in the appearance\nor non-realistic intermediate images. In this paper, we argue that one of the\nmain reasons behind this problem is the lack of sufficient inter-domain\ntraining data and we propose two different regularization methods to alleviate\nthis issue: a new shrinkage loss, which compacts the latent space, and a Mixup\ndata-augmentation strategy, which flattens the style representations between\ndomains. We also propose a new metric to quantitatively evaluate the degree of\nthe interpolation smoothness, an aspect which is not sufficiently covered by\nthe existing I2I translation metrics. Using both our proposed metric and\nstandard evaluation protocols, we show that our regularization techniques can\nimprove the state-of-the-art multi-domain I2I translations by a large margin.\nOur code will be made publicly available upon the acceptance of this article.",
    "descriptor": "",
    "authors": [
      "Yahui Liu",
      "Enver Sangineto",
      "Yajing Chen",
      "Linchao Bao",
      "Haoxian Zhang",
      "Nicu Sebe",
      "Bruno Lepri",
      "Marco De Nadai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00841"
  },
  {
    "id": "arXiv:2210.00842",
    "title": "A micromechanics-based recurrent neural networks model for  path-dependent cyclic deformation of short fiber composites",
    "abstract": "The macroscopic response of short fiber reinforced composites is dependent on\nan extensive range of microstructural parameters. Thus, micromechanical\nmodeling of these materials is challenging and in some cases, computationally\nexpensive. This is particularly important when path-dependent plastic behavior\nis needed to be predicted. A solution to this challenge is to enhance\nmicromechanical solutions with machine learning techniques such as artificial\nneural networks. In this work, a recurrent deep neural network model is trained\nto predict the path-dependent elasto-plastic stress response of short fiber\nreinforced composites, given the microstructural parameters and the strain\npath. Micromechanical meanfield simulations are conducted to create a data base\nfor training the validating the model. The model gives very accurate\npredictions in a computationally efficient manner when compared with\nindependent micromechanical simulations.",
    "descriptor": "",
    "authors": [
      "J. Friemann",
      "B. Dashtbozorg",
      "M. Fagerstr\u00f6m",
      "S.M. Mirkhalaf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.00842"
  },
  {
    "id": "arXiv:2210.00843",
    "title": "A Strong Transfer Baseline for RGB-D Fusion in Vision Transformers",
    "abstract": "The Vision Transformer (ViT) architecture has recently established its place\nin the computer vision literature, with multiple architectures for recognition\nof image data or other visual modalities. However, training ViTs for RGB-D\nobject recognition remains an understudied topic, viewed in recent literature\nonly through the lens of multi-task pretraining in multiple modalities. Such\napproaches are often computationally intensive and have not yet been applied\nfor challenging object-level classification tasks. In this work, we propose a\nsimple yet strong recipe for transferring pretrained ViTs in RGB-D domains for\nsingle-view 3D object recognition, focusing on fusing RGB and depth\nrepresentations encoded jointly by the ViT. Compared to previous works in\nmultimodal Transformers, the key challenge here is to use the atested\nflexibility of ViTs to capture cross-modal interactions at the downstream and\nnot the pretraining stage. We explore which depth representation is better in\nterms of resulting accuracy and compare two methods for injecting RGB-D fusion\nwithin the ViT architecture (i.e., early vs. late fusion). Our results in the\nWashington RGB-D Objects dataset demonstrates that in such RGB $\\rightarrow$\nRGB-D scenarios, late fusion techniques work better than most popularly\nemployed early fusion. With our transfer baseline, adapted ViTs score up to\n95.1\\% top-1 accuracy in Washington, achieving new state-of-the-art results in\nthis benchmark. We additionally evaluate our approach with an open-ended\nlifelong learning protocol, where we show that our adapted RGB-D encoder leads\nto features that outperform unimodal encoders, even without explicit\nfine-tuning. We further integrate our method with a robot framework and\ndemonstrate how it can serve as a perception utility in an interactive robot\nlearning scenario, both in simulation and with a real robot.",
    "descriptor": "\nComments: Submitted ICRA 23. Supplementary video here: this https URL\n",
    "authors": [
      "Georgios Tziafas",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00843"
  },
  {
    "id": "arXiv:2210.00844",
    "title": "A Dual Realization of Chua's Chaotic Oscillator Using a  Current-Controlled Nonlinear Resistor",
    "abstract": "A dual realization of Chuas chaotic oscillator is proposed using\ncurrent-controlled nonlinear resistors, one linear resistor, one capacitor and\ntwo inductors. Two problems are solved. First, unit rescaling is necessary when\ntransforming the standard chaotic equations into circuit equations to ensure\nthat the current units are milliamperes. In addition, the connection and\nparameters of two current-controlled nonlinear resistors are set to build the\nrequired volt-ampere characteristics. The inductor currents show the classical\ncharacteristics of being sensitive to the circuit parameters and initial\nconditions. In addition, experimental verification is performed to demonstrate\nthe feasibility of the circuit. Chuas dual circuit exhibits rich dynamic\nchaotic features and might bring new applications due to chaotic currents.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Yihang Chen",
      "Weijie Dong",
      "Yongping Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00844"
  },
  {
    "id": "arXiv:2210.00848",
    "title": "I Speak, You Verify: Toward Trustworthy Neural Program Synthesis",
    "abstract": "We develop an approach for improving the trustworthiness and overall accuracy\nof program synthesizers based on large language models for source code. Given a\nnatural language description of a programming problem, our method samples both\ncandidate programs as well as candidate predicates specifying how the program\nshould behave. We learn to analyze the agreement between programs and\npredicates to judge both which program is most likely to be correct, and also\njudge whether the language model is able to solve the programming problem in\nthe first place. This latter capacity allows favoring high precision over broad\nrecall: fostering trust by only proposing a program when the system is certain\nthat it is correct.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Darren Key",
      "Wen-Ding Li",
      "Kevin Ellis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.00848"
  },
  {
    "id": "arXiv:2210.00849",
    "title": "Scaling Laws for a Multi-Agent Reinforcement Learning Model",
    "abstract": "The recent observation of neural power-law scaling relations has made a\nsignificant impact in the field of deep learning. A substantial amount of\nattention has been dedicated as a consequence to the description of scaling\nlaws, although mostly for supervised learning and only to a reduced extent for\nreinforcement learning frameworks. In this paper we present an extensive study\nof performance scaling for a cornerstone reinforcement learning algorithm,\nAlphaZero. On the basis of a relationship between Elo rating, playing strength\nand power-law scaling, we train AlphaZero agents on the games Connect Four and\nPentago and analyze their performance. We find that player strength scales as a\npower law in neural network parameter count when not bottlenecked by available\ncompute, and as a power of compute when training optimally sized agents. We\nobserve nearly identical scaling exponents for both games. Combining the two\nobserved scaling laws we obtain a power law relating optimal size to compute\nsimilar to the ones observed for language models. We find that the predicted\nscaling of optimal neural network size fits our data for both games. This\nscaling law implies that previously published state-of-the-art game-playing\nmodels are significantly smaller than their optimal size, given the respective\ncompute budgets. We also show that large AlphaZero models are more sample\nefficient, performing better than smaller models with the same amount of\ntraining data.",
    "descriptor": "",
    "authors": [
      "Oren Neumann",
      "Claudius Gros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00849"
  },
  {
    "id": "arXiv:2210.00850",
    "title": "Concepts and Experiments on Psychoanalysis Driven Computing",
    "abstract": "This research investigates the effective incorporation of the human factor\nand user perception in text-based interactive media. In such contexts, the\nreliability of user texts is often compromised by behavioural and emotional\ndimensions. To this end, several attempts have been made in the state of the\nart, to introduce psychological approaches in such systems, including\ncomputational psycholinguistics, personality traits and cognitive psychology\nmethods.\nIn contrast, our method is fundamentally different since we employ a\npsychoanalysis-based approach; in particular, we use the notion of Lacanian\ndiscourse types, to capture and deeply understand real (possibly elusive)\ncharacteristics, qualities and contents of texts, and evaluate their\nreliability. As far as we know, this is the first time computational methods\nare systematically combined with psychoanalysis. We believe such psychoanalytic\nframework is fundamentally more effective than standard methods, since it\naddresses deeper, quite primitive elements of human personality, behaviour and\nexpression which usually escape methods functioning at \"higher\", conscious\nlayers. In fact, this research is a first attempt to form a new paradigm of\npsychoanalysis-driven interactive technologies, with broader impact and diverse\napplications.\nTo exemplify this generic approach, we apply it to the case-study of fake\nnews detection; we first demonstrate certain limitations of the well-known\nMyers-Briggs Type Indicator (MBTI) personality type method, and then propose\nand evaluate our new method of analysing user texts and detecting fake news\nbased on the Lacanian discourses psychoanalytic approach.",
    "descriptor": "",
    "authors": [
      "Minas Gadalla",
      "Sotiris Nikoletseas",
      "Jos\u00e9 Roberto de A. Amazonas",
      "Jos\u00e9 D. P. Rolim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00850"
  },
  {
    "id": "arXiv:2210.00852",
    "title": "A note on the potentials of probabilistic and fuzzy logic",
    "abstract": "This paper mainly focuses on (1) a generalized treatment of fuzzy sets of\ntype $n$, where $n$ is an integer larger than or equal to $1$, with an example,\nmathematical discussions, and real-life interpretation of the given\nmathematical concepts; (2) the potentials and links between fuzzy logic and\nprobability logic that have not been discussed in one document in literature;\n(3) representation of real-life random and fuzzy uncertainties and ambiguities\nthat arise in data-driven real-life problems, due to uncertain mathematical and\nvague verbal terms in datasets.",
    "descriptor": "",
    "authors": [
      "Anahita Jamshidnejad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00852"
  },
  {
    "id": "arXiv:2210.00853",
    "title": "Road Network Variation Based on HD Map Analysis for the Simulative  Safety Assurance of Automated Vehicles",
    "abstract": "The validation and verification of automated driving functions (ADFs) is a\nchallenging task on the journey of making those functions available to the\npublic beyond the current research context. Simulation is a valuable building\nblock for scenario-based testing that can help to model traffic situations that\nare relevant for ADFs. In addition to the surrounding traffic and environment\nof the ADF under test, the logical description and automated generation of\nconcrete road networks have an important role. We aim to reduce efforts for\nmanual map generation and to improve the automated testing process during\ndevelopment.\nHence, this paper proposes a method to analyze real road networks and extract\nrelevant parameters for the variation of synthetic simulation maps that\ncorrespond to real-world properties. Consequently, characteristics for\ninner-city junctions are selected from Here HD map. Then, parameter\ndistributions are determined, analyzed and used to generate variations of road\nnetworks in the OpenDRIVE standard. The presented methodology enables efficient\nroad network modeling which can be used for large scale simulations. The\ndeveloped road network generation tool is publicly available on GitHub.",
    "descriptor": "\nComments: Proc. of the International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME), 16-18 November 2022, Maldives\n",
    "authors": [
      "Daniel Becker",
      "Christian Geller",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00853"
  },
  {
    "id": "arXiv:2210.00854",
    "title": "Deep learning and multi-level featurization of graph representations of  microstructural data",
    "abstract": "Many material response functions depend strongly on microstructure, such as\ninhomogeneities in phase or orientation. Homogenization presents the task of\npredicting the mean response of a sample of the microstructure to external\nloading for use in subgrid models and structure-property explorations. Although\nmany microstructural fields have obvious segmentations, learning directly from\nthe graph induced by the segmentation can be difficult because this\nrepresentation does not encode all the information of the full field. We\ndevelop a means of deep learning of hidden features on the reduced graph given\nthe native discretization and a segmentation of the initial input field. The\nfeatures are associated with regions represented as nodes on the reduced graph.\nThis reduced representation is then the basis for the subsequent\nmulti-level/scale graph convolutional network model. There are a number of\nadvantages of reducing the graph before fully processing with convolutional\nlayers it, such as interpretable features and efficiency on large meshes. We\ndemonstrate the performance of the proposed network relative to convolutional\nneural networks operating directly on the native discretization of the data\nusing three physical exemplars.",
    "descriptor": "\nComments: 27 pages, 17 figures\n",
    "authors": [
      "Reese Jones",
      "Cosmin Safta",
      "Ari Frankel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00854"
  },
  {
    "id": "arXiv:2210.00856",
    "title": "A forensic analysis of the Google Home: repairing compressed data  without error correction",
    "abstract": "This paper provides a detailed explanation of the steps taken to extract and\nrepair a Google Home's internal data. Starting with reverse engineering the\nhardware of a commercial off-the-shelf Google Home, internal data is then\nextracted by desoldering and dumping the flash memory. As error correction is\nperformed by the CPU using an undisclosed method, a new alternative method is\nshown to repair a corrupted SquashFS filesystem, under the assumption of a\nsingle or double bitflip per gzip-compressed fragment. Finally, a new method to\nhandle multiple possible repairs using three-valued logic is presented.",
    "descriptor": "\nComments: 28 pages, modified version of paper that appeared originally at Forensic Science International: Digital Investigation\n",
    "authors": [
      "Hadrien Barral",
      "Georges-Axel Jaloyan",
      "Fabien Thomas-Brans",
      "Matthieu Regnery",
      "R\u00e9mi G\u00e9raud-Stewart",
      "Thibaut Heckmann",
      "Thomas Souvignet",
      "David Naccache"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.00856"
  },
  {
    "id": "arXiv:2210.00858",
    "title": "A Hybrid Compositional Reasoning Approach for Interactive Robot  Manipulation",
    "abstract": "In this paper we present a neuro-symbolic (hybrid) compositional reasoning\nmodel for coupling language-guided visual reasoning with robot manipulation. A\nnon-expert human user can prompt the robot agent using natural language,\nproviding either a referring expression (REC), a question (VQA) or a grasp\naction instruction. The model can tackle all cases in a task-agnostic fashion\nthrough the utilization of a shared library of primitive skills. Each primitive\nhandles an independent sub-task, such as reasoning about visual attributes,\nspatial relation comprehension, logic and enumeration, as well as arm control.\nA language parser maps the input query to an executable program composed of\nsuch primitives depending on the context. While some primitives are purely\nsymbolic operations (e.g. counting), others are trainable neural functions\n(e.g. grounding words to images), therefore marrying the interpretability and\nsystematic generalization benefits of discrete symbolic approaches with the\nscalability and representational power of deep networks. We generate a\nsynthetic dataset of tabletop scenes to train our approach and perform several\nevaluation experiments for VQA in the synthetic and a real RGB-D dataset.\nResults show that the proposed method achieves very high accuracy while being\ntransferable to novel content with few-shot visual fine-tuning. Finally, we\nintegrate our method with a robot framework and demonstrate how it can serve as\nan interpretable solution for an interactive object picking task, both in\nsimulation and with a real robot.",
    "descriptor": "\nComments: Submitted in RA-L, supplemetary video: this https URL\n",
    "authors": [
      "Georgios Tziafas",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.00858"
  },
  {
    "id": "arXiv:2210.00859",
    "title": "Requirements Engineering for Machine Learning: A Review and Reflection",
    "abstract": "Today, many industrial processes are undergoing digital transformation, which\noften requires the integration of well-understood domain models and\nstate-of-the-art machine learning technology in business processes. However,\nrequirements elicitation and design decision making about when, where and how\nto embed various domain models and end-to-end machine learning techniques\nproperly into a given business workflow requires further exploration. This\npaper aims to provide an overview of the requirements engineering process for\nmachine learning applications in terms of cross domain collaborations. We first\nreview the literature on requirements engineering for machine learning, and\nthen go through the collaborative requirements analysis process step-by-step.\nAn example case of industrial data-driven intelligence applications is also\ndiscussed in relation to the aforementioned steps.",
    "descriptor": "",
    "authors": [
      "Zhongyi Pei",
      "Lin Liu",
      "Chen Wang",
      "Jianmin Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00859"
  },
  {
    "id": "arXiv:2210.00867",
    "title": "DRACo-SLAM: Distributed Robust Acoustic Communication-efficient SLAM for  Imaging Sonar Equipped Underwater Robot Teams",
    "abstract": "An essential task for a multi-robot system is generating a common\nunderstanding of the environment and relative poses between robots. Cooperative\ntasks can be executed only when a vehicle has knowledge of its own state and\nthe states of the team members. However, this has primarily been achieved with\ndirect rendezvous between underwater robots, via inter-robot ranging. We\npropose a novel distributed multi-robot simultaneous localization and mapping\n(SLAM) framework for underwater robots using imaging sonar-based perception. By\npassing only scene descriptors between robots, we do not need to pass raw\nsensor data unless there is a likelihood of inter-robot loop closure. We\nutilize pairwise consistent measurement set maximization (PCM), making our\nsystem robust to erroneous loop closures. The functionality of our system is\ndemonstrated using two real-world datasets, one with three robots and another\nwith two robots. We show that our system effectively estimates the trajectories\nof the multi-robot system and keeps the bandwidth requirements of inter-robot\ncommunication low. To our knowledge, this paper describes the first instance of\nmulti-robot SLAM using real imaging sonar data (which we implement offline,\nusing simulated communication). Code link:\nhttps://github.com/jake3991/DRACo-SLAM.",
    "descriptor": "\nComments: To appear at IROS 2022 in Kyoto, Japan\n",
    "authors": [
      "John McConnell",
      "Yewei Huang",
      "Paul Szenher",
      "Ivana Collado-Gonzalez",
      "Brendan Englot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00867"
  },
  {
    "id": "arXiv:2210.00868",
    "title": "Strain energy density as a Gaussian process and its utilization in  stochastic finite element analysis: application to planar soft tissues",
    "abstract": "Data-based approaches are promising alternatives to the traditional\nanalytical constitutive models for solid mechanics. Herein, we propose a\nGaussian process (GP) based constitutive modeling framework, specifically\nfocusing on planar, hyperelastic and incompressible soft tissues. The strain\nenergy density of soft tissues is modeled as a GP, which can be regressed to\nexperimental stress-strain data obtained from biaxial experiments. Moreover,\nthe GP model can be weakly constrained to be convex. A key advantage of a\nGP-based model is that, in addition to the mean value, it provides a\nprobability density (i.e. associated uncertainty) for the strain energy\ndensity. To simulate the effect of this uncertainty, a non-intrusive stochastic\nfinite element analysis (SFEA) framework is proposed. The proposed framework is\nverified against an artificial dataset based on the Gasser--Ogden--Holzapfel\nmodel and applied to a real experimental dataset of a porcine aortic valve\nleaflet tissue. Results show that the proposed framework can be trained with\nlimited experimental data and fits the data better than several existing\nmodels. The SFEA framework provides a straightforward way of using the\nexperimental data and quantifying the resulting uncertainty in simulation-based\npredictions.",
    "descriptor": "",
    "authors": [
      "Ankush Aggarwal",
      "Bj\u00f8rn Sand Jensen",
      "Sanjay Pant",
      "Chung-Hao Lee"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2210.00868"
  },
  {
    "id": "arXiv:2210.00869",
    "title": "Explainable classification of astronomical uncertain time series",
    "abstract": "Exploring the expansion history of the universe, understanding its\nevolutionary stages, and predicting its future evolution are important goals in\nastrophysics. Today, machine learning tools are used to help achieving these\ngoals by analyzing transient sources, which are modeled as uncertain time\nseries. Although black-box methods achieve appreciable performance, existing\ninterpretable time series methods failed to obtain acceptable performance for\nthis type of data. Furthermore, data uncertainty is rarely taken into account\nin these methods. In this work, we propose an uncertaintyaware subsequence\nbased model which achieves a classification comparable to that of\nstate-of-the-art methods. Unlike conformal learning which estimates model\nuncertainty on predictions, our method takes data uncertainty as additional\ninput. Moreover, our approach is explainable-by-design, giving domain experts\nthe ability to inspect the model and explain its predictions. The\nexplainability of the proposed method has also the potential to inspire new\ndevelopments in theoretical astrophysics modeling by suggesting important\nsubsequences which depict details of light curve shapes. The dataset, the\nsource code of our experiment, and the results are made available on a public\nrepository.",
    "descriptor": "",
    "authors": [
      "Michael Franklin Mbouopda",
      "Emille E O Ishida",
      "Engelbert Mephu Nguifo",
      "Emmanuel Gangler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00869"
  },
  {
    "id": "arXiv:2210.00875",
    "title": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset  Copyright Protection",
    "abstract": "Deep neural networks (DNNs) have demonstrated their superiority in practice.\nArguably, the rapid development of DNNs is largely benefited from high-quality\n(open-sourced) datasets, based on which researchers and developers can easily\nevaluate and improve their learning methods. Since the data collection is\nusually time-consuming or even expensive, how to protect their copyrights is of\ngreat significance and worth further exploration. In this paper, we revisit\ndataset ownership verification. We find that existing verification methods\nintroduced new security risks in DNNs trained on the protected dataset, due to\nthe targeted nature of poison-only backdoor watermarks. To alleviate this\nproblem, in this work, we explore the untargeted backdoor watermarking scheme,\nwhere the abnormal model behaviors are not deterministic. Specifically, we\nintroduce two dispersibilities and prove their correlation, based on which we\ndesign the untargeted backdoor watermark under both poisoned-label and\nclean-label settings. We also discuss how to use the proposed untargeted\nbackdoor watermark for dataset ownership verification. Experiments on benchmark\ndatasets verify the effectiveness of our methods and their resistance to\nexisting backdoor defenses. Our codes are available at\n\\url{https://github.com/THUYimingLi/Untargeted_Backdoor_Watermark}.",
    "descriptor": "\nComments: This work is accepted by the NeurIPS 2022. The first two authors contributed equally to this work. 25 pages\n",
    "authors": [
      "Yiming Li",
      "Yang Bai",
      "Yong Jiang",
      "Yong Yang",
      "Shu-Tao Xia",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00875"
  },
  {
    "id": "arXiv:2210.00881",
    "title": "Predicting the Future of AI with AI: High-quality link prediction in an  exponentially growing knowledge network",
    "abstract": "A tool that could suggest new personalized research directions and ideas by\ntaking insights from the scientific literature could significantly accelerate\nthe progress of science. A field that might benefit from such an approach is\nartificial intelligence (AI) research, where the number of scientific\npublications has been growing exponentially over the last years, making it\nchallenging for human researchers to keep track of the progress. Here, we use\nAI techniques to predict the future research directions of AI itself. We\ndevelop a new graph-based benchmark based on real-world data -- the\nScience4Cast benchmark, which aims to predict the future state of an evolving\nsemantic network of AI. For that, we use more than 100,000 research papers and\nbuild up a knowledge network with more than 64,000 concept nodes. We then\npresent ten diverse methods to tackle this task, ranging from pure statistical\nto pure learning methods. Surprisingly, the most powerful methods use a\ncarefully curated set of network features, rather than an end-to-end AI\napproach. It indicates a great potential that can be unleashed for purely ML\napproaches without human knowledge. Ultimately, better predictions of new\nfuture research directions will be a crucial component of more advanced\nresearch suggestion tools.",
    "descriptor": "\nComments: 13 pages, 7 figures. Comments welcome!\n",
    "authors": [
      "Mario Krenn",
      "Lorenzo Buffoni",
      "Bruno Coutinho",
      "Sagi Eppel",
      "Jacob Gates Foster",
      "Andrew Gritsevskiy",
      "Harlin Lee",
      "Yichao Lu",
      "Joao P. Moutinho",
      "Nima Sanjabi",
      "Rishi Sonthalia",
      "Ngoc Mai Tran",
      "Francisco Valente",
      "Yangxinyu Xie",
      "Rose Yu",
      "Michael Kopp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00881"
  },
  {
    "id": "arXiv:2210.00882",
    "title": "MSRL: Distributed Reinforcement Learning with Dataflow Fragments",
    "abstract": "Reinforcement learning~(RL) trains many agents, which is resource-intensive\nand must scale to large GPU clusters. Different RL training algorithms offer\ndifferent opportunities for distributing and parallelising the computation.\nYet, current distributed RL systems tie the definition of RL algorithms to\ntheir distributed execution: they hard-code particular distribution strategies\nand only accelerate specific parts of the computation (e.g. policy network\nupdates) on GPU workers. Fundamentally, current systems lack abstractions that\ndecouple RL algorithms from their execution.\nWe describe MindSpore Reinforcement Learning (MSRL), a distributed RL\ntraining system that supports distribution policies that govern how RL training\ncomputation is parallelised and distributed on cluster resources, without\nrequiring changes to the algorithm implementation. MSRL introduces the new\nabstraction of a fragmented dataflow graph, which maps Python functions from an\nRL algorithm's training loop to parallel computational fragments. Fragments are\nexecuted on different devices by translating them to low-level dataflow\nrepresentations, e.g. computational graphs as supported by deep learning\nengines, CUDA implementations or multi-threaded CPU processes. We show that\nMSRL subsumes the distribution strategies of existing systems, while scaling RL\ntraining to 64 GPUs.",
    "descriptor": "",
    "authors": [
      "Huanzhou Zhu",
      "Bo Zhao",
      "Gang Chen",
      "Weifeng Chen",
      "Yijie Chen",
      "Liang Shi",
      "Peter Pietzuch",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00882"
  },
  {
    "id": "arXiv:2210.00888",
    "title": "Smart-Badge: A wearable badge with multi-modal sensors for kitchen  activity recognition",
    "abstract": "Human health is closely associated with their daily behavior and environment.\nHowever, keeping a healthy lifestyle is still challenging for most people as it\nis difficult to recognize their living behaviors and identify their surrounding\nsituations to take appropriate action. Human activity recognition is a\npromising approach to building a behavior model of users, by which users can\nget feedback about their habits and be encouraged to develop a healthier\nlifestyle. In this paper, we present a smart light wearable badge with six\nkinds of sensors, including an infrared array sensor MLX90640 offering\nprivacy-preserving, low-cost, and non-invasive features, to recognize daily\nactivities in a realistic unmodified kitchen environment. A multi-channel\nconvolutional neural network (MC-CNN) based on data and feature fusion methods\nis applied to classify 14 human activities associated with potentially\nunhealthy habits. Meanwhile, we evaluate the impact of the infrared array\nsensor on the recognition accuracy of these activities. We demonstrate the\nperformance of the proposed work to detect the 14 activities performed by ten\nvolunteers with an average accuracy of 92.44 % and an F1 score of 88.27 %.",
    "descriptor": "\nComments: Presented at HASCA workshop of Ubicomp2022\n",
    "authors": [
      "Mengxi Liu",
      "Sungho Suh",
      "Bo Zhou",
      "Agnes Gruenerbl",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00888"
  },
  {
    "id": "arXiv:2210.00891",
    "title": "Information Removal at the bottleneck in Deep Neural Networks",
    "abstract": "Deep learning models are nowadays broadly deployed to solve an incredibly\nlarge variety of tasks. Commonly, leveraging over the availability of \"big\ndata\", deep neural networks are trained as black-boxes, minimizing an objective\nfunction at its output. This however does not allow control over the\npropagation of some specific features through the model, like gender or race,\nfor solving some an uncorrelated task. This raises issues either in the privacy\ndomain (considering the propagation of unwanted information) and of bias\n(considering that these features are potentially used to solve the given task).\nIn this work we propose IRENE, a method to achieve information removal at the\nbottleneck of deep neural networks, which explicitly minimizes the estimated\nmutual information between the features to be kept ``private'' and the target.\nExperiments on a synthetic dataset and on CelebA validate the effectiveness of\nthe proposed approach, and open the road towards the development of approaches\nguaranteeing information removal in deep neural networks.",
    "descriptor": "",
    "authors": [
      "Enzo Tartaglione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00891"
  },
  {
    "id": "arXiv:2210.00893",
    "title": "Combining Efficient and Precise Sign Language Recognition: Good pose  estimation library is all you need",
    "abstract": "Sign language recognition could significantly improve the user experience for\nd/Deaf people with the general consumer technology, such as IoT devices or\nvideoconferencing. However, current sign language recognition architectures are\nusually computationally heavy and require robust GPU-equipped hardware to run\nin real-time. Some models aim for lower-end devices (such as smartphones) by\nminimizing their size and complexity, which leads to worse accuracy. This\nhighly scrutinizes accurate in-the-wild applications. We build upon the SPOTER\narchitecture, which belongs to the latter group of light methods, as it came\nclose to the performance of large models employed for this task. By\nsubstituting its original third-party pose estimation module with the MediaPipe\nlibrary, we achieve an overall state-of-the-art result on the WLASL100 dataset.\nSignificantly, our method beats previous larger architectures while still being\ntwice as computationally efficient and almost $11$ times faster on inference\nwhen compared to a relevant benchmark. To demonstrate our method's combined\nefficiency and precision, we built an online demo that enables users to\ntranslate sign lemmas of American sign language in their browsers. This is the\nfirst publicly available online application demonstrating this task to the best\nof our knowledge.",
    "descriptor": "\nComments: 5 pages, 2 figures, CVPR 2022 AVA workshop extended abstract\n",
    "authors": [
      "Maty\u00e1\u0161 Boh\u00e1\u010dek",
      "Zhuo Cao",
      "Marek Hr\u00faz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00893"
  },
  {
    "id": "arXiv:2210.00894",
    "title": "A Novel Explainable Out-of-Distribution Detection Approach for Spiking  Neural Networks",
    "abstract": "Research around Spiking Neural Networks has ignited during the last years due\nto their advantages when compared to traditional neural networks, including\ntheir efficient processing and inherent ability to model complex temporal\ndynamics. Despite these differences, Spiking Neural Networks face similar\nissues than other neural computation counterparts when deployed in real-world\nsettings. This work addresses one of the practical circumstances that can\nhinder the trustworthiness of this family of models: the possibility of\nquerying a trained model with samples far from the distribution of its training\ndata (also referred to as Out-of-Distribution or OoD data). Specifically, this\nwork presents a novel OoD detector that can identify whether test examples\ninput to a Spiking Neural Network belong to the distribution of the data over\nwhich it was trained. For this purpose, we characterize the internal\nactivations of the hidden layers of the network in the form of spike count\npatterns, which lay a basis for determining when the activations induced by a\ntest instance is atypical. Furthermore, a local explanation method is devised\nto produce attribution maps revealing which parts of the input instance push\nmost towards the detection of an example as an OoD sample. Experimental results\nare performed over several image classification datasets to compare the\nproposed detector to other OoD detection schemes from the literature. As the\nobtained results clearly show, the proposed detector performs competitively\nagainst such alternative schemes, and produces relevance attribution maps that\nconform to expectations for synthetically created OoD instances.",
    "descriptor": "\nComments: 37 pages, 10 figures, under review\n",
    "authors": [
      "Aitor Martinez Seras",
      "Javier Del Ser",
      "Jesus L. Lobo",
      "Pablo Garcia-Bringas",
      "Nikola Kasabov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00894"
  },
  {
    "id": "arXiv:2210.00895",
    "title": "On Best-Arm Identification with a Fixed Budget in Non-Parametric  Multi-Armed Bandits",
    "abstract": "We lay the foundations of a non-parametric theory of best-arm identification\nin multi-armed bandits with a fixed budget T. We consider general, possibly\nnon-parametric, models D for distributions over the arms; an overarching\nexample is the model D = P(0,1) of all probability distributions over [0,1]. We\npropose upper bounds on the average log-probability of misidentifying the\noptimal arm based on information-theoretic quantities that correspond to infima\nover Kullback-Leibler divergences between some distributions in D and a given\ndistribution. This is made possible by a refined analysis of the\nsuccessive-rejects strategy of Audibert, Bubeck, and Munos (2010). We finally\nprovide lower bounds on the same average log-probability, also in terms of the\nsame new information-theoretic quantities; these lower bounds are larger when\nthe (natural) assumptions on the considered strategies are stronger. All these\nnew upper and lower bounds generalize existing bounds based, e.g., on gaps\nbetween distributions.",
    "descriptor": "",
    "authors": [
      "Antoine Barrier",
      "Aur\u00e9lien Garivier",
      "Gilles Stoltz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00895"
  },
  {
    "id": "arXiv:2210.00898",
    "title": "Robust $Q$-learning Algorithm for Markov Decision Processes under  Wasserstein Uncertainty",
    "abstract": "We present a novel $Q$-learning algorithm to solve distributionally robust\nMarkov decision problems, where the corresponding ambiguity set of transition\nprobabilities for the underlying Markov decision process is a Wasserstein ball\naround a (possibly estimated) reference measure. We prove convergence of the\npresented algorithm and provide several examples also using real data to\nillustrate both the tractability of our algorithm as well as the benefits of\nconsidering distributional robustness when solving stochastic optimal control\nproblems, in particular when the estimated distributions turn out to be\nmisspecified in practice.",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00898"
  },
  {
    "id": "arXiv:2210.00901",
    "title": "On the Salient Limitations of the Methods of Assembly Theory and their  Classification of Molecular Biosignatures",
    "abstract": "A recently introduced approach termed ``Assembly Theory\", featuring a\ncomputable index based on basic principles of statistical compression has been\nclaimed to be a novel and superior approach to classifying and distinguishing\nliving from non-living systems and the complexity of molecular biosignatures.\nHere, we demonstrate that the assembly pathway method underlying this index is\na suboptimal restricted version of Huffman's encoding (Fano-type), widely\nadopted in computer science in the 1950s, that is comparable (or inferior) to\nother popular statistical compression schemes. We show how simple modular\ninstructions can mislead the assembly index, leading to failure to capture\nsubtleties beyond trivial statistical properties that are pervasive in\nbiological systems. We present cases whose low complexities can arbitrarily\ndiverge from the random-like appearance to which the assembly pathway method\nwould assign arbitrarily high statistical significance, and show that it fails\nin simple cases (synthetic or natural). Our theoretical and empirical results\nimply that the assembly index, whose computable nature we show is not an\nadvantage, does not offer any substantial advantage over existing concepts and\nmethods. Alternatives are discussed.",
    "descriptor": "\nComments: 36 pages with the appendix, 3 figures\n",
    "authors": [
      "Abicumaran Uthamacumaran",
      "Felipe S. Abra\u00e3o",
      "Narsis A. Kiani",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00901"
  },
  {
    "id": "arXiv:2210.00902",
    "title": "AdaComm: Tracing Channel Dynamics for Reliable Cross-Technology  Communication",
    "abstract": "Cross-Technology Communication (CTC) is an emerging technology to support\ndirect communication between wireless devices that follow different standards.\nIn spite of the many different proposals from the community to enable CTC, the\nperformance aspect of CTC is an equally important problem but has seldom been\nstudied before. We find this problem is extremely challenging, due to the\nfollowing reasons: on one hand, a link for CTC is essentially different from a\nconventional wireless link. The conventional link indicators like RSSI\n(received signal strength indicator) and SNR (signal to noise ratio) cannot be\nused to directly characterize a CTC link. On the other hand, the indirect\nindicators like PER (packet error rate), which is adopted by many existing CTC\nproposals, cannot capture the short-term link behavior. As a result, the\nexisting CTC proposals fail to keep reliable performance under dynamic channel\nconditions. In order to address the above challenge, we in this paper propose\nAdaComm, a generic framework to achieve self-adaptive CTC in dynamic channels.\nInstead of reactively adjusting the CTC sender, AdaComm adopts online learning\nmechanism to adaptively adjust the decoding model at the CTC receiver. The\nself-adaptive decoding model automatically learns the effective features\ndirectly from the raw received signals that are embedded with the current\nchannel state. With the lossless channel information, AdaComm further adopts\nthe fine tuning and full training modes to cope with the continuous and abrupt\nchannel dynamics. We implement AdaComm and integrate it with two existing CTC\napproaches that respectively employ CSI (channel state information) and RSSI as\nthe information carrier. The evaluation results demonstrate that AdaComm can\nsignificantly reduce the SER (symbol error rate) by 72.9% and 49.2%,\nrespectively, compared with the existing approaches.",
    "descriptor": "",
    "authors": [
      "Weiguo Wang",
      "Xiaolong Zheng",
      "Yuan He",
      "Xiuzhen Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00902"
  },
  {
    "id": "arXiv:2210.00903",
    "title": "MotorBeat: Acoustic Communication for Home Appliances via Variable Pulse  Width Modulation",
    "abstract": "More and more home appliances are now connected to the Internet, thus\nenabling various smart home applications. However, a critical problem that may\nimpede the further development of smart home is overlooked: Small appliances\naccount for the majority of home appliances, but they receive little attention\nand most of them are cut off from the Internet. To fill this gap, we propose\nMotorBeat, an acoustic communication approach that connects small appliances to\na smart speaker. Our key idea is to exploit direct current (DC) motors, which\nare common components of small appliances, to transmit acoustic messages. We\ndesign a novel scheme named Variable Pulse Width Modulation (V-PWM) to drive DC\nmotors. MotorBeat achieves the following 3C goals: (1) Comfortable to hear, (2)\nCompatible with multiple motor modes, and (3) Concurrent transmission. We\nimplement MotorBeat with commercial devices and evaluate its performance on\nthree small appliances and ten DC motors. The results show that the\ncommunication range can be up to 10 m",
    "descriptor": "",
    "authors": [
      "Weiguo Wang",
      "Jinming Li",
      "Yuan He",
      "Xiuzhen Guo",
      "Yunhao Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.00903"
  },
  {
    "id": "arXiv:2210.00904",
    "title": "Towards Exascale for Wind Energy Simulations",
    "abstract": "We examine large-eddy-simulation modeling approaches and computational\nperformance of two open-source computational fluid dynamics codes for the\nsimulation of atmospheric boundary layer (ABL) flows that are of direct\nrelevance to wind energy production. The first is NekRS, a high-order,\nunstructured-grid, spectral element code. The second, AMR-Wind, is a\nblock-structured, second-order finite-volume code with adaptive-mesh-refinement\ncapabilities. The objective of this study is to co-develop these codes in order\nto improve model fidelity and performance for each. These features will be\ncritical for running ABL-based applications such as wind farm analysis on\nadvanced computing architectures. To this end, we investigate the performance\nof NekRS and AMR-Wind on the Oak Ridge Leadership Facility supercomputers\nSummit, using 4 to 800 nodes (24 to 4,800 NVIDIA V100 GPUs), and Crusher, the\ntestbed for the Frontier exascale system using 18 to 384 Graphics Compute Dies\non AMD MI250X GPUs. We compare strong- and weak-scaling capabilities, linear\nsolver performance, and time to solution. We also identify leading inhibitors\nto parallel scaling.",
    "descriptor": "\nComments: 13 pages, 7 figures, 6 tables\n",
    "authors": [
      "Misun Min",
      "Michael Brazell",
      "Ananias Tomboulides",
      "Matthew Churchfield",
      "Paul Fischer",
      "Michael Sprague"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.00904"
  },
  {
    "id": "arXiv:2210.00907",
    "title": "The Effectiveness of Masked Language Modeling and Adapters for Factual  Knowledge Injection",
    "abstract": "This paper studies the problem of injecting factual knowledge into large\npre-trained language models. We train adapter modules on parts of the\nConceptNet knowledge graph using the masked language modeling objective and\nevaluate the success of the method by a series of probing experiments on the\nLAMA probe. Mean P@K curves for different configurations indicate that the\ntechnique is effective, increasing the performance on subsets of the LAMA probe\nfor large values of k by adding as little as 2.1% additional parameters to the\noriginal models.",
    "descriptor": "\nComments: Camera ready version for the 16th TextGraphs workshop, located at Coling 2022\n",
    "authors": [
      "Sondre Wold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00907"
  },
  {
    "id": "arXiv:2210.00910",
    "title": "Hypothesis Engineering for Zero-Shot Hate Speech Detection",
    "abstract": "Standard approaches to hate speech detection rely on sufficient available\nhate speech annotations. Extending previous work that repurposes natural\nlanguage inference (NLI) models for zero-shot text classification, we propose a\nsimple approach that combines multiple hypotheses to improve English NLI-based\nzero-shot hate speech detection. We first conduct an error analysis for vanilla\nNLI-based zero-shot hate speech detection and then develop four strategies\nbased on this analysis. The strategies use multiple hypotheses to predict\nvarious aspects of an input text and combine these predictions into a final\nverdict. We find that the zero-shot baseline used for the initial error\nanalysis already outperforms commercial systems and fine-tuned BERT-based hate\nspeech detection models on HateCheck. The combination of the proposed\nstrategies further increases the zero-shot accuracy of 79.4% on HateCheck by\n7.9 percentage points (pp), and the accuracy of 69.6% on ETHOS by 10.0pp.",
    "descriptor": "\nComments: Third Workshop on Threat, Aggression and Cyberbullying (COLING 2022)\n",
    "authors": [
      "Janis Goldzycher",
      "Gerold Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00910"
  },
  {
    "id": "arXiv:2210.00911",
    "title": "Learning Equivariant Segmentation with Instance-Unique Querying",
    "abstract": "Prevalent state-of-the-art instance segmentation methods fall into a\nquery-based scheme, in which instance masks are derived by querying the image\nfeature using a set of instance-aware embeddings. In this work, we devise a new\ntraining framework that boosts query-based models through discriminative query\nembedding learning. It explores two essential properties, namely dataset-level\nuniqueness and transformation equivariance, of the relation between queries and\ninstances. First, our algorithm uses the queries to retrieve the corresponding\ninstances from the whole training dataset, instead of only searching within\nindividual scenes. As querying instances across scenes is more challenging, the\nsegmenters are forced to learn more discriminative queries for effective\ninstance separation. Second, our algorithm encourages both image (instance)\nrepresentations and queries to be equivariant against geometric\ntransformations, leading to more robust, instance-query matching. On top of\nfour famous, query-based models ($i.e.,$ CondInst, SOLOv2, SOTR, and\nMask2Former), our training algorithm provides significant performance gains\n($e.g.,$ +1.6 - 3.2 AP) on COCO dataset. In addition, our algorithm promotes\nthe performance of SOLOv2 by 2.7 AP, on LVISv1 dataset.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022; Code: this https URL\n",
    "authors": [
      "Wenguan Wang",
      "James Liang",
      "Dongfang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00911"
  },
  {
    "id": "arXiv:2210.00912",
    "title": "Federated Domain Generalization for Image Recognition via Cross-Client  Style Transfer",
    "abstract": "Domain generalization (DG) has been a hot topic in image recognition, with a\ngoal to train a general model that can perform well on unseen domains.\nRecently, federated learning (FL), an emerging machine learning paradigm to\ntrain a global model from multiple decentralized clients without compromising\ndata privacy, brings new challenges, also new possibilities, to DG. In the FL\nscenario, many existing state-of-the-art (SOTA) DG methods become ineffective,\nbecause they require the centralization of data from different domains during\ntraining. In this paper, we propose a novel domain generalization method for\nimage recognition under federated learning through cross-client style transfer\n(CCST) without exchanging data samples. Our CCST method can lead to more\nuniform distributions of source clients, and thus make each local model learn\nto fit the image styles of all the clients to avoid the different model biases.\nTwo types of style (single image style and overall domain style) with\ncorresponding mechanisms are proposed to be chosen according to different\nscenarios. Our style representation is exceptionally lightweight and can hardly\nbe used for the reconstruction of the dataset. The level of diversity is also\nflexible to be controlled with a hyper-parameter. Our method outperforms recent\nSOTA DG methods on two DG benchmarks (PACS, OfficeHome) and a large-scale\nmedical image dataset (Camelyon17) in the FL setting. Last but not least, our\nmethod is orthogonal to many classic DG methods, achieving additive performance\nby combined utilization.",
    "descriptor": "\nComments: Accepted by WACV 2023\n",
    "authors": [
      "Junming Chen",
      "Meirui Jiang",
      "Qi Dou",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00912"
  },
  {
    "id": "arXiv:2210.00917",
    "title": "A stable loosely-coupled scheme for cardiac electro-fluid-structure  interaction",
    "abstract": "We present a loosely coupled scheme for the numerical simulation of the\ncardiac electro-fluid-structure interaction problem, whose solution is\ntypically computationally intensive due to the need to suitably treat the\ncoupling of the different submodels. Our scheme relies on a segregated\ntreatment of the subproblems, in particular on an explicit Robin-Neumann\nalgorithm for the fluid-structure interaction, aiming at reducing the\ncomputational burden of numerical simulations. The results, both in an ideal\nand a realistic cardiac setting, show that the proposed scheme is stable at the\nregimes typical of cardiac simulations. From a comparison with a scheme with\nimplicit fluid-structure interaction, it emerges that, while conservation\nproperties are not fully preserved, computational times significantly benefit\nfrom the explicit scheme. Overall, the explicit discretization represents a\ngood trade-off between accuracy and cost, and is a valuable alternative to\nimplicit schemes for fast large-scale simulations.",
    "descriptor": "",
    "authors": [
      "Michele Bucelli",
      "Martin Geraint Gabriel",
      "Giacomo Gigante",
      "Alfio Quarteroni",
      "Christian Vergara"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00917"
  },
  {
    "id": "arXiv:2210.00918",
    "title": "Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based  Virtual Try-On",
    "abstract": "Previous virtual try-on methods usually focus on aligning a clothing item\nwith a person, limiting their ability to exploit the complex pose, shape and\nskin color of the person, as well as the overall structure of the clothing,\nwhich is vital to photo-realistic virtual try-on. To address this potential\nweakness, we propose a fill in fabrics (FIFA) model, a self-supervised\nconditional generative adversarial network based framework comprised of a\nFabricator and a unified virtual try-on pipeline with a Segmenter, Warper and\nFuser. The Fabricator aims to reconstruct the clothing image when provided with\na masked clothing as input, and learns the overall structure of the clothing by\nfilling in fabrics. A virtual try-on pipeline is then trained by transferring\nthe learned representations from the Fabricator to Warper in an effort to warp\nand refine the target clothing. We also propose to use a multi-scale structural\nconstraint to enforce global context at multiple scales while warping the\ntarget clothing to better fit the pose and shape of the person. Extensive\nexperiments demonstrate that our FIFA model achieves state-of-the-art results\non the standard VITON dataset for virtual try-on of clothing items, and is\nshown to be effective at handling complex poses and retaining the texture and\nembroidery of the clothing.",
    "descriptor": "",
    "authors": [
      "H. Zunair",
      "Y. Gobeil",
      "S. Mercier",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00918"
  },
  {
    "id": "arXiv:2210.00920",
    "title": "Unbiased Scene Graph Generation using Predicate Similarities",
    "abstract": "Scene Graphs are widely applied in computer vision as a graphical\nrepresentation of relationships between objects shown in images. However, these\napplications have not yet reached a practical stage of development owing to\nbiased training caused by long-tailed predicate distributions. In recent years,\nmany studies have tackled this problem. In contrast, relatively few works have\nconsidered predicate similarities as a unique dataset feature which also leads\nto the biased prediction. Due to the feature, infrequent predicates (e.g.,\nparked on, covered in) are easily misclassified as closely-related frequent\npredicates (e.g., on, in). Utilizing predicate similarities, we propose a new\nclassification scheme that branches the process to several fine-grained\nclassifiers for similar predicate groups. The classifiers aim to capture the\ndifferences among similar predicates in detail. We also introduce the idea of\ntransfer learning to enhance the features for the predicates which lack\nsufficient training samples to learn the descriptive representations. The\nresults of extensive experiments on the Visual Genome dataset show that the\ncombination of our method and an existing debiasing approach greatly improves\nperformance on tail predicates in challenging SGCls/SGDet tasks. Nonetheless,\nthe overall performance of the proposed approach does not reach that of the\ncurrent state of the art, so further analysis remains necessary as future work.",
    "descriptor": "",
    "authors": [
      "Misaki Ohashi",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00920"
  },
  {
    "id": "arXiv:2210.00923",
    "title": "Masked Supervised Learning for Semantic Segmentation",
    "abstract": "Self-attention is of vital importance in semantic segmentation as it enables\nmodeling of long-range context, which translates into improved performance. We\nargue that it is equally important to model short-range context, especially to\ntackle cases where not only the regions of interest are small and ambiguous,\nbut also when there exists an imbalance between the semantic classes. To this\nend, we propose Masked Supervised Learning (MaskSup), an effective single-stage\nlearning paradigm that models both short- and long-range context, capturing the\ncontextual relationships between pixels via random masking. Experimental\nresults demonstrate the competitive performance of MaskSup against strong\nbaselines in both binary and multi-class segmentation tasks on three standard\nbenchmark datasets, particularly at handling ambiguous regions and retaining\nbetter segmentation of minority classes with no added inference cost. In\naddition to segmenting target regions even when large portions of the input are\nmasked, MaskSup is also generic and can be easily integrated into a variety of\nsemantic segmentation methods. We also show that the proposed method is\ncomputationally efficient, yielding an improved performance by 10\\% on the mean\nintersection-over-union (mIoU) while requiring $3\\times$ less learnable\nparameters.",
    "descriptor": "",
    "authors": [
      "H. Zunair",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00923"
  },
  {
    "id": "arXiv:2210.00924",
    "title": "Multi-view object pose estimation from correspondence distributions and  epipolar geometry",
    "abstract": "In many automation tasks involving manipulation of rigid objects, the poses\nof the objects must be acquired. Vision-based pose estimation using a single\nRGB or RGB-D sensor is especially popular due to its broad applicability.\nHowever, single-view pose estimation is inherently limited by depth ambiguity\nand ambiguities imposed by various phenomena like occlusion, self-occlusion,\nreflections, etc. Aggregation of information from multiple views can\npotentially resolve these ambiguities, but the current state-of-the-art\nmulti-view pose estimation method only uses multiple views to aggregate\nsingle-view pose estimates, and thus rely on obtaining good single-view\nestimates. We present a multi-view pose estimation method which aggregates\nlearned 2D-3D distributions from multiple views for both the initial estimate\nand optional refinement. Our method performs probabilistic sampling of 3D-3D\ncorrespondences under epipolar constraints using learned 2D-3D correspondence\ndistributions which are implicitly trained to respect visual ambiguities such\nas symmetry. Evaluation on the T-LESS dataset shows that our method reduces\npose estimation errors by 80-91% compared to the best single-view method, and\nwe present state-of-the-art results on T-LESS with four views, even compared\nwith methods using five and eight views.",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 table\n",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00924"
  },
  {
    "id": "arXiv:2210.00933",
    "title": "Perceptual Attacks of No-Reference Image Quality Models with  Human-in-the-Loop",
    "abstract": "No-reference image quality assessment (NR-IQA) aims to quantify how humans\nperceive visual distortions of digital images without access to their\nundistorted references. NR-IQA models are extensively studied in computational\nvision, and are widely used for performance evaluation and perceptual\noptimization of man-made vision systems. Here we make one of the first attempts\nto examine the perceptual robustness of NR-IQA models. Under a Lagrangian\nformulation, we identify insightful connections of the proposed perceptual\nattack to previous beautiful ideas in computer vision and machine learning. We\ntest one knowledge-driven and three data-driven NR-IQA methods under four\nfull-reference IQA models (as approximations to human perception of\njust-noticeable differences). Through carefully designed psychophysical\nexperiments, we find that all four NR-IQA models are vulnerable to the proposed\nperceptual attack. More interestingly, we observe that the generated\ncounterexamples are not transferable, manifesting themselves as distinct design\nflows of respective NR-IQA methods.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Weixia Zhang",
      "Dingquan Li",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Guodong Guo",
      "Xiaokang Yang",
      "Kede Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.00933"
  },
  {
    "id": "arXiv:2210.00934",
    "title": "Still Unsolved High-Performance Computing Challenges for up to  Pre-Petascale Homogeneous Supercomputers",
    "abstract": "Pre-exascale High Performance Computers (HPC) can reach more than 400 Pflop/s\nreal perfor-mance according the HPLinpack benchmarks. For nanoscience and\nquantum biology there are requirements for those program codes based on quantum\nphysics algorithms which is difficult to ideally parallelize. Such parallel\ncodes reach their limitations at terascale performance clus-ters. The standard\nAmdahl's law suggestions for code parallelization complicates focusing and\nplanning for the next step the parallel code developments. In this report we\nfocused on a three key applications domain which are highly parallelizable: HPC\nbenchmarks, quantum compu-ting simulators and Car-Parinello molecular dynamics.\nAccording the results we summarize the Amdahl's Law & Parallel Speedup\nperformance achievements with supercomputer with pre-petascale homogeneous HPC\nhardware. We conclude as an universal computer the pre-petascale supercomputing\nperformance homogeneous hardware still has the basic challeng-es which must be\naddressed by the researchers or developer in order efficiently to use them.",
    "descriptor": "",
    "authors": [
      "Mindaugas Macernis",
      "Vaidotas Mickus",
      "Janne Ahonen",
      "Laurynas Diska",
      "Jonas Franukevicius",
      "Juozas Sulskus"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00934"
  },
  {
    "id": "arXiv:2210.00935",
    "title": "Analysis of (sub-)Riemannian PDE-G-CNNs",
    "abstract": "Group equivariant convolutional neural networks (G-CNNs) have been\nsuccessfully applied in geometric deep-learning. Typically, G-CNNs have the\nadvantage over CNNs that they do not waste network capacity on training\nsymmetries that should have been hard-coded in the network. The recently\nintroduced framework of PDE-based G-CNNs (PDE-G-CNNs) generalize G-CNNs.\nPDE-G-CNNs have the core advantages that they simultaneously 1) reduce network\ncomplexity, 2) increase classification performance, 3) provide geometric\nnetwork interpretability. Their implementations solely consist of linear and\nmorphological convolutions with kernels.\nIn this paper we show that the previously suggested approximative\nmorphological kernels do not always approximate the exact kernels accurately.\nMore specifically, depending on the spatial anisotropy of the Riemannian\nmetric, we argue that one must resort to sub-Riemannian approximations. We\nsolve this problem by providing a new approximative kernel that works\nregardless of the anisotropy. We provide new theorems with better error\nestimates of the approximative kernels, and prove that they all carry the same\nreflectional symmetries as the exact ones.\nWe test the effectiveness of multiple approximative kernels within the\nPDE-G-CNN framework on two datasets, and observe an improvement with the new\napproximative kernel. We report that the PDE-G-CNNs again allow for a\nconsiderable reduction of network complexity while having a comparable or\nbetter performance than G-CNNs and CNNs on the two datasets. Moreover,\nPDE-G-CNNs have the advantage of better geometric interpretability over G-CNNs,\nas the morphological kernels are related to association fields from\nneurogeometry.",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Gijs Bellaard",
      "Daan Bon",
      "Gautam Pai",
      "Bart Smets",
      "Remco Duits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2210.00935"
  },
  {
    "id": "arXiv:2210.00939",
    "title": "Improving Sample Quality of Diffusion Model Using Self-Attention  Guidance",
    "abstract": "Following generative adversarial networks (GANs), a de facto standard model\nfor image generation, denoising diffusion models (DDMs) have been actively\nresearched and attracted strong attention due to their capability to generate\nimages with high quality and diversity. However, the way the internal\nself-attention mechanism works inside the UNet of DDMs is under-explored. To\nunveil them, in this paper, we first investigate the self-attention operations\nwithin the black-boxed diffusion models and build hypotheses. Next, we verify\nthe hypotheses about the self-attention map by conducting frequency analysis\nand testing the relationships with the generated objects. In consequence, we\nfind out that the attention map is closely related to the quality of generated\nimages. On the other hand, diffusion guidance methods based on additional\ninformation such as labels are proposed to improve the quality of generated\nimages. Inspired by these methods, we present label-free guidance based on the\nintermediate self-attention map that can guide existing pretrained diffusion\nmodels to generate images with higher fidelity. In addition to the enhanced\nsample quality when used alone, we show that the results are further improved\nby combining our method with classifier guidance on ImageNet 128x128.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Susung Hong",
      "Gyuseong Lee",
      "Wooseok Jang",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00939"
  },
  {
    "id": "arXiv:2210.00940",
    "title": "How Relevant is Selective Memory Population in Lifelong Language  Learning?",
    "abstract": "Lifelong language learning seeks to have models continuously learn multiple\ntasks in a sequential order without suffering from catastrophic forgetting.\nState-of-the-art approaches rely on sparse experience replay as the primary\napproach to prevent forgetting. Experience replay usually adopts sampling\nmethods for the memory population; however, the effect of the chosen sampling\nstrategy on model performance has not yet been studied. In this paper, we\ninvestigate how relevant the selective memory population is in the lifelong\nlearning process of text classification and question-answering tasks. We found\nthat methods that randomly store a uniform number of samples from the entire\ndata stream lead to high performances, especially for low memory size, which is\nconsistent with computer vision studies.",
    "descriptor": "\nComments: Accepted paper at AACL2022\n",
    "authors": [
      "Vladimir Araujo",
      "Helena Balabin",
      "Julio Hurtado",
      "Alvaro Soto",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00940"
  },
  {
    "id": "arXiv:2210.00941",
    "title": "Unsupervised Multimodal Change Detection Based on Structural  Relationship Graph Representation Learning",
    "abstract": "Unsupervised multimodal change detection is a practical and challenging topic\nthat can play an important role in time-sensitive emergency applications. To\naddress the challenge that multimodal remote sensing images cannot be directly\ncompared due to their modal heterogeneity, we take advantage of two types of\nmodality-independent structural relationships in multimodal images. In\nparticular, we present a structural relationship graph representation learning\nframework for measuring the similarity of the two structural relationships.\nFirstly, structural graphs are generated from preprocessed multimodal image\npairs by means of an object-based image analysis approach. Then, a structural\nrelationship graph convolutional autoencoder (SR-GCAE) is proposed to learn\nrobust and representative features from graphs. Two loss functions aiming at\nreconstructing vertex information and edge information are presented to make\nthe learned representations applicable for structural relationship similarity\nmeasurement. Subsequently, the similarity levels of two structural\nrelationships are calculated from learned graph representations and two\ndifference images are generated based on the similarity levels. After obtaining\nthe difference images, an adaptive fusion strategy is presented to fuse the two\ndifference images. Finally, a morphological filtering-based postprocessing\napproach is employed to refine the detection results. Experimental results on\nfive datasets with different modal combinations demonstrate the effectiveness\nof the proposed method.",
    "descriptor": "",
    "authors": [
      "Hongruixuan Chen",
      "Naoto Yokoya",
      "Chen Wu",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00941"
  },
  {
    "id": "arXiv:2210.00944",
    "title": "Attention Distillation: self-supervised vision transformer students need  more guidance",
    "abstract": "Self-supervised learning has been widely applied to train high-quality vision\ntransformers. Unleashing their excellent performance on memory and compute\nconstraint devices is therefore an important research topic. However, how to\ndistill knowledge from one self-supervised ViT to another has not yet been\nexplored. Moreover, the existing self-supervised knowledge distillation (SSKD)\nmethods focus on ConvNet based architectures are suboptimal for ViT knowledge\ndistillation. In this paper, we study knowledge distillation of self-supervised\nvision transformers (ViT-SSKD). We show that directly distilling information\nfrom the crucial attention mechanism from teacher to student can significantly\nnarrow the performance gap between both. In experiments on ImageNet-Subset and\nImageNet-1K, we show that our method AttnDistill outperforms existing\nself-supervised knowledge distillation (SSKD) methods and achieves\nstate-of-the-art k-NN accuracy compared with self-supervised learning (SSL)\nmethods learning from scratch (with the ViT-S model). We are also the first to\napply the tiny ViT-T model on self-supervised learning. Moreover, AttnDistill\nis independent of self-supervised learning algorithms, it can be adapted to ViT\nbased SSL methods to improve the performance in future research. The code is\nhere: https://github.com/wangkai930418/attndistill",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Kai Wang",
      "Fei Yang",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00944"
  },
  {
    "id": "arXiv:2210.00945",
    "title": "Cooperative Multi-Agent Deep Reinforcement Learning for Reliable and  Energy-Efficient Mobile Access via Multi-UAV Control",
    "abstract": "This paper addresses a novel multi-agent deep reinforcement learning\n(MADRL)-based multiple unmanned aerial vehicles (UAV) positioning algorithm for\nreliable mobile access services (i.e., UAVs work as mobile base stations),\nwhere the MADRL is designed by the concept of centralized training and\ndistributed execution (CTDE) for multi-agent cooperation and coordination. The\nreliable mobile access services can be achieved in following two ways, i.e.,\n(i) energy-efficient UAV operation and (ii) reliable wireless communication\nservices. For energy-efficient UAV operation, the reward of our proposed MADRL\nalgorithm contains the features for UAV energy consumption models in order to\nrealize efficient operations. Furthermore, for reliable wireless communication\nservices, the quality of service (QoS) requirements of individual users are\nconsidered as a part of rewards and 60GHz mmWave radio is used for mobile\naccess. This paper considers the 60GHz mmWave access for utilizing the benefits\nof (i) ultra-wide-bandwidth for multi-Gbps high-speed communications and (ii)\nhigh-directional communications for spatial reuse that is obviously good for\ndensely deployed users. Lastly, the performance of our proposed MADRL-based\nmulti-UAV positioning algorithm is evaluated; and it can be confirmed that the\nproposed algorithm outperforms the other existing algorithms.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Chanyoung Park",
      "Haemin Lee",
      "Won Joon Yun",
      "Soyi Jung",
      "Carlos Cordeiro",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00945"
  },
  {
    "id": "arXiv:2210.00946",
    "title": "A generic polynomial time approach to separation by first-order logic  without quantifier alternation",
    "abstract": "We look at classes of languages associated to the fragment of first-order\nlogic B{\\Sigma}1 which disallows quantifier alternations. Each class is defined\nby choosing the set of predicates on positions that may be used. Two key such\nfragments are those equipped with the linear ordering and possibly the\nsuccessor relation. It is known that these two variants have decidable\nmembership: \"does an input regular language belong to the class ?\". We rely on\na characterization of B{\\Sigma}1 by the operator BPol: given an input class C,\nit outputs a class BPol(C) that corresponds to a variant of B{\\Sigma}1 equipped\nwith special predicates associated to C. We extend these results in two\northogonal directions. First, we use two kinds of inputs: classes G of group\nlanguages (i.e., recognized by a DFA in which each letter induces a permutation\nof the states) and extensions thereof, written G+. The classes BPol(G) and\nBPol(G+) capture many variants of B{\\Sigma}1 which use predicates such as the\nlinear ordering, the successor, the modular predicates or the alphabetic\nmodular predicates.\nSecond, instead of membership, we explore the more general separation\nproblem: decide if two regular languages can be separated by a language from\nthe class under study. We show it is decidable for BPol(G) and BPol(G+) when\nthis is the case for G. This was known for BPol(G) and for two particular\nclasses BPol(G+). Yet, the algorithms were indirect and relied on involved\nframeworks, yielding poor upper complexity bounds. Our approach is direct. We\nwork with elementary concepts (mainly, finite automata). Our main contribution\nconsists in polynomial time Turing reductions from both BPol(G)- and\nBPol(G+)-separation to G-separation. This yields polynomial algorithms for key\nvariants of B{\\Sigma}1, including those equipped with the linear ordering and\npossibly the successor and/or the modular predicates.",
    "descriptor": "",
    "authors": [
      "Thomas Place",
      "Marc Zeitoun"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.00946"
  },
  {
    "id": "arXiv:2210.00947",
    "title": "An efficient topology optimization based on multigrid assisted  reanalysis for heat transfer problem",
    "abstract": "To improve the computational efficiency of heat transfer topology\noptimization, a Multigrid Assisted Reanalysis (MGAR) method is proposed in this\nstudy. The MGAR not only significantly improves the computational efficiency,\nbut also relieves the hardware burden, and thus can efficiently solve\nlarge-scale heat transfer topology optimization problems. In addition, a\nprojection-based post-processing strategy is also proposed and integrated with\na continuous density filtering strategy to successfully obtain smooth boundary\nwhile eliminating some small-sized features. Several 2D and 3D numerical\nexamples demonstrate that the computational efficiency of the MGAR is close to\nor even higher than that of the MGCG with almost identical optimization\nresults, moreover, the efficiency improvement in the 3D scenario is superior\nthan that of the 2D scenario, which reveals the excellent potential of the MGAR\nto save computational cost for large-scale problems.",
    "descriptor": "\nComments: 35 pages, 21 figures\n",
    "authors": [
      "Jichao Yin",
      "Hu Wang",
      "Daozhen Guo",
      "Shuhao Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.00947"
  },
  {
    "id": "arXiv:2210.00949",
    "title": "Module-wise Training of Residual Networks via the Minimizing Movement  Scheme",
    "abstract": "Greedy layer-wise or module-wise training of neural networks is compelling in\nconstrained and on-device settings, as it circumvents a number of problems of\nend-to-end back-propagation. However, it suffers from a stagnation problem,\nwhereby early layers overfit and deeper layers stop increasing the test\naccuracy after a certain depth. We propose to solve this issue by introducing a\nsimple module-wise regularization inspired by the minimizing movement scheme\nfor gradient flows in distribution space. The method, which we call TRGL for\nTransport Regularized Greedy Learning, is particularly well-adapted to residual\nnetworks. We study it theoretically, proving that it leads to greedy modules\nthat are regular and that successively solve the task. Experimentally, we show\nimproved accuracy of module-wise trained networks when our regularization is\nadded.",
    "descriptor": "\nComments: 1st International Workshop on Practical Deep Learning in the Wild AAAI 2022\n",
    "authors": [
      "Skander Karkar",
      "Ibrahim Ayed",
      "Emmanuel de B\u00e9zenac",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00949"
  },
  {
    "id": "arXiv:2210.00951",
    "title": "Hierarchical I3D for Sign Spotting",
    "abstract": "Most of the vision-based sign language research to date has focused on\nIsolated Sign Language Recognition (ISLR), where the objective is to predict a\nsingle sign class given a short video clip. Although there has been significant\nprogress in ISLR, its real-life applications are limited. In this paper, we\nfocus on the challenging task of Sign Spotting instead, where the goal is to\nsimultaneously identify and localise signs in continuous co-articulated sign\nvideos. To address the limitations of current ISLR-based models, we propose a\nhierarchical sign spotting approach which learns coarse-to-fine spatio-temporal\nsign features to take advantage of representations at various temporal levels\nand provide more precise sign localisation. Specifically, we develop\nHierarchical Sign I3D model (HS-I3D) which consists of a hierarchical network\nhead that is attached to the existing spatio-temporal I3D model to exploit\nfeatures at different layers of the network. We evaluate HS-I3D on the ChaLearn\n2022 Sign Spotting Challenge - MSSL track and achieve a state-of-the-art 0.607\nF1 score, which was the top-1 winning solution of the competition.",
    "descriptor": "",
    "authors": [
      "Ryan Wong",
      "Necati Cihan Camg\u00f6z",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00951"
  },
  {
    "id": "arXiv:2210.00954",
    "title": "Machine Learning-powered Course Allocation",
    "abstract": "We introduce a machine learning-powered course allocation mechanism.\nConcretely, we extend the state-of-the-art Course Match mechanism with a\nmachine learning-based preference elicitation module. In an iterative,\nasynchronous manner, this module generates pairwise comparison queries that are\ntailored to each individual student. Regarding incentives, our machine\nlearning-powered course match (MLCM) mechanism retains the attractive\nstrategyproofness in the large property of Course Match. Regarding welfare, we\nperform computational experiments using a simulator that was fitted to\nreal-world data. We find that, compared to Course Match, MLCM is able to\nincrease average student utility by 4%-9% and minimum student utility by\n10%-21%, even with only ten comparison queries.",
    "descriptor": "",
    "authors": [
      "Ermis Soumalias",
      "Behnoosh Zamanlooy",
      "Jakob Weissteiner",
      "Sven Seuken"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00954"
  },
  {
    "id": "arXiv:2210.00956",
    "title": "Minimizing Age of Processed Information in Wireless Networks",
    "abstract": "The freshness of real-time status processing of time-sensitive information is\ncrucial for several applications, including healthcare monitoring and\nautonomous vehicles. This freshness is considered in this paper for the system\nwhere unprocessed information is sent from sensors to a base station over a\nshared wireless network. The base station has a dedicated non-preemptive\nprocessor with a constant processing time to process information from each\nsensor. The age of processed information is the time elapsed since the\ngeneration of the packet that was most recently processed by a processor. Our\nobjective is to minimize the average age of processed information over an\ninfinite time-horizon. We first show that a drop-free policy simplifies the\nsystem without sacrificing optimality. From this simplification, we propose\nthree transmission-scheduling policies with 2-optimal guarantees for different\nrequirements. A distributed Power-2 policy can be implemented without a central\nscheduler. With a central scheduler, both Back-Off and Max-Weight policies are\nnear optimal with different advantages. The Back-Off policy guarantees a bound\non the maximum age of processed information, while the Max-Weight policy\nachieves the lowest average age in simulation without the guarantee of bound.\nSimulation results confirm our theoretical findings.",
    "descriptor": "\nComments: 13 pages,5 figures\n",
    "authors": [
      "Chanikarn Nikunram",
      "Wasin Meesena",
      "Stephen John Turner",
      "Sucha Supittayapornpong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.00956"
  },
  {
    "id": "arXiv:2210.00957",
    "title": "UnGANable: Defending Against GAN-based Face Manipulation",
    "abstract": "Deepfakes pose severe threats of visual misinformation to our society. One\nrepresentative deepfake application is face manipulation that modifies a\nvictim's facial attributes in an image, e.g., changing her age or hair color.\nThe state-of-the-art face manipulation techniques rely on Generative\nAdversarial Networks (GANs). In this paper, we propose the first defense\nsystem, namely UnGANable, against GAN-inversion-based face manipulation. In\nspecific, UnGANable focuses on defending GAN inversion, an essential step for\nface manipulation. Its core technique is to search for alternative images\n(called cloaked images) around the original images (called target images) in\nimage space. When posted online, these cloaked images can jeopardize the GAN\ninversion process. We consider two state-of-the-art inversion techniques\nincluding optimization-based inversion and hybrid inversion, and design five\ndifferent defenses under five scenarios depending on the defender's background\nknowledge. Extensive experiments on four popular GAN models trained on two\nbenchmark face datasets show that UnGANable achieves remarkable effectiveness\nand utility performance, and outperforms multiple baseline methods. We further\ninvestigate four adaptive adversaries to bypass UnGANable and show that some of\nthem are slightly effective.",
    "descriptor": "\nComments: Accepted by USENIX Security 2023\n",
    "authors": [
      "Zheng Li",
      "Ning Yu",
      "Ahmed Salem",
      "Michael Backes",
      "Mario Fritz",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00957"
  },
  {
    "id": "arXiv:2210.00960",
    "title": "Stability Analysis and Generalization Bounds of Adversarial Training",
    "abstract": "In adversarial machine learning, deep neural networks can fit the adversarial\nexamples on the training dataset but have poor generalization ability on the\ntest set. This phenomenon is called robust overfitting, and it can be observed\nwhen adversarially training neural nets on common datasets, including SVHN,\nCIFAR-10, CIFAR-100, and ImageNet. In this paper, we study the robust\noverfitting issue of adversarial training by using tools from uniform\nstability. One major challenge is that the outer function (as a maximization of\nthe inner function) is nonsmooth, so the standard technique (e.g., hardt et\nal., 2016) cannot be applied. Our approach is to consider $\\eta$-approximate\nsmoothness: we show that the outer function satisfies this modified smoothness\nassumption with $\\eta$ being a constant related to the adversarial\nperturbation. Based on this, we derive stability-based generalization bounds\nfor stochastic gradient descent (SGD) on the general class of\n$\\eta$-approximate smooth functions, which covers the adversarial loss. Our\nresults provide a different understanding of robust overfitting from the\nperspective of uniform stability. Additionally, we show that a few popular\ntechniques for adversarial training (\\emph{e.g.,} early stopping, cyclic\nlearning rate, and stochastic weight averaging) are stability-promoting in\ntheory.",
    "descriptor": "\nComments: Published as a conference paper in NeurIPS2022\n",
    "authors": [
      "Jiancong Xiao",
      "Yanbo Fan",
      "Ruoyu Sun",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00960"
  },
  {
    "id": "arXiv:2210.00961",
    "title": "Control and Evaluation of a Humanoid Robot with Rolling Contact Knees",
    "abstract": "In this paper, we introduce the humanoid robot DRACO 3 by providing a\nhigh-level description of its design and control. This robot features proximal\nactuation and mechanical artifacts to provide a high range of hip, knee and\nankle motion. Its versatile design brings interesting problems as it requires a\nmore elaborate control system to perform its motions. For this reason, we\nintroduce a whole body controller (WBC) with support for rolling contact joints\nand show how it can be easily integrated into our previously presented\nopen-source Planning and Control (PnC) framework. We then validate our\ncontroller experimentally on DRACO 3 by showing preliminary results carrying\nout two postural tasks. Lastly, we analyze the impact of the proximal actuation\ndesign and show where it stands in comparison to other adult-size humanoids.",
    "descriptor": "",
    "authors": [
      "Seung Hyeon Bang",
      "Carlos Gonzalez",
      "Junhyeok Ahn",
      "Nicholas Paine",
      "Luis Sentis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00961"
  },
  {
    "id": "arXiv:2210.00965",
    "title": "Green Learning: Introduction, Examples and Outlook",
    "abstract": "Rapid advances in artificial intelligence (AI) in the last decade have\nlargely been built upon the wide applications of deep learning (DL). However,\nthe high carbon footprint yielded by larger and larger DL networks becomes a\nconcern for sustainability. Furthermore, DL decision mechanism is somewhat\nobsecure and can only be verified by test data. Green learning (GL) has been\nproposed as an alternative paradigm to address these concerns. GL is\ncharacterized by low carbon footprints, small model sizes, low computational\ncomplexity, and logical transparency. It offers energy-effective solutions in\ncloud centers as well as mobile/edge devices. GL also provides a clear and\nlogical decision-making process to gain people's trust. Several statistical\ntools have been developed to achieve this goal in recent years. They include\nsubspace approximation, unsupervised and supervised representation learning,\nsupervised discriminant feature selection, and feature space partitioning. We\nhave seen a few successful GL examples with performance comparable with\nstate-of-the-art DL solutions. This paper offers an introduction to GL, its\ndemonstrated applications, and future outlook.",
    "descriptor": "",
    "authors": [
      "C.-C. Jay Kuo",
      "Azad M. Madni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00965"
  },
  {
    "id": "arXiv:2210.00968",
    "title": "Membership Inference Attacks Against Text-to-image Generation Models",
    "abstract": "Text-to-image generation models have recently attracted unprecedented\nattention as they unlatch imaginative applications in all areas of life.\nHowever, developing such models requires huge amounts of data that might\ncontain privacy-sensitive information, e.g., face identity. While privacy risks\nhave been extensively demonstrated in the image classification and GAN\ngeneration domains, privacy risks in the text-to-image generation domain are\nlargely unexplored. In this paper, we perform the first privacy analysis of\ntext-to-image generation models through the lens of membership inference.\nSpecifically, we propose three key intuitions about membership information and\ndesign four attack methodologies accordingly. We conduct comprehensive\nevaluations on two mainstream text-to-image generation models including\nsequence-to-sequence modeling and diffusion-based modeling. The empirical\nresults show that all of the proposed attacks can achieve significant\nperformance, in some cases even close to an accuracy of 1, and thus the\ncorresponding risk is much more severe than that shown by existing membership\ninference attacks. We further conduct an extensive ablation study to analyze\nthe factors that may affect the attack performance, which can guide developers\nand researchers to be alert to vulnerabilities in text-to-image generation\nmodels. All these findings indicate that our proposed attacks pose a realistic\nprivacy threat to the text-to-image generation models.",
    "descriptor": "",
    "authors": [
      "Yixin Wu",
      "Ning Yu",
      "Zheng Li",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00968"
  },
  {
    "id": "arXiv:2210.00969",
    "title": "Almost Exact Risk Budgeting with Return Forecasts for Portfolio  Allocation",
    "abstract": "In this paper, we revisit the portfolio allocation problem with designated\nrisk-budget [Qian, 2005]. We generalize the problem of arbitrary risk budgets\nwith unequal correlations to one that includes return forecasts and transaction\ncosts while keeping the no-shorting (long-only positions) constraint. We offer\na convex second order cone formulation that scales well with the number of\nassets and explore solutions to the problem in different settings. In\nparticular, the problem is solved on a few practical cases - on equity and bond\nasset allocation problems as well as formulating index constituents for the\nNASDAQ100 index, illustrating the benefits of this approach.",
    "descriptor": "",
    "authors": [
      "Avinash Bhardwaj",
      "Manjesh K Hanawal",
      "Purushottam Parthasarathy"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.00969"
  },
  {
    "id": "arXiv:2210.00973",
    "title": "NCVX: A General-Purpose Optimization Solver for Constrained Machine and  Deep Learning",
    "abstract": "Imposing explicit constraints is relatively new but increasingly pressing in\ndeep learning, stimulated by, e.g., trustworthy AI that performs robust\noptimization over complicated perturbation sets and scientific applications\nthat need to respect physical laws and constraints. However, it can be hard to\nreliably solve constrained deep learning problems without optimization\nexpertise. The existing deep learning frameworks do not admit constraints.\nGeneral-purpose optimization packages can handle constraints but do not perform\nauto-differentiation and have trouble dealing with nonsmoothness. In this\npaper, we introduce a new software package called NCVX, whose initial release\ncontains the solver PyGRANSO, a PyTorch-enabled general-purpose optimization\npackage for constrained machine/deep learning problems, the first of its kind.\nNCVX inherits auto-differentiation, GPU acceleration, and tensor variables from\nPyTorch, and is built on freely available and widely used open-source\nframeworks. NCVX is available at https://ncvx.org, with detailed documentation\nand numerous examples from machine/deep learning and other fields.",
    "descriptor": "\nComments: Submitted to the 14th International OPT Workshop on Optimization for Machine Learning. arXiv admin note: text overlap with arXiv:2111.13984\n",
    "authors": [
      "Buyun Liang",
      "Tim Mitchell",
      "Ju Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Mathematical Software (cs.MS)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00973"
  },
  {
    "id": "arXiv:2210.00975",
    "title": "DOTIE -- Detecting Objects through Temporal Isolation of Events using a  Spiking Architecture",
    "abstract": "Vision-based autonomous navigation systems rely on fast and accurate object\ndetection algorithms to avoid obstacles. Algorithms and sensors designed for\nsuch systems need to be computationally efficient, due to the limited energy of\nthe hardware used for deployment. Biologically inspired event cameras are a\ngood candidate as a vision sensor for such systems due to their speed, energy\nefficiency, and robustness to varying lighting conditions. However, traditional\ncomputer vision algorithms fail to work on event-based outputs, as they lack\nphotometric features such as light intensity and texture. In this work, we\npropose a novel technique that utilizes the temporal information inherently\npresent in the events to efficiently detect moving objects. Our technique\nconsists of a lightweight spiking neural architecture that is able to separate\nevents based on the speed of the corresponding objects. These separated events\nare then further grouped spatially to determine object boundaries. This method\nof object detection is both asynchronous and robust to camera noise. In\naddition, it shows good performance in scenarios with events generated by\nstatic objects in the background, where existing event-based algorithms fail.\nWe show that by utilizing our architecture, autonomous navigation systems can\nhave minimal latency and energy overheads for performing object detection.",
    "descriptor": "",
    "authors": [
      "Manish Nagaraj",
      "Chamika Mihiranga Liyanagedera",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00975"
  },
  {
    "id": "arXiv:2210.00976",
    "title": "Task Space Tracking of Soft Manipulators: Inner-Outer Loop Control Based  on Cosserat-Rod Models",
    "abstract": "Soft robots are robotic systems made of deformable materials and exhibit\nunique flexibility that can be exploited for complex environments and tasks.\nHowever, their control problem has been considered a challenging subject\nbecause they are of infinite degrees of freedom and highly under-actuated.\nExisting studies have mainly relied on simplified and approximated\nfinite-dimensional models. In this work, we exploit infinite-dimensional\nnonlinear control for soft robots. We adopt the Cosserat-rod theory and employ\nnonlinear partial differential equations (PDEs) to model the kinematics and\ndynamics of soft manipulators, including their translational motions (for shear\nand elongation) and rotational motions (for bending and torsion). The objective\nis to achieve position tracking of the whole manipulator in a planar task space\nby controlling the moments (generated by actuators). The control design is\ninspired by the energy decay property of damped wave equations and has an\ninner-outer loop structure. In the outer loop, we design desired rotational\nmotions that rotate the translational component into a direction that\nasymptotically dissipates the energy associated with position tracking errors.\nIn the inner loop, we design inputs for the rotational components to track\ntheir desired motions, again by dissipating the rotational energy. We prove\nthat the closed-loop system is exponentially stable and evaluate its\nperformance through simulations.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00976"
  },
  {
    "id": "arXiv:2210.00978",
    "title": "Uncertainty-Driven Active Vision for Implicit Scene Reconstruction",
    "abstract": "Multi-view implicit scene reconstruction methods have become increasingly\npopular due to their ability to represent complex scene details. Recent efforts\nhave been devoted to improving the representation of input information and to\nreducing the number of views required to obtain high quality reconstructions.\nYet, perhaps surprisingly, the study of which views to select to maximally\nimprove scene understanding remains largely unexplored. We propose an\nuncertainty-driven active vision approach for implicit scene reconstruction,\nwhich leverages occupancy uncertainty accumulated across the scene using volume\nrendering to select the next view to acquire. To this end, we develop an\noccupancy-based reconstruction method which accurately represents scenes using\neither 2D or 3D supervision. We evaluate our proposed approach on the ABC\ndataset and the in the wild CO3D dataset, and show that: (1) we are able to\nobtain high quality state-of-the-art occupancy reconstructions; (2) our\nperspective conditioned uncertainty definition is effective to drive\nimprovements in next best view selection and outperforms strong baseline\napproaches; and (3) we can further improve shape understanding by performing a\ngradient-based search on the view selection candidates. Overall, our results\nhighlight the importance of view selection for implicit scene reconstruction,\nmaking it a promising avenue to explore further.",
    "descriptor": "",
    "authors": [
      "Edward J. Smith",
      "Michal Drozdzal",
      "Derek Nowrouzezahrai",
      "David Meger",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00978"
  },
  {
    "id": "arXiv:2210.00979",
    "title": "Dissipative Imitation Learning for Robust Dynamic Output Feedback",
    "abstract": "Robust imitation learning seeks to mimic expert controller behavior while\nensuring stability, but current methods require accurate plant models. Here,\nrobust imitation learning is addressed for stabilizing poorly modeled plants\nwith linear dynamic output feedback. Open-loop input-output properties are used\nto characterize an uncertain plant, and the feedback matrix of the dynamic\ncontroller is learned while enforcing stability through the controller's\nopen-loop QSR-dissipativity properties. The imitation learning method is\napplied to two systems with parametric uncertainty.",
    "descriptor": "\nComments: IEEE Conference on Decision and Control (2022)\n",
    "authors": [
      "Amy K. Strong",
      "Ethan J. LoCicero",
      "Leila Bridgeman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00979"
  },
  {
    "id": "arXiv:2210.00982",
    "title": "Assuring safety of vision-based swarm formation control",
    "abstract": "Vision-based formation control systems recently have attracted attentions\nfrom both the research community and the industry for its applicability in\nGPS-denied environments. The safety assurance for such systems is challenging\ndue to the lack of formal specifications for computer vision systems and the\ncomplex impact of imprecise estimations on distributed control. We propose a\ntechnique for safety assurance of vision-based formation control. Our technique\ncombines (1) the construction of a piecewise approximation of the worst-case\nerror of perception and (2) a classical Lyapunov-based safety analysis of the\nconsensus control algorithm. The analysis provides the ultimate bound on the\nrelative distance between drones. This ultimate bound can then be used to\nguarantee safe separation of all drones. We implement an instance of the\nvision-based control system on top of the photo-realistic AirSim simulator. We\nconstruct the piecewise approximation for varying perception error under\ndifferent environments and weather conditions, and we are able to validate the\nsafe separation provided by our analysis across the different weather\nconditions with AirSim simulation.",
    "descriptor": "\nComments: 7 pages, 9 figures, submitted to the 40th IEEE Conference on Robotics and Automation (ICRA 2023)\n",
    "authors": [
      "Chiao Hsieh",
      "Yangge Li",
      "Yubin Koh",
      "Sayan Mitra"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.00982"
  },
  {
    "id": "arXiv:2210.00987",
    "title": "Data Budgeting for Machine Learning",
    "abstract": "Data is the fuel powering AI and creates tremendous value for many domains.\nHowever, collecting datasets for AI is a time-consuming, expensive, and\ncomplicated endeavor. For practitioners, data investment remains to be a leap\nof faith in practice. In this work, we study the data budgeting problem and\nformulate it as two sub-problems: predicting (1) what is the saturating\nperformance if given enough data, and (2) how many data points are needed to\nreach near the saturating performance. Different from traditional\ndataset-independent methods like PowerLaw, we proposed a learning method to\nsolve data budgeting problems. To support and systematically evaluate the\nlearning-based method for data budgeting, we curate a large collection of 383\ntabular ML datasets, along with their data vs performance curves. Our empirical\nevaluation shows that it is possible to perform data budgeting given a small\npilot study dataset with as few as $50$ data points.",
    "descriptor": "",
    "authors": [
      "Xinyi Zhao",
      "Weixin Liang",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00987"
  },
  {
    "id": "arXiv:2210.00989",
    "title": "Uniqueness of logical connectives in a bilateralist setting",
    "abstract": "In this paper I will show the problems that are encountered when dealing with\nuniqueness of connectives in a bilateralist setting within the larger framework\nof proof-theoretic semantics and suggest a solution. Therefore, the logic 2Int\nis suitable, for which I introduce a sequent calculus system, displaying - just\nlike the corresponding natural deduction system - a consequence relation for\nprovability as well as one dual to provability. I will propose a modified\ncharacterization of uniqueness incorporating such a duality of consequence\nrelations, with which we can maintain uniqueness in a bilateralist setting.",
    "descriptor": "",
    "authors": [
      "Sara Ayhan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.00989"
  },
  {
    "id": "arXiv:2210.00990",
    "title": "Visual Prompt Tuning for Generative Transfer Learning",
    "abstract": "Transferring knowledge from an image synthesis model trained on a large\ndataset is a promising direction for learning generative image models from\nvarious domains efficiently. While previous works have studied GAN models, we\npresent a recipe for learning vision transformers by generative knowledge\ntransfer. We base our framework on state-of-the-art generative vision\ntransformers that represent an image as a sequence of visual tokens to the\nautoregressive or non-autoregressive transformers. To adapt to a new domain, we\nemploy prompt tuning, which prepends learnable tokens called prompt to the\nimage token sequence, and introduce a new prompt design for our task. We study\non a variety of visual domains, including visual task adaptation\nbenchmark~\\cite{zhai2019large}, with varying amount of training images, and\nshow effectiveness of knowledge transfer and a significantly better image\ngeneration quality over existing works.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Kihyuk Sohn",
      "Yuan Hao",
      "Jos\u00e9 Lezama",
      "Luisa Polania",
      "Huiwen Chang",
      "Han Zhang",
      "Irfan Essa",
      "Lu Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00990"
  },
  {
    "id": "arXiv:2210.00991",
    "title": "Policy Gradient for Reinforcement Learning with General Utilities",
    "abstract": "In Reinforcement Learning (RL), the goal of agents is to discover an optimal\npolicy that maximizes the expected cumulative rewards. This objective may also\nbe viewed as finding a policy that optimizes a linear function of its\nstate-action occupancy measure, hereafter referred as Linear RL. However, many\nsupervised and unsupervised RL problems are not covered in the Linear RL\nframework, such as apprenticeship learning, pure exploration and variational\nintrinsic control, where the objectives are non-linear functions of the\noccupancy measures. RL with non-linear utilities looks unwieldy, as methods\nlike Bellman equation, value iteration, policy gradient, dynamic programming\nthat had tremendous success in Linear RL, fail to trivially generalize. In this\npaper, we derive the policy gradient theorem for RL with general utilities. The\npolicy gradient theorem proves to be a cornerstone in Linear RL due to its\nelegance and ease of implementability. Our policy gradient theorem for RL with\ngeneral utilities shares the same elegance and ease of implementability. Based\non the policy gradient theorem derived, we also present a simple sample-based\nalgorithm. We believe our results will be of interest to the community and\noffer inspiration to future works in this generalized setting.",
    "descriptor": "",
    "authors": [
      "Navdeep Kumar",
      "Kaixin Wang",
      "Kfir Levy",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00991"
  },
  {
    "id": "arXiv:2210.00992",
    "title": "Feature Embedding by Template Matching as a ResNet Block",
    "abstract": "Convolution blocks serve as local feature extractors and are the key to\nsuccess of the neural networks. To make local semantic feature embedding rather\nexplicit, we reformulate convolution blocks as feature selection according to\nthe best matching kernel. In this manner, we show that typical ResNet blocks\nindeed perform local feature embedding via template matching once batch\nnormalization (BN) followed by a rectified linear unit (ReLU) is interpreted as\narg-max optimizer. Following this perspective, we tailor a residual block that\nexplicitly forces semantically meaningful local feature embedding through using\nlabel information. Specifically, we assign a feature vector to each local\nregion according to the classes that the corresponding region matches. We\nevaluate our method on three popular benchmark datasets with several\narchitectures for image classification and consistently show that our approach\nsubstantially improves the performance of the baseline architectures.",
    "descriptor": "",
    "authors": [
      "Ada Gorgun",
      "Yeti Z. Gurbuz",
      "A. Aydin Alatan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00992"
  },
  {
    "id": "arXiv:2210.00993",
    "title": "Efficient Bayes Inference in Neural Networks through Adaptive Importance  Sampling",
    "abstract": "Bayesian neural networks (BNNs) have received an increased interest in the\nlast years. In BNNs, a complete posterior distribution of the unknown weight\nand bias parameters of the network is produced during the training stage. This\nprobabilistic estimation offers several advantages with respect to point-wise\nestimates, in particular, the ability to provide uncertainty quantification\nwhen predicting new data. This feature inherent to the Bayesian paradigm, is\nuseful in countless machine learning applications. It is particularly appealing\nin areas where decision-making has a crucial impact, such as medical healthcare\nor autonomous driving. The main challenge of BNNs is the computational cost of\nthe training procedure since Bayesian techniques often face a severe curse of\ndimensionality. Adaptive importance sampling (AIS) is one of the most prominent\nMonte Carlo methodologies benefiting from sounded convergence guarantees and\nease for adaptation. This work aims to show that AIS constitutes a successful\napproach for designing BNNs. More precisely, we propose a novel algorithm\nPMCnet that includes an efficient adaptation mechanism, exploiting geometric\ninformation on the complex (often multimodal) posterior distribution. Numerical\nresults illustrate the excellent performance and the improved exploration\ncapabilities of the proposed method for both shallow and deep neural networks.",
    "descriptor": "",
    "authors": [
      "Yunshi Huang",
      "Emilie Chouzenoux",
      "Victor Elvira",
      "Jean-Christophe Pesquet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00993"
  },
  {
    "id": "arXiv:2210.00999",
    "title": "Latent State Marginalization as a Low-cost Approach for Improving  Exploration",
    "abstract": "While the maximum entropy (MaxEnt) reinforcement learning (RL) framework --\noften touted for its exploration and robustness capabilities -- is usually\nmotivated from a probabilistic perspective, the use of deep probabilistic\nmodels has not gained much traction in practice due to their inherent\ncomplexity. In this work, we propose the adoption of latent variable policies\nwithin the MaxEnt framework, which we show can provably approximate any policy\ndistribution, and additionally, naturally emerges under the use of world models\nwith a latent belief state. We discuss why latent variable policies are\ndifficult to train, how naive approaches can fail, then subsequently introduce\na series of improvements centered around low-cost marginalization of the latent\nstate, allowing us to make full use of the latent state at minimal additional\ncost. We instantiate our method under the actor-critic framework, marginalizing\nboth the actor and critic. The resulting algorithm, referred to as Stochastic\nMarginal Actor-Critic (SMAC), is simple yet effective. We experimentally\nvalidate our method on continuous control tasks, showing that effective\nmarginalization can lead to better exploration and more robust training.",
    "descriptor": "",
    "authors": [
      "Dinghuai Zhang",
      "Aaron Courville",
      "Yoshua Bengio",
      "Qinqing Zheng",
      "Amy Zhang",
      "Ricky T. Q. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00999"
  },
  {
    "id": "arXiv:2210.01000",
    "title": "Mutual Information Learned Classifiers: an Information-theoretic  Viewpoint of Training Deep Learning Classification Systems",
    "abstract": "Deep learning systems have been reported to acheive state-of-the-art\nperformances in many applications, and one of the keys for achieving this is\nthe existence of well trained classifiers on benchmark datasets which can be\nused as backbone feature extractors in downstream tasks. As a main-stream loss\nfunction for training deep neural network (DNN) classifiers, the cross entropy\nloss can easily lead us to find models which demonstrate severe overfitting\nbehavior when no other techniques are used for alleviating it such as data\naugmentation. In this paper, we prove that the existing cross entropy loss\nminimization for training DNN classifiers essentially learns the conditional\nentropy of the underlying data distribution of the dataset, i.e., the\ninformation or uncertainty remained in the labels after revealing the input. In\nthis paper, we propose a mutual information learning framework where we train\nDNN classifiers via learning the mutual information between the label and\ninput. Theoretically, we give the population error probability lower bound in\nterms of the mutual information. In addition, we derive the mutual information\nlower and upper bounds for a concrete binary classification data model in\n$\\mbR^n$, and also the error probability lower bound in this scenario. Besides,\nwe establish the sample complexity for accurately learning the mutual\ninformation from empirical data samples drawn from the underlying data\ndistribution. Empirically, we conduct extensive experiments on several\nbenchmark datasets to support our theory. Without whistles and bells, the\nproposed mutual information learned classifiers (MILCs) acheive far better\ngeneralization performances than the state-of-the-art classifiers with an\nimprovement which can exceed more than 10\\% in testing accuracy.",
    "descriptor": "\nComments: 42 pages, 15 figures, 4 tables, 14 lemmas, theorems, or corollaries. arXiv admin note: text overlap with arXiv:2209.10058\n",
    "authors": [
      "Jirong Yi",
      "Qiaosheng Zhang",
      "Zhen Chen",
      "Qiao Liu",
      "Wei Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.01000"
  },
  {
    "id": "arXiv:2210.01002",
    "title": "ASGNN: Graph Neural Networks with Adaptive Structure",
    "abstract": "The graph neural network (GNN) models have presented impressive achievements\nin numerous machine learning tasks. However, many existing GNN models are shown\nto be vulnerable to adversarial attacks, which creates a stringent need to\nbuild robust GNN architectures. In this work, we propose a novel interpretable\nmessage passing scheme with adaptive structure (ASMP) to defend against\nadversarial attacks on graph structure. Layers in ASMP are derived based on\noptimization steps that minimize an objective function that learns the node\nfeature and the graph structure simultaneously. ASMP is adaptive in the sense\nthat the message passing process in different layers is able to be carried out\nover dynamically adjusted graphs. Such property allows more fine-grained\nhandling of the noisy (or perturbed) graph structure and hence improves the\nrobustness. Convergence properties of the ASMP scheme are theoretically\nestablished. Integrating ASMP with neural networks can lead to a new family of\nGNN models with adaptive structure (ASGNN). Extensive experiments on\nsemi-supervised node classification tasks demonstrate that the proposed ASGNN\noutperforms the state-of-the-art GNN architectures in terms of classification\nperformance under various adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Zepeng Zhang",
      "Songtao Lu",
      "Zengfeng Huang",
      "Ziping Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01002"
  },
  {
    "id": "arXiv:2210.01005",
    "title": "Quantifying COVID-19 transmission risks based on human mobility data: A  personalized PageRank approach for efficient contact-tracing",
    "abstract": "Given its wide-ranging and long-lasting impacts, COVID-19, especially its\nspatial spreading dynamics has received much attention. Knowledge of such\ndynamics helps public health professionals and city managers devise and deploy\nefficient contact-tracing and treatment measures. However, most existing\nstudies focus on aggregate mobility flows and have rarely exploited the widely\navailable disaggregate-level human mobility data. In this paper, we propose a\nPersonalized PageRank (PPR) method to estimate COVID-19 transmission risks\nbased on a bipartite network of people and locations. The method incorporates\nboth mobility patterns of individuals and their spatiotemporal interactions. To\nvalidate the applicability and relevance of the proposed method, we examine the\ninterplay between the spread of COVID-19 cases and intra-city mobility patterns\nin a small synthetic network and a real-world mobility network from Hong Kong,\nChina based on transit smart card data. We compare the recall (sensitivity),\naccuracy, and Spearmans correlation coefficient between the estimated\ntransmission risks and number of actual cases based on various mass tracing and\ntesting strategies, including PPR-based, PageRank (PR)-based, location-based,\nroute-based, and base case (no strategy). The results show that the PPR-based\nmethod achieves the highest efficiency, accuracy, and Spearmans correlation\ncoefficient with the actual case number. This demonstrates the value of PPR for\ntransmission risk estimation and the importance of incorporating individual\nmobility patterns for efficient contact-tracing and testing.",
    "descriptor": "",
    "authors": [
      "Jiali Zhou",
      "Zhan Zhao",
      "Jiangping Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.01005"
  },
  {
    "id": "arXiv:2210.01007",
    "title": "Reward Learning with Trees: Methods and Evaluation",
    "abstract": "Recent efforts to learn reward functions from human feedback have tended to\nuse deep neural networks, whose lack of transparency hampers our ability to\nexplain agent behaviour or verify alignment. We explore the merits of learning\nintrinsically interpretable tree models instead. We develop a recently proposed\nmethod for learning reward trees from preference labels, and show it to be\nbroadly competitive with neural networks on challenging high-dimensional tasks,\nwith good robustness to limited or corrupted data. Having found that reward\ntree learning can be done effectively in complex settings, we then consider why\nit should be used, demonstrating that the interpretable reward structure gives\nsignificant scope for traceability, verification and explanation.",
    "descriptor": "\nComments: 22 pages (9 main body). Preprint, under review\n",
    "authors": [
      "Tom Bewley",
      "Jonathan Lawry",
      "Arthur Richards",
      "Rachel Craddock",
      "Ian Henderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01007"
  },
  {
    "id": "arXiv:2210.01015",
    "title": "Robust Set Stability of Logic Dynamical Systems with respect to  Uncertain Switching",
    "abstract": "This paper proposes several definitions of robust stability for logic\ndynamical systems (LDSs) with uncertain switching, including robust/uniform\nrobust set stability and asymptotical (or infinitely convergent)/finite-time\nset stability with ratio one. It is proved herein that an LDS is robustly set\nstable if and only if the destination set contains all loops (i.e., the paths\nfrom each state to itself); an LDS is uniformly robustly set stable, or\nfinite-time set stable with ratio one, if and only if all states outside the\ndestination set are unreachable from any self-reachable state; and an LDS is\nasymptotically set stable with ratio one if and only if the largest robustly\ninvariant subset (LRIS) in the destination set is reachable from any state. In\naddition, it is proved that uniform robust set stability implies robust set\nstability, and robust set stability implies asymptotical set stability with\nratio one. However, the inverse claims are not generally true. The relations\nbetween robust stability and stability under random switching are revealed,\nthat is, the asymptotical/finite-time set stability with ratio one under\nuncertain switching is equivalent to asymptotical/finite-time set stability of\nthe LDS under random switching. Furthermore, it is proved that, for uniform set\nstability and asymptotical/finite-time set stability with ratio one, the set\nstability is equivalent to the stability with respect to the LRIS in the\ndestination set. However, robust set stability does not imply robust stability\nwith respect to the LRIS in the destination set. This finding corrects a result\nin a previous study.",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Yuqian Guo",
      "Zhitao Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01015"
  },
  {
    "id": "arXiv:2210.01021",
    "title": "Sequential Brick Assembly with Efficient Constraint Satisfaction",
    "abstract": "We address the problem of generating a sequence of LEGO brick assembly with\nhigh-fidelity structures, satisfying physical constraints between bricks. The\nassembly problem is challenging since the number of possible structures\nincreases exponentially with the number of available bricks, complicating the\nphysical constraints to satisfy across bricks. To tackle this problem, our\nmethod performs a brick structure assessment to predict the next brick position\nand its confidence by employing a U-shaped sparse 3D convolutional network. The\nconvolution filter efficiently validates physical constraints in a\nparallelizable and scalable manner, allowing to process of different brick\ntypes. To generate a novel structure, we devise a sampling strategy to\ndetermine the next brick position by considering attachable positions under\nphysical constraints. Instead of using handcrafted brick assembly datasets, our\nmodel is trained with a large number of 3D objects that allow to create a new\nhigh-fidelity structure. We demonstrate that our method successfully generates\ndiverse brick structures while handling two different brick types and\noutperforms existing methods based on Bayesian optimization, graph generative\nmodel, and reinforcement learning, all of which are limited to a single brick\ntype.",
    "descriptor": "",
    "authors": [
      "Seokjun Ahn",
      "Jungtaek Kim",
      "Minsu Cho",
      "Jaesik Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01021"
  },
  {
    "id": "arXiv:2210.01023",
    "title": "The Long Tail of Context: Does it Exist and Matter?",
    "abstract": "Context has been an important topic in recommender systems over the past two\ndecades. A standard representational approach to context assumes that\ncontextual variables and their structures are known in an application. Most of\nthe prior CARS papers following representational approach manually selected and\nconsidered only a few crucial contextual variables in an application, such as\ntime, location, and company of a person. This prior work demonstrated\nsignificant recommendation performance improvements when various CARS-based\nmethods have been deployed in numerous applications. However, some recommender\nsystems applications deal with a much bigger and broader types of contexts, and\nmanually identifying and capturing a few contextual variables is not sufficient\nin such cases. In this paper, we study such ``context-rich'' applications\ndealing with a large variety of different types of contexts. We demonstrate\nthat supporting only a few most important contextual variables, although\nuseful, is not sufficient. In our study, we focus on the application that\nrecommends various banking products to commercial customers within the context\nof dialogues initiated by customer service representatives. In this\napplication, we managed to identify over two hundred types of contextual\nvariables. Sorting those variables by their importance forms the Long Tail of\nContext (LTC). In this paper, we empirically demonstrate that LTC matters and\nusing all these contextual variables from the Long Tail leads to significant\nimprovements in recommendation performance.",
    "descriptor": "",
    "authors": [
      "Konstantin Bauman",
      "Alexey Vasilev",
      "Alexander Tuzhilin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01023"
  },
  {
    "id": "arXiv:2210.01032",
    "title": "Hip Fracture Prediction using the First Principal Component Derived from  FEA-Computed Fracture Loads",
    "abstract": "Hip fracture risk assessment is an important but challenging task.\nQuantitative CT-based patient specific finite element analysis (FEA) computes\nthe force (fracture load) to break the proximal femur in a particular loading\ncondition. It provides different structural information about the proximal\nfemur that can influence a subject overall fracture risk. To obtain a more\nrobust measure of fracture risk, we used principal component analysis (PCA) to\ndevelop a global FEA computed fracture risk index that incorporates the\nFEA-computed yield and ultimate failure loads and energies to failure in four\nloading conditions (single-limb stance and impact from a fall onto the\nposterior, posterolateral, and lateral aspects of the greater trochanter) of\n110 hip fracture subjects and 235 age and sex matched control subjects from the\nAGES-Reykjavik study. We found that the first PC (PC1) of the FE parameters was\nthe only significant predictor of hip fracture. Using a logistic regression\nmodel, we determined if prediction performance for hip fracture using PC1\ndiffered from that using FE parameters combined by stratified random resampling\nwith respect to hip fracture status. The results showed that the average of the\narea under the receive operating characteristic curve (AUC) using PC1 was\nalways higher than that using all FE parameters combined in the male subjects.\nThe AUC of PC1 and AUC of the FE parameters combined were not significantly\ndifferent than that in the female subjects or in all subjects",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Xuewei Cao",
      "Joyce H Keyak",
      "Sigurdur Sigurdsson",
      "Chen Zhao",
      "Weihua Zhou",
      "Anqi Liu",
      "Thomas Lang",
      "Hong-Wen Deng",
      "Vilmundur Gudnason",
      "Qiuying Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.01032"
  },
  {
    "id": "arXiv:2210.01033",
    "title": "LPT: Long-tailed Prompt Tuning for Image Classification",
    "abstract": "For long-tailed classification, most works often pretrain a big model on a\nlarge-scale dataset, and then fine-tune the whole model for adapting to\nlong-tailed data. Though promising, fine-tuning the whole pretrained model\ntends to suffer from high cost in computation and deployment of different\nmodels for different tasks, as well as weakened generalization ability for\noverfitting to certain features of long-tailed data. To alleviate these issues,\nwe propose an effective Long-tailed Prompt Tuning method for long-tailed\nclassification. LPT introduces several trainable prompts into a frozen\npretrained model to adapt it to long-tailed data. For better effectiveness, we\ndivide prompts into two groups: 1) a shared prompt for the whole long-tailed\ndataset to learn general features and to adapt a pretrained model into target\ndomain; and 2) group-specific prompts to gather group-specific features for the\nsamples which have similar features and also to empower the pretrained model\nwith discrimination ability. Then we design a two-phase training paradigm to\nlearn these prompts. In phase 1, we train the shared prompt via supervised\nprompt tuning to adapt a pretrained model to the desired long-tailed domain. In\nphase 2, we use the learnt shared prompt as query to select a small best\nmatched set for a group of similar samples from the group-specific prompt set\nto dig the common features of these similar samples, then optimize these\nprompts with dual sampling strategy and asymmetric GCL loss. By only\nfine-tuning a few prompts while fixing the pretrained model, LPT can reduce\ntraining and deployment cost by storing a few prompts, and enjoys a strong\ngeneralization ability of the pretrained model. Experiments show that on\nvarious long-tailed benchmarks, with only ~1.1% extra parameters, LPT achieves\ncomparable performance than previous whole model fine-tuning methods, and is\nmore robust to domain-shift.",
    "descriptor": "",
    "authors": [
      "Bowen Dong",
      "Pan Zhou",
      "Shuicheng Yan",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01033"
  },
  {
    "id": "arXiv:2210.01034",
    "title": "Complexity of Polyadic Boolean Modal Logics: Model Checking and  Satisfiability",
    "abstract": "We study the computational complexity of model checking and satisfiability\nproblems of polyadic modal logics extended with permutations and Boolean\noperators on accessibility relations. First, we show that the combined\ncomplexity of the model checking problem for the resulting logic is\nPTime-complete. Secondly, we show that the satisfiability problem of polyadic\nmodal logic extended with negation on accessibility relations is\nExpTime-complete. Finally, we show that the satisfiability problem of polyadic\nmodal logic with permutations and Boolean operators on accessibility relations\nis ExpTime-complete, under the necessary assumption that the number of\naccessibility relations that can be used is bounded by a constant.",
    "descriptor": "\nComments: 17 pages, accepted to CSL 2023\n",
    "authors": [
      "Reijo Jaakkola"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.01034"
  },
  {
    "id": "arXiv:2210.01035",
    "title": "Expediting Large-Scale Vision Transformer for Dense Prediction without  Fine-tuning",
    "abstract": "Vision transformers have recently achieved competitive results across various\nvision tasks but still suffer from heavy computation costs when processing a\nlarge number of tokens. Many advanced approaches have been developed to reduce\nthe total number of tokens in large-scale vision transformers, especially for\nimage classification tasks. Typically, they select a small group of essential\ntokens according to their relevance with the class token, then fine-tune the\nweights of the vision transformer. Such fine-tuning is less practical for dense\nprediction due to the much heavier computation and GPU memory cost than image\nclassification. In this paper, we focus on a more challenging problem, i.e.,\naccelerating large-scale vision transformers for dense prediction without any\nadditional re-training or fine-tuning. In response to the fact that\nhigh-resolution representations are necessary for dense prediction, we present\ntwo non-parametric operators, a token clustering layer to decrease the number\nof tokens and a token reconstruction layer to increase the number of tokens.\nThe following steps are performed to achieve this: (i) we use the token\nclustering layer to cluster the neighboring tokens together, resulting in\nlow-resolution representations that maintain the spatial structures; (ii) we\napply the following transformer layers only to these low-resolution\nrepresentations or clustered tokens; and (iii) we use the token reconstruction\nlayer to re-create the high-resolution representations from the refined\nlow-resolution representations. The results obtained by our method are\npromising on five dense prediction tasks, including object detection, semantic\nsegmentation, panoptic segmentation, instance segmentation, and depth\nestimation.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022, camera-ready version, 22 pages, 14 figures\n",
    "authors": [
      "Weicong Liang",
      "Yuhui Yuan",
      "Henghui Ding",
      "Xiao Luo",
      "Weihong Lin",
      "Ding Jia",
      "Zheng Zhang",
      "Chao Zhang",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01035"
  },
  {
    "id": "arXiv:2210.01041",
    "title": "Probabilistic Safeguard for Reinforcement Learning Using Safety Index  Guided Gaussian Process Models",
    "abstract": "Safety is one of the biggest concerns to applying reinforcement learning (RL)\nto the physical world. In its core part, it is challenging to ensure RL agents\npersistently satisfy a hard state constraint without white-box or black-box\ndynamics models. This paper presents an integrated model learning and safe\ncontrol framework to safeguard any agent, where its dynamics are learned as\nGaussian processes. The proposed theory provides (i) a novel method to\nconstruct an offline dataset for model learning that best achieves safety\nrequirements; (ii) a parameterization rule for safety index to ensure the\nexistence of safe control; (iii) a safety guarantee in terms of probabilistic\nforward invariance when the model is learned using the aforementioned dataset.\nSimulation results show that our framework guarantees almost zero safety\nviolation on various continuous control tasks.",
    "descriptor": "\nComments: First paper to use Gaussian Process for providing safety guarantee in energy-based safe control\n",
    "authors": [
      "Weiye Zhao",
      "Tairan He",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01041"
  },
  {
    "id": "arXiv:2210.01044",
    "title": "SPARC: Sparse Render-and-Compare for CAD model alignment in a single RGB  image",
    "abstract": "Estimating 3D shapes and poses of static objects from a single image has\nimportant applications for robotics, augmented reality and digital content\ncreation. Often this is done through direct mesh predictions which produces\nunrealistic, overly tessellated shapes or by formulating shape prediction as a\nretrieval task followed by CAD model alignment. Directly predicting CAD model\nposes from 2D image features is difficult and inaccurate. Some works, such as\nROCA, regress normalised object coordinates and use those for computing poses.\nWhile this can produce more accurate pose estimates, predicting normalised\nobject coordinates is susceptible to systematic failure. Leveraging efficient\ntransformer architectures we demonstrate that a sparse, iterative,\nrender-and-compare approach is more accurate and robust than relying on\nnormalised object coordinates. For this we combine 2D image information\nincluding sparse depth and surface normal values which we estimate directly\nfrom the image with 3D CAD model information in early fusion. In particular, we\nreproject points sampled from the CAD model in an initial, random pose and\ncompute their depth and surface normal values. This combined information is the\ninput to a pose prediction network, SPARC-Net which we train to predict a 9 DoF\nCAD model pose update. The CAD model is reprojected again and the next pose\nupdate is predicted. Our alignment procedure converges after just 3 iterations,\nimproving the state-of-the-art performance on the challenging real-world\ndataset ScanNet from 25.0% to 31.8% instance alignment accuracy. Code will be\nreleased at https://github.com/florianlanger/SPARC .",
    "descriptor": "",
    "authors": [
      "Florian Langer",
      "Gwangbin Bae",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01044"
  },
  {
    "id": "arXiv:2210.01047",
    "title": "Testing by Dualization",
    "abstract": "Software engineering requires rigorous testing to guarantee the product's\nquality. Semantic testing of functional correctness is challenged by\nnondeterminism in behavior, which makes testers difficult to write and reason\nabout.\nThis thesis presents a language-based technique for testing interactive\nsystems. I propose a theory for specifying and validating nondeterministic\nbehaviors, with guaranteed soundness and correctness. I then apply the theory\nto testing practices, and show how to derive specifications into interactive\ntester programs. I also introduce a language design for producing test inputs\nthat can effectively detect and reproduce invalid behaviors.\nI evaluate the methodology by specifying and testing real-world systems such\nas web servers and file synchronizers, demonstrating the derived testers'\nability to find disagreements between the specification and the implementation.",
    "descriptor": "",
    "authors": [
      "Yishuai Li"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.01047"
  },
  {
    "id": "arXiv:2210.01048",
    "title": "Extrinsic calibration for highly accurate trajectories reconstruction",
    "abstract": "In the context of robotics, accurate ground-truth positioning is the\ncornerstone for the development of mapping and localization algorithms. In\noutdoor environments and over long distances, total stations provide accurate\nand precise measurements, that are unaffected by the usual factors that\ndeteriorate the accuracy of Global Navigation Satellite System (GNSS). While a\nsingle robotic total station can track the position of a target in three\nDegrees Of Freedom (DOF), three robotic total stations and three targets are\nnecessary to yield the full six DOF pose reference. Since it is crucial to\nexpress the position of targets in a common coordinate frame, we present a\nnovel extrinsic calibration method of multiple robotic total stations with\nfield deployment in mind. The proposed method does not require the manual\ncollection of ground control points during the system setup, nor does it\nrequire tedious synchronous measurement on each robotic total station. Based on\nextensive experimental work, we compare our approach to the classical extrinsic\ncalibration methods used in geomatics for surveying and demonstrate that our\napproach brings substantial time savings during the deployment. Tested on more\nthan 30 km of trajectories, our new method increases the precision of the\nextrinsic calibration by 25 % compared to the best state-of-the-art method,\nwhich is the one taking manually static ground control points.",
    "descriptor": "\nComments: 8 pages, 6 figures, submitted to ICRA 2023\n",
    "authors": [
      "Maxime Vaidis",
      "William Dubois",
      "Alexandre Gu\u00e9nette",
      "Johann Laconte",
      "Vladim\u00edr Kubelka",
      "Fran\u00e7ois Pomerleau"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01048"
  },
  {
    "id": "arXiv:2210.01050",
    "title": "Faster Last-iterate Convergence of Policy Optimization in Zero-Sum  Markov Games",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) -- where multiple agents learn to\ninteract in a shared dynamic environment -- permeates across a wide range of\ncritical applications. While there has been substantial progress on\nunderstanding the global convergence of policy optimization methods in\nsingle-agent RL, designing and analysis of efficient policy optimization\nalgorithms in the MARL setting present significant challenges, which\nunfortunately, remain highly inadequately addressed by existing theory. In this\npaper, we focus on the most basic setting of competitive multi-agent RL, namely\ntwo-player zero-sum Markov games, and study equilibrium finding algorithms in\nboth the infinite-horizon discounted setting and the finite-horizon episodic\nsetting. We propose a single-loop policy optimization method with symmetric\nupdates from both agents, where the policy is updated via the\nentropy-regularized optimistic multiplicative weights update (OMWU) method and\nthe value is updated on a slower timescale. We show that, in the\nfull-information tabular setting, the proposed method achieves a finite-time\nlast-iterate linear convergence to the quantal response equilibrium of the\nregularized problem, which translates to a sublinear last-iterate convergence\nto the Nash equilibrium by controlling the amount of regularization. Our\nconvergence results improve upon the best known iteration complexities, and\nlead to a better understanding of policy optimization in competitive Markov\ngames.",
    "descriptor": "",
    "authors": [
      "Shicong Cen",
      "Yuejie Chi",
      "Simon S. Du",
      "Lin Xiao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01050"
  },
  {
    "id": "arXiv:2210.01055",
    "title": "CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth  Pre-training",
    "abstract": "Pre-training across 3D vision and language remains under development because\nof limited training data. Recent works attempt to transfer vision-language\npre-training models to 3D vision. PointCLIP converts point cloud data to\nmulti-view depth maps, adopting CLIP for shape classification. However, its\nperformance is restricted by the domain gap between rendered depth maps and\nimages, as well as the diversity of depth distributions. To address this issue,\nwe propose CLIP2Point, an image-depth pre-training method by contrastive\nlearning to transfer CLIP to the 3D domain, and adapt it to point cloud\nclassification. We introduce a new depth rendering setting that forms a better\nvisual effect, and then render 52,460 pairs of images and depth maps from\nShapeNet for pre-training. The pre-training scheme of CLIP2Point combines\ncross-modality learning to enforce the depth features for capturing expressive\nvisual and textual features and intra-modality learning to enhance the\ninvariance of depth aggregation. Additionally, we propose a novel Dual-Path\nAdapter (DPA) module, i.e., a dual-path structure with simplified adapters for\nfew-shot learning. The dual-path structure allows the joint use of CLIP and\nCLIP2Point, and the simplified adapter can well fit few-shot tasks without\npost-search. Experimental results show that CLIP2Point is effective in\ntransferring CLIP knowledge to 3D vision. Our CLIP2Point outperforms PointCLIP\nand other self-supervised 3D networks, achieving state-of-the-art results on\nzero-shot and few-shot classification.",
    "descriptor": "",
    "authors": [
      "Tianyu Huang",
      "Bowen Dong",
      "Yunhan Yang",
      "Xiaoshui Huang",
      "Rynson W.H. Lau",
      "Wanli Ouyang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01055"
  },
  {
    "id": "arXiv:2210.01060",
    "title": "Process Modeling, Hidden Markov Models, and Non-negative Tensor  Factorization with Model Selection",
    "abstract": "Monitoring of industrial processes is a critical capability in industry and\nin government to ensure reliability of production cycles, quick emergency\nresponse, and national security. Process monitoring allows users to gauge the\ninvolvement of an organization in an industrial process or predict the\ndegradation or aging of machine parts in processes taking place at a remote\nlocation. Similar to many data science applications, we usually only have\naccess to limited raw data, such as satellite imagery, short video clips, some\nevent logs, and signatures captured by a small set of sensors. To combat data\nscarcity, we leverage the knowledge of subject matter experts (SMEs) who are\nfamiliar with the process. Various process mining techniques have been\ndeveloped for this type of analysis; typically such approaches combine\ntheoretical process models built based on domain expert insights with ad-hoc\nintegration of available pieces of raw data. Here, we introduce a novel\nmathematically sound method that integrates theoretical process models (as\nproposed by SMEs) with interrelated minimal Hidden Markov Models (HMM), built\nvia non-negative tensor factorization and discrete model simulations. Our\nmethod consolidates: (a) Theoretical process models development, (b) Discrete\nmodel simulations (c) HMM, (d) Joint Non-negative Matrix Factorization (NMF)\nand Non-negative Tensor Factorization (NTF), and (e) Custom model selection. To\ndemonstrate our methodology and its abilities, we apply it on simple synthetic\nand real world process models.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Erik Skau",
      "Andrew Hollis",
      "Stephan Eidenbenz",
      "Kim Rasmussen",
      "Boian Alexandrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01060"
  },
  {
    "id": "arXiv:2210.01063",
    "title": "On Stability and Generalization of Bilevel Optimization Problem",
    "abstract": "(Stochastic) bilevel optimization is a frequently encountered problem in\nmachine learning with a wide range of applications such as meta-learning,\nhyper-parameter optimization, and reinforcement learning. Most of the existing\nstudies on this problem only focused on analyzing the convergence or improving\nthe convergence rate, while little effort has been devoted to understanding its\ngeneralization behaviors. In this paper, we conduct a thorough analysis on the\ngeneralization of first-order (gradient-based) methods for the bilevel\noptimization problem. We first establish a fundamental connection between\nalgorithmic stability and generalization error in different forms and give a\nhigh probability generalization bound which improves the previous best one from\n$\\bigO(\\sqrt{n})$ to $\\bigO(\\log n)$, where $n$ is the sample size. We then\nprovide the first stability bounds for the general case where both inner and\nouter level parameters are subject to continuous update, while existing work\nallows only the outer level parameter to be updated. Our analysis can be\napplied in various standard settings such as strongly-convex-strongly-convex\n(SC-SC), convex-convex (C-C), and nonconvex-nonconvex (NC-NC). Our analysis for\nthe NC-NC setting can also be extended to a particular\nnonconvex-strongly-convex (NC-SC) setting that is commonly encountered in\npractice. Finally, we corroborate our theoretical analysis and demonstrate how\niterations can affect the generalization error by experiments on meta-learning\nand hyper-parameter optimization.",
    "descriptor": "",
    "authors": [
      "Meng Ding",
      "Mingxi Lei",
      "Yunwen Lei",
      "Di Wang",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01063"
  },
  {
    "id": "arXiv:2210.01069",
    "title": "Dual-former: Hybrid Self-attention Transformer for Efficient Image  Restoration",
    "abstract": "Recently, image restoration transformers have achieved comparable performance\nwith previous state-of-the-art CNNs. However, how to efficiently leverage such\narchitectures remains an open problem. In this work, we present Dual-former\nwhose critical insight is to combine the powerful global modeling ability of\nself-attention modules and the local modeling ability of convolutions in an\noverall architecture. With convolution-based Local Feature Extraction modules\nequipped in the encoder and the decoder, we only adopt a novel Hybrid\nTransformer Block in the latent layer to model the long-distance dependence in\nspatial dimensions and handle the uneven distribution between channels. Such a\ndesign eliminates the substantial computational complexity in previous image\nrestoration transformers and achieves superior performance on multiple image\nrestoration tasks. Experiments demonstrate that Dual-former achieves a 1.91dB\ngain over the state-of-the-art MAXIM method on the Indoor dataset for single\nimage dehazing while consuming only 4.2% GFLOPs as MAXIM. For single image\nderaining, it exceeds the SOTA method by 0.1dB PSNR on the average results of\nfive datasets with only 21.5% GFLOPs. Dual-former also substantially surpasses\nthe latest desnowing method on various datasets, with fewer parameters.",
    "descriptor": "",
    "authors": [
      "Sixiang Chen",
      "Tian Ye",
      "Yun Liu",
      "Erkang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01069"
  },
  {
    "id": "arXiv:2210.01072",
    "title": "Understanding Influence Functions and Datamodels via Harmonic Analysis",
    "abstract": "Influence functions estimate effect of individual data points on predictions\nof the model on test data and were adapted to deep learning in Koh and Liang\n[2017]. They have been used for detecting data poisoning, detecting helpful and\nharmful examples, influence of groups of datapoints, etc. Recently, Ilyas et\nal. [2022] introduced a linear regression method they termed datamodels to\npredict the effect of training points on outputs on test data. The current\npaper seeks to provide a better theoretical understanding of such interesting\nempirical phenomena. The primary tool is harmonic analysis and the idea of\nnoise stability. Contributions include: (a) Exact characterization of the\nlearnt datamodel in terms of Fourier coefficients. (b) An efficient method to\nestimate the residual error and quality of the optimum linear datamodel without\nhaving to train the datamodel. (c) New insights into when influences of groups\nof datapoints may or may not add up linearly.",
    "descriptor": "",
    "authors": [
      "Nikunj Saunshi",
      "Arushi Gupta",
      "Mark Braverman",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01072"
  },
  {
    "id": "arXiv:2210.01073",
    "title": "Distributed-Something: scripts to leverage AWS storage and computing for  distributed workflows at scale",
    "abstract": "Distributed-Something coordinates the distribution of any Dockerized workflow\nusing on-demand computational infrastructure from Amazon Web Services to enable\nat-scale workflows where neither computing power nor data storage are limited\nby local availability while minimizing the time-consuming and confusing aspects\nof architecture coordination. We also provide Distributed-Something\nimplementations of several bioimaging tools: Distributed-CellProfiler, -Fiji,\nand -OmeZarrCreator. All are open-source and available at\nthis http URL",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Erin Weisbart",
      "Beth A. Cimini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.01073"
  },
  {
    "id": "arXiv:2210.01074",
    "title": "Nonlinear Reconstruction for Operator Learning of PDEs with  Discontinuities",
    "abstract": "A large class of hyperbolic and advection-dominated PDEs can have solutions\nwith discontinuities. This paper investigates, both theoretically and\nempirically, the operator learning of PDEs with discontinuous solutions. We\nrigorously prove, in terms of lower approximation bounds, that methods which\nentail a linear reconstruction step (e.g. DeepONet or PCA-Net) fail to\nefficiently approximate the solution operator of such PDEs. In contrast, we\nshow that certain methods employing a non-linear reconstruction mechanism can\novercome these fundamental lower bounds and approximate the underlying operator\nefficiently. The latter class includes Fourier Neural Operators and a novel\nextension of DeepONet termed shift-DeepONet. Our theoretical findings are\nconfirmed by empirical results for advection equation, inviscid Burgers'\nequation and compressible Euler equations of aerodynamics.",
    "descriptor": "",
    "authors": [
      "Samuel Lanthaler",
      "Roberto Molinaro",
      "Patrik Hadorn",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.01074"
  },
  {
    "id": "arXiv:2210.01075",
    "title": "Decompiling x86 Deep Neural Network Executables",
    "abstract": "Due to their widespread use on heterogeneous hardware devices, deep learning\n(DL) models are compiled into executables by DL compilers to fully leverage\nlow-level hardware primitives. This approach allows DL computations to be\nundertaken at low cost across a variety of computing platforms, including CPUs,\nGPUs, and various hardware accelerators. We present BTD (Bin to DNN), a\ndecompiler for deep neural network (DNN) executables. BTD takes DNN executables\nand outputs full model specifications, including types of DNN operators,\nnetwork topology, dimensions, and parameters that are (nearly) identical to\nthose of the input models. BTD delivers a practical framework to process DNN\nexecutables compiled by different DL compilers and with full optimizations\nenabled on x86 platforms. It employs learning-based techniques to infer DNN\noperators, dynamic analysis to reveal network architectures, and symbolic\nexecution to facilitate inferring dimensions and parameters of DNN operators.\nOur evaluation reveals that BTD enables accurate recovery of full\nspecifications of complex DNNs with millions of parameters (e.g., ResNet). The\nrecovered DNN specifications can be re-compiled into a new DNN executable\nexhibiting identical behavior to the input executable. We show that BTD can\nboost two representative attacks, adversarial example generation and knowledge\nstealing, against DNN executables. We also demonstrate cross-architecture\nlegacy code reuse using BTD, and envision BTD being used for other critical\ndownstream tasks like DNN security hardening and patching.",
    "descriptor": "\nComments: The extended version of a paper to appear in the Proceedings of the 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 25 pages\n",
    "authors": [
      "Zhibo Liu",
      "Yuanyuan Yuan",
      "Shuai Wang",
      "Xiaofei Xie",
      "Lei Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01075"
  },
  {
    "id": "arXiv:2210.01076",
    "title": "qTask: Task-parallel Quantum Circuit Simulation with Incrementality",
    "abstract": "Incremental quantum circuit simulation has emerged as an important tool for\nsimulation-driven quantum applications, such as circuit synthesis,\nverification, and analysis. When a small portion of the circuit is modified,\nthe simulator must incrementally update state amplitudes for reasonable\nturnaround time and productivity. However, this type of incrementality has been\nlargely ignored by existing research. To fill this gap, we introduce a new\nincremental quantum circuit simulator called qTask. qTask leverages a\ntask-parallel decomposition strategy to explore both inter- and intra-gate\noperation parallelisms from partitioned data blocks. Our partitioning strategy\neffectively narrows down incremental update to a small set of partitions\naffected by circuit modifiers. We have demonstrated the promising performance\nof qTask on QASMBench benchmarks. Compared to two state-of-the-art simulators,\nQulacs and Qiskit, qTask is respectively 1.46x and 1.71x faster for full\nsimulation and 5.77x and 9.76x faster for incremental simulation.",
    "descriptor": "",
    "authors": [
      "Tsung-Wei Huang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.01076"
  },
  {
    "id": "arXiv:2210.01077",
    "title": "Improving Convolutional Neural Networks for Fault Diagnosis by  Assimilating Global Features",
    "abstract": "Deep learning techniques have become prominent in modern fault diagnosis for\ncomplex processes. In particular, convolutional neural networks (CNNs) have\nshown an appealing capacity to deal with multivariate time-series data by\nconverting them into images. However, existing CNN techniques mainly focus on\ncapturing local or multi-scale features from input images. A deep CNN is often\nrequired to indirectly extract global features, which are critical to describe\nthe images converted from multivariate dynamical data. This paper proposes a\nnovel local-global CNN (LG-CNN) architecture that directly accounts for both\nlocal and global features for fault diagnosis. Specifically, the local features\nare acquired by traditional local kernels whereas global features are extracted\nby using 1D tall and fat kernels that span the entire height and width of the\nimage. Both local and global features are then merged for classification using\nfully-connected layers. The proposed LG-CNN is validated on the benchmark\nTennessee Eastman process (TEP) dataset. Comparison with traditional CNN shows\nthat the proposed LG-CNN can greatly improve the fault diagnosis performance\nwithout significantly increasing the model complexity. This is attributed to\nthe much wider local receptive field created by the LG-CNN than that by CNN.\nThe proposed LG-CNN architecture can be easily extended to other image\nprocessing and computer vision tasks.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Saif S. S. Al-Wahaibi",
      "Qiugang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.01077"
  },
  {
    "id": "arXiv:2210.01078",
    "title": "Unsupervised Model Selection for Time-series Anomaly Detection",
    "abstract": "Anomaly detection in time-series has a wide range of practical applications.\nWhile numerous anomaly detection methods have been proposed in the literature,\na recent survey concluded that no single method is the most accurate across\nvarious datasets. To make matters worse, anomaly labels are scarce and rarely\navailable in practice. The practical problem of selecting the most accurate\nmodel for a given dataset without labels has received little attention in the\nliterature. This paper answers this question i.e. Given an unlabeled dataset\nand a set of candidate anomaly detectors, how can we select the most accurate\nmodel? To this end, we identify three classes of surrogate (unsupervised)\nmetrics, namely, prediction error, model centrality, and performance on\ninjected synthetic anomalies, and show that some metrics are highly correlated\nwith standard supervised anomaly detection performance metrics such as the\n$F_1$ score, but to varying degrees. We formulate metric combination with\nmultiple imperfect surrogate metrics as a robust rank aggregation problem. We\nthen provide theoretical justification behind the proposed approach.\nLarge-scale experiments on multiple real-world datasets demonstrate that our\nproposed unsupervised approach is as effective as selecting the most accurate\nmodel based on partially labeled data.",
    "descriptor": "",
    "authors": [
      "Mononito Goswami",
      "Cristian Challu",
      "Laurent Callot",
      "Lenon Minorics",
      "Andrey Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01078"
  },
  {
    "id": "arXiv:2210.01081",
    "title": "On The Effects Of Data Normalisation For Domain Adaptation On EEG Data",
    "abstract": "In the Machine Learning (ML) literature, a well-known problem is the Dataset\nShift problem where, differently from the ML standard hypothesis, the data in\nthe training and test sets can follow different probability distributions,\nleading ML systems toward poor generalisation performances. This problem is\nintensely felt in the Brain-Computer Interface (BCI) context, where bio-signals\nas Electroencephalographic (EEG) are often used. In fact, EEG signals are\nhighly non-stationary both over time and between different subjects. To\novercome this problem, several proposed solutions are based on recent transfer\nlearning approaches such as Domain Adaption (DA). In several cases, however,\nthe actual causes of the improvements remain ambiguous. This paper focuses on\nthe impact of data normalisation, or standardisation strategies applied\ntogether with DA methods. In particular, using \\textit{SEED}, \\textit{DEAP},\nand \\textit{BCI Competition IV 2a} EEG datasets, we experimentally evaluated\nthe impact of different normalization strategies applied with and without\nseveral well-known DA methods, comparing the obtained performances. It results\nthat the choice of the normalisation strategy plays a key role on the\nclassifier performances in DA scenarios, and interestingly, in several cases,\nthe use of only an appropriate normalisation schema outperforms the DA\ntechnique.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgr\u00f2",
      "Andrea Pollastro",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.01081"
  },
  {
    "id": "arXiv:2210.01089",
    "title": "Acoustic Localization and Communication Using a MEMS Microphone for  Low-cost and Low-power Bio-inspired Underwater Robots",
    "abstract": "Having accurate localization capabilities is one of the fundamental\nrequirements of autonomous robots. For underwater vehicles, the choices for\neffective localization are limited due to limitations of GPS use in water and\npoor environmental visibility that makes camera-based methods ineffective.\nPopular inertial navigation methods for underwater localization using\nDoppler-velocity log sensors, sonar, high-end inertial navigation systems, or\nacoustic positioning systems require bulky expensive hardware which are\nincompatible with low cost, bio-inspired underwater robots. In this paper, we\nintroduce an approach for underwater robot localization inspired by GPS methods\nknown as acoustic pseudoranging. Our method allows us to potentially localize\nmultiple bio-inspired robots equipped with commonly available micro\nelectro-mechanical systems microphones. This is achieved through estimating the\ntime difference of arrival of acoustic signals sent simultaneously through four\nspeakers with a known constellation geometry. We also leverage the same\nacoustic framework to perform oneway communication with the robot to execute\nsome primitive motions. To our knowledge, this is the first application of the\napproach for the on-board localization of small bio-inspired robots in water.\nHardware schematics and the accompanying code are released to aid further\ndevelopment in the field3.",
    "descriptor": "",
    "authors": [
      "Akshay Hinduja",
      "Yunsik Ohm",
      "Jiahe Liao",
      "Carmel Majidi",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01089"
  },
  {
    "id": "arXiv:2210.01090",
    "title": "Nonstationary data stream classification with online active learning and  siamese neural networks",
    "abstract": "We have witnessed in recent years an ever-growing volume of information\nbecoming available in a streaming manner in various application areas. As a\nresult, there is an emerging need for online learning methods that train\npredictive models on-the-fly. A series of open challenges, however, hinder\ntheir deployment in practice. These are, learning as data arrive in real-time\none-by-one, learning from data with limited ground truth information, learning\nfrom nonstationary data, and learning from severely imbalanced data, while\noccupying a limited amount of memory for data storage. We propose the\nActiSiamese algorithm, which addresses these challenges by combining online\nactive learning, siamese networks, and a multi-queue memory. It develops a new\ndensity-based active learning strategy which considers similarity in the latent\n(rather than the input) space. We conduct an extensive study that compares the\nrole of different active learning budgets and strategies, the performance\nwith/without memory, the performance with/without ensembling, in both synthetic\nand real-world datasets, under different data nonstationarity characteristics\nand class imbalance levels. ActiSiamese outperforms baseline and\nstate-of-the-art algorithms, and is effective under severe imbalance, even only\nwhen a fraction of the arriving instances' labels is available. We publicly\nrelease our code to the community.",
    "descriptor": "\nComments: Keywords: Incremental learning, Active learning, Data streams, Concept drift, Class imbalance\n",
    "authors": [
      "Kleanthis Malialis",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01090"
  },
  {
    "id": "arXiv:2210.01091",
    "title": "Characterization of effects of transfer learning across domains and  languages",
    "abstract": "With ever-expanding datasets of domains, tasks and languages, transfer\nlearning (TL) from pre-trained neural language models has emerged as a powerful\ntechnique over the years. Many pieces of research have shown the effectiveness\nof transfer learning across different domains and tasks. However, there remains\nuncertainty around when a transfer will lead to positive or negative impacts on\nperformance of the model. To understand the uncertainty, we investigate how TL\naffects the performance of popular pre-trained models like BERT, RoBERTa and\nXLNet over three natural language processing (NLP) tasks. We believe this work\nwill inform about specifics on when and what to transfer related to domain,\nmulti-lingual dataset and various NLP tasks.",
    "descriptor": "",
    "authors": [
      "Sovesh Mohapatra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.01091"
  },
  {
    "id": "arXiv:2210.01096",
    "title": "Doing data science with platforms crumbs: an investigation into fakes  views on YouTube",
    "abstract": "This paper contributes to the ongoing discussions on the scholarly access to\nsocial media data, discussing a case where this access is barred despite its\nvalue for understanding and countering online disinformation and despite the\nabsence of privacy or copyright issues. Our study concerns YouTube's engagement\nmetrics and, more specifically, the way in which the platform removes \"fake\nviews\" (i.e., views considered as artificial or illegitimate by the platform).\nWorking with one and a half year of data extracted from a thousand French\nYouTube channels, we show the massive extent of this phenomenon, which concerns\nthe large majority of the channels and more than half the videos in our corpus.\nOur analysis indicates that most fakes news are corrected relatively late in\nthe life of the videos and that the final view counts of the videos are not\nindependent from the fake views they received. We discuss the potential harm\nthat delays in corrections could produce in content diffusion: by inflating\nviews counts, illegitimate views could make a video appear more popular than it\nis and unwarrantedly encourage its human and algorithmic recommendation.\nUnfortunately, we cannot offer a definitive assessment of this phenomenon,\nbecause YouTube provides no information on fake views in its API or interface.\nThis paper is, therefore, also a call for greater transparency by YouTube and\nother online platforms about information that can have crucial implications for\nthe quality of online public debate.",
    "descriptor": "",
    "authors": [
      "Maria Castaldo",
      "Paolo Frasca",
      "Tommaso Venturini",
      "Floriana Gargiulo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.01096"
  },
  {
    "id": "arXiv:2210.01104",
    "title": "Local Computation of Maximal Independent Set",
    "abstract": "We present a randomized Local Computation Algorithm (LCA) with query\ncomplexity $poly(\\Delta) \\cdot \\log n$ for the Maximal Independent Set (MIS)\nproblem. That is, the algorithm determines whether each node is in the computed\nMIS or not using $poly(\\Delta) \\cdot \\log n$ queries to the adjacency lists of\nthe graph, with high probability, and this can be done for different nodes\nsimultaneously and independently. Here $\\Delta$ and $n$ denote the maximum\ndegree and the number of nodes. This algorithm resolves a key open problem in\nthe study of local computations and sublinear algorithms (attributed to\nRubinfeld).",
    "descriptor": "\nComments: An extended abstract appears at FOCS'22\n",
    "authors": [
      "Mohsen Ghaffari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.01104"
  },
  {
    "id": "arXiv:2210.01108",
    "title": "SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis",
    "abstract": "We propose MINT, a new Multilingual INTimacy analysis dataset covering 13,384\ntweets in 10 languages including English, French, Spanish, Italian, Portuguese,\nKorean, Dutch, Chinese, Hindi, and Arabic. We benchmarked a list of popular\nmultilingual pre-trained language models. The dataset is released along with\nthe SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n(https://sites.google.com/umich.edu/semeval-2023-tweet-intimacy).",
    "descriptor": "\nComments: SemEval 2023 Task 9: Multilingual Tweet Intimacy Analysis\n",
    "authors": [
      "Jiaxin Pei",
      "V\u00edtor Silva",
      "Maarten Bos",
      "Yozon Liu",
      "Leonardo Neves",
      "David Jurgens",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01108"
  },
  {
    "id": "arXiv:2210.01111",
    "title": "MultiGuard: Provably Robust Multi-label Classification against  Adversarial Examples",
    "abstract": "Multi-label classification, which predicts a set of labels for an input, has\nmany applications. However, multiple recent studies showed that multi-label\nclassification is vulnerable to adversarial examples. In particular, an\nattacker can manipulate the labels predicted by a multi-label classifier for an\ninput via adding carefully crafted, human-imperceptible perturbation to it.\nExisting provable defenses for multi-class classification achieve sub-optimal\nprovable robustness guarantees when generalized to multi-label classification.\nIn this work, we propose MultiGuard, the first provably robust defense against\nadversarial examples to multi-label classification. Our MultiGuard leverages\nrandomized smoothing, which is the state-of-the-art technique to build provably\nrobust classifiers. Specifically, given an arbitrary multi-label classifier,\nour MultiGuard builds a smoothed multi-label classifier via adding random noise\nto the input. We consider isotropic Gaussian noise in this work. Our major\ntheoretical contribution is that we show a certain number of ground truth\nlabels of an input are provably in the set of labels predicted by our\nMultiGuard when the $\\ell_2$-norm of the adversarial perturbation added to the\ninput is bounded. Moreover, we design an algorithm to compute our provable\nrobustness guarantees. Empirically, we evaluate our MultiGuard on VOC 2007,\nMS-COCO, and NUS-WIDE benchmark datasets. Our code is available at:\n\\url{https://github.com/quwenjie/MultiGuard}",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Jinyuan Jia",
      "Wenjie Qu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01111"
  },
  {
    "id": "arXiv:2210.01112",
    "title": "Generative Category-Level Shape and Pose Estimation with Semantic  Primitives",
    "abstract": "Empowering autonomous agents with 3D understanding for daily objects is a\ngrand challenge in robotics applications. When exploring in an unknown\nenvironment, existing methods for object pose estimation are still not\nsatisfactory due to the diversity of object shapes. In this paper, we propose a\nnovel framework for category-level object shape and pose estimation from a\nsingle RGB-D image. To handle the intra-category variation, we adopt a semantic\nprimitive representation that encodes diverse shapes into a unified latent\nspace, which is the key to establish reliable correspondences between observed\npoint clouds and estimated shapes. Then, by using a SIM(3)-invariant shape\ndescriptor, we gracefully decouple the shape and pose of an object, thus\nsupporting latent shape optimization of target objects in arbitrary poses.\nExtensive experiments show that the proposed method achieves SOTA pose\nestimation performance and better generalization in the real-world dataset.\nCode and video are available at https://zju3dv.github.io/gCasp",
    "descriptor": "\nComments: CoRL 2022, 17 pages, 13 figures\n",
    "authors": [
      "Guanglin Li",
      "Yifeng Li",
      "Zhichao Ye",
      "Qihang Zhang",
      "Tao Kong",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01112"
  },
  {
    "id": "arXiv:2210.01115",
    "title": "Language-Aware Soft Prompting for Vision & Language Foundation Models",
    "abstract": "This paper is on soft prompt learning for Vision \\& Language (V&L) models.\nSimilarly to their NLP counterparts, V\\&L models can be adapted to a downstream\ntask by learning soft continuous prompts using a few training examples. Current\nmethods learn the soft prompts by minimizing a cross-entropy loss using as\nclass weights the features obtained by passing the prompts plus the class names\nthrough the text encoder. Such methods, however, significantly overfit the\ntraining data suffering from large accuracy degradation when tested on unseen\nclasses from the same domain. Our main contribution, in this paper, is a\nsurprisingly simple approach to alleviate this problem: we use a second cross\nentropy loss to minimize the distance between the learned soft prompts and a\nset of hand-engineered manual prompts (obtained by prompt engineering). The\nproposed loss can be interpreted in multiple ways including as a regularizer,\nas a means for language-based augmentation, and as a way of learning more\ndiscriminative class centroids. Importantly, our formulation is inherently\namenable to including, during training, virtual classes, i.e. class names for\nwhich no visual samples are available, further increasing the robustness of the\nlearned prompts. Through extensive evaluations on 11 datasets, we show that our\napproach (a) significantly outperforms all prior works on soft prompting, and\n(b) matches and surpasses, for the first time, the accuracy on novel classes\nobtained by hand-crafted prompts and CLIP for the majority of the test\ndatasets. Code will be made available.",
    "descriptor": "",
    "authors": [
      "Adrian Bulat",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01115"
  },
  {
    "id": "arXiv:2210.01116",
    "title": "That Sounds Right: Auditory Self-Supervision for Dynamic Robot  Manipulation",
    "abstract": "Learning to produce contact-rich, dynamic behaviors from raw sensory data has\nbeen a longstanding challenge in robotics. Prominent approaches primarily focus\non using visual or tactile sensing, where unfortunately one fails to capture\nhigh-frequency interaction, while the other can be too delicate for large-scale\ndata collection. In this work, we propose a data-centric approach to dynamic\nmanipulation that uses an often ignored source of information: sound. We first\ncollect a dataset of 25k interaction-sound pairs across five dynamic tasks\nusing commodity contact microphones. Then, given this data, we leverage\nself-supervised learning to accelerate behavior prediction from sound. Our\nexperiments indicate that this self-supervised 'pretraining' is crucial to\nachieving high performance, with a 34.5% lower MSE than plain supervised\nlearning and a 54.3% lower MSE over visual training. Importantly, we find that\nwhen asked to generate desired sound profiles, online rollouts of our models on\na UR10 robot can produce dynamic behavior that achieves an average of 11.5%\nimprovement over supervised learning on audio similarity metrics.",
    "descriptor": "\nComments: Videos and audio data are best seen on our project website: audio-robot-learning.github.io\n",
    "authors": [
      "Abitha Thankaraj",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.01116"
  },
  {
    "id": "arXiv:2210.01117",
    "title": "Omnigrok: Grokking Beyond Algorithmic Data",
    "abstract": "Grokking, the unusual phenomenon for algorithmic datasets where\ngeneralization happens long after overfitting the training data, has remained\nelusive. We aim to understand grokking by analyzing the loss landscapes of\nneural networks, identifying the mismatch between training and test losses as\nthe cause for grokking. We refer to this as the \"LU mechanism\" because training\nand test losses (against model weight norm) typically resemble \"L\" and \"U\",\nrespectively. This simple mechanism can nicely explain many aspects of\ngrokking: data size dependence, weight decay dependence, the emergence of\nrepresentations, etc. Guided by the intuitive picture, we are able to induce\ngrokking on tasks involving images, language and molecules. In the reverse\ndirection, we are able to eliminate grokking for algorithmic datasets. We\nattribute the dramatic nature of grokking for algorithmic datasets to\nrepresentation learning.",
    "descriptor": "",
    "authors": [
      "Ziming Liu",
      "Eric J. Michaud",
      "Max Tegmark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01117"
  },
  {
    "id": "arXiv:2006.11462",
    "title": "Transporting Robotic Swarms via Mean-Field Feedback Control",
    "abstract": "With the rapid development of AI and robotics, transporting a large swarm of\nnetworked robots has foreseeable applications in the near future. Existing\nresearch in swarm robotics has mainly followed a bottom-up philosophy with\npredefined local coordination and control rules. However, it is arduous to\nverify the global requirements and analyze their performance. This motivates us\nto pursue a top-down approach, and develop a provable control strategy for\ndeploying a robotic swarm to achieve a desired global configuration.\nSpecifically, we use mean-field partial differential equations (PDEs) to model\nthe swarm and control its mean-field density (i.e., probability density) over a\nbounded spatial domain using mean-field feedback. The presented control law\nuses density estimates as feedback signals and generates corresponding velocity\nfields that, by acting locally on individual robots, guide their global\ndistribution to a target profile. The design of the velocity field is therefore\ncentralized, but the implementation of the controller can be fully distributed\n-- individual robots sense the velocity field and derive their own velocity\ncontrol signals accordingly. The key contribution lies in applying the concept\nof input-to-state stability (ISS) to show that the perturbed closed-loop system\n(a nonlinear and time-varying PDE) is locally ISS with respect to density\nestimation errors. The effectiveness of the proposed control laws is verified\nusing agent-based simulations.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2006.11462"
  },
  {
    "id": "arXiv:2106.00895",
    "title": "Field Estimation using Robotic Swarms through Bayesian Regression and  Mean-Field Feedback",
    "abstract": "Recent years have seen an increased interest in using mean-field density\nbased modelling and control strategy for deploying robotic swarms. In this\npaper, we study how to dynamically deploy the robots subject to their physical\nconstraints to efficiently measure and reconstruct certain unknown spatial\nfield (e.g. the air pollution index over a city). Specifically, the evolution\nof the robots' density is modelled by mean-field partial differential equations\n(PDEs) which are uniquely determined by the robots' individual dynamics.\nBayesian regression models are used to obtain predictions and return a variance\nfunction that represents the confidence of the prediction. We formulate a PDE\nconstrained optimization problem based on this variance function to dynamically\ngenerate a reference density signal which guides the robots to uncertain areas\nto collect new data, and design mean-field feedback-based control laws such\nthat the robots' density converges to this reference signal. We also show that\nthe proposed feedback law is robust to density estimation errors in the sense\nof input-to-state stability. Simulations are included to verify the\neffectiveness of the algorithms.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00895"
  },
  {
    "id": "arXiv:2210.00005",
    "title": "Cadabra and Python algorithms in General Relativity and Cosmology I:  Generalities",
    "abstract": "The aim of this work is to present a series of concrete examples which\nillustrate how the computer algebra system Cadabra can be used to manipulate\nexpressions appearing in General Relativity and other gravitational theories.\nWe highlight the way in which Cadabra's philosophy differs from other systems\nwith related functionality. The use of various new built-in packages is\ndiscussed, and we show how such packages can also be created by end-users\ndirectly using the notebook interface.\nThe current paper focuses on fairly generic applications in gravitational\ntheories, including the use of differential forms, the derivation of field\nequations and the construction of their solutions. A follow-up paper discusses\nmore specific applications related to the analysis of gravitational waves.",
    "descriptor": "\nComments: 30 pages, 3 figures, cadabra code blocks. For associated files, see this https URL\n",
    "authors": [
      "Oscar Castillo-Felisola",
      "Dominic T. Price",
      "Mattia Scomparin"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Mathematical Software (cs.MS)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00005"
  },
  {
    "id": "arXiv:2210.00006",
    "title": "ModelAngelo: Automated Model Building in Cryo-EM Maps",
    "abstract": "Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of\nthe electrostatic potential of biological macromolecules, including proteins.\nAt sufficient resolution, the cryo-EM maps, along with some knowledge about the\nimaged molecules, allow de novo atomic modelling. Typically, this is done\nthrough a laborious manual process. Recent advances in machine learning\napplications to protein structure prediction show potential for automating this\nprocess. Taking inspiration from these techniques, we have built ModelAngelo\nfor automated model building of proteins in cryo-EM maps. ModelAngelo first\nuses a residual convolutional neural network (CNN) to initialize a graph\nrepresentation with nodes assigned to individual amino acids of the proteins in\nthe map and edges representing the protein chain. The graph is then refined\nwith a graph neural network (GNN) that combines the cryo-EM data, the amino\nacid sequence data and prior knowledge about protein geometries. The GNN\nrefines the geometry of the protein chain and classifies the amino acids for\neach of its nodes. The final graph is post-processed with a hidden Markov model\n(HMM) search to map each protein chain to entries in a user provided sequence\nfile. Application to 28 test cases shows that ModelAngelo outperforms the\nstate-of-the-art and approximates manual building for cryo-EM maps with\nresolutions better than 3.5 \\r{A}.",
    "descriptor": "\nComments: Submitted to ICLR 2023\n",
    "authors": [
      "Kiarash Jamali",
      "Dari Kimanius",
      "Sjors Scheres"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.00006"
  },
  {
    "id": "arXiv:2210.00007",
    "title": "Cadabra and Python algorithms in General Relativity and Cosmology II:  Gravitational Waves",
    "abstract": "Computer Algebra Systems (CASs) like Cadabra Software play a prominent role\nin a wide range of research activities in physics and related fields. We show\nhow Cadabra language is easily implemented in the well established Python\nprogramming framework, gaining excellent flexibility and customization to\naddress the issue of tensor perturbations in General Relativity. We obtain a\nperforming algorithm to decompose tensorial quantities up to any perturbative\norder of the metric. The features of our code are tested by discussing some\nconcrete computational issues in research activities related to\nfirst/higher-order gravitational waves.",
    "descriptor": "\nComments: 32 pages, 3 figures, cadabra code blocks. For associated files, see this https URL\n",
    "authors": [
      "Oscar Castillo-Felisola",
      "Dominic T. Price",
      "Mattia Scomparin"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Mathematical Software (cs.MS)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00007"
  },
  {
    "id": "arXiv:2210.00042",
    "title": "Direct Estimation of Porosity from Seismic Data using Rock and Wave  Physics Informed Neural Networks (RW-PINN)",
    "abstract": "Petrophysical inversion is an important aspect of reservoir modeling. However\ndue to the lack of a unique and straightforward relationship between seismic\ntraces and rock properties, predicting petrophysical properties directly from\nseismic data is a complex task. Many studies have attempted to identify the\ndirect end-to-end link using supervised machine learning techniques, but face\ndifferent challenges such as a lack of large petrophysical training dataset or\nestimates that may not conform with physics or depositional history of the\nrocks. We present a rock and wave physics informed neural network (RW-PINN)\nmodel that can estimate porosity directly from seismic image traces with no or\nlimited number of wells, with predictions that are consistent with rock physics\nand geologic knowledge of deposition. As an example, we use the uncemented sand\nrock physics model and normal-incidence wave physics to guide the learning of\nRW-PINN to eventually get good estimates of porosities from normal-incidence\nseismic traces and limited well data. Training RW-PINN with few wells (weakly\nsupervised) helps in tackling the problem of non-uniqueness as different\nporosity logs can give similar seismic traces. We use weighted normalized root\nmean square error loss function to train the weakly supervised network and\ndemonstrate the impact of different weights on porosity predictions. The\nRW-PINN estimated porosities and seismic traces are compared to predictions\nfrom a completely supervised model, which gives slightly better porosity\nestimates but poorly matches the seismic traces, in addition to requiring a\nlarge amount of labeled training data. In this paper, we demonstrate the\ncomplete workflow for executing petrophysical inversion of seismic data using\nself-supervised or weakly supervised rock physics informed neural networks.",
    "descriptor": "",
    "authors": [
      "Divakar Vashisth",
      "Tapan Mukerji"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00042"
  },
  {
    "id": "arXiv:2210.00050",
    "title": "Distributionally Robust Covariance Steering with Optimal Risk Allocation",
    "abstract": "This article extends the optimal covariance steering (CS) problem for\ndiscrete time linear stochastic systems modeled using moment-based ambiguity\nsets. To hedge against the uncertainty in the state distributions while\nperforming covariance steering, distributionally robust risk constraints are\nemployed during the optimal allocation of the risk. Specifically, a\ndistributionally robust iterative risk allocation (DR-IRA) formalism is used to\nsolve the optimal risk allocation problem for the CS problem using a two-stage\napproach. The upper-stage of DR-IRA is a convex problem that optimizes the\nrisk, while the lower-stage optimizes the controller with the new\ndistributionally robust risk constraints. The proposed framework results in\nsolutions that are robust against arbitrary distributions in the considered\nambiguity set. Finally, we demonstrate our proposed approach using numerical\nsimulations. Addressing the covariance steering problem through the lens of\ndistributional robustness marks the novel contribution of this article.",
    "descriptor": "",
    "authors": [
      "Venkatraman Renganathan",
      "Joshua Pilipovsky",
      "Panagiotis Tsoitras"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00050"
  },
  {
    "id": "arXiv:2210.00077",
    "title": "E-Branchformer: Branchformer with Enhanced merging for speech  recognition",
    "abstract": "Conformer, combining convolution and self-attention sequentially to capture\nboth local and global information, has shown remarkable performance and is\ncurrently regarded as the state-of-the-art for automatic speech recognition\n(ASR). Several other studies have explored integrating convolution and\nself-attention but they have not managed to match Conformer's performance. The\nrecently introduced Branchformer achieves comparable performance to Conformer\nby using dedicated branches of convolution and self-attention and merging local\nand global context from each branch. In this paper, we propose E-Branchformer,\nwhich enhances Branchformer by applying an effective merging method and\nstacking additional point-wise modules. E-Branchformer sets new\nstate-of-the-art word error rates (WERs) 1.81% and 3.65% on LibriSpeech\ntest-clean and test-other sets without using any external training data.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Kwangyoun Kim",
      "Felix Wu",
      "Yifan Peng",
      "Jing Pan",
      "Prashant Sridhar",
      "Kyu J. Han",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00077"
  },
  {
    "id": "arXiv:2210.00079",
    "title": "Causal Estimation for Text Data with (Apparent) Overlap Violations",
    "abstract": "Consider the problem of estimating the causal effect of some attribute of a\ntext document; for example: what effect does writing a polite vs. rude email\nhave on response time? To estimate a causal effect from observational data, we\nneed to adjust for confounding aspects of the text that affect both the\ntreatment and outcome -- e.g., the topic or writing level of the text. These\nconfounding aspects are unknown a priori, so it seems natural to adjust for the\nentirety of the text (e.g., using a transformer). However, causal\nidentification and estimation procedures rely on the assumption of overlap: for\nall levels of the adjustment variables, there is randomness leftover so that\nevery unit could have (not) received treatment. Since the treatment here is\nitself an attribute of the text, it is perfectly determined, and overlap is\napparently violated. The purpose of this paper is to show how to handle causal\nidentification and obtain robust causal estimation in the presence of apparent\noverlap violations. In brief, the idea is to use supervised representation\nlearning to produce a data representation that preserves confounding\ninformation while eliminating information that is only predictive of the\ntreatment. This representation then suffices for adjustment and can satisfy\noverlap. Adapting results on non-parametric estimation, we find that this\nprocedure is robust to conditional outcome misestimation, yielding a low-bias\nestimator with valid uncertainty quantification under weak conditions.\nEmpirical results show strong improvements in bias and uncertainty\nquantification relative to the natural baseline.",
    "descriptor": "",
    "authors": [
      "Lin Gui",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00079"
  },
  {
    "id": "arXiv:2210.00117",
    "title": "Blind Signal Dereverberation for Machine Speech Recognition",
    "abstract": "We present a method to remove unknown convolutive noise introduced to speech\nby reverberations of recording environments, utilizing some amount of training\nspeech data from the reverberant environment, and any available non-reverberant\nspeech data. Using Fourier transform computed over long temporal windows, which\nideally cover the entire room impulse response, we convert room induced\nconvolution to additions in the log spectral domain. Next, we compute a\nspectral normalization vector from statistics gathered over reverberated as\nwell as over clean speech in the log spectral domain. During operation, this\nnormalization vectors are used to alleviate reverberations from complex speech\nspectra recorded under the same reverberant conditions . Such dereverberated\ncomplex speech spectra are used to compute complex FDLP-spectrograms for use in\nautomatic speech recognition.",
    "descriptor": "",
    "authors": [
      "Samik Sadhu",
      "Hynek Hermansky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00117"
  },
  {
    "id": "arXiv:2210.00158",
    "title": "Local and global expansion in random geometric graphs",
    "abstract": "Consider a random geometric 2-dimensional simplicial complex $X$ sampled as\nfollows: first, sample $n$ vectors $\\boldsymbol{u_1},\\ldots,\\boldsymbol{u_n}$\nuniformly at random on $\\mathbb{S}^{d-1}$; then, for each triple $i,j,k \\in\n[n]$, add $\\{i,j,k\\}$ and all of its subsets to $X$ if and only if\n$\\langle{\\boldsymbol{u_i},\\boldsymbol{u_j}}\\rangle \\ge \\tau,\n\\langle{\\boldsymbol{u_i},\\boldsymbol{u_k}}\\rangle \\ge \\tau$, and $\\langle\n\\boldsymbol{u_j}, \\boldsymbol{u_k}\\rangle \\ge \\tau$. We prove that for every\n$\\varepsilon > 0$, there exists a choice of $d = \\Theta(\\log n)$ and $\\tau =\n\\tau(\\varepsilon,d)$ so that with high probability, $X$ is a high-dimensional\nexpander of average degree $n^\\varepsilon$ in which each $1$-link has spectral\ngap bounded away from $\\frac{1}{2}$.\nTo our knowledge, this is the first demonstration of a natural distribution\nover $2$-dimensional expanders of arbitrarily small polynomial average degree\nand spectral link expansion better than $\\frac{1}{2}$. All previously known\nconstructions are algebraic. This distribution also furnishes an example of\nsimplicial complexes for which the trickle-down theorem is nearly tight.\nEn route, we prove general bounds on the spectral expansion of random induced\nsubgraphs of arbitrary vertex transitive graphs, which may be of independent\ninterest. For example, one consequence is an almost-sharp bound on the second\neigenvalue of random $n$-vertex geometric graphs on $\\mathbb{S}^{d-1}$, which\nwas previously unknown for most $n,d$ pairs.",
    "descriptor": "\nComments: 59 pages\n",
    "authors": [
      "Siqi Liu",
      "Sidhanth Mohanty",
      "Tselil Schramm",
      "Elizabeth Yang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.00158"
  },
  {
    "id": "arXiv:2210.00166",
    "title": "Automated segmentation of microvessels in intravascular OCT images using  deep learning",
    "abstract": "To analyze this characteristic of vulnerability, we developed an automated\ndeep learning method for detecting microvessels in intravascular optical\ncoherence tomography (IVOCT) images. A total of 8,403 IVOCT image frames from\n85 lesions and 37 normal segments were analyzed. Manual annotation was done\nusing a dedicated software (OCTOPUS) previously developed by our group. Data\naugmentation in the polar (r,{\\theta}) domain was applied to raw IVOCT images\nto ensure that microvessels appear at all possible angles. Pre-processing\nmethods included guidewire/shadow detection, lumen segmentation, pixel\nshifting, and noise reduction. DeepLab v3+ was used to segment microvessel\ncandidates. A bounding box on each candidate was classified as either\nmicrovessel or non-microvessel using a shallow convolutional neural network.\nFor better classification, we used data augmentation (i.e., angle rotation) on\nbounding boxes with a microvessel during network training. Data augmentation\nand pre-processing steps improved microvessel segmentation performance\nsignificantly, yielding a method with Dice of 0.71+/-0.10 and pixel-wise\nsensitivity/specificity of 87.7+/-6.6%/99.8+/-0.1%. The network for classifying\nmicrovessels from candidates performed exceptionally well, with sensitivity of\n99.5+/-0.3%, specificity of 98.8+/-1.0%, and accuracy of 99.1+/-0.5%. The\nclassification step eliminated the majority of residual false positives, and\nthe Dice coefficient increased from 0.71 to 0.73. In addition, our method\nproduced 698 image frames with microvessels present, compared to 730 from\nmanual analysis, representing a 4.4% difference. When compared to the manual\nmethod, the automated method improved microvessel continuity, implying improved\nsegmentation performance. The method will be useful for research purposes as\nwell as potential future treatment planning.",
    "descriptor": "\nComments: 21 pages, 9 figures, 3 tables\n",
    "authors": [
      "Juhwan Lee",
      "Justin N. Kim",
      "Lia Gomez-Perez",
      "Yazan Gharaibeh",
      "Issam Motairek",
      "Ga-briel T. R. Pereira",
      "Vladislav N. Zimin",
      "Luis A. P. Dallan",
      "Ammar Hoori",
      "Sadeer Al-Kindi",
      "Giulio Guagliumi",
      "Hiram G. Bezerra",
      "David L. Wilson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00166"
  },
  {
    "id": "arXiv:2210.00208",
    "title": "Summing free unitary Brownian motions with applications to quantum  information",
    "abstract": "Motivated by quantum information theory, we introduce a dynamical random\nstate built out of the sum of $k \\geq 2$ independent unitary Brownian motions.\nIn the large size limit, its spectral distribution equals, up to a normalising\nfactor, that of the free Jacobi process associated with a single self-adjoint\nprojection with trace $1/k$. Using free stochastic calculus, we extend this\nequality to the radial part of the free average of $k$ free unitary Brownian\nmotions and to the free Jacobi process associated with two self-adjoint\nprojections with trace $1/k$, provided the initial distributions coincide. In\nthe single projection case, we derive a binomial-type expansion of the moments\nof the free Jacobi process which extends to any $k \\geq 3$ the one derived in\n\\cite {DHH} in the special case $k=2$. Doing so give rise to a non normal\n(except for $k=2$) operator arising from the splitting of a self-adjoint\nprojection into the convex sum of $k$ unitary operators. This binomial\nexpansion is then used to derive a pde for the moment generating function of\nthis non normal operator.",
    "descriptor": "\nComments: Submitted, comments are welcome\n",
    "authors": [
      "Nizar Demni",
      "Tarek Hamdi"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2210.00208"
  },
  {
    "id": "arXiv:2210.00212",
    "title": "Efficient Quantum Agnostic Improper Learning of Decision Trees",
    "abstract": "The agnostic setting is the hardest generalization of the PAC model since it\nis akin to learning with adversarial noise. We study an open question on the\nexistence of efficient quantum boosting algorithms in this setting. We answer\nthis question in the affirmative by providing a quantum version of the\nKalai-Kanade potential boosting algorithm. This algorithm shows the standard\nquadratic speedup in the VC dimension of the weak learner compared to the\nclassical case.\nUsing our boosting algorithm as a subroutine, we give a quantum algorithm for\nagnostically learning decision trees in polynomial running time without using\nmembership queries. To the best of our knowledge, this is the first algorithm\n(quantum or classical) to do so. Learning decision trees without membership\nqueries is hard (and an open problem) in the standard classical realizable\nsetting. In general, even coming up with weak learners in the agnostic setting\nis a challenging task. We show how to construct a quantum agnostic weak learner\nusing standard quantum algorithms, which is of independent interest for\ndesigning ensemble learning setups.",
    "descriptor": "\nComments: 20 pages, 3 algorithms, 1 table\n",
    "authors": [
      "Debajyoti Bera",
      "Sagnik Chatterjee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00212"
  },
  {
    "id": "arXiv:2210.00227",
    "title": "Attention Augmented ConvNeXt UNet For Rectal Tumour Segmentation",
    "abstract": "It is a challenge to segment the location and size of rectal cancer tumours\nthrough deep learning. In this paper, in order to improve the ability of\nextracting suffi-cient feature information in rectal tumour segmentation,\nattention enlarged ConvNeXt UNet (AACN-UNet), is proposed. The network mainly\nincludes two improvements: 1) the encoder stage of UNet is changed to ConvNeXt\nstructure for encoding operation, which can not only integrate multi-scale\nsemantic information on a large scale, but al-so reduce information loss and\nextract more feature information from CT images; 2) CBAM attention mechanism is\nadded to improve the connection of each feature in channel and space, which is\nconducive to extracting the effective feature of the target and improving the\nsegmentation accuracy.The experiment with UNet and its variant network shows\nthat AACN-UNet is 0.9% ,1.1% and 1.4% higher than the current best results in\nP, F1 and Miou.Compared with the training time, the number of parameters in\nUNet network is less. This shows that our proposed AACN-UNet has achieved\nex-cellent results in CT image segmentation of rectal cancer.",
    "descriptor": "",
    "authors": [
      "Hongwei Wu",
      "Junlin Wang",
      "Xin Wang",
      "Hui Nan",
      "Yaxin Wang",
      "Haonan Jing",
      "Kaixuan Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00227"
  },
  {
    "id": "arXiv:2210.00231",
    "title": "Unbiased quantum phase estimation",
    "abstract": "Quantum phase estimation algorithm (PEA) is one of the most important\nalgorithms in early studies of quantum computation. It is also a key for many\nother quantum algorithms, such as the quantum counting algorithm and the Shor's\ninteger factorization algorithm. However, we find that the PEA is not an\nunbiased estimation, which prevents the estimation error from achieving an\narbitrarily small level. In this paper, we propose an unbiased phase estimation\nalgorithm (UPEA) based on the original PEA, and study its application in\nquantum counting. We also show that a maximum likelihood post-processing step\ncan further improve its robustness. In the end, we apply UPEA to quantum\ncounting, and use an additional correction step to make the quantum counting\nalgorithm unbiased.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Xi Lu",
      "Hongwei Lin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.00231"
  },
  {
    "id": "arXiv:2210.00255",
    "title": "Cascaded Multi-Modal Mixing Transformers for Alzheimer's Disease  Classification with Incomplete Data",
    "abstract": "Accurate medical classification requires a large number of multi-modal data,\nand in many cases, in different formats. Previous studies have shown promising\nresults when using multi-modal data, outperforming single-modality models on\nwhen classifying disease such as AD. However, those models are usually not\nflexible enough to handle missing modalities. Currently, the most common\nworkaround is excluding samples with missing modalities which leads to\nconsiderable data under-utilisation. Adding to the fact that labelled medical\nimages are already scarce, the performance of data-driven methods like deep\nlearning is severely hampered. Therefore, a multi-modal method that can\ngracefully handle missing data in various clinical settings is highly\ndesirable. In this paper, we present the Multi-Modal Mixing Transformer (3MT),\na novel Transformer for disease classification based on multi-modal data. In\nthis work, we test it for \\ac{AD} or \\ac{CN} classification using neuroimaging\ndata, gender, age and MMSE scores. The model uses a novel Cascaded Modality\nTransformers architecture with cross-attention to incorporate multi-modal\ninformation for more informed predictions. Auxiliary outputs and a novel\nmodality dropout mechanism were incorporated to ensure an unprecedented level\nof modality independence and robustness. The result is a versatile network that\nenables the mixing of an unlimited number of modalities with different formats\nand full data utilization. 3MT was first tested on the ADNI dataset and\nachieved state-of-the-art test accuracy of $0.987\\pm0.0006$. To test its\ngeneralisability, 3MT was directly applied to the AIBL after training on the\nADNI dataset, and achieved a test accuracy of $0.925\\pm0.0004$ without\nfine-tuning. Finally, we show that Grad-CAM visualizations are also possible\nwith our model for explainable results.",
    "descriptor": "",
    "authors": [
      "Linfeng Liu",
      "Siyu Liu",
      "Lu Zhang",
      "Xuan Vinh To",
      "Fatima Nasrallah",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00255"
  },
  {
    "id": "arXiv:2210.00259",
    "title": "Pre-trained Speech Representations as Feature Extractors for Speech  Quality Assessment in Online Conferencing Applications",
    "abstract": "Speech quality in online conferencing applications is typically assessed\nthrough human judgements in the form of the mean opinion score (MOS) metric.\nSince such a labor-intensive approach is not feasible for large-scale speech\nquality assessments in most settings, the focus has shifted towards automated\nMOS prediction through end-to-end training of deep neural networks (DNN).\nInstead of training a network from scratch, we propose to leverage the speech\nrepresentations from the pre-trained wav2vec-based XLS-R model. However, the\nnumber of parameters of such a model exceeds task-specific DNNs by several\norders of magnitude, which poses a challenge for resulting fine-tuning\nprocedures on smaller datasets. Therefore, we opt to use pre-trained speech\nrepresentations from XLS-R in a feature extraction rather than a fine-tuning\nsetting, thereby significantly reducing the number of trainable model\nparameters. We compare our proposed XLS-R-based feature extractor to a\nMel-frequency cepstral coefficient (MFCC)-based one, and experiment with\nvarious combinations of bidirectional long short term memory (Bi-LSTM) and\nattention pooling feedforward (AttPoolFF) networks trained on the output of the\nfeature extractors. We demonstrate the increased performance of pre-trained\nXLS-R embeddings in terms a reduced root mean squared error (RMSE) on the\nConferencingSpeech 2022 MOS prediction task.",
    "descriptor": "\nComments: 5 pages, submitted to INTERSPEECH 2022\n",
    "authors": [
      "Bastiaan Tamm",
      "Helena Balabin",
      "Rik Vandenberghe",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00259"
  },
  {
    "id": "arXiv:2210.00263",
    "title": "Fine-tuning Wav2vec for Vocal-burst Emotion Recognition",
    "abstract": "The ACII Affective Vocal Bursts (A-VB) competition introduces a new topic in\naffective computing, which is understanding emotional expression using the\nnon-verbal sound of humans. We are familiar with emotion recognition via verbal\nvocal or facial expression. However, the vocal bursts such as laughs, cries,\nand signs, are not exploited even though they are very informative for behavior\nanalysis. The A-VB competition comprises four tasks that explore non-verbal\ninformation in different spaces. This technical report describes the method and\nthe result of SclabCNU Team for the tasks of the challenge. We achieved\npromising results compared to the baseline model provided by the organizers.",
    "descriptor": "",
    "authors": [
      "Dang-Khanh Nguyen",
      "Sudarshan Pant",
      "Ngoc-Huynh Ho",
      "Guee-Sang Lee",
      "Soo-Huyng Kim",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00263"
  },
  {
    "id": "arXiv:2210.00345",
    "title": "Identifying Selections Operating on HIV-1 Reverse Transcriptase via  Uniform Manifold Approximation and Projection",
    "abstract": "We analyze 14,651 HIV1 reverse transcriptase (HIV RT) sequences from the\nStanford HIV Drug Resistance Database labeled with treatment regimen in order\nto study the evolution this enzyme under drug selection in the clinic. Our goal\nis to identify distinct sectors of HIV RT's sequence space that are undergoing\nevolution as a way to identify individual selections and/or evolutionary\nsolutions. We utilize Uniform Manifold Approximation and Projection (UMAP), a\ngraph-based dimensionality reduction technique uniquely suited for the\ndetection of non-linear dependencies and visualize the results using an\nunsupervised clustering algorithm based on density analysis. Our analysis\nproduced 21 distinct clusters of sequences. Supporting the biological\nsignificance of these clusters, they tend to represent phylogenetically related\nsequences with strong correspondence to distinct treatment regimens. Thus, this\nmethod for visualization of areas of HIV RT undergoing evolution can help infer\ninformation about selective pressures, although it is correlative. The mutation\nsignatures associated with each cluster may represent the higher-order\nepistatic context facilitating these evolutionary pathways, information that is\ngenerally not accessible by other types of mutational co-dependence analyses.",
    "descriptor": "\nComments: To be published in ICBRA 2022 ACM Conference Proceedings (ISBN: 978-1-4503-8426-1); 15 pages, 4 figures, 2 tables; Code available at github.com/shefaliqamar/HIV-Epistatic\n",
    "authors": [
      "Shefali Qamar",
      "Manel Camps",
      "Jay Kim"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00345"
  },
  {
    "id": "arXiv:2210.00353",
    "title": "Sustained oscillations in multi-topic belief dynamics over signed  networks",
    "abstract": "We study the dynamics of belief formation on multiple interconnected topics\nin networks of agents with a shared belief system. We establish sufficient\nconditions and necessary conditions under which sustained oscillations of\nbeliefs arise on the network in a Hopf bifurcation and characterize the role of\nthe communication graph and the belief system graph in shaping the relative\nphase and amplitude patterns of the oscillations.",
    "descriptor": "",
    "authors": [
      "Anastasia Bizyaeva",
      "Alessio Franci",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00353"
  },
  {
    "id": "arXiv:2210.00359",
    "title": "Counter-Adversarial Learning with Inverse Unscented Kalman Filter",
    "abstract": "In order to infer the strategy of an intelligent attacker, it is desired for\nthe defender to cognitively sense the attacker's state. In this context, we aim\nto learn the information that an adversary has gathered about us from a\nBayesian perspective. Prior works employ linear Gaussian state-space models and\nsolve this inverse cognition problem through the design of inverse stochastic\nfilters. In practice, these counter-adversarial settings are highly nonlinear\nsystems. We address this by formulating the inverse cognition as a nonlinear\nGaussian state-space model, wherein the adversary employs an unscented Kalman\nfilter (UKF) to estimate our state with reduced linearization errors. To\nestimate the adversary's estimate of us, we propose and develop an inverse UKF\n(IUKF), wherein the system model is known to both the adversary and the\ndefender. We also derive the conditions for the stochastic stability of IUKF in\nthe mean-squared boundedness sense. Numerical experiments for multiple\npractical system models show that the estimation error of IUKF converges and\nclosely follows the recursive Cram\\'{e}r-Rao lower bound.",
    "descriptor": "\nComments: Conference paper, 10 pages, 1 figure. Proofs are provided at the end only in the arXiv version\n",
    "authors": [
      "Himali Singh",
      "Kumar Vijay Mishra",
      "Arpan Chattopadhyay"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00359"
  },
  {
    "id": "arXiv:2210.00367",
    "title": "A Comparison of Transformer, Convolutional, and Recurrent Neural  Networks on Phoneme Recognition",
    "abstract": "Phoneme recognition is a very important part of speech recognition that\nrequires the ability to extract phonetic features from multiple frames. In this\npaper, we compare and analyze CNN, RNN, Transformer, and Conformer models using\nphoneme recognition. For CNN, the ContextNet model is used for the experiments.\nFirst, we compare the accuracy of various architectures under different\nconstraints, such as the receptive field length, parameter size, and layer\ndepth. Second, we interpret the performance difference of these models,\nespecially when the observable sequence length varies. Our analyses show that\nTransformer and Conformer models benefit from the long-range accessibility of\nself-attention through input frames.",
    "descriptor": "",
    "authors": [
      "Kyuhong Shim",
      "Wonyong Sung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00367"
  },
  {
    "id": "arXiv:2210.00376",
    "title": "Convolutional Neural Networks on Manifolds: From Graphs and Back",
    "abstract": "Geometric deep learning has gained much attention in recent years due to more\navailable data acquired from non-Euclidean domains. Some examples include point\nclouds for 3D models and wireless sensor networks in communications. Graphs are\ncommon models to connect these discrete data points and capture the underlying\ngeometric structure. With the large amount of these geometric data, graphs with\narbitrarily large size tend to converge to a limit model -- the manifold. Deep\nneural network architectures have been proved as a powerful technique to solve\nproblems based on these data residing on the manifold. In this paper, we\npropose a manifold neural network (MNN) composed of a bank of manifold\nconvolutional filters and point-wise nonlinearities. We define a manifold\nconvolution operation which is consistent with the discrete graph convolution\nby discretizing in both space and time domains. To sum up, we focus on the\nmanifold model as the limit of large graphs and construct MNNs, while we can\nstill bring back graph neural networks by the discretization of MNNs. We carry\nout experiments based on point-cloud dataset to showcase the performance of our\nproposed MNNs.",
    "descriptor": "\nComments: 7 pages, 1 figure, 1 table\n",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00376"
  },
  {
    "id": "arXiv:2210.00378",
    "title": "Optimized Decoders for Mixed-Order Ambisonics",
    "abstract": "In this paper we discuss the motivation, design, and analysis of ambisonic\ndecoders for systems where the vertical order is less than the horizontal\norder, known as mixed-order Ambisonic systems. This can be due to the use of\nmicrophone arrays that emphasize horizontal spatial resolution or speaker\narrays that provide sparser coverage vertically. First, we review Ambisonic\nreproduction criteria, as defined by Gerzon, and summarize recent results on\nthe relative perceptual importance of the various criteria. Then we show that\nusing full-order decoders with mixed-order program material results in poorer\nperformance than with a properly designed mixed-order decoder. We then\nintroduce a new implementation of a decoder optimizer that draws upon\ntechniques from machine learning for quick and robust convergence, discuss the\nconstruction of the objective function, and apply it to the problem of\ndesigning two-band decoders for mixed-order signal sets and non-uniform\nloudspeaker layouts. Results of informal listening tests are summarized and\nfuture directions discussed.",
    "descriptor": "\nComments: 9 pages, 10 figures,\n",
    "authors": [
      "Aaron Heller",
      "Eric Benjamin",
      "Fernando Lopez-Lezcano"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00378"
  },
  {
    "id": "arXiv:2210.00383",
    "title": "Conditions for minimally tough graphs",
    "abstract": "Katona, Solt\\'esz, and Varga showed that no induced subgraph can be excluded\nfrom the class of minimally tough graphs. In this paper, we consider the\nopposite question, namely which induced subgraphs, if any, must necessarily be\npresent in each minimally $t$-tough graph.\nKatona and Varga showed that for any rational number $t \\in (1/2,1]$, every\nminimally $t$-tough graph contains a hole. We complement this result by showing\nthat for any rational number $t>1$, every minimally $t$-tough graph must\ncontain either a hole or an induced subgraph isomorphic to the $k$-sun for some\ninteger $k \\ge 3$.\nWe also show that for any rational number $t > 1/2$, every minimally\n$t$-tough graph must contain either an induced $4$-cycle, an induced $5$-cycle,\nor two independent edges as an induced subgraph.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Blas Fern\u00e1ndez",
      "Gyula Y. Katona",
      "Martin Milani\u010d",
      "Kitti Varga"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.00383"
  },
  {
    "id": "arXiv:2210.00384",
    "title": "Using matrix sparsification to solve tropical linear vector equations",
    "abstract": "A linear vector equation in two unknown vectors is examined in the framework\nof tropical algebra dealing with the theory and applications of semirings and\nsemifields with idempotent addition. We consider a two-sided equation where\neach side is a tropical product of a given matrix by one of the unknown\nvectors. We use a matrix sparsification technique to reduce the equation to a\nset of vector inequalities that involve row-monomial matrices obtained from the\ngiven matrices. An existence condition of solutions for the inequalities is\nestablished, and a direct representation of the solutions is derived in a\ncompact vector form. To illustrate the proposed approach and to compare the\nobtained result with that of an existing solution procedure, we apply our\nsolution technique to handle two-sided equations known in the literature.\nFinally, a computational scheme based on the approach to derive all solutions\nof the two-sided equation is discussed.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nikolai Krivulin"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00384"
  },
  {
    "id": "arXiv:2210.00392",
    "title": "Physical computation and compositionality",
    "abstract": "Developments in quantum computing and, more in general, non-standard\ncomputing systems, represent a clear indication that the very notion of what a\nphysical computing device is and does should be recast in a rigorous and sound\nframework. Physical computing has opened a whole stream of new research aimed\nto understand and control how information is processed by several types of\nphysical devices. Therefore, classical definitions and entire frameworks need\nto be adapted in order to fit a broader notion of what physical computing\nsystems really are. Recent studies have proposed a formalism that can be used\nto carve out a more proper notion of physical computing. In this paper we\npresent a framework which capture such results in a very natural way via some\nbasic constructions in Category Theory. Furthermore, we show that, within our\nframework, the compositional nature of physical computing systems is naturally\nformalized, and that it can be organized in coherent structures by the means of\ntheir relational nature.",
    "descriptor": "",
    "authors": [
      "Nima Dehghani",
      "Gianluca Caterina"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computational Physics (physics.comp-ph)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.00392"
  },
  {
    "id": "arXiv:2210.00407",
    "title": "PCONet: A Convolutional Neural Network Architecture to Detect Polycystic  Ovary Syndrome (PCOS) from Ovarian Ultrasound Images",
    "abstract": "Polycystic Ovary Syndrome (PCOS) is an endrocrinological dysfunction\nprevalent among women of reproductive age. PCOS is a combination of syndromes\ncaused by an excess of androgens - a group of sex hormones - in women.\nSyndromes including acne, alopecia, hirsutism, hyperandrogenaemia,\noligo-ovulation, etc. are caused by PCOS. It is also a major cause of female\ninfertility. An estimated 15% of reproductive-aged women are affected by PCOS\nglobally. The necessity of detecting PCOS early due to the severity of its\ndeleterious effects cannot be overstated. In this paper, we have developed\nPCONet - a Convolutional Neural Network (CNN) - to detect polycistic ovary from\novarian ultrasound images. We have also fine tuned InceptionV3 - a pretrained\nconvolutional neural network of 45 layers - by utilizing the transfer learning\nmethod to classify polcystic ovarian ultrasound images. We have compared these\ntwo models on various quantitative performance evaluation parameters and\ndemonstrated that PCONet is the superior one among these two with an accuracy\nof 98.12%, whereas the fine tuned InceptionV3 showcased an accuracy of 96.56%\non test images.",
    "descriptor": "",
    "authors": [
      "A.K.M. Salman Hosain",
      "Md Humaion Kabir Mehedi",
      "Irteza Enan Kabir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00407"
  },
  {
    "id": "arXiv:2210.00417",
    "title": "Voice Spoofing Countermeasures: Taxonomy, State-of-the-art, experimental  analysis of generalizability, open challenges, and the way forward",
    "abstract": "Malicious actors may seek to use different voice-spoofing attacks to fool ASV\nsystems and even use them for spreading misinformation. Various countermeasures\nhave been proposed to detect these spoofing attacks. Due to the extensive work\ndone on spoofing detection in automated speaker verification (ASV) systems in\nthe last 6-7 years, there is a need to classify the research and perform\nqualitative and quantitative comparisons on state-of-the-art countermeasures.\nAdditionally, no existing survey paper has reviewed integrated solutions to\nvoice spoofing evaluation and speaker verification, adversarial/antiforensics\nattacks on spoofing countermeasures, and ASV itself, or unified solutions to\ndetect multiple attacks using a single model. Further, no work has been done to\nprovide an apples-to-apples comparison of published countermeasures in order to\nassess their generalizability by evaluating them across corpora. In this work,\nwe conduct a review of the literature on spoofing detection using hand-crafted\nfeatures, deep learning, end-to-end, and universal spoofing countermeasure\nsolutions to detect speech synthesis (SS), voice conversion (VC), and replay\nattacks. Additionally, we also review integrated solutions to voice spoofing\nevaluation and speaker verification, adversarial and anti-forensics attacks on\nvoice countermeasures, and ASV. The limitations and challenges of the existing\nspoofing countermeasures are also presented. We report the performance of these\ncountermeasures on several datasets and evaluate them across corpora. For the\nexperiments, we employ the ASVspoof2019 and VSDC datasets along with GMM, SVM,\nCNN, and CNN-GRU classifiers. (For reproduceability of the results, the code of\nthe test bed can be found in our GitHub Repository.",
    "descriptor": "",
    "authors": [
      "Awais Khan",
      "Khalid Mahmood Malik",
      "James Ryan",
      "Mikul Saravanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00417"
  },
  {
    "id": "arXiv:2210.00434",
    "title": "Music-to-Text Synaesthesia: Generating Descriptive Text from Music  Recordings",
    "abstract": "In this paper, we consider a novel research problem, music-to-text\nsynaesthesia. Different from the classical music tagging problem that\nclassifies a music recording into pre-defined categories, the music-to-text\nsynaesthesia aims to generate descriptive texts from music recordings for\nfurther understanding. Although this is a new and interesting application to\nthe machine learning community, to our best knowledge, the existing\nmusic-related datasets do not contain the semantic descriptions on music\nrecordings and cannot serve the music-to-text synaesthesia task. In light of\nthis, we collect a new dataset that contains 1,955 aligned pairs of classical\nmusic recordings and text descriptions. Based on this, we build a computational\nmodel to generate sentences that can describe the content of the music\nrecording. To tackle the highly non-discriminative classical music, we design a\ngroup topology-preservation loss in our computational model, which considers\nmore samples as a group reference and preserves the relative topology among\ndifferent samples. Extensive experimental results qualitatively and\nquantitatively demonstrate the effectiveness of our proposed model over five\nheuristics or pre-trained competitive methods and their variants on our\ncollected dataset.",
    "descriptor": "",
    "authors": [
      "Zhihuan Kuang",
      "Shi Zong",
      "Jianbing Zhang",
      "Jiajun Chen",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00434"
  },
  {
    "id": "arXiv:2210.00437",
    "title": "A Unified Framework for Optimization-Based Graph Coarsening",
    "abstract": "Graph coarsening is a widely used dimensionality reduction technique for\napproaching large-scale graph machine learning problems. Given a large graph,\ngraph coarsening aims to learn a smaller-tractable graph while preserving the\nproperties of the originally given graph. Graph data consist of node features\nand graph matrix (e.g., adjacency and Laplacian). The existing graph coarsening\nmethods ignore the node features and rely solely on a graph matrix to simplify\ngraphs. In this paper, we introduce a novel optimization-based framework for\ngraph dimensionality reduction. The proposed framework lies in the unification\nof graph learning and dimensionality reduction. It takes both the graph matrix\nand the node features as the input and learns the coarsen graph matrix and the\ncoarsen feature matrix jointly while ensuring desired properties. The proposed\noptimization formulation is a multi-block non-convex optimization problem,\nwhich is solved efficiently by leveraging block majorization-minimization,\n$\\log$ determinant, Dirichlet energy, and regularization frameworks. The\nproposed algorithms are provably convergent and practically amenable to\nnumerous tasks. It is also established that the learned coarsened graph is\n$\\epsilon\\in(0,1)$ similar to the original graph. Extensive experiments\nelucidate the efficacy of the proposed framework for real-world applications.",
    "descriptor": "\nComments: 34 pages, 15 figures\n",
    "authors": [
      "Manoj Kumar",
      "Anurag Sharma",
      "Sandeep Kumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00437"
  },
  {
    "id": "arXiv:2210.00506",
    "title": "Loc-VAE: Learning Structurally Localized Representation from 3D Brain MR  Images for Content-Based Image Retrieval",
    "abstract": "Content-based image retrieval (CBIR) systems are an emerging technology that\nsupports reading and interpreting medical images. Since 3D brain MR images are\nhigh dimensional, dimensionality reduction is necessary for CBIR using machine\nlearning techniques. In addition, for a reliable CBIR system, each dimension in\nthe resulting low-dimensional representation must be associated with a\nneurologically interpretable region. We propose a localized variational\nautoencoder (Loc-VAE) that provides neuroanatomically interpretable\nlow-dimensional representation from 3D brain MR images for clinical CBIR.\nLoc-VAE is based on $\\beta$-VAE with the additional constraint that each\ndimension of the low-dimensional representation corresponds to a local region\nof the brain. The proposed Loc-VAE is capable of acquiring representation that\npreserves disease features and is highly localized, even under high-dimensional\ncompression ratios (4096:1). The low-dimensional representation obtained by\nLoc-VAE improved the locality measure of each dimension by 4.61 points compared\nto naive $\\beta$-VAE, while maintaining comparable brain reconstruction\ncapability and information about the diagnosis of Alzheimer's disease.",
    "descriptor": "\nComments: 6 pages, 6 figures. Accepted at the International Conference on Systems, Man, and Cybernetics (IEEE SMC '22)\n",
    "authors": [
      "Kei Nishimaki",
      "Kumpei Ikuta",
      "Yuto Onga",
      "Hitoshi Iyatomi",
      "Kenichi Oishi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.00506"
  },
  {
    "id": "arXiv:2210.00508",
    "title": "The lexicographically least square-free word with a given prefix",
    "abstract": "The lexicographically least square-free infinite word on the alphabet of\nnon-negative integers with a given prefix $p$ is denoted $L(p)$. When $p$ is\nthe empty word, this word was shown by Guay-Paquet and Shallit to be the ruler\nsequence. For other prefixes, the structure is significantly more complicated.\nIn this paper, we show that $L(p)$ reflects the structure of the ruler sequence\nfor several words $p$. We provide morphisms that generate $L(n)$ for letters\n$n=1$ and $n\\geq3$, and $L(p)$ for most families of two-letter words $p$.",
    "descriptor": "",
    "authors": [
      "Siddharth Berera",
      "Andr\u00e9s G\u00f3mez-Colunga",
      "Joey Lakerdas-Gayle",
      "John L\u00f3pez",
      "Mauditra Matin",
      "Daniel Roebuck",
      "Eric Rowland",
      "Noam Scully",
      "Juliet Whidden"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.00508"
  },
  {
    "id": "arXiv:2210.00515",
    "title": "Deep-OCTA: Ensemble Deep Learning Approaches for Diabetic Retinopathy  Analysis on OCTA Images",
    "abstract": "The ultra-wide optical coherence tomography angiography (OCTA) has become an\nimportant imaging modality in diabetic retinopathy (DR) diagnosis. However,\nthere are few researches focusing on automatic DR analysis using ultra-wide\nOCTA. In this paper, we present novel and practical deep-learning solutions\nbased on ultra-wide OCTA for the Diabetic Retinopathy Analysis Challenge\n(DRAC). In the segmentation of DR lesions task, we utilize UNet and UNet++ to\nsegment three lesions with strong data augmentation and model ensemble. In the\nimage quality assessment task, we create an ensemble of InceptionV3,\nSE-ResNeXt, and Vision Transformer models. Pre-training on the large dataset as\nwell as the hybrid MixUp and CutMix strategy are both adopted to boost the\ngeneralization ability of our model. In the DR grading task, we build a Vision\nTransformer (ViT) and fnd that the ViT model pre-trained on color fundus images\nserves as a useful substrate for OCTA images. Our proposed methods ranked 4th,\n3rd, and 5th on the three leaderboards of DRAC, respectively. The source code\nwill be made available at https://github.com/FDU-VTS/DRAC.",
    "descriptor": "",
    "authors": [
      "Junlin Hou",
      "Fan Xiao",
      "Jilan Xu",
      "Yuejie Zhang",
      "Haidong Zou",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00515"
  },
  {
    "id": "arXiv:2210.00520",
    "title": "Periodic orbits in evolutionary game dynamics: An information-theoretic  perspective",
    "abstract": "Even though existence of non-convergent evolution of the states of\npopulations in ecological and evolutionary contexts is an undeniable fact,\ninsightful game-theoretic interpretations of such outcomes are scarce in the\nliterature of evolutionary game theory. Here we tap into the\ninformation-theoretic concept of relative entropy in order to construct a\ngame-theoretic interpretation for periodic orbits in a wide class of\nevolutionary game dynamics. Effectively, we present a consistent generalization\nof the evolutionarily stable strategy-the cornerstone of the evolutionary game\ntheory-and aptly term the generalized concept: information stable orbit. The\ninformation stable orbit captures the essence of the evolutionarily stable\nstrategy in that it compares the total payoff obtained against an evolving\nmutant with the total payoff that the mutant gets while playing against itself.\nFurthermore, we discuss the connection of the information stable orbit with the\ndynamical stability of the corresponding periodic orbit.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Sayak Bhattacharjee",
      "Vikash Kumar Dubey",
      "Archan Mukhopadhyay",
      "Sagar Chakraborty"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Information Theory (cs.IT)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2210.00520"
  },
  {
    "id": "arXiv:2210.00531",
    "title": "The Second-Order Football-Pool Problem and the Optimal Rate of  Generalized-Covering Codes",
    "abstract": "The goal of the classic football-pool problem is to determine how many\nlottery tickets are to be bought in order to guarantee at least $n-r$ correct\nguesses out of a sequence of $n$ games played. We study a generalized\n(second-order) version of this problem, in which any of these $n$ games\nconsists of two sub-games. The second-order version of the football-pool\nproblem is formulated using the notion of generalized-covering radius, recently\nproposed as a fundamental property of linear codes. We consider an extension of\nthis property to general (not necessarily linear) codes, and provide an\nasymptotic solution to our problem by finding the optimal rate function of\nsecond-order covering codes given a fixed normalized covering radius. We also\nprove that the fraction of second-order covering codes among codes of\nsufficiently large rate tends to $1$ as the code length tends to $\\infty$.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Dor Elimelech",
      "Moshe Schwartz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00531"
  },
  {
    "id": "arXiv:2210.00551",
    "title": "Gradient-tracking based Distributed Optimization with Guaranteed  Optimality under Noisy Information Sharing",
    "abstract": "Distributed optimization enables networked agents to cooperatively solve a\nglobal optimization problem even with each participating agent only having\naccess to a local partial view of the objective function. Despite making\nsignificant inroads, most existing results on distributed optimization rely on\nnoise-free information sharing among the agents, which is problematic when\ncommunication channels are noisy, messages are coarsely quantized, or shared\ninformation are obscured by additive noise for the purpose of achieving\ndifferential privacy. The problem of information-sharing noise is particularly\npronounced in the state-of-the-art gradient-tracking based distributed\noptimization algorithms, in that information-sharing noise will accumulate with\niterations on the gradient-tracking estimate of these algorithms, and the\nensuing variance will even grow unbounded when the noise is persistent. This\npaper proposes a new gradient-tracking based distributed optimization approach\nthat can avoid information-sharing noise from accumulating in the gradient\nestimation. The approach is applicable even when the {inter-agent interaction\nis} time-varying, which is key to enable the incorporation of a decaying factor\nin inter-agent interaction to gradually eliminate the influence of\ninformation-sharing noise. In fact, we rigorously prove that the proposed\napproach can ensure the almost sure convergence of all agents to the same\noptimal solution even in the presence of persistent information-sharing noise.\nThe approach is applicable to general directed graphs. It is also capable of\nensuring the almost sure convergence of all agents to an optimal solution when\nthe gradients are noisy, which is common in machine learning applications.\nNumerical simulations confirm the effectiveness of the proposed approach.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Automatic Control as a full paper. arXiv admin note: text overlap with arXiv:2202.01113\n",
    "authors": [
      "Yongqiang Wang",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00551"
  },
  {
    "id": "arXiv:2210.00579",
    "title": "Large-scale machine-learning-assisted exploration of the whole materials  space",
    "abstract": "Crystal-graph attention networks have emerged recently as remarkable tools\nfor the prediction of thermodynamic stability and materials properties from\nunrelaxed crystal structures. Previous networks trained on two million\nmaterials exhibited, however, strong biases originating from underrepresented\nchemical elements and structural prototypes in the available data. We tackled\nthis issue computing additional data to provide better balance across both\nchemical and crystal-symmetry space. Crystal-graph networks trained with this\nnew data show unprecedented generalization accuracy, and allow for reliable,\naccelerated exploration of the whole space of inorganic compounds. We applied\nthis universal network to perform machine-learning assisted high-throughput\nmaterials searches including 2500 binary and ternary structure prototypes and\nspanning about 1 billion compounds. After validation using density-functional\ntheory, we uncover in total 19512 additional materials on the convex hull of\nthermodynamic stability and ~150000 compounds with a distance of less than 50\nmeV/atom from the hull. Combining again machine learning and ab-initio methods,\nwe finally evaluate the discovered materials for applications as\nsuperconductors, superhard materials, and we look for candidates with large gap\ndeformation potentials, finding several compounds with extreme values of these\nproperties.",
    "descriptor": "",
    "authors": [
      "Jonathan Schmidt",
      "Noah Hoffmann",
      "Hai-Chen Wang",
      "Pedro Borlido",
      "Pedro J. M. A. Carri\u00e7o",
      "Tiago F. T. Cerqueira",
      "Silvana Botti",
      "Miguel A. L. Marques"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00579"
  },
  {
    "id": "arXiv:2210.00623",
    "title": "Inability of a graph neural network heuristic to outperform greedy  algorithms in solving combinatorial optimization problems like Max-Cut",
    "abstract": "In Nature Machine Intelligence 4, 367 (2022), Schuetz et al provide a scheme\nto employ graph neural networks (GNN) as a heuristic to solve a variety of\nclassical, NP-hard combinatorial optimization problems. It describes how the\nnetwork is trained on sample instances and the resulting GNN heuristic is\nevaluated applying widely used techniques to determine its ability to succeed.\nClearly, the idea of harnessing the powerful abilities of such networks to\n``learn'' the intricacies of complex, multimodal energy landscapes in such a\nhands-off approach seems enticing. And based on the observed performance, the\nheuristic promises to be highly scalable, with a computational cost linear in\nthe input size $n$, although there is likely a significant overhead in the\npre-factor due to the GNN itself. However, closer inspection shows that the\nreported results for this GNN are only minutely better than those for gradient\ndescent and get outperformed by a greedy algorithm, for example, for Max-Cut.\nThe discussion also highlights what I believe are some common misconceptions in\nthe evaluations of heuristics.",
    "descriptor": "\nComments: RevTex4, 2 pages, 1 figure; comment on arXiv:2107.01188. Related information at this http URL\n",
    "authors": [
      "Stefan Boettcher"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00623"
  },
  {
    "id": "arXiv:2210.00644",
    "title": "Analysis of Gradient Descent with Varying Step Sizes using Integral  Quadratic Constraints",
    "abstract": "In this paper, we present an analysis of the convergence rate of gradient\ndescent with a varying step size, on strongly convex functions. We assume that\na line search has been carried out and produces a step size that varies in a\nknown interval. The algorithm is then handled as a linear, parameter-varying\n(LPV) system. Building on prior work that uses Integral Quadratic Constraints\n(IQCs) to analyze optimization algorithms, we construct a linear matrix\ninequality (LMI) condition to numerically obtain convergence rates. For the LPV\nsystem, this condition is solved by a gridding approach on the step size\ninterval. Our results indicate that the algorithm converges in a restricted set\nwithin the step size interval. Further, when this interval reduces to a point,\ni.e., when a constant step size is used, the algorithm recovers the gradient\nrate corresponding to constant step sizes.",
    "descriptor": "\nComments: Submitted to ACC 2023. 6 pages, 4 figures\n",
    "authors": [
      "Ram Padmanabhan",
      "Peter Seiler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00644"
  },
  {
    "id": "arXiv:2210.00657",
    "title": "Q2Graph: a modelling tool for measurement-based quantum computing",
    "abstract": "The quantum circuit model is the default for encoding an algorithm intended\nfor a NISQ computer or a quantum computing simulator. A simple graph and\nthrough it, a graph state - quantum state physically manifesting an abstract\ngraph structure - is syntactically expressive and tractable. A graph\nrepresentation is well-suited for algorithms intended for a quantum computing\nfacility founded on measurement-based quantum computing (MBQC) principles.\nIndeed, the process of creating an algorithm-specific graph can be efficiently\nrealised through classical computing hardware. A graph state is a stabiliser\nstate, which means a graph is a (quantum) intermediate representation at all\npoints of the algorithm-specific graph process. We submit Q2Graph, a software\npackage for designing and testing of simple graphs as algorithms for quantum\ncomputing facilities based on MQBC design principles. Q2Graph is a suitable\nmodelling tool for NISQ computing facilities: the user is free to reason about\nstructure or characteristics of its graph-as-algorithm without also having to\naccount for (quantum) errors and their impact upon state.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Greg Bowen",
      "Simon Devitt"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.00657"
  },
  {
    "id": "arXiv:2210.00676",
    "title": "Some pointwise and decidable properties of non-uniform cellular automata",
    "abstract": "For non-uniform cellular automata (NUCA) with finite memory over an arbitrary\nuniverse with multiple local transition rules, we show that pointwise\nnilpotency, pointwise periodicity, and pointwise eventual periodicity\nproperties are respectively equivalent to nilpotency, periodicity, and eventual\nperiodicity. Moreover, we prove that every linear NUCA which satisfies\npointwise a polynomial equation (which may depend on the configuration) must be\nan eventually periodic linear NUCA. Generalizing results for higher dimensional\ngroup and linear CA, we also establish the decidability results of the above\ndynamical properties as well as the injectivity for arbitrary NUCA with finite\nmemory which are local perturbations of higher dimensional linear and group CA.\nSome generalizations to the case of sparse global perturbations of higher\ndimensional linear and group CA are also obtained.",
    "descriptor": "",
    "authors": [
      "Xuan Kien Phung"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00676"
  },
  {
    "id": "arXiv:2210.00679",
    "title": "High Probability Convergence for Accelerated Stochastic Mirror Descent",
    "abstract": "In this work, we describe a generic approach to show convergence with high\nprobability for stochastic convex optimization. In previous works, either the\nconvergence is only in expectation or the bound depends on the diameter of the\ndomain. Instead, we show high probability convergence with bounds depending on\nthe initial distance to the optimal solution as opposed to the domain diameter.\nThe algorithms use step sizes analogous to the standard settings and are\nuniversal to Lipschitz functions, smooth functions, and their linear\ncombinations.",
    "descriptor": "",
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00679"
  },
  {
    "id": "arXiv:2210.00688",
    "title": "On the infinite-depth limit of finite-width neural networks",
    "abstract": "In this paper, we study the infinite-depth limit of finite-width residual\nneural networks with random Gaussian weights. With proper scaling, we show that\nby fixing the width and taking the depth to infinity, the vector of\npre-activations converges in distribution to a zero-drift diffusion process.\nUnlike the infinite-width limit where the pre-activation converge weakly to a\nGaussian random variable, we show that the infinite-depth limit yields\ndifferent distributions depending on the choice of the activation function. We\ndocument two cases where these distributions have closed-form (different)\nexpressions. We further show an intriguing phase-transition phenomenon of the\npost-activation norms when the width increases from 3 to 4. Lastly, we study\nthe sequential limit infinite-depth-then-infinite-width, and show some key\ndifferences with the more commonly studied infinite-width-then-infinite-depth\nlimit.",
    "descriptor": "\nComments: 65 pages, 19 figures\n",
    "authors": [
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.00688"
  },
  {
    "id": "arXiv:2210.00695",
    "title": "Automated Performance Estimation for Decentralized Optimization via  Network Size Independent Problems",
    "abstract": "We develop a novel formulation of the Performance Estimation Problem (PEP)\nfor decentralized optimization whose size is independent of the number of\nagents in the network. The PEP approach allows computing automatically the\nworst-case performance and worst-case instance of first-order optimization\nmethods by solving an SDP. Unlike previous work, the size of our new PEP\nformulation is independent of the network size. For this purpose, we take a\nglobal view of the decentralized problem and we also decouple the consensus\nsubspace and its orthogonal complement. We apply our methodology to different\ndecentralized methods such as DGD, DIGing and EXTRA and obtain numerically\ntight performance guarantees that are valid for any network size.",
    "descriptor": "\nComments: 8 pages, 3 figures, accepted for Conference on Decision and Control 2022. arXiv admin note: text overlap with arXiv:2203.05963\n",
    "authors": [
      "Sebastien Colla",
      "Julien M. Hendrickx"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.00695"
  },
  {
    "id": "arXiv:2210.00727",
    "title": "Privacy-Preserving Feature Coding for Machines",
    "abstract": "Automated machine vision pipelines do not need the exact visual content to\nperform their tasks. Therefore, there is a potential to remove private\ninformation from the data without significantly affecting the machine vision\naccuracy. We present a novel method to create a privacy-preserving latent\nrepresentation of an image that could be used by a downstream machine vision\nmodel. This latent representation is constructed using adversarial training to\nprevent accurate reconstruction of the input while preserving the task\naccuracy. Specifically, we split a Deep Neural Network (DNN) model and insert\nan autoencoder whose purpose is to both reduce the dimensionality as well as\nremove information relevant to input reconstruction while minimizing the impact\non task accuracy. Our results show that input reconstruction ability can be\nreduced by about 0.8 dB at the equivalent task accuracy, with degradation\nconcentrated near the edges, which is important for privacy. At the same time,\n30% bit savings are achieved compared to coding the features directly.",
    "descriptor": "\nComments: 5 pages, 3 figures, Picture Coding Symposium (PCS) 2022\n",
    "authors": [
      "Bardia Azizian",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00727"
  },
  {
    "id": "arXiv:2210.00731",
    "title": "Sentiment Analysis of ESG disclosures on Stock Market",
    "abstract": "In this paper, we look at the impact of Environment, Social and Governance\nrelated news articles and social media data on the stock market performance. We\npick four stocks of companies which are widely known in their domain to\nunderstand the complete effect of ESG as the newly opted investment style\nremains restricted to only the stocks with widespread information. We summarise\nlive data of both twitter tweets and newspaper articles and create a sentiment\nindex using a dictionary technique based on online information for the month of\nJuly, 2022. We look at the stock price data for all the four companies and\ncalculate the percentage change in each of them. We also compare the overall\nsentiment of the company to its percentage change over a specific historical\nperiod.",
    "descriptor": "",
    "authors": [
      "Sudeep R. Bapat",
      "Saumya Kothari",
      "Rushil Bansal"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00731"
  },
  {
    "id": "arXiv:2210.00736",
    "title": "A large sample theory for infinitesimal gradient boosting",
    "abstract": "Infinitesimal gradient boosting is defined as the vanishing-learning-rate\nlimit of the popular tree-based gradient boosting algorithm from machine\nlearning (Dombry and Duchamps, 2021). It is characterized as the solution of a\nnonlinear ordinary differential equation in a infinite-dimensional function\nspace where the infinitesimal boosting operator driving the dynamics depends on\nthe training sample. We consider the asymptotic behavior of the model in the\nlarge sample limit and prove its convergence to a deterministic process. This\ninfinite population limit is again characterized by a differential equation\nthat depends on the population distribution. We explore some properties of this\npopulation limit: we prove that the dynamics makes the test error decrease and\nwe consider its long time behavior.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Clement Dombry",
      "Jean-Jil Duchamps"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.00736"
  },
  {
    "id": "arXiv:2210.00747",
    "title": "Stochastic optimization of a mixed moving average process for  controlling non-Markovian streamflow environments",
    "abstract": "In this study, we investigated a cost-constrained static ergodic control\nproblem of the variance of measure-valued affine processes and its application\nin streamflow management. The controlled system is a jump-driven mixed moving\naverage process that generates subexponential autocorrelation functions, and\nthe static nature of the control originates from a realistic observability\nassumption in the system. The Markovian lift was effectively used to discretize\nthe system into a finite-dimensional process, which is easier to analyze. The\nresolution of the problem is based on backward Kolmogorov equations and a\nquadratic solution ansatz. The control problem has a closed-form solution, and\nthe variance has both strict upper and lower bounds, indicating that the\nvariance cannot take an arbitrary value even when it is subject to a high\ncontrol cost. The correspondence between the discretized system based on the\nMarkovian lift and the original infinite-dimensional one is discussed. Then, a\nconvergent Markovian lift is presented to approximate the infinite-dimensional\nsystem. Finally, the control problem was applied to real cases using available\ndata for a river reach. An extended problem subject to an additional constraint\non maintaining the flow variability was also analyzed without significantly\ndegrading the tractability of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Hidekazu Yoshioka",
      "Tomohiro Tanaka",
      "Yumi Yoshika",
      "Ayumi Hashuguchi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00747"
  },
  {
    "id": "arXiv:2210.00794",
    "title": "SDC-based Resource Constrained Scheduling for Quantum Control  Architectures",
    "abstract": "Instruction scheduling is a key transformation in backend compilers that take\nan untimed description of an algorithm and assigns time slots to the\nalgorithm's instructions so that they can be executed as efficiently as\npossible while taking into account the target processor limitations, such as\nthe amount of computational units available. For example, for a superconducting\nquantum processor these restrictions include the amount of analogue instruments\navailable to play the waveforms to drive the qubit rotations or on-chip\nconnectivity between qubits. Current small-scale quantum processors contain\nonly a few qubits; therefore, it is feasible to drive qubits individually\nalbeit not scalable. Consequently, for NISQ and beyond NISQ devices, it is\nexpected that classical instrument sharing to be designed in the future quantum\ncontrol architectures where several qubits are connected to an instrument and\nmultiplexing is used to activate only the qubits performing the same quantum\noperation at a time. Existing quantum scheduling algorithms either rely on ILP\nformulations, which do not scale well, or use heuristic based algorithms such\nas list scheduling which are not versatile enough to deal with quantum\nrequirements such as scheduling with exact relative timing constraints between\ninstructions, situation that might occur when decomposing complex instructions\ninto native ones and requiring to keep a fixed timing between the primitive\nones to guarantee correctness. In this paper, we propose a novel resource\nconstrained scheduling algorithm that is based on the SDC formulation, which is\nthe state-of-the-art algorithm used in the reconfigurable computing. We\nevaluate it against a list scheduler and describe the benefits of the proposed\napproach. We find that the SDC-based scheduling is not only able to find better\nschedules but also model flexible relative timing constraints.",
    "descriptor": "",
    "authors": [
      "Razvan Nane"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.00794"
  },
  {
    "id": "arXiv:2210.00802",
    "title": "DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm",
    "abstract": "Background: Drug synergy occurs when the combined effect of two drugs is\ngreater than the sum of the individual drugs' effect. While cell line data\nmeasuring the effect of single drugs are readily available, there is relatively\nless comparable data on drug synergy given the vast amount of possible drug\ncombinations. Thus, there is interest to use computational approaches to\npredict drug synergy for untested pairs of drugs.\nMethods: We introduce a Graph Neural Network (GNN) based model for drug\nsynergy prediction, which utilizes drug chemical structures and cell line gene\nexpression data. We use information from the largest drug combination database\navailable (DrugComb), combining drug synergy scores in order to construct high\nconfidence benchmark datasets.\nResults: Our proposed solution for drug synergy predictions offers a number\nof benefits: 1) It is trained on high confidence benchmark dataset. 2) It\nutilizes 34 distinct drug synergy datasets to learn on a wide variety of drugs\nand cell lines representations. 3) It learns task-specific drug\nrepresentations, instead of relying on generalized and pre-computed chemical\ndrug features. 4) It achieves similar or better prediction performance (AUPR\nscores ranging from 0.777 to 0.964) compared to state-of-the-art baseline\nmodels when tested on various benchmark datasets.\nConclusions: We demonstrate that a GNN based model can provide\nstate-of-the-art drug synergy predictions by learning task-specific\nrepresentations of drugs.",
    "descriptor": "",
    "authors": [
      "Kyriakos Schwarz",
      "Alicia Pliego-Mendieta",
      "Lara Planas-Paz",
      "Chantal Pauli",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.00802"
  },
  {
    "id": "arXiv:2210.00815",
    "title": "Measurement of Trustworthiness of the Online Reviews",
    "abstract": "In electronic commerce (e-commerce)markets, a decision-maker faces a\nsequential choice problem. Third-party intervention plays an important role in\nmaking purchase decisions in this choice process. For instance, while\npurchasing products/services online, a buyer's choice or behavior is often\naffected by the overall reviewers' ratings, feedback, etc. Moreover, the\nreviewer is also a decision-maker. After purchase, the decision-maker would put\nforth their reviews for the product, online. Such reviews would affect the\npurchase decision of another potential buyer, who would read the reviews before\nconforming to his/her final purchase. The question that arises is \\textit{how\ntrustworthy are these review reports and ratings?} The trustworthiness of these\nreview reports and ratings is based on whether the reviewer is a rational or an\nirrational person. Indexing the reviewer's rationality could be a way to\nquantify a reviewer's rationality but it does not communicate the history of\nhis/her behavior. In this article, the researcher aims at formally deriving a\nrationality pattern function and thereby, the degree of rationality of the\ndecision-maker or the reviewer in the sequential choice problem in the\ne-commerce markets. Applying such a rationality pattern function could make it\neasier to quantify the rational behavior of an agent who participates in the\ndigital markets. This, in turn, is expected to minimize the information\nasymmetry within the decision-making process and identify the paid reviewers or\nmanipulative reviews.",
    "descriptor": "",
    "authors": [
      "Dipankar Das"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00815"
  },
  {
    "id": "arXiv:2210.00823",
    "title": "BVI-VFI: A Video Quality Database for Video Frame Interpolation",
    "abstract": "Video frame interpolation (VFI) is a fundamental research topic in video\nprocessing, which is currently attracting increased attention across the\nresearch community. While the development of more advanced VFI algorithms has\nbeen extensively researched, there remains little understanding of how humans\nperceive the quality of interpolated content and how well existing objective\nquality assessment methods perform when measuring the perceived quality. In\norder to narrow this research gap, we have developed a new video quality\ndatabase named BVI-VFI, which contains 540 distorted sequences generated by\napplying five commonly used VFI algorithms to 36 diverse source videos with\nvarious spatial resolutions and frame rates. We collected more than 10,800\nquality ratings for these videos through a large scale subjective study\ninvolving 189 human subjects. Based on the collected subjective scores, we\nfurther analysed the influence of VFI algorithms and frame rates on the\nperceptual quality of interpolated videos. Moreover, we benchmarked the\nperformance of 28 classic and state-of-the-art objective image/video quality\nmetrics on the new database, and demonstrated the urgent requirement for more\naccurate bespoke quality assessment methods for VFI. To facilitate further\nresearch in this area, we have made BVI-VFI publicly available at\nhttps://github.com/danielism97/BVI-VFI-database.",
    "descriptor": "",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00823"
  },
  {
    "id": "arXiv:2210.00824",
    "title": "Random Data Augmentation based Enhancement: A Generalized Enhancement  Approach for Medical Datasets",
    "abstract": "Over the years, the paradigm of medical image analysis has shifted from\nmanual expertise to automated systems, often using deep learning (DL) systems.\nThe performance of deep learning algorithms is highly dependent on data\nquality. Particularly for the medical domain, it is an important aspect as\nmedical data is very sensitive to quality and poor quality can lead to\nmisdiagnosis. To improve the diagnostic performance, research has been done\nboth in complex DL architectures and in improving data quality using dataset\ndependent static hyperparameters. However, the performance is still constrained\ndue to data quality and overfitting of hyperparameters to a specific dataset.\nTo overcome these issues, this paper proposes random data augmentation based\nenhancement. The main objective is to develop a generalized, data-independent\nand computationally efficient enhancement approach to improve medical data\nquality for DL. The quality is enhanced by improving the brightness and\ncontrast of images. In contrast to the existing methods, our method generates\nenhancement hyperparameters randomly within a defined range, which makes it\nrobust and prevents overfitting to a specific dataset. To evaluate the\ngeneralization of the proposed method, we use four medical datasets and compare\nits performance with state-of-the-art methods for both classification and\nsegmentation tasks. For grayscale imagery, experiments have been performed\nwith: COVID-19 chest X-ray, KiTS19, and for RGB imagery with: LC25000 datasets.\nExperimental results demonstrate that with the proposed enhancement\nmethodology, DL architectures outperform other existing methods. Our code is\npublicly available at:\nhttps://github.com/aleemsidra/Augmentation-Based-Generalized-Enhancement",
    "descriptor": "\nComments: Our paper is accepted at 24th Irish Machine Vision and Image Processing (IMVIP) Conference, Belfast. Paper got BCS NI Best Poster Presentation Award and copy of proceeding is at this https URL\n",
    "authors": [
      "Sidra Aleem",
      "Teerath Kumar",
      "Suzanne Little",
      "Malika Bendechache",
      "Rob Brennan",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00824"
  },
  {
    "id": "arXiv:2210.00864",
    "title": "quEEGNet: Quantum AI for Biosignal Processing",
    "abstract": "In this paper, we introduce an emerging quantum machine learning (QML)\nframework to assist classical deep learning methods for biosignal processing\napplications. Specifically, we propose a hybrid quantum-classical neural\nnetwork model that integrates a variational quantum circuit (VQC) into a deep\nneural network (DNN) for electroencephalogram (EEG), electromyogram (EMG), and\nelectrocorticogram (ECoG) analysis. We demonstrate that the proposed quantum\nneural network (QNN) achieves state-of-the-art performance while the number of\ntrainable parameters is kept small for VQC.",
    "descriptor": "\nComments: 4 pages, 2 figures, BHI-BSN 2022\n",
    "authors": [
      "Toshiaki Koike-Akino",
      "Ye Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00864"
  },
  {
    "id": "arXiv:2210.00870",
    "title": "Multiclass Sentiment Prediction for Stock Trading",
    "abstract": "Python was used to download and format NewsAPI article data relating to 400\npublicly traded, low cap. Biotech companies. Crowd-sourcing was used to label a\nsubset of this data to then train and evaluate a variety of models to classify\nthe public sentiment of each company. The best performing models were then used\nto show that trading entirely off public sentiment could provide market beating\nreturns.",
    "descriptor": "\nComments: 5 pages, 11 figures, written for course credit in the spring semester of 2020\n",
    "authors": [
      "Marshall R. McCraw"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00870"
  },
  {
    "id": "arXiv:2210.00874",
    "title": "Stability Via Adversarial Training of Neural Network Stochastic Control  of Mean-Field Type",
    "abstract": "In this paper, we present an approach to neural network mean-field-type\ncontrol and its stochastic stability analysis by means of adversarial inputs\n(aka adversarial attacks). This is a class of data-driven mean-field-type\ncontrol where the distribution of the variables such as the system states and\ncontrol inputs are incorporated into the problem. Besides, we present a\nmethodology to validate the feasibility of the approximations of the solutions\nvia neural networks and evaluate their stability. Moreover, we enhance the\nstability by enlarging the training set with adversarial inputs to obtain a\nmore robust neural network. Finally, a worked-out example based on the\nlinear-quadratic mean-field type control problem (LQ-MTC) is presented to\nillustrate our methodology.",
    "descriptor": "",
    "authors": [
      "Julian Barreiro-Gomez",
      "Salah Eddine Choutri",
      "Boualem Djehiche"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.00874"
  },
  {
    "id": "arXiv:2210.00876",
    "title": "Embedding-based neural network for investment return prediction",
    "abstract": "In addition to being familiar with policies, high investment returns also\nrequire extensive knowledge of relevant industry knowledge and news. In\naddition, it is necessary to leverage relevant theories for investment to make\ndecisions, thereby amplifying investment returns. A effective investment return\nestimate can feedback the future rate of return of investment behavior. In\nrecent years, deep learning are developing rapidly, and investment return\nprediction based on deep learning has become an emerging research topic. This\npaper proposes an embedding-based dual branch approach to predict an\ninvestment's return. This approach leverages embedding to encode the investment\nid into a low-dimensional dense vector, thereby mapping high-dimensional data\nto a low-dimensional manifold, so that highdimensional features can be\nrepresented competitively. In addition, the dual branch model realizes the\ndecoupling of features by separately encoding different information in the two\nbranches. In addition, the swish activation function further improves the model\nperformance. Our approach are validated on the Ubiquant Market Prediction\ndataset. The results demonstrate the superiority of our approach compared to\nXgboost, Lightgbm and Catboost.",
    "descriptor": "\nComments: Accepted at 2022 2nd IEEE International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology\n",
    "authors": [
      "Jianlong Zhu",
      "Dan Xian",
      "Fengxiao",
      "Yichen Nie"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00876"
  },
  {
    "id": "arXiv:2210.00883",
    "title": "Forecasting Cryptocurrencies Log-Returns: a LASSO-VAR and Sentiment  Approach",
    "abstract": "Cryptocurrencies have become a trendy topic recently, primarily due to their\ndisruptive potential and reports of unprecedented returns. In addition,\nacademics increasingly acknowledge the predictive power of Social Media in many\nfields and, more specifically, for financial markets and economics. In this\npaper, we leverage the predictive power of Twitter and Reddit sentiment\ntogether with Google Trends indexes and volume to forecast the log returns of\nten cryptocurrencies. Specifically, we consider $Bitcoin$, $Ethereum$,\n$Tether$, $Binance Coin$, $Litecoin$, $Enjin Coin$, $Horizen$, $Namecoin$,\n$Peercoin$, and $Feathercoin$. We evaluate the performance of LASSO-VAR using\ndaily data from January 2018 to January 2022. In a 30 days recursive forecast,\nwe can retrieve the correct direction of the actual series more than 50% of the\ntime. We compare this result with the main benchmarks, and we see a 10%\nimprovement in Mean Directional Accuracy (MDA). The use of sentiment and\nattention variables as predictors increase significantly the forecast accuracy\nin terms of MDA but not in terms of Root Mean Squared Errors. We perform a\nGranger causality test using a post-double LASSO selection for high-dimensional\nVARs. Results show no \"causality\" from Social Media sentiment to\ncryptocurrencies returns",
    "descriptor": "",
    "authors": [
      "Federico D'Amario",
      "Milos Ciganovic"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2210.00883"
  },
  {
    "id": "arXiv:2210.00896",
    "title": "CBLab: Scalable Traffic Simulation with Enriched Data Supporting",
    "abstract": "Traffic simulation provides interactive data for the optimization of traffic\npolicies. However, existing traffic simulators are limited by their lack of\nscalability and shortage in input data, which prevents them from generating\ninteractive data from traffic simulation in the scenarios of real large-scale\ncity road networks.\nIn this paper, we present City Brain Lab, a toolkit for scalable traffic\nsimulation. CBLab is consist of three components: CBEngine, CBData, and\nCBScenario. CBEngine is a highly efficient simulators supporting large scale\ntraffic simulation. CBData includes a traffic dataset with road network data of\n100 cities all around the world. We also develop a pipeline to conduct\none-click transformation from raw road networks to input data of our traffic\nsimulation. Combining CBEngine and CBData allows researchers to run scalable\ntraffic simulation in the road network of real large-scale cities. Based on\nthat, CBScenario implements an interactive environment and several baseline\nmethods for two scenarios of traffic policies respectively, with which traffic\npolicies adaptable for large-scale urban traffic can be trained and tuned. To\nthe best of our knowledge, CBLab is the first infrastructure supporting traffic\npolicy optimization on large-scale urban scenarios. The code is available on\nGithub: https://github.com/CityBrainLab/CityBrainLab.git.",
    "descriptor": "",
    "authors": [
      "Chumeng Liang",
      "Zherui Huang",
      "Yicheng Liu",
      "Zhanyu Liu",
      "Guanjie Zheng",
      "Hanyuan Shi",
      "Yuhao Du",
      "Fuliang Li",
      "Zhenhui Li"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.00896"
  },
  {
    "id": "arXiv:2210.00916",
    "title": "One Diamond to Rule Them All: Old and new topics about zigzag, levelsets  and extended persistence",
    "abstract": "Extended and zigzag persistence were introduced more than ten years ago, as\ngeneralizations of ordinary persistence. While overcoming certain limitations\nof ordinary persistence, they both enjoy nice computational properties, which\nmake them an intermediate between ordinary and multi-parameter persistence,\nwith already existing efficient software implementations. Nevertheless, their\nalgebraic theory is more intricate, and in the case of extended persistence,\nwas formulated only very recently. In this context, this paper presents a\nrichly illustrated self-contained introduction to the foundational aspects of\nthe topic, with an eye towards recent applications in which they are involved,\nsuch as computational sheaf theory and multi-parameter persistence.",
    "descriptor": "",
    "authors": [
      "Nicolas Berkouk",
      "Luca Nyckees"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00916"
  },
  {
    "id": "arXiv:2210.00928",
    "title": "PAC-Bayes with Unbounded Losses through Supermartingales",
    "abstract": "While PAC-Bayes is now an established learning framework for bounded losses,\nits extension to the case of unbounded losses (as simple as the squared loss on\nan unbounded space) remains largely uncharted and has attracted a growing\ninterest in recent years. We contribute to this line of work by developing an\nextention of Markov's inequality for supermartingales, which we use to\nestablish a novel PAC-Bayesian generalisation bound holding for unbounded\nlosses. We show that this bound extends, unifies and even improves on existing\nPAC-Bayesian bounds.",
    "descriptor": "",
    "authors": [
      "Maxime Haddouche",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.00928"
  },
  {
    "id": "arXiv:2210.00930",
    "title": "Multi-Wavelength Photonic Neuromorphic Computing for Intra and  Inter-Channel Distortion Compensations in WDM Optical Communication Systems",
    "abstract": "DSP (digital signal processing) has been widely applied in optical\ncommunication systems to mitigate signal distortions and has become one of the\nkey technologies that have sustained data traffic growth over the past decade.\nHowever, the strict energy budget of application-specific integrated\ncircuit-based DSP chips has prevented the deployment of some powerful but\ncomputationally costly DSP algorithms. As a result, fiber nonlinearity-induced\nsignal distortions impede fiber communications systems, especially in\nwavelength-division multiplexed (WDM) transmission systems. To solve these\nchallenges, photonics hardware (i.e., photonic neural networks) promises to\nbreak performance limitations in electronics and gain advantages in bandwidth,\nlatency, and power consumption in solving intellectual tasks that are\nunreachable by conventional digital electronic platforms. This work proposes a\nphotonic recurrent neural network (RNN) capable of simultaneously resolving\ndispersion and both intra and inter-channel fiber nonlinearities in multiple\nWDM channels in the photonic domain, for the first time to our best knowledge.\nFurthermore, our photonic RNN can directly process optical WDM signals in the\nphotonic domain, avoiding prohibitive energy consumption and speed overhead in\nanalog to digital converters (ADC). We demonstrate in simulation that our\nphotonic RNN can process multiple WDM channels simultaneously and achieve a\nreduced bit error rate compared to typical DSP algorithms for all WDM channels\nin a pulse-amplitude modulation 4-level (PAM4) transmission system, thanks to\nits unique capability to address inter-channel fiber nonlinearities. In\naddition to signal quality performance, the proposed system also promises to\nsignificantly reduce the power consumption and the latency compared to the\nstate-of-the-art DSP chips, according to our power and latency analysis.",
    "descriptor": "",
    "authors": [
      "Benshan Wang",
      "Thomas Ferreira de Lima",
      "Bhavin J Shastri",
      "Paul R Prucnal",
      "Chaoran Huang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.00930"
  },
  {
    "id": "arXiv:2210.00943",
    "title": "Simple Pooling Front-ends For Efficient Audio Classification",
    "abstract": "Recently, there has been increasing interest in building efficient audio\nneural networks for on-device scenarios. While most existing approaches are\ndesigned to reduce the size of audio neural networks using methods such as\nmodel pruning. In this work, we show that instead of reducing model size using\ncomplex methods, eliminating the temporal redundancy in the input audio\nfeatures (e.g., Mel-spectrogram) could be an effective approach for efficient\naudio classification. To do so, we proposed a family of simple pooling\nfront-ends (SimPFs) which use simple non-parametric pooling operations to\nreduce the redundant information within the Mel-spectrogram. We perform\nextensive experiments on four audio classification tasks to evaluate the\nperformance of SimPFs. Experimental results show that SimPFs can achieve a\nreduction in more than half of the FLOPs for off-the-shelf audio neural\nnetworks, with negligible degradation or even decent improvement in audio\nclassification performance.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xubo Liu",
      "Haohe Liu",
      "Qiuqiang Kong",
      "Xinhao Mei",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00943"
  },
  {
    "id": "arXiv:2210.00950",
    "title": "Optimal consumption-investment choices under wealth-driven risk aversion",
    "abstract": "CRRA utility where the risk aversion coefficient is a constant is commonly\nseen in various economics models. But wealth-driven risk aversion rarely shows\nup in investor's investment problems. This paper mainly focus on numerical\nsolutions to the optimal consumption-investment choices under wealth-driven\naversion done by neural network. A jump-diffusion model is used to simulate the\nartificial data that is needed for the neural network training. The WDRA Model\nis set up for describing the investment problem and there are two parameters\nthat require to be optimized, which are the investment rate of the wealth on\nthe risky assets and the consumption during the investment time horizon. Under\nthis model, neural network LSTM with one objective function is implemented and\nshows promising results.",
    "descriptor": "",
    "authors": [
      "Ruoxin Xiao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2210.00950"
  },
  {
    "id": "arXiv:2210.00953",
    "title": "Bias and Extrapolation in Markovian Linear Stochastic Approximation with  Constant Stepsizes",
    "abstract": "We consider Linear Stochastic Approximation (LSA) with a constant stepsize\nand Markovian data. Viewing the joint process of the data and LSA iterate as a\ntime-homogeneous Markov chain, we prove its convergence to a unique limiting\nand stationary distribution in Wasserstein distance and establish\nnon-asymptotic, geometric convergence rates. Furthermore, we show that the bias\nvector of this limit admits an infinite series expansion with respect to the\nstepsize. Consequently, the bias is proportional to the stepsize up to higher\norder terms. This result stands in contrast with LSA under i.i.d. data, for\nwhich the bias vanishes. In the reversible chain setting, we provide a general\ncharacterization of the relationship between the bias and the mixing time of\nthe Markovian data, establishing that they are roughly proportional to each\nother.\nWhile Polyak-Ruppert tail-averaging reduces the variance of the LSA iterates,\nit does not affect the bias. The above characterization allows us to show that\nthe bias can be reduced using Richardson-Romberg extrapolation with $m \\ge 2$\nstepsizes, which eliminates the $m - 1$ leading terms in the bias expansion.\nThis extrapolation scheme leads to an exponentially smaller bias and an\nimproved mean squared error, both in theory and empirically. Our results\nimmediately apply to the Temporal Difference learning algorithm with linear\nfunction approximation, Markovian data and constant stepsizes.",
    "descriptor": "",
    "authors": [
      "Dongyan",
      "Yudong Chen",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00953"
  },
  {
    "id": "arXiv:2210.00974",
    "title": "Dealing with Unknown Variances in Best-Arm Identification",
    "abstract": "The problem of identifying the best arm among a collection of items having\nGaussian rewards distribution is well understood when the variances are known.\nDespite its practical relevance for many applications, few works studied it for\nunknown variances. In this paper we introduce and analyze two approaches to\ndeal with unknown variances, either by plugging in the empirical variance or by\nadapting the transportation costs. In order to calibrate our two stopping\nrules, we derive new time-uniform concentration inequalities, which are of\nindependent interest. Then, we illustrate the theoretical and empirical\nperformances of our two sampling rule wrappers on Track-and-Stop and on a Top\nTwo algorithm. Moreover, by quantifying the impact on the sample complexity of\nnot knowing the variances, we reveal that it is rather small.",
    "descriptor": "\nComments: 73 pages, 5 figures, 3 tables\n",
    "authors": [
      "Marc Jourdan",
      "R\u00e9my Degenne",
      "Emilie Kaufmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00974"
  },
  {
    "id": "arXiv:2210.00984",
    "title": "A Comparative Study of Hierarchical Risk Parity Portfolio and Eigen  Portfolio on the NIFTY 50 Stocks",
    "abstract": "Portfolio optimization has been an area of research that has attracted a lot\nof attention from researchers and financial analysts. Designing an optimum\nportfolio is a complex task since it not only involves accurate forecasting of\nfuture stock returns and risks but also needs to optimize them. This paper\npresents a systematic approach to portfolio optimization using two approaches,\nthe hierarchical risk parity algorithm and the Eigen portfolio on seven sectors\nof the Indian stock market. The portfolios are built following the two\napproaches to historical stock prices from Jan 1, 2016, to Dec 31, 2020. The\nportfolio performances are evaluated on the test data from Jan 1, 2021, to Nov\n1, 2021. The backtesting results of the portfolios indicate that the\nperformance of the HRP portfolio is superior to that of its Eigen counterpart\non both training and test data for the majority of the sectors studied.",
    "descriptor": "\nComments: This is the accepted version of our paper at the 2nd International Conference on Computational Intelligence and Data Analytics, January 8 - 9, 2021, Hyderabad. The paper is 15 pages long and it contains 21 figures and 7 tables. arXiv admin note: substantial text overlap with arXiv:2202.02728\n",
    "authors": [
      "Jaydip Sen",
      "Abhishek Dutta"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00984"
  },
  {
    "id": "arXiv:2210.00997",
    "title": "Online Self-Concordant and Relatively Smooth Minimization, With  Applications to Online Portfolio Selection and Learning Quantum States",
    "abstract": "Consider an online convex optimization problem where the loss functions are\nself-concordant barriers, smooth relative to a convex function $h$, and\npossibly non-Lipschitz. We analyze the regret of online mirror descent with\n$h$. Then, based on the result, we prove the following in a unified manner.\nDenote by $T$ the time horizon and $d$ the parameter dimension. 1. For online\nportfolio selection, the regret of $\\widetilde{\\text{EG}}$, a variant of\nexponentiated gradient due to Helmbold et al., is $\\tilde{O} ( T^{2/3} d^{1/3}\n)$ when $T > 4 d / \\log d$. This improves on the original $\\tilde{O} ( T^{3/4}\nd^{1/2} )$ regret bound for $\\widetilde{\\text{EG}}$. 2. For online portfolio\nselection, the regret of online mirror descent with the logarithmic barrier is\n$\\tilde{O}(\\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due\nto Orseau et al. up to logarithmic terms. 3. For online learning quantum states\nwith the logarithmic loss, the regret of online mirror descent with the\nlog-determinant function is also $\\tilde{O} ( \\sqrt{T d} )$. Its per-iteration\ntime is shorter than all existing algorithms we know.",
    "descriptor": "\nComments: 19 pages, 1 figure\n",
    "authors": [
      "Chung-En Tsai",
      "Hao-Chung Cheng",
      "Yen-Huan Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2210.00997"
  },
  {
    "id": "arXiv:2210.01006",
    "title": "Neural network for determining an asteroid mineral composition from  reflectance spectra",
    "abstract": "Chemical and mineral compositions of asteroids reflect the formation and\nhistory of our Solar System. This knowledge is also important for planetary\ndefence and in-space resource utilisation. We aim to develop a fast and robust\nneural-network-based method for deriving the mineral modal and chemical\ncompositions of silicate materials from their visible and near-infrared\nspectra. The method should be able to process raw spectra without significant\npre-processing. We designed a convolutional neural network with two hidden\nlayers for the analysis of the spectra, and trained it using labelled\nreflectance spectra. For the training, we used a dataset that consisted of\nreflectance spectra of real silicate samples stored in the RELAB and C-Tape\ndatabases, namely olivine, orthopyroxene, clinopyroxene, their mixtures, and\nolivine-pyroxene-rich meteorites. We used the model on two datasets. First, we\nevaluated the model reliability on a test dataset where we compared the model\nclassification with known compositional reference values. The individual\nclassification results are mostly within 10 percentage-point intervals around\nthe correct values. Second, we classified the reflectance spectra of S-complex\n(Q-type and V-type, also including A-type) asteroids with known Bus-DeMeo\ntaxonomy classes. The predicted mineral chemical composition of S-type and\nQ-type asteroids agree with the chemical composition of ordinary chondrites.\nThe modal abundances of V-type and A-type asteroids show a dominant\ncontribution of orthopyroxene and olivine, respectively. Additionally, our\npredictions of the mineral modal composition of S-type and Q-type asteroids\nshow an apparent depletion of olivine related to the attenuation of its\ndiagnostic absorptions with space weathering. This trend is consistent with\nprevious results of the slower pyroxene response to space weathering relative\nto olivine.",
    "descriptor": "\nComments: main text: 12 pages, 12 figures, 10 tables; appendix: 8 pages, 20 figures, 6 tables\n",
    "authors": [
      "David Korda",
      "Antti Penttil\u00e4",
      "Arto Klami",
      "Tom\u00e1\u0161 Kohout"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01006"
  },
  {
    "id": "arXiv:2210.01010",
    "title": "A general framework for probabilistic sensitivity analysis with respect  to distribution parameters",
    "abstract": "Probabilistic sensitivity analysis identifies the influential uncertain input\nto guide decision-makings. We propose a general sensitivity framework with\nrespect to input distribution parameters that unifies a wide range of\nsensitivity measures, including information theoretical metrics such as the\nFisher information. The framework is derived analytically via a constrained\nmaximization and the sensitivity analysis is reformulated into an eigenvalue\nproblem. There are only two main steps to implement the sensitivity framework\nutilising the likelihood ratio/score function method, a Monte Carlo type\nsampling followed by solving an eigenvalue equation. The resulted eigenvectors\nthen provide the directions for simultaneous variations of the input parameters\nand guide the focus to perturb uncertainty the most. Not only is it\nconceptually simple, numerical examples demonstrate that the proposed framework\nalso provides new sensitivity insights, such as the combined sensitivity of\nmultiple correlated uncertainty metrics, robust sensitivity analysis with a\nentropic constraint and approximation of deterministic sensitivities.",
    "descriptor": "\nComments: The datasets generated during and/or analysed during the current study are available in the GitHub repository: this https URL\n",
    "authors": [
      "Jiannan Yang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.01010"
  },
  {
    "id": "arXiv:2210.01019",
    "title": "Plateau in Monotonic Linear Interpolation -- A \"Biased\" View of Loss  Landscape for Deep Networks",
    "abstract": "Monotonic linear interpolation (MLI) - on the line connecting a random\ninitialization with the minimizer it converges to, the loss and accuracy are\nmonotonic - is a phenomenon that is commonly observed in the training of neural\nnetworks. Such a phenomenon may seem to suggest that optimization of neural\nnetworks is easy. In this paper, we show that the MLI property is not\nnecessarily related to the hardness of optimization problems, and empirical\nobservations on MLI for deep neural networks depend heavily on biases. In\nparticular, we show that interpolating both weights and biases linearly leads\nto very different influences on the final output, and when different classes\nhave different last-layer biases on a deep network, there will be a long\nplateau in both the loss and accuracy interpolation (which existing theory of\nMLI cannot explain). We also show how the last-layer biases for different\nclasses can be different even on a perfectly balanced dataset using a simple\nmodel. Empirically we demonstrate that similar intuitions hold on practical\nnetworks and realistic datasets.",
    "descriptor": "",
    "authors": [
      "Xiang Wang",
      "Annie N. Wang",
      "Mo Zhou",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01019"
  },
  {
    "id": "arXiv:2210.01029",
    "title": "WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on  Fixed-Point Iteration",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) and generative adversarial\nnetworks (GANs) are popular generative models for neural vocoders. The DDPMs\nand GANs can be characterized by the iterative denoising framework and\nadversarial training, respectively. This study proposes a fast and high-quality\nneural vocoder called \\textit{WaveFit}, which integrates the essence of GANs\ninto a DDPM-like iterative framework based on fixed-point iteration. WaveFit\niteratively denoises an input signal, and trains a deep neural network (DNN)\nfor minimizing an adversarial loss calculated from intermediate outputs at all\niterations. Subjective (side-by-side) listening tests showed no statistically\nsignificant differences in naturalness between human natural speech and those\nsynthesized by WaveFit with five iterations. Furthermore, the inference speed\nof WaveFit was more than 240 times faster than WaveRNN. Audio demos are\navailable at \\url{google.github.io/df-conformer/wavefit/}.",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Yuma Koizumi",
      "Kohei Yatabe",
      "Heiga Zen",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01029"
  },
  {
    "id": "arXiv:2210.01062",
    "title": "Minimal entropy production in anisotropic temperature fields",
    "abstract": "Anisotropy of temperature fields, chemical potentials and ion concentration\ngradients provide the fuel that feeds dynamical processes that sustain life.\nDynamical flows in respective environments incur losses manifested as entropy\nproduction. In this work we consider a rudimentary model of an overdamped\nstochastic thermodynamic system in an anisotropic temperature heat bath, and\nanalyze the problem to minimize entropy production while driving the system\nbetween thermodynamic states in finite time. It is noted that entropy\nproduction in a fully isotropic temperature field, can be expressed as the\nWasserstein-2 length of the path traversed by the thermodynamic state of the\nsystem. In the presence of an anisotropic temperature field, the mechanism of\nentropy production is substantially more complicated as, besides dissipation,\nit entails seepage of energy between the ambient heat sources by way of the\nsystem dynamics. We show that, in this case, the entropy production can be\nexpressed as the solution of a suitably constrained and generalized Optimal\nMass Transport (OMT) problem. In contrast to the situation in standard OMT,\nentropy production may not be identically zero, even when the thermodynamic\nstate remains unchanged. Physically, this is due to the fact that maintaining a\nNon-Equilibrium Steady State (NESS), incurs an intrinsic entropic cost. As\nalready noted, NESSs are the hallmark of life and living systems by necessity\noperate away from equilibrium. Thus our problem of minimizing entropy\nproduction appears of central importance in understanding biological processes,\nsuch as molecular motors and motor proteins, and on how such processes may have\nevolved to optimize for available usage of resources.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Olga Movilla Miangolarra",
      "Amirhossein Taghvaei",
      "Tryphon T. Georgiou"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.01062"
  },
  {
    "id": "arXiv:2210.01071",
    "title": "New Paradigms for Exploiting Parallel Experiments in Bayesian  Optimization",
    "abstract": "Bayesian optimization (BO) is one of the most effective methods for\nclosed-loop experimental design and black-box optimization. However, a key\nlimitation of BO is that it is an inherently sequential algorithm (one\nexperiment is proposed per round) and thus cannot directly exploit\nhigh-throughput (parallel) experiments. Diverse modifications to the BO\nframework have been proposed in the literature to enable exploitation of\nparallel experiments but such approaches are limited in the degree of\nparallelization that they can achieve and can lead to redundant experiments\n(thus wasting resources and potentially compromising performance). In this\nwork, we present new parallel BO paradigms that exploit the structure of the\nsystem to partition the design space. Specifically, we propose an approach that\npartitions the design space by following the level sets of the performance\nfunction and an approach that exploits partially-separable structures of the\nperformance function found. We conduct extensive numerical experiments using a\nreactor case study to benchmark the effectiveness of these approaches against a\nvariety of state-of-the-art parallel algorithms reported in the literature. Our\ncomputational results show that our approaches significantly reduce the\nrequired search time and increase the probability of finding a global (rather\nthan local) solution.",
    "descriptor": "\nComments: 32 pages, 16 figures, 7 algorithms\n",
    "authors": [
      "Leonardo D. Gonz\u00e1lez",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.01071"
  },
  {
    "id": "arXiv:2210.01099",
    "title": "Model error and its estimation, with particular application to loss  reserving",
    "abstract": "This paper is concerned with forecast error, particularly in relation to loss\nreserving. This is generally regarded as consisting of three components, namely\nparameter, process and model errors. The first two of these components, and\ntheir estimation, are well understood, but less so model error. Model error\nitself is considered in two parts: one part that is capable of estimation from\npast data (internal model error), and another part that is not (external model\nerror). Attention is focused here on internal model error. Estimation of this\nerror component is approached by means of Bayesian model averaging, using the\nBayesian interpretation of the LASSO. This is used to generate a set of\nadmissible models, each with its prior probability and the likelihood of\nobserved data. A posterior on the model set, conditional on the data, results,\nand an estimate of model error (contained in a loss reserve) is obtained as the\nvariance of the loss reserve according to this posterior. The population of\nmodels entering materially into the support of the posterior may turn out to be\nthinner than desired, and bootstrapping of the LASSO is used to gain bulk. This\nprovides the bonus of an estimate of parameter error also. It turns out that\nthe estimates of parameter and model errors are entangled, and dissociation of\nthem is at least difficult, and possibly not even meaningful. These matters are\ndiscussed. The majority of the discussion applies to forecasting generally, but\nnumerical illustration of the concepts is given in relation to insurance data\nand the problem of insurance loss reserving.",
    "descriptor": "",
    "authors": [
      "G Taylor",
      "G McGuire"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01099"
  },
  {
    "id": "arXiv:2210.01100",
    "title": "SPRAT: A Spatially-Explicit Marine Ecosystem Model Based on Population  Balance Equations",
    "abstract": "To successfully manage marine fisheries using an ecosystem-based approach,\nlong-term predictions of fish stock development considering changing\nenvironmental conditions are necessary. Such predictions can be provided by\nend-to-end ecosystem models, which couple existing physical and biogeochemical\nocean models with newly developed spatially-explicit fish stock models.\nTypically, Individual-Based Models (IBMs) and models based on\nAdvection-Diffusion-Reaction (ADR) equations are employed for the fish stock\nmodels. In this paper, we present a novel fish stock model called SPRAT for\nend-to\\hyp{}end ecosystem modeling based on Population Balance Equations (PBEs)\nthat combines the advantages of IBMs and ADR models while avoiding their main\ndrawbacks. SPRAT accomplishes this by describing the modeled ecosystem\nprocesses from the perspective of individuals while still being based on\npartial differential equations. We apply the SPRAT model to explore a\nwell-documented regime shift observed on the eastern Scotian Shelf in the 1990s\nfrom a cod-dominated to a herring-dominated ecosystem. Model simulations are\nable to reconcile the observed multitrophic dynamics with documented changes in\nboth fishing pressure and water temperature, followed by a predator-prey\nreversal that may have impeded recovery of depleted cod stocks. We conclude\nthat our model can be used to generate new hypotheses and test ideas about\nspatially interacting fish populations, and their joint responses to both\nenvironmental and fisheries forcing.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Arne N. Johanson",
      "Andreas Oschlies",
      "Wilhelm Hasselbring",
      "Wilhelm Hasselbring",
      "Boris Worm"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.01100"
  },
  {
    "id": "arXiv:1707.02530",
    "title": "Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web  Data",
    "abstract": "Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web  Data",
    "descriptor": "",
    "authors": [
      "Anurag Kumar",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1707.02530"
  },
  {
    "id": "arXiv:1901.09193",
    "title": "Scene Text Synthesis for Efficient and Effective Deep Network Training",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Hongyuan Zhu",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.09193"
  },
  {
    "id": "arXiv:1905.11475",
    "title": "GAT: Generative Adversarial Training for Adversarial Example Detection  and Robust Classification",
    "abstract": "Comments: ICLR 2020, code is available at this https URL; v4 fixed error in Figure 2",
    "descriptor": "\nComments: ICLR 2020, code is available at this https URL; v4 fixed error in Figure 2\n",
    "authors": [
      "Xuwang Yin",
      "Soheil Kolouri",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11475"
  },
  {
    "id": "arXiv:1906.10643",
    "title": "A Review on Deep Learning in Medical Image Reconstruction",
    "abstract": "Comments: 31 pages, 6 figures. Survey paper. Revise the typos",
    "descriptor": "\nComments: 31 pages, 6 figures. Survey paper. Revise the typos\n",
    "authors": [
      "Haimiao Zhang",
      "Bin Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/1906.10643"
  },
  {
    "id": "arXiv:1910.07770",
    "title": "On the Risk of Cancelable Biometrics",
    "abstract": "On the Risk of Cancelable Biometrics",
    "descriptor": "",
    "authors": [
      "Xingbo Dong",
      "Jaewoo Park",
      "Zhe Jin",
      "Andrew Beng Jin Teoh",
      "Massimo Tistarelli",
      "KokSheik Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1910.07770"
  },
  {
    "id": "arXiv:1910.12263",
    "title": "Prior Specification for Bayesian Matrix Factorization via Prior  Predictive Matching",
    "abstract": "Prior Specification for Bayesian Matrix Factorization via Prior  Predictive Matching",
    "descriptor": "",
    "authors": [
      "Eliezer de Souza da Silva",
      "Tomasz Ku\u015bmierczyk",
      "Marcelo Hartmann",
      "Arto Klami"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.12263"
  },
  {
    "id": "arXiv:1911.10454",
    "title": "Regularized and Smooth Double Core Tensor Factorization for  Heterogeneous Data",
    "abstract": "Comments: 49 pages, 4 figures",
    "descriptor": "\nComments: 49 pages, 4 figures\n",
    "authors": [
      "Davoud Ataee Tarzanagh",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.10454"
  },
  {
    "id": "arXiv:1911.11312",
    "title": "Spatial-Aware GAN for Unsupervised Person Re-identification",
    "abstract": "Comments: Accepted to ICPR2020",
    "descriptor": "\nComments: Accepted to ICPR2020\n",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.11312"
  },
  {
    "id": "arXiv:2004.00771",
    "title": "Butson-Hadamard matrices and Plotkin-optimal p^k-ary codes",
    "abstract": "Butson-Hadamard matrices and Plotkin-optimal p^k-ary codes",
    "descriptor": "",
    "authors": [
      "Damla Acar",
      "B\u00fclent Sara\u00e7",
      "O\u011fuz Yayla"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.00771"
  },
  {
    "id": "arXiv:2004.13938",
    "title": "Families of sequences with good family complexity and cross-correlation  measure",
    "abstract": "Comments: 13 pages. Comments are welcome!",
    "descriptor": "\nComments: 13 pages. Comments are welcome!\n",
    "authors": [
      "O\u011fuz Yayla"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2004.13938"
  },
  {
    "id": "arXiv:2006.06137",
    "title": "Analysis of Trade-offs in Fair Principal Component Analysis Based on  Multi-objective Optimization",
    "abstract": "Analysis of Trade-offs in Fair Principal Component Analysis Based on  Multi-objective Optimization",
    "descriptor": "",
    "authors": [
      "Guilherme D. Pelegrina",
      "Renan D. B. Brotto",
      "Leonardo T. Duarte",
      "Romis Attux",
      "Jo\u00e3o M. T. Romano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06137"
  },
  {
    "id": "arXiv:2006.16365",
    "title": "Multi-Partition Embedding Interaction with Block Term Format for  Knowledge Graph Completion",
    "abstract": "Comments: Accepted at the European Conference on Artificial Intelligence (ECAI), 2020; add source code; update appendix",
    "descriptor": "\nComments: Accepted at the European Conference on Artificial Intelligence (ECAI), 2020; add source code; update appendix\n",
    "authors": [
      "Hung Nghiep Tran",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16365"
  },
  {
    "id": "arXiv:2007.07066",
    "title": "Towards Realistic 3D Embedding via View Alignment",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Shijian Lu",
      "Feiying Ma",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.07066"
  },
  {
    "id": "arXiv:2007.08444",
    "title": "Dynamics of Mobile Manipulators using Dual Quaternion Algebra",
    "abstract": "Comments: 16 pages, 3 figures, 2 tables. Accepted on JMR 2022. This version corrects a few typos",
    "descriptor": "\nComments: 16 pages, 3 figures, 2 tables. Accepted on JMR 2022. This version corrects a few typos\n",
    "authors": [
      "Frederico F. A. Silva",
      "Juan J. Quiroz-Oma\u00f1a",
      "Bruno V. Adorno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2007.08444"
  },
  {
    "id": "arXiv:2008.03225",
    "title": "BayesCG As An Uncertainty Aware Version of CG",
    "abstract": "Comments: 34 Pages including supplementary material (main paper is 23 pages, supplement is 11 pages). Computer codes are available at this https URL",
    "descriptor": "\nComments: 34 Pages including supplementary material (main paper is 23 pages, supplement is 11 pages). Computer codes are available at this https URL\n",
    "authors": [
      "Tim W. Reid",
      "Ilse C. F. Ipsen",
      "Jon Cockayne",
      "Chris J. Oates"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.03225"
  },
  {
    "id": "arXiv:2008.07007",
    "title": "Interpretable Representations in Explainable AI: From Theory to Practice",
    "abstract": "Interpretable Representations in Explainable AI: From Theory to Practice",
    "descriptor": "",
    "authors": [
      "Kacper Sokol",
      "Peter Flach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.07007"
  },
  {
    "id": "arXiv:2009.08265",
    "title": "Dimension Reduction in Contextual Online Learning via Nonparametric  Variable Selection",
    "abstract": "Dimension Reduction in Contextual Online Learning via Nonparametric  Variable Selection",
    "descriptor": "",
    "authors": [
      "Wenhao Li",
      "Ningyuan Chen",
      "L. Jeff Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08265"
  },
  {
    "id": "arXiv:2010.00577",
    "title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge  Masking",
    "abstract": "Interpreting Graph Neural Networks for NLP With Differentiable Edge  Masking",
    "descriptor": "",
    "authors": [
      "Michael Sejr Schlichtkrull",
      "Nicola De Cao",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00577"
  },
  {
    "id": "arXiv:2011.05157",
    "title": "Bridging the Performance Gap between FGSM and PGD Adversarial Training",
    "abstract": "Bridging the Performance Gap between FGSM and PGD Adversarial Training",
    "descriptor": "",
    "authors": [
      "Tianjin Huang",
      "Vlado Menkovski",
      "Yulong Pei",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05157"
  },
  {
    "id": "arXiv:2012.03178",
    "title": "Probabilistic Federated Learning of Neural Networks Incorporated with  Global Posterior Information",
    "abstract": "Comments: The proposed algorithm lacks sufficient proof",
    "descriptor": "\nComments: The proposed algorithm lacks sufficient proof\n",
    "authors": [
      "Peng Xiao",
      "Samuel Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.03178"
  },
  {
    "id": "arXiv:2102.04657",
    "title": "Structure vs. Randomness for Bilinear Maps",
    "abstract": "Comments: Published version for Discrete Analysis",
    "descriptor": "\nComments: Published version for Discrete Analysis\n",
    "authors": [
      "Alex Cohen",
      "Guy Moshkovitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2102.04657"
  },
  {
    "id": "arXiv:2102.07758",
    "title": "Decentralized Distributed Optimization for Saddle Point Problems",
    "abstract": "Decentralized Distributed Optimization for Saddle Point Problems",
    "descriptor": "",
    "authors": [
      "Alexander Rogozin",
      "Aleksandr Beznosikov",
      "Darina Dvinskikh",
      "Dmitry Kovalev",
      "Pavel Dvurechensky",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.07758"
  },
  {
    "id": "arXiv:2102.09673",
    "title": "Effective Cache Apportioning for Performance Isolation Under Compiler  Guidance",
    "abstract": "Effective Cache Apportioning for Performance Isolation Under Compiler  Guidance",
    "descriptor": "",
    "authors": [
      "Bodhisatwa Chatterjee",
      "Sharjeel Khan",
      "Santosh Pande"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09673"
  },
  {
    "id": "arXiv:2103.02410",
    "title": "OAG-BERT: Towards A Unified Backbone Language Model For Academic  Knowledge Services",
    "abstract": "Comments: Accepted to KDD 2022",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Xiao Liu",
      "Da Yin",
      "Jingnan Zheng",
      "Xingjian Zhang",
      "Peng Zhang",
      "Hongxia Yang",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.02410"
  },
  {
    "id": "arXiv:2103.08280",
    "title": "Lower Complexity Bounds of Finite-Sum Optimization Problems: The Results  and Construction",
    "abstract": "Comments: We reorganize the structure of the paper and extend the definition of PIFO algorithms",
    "descriptor": "\nComments: We reorganize the structure of the paper and extend the definition of PIFO algorithms\n",
    "authors": [
      "Yuze Han",
      "Guangzeng Xie",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.08280"
  },
  {
    "id": "arXiv:2103.09728",
    "title": "Learning migration models for supporting incremental language migrations  of software applications",
    "abstract": "Learning migration models for supporting incremental language migrations  of software applications",
    "descriptor": "",
    "authors": [
      "Bruno G\u00f3is Mateus",
      "Matias Martinez",
      "Christophe Kolski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.09728"
  },
  {
    "id": "arXiv:2103.09865",
    "title": "A Novel Approach to Disturbance Rejection in Constrained Model  Predictive Control",
    "abstract": "Comments: To be updated",
    "descriptor": "\nComments: To be updated\n",
    "authors": [
      "Isah Abdulrasheed Jimoh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.09865"
  },
  {
    "id": "arXiv:2104.01677",
    "title": "A contrastive rule for meta-learning",
    "abstract": "Comments: 32 pages, 10 figures, published at NeurIPS 2022",
    "descriptor": "\nComments: 32 pages, 10 figures, published at NeurIPS 2022\n",
    "authors": [
      "Nicolas Zucchet",
      "Simon Schug",
      "Johannes von Oswald",
      "Dominic Zhao",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2104.01677"
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "abstract": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Hong Liu",
      "Pinhao Song",
      "Linhui Dai",
      "Xiaochuan Zhang",
      "Runwei Ding",
      "Shengquan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02230"
  },
  {
    "id": "arXiv:2104.03154",
    "title": "Improving Robustness of Deep Reinforcement Learning Agents: Environment  Attack based on the Critic Network",
    "abstract": "Comments: 8 pages, 8 figures",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Lucas Schott",
      "Hatem Hajri",
      "Sylvain Lamprier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03154"
  },
  {
    "id": "arXiv:2104.05477",
    "title": "Stochastic Stability of Discrete-time Phase-coupled Oscillators over  Uncertain and Random Networks",
    "abstract": "Stochastic Stability of Discrete-time Phase-coupled Oscillators over  Uncertain and Random Networks",
    "descriptor": "",
    "authors": [
      "Matin Jafarian",
      "Mohammad H. Mamduhi",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.05477"
  },
  {
    "id": "arXiv:2104.07631",
    "title": "Fair and Reliable Reconnections for Temporary Disruptions in Electric  Distribution Networks using Submodularity",
    "abstract": "Comments: 36 pages, 9 figures",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Cyrus Hettle",
      "Swati Gupta",
      "Daniel Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.07631"
  },
  {
    "id": "arXiv:2104.07699",
    "title": "pLUTo: Enabling Massively Parallel Computation in DRAM via Lookup Tables",
    "abstract": "pLUTo: Enabling Massively Parallel Computation in DRAM via Lookup Tables",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Dinis Ferreira",
      "Gabriel Falcao",
      "Juan G\u00f3mez-Luna",
      "Mohammed Alser",
      "Lois Orosa",
      "Mohammad Sadrosadati",
      "Jeremie S. Kim",
      "Geraldo F. Oliveira",
      "Taha Shahroodi",
      "Anant Nori",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.07699"
  },
  {
    "id": "arXiv:2104.13971",
    "title": "SMLSOM: The shrinking maximum likelihood self-organizing map",
    "abstract": "SMLSOM: The shrinking maximum likelihood self-organizing map",
    "descriptor": "",
    "authors": [
      "Ryosuke Motegi",
      "Yoichi Seki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.13971"
  },
  {
    "id": "arXiv:2104.14654",
    "title": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "abstract": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Libo Zhang",
      "Jiamou Liu",
      "Michael Witbrock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14654"
  },
  {
    "id": "arXiv:2105.06194",
    "title": "Geometric Model Checking of Continuous Space",
    "abstract": "Geometric Model Checking of Continuous Space",
    "descriptor": "",
    "authors": [
      "Nick Bezhanishvili",
      "Vincenzo Ciancia",
      "David Gabelaia",
      "Gianluca Grilletti",
      "Diego Latella",
      "Mieke Massink"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.06194"
  },
  {
    "id": "arXiv:2105.07582",
    "title": "RAIDER: Reinforcement-aided Spear Phishing Detector",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Keelan Evans",
      "Alsharif Abuadbba",
      "Tingmin Wu",
      "Kristen Moore",
      "Mohiuddin Ahmed",
      "Ganna Pogrebna",
      "Surya Nepal",
      "Mike Johnstone"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07582"
  },
  {
    "id": "arXiv:2105.14173",
    "title": "FoveaTer: Foveated Transformer for Image Classification",
    "abstract": "FoveaTer: Foveated Transformer for Image Classification",
    "descriptor": "",
    "authors": [
      "Aditya Jonnalagadda",
      "William Yang Wang",
      "B. S. Manjunath",
      "Miguel P. Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14173"
  },
  {
    "id": "arXiv:2106.08647",
    "title": "Exponential Approximation of Band-limited Signals from Nonuniform  Sampling",
    "abstract": "Comments: incomplete",
    "descriptor": "\nComments: incomplete\n",
    "authors": [
      "Yunfei Yang",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08647"
  },
  {
    "id": "arXiv:2106.10566",
    "title": "Scalable Safety-Critical Policy Evaluation with Accelerated Rare Event  Sampling",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Mengdi Xu",
      "Peide Huang",
      "Fengpei Li",
      "Jiacheng Zhu",
      "Xuewei Qi",
      "Kentaro Oguchi",
      "Zhiyuan Huang",
      "Henry Lam",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10566"
  },
  {
    "id": "arXiv:2106.12199",
    "title": "Bayesian Joint Chance Constrained Optimization: Approximations and  Statistical Consistency",
    "abstract": "Bayesian Joint Chance Constrained Optimization: Approximations and  Statistical Consistency",
    "descriptor": "",
    "authors": [
      "Prateek Jaiswal",
      "Harsha Honnappa",
      "Vinayak A. Rao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.12199"
  },
  {
    "id": "arXiv:2106.12271",
    "title": "Unsupervised Speech Enhancement using Dynamical Variational  Auto-Encoders",
    "abstract": "Unsupervised Speech Enhancement using Dynamical Variational  Auto-Encoders",
    "descriptor": "",
    "authors": [
      "Xiaoyu Bie",
      "Simon Leglaive",
      "Xavier Alameda-Pineda",
      "Laurent Girin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.12271"
  },
  {
    "id": "arXiv:2106.15098",
    "title": "Molecule Generation by Principal Subgraph Mining and Assembling",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Xiangzhe Kong",
      "Wenbing Huang",
      "Zhixing Tan",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.15098"
  },
  {
    "id": "arXiv:2107.02238",
    "title": "High-Speed CMOS-Free Purely Spintronic Asynchronous Recurrent Neural  Network",
    "abstract": "High-Speed CMOS-Free Purely Spintronic Asynchronous Recurrent Neural  Network",
    "descriptor": "",
    "authors": [
      "Pranav O. Mathews",
      "Christian B. Duffee",
      "Abel Thayil",
      "Ty E. Stovall",
      "Christopher H. Bennett",
      "Felipe Garcia-Sanchez",
      "Matthew J. Marinella",
      "Jean Anne C. Incorvia",
      "Naimul Hassan",
      "Xuan Hu",
      "Joseph S. Friedman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.02238"
  },
  {
    "id": "arXiv:2107.02453",
    "title": "Neural Mixture Models with Expectation-Maximization for End-to-end Deep  Clustering",
    "abstract": "Comments: Accepted and published at Neurocomputing 2022",
    "descriptor": "\nComments: Accepted and published at Neurocomputing 2022\n",
    "authors": [
      "Dumindu Tissera",
      "Kasun Vithanage",
      "Rukshan Wijesinghe",
      "Alex Xavier",
      "Sanath Jayasena",
      "Subha Fernando",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02453"
  },
  {
    "id": "arXiv:2107.04401",
    "title": "Improving Model Robustness with Latent Distribution Locally and Globally",
    "abstract": "Improving Model Robustness with Latent Distribution Locally and Globally",
    "descriptor": "",
    "authors": [
      "Zhuang Qian",
      "Shufei Zhang",
      "Kaizhu Huang",
      "Qiufeng Wang",
      "Rui Zhang",
      "Xinping Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04401"
  },
  {
    "id": "arXiv:2107.04565",
    "title": "Universal Multilayer Network Exploration by Random Walk with Restart",
    "abstract": "Universal Multilayer Network Exploration by Random Walk with Restart",
    "descriptor": "",
    "authors": [
      "Anthony Baptista",
      "Aitor Gonzalez",
      "Ana\u00efs Baudot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2107.04565"
  },
  {
    "id": "arXiv:2107.09249",
    "title": "Self-Supervised Aggregation of Diverse Experts for Test-Agnostic  Long-Tailed Recognition",
    "abstract": "Comments: NeurIPS 2022. Source code: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Source code: this https URL\n",
    "authors": [
      "Yifan Zhang",
      "Bryan Hooi",
      "Lanqing Hong",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09249"
  },
  {
    "id": "arXiv:2107.12100",
    "title": "Predicting Influential Higher-Order Patterns in Temporal Network Data",
    "abstract": "Comments: 18 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 18 pages, 4 figures, 2 tables\n",
    "authors": [
      "Christoph Gote",
      "Vincenzo Perri",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.12100"
  },
  {
    "id": "arXiv:2107.12183",
    "title": "A Simple Approach to Automated Spectral Clustering",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Jicong Fan",
      "Yiheng Tu",
      "Zhao Zhang",
      "Mingbo Zhao",
      "Haijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.12183"
  },
  {
    "id": "arXiv:2107.13109",
    "title": "Pixyz: a library for developing deep generative models",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Masahiro Suzuki",
      "Takaaki Kaneko",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.13109"
  },
  {
    "id": "arXiv:2108.01941",
    "title": "Automatic cerebral hemisphere segmentation in rat MRI with lesions via  attention-based convolutional neural networks",
    "abstract": "Comments: Published in NeuroInformatics",
    "descriptor": "\nComments: Published in NeuroInformatics\n",
    "authors": [
      "Juan Miguel Valverde",
      "Artem Shatillo",
      "Riccardo de Feo",
      "Jussi Tohka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01941"
  },
  {
    "id": "arXiv:2108.08979",
    "title": "Computing committors in collective variables via Mahalanobis diffusion  maps",
    "abstract": "Comments: Restructured introduction, additional Theorem 3.1 and Appendix A, B",
    "descriptor": "\nComments: Restructured introduction, additional Theorem 3.1 and Appendix A, B\n",
    "authors": [
      "Luke Evans",
      "Maria K. Cameron",
      "Pratyush Tiwary"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2108.08979"
  },
  {
    "id": "arXiv:2108.11299",
    "title": "Availability Attacks Against Neural Network Certifiers Based on  Backdoors",
    "abstract": "Availability Attacks Against Neural Network Certifiers Based on  Backdoors",
    "descriptor": "",
    "authors": [
      "Tobias Lorenz",
      "Marta Kwiatkowska",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11299"
  },
  {
    "id": "arXiv:2109.02436",
    "title": "ReLaX: Retinal Layer Attribution for Guided Explanations of Automated  Optical Coherence Tomography Classification",
    "abstract": "Comments: ECCV 2022 Medical Computer Vision Workshop",
    "descriptor": "\nComments: ECCV 2022 Medical Computer Vision Workshop\n",
    "authors": [
      "Evan Wen",
      "Rebecca Sorenson",
      "Max Ehrlich"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02436"
  },
  {
    "id": "arXiv:2109.04320",
    "title": "Discovery of New Multi-Level Features for Domain Generalization via  Knowledge Corruption",
    "abstract": "Comments: Accepted at AAAI 2022 (AIBSD Workshop) and ICPR 2022",
    "descriptor": "\nComments: Accepted at AAAI 2022 (AIBSD Workshop) and ICPR 2022\n",
    "authors": [
      "Ahmed Frikha",
      "Denis Krompa\u00df",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04320"
  },
  {
    "id": "arXiv:2109.06922",
    "title": "Application of integral invariants to apictorial jigsaw puzzle assembly",
    "abstract": "Comments: 17 pages. J Math Imaging Vis (2022)",
    "descriptor": "\nComments: 17 pages. J Math Imaging Vis (2022)\n",
    "authors": [
      "Peter Illig",
      "Robert Thompson",
      "Qimeng Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.06922"
  },
  {
    "id": "arXiv:2109.07706",
    "title": "Basil: A Fast and Byzantine-Resilient Approach for Decentralized  Training",
    "abstract": "Comments: Under submission",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Ahmed Roushdy Elkordy",
      "Saurav Prakash",
      "A. Salman Avestimehr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07706"
  },
  {
    "id": "arXiv:2109.13055",
    "title": "Minimax Mixing Time of the Metropolis-Adjusted Langevin Algorithm for  Log-Concave Sampling",
    "abstract": "Comments: 63 pages, 2 figures",
    "descriptor": "\nComments: 63 pages, 2 figures\n",
    "authors": [
      "Keru Wu",
      "Scott Schmidler",
      "Yuansi Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.13055"
  },
  {
    "id": "arXiv:2110.01360",
    "title": "Posterior predictive model assessment using formal methods in a  spatio-temporal mode",
    "abstract": "Posterior predictive model assessment using formal methods in a  spatio-temporal mode",
    "descriptor": "",
    "authors": [
      "Laura Vana",
      "Ennio Visconti",
      "Laura Nenzi",
      "Annalisa Cadonna",
      "Gregor Kastner"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.01360"
  },
  {
    "id": "arXiv:2110.02651",
    "title": "Weak Novel Categories without Tears: A Survey on Weak-Shot Learning",
    "abstract": "Weak Novel Categories without Tears: A Survey on Weak-Shot Learning",
    "descriptor": "",
    "authors": [
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02651"
  },
  {
    "id": "arXiv:2110.02732",
    "title": "On Margin Maximization in Linear and ReLU Networks",
    "abstract": "Comments: This version includes some minor updates",
    "descriptor": "\nComments: This version includes some minor updates\n",
    "authors": [
      "Gal Vardi",
      "Ohad Shamir",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02732"
  },
  {
    "id": "arXiv:2110.02792",
    "title": "Hierarchical Potential-based Reward Shaping from Task Specifications",
    "abstract": "Comments: 7 pages main, 5 pages appendix - added f1tenth racing car environment",
    "descriptor": "\nComments: 7 pages main, 5 pages appendix - added f1tenth racing car environment\n",
    "authors": [
      "Luigi Berducci",
      "Edgar A. Aguilar",
      "Dejan Ni\u010dkovi\u0107",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02792"
  },
  {
    "id": "arXiv:2110.03251",
    "title": "A Cough-based deep learning framework for detecting COVID-19",
    "abstract": "Comments: COVID-19, EMBC-2022, DiCOVA, top 2nd, benchmark on Spec &gt; 0.95%",
    "descriptor": "\nComments: COVID-19, EMBC-2022, DiCOVA, top 2nd, benchmark on Spec &gt; 0.95%\n",
    "authors": [
      "Truong Hoang",
      "Lam Pham",
      "Dat Ngo",
      "Hoang D. Nguyen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03251"
  },
  {
    "id": "arXiv:2110.04545",
    "title": "Towards Data-Free Domain Generalization",
    "abstract": "Comments: Accepted at NeurIPS 2021 (DistShift Workshop) and ACML 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 (DistShift Workshop) and ACML 2022\n",
    "authors": [
      "Ahmed Frikha",
      "Haokun Chen",
      "Denis Krompa\u00df",
      "Thomas Runkler",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04545"
  },
  {
    "id": "arXiv:2110.04926",
    "title": "Convergence of Random Reshuffling Under The Kurdyka-\u0141ojasiewicz  Inequality",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Xiao Li",
      "Andre Milzarek",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04926"
  },
  {
    "id": "arXiv:2110.07478",
    "title": "Inferring Manifolds From Noisy Data Using Gaussian Processes",
    "abstract": "Comments: 44 pages, 17 figures",
    "descriptor": "\nComments: 44 pages, 17 figures\n",
    "authors": [
      "David B Dunson",
      "Nan Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07478"
  },
  {
    "id": "arXiv:2110.08065",
    "title": "Description of random level sets by polynomial chaos expansions",
    "abstract": "Description of random level sets by polynomial chaos expansions",
    "descriptor": "",
    "authors": [
      "Markus Bambach",
      "Stephan Gerster",
      "Michael Herty",
      "Aleksey Sikstel"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08065"
  },
  {
    "id": "arXiv:2110.08984",
    "title": "Optimistic Policy Optimization is Provably Efficient in Non-stationary  MDPs",
    "abstract": "Optimistic Policy Optimization is Provably Efficient in Non-stationary  MDPs",
    "descriptor": "",
    "authors": [
      "Han Zhong",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08984"
  },
  {
    "id": "arXiv:2110.11088",
    "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "abstract": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "descriptor": "",
    "authors": [
      "Natan Levy",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11088"
  },
  {
    "id": "arXiv:2110.11774",
    "title": "Learning Stable Vector Fields on Lie Groups",
    "abstract": "Comments: ICRA RA-L preprint",
    "descriptor": "\nComments: ICRA RA-L preprint\n",
    "authors": [
      "Julen Urain",
      "Davide Tateo",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11774"
  },
  {
    "id": "arXiv:2110.13188",
    "title": "Simultaneous Perturbation Method for Multi-Task Weight Optimization in  One-Shot Meta-Learning",
    "abstract": "Comments: Accepted at ICONIP 2022",
    "descriptor": "\nComments: Accepted at ICONIP 2022\n",
    "authors": [
      "Andrei Boiarov",
      "Kostiantyn Khabarlak",
      "Igor Yastrebov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13188"
  },
  {
    "id": "arXiv:2111.00684",
    "title": "Graph Structural Attack by Perturbing Spectral Distance",
    "abstract": "Comments: Proceedings of the 28th ACM SIGKDD international conference on knowledge discovery & data mining (KDD'22)",
    "descriptor": "\nComments: Proceedings of the 28th ACM SIGKDD international conference on knowledge discovery & data mining (KDD'22)\n",
    "authors": [
      "Lu Lin",
      "Ethan Blaser",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00684"
  },
  {
    "id": "arXiv:2111.00830",
    "title": "Deep Learning Transformer Architecture for Named Entity Recognition on  Low Resourced Languages: State of the art results",
    "abstract": "Comments: 8 pages, 6 tables, and 3 figures",
    "descriptor": "\nComments: 8 pages, 6 tables, and 3 figures\n",
    "authors": [
      "Ridewaan Hanslo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00830"
  },
  {
    "id": "arXiv:2111.03030",
    "title": "Exact Representation of Sparse Networks with Symmetric Nonnegative  Embeddings",
    "abstract": "Exact Representation of Sparse Networks with Symmetric Nonnegative  Embeddings",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Ryan A. Rossi",
      "Anup Rao",
      "Tung Mai",
      "Nedim Lipka",
      "Zhao Song",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.03030"
  },
  {
    "id": "arXiv:2111.04873",
    "title": "An Instance-Dependent Analysis for the Cooperative Multi-Player  Multi-Armed Bandit",
    "abstract": "Comments: 50 pages",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Aldo Pacchiano",
      "Peter Bartlett",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.04873"
  },
  {
    "id": "arXiv:2111.05949",
    "title": "How to See Hidden Patterns in Metamaterials with Interpretable Machine  Learning",
    "abstract": "Comments: Accepted to Extreme Mechanics Letters, 2022",
    "descriptor": "\nComments: Accepted to Extreme Mechanics Letters, 2022\n",
    "authors": [
      "Zhi Chen",
      "Alexander Ogren",
      "Chiara Daraio",
      "L. Catherine Brinson",
      "Cynthia Rudin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.05949"
  },
  {
    "id": "arXiv:2111.07466",
    "title": "Discrete-Time Nonlinear Systems Identification with Probabilistic Safety  and Stability Constraints",
    "abstract": "Discrete-Time Nonlinear Systems Identification with Probabilistic Safety  and Stability Constraints",
    "descriptor": "",
    "authors": [
      "Iman Salehi",
      "Tyler Taplin",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07466"
  },
  {
    "id": "arXiv:2111.10601",
    "title": "Deep Safe Multi-Task Learning",
    "abstract": "Deep Safe Multi-Task Learning",
    "descriptor": "",
    "authors": [
      "Zhixiong Yue",
      "Feiyang Ye",
      "Yu Zhang",
      "Christy Liang",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10601"
  },
  {
    "id": "arXiv:2111.10881",
    "title": "Solving Infinite Games in the Baire Space",
    "abstract": "Comments: Updated header on title page. 26 pages, 1 figure",
    "descriptor": "\nComments: Updated header on title page. 26 pages, 1 figure\n",
    "authors": [
      "Benedikt Br\u00fctsch",
      "Wolfgang Thomas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.10881"
  },
  {
    "id": "arXiv:2111.11827",
    "title": "A General Divergence Modeling Strategy for Salient Object Detection",
    "abstract": "Comments: Code is available at: this https URL",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Xinyu Tian",
      "Jing Zhang",
      "Yuchao Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11827"
  },
  {
    "id": "arXiv:2111.12242",
    "title": "PU-Transformer: Point Cloud Upsampling Transformer",
    "abstract": "Comments: ACCV 2022",
    "descriptor": "\nComments: ACCV 2022\n",
    "authors": [
      "Shi Qiu",
      "Saeed Anwar",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12242"
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12273"
  },
  {
    "id": "arXiv:2111.12706",
    "title": "Gap Edit Distance via Non-Adaptive Queries: Simple and Optimal",
    "abstract": "Comments: Accepted to FOCS 2022",
    "descriptor": "\nComments: Accepted to FOCS 2022\n",
    "authors": [
      "Elazar Goldenberg",
      "Tomasz Kociumaka",
      "Robert Krauthgamer",
      "Barna Saha"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12706"
  },
  {
    "id": "arXiv:2112.02494",
    "title": "Implicit Neural Deformation for Sparse-View Face Reconstruction",
    "abstract": "Comments: 10 pages, 6 figures, The 30th Pacific Conference on Computer Graphics and Applications. Pacific Graphics(PG) 2022",
    "descriptor": "\nComments: 10 pages, 6 figures, The 30th Pacific Conference on Computer Graphics and Applications. Pacific Graphics(PG) 2022\n",
    "authors": [
      "Moran Li",
      "Haibin Huang",
      "Yi Zheng",
      "Mengtian Li",
      "Nong Sang",
      "Chongyang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02494"
  },
  {
    "id": "arXiv:2112.03237",
    "title": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "abstract": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "descriptor": "",
    "authors": [
      "Maan Qraitem",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03237"
  },
  {
    "id": "arXiv:2112.04548",
    "title": "Relaxation of Conditions for Convergence of Dynamic Regressor Extension  and Mixing Procedure",
    "abstract": "Comments: 37 pages, 17 figures",
    "descriptor": "\nComments: 37 pages, 17 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04548"
  },
  {
    "id": "arXiv:2112.04744",
    "title": "Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks",
    "abstract": "Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Jun Wang",
      "Zhoujing Li",
      "Yixuan Qiao",
      "Qiming Qin",
      "Peng Gao",
      "Guotong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.04744"
  },
  {
    "id": "arXiv:2112.05855",
    "title": "Inversion of band-limited discrete Fourier transforms of binary images:  Uniqueness and algorithms",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Howard W. Levinson",
      "Vadim A. Markel",
      "Nicholas Triantafillou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.05855"
  },
  {
    "id": "arXiv:2112.06343",
    "title": "Change Detection Meets Visual Question Answering",
    "abstract": "Change Detection Meets Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Zhenghang Yuan",
      "Lichao Mou",
      "Zhitong Xiong",
      "Xiaoxiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06343"
  },
  {
    "id": "arXiv:2112.06909",
    "title": "Hallucinating Pose-Compatible Scenes",
    "abstract": "Hallucinating Pose-Compatible Scenes",
    "descriptor": "",
    "authors": [
      "Tim Brooks",
      "Alexei A. Efros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06909"
  },
  {
    "id": "arXiv:2112.09747",
    "title": "A Simple Single-Scale Vision Transformer for Object Localization and  Instance Segmentation",
    "abstract": "Comments: ECCV 2022 accepted",
    "descriptor": "\nComments: ECCV 2022 accepted\n",
    "authors": [
      "Wuyang Chen",
      "Xianzhi Du",
      "Fan Yang",
      "Lucas Beyer",
      "Xiaohua Zhai",
      "Tsung-Yi Lin",
      "Huizhong Chen",
      "Jing Li",
      "Xiaodan Song",
      "Zhangyang Wang",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09747"
  },
  {
    "id": "arXiv:2112.11534",
    "title": "Noise-injected analog Ising machines enable ultrafast statistical  sampling and machine learning",
    "abstract": "Noise-injected analog Ising machines enable ultrafast statistical  sampling and machine learning",
    "descriptor": "",
    "authors": [
      "Fabian B\u00f6hm",
      "Diego Alonso-Urquijo",
      "Guy Verschaffelt",
      "Guy Van der Sande"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.11534"
  },
  {
    "id": "arXiv:2112.11644",
    "title": "Reconstructing social sensitivity from evolution of content volume in  Twitter",
    "abstract": "Reconstructing social sensitivity from evolution of content volume in  Twitter",
    "descriptor": "",
    "authors": [
      "Sebasti\u00e1n Pinto",
      "Marcos Trevisan",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.11644"
  },
  {
    "id": "arXiv:2112.14804",
    "title": "Learning Spatially-Adaptive Squeeze-Excitation Networks for Image  Synthesis and Image Recognition",
    "abstract": "Learning Spatially-Adaptive Squeeze-Excitation Networks for Image  Synthesis and Image Recognition",
    "descriptor": "",
    "authors": [
      "Jianghao Shen",
      "Tianfu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14804"
  },
  {
    "id": "arXiv:2112.15106",
    "title": "Colour alignment for relative colour constancy via non-standard  references",
    "abstract": "Comments: 14 pages, 8 figures, 2 tables, accepted by IEEE Transactions on Image Processing",
    "descriptor": "\nComments: 14 pages, 8 figures, 2 tables, accepted by IEEE Transactions on Image Processing\n",
    "authors": [
      "Yunfeng Zhao",
      "Stuart Ferguson",
      "Huiyu Zhou",
      "Chris Elliott",
      "Karen Rafferty"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15106"
  },
  {
    "id": "arXiv:2201.00627",
    "title": "Uncertainty Detection and Reduction in Neural Decoding of EEG Signals",
    "abstract": "Uncertainty Detection and Reduction in Neural Decoding of EEG Signals",
    "descriptor": "",
    "authors": [
      "Tiehang Duan",
      "Zhenyi Wang",
      "Sheng Liu",
      "Sargur N. Srihari",
      "Hui Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00627"
  },
  {
    "id": "arXiv:2201.05314",
    "title": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "abstract": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "descriptor": "",
    "authors": [
      "Parham Hadikhani",
      "Daphne Teck Ching Lai",
      "Wee-Hong Ong",
      "Mohammad H. Nadimi-shahraki",
      "Seyedali Mirjalil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05314"
  },
  {
    "id": "arXiv:2201.05820",
    "title": "Offline-Online Associated Camera-Aware Proxies for Unsupervised Person  Re-identification",
    "abstract": "Comments: Accepted to TIP",
    "descriptor": "\nComments: Accepted to TIP\n",
    "authors": [
      "Menglin Wang",
      "Jiachen Li",
      "Baisheng Lai",
      "Xiaojin Gong",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05820"
  },
  {
    "id": "arXiv:2201.05887",
    "title": "Domain Adaptation via Bidirectional Cross-Attention Transformer",
    "abstract": "Domain Adaptation via Bidirectional Cross-Attention Transformer",
    "descriptor": "",
    "authors": [
      "Xiyu Wang",
      "Pengxin Guo",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05887"
  },
  {
    "id": "arXiv:2201.08670",
    "title": "Context-Tuning: Learning Contextualized Prompts for Natural Language  Generation",
    "abstract": "Comments: 15 pages, accepted by COLING 2022",
    "descriptor": "\nComments: 15 pages, accepted by COLING 2022\n",
    "authors": [
      "Tianyi Tang",
      "Junyi Li",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08670"
  },
  {
    "id": "arXiv:2201.09433",
    "title": "Active Learning Polynomial Threshold Functions",
    "abstract": "Active Learning Polynomial Threshold Functions",
    "descriptor": "",
    "authors": [
      "Omri Ben-Eliezer",
      "Max Hopkins",
      "Chutong Yang",
      "Hantao Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.09433"
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": "Deep Generative Model for Periodic Graphs",
    "descriptor": "",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11932"
  },
  {
    "id": "arXiv:2201.12632",
    "title": "Towards Robust Deep Active Learning for Scientific Computing",
    "abstract": "Towards Robust Deep Active Learning for Scientific Computing",
    "descriptor": "",
    "authors": [
      "Simiao Ren",
      "Yang Deng",
      "Willie J. Padilla",
      "Jordan Malof"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12632"
  },
  {
    "id": "arXiv:2201.12674",
    "title": "Rewiring with Positional Encodings for Graph Neural Networks",
    "abstract": "Rewiring with Positional Encodings for Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12674"
  },
  {
    "id": "arXiv:2201.12843",
    "title": "Graph Representation Learning Through Recoverability",
    "abstract": "Graph Representation Learning Through Recoverability",
    "descriptor": "",
    "authors": [
      "Maxim Fishman",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Almog David",
      "Ron Banner",
      "Avi Mendelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12843"
  },
  {
    "id": "arXiv:2201.12880",
    "title": "Self-stabilizing Byzantine Fault-tolerant Repeated Reliable Broadcast",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2110.08592",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.08592\n",
    "authors": [
      "Romaric Duvignau",
      "Michel Raynal",
      "Elad Michael Schiller"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.12880"
  },
  {
    "id": "arXiv:2202.05550",
    "title": "The Factorial-Basis Method for Finding Definite-Sum Solutions of Linear  Recurrences With Polynomial Coefficients",
    "abstract": "Comments: 62 pages",
    "descriptor": "\nComments: 62 pages\n",
    "authors": [
      "Antonio Jim\u00e9nez-Pastor",
      "Marko Petkov\u0161ek"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.05550"
  },
  {
    "id": "arXiv:2202.06054",
    "title": "When do Models Generalize? A Perspective from Data-Algorithm  Compatibility",
    "abstract": "When do Models Generalize? A Perspective from Data-Algorithm  Compatibility",
    "descriptor": "",
    "authors": [
      "Jing Xu",
      "Jiaye Teng",
      "Yang Yuan",
      "Andrew Chi-Chih Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06054"
  },
  {
    "id": "arXiv:2202.06956",
    "title": "DermX: an end-to-end framework for explainable automated dermatological  diagnosis",
    "abstract": "DermX: an end-to-end framework for explainable automated dermatological  diagnosis",
    "descriptor": "",
    "authors": [
      "Raluca Jalaboi",
      "Frederik Faye",
      "Mauricio Orbes-Arteaga",
      "Dan J\u00f8rgensen",
      "Ole Winther",
      "Alfiia Galimzianova"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06956"
  },
  {
    "id": "arXiv:2202.07792",
    "title": "Efficient Content Delivery in User-Centric and Cache-Enabled Vehicular  Edge Networks with Deadline-Constrained Heterogeneous Demands",
    "abstract": "Efficient Content Delivery in User-Centric and Cache-Enabled Vehicular  Edge Networks with Deadline-Constrained Heterogeneous Demands",
    "descriptor": "",
    "authors": [
      "Md Ferdous Pervej",
      "Richeng Jin",
      "Shih-Chun Lin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07792"
  },
  {
    "id": "arXiv:2202.09557",
    "title": "Safe Control Synthesis with Uncertain Dynamics and Constraints",
    "abstract": "Comments: Fix typos",
    "descriptor": "\nComments: Fix typos\n",
    "authors": [
      "Kehan Long",
      "Vikas Dhiman",
      "Melvin Leok",
      "Jorge Cort\u00e9s",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.09557"
  },
  {
    "id": "arXiv:2202.10184",
    "title": "Path of Destruction: Learning an Iterative Level Generator Using a Small  Dataset",
    "abstract": "Comments: 7 pages, 7 figures, and 3 tables. Published at SSCI Conference 2022",
    "descriptor": "\nComments: 7 pages, 7 figures, and 3 tables. Published at SSCI Conference 2022\n",
    "authors": [
      "Matthew Siper",
      "Ahmed Khalifa",
      "Julian Togelius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10184"
  },
  {
    "id": "arXiv:2202.12939",
    "title": "Automated Extraction of Energy Systems Information from Remotely Sensed  Data: A Review and Analysis",
    "abstract": "Comments: This is only an Arxived version. For actual publication please refer to this https URL",
    "descriptor": "\nComments: This is only an Arxived version. For actual publication please refer to this https URL\n",
    "authors": [
      "Simiao Ren",
      "Wei Hu",
      "Kyle Bradbury",
      "Dylan Harrison-Atlas",
      "Laura Malaguzzi Valeri",
      "Brian Murray",
      "Jordan M. Malof"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12939"
  },
  {
    "id": "arXiv:2202.13013",
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation  Learning",
    "abstract": "Comments: 42 pages",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Lingxiao Zhao",
      "Tess Smidt",
      "Suvrit Sra",
      "Haggai Maron",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13013"
  },
  {
    "id": "arXiv:2202.13060",
    "title": "Graph Attention Retrospective",
    "abstract": "Comments: 53 pages, 18 figures",
    "descriptor": "\nComments: 53 pages, 18 figures\n",
    "authors": [
      "Kimon Fountoulakis",
      "Amit Levi",
      "Shenghao Yang",
      "Aseem Baranwal",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13060"
  },
  {
    "id": "arXiv:2202.13808",
    "title": "DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training",
    "abstract": "Comments: 16 pages. DropIT can save memory & improve accuracy, providing a new perspective of dropping in activation compressed training than quantization",
    "descriptor": "\nComments: 16 pages. DropIT can save memory & improve accuracy, providing a new perspective of dropping in activation compressed training than quantization\n",
    "authors": [
      "Joya Chen",
      "Kai Xu",
      "Yuhui Wang",
      "Yifei Cheng",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13808"
  },
  {
    "id": "arXiv:2203.01721",
    "title": "Asymptotic Optimality of Speed-Aware JSQ for Heterogeneous Systems",
    "abstract": "Comments: 36 pages, 3 figures",
    "descriptor": "\nComments: 36 pages, 3 figures\n",
    "authors": [
      "Sanidhay Bhambay",
      "Arpan Mukhopadhyay"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.01721"
  },
  {
    "id": "arXiv:2203.03392",
    "title": "Naturally-meaningful and efficient descriptors: machine learning of  material properties based on robust one-shot ab initio descriptors",
    "abstract": "Comments: 13 pages, accepted in Journal of Cheminformatics",
    "descriptor": "\nComments: 13 pages, accepted in Journal of Cheminformatics\n",
    "authors": [
      "Sherif Abdulkader Tawfik",
      "Salvy P. Russo"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03392"
  },
  {
    "id": "arXiv:2203.03411",
    "title": "Self-employment for autonomous robots using smart contracts",
    "abstract": "Comments: Discussion extended with the legal implications subsection",
    "descriptor": "\nComments: Discussion extended with the legal implications subsection\n",
    "authors": [
      "Eduardo Castell\u00f3 Ferrer",
      "Ivan Berman",
      "Aleksandr Kapitonov",
      "Vadim Manaenko",
      "Makar Chernyaev",
      "Pavel Tarasov",
      "Bryan Wilson",
      "Dazza Greenwood",
      "Ed Walters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03411"
  },
  {
    "id": "arXiv:2203.04749",
    "title": "Bilateral Deep Reinforcement Learning Approach for Better-than-human Car  Following Model",
    "abstract": "Bilateral Deep Reinforcement Learning Approach for Better-than-human Car  Following Model",
    "descriptor": "",
    "authors": [
      "Tianyu Shi",
      "Yifei Ai",
      "Omar ElSamadisy",
      "Baher Abdulhai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04749"
  },
  {
    "id": "arXiv:2203.06276",
    "title": "Randomized quasi-optimal local approximation spaces in time",
    "abstract": "Randomized quasi-optimal local approximation spaces in time",
    "descriptor": "",
    "authors": [
      "Julia Schleu\u00df",
      "Kathrin Smetana",
      "Lukas ter Maat"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.06276"
  },
  {
    "id": "arXiv:2203.07207",
    "title": "A Self-Supervised, Differentiable Kalman Filter for Uncertainty-Aware  Visual-Inertial Odometry",
    "abstract": "Comments: In Proceedings of the IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM'22), Sapporo, Japan, Jul. 11-15, 2022",
    "descriptor": "\nComments: In Proceedings of the IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM'22), Sapporo, Japan, Jul. 11-15, 2022\n",
    "authors": [
      "Brandon Wagstaff",
      "Emmett Wise",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07207"
  },
  {
    "id": "arXiv:2203.07815",
    "title": "Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification",
    "abstract": "Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification",
    "descriptor": "",
    "authors": [
      "Tian Xia",
      "Pedro Sanchez",
      "Chen Qin",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07815"
  },
  {
    "id": "arXiv:2203.10385",
    "title": "PressureVision: Estimating Hand Pressure from a Single RGB Image",
    "abstract": "Comments: ECCV 2022 oral",
    "descriptor": "\nComments: ECCV 2022 oral\n",
    "authors": [
      "Patrick Grady",
      "Chengcheng Tang",
      "Samarth Brahmbhatt",
      "Christopher D. Twigg",
      "Chengde Wan",
      "James Hays",
      "Charles C. Kemp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10385"
  },
  {
    "id": "arXiv:2203.11315",
    "title": "Landscape Analysis for Surrogate Models in the Evolutionary Black-Box  Context",
    "abstract": "Comments: 25 pages main article, 28 pages supplementary material, 3 figures, currently under review at Evolutionary Computation journal",
    "descriptor": "\nComments: 25 pages main article, 28 pages supplementary material, 3 figures, currently under review at Evolutionary Computation journal\n",
    "authors": [
      "Zbyn\u011bk Pitra",
      "Jan Koza",
      "Ji\u0159\u00ed Tumpach",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11315"
  },
  {
    "id": "arXiv:2203.13738",
    "title": "Nonlinear Field-split Preconditioners for Solving Monolithic Phase-field  Models of Brittle Fracture",
    "abstract": "Nonlinear Field-split Preconditioners for Solving Monolithic Phase-field  Models of Brittle Fracture",
    "descriptor": "",
    "authors": [
      "Alena Kopani\u010d\u00e1kov\u00e1",
      "Hardik Kothari",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13738"
  },
  {
    "id": "arXiv:2203.14094",
    "title": "SlimFL: Federated Learning with Superposition Coding over Slimmable  Neural Networks",
    "abstract": "SlimFL: Federated Learning with Superposition Coding over Slimmable  Neural Networks",
    "descriptor": "",
    "authors": [
      "Won Joon Yun",
      "Yunseok Kwak",
      "Hankyul Baek",
      "Soyi Jung",
      "Mingyue Ji",
      "Mehdi Bennis",
      "Jihong Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.14094"
  },
  {
    "id": "arXiv:2203.14310",
    "title": "Sublinear Dynamic Interval Scheduling (on one or multiple machines)",
    "abstract": "Sublinear Dynamic Interval Scheduling (on one or multiple machines)",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Gawrychowski",
      "Karol Pokorski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.14310"
  },
  {
    "id": "arXiv:2203.16009",
    "title": "Towards Collaborative Intelligence: Routability Estimation based on  Decentralized Private Data",
    "abstract": "Comments: 6 pages, 2 figures, 5 tables, accepted by DAC'22",
    "descriptor": "\nComments: 6 pages, 2 figures, 5 tables, accepted by DAC'22\n",
    "authors": [
      "Jingyu Pan",
      "Chen-Chia Chang",
      "Zhiyao Xie",
      "Ang Li",
      "Minxue Tang",
      "Tunhou Zhang",
      "Jiang Hu",
      "Yiran Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16009"
  },
  {
    "id": "arXiv:2204.00563",
    "title": "Arithmetic logical Irreversibility and the Turing's Halt Problem",
    "abstract": "Comments: Irreversibility and undecidability are not one and the same. There are models of computation for which the halting problem is trivially decidable, such as primitive recursion. Conversely, there are reversible models for which it remains undecidable, like the model of reversible Turing machines",
    "descriptor": "\nComments: Irreversibility and undecidability are not one and the same. There are models of computation for which the halting problem is trivially decidable, such as primitive recursion. Conversely, there are reversible models for which it remains undecidable, like the model of reversible Turing machines\n",
    "authors": [
      "Yair Lapin"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2204.00563"
  },
  {
    "id": "arXiv:2204.00588",
    "title": "Time-invariant Prefix Coding for LQG Control",
    "abstract": "Comments: Under submission to the IEEE Journal on Selected Areas in Information Theory (Modern Compression Issue). Revised submission. 35 pages main paper, 10 page appendix, 3 figures",
    "descriptor": "\nComments: Under submission to the IEEE Journal on Selected Areas in Information Theory (Modern Compression Issue). Revised submission. 35 pages main paper, 10 page appendix, 3 figures\n",
    "authors": [
      "Travis Cuvelier",
      "Takashi Tanaka",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.00588"
  },
  {
    "id": "arXiv:2204.00616",
    "title": "Simplicial Embeddings in Self-Supervised Learning and Downstream  Classification",
    "abstract": "Comments: 30 pages, 8 figures, Preprint",
    "descriptor": "\nComments: 30 pages, 8 figures, Preprint\n",
    "authors": [
      "Samuel Lavoie",
      "Christos Tsirigotis",
      "Max Schwarzer",
      "Ankit Vani",
      "Michael Noukhovitch",
      "Kenji Kawaguchi",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00616"
  },
  {
    "id": "arXiv:2204.00865",
    "title": "UrbanFly: Uncertainty-Aware Planning for Navigation Amongst High-Rises  with Monocular Visual-Inertial SLAM Maps",
    "abstract": "Comments: Submitted to ACC 2023, Code available at this https URL",
    "descriptor": "\nComments: Submitted to ACC 2023, Code available at this https URL\n",
    "authors": [
      "Sudarshan S Harithas",
      "Ayyappa Swamy Thatavarthy",
      "Gurkirat Singh",
      "Arun K Singh",
      "K Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.00865"
  },
  {
    "id": "arXiv:2204.02507",
    "title": "Co-optimization of power line de-energization and restoration under high  wildfire ignition risk",
    "abstract": "Co-optimization of power line de-energization and restoration under high  wildfire ignition risk",
    "descriptor": "",
    "authors": [
      "Noah Rhodes",
      "Line Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02507"
  },
  {
    "id": "arXiv:2204.02849",
    "title": "KNN-Diffusion: Image Generation via Large-Scale Retrieval",
    "abstract": "KNN-Diffusion: Image Generation via Large-Scale Retrieval",
    "descriptor": "",
    "authors": [
      "Shelly Sheynin",
      "Oron Ashual",
      "Adam Polyak",
      "Uriel Singer",
      "Oran Gafni",
      "Eliya Nachmani",
      "Yaniv Taigman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02849"
  },
  {
    "id": "arXiv:2204.03359",
    "title": "ECCV Caption: Correcting False Negatives by Collecting  Machine-and-Human-verified Image-Caption Associations for MS-COCO",
    "abstract": "Comments: Accepted at ECCV 2022; 32 pages (2.9MB); Code and dataset: this https URL; v4 fixes errors in v3 (1) Fixing captions in Fig 1 (2) Fixing ill-defined precisions in Tab 3 (3) Fixing wrong (A)-(E) numbering for human study -- Figure D.1. and description in Sec 4.1",
    "descriptor": "\nComments: Accepted at ECCV 2022; 32 pages (2.9MB); Code and dataset: this https URL; v4 fixes errors in v3 (1) Fixing captions in Fig 1 (2) Fixing ill-defined precisions in Tab 3 (3) Fixing wrong (A)-(E) numbering for human study -- Figure D.1. and description in Sec 4.1\n",
    "authors": [
      "Sanghyuk Chun",
      "Wonjae Kim",
      "Song Park",
      "Minsuk Chang",
      "Seong Joon Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03359"
  },
  {
    "id": "arXiv:2204.03635",
    "title": "Zero-Shot Category-Level Object Pose Estimation",
    "abstract": "Comments: 28 pages, 6 figures",
    "descriptor": "\nComments: 28 pages, 6 figures\n",
    "authors": [
      "Walter Goodwin",
      "Sagar Vaze",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03635"
  },
  {
    "id": "arXiv:2204.06818",
    "title": "Interpretable Vertebral Fracture Quantification via Anchor-Free  Landmarks Localization",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2005.11960",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2005.11960\n",
    "authors": [
      "Alexey Zakharov",
      "Maxim Pisov",
      "Alim Bukharaev",
      "Alexey Petraikin",
      "Sergey Morozov",
      "Victor Gombolevskiy",
      "Mikhail Belyaev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06818"
  },
  {
    "id": "arXiv:2204.07028",
    "title": "Exploring the Distributed Knowledge Congruence in Proxy-data-free  Federated Distillation",
    "abstract": "Comments: 32 pages, 7 tables, 7 figures",
    "descriptor": "\nComments: 32 pages, 7 tables, 7 figures\n",
    "authors": [
      "Zhiyuan Wu",
      "Sheng Sun",
      "Min Liu",
      "Junbo Zhang",
      "Yuwei Wang",
      "Qingxiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07028"
  },
  {
    "id": "arXiv:2204.11618",
    "title": "Translating Clinical Delineation of Diabetic Foot Ulcers into Machine  Interpretable Segmentation",
    "abstract": "Comments: 7 pages, 3 figure and 2 tables",
    "descriptor": "\nComments: 7 pages, 3 figure and 2 tables\n",
    "authors": [
      "Connah Kendrick",
      "Bill Cassidy",
      "Joseph M. Pappachan",
      "Claire O'Shea",
      "Cornelious J. Fernandez",
      "Elias Chacko",
      "Koshy Jacob",
      "Neil D. Reeves",
      "Moi Hoon Yap"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11618"
  },
  {
    "id": "arXiv:2204.11639",
    "title": "Investigating Black-Box Function Recognition Using Hardware Performance  Counters",
    "abstract": "Investigating Black-Box Function Recognition Using Hardware Performance  Counters",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Benjamin Semal",
      "Konstantinos Markantonakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.11639"
  },
  {
    "id": "arXiv:2204.12162",
    "title": "Budgeted Out-tree Maximization with Submodular Prizes",
    "abstract": "Budgeted Out-tree Maximization with Submodular Prizes",
    "descriptor": "",
    "authors": [
      "Gianlorenzo D'Angelo",
      "Esmaeil Delfaraz",
      "Hugo Gilbert"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.12162"
  },
  {
    "id": "arXiv:2204.12489",
    "title": "Sound Localization by Self-Supervised Time Delay Estimation",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Ziyang Chen",
      "David F. Fouhey",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.12489"
  },
  {
    "id": "arXiv:2204.13620",
    "title": "Generative Adversarial Networks for Image Super-Resolution: A Survey",
    "abstract": "Generative Adversarial Networks for Image Super-Resolution: A Survey",
    "descriptor": "",
    "authors": [
      "Chunwei Tian",
      "Xuanyu Zhang",
      "Jerry Chun-Wei Lin",
      "Wangmeng Zuo",
      "Yanning Zhang",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13620"
  },
  {
    "id": "arXiv:2204.13858",
    "title": "One-Way Matching of Datasets with Low Rank Signals",
    "abstract": "One-Way Matching of Datasets with Low Rank Signals",
    "descriptor": "",
    "authors": [
      "Shuxiao Chen",
      "Sizun Jiang",
      "Zongming Ma",
      "Garry P. Nolan",
      "Bokai Zhu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.13858"
  },
  {
    "id": "arXiv:2205.00362",
    "title": "A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization",
    "abstract": "A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization",
    "descriptor": "",
    "authors": [
      "Luhao Zhang",
      "Jincheng Yang",
      "Rui Gao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.00362"
  },
  {
    "id": "arXiv:2205.04358",
    "title": "Towards Implementing Responsible AI",
    "abstract": "Comments: extended and revised version of arXiv:2111.09478",
    "descriptor": "\nComments: extended and revised version of arXiv:2111.09478\n",
    "authors": [
      "Conrad Sanderson",
      "Qinghua Lu",
      "David Douglas",
      "Xiwei Xu",
      "Liming Zhu",
      "Jon Whittle"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.04358"
  },
  {
    "id": "arXiv:2205.05095",
    "title": "Design and Implementation of a Secure RISC-V Microprocessor",
    "abstract": "Comments: Submitted to IEEE for possible publication. Copyright may be transferred. This version may no longer be accessible",
    "descriptor": "\nComments: Submitted to IEEE for possible publication. Copyright may be transferred. This version may no longer be accessible\n",
    "authors": [
      "Kleber Stangherlin",
      "Manoj Sachdev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05095"
  },
  {
    "id": "arXiv:2205.05435",
    "title": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "abstract": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "descriptor": "",
    "authors": [
      "Rabab Alkhalifa",
      "Elena Kochkina",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05435"
  },
  {
    "id": "arXiv:2205.06360",
    "title": "Plain and Simple Inductive Invariant Inference for Distributed Protocols  in TLA+",
    "abstract": "Plain and Simple Inductive Invariant Inference for Distributed Protocols  in TLA+",
    "descriptor": "",
    "authors": [
      "William Schultz",
      "Ian Dardik",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.06360"
  },
  {
    "id": "arXiv:2205.06570",
    "title": "Convergence of Deep Neural Networks with General Activation Functions  and Pooling",
    "abstract": "Comments: incomplete",
    "descriptor": "\nComments: incomplete\n",
    "authors": [
      "Wentao Huang",
      "Yuesheng Xu",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2205.06570"
  },
  {
    "id": "arXiv:2205.08916",
    "title": "Monoidal Width: Capturing Rank Width",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Elena Di Lavore",
      "Pawe\u0142 Soboci\u0144ski"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.08916"
  },
  {
    "id": "arXiv:2205.09801",
    "title": "Graph Neural Networks Are More Powerful Than we Think",
    "abstract": "Graph Neural Networks Are More Powerful Than we Think",
    "descriptor": "",
    "authors": [
      "Charilaos I. Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09801"
  },
  {
    "id": "arXiv:2205.09809",
    "title": "Calibration Matters: Tackling Maximization Bias in Large-scale  Advertising Recommendation Systems",
    "abstract": "Calibration Matters: Tackling Maximization Bias in Large-scale  Advertising Recommendation Systems",
    "descriptor": "",
    "authors": [
      "Yewen Fan",
      "Nian Si",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.09809"
  },
  {
    "id": "arXiv:2205.09971",
    "title": "On Tackling Explanation Redundancy in Decision Trees",
    "abstract": "On Tackling Explanation Redundancy in Decision Trees",
    "descriptor": "",
    "authors": [
      "Yacine Izza",
      "Alexey Ignatiev",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09971"
  },
  {
    "id": "arXiv:2205.10089",
    "title": "Kernel Normalized Convolutional Networks",
    "abstract": "Kernel Normalized Convolutional Networks",
    "descriptor": "",
    "authors": [
      "Reza Nasirigerdeh",
      "Reihaneh Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10089"
  },
  {
    "id": "arXiv:2205.10664",
    "title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks",
    "abstract": "Comments: Preprint: 17 pages, 6 figures",
    "descriptor": "\nComments: Preprint: 17 pages, 6 figures\n",
    "authors": [
      "Guangji Bai",
      "Chen Ling",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10664"
  },
  {
    "id": "arXiv:2205.10752",
    "title": "Covariance Matrix Adaptation MAP-Annealing",
    "abstract": "Covariance Matrix Adaptation MAP-Annealing",
    "descriptor": "",
    "authors": [
      "Matthew C. Fontaine",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10752"
  },
  {
    "id": "arXiv:2205.10763",
    "title": "A Deep Conjugate Direction Method for Iteratively Solving Linear Systems",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Ayano Kaneda",
      "Osman Akar",
      "Jingyu Chen",
      "Victoria Kala",
      "David Hyde",
      "Joseph Teran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.10763"
  },
  {
    "id": "arXiv:2205.11916",
    "title": "Large Language Models are Zero-Shot Reasoners",
    "abstract": "Comments: Accepted to NeurIPS2022. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS2022. Our code is available at this https URL\n",
    "authors": [
      "Takeshi Kojima",
      "Shixiang Shane Gu",
      "Machel Reid",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11916"
  },
  {
    "id": "arXiv:2205.12519",
    "title": "Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset",
    "abstract": "Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset",
    "descriptor": "",
    "authors": [
      "Sushruth Nagesh",
      "Asfiya Baig",
      "Savitha Srinivasan",
      "Akshay Rangesh",
      "Mohan Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12519"
  },
  {
    "id": "arXiv:2205.12940",
    "title": "Conformal Prediction Intervals with Temporal Dependence",
    "abstract": "Comments: 16 pages (main paper, including references) + 6 pages (supplementary material). Transactions of Machine Learning Research (September 2022). Code is available at this https URL",
    "descriptor": "\nComments: 16 pages (main paper, including references) + 6 pages (supplementary material). Transactions of Machine Learning Research (September 2022). Code is available at this https URL\n",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.12940"
  },
  {
    "id": "arXiv:2205.13016",
    "title": "BiT: Robustly Binarized Multi-distilled Transformer",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zechun Liu",
      "Barlas Oguz",
      "Aasish Pappu",
      "Lin Xiao",
      "Scott Yih",
      "Meng Li",
      "Raghuraman Krishnamoorthi",
      "Yashar Mehdad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.13016"
  },
  {
    "id": "arXiv:2205.13022",
    "title": "Towards Using Data-Influence Methods to Detect Noisy Samples in Source  Code Corpora",
    "abstract": "Comments: The 37th IEEE/ACM International Conference on Automated Software Engineering",
    "descriptor": "\nComments: The 37th IEEE/ACM International Conference on Automated Software Engineering\n",
    "authors": [
      "Anh T. V. Dau",
      "Thang Nguyen-Duc",
      "Hoang Thanh-Tung",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.13022"
  },
  {
    "id": "arXiv:2205.13147",
    "title": "Matryoshka Representation Learning",
    "abstract": "Comments: 35 pages, 12 figures. NeurIPS 2022 camera ready publication",
    "descriptor": "\nComments: 35 pages, 12 figures. NeurIPS 2022 camera ready publication\n",
    "authors": [
      "Aditya Kusupati",
      "Gantavya Bhatt",
      "Aniket Rege",
      "Matthew Wallingford",
      "Aditya Sinha",
      "Vivek Ramanujan",
      "William Howard-Snyder",
      "Kaifeng Chen",
      "Sham Kakade",
      "Prateek Jain",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13147"
  },
  {
    "id": "arXiv:2205.13524",
    "title": "PREF: Phasorial Embedding Fields for Compact Neural Representations",
    "abstract": "PREF: Phasorial Embedding Fields for Compact Neural Representations",
    "descriptor": "",
    "authors": [
      "Binbin Huang",
      "Xinhao Yan",
      "Anpei Chen",
      "Shenghua Gao",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.13524"
  },
  {
    "id": "arXiv:2205.13671",
    "title": "Transformer for Partial Differential Equations' Operator Learning",
    "abstract": "Transformer for Partial Differential Equations' Operator Learning",
    "descriptor": "",
    "authors": [
      "Zijie Li",
      "Kazem Meidani",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13671"
  },
  {
    "id": "arXiv:2205.14691",
    "title": "On the Robustness of Safe Reinforcement Learning under Observational  Perturbations",
    "abstract": "Comments: 30 pages, 4 figures, 8 tables",
    "descriptor": "\nComments: 30 pages, 4 figures, 8 tables\n",
    "authors": [
      "Zuxin Liu",
      "Zijian Guo",
      "Zhepeng Cen",
      "Huan Zhang",
      "Jie Tan",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.14691"
  },
  {
    "id": "arXiv:2205.14938",
    "title": "Harnessing spectral representations for subgraph alignment",
    "abstract": "Harnessing spectral representations for subgraph alignment",
    "descriptor": "",
    "authors": [
      "Marco Pegoraro",
      "Riccardo Marin",
      "Arianna Rampini",
      "Simone Melzi",
      "Luca Cosmo",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14938"
  },
  {
    "id": "arXiv:2205.15213",
    "title": "Backpropagation through Combinatorial Algorithms: Identity with  Projection Works",
    "abstract": "Comments: The first two authors contributed equally",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Subham Sekhar Sahoo",
      "Anselm Paulus",
      "Marin Vlastelica",
      "V\u00edt Musil",
      "Volodymyr Kuleshov",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15213"
  },
  {
    "id": "arXiv:2205.15544",
    "title": "Refining Low-Resource Unsupervised Translation by Language  Disentanglement of Multilingual Model",
    "abstract": "Comments: Published in NeurIPS 2022",
    "descriptor": "\nComments: Published in NeurIPS 2022\n",
    "authors": [
      "Xuan-Phi Nguyen",
      "Shafiq Joty",
      "Wu Kui",
      "Ai Ti Aw"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15544"
  },
  {
    "id": "arXiv:2205.15987",
    "title": "Achieving Lightweight Federated Advertising with Self-Supervised Split  Distillation",
    "abstract": "Comments: Accepted to the Trustworthy Federated Learning workshop of IJCAI2022 (FL-IJCAI22). 6 pages, 3 figures, 3 tables Old title: Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer",
    "descriptor": "\nComments: Accepted to the Trustworthy Federated Learning workshop of IJCAI2022 (FL-IJCAI22). 6 pages, 3 figures, 3 tables Old title: Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer\n",
    "authors": [
      "Wenjie Li",
      "Qiaolin Xia",
      "Junfeng Deng",
      "Hao Cheng",
      "Jiangming Liu",
      "Kouying Xue",
      "Yong Cheng",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15987"
  },
  {
    "id": "arXiv:2205.16004",
    "title": "What Knowledge Gets Distilled in Knowledge Distillation?",
    "abstract": "What Knowledge Gets Distilled in Knowledge Distillation?",
    "descriptor": "",
    "authors": [
      "Utkarsh Ojha",
      "Yuheng Li",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.16004"
  },
  {
    "id": "arXiv:2206.00057",
    "title": "Distributed Graph Neural Network Training with Periodic Stale  Representation Synchronization",
    "abstract": "Comments: Preprint: 20 pages, 9 figures",
    "descriptor": "\nComments: Preprint: 20 pages, 9 figures\n",
    "authors": [
      "Zheng Chai",
      "Guangji Bai",
      "Liang Zhao",
      "Yue Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.00057"
  },
  {
    "id": "arXiv:2206.00236",
    "title": "Continuous Prediction with Experts' Advice",
    "abstract": "Comments: 30 pages, 1 figure. Version 2 diff: minor edits, reorganization for a journal submission, correct statement of Lemma 5.1 and a better formatted proof of the same lemma",
    "descriptor": "\nComments: 30 pages, 1 figure. Version 2 diff: minor edits, reorganization for a journal submission, correct statement of Lemma 5.1 and a better formatted proof of the same lemma\n",
    "authors": [
      "Victor Sanches Portella",
      "Christopher Liaw",
      "Nicholas J. A. Harvey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00236"
  },
  {
    "id": "arXiv:2206.00469",
    "title": "A barycentric trigonometric Hermite interpolant via an iterative  approach",
    "abstract": "A barycentric trigonometric Hermite interpolant via an iterative  approach",
    "descriptor": "",
    "authors": [
      "Giacomo Elefante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00469"
  },
  {
    "id": "arXiv:2206.00702",
    "title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "abstract": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Zawalski",
      "Micha\u0142 Tyrolski",
      "Konrad Czechowski",
      "Damian Stachura",
      "Piotr Pi\u0119kos",
      "Tomasz Odrzyg\u00f3\u017ad\u017a",
      "Yuhuai Wu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00702"
  },
  {
    "id": "arXiv:2206.00787",
    "title": "On the Generalization of Neural Combinatorial Optimization Heuristics",
    "abstract": "Comments: Published in ECML PKDD 2022",
    "descriptor": "\nComments: Published in ECML PKDD 2022\n",
    "authors": [
      "Sahil Manchanda",
      "Sofia Michel",
      "Darko Drakulic",
      "Jean-Marc Andreoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00787"
  },
  {
    "id": "arXiv:2206.00941",
    "title": "Improving Diffusion Models for Inverse Problems using Manifold  Constraints",
    "abstract": "Comments: NeurIPS 2022 camera-ready; 29 pages, 16 figures",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready; 29 pages, 16 figures\n",
    "authors": [
      "Hyungjin Chung",
      "Byeongsu Sim",
      "Dohoon Ryu",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00941"
  },
  {
    "id": "arXiv:2206.01545",
    "title": "Mesh-free Eulerian Physics-Informed Neural Networks",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Fabricio Arend Torres",
      "Marcello Massimo Negri",
      "Monika Nagy-Huber",
      "Maxim Samarin",
      "Volker Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01545"
  },
  {
    "id": "arXiv:2206.01742",
    "title": "Learning Probabilistic Topological Representations Using Discrete Morse  Theory",
    "abstract": "Comments: 16 pages, 11 figures",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Xiaoling Hu",
      "Dimitris Samaras",
      "Chao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01742"
  },
  {
    "id": "arXiv:2206.02338",
    "title": "OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal  Regression",
    "abstract": "Comments: Accepted by NeurIPS2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS2022. Code is available at this https URL\n",
    "authors": [
      "Wanhua Li",
      "Xiaoke Huang",
      "Zheng Zhu",
      "Yansong Tang",
      "Xiu Li",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02338"
  },
  {
    "id": "arXiv:2206.02607",
    "title": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural  Representations",
    "abstract": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural  Representations",
    "descriptor": "",
    "authors": [
      "Peter Yichen Chen",
      "Jinxu Xiang",
      "Dong Heon Cho",
      "Yue Chang",
      "G A Pershing",
      "Henrique Teles Maia",
      "Maurizio Chiaramonte",
      "Kevin Carlberg",
      "Eitan Grinspun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02607"
  },
  {
    "id": "arXiv:2206.02928",
    "title": "Neuro-Symbolic Procedural Planning with Commonsense Prompting",
    "abstract": "Neuro-Symbolic Procedural Planning with Commonsense Prompting",
    "descriptor": "",
    "authors": [
      "Yujie Lu",
      "Weixi Feng",
      "Wanrong Zhu",
      "Wenda Xu",
      "Xin Eric Wang",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02928"
  },
  {
    "id": "arXiv:2206.03480",
    "title": "SHRED: 3D Shape Region Decomposition with Learned Local Operations",
    "abstract": "Comments: SIGGRAPH ASIA 2022",
    "descriptor": "\nComments: SIGGRAPH ASIA 2022\n",
    "authors": [
      "R. Kenny Jones",
      "Aalia Habib",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03480"
  },
  {
    "id": "arXiv:2206.04038",
    "title": "Scaleformer: Iterative Multi-scale Refining Transformers for Time Series  Forecasting",
    "abstract": "Scaleformer: Iterative Multi-scale Refining Transformers for Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Amin Shabani",
      "Amir Abdi",
      "Lili Meng",
      "Tristan Sylvain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04038"
  },
  {
    "id": "arXiv:2206.04734",
    "title": "Fast Bayesian Inference with Batch Bayesian Quadrature via Kernel  Recombination",
    "abstract": "Comments: 38 pages, 6 figures",
    "descriptor": "\nComments: 38 pages, 6 figures\n",
    "authors": [
      "Masaki Adachi",
      "Satoshi Hayakawa",
      "Martin J\u00f8rgensen",
      "Harald Oberhauser",
      "Michael A. Osborne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04734"
  },
  {
    "id": "arXiv:2206.04936",
    "title": "Improved lower and upper bounds for LCD codes",
    "abstract": "Improved lower and upper bounds for LCD codes",
    "descriptor": "",
    "authors": [
      "Shitao Li",
      "Minjia Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.04936"
  },
  {
    "id": "arXiv:2206.05880",
    "title": "Confident Sinkhorn Allocation for Pseudo-Labeling",
    "abstract": "Comments: 23 pages. Code this https URL",
    "descriptor": "\nComments: 23 pages. Code this https URL\n",
    "authors": [
      "Vu Nguyen",
      "Sachin Farfade",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05880"
  },
  {
    "id": "arXiv:2206.06290",
    "title": "Constrained Quantum Optimization for Extractive Summarization on a  Trapped-ion Quantum Computer",
    "abstract": "Comments: camera-ready version",
    "descriptor": "\nComments: camera-ready version\n",
    "authors": [
      "Pradeep Niroula",
      "Ruslan Shaydulin",
      "Romina Yalovetzky",
      "Pierre Minssen",
      "Dylan Herman",
      "Shaohan Hu",
      "Marco Pistoia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.06290"
  },
  {
    "id": "arXiv:2206.07393",
    "title": "Structure and Power: an emerging landscape",
    "abstract": "Comments: To appear in special issue for Trakhtenbrot centenary of Fundamenta Informaticae vol. 186 no 1-4",
    "descriptor": "\nComments: To appear in special issue for Trakhtenbrot centenary of Fundamenta Informaticae vol. 186 no 1-4\n",
    "authors": [
      "Samson Abramsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.07393"
  },
  {
    "id": "arXiv:2206.07729",
    "title": "Taxonomy of Benchmarks in Graph Representation Learning",
    "abstract": "Taxonomy of Benchmarks in Graph Representation Learning",
    "descriptor": "",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Dylan Sandfelder",
      "Devin Kreuzer",
      "Anna Little",
      "Sarah McGuire",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07729"
  },
  {
    "id": "arXiv:2206.08396",
    "title": "User Customizable and Robust Geo-Indistinguishability for Location  Privacy",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Primal Pappachan",
      "Chenxi Qiu",
      "Anna Squicciarini",
      "Vishnu Sharma Hunsur Manjunath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.08396"
  },
  {
    "id": "arXiv:2206.09269",
    "title": "Automatic Self-Adaptive Local Voltage Control Under Limited Reactive  Power",
    "abstract": "Automatic Self-Adaptive Local Voltage Control Under Limited Reactive  Power",
    "descriptor": "",
    "authors": [
      "Rui Cheng",
      "Naihao Shi",
      "Salish Maharjan",
      "Zhaoyu Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09269"
  },
  {
    "id": "arXiv:2206.09305",
    "title": "Adversarial Scrutiny of Evidentiary Statistical Software",
    "abstract": "Comments: Typos corrected, appendix B removed",
    "descriptor": "\nComments: Typos corrected, appendix B removed\n",
    "authors": [
      "Rediet Abebe",
      "Moritz Hardt",
      "Angela Jin",
      "John Miller",
      "Ludwig Schmidt",
      "Rebecca Wexler"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09305"
  },
  {
    "id": "arXiv:2206.09959",
    "title": "Global Context Vision Transformers",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Ali Hatamizadeh",
      "Hongxu Yin",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09959"
  },
  {
    "id": "arXiv:2206.13093",
    "title": "Learning Deep Input-Output Stable Dynamics",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Yuji Okamoto",
      "Ryosuke Kojima"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13093"
  },
  {
    "id": "arXiv:2206.13397",
    "title": "Generative Modelling With Inverse Heat Dissipation",
    "abstract": "Generative Modelling With Inverse Heat Dissipation",
    "descriptor": "",
    "authors": [
      "Severi Rissanen",
      "Markus Heinonen",
      "Arno Solin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13397"
  },
  {
    "id": "arXiv:2207.01848",
    "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems  in a Second",
    "abstract": "TabPFN: A Transformer That Solves Small Tabular Classification Problems  in a Second",
    "descriptor": "",
    "authors": [
      "Noah Hollmann",
      "Samuel M\u00fcller",
      "Katharina Eggensperger",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01848"
  },
  {
    "id": "arXiv:2207.02632",
    "title": "Network Pruning via Feature Shift Minimization",
    "abstract": "Network Pruning via Feature Shift Minimization",
    "descriptor": "",
    "authors": [
      "Yuanzhi Duan",
      "Yue Zhou",
      "Peng He",
      "Qiang Liu",
      "Shukai Duan",
      "Xiaofang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02632"
  },
  {
    "id": "arXiv:2207.02808",
    "title": "Improved conformalized quantile regression",
    "abstract": "Comments: 10 pages, 17 figures",
    "descriptor": "\nComments: 10 pages, 17 figures\n",
    "authors": [
      "Martim Sousa",
      "Ana Maria Tom\u00e9",
      "Jos\u00e9 Moreira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02808"
  },
  {
    "id": "arXiv:2207.02958",
    "title": "SphereVLAD++: Attention-based and Signal-enhanced Viewpoint Invariant  Descriptor",
    "abstract": "Comments: 8 pages, 7 figures, IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: 8 pages, 7 figures, IEEE Robotics and Automation Letters\n",
    "authors": [
      "Shiqi Zhao",
      "Peng Yin",
      "Ge Yi",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.02958"
  },
  {
    "id": "arXiv:2207.05013",
    "title": "Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models",
    "abstract": "Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models",
    "descriptor": "",
    "authors": [
      "Alexey N. Korovin",
      "Innokentiy S. Humonen",
      "Artem I. Samtsevich",
      "Roman A. Eremin",
      "Artem I. Vasilyev",
      "Vladimir D. Lazarev",
      "Semen A. Budennyy"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05013"
  },
  {
    "id": "arXiv:2207.05727",
    "title": "Enhancing Fairness of Visual Attribute Predictors",
    "abstract": "Comments: Camera Ready, ACCV 2022",
    "descriptor": "\nComments: Camera Ready, ACCV 2022\n",
    "authors": [
      "Tobias H\u00e4nel",
      "Nishant Kumar",
      "Dmitrij Schlesinger",
      "Mengze Li",
      "Erdem \u00dcnal",
      "Abouzar Eslami",
      "Stefan Gumhold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.05727"
  },
  {
    "id": "arXiv:2207.05785",
    "title": "Domain Gap Estimation for Source Free Unsupervised Domain Adaptation  with Many Classifiers",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Ziyang Zong",
      "Jun He",
      "Lei Zhang",
      "Hai Huan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05785"
  },
  {
    "id": "arXiv:2207.06324",
    "title": "PointNorm: Dual Normalization is All You Need for Point Cloud Analysis",
    "abstract": "PointNorm: Dual Normalization is All You Need for Point Cloud Analysis",
    "descriptor": "",
    "authors": [
      "Shen Zheng",
      "Jinqian Pan",
      "Changjie Lu",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06324"
  },
  {
    "id": "arXiv:2207.06635",
    "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "abstract": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "descriptor": "",
    "authors": [
      "Min Zhao",
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06635"
  },
  {
    "id": "arXiv:2207.06929",
    "title": "Data Curation from Privacy-Aware Agents",
    "abstract": "Data Curation from Privacy-Aware Agents",
    "descriptor": "",
    "authors": [
      "Roy Shahmoon",
      "Rann Smorodinsky",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.06929"
  },
  {
    "id": "arXiv:2207.07336",
    "title": "PoLyScriber: Integrated Training of Extractor and Lyrics Transcriber for  Polyphonic Music",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Xiaoxue Gao",
      "Chitralekha Gupta",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.07336"
  },
  {
    "id": "arXiv:2207.07506",
    "title": "Augmenting Softmax Information for Selective Classification with  Out-of-Distribution Data",
    "abstract": "Comments: ACCV 2022 (Oral)",
    "descriptor": "\nComments: ACCV 2022 (Oral)\n",
    "authors": [
      "Guoxuan Xia",
      "Christos-Savvas Bouganis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07506"
  },
  {
    "id": "arXiv:2207.07751",
    "title": "MARLAS: Multi Agent Reinforcement Learning for cooperated Adaptive  Sampling",
    "abstract": "Comments: 15 pages, 9 figures, submitted",
    "descriptor": "\nComments: 15 pages, 9 figures, submitted\n",
    "authors": [
      "Lishuo Pan",
      "Sandeep Manjanna",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.07751"
  },
  {
    "id": "arXiv:2207.08204",
    "title": "Fast Composite Optimization and Statistical Recovery in Federated  Learning",
    "abstract": "Comments: This is a revised version to fix the imprecise statements about linear speedup from the ICML proceedings. We use another averaging scheme for the returned solutions in Theorem 2.1 and 3.1 to guarantee linear speedup when the number of iterations is large",
    "descriptor": "\nComments: This is a revised version to fix the imprecise statements about linear speedup from the ICML proceedings. We use another averaging scheme for the returned solutions in Theorem 2.1 and 3.1 to guarantee linear speedup when the number of iterations is large\n",
    "authors": [
      "Yajie Bao",
      "Michael Crawshaw",
      "Shan Luo",
      "Mingrui Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.08204"
  },
  {
    "id": "arXiv:2207.09280",
    "title": "Exploiting Inter-Sample Affinity for Knowability-Aware Universal Domain  Adaptation",
    "abstract": "Exploiting Inter-Sample Affinity for Knowability-Aware Universal Domain  Adaptation",
    "descriptor": "",
    "authors": [
      "Yifan Wang",
      "Lin Zhang",
      "Ran Song",
      "Lin Ma",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09280"
  },
  {
    "id": "arXiv:2207.09353",
    "title": "Beyond Transmitting Bits: Context, Semantics, and Task-Oriented  Communications",
    "abstract": "Comments: 32 pages, 14 figures",
    "descriptor": "\nComments: 32 pages, 14 figures\n",
    "authors": [
      "Deniz Gunduz",
      "Zhijin Qin",
      "Inaki Estella Aguerri",
      "Harpreet S. Dhillon",
      "Zhaohui Yang",
      "Aylin Yener",
      "Kai Kit Wong",
      "Chan-Byoung Chae"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09353"
  },
  {
    "id": "arXiv:2207.09460",
    "title": "Money & Trust in Digital Society, Bitcoin and Stablecoins in ML enabled  Metaverse Telecollaboration",
    "abstract": "Money & Trust in Digital Society, Bitcoin and Stablecoins in ML enabled  Metaverse Telecollaboration",
    "descriptor": "",
    "authors": [
      "John Joseph O'Hare",
      "Allen Fairchild",
      "Umran Ali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09460"
  },
  {
    "id": "arXiv:2207.10035",
    "title": "Fully Sparse 3D Object Detection",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Lue Fan",
      "Feng Wang",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10035"
  },
  {
    "id": "arXiv:2207.10293",
    "title": "Affective Behavior Analysis using Action Unit Relation Graph and  Multi-task Cross Attention",
    "abstract": "Affective Behavior Analysis using Action Unit Relation Graph and  Multi-task Cross Attention",
    "descriptor": "",
    "authors": [
      "Dang-Khanh Nguyen",
      "Sudarshan Pant",
      "Ngoc-Huynh Ho",
      "Guee-Sang Lee",
      "Soo-Huyng Kim",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10293"
  },
  {
    "id": "arXiv:2207.11709",
    "title": "TVCalib: Camera Calibration for Sports Field Registration in Soccer",
    "abstract": "Comments: Accepted for publication at WACV'23",
    "descriptor": "\nComments: Accepted for publication at WACV'23\n",
    "authors": [
      "Jonas Theiner",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11709"
  },
  {
    "id": "arXiv:2207.11744",
    "title": "New MDS self-dual codes over finite fields $\\F_{r^2}$",
    "abstract": "Comments: 16 pages, 3 table",
    "descriptor": "\nComments: 16 pages, 3 table\n",
    "authors": [
      "Ruhao Wan",
      "Yang Li",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.11744"
  },
  {
    "id": "arXiv:2207.12022",
    "title": "Peer-to-Peer Sharing of Energy Storage Systems under Net Metering and  Time-of-Use Pricing",
    "abstract": "Peer-to-Peer Sharing of Energy Storage Systems under Net Metering and  Time-of-Use Pricing",
    "descriptor": "",
    "authors": [
      "K. Victor Sam Moses Babu",
      "Satya Surya Vinay K",
      "Pratyush Chakraborty"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.12022"
  },
  {
    "id": "arXiv:2207.12559",
    "title": "Static Hand Gesture Recognition for American Sign Language using  Neuromorphic Hardware",
    "abstract": "Comments: Authors MohammedReza Mohammadi, and Peyton Chandarana contributed equally",
    "descriptor": "\nComments: Authors MohammedReza Mohammadi, and Peyton Chandarana contributed equally\n",
    "authors": [
      "MohammadReza Mohammadi",
      "Peyton Chandarana",
      "James Seekings",
      "Sara Hendrix",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.12559"
  },
  {
    "id": "arXiv:2207.14294",
    "title": "Knowledge-Driven Mechanistic Enrichment of the Preeclampsia Ignorome",
    "abstract": "Comments: Preprint of an article submitted for consideration in Pacific Symposium on Biocomputing \\copyright 2022 copyright World Scientific Publishing Company this https URL",
    "descriptor": "\nComments: Preprint of an article submitted for consideration in Pacific Symposium on Biocomputing \\copyright 2022 copyright World Scientific Publishing Company this https URL\n",
    "authors": [
      "Tiffany J. Callahan",
      "Adrianne L. Stefanski",
      "Jin-Dong Kim",
      "William A. Baumgartner Jr.",
      "Jordan M. Wyrwa",
      "Lawrence E. Hunter"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.14294"
  },
  {
    "id": "arXiv:2207.14584",
    "title": "Decentralized Machine Learning for Intelligent Health Care Systems on  the Computing Continuum",
    "abstract": "Decentralized Machine Learning for Intelligent Health Care Systems on  the Computing Continuum",
    "descriptor": "",
    "authors": [
      "Dragi Kimovski",
      "Sasko Ristov",
      "Radu Prodan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14584"
  },
  {
    "id": "arXiv:2207.14709",
    "title": "Robust Quantitative Susceptibility Mapping via Approximate Message  Passing",
    "abstract": "Comments: Keywords: Approximate message passing, Compressive sensing, Parameter estimation, QSM",
    "descriptor": "\nComments: Keywords: Approximate message passing, Compressive sensing, Parameter estimation, QSM\n",
    "authors": [
      "Shuai Huang",
      "James J. Lah",
      "Jason W. Allen",
      "Deqiang Qiu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.14709"
  },
  {
    "id": "arXiv:2208.01439",
    "title": "Unsupervised machine learning framework for discriminating major  variants of concern during COVID-19",
    "abstract": "Unsupervised machine learning framework for discriminating major  variants of concern during COVID-19",
    "descriptor": "",
    "authors": [
      "Rohitash Chandra",
      "Chaarvi Bansal",
      "Mingyue Kang",
      "Tom Blau",
      "Vinti Agarwal",
      "Pranjal Singh",
      "Laurence O. W. Wilson",
      "Seshadri Vasan"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.01439"
  },
  {
    "id": "arXiv:2208.02531",
    "title": "InitialGAN: A Language GAN with Completely Random Initialization",
    "abstract": "InitialGAN: A Language GAN with Completely Random Initialization",
    "descriptor": "",
    "authors": [
      "Da Ren",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.02531"
  },
  {
    "id": "arXiv:2208.02900",
    "title": "Petri Nets for Concurrent Programming",
    "abstract": "Petri Nets for Concurrent Programming",
    "descriptor": "",
    "authors": [
      "Marshall Rawson",
      "Michael Rawson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2208.02900"
  },
  {
    "id": "arXiv:2208.03238",
    "title": "Learning programs with magic values",
    "abstract": "Learning programs with magic values",
    "descriptor": "",
    "authors": [
      "C\u00e9line Hocquette",
      "Andrew Cropper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03238"
  },
  {
    "id": "arXiv:2208.04139",
    "title": "DALLE-URBAN: Capturing the urban design expertise of large text to image  transformers",
    "abstract": "Comments: Accepted to DICTA 2022, released 11000+ environmental scene images generated by Stable Diffusion and 1000+ images generated by DALLE-2",
    "descriptor": "\nComments: Accepted to DICTA 2022, released 11000+ environmental scene images generated by Stable Diffusion and 1000+ images generated by DALLE-2\n",
    "authors": [
      "Sachith Seneviratne",
      "Damith Senanayake",
      "Sanka Rasnayaka",
      "Rajith Vidanaarachchi",
      "Jason Thompson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.04139"
  },
  {
    "id": "arXiv:2208.04509",
    "title": "Reconfigurable Intelligent Computational Surfaces: When Wave Propagation  Control Meets Computing",
    "abstract": "Reconfigurable Intelligent Computational Surfaces: When Wave Propagation  Control Meets Computing",
    "descriptor": "",
    "authors": [
      "Bo Yang",
      "Xuelin Cao",
      "Jindan Xu",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Linglong Dai",
      "M'erouane Debbah",
      "H. Vincent Poor",
      "Chau Yuen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.04509"
  },
  {
    "id": "arXiv:2208.04564",
    "title": "Statistical Properties of the log-cosh Loss Function Used in Machine  Learning",
    "abstract": "Comments: 10 pages, 17 figures",
    "descriptor": "\nComments: 10 pages, 17 figures\n",
    "authors": [
      "Resve A. Saleh",
      "A.K.Md. Ehsanes Saleh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.04564"
  },
  {
    "id": "arXiv:2208.05925",
    "title": "Near-Optimal Algorithms for Making the Gradient Small in Stochastic  Minimax Optimization",
    "abstract": "Near-Optimal Algorithms for Making the Gradient Small in Stochastic  Minimax Optimization",
    "descriptor": "",
    "authors": [
      "Lesi Chen",
      "Luo Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.05925"
  },
  {
    "id": "arXiv:2208.05963",
    "title": "RelPose: Predicting Probabilistic Relative Rotation for Single Objects  in the Wild",
    "abstract": "Comments: In ECCV 2022. V2: updated references",
    "descriptor": "\nComments: In ECCV 2022. V2: updated references\n",
    "authors": [
      "Jason Y. Zhang",
      "Deva Ramanan",
      "Shubham Tulsiani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.05963"
  },
  {
    "id": "arXiv:2208.05994",
    "title": "Anomaly segmentation model for defects detection in electroluminescence  images of heterojunction solar cells",
    "abstract": "Anomaly segmentation model for defects detection in electroluminescence  images of heterojunction solar cells",
    "descriptor": "",
    "authors": [
      "Alexey Korovin",
      "Artem Vasilyev",
      "Fedor Egorov",
      "Dmitry Saykin",
      "Evgeny Terukov",
      "Igor Shakhray",
      "Leonid Zhukov",
      "Semen Budennyy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05994"
  },
  {
    "id": "arXiv:2208.06366",
    "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers",
    "abstract": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers",
    "descriptor": "",
    "authors": [
      "Zhiliang Peng",
      "Li Dong",
      "Hangbo Bao",
      "Qixiang Ye",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06366"
  },
  {
    "id": "arXiv:2208.06783",
    "title": "Stabilizing Unstable Periodic Orbit of Unknown Fractional-Order Systems  via Adaptive Delayed Feedback Control",
    "abstract": "Stabilizing Unstable Periodic Orbit of Unknown Fractional-Order Systems  via Adaptive Delayed Feedback Control",
    "descriptor": "",
    "authors": [
      "Bahram Yaghooti",
      "Kaveh Safavigerdini",
      "Reza Hajiloo",
      "Hassan Salarieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.06783"
  },
  {
    "id": "arXiv:2208.06876",
    "title": "Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces",
    "abstract": "Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces",
    "descriptor": "",
    "authors": [
      "Li Fan",
      "Jianchang Liu",
      "Wenle Zhang",
      "Peng Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.06876"
  },
  {
    "id": "arXiv:2208.06957",
    "title": "Syntax-driven Data Augmentation for Named Entity Recognition",
    "abstract": "Comments: submitted to Pattern-based Approaches to NLP in the Age of Deep Learning 2022 (Pan-DL 2022)",
    "descriptor": "\nComments: submitted to Pattern-based Approaches to NLP in the Age of Deep Learning 2022 (Pan-DL 2022)\n",
    "authors": [
      "Arie Pratama Sutiono",
      "Gus Hahn-Powell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06957"
  },
  {
    "id": "arXiv:2208.07369",
    "title": "Cellular liberality is measurable as Lempel-Ziv complexity of fastq  files",
    "abstract": "Comments: 6 pages, single table, 4 figures",
    "descriptor": "\nComments: 6 pages, single table, 4 figures\n",
    "authors": [
      "Norichika Ogata",
      "Aoi Hosaka"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.07369"
  },
  {
    "id": "arXiv:2208.07657",
    "title": "Uconv-Conformer: High Reduction of Input Sequence Length for End-to-End  Speech Recognition",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Andrei Andrusenko",
      "Rauf Nasretdinov",
      "Aleksei Romanenko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2208.07657"
  },
  {
    "id": "arXiv:2208.08003",
    "title": "The Final Ascent: When Bigger Models Generalize Worse on Noisy-Labeled  Data",
    "abstract": "Comments: added more experiments and discussion on sample size",
    "descriptor": "\nComments: added more experiments and discussion on sample size\n",
    "authors": [
      "Yihao Xue",
      "Kyle Whitecross",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.08003"
  },
  {
    "id": "arXiv:2208.08084",
    "title": "AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Zhijun Tu",
      "Xinghao Chen",
      "Pengju Ren",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08084"
  },
  {
    "id": "arXiv:2208.08110",
    "title": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation",
    "abstract": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation",
    "descriptor": "",
    "authors": [
      "Hongyuan Lu",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08110"
  },
  {
    "id": "arXiv:2208.09298",
    "title": "Applying Back Propagation Algorithm and Analytic Hierarchy Process to  Environment Assessment",
    "abstract": "Applying Back Propagation Algorithm and Analytic Hierarchy Process to  Environment Assessment",
    "descriptor": "",
    "authors": [
      "Chunyu Sui",
      "Xinrui Li",
      "Yinghang Song",
      "Chen Wu",
      "Ziyang Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09298"
  },
  {
    "id": "arXiv:2208.09578",
    "title": "Contrastive Domain Adaptation for Early Misinformation Detection: A Case  Study on COVID-19",
    "abstract": "Comments: Accepted to CIKM 2022",
    "descriptor": "\nComments: Accepted to CIKM 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09578"
  },
  {
    "id": "arXiv:2208.10606",
    "title": "LEAPER: Fast and Accurate FPGA-based System Performance Prediction via  Transfer Learning",
    "abstract": "LEAPER: Fast and Accurate FPGA-based System Performance Prediction via  Transfer Learning",
    "descriptor": "",
    "authors": [
      "Gagandeep Singh",
      "Dionysios Diamantopoulos",
      "Juan G\u00f3mez-Luna",
      "Sander Stuijk",
      "Henk Corporaal",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10606"
  },
  {
    "id": "arXiv:2208.11112",
    "title": "DeepInteraction: 3D Object Detection via Modality Interaction",
    "abstract": "Comments: To appear at NeurIPS 2022. 16 pages, 7 figure",
    "descriptor": "\nComments: To appear at NeurIPS 2022. 16 pages, 7 figure\n",
    "authors": [
      "Zeyu Yang",
      "Jiaqi Chen",
      "Zhenwei Miao",
      "Wei Li",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11112"
  },
  {
    "id": "arXiv:2208.13422",
    "title": "Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios",
    "abstract": "Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Bo Li",
      "Fei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13422"
  },
  {
    "id": "arXiv:2208.14845",
    "title": "Listen2YourHeart: A Self-Supervised Approach for Detecting Murmur in  Heart-Beat Sounds",
    "abstract": "Comments: To be published in the proceedings of CinC 2022 (this https URL). This is a preprint version of the final paper",
    "descriptor": "\nComments: To be published in the proceedings of CinC 2022 (this https URL). This is a preprint version of the final paper\n",
    "authors": [
      "Aristotelis Ballas",
      "Vasileios Papapanagiotou",
      "Anastasios Delopoulos",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.14845"
  },
  {
    "id": "arXiv:2209.00797",
    "title": "Random Text Perturbations Work, but not Always",
    "abstract": "Comments: 7 pages; 8 tables; 3 figures",
    "descriptor": "\nComments: 7 pages; 8 tables; 3 figures\n",
    "authors": [
      "Zhengxiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.00797"
  },
  {
    "id": "arXiv:2209.01217",
    "title": "A Method for Discovering Novel Classes in Tabular Data",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Colin Troisemaine",
      "Joachim Flocon-Cholet",
      "St\u00e9phane Gosselin",
      "Sandrine Vaton",
      "Alexandre Reiffers-Masson",
      "Vincent Lemaire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.01217"
  },
  {
    "id": "arXiv:2209.03416",
    "title": "Bispectral Neural Networks",
    "abstract": "Bispectral Neural Networks",
    "descriptor": "",
    "authors": [
      "Sophia Sanborn",
      "Christian Shewmake",
      "Bruno Olshausen",
      "Christopher Hillar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03416"
  },
  {
    "id": "arXiv:2209.03993",
    "title": "Q-learning Decision Transformer: Leveraging Dynamic Programming for  Conditional Sequence Modelling in Offline RL",
    "abstract": "Q-learning Decision Transformer: Leveraging Dynamic Programming for  Conditional Sequence Modelling in Offline RL",
    "descriptor": "",
    "authors": [
      "Taku Yamagata",
      "Ahmed Khalil",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03993"
  },
  {
    "id": "arXiv:2209.04257",
    "title": "Non-isothermal direct bundle simulation of SMC compression molding with  a non-Newtonian compressible matrix",
    "abstract": "Non-isothermal direct bundle simulation of SMC compression molding with  a non-Newtonian compressible matrix",
    "descriptor": "",
    "authors": [
      "Nils Meyer",
      "Sergej Ilinzeer",
      "Andrew N. Hrymak",
      "Frank Henning",
      "Luise K\u00e4rger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.04257"
  },
  {
    "id": "arXiv:2209.04998",
    "title": "Domain Adaptation for Question Answering via Question Classification",
    "abstract": "Comments: Accepted to COLING 2022",
    "descriptor": "\nComments: Accepted to COLING 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04998"
  },
  {
    "id": "arXiv:2209.05247",
    "title": "TrackletMapper: Ground Surface Segmentation and Mapping from Traffic  Participant Trajectories",
    "abstract": "Comments: 19 pages, 14 figures, CoRL 2022 v3",
    "descriptor": "\nComments: 19 pages, 14 figures, CoRL 2022 v3\n",
    "authors": [
      "Jannik Z\u00fcrn",
      "Sebastian Weber",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.05247"
  },
  {
    "id": "arXiv:2209.05837",
    "title": "Large data limit of the MBO scheme for data clustering: convergence of  the dynamics",
    "abstract": "Comments: Corrected typos, updated bibliography",
    "descriptor": "\nComments: Corrected typos, updated bibliography\n",
    "authors": [
      "Tim Laux",
      "Jona Lelmi"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.05837"
  },
  {
    "id": "arXiv:2209.06203",
    "title": "Normalizing Flows for Interventional Density Estimation",
    "abstract": "Normalizing Flows for Interventional Density Estimation",
    "descriptor": "",
    "authors": [
      "Valentyn Melnychuk",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.06203"
  },
  {
    "id": "arXiv:2209.06239",
    "title": "On the search for expanded grid control capabilities: Discrete control  on emerging power technologies",
    "abstract": "On the search for expanded grid control capabilities: Discrete control  on emerging power technologies",
    "descriptor": "",
    "authors": [
      "Hector Pulgar-Painemal",
      "Sebastian Martinez-Lizana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06239"
  },
  {
    "id": "arXiv:2209.06351",
    "title": "DevNet: Self-supervised Monocular Depth Learning via Density Volume  Construction",
    "abstract": "Comments: Accepted by European Conference on Computer Vision 2022 (ECCV2022)",
    "descriptor": "\nComments: Accepted by European Conference on Computer Vision 2022 (ECCV2022)\n",
    "authors": [
      "Kaichen Zhou",
      "Lanqing Hong",
      "Changhao Chen",
      "Hang Xu",
      "Chaoqiang Ye",
      "Qingyong Hu",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06351"
  },
  {
    "id": "arXiv:2209.06423",
    "title": "SCULPTOR: Skeleton-Consistent Face Creation Using a Learned Parametric  Generator",
    "abstract": "Comments: 16 page, 13 figs",
    "descriptor": "\nComments: 16 page, 13 figs\n",
    "authors": [
      "Zesong Qiu",
      "Yuwei Li",
      "Dongming He",
      "Qixuan Zhang",
      "Longwen Zhang",
      "Yinghao Zhang",
      "Jingya Wang",
      "Lan Xu",
      "Xudong Wang",
      "Yuyao Zhang",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06423"
  },
  {
    "id": "arXiv:2209.07164",
    "title": "Challenges and Opportunities of Machine Learning for Monitoring and  Operational Data Analytics in Quantitative Codesign of Supercomputers",
    "abstract": "Challenges and Opportunities of Machine Learning for Monitoring and  Operational Data Analytics in Quantitative Codesign of Supercomputers",
    "descriptor": "",
    "authors": [
      "Thomas Jakobsche",
      "Nicolas Lachiche",
      "Florina M. Ciorba"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.07164"
  },
  {
    "id": "arXiv:2209.07324",
    "title": "Stability Guarantees for Continuous RL Control",
    "abstract": "Stability Guarantees for Continuous RL Control",
    "descriptor": "",
    "authors": [
      "Bing Song",
      "Jean-Jacques Slotine",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07324"
  },
  {
    "id": "arXiv:2209.07417",
    "title": "Examining Large Pre-Trained Language Models for Machine Translation:  What You Don't Know About It",
    "abstract": "Comments: System paper submitted to WMT2022: BiomedicalMT Track (ClinSpEn2022)",
    "descriptor": "\nComments: System paper submitted to WMT2022: BiomedicalMT Track (ClinSpEn2022)\n",
    "authors": [
      "Lifeng Han",
      "Gleb Erofeev",
      "Irina Sorokina",
      "Serge Gladkoff",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07417"
  },
  {
    "id": "arXiv:2209.07589",
    "title": "PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF  Tracking",
    "abstract": "Comments: 3DV Oral",
    "descriptor": "\nComments: 3DV Oral\n",
    "authors": [
      "Van Nguyen Nguyen",
      "Yuming Du",
      "Yang Xiao",
      "Michael Ramamonjisoa",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07589"
  },
  {
    "id": "arXiv:2209.08657",
    "title": "Online Regenerative Learning",
    "abstract": "Online Regenerative Learning",
    "descriptor": "",
    "authors": [
      "Owen Shen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08657"
  },
  {
    "id": "arXiv:2209.08697",
    "title": "Quantifying How Hateful Communities Radicalize Online Users",
    "abstract": "Quantifying How Hateful Communities Radicalize Online Users",
    "descriptor": "",
    "authors": [
      "Matheus Schmitz",
      "Keith Burghardt",
      "Goran Muric"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2209.08697"
  },
  {
    "id": "arXiv:2209.09124",
    "title": "DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using  Attention-Based Generative Adverserial Network",
    "abstract": "DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using  Attention-Based Generative Adverserial Network",
    "descriptor": "",
    "authors": [
      "Payam Nikdel",
      "Mohammad Mahdavian",
      "Mo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.09124"
  },
  {
    "id": "arXiv:2209.09528",
    "title": "Demonstration of SDN-Based Heterogeneous Quantum Key Distribution Chain  Orchestration over Optical Networks",
    "abstract": "Demonstration of SDN-Based Heterogeneous Quantum Key Distribution Chain  Orchestration over Optical Networks",
    "descriptor": "",
    "authors": [
      "Yuan Cao",
      "Yongli Zhao",
      "Jie Zhang",
      "Qin Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.09528"
  },
  {
    "id": "arXiv:2209.09898",
    "title": "Text2Light: Zero-Shot Text-Driven HDR Panorama Generation",
    "abstract": "Comments: SIGGRAPH Asia 2022; Project Page this https URL Codes are available at this https URL",
    "descriptor": "\nComments: SIGGRAPH Asia 2022; Project Page this https URL Codes are available at this https URL\n",
    "authors": [
      "Zhaoxi Chen",
      "Guangcong Wang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2209.09898"
  },
  {
    "id": "arXiv:2209.09941",
    "title": "Predicting Drug-Drug Interactions using Deep Generative Models on Graphs",
    "abstract": "Predicting Drug-Drug Interactions using Deep Generative Models on Graphs",
    "descriptor": "",
    "authors": [
      "Nhat Khang Ngo",
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.09941"
  },
  {
    "id": "arXiv:2209.10631",
    "title": "An Image Processing approach to identify solar plages observed at 393.37  nm by Kodaikanal Solar Observatory",
    "abstract": "An Image Processing approach to identify solar plages observed at 393.37  nm by Kodaikanal Solar Observatory",
    "descriptor": "",
    "authors": [
      "Sarvesh Gharat",
      "Bhaskar Bose",
      "Abhimanyu Borthakur"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10631"
  },
  {
    "id": "arXiv:2209.10658",
    "title": "Explaining Anomalies using Denoising Autoencoders for Financial Tabular  Data",
    "abstract": "Comments: 10 pages, 4 figures, 3 tables, preprint version",
    "descriptor": "\nComments: 10 pages, 4 figures, 3 tables, preprint version\n",
    "authors": [
      "Timur Sattarov",
      "Dayananda Herurkar",
      "J\u00f6rn Hees"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.10658"
  },
  {
    "id": "arXiv:2209.10800",
    "title": "Unified Implementation of Adaptive Finite Element Methods in Matlab",
    "abstract": "Comments: adaptive fem. arXiv admin note: text overlap with arXiv:2206.06918",
    "descriptor": "\nComments: adaptive fem. arXiv admin note: text overlap with arXiv:2206.06918\n",
    "authors": [
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.10800"
  },
  {
    "id": "arXiv:2209.11388",
    "title": "LGDN: Language-Guided Denoising Network for Video-Language Modeling",
    "abstract": "Comments: Accepted by NeurIPS2022",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Haoyu Lu",
      "Mingyu Ding",
      "Nanyi Fei",
      "Yuqi Huo",
      "Zhiwu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11388"
  },
  {
    "id": "arXiv:2209.11537",
    "title": "Planar graph with twin-width seven",
    "abstract": "Planar graph with twin-width seven",
    "descriptor": "",
    "authors": [
      "Daniel Kral",
      "Ander Lamaison"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.11537"
  },
  {
    "id": "arXiv:2209.11628",
    "title": "A Neural Model for Regular Grammar Induction",
    "abstract": "Comments: Accepted to the 21st IEEE International Conference on Machine Learning and Applications (ICMLA) 2022, 6 pages, 4 figures",
    "descriptor": "\nComments: Accepted to the 21st IEEE International Conference on Machine Learning and Applications (ICMLA) 2022, 6 pages, 4 figures\n",
    "authors": [
      "Peter Belc\u00e1k",
      "David Hofer",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11628"
  },
  {
    "id": "arXiv:2209.11785",
    "title": "Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search",
    "abstract": "Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search",
    "descriptor": "",
    "authors": [
      "S\u0142awomir Kierat",
      "Mateusz Sieniawski",
      "Denys Fridman",
      "Chen-Han Yu",
      "Szymon Migacz",
      "Pawe\u0142 Morkisz",
      "Alex-Fit Florea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11785"
  },
  {
    "id": "arXiv:2209.11805",
    "title": "Tracking the State and Behavior of People in Response to COVID-1 19  Through the Fusion of Multiple Longitudinal Data Streams",
    "abstract": "Tracking the State and Behavior of People in Response to COVID-1 19  Through the Fusion of Multiple Longitudinal Data Streams",
    "descriptor": "",
    "authors": [
      "Mohamed Amine Bouzaghrane",
      "Hassan Obeid",
      "Drake Hayes",
      "Minnie Chen",
      "Meiqing Li",
      "Madeleine Parker",
      "Daniel A. Rodr\u00edguez",
      "Daniel G. Chatman",
      "Karen Trapenberg Frick",
      "Raja Sengupta",
      "Joan Walker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.11805"
  },
  {
    "id": "arXiv:2209.12018",
    "title": "Facilitating Self-monitored Physical Rehabilitation with Virtual Reality  and Haptic feedback",
    "abstract": "Facilitating Self-monitored Physical Rehabilitation with Virtual Reality  and Haptic feedback",
    "descriptor": "",
    "authors": [
      "Yu Jiang",
      "Zhipeng Li",
      "Ziyue Dang",
      "Yuntao Wang",
      "Yukang Yan",
      "Y Zhang",
      "Xinguang Wang",
      "Yansong Li",
      "Mouwang Zhou",
      "Hua Tian",
      "Yuanchun Shi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.12018"
  },
  {
    "id": "arXiv:2209.12138",
    "title": "Towards Stable Co-saliency Detection and Object Co-segmentation",
    "abstract": "Towards Stable Co-saliency Detection and Object Co-segmentation",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Lv Tang",
      "Senyun Kuang",
      "Mofei Song",
      "Shouhong Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12138"
  },
  {
    "id": "arXiv:2209.12163",
    "title": "Reduced basis stochastic Galerkin methods for partial differential  equations with random inputs",
    "abstract": "Reduced basis stochastic Galerkin methods for partial differential  equations with random inputs",
    "descriptor": "",
    "authors": [
      "Guanjie Wang",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.12163"
  },
  {
    "id": "arXiv:2209.12324",
    "title": "Matching Queues with Abandonments in Quantum Switches: Stability and  Throughput Analysis",
    "abstract": "Matching Queues with Abandonments in Quantum Switches: Stability and  Throughput Analysis",
    "descriptor": "",
    "authors": [
      "Martin Zubeldia",
      "Prakirt R. Jhunjhunwala",
      "Siva Theja Maguluri"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2209.12324"
  },
  {
    "id": "arXiv:2209.12354",
    "title": "InterCap: Joint Markerless 3D Tracking of Humans and Objects in  Interaction",
    "abstract": "Comments: To appear at GCPR2022",
    "descriptor": "\nComments: To appear at GCPR2022\n",
    "authors": [
      "Yinghao Huang",
      "Omid Tehari",
      "Michael J. Black",
      "Dimitrios Tzionas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12354"
  },
  {
    "id": "arXiv:2209.12374",
    "title": "High moment and pathwise error estimates for fully discrete mixed finite  element approximattions of stochastic Navier-Stokes equations with additive  noise",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Xiaobing Feng",
      "Liet Vo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.12374"
  },
  {
    "id": "arXiv:2209.12381",
    "title": "Convergence of score-based generative modeling for general data  distributions",
    "abstract": "Convergence of score-based generative modeling for general data  distributions",
    "descriptor": "",
    "authors": [
      "Holden Lee",
      "Jianfeng Lu",
      "Yixin Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.12381"
  },
  {
    "id": "arXiv:2209.12394",
    "title": "Multi-stage image denoising with the wavelet transform",
    "abstract": "Multi-stage image denoising with the wavelet transform",
    "descriptor": "",
    "authors": [
      "Chunwei Tian",
      "Menghua Zheng",
      "Wangmeng Zuo",
      "Bob Zhang",
      "Yanning Zhang",
      "David Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12394"
  },
  {
    "id": "arXiv:2209.12629",
    "title": "Power System Anomaly Detection and Classification Utilizing WLS-EKF  State Estimation and Machine Learning",
    "abstract": "Comments: 12 pages, 11 figures, source code is available",
    "descriptor": "\nComments: 12 pages, 11 figures, source code is available\n",
    "authors": [
      "Sajjad Asefi",
      "Mile Mitrovic",
      "Dragan \u0106etenovi\u0107",
      "Victor Levi",
      "Elena Gryazina",
      "Vladimir Terzija"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12629"
  },
  {
    "id": "arXiv:2209.12782",
    "title": "Learning GFlowNets from partial episodes for improved convergence and  stability",
    "abstract": "Learning GFlowNets from partial episodes for improved convergence and  stability",
    "descriptor": "",
    "authors": [
      "Kanika Madan",
      "Jarrid Rector-Brooks",
      "Maksym Korablyov",
      "Emmanuel Bengio",
      "Moksh Jain",
      "Andrei Nica",
      "Tom Bosc",
      "Yoshua Bengio",
      "Nikolay Malkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.12782"
  },
  {
    "id": "arXiv:2209.12846",
    "title": "Codes parameterized by the edges of a bipartite graph with a perfect  matching",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Manuel Gonzalez Sarabia",
      "Rafael H. Villarreal"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.12846"
  },
  {
    "id": "arXiv:2209.13020",
    "title": "Law Informs Code: A Legal Informatics Approach to Aligning Artificial  Intelligence with Humans",
    "abstract": "Comments: Draft; Forthcoming in Northwestern Journal of Technology and Intellectual Property, Volume 20",
    "descriptor": "\nComments: Draft; Forthcoming in Northwestern Journal of Technology and Intellectual Property, Volume 20\n",
    "authors": [
      "John J. Nay"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13020"
  },
  {
    "id": "arXiv:2209.13388",
    "title": "Efficient Fault Detection Architecture of Bit-Parallel Multiplier in  Polynomial Basis of GF(2m) Using BCH Code",
    "abstract": "Comments: 8 pages, 4 Figures, 3 Tables",
    "descriptor": "\nComments: 8 pages, 4 Figures, 3 Tables\n",
    "authors": [
      "Saeideh Nabipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.13388"
  },
  {
    "id": "arXiv:2209.13423",
    "title": "Deterministic non-adaptive contention resolution on a shared channel",
    "abstract": "Deterministic non-adaptive contention resolution on a shared channel",
    "descriptor": "",
    "authors": [
      "Gianluca De Marco",
      "Dariusz R. Kowalski",
      "Grzegorz Stachowiak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.13423"
  },
  {
    "id": "arXiv:2209.13599",
    "title": "A characterization of polynomial time computable functions from the  integers to the reals using discrete ordinary differential equations",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2209.13404",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.13404\n",
    "authors": [
      "Manon Blanc",
      "Olivier Bournez"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2209.13599"
  },
  {
    "id": "arXiv:2209.13701",
    "title": "Spectral clustering and model reduction for weakly-connected coherent  network systems",
    "abstract": "Spectral clustering and model reduction for weakly-connected coherent  network systems",
    "descriptor": "",
    "authors": [
      "Hancheng Min",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.13701"
  },
  {
    "id": "arXiv:2209.13767",
    "title": "Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster)",
    "abstract": "Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster)",
    "descriptor": "",
    "authors": [
      "Asma Enayet",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.13767"
  },
  {
    "id": "arXiv:2209.13822",
    "title": "TokenFlow: Rethinking Fine-grained Cross-modal Alignment in  Vision-Language Retrieval",
    "abstract": "TokenFlow: Rethinking Fine-grained Cross-modal Alignment in  Vision-Language Retrieval",
    "descriptor": "",
    "authors": [
      "Xiaohan Zou",
      "Changqiao Wu",
      "Lele Cheng",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.13822"
  },
  {
    "id": "arXiv:2209.13857",
    "title": "An Arbitrarily High Order Unfitted Finite Element Method for Elliptic  Interface Problems with Automatic Mesh Generation",
    "abstract": "Comments: 33 pages, 19 figures",
    "descriptor": "\nComments: 33 pages, 19 figures\n",
    "authors": [
      "Zhiming Chen",
      "Yong Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.13857"
  },
  {
    "id": "arXiv:2209.14265",
    "title": "360FusionNeRF: Panoramic Neural Radiance Fields with Joint Guidance",
    "abstract": "Comments: 8 pages, Fig 3, Submitted to IEEE RAL. arXiv admin note: text overlap with arXiv:2106.10859, arXiv:2104.00677, arXiv:2203.09957, arXiv:2204.00928 by other authors",
    "descriptor": "\nComments: 8 pages, Fig 3, Submitted to IEEE RAL. arXiv admin note: text overlap with arXiv:2106.10859, arXiv:2104.00677, arXiv:2203.09957, arXiv:2204.00928 by other authors\n",
    "authors": [
      "Shreyas Kulkarni",
      "Peng Yin",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.14265"
  },
  {
    "id": "arXiv:2209.14491",
    "title": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Wenhu Chen",
      "Hexiang Hu",
      "Chitwan Saharia",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14491"
  },
  {
    "id": "arXiv:2209.14552",
    "title": "Centralized and Decentralized Techniques for Analysis and Synthesis of  Non-Linear Networked Systems",
    "abstract": "Comments: To be submitted to ACC 2023",
    "descriptor": "\nComments: To be submitted to ACC 2023\n",
    "authors": [
      "Shirantha Welikala",
      "Hai Lin",
      "Panos J. Antsaklis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.14552"
  },
  {
    "id": "arXiv:2209.14553",
    "title": "Regularizing Neural Network Training via Identity-wise Discriminative  Feature Suppression",
    "abstract": "Comments: DICTA 2022",
    "descriptor": "\nComments: DICTA 2022\n",
    "authors": [
      "Avraham Chapman",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14553"
  },
  {
    "id": "arXiv:2209.14703",
    "title": "Lattice Linear Algorithms",
    "abstract": "Lattice Linear Algorithms",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta",
      "Sandeep S Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.14703"
  },
  {
    "id": "arXiv:2209.14916",
    "title": "Human Motion Diffusion Model",
    "abstract": "Human Motion Diffusion Model",
    "descriptor": "",
    "authors": [
      "Guy Tevet",
      "Sigal Raab",
      "Brian Gordon",
      "Yonatan Shafir",
      "Daniel Cohen-Or",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2209.14916"
  },
  {
    "id": "arXiv:2209.14952",
    "title": "CacheQL: Quantifying and Localizing Cache Side-Channel Vulnerabilities  in Production Software",
    "abstract": "Comments: The extended version of a paper to appear in the Proceedings of the 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 24 pages",
    "descriptor": "\nComments: The extended version of a paper to appear in the Proceedings of the 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 24 pages\n",
    "authors": [
      "Yuanyuan Yuan",
      "Zhibo Liu",
      "Shuai Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.14952"
  },
  {
    "id": "arXiv:2209.15076",
    "title": "3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical  Transformer for Medical Image Segmentation",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Ho Hin Lee",
      "Shunxing Bao",
      "Yuankai Huo",
      "Bennett A. Landman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15076"
  },
  {
    "id": "arXiv:2209.15486",
    "title": "Graph Neural Networks for Link Prediction with Subgraph Sketching",
    "abstract": "Comments: 9 pages, 6 figures, 6 appendices",
    "descriptor": "\nComments: 9 pages, 6 figures, 6 appendices\n",
    "authors": [
      "Benjamin Paul Chamberlain",
      "Sergey Shirobokov",
      "Emanuele Rossi",
      "Fabrizio Frasca",
      "Thomas Markovich",
      "Nils Hammerla",
      "Michael M. Bronstein",
      "Max Hansmire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.15486"
  },
  {
    "id": "arXiv:2209.15589",
    "title": "Where Should I Spend My FLOPS? Efficiency Evaluations of Visual  Pre-training Methods",
    "abstract": "Where Should I Spend My FLOPS? Efficiency Evaluations of Visual  Pre-training Methods",
    "descriptor": "",
    "authors": [
      "Skanda Koppula",
      "Yazhe Li",
      "Evan Shelhamer",
      "Andrew Jaegle",
      "Nikhil Parthasarathy",
      "Relja Arandjelovic",
      "Jo\u00e3o Carreira",
      "Olivier H\u00e9naff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15589"
  },
  {
    "id": "arXiv:2209.15605",
    "title": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "abstract": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "descriptor": "",
    "authors": [
      "Maan Qraitem",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15605"
  }
]
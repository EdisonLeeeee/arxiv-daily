[
  {
    "id": "arXiv:2210.14905",
    "title": "RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding",
    "abstract": "Knowledge graph (KG) reasoning is an important problem for knowledge graphs.\nIt predicts missing links by reasoning on existing facts. Knowledge graph\nembedding (KGE) is one of the most popular methods to address this problem. It\nembeds entities and relations into low-dimensional vectors and uses the learned\nentity/relation embeddings to predict missing facts. However, KGE only uses\nzeroth-order (propositional) logic to encode existing triplets (e.g., ``Alice\nis Bob's wife.\"); it is unable to leverage first-order (predicate) logic to\nrepresent generally applicable logical \\textbf{rules} (e.g., ``$\\forall x,y\n\\colon x ~\\text{is}~ y\\text{'s wife} \\rightarrow y ~\\text{is}~ x\\text{'s\nhusband}$''). On the other hand, traditional rule-based KG reasoning methods\nusually rely on hard logical rule inference, making it brittle and hardly\ncompetitive with KGE. In this paper, we propose RulE, a novel and principled\nframework to represent and model logical rules and triplets. RulE jointly\nrepresents entities, relations and logical rules in a unified embedding space.\nBy learning an embedding for each logical rule, RulE can perform logical rule\ninference in a soft way and give a confidence score to each grounded rule,\nsimilar to how KGE gives each triplet a confidence score. Compared to KGE\nalone, RulE allows injecting prior logical rule information into the embedding\nspace, which improves the generalization of knowledge graph embedding. Besides,\nthe learned confidence scores of rules improve the logical rule inference\nprocess by softly controlling the contribution of each rule, which alleviates\nthe brittleness of logic. We evaluate our method with link prediction tasks.\nExperimental results on multiple benchmark KGs demonstrate the effectiveness of\nRulE.",
    "descriptor": "",
    "authors": [
      "Xiaojuan Tang",
      "Song-Chun Zhu",
      "Yitao Liang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14905"
  },
  {
    "id": "arXiv:2210.14906",
    "title": "An Intelligent Decision Support Ensemble Voting Model for Coronary  Artery Disease Prediction in Smart Healthcare Monitoring Environments",
    "abstract": "Coronary artery disease (CAD) is one of the most common cardiac diseases\nworldwide and causes disability and economic burden. It is the world's leading\nand most serious cause of mortality, with approximately 80% of deaths reported\nin low- and middle-income countries. The preferred and most precise diagnostic\ntool for CAD is angiography, but it is invasive, expensive, and technically\ndemanding. However, the research community is increasingly interested in the\ncomputer-aided diagnosis of CAD via the utilization of machine learning (ML)\nmethods. The purpose of this work is to present an e-diagnosis tool based on ML\nalgorithms that can be used in a smart healthcare monitoring system. We applied\nthe most accurate machine learning methods that have shown superior results in\nthe literature to different medical datasets such as RandomForest, XGboost,\nMLP, J48, AdaBoost, NaiveBayes, LogitBoost, KNN. Every single classifier can be\nefficient on a different dataset. Thus, an ensemble model using majority voting\nwas designed to take advantage of the well-performed single classifiers,\nEnsemble learning aims to combine the forecasts of multiple individual\nclassifiers to achieve higher performance than individual classifiers in terms\nof precision, specificity, sensitivity, and accuracy; furthermore, we have\nbenchmarked our proposed model with the most efficient and well-known ensemble\nmodels, such as Bagging, Stacking methods based on the cross-validation\ntechnique, The experimental results confirm that the ensemble majority voting\napproach based on the top 3 classifiers: MultilayerPerceptron, RandomForest,\nand AdaBoost, achieves the highest accuracy of 88,12% and outperforms all other\nclassifiers. This study demonstrates that the majority voting ensemble approach\nproposed above is the most accurate machine learning classification approach\nfor the prediction and detection of coronary artery disease.",
    "descriptor": "\nComments: International Journal of Advanced Computer Science and Applications 2022\n",
    "authors": [
      "Anas Maach",
      "Jamila Elalami",
      "Noureddine Elalami",
      "El Houssine El Mazoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14906"
  },
  {
    "id": "arXiv:2210.14907",
    "title": "Neuro-symbolic partial differential equation solver",
    "abstract": "We present a highly scalable strategy for developing mesh-free neuro-symbolic\npartial differential equation solvers from existing numerical discretizations\nfound in scientific computing. This strategy is unique in that it can be used\nto efficiently train neural network surrogate models for the solution functions\nand the differential operators, while retaining the accuracy and convergence\nproperties of state-of-the-art numerical solvers. This neural bootstrapping\nmethod is based on minimizing residuals of discretized differential systems on\na set of random collocation points with respect to the trainable parameters of\nthe neural network, achieving unprecedented resolution and optimal scaling for\nsolving physical and biological systems.",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2022 (ML4PS workshop). arXiv admin note: substantial text overlap with arXiv:2210.14312\n",
    "authors": [
      "Pouria Mistani",
      "Samira Pakravan",
      "Rajesh Ilango",
      "Sanjay Choudhry",
      "Frederic Gibou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.14907"
  },
  {
    "id": "arXiv:2210.14910",
    "title": "The eyes and hearts of UAV pilots: observations of physiological  responses in real-life scenarios",
    "abstract": "The drone industry is diversifying and the number of pilots increases\nrapidly. In this context, flight schools need adapted tools to train pilots,\nmost importantly with regard to their own awareness of their physiological and\ncognitive limits. In civil and military aviation, pilots can train themselves\non realistic simulators to tune their reaction and reflexes, but also to gather\ndata on their piloting behavior and physiological states. It helps them to\nimprove their performances. Opposed to cockpit scenarios, drone teleoperation\nis conducted outdoor in the field, thus with only limited potential from\ndesktop simulation training. This work aims to provide a solution to gather\npilots behavior out in the field and help them increase their performance. We\ncombined advance object detection from a frontal camera to gaze and heart-rate\nvariability measurements. We observed pilots and analyze their behavior over\nthree flight challenges. We believe this tool can support pilots both in their\ntraining and in their regular flight tasks. A demonstration video is available\non https://www.youtube.com/watch?v=eePhjd2qNiI",
    "descriptor": "",
    "authors": [
      "Alexandre Duval",
      "Anita Paas",
      "Abdalwhab Abdalwhab",
      "David St-Onge"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.14910"
  },
  {
    "id": "arXiv:2210.14913",
    "title": "AltUB: Alternating Training Method to Update Base Distribution of  Normalizing Flow for Anomaly Detection",
    "abstract": "Unsupervised anomaly detection is coming into the spotlight these days in\nvarious practical domains due to the limited amount of anomaly data. One of the\nmajor approaches for it is a normalizing flow which pursues the invertible\ntransformation of a complex distribution as images into an easy distribution as\nN(0, I). In fact, algorithms based on normalizing flow like FastFlow and\nCFLOW-AD establish state-of-the-art performance on unsupervised anomaly\ndetection tasks. Nevertheless, we investigate these algorithms convert normal\nimages into not N(0, I) as their destination, but an arbitrary normal\ndistribution. Moreover, their performances are often unstable, which is highly\ncritical for unsupervised tasks because data for validation are not provided.\nTo break through these observations, we propose a simple solution AltUB which\nintroduces alternating training to update the base distribution of normalizing\nflow for anomaly detection. AltUB effectively improves the stability of\nperformance of normalizing flow. Furthermore, our method achieves the new\nstate-of-the-art performance of the anomaly segmentation task on the MVTec AD\ndataset with 98.8% AUROC.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yeongmin Kim",
      "Huiwon Jang",
      "DongKeon Lee",
      "Ho-Jin Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14913"
  },
  {
    "id": "arXiv:2210.14914",
    "title": "Multi-Viewpoint and Multi-Evaluation with Felicitous Inductive Bias  Boost Machine Abstract Reasoning Ability",
    "abstract": "Great endeavors have been made to study AI's ability in abstract reasoning,\nalong with which different versions of RAVEN's progressive matrices (RPM) are\nproposed as benchmarks. Previous works give inkling that without sophisticated\ndesign or extra meta-data containing semantic information, neural networks may\nstill be indecisive in making decisions regarding RPM problems, after\nrelentless training. Evidenced by thorough experiments and ablation studies, we\nshowcase that end-to-end neural networks embodied with felicitous inductive\nbias, intentionally design or serendipitously match, can solve RPM problems\nelegantly, without the augment of any extra meta-data or preferences of any\nspecific backbone. Our work also reveals that multi-viewpoint with\nmulti-evaluation is a key learning strategy for successful reasoning. Finally,\npotential explanations for the failure of connectionist models in\ngeneralization are provided. We hope that these results will serve as\ninspections of AI's ability beyond perception and toward abstract reasoning.\nSource code can be found in https://github.com/QinglaiWeiCASIA/RavenSolver.",
    "descriptor": "",
    "authors": [
      "Qinglai Wei",
      "Diancheng Chen",
      "Beiming Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14914"
  },
  {
    "id": "arXiv:2210.14944",
    "title": "Detection and Prevention Against Poisoning Attacks in Federated Learning",
    "abstract": "This paper proposes and investigates a new approach for detecting and\npreventing several different types of poisoning attacks from affecting a\ncentralized Federated Learning model via average accuracy deviation detection\n(AADD). By comparing each client's accuracy to all clients' average accuracy,\nAADD detect clients with an accuracy deviation. The implementation is further\nable to blacklist clients that are considered poisoned, securing the global\nmodel from being affected by the poisoned nodes. The proposed implementation\nshows promising results in detecting poisoned clients and preventing the global\nmodel's accuracy from deteriorating.",
    "descriptor": "",
    "authors": [
      "Viktor Valadi",
      "Madeleine Englund",
      "Mark Spanier",
      "Austin O'brien"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14944"
  },
  {
    "id": "arXiv:2210.14948",
    "title": "kube-volttron: Rearchitecting the VOLTTRON Building Energy Management  System for Cloud Native Deployment",
    "abstract": "Managing the energy consumption of the built environment is an important\nsource of flexible load and decarbonization, enabling building managers and\nutilities to schedule consumption to avoid costly demand charges and peak times\nwhen carbon emissions from grid generated electricity are highest. A key\ntechnology component in building energy management is the building energy\nmanagement system. Eclipse VOLTTRON is a legacy software platform which enables\nbuilding energy management. It was developed for the US Department of Energy\n(DOE) at Pacific Northwest National Labs (PNNL) written in Python and based on\na monolithic build-configure-and-run-in-place system architecture that predates\ncloud native architectural concepts. Yet the software architecture is\ncomponentized in a way that anticipates modular containerized applications,\nwith software agents handling functions like data storage, web access, and\ncommunication with IoT devices over specific IoT protocols such as BACnet and\nModbus. The agents communicate among themselves over a message bus. This paper\ndescribes a proof-of-concept prototype to rearchitect VOLTTRON into a\ncollection of microservices suitable for deployment on the Kubernetes cloud\nnative container orchestration platform. The agents are packaged in\nredistributable containers that perform specific functions and which can be\nconfigured when they are deployed. The deployment architecture consists of\nsingle Kubernetes cluster containing a central node, nominally in a cloud-based\nVM, where a microservice containing the database agent (called a \"historian\")\nand the web site agent for the service run, and gateway nodes running on sites\nin buildings where a microservice containing IoT protocol-specific agents\nhandles control and data collection to and from devices, and communication back\nto the central node.",
    "descriptor": "",
    "authors": [
      "James Kempf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.14948"
  },
  {
    "id": "arXiv:2210.14951",
    "title": "TraVaS: Differentially Private Trace Variant Selection for Process  Mining",
    "abstract": "In the area of industrial process mining, privacy-preserving event data\npublication is becoming increasingly relevant. Consequently, the trade-off\nbetween high data utility and quantifiable privacy poses new challenges.\nState-of-the-art research mainly focuses on differentially private trace\nvariant construction based on prefix expansion methods. However, these\nalgorithms face several practical limitations such as high computational\ncomplexity, introducing fake variants, removing frequent variants, and a\nbounded variant length. In this paper, we introduce a new approach for direct\ndifferentially private trace variant release which uses anonymized\n\\textit{partition selection} strategies to overcome the aforementioned\nrestraints. Experimental results on real-life event data show that our\nalgorithm outperforms state-of-the-art methods in terms of both plain data\nutility and result utility preservation.",
    "descriptor": "",
    "authors": [
      "Majid Rafiei",
      "Frederik Wangelik",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.14951"
  },
  {
    "id": "arXiv:2210.14956",
    "title": "A new Stack Autoencoder: Neighbouring Sample Envelope Embedded Stack  Autoencoder Ensemble Model",
    "abstract": "Stack autoencoder (SAE), as a representative deep network, has unique and\nexcellent performance in feature learning, and has received extensive attention\nfrom researchers. However, existing deep SAEs focus on original samples without\nconsidering the hierarchical structural information between samples. To address\nthis limitation, this paper proposes a new SAE model-neighbouring envelope\nembedded stack autoencoder ensemble (NE_ESAE). Firstly, the neighbouring sample\nenvelope learning mechanism (NSELM) is proposed for preprocessing of input of\nSAE. NSELM constructs sample pairs by combining neighbouring samples. Besides,\nthe NSELM constructs a multilayer sample spaces by multilayer iterative mean\nclustering, which considers the similar samples and generates layers of\nenvelope samples with hierarchical structural information. Second, an embedded\nstack autoencoder (ESAE) is proposed and trained in each layer of sample space\nto consider the original samples during training and in the network structure,\nthereby better finding the relationship between original feature samples and\ndeep feature samples. Third, feature reduction and base classifiers are\nconducted on the layers of envelope samples respectively, and output\nclassification results of every layer of samples. Finally, the classification\nresults of the layers of envelope sample space are fused through the ensemble\nmechanism. In the experimental section, the proposed algorithm is validated\nwith over ten representative public datasets. The results show that our method\nsignificantly has better performance than existing traditional feature learning\nmethods and the representative deep autoencoders.",
    "descriptor": "\nComments: 17 pages,6 figures\n",
    "authors": [
      "Chuanyan Zhou",
      "Jie Ma",
      "Fan Li",
      "Yongming Li",
      "Pin Wang",
      "Xiaoheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14956"
  },
  {
    "id": "arXiv:2210.14957",
    "title": "Disentangled Text Representation Learning with Information-Theoretic  Perspective for Adversarial Robustness",
    "abstract": "Adversarial vulnerability remains a major obstacle to constructing reliable\nNLP systems. When imperceptible perturbations are added to raw input text, the\nperformance of a deep learning model may drop dramatically under attacks.\nRecent work argues the adversarial vulnerability of the model is caused by the\nnon-robust features in supervised training. Thus in this paper, we tackle the\nadversarial robustness challenge from the view of disentangled representation\nlearning, which is able to explicitly disentangle robust and non-robust\nfeatures in text. Specifically, inspired by the variation of information (VI)\nin information theory, we derive a disentangled learning objective composed of\nmutual information to represent both the semantic representativeness of latent\nembeddings and differentiation of robust and non-robust features. On the basis\nof this, we design a disentangled learning network to estimate these mutual\ninformation. Experiments on text classification and entailment tasks show that\nour method significantly outperforms the representative methods under\nadversarial attacks, indicating that discarding non-robust features is critical\nfor improving adversarial robustness.",
    "descriptor": "",
    "authors": [
      "Jiahao Zhao",
      "Wenji Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14957"
  },
  {
    "id": "arXiv:2210.14958",
    "title": "Constrained Approximate Similarity Search on Proximity Graph",
    "abstract": "Search engines and recommendation systems are built to efficiently display\nrelevant information from those massive amounts of candidates. Typically a\nthree-stage mechanism is employed in those systems: (i) a small collection of\nitems are first retrieved by (e.g.,) approximate near neighbor search\nalgorithms; (ii) then a collection of constraints are applied on the retrieved\nitems; (iii) a fine-grained ranking neural network is employed to determine the\nfinal recommendation. We observe a major defect of the original three-stage\npipeline: Although we only target to retrieve $k$ vectors in the final\nrecommendation, we have to preset a sufficiently large $s$ ($s > k$) for each\nquery, and ``hope'' the number of survived vectors after the filtering is not\nsmaller than $k$. That is, at least $k$ vectors in the $s$ similar candidates\nsatisfy the query constraints.\nIn this paper, we investigate this constrained similarity search problem and\nattempt to merge the similarity search stage and the filtering stage into one\nsingle search operation. We introduce AIRSHIP, a system that integrates a\nuser-defined function filtering into the similarity search framework. The\nproposed system does not need to build extra indices nor require prior\nknowledge of the query constraints. We propose three optimization strategies:\n(1) starting point selection, (2) multi-direction search, and (3) biased\npriority queue selection. Experimental evaluations on both synthetic and real\ndata confirm the effectiveness of the proposed AIRSHIP algorithm. We focus on\nconstrained graph-based approximate near neighbor (ANN) search in this study,\nin part because graph-based ANN is known to achieve excellent performance. We\nbelieve it is also possible to develop constrained hashing-based ANN or\nconstrained quantization-based ANN.",
    "descriptor": "",
    "authors": [
      "Weijie Zhao",
      "Shulong Tan",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.14958"
  },
  {
    "id": "arXiv:2210.14962",
    "title": "Identifying Diversity, Equity, Inclusion, and Accessibility (DEIA)  Indicators for Transportation Systems using Social Media Data: The Case of  New York City during Covid-19 Pandemic",
    "abstract": "The adoption of transportation policies that prioritized highway expansion\nover public transportation has disproportionately impacted minorities and\nlow-income people by restricting their access to social and economic\nopportunities and thus resulting in residential segregation. Policymakers,\ntransportation researchers, planners, and practitioners have started\nacknowledging the need to build a diverse, equitable, inclusive, and accessible\n(DEIA) transportation system. Traditionally, this has been done through\nsurvey-based approaches that are time-consuming and expensive. While there is\nrecent attention on leveraging social media data in transportation, the\nliterature is inconclusive regarding the use of social media data as a viable\nalternative to traditional sources to identify the latent DEIA indicators based\non public reactions and perspectives on social media. This study utilized\nlarge-scale Twitter data covering eight counties around the New York City (NYC)\narea during the initial phase of the Covid-19 lockdown to address this research\ngap. Natural language processing techniques were used to identify\ntransportation-related major DEIA issues for residents living around NYC by\nanalyzing their relevant tweet conversations. The study revealed that citizens,\nwho had negative sentiments toward the DEIA of their local transportation\nsystem, broadly discussed racism, income, unemployment, gender, ride\ndependency, transportation modes, and dependent groups. Analyzing the\nsocio-demographic information based on census tracts, the study also observed\nthat areas with a higher percentage of low-income, female, Hispanic, and Latino\npopulations share more concerns about transportation DEIA on Twitter.",
    "descriptor": "",
    "authors": [
      "Fariha Nazneen Rista",
      "Khondhaker Al Momin",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.14962"
  },
  {
    "id": "arXiv:2210.14966",
    "title": "What's Different between Visual Question Answering for Machine  \"Understanding\" Versus for Accessibility?",
    "abstract": "In visual question answering (VQA), a machine must answer a question given an\nassociated image. Recently, accessibility researchers have explored whether VQA\ncan be deployed in a real-world setting where users with visual impairments\nlearn about their environment by capturing their visual surroundings and asking\nquestions. However, most of the existing benchmarking datasets for VQA focus on\nmachine \"understanding\" and it remains unclear how progress on those datasets\ncorresponds to improvements in this real-world use case. We aim to answer this\nquestion by evaluating discrepancies between machine \"understanding\" datasets\n(VQA-v2) and accessibility datasets (VizWiz) by evaluating a variety of VQA\nmodels. Based on our findings, we discuss opportunities and challenges in VQA\nfor accessibility and suggest directions for future work.",
    "descriptor": "",
    "authors": [
      "Yang Trista Cao",
      "Kyle Seelman",
      "Kyungjun Lee",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14966"
  },
  {
    "id": "arXiv:2210.14970",
    "title": "Identifying Crisis Response Communities in Online Social Networks for  Compound Disasters: The Case of Hurricane Laura and Covid-19",
    "abstract": "Online social networks allow different agencies and the public to interact\nand share the underlying risks and protective actions during major disasters.\nThis study revealed such crisis communication patterns during hurricane Laura\ncompounded by the COVID-19 pandemic. Laura was one of the strongest (Category\n4) hurricanes on record to make landfall in Cameron, Louisiana. Using the\nApplication Programming Interface (API), this study utilizes large-scale social\nmedia data obtained from Twitter through the recently released academic track\nthat provides complete and unbiased observations. The data captured publicly\navailable tweets shared by active Twitter users from the vulnerable areas\nthreatened by Laura. Online social networks were based on user influence\nfeature ( mentions or tags) that allows notifying other users while posting a\ntweet. Using network science theories and advanced community detection\nalgorithms, the study split these networks into twenty-one components of\nvarious sizes, the largest of which contained eight well-defined communities.\nSeveral natural language processing techniques (i.e., word clouds, bigrams,\ntopic modeling) were applied to the tweets shared by the users in these\ncommunities to observe their risk-taking or risk-averse behavior during a major\ncompounding crisis. Social media accounts of local news media, radio,\nuniversities, and popular sports pages were among those who involved heavily\nand interacted closely with local residents. In contrast, emergency management\nand planning units in the area engaged less with the public. The findings of\nthis study provide novel insights into the design of efficient social media\ncommunication guidelines to respond better in future disasters.",
    "descriptor": "",
    "authors": [
      "Khondhaker Al Momin",
      "H M Imran Kays",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.14970"
  },
  {
    "id": "arXiv:2210.14972",
    "title": "Environment Design for Inverse Reinforcement Learning",
    "abstract": "The task of learning a reward function from expert demonstrations suffers\nfrom high sample complexity as well as inherent limitations to what can be\nlearned from demonstrations in a given environment. As the samples used for\nreward learning require human input, which is generally expensive, much effort\nhas been dedicated towards designing more sample-efficient algorithms.\nMoreover, even with abundant data, current methods can still fail to learn\ninsightful reward functions that are robust to minor changes in the environment\ndynamics. We approach these challenges differently than prior work by improving\nthe sample-efficiency as well as the robustness of learned rewards through\nadaptively designing a sequence of demonstration environments for the expert to\nact in. We formalise a framework for this environment design process in which\nlearner and expert repeatedly interact, and construct algorithms that actively\nseek information about the rewards by carefully curating environments for the\nhuman to demonstrate the task in.",
    "descriptor": "",
    "authors": [
      "Thomas Kleine Buening",
      "Christos Dimitrakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14972"
  },
  {
    "id": "arXiv:2210.14975",
    "title": "MABEL: Attenuating Gender Bias using Textual Entailment Data",
    "abstract": "Pre-trained language models encode undesirable social biases, which are\nfurther exacerbated in downstream use. To this end, we propose MABEL (a Method\nfor Attenuating Gender Bias using Entailment Labels), an intermediate\npre-training approach for mitigating gender bias in contextualized\nrepresentations. Key to our approach is the use of a contrastive learning\nobjective on counterfactually augmented, gender-balanced entailment pairs from\nnatural language inference (NLI) datasets. We also introduce an alignment\nregularizer that pulls identical entailment pairs along opposite gender\ndirections closer. We extensively evaluate our approach on intrinsic and\nextrinsic metrics, and show that MABEL outperforms previous task-agnostic\ndebiasing approaches in terms of fairness. It also preserves task performance\nafter fine-tuning on downstream tasks. Together, these findings demonstrate the\nsuitability of NLI data as an effective means of bias mitigation, as opposed to\nonly using unlabeled sentences in the literature. Finally, we identify that\nexisting approaches often use evaluation settings that are insufficient or\ninconsistent. We make an effort to reproduce and compare previous methods, and\ncall for unifying the evaluation settings across gender debiasing methods for\nbetter future comparison.",
    "descriptor": "\nComments: Accepted to EMNLP 2022. Code and models are publicly available at this https URL\n",
    "authors": [
      "Jacqueline He",
      "Mengzhou Xia",
      "Christiane Fellbaum",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14975"
  },
  {
    "id": "arXiv:2210.14977",
    "title": "Knowledge Transfer For On-Device Speech Emotion Recognition with Neural  Structured Learning",
    "abstract": "Speech emotion recognition (SER) has been a popular research topic in\nhuman-computer interaction (HCI). As edge devices are rapidly springing up,\napplying SER to edge devices is promising for a huge number of HCI\napplications. Although deep learning has been investigated to improve the\nperformance of SER by training complex models, the memory space and\ncomputational capability of edge devices represents a constraint for embedding\ndeep learning models. We propose a neural structured learning (NSL) framework\nthrough building synthesized graphs. An SER model is trained on a source\ndataset and used to build graphs on a target dataset. A lightweight model is\nthen trained with the speech samples and graphs together as the input. Our\nexperiments demonstrate that training a lightweight SER model on the target\ndataset with speech samples and graphs can not only produce small SER models,\nbut also enhance the model performance over models with speech samples only.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yi Chang",
      "Zhao Ren",
      "Thanh Tam Nguyen",
      "Kun Qian",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.14977"
  },
  {
    "id": "arXiv:2210.14979",
    "title": "Robust Domain Adaptation for Pre-trained Multilingual Neural Machine  Translation Models",
    "abstract": "Recent literature has demonstrated the potential of multilingual Neural\nMachine Translation (mNMT) models. However, the most efficient models are not\nwell suited to specialized industries. In these cases, internal data is scarce\nand expensive to find in all language pairs. Therefore, fine-tuning a mNMT\nmodel on a specialized domain is hard. In this context, we decided to focus on\na new task: Domain Adaptation of a pre-trained mNMT model on a single pair of\nlanguage while trying to maintain model quality on generic domain data for all\nlanguage pairs. The risk of loss on generic domain and on other pairs is high.\nThis task is key for mNMT model adoption in the industry and is at the border\nof many others. We propose a fine-tuning procedure for the generic mNMT that\ncombines embeddings freezing and adversarial loss. Our experiments demonstrated\nthat the procedure improves performances on specialized data with a minimal\nloss in initial performances on generic domain for all languages pairs,\ncompared to a naive standard approach (+10.0 BLEU score on specialized data,\n-0.01 to -0.5 BLEU on WMT and Tatoeba datasets on the other pairs with M2M100).",
    "descriptor": "\nComments: Accepted by EMNLP 2022 MMNLU Workshop\n",
    "authors": [
      "Mathieu Grosso",
      "Pirashanth Ratnamogan",
      "Alexis Mathey",
      "William Vanhuffel",
      "Michael Fotso Fotso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14979"
  },
  {
    "id": "arXiv:2210.14981",
    "title": "Fast and Efficient Scene Categorization for Autonomous Driving using  VAEs",
    "abstract": "Scene categorization is a useful precursor task that provides prior knowledge\nfor many advanced computer vision tasks with a broad range of applications in\ncontent-based image indexing and retrieval systems. Despite the success of data\ndriven approaches in the field of computer vision such as object detection,\nsemantic segmentation, etc., their application in learning high-level features\nfor scene recognition has not achieved the same level of success. We propose to\ngenerate a fast and efficient intermediate interpretable generalized global\ndescriptor that captures coarse features from the image and use a\nclassification head to map the descriptors to 3 scene categories: Rural, Urban\nand Suburban. We train a Variational Autoencoder in an unsupervised manner and\nmap images to a constrained multi-dimensional latent space and use the latent\nvectors as compact embeddings that serve as global descriptors for images. The\nexperimental results evidence that the VAE latent vectors capture coarse\ninformation from the image, supporting their usage as global descriptors. The\nproposed global descriptor is very compact with an embedding length of 128,\nsignificantly faster to compute, and is robust to seasonal and illuminational\nchanges, while capturing sufficient scene information required for scene\ncategorization.",
    "descriptor": "\nComments: Published in the 24th Irish Machine Vision and Image Processing Conference (IMVIP 2022)\n",
    "authors": [
      "Saravanabalagi Ramachandran",
      "Jonathan Horgan",
      "Ganesh Sistu",
      "John McDonald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14981"
  },
  {
    "id": "arXiv:2210.14984",
    "title": "The Global Care Ecosystems of 3D Printed Assistive Devices",
    "abstract": "The popularity of 3D printed assistive technology has led to the emergence of\nnew ecosystems of care, where multiple stakeholders (makers, clinicians, and\nrecipients with disabilities) work toward creating new upper limb prosthetic\ndevices. However, despite the increasing growth, we currently know little about\nthe differences between these care ecosystems. Medical regulations and the\nprevailing culture have greatly impacted how ecosystems are structured and\nstakeholders work together, including whether clinicians and makers\ncollaborate. To better understand these care ecosystems, we interviewed a range\nof stakeholders from multiple countries, including Brazil, Chile, Costa Rica,\nFrance, India, Mexico, and the U.S. Our broad analysis allowed us to uncover\ndifferent working examples of how multiple stakeholders collaborate within\nthese care ecosystems and the main challenges they face. Through our study, we\nwere able to uncover that the ecosystems with multi-stakeholder collaborations\nexist (something prior work had not seen), and these ecosystems showed\nincreased success and impact. We also identified some of the key follow-up\npractices to reduce device abandonment. Of particular importance are to have\necosystems put in place follow up practices that integrate formal agreements\nand compensations for participation (which do not need to be just monetary). We\nidentified that these features helped to ensure multi-stakeholder involvement\nand ecosystem sustainability. We finished the paper with socio-technical\nrecommendations to create vibrant care ecosystems that include multiple\nstakeholders in the production of 3D printed assistive devices.",
    "descriptor": "",
    "authors": [
      "Saiph Savage",
      "Claudia Flores-Saviaga",
      "Rachel Rodney",
      "Liliana Savage",
      "Jon Schull",
      "Jennifer Mankoff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.14984"
  },
  {
    "id": "arXiv:2210.14985",
    "title": "Learning Deep Sensorimotor Policies for Vision-based Autonomous Drone  Racing",
    "abstract": "Autonomous drones can operate in remote and unstructured environments,\nenabling various real-world applications. However, the lack of effective\nvision-based algorithms has been a stumbling block to achieving this goal.\nExisting systems often require hand-engineered components for state estimation,\nplanning, and control. Such a sequential design involves laborious tuning,\nhuman heuristics, and compounding delays and errors. This paper tackles the\nvision-based autonomous-drone-racing problem by learning deep sensorimotor\npolicies. We use contrastive learning to extract robust feature representations\nfrom the input images and leverage a two-stage learning-by-cheating framework\nfor training a neural network policy. The resulting policy directly infers\ncontrol commands with feature representations learned from raw images, forgoing\nthe need for globally-consistent state estimation, trajectory planning, and\nhandcrafted control design. Our experimental results indicate that our\nvision-based policy can achieve the same level of racing performance as the\nstate-based policy while being robust against different visual disturbances and\ndistractors. We believe this work serves as a stepping-stone toward developing\nintelligent vision-based autonomous systems that control the drone purely from\nimage inputs, like human pilots.",
    "descriptor": "",
    "authors": [
      "Jiawei Fu",
      "Yunlong Song",
      "Yan Wu",
      "Fisher Yu",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14985"
  },
  {
    "id": "arXiv:2210.14986",
    "title": "Large language models are not zero-shot communicators",
    "abstract": "Despite widespread use of LLMs as conversational agents, evaluations of\nperformance fail to capture a crucial aspect of communication: interpreting\nlanguage in context. Humans interpret language using beliefs and prior\nknowledge about the world. For example, we intuitively understand the response\n\"I wore gloves\" to the question \"Did you leave fingerprints?\" as meaning \"No\".\nTo investigate whether LLMs have the ability to make this type of inference,\nknown as an implicature, we design a simple task and evaluate widely used\nstate-of-the-art models. We find that, despite only evaluating on utterances\nthat require a binary inference (yes or no), most perform close to random.\nModels adapted to be \"aligned with human intent\" perform much better, but still\nshow a significant gap with human performance. We present our findings as the\nstarting point for further research into evaluating how LLMs interpret language\nin context and to drive the development of more pragmatic and useful models of\nhuman discourse.",
    "descriptor": "",
    "authors": [
      "Laura Ruis",
      "Akbir Khan",
      "Stella Biderman",
      "Sara Hooker",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14986"
  },
  {
    "id": "arXiv:2210.14991",
    "title": "Reachability Verification Based Reliability Assessment for Deep  Reinforcement Learning Controlled Robotics and Autonomous Systems",
    "abstract": "Deep Reinforcement Learning (DRL) has achieved impressive performance in\nrobotics and autonomous systems (RASs). A key impediment to its deployment in\nreal-life operations is the spuriously unsafe DRL policies--unexplored states\nmay lead the agent to make wrong decisions that may cause hazards, especially\nin applications where end-to-end controllers of the RAS were trained by DRL. In\nthis paper, we propose a novel quantitative reliability assessment framework\nfor DRL-controlled RASs, leveraging verification evidence generated from formal\nreliability analysis of neural networks. A two-level verification framework is\nintroduced to check the safety property with respect to inaccurate observations\nthat are due to, e.g., environmental noises and state changes. Reachability\nverification tools are leveraged at the local level to generate safety evidence\nof trajectories, while at the global level, we quantify the overall reliability\nas an aggregated metric of local safety evidence, according to an operational\nprofile. The effectiveness of the proposed verification framework is\ndemonstrated and validated via experiments on real RASs.",
    "descriptor": "\nComments: Submitted, under review\n",
    "authors": [
      "Yi Dong",
      "Xingyu Zhao",
      "Sen Wang",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14991"
  },
  {
    "id": "arXiv:2210.14993",
    "title": "Annotating Privacy Policies in the Sharing Economy",
    "abstract": "Applications (apps) of the Digital Sharing Economy (DSE), such as Uber,\nAirbnb, and TaskRabbit, have become a main enabler of economic growth and\nshared prosperity in modern-day societies. However, the complex exchange of\ngoods, services, and data that takes place over these apps frequently puts\ntheir end-users' privacy at risk. Privacy policies of DSE apps are provided to\ndisclose how private user data is being collected and handled. However, in\nreality, such policies are verbose and difficult to understand, leaving DSE\nusers vulnerable to privacy intrusive practices. To address these concerns, in\nthis paper, we propose an automated approach for annotating privacy policies in\nthe DSE market. Our approach identifies data collection claims in these\npolicies and maps them to the quality features of their apps. Visual and\ntextual annotations are then used to further explain and justify these claims.\nThe proposed approach is evaluated with 18 DSE app users. The results show that\nannotating privacy policies can significantly enhance their comprehensibility\nto the average DSE user. Our findings are intended to help DSE app developers\nto draft more comprehensible privacy policies as well as help their end-users\nto make more informed decisions in one of the fastest growing software\necosystems in the world.",
    "descriptor": "",
    "authors": [
      "Fahimeh Ebrahimi",
      "Miroslav Tushev",
      "Anas Mahmoud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.14993"
  },
  {
    "id": "arXiv:2210.14997",
    "title": "LiDAR-guided object search and detection in Subterranean Environments",
    "abstract": "Detecting objects of interest, such as human survivors, safety equipment, and\nstructure access points, is critical to any search-and-rescue operation. Robots\ndeployed for such time-sensitive efforts rely on their onboard sensors to\nperform their designated tasks. However, as disaster response operations are\npredominantly conducted under perceptually degraded conditions, commonly\nutilized sensors such as visual cameras and LiDARs suffer in terms of\nperformance degradation. In response, this work presents a method that utilizes\nthe complementary nature of vision and depth sensors to leverage multi-modal\ninformation to aid object detection at longer distances. In particular, depth\nand intensity values from sparse LiDAR returns are used to generate proposals\nfor objects present in the environment. These proposals are then utilized by a\nPan-Tilt-Zoom (PTZ) camera system to perform a directed search by adjusting its\npose and zoom level for performing object detection and classification in\ndifficult environments. The proposed work has been thoroughly verified using an\nANYmal quadruped robot in underground settings and on datasets collected during\nthe DARPA Subterranean Challenge finals.",
    "descriptor": "\nComments: 6 pages, 5 Figures, 2 Tables, conference: IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR-2022), Seville, Spain\n",
    "authors": [
      "Manthan Patel",
      "Gabriel Waibel",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14997"
  },
  {
    "id": "arXiv:2210.14998",
    "title": "One Arrow, Two Kills: An Unified Framework for Achieving Optimal Regret  Guarantees in Sleeping Bandits",
    "abstract": "We address the problem of \\emph{`Internal Regret'} in \\emph{Sleeping Bandits}\nin the fully adversarial setup, as well as draw connections between different\nexisting notions of sleeping regrets in the multiarmed bandits (MAB) literature\nand consequently analyze the implications: Our first contribution is to propose\nthe new notion of \\emph{Internal Regret} for sleeping MAB. We then proposed an\nalgorithm that yields sublinear regret in that measure, even for a completely\nadversarial sequence of losses and availabilities. We further show that a low\nsleeping internal regret always implies a low external regret, and as well as a\nlow policy regret for iid sequence of losses. The main contribution of this\nwork precisely lies in unifying different notions of existing regret in\nsleeping bandits and understand the implication of one to another. Finally, we\nalso extend our results to the setting of \\emph{Dueling Bandits} (DB)--a\npreference feedback variant of MAB, and proposed a reduction to MAB idea to\ndesign a low regret algorithm for sleeping dueling bandits with stochastic\npreferences and adversarial availabilities. The efficacy of our algorithms is\njustified through empirical evaluations.",
    "descriptor": "",
    "authors": [
      "Pierre Gaillard",
      "Aadirupa Saha",
      "Soham Dan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14998"
  },
  {
    "id": "arXiv:2210.14999",
    "title": "EIPSIM: Modeling Secure IP Address Allocation at Cloud Scale",
    "abstract": "Public clouds provide impressive capability through resource sharing.\nHowever, recent works have shown that the reuse of IP addresses can allow\nadversaries to exploit the latent configurations left by previous tenants. In\nthis work, we perform a comprehensive analysis of the effect of cloud IP\naddress allocation on exploitation of latent configuration. We first develop a\nstatistical model of cloud tenant behavior and latent configuration based on\nliterature and deployed systems. Through these, we analyze IP allocation\npolicies under existing and novel threat models. Our resulting framework,\nEIPSim, simulates our models in representative public cloud scenarios,\nevaluating adversarial objectives against pool policies. In response to our\nstronger proposed threat model, we also propose IP scan segmentation, an IP\nallocation policy that protects the IP pool against adversarial scanning even\nwhen an adversary is not limited by number of cloud tenants. Our evaluation\nshows that IP scan segmentation reduces latent configuration exploitability by\n97.1% compared to policies proposed in literature and 99.8% compared to those\ncurrently deployed by cloud providers. Finally, we evaluate our statistical\nassumptions by analyzing real allocation and configuration data, showing that\nresults generalize to deployed cloud workloads. In this way, we show that\nprincipled analysis of cloud IP address allocation can lead to substantial\nsecurity gains for tenants and their users.",
    "descriptor": "",
    "authors": [
      "Eric Pauley",
      "Kyle Domico",
      "Blaine Hoak",
      "Ryan Sheatsley",
      "Quinn Burke",
      "Yohan Beugin",
      "Patrick McDaniel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.14999"
  },
  {
    "id": "arXiv:2210.15000",
    "title": "Trade-off between reconstruction loss and feature alignment for domain  generalization",
    "abstract": "Domain generalization (DG) is a branch of transfer learning that aims to\ntrain the learning models on several seen domains and subsequently apply these\npre-trained models to other unseen (unknown but related) domains. To deal with\nchallenging settings in DG where both data and label of the unseen domain are\nnot available at training time, the most common approach is to design the\nclassifiers based on the domain-invariant representation features, i.e., the\nlatent representations that are unchanged and transferable between domains.\nContrary to popular belief, we show that designing classifiers based on\ninvariant representation features alone is necessary but insufficient in DG.\nOur analysis indicates the necessity of imposing a constraint on the\nreconstruction loss induced by representation functions to preserve most of the\nrelevant information about the label in the latent space. More importantly, we\npoint out the trade-off between minimizing the reconstruction loss and\nachieving domain alignment in DG. Our theoretical results motivate a new DG\nframework that jointly optimizes the reconstruction loss and the domain\ndiscrepancy. Both theoretical and numerical results are provided to justify our\napproach.",
    "descriptor": "\nComments: 13 pages, 2 tables\n",
    "authors": [
      "Thuan Nguyen",
      "Boyang Lyu",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15000"
  },
  {
    "id": "arXiv:2210.15009",
    "title": "Hypergraph Artificial Benchmark for Community Detection (h-ABCD)",
    "abstract": "The Artificial Benchmark for Community Detection (ABCD) graph is a recently\nintroduced random graph model with community structure and power-law\ndistribution for both degrees and community sizes. The model generates graphs\nwith similar properties as the well-known LFR one, and its main parameter can\nbe tuned to mimic its counterpart in the LFR model, the mixing parameter. In\nthis paper, we introduce hypergraph counterpart of the ABCD model, h-ABCD,\nwhich produces random hypergraph with distributions of ground-truth community\nsizes and degrees following power-law. As in the original ABCD, the new model\nh-ABCD can produce hypergraphs with various levels of noise. More importantly,\nthe model is flexible and can mimic any desired level of homogeneity of\nhyperedges that fall into one community. As a result, it can be used as a\nsuitable, synthetic playground for analyzing and tuning hypergraph community\ndetection algorithms.",
    "descriptor": "\nComments: 18 pages, 6 figures, 2 tables\n",
    "authors": [
      "Bogumi\u0142 Kami\u0144ski",
      "Pawe\u0142 Pra\u0142at",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.15009"
  },
  {
    "id": "arXiv:2210.15010",
    "title": "On the Role of Risk Perceptions in Cyber Insurance Contracts",
    "abstract": "Risk perceptions are essential in cyber insurance contracts. With the recent\nsurge of information, human risk perceptions are exposed to the influences from\nboth beneficial knowledge and fake news. In this paper, we study the role of\nthe risk perceptions of the insurer and the user in cyber insurance contracts.\nWe formulate the cyber insurance problem into a principal-agent problem where\nthe insurer designs the contract containing a premium payment and a coverage\nplan. The risk perceptions of the insurer and the user are captured by coherent\nrisk measures. Our framework extends the cyber insurance problem containing a\nrisk-neutral insurer and a possibly risk-averse user, which is often considered\nin the literature. The explicit characterizations of both the insurer's and the\nuser's risk perceptions allow us to show that cyber insurance has the potential\nto incentivize the user to invest more on system protection. This possibility\nto increase cyber security relies on the facts that the insurer is more\nrisk-averse than the user (in a minimization setting) and that the insurer's\nrisk perception is more sensitive to the changes in the user's actions than the\nuser himself. We investigate the properties of feasible contracts in a case\nstudy on the insurance of a computer system against ransomware.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Shutian Liu",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.15010"
  },
  {
    "id": "arXiv:2210.15011",
    "title": "Using Deception in Markov Game to Understand Adversarial Behaviors  through a Capture-The-Flag Environment",
    "abstract": "Identifying the actual adversarial threat against a system vulnerability has\nbeen a long-standing challenge for cybersecurity research. To determine an\noptimal strategy for the defender, game-theoretic based decision models have\nbeen widely used to simulate the real-world attacker-defender scenarios while\ntaking the defender's constraints into consideration. In this work, we focus on\nunderstanding human attacker behaviors in order to optimize the defender's\nstrategy. To achieve this goal, we model attacker-defender engagements as\nMarkov Games and search for their Bayesian Stackelberg Equilibrium. We validate\nour modeling approach and report our empirical findings using a\nCapture-The-Flag (CTF) setup, and we conduct user studies on adversaries with\nvarying skill-levels. Our studies show that application-level deceptions are an\noptimal mitigation strategy against targeted attacks -- outperforming classic\ncyber-defensive maneuvers, such as patching or blocking network requests. We\nuse this result to further hypothesize over the attacker's behaviors when\ntrapped in an embedded honeypot environment and present a detailed analysis of\nthe same.",
    "descriptor": "\nComments: Accepted at GameSec 2022\n",
    "authors": [
      "Siddhant Bhambri",
      "Purv Chauhan",
      "Frederico Araujo",
      "Adam Doup\u00e9",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15011"
  },
  {
    "id": "arXiv:2210.15014",
    "title": "Counting Perfect Matchings in Dense Graphs Is Hard",
    "abstract": "We show that the problem of counting perfect matchings remains #P-complete\neven if we restrict the input to very dense graphs, proving the conjecture in\n[5]. Here \"dense graphs\" refer to bipartite graphs of bipartite independence\nnumber $\\leq 2$, or general graphs of independence number $\\leq 2$. Our proof\nis by reduction from counting perfect matchings in bipartite graphs, via\nelementary linear algebra tricks and graph constructions.",
    "descriptor": "",
    "authors": [
      "Nicolas El Maalouly",
      "Yanheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.15014"
  },
  {
    "id": "arXiv:2210.15016",
    "title": "TPU-MLIR: A Compiler For TPU Using MLIR",
    "abstract": "Multi-level intermediate representations (MLIR) show great promise for\nreducing the cost of building domain-specific compilers by providing a reusable\nand extensible compiler infrastructure. This work presents TPU-MLIR, an\nend-to-end compiler based on MLIR that deploys pre-trained neural network (NN)\nmodels to a custom ASIC called a Tensor Processing Unit (TPU). TPU-MLIR defines\ntwo new dialects to implement its functionality: 1. a Tensor operation (TOP)\ndialect that encodes the deep learning graph semantics and independent of the\ndeep learning framework and 2. a TPU kernel dialect to provide a standard\nkernel computation on TPU. A NN model is translated to the TOP dialect and then\nlowered to the TPU dialect for different TPUs according to the chip's\nconfiguration. We demonstrate how to use the MLIR pass pipeline to organize and\nperform optimization on TPU to generate machine code. The paper also presents a\nverification procedure to ensure the correctness of each transform stage.",
    "descriptor": "\nComments: A way to design AI Compiler for ASIC chips by MLIR\n",
    "authors": [
      "Pengchao Hu",
      "Man Lu",
      "Lei Wang",
      "Guoyue Jiang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15016"
  },
  {
    "id": "arXiv:2210.15017",
    "title": "Accountable Safety for Rollups",
    "abstract": "Accountability, the ability to provably identify protocol violators, gained\nprominence as the main economic argument for the security of proof-of-stake\n(PoS) protocols. Rollups, the most popular scaling solution for blockchains,\ntypically use PoS protocols as their parent chain. We define accountability for\nrollups, and present an attack that shows the absence of accountability on\nexisting designs. We provide an accountable rollup design and prove its\nsecurity, both for the traditional `enshrined' rollups and for sovereign\nrollups, an emergent alternative built on lazy blockchains, tasked only with\nordering and availability of the rollup data.",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Ertem Nusret Tas",
      "John Adler",
      "Mustafa Al-Bassam",
      "Ismail Khoffi",
      "David Tse",
      "Nima Vaziri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15017"
  },
  {
    "id": "arXiv:2210.15025",
    "title": "Addressing Heterogeneity in Federated Learning via Distributional  Transformation",
    "abstract": "Federated learning (FL) allows multiple clients to collaboratively train a\ndeep learning model. One major challenge of FL is when data distribution is\nheterogeneous, i.e., differs from one client to another. Existing personalized\nFL algorithms are only applicable to narrow cases, e.g., one or two data\nclasses per client, and therefore they do not satisfactorily address FL under\nvarying levels of data heterogeneity. In this paper, we propose a novel\nframework, called DisTrans, to improve FL performance (i.e., model accuracy)\nvia train and test-time distributional transformations along with a\ndouble-input-channel model structure. DisTrans works by optimizing\ndistributional offsets and models for each FL client to shift their data\ndistribution, and aggregates these offsets at the FL server to further improve\nperformance in case of distributional heterogeneity. Our evaluation on multiple\nbenchmark datasets shows that DisTrans outperforms state-of-the-art FL methods\nand data augmentation methods under various settings and different degrees of\nclient distributional heterogeneity.",
    "descriptor": "\nComments: In the Proceedings of European Conference on Computer Vision (ECCV), 2022\n",
    "authors": [
      "Haolin Yuan",
      "Bo Hui",
      "Yuchen Yang",
      "Philippe Burlina",
      "Neil Zhenqiang Gong",
      "Yinzhi Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15025"
  },
  {
    "id": "arXiv:2210.15027",
    "title": "A novel information gain-based approach for classification and  dimensionality reduction of hyperspectral images",
    "abstract": "Recently, the hyperspectral sensors have improved our ability to monitor the\nearth surface with high spectral resolution. However, the high dimensionality\nof spectral data brings challenges for the image processing. Consequently, the\ndimensionality reduction is a necessary step in order to reduce the\ncomputational complexity and increase the classification accuracy. In this\npaper, we propose a new filter approach based on information gain for\ndimensionality reduction and classification of hyperspectral images. A special\nstrategy based on hyperspectral bands selection is adopted to pick the most\ninformative bands and discard the irrelevant and noisy ones. The algorithm\nevaluates the relevancy of the bands based on the information gain function\nwith the support vector machine classifier. The proposed method is compared\nusing two benchmark hyperspectral datasets (Indiana, Pavia) with three\ncompeting methods. The comparison results showed that the information gain\nfilter approach outperforms the other methods on the tested datasets and could\nsignificantly reduce the computation cost while improving the classification\naccuracy. Keywords: Hyperspectral images; dimensionality reduction; information\ngain; classification accuracy.\nKeywords: Hyperspectral images; dimensionality reduction; information gain;\nclassification accuracy.",
    "descriptor": "",
    "authors": [
      "Asma Elmaizi",
      "Hasna Nhaila",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch",
      "Chafik Nacir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15027"
  },
  {
    "id": "arXiv:2210.15028",
    "title": "FaD-VLP: Fashion Vision-and-Language Pre-training towards Unified  Retrieval and Captioning",
    "abstract": "Multimodal tasks in the fashion domain have significant potential for\ne-commerce, but involve challenging vision-and-language learning problems -\ne.g., retrieving a fashion item given a reference image plus text feedback from\na user. Prior works on multimodal fashion tasks have either been limited by the\ndata in individual benchmarks, or have leveraged generic vision-and-language\npre-training but have not taken advantage of the characteristics of fashion\ndata. Additionally, these works have mainly been restricted to multimodal\nunderstanding tasks. To address these gaps, we make two key contributions.\nFirst, we propose a novel fashion-specific pre-training framework based on\nweakly-supervised triplets constructed from fashion image-text pairs. We show\nthe triplet-based tasks are an effective addition to standard multimodal\npre-training tasks. Second, we propose a flexible decoder-based model\narchitecture capable of both fashion retrieval and captioning tasks. Together,\nour model design and pre-training approach are competitive on a diverse set of\nfashion tasks, including cross-modal retrieval, image retrieval with text\nfeedback, image captioning, relative image captioning, and multimodal\ncategorization.",
    "descriptor": "\nComments: 14 pages, 4 figures. To appear at Conference on Empirical Methods in Natural Language Processing (EMNLP) 2022\n",
    "authors": [
      "Suvir Mirchandani",
      "Licheng Yu",
      "Mengjiao Wang",
      "Animesh Sinha",
      "Wenwen Jiang",
      "Tao Xiang",
      "Ning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15028"
  },
  {
    "id": "arXiv:2210.15030",
    "title": "A Hierarchical Approach to Conditional Random Fields for System Anomaly  Detection",
    "abstract": "Anomaly detection to recognize unusual events in large scale systems in a\ntime sensitive manner is critical in many industries, eg. bank fraud,\nenterprise systems, medical alerts, etc. Large-scale systems often grow in size\nand complexity over time, and anomaly detection algorithms need to adapt to\nchanging structures. A hierarchical approach takes advantage of the implicit\nrelationships in complex systems and localized context. The features in complex\nsystems may vary drastically in data distribution, capturing different aspects\nfrom multiple data sources, and when put together provide a more complete view\nof the system. In this paper, two datasets are considered, the 1st comprising\nof system metrics from machines running on a cloud service, and the 2nd of\napplication metrics from a distributed software system with inherent\nhierarchies and interconnections amongst its system nodes. Comparing\nalgorithms, across the changepoint based PELT algorithm, cognitive\nlearning-based Hierarchical Temporal Memory algorithms, Support Vector Machines\nand Conditional Random Fields provides a basis for proposing a Hierarchical\nGlobal-Local Conditional Random Field approach to accurately capture anomalies\nin complex systems, and across various features. Hierarchical algorithms can\nlearn both the intricacies of lower-level or specific features, and utilize\nthese in the global abstracted representation to detect anomalous patterns\nrobustly across multi-source feature data and distributed systems. A graphical\nnetwork analysis on complex systems can further fine-tune datasets to mine\nrelationships based on available features, which can benefit hierarchical\nmodels. Furthermore, hierarchical solutions can adapt well to changes at a\nlocalized level, learning on new data and changing environments when parts of a\nsystem are over-hauled, and translate these learnings to a global view of the\nsystem over time.",
    "descriptor": "\nComments: 8 pages, This paper was originally written in 2019\n",
    "authors": [
      "Srishti Mishra",
      "Tvarita Jain",
      "Dr. Dinkar Sitaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.15030"
  },
  {
    "id": "arXiv:2210.15031",
    "title": "Characterizing Datapoints via Second-Split Forgetting",
    "abstract": "Researchers investigating example hardness have increasingly focused on the\ndynamics by which neural networks learn and forget examples throughout\ntraining. Popular metrics derived from these dynamics include (i) the epoch at\nwhich examples are first correctly classified; (ii) the number of times their\npredictions flip during training; and (iii) whether their prediction flips if\nthey are held out. However, these metrics do not distinguish among examples\nthat are hard for distinct reasons, such as membership in a rare subpopulation,\nbeing mislabeled, or belonging to a complex subpopulation. In this paper, we\npropose $second$-$split$ $forgetting$ $time$ (SSFT), a complementary metric\nthat tracks the epoch (if any) after which an original training example is\nforgotten as the network is fine-tuned on a randomly held out partition of the\ndata. Across multiple benchmark datasets and modalities, we demonstrate that\n$mislabeled$ examples are forgotten quickly, and seemingly $rare$ examples are\nforgotten comparatively slowly. By contrast, metrics only considering the first\nsplit learning dynamics struggle to differentiate the two. At large learning\nrates, SSFT tends to be robust across architectures, optimizers, and random\nseeds. From a practical standpoint, the SSFT can (i) help to identify\nmislabeled samples, the removal of which improves generalization; and (ii)\nprovide insights about failure modes. Through theoretical analysis addressing\noverparameterized linear models, we provide insights into how the observed\nphenomena may arise. Code for reproducing our experiments can be found here:\nhttps://github.com/pratyushmaini/ssft",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Pratyush Maini",
      "Saurabh Garg",
      "Zachary C. Lipton",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15031"
  },
  {
    "id": "arXiv:2210.15034",
    "title": "InfoShape: Task-Based Neural Data Shaping via Mutual Information",
    "abstract": "The use of mutual information as a tool in private data sharing has remained\nan open challenge due to the difficulty of its estimation in practice. In this\npaper, we propose InfoShape, a task-based encoder that aims to remove\nunnecessary sensitive information from training data while maintaining enough\nrelevant information for a particular ML training task. We achieve this goal by\nutilizing mutual information estimators that are based on neural networks, in\norder to measure two performance metrics, privacy and utility. Using these\ntogether in a Lagrangian optimization, we train a separate neural network as a\nlossy encoder. We empirically show that InfoShape is capable of shaping the\nencoded samples to be informative for a specific downstream task while\neliminating unnecessary sensitive information. Moreover, we demonstrate that\nthe classification accuracy of downstream models has a meaningful connection\nwith our utility and privacy measures.",
    "descriptor": "\nComments: 5 pages, submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Homa Esfahanizadeh",
      "William Wu",
      "Manya Ghobadi",
      "Regina Barzilay",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15034"
  },
  {
    "id": "arXiv:2210.15037",
    "title": "Generalization Differences between End-to-End and Neuro-Symbolic  Vision-Language Reasoning Systems",
    "abstract": "For vision-and-language reasoning tasks, both fully connectionist, end-to-end\nmethods and hybrid, neuro-symbolic methods have achieved high in-distribution\nperformance. In which out-of-distribution settings does each paradigm excel? We\ninvestigate this question on both single-image and multi-image visual\nquestion-answering through four types of generalization tests: a novel\nsegment-combine test for multi-image queries, contrast set, compositional\ngeneralization, and cross-benchmark transfer. Vision-and-language end-to-end\ntrained systems exhibit sizeable performance drops across all these tests.\nNeuro-symbolic methods suffer even more on cross-benchmark transfer from GQA to\nVQA, but they show smaller accuracy drops on the other generalization tests and\ntheir performance quickly improves by few-shot training. Overall, our results\ndemonstrate the complementary benefits of these two paradigms, and emphasize\nthe importance of using a diverse suite of generalization tests to fully\ncharacterize model robustness to distribution shift.",
    "descriptor": "\nComments: Accepted by the Findings of EMNLP 2022\n",
    "authors": [
      "Wang Zhu",
      "Jesse Thomason",
      "Robin Jia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15037"
  },
  {
    "id": "arXiv:2210.15040",
    "title": "PERGAMO: Personalized 3D Garments from Monocular Video",
    "abstract": "Clothing plays a fundamental role in digital humans. Current approaches to\nanimate 3D garments are mostly based on realistic physics simulation, however,\nthey typically suffer from two main issues: high computational run-time cost,\nwhich hinders their development; and simulation-to-real gap, which impedes the\nsynthesis of specific real-world cloth samples. To circumvent both issues we\npropose PERGAMO, a data-driven approach to learn a deformable model for 3D\ngarments from monocular images. To this end, we first introduce a novel method\nto reconstruct the 3D geometry of garments from a single image, and use it to\nbuild a dataset of clothing from monocular videos. We use these 3D\nreconstructions to train a regression model that accurately predicts how the\ngarment deforms as a function of the underlying body pose. We show that our\nmethod is capable of producing garment animations that match the real-world\nbehaviour, and generalizes to unseen body motions extracted from motion capture\ndataset.",
    "descriptor": "\nComments: Published at Computer Graphics Forum (Proc. of ACM/SIGGRAPH SCA), 2022. Project website this http URL\n",
    "authors": [
      "Andr\u00e9s Casado-Elvira",
      "Marc Comino Trinidad",
      "Dan Casas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15040"
  },
  {
    "id": "arXiv:2210.15042",
    "title": "EW-Tune: A Framework for Privately Fine-Tuning Large Language Models  with Differential Privacy",
    "abstract": "Pre-trained Large Language Models (LLMs) are an integral part of modern AI\nthat have led to breakthrough performances in complex AI tasks. Major AI\ncompanies with expensive infrastructures are able to develop and train these\nlarge models with billions and millions of parameters from scratch. Third\nparties, researchers, and practitioners are increasingly adopting these\npre-trained models and fine-tuning them on their private data to accomplish\ntheir downstream AI tasks. However, it has been shown that an adversary can\nextract/reconstruct the exact training samples from these LLMs, which can lead\nto revealing personally identifiable information. The issue has raised deep\nconcerns about the privacy of LLMs. Differential privacy (DP) provides a\nrigorous framework that allows adding noise in the process of training or\nfine-tuning LLMs such that extracting the training data becomes infeasible\n(i.e., with a cryptographically small success probability). While the\ntheoretical privacy guarantees offered in most extant studies assume learning\nmodels from scratch through many training iterations in an asymptotic setting,\nthis assumption does not hold in fine-tuning scenarios in which the number of\ntraining iterations is significantly smaller. To address the gap, we present\n\\ewtune, a DP framework for fine-tuning LLMs based on Edgeworth accountant with\nfinite-sample privacy guarantees. Our results across four well-established\nnatural language understanding (NLU) tasks show that while \\ewtune~adds privacy\nguarantees to LLM fine-tuning process, it directly contributes to decreasing\nthe induced noise to up to 5.6\\% and improves the state-of-the-art LLMs\nperformance by up to 1.1\\% across all NLU tasks. We have open-sourced our\nimplementations for wide adoption and public testing purposes.",
    "descriptor": "\nComments: Accepted at IEEE ICDM Workshop on Machine Learning for Cybersecurity (MLC) 2022\n",
    "authors": [
      "Rouzbeh Behnia",
      "Mohamamdreza Ebrahimi",
      "Jason Pacheco",
      "balaji Padmanabhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15042"
  },
  {
    "id": "arXiv:2210.15043",
    "title": "Active Countermeasures for Email Fraud",
    "abstract": "As a major component of online crime, email-based fraud is a threat that\ncauses substantial economic losses every year. To counteract these scammers,\nvolunteers called scam-baiters play the roles of victims, reply to scammers,\nand try to waste their time and attention with long and unproductive\nconversations. To curb email fraud and magnify the effectiveness of\nscam-baiting, we developed and deployed an expandable scam-baiting mailserver\nthat can conduct scam-baiting activities automatically. We implemented three\nreply strategies using three different models and conducted a one-month-long\nexperiment during which we elicited 150 messages from 130 different scammers.\nWe compare the performance of each strategy at attracting and holding the\nattention of scammers, finding tradeoffs between human-written and\nautomatically-generated response strategies, and we release both our platform\nand a dataset containing conversations between our automatic scam-baiters and\nreal human scammers, to support future work in preventing online fraud.",
    "descriptor": "",
    "authors": [
      "Wentao Chen",
      "Fuzhou Wang",
      "Matthew Edwards"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.15043"
  },
  {
    "id": "arXiv:2210.15045",
    "title": "An Optimal Patrolling Strategy for Tree Networks",
    "abstract": "We settle a recent conjecture on a continuous patrolling game. In this\nzero-sum game, an Attacker chooses a time and place to attack a network for a\nfixed amount of time. A Patroller patrols the network with the aim of\nintercepting the attack with maximum probability. The conjecture asserts that a\nparticular patrolling strategy called the E-patrolling strategy is optimal for\nall tree networks. The conjecture was previously known to be true in a limited\nclass of special cases. The E-patrolling strategy has the advantage of being\nstraightforward to calculate and implement. We prove the conjecture by\npresenting $\\varepsilon$-optimal strategies for the Attacker which provide\nupper bounds for the value of the game that come arbitrarily close to the lower\nbound provided by the E-patrolling strategy.",
    "descriptor": "",
    "authors": [
      "Thomas Lidbetter",
      "Thuy Bui"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15045"
  },
  {
    "id": "arXiv:2210.15048",
    "title": "DyREx: Dynamic Query Representation for Extractive Question Answering",
    "abstract": "Extractive question answering (ExQA) is an essential task for Natural\nLanguage Processing. The dominant approach to ExQA is one that represents the\ninput sequence tokens (question and passage) with a pre-trained transformer,\nthen uses two learned query vectors to compute distributions over the start and\nend answer span positions. These query vectors lack the context of the inputs,\nwhich can be a bottleneck for the model performance. To address this problem,\nwe propose \\textit{DyREx}, a generalization of the \\textit{vanilla} approach\nwhere we dynamically compute query vectors given the input, using an attention\nmechanism through transformer layers. Empirical observations demonstrate that\nour approach consistently improves the performance over the standard one. The\ncode and accompanying files for running the experiments are available at\n\\url{https://github.com/urchade/DyReX}.",
    "descriptor": "\nComments: Accepted at \"2nd Workshop on Efficient Natural Language and Speech Processing (ENLSP-II)\" @ NeurIPS 2022\n",
    "authors": [
      "Urchade Zaratiana",
      "Niama El Khbir",
      "Dennis N\u00fa\u00f1ez",
      "Pierre Holat",
      "Nadi Tomeh",
      "Thierry Charnois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15048"
  },
  {
    "id": "arXiv:2210.15050",
    "title": "TILDE-Q: A Transformation Invariant Loss Function for Time-Series  Forecasting",
    "abstract": "Time-series forecasting has caught increasing attention in the AI research\nfield due to its importance in solving real-world problems across different\ndomains, such as energy, weather, traffic, and economy. As shown in various\ntypes of data, it has been a must-see issue to deal with drastic changes,\ntemporal patterns, and shapes in sequential data that previous models are weak\nin prediction. This is because most cases in time-series forecasting aim to\nminimize $L_p$ norm distances as loss functions, such as mean absolute error\n(MAE) or mean square error (MSE). These loss functions are vulnerable to not\nonly considering temporal dynamics modeling but also capturing the shape of\nsignals. In addition, these functions often make models misbehave and return\nuncorrelated results to the original time-series. To become an effective loss\nfunction, it has to be invariant to the set of distortions between two\ntime-series data instead of just comparing exact values. In this paper, we\npropose a novel loss function, called TILDE-Q (Transformation Invariant Loss\nfunction with Distance EQuilibrium), that not only considers the distortions in\namplitude and phase but also allows models to capture the shape of time-series\nsequences. In addition, TILDE-Q supports modeling periodic and non-periodic\ntemporal dynamics at the same time. We evaluate the effectiveness of TILDE-Q by\nconducting extensive experiments with respect to periodic and non-periodic\nconditions of data, from naive models to state-of-the-art models. The\nexperiment results indicate that the models trained with TILDE-Q outperform\nthose trained with other training metrics (e.g., MSE, dynamic time warping\n(DTW), temporal distortion index (TDI), and longest common subsequence (LCSS)).",
    "descriptor": "\nComments: 9 pages paper, 2 pages references, and 7 pages appendix. Submitted as conference paper to ICLR 2023\n",
    "authors": [
      "Hyunwook Lee",
      "Chunggi Lee",
      "Hongkyu Lim",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15050"
  },
  {
    "id": "arXiv:2210.15051",
    "title": "Federated Continual Learning to Detect Accounting Anomalies in Financial  Auditing",
    "abstract": "The International Standards on Auditing require auditors to collect\nreasonable assurance that financial statements are free of material\nmisstatement. At the same time, a central objective of Continuous Assurance is\nthe real-time assessment of digital accounting journal entries. Recently,\ndriven by the advances in artificial intelligence, Deep Learning techniques\nhave emerged in financial auditing to examine vast quantities of accounting\ndata. However, learning highly adaptive audit models in decentralised and\ndynamic settings remains challenging. It requires the study of data\ndistribution shifts over multiple clients and time periods. In this work, we\npropose a Federated Continual Learning framework enabling auditors to learn\naudit models from decentral clients continuously. We evaluate the framework's\nability to detect accounting anomalies in common scenarios of organizational\nactivity. Our empirical results, using real-world datasets and combined\nfederated continual learning strategies, demonstrate the learned model's\nability to detect anomalies in audit settings of data distribution shifts.",
    "descriptor": "\nComments: 6 pages (excl. appendix), 5 figures, 1 table, preprint version, currently under review\n",
    "authors": [
      "Marco Schreyer",
      "Hamed Hemati",
      "Damian Borth",
      "Miklos A. Vasarhelyi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15051"
  },
  {
    "id": "arXiv:2210.15055",
    "title": "Adaptive Model Learning of Neural Networks with UUB Stability for Robot  Dynamic Estimation",
    "abstract": "Since batch algorithms suffer from lack of proficiency in confronting model\nmismatches and disturbances, this contribution proposes an adaptive scheme\nbased on continuous Lyapunov function for online robot dynamic identification.\nThis paper suggests stable updating rules to drive neural networks inspiring\nfrom model reference adaptive paradigm. Network structure consists of three\nparallel self-driving neural networks which aim to estimate robot dynamic terms\nindividually. Lyapunov candidate is selected to construct energy surface for a\nconvex optimization framework. Learning rules are driven directly from Lyapunov\nfunctions to make the derivative negative. Finally, experimental results on\n3-DOF Phantom Omni Haptic device demonstrate efficiency of the proposed method.",
    "descriptor": "\nComments: 6 pages, 12 figures\n",
    "authors": [
      "Pedram Agand",
      "Mahdi Aliyari Shoorehdeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15055"
  },
  {
    "id": "arXiv:2210.15056",
    "title": "UnfoldML: Cost-Aware and Uncertainty-Based Dynamic 2D Prediction for  Multi-Stage Classification",
    "abstract": "Machine Learning (ML) research has focused on maximizing the accuracy of\npredictive tasks. ML models, however, are increasingly more complex, resource\nintensive, and costlier to deploy in resource-constrained environments. These\nissues are exacerbated for prediction tasks with sequential classification on\nprogressively transitioned stages with ''happens-before'' relation between\nthem.We argue that it is possible to ''unfold'' a monolithic single multi-class\nclassifier, typically trained for all stages using all data, into a series of\nsingle-stage classifiers. Each single-stage classifier can be cascaded\ngradually from cheaper to more expensive binary classifiers that are trained\nusing only the necessary data modalities or features required for that stage.\nUnfoldML is a cost-aware and uncertainty-based dynamic 2D prediction pipeline\nfor multi-stage classification that enables (1) navigation of the accuracy/cost\ntradeoff space, (2) reducing the spatio-temporal cost of inference by orders of\nmagnitude, and (3) early prediction on proceeding stages. UnfoldML achieves\norders of magnitude better cost in clinical settings, while detecting\nmulti-stage disease development in real time. It achieves within 0.1% accuracy\nfrom the highest-performing multi-class baseline, while saving close to 20X on\nspatio-temporal cost of inference and earlier (3.5hrs) disease onset\nprediction. We also show that UnfoldML generalizes to image classification,\nwhere it can predict different level of labels (from coarse to fine) given\ndifferent level of abstractions of a image, saving close to 5X cost with as\nlittle as 0.4% accuracy reduction.",
    "descriptor": "\nComments: To be published in NuerIPS'22\n",
    "authors": [
      "Yanbo Xu",
      "Alind Khare",
      "Glenn Matlin",
      "Monish Ramadoss",
      "Rishikesan Kamaleswaran",
      "Chao Zhang",
      "Alexey Tumanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15056"
  },
  {
    "id": "arXiv:2210.15059",
    "title": "Automated Reconstruction of 3D Open Surfaces from Sparse Point Clouds",
    "abstract": "Real-world 3D data may contain intricate details defined by salient surface\ngaps. Automated reconstruction of these open surfaces (e.g., non-watertight\nmeshes) is a challenging problem for environment synthesis in mixed reality\napplications. Current learning-based implicit techniques can achieve high\nfidelity on closed-surface reconstruction. However, their dependence on the\ndistinction between the inside and outside of a surface makes them incapable of\nreconstructing open surfaces. Recently, a new class of implicit functions have\nshown promise in reconstructing open surfaces by regressing an unsigned\ndistance field. Yet, these methods rely on a discretized representation of the\nraw data, which loses important surface details and can lead to outliers in the\nreconstruction. We propose IPVNet, a learning-based implicit model that\npredicts the unsigned distance between a surface and a query point in 3D space\nby leveraging both raw point cloud data and its discretized voxel counterpart.\nExperiments on synthetic and real-world public datasets demonstrates that\nIPVNet outperforms the state of the art while producing far fewer outliers in\nthe reconstruction.",
    "descriptor": "\nComments: To be presented at the 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR) Workshop on Photorealistic Image and Environment Synthesis for Mixed Reality (PIES-MR)\n",
    "authors": [
      "Mohammad Samiul Arshad",
      "William J. Beksi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15059"
  },
  {
    "id": "arXiv:2210.15063",
    "title": "Four-in-One: A Joint Approach to Inverse Text Normalization,  Punctuation, Capitalization, and Disfluency for Automatic Speech Recognition",
    "abstract": "Features such as punctuation, capitalization, and formatting of entities are\nimportant for readability, understanding, and natural language processing\ntasks. However, Automatic Speech Recognition (ASR) systems produce spoken-form\ntext devoid of formatting, and tagging approaches to formatting address just\none or two features at a time. In this paper, we unify spoken-to-written text\nconversion via a two-stage process: First, we use a single transformer tagging\nmodel to jointly produce token-level tags for inverse text normalization (ITN),\npunctuation, capitalization, and disfluencies. Then, we apply the tags to\ngenerate written-form text and use weighted finite state transducer (WFST)\ngrammars to format tagged ITN entity spans. Despite joining four models into\none, our unified tagging approach matches or outperforms task-specific models\nacross all four tasks on benchmark test sets across several domains.",
    "descriptor": "",
    "authors": [
      "Sharman Tan",
      "Piyush Behre",
      "Nick Kibre",
      "Issac Alphonso",
      "Shuangyu Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15063"
  },
  {
    "id": "arXiv:2210.15067",
    "title": "arXivEdits: Understanding the Human Revision Process in Scientific  Writing",
    "abstract": "Scientific publications are the primary means to communicate research\ndiscoveries, where the writing quality is of crucial importance. However, prior\nwork studying the human editing process in this domain mainly focused on the\nabstract or introduction sections, resulting in an incomplete picture. In this\nwork, we provide a complete computational framework for studying text revision\nin scientific writing. We first introduce arXivEdits, a new annotated corpus of\n751 full papers from arXiv with gold sentence alignment across their multiple\nversions of revision, as well as fine-grained span-level edits and their\nunderlying intentions for 1,000 sentence pairs. It supports our data-driven\nanalysis to unveil the common strategies practiced by researchers for revising\ntheir papers. To scale up the analysis, we also develop automatic methods to\nextract revision at document-, sentence-, and word-levels. A neural CRF\nsentence alignment model trained on our corpus achieves 93.8 F1, enabling the\nreliable matching of sentences between different versions. We formulate the\nedit extraction task as a span alignment problem, and our proposed method\nextracts more fine-grained and explainable edits, compared to the commonly used\ndiff algorithm. An intention classifier trained on our dataset achieves 78.9 F1\non the fine-grained intent classification task. Our data and system are\nreleased at tiny.one/arxivedits.",
    "descriptor": "\nComments: This paper has been accepted to EMNLP 2022\n",
    "authors": [
      "Chao Jiang",
      "Wei Xu",
      "Samuel Stevens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15067"
  },
  {
    "id": "arXiv:2210.15068",
    "title": "Improving Adversarial Robustness with Self-Paced Hard-Class Pair  Reweighting",
    "abstract": "Deep Neural Networks are vulnerable to adversarial attacks. Among many\ndefense strategies, adversarial training with untargeted attacks is one of the\nmost recognized methods. Theoretically, the predicted labels of untargeted\nattacks should be unpredictable and uniformly-distributed overall false\nclasses. However, we find that the naturally imbalanced inter-class semantic\nsimilarity makes those hard-class pairs to become the virtual targets of each\nother. This study investigates the impact of such closely-coupled classes on\nadversarial attacks and develops a self-paced reweighting strategy in\nadversarial training accordingly. Specifically, we propose to upweight\nhard-class pair loss in model optimization, which prompts learning\ndiscriminative features from hard classes. We further incorporate a term to\nquantify hard-class pair consistency in adversarial training, which greatly\nboost model robustness. Extensive experiments show that the proposed\nadversarial training method achieves superior robustness performance over\nstate-of-the-art defenses against a wide range of adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Pengyue Hou",
      "Jie Han",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15068"
  },
  {
    "id": "arXiv:2210.15072",
    "title": "Live Captions in Virtual Reality (VR)",
    "abstract": "Few VR applications and games implement captioning of speech and audio cues,\nwhich either inhibits or prevents access of their application by deaf or hard\nof hearing (DHH) users, new language learners, and other caption users.\nAdditionally, little to no guidelines exist on how to implement live captioning\non VR headsets and how it may differ from traditional television captioning. To\nhelp fill the void of information behind user preferences of different VR\ncaptioning styles, we conducted a study with eight DHH participants to test\nthree caption movement behaviors (headlocked, lag, and appear) while watching\nlive-captioned, single-speaker presentations in VR. Participants answered a\nseries of Likert scale and open-ended questions about their experience.\nParticipant preferences were split, but the majority of participants reported\nfeeling comfortable with using live captions in VR and enjoyed the experience.\nWhen participants ranked the caption behaviors, there was almost an equal\ndivide between the three types tested. IPQ results indicated each behavior had\nsimilar immersion ratings, however participants found headlocked and lag\ncaptions more user-friendly than appear captions. We suggest that participants\nmay vary in caption preference depending on how they use captions, and that\nproviding opportunities for caption customization is best.",
    "descriptor": "",
    "authors": [
      "Pranav Pidathala",
      "Dawson Franz",
      "James Waller",
      "Raja Kushalnagar",
      "Christian Vogler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15072"
  },
  {
    "id": "arXiv:2210.15075",
    "title": "IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised  Medical Image Segmentation",
    "abstract": "Due to the scarcity of labeled data, Contrastive Self-Supervised Learning\n(SSL) frameworks have lately shown great potential in several medical image\nanalysis tasks. However, the existing contrastive mechanisms are sub-optimal\nfor dense pixel-level segmentation tasks due to their inability to mine local\nfeatures. To this end, we extend the concept of metric learning to the\nsegmentation task, using a dense (dis)similarity learning for pre-training a\ndeep encoder network, and employing a semi-supervised paradigm to fine-tune for\nthe downstream task. Specifically, we propose a simple convolutional projection\nhead for obtaining dense pixel-level features, and a new contrastive loss to\nutilize these dense projections thereby improving the local representations. A\nbidirectional consistency regularization mechanism involving two-stream model\ntraining is devised for the downstream task. Upon comparison, our IDEAL method\noutperforms the SoTA methods by fair margins on cardiac MRI segmentation.",
    "descriptor": "",
    "authors": [
      "Hritam Basak",
      "Soumitri Chattopadhyay",
      "Rohit Kundu",
      "Sayan Nag",
      "Rammohan Mallipeddi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15075"
  },
  {
    "id": "arXiv:2210.15078",
    "title": "Age of Information in Downlink Systems: Broadcast or Distributed  Transmission?",
    "abstract": "We analytically decide whether the broadcast transmission scheme or the\ndistributed transmission scheme achieves the optimal age of information (AoI)\nperformance of a multiuser system where a base station (BS) generates and\ntransmits status updates to multiple user equipments (UEs). In the broadcast\ntransmission scheme, the status update for all UEs is jointly encoded into a\npacket for transmission, while in the distributed transmission scheme, the\nstatus update for each UE is encoded individually and transmitted by following\nthe round robin policy. For both transmission schemes, we examine three packet\nmanagement strategies, namely the non-preemption strategy, the preemption in\nbuffer strategy, and the preemption in serving strategy. We first derive new\nclosed-form expressions for the average AoI achieved by two transmission\nschemes with three packet management strategies. Based on them, we compare the\nAoI performance of two transmission schemes in two systems, namely, the remote\ncontrol system and the dynamic system. Aided by simulation results, we verify\nour analysis and investigate the impact of system parameters on the average\nAoI. For example, the distributed transmission scheme is more appropriate for\nthe system with a large number UEs. Otherwise, the broadcast transmission\nscheme is more appropriate.",
    "descriptor": "",
    "authors": [
      "Zhifeng Tang",
      "Nan Yang",
      "Parastoo Sadeghi",
      "Xiangyun Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15078"
  },
  {
    "id": "arXiv:2210.15079",
    "title": "The Inconvenient Truths of Ground Truth for Binary Analysis",
    "abstract": "The effectiveness of binary analysis tools and techniques is often measured\nwith respect to how well they map to a ground truth. We have found that not all\nground truths are created equal. This paper challenges the binary analysis\ncommunity to take a long look at the concept of ground truth, to ensure that we\nare in agreement with definition(s) of ground truth, so that we can be\nconfident in the evaluation of tools and techniques. This becomes even more\nimportant as we move to trained machine learning models, which are only as\nuseful as the validity of the ground truth in the training.",
    "descriptor": "",
    "authors": [
      "Jim Alves-Foss",
      "Varsah Venugopal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15079"
  },
  {
    "id": "arXiv:2210.15082",
    "title": "A Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid  Dynamical Systems",
    "abstract": "This paper proposes a rapidly-exploring random trees (RRT) algorithm to solve\nthe motion planning problem for hybrid systems. At each iteration, the proposed\nalgorithm, called HyRRT, randomly picks a state sample and extends the search\ntree by flow or jump, which is also chosen randomly when both regimes are\npossible. Through a definition of concatenation of functions defined on hybrid\ntime domains, we show that HyRRT is probabilistically complete, namely, the\nprobability of failing to find a motion plan approaches zero as the number of\niterations of the algorithm increases. This property is guaranteed under mild\nconditions on the data defining the motion plan, which include a relaxation of\nthe usual positive clearance assumption imposed in the literature of classical\nsystems. The motion plan is computed through the solution of two optimization\nproblems, one associated with the flow and the other with the jumps of the\nsystem. The proposed algorithm is applied to a walking robot so as to highlight\nits generality and computational features.",
    "descriptor": "\nComments: This paper has been accepted for publication at the 2022 Conference of Decision and Control (CDC)\n",
    "authors": [
      "Nan Wang",
      "Ricardo G. Sanfelice"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15082"
  },
  {
    "id": "arXiv:2210.15085",
    "title": "Robot to Human Object Handover using Vision and Joint Torque Sensor  Modalities",
    "abstract": "We present a robot-to-human object handover algorithm and implement it on a\n7-DOF arm equipped with a 3-finger mechanical hand. The system performs a fully\nautonomous and robust object handover to a human receiver in real-time. Our\nalgorithm relies on two complementary sensor modalities: joint torque sensors\non the arm and an eye-in-hand RGB-D camera for sensor feedback. Our approach is\nentirely implicit, i.e., there is no explicit communication between the robot\nand the human receiver. Information obtained via the aforementioned sensor\nmodalities is used as inputs to their related deep neural networks. While the\ntorque sensor network detects the human receiver's \"intention\" such as: pull,\nhold, or bump, the vision sensor network detects if the receiver's fingers have\nwrapped around the object. Networks' outputs are then fused, based on which a\ndecision is made to either release the object or not. Despite substantive\nchallenges in sensor feedback synchronization, object, and human hand\ndetection, our system achieves robust robot-to-human handover with 98\\%\naccuracy in our preliminary real experiments using human receivers.",
    "descriptor": "\nComments: Note: This paper is submitted to RITA 2022 conference and waiting for results\n",
    "authors": [
      "Mohammadhadi Mohandes",
      "Behnam Moradi",
      "Kamal Gupta",
      "Mehran Mehrandezh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15085"
  },
  {
    "id": "arXiv:2210.15088",
    "title": "Personalized Dialogue Generation with Persona-Adaptive Attention",
    "abstract": "Persona-based dialogue systems aim to generate consistent responses based on\nhistorical context and predefined persona. Unlike conventional dialogue\ngeneration, the persona-based dialogue needs to consider both dialogue context\nand persona, posing a challenge for coherent training. Specifically, this\nrequires a delicate weight balance between context and persona. To achieve\nthat, in this paper, we propose an effective framework with Persona-Adaptive\nAttention (PAA), which adaptively integrates the weights from the persona and\ncontext information via our designed attention. In addition, a dynamic masking\nmechanism is applied to the PAA to not only drop redundant information in\ncontext and persona but also serve as a regularization mechanism to avoid\noverfitting. Experimental results demonstrate the superiority of the proposed\nPAA framework compared to the strong baselines in both automatic and human\nevaluation. Moreover, the proposed PAA approach can perform equivalently well\nin a low-resource regime compared to models trained in a full-data setting,\nwhich achieve a similar result with only 20% to 30% of data compared to the\nlarger models trained in the full-data setting. To fully exploit the\neffectiveness of our design, we designed several variants for handling the\nweighted information in different ways, showing the necessity and sufficiency\nof our weighting and masking designs.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Qiushi Huang",
      "Yu Zhang",
      "Tom Ko",
      "Xubo Liu",
      "Bo Wu",
      "Wenwu Wang",
      "Lilian Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15088"
  },
  {
    "id": "arXiv:2210.15091",
    "title": "Segmentation of Multiple Sclerosis Lesions across Hospitals: Learn  Continually or Train from Scratch?",
    "abstract": "Segmentation of Multiple Sclerosis (MS) lesions is a challenging problem.\nSeveral deep-learning-based methods have been proposed in recent years.\nHowever, most methods tend to be static, that is, a single model trained on a\nlarge, specialized dataset, which does not generalize well. Instead, the model\nshould learn across datasets arriving sequentially from different hospitals by\nbuilding upon the characteristics of lesions in a continual manner. In this\nregard, we explore experience replay, a well-known continual learning method,\nin the context of MS lesion segmentation across multi-contrast data from 8\ndifferent hospitals. Our experiments show that replay is able to achieve\npositive backward transfer and reduce catastrophic forgetting compared to\nsequential fine-tuning. Furthermore, replay outperforms the multi-domain\ntraining, thereby emerging as a promising solution for the segmentation of MS\nlesions. The code is available at this link:\nhttps://github.com/naga-karthik/continual-learning-ms",
    "descriptor": "\nComments: Accepted at the Medical Imaging Meets NeurIPS (MedNeurIPS) Workshop 2022\n",
    "authors": [
      "Enamundram Naga Karthik",
      "Anne Kerbrat",
      "Pierre Labauge",
      "Tobias Granberg",
      "Jason Talbott",
      "Daniel S. Reich",
      "Massimo Filippi",
      "Rohit Bakshi",
      "Virginie Callot",
      "Sarath Chandar",
      "Julien Cohen-Adad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15091"
  },
  {
    "id": "arXiv:2210.15092",
    "title": "Generalized Laplacian Regularized Framelet GCNs",
    "abstract": "This paper introduces a novel Framelet Graph approach based on p-Laplacian\nGNN. The proposed two models, named p-Laplacian undecimated framelet graph\nconvolution (pL-UFG) and generalized p-Laplacian undecimated framelet graph\nconvolution (pL-fUFG) inherit the nature of p-Laplacian with the expressive\npower of multi-resolution decomposition of graph signals. The empirical study\nhighlights the excellent performance of the pL-UFG and pL-fUFG in different\ngraph learning tasks including node classification and signal denoising.",
    "descriptor": "",
    "authors": [
      "Zhiqi Shao",
      "Andi Han",
      "Dai Shi",
      "Andrey Vasnev",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15092"
  },
  {
    "id": "arXiv:2210.15093",
    "title": "Predicting Visual Attention and Distraction During Visual Search Using  Convolutional Neural Networks",
    "abstract": "Most studies in computational modeling of visual attention encompass\ntask-free observation of images. Free-viewing saliency considers limited\nscenarios of daily life. Most visual activities are goal-oriented and demand a\ngreat amount of top-down attention control. Visual search task demands more\ntop-down control of attention, compared to free-viewing. In this paper, we\npresent two approaches to model visual attention and distraction of observers\nduring visual search. Our first approach adapts a light-weight free-viewing\nsaliency model to predict eye fixation density maps of human observers over\npixels of search images, using a two-stream convolutional encoder-decoder\nnetwork, trained and evaluated on COCO-Search18 dataset. This method predicts\nwhich locations are more distracting when searching for a particular target.\nOur network achieves good results on standard saliency metrics (AUC-Judd=0.95,\nAUC-Borji=0.85, sAUC=0.84, NSS=4.64, KLD=0.93, CC=0.72, SIM=0.54, and IG=2.59).\nOur second approach is object-based and predicts the distractor and target\nobjects during visual search. Distractors are all objects except the target\nthat observers fixate on during search. This method uses a Mask-RCNN\nsegmentation network pre-trained on MS-COCO and fine-tuned on COCO-Search18\ndataset. We release our segmentation annotations of targets and distractors in\nCOCO-Search18 for three target categories: bottle, bowl, and car. The average\nscores over the three categories are: F1-score=0.64, MAP(iou:0.5)=0.57,\nMAR(iou:0.5)=0.73. Our implementation code in Tensorflow is publicly available\nat https://github.com/ManooshSamiei/Distraction-Visual-Search .",
    "descriptor": "\nComments: 33 pages, 24 figures, 12 tables, this is a pre-print manuscript currently under review in Journal of Vision\n",
    "authors": [
      "Manoosh Samiei",
      "James J. Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.15093"
  },
  {
    "id": "arXiv:2210.15096",
    "title": "Towards customizable reinforcement learning agents: Enabling preference  specification through online vocabulary expansion",
    "abstract": "There is a growing interest in developing automated agents that can work\nalongside humans. In addition to completing the assigned task, such an agent\nwill undoubtedly be expected to behave in a manner that is preferred by the\nhuman. This requires the human to communicate their preferences to the agent.\nTo achieve this, the current approaches either require the users to specify the\nreward function or the preference is interactively learned from queries that\nask the user to compare trajectories. The former approach can be challenging if\nthe internal representation used by the agent is inscrutable to the human while\nthe latter is unnecessarily cumbersome for the user if their preference can be\nspecified more easily in symbolic terms. In this work, we propose PRESCA\n(PREference Specification through Concept Acquisition), a system that allows\nusers to specify their preferences in terms of concepts that they understand.\nPRESCA maintains a set of such concepts in a shared vocabulary. If the relevant\nconcept is not in the shared vocabulary, then it is learned. To make learning a\nnew concept more efficient, PRESCA leverages causal associations between the\ntarget concept and concepts that are already known. Additionally, the effort of\nlearning the new concept is amortized by adding the concept to the shared\nvocabulary for supporting preference specification in future interactions. We\nevaluate PRESCA by using it on a Minecraft environment and show that it can be\neffectively used to make the agent align with the user's preference.",
    "descriptor": "",
    "authors": [
      "Utkarsh Soni",
      "Sarath Sreedharan",
      "Mudit Verma",
      "Lin Guan",
      "Matthew Marquez",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15096"
  },
  {
    "id": "arXiv:2210.15097",
    "title": "Contrastive Decoding: Open-ended Text Generation as Optimization",
    "abstract": "Likelihood, although useful as a training loss, is a poor search objective\nfor guiding open-ended generation from language models (LMs). Existing\ngeneration algorithms must avoid both unlikely strings, which are incoherent,\nand highly likely ones, which are short and repetitive. We propose contrastive\ndecoding (CD), a more reliable search objective that returns the difference\nbetween likelihood under a large LM (called the expert, e.g. OPT-13b) and a\nsmall LM (called the amateur, e.g. OPT-125m). CD is inspired by the fact that\nthe failures of larger LMs are even more prevalent in smaller LMs, and that\nthis difference signals exactly which texts should be preferred. CD requires\nzero training, and produces higher quality text than decoding from the larger\nLM alone. It also generalizes across model types (OPT and GPT2) and\nsignificantly outperforms four strong decoding algorithms in automatic and\nhuman evaluations.",
    "descriptor": "",
    "authors": [
      "Xiang Lisa Li",
      "Ari Holtzman",
      "Daniel Fried",
      "Percy Liang",
      "Jason Eisner",
      "Tatsunori Hashimoto",
      "Luke Zettlemoyer",
      "Mike Lewis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15097"
  },
  {
    "id": "arXiv:2210.15098",
    "title": "Natural Language Syntax Complies with the Free-Energy Principle",
    "abstract": "Natural language syntax yields an unbounded array of hierarchically\nstructured expressions. We claim that these are used in the service of active\ninference in accord with the free-energy principle (FEP). While conceptual\nadvances alongside modelling and simulation work have attempted to connect\nspeech segmentation and linguistic communication with the FEP, we extend this\nprogram to the underlying computations responsible for generating syntactic\nobjects. We argue that recently proposed principles of economy in language\ndesign - such as \"minimal search\" criteria from theoretical syntax - adhere to\nthe FEP. This affords a greater degree of explanatory power to the FEP - with\nrespect to higher language functions - and offers linguistics a grounding in\nfirst principles with respect to computability. We show how both tree-geometric\ndepth and a Kolmogorov complexity estimate (recruiting a Lempel-Ziv compression\nalgorithm) can be used to accurately predict legal operations on syntactic\nworkspaces, directly in line with formulations of variational free energy\nminimization. This is used to motivate a general principle of language design\nthat we term Turing-Chomsky Compression (TCC). We use TCC to align concerns of\nlinguists with the normative account of self-organization furnished by the FEP,\nby marshalling evidence from theoretical linguistics and psycholinguistics to\nground core principles of efficient syntactic computation within active\ninference.",
    "descriptor": "",
    "authors": [
      "Elliot Murphy",
      "Emma Holmes",
      "Karl Friston"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15098"
  },
  {
    "id": "arXiv:2210.15099",
    "title": "Coordination with Humans via Strategy Matching",
    "abstract": "Human and robot partners increasingly need to work together to perform tasks\nas a team. Robots designed for such collaboration must reason about how their\ntask-completion strategies interplay with the behavior and skills of their\nhuman team members as they coordinate on achieving joint goals. Our goal in\nthis work is to develop a computational framework for robot adaptation to human\npartners in human-robot team collaborations. We first present an algorithm for\nautonomously recognizing available task-completion strategies by observing\nhuman-human teams performing a collaborative task. By transforming team actions\ninto low dimensional representations using hidden Markov models, we can\nidentify strategies without prior knowledge. Robot policies are learned on each\nof the identified strategies to construct a Mixture-of-Experts model that\nadapts to the task strategies of unseen human partners. We evaluate our model\non a collaborative cooking task using an Overcooked simulator. Results of an\nonline user study with 125 participants demonstrate that our framework improves\nthe task performance and collaborative fluency of human-agent teams, as\ncompared to state of the art reinforcement learning methods.",
    "descriptor": "\nComments: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Michelle Zhao",
      "Reid Simmons",
      "Henny Admoni"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15099"
  },
  {
    "id": "arXiv:2210.15103",
    "title": "Several classes of 0-APN power functions over $\\mathbb{F}_{2^n}$",
    "abstract": "Recently, the investigation of Partially APN functions has attracted a lot of\nattention. In this paper, with the help of resultant elimination and MAGMA, we\npropose several new infinite classes of 0-APN power functions over\n$\\mathbb{F}_{2^{n}}$. By the main result in [4], these $0$-APN power functions\nare CCZ-inequivalent to the known ones. Moreover, these infinite classes of\n0-APN power functions can explain some exponents for $1\\leq n\\leq11$ which are\nnot yet ``explained\" in the tables of Budaghyan et al. [3].",
    "descriptor": "",
    "authors": [
      "Tao Fu",
      "Haode Yan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15103"
  },
  {
    "id": "arXiv:2210.15104",
    "title": "TRScore: A Novel GPT-based Readability Scorer for ASR Segmentation and  Punctuation model evaluation and selection",
    "abstract": "Punctuation and Segmentation are key to readability in Automatic Speech\nRecognition (ASR), often evaluated using F1 scores that require high-quality\nhuman transcripts and do not reflect readability well. Human evaluation is\nexpensive, time-consuming, and suffers from large inter-observer variability,\nespecially in conversational speech devoid of strict grammatical structures.\nLarge pre-trained models capture a notion of grammatical structure. We present\nTRScore, a novel readability measure using the GPT model to evaluate different\nsegmentation and punctuation systems. We validate our approach with human\nexperts. Additionally, our approach enables quantitative assessment of text\npost-processing techniques such as capitalization, inverse text normalization\n(ITN), and disfluency on overall readability, which traditional word error rate\n(WER) and slot error rate (SER) metrics fail to capture. TRScore is strongly\ncorrelated to traditional F1 and human readability scores, with Pearson's\ncorrelation coefficients of 0.67 and 0.98, respectively. It also eliminates the\nneed for human transcriptions for model selection.",
    "descriptor": "",
    "authors": [
      "Piyush Behre",
      "Sharman Tan",
      "Amy Shah",
      "Harini Kesavamoorthy",
      "Shuangyu Chang",
      "Fei Zuo",
      "Chris Basoglu",
      "Sayan Pathak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15104"
  },
  {
    "id": "arXiv:2210.15107",
    "title": "Boosting Point Clouds Rendering via Radiance Mapping",
    "abstract": "Recent years we have witnessed rapid development in NeRF-based image\nrendering due to its high quality. However, point clouds rendering is somehow\nless explored. Compared to NeRF-based rendering which suffers from dense\nspatial sampling, point clouds rendering is naturally less computation\nintensive, which enables its deployment in mobile computing device. In this\nwork, we focus on boosting the image quality of point clouds rendering with a\ncompact model design. We first analyze the adaption of the volume rendering\nformulation on point clouds. Based on the analysis, we simplify the NeRF\nrepresentation to a spatial mapping function which only requires single\nevaluation per pixel. Further, motivated by ray marching, we rectify the the\nnoisy raw point clouds to the estimated intersection between rays and surfaces\nas queried coordinates, which could avoid spatial frequency collapse and\nneighbor point disturbance. Composed of rasterization, spatial mapping and the\nrefinement stages, our method achieves the state-of-the-art performance on\npoint clouds rendering, outperforming prior works by notable margins, with a\nsmaller model size. We obtain a PSNR of 31.74 on NeRF-Synthetic, 25.88 on\nScanNet and 30.81 on DTU. Code and data would be released soon.",
    "descriptor": "",
    "authors": [
      "Xiaoyang Huang",
      "Yi Zhang",
      "Bingbing Ni",
      "Teng Li",
      "Kai Chen",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15107"
  },
  {
    "id": "arXiv:2210.15109",
    "title": "Vetaverse: Technologies, Applications, and Visions toward the  Intersection of Metaverse, Vehicles, and Transportation Systems",
    "abstract": "Since 2021, the term \"Metaverse\" has been the most popular one, garnering a\nlot of interest. Because of its contained environment and built-in computing\nand networking capabilities, a modern car makes an intriguing location to host\nits own little metaverse. Additionally, the travellers don't have much to do to\npass the time while traveling, making them ideal customers for immersive\nservices. Vetaverse (Vehicular-Metaverse), which we define as the future\ncontinuum between vehicular industries and Metaverse, is envisioned as a\nblended immersive realm that scales up to cities and countries, as digital\ntwins of the intelligent Transportation Systems, referred to as \"TS-Metaverse\",\nas well as customized XR services inside each Individual Vehicle, referred to\nas \"IV-Metaverse\". The two subcategories serve fundamentally different\npurposes, namely long-term interconnection, maintenance, monitoring, and\nmanagement on scale for large transportation systems (TS), and personalized,\nprivate, and immersive infotainment services (IV). By outlining the framework\nof Vetaverse and examining important enabler technologies, we reveal this\nimpending trend. Additionally, we examine unresolved issues and potential\nroutes for future study while highlighting some intriguing Vetaverse services.",
    "descriptor": "\nComments: 24 pages, 17 figures\n",
    "authors": [
      "Pengyuan Zhou",
      "Jinjing Zhu",
      "Yiting Wang",
      "Yunfan Lu",
      "Zixiang Wei",
      "Haolin Shi",
      "Yuchen Ding",
      "Yu Gao",
      "Qinglong Huang",
      "Yan Shi",
      "Ahmad Alhilal",
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pan Hui",
      "Lin Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15109"
  },
  {
    "id": "arXiv:2210.15110",
    "title": "Masked Vision-Language Transformer in Fashion",
    "abstract": "We present a masked vision-language transformer (MVLT) for fashion-specific\nmulti-modal representation. Technically, we simply utilize vision transformer\narchitecture for replacing the BERT in the pre-training model, making MVLT the\nfirst end-to-end framework for the fashion domain. Besides, we designed masked\nimage reconstruction (MIR) for a fine-grained understanding of fashion. MVLT is\nan extensible and convenient architecture that admits raw multi-modal inputs\nwithout extra pre-processing models (e.g., ResNet), implicitly modeling the\nvision-language alignments. More importantly, MVLT can easily generalize to\nvarious matching and generative tasks. Experimental results show obvious\nimprovements in retrieval (rank@5: 17%) and recognition (accuracy: 3%) tasks\nover the Fashion-Gen 2018 winner Kaleido-BERT. Code is made available at\nhttps://github.com/GewelsJI/MVLT.",
    "descriptor": "\nComments: Accepted by Machine Intelligence Research (2023)\n",
    "authors": [
      "Ge-Peng Ji",
      "Mingcheng Zhuge",
      "Dehong Gao",
      "Deng-Ping Fan",
      "Christos Sakaridis",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15110"
  },
  {
    "id": "arXiv:2210.15111",
    "title": "MEET: Mobility-Enhanced Edge inTelligence for Smart and Green 6G  Networks",
    "abstract": "Edge intelligence is an emerging paradigm for real-time training and\ninference at the wireless edge, thus enabling mission-critical applications.\nAccordingly, base stations (BSs) and edge servers (ESs) need to be densely\ndeployed, leading to huge deployment and operation costs, in particular the\nenergy costs. In this article, we propose a new framework called\nMobility-Enhanced Edge inTelligence (MEET), which exploits the sensing,\ncommunication, computing, and self-powering capabilities of intelligent\nconnected vehicles for the smart and green 6G networks. Specifically, the\noperators can incorporate infrastructural vehicles as movable BSs or ESs, and\nschedule them in a more flexible way to align with the communication and\ncomputation traffic fluctuations. Meanwhile, the remaining compute resources of\nopportunistic vehicles are exploited for edge training and inference, where\nmobility can further enhance edge intelligence by bringing more compute\nresources, communication opportunities, and diverse data. In this way, the\ndeployment and operation costs are spread over the vastly available vehicles,\nso that the edge intelligence is realized cost-effectively and sustainably.\nFurthermore, these vehicles can be either powered by renewable energy to reduce\ncarbon emissions, or charged more flexibly during off-peak hours to cut\nelectricity bills.",
    "descriptor": "\nComments: This paper has been accepted by IEEE Communications Magazine\n",
    "authors": [
      "Yuxuan Sun",
      "Bowen Xie",
      "Sheng Zhou",
      "Zhisheng Niu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15111"
  },
  {
    "id": "arXiv:2210.15112",
    "title": "Deep Latent Mixture Model for Recommendation",
    "abstract": "Recent advances in neural networks have been successfully applied to many\ntasks in online recommendation applications. We propose a new framework called\ncone latent mixture model which makes use of hand-crafted state being able to\nfactor distinct dependencies among multiple related documents. Specifically, it\nuses discriminative optimization techniques in order to generate effective\nmulti-level knowledge bases, and uses online discriminative learning techniques\nin order to leverage these features. And for this joint model which uses\nconfidence estimates for each topic and is able to learn a discriminatively\ntrained jointly to automatically extracted salient features where\ndiscriminative training is only uses features and then is able to accurately\ntrained.",
    "descriptor": "",
    "authors": [
      "Jun Zhang",
      "Ping Li",
      "Wei Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15112"
  },
  {
    "id": "arXiv:2210.15114",
    "title": "Faster Linear Algebra for Distance Matrices",
    "abstract": "The distance matrix of a dataset $X$ of $n$ points with respect to a distance\nfunction $f$ represents all pairwise distances between points in $X$ induced by\n$f$. Due to their wide applicability, distance matrices and related families of\nmatrices have been the focus of many recent algorithmic works. We continue this\nline of research and take a broad view of algorithm design for distance\nmatrices with the goal of designing fast algorithms, which are specifically\ntailored for distance matrices, for fundamental linear algebraic primitives.\nOur results include efficient algorithms for computing matrix-vector products\nfor a wide class of distance matrices, such as the $\\ell_1$ metric for which we\nget a linear runtime, as well as an $\\Omega(n^2)$ lower bound for any algorithm\nwhich computes a matrix-vector product for the $\\ell_{\\infty}$ case, showing a\nseparation between the $\\ell_1$ and the $\\ell_{\\infty}$ metrics. Our upper\nbound results, in conjunction with recent works on the matrix-vector query\nmodel, have many further downstream applications, including the fastest\nalgorithm for computing a relative error low-rank approximation for the\ndistance matrix induced by $\\ell_1$ and $\\ell_2^2$ functions and the fastest\nalgorithm for computing an additive error low-rank approximation for the\n$\\ell_2$ metric, in addition to applications for fast matrix multiplication\namong others. We also give algorithms for constructing distance matrices and\nshow that one can construct an approximate $\\ell_2$ distance matrix in time\nfaster than the bound implied by the Johnson-Lindenstrauss lemma.",
    "descriptor": "\nComments: Selected as Oral for NeurIPS 2022\n",
    "authors": [
      "Piotr Indyk",
      "Sandeep Silwal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15114"
  },
  {
    "id": "arXiv:2210.15119",
    "title": "Light-weighted CNN-Attention based architecture for Hand Gesture  Recognition via ElectroMyography",
    "abstract": "Advancements in Biological Signal Processing (BSP) and Machine-Learning (ML)\nmodels have paved the path for development of novel immersive Human-Machine\nInterfaces (HMI). In this context, there has been a surge of significant\ninterest in Hand Gesture Recognition (HGR) utilizing Surface-Electromyogram\n(sEMG) signals. This is due to its unique potential for decoding wearable data\nto interpret human intent for immersion in Mixed Reality (MR) environments. To\nachieve the highest possible accuracy, complicated and heavy-weighted Deep\nNeural Networks (DNNs) are typically developed, which restricts their practical\napplication in low-power and resource-constrained wearable systems. In this\nwork, we propose a light-weighted hybrid architecture (HDCAM) based on\nConvolutional Neural Network (CNN) and attention mechanism to effectively\nextract local and global representations of the input. The proposed HDCAM model\nwith 58,441 parameters reached a new state-of-the-art (SOTA) performance with\n82.91% and 81.28% accuracy on window sizes of 300 ms and 200 ms for classifying\n17 hand gestures. The number of parameters to train the proposed HDCAM\narchitecture is 18.87 times less than its previous SOTA counterpart.",
    "descriptor": "",
    "authors": [
      "Soheil Zabihi",
      "Elahe Rahimian",
      "Amir Asif",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15119"
  },
  {
    "id": "arXiv:2210.15120",
    "title": "Federated Graph Representation Learning using Self-Supervision",
    "abstract": "Federated graph representation learning (FedGRL) brings the benefits of\ndistributed training to graph structured data while simultaneously addressing\nsome privacy and compliance concerns related to data curation. However, several\ninteresting real-world graph data characteristics viz. label deficiency and\ndownstream task heterogeneity are not taken into consideration in current\nFedGRL setups. In this paper, we consider a realistic and novel problem\nsetting, wherein cross-silo clients have access to vast amounts of unlabeled\ndata with limited or no labeled data and additionally have diverse downstream\nclass label domains. We then propose a novel FedGRL formulation based on model\ninterpolation where we aim to learn a shared global model that is optimized\ncollaboratively using a self-supervised objective and gets downstream task\nsupervision through local client models. We provide a specific instantiation of\nour general formulation using BGRL a SoTA self-supervised graph representation\nlearning method and we empirically verify its effectiveness through realistic\ncross-slio datasets: (1) we adapt the Twitch Gamer Network which naturally\nsimulates a cross-geo scenario and show that our formulation can provide\nconsistent and avg. 6.1% gains over traditional supervised federated learning\nobjectives and on avg. 1.7% gains compared to individual client specific\nself-supervised training and (2) we construct and introduce a new cross-silo\ndataset called Amazon Co-purchase Networks that have both the characteristics\nof the motivated problem setting. And, we witness on avg. 11.5% gains over\ntraditional supervised federated learning and on avg. 1.9% gains over\nindividually trained self-supervised models. Both experimental results point to\nthe effectiveness of our proposed formulation. Finally, both our novel problem\nsetting and dataset contributions provide new avenues for the research in\nFedGRL.",
    "descriptor": "\nComments: FedGraph'22 workshop (non archival) version. (this https URL)\n",
    "authors": [
      "Susheel Suresh",
      "Danny Godbout",
      "Arko Mukherjee",
      "Mayank Shrivastava",
      "Jennifer Neville",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15120"
  },
  {
    "id": "arXiv:2210.15121",
    "title": "Bootstrapping Human Optical Flow and Pose",
    "abstract": "We propose a bootstrapping framework to enhance human optical flow and pose.\nWe show that, for videos involving humans in scenes, we can improve both the\noptical flow and the pose estimation quality of humans by considering the two\ntasks at the same time. We enhance optical flow estimates by fine-tuning them\nto fit the human pose estimates and vice versa. In more detail, we optimize the\npose and optical flow networks to, at inference time, agree with each other. We\nshow that this results in state-of-the-art results on the Human 3.6M and 3D\nPoses in the Wild datasets, as well as a human-related subset of the Sintel\ndataset, both in terms of pose estimation accuracy and the optical flow\naccuracy at human joint locations. Code available at\nhttps://github.com/ubc-vision/bootstrapping-human-optical-flow-and-pose",
    "descriptor": "\nComments: Accepted at BMVC 2022. Supplementary qualitative results - this https URL\n",
    "authors": [
      "Aritro Roy Arko",
      "Kwang Moo Yi",
      "James J. Little"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15121"
  },
  {
    "id": "arXiv:2210.15125",
    "title": "ViT-CAT: Parallel Vision Transformers with Cross Attention Fusion for  Popularity Prediction in MEC Networks",
    "abstract": "Mobile Edge Caching (MEC) is a revolutionary technology for the Sixth\nGeneration (6G) of wireless networks with the promise to significantly reduce\nusers' latency via offering storage capacities at the edge of the network. The\nefficiency of the MEC network, however, critically depends on its ability to\ndynamically predict/update the storage of caching nodes with the top-K popular\ncontents. Conventional statistical caching schemes are not robust to the\ntime-variant nature of the underlying pattern of content requests, resulting in\na surge of interest in using Deep Neural Networks (DNNs) for time-series\npopularity prediction in MEC networks. However, existing DNN models within the\ncontext of MEC fail to simultaneously capture both temporal correlations of\nhistorical request patterns and the dependencies between multiple contents.\nThis necessitates an urgent quest to develop and design a new and innovative\npopularity prediction architecture to tackle this critical challenge. The paper\naddresses this gap by proposing a novel hybrid caching framework based on the\nattention mechanism. Referred to as the parallel Vision Transformers with Cross\nAttention (ViT-CAT) Fusion, the proposed architecture consists of two parallel\nViT networks, one for collecting temporal correlation, and the other for\ncapturing dependencies between different contents. Followed by a Cross\nAttention (CA) module as the Fusion Center (FC), the proposed ViT-CAT is\ncapable of learning the mutual information between temporal and spatial\ncorrelations, as well, resulting in improving the classification accuracy, and\ndecreasing the model's complexity about 8 times. Based on the simulation\nresults, the proposed ViT-CAT architecture outperforms its counterparts across\nthe classification accuracy, complexity, and cache-hit ratio.",
    "descriptor": "",
    "authors": [
      "Zohreh HajiAkhondi-Meybodi",
      "Arash Mohammadi",
      "Ming Hou",
      "Jamshid Abouei",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15125"
  },
  {
    "id": "arXiv:2210.15126",
    "title": "SWheg: A Wheel-Leg Transformable Robot With Minimalist Actuator  Realization",
    "abstract": "This article presents the design, implementation, and performance evaluation\nof SWheg, a novel modular wheel-leg transformable robot family with minimalist\nactuator realization. SWheg takes advantage of both wheeled and legged\nlocomotion by seamlessly integrating them on a single platform. In contrast to\nother designs that use multiple actuators, SWheg uses only one actuator to\ndrive the transformation of all the wheel-leg modules in sync. This means an\nN-legged SWheg robot requires only N+1 actuators, which can significantly\nreduce the cost and malfunction rate of the platform. The tendon-driven\nwheel-leg transformation mechanism based on a four-bar linkage can perform fast\nmorphology transitions between wheels and legs. We validated the design\nprinciple with two SWheg robots with four and six wheel-leg modules separately,\nnamely Quadrupedal SWheg and Hexapod SWheg. The design process, mechatronics\ninfrastructure, and the gait behavioral development of both platforms were\ndiscussed. The performance of the robot was evaluated in various scenarios,\nincluding driving and turning in wheeled mode, step crossing, irregular terrain\npassing, and stair climbing in legged mode. The comparison between these two\nplatforms was also discussed.",
    "descriptor": "",
    "authors": [
      "Cunxi Dai",
      "Xiaohan Liu",
      "Jianxiang Zhou",
      "Zhengtao Liu",
      "Zhenzhong Jia"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15126"
  },
  {
    "id": "arXiv:2210.15127",
    "title": "Rethinking the Reverse-engineering of Trojan Triggers",
    "abstract": "Deep Neural Networks are vulnerable to Trojan (or backdoor) attacks.\nReverse-engineering methods can reconstruct the trigger and thus identify\naffected models. Existing reverse-engineering methods only consider input space\nconstraints, e.g., trigger size in the input space. Expressly, they assume the\ntriggers are static patterns in the input space and fail to detect models with\nfeature space triggers such as image style transformations. We observe that\nboth input-space and feature-space Trojans are associated with feature space\nhyperplanes. Based on this observation, we design a novel reverse-engineering\nmethod that exploits the feature space constraint to reverse-engineer Trojan\ntriggers. Results on four datasets and seven different attacks demonstrate that\nour solution effectively defends both input-space and feature-space Trojans. It\noutperforms state-of-the-art reverse-engineering methods and other types of\ndefenses in both Trojaned model detection and mitigation tasks. On average, the\ndetection accuracy of our method is 93\\%. For Trojan mitigation, our method can\nreduce the ASR (attack success rate) to only 0.26\\% with the BA (benign\naccuracy) remaining nearly unchanged. Our code can be found at\nhttps://github.com/RU-System-Software-and-Security/FeatureRE.",
    "descriptor": "",
    "authors": [
      "Zhenting Wang",
      "Kai Mei",
      "Hailun Ding",
      "Juan Zhai",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15127"
  },
  {
    "id": "arXiv:2210.15128",
    "title": "MMFL-Net: Multi-scale and Multi-granularity Feature Learning for  Cross-domain Fashion Retrieval",
    "abstract": "Instance-level image retrieval in fashion is a challenging issue owing to its\nincreasing importance in real-scenario visual fashion search. Cross-domain\nfashion retrieval aims to match the unconstrained customer images as queries\nfor photographs provided by retailers; however, it is a difficult task due to a\nwide range of consumer-to-shop (C2S) domain discrepancies and also considering\nthat clothing image is vulnerable to various non-rigid deformations. To this\nend, we propose a novel multi-scale and multi-granularity feature learning\nnetwork (MMFL-Net), which can jointly learn global-local aggregation feature\nrepresentations of clothing images in a unified framework, aiming to train a\ncross-domain model for C2S fashion visual similarity. First, a new\nsemantic-spatial feature fusion part is designed to bridge the semantic-spatial\ngap by applying top-down and bottom-up bidirectional multi-scale feature\nfusion. Next, a multi-branch deep network architecture is introduced to capture\nglobal salient, part-informed, and local detailed information, and extracting\nrobust and discrimination feature embedding by integrating the similarity\nlearning of coarse-to-fine embedding with the multiple granularities. Finally,\nthe improved trihard loss, center loss, and multi-task classification loss are\nadopted for our MMFL-Net, which can jointly optimize intra-class and\ninter-class distance and thus explicitly improve intra-class compactness and\ninter-class discriminability between its visual representations for feature\nlearning. Furthermore, our proposed model also combines the multi-task\nattribute recognition and classification module with multi-label semantic\nattributes and product ID labels. Experimental results demonstrate that our\nproposed MMFL-Net achieves significant improvement over the state-of-the-art\nmethods on the two datasets, DeepFashion-C2S and Street2Shop.",
    "descriptor": "\nComments: 27 pages, 12 figures, Published by &lt;Multimedia Tools and Applications&gt;\n",
    "authors": [
      "Chen Bao",
      "Xudong Zhang",
      "Jiazhou Chen",
      "Yongwei Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15128"
  },
  {
    "id": "arXiv:2210.15130",
    "title": "A Unified Blockchain-Semantic Framework for Wireless Edge Intelligence  Enabled Web 3.0",
    "abstract": "Web 3.0 enables user-generated contents and user-selected authorities. With\ndecentralized wireless edge computing architectures, Web 3.0 allows users to\nread, write, and own contents. A core technology that enables Web 3.0 goals is\nblockchain, which provides security services by recording content in a\ndecentralized and transparent manner. However, the explosion of on-chain\nrecorded contents and the fast-growing number of users cause increasingly\nunaffordable computing and storage resource consumption. A promising paradigm\nis to analyze the semantic information of contents that can convey precisely\nthe desired meanings without consuming many resources. In this article, we\npropose a unified blockchain-semantic ecosystems framework for wireless edge\nintelligence-enabled Web 3.0. Our framework consists of six key components to\nexchange semantic demands. We then introduce an Oracle-based proof of semantic\nmechanism to implement on-chain and off-chain interactions of Web 3.0\necosystems on semantic verification algorithms while maintaining service\nsecurity. An adaptive Deep Reinforcement Learning-based sharding mechanism on\nOracle is designed to improve interaction efficiency, which can facilitate Web\n3.0 ecosystems to deal with varied semantic demands. Finally, a case study is\npresented to show that the proposed framework can dynamically adjust Oracle\nsettings according to varied semantic demands.",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table\n",
    "authors": [
      "Yijing Lin",
      "Zhipeng Gao",
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Ruilong Deng",
      "Xuemin Sherman Shen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.15130"
  },
  {
    "id": "arXiv:2210.15131",
    "title": "Towards High-Quality Neural TTS for Low-Resource Languages by Learning  Compact Speech Representations",
    "abstract": "This paper aims to enhance low-resource TTS by reducing training data\nrequirements using compact speech representations. A Multi-Stage Multi-Codebook\n(MSMC) VQ-GAN is trained to learn the representation, MSMCR, and decode it to\nwaveforms. Subsequently, we train the multi-stage predictor to predict MSMCRs\nfrom the text for TTS synthesis. Moreover, we optimize the training strategy by\nleveraging more audio to learn MSMCRs better for low-resource languages. It\nselects audio from other languages using speaker similarity metric to augment\nthe training set, and applies transfer learning to improve training quality. In\nMOS tests, the proposed system significantly outperforms FastSpeech and VITS in\nstandard and low-resource scenarios, showing lower data requirements. The\nproposed training strategy effectively enhances MSMCRs on waveform\nreconstruction. It improves TTS performance further, which wins 77% votes in\nthe preference test for the low-resource TTS with only 15 minutes of paired\ndata.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Haohan Guo",
      "Fenglong Xie",
      "Xixin Wu",
      "Hui Lu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15131"
  },
  {
    "id": "arXiv:2210.15132",
    "title": "Hybrid Indoor Localization via Reinforcement Learning-based Information  Fusion",
    "abstract": "The paper is motivated by the importance of the Smart Cities (SC) concept for\nfuture management of global urbanization. Among all Internet of Things\n(IoT)-based communication technologies, Bluetooth Low Energy (BLE) plays a\nvital role in city-wide decision making and services. Extreme fluctuations of\nthe Received Signal Strength Indicator (RSSI), however, prevent this technology\nfrom being a reliable solution with acceptable accuracy in the dynamic indoor\ntracking/localization approaches for ever-changing SC environments. The latest\nversion of the BLE v.5.1 introduced a better possibility for tracking users by\nutilizing the direction finding approaches based on the Angle of Arrival (AoA),\nwhich is more reliable. There are still some fundamental issues remaining to be\naddressed. Existing works mainly focus on implementing stand-alone models\noverlooking potentials fusion strategies. The paper addresses this gap and\nproposes a novel Reinforcement Learning (RL)-based information fusion framework\n(RL-IFF) by coupling AoA with RSSI-based particle filtering and Inertial\nMeasurement Unit (IMU)-based Pedestrian Dead Reckoning (PDR) frameworks. The\nproposed RL-IFF solution is evaluated through a comprehensive set of\nexperiments illustrating superior performance compared to its counterparts.",
    "descriptor": "",
    "authors": [
      "Mohammad Salimibeni",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15132"
  },
  {
    "id": "arXiv:2210.15133",
    "title": "Retrieval Oriented Masking Pre-training Language Model for Dense Passage  Retrieval",
    "abstract": "Pre-trained language model (PTM) has been shown to yield powerful text\nrepresentations for dense passage retrieval task. The Masked Language Modeling\n(MLM) is a major sub-task of the pre-training process. However, we found that\nthe conventional random masking strategy tend to select a large number of\ntokens that have limited effect on the passage retrieval task (e,g. stop-words\nand punctuation). By noticing the term importance weight can provide valuable\ninformation for passage retrieval, we hereby propose alternative retrieval\noriented masking (dubbed as ROM) strategy where more important tokens will have\na higher probability of being masked out, to capture this straightforward yet\nessential information to facilitate the language model pre-training process.\nNotably, the proposed new token masking method will not change the architecture\nand learning objective of original PTM. Our experiments verify that the\nproposed ROM enables term importance information to help language model\npre-training thus achieving better performance on multiple passage retrieval\nbenchmarks.",
    "descriptor": "\nComments: Search LM part of the \"AliceMind SLM + HLAR\" method in MS MARCO Passage Ranking Leaderboard Submission\n",
    "authors": [
      "Dingkun Long",
      "Yanzhao Zhang",
      "Guangwei Xu",
      "Pengjun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15133"
  },
  {
    "id": "arXiv:2210.15134",
    "title": "Learning Variational Motion Prior for Video-based Motion Capture",
    "abstract": "Motion capture from a monocular video is fundamental and crucial for us\nhumans to naturally experience and interact with each other in Virtual Reality\n(VR) and Augmented Reality (AR). However, existing methods still struggle with\nchallenging cases involving self-occlusion and complex poses due to the lack of\neffective motion prior modeling. In this paper, we present a novel variational\nmotion prior (VMP) learning approach for video-based motion capture to resolve\nthe above issue. Instead of directly building the correspondence between the\nvideo and motion domain, We propose to learn a generic latent space for\ncapturing the prior distribution of all natural motions, which serve as the\nbasis for subsequent video-based motion capture tasks. To improve the\ngeneralization capacity of prior space, we propose a transformer-based\nvariational autoencoder pretrained over marker-based 3D mocap data, with a\nnovel style-mapping block to boost the generation quality. Afterward, a\nseparate video encoder is attached to the pretrained motion generator for\nend-to-end fine-tuning over task-specific video datasets. Compared to existing\nmotion prior models, our VMP model serves as a motion rectifier that can\neffectively reduce temporal jittering and failure modes in frame-wise pose\nestimation, leading to temporally stable and visually realistic motion capture\nresults. Furthermore, our VMP-based framework models motion at sequence level\nand can directly generate motion clips in the forward pass, achieving real-time\nmotion capture during inference. Extensive experiments over both public\ndatasets and in-the-wild videos have demonstrated the efficacy and\ngeneralization capability of our framework.",
    "descriptor": "\nComments: 9 pages, 9 figures, IEEE VR 2023 submission\n",
    "authors": [
      "Xin Chen",
      "Zhuo Su",
      "Lingbo Yang",
      "Pei Cheng",
      "Lan Xu",
      "Bin Fu",
      "Gang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15134"
  },
  {
    "id": "arXiv:2210.15135",
    "title": "Training Autoregressive Speech Recognition Models with Limited in-domain  Supervision",
    "abstract": "Advances in self-supervised learning have significantly reduced the amount of\ntranscribed audio required for training. However, the majority of work in this\narea is focused on read speech. We explore limited supervision in the domain of\nconversational speech. While we assume the amount of in-domain data is limited,\nwe augment the model with open source read speech data. The XLS-R model has\nbeen shown to perform well with limited adaptation data and serves as a strong\nbaseline. We use untranscribed data for self-supervised learning and\nsemi-supervised training in an autoregressive encoder-decoder model. We\ndemonstrate that by using the XLS-R model for pseudotranscription, a much\nsmaller autoregressive model can outperform a finetuned XLS-R model when\ntranscribed in-domain data is limited, reducing WER by as much as 8% absolute.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Chak-Fai Li",
      "Francis Keith",
      "William Hartmann",
      "Matthew Snover"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15135"
  },
  {
    "id": "arXiv:2210.15136",
    "title": "3D Shape Knowledge Graph for Cross-domain and Cross-modal 3D Shape  Retrieval",
    "abstract": "With the development of 3D modeling and fabrication, 3D shape retrieval has\nbecome a hot topic. In recent years, several strategies have been put forth to\naddress this retrieval issue. However, it is difficult for them to handle\ncross-modal 3D shape retrieval because of the natural differences between\nmodalities. In this paper, we propose an innovative concept, namely, geometric\nwords, which is regarded as the basic element to represent any 3D or 2D entity\nby combination, and assisted by which, we can simultaneously handle\ncross-domain or cross-modal retrieval problems. First, to construct the\nknowledge graph, we utilize the geometric word as the node, and then use the\ncategory of the 3D shape as well as the attribute of the geometry to bridge the\nnodes. Second, based on the knowledge graph, we provide a unique way for\nlearning each entity's embedding. Finally, we propose an effective similarity\nmeasure to handle the cross-domain and cross-modal 3D shape retrieval.\nSpecifically, every 3D or 2D entity could locate its geometric terms in the 3D\nknowledge graph, which serve as a link between cross-domain and cross-modal\ndata. Thus, our approach can achieve the cross-domain and cross-modal 3D shape\nretrieval at the same time. We evaluated our proposed method on the ModelNet40\ndataset and ShapeNetCore55 dataset for both the 3D shape retrieval task and\ncross-domain 3D shape retrieval task. The classic cross-modal dataset (MI3DOR)\nis utilized to evaluate cross-modal 3D shape retrieval. Experimental results\nand comparisons with state-of-the-art methods illustrate the superiority of our\napproach.",
    "descriptor": "",
    "authors": [
      "Weizhi Nie",
      "Rihao Chang",
      "Tong Hao",
      "Anan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15136"
  },
  {
    "id": "arXiv:2210.15137",
    "title": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "abstract": "Generative Adversarial Networks (GANs) typically suffer from overfitting when\nlimited training data is available. To facilitate GAN training, current methods\npropose to use data-specific augmentation techniques. Despite the\neffectiveness, it is difficult for these methods to scale to practical\napplications. In this work, we present ScoreMix, a novel and scalable data\naugmentation approach for various image synthesis tasks. We first produce\naugmented samples using the convex combinations of the real samples. Then, we\noptimize the augmented samples by minimizing the norms of the data scores,\ni.e., the gradients of the log-density functions. This procedure enforces the\naugmented samples close to the data manifold. To estimate the scores, we train\na deep estimation network with multi-scale score matching. For different image\nsynthesis tasks, we train the score estimation network using different data. We\ndo not require the tuning of the hyperparameters or modifications to the\nnetwork architecture. The ScoreMix method effectively increases the diversity\nof data and reduces the overfitting problem. Moreover, it can be easily\nincorporated into existing GAN models with minor modifications. Experimental\nresults on numerous tasks demonstrate that GAN models equipped with the\nScoreMix method achieve significant improvements.",
    "descriptor": "",
    "authors": [
      "Jie Cao",
      "Mandi Luo",
      "Junchi Yu",
      "Ming-Hsuan Yang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15137"
  },
  {
    "id": "arXiv:2210.15138",
    "title": "Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models",
    "abstract": "When trained at a sufficient scale, self-supervised learning has exhibited a\nnotable ability to solve a wide range of visual or language understanding\ntasks. In this paper, we investigate simple, yet effective approaches for\nadapting the pre-trained foundation models to the downstream task of interest,\nnamely, open-vocabulary semantic segmentation. To this end, we make the\nfollowing contributions: (i) we introduce Fusioner, with a lightweight,\ntransformer-based fusion module, that pairs the frozen visual representation\nwith language concept through a handful of image segmentation data. As a\nconsequence, the model gains the capability of zero-shot transfer to segment\nnovel categories; (ii) without loss of generality, we experiment on a broad\nrange of self-supervised models that have been pre-trained with different\nschemes, e.g. visual-only models (MoCo v3, DINO), language-only models (BERT),\nvisual-language model (CLIP), and show that, the proposed fusion approach is\neffective to any pair of visual and language models, even those pre-trained on\na corpus of uni-modal data; (iii) we conduct thorough ablation studies to\nanalyze the critical components in our proposed Fusioner, while evaluating on\nstandard benchmarks, e.g. PASCAL-5i and COCO-20i , it surpasses existing\nstate-of-the-art models by a large margin, despite only being trained on frozen\nvisual and language features; (iv) to measure the model's robustness on\nlearning visual-language correspondence, we further evaluate on synthetic\ndataset, named Mosaic-4, where images are constructed by mosaicking the samples\nfrom FSS-1000. Fusioner demonstrates superior performance over previous models.",
    "descriptor": "\nComments: BMVC 2022 Oral\n",
    "authors": [
      "Chaofan Ma",
      "Yuhuan Yang",
      "Yanfeng Wang",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15138"
  },
  {
    "id": "arXiv:2210.15140",
    "title": "V-Cloak: Intelligibility-, Naturalness- & Timbre-Preserving Real-Time  Voice Anonymization",
    "abstract": "Voice data generated on instant messaging or social media applications\ncontains unique user voiceprints that may be abused by malicious adversaries\nfor identity inference or identity theft. Existing voice anonymization\ntechniques, e.g., signal processing and voice conversion/synthesis, suffer from\ndegradation of perceptual quality. In this paper, we develop a voice\nanonymization system, named V-Cloak, which attains real-time voice\nanonymization while preserving the intelligibility, naturalness and timbre of\nthe audio. Our designed anonymizer features a one-shot generative model that\nmodulates the features of the original audio at different frequency levels. We\ntrain the anonymizer with a carefully-designed loss function. Apart from the\nanonymity loss, we further incorporate the intelligibility loss and the\npsychoacoustics-based naturalness loss. The anonymizer can realize untargeted\nand targeted anonymization to achieve the anonymity goals of unidentifiability\nand unlinkability.\nWe have conducted extensive experiments on four datasets, i.e., LibriSpeech\n(English), AISHELL (Chinese), CommonVoice (French) and CommonVoice (Italian),\nfive Automatic Speaker Verification (ASV) systems (including two DNN-based, two\nstatistical and one commercial ASV), and eleven Automatic Speech Recognition\n(ASR) systems (for different languages). Experiment results confirm that\nV-Cloak outperforms five baselines in terms of anonymity performance. We also\ndemonstrate that V-Cloak trained only on the VoxCeleb1 dataset against\nECAPA-TDNN ASV and DeepSpeech2 ASR has transferable anonymity against other\nASVs and cross-language intelligibility for other ASRs. Furthermore, we verify\nthe robustness of V-Cloak against various de-noising techniques and adaptive\nattacks. Hopefully, V-Cloak may provide a cloak for us in a prism world.",
    "descriptor": "\nComments: Accepted by USENIX Security Symposium 2023\n",
    "authors": [
      "Jiangyi Deng",
      "Fei Teng",
      "Yanjiao Chen",
      "Xiaofu Chen",
      "Zhaohui Wang",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15140"
  },
  {
    "id": "arXiv:2210.15142",
    "title": "Taxonomic Recommendations of Real Estate Properties with Textual  Attribute Information",
    "abstract": "In this extended abstract, we present an end to end approach for building a\ntaxonomy of home attribute terms that enables hierarchical recommendations of\nreal estate properties. We cover the methodology for building a real-estate\ntaxonomy, metrics for measuring this structure's quality, and then conclude\nwith a production use-case of making recommendations from search keywords at\ndifferent levels of topical similarity.",
    "descriptor": "\nComments: In Sixteenth ACM Conference on Recommender Systems (RecSys 2022)\n",
    "authors": [
      "Zachary Harrison",
      "Anish Khazane"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15142"
  },
  {
    "id": "arXiv:2210.15143",
    "title": "Audio Signal Enhancement with Learning from Positive and Unlabelled Data",
    "abstract": "Supervised learning is a mainstream approach to audio signal enhancement (SE)\nand requires parallel training data consisting of noisy signals and the\ncorresponding clean signals. Such data can only be synthesised and are thus\nmismatched with real data, which can result in poor performance. Moreover, it\nis often difficult/impossible to obtain clean signals, which makes it\ndifficult/impossible to apply the approach. Here we explore SE using\nnon-parallel training data consisting of noisy signal clips and noise clips,\nwhich can be easily recorded. We define the positive (P) and the negative (N)\nclasses as signal absence and presence, respectively. We observe that the\nspectrogram patches of noise clips can be used as P data and those of noisy\nsignal clips as unlabelled data. These data enable a convolutional neural\nnetwork to learn to classify each spectrogram patch as P or N for SE through\nlearning from positive and unlabelled data.",
    "descriptor": "",
    "authors": [
      "Nobutaka Ito",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15143"
  },
  {
    "id": "arXiv:2210.15144",
    "title": "Gendered Mental Health Stigma in Masked Language Models",
    "abstract": "Mental health stigma prevents many individuals from receiving the appropriate\ncare, and social psychology studies have shown that mental health tends to be\noverlooked in men. In this work, we investigate gendered mental health stigma\nin masked language models. In doing so, we operationalize mental health stigma\nby developing a framework grounded in psychology research: we use clinical\npsychology literature to curate prompts, then evaluate the models' propensity\nto generate gendered words. We find that masked language models capture\nsocietal stigma about gender in mental health: models are consistently more\nlikely to predict female subjects than male in sentences about having a mental\nhealth condition (32% vs. 19%), and this disparity is exacerbated for sentences\nthat indicate treatment-seeking behavior. Furthermore, we find that different\nmodels capture dimensions of stigma differently for men and women, associating\nstereotypes like anger, blame, and pity more with women with mental health\nconditions than with men. In showing the complex nuances of models' gendered\nmental health stigma, we demonstrate that context and overlapping dimensions of\nidentity are important considerations when assessing computational models'\nsocial biases.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Inna Wanyin Lin",
      "Lucille Njoo",
      "Anjalie Field",
      "Ashish Sharma",
      "Katharina Reinecke",
      "Tim Althoff",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.15144"
  },
  {
    "id": "arXiv:2210.15145",
    "title": "InGVIO: A Consistent Invariant Filter for Fast and High-Accuracy  GNSS-Visual-Inertial Odometry",
    "abstract": "Combining Global Navigation Satellite System (GNSS) with visual and inertial\nsensors can give smooth pose estimation without drifting in geographical\ncoordinates. The fusion system gradually degrades to Visual-Inertial Odometry\n(VIO) with the number of satellites decreasing, which guarantees robust global\nnavigation in GNSS unfriendly environments. In this letter, we propose an\nopen-sourced invariant filter-based platform, InGVIO, to tightly fuse\nmonocular/stereo visual-inertial measurements, along with raw data from GNSS,\ni.e. pseudo ranges and Doppler shifts. InGVIO gives highly competitive results\nin terms of accuracy and computational load compared to current graph-based and\n`naive' EKF-based algorithms. Thanks to our proposed key-frame marginalization\nstrategies, the baseline for triangulation is large although only a few cloned\nposes are kept. Besides, landmarks are anchored to a single cloned pose to fit\nthe nonlinear log-error form of the invariant filter while achieving decoupled\npropagation with IMU states. Moreover, we exploit the infinitesimal symmetries\nof the system, which gives equivalent results for the pattern of degenerate\nmotions and the structure of unobservable subspaces compared to our previous\nwork using observability analysis. We show that the properly-chosen invariant\nerror captures such symmetries and has intrinsic consistency properties. InGVIO\nis tested on both open datasets and our proposed fixed-wing datasets with\nvariable levels of difficulty. The latter, to the best of our knowledge, are\nthe first datasets open-sourced to the community on a fixed-wing aircraft with\nraw GNSS.",
    "descriptor": "\nComments: 8 pages, 8 figures; manuscript will be submitted to IEEE RA-L for possible publication\n",
    "authors": [
      "Changwu Liu",
      "Chen Jiang",
      "Haowen Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15145"
  },
  {
    "id": "arXiv:2210.15146",
    "title": "Towards Practicality of Sketch-Based Visual Understanding",
    "abstract": "Sketches have been used to conceptualise and depict visual objects from\npre-historic times. Sketch research has flourished in the past decade,\nparticularly with the proliferation of touchscreen devices. Much of the\nutilisation of sketch has been anchored around the fact that it can be used to\ndelineate visual concepts universally irrespective of age, race, language, or\ndemography. The fine-grained interactive nature of sketches facilitates the\napplication of sketches to various visual understanding tasks, like image\nretrieval, image-generation or editing, segmentation, 3D-shape modelling etc.\nHowever, sketches are highly abstract and subjective based on the perception of\nindividuals. Although most agree that sketches provide fine-grained control to\nthe user to depict a visual object, many consider sketching a tedious process\ndue to their limited sketching skills compared to other query/support\nmodalities like text/tags. Furthermore, collecting fine-grained sketch-photo\nassociation is a significant bottleneck to commercialising sketch applications.\nTherefore, this thesis aims to progress sketch-based visual understanding\ntowards more practicality.",
    "descriptor": "\nComments: PhD thesis successfully defended by Ayan Kumar Bhunia, Supervisor: Prof. Yi-Zhe Song, Thesis Examiners: Prof Stella Yu and Prof Adrian Hilton\n",
    "authors": [
      "Ayan Kumar Bhunia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15146"
  },
  {
    "id": "arXiv:2210.15147",
    "title": "A Curriculum Learning Approach for Multi-domain Text Classification  Using Keyword weight Ranking",
    "abstract": "Text classification is a very classic NLP task, but it has two prominent\nshortcomings: On the one hand, text classification is deeply domain-dependent.\nThat is, a classifier trained on the corpus of one domain may not perform so\nwell in another domain. On the other hand, text classification models require a\nlot of annotated data for training. However, for some domains, there may not\nexist enough annotated data. Therefore, it is valuable to investigate how to\nefficiently utilize text data from different domains to improve the performance\nof models in various domains. Some multi-domain text classification models are\ntrained by adversarial training to extract shared features among all domains\nand the specific features of each domain. We noted that the distinctness of the\ndomain-specific features is different, so in this paper, we propose to use a\ncurriculum learning strategy based on keyword weight ranking to improve the\nperformance of multi-domain text classification models. The experimental\nresults on the Amazon review and FDU-MTL datasets show that our curriculum\nlearning strategy effectively improves the performance of multi-domain text\nclassification models based on adversarial learning and outperforms\nstate-of-the-art methods.",
    "descriptor": "\nComments: Submitted to ICASSP2023 (currently under review)\n",
    "authors": [
      "Zilin Yuan",
      "Yinghui Li",
      "Yangning Li",
      "Rui Xie",
      "Wei Wu",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15147"
  },
  {
    "id": "arXiv:2210.15152",
    "title": "Robust output regulation of linear system subject to modeled and  unmodeled uncertainty",
    "abstract": "In this paper, a novel robust output regulation control framework is proposed\nfor the system subject to noise, modeled disturbance and unmodeled disturbance\nto seek tracking performance and robustness simultaneously. The output\nregulation scheme is utilized in the framework to track the reference in the\npresence of modeled disturbance, and the effect of unmodeled disturbance is\nreduced by an $\\mathcal{H}_\\infty$ compensator. The Kalman filter can be also\nintroduced in the stabilization loop to deal with the white noise. Furthermore,\nthe tracking error in the presence/absence of noise and disturbance is\nestimated. The effectiveness and performance of our proposed control framework\nis verified in the numerical example by applying in the Furuta Inverted\nPendulum system.",
    "descriptor": "",
    "authors": [
      "Zhicheng Zhang",
      "Zhiqiang Zuo",
      "Xiang Chen",
      "Ying Tan",
      "Yijing Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15152"
  },
  {
    "id": "arXiv:2210.15154",
    "title": "AutoAttention: Automatic Field Pair Selection for Attention in User  Behavior Modeling",
    "abstract": "In Click-through rate (CTR) prediction models, a user's interest is usually\nrepresented as a fixed-length vector based on her history behaviors. Recently,\nseveral methods are proposed to learn an attentive weight for each user\nbehavior and conduct weighted sum pooling. However, these methods only manually\nselect several fields from the target item side as the query to interact with\nthe behaviors, neglecting the other target item fields, as well as user and\ncontext fields. Directly including all these fields in the attention may\nintroduce noise and deteriorate the performance. In this paper, we propose a\nnovel model named AutoAttention, which includes all item/user/context side\nfields as the query, and assigns a learnable weight for each field pair between\nbehavior fields and query fields. Pruning on these field pairs via these\nlearnable weights lead to automatic field pair selection, so as to identify and\nremove noisy field pairs. Though including more fields, the computation cost of\nAutoAttention is still low due to using a simple attention function and field\npair selection. Extensive experiments on the public dataset and Tencent's\nproduction dataset demonstrate the effectiveness of the proposed approach.",
    "descriptor": "\nComments: Accepted by ICDM 2022\n",
    "authors": [
      "Zuowu Zheng",
      "Xiaofeng Gao",
      "Junwei Pan",
      "Qi Luo",
      "Guihai Chen",
      "Dapeng Liu",
      "Jie Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15154"
  },
  {
    "id": "arXiv:2210.15156",
    "title": "Towards Complex Backgrounds: A Unified Difference-Aware Decoder for  Binary Segmentation",
    "abstract": "Binary segmentation is used to distinguish objects of interest from\nbackground, and is an active area of convolutional encoder-decoder network\nresearch. The current decoders are designed for specific objects based on the\ncommon backbones as the encoders, but cannot deal with complex backgrounds.\nInspired by the way human eyes detect objects of interest, a new unified\ndual-branch decoder paradigm named the difference-aware decoder is proposed in\nthis paper to explore the difference between the foreground and the background\nand separate the objects of interest in optical images. The difference-aware\ndecoder imitates the human eye in three stages using the multi-level features\noutput by the encoder. In Stage A, the first branch decoder of the\ndifference-aware decoder is used to obtain a guide map. The highest-level\nfeatures are enhanced with a novel field expansion module and a dual residual\nattention module, and are combined with the lowest-level features to obtain the\nguide map. In Stage B, the other branch decoder adopts a middle feature fusion\nmodule to make trade-offs between textural details and semantic information and\ngenerate background-aware features. In Stage C, the proposed difference-aware\nextractor, consisting of a difference guidance model and a difference\nenhancement module, fuses the guide map from Stage A and the background-aware\nfeatures from Stage B, to enlarge the differences between the foreground and\nthe background and output a final detection result. The results demonstrate\nthat the difference-aware decoder can achieve a higher accuracy than the other\nstate-of-the-art binary segmentation methods for these tasks.",
    "descriptor": "",
    "authors": [
      "Jiepan Li",
      "Wei He",
      "Hongyan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15156"
  },
  {
    "id": "arXiv:2210.15157",
    "title": "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1  Problems Using Natural Language",
    "abstract": "GitHub Copilot is an artificial intelligence model for automatically\ngenerating source code from natural language problem descriptions. Since June\n2022, Copilot has officially been available for free to all students as a\nplug-in to development environments like Visual Studio Code. Prior work\nexploring OpenAI Codex, the underlying model that powers Copilot, has shown it\nperforms well on typical CS1 problems thus raising concerns about the impact it\nwill have on how introductory programming courses are taught. However, little\nis known about the types of problems for which Copilot does not perform well,\nor about the natural language interactions that a student might have with\nCopilot when resolving errors. We explore these questions by evaluating the\nperformance of Copilot on a publicly available dataset of 166 programming\nproblems. We find that it successfully solves around half of these problems on\nits very first attempt, and that it solves 60\\% of the remaining problems using\nonly natural language changes to the problem description. We argue that this\ntype of prompt engineering, which we believe will become a standard interaction\nbetween human and Copilot when it initially fails, is a potentially useful\nlearning activity that promotes computational thinking skills, and is likely to\nchange the nature of code writing skill development.",
    "descriptor": "",
    "authors": [
      "Paul Denny",
      "Viraj Kumar",
      "Nasser Giacaman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15157"
  },
  {
    "id": "arXiv:2210.15159",
    "title": "Comparing One with Many -- Solving Binary2source Function Matching Under  Function Inlining",
    "abstract": "Binary2source function matching is a fundamental task for many security\napplications, including Software Component Analysis (SCA). The \"1-to-1\"\nmechanism has been applied in existing binary2source matching works, in which\none binary function is matched against one source function. However, we\ndiscovered that such mapping could be \"1-to-n\" (one query binary function maps\nmultiple source functions), due to the existence of function inlining.\nTo help conduct binary2source function matching under function inlining, we\npropose a method named O2NMatcher to generate Source Function Sets (SFSs) as\nthe matching target for binary functions with inlining. We first propose a\nmodel named ECOCCJ48 for inlined call site prediction. To train this model, we\nleverage the compilable OSS to generate a dataset with labeled call sites\n(inlined or not), extract several features from the call sites, and design a\ncompiler-opt-based multi-label classifier by inspecting the inlining\ncorrelations between different compilations. Then, we use this model to predict\nthe labels of call sites in the uncompilable OSS projects without compilation\nand obtain the labeled function call graphs of these projects. Next, we regard\nthe construction of SFSs as a sub-tree generation problem and design root node\nselection and edge extension rules to construct SFSs automatically. Finally,\nthese SFSs will be added to the corpus of source functions and compared with\nbinary functions with inlining. We conduct several experiments to evaluate the\neffectiveness of O2NMatcher and results show our method increases the\nperformance of existing works by 6% and exceeds all the state-of-the-art works.",
    "descriptor": "",
    "authors": [
      "Ang Jia",
      "Ming Fan",
      "Xi Xu",
      "Wuxia Jin",
      "Haijun Wang",
      "Qiyi Tang",
      "Sen Nie",
      "Shi Wu",
      "Ting Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15159"
  },
  {
    "id": "arXiv:2210.15160",
    "title": "Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection",
    "abstract": "Expressions and facial action units (AUs) are two levels of facial behavior\ndescriptors. Expression auxiliary information has been widely used to improve\nthe AU detection performance. However, most existing expression representations\ncan only describe pre-determined discrete categories (e.g., Angry, Disgust,\nHappy, Sad, etc.) and cannot capture subtle expression transformations like\nAUs. In this paper, we propose a novel fine-grained \\textsl{Global Expression\nrepresentation Encoder} to capture subtle and continuous facial movements, to\npromote AU detection. To obtain such a global expression representation, we\npropose to train an expression embedding model on a large-scale expression\ndataset according to global expression similarity. Moreover, considering the\nlocal definition of AUs, it is essential to extract local AU features.\nTherefore, we design a \\textsl{Local AU Features Module} to generate local\nfacial features for each AU. Specifically, it consists of an AU feature map\nextractor and a corresponding AU mask extractor. First, the two extractors\ntransform the global expression representation into AU feature maps and masks,\nrespectively. Then, AU feature maps and their corresponding AU masks are\nmultiplied to generate AU masked features focusing on local facial region.\nFinally, the AU masked features are fed into an AU classifier for judging the\nAU occurrence. Extensive experiment results demonstrate the superiority of our\nproposed method. Our method validly outperforms previous works and achieves\nstate-of-the-art performances on widely-used face datasets, including BP4D,\nDISFA, and BP4D+.",
    "descriptor": "",
    "authors": [
      "Rudong An",
      "Wei Zhang",
      "Hao Zeng",
      "Wei Chen",
      "Zhigang Deng",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15160"
  },
  {
    "id": "arXiv:2210.15164",
    "title": "FAS-UNet: A Novel FAS-driven Unet to Learn Variational Image  Segmentation",
    "abstract": "Solving variational image segmentation problems with hidden physics is often\nexpensive and requires different algorithms and manually tunes model parameter.\nThe deep learning methods based on the U-Net structure have obtained\noutstanding performances in many different medical image segmentation tasks,\nbut designing such networks requires a lot of parameters and training data, not\nalways available for practical problems. In this paper, inspired by traditional\nmulti-phase convexity Mumford-Shah variational model and full approximation\nscheme (FAS) solving the nonlinear systems, we propose a novel\nvariational-model-informed network (denoted as FAS-Unet) that exploits the\nmodel and algorithm priors to extract the multi-scale features. The proposed\nmodel-informed network integrates image data and mathematical models, and\nimplements them through learning a few convolution kernels. Based on the\nvariational theory and FAS algorithm, we first design a feature extraction\nsub-network (FAS-Solution module) to solve the model-driven nonlinear systems,\nwhere a skip-connection is employed to fuse the multi-scale features. Secondly,\nwe further design a convolution block to fuse the extracted features from the\nprevious stage, resulting in the final segmentation possibility. Experimental\nresults on three different medical image segmentation tasks show that the\nproposed FAS-Unet is very competitive with other state-of-the-art methods in\nqualitative, quantitative and model complexity evaluations. Moreover, it may\nalso be possible to train specialized network architectures that automatically\nsatisfy some of the mathematical and physical laws in other image problems for\nbetter accuracy, faster training and improved generalization.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Hui Zhu",
      "Shi Shu",
      "Jianping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15164"
  },
  {
    "id": "arXiv:2210.15170",
    "title": "Improved Projection Learning for Lower Dimensional Feature Maps",
    "abstract": "The requirement to repeatedly move large feature maps off- and on-chip during\ninference with convolutional neural networks (CNNs) imposes high costs in terms\nof both energy and time. In this work we explore an improved method for\ncompressing all feature maps of pre-trained CNNs to below a specified limit.\nThis is done by means of learned projections trained via end-to-end finetuning,\nwhich can then be folded and fused into the pre-trained network. We also\nintroduce a new `ceiling compression' framework in which evaluate such\ntechniques in view of the future goal of performing inference fully on-chip.",
    "descriptor": "",
    "authors": [
      "Ilan Price",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15170"
  },
  {
    "id": "arXiv:2210.15171",
    "title": "Computing the extremal nonnegative solutions of the M-tensor equation  with a nonnegative right side vector",
    "abstract": "We consider the tensor equation whose coefficient tensor is a nonsingular\nM-tensor and whose right side vector is nonnegative. Such a tensor equation may\nhave a large number of nonnegative solutions. It is already known that the\ntensor equation has a maximal nonnegative solution and a minimal nonnegative\nsolution (called extremal solutions collectively). However, the existing proofs\ndo not show how the extremal solutions can be computed. The existing numerical\nmethods can find one of the nonnegative solutions, without knowing whether the\ncomputed solution is an extremal solution. In this paper, we present new proofs\nfor the existence of extremal solutions. Our proofs are much shorter than\nexisting ones and more importantly they give numerical methods that can compute\nthe extremal solutions. Linear convergence of these numerical methods is also\nproved under mild assumptions. Some of our discussions also allow the\ncoefficient tensor to be a Z-tensor or allow the right side vector to have some\nnegative elements.",
    "descriptor": "",
    "authors": [
      "Chun-Hua Guo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15171"
  },
  {
    "id": "arXiv:2210.15172",
    "title": "Dictionary-Assisted Supervised Contrastive Learning",
    "abstract": "Text analysis in the social sciences often involves using specialized\ndictionaries to reason with abstract concepts, such as perceptions about the\neconomy or abuse on social media. These dictionaries allow researchers to\nimpart domain knowledge and note subtle usages of words relating to a\nconcept(s) of interest. We introduce the dictionary-assisted supervised\ncontrastive learning (DASCL) objective, allowing researchers to leverage\nspecialized dictionaries when fine-tuning pretrained language models. The text\nis first keyword simplified: a common, fixed token replaces any word in the\ncorpus that appears in the dictionary(ies) relevant to the concept of interest.\nDuring fine-tuning, a supervised contrastive objective draws closer the\nembeddings of the original and keyword-simplified texts of the same class while\npushing further apart the embeddings of different classes. The\nkeyword-simplified texts of the same class are more textually similar than\ntheir original text counterparts, which additionally draws the embeddings of\nthe same class closer together. Combining DASCL and cross-entropy improves\nclassification performance metrics in few-shot learning settings and social\nscience applications compared to using cross-entropy alone and alternative\ncontrastive and data augmentation methods.",
    "descriptor": "\nComments: 6 pages, 5 figures, EMNLP 2022\n",
    "authors": [
      "Patrick Y. Wu",
      "Richard Bonneau",
      "Joshua A. Tucker",
      "Jonathan Nagler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15172"
  },
  {
    "id": "arXiv:2210.15173",
    "title": "Articulation GAN: Unsupervised modeling of articulatory learning",
    "abstract": "Generative deep neural networks are widely used for speech synthesis, but\nmost existing models directly generate waveforms or spectral outputs. Humans,\nhowever, produce speech by controlling articulators, which results in the\nproduction of speech sounds through physical properties of sound propagation.\nWe propose a new unsupervised generative model of speech production/synthesis\nthat includes articulatory representations and thus more closely mimics human\nspeech production. We introduce the Articulatory Generator to the Generative\nAdversarial Network paradigm. The Articulatory Generator needs to learn to\ngenerate articulatory representations (electromagnetic articulography or EMA)\nin a fully unsupervised manner without ever accessing EMA data. A separate\npre-trained physical model (ema2wav) then transforms the generated EMA\nrepresentations to speech waveforms, which get sent to the Discriminator for\nevaluation. Articulatory analysis of the generated EMA representations suggests\nthat the network learns to control articulators in a manner that closely\nfollows human articulators during speech production. Acoustic analysis of the\noutputs suggest that the network learns to generate words that are part of\ntraining data as well as novel innovative words that are absent from training\ndata. Our proposed architecture thus allows modeling of articulatory learning\nwith deep neural networks from raw audio inputs in a fully unsupervised manner.\nWe additionally discuss implications of articulatory representations for\ncognitive models of human language and speech technology in general.",
    "descriptor": "",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou",
      "Peter Wu",
      "Gopala K Anumanchipalli"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15173"
  },
  {
    "id": "arXiv:2210.15175",
    "title": "Private Isotonic Regression",
    "abstract": "In this paper, we consider the problem of differentially private (DP)\nalgorithms for isotonic regression. For the most general problem of isotonic\nregression over a partially ordered set (poset) $\\mathcal{X}$ and for any\nLipschitz loss function, we obtain a pure-DP algorithm that, given $n$ input\npoints, has an expected excess empirical risk of roughly\n$\\mathrm{width}(\\mathcal{X}) \\cdot \\log|\\mathcal{X}| / n$, where\n$\\mathrm{width}(\\mathcal{X})$ is the width of the poset. In contrast, we also\nobtain a near-matching lower bound of roughly $(\\mathrm{width}(\\mathcal{X}) +\n\\log |\\mathcal{X}|) / n$, that holds even for approximate-DP algorithms.\nMoreover, we show that the above bounds are essentially the best that can be\nobtained without utilizing any further structure of the poset.\nIn the special case of a totally ordered set and for $\\ell_1$ and $\\ell_2^2$\nlosses, our algorithm can be implemented in near-linear running time; we also\nprovide extensions of this algorithm to the problem of private isotonic\nregression with additional structural constraints on the output function.",
    "descriptor": "\nComments: Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15175"
  },
  {
    "id": "arXiv:2210.15176",
    "title": "Domain Adaptive Object Detection for Autonomous Driving under Foggy  Weather",
    "abstract": "Most object detection methods for autonomous driving usually assume a\nconsistent feature distribution between training and testing data, which is not\nalways the case when weathers differ significantly. The object detection model\ntrained under clear weather might not be effective enough in foggy weather\nbecause of the domain gap. This paper proposes a novel domain adaptive object\ndetection framework for autonomous driving under foggy weather. Our method\nleverages both image-level and object-level adaptation to diminish the domain\ndiscrepancy in image style and object appearance. To further enhance the\nmodel's capabilities under challenging samples, we also come up with a new\nadversarial gradient reversal layer to perform adversarial mining for the hard\nexamples together with domain adaptation. Moreover, we propose to generate an\nauxiliary domain by data augmentation to enforce a new domain-level metric\nregularization. Experimental results on public benchmarks show the\neffectiveness and accuracy of the proposed method. The code is available at\nhttps://github.com/jinlong17/DA-Detect.",
    "descriptor": "\nComments: Accepted by WACV2023. Code is available at this https URL\n",
    "authors": [
      "Jinlong Li",
      "Runsheng Xu",
      "Jin Ma",
      "Qin Zou",
      "Jiaqi Ma",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15176"
  },
  {
    "id": "arXiv:2210.15178",
    "title": "Anonymized Histograms in Intermediate Privacy Models",
    "abstract": "We study the problem of privately computing the anonymized histogram (a.k.a.\nunattributed histogram), which is defined as the histogram without item labels.\nPrevious works have provided algorithms with $\\ell_1$- and $\\ell_2^2$-errors of\n$O_\\varepsilon(\\sqrt{n})$ in the central model of differential privacy (DP).\nIn this work, we provide an algorithm with a nearly matching error guarantee\nof $\\tilde{O}_\\varepsilon(\\sqrt{n})$ in the shuffle DP and pan-private models.\nOur algorithm is very simple: it just post-processes the discrete\nLaplace-noised histogram! Using this algorithm as a subroutine, we show\napplications in privately estimating symmetric properties of distributions such\nas entropy, support coverage, and support size.",
    "descriptor": "\nComments: Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15178"
  },
  {
    "id": "arXiv:2210.15180",
    "title": "Disentangled and Robust Representation Learning for Bragging  Classification in Social Media",
    "abstract": "Researching bragging behavior on social media arouses interest of\ncomputational (socio) linguists. However, existing bragging classification\ndatasets suffer from a serious data imbalance issue. Because labeling a\ndata-balance dataset is expensive, most methods introduce external knowledge to\nimprove model learning. Nevertheless, such methods inevitably introduce noise\nand non-relevance information from external knowledge. To overcome the\ndrawback, we propose a novel bragging classification method with\ndisentangle-based representation augmentation and domain-aware adversarial\nstrategy. Specifically, model learns to disentangle and reconstruct\nrepresentation and generate augmented features via disentangle-based\nrepresentation augmentation. Moreover, domain-aware adversarial strategy aims\nto constrain domain of augmented features to improve their robustness.\nExperimental results demonstrate that our method achieves state-of-the-art\nperformance compared to other methods.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Yucheng Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15180"
  },
  {
    "id": "arXiv:2210.15182",
    "title": "Text2Model: Model Induction for Zero-shot Generalization Using Task  Descriptions",
    "abstract": "We study the problem of generating a training-free task-dependent visual\nclassifier from text descriptions without visual samples. This\n\\textit{Text-to-Model} (T2M) problem is closely related to zero-shot learning,\nbut unlike previous work, a T2M model infers a model tailored to a task, taking\ninto account all classes in the task. We analyze the symmetries of T2M, and\ncharacterize the equivariance and invariance properties of corresponding\nmodels. In light of these properties, we design an architecture based on\nhypernetworks that given a set of new class descriptions predicts the weights\nfor an object recognition model which classifies images from those zero-shot\nclasses. We demonstrate the benefits of our approach compared to zero-shot\nlearning from text descriptions in image and point-cloud classification using\nvarious types of text descriptions: From single words to rich text\ndescriptions.",
    "descriptor": "",
    "authors": [
      "Ohad Amosy",
      "Tomer Volk",
      "Eyal Ben-David",
      "Roi Reichart",
      "Gal Chechik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15182"
  },
  {
    "id": "arXiv:2210.15183",
    "title": "Outlier-Aware Training for Improving Group Accuracy Disparities",
    "abstract": "Methods addressing spurious correlations such as Just Train Twice (JTT,\narXiv:2107.09044v2) involve reweighting a subset of the training set to\nmaximize the worst-group accuracy. However, the reweighted set of examples may\npotentially contain unlearnable examples that hamper the model's learning. We\npropose mitigating this by detecting outliers to the training set and removing\nthem before reweighting. Our experiments show that our method achieves\ncompetitive or better accuracy compared with JTT and can detect and remove\nannotation errors in the subset being reweighted in JTT.",
    "descriptor": "",
    "authors": [
      "Li-Kuang Chen",
      "Canasai Kruengkrai",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15183"
  },
  {
    "id": "arXiv:2210.15184",
    "title": "Too Brittle To Touch: Comparing the Stability of Quantization and  Distillation Towards Developing Lightweight Low-Resource MT Models",
    "abstract": "Leveraging shared learning through Massively Multilingual Models,\nstate-of-the-art machine translation models are often able to adapt to the\npaucity of data for low-resource languages. However, this performance comes at\nthe cost of significantly bloated models which are not practically deployable.\nKnowledge Distillation is one popular technique to develop competitive,\nlightweight models: In this work, we first evaluate its use to compress MT\nmodels focusing on languages with extremely limited training data. Through our\nanalysis across 8 languages, we find that the variance in the performance of\nthe distilled models due to their dependence on priors including the amount of\nsynthetic data used for distillation, the student architecture, training\nhyperparameters and confidence of the teacher models, makes distillation a\nbrittle compression mechanism. To mitigate this, we explore the use of\npost-training quantization for the compression of these models. Here, we find\nthat while distillation provides gains across some low-resource languages,\nquantization provides more consistent performance trends for the entire range\nof languages, especially the lowest-resource languages in our target set.",
    "descriptor": "\nComments: 16 Pages, 7 Figures, Accepted to WMT 2022 (Research Track)\n",
    "authors": [
      "Harshita Diddee",
      "Sandipan Dandapat",
      "Monojit Choudhury",
      "Tanuja Ganu",
      "Kalika Bali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15184"
  },
  {
    "id": "arXiv:2210.15185",
    "title": "SAM-RL: Sensing-Aware Model-Based Reinforcement Learning via  Differentiable Physics-Based Simulation and Rendering",
    "abstract": "Model-based reinforcement learning (MBRL) is recognized with the potential to\nbe significantly more sample efficient than model-free RL. How an accurate\nmodel can be developed automatically and efficiently from raw sensory inputs\n(such as images), especially for complex environments and tasks, is a\nchallenging problem that hinders the broad application of MBRL in the real\nworld. In this work, we propose a sensing-aware model-based reinforcement\nlearning system called SAM-RL. Leveraging the differentiable physics-based\nsimulation and rendering, SAM-RL automatically updates the model by comparing\nrendered images with real raw images and produces the policy efficiently. With\nthe sensing-aware learning pipeline, SAM-RL allows a robot to select an\ninformative viewpoint to monitor the task process. We apply our framework to\nreal-world experiments for accomplishing three manipulation tasks: robotic\nassembly, tool manipulation, and deformable object manipulation. We demonstrate\nthe effectiveness of SAM-RL via extensive experiments. Supplemental materials\nand videos are available on our project webpage at\nhttps://sites.google.com/view/sam-rl.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Jun Lv",
      "Yunhai Feng",
      "Cheng Zhang",
      "Shuang Zhao",
      "Lin Shao",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15185"
  },
  {
    "id": "arXiv:2210.15187",
    "title": "Learning Joint Representation of Human Motion and Language",
    "abstract": "In this work, we present MoLang (a Motion-Language connecting model) for\nlearning joint representation of human motion and language, leveraging both\nunpaired and paired datasets of motion and language modalities. To this end, we\npropose a motion-language model with contrastive learning, empowering our model\nto learn better generalizable representations of the human motion domain.\nEmpirical results show that our model learns strong representations of human\nmotion data through navigating language modality. Our proposed method is able\nto perform both action recognition and motion retrieval tasks with a single\nmodel where it outperforms state-of-the-art approaches on a number of action\nrecognition benchmarks.",
    "descriptor": "",
    "authors": [
      "Jihoon Kim",
      "Youngjae Yu",
      "Seungyoun Shin",
      "Taehyun Byun",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15187"
  },
  {
    "id": "arXiv:2210.15189",
    "title": "Partially Oblivious Neural Network Inference",
    "abstract": "Oblivious inference is the task of outsourcing a ML model, like\nneural-networks, without disclosing critical and sensitive information, like\nthe model's parameters. One of the most prominent solutions for secure\noblivious inference is based on a powerful cryptographic tools, like\nHomomorphic Encryption (HE) and/or multi-party computation (MPC). Even though\nthe implementation of oblivious inference systems schemes has impressively\nimproved the last decade, there are still significant limitations on the ML\nmodels that they can practically implement. Especially when both the ML model\nand the input data's confidentiality must be protected. In this paper, we\nintroduce the notion of partially oblivious inference. We empirically show that\nfor neural network models, like CNNs, some information leakage can be\nacceptable. We therefore propose a novel trade-off between security and\nefficiency. In our research, we investigate the impact on security and\ninference runtime performance from the CNN model's weights partial leakage. We\nexperimentally demonstrate that in a CIFAR-10 network we can leak up to $80\\%$\nof the model's weights with practically no security impact, while the necessary\nHE-mutliplications are performed four times faster.",
    "descriptor": "\nComments: P. Rizomiliotis, C. Diou, A. Triakosia, I. Kyrannas and K. Tserpes. Partially oblivious neural network inference. In Proceedings of the 19th International Conference on Security and Cryptography, SECRYPT (pp. 158-169), 2022\n",
    "authors": [
      "Panagiotis Rizomiliotis",
      "Christos Diou",
      "Aikaterini Triakosia",
      "Ilias Kyrannas",
      "Konstantinos Tserpes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15189"
  },
  {
    "id": "arXiv:2210.15191",
    "title": "Truncation Sampling as Language Model Desmoothing",
    "abstract": "Long samples of text from neural language models can be of poor quality.\nTruncation sampling algorithms--like top-$p$ or top-$k$ -- address this by\nsetting some words' probabilities to zero at each step. This work provides\nframing for the aim of truncation, and an improved algorithm for that aim. We\npropose thinking of a neural language model as a mixture of a true distribution\nand a smoothing distribution that avoids infinite perplexity. In this light,\ntruncation algorithms aim to perform desmoothing, estimating a subset of the\nsupport of the true distribution. Finding a good subset is crucial: we show\nthat top-$p$ unnecessarily truncates high-probability words, for example\ncausing it to truncate all words but Trump for a document that starts with\nDonald. We introduce $\\eta$-sampling, which truncates words below an\nentropy-dependent probability threshold. Compared to previous algorithms,\n$\\eta$-sampling generates more plausible long English documents according to\nhumans, is better at breaking out of repetition, and behaves more reasonably on\na battery of test distributions.",
    "descriptor": "\nComments: Findings of EMNLP, + small fixes\n",
    "authors": [
      "John Hewitt",
      "Christopher D. Manning",
      "Percy Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15191"
  },
  {
    "id": "arXiv:2210.15192",
    "title": "Monte Carlo method for parabolic equations involving fractional  Laplacian",
    "abstract": "We apply the Monte Carlo method to solving the Dirichlet problem of linear\nparabolic equations with fractional Laplacian. This method exploit- s the idea\nof weak approximation of related stochastic differential equations driven by\nthe symmetric stable L\\'evy process with jumps. We utilize the jump- adapted\nscheme to approximate L\\'evy process which gives exact exit time to the\nboundary. When the solution has low regularity, we establish a numeri- cal\nscheme by removing the small jumps of the L\\'evy process and then show the\nconvergence order. When the solution has higher regularity, we build up a\nhigher-order numerical scheme by replacing small jumps with a simple process\nand then display the higher convergence order. Finally, numerical experiments\nincluding ten- and one hundred-dimensional cases are presented, which confirm\nthe theoretical estimates and show the numerical efficiency of the proposed\nschemes for high dimensional parabolic equations.",
    "descriptor": "\nComments: 30pages 2 figures\n",
    "authors": [
      "Caiyu Jiao",
      "Changpin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15192"
  },
  {
    "id": "arXiv:2210.15194",
    "title": "Few-shot Image Generation via Masked Discrimination",
    "abstract": "Few-shot image generation aims to generate images of high quality and great\ndiversity with limited data. However, it is difficult for modern GANs to avoid\noverfitting when trained on only a few images. The discriminator can easily\nremember all the training samples and guide the generator to replicate them,\nleading to severe diversity degradation. Several methods have been proposed to\nrelieve overfitting by adapting GANs pre-trained on large source domains to\ntarget domains with limited real samples. In this work, we present a novel\napproach to realize few-shot GAN adaptation via masked discrimination. Random\nmasks are applied to features extracted by the discriminator from input images.\nWe aim to encourage the discriminator to judge more diverse images which share\npartially common features with training samples as realistic images.\nCorrespondingly, the generator is guided to generate more diverse images\ninstead of replicating training samples. In addition, we employ cross-domain\nconsistency loss for the discriminator to keep relative distances between\nsamples in its feature space. The discriminator cross-domain consistency loss\nserves as another optimization target in addition to adversarial loss and\nguides adapted GANs to preserve more information learned from source domains\nfor higher image quality. The effectiveness of our approach is demonstrated\nboth qualitatively and quantitatively with higher quality and greater diversity\non a series of few-shot image generation tasks than prior methods.",
    "descriptor": "",
    "authors": [
      "Jingyuan Zhu",
      "Huimin Ma",
      "Jiansheng Chen",
      "Jian Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15194"
  },
  {
    "id": "arXiv:2210.15198",
    "title": "Watermarking for Out-of-distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection aims to identify OOD data based on\nrepresentations extracted from well-trained deep models. However, existing\nmethods largely ignore the reprogramming property of deep models and thus may\nnot fully unleash their intrinsic strength: without modifying parameters of a\nwell-trained deep model, we can reprogram this model for a new purpose via\ndata-level manipulation (e.g., adding a specific feature perturbation to the\ndata). This property motivates us to reprogram a classification model to excel\nat OOD detection (a new task), and thus we propose a general methodology named\nwatermarking in this paper. Specifically, we learn a unified pattern that is\nsuperimposed onto features of original data, and the model's detection\ncapability is largely boosted after watermarking. Extensive experiments verify\nthe effectiveness of watermarking, demonstrating the significance of the\nreprogramming property of deep models in OOD detection.",
    "descriptor": "",
    "authors": [
      "Qizhou Wang",
      "Feng Liu",
      "Yonggang Zhang",
      "Jing Zhang",
      "Chen Gong",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15198"
  },
  {
    "id": "arXiv:2210.15199",
    "title": "Characterising the Robustness of Reinforcement Learning for Continuous  Control using Disturbance Injection",
    "abstract": "In this study, we leverage the deliberate and systematic fault-injection\ncapabilities of an open-source benchmark suite to perform a series of\nexperiments on state-of-the-art deep and robust reinforcement learning\nalgorithms. We aim to benchmark robustness in the context of continuous action\nspaces -- crucial for deployment in robot control. We find that robustness is\nmore prominent for action disturbances than it is for disturbances to\nobservations and dynamics. We also observe that state-of-the-art approaches\nthat are not explicitly designed to improve robustness perform at a level\ncomparable to that achieved by those that are. Our study and results are\nintended to provide insight into the current state of safe and robust\nreinforcement learning and a foundation for the advancement of the field, in\nparticular, for deployment in robotic systems.",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Catherine R. Glossop",
      "Jacopo Panerati",
      "Amrit Krishnan",
      "Zhaocong Yuan",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15199"
  },
  {
    "id": "arXiv:2210.15200",
    "title": "Deep-MDS Framework for Recovering the 3D Shape of 2D Landmarks from a  Single Image",
    "abstract": "In this paper, a low parameter deep learning framework utilizing the\nNon-metric Multi-Dimensional scaling (NMDS) method, is proposed to recover the\n3D shape of 2D landmarks on a human face, in a single input image. Hence, NMDS\napproach is used for the first time to establish a mapping from a 2D landmark\nspace to the corresponding 3D shape space. A deep neural network learns the\npairwise dissimilarity among 2D landmarks, used by NMDS approach, whose\nobjective is to learn the pairwise 3D Euclidean distance of the corresponding\n2D landmarks on the input image. This scheme results in a symmetric\ndissimilarity matrix, with the rank larger than 2, leading the NMDS approach\ntoward appropriately recovering the 3D shape of corresponding 2D landmarks. In\nthe case of posed images and complex image formation processes like perspective\nprojection which causes occlusion in the input image, we consider an\nautoencoder component in the proposed framework, as an occlusion removal part,\nwhich turns different input views of the human face into a profile view. The\nresults of a performance evaluation using different synthetic and real-world\nhuman face datasets, including Besel Face Model (BFM), CelebA, CoMA - FLAME,\nand CASIA-3D, indicates the comparable performance of the proposed framework,\ndespite its small number of training parameters, with the related\nstate-of-the-art and powerful 3D reconstruction methods from the literature, in\nterms of efficiency and accuracy.",
    "descriptor": "",
    "authors": [
      "Shima Kamyab",
      "Zohreh Azimifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15200"
  },
  {
    "id": "arXiv:2210.15201",
    "title": "Multi-view Contrastive Learning with Additive Margin for Adaptive  Nasopharyngeal Carcinoma Radiotherapy Prediction",
    "abstract": "The prediction of adaptive radiation therapy (ART) prior to radiation therapy\n(RT) for nasopharyngeal carcinoma (NPC) patients is important to reduce\ntoxicity and prolong the survival of patients. Currently, due to the complex\ntumor micro-environment, a single type of high-resolution image can provide\nonly limited information. Meanwhile, the traditional softmax-based loss is\ninsufficient for quantifying the discriminative power of a model. To overcome\nthese challenges, we propose a supervised multi-view contrastive learning\nmethod with an additive margin (MMCon). For each patient, four medical images\nare considered to form multi-view positive pairs, which can provide additional\ninformation and enhance the representation of medical images. In addition, the\nembedding space is learned by means of contrastive learning. NPC samples from\nthe same patient or with similar labels will remain close in the embedding\nspace, while NPC samples with different labels will be far apart. To improve\nthe discriminative ability of the loss function, we incorporate a margin into\nthe contrastive learning. Experimental result show this new learning objective\ncan be used to find an embedding space that exhibits superior discrimination\nability for NPC images.",
    "descriptor": "\nComments: submitted to ICASSP 2023, 5 pages\n",
    "authors": [
      "Jiabao Sheng",
      "Yuanpeng Zhang",
      "Jing Cai",
      "Sai-Kit Lam",
      "Zhe Li",
      "Jiang Zhang",
      "Xinzhi Teng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15201"
  },
  {
    "id": "arXiv:2210.15202",
    "title": "A Survey on Parallelism and Determinism",
    "abstract": "Parallelism is often required for performance. In these situations an excess\nof non-determinism is harmful as it means the program can have several\ndifferent behaviours or even different results. Even in domains such as\nhigh-performance computing where parallelism is crucial for performance, the\ncomputed value should be deterministic. Unfortunately, non-determinism in\nprograms also allows dynamic scheduling of tasks, reacting to the first task\nthat succeeds, cancelling tasks that cannot lead to a result, etc.\nNon-determinism is thus both a desired asset or an undesired property depending\non the situation. In practice, it is often necessary to limit non-determinism\nand to identify precisely the sources of non-determinism in order to control\nwhat parts of a program are deterministic or not. This survey takes the\nperspective of programming languages, and studies how programming models can\nensure the determinism of parallel programs. This survey studies not only\ndeterministic languages but also programming models that prevent one\nparticularly demanding source of non-determinism: data races. Our objective is\nto compare existing solutions to the following questions: How programming\nlanguages can help programmers write programs that run in a parallel manner\nwithout visible non-determinism? What programming paradigms ensure this kind of\nproperties? We study these questions and discuss the merits and limitations of\ndifferent approaches.",
    "descriptor": "\nComments: ACM Computing Surveys, Association for Computing Machinery, 2022\n",
    "authors": [
      "Laure Gonnord",
      "Ludovic Henrio",
      "Lionel Morel",
      "Gabriel Radanne"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.15202"
  },
  {
    "id": "arXiv:2210.15203",
    "title": "Joint Optimization of Deployment and Trajectory in UAV and IRS-Assisted  IoT Data Collection System",
    "abstract": "Unmanned aerial vehicles (UAVs) can be applied in many Internet of Things\n(IoT) systems, e.g., smart farms, as a data collection platform. However, the\nUAV-IoT wireless channels may be occasionally blocked by trees or high-rise\nbuildings. An intelligent reflecting surface (IRS) can be applied to improve\nthe wireless channel quality by smartly reflecting the signal via a large\nnumber of low-cost passive reflective elements. This article aims to minimize\nthe energy consumption of the system by jointly optimizing the deployment and\ntrajectory of the UAV. The problem is formulated as a\nmixed-integer-and-nonlinear programming (MINLP), which is challenging to\naddress by the traditional solution, because the solution may easily fall into\nthe local optimal. To address this issue, we propose a joint optimization\nframework of deployment and trajectory (JOLT), where an adaptive whale\noptimization algorithm (AWOA) is applied to optimize the deployment of the UAV,\nand an elastic ring self-organizing map (ERSOM) is introduced to optimize the\ntrajectory of the UAV. Specifically, in AWOA, a variable-length population\nstrategy is applied to find the optimal number of stop points, and a nonlinear\nparameter a and a partial mutation rule are introduced to balance the\nexploration and exploitation. In ERSOM, a competitive neural network is also\nintroduced to learn the trajectory of the UAV by competitive learning, and a\nring structure is presented to avoid the trajectory intersection. Extensive\nexperiments are carried out to show the effectiveness of the proposed JOLT\nframework.",
    "descriptor": "\nComments: 11 pages, 7 figures, 4 tables\n",
    "authors": [
      "Li Dong",
      "Zhibin Liu",
      "Feibo Jiang",
      "Kezhi Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.15203"
  },
  {
    "id": "arXiv:2210.15205",
    "title": "Torque Controlled Locomotion of a Biped Robot with Link Flexibility",
    "abstract": "When a big and heavy robot moves, it exerts large forces on the environment\nand on its own structure, its angular momentum can varysubstantially, and even\nthe robot's structure can deform if there is a mechanical weakness. Under these\nconditions, standard locomotion controllers can fail easily. In this article,\nwe propose a complete control scheme to work with heavy robots in torque\ncontrol. The full centroidal dynamics is used to generate walking gaits online,\nlink deflections are taken into account to estimate the robot posture and all\npostural instructions are designed to avoid conflicting with each other,\nimproving balance. These choices reduce model and control errors, allowing our\ncentroidal stabilizer to compensate for the remaining residual errors. The\nstabilizer and motion generator are designed together to ensure feasibility\nunder the assumption of bounded errors. We deploy this scheme to control the\nlocomotion of the humanoid robot Talos, whose hip links flex when walking. It\nallows us to reach steps of 35~cm, for an average speed of 25~cm/sec, which is\namong the best performances so far for torque-controlled electric robots.",
    "descriptor": "\nComments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022), IEEE, Nov 2022, Ginowan, Okinawa, Japan\n",
    "authors": [
      "Nahuel A Villa",
      "Pierre Fernbach",
      "Maximilien Naveau",
      "Guilhem Saurel",
      "Ewen Dantec",
      "Nicolas Mansard",
      "Olivier Stasse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15205"
  },
  {
    "id": "arXiv:2210.15206",
    "title": "Learning on the Job: Self-Rewarding Offline-to-Online Finetuning for  Industrial Insertion of Novel Connectors from Vision",
    "abstract": "Learning-based methods in robotics hold the promise of generalization, but\nwhat can be done if a learned policy does not generalize to a new situation? In\nprinciple, if an agent can at least evaluate its own success (i.e., with a\nreward classifier that generalizes well even when the policy does not), it\ncould actively practice the task and finetune the policy in this situation. We\nstudy this problem in the setting of industrial insertion tasks, such as\ninserting connectors in sockets and setting screws. Existing algorithms rely on\nprecise localization of the connector or socket and carefully managed physical\nsetups, such as assembly lines, to succeed at the task. But in unstructured\nenvironments such as homes or even some industrial settings, robots cannot rely\non precise localization and may be tasked with previously unseen connectors.\nOffline reinforcement learning on a variety of connector insertion tasks is a\npotential solution, but what if the robot is tasked with inserting previously\nunseen connector? In such a scenario, we will still need methods that can\nrobustly solve such tasks with online practice. One of the main observations we\nmake in this work is that, with a suitable representation learning and domain\ngeneralization approach, it can be significantly easier for the reward function\nto generalize to a new but structurally similar task (e.g., inserting a new\ntype of connector) than for the policy. This means that a learned reward\nfunction can be used to facilitate the finetuning of the robot's policy in\nsituations where the policy fails to generalize in zero shot, but the reward\nfunction generalizes successfully. We show that such an approach can be\ninstantiated in the real world, pretrained on 50 different connectors, and\nsuccessfully finetuned to new connectors via the learned reward function.\nVideos can be viewed at https://sites.google.com/view/learningonthejob",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ashvin Nair",
      "Brian Zhu",
      "Gokul Narayanan",
      "Eugen Solowjow",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15206"
  },
  {
    "id": "arXiv:2210.15209",
    "title": "Timed Alignments with Mixed Moves",
    "abstract": "The subject of this paper is to study conformance checking for timed models,\nthat is, process models that consider both the sequence of events in a process\nas well as the timestamps at which each event is recorded. Time-aware process\nmining is a growing subfield of research, and as tools that seek to discover\ntiming related properties in processes develop, so does the need for\nconformance checking techniques that can tackle time constraints and provide\ninsightful quality measures for time-aware process models. In particular, one\nof the most useful conformance artefacts is the alignment, that is, finding the\nminimal changes necessary to correct a new observation to conform to a process\nmodel. This paper follows a previous one, where we have set our problem of\ntimed alignment. In the present paper, we solve the case where the metrics used\nto compare timed processes allows mixed moves, i.e. an error on the timestamp\nof an event may or may not have propagated to its successors, and provide\nlinear time algorithms for distance computation and alignment on models with\nsequential causal processes.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.01870\n",
    "authors": [
      "Neha Rino",
      "Thomas Chatain"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.15209"
  },
  {
    "id": "arXiv:2210.15212",
    "title": "COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with  Contrastive and Distributionally Robust Learning",
    "abstract": "We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to\nimprove the generalization ability of dense retrieval by combating the\ndistribution shifts between source training tasks and target scenarios. To\nmitigate the impact of document differences, COCO-DR continues pretraining the\nlanguage model on the target corpora to adapt the model to target distributions\nvia COtinuous COtrastive learning. To prepare for unseen target queries,\nCOCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to\nreweight samples from different source query clusters for improving model\nrobustness over rare queries during fine-tuning. COCO-DR achieves superior\naverage performance on BEIR, the zero-shot retrieval benchmark. At BERT Base\nscale, COCO-DR Base outperforms other ZeroDR models with 60x larger size. At\nBERT Large scale, COCO-DR Large outperforms the giant GPT-3 embedding model\nwhich has 500x more parameters. Our analysis show the correlation between\nCOCO-DR's effectiveness in combating distribution shifts and improving\nzero-shot accuracy. Our code and model can be found at\n\\url{https://github.com/OpenMatch/COCO-DR}.",
    "descriptor": "\nComments: EMNLP 2022 Main Conference (Code and Model can be found at this https URL)\n",
    "authors": [
      "Yue Yu",
      "Chenyan Xiong",
      "Si Sun",
      "Chao Zhang",
      "Arnold Overwijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15212"
  },
  {
    "id": "arXiv:2210.15214",
    "title": "Trust and Believe -- Should We? Evaluating the Trustworthiness of  Twitter Users",
    "abstract": "Social networking and micro-blogging services, such as Twitter, play an\nimportant role in sharing digital information. Despite the popularity and\nusefulness of social media, they are regularly abused by corrupt users. One of\nthese nefarious activities is so-called fake news -- a \"virus\" that has been\nspreading rapidly thanks to the hospitable environment provided by social media\nplatforms. The extensive spread of fake news is now becoming a major problem\nwith far-reaching negative repercussions on both individuals and society.\nHence, the identification of fake news on social media is a problem of utmost\nimportance that has attracted the interest not only of the research community\nbut most of the big players on both sides - such as Facebook, on the industry\nside, and political parties on the societal one. In this work, we create a\nmodel through which we hope to be able to offer a solution that will instill\ntrust in social network communities. Our model analyses the behaviour of 50,000\npoliticians on Twitter and assigns an influence score for each evaluated user\nbased on several collected and analysed features and attributes. Next, we\nclassify political Twitter users as either trustworthy or untrustworthy using\nrandom forest and support vector machine classifiers. An active learning model\nhas been used to classify any unlabeled ambiguous records from our dataset.\nFinally, to measure the performance of the proposed model, we used accuracy as\nthe main evaluation metric.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.08027\n",
    "authors": [
      "Tanveer Khan",
      "Antonis Michalas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15214"
  },
  {
    "id": "arXiv:2210.15219",
    "title": "Parsing linearizations appreciate PoS tags - but some are fussy about  errors",
    "abstract": "PoS tags, once taken for granted as a useful resource for syntactic parsing,\nhave become more situational with the popularization of deep learning. Recent\nwork on the impact of PoS tags on graph- and transition-based parsers suggests\nthat they are only useful when tagging accuracy is prohibitively high, or in\nlow-resource scenarios. However, such an analysis is lacking for the emerging\nsequence labeling parsing paradigm, where it is especially relevant as some\nmodels explicitly use PoS tags for encoding and decoding. We undertake a study\nand uncover some trends. Among them, PoS tags are generally more useful for\nsequence labeling parsers than for other paradigms, but the impact of their\naccuracy is highly encoding-dependent, with the PoS-based head-selection\nencoding being best only when both tagging accuracy and resource availability\nare high.",
    "descriptor": "\nComments: Accepted at AACL 2022\n",
    "authors": [
      "Alberto Mu\u00f1oz-Ortiz",
      "Mark Anderson",
      "David Vilares",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15219"
  },
  {
    "id": "arXiv:2210.15220",
    "title": "End-to-End Pareto Set Prediction with Graph Neural Networks for  Multi-objective Facility Location",
    "abstract": "The facility location problems (FLPs) are a typical class of NP-hard\ncombinatorial optimization problems, which are widely seen in the supply chain\nand logistics. Many mathematical and heuristic algorithms have been developed\nfor optimizing the FLP. In addition to the transportation cost, there are\nusually multiple conflicting objectives in realistic applications. It is\ntherefore desirable to design algorithms that find a set of Pareto solutions\nefficiently without enormous search cost. In this paper, we consider the\nmulti-objective facility location problem (MO-FLP) that simultaneously\nminimizes the overall cost and maximizes the system reliability. We develop a\nlearning-based approach to predicting the distribution probability of the\nentire Pareto set for a given problem. To this end, the MO-FLP is modeled as a\nbipartite graph optimization problem and two graph neural networks are\nconstructed to learn the implicit graph representation on nodes and edges. The\nnetwork outputs are then converted into the probability distribution of the\nPareto set, from which a set of non-dominated solutions can be sampled\nnon-autoregressively. Experimental results on MO-FLP instances of different\nscales show that the proposed approach achieves a comparable performance to a\nwidely used multi-objective evolutionary algorithm in terms of the solution\nquality while significantly reducing the computational cost for search.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Shiqing Liu",
      "Xueming Yan",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.15220"
  },
  {
    "id": "arXiv:2210.15221",
    "title": "TASA: Deceiving Question Answering Models by Twin Answer Sentences  Attack",
    "abstract": "We present Twin Answer Sentences Attack (TASA), an adversarial attack method\nfor question answering (QA) models that produces fluent and grammatical\nadversarial contexts while maintaining gold answers. Despite phenomenal\nprogress on general adversarial attacks, few works have investigated the\nvulnerability and attack specifically for QA models. In this work, we first\nexplore the biases in the existing models and discover that they mainly rely on\nkeyword matching between the question and context, and ignore the relevant\ncontextual relations for answer prediction. Based on two biases above, TASA\nattacks the target model in two folds: (1) lowering the model's confidence on\nthe gold answer with a perturbed answer sentence; (2) misguiding the model\ntowards a wrong answer with a distracting answer sentence. Equipped with\ndesigned beam search and filtering methods, TASA can generate more effective\nattacks than existing textual attack methods while sustaining the quality of\ncontexts, in extensive experiments on five QA datasets and human evaluations.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (long), 9 pages main + 2 pages references + 7 pages appendix\n",
    "authors": [
      "Yu Cao",
      "Dianqi Li",
      "Meng Fang",
      "Tianyi Zhou",
      "Jun Gao",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15221"
  },
  {
    "id": "arXiv:2210.15224",
    "title": "The Effect of Normalization for Bi-directional Amharic-English Neural  Machine Translation",
    "abstract": "Machine translation (MT) is one of the main tasks in natural language\nprocessing whose objective is to translate texts automatically from one natural\nlanguage to another. Nowadays, using deep neural networks for MT tasks has\nreceived great attention. These networks require lots of data to learn abstract\nrepresentations of the input and store it in continuous vectors. This paper\npresents the first relatively large-scale Amharic-English parallel sentence\ndataset. Using these compiled data, we build bi-directional Amharic-English\ntranslation models by fine-tuning the existing Facebook M2M100 pre-trained\nmodel achieving a BLEU score of 37.79 in Amharic-English 32.74 in\nEnglish-Amharic translation. Additionally, we explore the effects of Amharic\nhomophone normalization on the machine translation task. The results show that\nthe normalization of Amharic homophone characters increases the performance of\nAmharic-English machine translation in both directions.",
    "descriptor": "",
    "authors": [
      "Tadesse Destaw Belay",
      "Atnafu Lambebo Tonja",
      "Olga Kolesnikova",
      "Seid Muhie Yimam",
      "Abinew Ali Ayele",
      "Silesh Bogale Haile",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15224"
  },
  {
    "id": "arXiv:2210.15225",
    "title": "BERT-Flow-VAE: A Weakly-supervised Model for Multi-Label Text  Classification",
    "abstract": "Multi-label Text Classification (MLTC) is the task of categorizing documents\ninto one or more topics. Considering the large volumes of data and varying\ndomains of such tasks, fully supervised learning requires manually fully\nannotated datasets which is costly and time-consuming. In this paper, we\npropose BERT-Flow-VAE (BFV), a Weakly-Supervised Multi-Label Text\nClassification (WSMLTC) model that reduces the need for full supervision. This\nnew model (1) produces BERT sentence embeddings and calibrates them using a\nflow model, (2) generates an initial topic-document matrix by averaging results\nof a seeded sparse topic model and a textual entailment model which only\nrequire surface name of topics and 4-6 seed words per topic, and (3) adopts a\nVAE framework to reconstruct the embeddings under the guidance of the\ntopic-document matrix. Finally, (4) it uses the means produced by the encoder\nmodel in the VAE architecture as predictions for MLTC. Experimental results on\n6 multi-label datasets show that BFV can substantially outperform other\nbaseline WSMLTC models in key metrics and achieve approximately 84% performance\nof a fully-supervised model.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Ziwen Liu",
      "Josep Grau-Bove",
      "Scott Allan Orr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15225"
  },
  {
    "id": "arXiv:2210.15226",
    "title": "Iterative pseudo-forced alignment by acoustic CTC loss for  self-supervised ASR domain adaptation",
    "abstract": "High-quality data labeling from specific domains is costly and human\ntime-consuming. In this work, we propose a self-supervised domain adaptation\nmethod, based upon an iterative pseudo-forced alignment algorithm. The produced\nalignments are employed to customize an end-to-end Automatic Speech Recognition\n(ASR) and iteratively refined. The algorithm is fed with frame-wise character\nposteriors produced by a seed ASR, trained with out-of-domain data, and\noptimized throughout a Connectionist Temporal Classification (CTC) loss. The\nalignments are computed iteratively upon a corpus of broadcast TV. The process\nis repeated by reducing the quantity of text to be aligned or expanding the\nalignment window until finding the best possible audio-text alignment. The\nstarting timestamps, or temporal anchors, are produced uniquely based on the\nconfidence score of the last aligned utterance. This score is computed with the\npaths of the CTC-alignment matrix. With this methodology, no human-revised text\nreferences are required. Alignments from long audio files with low-quality\ntranscriptions, like TV captions, are filtered out by confidence score and\nready for further ASR adaptation. The obtained results, on both the Spanish\nRTVE2022 and CommonVoice databases, underpin the feasibility of using CTC-based\nsystems to perform: highly accurate audio-text alignments, domain adaptation\nand semi-supervised training of end-to-end ASR.",
    "descriptor": "\nComments: 5 pages, 4 figures, IberSPEECH2022\n",
    "authors": [
      "Fernando L\u00f3pez",
      "Jordi Luque"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15226"
  },
  {
    "id": "arXiv:2210.15230",
    "title": "How well can Text-to-Image Generative Models understand Ethical Natural  Language Interventions?",
    "abstract": "Text-to-image generative models have achieved unprecedented success in\ngenerating high-quality images based on natural language descriptions. However,\nit is shown that these models tend to favor specific social groups when\nprompted with neutral text descriptions (e.g., 'a photo of a lawyer').\nFollowing Zhao et al. (2021), we study the effect on the diversity of the\ngenerated images when adding ethical intervention that supports equitable\njudgment (e.g., 'if all individuals can be a lawyer irrespective of their\ngender') in the input prompts. To this end, we introduce an Ethical NaTural\nLanguage Interventions in Text-to-Image GENeration (ENTIGEN) benchmark dataset\nto evaluate the change in image generations conditional on ethical\ninterventions across three social axes -- gender, skin color, and culture.\nThrough ENTIGEN framework, we find that the generations from minDALL.E,\nDALL.E-mini and Stable Diffusion cover diverse social groups while preserving\nthe image quality. Preliminary studies indicate that a large change in the\nmodel predictions is triggered by certain phrases such as 'irrespective of\ngender' in the context of gender bias in the ethical interventions. We release\ncode and annotated data at https://github.com/Hritikbansal/entigen_emnlp.",
    "descriptor": "\nComments: 13 pages, 8 figures, 6 tables. Accepted as Oral Presentation at EMNLP 2022\n",
    "authors": [
      "Hritik Bansal",
      "Da Yin",
      "Masoud Monajatipoor",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15230"
  },
  {
    "id": "arXiv:2210.15231",
    "title": "Unsupervised Boundary-Aware Language Model Pretraining for Chinese  Sequence Labeling",
    "abstract": "Boundary information is critical for various Chinese language processing\ntasks, such as word segmentation, part-of-speech tagging, and named entity\nrecognition. Previous studies usually resorted to the use of a high-quality\nexternal lexicon, where lexicon items can offer explicit boundary information.\nHowever, to ensure the quality of the lexicon, great human effort is always\nnecessary, which has been generally ignored. In this work, we suggest\nunsupervised statistical boundary information instead, and propose an\narchitecture to encode the information directly into pre-trained language\nmodels, resulting in Boundary-Aware BERT (BABERT). We apply BABERT for feature\ninduction of Chinese sequence labeling tasks. Experimental results on ten\nbenchmarks of Chinese sequence labeling demonstrate that BABERT can provide\nconsistent improvements on all datasets. In addition, our method can complement\nprevious supervised lexicon exploration, where further improvements can be\nachieved when integrated with external lexicon information.",
    "descriptor": "\nComments: 12 pages, 2 figures, 7 tables, EMNLP 2022\n",
    "authors": [
      "Peijie Jiang",
      "Dingkun Long",
      "Yanzhao Zhang",
      "Pengjun Xie",
      "Meishan Zhang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15231"
  },
  {
    "id": "arXiv:2210.15232",
    "title": "Visualizing Squircular Implicit Surfaces",
    "abstract": "The squircle is an intermediate shape between the square and the circle. In\nthis paper, we examine and discuss equations for different types of squircles.\nWe then build upon these 2D shapes to come-up with various 3D surfaces based on\nsquircles.",
    "descriptor": "\nComments: 23 pages, 27 figures\n",
    "authors": [
      "Chamberlain Fong"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15232"
  },
  {
    "id": "arXiv:2210.15234",
    "title": "Creating a morphological and syntactic tagged corpus for the Uzbek  language",
    "abstract": "Nowadays, creation of the tagged corpora is becoming one of the most\nimportant tasks of Natural Language Processing (NLP). There are not enough\ntagged corpora to build machine learning models for the low-resource Uzbek\nlanguage. In this paper, we tried to fill that gap by developing a novel Part\nOf Speech (POS) and syntactic tagset for creating the syntactic and\nmorphologically tagged corpus of the Uzbek language. This work also includes\ndetailed description and presentation of a web-based application to work on a\ntagging as well. Based on the developed annotation tool and the software, we\nshare our experience results of the first stage of the tagged corpus creation",
    "descriptor": "",
    "authors": [
      "Maksud Sharipov",
      "Jamolbek Mattiev",
      "Jasur Sobirov",
      "Rustam Baltayev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15234"
  },
  {
    "id": "arXiv:2210.15235",
    "title": "Towards Better Text-Image Consistency in Text-to-Image Generation",
    "abstract": "Generating consistent and high-quality images from given texts is essential\nfor visual-language understanding. Although impressive results have been\nachieved in generating high-quality images, text-image consistency is still a\nmajor concern in existing GAN-based methods. Particularly, the most popular\nmetric $R$-precision may not accurately reflect the text-image consistency,\noften resulting in very misleading semantics in the generated images. Albeit\nits significance, how to design a better text-image consistency metric\nsurprisingly remains under-explored in the community. In this paper, we make a\nfurther step forward to develop a novel CLIP-based metric termed as Semantic\nSimilarity Distance (SSD), which is both theoretically founded from a\ndistributional viewpoint and empirically verified on benchmark datasets.\nBenefiting from the proposed metric, we further design the Parallel Deep Fusion\nGenerative Adversarial Networks (PDF-GAN), which can fuse semantic information\nat different granularities and capture accurate semantics. Equipped with two\nnovel plug-and-play components: Hard-Negative Sentence Constructor and Semantic\nProjection, the proposed PDF-GAN can mitigate inconsistent semantics and bridge\nthe text-image semantic gap. A series of experiments show that, as opposed to\ncurrent state-of-the-art methods, our PDF-GAN can lead to significantly better\ntext-image consistency while maintaining decent image quality on the CUB and\nCOCO datasets.",
    "descriptor": "",
    "authors": [
      "Zhaorui Tan",
      "Zihan Ye",
      "Xi Yang",
      "Qiufeng Wang",
      "Yuyao Yan",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15235"
  },
  {
    "id": "arXiv:2210.15236",
    "title": "Painting the black box white: experimental findings from applying XAI to  an ECG reading setting",
    "abstract": "The shift from symbolic AI systems to black-box, sub-symbolic, and\nstatistical ones has motivated a rapid increase in the interest toward\nexplainable AI (XAI), i.e. approaches to make black-box AI systems explainable\nto human decision makers with the aim of making these systems more acceptable\nand more usable tools and supports. However, we make the point that, rather\nthan always making black boxes transparent, these approaches are at risk of\n\\emph{painting the black boxes white}, thus failing to provide a level of\ntransparency that would increase the system's usability and comprehensibility;\nor, even, at risk of generating new errors, in what we termed the\n\\emph{white-box paradox}. To address these usability-related issues, in this\nwork we focus on the cognitive dimension of users' perception of explanations\nand XAI systems. To this aim, we designed and conducted a questionnaire-based\nexperiment by which we involved 44 cardiology residents and specialists in an\nAI-supported ECG reading task. In doing so, we investigated different research\nquestions concerning the relationship between users' characteristics (e.g.\nexpertise) and their perception of AI and XAI systems, including their trust,\nthe perceived explanations' quality and their tendency to defer the decision\nprocess to automation (i.e. technology dominance), as well as the mutual\nrelationships among these different dimensions. Our findings provide a\ncontribution to the evaluation of AI-based support systems from a Human-AI\ninteraction-oriented perspective and lay the ground for further investigation\nof XAI and its effects on decision making and user experience.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Federico Cabitza",
      "Matteo Cameli",
      "Andrea Campagner",
      "Chiara Natali",
      "Luca Ronzio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15236"
  },
  {
    "id": "arXiv:2210.15239",
    "title": "Data-Driven Process Optimization of Fused Filament Fabrication based on  In Situ Measurements",
    "abstract": "The tuning of fused filament fabrication parameters is notoriously\nchallenging. We propose an autonomous data-driven method to select parameters\nbased on in situ measurements. We use a laser sensor to evaluate the surface\nroughness of a printed part. We then correlate the roughness to the mechanical\nproperties of the part, and show how print quality affects mechanical\nperformance. Finally, we use Bayesian optimization to search for optimal print\nparameters. We demonstrate our method by printing liquid crystal polymer\nsamples, and successfully find parameters that produce high-performance prints\nand maximize the manufacturing process efficiency.",
    "descriptor": "\nComments: 7 pages, 6 figures. Submitted to IFAC WC 2023\n",
    "authors": [
      "Xavier Guidetti",
      "Marino K\u00fchne",
      "Yannick Nagel",
      "Efe C. Balta",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15239"
  },
  {
    "id": "arXiv:2210.15244",
    "title": "Learning Deep Robotic Skills on Riemannian manifolds",
    "abstract": "In this paper, we propose RiemannianFlow, a deep generative model that allows\nrobots to learn complex and stable skills evolving on Riemannian manifolds.\nExamples of Riemannian data in robotics include stiffness (symmetric and\npositive definite matrix (SPD)) and orientation (unit quaternion (UQ))\ntrajectories. For Riemannian data, unlike Euclidean ones, different dimensions\nare interconnected by geometric constraints which have to be properly\nconsidered during the learning process. Using distance preserving mappings, our\napproach transfers the data between their original manifold and the tangent\nspace, realizing the removing and re-fulfilling of the geometric constraints.\nThis allows to extend existing frameworks to learn stable skills from\nRiemannian data while guaranteeing the stability of the learning results. The\nability of RiemannianFlow to learn various data patterns and the stability of\nthe learned models are experimentally shown on a dataset of manifold motions.\nFurther, we analyze from different perspectives the robustness of the model\nwith different hyperparameter combinations. It turns out that the model's\nstability is not affected by different hyperparameters, a proper combination of\nthe hyperparameters leads to a significant improvement (up to 27.6%) of the\nmodel accuracy. Last, we show the effectiveness of RiemannianFlow in a real\npeg-in-hole (PiH) task where we need to generate stable and consistent position\nand orientation trajectories for the robot starting from different initial\nposes.",
    "descriptor": "",
    "authors": [
      "Weitao Wang",
      "Matteo Saveriano",
      "Fares J. Abu-Dakka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15244"
  },
  {
    "id": "arXiv:2210.15247",
    "title": "A few-shot learning approach with domain adaptation for personalized  real-life stress detection in close relationships",
    "abstract": "We design a metric learning approach that aims to address computational\nchallenges that yield from modeling human outcomes from ambulatory real-life\ndata. The proposed metric learning is based on a Siamese neural network (SNN)\nthat learns the relative difference between pairs of samples from a target user\nand non-target users, thus being able to address the scarcity of labelled data\nfrom the target. The SNN further minimizes the Wasserstein distance of the\nlearned embeddings between target and non-target users, thus mitigating the\ndistribution mismatch between the two. Finally, given the fact that the base\nrate of focal behaviors is different per user, the proposed method approximates\nthe focal base rate based on labelled samples that lay closest to the target,\nbased on which further minimizes the Wasserstein distance. Our method is\nexemplified for the purpose of hourly stress classification using real-life\nmultimodal data from 72 dating couples. Results in few-shot and one-shot\nlearning experiments indicate that proposed formulation benefits stress\nclassification and can help mitigate the aforementioned challenges.",
    "descriptor": "",
    "authors": [
      "Kexin Feng",
      "Jacqueline B. Duong",
      "Kayla E. Carta",
      "Sierra Walters",
      "Gayla Margolin",
      "Adela C. Timmons",
      "Theodora Chaspari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15247"
  },
  {
    "id": "arXiv:2210.15248",
    "title": "Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI",
    "abstract": "With the advance of natural language inference (NLI), a rising demand for NLI\nis to handle scientific texts. Existing methods depend on pre-trained models\n(PTM) which lack domain-specific knowledge. To tackle this drawback, we\nintroduce a scientific knowledge graph to generalize PTM to scientific domain.\nHowever, existing knowledge graph construction approaches suffer from some\ndrawbacks, i.e., expensive labeled data, failure to apply in other domains,\nlong inference time and difficulty extending to large corpora. Therefore, we\npropose an unsupervised knowledge graph construction method to build a\nscientific knowledge graph (SKG) without any labeled data. Moreover, to\nalleviate noise effect from SKG and complement knowledge in sentences better,\nwe propose an event-centric knowledge infusion method to integrate external\nknowledge into each event that is a fine-grained semantic unit in sentences.\nExperimental results show that our method achieves state-of-the-art performance\nand the effectiveness and reliability of SKG.",
    "descriptor": "",
    "authors": [
      "Chenglin Wang",
      "Yucheng Zhou",
      "Guodong Long",
      "Xiaodong Wang",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15248"
  },
  {
    "id": "arXiv:2210.15255",
    "title": "RePAST: A ReRAM-based PIM Accelerator for Second-order Training of DNN",
    "abstract": "The second-order training methods can converge much faster than first-order\noptimizers in DNN training. This is because the second-order training utilizes\nthe inversion of the second-order information (SOI) matrix to find a more\naccurate descent direction and step size. However, the huge SOI matrices bring\nsignificant computational and memory overheads in the traditional architectures\nlike GPU and CPU. On the other side, the ReRAM-based process-in-memory (PIM)\ntechnology is suitable for the second-order training because of the following\nthree reasons: First, PIM's computation happens in memory, which reduces data\nmovement overheads; Second, ReRAM crossbars can compute SOI's inversion in\n$O\\left(1\\right)$ time; Third, if architected properly, ReRAM crossbars can\nperform matrix inversion and vector-matrix multiplications which are important\nto the second-order training algorithms.\nNevertheless, current ReRAM-based PIM techniques still face a key challenge\nfor accelerating the second-order training. The existing ReRAM-based matrix\ninversion circuitry can only support 8-bit accuracy matrix inversion and the\ncomputational precision is not sufficient for the second-order training that\nneeds at least 16-bit accurate matrix inversion. In this work, we propose a\nmethod to achieve high-precision matrix inversion based on a proven 8-bit\nmatrix inversion (INV) circuitry and vector-matrix multiplication (VMM)\ncircuitry. We design \\archname{}, a ReRAM-based PIM accelerator architecture\nfor the second-order training. Moreover, we propose a software mapping scheme\nfor \\archname{} to further optimize the performance by fusing VMM and INV\ncrossbar. Experiment shows that \\archname{} can achieve an average of\n115.8$\\times$/11.4$\\times$ speedup and 41.9$\\times$/12.8$\\times$energy saving\ncompared to a GPU counterpart and PipeLayer on large-scale DNNs.",
    "descriptor": "\nComments: 13pages, 13 figures\n",
    "authors": [
      "Yilong Zhao",
      "Li Jiang",
      "Mingyu Gao",
      "Naifeng Jing",
      "Chengyang Gu",
      "Qidong Tang",
      "Fangxin Liu",
      "Tao Yang",
      "Xiaoyao Liang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.15255"
  },
  {
    "id": "arXiv:2210.15256",
    "title": "PolyGloT: A Personalized and Gamified eTutoring System",
    "abstract": "The digital age is changing the role of educators and pushing for a paradigm\nshift in the education system as a whole. Growing demand for general and\nspecialized education inside and outside classrooms is at the heart of this\nrising trend. In modern, heterogeneous learning environments, the\none-size-fits-all approach is proven to be fundamentally flawed.\nIndividualization through adaptivity is, therefore, crucial to nurture\nindividual potential and address accessibility needs and neurodiversity. By\nformalizing a learning framework that takes into account all these different\naspects, we aim to define and implement an open, content-agnostic, and\nextensible eTutoring platform to design and consume adaptive and gamified\nlearning experiences. Adaptive technology supplementing teaching can extend the\nreach of every teacher, making it possible to scale 1-1 learning experiences.\nThere are many successful existing technologies available but they come with\nfixed environments that are not always suitable for the targeted audiences of\nthe course material. This paper presents PolyGloT, a system able to help\nteachers to design and implement a gamified and adaptive learning paths.\nThrough it we address some important issues including the engagement, fairness,\nand effectiveness of learning environments. We do not only propose an\ninnovative platform that could foster the learning process of different\ndisciplines, but it could also help teachers and instructors in organizing\nlearning material in an easy-access repository",
    "descriptor": "\nComments: 6 pages; 5 figures\n",
    "authors": [
      "Antonio Bucchiarone",
      "Tommaso Martorella",
      "Diego Colombo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15256"
  },
  {
    "id": "arXiv:2210.15257",
    "title": "ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with  Knowledge-Enhanced Mixture-of-Denoising-Experts",
    "abstract": "Recent progress in diffusion models has revolutionized the popular technology\nof text-to-image generation. While existing approaches could produce\nphotorealistic high-resolution images with text conditions, there are still\nseveral open problems to be solved, which limits the further improvement of\nimage fidelity and text relevancy. In this paper, we propose ERNIE-ViLG 2.0, a\nlarge-scale Chinese text-to-image diffusion model, which progressively upgrades\nthe quality of generated images~by: (1) incorporating fine-grained textual and\nvisual knowledge of key elements in the scene, and (2) utilizing different\ndenoising experts at different denoising stages. With the proposed mechanisms,\nERNIE-ViLG 2.0 not only achieves the state-of-the-art on MS-COCO with zero-shot\nFID score of 6.75, but also significantly outperforms recent models in terms of\nimage fidelity and image-text alignment, with side-by-side human evaluation on\nthe bilingual prompt set ViLG-300.",
    "descriptor": "",
    "authors": [
      "Zhida Feng",
      "Zhenyu Zhang",
      "Xintong Yu",
      "Yewei Fang",
      "Lanxin Li",
      "Xuyi Chen",
      "Yuxiang Lu",
      "Jiaxiang Liu",
      "Weichong Yin",
      "Shikun Feng",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15257"
  },
  {
    "id": "arXiv:2210.15259",
    "title": "High SNR Analysis of RIS aided MIMO BC Channels",
    "abstract": "We analyze the influence of an reconfigurable intelligent surface (RIS) on\nthe channel eigenvalues within a high signal-to-noise ratio (SNR) scenario.\nThis allows to connect specific channel properties with the rank improvement\ncapabilities of the RIS. In particular, fundamental limits due to a possible\nline of sight (LOS) setup between the base station (BS) and the RIS are\nderived. Furthermore, dirty paper coding (DPC) based schemes are compared to\nlinear precoding in such a scenario and it is shown that under certain channel\nconditions, the performance gap between DPC and linear precoding can be made\narbitrarily small by the RIS.",
    "descriptor": "",
    "authors": [
      "Dominik Semmler",
      "Michael Joham",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15259"
  },
  {
    "id": "arXiv:2210.15261",
    "title": "A knowledge-driven vowel-based approach of depression classification  from speech using data augmentation",
    "abstract": "We propose a novel explainable machine learning (ML) model that identifies\ndepression from speech, by modeling the temporal dependencies across utterances\nand utilizing the spectrotemporal information at the vowel level. Our method\nfirst models the variable-length utterances at the local-level into a\nfixed-size vowel-based embedding using a convolutional neural network with a\nspatial pyramid pooling layer (\"vowel CNN\"). Following that, the depression is\nclassified at the global-level from a group of vowel CNN embeddings that serve\nas the input of another 1D CNN (\"depression CNN\"). Different data augmentation\nmethods are designed for both the training of vowel CNN and depression CNN. We\ninvestigate the performance of the proposed system at various temporal\ngranularities when modeling short, medium, and long analysis windows,\ncorresponding to 10, 21, and 42 utterances, respectively. The proposed method\nreaches comparable performance with previous state-of-the-art approaches and\ndepicts explainable properties with respect to the depression outcome. The\nfindings from this work may benefit clinicians by providing additional\nintuitions during joint human-ML decision-making tasks.",
    "descriptor": "",
    "authors": [
      "Kexin Feng",
      "Theodora Chaspari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15261"
  },
  {
    "id": "arXiv:2210.15265",
    "title": "Conversation Disentanglement with Bi-Level Contrastive Learning",
    "abstract": "Conversation disentanglement aims to group utterances into detached sessions,\nwhich is a fundamental task in processing multi-party conversations. Existing\nmethods have two main drawbacks. First, they overemphasize pairwise utterance\nrelations but pay inadequate attention to the utterance-to-context relation\nmodeling. Second, huge amount of human annotated data is required for training,\nwhich is expensive to obtain in practice. To address these issues, we propose a\ngeneral disentangle model based on bi-level contrastive learning. It brings\ncloser utterances in the same session while encourages each utterance to be\nnear its clustered session prototypes in the representation space. Unlike\nexisting approaches, our disentangle model works in both supervised setting\nwith labeled data and unsupervised setting when no such data is available. The\nproposed method achieves new state-of-the-art performance on both settings\nacross several public datasets.",
    "descriptor": "",
    "authors": [
      "Chengyu Huang",
      "Zheng Zhang",
      "Hao Fei",
      "Lizi Liao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15265"
  },
  {
    "id": "arXiv:2210.15274",
    "title": "Improved Feature Distillation via Projector Ensemble",
    "abstract": "In knowledge distillation, previous feature distillation methods mainly focus\non the design of loss functions and the selection of the distilled layers,\nwhile the effect of the feature projector between the student and the teacher\nremains under-explored. In this paper, we first discuss a plausible mechanism\nof the projector with empirical evidence and then propose a new feature\ndistillation method based on a projector ensemble for further performance\nimprovement. We observe that the student network benefits from a projector even\nif the feature dimensions of the student and the teacher are the same. Training\na student backbone without a projector can be considered as a multi-task\nlearning process, namely achieving discriminative feature extraction for\nclassification and feature matching between the student and the teacher for\ndistillation at the same time. We hypothesize and empirically verify that\nwithout a projector, the student network tends to overfit the teacher's feature\ndistributions despite having different architecture and weights initialization.\nThis leads to degradation on the quality of the student's deep features that\nare eventually used in classification. Adding a projector, on the other hand,\ndisentangles the two learning tasks and helps the student network to focus\nbetter on the main feature extraction task while still being able to utilize\nteacher features as a guidance through the projector. Motivated by the positive\neffect of the projector in feature distillation, we propose an ensemble of\nprojectors to further improve the quality of student features. Experimental\nresults on different datasets with a series of teacher-student pairs illustrate\nthe effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yudong Chen",
      "Sen Wang",
      "Jiajun Liu",
      "Xuwei Xu",
      "Frank de Hoog",
      "Zi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15274"
  },
  {
    "id": "arXiv:2210.15279",
    "title": "On the Approximation and Complexity of Deep Neural Networks to Invariant  Functions",
    "abstract": "Recent years have witnessed a hot wave of deep neural networks in various\ndomains; however, it is not yet well understood theoretically. A theoretical\ncharacterization of deep neural networks should point out their approximation\nability and complexity, i.e., showing which architecture and size are\nsufficient to handle the concerned tasks. This work takes one step on this\ndirection by theoretically studying the approximation and complexity of deep\nneural networks to invariant functions. We first prove that the invariant\nfunctions can be universally approximated by deep neural networks. Then we show\nthat a broad range of invariant functions can be asymptotically approximated by\nvarious types of neural network models that includes the complex-valued neural\nnetworks, convolutional neural networks, and Bayesian neural networks using a\npolynomial number of parameters or optimization iterations. We also provide a\nfeasible application that connects the parameter estimation and forecasting of\nhigh-resolution signals with our theoretical conclusions. The empirical results\nobtained on simulation experiments demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Gao Zhang",
      "Jin-Hui Wu",
      "Shao-Qun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15279"
  },
  {
    "id": "arXiv:2210.15280",
    "title": "A matrix-free ILU realization based on surrogates",
    "abstract": "Matrix-free techniques play an increasingly important role in large-scale\nsimulations. Schur complement techniques and massively parallel multigrid\nsolvers for second-order elliptic partial differential equations can\nsignificantly benefit from reduced memory traffic and consumption. The\nmatrix-free approach often restricts solver components to purely local\noperations, for instance, the Jacobi- or Gauss--Seidel-Smoothers in multigrid\nmethods. An incomplete LU (ILU) decomposition cannot be calculated from local\ninformation and is therefore not amenable to an on-the-fly computation which is\ntypically needed for matrix-free calculations. It generally requires the\nstorage and factorization of a sparse matrix which contradicts the low memory\nrequirements in large scale scenarios. In this work, we propose a matrix-free\nILU realization. More precisely, we introduce a memory-efficient, matrix-free\nILU(0)-Smoother component for low-order conforming finite elements on\ntetrahedral hybrid grids. Hybrid grids consist of an unstructured macro-mesh\nwhich is subdivided into a structured micro-mesh. The ILU(0) is used for\ndegrees-of-freedom assigned to the interior of macro-tetrahedra. This\nILU(0)-Smoother can be used for the efficient matrix-free evaluation of the\nSteklov-Poincare operator from domain-decomposition methods. After introducing\nand formally defining our smoother, we investigate its performance on refined\nmacro-tetrahedra. Secondly, the ILU(0)-Smoother on the macro-tetrahedrons is\nimplemented via surrogate matrix polynomials in conjunction with a fast\non-the-fly evaluation scheme resulting in an efficient matrix-free algorithm.\nThe polynomial coefficients are obtained by solving a least-squares problem on\na small part of the factorized ILU(0) matrices to stay memory efficient. The\nconvergence rates of this smoother with respect to the polynomial order are\nthoroughly studied.",
    "descriptor": "",
    "authors": [
      "Daniel Drzisga",
      "Andreas Wagner",
      "Barbara Wohlmuth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15280"
  },
  {
    "id": "arXiv:2210.15281",
    "title": "The 1st-place Solution for ECCV 2022 Multiple People Tracking in Group  Dance Challenge",
    "abstract": "We present our 1st place solution to the Group Dance Multiple People Tracking\nChallenge. Based on MOTR: End-to-End Multiple-Object Tracking with Transformer,\nwe explore: 1) detect queries as anchors, 2) tracking as query denoising, 3)\njoint training on pseudo video clips generated from CrowdHuman dataset, and 4)\nusing the YOLOX detection proposals for the anchor initialization of detect\nqueries. Our method achieves 73.4% HOTA on the DanceTrack test set, surpassing\nthe second-place solution by +6.8% HOTA.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yuang Zhang",
      "Tiancai Wang",
      "Weiyao Lin",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15281"
  },
  {
    "id": "arXiv:2210.15283",
    "title": "On Out-of-Distribution Detection for Audio with Deep Nearest Neighbors",
    "abstract": "Out-of-distribution (OOD) detection is concerned with identifying data points\nthat do not belong to the same distribution as the model's training data. For\nthe safe deployment of predictive models in a real-world environment, it is\ncritical to avoid making confident predictions on OOD inputs as it can lead to\npotentially dangerous consequences. However, OOD detection largely remains an\nunder-explored area in the audio (and speech) domain. This is despite the fact\nthat audio is a central modality for many tasks, such as speaker diarization,\nautomatic speech recognition, and sound event detection. To address this, we\npropose to leverage feature-space of the model with deep k-nearest neighbors to\ndetect OOD samples. We show that this simple and flexible method effectively\ndetects OOD inputs across a broad category of audio (and speech) datasets.\nSpecifically, it improves the false positive rate (FPR@TPR95) by 17% and the\nAUROC score by 7% than other prior techniques.",
    "descriptor": "",
    "authors": [
      "Zaharah Bukhsh",
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15283"
  },
  {
    "id": "arXiv:2210.15285",
    "title": "SAN: a robust end-to-end ASR model architecture",
    "abstract": "In this paper, we propose a novel Siamese Adversarial Network (SAN)\narchitecture for automatic speech recognition, which aims at solving the\ndifficulty of fuzzy audio recognition. Specifically, SAN constructs two\nsub-networks to differentiate the audio feature input and then introduces a\nloss to unify the output distribution of these sub-networks. Adversarial\nlearning enables the network to capture more essential acoustic features and\nhelps the models achieve better performance when encountering fuzzy audio\ninput. We conduct numerical experiments with the SAN model on several datasets\nfor the automatic speech recognition task. All experimental results show that\nthe siamese adversarial nets significantly reduce the character error rate\n(CER). Specifically, we achieve a new state of art 4.37 CER without language\nmodel on the AISHELL-1 dataset, which leads to around 5% relative CER\nreduction. To reveal the generality of the siamese adversarial net, we also\nconduct experiments on the phoneme recognition task, which also shows the\nsuperiority of the siamese adversarial network.",
    "descriptor": "",
    "authors": [
      "Zeping Min",
      "Qian Ge",
      "Guanhua Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15285"
  },
  {
    "id": "arXiv:2210.15287",
    "title": "Learned Inertial Odometry for Autonomous Drone Racing",
    "abstract": "Inertial odometry is an attractive solution to the problem of state\nestimation for agile quadrotor flight. It is inexpensive, lightweight, and it\nis not affected by perceptual degradation. However, only relying on the\nintegration of the inertial measurements for state estimation is infeasible.\nThe errors and time-varying biases present in such measurements cause the\naccumulation of large drift in the pose estimates. Recently, inertial odometry\nhas made significant progress in estimating the motion of pedestrians.\nState-of-the-art algorithms rely on learning a motion prior that is typical of\nhumans but cannot be transferred to drones. In this work, we propose a\nlearning-based odometry algorithm that uses an inertial measurement unit (IMU)\nas the only sensor modality for autonomous drone racing tasks. The core idea of\nour system is to couple a model-based filter, driven by the inertial\nmeasurements, with a learning-based module that has access to the control\ncommands. We show that our inertial odometry algorithm is superior to the\nstate-of-the-art filter-based and optimization-based visual- inertial odometry\nas well as the state-of-the-art learned-inertial odometry. Additionally, we\nshow that our system is comparable to a visual-inertial odometry solution that\nuses a camera and exploits the known gate location and appearance. We believe\nthat the application in autonomous drone racing paves the way for novel\nresearch in inertial odometry for agile quadrotor flight. We will release the\ncode upon acceptance.",
    "descriptor": "",
    "authors": [
      "Giovanni Cioffi",
      "Leonard Bauersfeld",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15287"
  },
  {
    "id": "arXiv:2210.15289",
    "title": "On the Efficiency of Ethics as a Governing Tool for Artificial  Intelligence",
    "abstract": "The 4th Industrial Revolution is the culmination of the digital age.\nNowadays, technologies such as robotics, nanotechnology, genetics, and\nartificial intelligence promise to transform our world and the way we live.\nArtificial Intelligence Ethics and Safety is an emerging research field that\nhas been gaining popularity in recent years. Several private, public and\nnon-governmental organizations have published guidelines proposing ethical\nprinciples for regulating the use and development of autonomous intelligent\nsystems. Meta-analyses of the AI Ethics research field point to convergence on\ncertain principles that supposedly govern the AI industry. However, little is\nknown about the effectiveness of this form of Ethics. In this paper, we would\nlike to conduct a critical analysis of the current state of AI Ethics and\nsuggest that this form of governance based on principled ethical guidelines is\nnot sufficient to norm the AI industry and its developers. We believe that\ndrastic changes are necessary, both in the training processes of professionals\nin the fields related to the development of software and intelligent systems\nand in the increased regulation of these professionals and their industry. To\nthis end, we suggest that law should benefit from recent contributions from\nbioethics, to make the contributions of AI ethics to governance explicit in\nlegal terms.",
    "descriptor": "",
    "authors": [
      "Nicholas Kluge Corr\u00eaa",
      "Nythamar De Oliveira",
      "Diogo Massmann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15289"
  },
  {
    "id": "arXiv:2210.15291",
    "title": "Isometric 3D Adversarial Examples in the Physical World",
    "abstract": "3D deep learning models are shown to be as vulnerable to adversarial examples\nas 2D models. However, existing attack methods are still far from stealthy and\nsuffer from severe performance degradation in the physical world. Although 3D\ndata is highly structured, it is difficult to bound the perturbations with\nsimple metrics in the Euclidean space. In this paper, we propose a novel\n$\\epsilon$-isometric ($\\epsilon$-ISO) attack to generate natural and robust 3D\nadversarial examples in the physical world by considering the geometric\nproperties of 3D objects and the invariance to physical transformations. For\nnaturalness, we constrain the adversarial example to be $\\epsilon$-isometric to\nthe original one by adopting the Gaussian curvature as a surrogate metric\nguaranteed by a theoretical analysis. For invariance to physical\ntransformations, we propose a maxima over transformation (MaxOT) method that\nactively searches for the most harmful transformations rather than random ones\nto make the generated adversarial example more robust in the physical world.\nExperiments on typical point cloud recognition models validate that our\napproach can significantly improve the attack success rate and naturalness of\nthe generated 3D adversarial examples than the state-of-the-art attack methods.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yibo Miao",
      "Yinpeng Dong",
      "Jun Zhu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15291"
  },
  {
    "id": "arXiv:2210.15294",
    "title": "Modeling Inter-Dependence Between Time and Mark in Multivariate Temporal  Point Processes",
    "abstract": "Temporal Point Processes (TPP) are probabilistic generative frameworks. They\nmodel discrete event sequences localized in continuous time. Generally,\nreal-life events reveal descriptive information, known as marks. Marked TPPs\nmodel time and marks of the event together for practical relevance. Conditioned\non past events, marked TPPs aim to learn the joint distribution of the time and\nthe mark of the next event. For simplicity, conditionally independent TPP\nmodels assume time and marks are independent given event history. They\nfactorize the conditional joint distribution of time and mark into the product\nof individual conditional distributions. This structural limitation in the\ndesign of TPP models hurt the predictive performance on entangled time and mark\ninteractions. In this work, we model the conditional inter-dependence of time\nand mark to overcome the limitations of conditionally independent models. We\nconstruct a multivariate TPP conditioning the time distribution on the current\nevent mark in addition to past events. Besides the conventional intensity-based\nmodels for conditional joint distribution, we also draw on flexible\nintensity-free TPP models from the literature. The proposed TPP models\noutperform conditionally independent and dependent models in standard\nprediction tasks. Our experimentation on various datasets with multiple\nevaluation metrics highlights the merit of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Govind Waghmare",
      "Ankur Debnath",
      "Siddhartha Asthana",
      "Aakarsh Malhotra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15294"
  },
  {
    "id": "arXiv:2210.15300",
    "title": "Leveraging Computer Vision Application in Visual Arts: A Case Study on  the Use of Residual Neural Network to Classify and Analyze Baroque Paintings",
    "abstract": "With the increasing availability of large digitized fine art collections,\nautomated analysis and classification of paintings is becoming an interesting\narea of research. However, due to domain specificity, implicit subjectivity,\nand pervasive nuances that vaguely separate art movements, analyzing art using\nmachine learning techniques poses significant challenges. Residual networks, or\nvariants thereof, are one the most popular tools for image classification\ntasks, which can extract relevant features for well-defined classes. In this\ncase study, we focus on the classification of a selected painting 'Portrait of\nthe Painter Charles Bruni' by Johann Kupetzky and the analysis of the\nperformance of the proposed classifier. We show that the features extracted\nduring residual network training can be useful for image retrieval within\nsearch systems in online art collections.",
    "descriptor": "",
    "authors": [
      "Daniel Kvak"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15300"
  },
  {
    "id": "arXiv:2210.15303",
    "title": "Can language models handle recursively nested grammatical structures? A  case study on comparing models and humans",
    "abstract": "How should we compare the capabilities of language models and humans? Here, I\nconsider a case study: processing of recursively nested grammatical structures.\nPrior work has suggested that language models cannot handle these structures as\nreliably as humans can. However, the humans were provided with instructions and\ntraining before being evaluated, while the language models were evaluated\nzero-shot. I therefore attempt to more closely match the evaluation paradigms\nby providing language models with few-shot prompts. A simple prompt, which\ncontains substantially less content than the human training, allows large\nlanguage models to consistently outperform the human results. The same prompt\neven allows extrapolation to more-deeply-nested conditions than have been\ntested in humans. Further, a reanalysis of the prior human experiments suggests\nthat the humans may not perform above chance at the difficult structures\ninitially. These results suggest that large language models can in fact process\nrecursively nested grammatical structures comparably to humans. This case study\nhighlights how discrepancies in the quantity of experiment-specific context can\nconfound comparisons of language models and humans. I use this case study to\nreflect on the broader challenge of comparing human and model capabilities, and\nto suggest that there is an important difference between evaluating cognitive\nmodels of a specific phenomenon and evaluating broadly-trained models.",
    "descriptor": "",
    "authors": [
      "Andrew Kyle Lampinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15303"
  },
  {
    "id": "arXiv:2210.15304",
    "title": "Explaining the Explainers in Graph Neural Networks: a Comparative Study",
    "abstract": "Following a fast initial breakthrough in graph based learning, Graph Neural\nNetworks (GNNs) have reached a widespread application in many science and\nengineering fields, prompting the need for methods to understand their decision\nprocess.\nGNN explainers have started to emerge in recent years, with a multitude of\nmethods both novel or adapted from other domains. To sort out this plethora of\nalternative approaches, several studies have benchmarked the performance of\ndifferent explainers in terms of various explainability metrics. However, these\nearlier works make no attempts at providing insights into why different GNN\narchitectures are more or less explainable, or which explainer should be\npreferred in a given setting.\nIn this survey, we fill these gaps by devising a systematic experimental\nstudy, which tests ten explainers on eight representative architectures trained\non six carefully designed graph and node classification datasets. With our\nresults we provide key insights on the choice and applicability of GNN\nexplainers, we isolate key components that make them usable and successful and\nprovide recommendations on how to avoid common interpretation pitfalls. We\nconclude by highlighting open questions and directions of possible future\nresearch.",
    "descriptor": "",
    "authors": [
      "Antonio Longa",
      "Steve Azzolin",
      "Gabriele Santin",
      "Giulia Cencetti",
      "Pietro Li\u00f2",
      "Bruno Lepri",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15304"
  },
  {
    "id": "arXiv:2210.15305",
    "title": "Deformable Temporal Convolutional Networks for Monaural Noisy  Reverberant Speech Separation",
    "abstract": "Speech separation models are used for isolating individual speakers in many\nspeech processing applications. Deep learning models have been shown to lead to\nstate-of-the-art (SOTA) results on a number of speech separation benchmarks.\nOne such class of models known as temporal convolutional networks (TCNs) has\nshown promising results for speech separation tasks. A limitation of these\nmodels is that they have a fixed receptive field (RF). Recent research in\nspeech dereverberation has shown that the optimal RF of a TCN varies with the\nreverberation characteristics of the speech signal. In this work deformable\nconvolution is proposed as a solution to allow TCN models to have dynamic RFs\nthat can adapt to various reverberation times for reverberant speech\nseparation. The proposed models are capable of achieving an 11.1 dB average\nscale-invariant signal-to-distortion ratio (SISDR) improvement over the input\nsignal on the WHAMR benchmark. A relatively small deformable TCN model of 1.3M\nparameters is proposed which gives comparable separation performance to larger\nand more computationally complex models.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15305"
  },
  {
    "id": "arXiv:2210.15306",
    "title": "Rigid-Body Sound Synthesis with Differentiable Modal Resonators",
    "abstract": "Physical models of rigid bodies are used for sound synthesis in applications\nfrom virtual environments to music production. Traditional methods such as\nmodal synthesis often rely on computationally expensive numerical solvers,\nwhile recent deep learning approaches are limited by post-processing of their\nresults. In this work we present a novel end-to-end framework for training a\ndeep neural network to generate modal resonators for a given 2D shape and\nmaterial, using a bank of differentiable IIR filters. We demonstrate our method\non a dataset of synthetic objects, but train our model using an audio-domain\nobjective, paving the way for physically-informed synthesisers to be learned\ndirectly from recordings of real-world objects.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "R. Diaz",
      "B. Hayes",
      "C. Saitis",
      "G. Fazekas",
      "M. Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15306"
  },
  {
    "id": "arXiv:2210.15315",
    "title": "Noise in the Clouds: Influence of Network Performance Variability on  Application Scalability",
    "abstract": "Cloud computing represents an appealing opportunity for cost-effective\ndeployment of HPC workloads on the best-fitting hardware. However, although\ncloud and on-premise HPC systems offer similar computational resources, their\nnetwork architecture and performance may differ significantly. For example,\nthese systems use fundamentally different network transport and routing\nprotocols, which may introduce network noise that can eventually limit the\napplication scaling. This work analyzes network performance, scalability, and\ncost of running HPC workloads on cloud systems. First, we consider latency,\nbandwidth, and collective communication patterns in detailed small-scale\nmeasurements, and then we simulate network performance at a larger scale. We\nvalidate our approach on four popular cloud providers and three on-premise HPC\nsystems, showing that network (and also OS) noise can significantly impact\nperformance and cost both at small and large scale.",
    "descriptor": "\nComments: To appear in SIGMETRICS 2023\n",
    "authors": [
      "Daniele De Sensi",
      "Tiziano De Matteis",
      "Konstantin Taranov",
      "Salvatore Di Girolamo",
      "Tobias Rahn",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.15315"
  },
  {
    "id": "arXiv:2210.15316",
    "title": "MSF3DDETR: Multi-Sensor Fusion 3D Detection Transformer for Autonomous  Driving",
    "abstract": "3D object detection is a significant task for autonomous driving. Recently\nwith the progress of vision transformers, the 2D object detection problem is\nbeing treated with the set-to-set loss. Inspired by these approaches on 2D\nobject detection and an approach for multi-view 3D object detection DETR3D, we\npropose MSF3DDETR: Multi-Sensor Fusion 3D Detection Transformer architecture to\nfuse image and LiDAR features to improve the detection accuracy. Our end-to-end\nsingle-stage, anchor-free and NMS-free network takes in multi-view images and\nLiDAR point clouds and predicts 3D bounding boxes. Firstly, we link the object\nqueries learnt from data to the image and LiDAR features using a novel\nMSF3DDETR cross-attention block. Secondly, the object queries interacts with\neach other in multi-head self-attention block. Finally, MSF3DDETR block is\nrepeated for $L$ number of times to refine the object queries. The MSF3DDETR\nnetwork is trained end-to-end on the nuScenes dataset using Hungarian algorithm\nbased bipartite matching and set-to-set loss inspired by DETR. We present both\nquantitative and qualitative results which are competitive to the\nstate-of-the-art approaches.",
    "descriptor": "\nComments: Accepted at the ICPR 2022 Workshop DLVDR2022\n",
    "authors": [
      "Gopi Krishna Erabati",
      "Helder Araujo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15316"
  },
  {
    "id": "arXiv:2210.15318",
    "title": "Efficient and Effective Augmentation Strategy for Adversarial Training",
    "abstract": "Adversarial training of Deep Neural Networks is known to be significantly\nmore data-hungry when compared to standard training. Furthermore, complex data\naugmentations such as AutoAugment, which have led to substantial gains in\nstandard training of image classifiers, have not been successful with\nAdversarial Training. We first explain this contrasting behavior by viewing\naugmentation during training as a problem of domain generalization, and further\npropose Diverse Augmentation-based Joint Adversarial Training (DAJAT) to use\ndata augmentations effectively in adversarial training. We aim to handle the\nconflicting goals of enhancing the diversity of the training dataset and\ntraining with data that is close to the test distribution by using a\ncombination of simple and complex augmentations with separate batch\nnormalization layers during training. We further utilize the popular\nJensen-Shannon divergence loss to encourage the joint learning of the diverse\naugmentations, thereby allowing simple augmentations to guide the learning of\ncomplex ones. Lastly, to improve the computational efficiency of the proposed\nmethod, we propose and utilize a two-step defense, Ascending Constraint\nAdversarial Training (ACAT), that uses an increasing epsilon schedule and\nweight-space smoothing to prevent gradient masking. The proposed method DAJAT\nachieves substantially better robustness-accuracy trade-off when compared to\nexisting methods on the RobustBench Leaderboard on ResNet-18 and\nWideResNet-34-10. The code for implementing DAJAT is available here:\nhttps://github.com/val-iisc/DAJAT.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Sravanti Addepalli",
      "Samyak Jain",
      "R.Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15318"
  },
  {
    "id": "arXiv:2210.15323",
    "title": "Stochastic Mirror Descent in Average Ensemble Models",
    "abstract": "The stochastic mirror descent (SMD) algorithm is a general class of training\nalgorithms, which includes the celebrated stochastic gradient descent (SGD), as\na special case. It utilizes a mirror potential to influence the implicit bias\nof the training algorithm. In this paper we explore the performance of the SMD\niterates on mean-field ensemble models. Our results generalize earlier ones\nobtained for SGD on such models. The evolution of the distribution of\nparameters is mapped to a continuous time process in the space of probability\ndistributions. Our main result gives a nonlinear partial differential equation\nto which the continuous time process converges in the asymptotic regime of\nlarge networks. The impact of the mirror potential appears through a\nmultiplicative term that is equal to the inverse of its Hessian and which can\nbe interpreted as defining a gradient flow over an appropriately defined\nRiemannian manifold. We provide numerical simulations which allow us to study\nand characterize the effect of the mirror potential on the performance of\nnetworks trained with SMD for some binary classification problems.",
    "descriptor": "",
    "authors": [
      "Taylan Kargin",
      "Fariborz Salehi",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15323"
  },
  {
    "id": "arXiv:2210.15327",
    "title": "Towards Language-centric Scientific AI",
    "abstract": "Inspired by recent and revolutionary developments in AI, particularly in\nlanguage understanding and generation, we set about designing AI systems that\nare able to address complex scientific tasks that challenge human capabilities\nto make new discoveries. Central to our approach is the notion of natural\nlanguage as core representation, reasoning, and exchange format between\nscientific AI and human scientists. In this paper, we identify and discuss some\nof the main research challenges to accomplish such vision.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15327"
  },
  {
    "id": "arXiv:2210.15332",
    "title": "Dial2vec: Self-Guided Contrastive Learning of Unsupervised Dialogue  Embeddings",
    "abstract": "In this paper, we introduce the task of learning unsupervised dialogue\nembeddings. Trivial approaches such as combining pre-trained word or sentence\nembeddings and encoding through pre-trained language models (PLMs) have been\nshown to be feasible for this task. However, these approaches typically ignore\nthe conversational interactions between interlocutors, resulting in poor\nperformance. To address this issue, we proposed a self-guided contrastive\nlearning approach named dial2vec. Dial2vec considers a dialogue as an\ninformation exchange process. It captures the conversational interaction\npatterns between interlocutors and leverages them to guide the learning of the\nembeddings corresponding to each interlocutor. The dialogue embedding is\nobtained by an aggregation of the embeddings from all interlocutors. To verify\nour approach, we establish a comprehensive benchmark consisting of six\nwidely-used dialogue datasets. We consider three evaluation tasks: domain\ncategorization, semantic relatedness, and dialogue retrieval. Dial2vec achieves\non average 8.7, 9.0, and 13.8 points absolute improvements in terms of purity,\nSpearman's correlation, and mean average precision (MAP) over the strongest\nbaseline on the three tasks respectively. Further analysis shows that dial2vec\nobtains informative and discriminative embeddings for both interlocutors under\nthe guidance of the conversational interactions and achieves the best\nperformance when aggregating them through the interlocutor-level pooling\nstrategy. All codes and data are publicly available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial2vec.",
    "descriptor": "\nComments: Accepted as Long Paper at \"EMNLP,2022\"\n",
    "authors": [
      "Che Liu",
      "Rui Wang",
      "Junfeng Jiang",
      "Yongbin Li",
      "Fei Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15332"
  },
  {
    "id": "arXiv:2210.15344",
    "title": "A Classification Scheme for Local Energy Trading",
    "abstract": "The current trend towards more renewable and sustainable energy generation\nleads to an increased interest in new energy management systems and the concept\nof a smart grid. One important aspect of this is local energy trading, which is\nan extension of existing electricity markets by including prosumers, who are\nconsumers also producing electricity. Prosumers having a surplus of energy may\ndirectly trade this surplus with other prosumers, which are currently in\ndemand. In this paper, we present an overview of the literature in the area of\nlocal energy trading. In order to provide structure to the broad range of\npublications, we identify key characteristics, define the various settings, and\ncluster the considered literature along these characteristics. We identify\nthree main research lines, each with a distinct setting and research question.\nWe analyze and compare the settings, the used techniques, and the results and\nfindings within each cluster and derive connections between the clusters. In\naddition, we identify important aspects, which up to now have to a large extent\nbeen neglected in the considered literature and highlight interesting research\ndirections, and open problems for future work.",
    "descriptor": "\nComments: 38 pages, 1 figure, This work has been submitted and accepted at OR Spectrum\n",
    "authors": [
      "Jens H\u00f6nen",
      "Johann L. Hurink",
      "Bert Zwart"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15344"
  },
  {
    "id": "arXiv:2210.15347",
    "title": "Vision Transformer for Adaptive Image Transmission over MIMO Channels",
    "abstract": "This paper presents a vision transformer (ViT) based joint source and channel\ncoding (JSCC) scheme for wireless image transmission over multiple-input\nmultiple-output (MIMO) systems, called ViT-MIMO. The proposed ViT-MIMO\narchitecture, in addition to outperforming separation-based benchmarks, can\nflexibly adapt to different channel conditions without requiring retraining.\nSpecifically, exploiting the self-attention mechanism of the ViT enables the\nproposed ViT-MIMO model to adaptively learn the feature mapping and power\nallocation based on the source image and channel conditions. Numerical\nexperiments show that ViT-MIMO can significantly improve the transmission\nquality cross a large variety of scenarios, including varying channel\nconditions, making it an attractive solution for emerging semantic\ncommunication systems.",
    "descriptor": "",
    "authors": [
      "Haotian Wu",
      "Yulin Shao",
      "Chenghong Bian",
      "Krystian Mikolajczyk",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.15347"
  },
  {
    "id": "arXiv:2210.15349",
    "title": "On the Performance of Irregular Repetition Slotted ALOHA with an Age of  Information Threshold",
    "abstract": "The present paper focuses on an IoT setting in which a large number of\ndevices generate time-stamped updates addressed to a common gateway. Medium\naccess is regulated following a grant-free approach, and the system aims at\nmaintaining an up-to-date knowledge at the receiver, measured through the\naverage network age of information (AoI). In this context, we propose a\nvariation of the irregular repetition slotted ALOHA (IRSA) protocol. The\nscheme, referred to as age-threshold IRSA (AT-IRSA), leverages feedback\nprovided by the receiver to admit to the channel only devices whose AoI exceeds\na dynamically adapted target value. By means of detailed networks simulations,\nas well as of a simple yet tight analytical approximation, we demonstrate that\nthe approach can more than halve the average network AoI compared to plain\nIRSA, and offers notable improvements over feedback-based state-of-the-art\nslotted ALOHA solutions recently proposed in the literature.",
    "descriptor": "",
    "authors": [
      "Hooman Asgari",
      "Andrea Munari",
      "Gianluigi Liva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.15349"
  },
  {
    "id": "arXiv:2210.15350",
    "title": "Medical articles in questionable journals are less impactful than those  in non-questionable journals but still extensively cited",
    "abstract": "A key feature of questionable journals is a lack of adequate peer review of\ntheir articles. Content of thus unknown quality may be utilised by unsuspecting\npractitioners or incorporated into peer-reviewed research, becoming\nlegitimised. It is therefore necessary to examine the citation patterns of\narticles in questionable journals to understand the impact and reach of\nresearch in questionable journals. Similar research has tended to focus on\nauthors from low- and middle-income countries. As such, this study investigates\nthe profile and impact of research in questionable journals by authors in\nGermany. Questionable journals were identified by matching journals with\narticles by authors at German institutions from Dimensions to Cabell's\nPredatory Reports. Metadata for these articles and a comparative sample of\narticles in non-questionable journals were extracted from Dimensions and the 3\nyear citations, self-citations, uncited rate, profile of co-authoring and\nciting countries, and institution type of authors were compared between groups.\nNearly 600 articles in 88 questionable journals were published by German\nauthors in 2010-2020. Three-quarters were in the medical and health sciences.\nMedical articles in questionable journals received significantly fewer\ncitations than similar articles in non-questionable journals. However, articles\nin questionable journals were still extensively cited in 1,736 primarily\nnon-questionable journals. Self-citations accounted for only 12% of these\ncitations. Authors from non-university medical facilities were over-represented\nin articles in questionable journals. System-level changes are necessary to\neliminate questionable journals and shift high-quality research into reputable\nvenues.",
    "descriptor": "",
    "authors": [
      "Dimity Stephen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.15350"
  },
  {
    "id": "arXiv:2210.15353",
    "title": "Learning Discrete Directed Acyclic Graphs via Backpropagation",
    "abstract": "Recently continuous relaxations have been proposed in order to learn Directed\nAcyclic Graphs (DAGs) from data by backpropagation, instead of using\ncombinatorial optimization. However, a number of techniques for fully discrete\nbackpropagation could instead be applied. In this paper, we explore that\ndirection and propose DAG-DB, a framework for learning DAGs by Discrete\nBackpropagation. Based on the architecture of Implicit Maximum Likelihood\nEstimation [I-MLE, arXiv:2106.01798], DAG-DB adopts a probabilistic approach to\nthe problem, sampling binary adjacency matrices from an implicit probability\ndistribution. DAG-DB learns a parameter for the distribution from the loss\nincurred by each sample, performing competitively using either of two fully\ndiscrete backpropagation techniques, namely I-MLE and Straight-Through\nEstimation.",
    "descriptor": "\nComments: 15 pages, 2 figures, 7 tables. Accepted for NeurIPS 2022 workshops on: Causal Machine Learning for Real-World Impact; and Neuro Causal and Symbolic AI\n",
    "authors": [
      "Andrew J. Wren",
      "Pasquale Minervini",
      "Luca Franceschi",
      "Valentina Zantedeschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15353"
  },
  {
    "id": "arXiv:2210.15356",
    "title": "Convolutive Block-Matching Segmentation Algorithm with Application to  Music Structure Analysis",
    "abstract": "Music Structure Analysis (MSA) consists of representing a song in sections\n(such as ``chorus'', ``verse'', ``solo'' etc), and can be seen as the retrieval\nof a simplified organization of the song. This work presents a new algorithm,\ncalled Convolutive Block-Matching (CBM) algorithm, devoted to MSA. In\nparticular, the CBM algorithm is a dynamic programming algorithm, applying on\nautosimilarity matrices, a standard tool in MSA. In this work, autosimilarity\nmatrices are computed from the feature representation of an audio signal, and\ntime is sampled on the barscale. We study three different similarity functions\nfor the computation of autosimilarity matrices. We report that the proposed\nalgorithm achieves a level of performance competitive to that of supervised\nstate-of-the-art methods on 3 among 4 metrics, while being fully unsupervised.",
    "descriptor": "\nComments: 4 pages, 5 figures, 1 table. Submitted at ICASSP 2023. The associated toolbox is available at this https URL\n",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15356"
  },
  {
    "id": "arXiv:2210.15358",
    "title": "Leveraging knowledge graphs to update scientific word embeddings using  latent semantic imputation",
    "abstract": "The most interesting words in scientific texts will often be novel or rare.\nThis presents a challenge for scientific word embedding models to determine\nquality embedding vectors for useful terms that are infrequent or newly\nemerging. We demonstrate how \\gls{lsi} can address this problem by imputing\nembeddings for domain-specific words from up-to-date knowledge graphs while\notherwise preserving the original word embedding model. We use the MeSH\nknowledge graph to impute embedding vectors for biomedical terminology without\nretraining and evaluate the resulting embedding model on a domain-specific\nword-pair similarity task. We show that LSI can produce reliable embedding\nvectors for rare and OOV terms in the biomedical domain.",
    "descriptor": "\nComments: Accepted for the Workshop on Information Extraction from Scientific Publications at AACL-IJCNLP 2022\n",
    "authors": [
      "Jason Hoelscher-Obermaier",
      "Edward Stevinson",
      "Valentin Stauber",
      "Ivaylo Zhelev",
      "Victor Botev",
      "Ronin Wu",
      "Jeremy Minton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15358"
  },
  {
    "id": "arXiv:2210.15359",
    "title": "Exploiting modality-invariant feature for robust multimodal emotion  recognition with missing modalities",
    "abstract": "Multimodal emotion recognition leverages complementary information across\nmodalities to gain performance. However, we cannot guarantee that the data of\nall modalities are always present in practice. In the studies to predict the\nmissing data across modalities, the inherent difference between heterogeneous\nmodalities, namely the modality gap, presents a challenge. To address this, we\npropose to use invariant features for a missing modality imagination network\n(IF-MMIN) which includes two novel mechanisms: 1) an invariant feature learning\nstrategy that is based on the central moment discrepancy (CMD) distance under\nthe full-modality scenario; 2) an invariant feature based imagination module\n(IF-IM) to alleviate the modality gap during the missing modalities prediction,\nthus improving the robustness of multimodal joint representation. Comprehensive\nexperiments on the benchmark dataset IEMOCAP demonstrate that the proposed\nmodel outperforms all baselines and invariantly improves the overall emotion\nrecognition performance under uncertain missing-modality conditions. We release\nthe code at: https://github.com/ZhuoYulang/IF-MMIN.",
    "descriptor": "\nComments: 5 pages, 3 figures, 1 table. Submitted to ICASSP 2023. We release the code at: this https URL\n",
    "authors": [
      "Haolin Zuo",
      "Rui Liu",
      "Jinming Zhao",
      "Guanglai Gao",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15359"
  },
  {
    "id": "arXiv:2210.15360",
    "title": "FCTalker: Fine and Coarse Grained Context Modeling for Expressive  Conversational Speech Synthesis",
    "abstract": "Conversational Text-to-Speech (TTS) aims to synthesis an utterance with the\nright linguistic and affective prosody in a conversational context. The\ncorrelation between the current utterance and the dialogue history at the\nutterance level was used to improve the expressiveness of synthesized speech.\nHowever, the fine-grained information in the dialogue history at the word level\nalso has an important impact on the prosodic expression of an utterance, which\nhas not been well studied in the prior work. Therefore, we propose a novel\nexpressive conversational TTS model, termed as FCTalker, that learn the fine\nand coarse grained context dependency at the same time during speech\ngeneration. Specifically, the FCTalker includes fine and coarse grained\nencoders to exploit the word and utterance-level context dependency. To model\nthe word-level dependencies between an utterance and its dialogue history, the\nfine-grained dialogue encoder is built on top of a dialogue BERT model. The\nexperimental results show that the proposed method outperforms all baselines\nand generates more expressive speech that is contextually appropriate. We\nrelease the source code at: https://github.com/walker-hyf/FCTalker.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table. Submitted to ICASSP 2023. We release the source code at: this https URL\n",
    "authors": [
      "Yifan Hu",
      "Rui Liu",
      "Guanglai Gao",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15360"
  },
  {
    "id": "arXiv:2210.15362",
    "title": "A Novel Approach for Neuromorphic Vision Data Compression based on Deep  Belief Network",
    "abstract": "A neuromorphic camera is an image sensor that emulates the human eyes\ncapturing only changes in local brightness levels. They are widely known as\nevent cameras, silicon retinas or dynamic vision sensors (DVS). DVS records\nasynchronous per-pixel brightness changes, resulting in a stream of events that\nencode the brightness change's time, location, and polarity. DVS consumes\nlittle power and can capture a wider dynamic range with no motion blur and\nhigher temporal resolution than conventional frame-based cameras. Although this\nmethod of event capture results in a lower bit rate than traditional video\ncapture, it is further compressible. This paper proposes a novel deep\nlearning-based compression scheme for event data. Using a deep belief network\n(DBN), the high dimensional event data is reduced into a latent representation\nand later encoded using an entropy-based coding technique. The proposed scheme\nis among the first to incorporate deep learning for event compression. It\nachieves a high compression ratio while maintaining good reconstruction quality\noutperforming state-of-the-art event data coders and other lossless benchmark\ntechniques.",
    "descriptor": "",
    "authors": [
      "Sally Khaidem",
      "Mansi Sharma",
      "Abhipraay Nevatia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15362"
  },
  {
    "id": "arXiv:2210.15363",
    "title": "Block Codes on Pomset Metric",
    "abstract": "Given a regular multiset $M$ on $[n]=\\{1,2,\\ldots,n\\}$, a partial order $R$\non $M$, and a label map $\\pi : [n] \\rightarrow \\mathbb{N}$ defined by $\\pi(i) =\nk_i$ with $\\sum_{i=1}^{n}\\pi (i) = N$, we define a pomset block metric\n$d_{(Pm,\\pi)}$ on the direct sum $ \\mathbb{Z}_{m}^{k_1} \\oplus\n\\mathbb{Z}_{m}^{k_2} \\oplus \\ldots \\oplus \\mathbb{Z}_{m}^{k_n}$ of\n$\\mathbb{Z}_{m}^{N}$ based on the pomset $\\mathbb{P}=(M,R)$. This pomset block\nmetric $d_{(Pm,\\pi)}$ extends the classical pomset metric which accommodate Lee\nmetric introduced by I. G. Sudha and R. S. Selvaraj, in particular, and\ngeneralizes the poset block metric introduced by M. M. S. Alves et al, in\ngeneral, over $\\mathbb{Z}_m$. We find $I$-perfect pomset block codes for both\nideals with partial and full counts. Further, we determine the complete weight\ndistribution for $(P,\\pi)$-space, thereby obtaining it for $(P,w)$-space, and\npomset space, over $\\mathbb{Z}_m$. For chain pomset, packing radius and\nSingleton type bound are established for block codes, and the relation of MDS\ncodes with $I$-perfect codes is investigated. Moreover, we also determine the\nduality theorem of an MDS $(P,\\pi)$-code when all the blocks have the same\nlength.",
    "descriptor": "\nComments: 17 Pages\n",
    "authors": [
      "Atul Kumar Shriwastva",
      "R. S. Selvaraj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15363"
  },
  {
    "id": "arXiv:2210.15364",
    "title": "Explicit Intensity Control for Accented Text-to-speech",
    "abstract": "Accented text-to-speech (TTS) synthesis seeks to generate speech with an\naccent (L2) as a variant of the standard version (L1). How to control the\nintensity of accent in the process of TTS is a very interesting research\ndirection, and has attracted more and more attention. Recent work design a\nspeaker-adversarial loss to disentangle the speaker and accent information, and\nthen adjust the loss weight to control the accent intensity. However, such a\ncontrol method lacks interpretability, and there is no direct correlation\nbetween the controlling factor and natural accent intensity. To this end, this\npaper propose a new intuitive and explicit accent intensity control scheme for\naccented TTS. Specifically, we first extract the posterior probability, called\nas ``goodness of pronunciation (GoP)'' from the L1 speech recognition model to\nquantify the phoneme accent intensity for accented speech, then design a\nFastSpeech2 based TTS model, named Ai-TTS, to take the accent intensity\nexpression into account during speech generation. Experiments show that the our\nmethod outperforms the baseline model in terms of accent rendering and\nintensity control.",
    "descriptor": "\nComments: 5 pages, 3 figures. Submitted to ICASSP 2023. arXiv admin note: text overlap with arXiv:2209.10804\n",
    "authors": [
      "Rui Liu",
      "Haolin Zuo",
      "De Hu",
      "Guanglai Gao",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15364"
  },
  {
    "id": "arXiv:2210.15365",
    "title": "Li3DeTr: A LiDAR based 3D Detection Transformer",
    "abstract": "Inspired by recent advances in vision transformers for object detection, we\npropose Li3DeTr, an end-to-end LiDAR based 3D Detection Transformer for\nautonomous driving, that inputs LiDAR point clouds and regresses 3D bounding\nboxes. The LiDAR local and global features are encoded using sparse convolution\nand multi-scale deformable attention respectively. In the decoder head,\nfirstly, in the novel Li3DeTr cross-attention block, we link the LiDAR global\nfeatures to 3D predictions leveraging the sparse set of object queries learnt\nfrom the data. Secondly, the object query interactions are formulated using\nmulti-head self-attention. Finally, the decoder layer is repeated $L_{dec}$\nnumber of times to refine the object queries. Inspired by DETR, we employ\nset-to-set loss to train the Li3DeTr network. Without bells and whistles, the\nLi3DeTr network achieves 61.3% mAP and 67.6% NDS surpassing the\nstate-of-the-art methods with non-maximum suppression (NMS) on the nuScenes\ndataset and it also achieves competitive performance on the KITTI dataset. We\nalso employ knowledge distillation (KD) using a teacher and student model that\nslightly improves the performance of our network.",
    "descriptor": "\nComments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Gopi Krishna Erabati",
      "Helder Araujo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15365"
  },
  {
    "id": "arXiv:2210.15368",
    "title": "A Teacher-student Framework for Unsupervised Speech Enhancement Using  Noise Remixing Training and Two-stage Inference",
    "abstract": "The lack of clean speech is a practical challenge to the development of\nspeech enhancement systems, which means that the training of neural network\nmodels must be done in an unsupervised manner, and there is an inevitable\nmismatch between their training criterion and evaluation metric. In response to\nthis unfavorable situation, we propose a teacher-student training strategy that\ndoes not require any subjective/objective speech quality metrics as learning\nreference by improving the previously proposed noisy-target training (NyTT).\nBecause homogeneity between in-domain noise and extraneous noise is the key to\nthe effectiveness of NyTT, we train various student models by remixing the\nteacher model's estimated speech and noise for clean-target training or raw\nnoisy speech and the teacher model's estimated noise for noisy-target training.\nWe use the NyTT model as the initial teacher model. Experimental results show\nthat our proposed method outperforms several baselines, especially with\ntwo-stage inference, where clean speech is derived successively through the\nbootstrap model and the final student model.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Li-Wei Chen",
      "Yao-Fei Cheng",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15368"
  },
  {
    "id": "arXiv:2210.15370",
    "title": "CasNet: Investigating Channel Robustness for Speech Separation",
    "abstract": "Recording channel mismatch between training and testing conditions has been\nshown to be a serious problem for speech separation. This situation greatly\nreduces the separation performance, and cannot meet the requirement of daily\nuse. In this study, inheriting the use of our previously constructed TAT-2mix\ncorpus, we address the channel mismatch problem by proposing a channel-aware\naudio separation network (CasNet), a deep learning framework for end-to-end\ntime-domain speech separation. CasNet is implemented on top of TasNet. Channel\nembedding (characterizing channel information in a mixture of multiple\nutterances) generated by Channel Encoder is introduced into the separation\nmodule by the FiLM technique. Through two training strategies, we explore two\nroles that channel embedding may play: 1) a real-life noise disturbance, making\nthe model more robust, or 2) a guide, instructing the separation model to\nretain the desired channel information. Experimental results on TAT-2mix show\nthat CasNet trained with both training strategies outperforms the TasNet\nbaseline, which does not use channel embeddings.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Fan-Lin Wang",
      "Yao-Fei Cheng",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15370"
  },
  {
    "id": "arXiv:2210.15373",
    "title": "Self-consistent Reasoning For Solving Math Word Problems",
    "abstract": "Math word problems (MWPs) is a task that automatically derives solution\nexpression from a giving math problems in text. The previous studies suffer\nfrom spurious correlations between input text and output expression. To\nmitigate this issue, we propose a self-consistent reasoning framework called\nSCR, which attempts to adopt a pruning strategy to correct the output\ndistribution shift so as to implicitly fix those spurious correlative samples.\nSpecifically, we firstly obtain a sub-network by pruning a roberta2tree model,\nfor the sake to use the gap on output distribution between the original\nroberta2tree model and the pruned sub-network to expose spurious correlative\nsamples. Then, we calibrate the output distribution shift by applying symmetric\nKullback-Leibler divergence to alleviate spurious correlations. In addition,\nSCR generates equivalent expressions, thereby, capturing the original text's\nlogic rather than relying on hints from original text. Extensive experiments on\ntwo large-scale benchmarks demonstrate that our model substantially outperforms\nthe strong baseline methods.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Jing Xiong",
      "Zhongwei Wan",
      "Xiping Hu",
      "Min Yang",
      "Chengming Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15373"
  },
  {
    "id": "arXiv:2210.15374",
    "title": "2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth  Estimation",
    "abstract": "Stereo correspondence matching is an essential part of the multi-step stereo\ndepth estimation process. This paper revisits the depth estimation problem,\navoiding the explicit stereo matching step using a simple two-tower\nconvolutional neural network. The proposed algorithm is entitled as 2T-UNet.\nThe idea behind 2T-UNet is to replace cost volume construction with twin\nconvolution towers. These towers have an allowance for different weights\nbetween them. Additionally, the input for twin encoders in 2T-UNet are\ndifferent compared to the existing stereo methods. Generally, a stereo network\ntakes a right and left image pair as input to determine the scene geometry.\nHowever, in the 2T-UNet model, the right stereo image is taken as one input and\nthe left stereo image along with its monocular depth clue information, is taken\nas the other input. Depth clues provide complementary suggestions that help\nenhance the quality of predicted scene geometry. The 2T-UNet surpasses\nstate-of-the-art monocular and stereo depth estimation methods on the\nchallenging Scene flow dataset, both quantitatively and qualitatively. The\narchitecture performs incredibly well on complex natural scenes, highlighting\nits usefulness for various real-time applications. Pretrained weights and code\nwill be made readily available.",
    "descriptor": "",
    "authors": [
      "Rohit Choudhary",
      "Mansi Sharma",
      "Rithvik Anil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15374"
  },
  {
    "id": "arXiv:2210.15375",
    "title": "Grasping Causality for the Explanation of Criticality for Automated  Driving",
    "abstract": "The verification and validation of automated driving systems at SAE levels 4\nand 5 is a multi-faceted challenge for which classical statistical\nconsiderations become infeasible. For this, contemporary approaches suggest a\ndecomposition into scenario classes combined with statistical analysis thereof\nregarding the emergence of criticality. Unfortunately, these associational\napproaches may yield spurious inferences, or worse, fail to recognize the\ncausalities leading to critical scenarios, which are, in turn, prerequisite for\nthe development and safeguarding of automated driving systems. As to\nincorporate causal knowledge within these processes, this work introduces a\nformalization of causal queries whose answers facilitate a causal understanding\nof safety-relevant influencing factors for automated driving. This formalized\ncausal knowledge can be used to specify and implement abstract safety\nprinciples that provably reduce the criticality associated with these\ninfluencing factors. Based on Judea Pearl's causal theory, we define a causal\nrelation as a causal structure together with a context, both related to a\ndomain ontology, where the focus lies on modeling the effect of such\ninfluencing factors on criticality as measured by a suitable metric. As to\nassess modeling quality, we suggest various quantities and evaluate them on a\nsmall example. As availability and quality of data are imperative for validly\nestimating answers to the causal queries, we also discuss requirements on\nreal-world and synthetic data acquisition. We thereby contribute to\nestablishing causal considerations at the heart of the safety processes that\nare urgently needed as to ensure the safe operation of automated driving\nsystems.",
    "descriptor": "",
    "authors": [
      "Tjark Koopmann",
      "Christian Neurohr",
      "Lina Putze",
      "Lukas Westhofen",
      "Roman Gansch",
      "Ahmad Adee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.15375"
  },
  {
    "id": "arXiv:2210.15377",
    "title": "Structuring User-Generated Content on Social Media with Multimodal  Aspect-Based Sentiment Analysis",
    "abstract": "People post their opinions and experiences on social media, yielding rich\ndatabases of end users' sentiments. This paper shows to what extent machine\nlearning can analyze and structure these databases. An automated data analysis\npipeline is deployed to provide insights into user-generated content for\nresearchers in other domains. First, the domain expert can select an image and\na term of interest. Then, the pipeline uses image retrieval to find all images\nshowing similar contents and applies aspect-based sentiment analysis to outline\nusers' opinions about the selected term. As part of an interdisciplinary\nproject between architecture and computer science researchers, an empirical\nstudy of Hamburg's Elbphilharmonie was conveyed on 300 thousand posts from the\nplatform Flickr with the hashtag 'hamburg'. Image retrieval methods generated a\nsubset of slightly more than 1.5 thousand images displaying the\nElbphilharmonie. We found that these posts mainly convey a neutral or positive\nsentiment towards it. With this pipeline, we suggest a new big data analysis\nmethod that offers new insights into end-users opinions, e.g., for architecture\ndomain experts.",
    "descriptor": "\nComments: 9 pages, 5 figures, short paper version to be published at 9th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT2022)\n",
    "authors": [
      "Miriam Ansch\u00fctz",
      "Tobias Eder",
      "Georg Groh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15377"
  },
  {
    "id": "arXiv:2210.15379",
    "title": "MorphTE: Injecting Morphology in Tensorized Embeddings",
    "abstract": "In the era of deep learning, word embeddings are essential when dealing with\ntext tasks. However, storing and accessing these embeddings requires a large\namount of space. This is not conducive to the deployment of these models on\nresource-limited devices. Combining the powerful compression capability of\ntensor products, we propose a word embedding compression method with\nmorphological augmentation, Morphologically-enhanced Tensorized Embeddings\n(MorphTE). A word consists of one or more morphemes, the smallest units that\nbear meaning or have a grammatical function. MorphTE represents a word\nembedding as an entangled form of its morpheme vectors via the tensor product,\nwhich injects prior semantic and grammatical knowledge into the learning of\nembeddings. Furthermore, the dimensionality of the morpheme vector and the\nnumber of morphemes are much smaller than those of words, which greatly reduces\nthe parameters of the word embeddings. We conduct experiments on tasks such as\nmachine translation and question answering. Experimental results on four\ntranslation datasets of different languages show that MorphTE can compress word\nembedding parameters by about 20 times without performance loss and\nsignificantly outperforms related embedding compression methods.",
    "descriptor": "\nComments: 20 pages, 6 figures, 18 tables. Published at NeurIPS 2022\n",
    "authors": [
      "Guobing Gan",
      "Peng Zhang",
      "Sunzhu Li",
      "Xiuqing Lu",
      "Benyou Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15379"
  },
  {
    "id": "arXiv:2210.15386",
    "title": "Opening the Black Box of wav2vec Feature Encoder",
    "abstract": "Self-supervised models, namely, wav2vec and its variants, have shown\npromising results in various downstream tasks in the speech domain. However,\ntheir inner workings are poorly understood, calling for in-depth analyses on\nwhat the model learns. In this paper, we concentrate on the convolutional\nfeature encoder where its latent space is often speculated to represent\ndiscrete acoustic units. To analyze the embedding space in a reductive manner,\nwe feed the synthesized audio signals, which is the summation of simple sine\nwaves. Through extensive experiments, we conclude that various information is\nembedded inside the feature encoder representations: (1) fundamental frequency,\n(2) formants, and (3) amplitude, packed with (4) sufficient temporal detail.\nFurther, the information incorporated inside the latent representations is\nanalogous to spectrograms but with a fundamental difference: latent\nrepresentations construct a metric space so that closer representations imply\nacoustic similarity.",
    "descriptor": "",
    "authors": [
      "Kwanghee Choi",
      "Eun Jung Yeo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15386"
  },
  {
    "id": "arXiv:2210.15387",
    "title": "Automatic Severity Assessment of Dysarthric speech by using  Self-supervised Model with Multi-task Learning",
    "abstract": "Automatic assessment of dysarthric speech is essential for sustained\ntreatments and rehabilitation. However, obtaining atypical speech is\nchallenging, often leading to data scarcity issues. To tackle the problem, we\npropose a novel automatic severity assessment method for dysarthric speech,\nusing the self-supervised model in conjunction with multi-task learning.\nWav2vec 2.0 XLS-R is jointly trained for two different tasks: severity level\nclassification and an auxilary automatic speech recognition (ASR). For the\nbaseline experiments, we employ hand-crafted features such as eGeMaps and\nlinguistic features, and SVM, MLP, and XGBoost classifiers. Explored on the\nKorean dysarthric speech QoLT database, our model outperforms the traditional\nbaseline methods, with a relative percentage increase of 4.79% for\nclassification accuracy. In addition, the proposed model surpasses the model\ntrained without ASR head, achieving 10.09% relative percentage improvements.\nFurthermore, we present how multi-task learning affects the severity\nclassification performance by analyzing the latent representations and\nregularization effect.",
    "descriptor": "",
    "authors": [
      "Eun Jung Yeo",
      "Kwanghee Choi",
      "Sunhee Kim",
      "Minhwa Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15387"
  },
  {
    "id": "arXiv:2210.15390",
    "title": "A randomized Multi-index sequential Monte Carlo method",
    "abstract": "We consider the problem of estimating expectations with respect to a target\ndistribution with an unknown normalizing constant, and where even the\nunnormalized target needs to be approximated at finite resolution. Under such\nan assumption, this work builds upon a recently introduced multi-index\nSequential Monte Carlo (SMC) ratio estimator, which provably enjoys the\ncomplexity improvements of multi-index Monte Carlo (MIMC) and the efficiency of\nSMC for inference. The present work leverages a randomization strategy to\nremove bias entirely, which simplifies estimation substantially, particularly\nin the MIMC context, where the choice of index set is otherwise important.\nUnder reasonable assumptions, the proposed method provably achieves the same\ncanonical complexity of MSE^(-1) as the original method, but without\ndiscretization bias. It is illustrated on examples of Bayesian inverse\nproblems.",
    "descriptor": "\nComments: 26 pages 6 figures\n",
    "authors": [
      "Simon L. Cotter",
      "Kody J. H. Law",
      "Xinzhu Liang",
      "Shangda Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.15390"
  },
  {
    "id": "arXiv:2210.15392",
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with  Learnable Noise",
    "abstract": "Pixel-wise predction with deep neural network has become an effective\nparadigm for salient object detection (SOD) and achieved remakable performance.\nHowever, very few SOD models are robust against adversarial attacks which are\nvisually imperceptible for human visual attention. The previous work robust\nsalient object detection against adversarial attacks (ROSA) shuffles the\npre-segmented superpixels and then refines the coarse saliency map by the\ndensely connected CRF. Different from ROSA that rely on various pre- and\npost-processings, this paper proposes a light-weight Learnble Noise (LeNo) to\nagainst adversarial attacks for SOD models. LeNo preserves accuracy of SOD\nmodels on both adversarial and clean images, as well as inference speed. In\ngeneral, LeNo consists of a simple shallow noise and noise estimation that\nembedded in the encoder and decoder of arbitrary SOD networks respectively.\nInspired by the center prior of human visual attention mechanism, we initialize\nthe shallow noise with a cross-shaped gaussian distribution for better defense\nagainst adversarial attacks. Instead of adding additional network components\nfor post-processing, the proposed noise estimation modifies only one channel of\nthe decoder. With the deeply-supervised noise-decoupled training on\nstate-of-the-art RGB and RGB-D SOD networks, LeNo outperforms previous works\nnot only on adversarial images but also clean images, which contributes\nstronger robustness for SOD.",
    "descriptor": "\nComments: 8 pages, 5 figures, submitted to AAAI\n",
    "authors": [
      "He Tang",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15392"
  },
  {
    "id": "arXiv:2210.15395",
    "title": "Querying Incomplete Numerical Data: Between Certain and Possible Answers",
    "abstract": "Queries with aggregation and arithmetic operations, as well as incomplete\ndata, are common in real-world database, but we lack a good understanding of\nhow they should interact. On the one hand, systems based on SQL provide ad-hoc\nrules for numerical nulls, on the other, theoretical research largely\nconcentrates on the standard notions of certain and possible answers. In the\npresence of numerical attributes and aggregates, however, these answers are\noften meaningless, returning either too little or too much. Our goal is to\ndefine a principled framework for databases with numerical nulls and answering\nqueries with arithmetic and aggregations over them.\nTowards this goal, we assume that missing values in numerical attributes are\ngiven by probability distributions associated with marked nulls. This yields a\nmodel of probabilistic bag databases in which tuples are not necessarily\nindependent, since nulls can repeat. We provide a general compositional\nframework for query answering, and then concentrate on queries that resemble\nstandard SQL with arithmetic and aggregation. We show that these queries are\nmeasurable, and that their outputs have a finite representation. Moreover,\nsince the classical forms of answers provide little information in the\nnumerical setting, we look at the probability that numerical values in output\ntuples belong to specific intervals. Even though their exact computation is\nintractable, we show efficient approximation algorithms to compute such\nprobabilities.",
    "descriptor": "",
    "authors": [
      "Marco Console",
      "Leonid Libkin",
      "Liat Peterfreund"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.15395"
  },
  {
    "id": "arXiv:2210.15398",
    "title": "Make More of Your Data: Minimal Effort Data Augmentation for Automatic  Speech Recognition and Translation",
    "abstract": "Data augmentation is a technique to generate new training data based on\nexisting data. We evaluate the simple and cost-effective method of\nconcatenating the original data examples to build new training instances.\nContinued training with such augmented data is able to improve off-the-shelf\nTransformer and Conformer models that were optimized on the original data only.\nWe demonstrate considerable improvements on the LibriSpeech-960h test sets (WER\n2.83 and 6.87 for test-clean and test-other), which carry over to models\ncombined with shallow fusion (WER 2.55 and 6.27). Our method of continued\ntraining also leads to improvements of up to 0.9 WER on the ASR part of\nCoVoST-2 for four non English languages, and we observe that the gains are\nhighly dependent on the size of the original training data. We compare\ndifferent concatenation strategies and found that our method does not need\nspeaker information to achieve its improvements. Finally, we demonstrate on two\ndatasets that our methods also works for speech translation tasks.",
    "descriptor": "",
    "authors": [
      "Tsz Kin Lam",
      "Shigehiko Schamoni",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15398"
  },
  {
    "id": "arXiv:2210.15401",
    "title": "Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "abstract": "Video-based remote physiological measurement aims to estimate remote\nphotoplethysmography (rPPG) signals from human face videos and then measure\nmultiple vital signs (e.g. heart rate, respiration frequency) from rPPG\nsignals. Recent approaches achieve it by training deep neural networks, which\nnormally require abundant face videos and synchronously recorded\nphotoplethysmography (PPG) signals for supervision. However, the collection of\nthese annotated corpora is uneasy in practice. In this paper, we introduce a\nnovel frequency-inspired self-supervised framework that learns to estimate rPPG\nsignals from face videos without the need of ground truth PPG signals. Given a\nvideo sample, we first augment it into multiple positive/negative samples which\ncontain similar/dissimilar signal frequencies to the original one.\nSpecifically, positive samples are generated using spatial augmentation.\nNegative samples are generated via a learnable frequency augmentation module,\nwhich performs non-linear signal frequency transformation on the input without\nexcessively changing its visual appearance. Next, we introduce a local rPPG\nexpert aggregation module to estimate rPPG signals from augmented samples. It\nencodes complementary pulsation information from different face regions and\naggregate them into one rPPG prediction. Finally, we propose a series of\nfrequency-inspired losses, i.e. frequency contrastive loss, frequency ratio\nconsistency loss, and cross-video frequency agreement loss, for the\noptimization of estimated rPPG signals from multiple augmented video samples\nand across temporally neighboring video samples. We conduct rPPG-based heart\nrate, heart rate variability and respiration frequency estimation on four\nstandard benchmarks. The experimental results demonstrate that our method\nimproves the state of the art by a large margin.",
    "descriptor": "",
    "authors": [
      "Zijie Yue",
      "Miaojing Shi",
      "Shuai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15401"
  },
  {
    "id": "arXiv:2210.15406",
    "title": "Lupascian Non-Negativity Applied to Conceptual Modeling: Alternating  Static Potentiality and Dynamic Actuality",
    "abstract": "In software engineering, conceptual modeling focuses on creating\nrepresentations of the world that are as faithful and rich as possible, with\nthe aim of guiding the development of software systems. In contrast, in the\ncomputing realm, the notion of ontology has been characterized as being closely\nrelated to conceptual modeling and is often viewed as a specification of a\nconceptualization. Accordingly, conceptual modeling and ontology engineering\nnow address the same problem of representing the world in a suitable fashion. A\nhigh-level ontology provides a means to describe concepts and their\ninteractions with each other and to capture structural and behavioral features\nin the intended domain. This paper aims to analyze ontological concepts and\nsemantics of modeling notations to provide a common understanding among\nsoftware engineers. An important issue in this context concerns the question of\nwhether the modeled world might be stratified into ontological levels. We\nintroduce an abstract system of two-level domain ontology to be used as a\nfoundation for conceptual models. We study the two levels of staticity and\ndynamics in the context of the thinging machine (TM) model using the notions of\npotentiality and actuality that the Franco-Romanian philosopher Stephane\nLupasco developed in logic. He provided a quasi-universal rejection of\ncontradiction where every event was always associated with a no event, such\nthat the actualization of an event entails the potentialization of a no event\nand vice versa without either ever disappearing completely. This approach is\nillustrated by re-modeling UML state machines in TM modeling. The results\nstrengthen the semantics of a static versus dynamic levels in conceptual\nmodeling and sharpen the notion of events as a phenomenon without negativity\nalternating between the two levels of dynamics and staticity.",
    "descriptor": "\nComments: 11 pages, 21 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15406"
  },
  {
    "id": "arXiv:2210.15409",
    "title": "Constrained Differential Dynamic Programming: A primal-dual augmented  Lagrangian approach",
    "abstract": "Trajectory optimization is an efficient approach for solving optimal control\nproblems for complex robotic systems. It relies on two key components: first\nthe transcription into a sparse nonlinear program, and second the corresponding\nsolver to iteratively compute its solution. On one hand, differential dynamic\nprogramming (DDP) provides an efficient approach to transcribe the optimal\ncontrol problem into a finite-dimensional problem while optimally exploiting\nthe sparsity induced by time. On the other hand, augmented Lagrangian methods\nmake it possible to formulate efficient algorithms with advanced\nconstraint-satisfaction strategies. In this paper, we propose to combine these\ntwo approaches into an efficient optimal control algorithm accepting both\nequality and inequality constraints. Based on the augmented Lagrangian\nliterature, we first derive a generic primal-dual augmented Lagrangian strategy\nfor nonlinear problems with equality and inequality constraints. We then apply\nit to the dynamic programming principle to solve the value-greedy optimization\nproblems inherent to the backward pass of DDP, which we combine with a\ndedicated globalization strategy, resulting in a Newton-like algorithm for\nsolving constrained trajectory optimization problems. Contrary to previous\nattempts of formulating an augmented Lagrangian version of DDP, our approach\nexhibits adequate convergence properties without any switch in strategies. We\nempirically demonstrate its interest with several case-studies from the\nrobotics literature.",
    "descriptor": "",
    "authors": [
      "Wilson Jallet",
      "Antoine Bambade",
      "Nicolas Mansard",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15409"
  },
  {
    "id": "arXiv:2210.15414",
    "title": "Local Graph-homomorphic Processing for Privatized Distributed Systems",
    "abstract": "We study the generation of dependent random numbers in a distributed fashion\nin order to enable privatized distributed learning by networked agents. We\npropose a method that we refer to as local graph-homomorphic processing; it\nrelies on the construction of particular noises over the edges to ensure a\ncertain level of differential privacy. We show that the added noise does not\naffect the performance of the learned model. This is a significant improvement\nto previous works on differential privacy for distributed algorithms, where the\nnoise was added in a less structured manner without respecting the graph\ntopology and has often led to performance deterioration. We illustrate the\ntheoretical results by considering a linear regression problem over a network\nof agents.",
    "descriptor": "",
    "authors": [
      "Elsa Rizk",
      "Stefan Vlaski",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15414"
  },
  {
    "id": "arXiv:2210.15415",
    "title": "Exact Gradient Computation for Spiking Neural Networks Through Forward  Propagation",
    "abstract": "Spiking neural networks (SNN) have recently emerged as alternatives to\ntraditional neural networks, owing to energy efficiency benefits and capacity\nto better capture biological neuronal mechanisms. However, the classic\nbackpropagation algorithm for training traditional networks has been\nnotoriously difficult to apply to SNN due to the hard-thresholding and\ndiscontinuities at spike times. Therefore, a large majority of prior work\nbelieves exact gradients for SNN w.r.t. their weights do not exist and has\nfocused on approximation methods to produce surrogate gradients. In this paper,\n(1) by applying the implicit function theorem to SNN at the discrete spike\ntimes, we prove that, albeit being non-differentiable in time, SNNs have\nwell-defined gradients w.r.t. their weights, and (2) we propose a novel\ntraining algorithm, called \\emph{forward propagation} (FP), that computes exact\ngradients for SNN. FP exploits the causality structure between the spikes and\nallows us to parallelize computation forward in time. It can be used with other\nalgorithms that simulate the forward pass, and it also provides insights on why\nother related algorithms such as Hebbian learning and also recently-proposed\nsurrogate gradient methods may perform well.",
    "descriptor": "",
    "authors": [
      "Jane H. Lee",
      "Saeid Haghighatshoar",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.15415"
  },
  {
    "id": "arXiv:2210.15417",
    "title": "Dynamic Survival Transformers for Causal Inference with Electronic  Health Records",
    "abstract": "In medicine, researchers often seek to infer the effects of a given treatment\non patients' outcomes. However, the standard methods for causal survival\nanalysis make simplistic assumptions about the data-generating process and\ncannot capture complex interactions among patient covariates. We introduce the\nDynamic Survival Transformer (DynST), a deep survival model that trains on\nelectronic health records (EHRs). Unlike previous transformers used in survival\nanalysis, DynST can make use of time-varying information to predict evolving\nsurvival probabilities. We derive a semi-synthetic EHR dataset from MIMIC-III\nto show that DynST can accurately estimate the causal effect of a treatment\nintervention on restricted mean survival time (RMST). We demonstrate that DynST\nachieves better predictive and causal estimation than two alternative models.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 Workshop on Learning from Time Series for Health\n",
    "authors": [
      "Prayag Chatha",
      "Yixin Wang",
      "Zhenke Wu",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.15417"
  },
  {
    "id": "arXiv:2210.15418",
    "title": "FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion",
    "abstract": "Voice conversion (VC) can be achieved by first extracting source content\ninformation and target speaker information, and then reconstructing waveform\nwith these information. However, current approaches normally either extract\ndirty content information with speaker information leaked in, or demand a large\namount of annotated data for training. Besides, the quality of reconstructed\nwaveform can be degraded by the mismatch between conversion model and vocoder.\nIn this paper, we adopt the end-to-end framework of VITS for high-quality\nwaveform reconstruction, and propose strategies for clean content information\nextraction without text annotation. We disentangle content information by\nimposing an information bottleneck to WavLM features, and propose the\nspectrogram-resize based data augmentation to improve the purity of extracted\ncontent information. Experimental results show that the proposed method\noutperforms the latest VC models trained with annotated data and has greater\nrobustness.",
    "descriptor": "",
    "authors": [
      "Jingyi li",
      "Weiping tu",
      "Li xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15418"
  },
  {
    "id": "arXiv:2210.15421",
    "title": "AnyDijkstra, an algorithm to compute shortest paths on images with  anytime properties",
    "abstract": "Images conveniently capture the result of physical processes, representing\nrich source of information for data driven medicine, engineering, and science.\nThe modeling of an image as a graph allows the application of graph-based\nalgorithms for content analysis. Amongst these, one of the most used is the\nDijkstra Single Source Shortest Path algorithm (DSSSP), which computes the path\nwith minimal cost from one starting node to all the other nodes of the graph.\nHowever, the results of DSSSP remains unknown for nodes until they are\nexplored. Moreover, DSSSP execution is associated to frequent jumps between\ndistant locations in the graph, which results in non-optimal memory access,\nreduced parallelization, and finally increased execution time. Therefore, we\npropose AnyDijkstra, an iterative implementation of the Dijkstra SSSP algorithm\noptimized for images, that retains anytime properties while accessing memory\nfollowing a cache-friendly scheme and maximizing parallelization.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Diego Ulisse Pizzagalli",
      "Rolf Krause"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15421"
  },
  {
    "id": "arXiv:2210.15422",
    "title": "Supervised classification methods applied to airborne hyperspectral  images: Comparative study using mutual information",
    "abstract": "Nowadays, the hyperspectral remote sensing imagery HSI becomes an important\ntool to observe the Earth's surface, detect the climatic changes and many other\napplications. The classification of HSI is one of the most challenging tasks\ndue to the large amount of spectral information and the presence of redundant\nand irrelevant bands. Although great progresses have been made on\nclassification techniques, few studies have been done to provide practical\nguidelines to determine the appropriate classifier for HSI. In this paper, we\ninvestigate the performance of four supervised learning algorithms, namely,\nSupport Vector Machines SVM, Random Forest RF, K-Nearest Neighbors KNN and\nLinear Discriminant Analysis LDA with different kernels in terms of\nclassification accuracies. The experiments have been performed on three real\nhyperspectral datasets taken from the NASA's Airborne Visible/Infrared Imaging\nSpectrometer Sensor AVIRIS and the Reflective Optics System Imaging\nSpectrometer ROSIS sensors. The mutual information had been used to reduce the\ndimensionality of the used datasets for better classification efficiency. The\nextensive experiments demonstrate that the SVM classifier with RBF kernel and\nRF produced statistically better results and seems to be respectively the more\nsuitable as supervised classifiers for the hyperspectral remote sensing images.\nKeywords: hyperspectral images, mutual information, dimension reduction,\nSupport Vector Machines, K-Nearest Neighbors, Random Forest, Linear\nDiscriminant Analysis.",
    "descriptor": "",
    "authors": [
      "Hasna Nhaila",
      "Asma Elmaizi",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15422"
  },
  {
    "id": "arXiv:2210.15424",
    "title": "What Language Model to Train if You Have One Million GPU Hours?",
    "abstract": "The crystallization of modeling methods around the Transformer architecture\nhas been a boon for practitioners. Simple, well-motivated architectural\nvariations can transfer across tasks and scale, increasing the impact of\nmodeling research. However, with the emergence of state-of-the-art 100B+\nparameters models, large language models are increasingly expensive to\naccurately design and train. Notably, it can be difficult to evaluate how\nmodeling decisions may impact emergent capabilities, given that these\ncapabilities arise mainly from sheer scale alone. In the process of building\nBLOOM--the Big Science Large Open-science Open-access Multilingual language\nmodel--our goal is to identify an architecture and training setup that makes\nthe best use of our 1,000,000 A100-GPU-hours budget. Specifically, we perform\nan ablation study at the billion-parameter scale comparing different modeling\npractices and their impact on zero-shot generalization. In addition, we study\nthe impact of various popular pre-training corpora on zero-shot generalization.\nWe also study the performance of a multilingual model and how it compares to\nthe English-only one. Finally, we consider the scaling behaviour of\nTransformers to choose the target model size, shape, and training setup. All\nour models and code are open-sourced at https://huggingface.co/bigscience .",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Teven Le Scao",
      "Thomas Wang",
      "Daniel Hesslow",
      "Lucile Saulnier",
      "Stas Bekman",
      "M Saiful Bari",
      "Stella Bideman",
      "Hady Elsahar",
      "Niklas Muennighoff",
      "Jason Phang",
      "Ofir Press",
      "Colin Raffel",
      "Victor Sanh",
      "Sheng Shen",
      "Lintang Sutawika",
      "Jaesung Tae",
      "Zheng Xin Yong",
      "Julien Launay",
      "Iz Beltagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15424"
  },
  {
    "id": "arXiv:2210.15427",
    "title": "Are You Stealing My Model? Sample Correlation for Fingerprinting Deep  Neural Networks",
    "abstract": "An off-the-shelf model as a commercial service could be stolen by model\nstealing attacks, posing great threats to the rights of the model owner. Model\nfingerprinting aims to verify whether a suspect model is stolen from the victim\nmodel, which gains more and more attention nowadays. Previous methods always\nleverage the transferable adversarial examples as the model fingerprint, which\nis sensitive to adversarial defense or transfer learning scenarios. To address\nthis issue, we consider the pairwise relationship between samples instead and\npropose a novel yet simple model stealing detection method based on SAmple\nCorrelation (SAC). Specifically, we present SAC-w that selects wrongly\nclassified normal samples as model inputs and calculates the mean correlation\namong their model outputs. To reduce the training time, we further develop\nSAC-m that selects CutMix Augmented samples as model inputs, without the need\nfor training the surrogate models or generating adversarial examples. Extensive\nresults validate that SAC successfully defends against various model stealing\nattacks, even including adversarial training or transfer learning, and detects\nthe stolen models with the best performance in terms of AUC across different\ndatasets and model architectures. The codes are available at\nhttps://github.com/guanjiyang/SAC.",
    "descriptor": "",
    "authors": [
      "Jiyang Guan",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15427"
  },
  {
    "id": "arXiv:2210.15429",
    "title": "Multi-view Representation Learning from Malware to Defend Against  Adversarial Variants",
    "abstract": "Deep learning-based adversarial malware detectors have yielded promising\nresults in detecting never-before-seen malware executables without relying on\nexpensive dynamic behavior analysis and sandbox. Despite their abilities, these\ndetectors have been shown to be vulnerable to adversarial malware variants -\nmeticulously modified, functionality-preserving versions of original malware\nexecutables generated by machine learning. Due to the nature of these\nadversarial modifications, these adversarial methods often use a \\textit{single\nview} of malware executables (i.e., the binary/hexadecimal view) to generate\nadversarial malware variants. This provides an opportunity for the defenders\n(i.e., malware detectors) to detect the adversarial variants by utilizing more\nthan one view of a malware file (e.g., source code view in addition to the\nbinary view). The rationale behind this idea is that while the adversary\nfocuses on the binary view, certain characteristics of the malware file in the\nsource code view remain untouched which leads to the detection of the\nadversarial malware variants. To capitalize on this opportunity, we propose\nAdversarially Robust Multiview Malware Defense (ARMD), a novel multi-view\nlearning framework to improve the robustness of DL-based malware detectors\nagainst adversarial variants. Our experiments on three renowned open-source\ndeep learning-based malware detectors across six common malware categories show\nthat ARMD is able to improve the adversarial robustness by up to seven times on\nthese malware detectors.",
    "descriptor": "",
    "authors": [
      "James Lee Hu",
      "Mohammadreza Ebrahimi",
      "Weifeng Li",
      "Xin Li",
      "Hsinchun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15429"
  },
  {
    "id": "arXiv:2210.15430",
    "title": "Student-centric Model of Learning Management System Activity and  Academic Performance: from Correlation to Causation",
    "abstract": "In recent years, there is a lot of interest in modeling students' digital\ntraces in Learning Management System (LMS) to understand students' learning\nbehavior patterns including aspects of meta-cognition and self-regulation, with\nthe ultimate goal to turn those insights into actionable information to support\nstudents to improve their learning outcomes. In achieving this goal, however,\nthere are two main issues that need to be addressed given the existing\nliterature. Firstly, most of the current work is course-centered (i.e. models\nare built from data for a specific course) rather than student-centered;\nsecondly, a vast majority of the models are correlational rather than causal.\nThose issues make it challenging to identify the most promising actionable\nfactors for intervention at the student level where most of the campus-wide\nacademic support is designed for. In this paper, we explored a student-centric\nanalytical framework for LMS activity data that can provide not only\ncorrelational but causal insights mined from observational data. We\ndemonstrated this approach using a dataset of 1651 computing major students at\na public university in the US during one semester in the Fall of 2019. This\ndataset includes students' fine-grained LMS interaction logs and administrative\ndata, e.g. demographics and academic performance. In addition, we expand the\nrepository of LMS behavior indicators to include those that can characterize\nthe time-of-the-day of login (e.g. chronotype). Our analysis showed that\nstudent login volume, compared with other login behavior indicators, is both\nstrongly correlated and causally linked to student academic performance,\nespecially among students with low academic performance. We envision that those\ninsights will provide convincing evidence for college student support groups to\nlaunch student-centered and targeted interventions that are effective and\nscalable.",
    "descriptor": "\nComments: 43 pages, 9 figures, 18 tables, Journal of Educational Data Mining (Initial Submission)\n",
    "authors": [
      "Varun Mandalapu",
      "Lujie Karen Chen",
      "Sushruta Shetty",
      "Zhiyuan Chen",
      "Jiaqi Gong"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15430"
  },
  {
    "id": "arXiv:2210.15432",
    "title": "Many-Objective Reinforcement Learning for Online Testing of DNN-Enabled  Systems",
    "abstract": "Deep Neural Networks (DNNs) have been widely used to perform real-world tasks\nin cyber-physical systems such as Autonomous Diving Systems (ADS). Ensuring the\ncorrect behavior of such DNN-Enabled Systems (DES) is a crucial topic. Online\ntesting is one of the promising modes for testing such systems with their\napplication environments (simulated or real) in a closed loop taking into\naccount the continuous interaction between the systems and their environments.\nHowever, the environmental variables (e.g., lighting conditions) that might\nchange during the systems' operation in the real world, causing the DES to\nviolate requirements (safety, functional), are often kept constant during the\nexecution of an online test scenario due to the two major challenges: (1) the\nspace of all possible scenarios to explore would become even larger if they\nchanged and (2) there are typically many requirements to test simultaneously.\nIn this paper, we present MORLOT (Many-Objective Reinforcement Learning for\nOnline Testing), a novel online testing approach to address these challenges by\ncombining Reinforcement Learning (RL) and many-objective search. MORLOT\nleverages RL to incrementally generate sequences of environmental changes while\nrelying on many-objective search to determine the changes so that they are more\nlikely to achieve any of the uncovered objectives. We empirically evaluate\nMORLOT using CARLA, a high-fidelity simulator widely used for autonomous\ndriving research, integrated with Transfuser, a DNN-enabled ADS for end-to-end\ndriving. The evaluation results show that MORLOT is significantly more\neffective and efficient than alternatives with a large effect size. In other\nwords, MORLOT is a good option to test DES with dynamically changing\nenvironments while accounting for multiple safety requirements.",
    "descriptor": "",
    "authors": [
      "Fitash Ul Haq",
      "Donghwan Shin",
      "Lionel Briand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15432"
  },
  {
    "id": "arXiv:2210.15434",
    "title": "Multi-layered Discriminative Restricted Boltzmann Machine with Untrained  Probabilistic Layer",
    "abstract": "An extreme learning machine (ELM) is a three-layered feed-forward neural\nnetwork having untrained parameters, which are randomly determined before\ntraining. Inspired by the idea of ELM, a probabilistic untrained layer called a\nprobabilistic-ELM (PELM) layer is proposed, and it is combined with a\ndiscriminative restricted Boltzmann machine (DRBM), which is a probabilistic\nthree-layered neural network for solving classification problems. The proposed\nmodel is obtained by stacking DRBM on the PELM layer. The resultant model\n(i.e., multi-layered DRBM (MDRBM)) forms a probabilistic four-layered neural\nnetwork. In MDRBM, the parameters in the PELM layer can be determined using\nGaussian-Bernoulli restricted Boltzmann machine. Owing to the PELM layer, MDRBM\nobtains a strong immunity against noise in inputs, which is one of the most\nimportant advantages of MDRBM. Numerical experiments using some benchmark\ndatasets, MNIST, Fashion-MNIST, Urban Land Cover, and CIFAR-10, demonstrate\nthat MDRBM is superior to other existing models, particularly, in terms of the\nnoise-robustness property (or, in other words, the generalization property).",
    "descriptor": "",
    "authors": [
      "Yuri Kanno",
      "Muneki Yasuda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15434"
  },
  {
    "id": "arXiv:2210.15436",
    "title": "The weight distribution of codes over finite chain rings",
    "abstract": "In this work, we determine new linear equations for the weight distribution\nof linear codes over finite chain rings. The identities are determined by\ncounting the number of some special submatrices of the parity-check matrix of\nthe code. Thanks to these relations we are able to compute the full weight\ndistribution of codes with small Singleton defects, such as MDS, MDR and AMDR\ncodes.",
    "descriptor": "",
    "authors": [
      "Giulia Cavicchioni an Alessio Meneghetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2210.15436"
  },
  {
    "id": "arXiv:2210.15441",
    "title": "Toroidal Probabilistic Spherical Discriminant Analysis",
    "abstract": "In speaker recognition, where speech segments are mapped to embeddings on the\nunit hypersphere, two scoring back-ends are commonly used, namely cosine\nscoring and PLDA. We have recently proposed PSDA, an analog to PLDA that uses\nVon Mises-Fisher distributions instead of Gaussians. In this paper, we present\ntoroidal PSDA (T-PSDA). It extends PSDA with the ability to model within and\nbetween-speaker variabilities in toroidal submanifolds of the hypersphere. Like\nPLDA and PSDA, the model allows closed-form scoring and closed-form EM updates\nfor training. On VoxCeleb, we find T-PSDA accuracy on par with cosine scoring,\nwhile PLDA accuracy is inferior. On NIST SRE'21 we find that T-PSDA gives large\naccuracy gains compared to both cosine scoring and PLDA.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Anna Silnova",
      "Niko Br\u00fcmmer",
      "Albert Swart",
      "Luk\u00e1\u0161 Burget"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15441"
  },
  {
    "id": "arXiv:2210.15446",
    "title": "LP-BFGS attack: An adversarial attack based on the Hessian with limited  pixels",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks. Most white-box\nattacks are based on the gradient of models to the input. Since the computation\nand memory budget, adversarial attacks based on the Hessian information are not\npaid enough attention. In this work, we study the attack performance and\ncomputation cost of the attack method based on the Hessian with a limited\nperturbation pixel number. Specifically, we propose the Limited Pixel BFGS\n(LP-BFGS) attack method by incorporating the BFGS algorithm. Some pixels are\nselected as perturbation pixels by the Integrated Gradient algorithm, which are\nregarded as optimization variables of the LP-BFGS attack. Experimental results\nacross different networks and datasets with various perturbation pixel numbers\ndemonstrate our approach has a comparable attack with an acceptable computation\ncompared with existing solutions.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Jiebao Zhang",
      "Wenhua Qian",
      "Rencan Nie",
      "Jinde Cao",
      "Dan Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15446"
  },
  {
    "id": "arXiv:2210.15447",
    "title": "Virtuoso: Massive Multilingual Speech-Text Joint Semi-Supervised  Learning for Text-To-Speech",
    "abstract": "This paper proposes Virtuoso, a massively multilingual speech-text joint\nsemi-supervised learning framework for text-to-speech synthesis (TTS) models.\nExisting multilingual TTS typically supports tens of languages, which are a\nsmall fraction of the thousands of languages in the world. One difficulty to\nscale multilingual TTS to hundreds of languages is collecting high-quality\nspeech-text paired data in low-resource languages. This study extends Maestro,\na speech-text joint pretraining framework for automatic speech recognition\n(ASR), to speech generation tasks. To train a TTS model from various types of\nspeech and text data, different training schemes are designed to handle\nsupervised (paired TTS and ASR data) and unsupervised (untranscribed speech and\nunspoken text) datasets. Experimental evaluation shows that 1) multilingual TTS\nmodels trained on Virtuoso can achieve significantly better naturalness and\nintelligibility than baseline ones in seen languages, and 2) they can\nsynthesize reasonably intelligible and naturally sounding speech for unseen\nlanguages where no high-quality paired TTS data is available.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Takaaki Saeki",
      "Heiga Zen",
      "Zhehuai Chen",
      "Nobuyuki Morioka",
      "Gary Wang",
      "Yu Zhang",
      "Ankur Bapna",
      "Andrew Rosenberg",
      "Bhuvana Ramabhadran"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15447"
  },
  {
    "id": "arXiv:2210.15449",
    "title": "Conditional Goal-oriented Trajectory Prediction for Interacting Vehicles  with Vectorized Representation",
    "abstract": "This paper aims to tackle the interactive behavior prediction task, and\nproposes a novel Conditional Goal-oriented Trajectory Prediction (CGTP)\nframework to jointly generate scene-compliant trajectories of two interacting\nagents. Our CGTP framework is an end to end and interpretable model, including\nthree main stages: context encoding, goal interactive prediction and trajectory\ninteractive prediction. First, a Goals-of-Interest Network (GoINet) is designed\nto extract the interactive features between agent-to-agent and agent-to-goals\nusing a graph-based vectorized representation. Further, the Conditional Goal\nPrediction Network (CGPNet) focuses on goal interactive prediction via a\ncombined form of marginal and conditional goal predictors. Finally, the\nGoaloriented Trajectory Forecasting Network (GTFNet) is proposed to implement\ntrajectory interactive prediction via the conditional goal-oriented predictors,\nwith the predicted future states of the other interacting agent taken as\ninputs. In addition, a new goal interactive loss is developed to better learn\nthe joint probability distribution over goal candidates between two interacting\nagents. In the end, the proposed method is conducted on Argoverse motion\nforecasting dataset, In-house cut-in dataset, and Waymo open motion dataset.\nThe comparative results demonstrate the superior performance of our proposed\nCGTP model than the mainstream prediction methods.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Ding Li",
      "Qichao Zhang",
      "Shuai Lu",
      "Yifeng Pan",
      "Dongbin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15449"
  },
  {
    "id": "arXiv:2210.15451",
    "title": "Fine-Grained Session Recommendations in E-commerce using Deep  Reinforcement Learning",
    "abstract": "Sustaining users' interest and keeping them engaged in the platform is very\nimportant for the success of an e-commerce business. A session encompasses\ndifferent activities of a user between logging into the platform and logging\nout or making a purchase. User activities in a session can be classified into\ntwo groups: Known Intent and Unknown intent. Known intent activity pertains to\nthe session where the intent of a user to browse/purchase a specific product\ncan be easily captured. Whereas in unknown intent activity, the intent of the\nuser is not known. For example, consider the scenario where a user enters the\nsession to casually browse the products over the platform, similar to the\nwindow shopping experience in the offline setting. While recommending similar\nproducts is essential in the former, accurately understanding the intent and\nrecommending interesting products is essential in the latter setting in order\nto retain a user. In this work, we focus primarily on the unknown intent\nsetting where our objective is to recommend a sequence of products to a user in\na session to sustain their interest, keep them engaged and possibly drive them\ntowards purchase. We formulate this problem in the framework of the Markov\nDecision Process (MDP), a popular mathematical framework for sequential\ndecision making and solve it using Deep Reinforcement Learning (DRL)\ntechniques. However, training the next product recommendation is difficult in\nthe RL paradigm due to large variance in browse/purchase behavior of the users.\nTherefore, we break the problem down into predicting various product\nattributes, where a pattern/trend can be identified and exploited to build\naccurate models. We show that the DRL agent provides better performance\ncompared to a greedy strategy.",
    "descriptor": "",
    "authors": [
      "Diddigi Raghu Ram Bharadwaj",
      "Lakshya Kumar",
      "Saif Jawaid",
      "Sreekanth Vempati"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15451"
  },
  {
    "id": "arXiv:2210.15452",
    "title": "Exploring Predictive Uncertainty and Calibration in NLP: A Study on the  Impact of Method & Data Scarcity",
    "abstract": "We investigate the problem of determining the predictive confidence (or,\nconversely, uncertainty) of a neural classifier through the lens of\nlow-resource languages. By training models on sub-sampled datasets in three\ndifferent languages, we assess the quality of estimates from a wide array of\napproaches and their dependence on the amount of available data. We find that\nwhile approaches based on pre-trained models and ensembles achieve the best\nresults overall, the quality of uncertainty estimates can surprisingly suffer\nwith more data. We also perform a qualitative analysis of uncertainties on\nsequences, discovering that a model's total uncertainty seems to be influenced\nto a large degree by its data uncertainty, not model uncertainty. All model\nimplementations are open-sourced in a software package.",
    "descriptor": "",
    "authors": [
      "Dennis Ulmer",
      "Jes Frellsen",
      "Christian Hardmeier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15452"
  },
  {
    "id": "arXiv:2210.15456",
    "title": "JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions",
    "abstract": "Commonsense reasoning simulates the human ability to make presumptions about\nour physical world, and it is an essential cornerstone in building general AI\nsystems. We propose a new commonsense reasoning dataset based on human's\nInteractive Fiction (IF) gameplay walkthroughs as human players demonstrate\nplentiful and diverse commonsense reasoning. The new dataset provides a natural\nmixture of various reasoning types and requires multi-hop reasoning. Moreover,\nthe IF game-based construction procedure requires much less human interventions\nthan previous ones. Experiments show that the introduced dataset is challenging\nto previous machine reading models with a significant 20% performance gap\ncompared to human experts.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.09788\n",
    "authors": [
      "Mo Yu",
      "Xiaoxiao Guo",
      "Yufei Feng",
      "Yi Gu",
      "Xiaodan Zhu",
      "Michael Greenspan",
      "Murray Campbell",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15456"
  },
  {
    "id": "arXiv:2210.15457",
    "title": "Learning One-Class Hyperspectral Classifier from Positive and Unlabeled  Data for Low Proportion Target",
    "abstract": "Hyperspectral imagery (HSI) one-class classification is aimed at identifying\na single target class from the HSI by using only positive labels, which can\nsignificantly reduce the requirements for annotation. However, HSI one-class\nclassification is far more challenging than HSI multi-class classification, due\nthe lack of negative labels and the low target proportion, which are issues\nthat have rarely been considered in the previous HSI classification studies. In\nthis paper, a weakly supervised HSI one-class classifier, namely HOneCls is\nproposed to solve the problem of under-fitting of the positive class occurs in\nthe HSI data with low target proportion, where a risk estimator -- the\nOne-Class Risk Estimator -- is particularly introduced to make the full\nconvolutional neural network (FCN) with the ability of one class\nclassification. The experimental results obtained on challenging hyperspectral\nclassification datasets, which includes 20 kinds of ground objects with very\nsimilar spectra, demonstrate the efficiency and feasibility of the proposed\nOne-Class Risk Estimator. Compared with the state-of-the-art one-class\nclassifiers, the F1-score is improved significantly in the HSI data with low\ntarget proportion.",
    "descriptor": "",
    "authors": [
      "Hengwei Zhao",
      "Yanfei Zhong",
      "Xin He",
      "Xinyu Wang",
      "Hong Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15457"
  },
  {
    "id": "arXiv:2210.15458",
    "title": "Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models",
    "abstract": "Decoding methods for large language models often trade-off between diversity\nof outputs and parallelism of computation. Methods such as beam search and\nGumbel top-k sampling can guarantee a different output for each element of the\nbeam, but are not easy to parallelize. Alternatively, methods such as\ntemperature sampling and its modifications (top-k sampling, nucleus sampling,\ntypical decoding, and others), are embarrassingly parallel, but have no\nguarantees about duplicate samples. We present a framework for sampling\naccording to an arithmetic code book implicitly defined by a large language\nmodel, compatible with common sampling variations, with provable beam diversity\nunder certain conditions, as well as being embarrassingly parallel and\nproviding unbiased and consistent expectations from the original model. We\ndemonstrate the effectiveness of our approach on WMT machine translation,\nshowing substantially reduced variance when estimating expected BLEU score and\nup to 1 point increased BLEU in oracle experiments.",
    "descriptor": "\nComments: 14 pages. Preprint\n",
    "authors": [
      "Luke Vilnis",
      "Yury Zemlyanskiy",
      "Patrick Murray",
      "Alexandre Passos",
      "Sumit Sanghai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15458"
  },
  {
    "id": "arXiv:2210.15459",
    "title": "Keyword Targeting Optimization in Sponsored Search Advertising:  Combining Selection and Matching",
    "abstract": "In sponsored search advertising (SSA), advertisers need to select keywords\nand determine matching types for selected keywords simultaneously, i.e.,\nkeyword targeting. An optimal keyword targeting strategy guarantees reaching\nthe right population effectively. This paper aims to address the keyword\ntargeting problem, which is a challenging task because of the incomplete\ninformation of historical advertising performance indices and the high\nuncertainty in SSA environments. First, we construct a data distribution\nestimation model and apply a Markov Chain Monte Carlo method to make inference\nabout unobserved indices (i.e., impression and click-through rate) over three\nkeyword matching types (i.e., broad, phrase and exact). Second, we formulate a\nstochastic keyword targeting model (BB-KSM) combining operations of keyword\nselection and keyword matching to maximize the expected profit under the chance\nconstraint of the budget, and develop a branch-and-bound algorithm\nincorporating a stochastic simulation process for our keyword targeting model.\nFinally, based on a realworld dataset collected from field reports and logs of\npast SSA campaigns, computational experiments are conducted to evaluate the\nperformance of our keyword targeting strategy. Experimental results show that,\n(a) BB-KSM outperforms seven baselines in terms of profit; (b) BB-KSM shows its\nsuperiority as the budget increases, especially in situations with more\nkeywords and keyword combinations; (c) the proposed data distribution\nestimation approach can effectively address the problem of incomplete\nperformance indices over the three matching types and in turn significantly\npromotes the performance of keyword targeting decisions. This research makes\nimportant contributions to the SSA literature and the results offer critical\ninsights into keyword management for SSA advertisers.",
    "descriptor": "\nComments: 38 pages, 4 figures, 5 tables\n",
    "authors": [
      "Huiran Li",
      "Yanwu Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15459"
  },
  {
    "id": "arXiv:2210.15460",
    "title": "Accurate Bundle Matching and Generation via Multitask Learning with  Partially Shared Parameters",
    "abstract": "How can we recommend existing bundles to users accurately? How can we\ngenerate new tailored bundles for users? Recommending a bundle, or a group of\nvarious items, has attracted widespread attention in e-commerce owing to the\nincreased satisfaction of both users and providers. Bundle matching and bundle\ngeneration are two representative tasks in bundle recommendation. The bundle\nmatching task is to correctly match existing bundles to users while the bundle\ngeneration is to generate new bundles that users would prefer. Although many\nrecent works have developed bundle recommendation models, they fail to achieve\nhigh accuracy since they do not handle heterogeneous data effectively and do\nnot learn a method for customized bundle generation. In this paper, we propose\nBundleMage, an accurate approach for bundle matching and generation. BundleMage\neffectively mixes user preferences of items and bundles using an adaptive gate\ntechnique to achieve high accuracy for the bundle matching. BundleMage also\ngenerates a personalized bundle by learning a generation module that exploits a\nuser preference and the characteristic of a given incomplete bundle to be\ncompleted. BundleMage further improves its performance using multi-task\nlearning with partially shared parameters. Through extensive experiments, we\nshow that BundleMage achieves up to 6.6% higher nDCG in bundle matching and\n6.3x higher nDCG in bundle generation than the best competitors. We also\nprovide qualitative analysis that BundleMage effectively generates bundles\nconsidering both the tastes of users and the characteristics of target bundles.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Hyunsik Jeon",
      "Jun-Gi Jang",
      "Taehun Kim",
      "U Kang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15460"
  },
  {
    "id": "arXiv:2210.15461",
    "title": "LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine  Translation",
    "abstract": "Multimodal Machine Translation (MMT) focuses on enhancing text-only\ntranslation with visual features, which has attracted considerable attention\nfrom both natural language processing and computer vision communities. Recent\nadvances still struggle to train a separate model for each language pair, which\nis costly and unaffordable when the number of languages increases in the real\nworld. In other words, the multilingual multimodal machine translation\n(Multilingual MMT) task has not been investigated, which aims to handle the\naforementioned issues by providing a shared semantic space for multiple\nlanguages. Besides, the image modality has no language boundaries, which is\nsuperior to bridging the semantic gap between languages. To this end, we first\npropose the Multilingual MMT task by establishing two new Multilingual MMT\nbenchmark datasets covering seven languages. Then, an effective baseline LVP-M3\nusing visual prompts is proposed to support translations between different\nlanguages, which includes three stages (token encoding, language-aware visual\nprompt generation, and language translation). Extensive experimental results on\nour constructed benchmark datasets demonstrate the effectiveness of LVP-M3\nmethod for Multilingual MMT.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Hongcheng Guo",
      "Jiaheng Liu",
      "Haoyang Huang",
      "Jian Yang",
      "Zhoujun Li",
      "Dongdong Zhang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15461"
  },
  {
    "id": "arXiv:2210.15462",
    "title": "He Said, She Said: Style Transfer for Shifting the Perspective of  Dialogues",
    "abstract": "In this work, we define a new style transfer task: perspective shift, which\nreframes a dialogue from informal first person to a formal third person\nrephrasing of the text. This task requires challenging coreference resolution,\nemotion attribution, and interpretation of informal text. We explore several\nbaseline approaches and discuss further directions on this task when applied to\nshort dialogues. As a sample application, we demonstrate that applying\nperspective shifting to a dialogue summarization dataset (SAMSum) substantially\nimproves the zero-shot performance of extractive news summarization models on\nthis data. Additionally, supervised extractive models perform better when\ntrained on perspective shifted data than on the original dialogues. We release\nour code publicly.",
    "descriptor": "\nComments: Findings of EMNLP 2022, 18 pages\n",
    "authors": [
      "Amanda Bertsch",
      "Graham Neubig",
      "Matthew R. Gormley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15462"
  },
  {
    "id": "arXiv:2210.15463",
    "title": "Appendix for Nonparametric Multivariate Probability Density Forecast in  Smart Grids With Deep Learning",
    "abstract": "This paper proposes a nonparametric multivariate density forecast model based\non deep learning. It not only offers the whole marginal distribution of each\nrandom variable in forecasting targets, but also reveals the future correlation\nbetween them. Differing from existing multivariate density forecast models, the\nproposed method requires no a priori hypotheses on the forecasted joint\nprobability distribution of forecasting targets. In addition, based on the\nuniversal approximation capability of neural networks, the real joint\ncumulative distribution functions of forecasting targets are well-approximated\nby a special positive-weighted deep neural network in the proposed method.\nNumerical tests from different scenarios were implemented under a comprehensive\nverification framework for evaluation, including the very short-term forecast\nof the wind speed, wind power, and the day-ahead forecast of the aggregated\nelectricity load. Testing results corroborate the superiority of the proposed\nmethod over current multivariate density forecast models considering the\naccordance with reality, prediction interval width, and correlations between\ndifferent random variables.",
    "descriptor": "",
    "authors": [
      "Zichao Meng",
      "Ye Guo",
      "Wenjun Tang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15463"
  },
  {
    "id": "arXiv:2210.15469",
    "title": "Learning Failure-Inducing Models for Testing Software-Defined Networks",
    "abstract": "Software-defined networks (SDN) enable flexible and effective communication\nsystems, e.g., data centers, that are managed by centralized software\ncontrollers. However, such a controller can undermine the underlying\ncommunication network of an SDN-based system and thus must be carefully tested.\nWhen an SDN-based system fails, in order to address such a failure, engineers\nneed to precisely understand the conditions under which it occurs. In this\npaper, we introduce a machine learning-guided fuzzing method, named FuzzSDN,\naiming at both (1) generating effective test data leading to failures in\nSDN-based systems and (2) learning accurate failure-inducing models that\ncharacterize conditions under which such system fails. This is done in a\nsynergistic manner where models guide test generation and the latter also aims\nat improving the models. To our knowledge, FuzzSDN is the first attempt to\nsimultaneously address these two objectives for SDNs. We evaluate FuzzSDN by\napplying it to systems controlled by two open-source SDN controllers. Further,\nwe compare FuzzSDN with two state-of-the-art methods for fuzzing SDNs and two\nbaselines (i.e., simple extensions of these two existing methods) for learning\nfailure-inducing models. Our results show that (1) compared to the\nstate-of-the-art methods, FuzzSDN generates at least 12 times more failures,\nwithin the same time budget, with a controller that is fairly robust to fuzzing\nand (2) our failure-inducing models have, on average, a precision of 98% and a\nrecall of 86%, significantly outperforming the baselines.",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Ollando",
      "Seung Yeob Shin",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.15469"
  },
  {
    "id": "arXiv:2210.15470",
    "title": "DAGKT: Difficulty and Attempts Boosted Graph-based Knowledge Tracing",
    "abstract": "In the field of intelligent education, knowledge tracing (KT) has attracted\nincreasing attention, which estimates and traces students' mastery of knowledge\nconcepts to provide high-quality education. In KT, there are natural graph\nstructures among questions and knowledge concepts so some studies explored the\napplication of graph neural networks (GNNs) to improve the performance of the\nKT models which have not used graph structure. However, most of them ignored\nboth the questions' difficulties and students' attempts at questions. Actually,\nquestions with the same knowledge concepts have different difficulties, and\nstudents' different attempts also represent different knowledge mastery. In\nthis paper, we propose a difficulty and attempts boosted graph-based KT\n(DAGKT), using rich information from students' records. Moreover, a novel\nmethod is designed to establish the question similarity relationship inspired\nby the F1 score. Extensive experiments on three real-world datasets demonstrate\nthe effectiveness of the proposed DAGKT.",
    "descriptor": "\nComments: 12 pages, 3figures, conference:ICONIP\n",
    "authors": [
      "Rui Luo",
      "Fei Liu",
      "Wenhao Liang",
      "Yuhong Zhang",
      "Chenyang Bu",
      "Xuegang Hu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15470"
  },
  {
    "id": "arXiv:2210.15472",
    "title": "Intersection of triangles in space based on cutting off segment",
    "abstract": "The article proposes a new method for finding the triangle-triangle\nintersection in 3D space, based on the use of computer graphics algorithms --\ncutting off segments on the plane when moving and rotating the beginning of the\ncoordinate axes of space. This method is obtained by synthesis of two methods\nof cutting off segments on the plane -- Cohen-Sutherland algorithm and\nFC-algorithm. In the proposed method, the problem of triangle-triangle\nintersection in 3D space is reduced to a simpler and less resource-intensive\ncut-off problem on the plane. The main feature of the method is the developed\nscheme of coding the points of the cut-off in relation to the triangle segment\nplane. This scheme allows you to get rid of a large number of costly\ncalculations. In the article the cases of intersection of triangles at\nparallelism, intersection and coincidence of planes of triangles are\nconsidered. The proposed method can be used in solving the problem of\ntetrahedron intersection, using the finite element method, as well as in image\nprocessing.",
    "descriptor": "\nComments: Convergent Cognitive Information Technologies. Convergent 2019. Communications in Computer and Information Science, in press, Springer, Cham. this http URL (14 pages, 11 figures)\n",
    "authors": [
      "Irina Bolodurina",
      "Georgii Nigmatulin",
      "Denis Parfenov"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2210.15472"
  },
  {
    "id": "arXiv:2210.15476",
    "title": "Quotatives Indicate Decline in Objectivity in U.S. Political News",
    "abstract": "According to journalistic standards, direct quotes should be attributed to\nsources with objective quotatives such as \"said\" and \"told\", as nonobjective\nquotatives, like \"argued\" and \"insisted\" would influence the readers'\nperception of the quote and the quoted person. In this paper, we analyze the\nadherence to this journalistic norm to study trends in objectivity in political\nnews across U.S. outlets of different ideological leanings. We ask: 1) How has\nthe usage of nonobjective quotatives evolved? and 2) How do news outlets use\nnonobjective quotatives when covering politicians of different parties? To\nanswer these questions, we developed a dependency-parsing-based method to\nextract quotatives and applied it to Quotebank, a web-scale corpus of\nattributed quotes, obtaining nearly 7 million quotes, each enriched with the\nquoted speaker's political party and the ideological leaning of the outlet that\npublished the quote. We find that while partisan outlets are the ones that most\noften use nonobjective quotatives, between 2013 and 2020, the outlets that\nincreased their usage of nonobjective quotatives the most were \"moderate\"\ncentrist news outlets (around 0.6 percentage points, or 20% in relative\npercentage over 7 years). Further, we find that outlets use nonobjective\nquotatives more often when quoting politicians of the opposing ideology (e.g.,\nleft-leaning outlets quoting Republicans), and that this \"quotative bias\" is\nrising at a swift pace, increasing up to 0.5 percentage points, or 25% in\nrelative percentage, per year. These findings suggest an overall decline in\njournalistic objectivity in U.S. political news.",
    "descriptor": "\nComments: Repo: this https URL\n",
    "authors": [
      "Tiancheng Hu",
      "Manoel Horta Ribeiro",
      "Robert West",
      "Andreas Spitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.15476"
  },
  {
    "id": "arXiv:2210.15477",
    "title": "A Novel Filter Approach for Band Selection and Classification of  Hyperspectral Remotely Sensed Images Using Normalized Mutual Information and  Support Vector Machines",
    "abstract": "Band selection is a great challenging task in the classification of\nhyperspectral remotely sensed images HSI. This is resulting from its high\nspectral resolution, the many class outputs and the limited number of training\nsamples. For this purpose, this paper introduces a new filter approach for\ndimension reduction and classification of hyperspectral images using\ninformation theoretic (normalized mutual information) and support vector\nmachines SVM. This method consists to select a minimal subset of the most\ninformative and relevant bands from the input datasets for better\nclassification efficiency. We applied our proposed algorithm on two well-known\nbenchmark datasets gathered by the NASA's AVIRIS sensor over Indiana and\nSalinas valley in USA. The experimental results were assessed based on\ndifferent evaluation metrics widely used in this area. The comparison with the\nstate of the art methods proves that our method could produce good performance\nwith reduced number of selected bands in a good timing.\nKeywords: Dimension reduction, Hyperspectral images, Band selection,\nNormalized mutual information, Classification, Support vector machines",
    "descriptor": "\nComments: this http URL&partnerID=MN8TOARS\n",
    "authors": [
      "Hasna Nhaila",
      "Asma Elmaizi",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15477"
  },
  {
    "id": "arXiv:2210.15478",
    "title": "Human-Likeness Indicator for Robot Posture Control and Balance",
    "abstract": "Similarly to humans, humanoid robots require posture control and balance to\nwalk and interact with the environment. In this work posture control in\nperturbed conditions is evaluated as a performance test for humanoid control. A\nspecific performance indicator is proposed: the score is based on the\ncomparison between the body sway of the tested humanoid standing on a moving\nsurface and the sway produced by healthy subjects performing the same\nexperiment. This approach is here oriented to the evaluation of a\nhuman-likeness. The measure is tested using a humanoid robot in order to\ndemonstrate a typical usage of the proposed evaluation scheme and an example of\nhow to improve robot control on the basis of such a performance indicator score",
    "descriptor": "\nComments: 16 pages, 5 Figures. arXiv admin note: substantial text overlap with arXiv:2110.14395\n",
    "authors": [
      "Vittorio Lippi",
      "Christoph Maurer",
      "Thomas Mergner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15478"
  },
  {
    "id": "arXiv:2210.15479",
    "title": "Low-Rank Modular Reinforcement Learning via Muscle Synergy",
    "abstract": "Modular Reinforcement Learning (RL) decentralizes the control of multi-joint\nrobots by learning policies for each actuator. Previous work on modular RL has\nproven its ability to control morphologically different agents with a shared\nactuator policy. However, with the increase in the Degree of Freedom (DoF) of\nrobots, training a morphology-generalizable modular controller becomes\nexponentially difficult. Motivated by the way the human central nervous system\ncontrols numerous muscles, we propose a Synergy-Oriented LeARning (SOLAR)\nframework that exploits the redundant nature of DoF in robot control. Actuators\nare grouped into synergies by an unsupervised learning method, and a synergy\naction is learned to control multiple actuators in synchrony. In this way, we\nachieve a low-rank control at the synergy level. We extensively evaluate our\nmethod on a variety of robot morphologies, and the results show its superior\nefficiency and generalizability, especially on robots with a large DoF like\nHumanoids++ and UNIMALs.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Heng Dong",
      "Tonghan Wang",
      "Jiayuan Liu",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15479"
  },
  {
    "id": "arXiv:2210.15483",
    "title": "Circular Pythagorean fuzzy sets and applications to multi-criteria  decision making",
    "abstract": "In this paper, we introduce the concept of circular Pythagorean fuzzy set\n(value) (C-PFS(V)) as a new generalization of both circular intuitionistic\nfuzzy sets (C-IFSs) proposed by Atannassov and Pythagorean fuzzy sets (PFSs)\nproposed by Yager. A circular Pythagorean fuzzy set is represented by a circle\nthat represents the membership degree and the non-membership degree and whose\ncenter consists of non-negative real numbers $\\mu$ and $\\nu$ with the condition\n$\\mu^2+\\nu^2\\leq 1$. A C-PFS models the fuzziness of the uncertain information\nmore properly thanks to its structure that allows modelling the information\nwith points of a circle of a certain center and a radius. Therefore, a C-PFS\nlets decision makers to evaluate objects in a larger and more flexible region\nand thus more sensitive decisions can be made. After defining the concept of\nC-PFS we define some fundamental set operations between C-PFSs and propose some\nalgebraic operations between C-PFVs via general $t$-norms and $t$-conorms. By\nutilizing these algebraic operations, we introduce some weighted aggregation\noperators to transform input values represented by C-PFVs to a single output\nvalue. Then to determine the degree of similarity between C-PFVs we define a\ncosine similarity measure based on radius. Furthermore, we develop a method to\ntransform a collection of Pythagorean fuzzy values to a PFS. Finally, a method\nis given to solve multi-criteria decision making problems in circular\nPythagorean fuzzy environment and the proposed method is practiced to a problem\nabout selecting the best photovoltaic cell from the literature. We also study\nthe comparison analysis and time complexity of the proposed method.",
    "descriptor": "",
    "authors": [
      "Mahmut Can Bozyi\u011fit",
      "Murat Olgun",
      "Mehmet \u00dcnver"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15483"
  },
  {
    "id": "arXiv:2210.15489",
    "title": "Study of the Fractal decomposition based metaheuristic on  low-dimensional Black-Box optimization problems",
    "abstract": "This paper analyzes the performance of the Fractal Decomposition Algorithm\n(FDA) metaheuristic applied to low-dimensional continuous optimization\nproblems. This algorithm was originally developed specifically to deal\nefficiently with high-dimensional continuous optimization problems by building\na fractal-based search tree with a branching factor linearly proportional to\nthe number of dimensions. Here, we aim to answer the question of whether FDA\ncould be equally effective for low-dimensional problems. For this purpose, we\nevaluate the performance of FDA on the Black Box Optimization Benchmark (BBOB)\nfor dimensions 2, 3, 5, 10, 20, and 40. The experimental results show that\noverall the FDA in its current form does not perform well enough. Among\ndifferent function groups, FDA shows its best performance on Misc. moderate and\nWeak structure functions.",
    "descriptor": "",
    "authors": [
      "Arcadi Llanza",
      "Nadiya Shvai",
      "Amir Nakib"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15489"
  },
  {
    "id": "arXiv:2210.15491",
    "title": "GaitMixer: skeleton-based gait representation learning via wide-spectrum  multi-axial mixer",
    "abstract": "Most existing gait recognition methods are appearance-based, which rely on\nthe silhouettes extracted from the video data of human walking activities. The\nless-investigated skeleton-based gait recognition methods directly learn the\ngait dynamics from 2D/3D human skeleton sequences, which are theoretically more\nrobust solutions in the presence of appearance changes caused by clothes,\nhairstyles, and carrying objects. However, the performance of skeleton-based\nsolutions is still largely behind the appearance-based ones. This paper aims to\nclose such performance gap by proposing a novel network model, GaitMixer, to\nlearn more discriminative gait representation from skeleton sequence data. In\nparticular, GaitMixer follows a heterogeneous multi-axial mixer architecture,\nwhich exploits the spatial self-attention mixer followed by the temporal\nlarge-kernel convolution mixer to learn rich multi-frequency signals in the\ngait feature maps. Experiments on the widely used gait database, CASIA-B,\ndemonstrate that GaitMixer outperforms the previous SOTA skeleton-based methods\nby a large margin while achieving a competitive performance compared with the\nrepresentative appearance-based solutions. Code will be available at\nhttps://github.com/exitudio/gaitmixer",
    "descriptor": "",
    "authors": [
      "Ekkasit Pinyoanuntapong",
      "Ayman Ali",
      "Pu Wang",
      "Minwoo Lee",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15491"
  },
  {
    "id": "arXiv:2210.15492",
    "title": "Reconstruction of compressed spectral imaging based on global structure  and spectral correlation",
    "abstract": "In this paper, a convolution sparse coding method based on global structure\ncharacteristics and spectral correlation is proposed for the reconstruction of\ncompressive spectral images. The proposed method uses the convolution kernel to\noperate the global image, which can better preserve image structure information\nin the spatial dimension. To take full exploration of the constraints between\nspectra, the coefficients corresponding to the convolution kernel are\nconstrained by the norm to improve spectral accuracy. And, to solve the problem\nthat convolutional sparse coding is insensitive to low frequency, the global\ntotal-variation (TV) constraint is added to estimate the low-frequency\ncomponents. It not only ensures the effective estimation of the low-frequency\nbut also transforms the convolutional sparse coding into a de-noising process,\nwhich makes the reconstructing process simpler. Simulations show that compared\nwith the current mainstream optimization methods (DeSCI and Gap-TV), the\nproposed method improves the reconstruction quality by up to 7 dB in PSNR and\n10% in SSIM, and has a great improvement in the details of the reconstructed\nimage.",
    "descriptor": "",
    "authors": [
      "Pan Wang",
      "Jie Li",
      "Siqi Zhang",
      "Chun Qi",
      "Lin Wang",
      "Jieru Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.15492"
  },
  {
    "id": "arXiv:2210.15494",
    "title": "Service-Based Wireless Energy Crowdsourcing",
    "abstract": "We propose a novel service-based ecosystem to crowdsource wireless energy to\ncharge IoT devices. We leverage the service paradigm to abstract wireless\nenergy crowdsourcing from nearby IoT devices as energy services. The proposed\nenergy services ecosystem offers convenient, ubiquitous, and cost-effective\npower access to charge IoT devices. We discuss the impact of a crowdsourced\nwireless energy services ecosystem, the building components of the ecosystem,\nthe energy services composition framework, the challenges, and proposed\nsolutions.",
    "descriptor": "\nComments: 15 pages, 7 figures, This is an invited paper and it will appear in the proceedings of the 20th International Conference on Service Oriented Computing (ICSOC)\n",
    "authors": [
      "Amani Abusafia",
      "Abdallah Lakhdari",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.15494"
  },
  {
    "id": "arXiv:2210.15495",
    "title": "Leveraging Wikidata's edit history in knowledge graph refinement tasks",
    "abstract": "Knowledge graphs have been adopted in many diverse fields for a variety of\npurposes. Most of those applications rely on valid and complete data to deliver\ntheir results, pressing the need to improve the quality of knowledge graphs. A\nnumber of solutions have been proposed to that end, ranging from rule-based\napproaches to the use of probabilistic methods, but there is an element that\nhas not been considered yet: the edit history of the graph. In the case of\ncollaborative knowledge graphs (e.g., Wikidata), those edits represent the\nprocess in which the community reaches some kind of fuzzy and distributed\nconsensus over the information that best represents each entity, and can hold\npotentially interesting information to be used by knowledge graph refinement\nmethods. In this paper, we explore the use of edit history information from\nWikidata to improve the performance of type prediction methods. To do that, we\nhave first built a JSON dataset containing the edit history of every instance\nfrom the 100 most important classes in Wikidata. This edit history information\nis then explored and analyzed, with a focus on its potential applicability in\nknowledge graph refinement tasks. Finally, we propose and evaluate two new\nmethods to leverage this edit history information in knowledge graph embedding\nmodels for type prediction tasks. Our results show an improvement in one of the\nproposed methods against current approaches, showing the potential of using\nedit information in knowledge graph refinement tasks and opening new promising\nresearch lines within the field.",
    "descriptor": "\nComments: 18 pages, 7 figures. Submitted to the Journal of Web Semantics\n",
    "authors": [
      "Alejandro Gonzalez-Hevia",
      "Daniel Gayo-Avello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15495"
  },
  {
    "id": "arXiv:2210.15496",
    "title": "Resource Constrained Vehicular Edge Federated Learning with Highly  Mobile Connected Vehicles",
    "abstract": "This paper proposes a vehicular edge federated learning (VEFL) solution,\nwhere an edge server leverages highly mobile connected vehicles' (CVs') onboard\ncentral processing units (CPUs) and local datasets to train a global model.\nConvergence analysis reveals that the VEFL training loss depends on the\nsuccessful receptions of the CVs' trained models over the intermittent\nvehicle-to-infrastructure (V2I) wireless links. Owing to high mobility, in the\nfull device participation case (FDPC), the edge server aggregates client model\nparameters based on a weighted combination according to the CVs' dataset sizes\nand sojourn periods, while it selects a subset of CVs in the partial device\nparticipation case (PDPC). We then devise joint VEFL and radio access\ntechnology (RAT) parameters optimization problems under delay, energy and cost\nconstraints to maximize the probability of successful reception of the locally\ntrained models. Considering that the optimization problem is NP-hard, we\ndecompose it into a VEFL parameter optimization sub-problem, given the\nestimated worst-case sojourn period, delay and energy expense, and an online\nRAT parameter optimization sub-problem. Finally, extensive simulations are\nconducted to validate the effectiveness of the proposed solutions with a\npractical 5G new radio (5G-NR) RAT under a realistic microscopic mobility\nmodel.",
    "descriptor": "",
    "authors": [
      "Md Ferdous Pervej",
      "Richeng Jin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.15496"
  },
  {
    "id": "arXiv:2210.15497",
    "title": "LSG Attention: Extrapolation of pretrained Transformers to long  sequences",
    "abstract": "Transformer models achieve state-of-the-art performance on a wide range of\nNLP tasks. They however suffer from a prohibitive limitation due to the\nself-attention mechanism, inducing $O(n^2)$ complexity with regard to sequence\nlength. To answer this limitation we introduce the LSG architecture which\nrelies on Local, Sparse and Global attention. We show that LSG attention is\nfast, efficient and competitive in classification and summarization tasks on\nlong documents. Interestingly, it can also be used to adapt existing pretrained\nmodels to efficiently extrapolate to longer sequences with no additional\ntraining. Along with the introduction of the LSG attention mechanism, we\npropose tools to train new models and adapt existing ones based on this\nmechanism.",
    "descriptor": "",
    "authors": [
      "Charles Condevaux",
      "S\u00e9bastien Harispe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15497"
  },
  {
    "id": "arXiv:2210.15498",
    "title": "Deep reinforcement learning for automatic run-time adaptation of UWB PHY  radio settings",
    "abstract": "Ultra-wideband technology has become increasingly popular for indoor\nlocalization and location-based services. This has led recent advances to be\nfocused on reducing the ranging errors, whilst research focusing on enabling\nmore reliable and energy efficient communication has been largely unexplored.\nThe IEEE 802.15.4 UWB physical layer allows for several settings to be selected\nthat influence the energy consumption, range, and reliability. Combined with\nthe available link state diagnostics reported by UWB devices, there is an\nopportunity to dynamically select PHY settings based on the environment. To\naddress this, we propose a deep Q-learning approach for enabling reliable UWB\ncommunication, maximizing packet reception rate (PRR) and minimizing energy\nconsumption. Deep Q-learning is a good fit for this problem, as it is an\ninherently adaptive algorithm that responds to the environment. Validation in a\nrealistic office environment showed that the algorithm outperforms traditional\nQ-learning, linear search and using a fixed PHY layer. We found that deep\nQ-learning achieves a higher average PRR and reduces the ranging error while\nusing only 14% of the energy compared to a fixed PHY setting in a dynamic\noffice environment.",
    "descriptor": "\nComments: 13 pages, 9 figures, 9 tables and submitted to IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "Dieter Coppens",
      "Adnan Shahid",
      "Eli De Poorter"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15498"
  },
  {
    "id": "arXiv:2210.15500",
    "title": "COFFEE: Counterfactual Fairness for Personalized Text Generation in  Explainable Recommendation",
    "abstract": "Personalized text generation has broad industrial applications, such as\nexplanation generation for recommendations, conversational systems, etc.\nPersonalized text generators are usually trained on user written text, e.g.,\nreviews collected on e-commerce platforms. However, due to historical, social,\nor behavioral reasons, there may exist bias that associates certain linguistic\nquality of user written text with the users' protected attributes such as\ngender, race, etc. The generators can identify and inherit these correlations\nand generate texts discriminately w.r.t. the users' protected attributes.\nWithout proper intervention, such bias can adversarially influence the users'\ntrust and reliance on the system. From a broader perspective, bias in\nauto-generated contents can reinforce the social stereotypes about how online\nusers write through interactions with the users.\nIn this work, we investigate the fairness of personalized text generation in\nthe setting of explainable recommendation. We develop a general framework for\nachieving measure-specific counterfactual fairness on the linguistic quality of\npersonalized explanations. We propose learning disentangled representations for\ncounterfactual inference and develop a novel policy learning algorithm with\ncarefully designed rewards for fairness optimization. The framework can be\napplied for achieving fairness on any given specifications of linguistic\nquality measures, and can be adapted to most of existing models and real-world\nsettings. Extensive experiments demonstrate the superior ability of our method\nin achieving fairness while maintaining high generation performance.",
    "descriptor": "",
    "authors": [
      "Nan Wang",
      "Shaoliang Nie",
      "Qifan Wang",
      "Yi-Chia Wang",
      "Maziar Sanjabi",
      "Jingzhou Liu",
      "Hamed Firooz",
      "Hongning Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15500"
  },
  {
    "id": "arXiv:2210.15504",
    "title": "Perception-aware Tag Placement Planning for Robust Localization of UAVs  in Indoor Construction Environments",
    "abstract": "Tag-based visual-inertial localization is a lightweight method for enabling\nautonomous data collection missions of low-cost unmanned aerial vehicles (UAVs)\nin indoor construction environments. However, finding the optimal tag\nconfiguration (i.e., number, size, and location) on dynamic construction sites\nremains challenging. This paper proposes a perception-aware genetic\nalgorithm-based tag placement planner (PGA-TaPP) to determine the optimal tag\nconfiguration using 4D-BIM, considering the project progress, safety\nrequirements, and UAV's localizability. The proposed method provides a 4D plan\nfor tag placement by maximizing the localizability in user-specified regions of\ninterest (ROIs) while limiting the installation costs. Localizability is\nquantified using the Fisher information matrix (FIM) and encapsulated in\nnavigable grids. The experimental results show the effectiveness of our method\nin finding an optimal 4D tag placement plan for the robust localization of UAVs\non under-construction indoor sites.",
    "descriptor": "\nComments: [Final draft] This material may be downloaded for personal use only. Any other use requires prior permission of the American Society of Civil Engineers and the Journal of Computing in Civil Engineering\n",
    "authors": [
      "Navid Kayhani",
      "Angela Schoellig",
      "Brenda McCabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15504"
  },
  {
    "id": "arXiv:2210.15505",
    "title": "Investigating the Origins of Fractality Based on Two Novel Fractal  Network Models",
    "abstract": "Numerous network models have been investigated to gain insights into the\norigins of fractality. In this work, we introduce two novel network models, to\nbetter understand the growing mechanism and structural characteristics of\nfractal networks. The Repulsion Based Fractal Model (RBFM) is built on the\nwell-known Song-Havlin-Makse (SHM) model, but in RBFM repulsion is always\npresent among a specific group of nodes. The model resolves the contradiction\nbetween the SHM model and the Hub Attraction Dynamical Growth model, by showing\nthat repulsion is the characteristic that induces fractality. The Lattice\nSmall-world Transition Model (LSwTM) was motivated by the fact that repulsion\ndirectly influences the node distances. Through LSwTM we study the\nfractal-small-world transition. The model illustrates the transition on a fixed\nnumber of nodes and edges using a preferential-attachment-based edge rewiring\nprocess. It shows that a small average distance works against fractal scaling,\nand also demonstrates that fractality is not a dichotomous property, continuous\ntransition can be observed between the pure fractal and non-fractal\ncharacteristics.",
    "descriptor": "\nComments: 12 pages, 5 figures, to appear in: 978-3-031-17657-9, Pacheco et al (eds.): Complex Networks XIII\n",
    "authors": [
      "Enik\u0151 Zakar-Poly\u00e1k",
      "Marcell Nagy",
      "Roland Molontay"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15505"
  },
  {
    "id": "arXiv:2210.15507",
    "title": "How To Overcome Richness Axiom Fallacy",
    "abstract": "The paper points at the grieving problems implied by the richness axiom in\nthe Kleinberg's axiomatic system and suggests resolutions. The richness induces\nlearnability problem in general and leads to conflicts with consistency axiom.\nAs a resolution, learnability constraints and usage of centric consistency or\nrestriction of the domain of considered clusterings to super-ball-clusterings\nis proposed.",
    "descriptor": "\nComments: 18 pages, 3 figures, 3 tables, an extended version of ISMIS2022 paper\n",
    "authors": [
      "Mieczys\u0142aw A. K\u0142opotek",
      "Robert A. K\u0142opotek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15507"
  },
  {
    "id": "arXiv:2210.15510",
    "title": "Fusion-based Few-Shot Morphing Attack Detection and Fingerprinting",
    "abstract": "The vulnerability of face recognition systems to morphing attacks has posed a\nserious security threat due to the wide adoption of face biometrics in the real\nworld. Most existing morphing attack detection (MAD) methods require a large\namount of training data and have only been tested on a few predefined attack\nmodels. The lack of good generalization properties, especially in view of the\ngrowing interest in developing novel morphing attacks, is a critical limitation\nwith existing MAD research. To address this issue, we propose to extend MAD\nfrom supervised learning to few-shot learning and from binary detection to\nmulticlass fingerprinting in this paper. Our technical contributions include:\n1) We propose a fusion-based few-shot learning (FSL) method to learn\ndiscriminative features that can generalize to unseen morphing attack types\nfrom predefined presentation attacks; 2) The proposed FSL based on the fusion\nof the PRNU model and Noiseprint network is extended from binary MAD to\nmulticlass morphing attack fingerprinting (MAF). 3) We have collected a\nlarge-scale database, which contains five face datasets and eight different\nmorphing algorithms, to benchmark the proposed few-shot MAF (FS-MAF) method.\nExtensive experimental results show the outstanding performance of our\nfusion-based FS-MAF. The code and data will be publicly available at\nhttps://github.com/nz0001na/mad maf.",
    "descriptor": "",
    "authors": [
      "Na Zhang",
      "Shan Jia",
      "Siwei Lyu",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15510"
  },
  {
    "id": "arXiv:2210.15511",
    "title": "ProContEXT: Exploring Progressive Context Transformer for Tracking",
    "abstract": "Existing Visual Object Tracking (VOT) only takes the target area in the first\nframe as a template. This causes tracking to inevitably fail in fast-changing\nand crowded scenes, as it cannot account for changes in object appearance\nbetween frames. To this end, we revamped the tracking framework with\nProgressive Context Encoding Transformer Tracker (ProContEXT), which coherently\nexploits spatial and temporal contexts to predict object motion trajectories.\nSpecifically, ProContEXT leverages a context-aware self-attention module to\nencode the spatial and temporal context, refining and updating the multi-scale\nstatic and dynamic templates to progressively perform accurate tracking. It\nexplores the complementary between spatial and temporal context, raising a new\npathway to multi-context modeling for transformer-based trackers. In addition,\nProContEXT revised the token pruning technique to reduce computational\ncomplexity. Extensive experiments on popular benchmark datasets such as GOT-10k\nand TrackingNet demonstrate that the proposed ProContEXT achieves\nstate-of-the-art performance.",
    "descriptor": "\nComments: The source code is at this https URL\n",
    "authors": [
      "Jin-Peng Lan",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Bin Luo",
      "Xu Bao",
      "Wangmeng Xiang",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15511"
  },
  {
    "id": "arXiv:2210.15514",
    "title": "Point-Voxel Adaptive Feature Abstraction for Robust Point Cloud  Classification",
    "abstract": "Great progress has been made in point cloud classification with\nlearning-based methods. However, complex scene and sensor inaccuracy in\nreal-world application make point cloud data suffer from corruptions, such as\nocclusion, noise and outliers. In this work, we propose Point-Voxel based\nAdaptive (PV-Ada) feature abstraction for robust point cloud classification\nunder various corruptions. Specifically, the proposed framework iteratively\nvoxelize the point cloud and extract point-voxel feature with shared local\nencoding and Transformer. Then, adaptive max-pooling is proposed to robustly\naggregate the point cloud feature for classification. Experiments on ModelNet-C\ndataset demonstrate that PV-Ada outperforms the state-of-the-art methods. In\nparticular, we rank the $2^{nd}$ place in ModelNet-C classification track of\nPointCloud-C Challenge 2022, with Overall Accuracy (OA) being 0.865. Code will\nbe available at https://github.com/zhulf0804/PV-Ada.",
    "descriptor": "",
    "authors": [
      "Lifa Zhu",
      "Changwei Lin",
      "Cheng Zheng",
      "Ninghua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15514"
  },
  {
    "id": "arXiv:2210.15515",
    "title": "Meta-Reinforcement Learning Using Model Parameters",
    "abstract": "In meta-reinforcement learning, an agent is trained in multiple different\nenvironments and attempts to learn a meta-policy that can efficiently adapt to\na new environment. This paper presents RAMP, a Reinforcement learning Agent\nusing Model Parameters that utilizes the idea that a neural network trained to\npredict environment dynamics encapsulates the environment information. RAMP is\nconstructed in two phases: in the first phase, a multi-environment\nparameterized dynamic model is learned. In the second phase, the model\nparameters of the dynamic model are used as context for the multi-environment\npolicy of the model-free reinforcement learning agent.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Gabriel Hartmann",
      "Amos Azaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15515"
  },
  {
    "id": "arXiv:2210.15518",
    "title": "LongShortNet: Exploring Temporal and Semantic Features Fusion in  Streaming Perception",
    "abstract": "Streaming perception is a task of reporting the current state of autonomous\ndriving, which coherently considers the latency and accuracy of autopilot\nsystems. However, the existing streaming perception only uses the current and\nadjacent two frames as input for learning the movement patterns, which cannot\nmodel actual complex scenes, resulting in failed detection results. To solve\nthis problem, we propose an end-to-end dual-path network dubbed LongShortNet,\nwhich captures long-term temporal motion and calibrates it with short-term\nspatial semantics for real-time perception. Moreover, we investigate a\nLong-Short Fusion Module (LSFM) to explore spatiotemporal feature fusion, which\nis the first work to extend long-term temporal in streaming perception. We\nevaluate the proposed LongShortNet and compare it with existing methods on the\nbenchmark dataset Argoverse-HD. The results demonstrate that the proposed\nLongShortNet outperforms the other state-of-the-art methods with almost no\nextra computational cost.",
    "descriptor": "\nComments: The source code is at this https URL\n",
    "authors": [
      "Chenyang Li",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Pengyu Li",
      "Bin Luo",
      "Han-Yuan Chen",
      "Yifeng Geng",
      "Jin-Peng Lan",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15518"
  },
  {
    "id": "arXiv:2210.15523",
    "title": "COST-EFF: Collaborative Optimization of Spatial and Temporal Efficiency  with Slenderized Multi-exit Language Models",
    "abstract": "Transformer-based pre-trained language models (PLMs) mostly suffer from\nexcessive overhead despite their advanced capacity. For resource-constrained\ndevices, there is an urgent need for a spatially and temporally efficient model\nwhich retains the major capacity of PLMs. However, existing statically\ncompressed models are unaware of the diverse complexities between input\ninstances, potentially resulting in redundancy and inadequacy for simple and\ncomplex inputs. Also, miniature models with early exiting encounter challenges\nin the trade-off between making predictions and serving the deeper layers.\nMotivated by such considerations, we propose a collaborative optimization for\nPLMs that integrates static model compression and dynamic inference\nacceleration. Specifically, the PLM is slenderized in width while the depth\nremains intact, complementing layer-wise early exiting to speed up inference\ndynamically. To address the trade-off of early exiting, we propose a joint\ntraining approach that calibrates slenderization and preserves contributive\nstructures to each exit instead of only the final layer. Experiments are\nconducted on GLUE benchmark and the results verify the Pareto optimality of our\napproach at high compression and acceleration rate with 1/8 parameters and 1/19\nFLOPs of BERT.",
    "descriptor": "\nComments: Accepted in EMNLP 2022 main conference\n",
    "authors": [
      "Bowen Shen",
      "Zheng Lin",
      "Yuanxin Liu",
      "Zhengxiao Liu",
      "Lei Wang",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15523"
  },
  {
    "id": "arXiv:2210.15527",
    "title": "Exploiting Features and Logits in Heterogeneous Federated Learning",
    "abstract": "Due to the rapid growth of IoT and artificial intelligence, deploying neural\nnetworks on IoT devices is becoming increasingly crucial for edge intelligence.\nFederated learning (FL) facilitates the management of edge devices to\ncollaboratively train a shared model while maintaining training data local and\nprivate. However, a general assumption in FL is that all edge devices are\ntrained on the same machine learning model, which may be impractical\nconsidering diverse device capabilities. For instance, less capable devices may\nslow down the updating process because they struggle to handle large models\nappropriate for ordinary devices. In this paper, we propose a novel data-free\nFL method that supports heterogeneous client models by managing features and\nlogits, called Felo; and its extension with a conditional VAE deployed in the\nserver, called Velo. Felo averages the mid-level features and logits from the\nclients at the server based on their class labels to provide the average\nfeatures and logits, which are utilized for further training the client models.\nUnlike Felo, the server has a conditional VAE in Velo, which is used for\ntraining mid-level features and generating synthetic features according to the\nlabels. The clients optimize their models based on the synthetic features and\nthe average logits. We conduct experiments on two datasets and show\nsatisfactory performances of our methods compared with the state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Yun-Hin Chan",
      "Edith C.-H. Ngai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15527"
  },
  {
    "id": "arXiv:2210.15528",
    "title": "Data-Driven Analytic Differentiation via High Gain Observers and  Gaussian Process Priors",
    "abstract": "The presented paper tackles the problem of modeling an unknown function, and\nits first $r-1$ derivatives, out of scattered and poor-quality data. The\nconsidered setting embraces a large number of use cases addressed in the\nliterature and fits especially well in the context of control barrier\nfunctions, where high-order derivatives of the safe set are required to\npreserve the safety of the controlled system. The approach builds on a cascade\nof high-gain observers and a set of Gaussian process regressors trained on the\nobservers' data. The proposed structure allows for high robustness against\nmeasurement noise and flexibility with respect to the employed sampling law.\nUnlike previous approaches in the field, where a large number of samples are\nrequired to fit correctly the unknown function derivatives, here we suppose to\nhave access only to a small window of samples, sliding in time. The paper\npresents performance bounds on the attained regression error and numerical\nsimulations showing how the proposed method outperforms previous approaches.",
    "descriptor": "",
    "authors": [
      "Biagio Trimarchi",
      "Lorenzo Gentilini",
      "Fabrizio Schiano",
      "Lorenzo Marconi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15528"
  },
  {
    "id": "arXiv:2210.15529",
    "title": "Learning Location from Shared Elevation Profiles in Fitness Apps: A  Privacy Perspective",
    "abstract": "The extensive use of smartphones and wearable devices has facilitated many\nuseful applications. For example, with Global Positioning System (GPS)-equipped\nsmart and wearable devices, many applications can gather, process, and share\nrich metadata, such as geolocation, trajectories, elevation, and time. For\nexample, fitness applications, such as Runkeeper and Strava, utilize the\ninformation for activity tracking and have recently witnessed a boom in\npopularity. Those fitness tracker applications have their own web platforms and\nallow users to share activities on such platforms or even with other social\nnetwork platforms. To preserve the privacy of users while allowing sharing,\nseveral of those platforms may allow users to disclose partial information,\nsuch as the elevation profile for an activity, which supposedly would not leak\nthe location of the users. In this work, and as a cautionary tale, we create a\nproof of concept where we examine the extent to which elevation profiles can be\nused to predict the location of users. To tackle this problem, we devise three\nplausible threat settings under which the city or borough of the targets can be\npredicted. Those threat settings define the amount of information available to\nthe adversary to launch the prediction attacks. Establishing that simple\nfeatures of elevation profiles, e.g., spectral features, are insufficient, we\ndevise both natural language processing (NLP)-inspired text-like representation\nand computer vision-inspired image-like representation of elevation profiles,\nand we convert the problem at hand into text and image classification problem.\nWe use both traditional machine learning- and deep learning-based techniques\nand achieve a prediction success rate ranging from 59.59\\% to 99.80\\%. The\nfindings are alarming, highlighting that sharing elevation information may have\nsignificant location privacy risks.",
    "descriptor": "\nComments: 16 pages, 12 figures, 10 tables; accepted for publication in IEEE Transactions on Mobile Computing (October 2022). arXiv admin note: substantial text overlap with arXiv:1910.09041\n",
    "authors": [
      "Ulku Meteriz-Yildiran",
      "Necip Fazil Yildiran",
      "Joongheon Kim",
      "David Mohaisen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15529"
  },
  {
    "id": "arXiv:2210.15533",
    "title": "Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural  Vocoder",
    "abstract": "Our previous work, the unified source-filter GAN (uSFGAN) vocoder, introduced\na novel architecture based on the source-filter theory into the parallel\nwaveform generative adversarial network to achieve high voice quality and pitch\ncontrollability. However, the high temporal resolution inputs result in high\ncomputation costs. Although the HiFi-GAN vocoder achieves fast high-fidelity\nvoice generation thanks to the efficient upsampling-based generator\narchitecture, the pitch controllability is severely limited. To realize a fast\nand pitch-controllable high-fidelity neural vocoder, we introduce the\nsource-filter theory into HiFi-GAN by hierarchically conditioning the resonance\nfiltering network on a well-estimated source excitation information. According\nto the experimental results, our proposed method outperforms HiFi-GAN and\nuSFGAN on a singing voice generation in voice quality and synthesis speed on a\nsingle CPU. Furthermore, unlike the uSFGAN vocoder, the proposed method can be\neasily adopted/integrated in real-time applications and end-to-end systems.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Reo Yoneyama",
      "Yi-Chiao Wu",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15533"
  },
  {
    "id": "arXiv:2210.15540",
    "title": "Masked Transformer for image Anomaly Localization",
    "abstract": "Image anomaly detection consists in detecting images or image portions that\nare visually different from the majority of the samples in a dataset. The task\nis of practical importance for various real-life applications like biomedical\nimage analysis, visual inspection in industrial production, banking, traffic\nmanagement, etc. Most of the current deep learning approaches rely on image\nreconstruction: the input image is projected in some latent space and then\nreconstructed, assuming that the network (mostly trained on normal data) will\nnot be able to reconstruct the anomalous portions. However, this assumption\ndoes not always hold. We thus propose a new model based on the Vision\nTransformer architecture with patch masking: the input image is split in\nseveral patches, and each patch is reconstructed only from the surrounding\ndata, thus ignoring the potentially anomalous information contained in the\npatch itself. We then show that multi-resolution patches and their collective\nembeddings provide a large improvement in the model's performance compared to\nthe exclusive use of the traditional square patches. The proposed model has\nbeen tested on popular anomaly detection datasets such as MVTec and head CT and\nachieved good results when compared to other state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Axel De Nardin",
      "Pankaj Mishra",
      "Gian Luca Foresti",
      "Claudio Piciarelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15540"
  },
  {
    "id": "arXiv:2210.15541",
    "title": "Transformers meet Stochastic Block Models: Attention with Data-Adaptive  Sparsity and Cost",
    "abstract": "To overcome the quadratic cost of self-attention, recent works have proposed\nvarious sparse attention modules, most of which fall under one of two groups:\n1) sparse attention under a hand-crafted patterns and 2) full attention\nfollowed by a sparse variant of softmax such as $\\alpha$-entmax. Unfortunately,\nthe first group lacks adaptability to data while the second still requires\nquadratic cost in training. In this work, we propose SBM-Transformer, a model\nthat resolves both problems by endowing each attention head with a\nmixed-membership Stochastic Block Model (SBM). Then, each attention head\ndata-adaptively samples a bipartite graph, the adjacency of which is used as an\nattention mask for each input. During backpropagation, a straight-through\nestimator is used to flow gradients beyond the discrete sampling step and\nadjust the probabilities of sampled edges based on the predictive loss. The\nforward and backward cost are thus linear to the number of edges, which each\nattention head can also choose flexibly based on the input. By assessing the\ndistribution of graphs, we theoretically show that SBM-Transformer is a\nuniversal approximator for arbitrary sequence-to-sequence functions in\nexpectation. Empirical evaluations under the LRA and GLUE benchmarks\ndemonstrate that our model outperforms previous efficient variants as well as\nthe original Transformer with full attention. Our implementation can be found\nin https://github.com/sc782/SBM-Transformer .",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Sungjun Cho",
      "Seonwoo Min",
      "Jinwoo Kim",
      "Moontae Lee",
      "Honglak Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15541"
  },
  {
    "id": "arXiv:2210.15543",
    "title": "Beyond the Return: Off-policy Function Estimation under User-specified  Error-measuring Distributions",
    "abstract": "Off-policy evaluation often refers to two related tasks: estimating the\nexpected return of a policy and estimating its value function (or other\nfunctions of interest, such as density ratios). While recent works on\nmarginalized importance sampling (MIS) show that the former can enjoy provable\nguarantees under realizable function approximation, the latter is only known to\nbe feasible under much stronger assumptions such as prohibitively expressive\ndiscriminators. In this work, we provide guarantees for off-policy function\nestimation under only realizability, by imposing proper regularization on the\nMIS objectives. Compared to commonly used regularization in MIS, our\nregularizer is much more flexible and can account for an arbitrary\nuser-specified distribution, under which the learned function will be close to\nthe groundtruth. We provide exact characterization of the optimal dual solution\nthat needs to be realized by the discriminator class, which determines the\ndata-coverage assumption in the case of value-function learning. As another\nsurprising observation, the regularizer can be altered to relax the\ndata-coverage requirement, and completely eliminate it in the ideal case with\nstrong side information.",
    "descriptor": "",
    "authors": [
      "Audrey Huang",
      "Nan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15543"
  },
  {
    "id": "arXiv:2210.15546",
    "title": "Hyperspectral Images Classification and Dimensionality Reduction using  spectral interaction and SVM classifier",
    "abstract": "Over the past decades, the hyperspectral remote sensing technology\ndevelopment has attracted growing interest among scientists in various domains.\nThe rich and detailed spectral information provided by the hyperspectral\nsensors has improved the monitoring and detection capabilities of the earth\nsurface substances. However, the high dimensionality of the hyperspectral\nimages (HSI) is one of the main challenges for the analysis of the collected\ndata. The existence of noisy, redundant and irrelevant bands increases the\ncomputational complexity, induce the Hughes phenomenon and decrease the\ntarget's classification accuracy. Hence, the dimensionality reduction is an\nessential step to face the dimensionality challenges. In this paper, we propose\na novel filter approach based on the maximization of the spectral interaction\nmeasure and the support vector machines for dimensionality reduction and\nclassification of the HSI. The proposed Max Relevance Max Synergy (MRMS)\nalgorithm evaluates the relevance of every band through the combination of\nspectral synergy, redundancy and relevance measures. Our objective is to select\nthe optimal subset of synergistic bands providing accurate classification of\nthe supervised scene materials. Experimental results have been performed using\nthree different hyperspectral datasets: \"Indiana Pine\", \"Pavia University\" and\n\"Salinas\" provided by the \"NASA-AVIRIS\" and the \"ROSIS\" spectrometers.\nFurthermore, a comparison with the state of the art band selection methods has\nbeen carried out in order to demonstrate the robustness and efficiency of the\nproposed approach.\nKeywords: Hyperspectral images, remote sensing, dimensionality reduction,\nclassification, synergic, correlation, spectral interaction information, mutual\ninform",
    "descriptor": "",
    "authors": [
      "Asma Elmaizi",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch",
      "Nacir Chafik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15546"
  },
  {
    "id": "arXiv:2210.15551",
    "title": "Terminology-aware Medical Dialogue Generation",
    "abstract": "Medical dialogue generation aims to generate responses according to a history\nof dialogue turns between doctors and patients. Unlike open-domain dialogue\ngeneration, this requires background knowledge specific to the medical domain.\nExisting generative frameworks for medical dialogue generation fall short of\nincorporating domain-specific knowledge, especially with regard to medical\nterminology. In this paper, we propose a novel framework to improve medical\ndialogue generation by considering features centered on domain-specific\nterminology. We leverage an attention mechanism to incorporate terminologically\ncentred features, and fill in the semantic gap between medical background\nknowledge and common utterances by enforcing language models to learn\nterminology representations with an auxiliary terminology recognition task.\nExperimental results demonstrate the effectiveness of our approach, in which\nour proposed framework outperforms SOTA language models. Additionally, we\nprovide a new dataset with medical terminology annotations to support the\nresearch on medical dialogue generation. Our dataset and code are available at\nhttps://github.com/tangg555/meddialog.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chen Tang",
      "Hongbo Zhang",
      "Tyler Loakman",
      "Chenghua Lin",
      "Frank Guerin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15551"
  },
  {
    "id": "arXiv:2210.15553",
    "title": "Improving abstractive summarization with energy-based re-ranking",
    "abstract": "Current abstractive summarization systems present important weaknesses which\nprevent their deployment in real-world applications, such as the omission of\nrelevant information and the generation of factual inconsistencies (also known\nas hallucinations). At the same time, automatic evaluation metrics such as CTC\nscores have been recently proposed that exhibit a higher correlation with human\njudgments than traditional lexical-overlap metrics such as ROUGE. In this work,\nwe intend to close the loop by leveraging the recent advances in summarization\nmetrics to create quality-aware abstractive summarizers. Namely, we propose an\nenergy-based model that learns to re-rank summaries according to one or a\ncombination of these metrics. We experiment using several metrics to train our\nenergy-based re-ranker and show that it consistently improves the scores\nachieved by the predicted summaries. Nonetheless, human evaluation results show\nthat the re-ranking approach should be used with care for highly abstractive\nsummaries, as the available metrics are not yet sufficiently reliable for this\npurpose.",
    "descriptor": "\nComments: 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM) at EMNLP 2022\n",
    "authors": [
      "Diogo Pernes",
      "Afonso Mendes",
      "Andr\u00e9 F.T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15553"
  },
  {
    "id": "arXiv:2210.15559",
    "title": "Robust Monocular Localization of Drones by Adapting Domain Maps to Depth  Prediction Inaccuracies",
    "abstract": "We present a novel monocular localization framework by jointly training deep\nlearning-based depth prediction and Bayesian filtering-based pose reasoning.\nThe proposed cross-modal framework significantly outperforms deep learning-only\npredictions with respect to model scalability and tolerance to environmental\nvariations. Specifically, we show little-to-no degradation of pose accuracy\neven with extremely poor depth estimates from a lightweight depth predictor.\nOur framework also maintains high pose accuracy in extreme lighting variations\ncompared to standard deep learning, even without explicit domain adaptation. By\nopenly representing the map and intermediate feature maps (such as depth\nestimates), our framework also allows for faster updates and reusing\nintermediate predictions for other tasks, such as obstacle avoidance, resulting\nin much higher resource efficiency.",
    "descriptor": "",
    "authors": [
      "Priyesh Shukla",
      "Sureshkumar S.",
      "Alex C. Stutts",
      "Sathya Ravi",
      "Theja Tulabandhula",
      "Amit R. Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.15559"
  },
  {
    "id": "arXiv:2210.15560",
    "title": "The linear sampling method for random sources",
    "abstract": "We present an extension of the linear sampling method for solving the\nsound-soft inverse acoustic scattering problem with randomly distributed point\nsources. The theoretical justification of our sampling method is based on the\nHelmholtz--Kirchhoff identity, the cross-correlation between measurements, and\nthe volume and imaginary near-field operators, which we introduce and analyze.\nImplementations in MATLAB using boundary elements, the SVD, Tikhonov\nregularization, and Morozov's discrepancy principle are also discussed. We\ndemonstrate the robustness and accuracy of our algorithms with several\nnumerical experiments in two dimensions.",
    "descriptor": "",
    "authors": [
      "Josselin Garnier",
      "Houssem Haddar",
      "Hadrien Montanelli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15560"
  },
  {
    "id": "arXiv:2210.15561",
    "title": "Error estimates of a finite volume method for the compressible  Navier--Stokes--Fourier system",
    "abstract": "In this paper we study the convergence rate of a finite volume approximation\nof the compressible Navier--Stokes--Fourier system. To this end we first show\nthe local existence of a highly regular unique strong solution and analyse its\nglobal extension in time as far as the density and temperature remain bounded.\nWe make a physically reasonable assumption that the numerical density and\ntemperature are uniformly bounded from above and below. The relative energy\nprovides us an elegant way to derive a priori error estimates between finite\nvolume solutions and the strong solution.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Danica Basaric",
      "Maria Lukacova-Medvidova",
      "Hana Mizerova",
      "Bangwei She",
      "Yuhuan Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15561"
  },
  {
    "id": "arXiv:2210.15563",
    "title": "Multimodal Transformer Distillation for Audio-Visual Synchronization",
    "abstract": "Audio-visual synchronization aims to determine whether the mouth movements\nand speech in the video are synchronized. VocaLiST reaches state-of-the-art\nperformance by incorporating multimodal Transformers to model audio-visual\ninteract information. However, it requires high computing resources, making it\nimpractical for real-world applications. This paper proposed an MTDVocaLiST\nmodel, which is trained by our proposed multimodal Transformer distillation\n(MTD) loss. MTD loss enables MTDVocaLiST model to deeply mimic the\ncross-attention distribution and value-relation in the Transformer of VocaLiST.\nOur proposed method is effective in two aspects: From the distillation method\nperspective, MTD loss outperforms other strong distillation baselines. From the\ndistilled model's performance perspective: 1) MTDVocaLiST outperforms\nsimilar-size SOTA models, SyncNet, and PM models by 15.69% and 3.39%; 2)\nMTDVocaLiST reduces the model size of VocaLiST by 83.52%, yet still maintaining\nsimilar performance.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xuanjun Chen",
      "Haibin Wu",
      "Chung-Che Wang",
      "Hung-yi Lee",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15563"
  },
  {
    "id": "arXiv:2210.15565",
    "title": "Bridging the visual gap in VLN via semantically richer instructions",
    "abstract": "The Visual-and-Language Navigation (VLN) task requires understanding a\ntextual instruction to navigate a natural indoor environment using only visual\ninformation. While this is a trivial task for most humans, it is still an open\nproblem for AI models. In this work, we hypothesize that poor use of the visual\ninformation available is at the core of the low performance of current models.\nTo support this hypothesis, we provide experimental evidence showing that\nstate-of-the-art models are not severely affected when they receive just\nlimited or even no visual data, indicating a strong overfitting to the textual\ninstructions. To encourage a more suitable use of the visual information, we\npropose a new data augmentation method that fosters the inclusion of more\nexplicit visual information in the generation of textual navigational\ninstructions. Our main intuition is that current VLN datasets include textual\ninstructions that are intended to inform an expert navigator, such as a human,\nbut not a beginner visual navigational agent, such as a randomly initialized DL\nmodel. Specifically, to bridge the visual semantic gap of current VLN datasets,\nwe take advantage of metadata available for the Matterport3D dataset that,\namong others, includes information about object labels that are present in the\nscenes. Training a state-of-the-art model with the new set of instructions\nincrease its performance by 8% in terms of success rate on unseen environments,\ndemonstrating the advantages of the proposed data augmentation method.",
    "descriptor": "\nComments: Accepted in ECCV 2022. Research completed on November 21, 2021\n",
    "authors": [
      "Joaquin Ossand\u00f3n",
      "Benjamin Earle",
      "\u00c1lvaro Soto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15565"
  },
  {
    "id": "arXiv:2210.15567",
    "title": "Training Graph Neural Networks on Growing Stochastic Graphs",
    "abstract": "Graph Neural Networks (GNNs) rely on graph convolutions to exploit meaningful\npatterns in networked data. Based on matrix multiplications, convolutions incur\nin high computational costs leading to scalability limitations in practice. To\novercome these limitations, proposed methods rely on training GNNs in smaller\nnumber of nodes, and then transferring the GNN to larger graphs. Even though\nthese methods are able to bound the difference between the output of the GNN\nwith different number of nodes, they do not provide guarantees against the\noptimal GNN on the very large graph. In this paper, we propose to learn GNNs on\nvery large graphs by leveraging the limit object of a sequence of growing\ngraphs, the graphon. We propose to grow the size of the graph as we train, and\nwe show that our proposed methodology -- learning by transference -- converges\nto a neighborhood of a first order stationary point on the graphon data. A\nnumerical experiment validates our proposed approach.",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15567"
  },
  {
    "id": "arXiv:2210.15570",
    "title": "Efficient few-shot learning for pixel-precise handwritten document  layout analysis",
    "abstract": "Layout analysis is a task of uttermost importance in ancient handwritten\ndocument analysis and represents a fundamental step toward the simplification\nof subsequent tasks such as optical character recognition and automatic\ntranscription. However, many of the approaches adopted to solve this problem\nrely on a fully supervised learning paradigm. While these systems achieve very\ngood performance on this task, the drawback is that pixel-precise text labeling\nof the entire training set is a very time-consuming process, which makes this\ntype of information rarely available in a real-world scenario. In the present\npaper, we address this problem by proposing an efficient few-shot learning\nframework that achieves performances comparable to current state-of-the-art\nfully supervised methods on the publicly available DIVA-HisDB dataset.",
    "descriptor": "\nComments: Accepted for publication at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023\n",
    "authors": [
      "Axel De Nardin",
      "Silvia Zottin",
      "Matteo Paier",
      "Gian Luca Foresti",
      "Emanuela Colombi",
      "Claudio Piciarelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15570"
  },
  {
    "id": "arXiv:2210.15572",
    "title": "Quasi-Monte Carlo finite element approximation of the Navier-Stokes  equations with initial data modeled by log-normal random fields",
    "abstract": "In this paper, we analyze the numerical approximation of the Navier-Stokes\nproblem over a bounded polygonal domain in $\\mathbb{R}^2$, where the initial\ncondition is modeled by a log-normal random field. This problem usually arises\nin the area of uncertainty quantification. We aim to compute the expectation\nvalue of linear functionals of the solution to the Navier-Stokes equations and\nperform a rigorous error analysis for the problem. In particular, our method\nincludes the finite element, fully-discrete discretizations, truncated\nKarhunen-Lo\\'eve expansion for the realizations of the initial condition, and\nlattice-based quasi-Monte Carlo (QMC) method to estimate the expected values\nover the parameter space. Our QMC analysis is based on randomly-shifted lattice\nrules for the integration over the domain in high-dimensional space, which\nguarantees the error decays with $\\mathcal{O}(N^{-1+\\delta})$, where $N$ is the\nnumber of sampling points, $\\delta>0$ is an arbitrary small number, and the\nconstant in the decay estimate is independent of the dimension of integration.",
    "descriptor": "",
    "authors": [
      "Seungchan Ko",
      "Guanglian Li",
      "Yi Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15572"
  },
  {
    "id": "arXiv:2210.15573",
    "title": "Multi-task Bias-Variance Trade-off Through Functional Constraints",
    "abstract": "Multi-task learning aims to acquire a set of functions, either regressors or\nclassifiers, that perform well for diverse tasks. At its core, the idea behind\nmulti-task learning is to exploit the intrinsic similarity across data sources\nto aid in the learning process for each individual domain. In this paper we\ndraw intuition from the two extreme learning scenarios -- a single function for\nall tasks, and a task-specific function that ignores the other tasks\ndependencies -- to propose a bias-variance trade-off. To control the\nrelationship between the variance (given by the number of i.i.d. samples), and\nthe bias (coming from data from other task), we introduce a constrained\nlearning formulation that enforces domain specific solutions to be close to a\ncentral function. This problem is solved in the dual domain, for which we\npropose a stochastic primal-dual algorithm. Experimental results for a\nmulti-domain classification problem with real data show that the proposed\nprocedure outperforms both the task specific, as well as the single\nclassifiers.",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Juan Andres Bazerque",
      "Miguel Calvo-Fullana",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15573"
  },
  {
    "id": "arXiv:2210.15575",
    "title": "A Graph Is More Than Its Nodes: Towards Structured Uncertainty-Aware  Learning on Graphs",
    "abstract": "Current graph neural networks (GNNs) that tackle node classification on\ngraphs tend to only focus on nodewise scores and are solely evaluated by\nnodewise metrics. This limits uncertainty estimation on graphs since nodewise\nmarginals do not fully characterize the joint distribution given the graph\nstructure. In this work, we propose novel edgewise metrics, namely the edgewise\nexpected calibration error (ECE) and the agree/disagree ECEs, which provide\ncriteria for uncertainty estimation on graphs beyond the nodewise setting. Our\nexperiments demonstrate that the proposed edgewise metrics can complement the\nnodewise results and yield additional insights. Moreover, we show that GNN\nmodels which consider the structured prediction problem on graphs tend to have\nbetter uncertainty estimations, which illustrates the benefit of going beyond\nthe nodewise setting.",
    "descriptor": "\nComments: Presented at NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)\n",
    "authors": [
      "Hans Hao-Hsun Hsu",
      "Yuesong Shen",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15575"
  },
  {
    "id": "arXiv:2210.15578",
    "title": "GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs",
    "abstract": "Embedding knowledge graphs (KGs) for multi-hop logical reasoning is a\nchallenging problem due to massive and complicated structures in many KGs.\nRecently, many promising works projected entities and queries into a geometric\nspace to efficiently find answers. However, it remains challenging to model the\nnegation and union operator. The negation operator has no strict boundaries,\nwhich generates overlapped embeddings and leads to obtaining ambiguous answers.\nAn additional limitation is that the union operator is non-closure, which\nundermines the model to handle a series of union operators. To address these\nproblems, we propose a novel probabilistic embedding model, namely Gamma\nEmbeddings (GammaE), for encoding entities and queries to answer different\ntypes of FOL queries on KGs. We utilize the linear property and strong boundary\nsupport of the Gamma distribution to capture more features of entities and\nqueries, which dramatically reduces model uncertainty. Furthermore, GammaE\nimplements the Gamma mixture method to design the closed union operator. The\nperformance of GammaE is validated on three large logical query datasets.\nExperimental results show that GammaE significantly outperforms\nstate-of-the-art models on public benchmarks.",
    "descriptor": "",
    "authors": [
      "Dong Yang",
      "Peijun Qing",
      "Yang Li",
      "Haonan Lu",
      "Xiaodong Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.15578"
  },
  {
    "id": "arXiv:2210.15581",
    "title": "An arbitrary-order discrete rot-rot complex on polygonal meshes with  application to a quad-rot problem",
    "abstract": "In this work, following the discrete de Rham (DDR) approach, we develop a\ndiscrete counterpart of a two-dimensional de Rham complex with enhanced\nregularity. The proposed construction supports general polygonal meshes and\narbitrary approximation orders. We establish exactness on a contractible domain\nfor both the versions of the complex with and without boundary conditions and,\nfor the former, prove a complete set of Poincar\\'e-type inequalities. The\ndiscrete complex is then used to derive a novel discretisation method for a\nquad-rot problem which, unlike other schemes in the literature, does not\nrequire the forcing term to be prepared. We carry out complete stability and\nconvergence analyses for the proposed scheme and provide numerical validation\nof the results.",
    "descriptor": "",
    "authors": [
      "Daniele A. Di Pietro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15581"
  },
  {
    "id": "arXiv:2210.15586",
    "title": "Joint Multi-Person Body Detection and Orientation Estimation via One  Unified Embedding",
    "abstract": "Human body orientation estimation (HBOE) is widely applied into various\napplications, including robotics, surveillance, pedestrian analysis and\nautonomous driving. Although many approaches have been addressing the HBOE\nproblem from specific under-controlled scenes to challenging in-the-wild\nenvironments, they assume human instances are already detected and take a well\ncropped sub-image as the input. This setting is less efficient and prone to\nerrors in real application, such as crowds of people. In the paper, we propose\na single-stage end-to-end trainable framework for tackling the HBOE problem\nwith multi-persons. By integrating the prediction of bounding boxes and\ndirection angles in one embedding, our method can jointly estimate the location\nand orientation of all bodies in one image directly. Our key idea is to\nintegrate the HBOE task into the multi-scale anchor channel predictions of\npersons for concurrently benefiting from engaged intermediate features.\nTherefore, our approach can naturally adapt to difficult instances involving\nlow resolution and occlusion as in object detection. We validated the\nefficiency and effectiveness of our method in the recently presented benchmark\nMEBOW with extensive experiments. Besides, we completed ambiguous instances\nignored by the MEBOW dataset, and provided corresponding weak body-orientation\nlabels to keep the integrity and consistency of it for supporting studies\ntoward multi-persons. Our work is available at\n\\url{https://github.com/hnuzhy/JointBDOE}.",
    "descriptor": "",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Jiaxin Si",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15586"
  },
  {
    "id": "arXiv:2210.15593",
    "title": "An Investigation into Neuromorphic ICs using Memristor-CMOS Hybrid  Circuits",
    "abstract": "The memristance of a memristor depends on the amount of charge flowing\nthrough it and when current stops flowing through it, it remembers the state.\nThus, memristors are extremely suited for implementation of memory units.\nMemristors find great application in neuromorphic circuits as it is possible to\ncouple memory and processing, compared to traditional Von-Neumann digital\narchitectures where memory and processing are separate. Neural networks have a\nlayered structure where information passes from one layer to another and each\nof these layers have the possibility of a high degree of parallelism.\nCMOS-Memristor based neural network accelerators provide a method of speeding\nup neural networks by making use of this parallelism and analog computation. In\nthis project we have conducted an initial investigation into the current state\nof the art implementation of memristor based programming circuits. Various\nmemristor programming circuits and basic neuromorphic circuits have been\nsimulated. The next phase of our project revolved around designing basic\nbuilding blocks which can be used to design neural networks. A memristor bridge\nbased synaptic weighting block, a operational transconductor based summing\nblock were initially designed. We then designed activation function blocks\nwhich are used to introduce controlled non-linearity. Blocks for a basic\nrectified linear unit and a novel implementation for tan-hyperbolic function\nhave been proposed. An artificial neural network has been designed using these\nblocks to validate and test their performance. We have also used these\nfundamental blocks to design basic layers of Convolutional Neural Networks.\nConvolutional Neural Networks are heavily used in image processing\napplications. The core convolutional block has been designed and it has been\nused as an image processing kernel to test its performance.",
    "descriptor": "\nComments: Bachelor's thesis\n",
    "authors": [
      "Udit Kumar Agarwal",
      "Shikhar Makhija",
      "Varun Tripathi",
      "Kunwar Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15593"
  },
  {
    "id": "arXiv:2210.15598",
    "title": "Provable Sim-to-real Transfer in Continuous Domain with Partial  Observations",
    "abstract": "Sim-to-real transfer trains RL agents in the simulated environments and then\ndeploys them in the real world. Sim-to-real transfer has been widely used in\npractice because it is often cheaper, safer and much faster to collect samples\nin simulation than in the real world. Despite the empirical success of the\nsim-to-real transfer, its theoretical foundation is much less understood. In\nthis paper, we study the sim-to-real transfer in continuous domain with partial\nobservations, where the simulated environments and real-world environments are\nmodeled by linear quadratic Gaussian (LQG) systems. We show that a popular\nrobust adversarial training algorithm is capable of learning a policy from the\nsimulated environment that is competitive to the optimal policy in the\nreal-world environment. To achieve our results, we design a new algorithm for\ninfinite-horizon average-cost LQGs and establish a regret bound that depends on\nthe intrinsic complexity of the model class. Our algorithm crucially relies on\na novel history clipping scheme, which might be of independent interest.",
    "descriptor": "",
    "authors": [
      "Jiachen Hu",
      "Han Zhong",
      "Chi Jin",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15598"
  },
  {
    "id": "arXiv:2210.15600",
    "title": "Automatic Extraction of Materials and Properties from Superconductors  Scientific Literature",
    "abstract": "The automatic extraction of materials and related properties from the\nscientific literature is gaining attention in data-driven materials science\n(Materials Informatics). In this paper, we discuss Grobid-superconductors, our\nsolution for automatically extracting superconductor material names and\nrespective properties from text. Built as a Grobid module, it combines machine\nlearning and heuristic approaches in a multi-step architecture that supports\ninput data as raw text or PDF documents. Using Grobid-superconductors, we built\nSuperCon2, a database of 40324 materials and properties records from 37700\npapers. The material (or sample) information is represented by name, chemical\nformula, and material class, and is characterized by shape, doping,\nsubstitution variables for components, and substrate as adjoined information.\nThe properties include the Tc superconducting critical temperature and, when\navailable, applied pressure with the Tc measurement method.",
    "descriptor": "\nComments: 20 pages, 11 figures, 8 tables\n",
    "authors": [
      "Luca Foppiano",
      "Pedro Baptista de Castro",
      "Pedro Ortiz Suarez",
      "Kensei Terashima",
      "Yoshihiko Takano",
      "Masashi Ishii"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Superconductivity (cond-mat.supr-con)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15600"
  },
  {
    "id": "arXiv:2210.15603",
    "title": "Working Alliance Transformer for Psychotherapy Dialogue Classification",
    "abstract": "As a predictive measure of the treatment outcome in psychotherapy, the\nworking alliance measures the agreement of the patient and the therapist in\nterms of their bond, task and goal. Long been a clinical quantity estimated by\nthe patients' and therapists' self-evaluative reports, we believe that the\nworking alliance can be better characterized using natural language processing\ntechnique directly in the dialogue transcribed in each therapy session. In this\nwork, we propose the Working Alliance Transformer (WAT), a Transformer-based\nclassification model that has a psychological state encoder which infers the\nworking alliance scores by projecting the embedding of the dialogues turns onto\nthe embedding space of the clinical inventory for working alliance. We evaluate\nour method in a real-world dataset with over 950 therapy sessions with anxiety,\ndepression, schizophrenia and suicidal patients and demonstrate an empirical\nadvantage of using information about the therapeutic states in this sequence\nclassification task of psychotherapy dialogues.",
    "descriptor": "",
    "authors": [
      "Baihan Lin",
      "Guillermo Cecchi",
      "Djallel Bouneffouf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.15603"
  },
  {
    "id": "arXiv:2210.15604",
    "title": "Risk-Averse Model Predictive Control for Priced Timed Automata",
    "abstract": "In this paper, we propose a Risk-Averse Priced Timed Automata (PTA) Model\nPredictive Control (MPC) framework to increase flexibility of cyber-physical\nsystems. To improve flexibility in these systems, our risk-averse framework\nsolves a multi-objective optimization problem to minimize the cost and risk,\nsimultaneously. While minimizing cost ensures the least effort to achieve a\ntask, minimizing risk provides guarantees on the feasibility of the task even\nduring uncertainty. Our framework explores the trade-off between these two\nqualities to obtain risk-averse control actions. The solution of risk-averse\nPTA MPC dynamic decision-making algorithm reacts relatively better to PTA\nchanges compared to PTA MPC without risk-averse feature. An example from\nmanufacturing systems is presented to show the application of the proposed\ncontrol strategy.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Mostafa Tavakkoli Anbarani",
      "Efe C. Balta",
      "R\u00f4mulo Meira-G\u00f3es",
      "Ilya Kovalenko"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15604"
  },
  {
    "id": "arXiv:2210.15611",
    "title": "A positivity-preserving and conservative high-order flux reconstruction  method for the polyatomic Boltzmann--BGK equation",
    "abstract": "In this work, we present a positivity-preserving high-order flux\nreconstruction method for the polyatomic Boltzmann--BGK equation augmented with\na discrete velocity model that ensures the scheme is discretely conservative.\nThrough modeling the internal degrees of freedom, the approach is further\nextended to polyatomic molecules and can encompass arbitrary constitutive laws.\nThe approach is validated on a series of large-scale complex numerical\nexperiments, ranging from shock-dominated flows computed on unstructured grids\nto direct numerical simulation of three-dimensional compressible turbulent\nflows, the latter of which is the first instance of such a flow computed by\ndirectly solving the Boltzmann equation. The results show the ability of the\nscheme to directly resolve shock structures without any ad hoc numerical shock\ncapturing method and correctly approximate turbulent flow phenomena in a\nconsistent manner with the hydrodynamic equations.",
    "descriptor": "\nComments: 31 pages, 20 figures\n",
    "authors": [
      "Tarik Dzanic",
      "Freddie D. Witherden",
      "Luigi Martinelli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.15611"
  },
  {
    "id": "arXiv:2210.15614",
    "title": "Private and Reliable Neural Network Inference",
    "abstract": "Reliable neural networks (NNs) provide important inference-time reliability\nguarantees such as fairness and robustness. Complementarily, privacy-preserving\nNN inference protects the privacy of client data. So far these two emerging\nareas have been largely disconnected, yet their combination will be\nincreasingly important. In this work, we present the first system which enables\nprivacy-preserving inference on reliable NNs. Our key idea is to design\nefficient fully homomorphic encryption (FHE) counterparts for the core\nalgorithmic building blocks of randomized smoothing, a state-of-the-art\ntechnique for obtaining reliable models. The lack of required control flow in\nFHE makes this a demanding task, as na\\\"ive solutions lead to unacceptable\nruntime. We employ these building blocks to enable privacy-preserving NN\ninference with robustness and fairness guarantees in a system called Phoenix.\nExperimentally, we demonstrate that Phoenix achieves its goals without\nincurring prohibitive latencies. To our knowledge, this is the first work which\nbridges the areas of client data privacy and reliability guarantees for NNs.",
    "descriptor": "\nComments: In ACM Conference on Computer and Communications Security (CCS 2022)\n",
    "authors": [
      "Nikola Jovanovi\u0107",
      "Marc Fischer",
      "Samuel Steffen",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15614"
  },
  {
    "id": "arXiv:2210.15615",
    "title": "ACES: Translation Accuracy Challenge Sets for Evaluating Machine  Translation Metrics",
    "abstract": "As machine translation (MT) metrics improve their correlation with human\njudgement every year, it is crucial to understand the limitations of such\nmetrics at the segment level. Specifically, it is important to investigate\nmetric behaviour when facing accuracy errors in MT because these can have\ndangerous consequences in certain contexts (e.g., legal, medical). We curate\nACES, a translation accuracy challenge set, consisting of 68 phenomena ranging\nfrom simple perturbations at the word/character level to more complex errors\nbased on discourse and real-world knowledge. We use ACES to evaluate a wide\nrange of MT metrics including the submissions to the WMT 2022 metrics shared\ntask and perform several analyses leading to general recommendations for metric\ndevelopers. We recommend: a) combining metrics with different strengths, b)\ndeveloping metrics that give more weight to the source and less to\nsurface-level overlap with the reference and c) explicitly modelling additional\nlanguage-specific information beyond what is available via multilingual\nembeddings.",
    "descriptor": "\nComments: preprint for WMT 2022\n",
    "authors": [
      "Chantal Amrhein",
      "Nikita Moghe",
      "Liane Guillou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15615"
  },
  {
    "id": "arXiv:2210.15616",
    "title": "Cross-Domain Neural Entity Linking",
    "abstract": "Entity Linking is the task of matching a mention to an entity in a given\nknowledge base (KB). It contributes to annotating a massive amount of documents\nexisting on the Web to harness new facts about their matched entities. However,\nexisting Entity Linking systems focus on developing models that are typically\ndomain-dependent and robust only to a particular knowledge base on which they\nhave been trained. The performance is not as adequate when being evaluated on\ndocuments and knowledge bases from different domains.\nApproaches based on pre-trained language models, such as Wu et al. (2020),\nattempt to solve the problem using a zero-shot setup, illustrating some\npotential when evaluated on a general-domain KB. Nevertheless, the performance\nis not equivalent when evaluated on a domain-specific KB. To allow for more\naccurate Entity Linking across different domains, we propose our framework:\nCross-Domain Neural Entity Linking (CDNEL). Our objective is to have a single\nsystem that enables simultaneous linking to both the general-domain KB and the\ndomain-specific KB. CDNEL works by learning a joint representation space for\nthese knowledge bases from different domains. It is evaluated using the\nexternal Entity Linking dataset (Zeshel) constructed by Logeswaran et al.\n(2019) and the Reddit dataset collected by Botzer et al. (2021), to compare our\nproposed method with the state-of-the-art results. The proposed framework uses\ndifferent types of datasets for fine-tuning, resulting in different model\nvariants of CDNEL. When evaluated on four domains included in the Zeshel\ndataset, these variants achieve an average precision gain of 9%.",
    "descriptor": "\nComments: Master's thesis, 76 pages, 26 figures\n",
    "authors": [
      "Hassan Soliman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15616"
  },
  {
    "id": "arXiv:2210.15621",
    "title": "Class Based Thresholding in Early Exit Semantic Segmentation Networks",
    "abstract": "We propose Class Based Thresholding (CBT) to reduce the computational cost of\nearly exit semantic segmentation models while preserving the mean intersection\nover union (mIoU) performance. A key idea of CBT is to exploit the\nnaturally-occurring neural collapse phenomenon. Specifically, by calculating\nthe mean prediction probabilities of each class in the training set, CBT\nassigns different masking threshold values to each class, so that the\ncomputation can be terminated sooner for pixels belonging to easy-to-predict\nclasses. We show the effectiveness of CBT on Cityscapes and ADE20K datasets.\nCBT can reduce the computational cost by $23\\%$ compared to the previous\nstate-of-the-art early exit models.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Alperen G\u00f6rmez",
      "Erdem Koyuncu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15621"
  },
  {
    "id": "arXiv:2210.15623",
    "title": "Neural Networks with Quantization Constraints",
    "abstract": "Enabling low precision implementations of deep learning models, without\nconsiderable performance degradation, is necessary in resource and latency\nconstrained settings. Moreover, exploiting the differences in sensitivity to\nquantization across layers can allow mixed precision implementations to achieve\na considerably better computation performance trade-off. However,\nbackpropagating through the quantization operation requires introducing\ngradient approximations, and choosing which layers to quantize is challenging\nfor modern architectures due to the large search space. In this work, we\npresent a constrained learning approach to quantization aware training. We\nformulate low precision supervised learning as a constrained optimization\nproblem, and show that despite its non-convexity, the resulting problem is\nstrongly dual and does away with gradient estimations. Furthermore, we show\nthat dual variables indicate the sensitivity of the objective with respect to\nconstraint perturbations. We demonstrate that the proposed approach exhibits\ncompetitive performance in image classification tasks, and leverage the\nsensitivity result to apply layer selective quantization based on the value of\ndual variables, leading to considerable performance improvements.",
    "descriptor": "",
    "authors": [
      "Ignacio Hounie",
      "Juan Elenter",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15623"
  },
  {
    "id": "arXiv:2210.15628",
    "title": "Software-hardware Integration and Human-centered Benchmarking for  Socially-compliant Robot Navigation",
    "abstract": "The social compatibility (SC) is one of the most important parameters for\nservice robots. It characterises the interaction quality between a robot and a\nhuman. In this paper, we first introduce an open-source software-hardware\nintegration scheme for socially-compliant robot navigation and then propose a\nhuman-centered benchmarking framework. For the former, we integrate one 3D\nlidar, one 2D lidar, and four RGB-D cameras for robot exterior perception. The\nsoftware system is entirely based on the Robot Operating System (ROS) with high\nmodularity and fully deployed to the embedded hardware-based edge while running\nat a rate that exceeds the release frequency of sensor data. For the latter, we\npropose a new human-centered performance evaluation metric that can be used to\nmeasure SC quickly and efficiently. The values of this metric correlate with\nthe results of the Godspeed questionnaire, which is believed to be a golden\nstandard approach for SC measurements. Together with other commonly used\nmetrics, we benchmark two open-source socially-compliant robot navigation\nmethods, in an end-to-end manner. We clarify all aspects of the benchmarking to\nensure the reproducibility of the experiments. We also show that the proposed\nnew metric can provide further justification for the selection of numerical\nmetrics (objective) from a human perspective (subjective).",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Iaroslav Okunevich",
      "Vincent Hilaire",
      "Stephane Galland",
      "Olivier Lamotte",
      "Liubov Shilova",
      "Yassine Ruichek",
      "Zhi Yan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15628"
  },
  {
    "id": "arXiv:2210.15629",
    "title": "LAD: Language Augmented Diffusion for Reinforcement Learning",
    "abstract": "Learning skills from language provides a powerful avenue for generalization\nin reinforcement learning, although it remains a challenging task as it\nrequires agents to capture the complex interdependencies between language,\nactions, and states. In this paper, we propose leveraging Language Augmented\nDiffusion models as a planner conditioned on language (LAD). We demonstrate the\ncomparable performance of LAD with the state-of-the-art on the CALVIN language\nrobotics benchmark with a much simpler architecture that contains no inductive\nbiases specialized to robotics, achieving an average success rate (SR) of 72%\ncompared to the best performance of 76%. We also conduct an analysis on the\nproperties of language conditioned diffusion in reinforcement learning.",
    "descriptor": "\nComments: Language and Reinforcement Learning Workshop, NeurIPS 2022\n",
    "authors": [
      "Edwin Zhang",
      "Yujie Lu",
      "William Wang",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15629"
  },
  {
    "id": "arXiv:2210.15630",
    "title": "In-stream Probabilistic Cardinality Estimation for Bloom Filters",
    "abstract": "The amount of data coming from different sources such as IoT-sensors, social\nnetworks, cellular networks, has increased exponentially during the last few\nyears. Probabilistic Data Structures (PDS) are efficient alternatives to\ndeterministic data structures suitable for large data processing and streaming\napplications. They are mainly used for approximate membership queries,\nfrequency count, cardinality estimation and similarity research. Finding the\nnumber of distinct elements in a large dataset or in streaming data is an\nactive research area. In this work, we show that usual methods based on Bloom\nfilters for this kind of cardinality estimation are relatively accurate on\naverage but have a high variance. Therefore, reducing this variance is\ninteresting to obtain accurate statistics. We propose a probabilistic approach\nto estimate more accurately the cardinality of a Bloom filter based on its\nparameters, i.e., number of hash functions $k$, size $m$, and a counter $s$\nwhich is incremented whenever an element is not in the filter (i.e., when the\nresult of the membership query for this element is negative). The value of the\ncounter can never be larger than the exact cardinality due to the Bloom\nfilter's nature, but hash collisions can cause it to underestimate it. This\ncreates a counting error that we estimate accurately, in-stream, along with its\nstandard deviation. We also discuss a way to optimize the parameters of a Bloom\nfilter based on its counting error. We evaluate our approach with synthetic\ndata created from an analysis of a real mobility dataset provided by a mobile\nnetwork operator in the form of displacement matrices computed from mobile\nphone records. The approach proposed here performs at least as well on average\nand has a much lower variance (about 6 to 7 times less) than state of the art\nmethods.",
    "descriptor": "\nComments: 12 pages, 10 figures, 3 tables\n",
    "authors": [
      "Remy Scholler",
      "Jean-Francois Couchot",
      "Oumaima Alaoui-Ismaili",
      "Denis Renaud",
      "Eric Ballot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15630"
  },
  {
    "id": "arXiv:2210.15632",
    "title": "Aerial Manipulation Using a Novel Unmanned Aerial Vehicle Cyber-Physical  System",
    "abstract": "Unmanned Aerial Vehicles(UAVs) are attaining more and more maneuverability\nand sensory ability as a promising teleoperation platform for intelligent\ninteraction with the environments. This work presents a novel\n5-degree-of-freedom (DoF) unmanned aerial vehicle (UAV) cyber-physical system\nfor aerial manipulation. This UAV's body is capable of exerting powerful\npropulsion force in the longitudinal direction, decoupling the translational\ndynamics and the rotational dynamics on the longitudinal plane. A high-level\nimpedance control law is proposed to drive the vehicle for trajectory tracking\nand interaction with the environments. In addition, a vision-based real-time\ntarget identification and tracking method integrating a YOLO v3 real-time\nobject detector with feature tracking, and morphological operations is proposed\nto be implemented onboard the vehicle with support of model compression\ntechniques to eliminate latency caused by video wireless transmission and heavy\ncomputation burden on traditional teleoperation platforms.",
    "descriptor": "\nComments: Newsletter of IEEE Technical Committee on Cyber-Physical Systems\n",
    "authors": [
      "Caiwu Ding",
      "Hongwu Peng",
      "Lu Lu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15632"
  },
  {
    "id": "arXiv:2210.15637",
    "title": "Towards Correlated Sequential Rules",
    "abstract": "The goal of high-utility sequential pattern mining (HUSPM) is to efficiently\ndiscover profitable or useful sequential patterns in a large number of\nsequences. However, simply being aware of utility-eligible patterns is\ninsufficient for making predictions. To compensate for this deficiency,\nhigh-utility sequential rule mining (HUSRM) is designed to explore the\nconfidence or probability of predicting the occurrence of consequence\nsequential patterns based on the appearance of premise sequential patterns. It\nhas numerous applications, such as product recommendation and weather\nprediction. However, the existing algorithm, known as HUSRM, is limited to\nextracting all eligible rules while neglecting the correlation between the\ngenerated sequential rules. To address this issue, we propose a novel algorithm\ncalled correlated high-utility sequential rule miner (CoUSR) to integrate the\nconcept of correlation into HUSRM. The proposed algorithm requires not only\nthat each rule be correlated but also that the patterns in the antecedent and\nconsequent of the high-utility sequential rule be correlated. The algorithm\nadopts a utility-list structure to avoid multiple database scans. Additionally,\nseveral pruning strategies are used to improve the algorithm's efficiency and\nperformance. Based on several real-world datasets, subsequent experiments\ndemonstrated that CoUSR is effective and efficient in terms of operation time\nand memory consumption.",
    "descriptor": "\nComments: Preprint. 7 figures, 6 tables\n",
    "authors": [
      "Lili Chen",
      "Wensheng Gan",
      "Chien-Ming Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15637"
  },
  {
    "id": "arXiv:2210.15638",
    "title": "LyricJam Sonic: A Generative System for Real-Time Composition and  Musical Improvisation",
    "abstract": "Electronic music artists and sound designers have unique workflow practices\nthat necessitate specialized approaches for developing music information\nretrieval and creativity support tools. Furthermore, electronic music\ninstruments, such as modular synthesizers, have near-infinite possibilities for\nsound creation and can be combined to create unique and complex audio paths.\nThe process of discovering interesting sounds is often serendipitous and\nimpossible to replicate. For this reason, many musicians in electronic genres\nrecord audio output at all times while they work in the studio. Subsequently,\nit is difficult for artists to rediscover audio segments that might be suitable\nfor use in their compositions from thousands of hours of recordings. In this\npaper, we describe LyricJam Sonic -- a novel creative tool for musicians to\nrediscover their previous recordings, re-contextualize them with other\nrecordings, and create original live music compositions in real-time. A\nbi-modal AI-driven approach uses generated lyric lines to find matching audio\nclips from the artist's past studio recordings, and uses them to generate new\nlyric lines, which in turn are used to find other clips, thus creating a\ncontinuous and evolving stream of music and lyrics. The intent is to keep the\nartists in a state of creative flow conducive to music creation rather than\ntaking them into an analytical/critical state of deliberately searching for\npast audio segments. The system can run in either a fully autonomous mode\nwithout user input, or in a live performance mode, where the artist plays live\nmusic, while the system \"listens\" and creates a continuous stream of music and\nlyrics in response.",
    "descriptor": "\nComments: 15 pages, 9 figures, 2 tables\n",
    "authors": [
      "Olga Vechtomova",
      "Gaurav Sahu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15638"
  },
  {
    "id": "arXiv:2210.15642",
    "title": "Existential Definability over the Subword Ordering",
    "abstract": "We study first-order logic (FO) over the structure consisting of finite words\nover some alphabet $A$, together with the (non-contiguous) subword ordering. In\nterms of decidability of quantifier alternation fragments, this logic is\nwell-understood: If every word is available as a constant, then even the\n$\\Sigma_1$ (i.e., existential) fragment is undecidable, already for binary\nalphabets $A$. However, up to now, little is known about the expressiveness of\nthe quantifier alternation fragments: For example, the undecidability proof for\nthe existential fragment relies on Diophantine equations and only shows that\nrecursively enumerable languages over a singleton alphabet (and some auxiliary\npredicates) are definable. We show that if $|A|\\ge 3$, then a relation is\ndefinable in the existential fragment over $A$ with constants if and only if it\nis recursively enumerable. This implies characterizations for all fragments\n$\\Sigma_i$: If $|A|\\ge 3$, then a relation is definable in $\\Sigma_i$ if and\nonly if it belongs to the $i$-th level of the arithmetical hierarchy. In\naddition, our result yields an analogous complete description of the\n$\\Sigma_i$-fragments for $i\\ge 2$ of the pure logic, where the words of $A^*$\nare not available as constants.",
    "descriptor": "",
    "authors": [
      "Pascal Baumann",
      "Moses Ganardi",
      "Ramanathan S. Thinniyam",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.15642"
  },
  {
    "id": "arXiv:2210.15645",
    "title": "Dragoman: Efficiently Evaluating Declarative Mapping Languages over  Frameworks for Knowledge Graph Creation",
    "abstract": "In recent years, there have been valuable efforts and contributions to make\nthe process of RDF knowledge graph creation traceable and transparent;\nextending and applying declarative mapping languages is an example. One\nchallenging step is the traceability of procedures that aim to overcome\ninteroperability issues, a.k.a. data-level integration. In most pipelines, data\nintegration is performed by ad-hoc programs, preventing traceability and\nreusability. However, formal frameworks provided by function-based declarative\nmapping languages such as FunUL and RML+FnO empower expressiveness. Data-level\nintegration can be defined as functions and integrated as part of the mappings\nperforming schema-level integration. However, combining functions with the\nmappings introduces a new source of complexity that can considerably impact the\nrequired number of resources and execution time. We tackle the problem of\nefficiently executing mappings with functions and formalize the transformation\nof them into function-free mappings. These transformations are the basis of an\noptimization process that aims to perform an eager evaluation of function-based\nmapping rules. These techniques are implemented in a framework named Dragoman.\nWe demonstrate the correctness of the transformations while ensuring that the\nfunction-free data integration processes are equivalent to the original one.\nThe effectiveness of Dragoman is empirically evaluated in 230 testbeds composed\nof various types of functions integrated with mapping rules of different\ncomplexity. The outcomes suggest that evaluating function-free mapping rules\nreduces execution time in complex knowledge graph creation pipelines composed\nof large data sources and multiple types of mapping rules. The savings can be\nup to 75%, suggesting that eagerly executing functions in mapping rules enable\nmaking these pipelines applicable and scalable in real-world settings.",
    "descriptor": "",
    "authors": [
      "Samaneh Jozashoori",
      "Enrique Iglesias",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Other Computer Science (cs.OH)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.15645"
  },
  {
    "id": "arXiv:2210.15651",
    "title": "Learning Single-Index Models with Shallow Neural Networks",
    "abstract": "Single-index models are a class of functions given by an unknown univariate\n``link'' function applied to an unknown one-dimensional projection of the\ninput. These models are particularly relevant in high dimension, when the data\nmight present low-dimensional structure that learning algorithms should adapt\nto. While several statistical aspects of this model, such as the sample\ncomplexity of recovering the relevant (one-dimensional) subspace, are\nwell-understood, they rely on tailored algorithms that exploit the specific\nstructure of the target function. In this work, we introduce a natural class of\nshallow neural networks and study its ability to learn single-index models via\ngradient flow. More precisely, we consider shallow networks in which biases of\nthe neurons are frozen at random initialization. We show that the corresponding\noptimization landscape is benign, which in turn leads to generalization\nguarantees that match the near-optimal sample complexity of dedicated\nsemi-parametric methods.",
    "descriptor": "\nComments: 76 pages. To appear at NeurIPS 2022\n",
    "authors": [
      "Alberto Bietti",
      "Joan Bruna",
      "Clayton Sanford",
      "Min Jae Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15651"
  },
  {
    "id": "arXiv:2210.15654",
    "title": "Reductions in Higher-Order Rewriting and Their Equivalence",
    "abstract": "Proof terms are syntactic expressions that represent computations in term\nrewriting. They were introduced by Meseguer and exploited by van Oostrom and de\nVrijer to study {\\em equivalence of reductions} in (left-linear) first-order\nterm rewriting systems. We study the problem of extending the notion of proof\nterm to {\\em higher-order rewriting}, which generalizes the first-order setting\nby allowing terms with binders and higher-order substitution. In previous works\nthat devise proof terms for higher-order rewriting, such as Bruggink's, it has\nbeen noted that the challenge lies in reconciling composition of proof terms\nand higher-order substitution ($\\beta$-equivalence). This led Bruggink to\nreject ``nested'' composition, other than at the outermost level. In this\npaper, we propose a notion of higher-order proof term we dub \\emph{rewrites}\nthat supports nested composition. We then define {\\em two} notions of\nequivalence on rewrites, namely {\\em permutation equivalence} and {\\em\nprojection equivalence}, and show that they coincide.",
    "descriptor": "",
    "authors": [
      "Pablo Barenbaum",
      "Eduardo Bonelli"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.15654"
  },
  {
    "id": "arXiv:2210.15655",
    "title": "GILP: An Interactive Tool for Visualizing the Simplex Algorithm",
    "abstract": "The Simplex algorithm for solving linear programs-one of Computing in Science\n& Engineering's top 10 most influential algorithms of the 20th century-is an\nimportant topic in many algorithms courses. While the Simplex algorithm relies\non intuitive geometric ideas, the computationally-involved mechanics of the\nalgorithm can obfuscate a geometric understanding. In this paper, we present\ngilp, an easy-to-use Simplex algorithm visualization tool designed to\nexplicitly connect the mechanical steps of the algorithm with their geometric\ninterpretation. We provide an extensive library with example visualizations,\nand our tool allows an instructor to quickly produce custom interactive HTML\nfiles for students to experiment with the algorithm (without requiring students\nto install anything!). The tool can also be used for interactive assignments in\nJupyter notebooks, and has been incorporated into a forthcoming Data Science\nand Decision Making interactive textbook. In this paper, we first describe how\nthe tool fits into the existing literature on algorithm visualizations: how it\nwas designed to facilitate student engagement and instructor adoption, and how\nit substantially extends existing algorithm visualization tools for Simplex. We\nthen describe the development and usage of the tool, and report feedback from\nits use in a course with roughly 100 students. Student feedback was\noverwhelmingly positive, with students finding the tool easy to use: it\neffectively helped them link the algebraic and geometrical views of the Simplex\nalgorithm and understand its nuances. Finally, gilp is open-source, includes an\nextension to visualizing linear programming-based branch and bound, and is\nreadily amenable to further extensions.",
    "descriptor": "\nComments: ACM SIGCSE 2023 Manuscript, 13 pages, 5 figures\n",
    "authors": [
      "Henry W Robbins",
      "Samuel C Gutekunst",
      "Frans Schalekamp",
      "David B Shmoys",
      "David P Williamson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15655"
  },
  {
    "id": "arXiv:2210.15656",
    "title": "Taxonomic Classification of IoT Smart Home Voice Control",
    "abstract": "Voice control in the smart home is commonplace, enabling the convenient\ncontrol of smart home Internet of Things hubs, gateways and devices, along with\ninformation seeking dialogues. Cloud-based voice assistants are used to\nfacilitate the interaction, yet privacy concerns surround the cloud analysis of\ndata. To what extent can voice control be performed using purely local\ncomputation, to ensure user data remains private? In this paper we present a\ntaxonomy of the voice control technologies present in commercial smart home\nsystems. We first review literature on the topic, and summarise relevant work\ncategorising IoT devices and voice control in the home. The taxonomic\nclassification of these entities is then presented, and we analyse our\nfindings. Following on, we turn to academic efforts in implementing and\nevaluating voice-controlled smart home set-ups, and we then discuss open-source\nlibraries and devices that are applicable to the design of a privacy-preserving\nvoice assistant for smart homes and the IoT. Towards the end, we consider\nadditional technologies and methods that could support a cloud-free voice\nassistant, and conclude the work.",
    "descriptor": "",
    "authors": [
      "Mary Hewitt",
      "Hamish Cunningham"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15656"
  },
  {
    "id": "arXiv:2210.15657",
    "title": "Detecting fake accounts through Generative Adversarial Network in online  social media",
    "abstract": "Nowadays, online social media has become an inseparable part of human life,\nalso this phenomenon is being used by individuals to send messages and share\nfiles via videos and images. Twitter, Instagram, and Facebook are well-known\nsamples of these networks. One of the main challenges of privacy for users in\nthese networks is anomalies in security. Anomalies in online social networks\ncan be attributed to illegal behavior, such deviance is done by malicious\npeople like account forgers, online fraudsters, etc. This paper proposed a new\nmethod to identify fake user accounts by calculating the similarity measures\namong users, applying the Generative Adversarial Network (GAN) algorithm over\nthe Twitter dataset. The results of the proposed method showed, accuracy was\nable to reach 98.1% for classifying and detecting fake user accounts.",
    "descriptor": "",
    "authors": [
      "Jinus Bordbar",
      "Mohammadreza Mohammadrezaie",
      "Saman Ardalan",
      "Mohammad Ebrahim Shiri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15657"
  },
  {
    "id": "arXiv:2210.15658",
    "title": "All the Feels: A dexterous hand with large area sensing",
    "abstract": "High cost and lack of reliability has precluded the widespread adoption of\ndexterous hands in robotics. Furthermore, the lack of a viable tactile sensor\ncapable of sensing over the entire area of the hand impedes the rich, low-level\nfeedback that would improve learning of dexterous manipulation skills. This\npaper introduces an inexpensive, modular, robust, and scalable platform - the\nDManus- aimed at resolving these challenges while satisfying the large-scale\ndata collection capabilities demanded by deep robot learning paradigms. Studies\non human manipulation point to the criticality of low-level tactile feedback in\nperforming everyday dexterous tasks. The DManus comes with ReSkin sensing on\nthe entire surface of the palm as well as the fingertips. We demonstrate\neffectiveness of the fully integrated system in a tactile aware task - bin\npicking and sorting. Code, documentation, design files, detailed assembly\ninstructions, trained models, task videos, and all supplementary materials\nrequired to recreate the setup can be found on\nthis http URL",
    "descriptor": "\nComments: 6 pages + references and appendix, 7 figures. Submitted to ICRA 2023\n",
    "authors": [
      "Raunaq Bhirangi",
      "Abigail DeFranco",
      "Jacob Adkins",
      "Carmel Majidi",
      "Abhinav Gupta",
      "Tess Hellebrekers",
      "Vikash Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15658"
  },
  {
    "id": "arXiv:2210.15663",
    "title": "Deep Generative Models on 3D Representations: A Survey",
    "abstract": "Generative models, as an important family of statistical modeling, target\nlearning the observed data distribution via generating new instances. Along\nwith the rise of neural networks, deep generative models, such as variational\nautoencoders (VAEs) and generative adversarial network (GANs), have made\ntremendous progress in 2D image synthesis. Recently, researchers switch their\nattentions from the 2D space to the 3D space considering that 3D data better\naligns with our physical world and hence enjoys great potential in practice.\nHowever, unlike a 2D image, which owns an efficient representation (i.e., pixel\ngrid) by nature, representing 3D data could face far more challenges.\nConcretely, we would expect an ideal 3D representation to be capable enough to\nmodel shapes and appearances in details, and to be highly efficient so as to\nmodel high-resolution data with fast speed and low memory cost. However,\nexisting 3D representations, such as point clouds, meshes, and recent neural\nfields, usually fail to meet the above requirements simultaneously. In this\nsurvey, we make a thorough review of the development of 3D generation,\nincluding 3D shape generation and 3D-aware image synthesis, from the\nperspectives of both algorithms and more importantly representations. We hope\nthat our discussion could help the community track the evolution of this field\nand further spark some innovative ideas to advance this challenging task.",
    "descriptor": "",
    "authors": [
      "Zifan Shi",
      "Sida Peng",
      "Yinghao Xu",
      "Yiyi Liao",
      "Yujun Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15663"
  },
  {
    "id": "arXiv:2210.15664",
    "title": "State of the Art in Dense Monocular Non-Rigid 3D Reconstruction",
    "abstract": "3D reconstruction of deformable (or non-rigid) scenes from a set of monocular\n2D image observations is a long-standing and actively researched area of\ncomputer vision and graphics. It is an ill-posed inverse problem,\nsince--without additional prior assumptions--it permits infinitely many\nsolutions leading to accurate projection to the input 2D images. Non-rigid\nreconstruction is a foundational building block for downstream applications\nlike robotics, AR/VR, or visual content creation. The key advantage of using\nmonocular cameras is their omnipresence and availability to the end users as\nwell as their ease of use compared to more sophisticated camera set-ups such as\nstereo or multi-view systems. This survey focuses on state-of-the-art methods\nfor dense non-rigid 3D reconstruction of various deformable objects and\ncomposite scenes from monocular videos or sets of monocular views. It reviews\nthe fundamentals of 3D reconstruction and deformation modeling from 2D image\nobservations. We then start from general methods--that handle arbitrary scenes\nand make only a few prior assumptions--and proceed towards techniques making\nstronger assumptions about the observed objects and types of deformations (e.g.\nhuman faces, bodies, hands, and animals). A significant part of this STAR is\nalso devoted to classification and a high-level comparison of the methods, as\nwell as an overview of the datasets for training and evaluation of the\ndiscussed techniques. We conclude by discussing open challenges in the field\nand the social aspects associated with the usage of the reviewed methods.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Edith Tretschk",
      "Navami Kairanda",
      "Mallikarjun B R",
      "Rishabh Dabral",
      "Adam Kortylewski",
      "Bernhard Egger",
      "Marc Habermann",
      "Pascal Fua",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15664"
  },
  {
    "id": "arXiv:2205.05345",
    "title": "Variational Autoencoder Leveraged MMSE Channel Estimation",
    "abstract": "We propose to utilize a variational autoencoder (VAE) for data-driven channel\nestimation. The underlying true and unknown channel distribution is modeled by\nthe VAE as a conditional Gaussian distribution in a novel way, parameterized by\nthe respective first and second order conditional moments. As a result, it can\nbe observed that the linear minimum mean square error (LMMSE) estimator in its\nvariant conditioned on the latent sample of the VAE approximates an optimal MSE\nestimator. Furthermore, we argue how a VAE-based channel estimator can\napproximate the MMSE channel estimator. We propose three variants of VAE\nestimators that differ in the data used during training and estimation. First,\nwe show that given perfectly known channel state information at the input of\nthe VAE during estimation, which is impractical, we obtain an estimator that\ncan serve as a benchmark result for an estimation scenario. We then propose\npractically feasible approaches, where perfectly known channel state\ninformation is only necessary in the training phase or is not needed at all.\nSimulation results on 3GPP and QuaDRiGa channel data attest a small performance\nloss of the practical approaches and the superiority of our VAE approaches in\ncomparison to other related channel estimation methods.",
    "descriptor": "\nComments: Submitted to the IEEE for possible publication\n",
    "authors": [
      "Michael Baur",
      "Benedikt Fesl",
      "Michael Koller",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05345"
  },
  {
    "id": "arXiv:2210.14909",
    "title": "Automated Diagnosis of Cardiovascular Diseases from Cardiac Magnetic  Resonance Imaging Using Deep Learning Models: A Review",
    "abstract": "In recent years, cardiovascular diseases (CVDs) have become one of the\nleading causes of mortality globally. CVDs appear with minor symptoms and\nprogressively get worse. The majority of people experience symptoms such as\nexhaustion, shortness of breath, ankle swelling, fluid retention, and other\nsymptoms when starting CVD. Coronary artery disease (CAD), arrhythmia,\ncardiomyopathy, congenital heart defect (CHD), mitral regurgitation, and angina\nare the most common CVDs. Clinical methods such as blood tests,\nelectrocardiography (ECG) signals, and medical imaging are the most effective\nmethods used for the detection of CVDs. Among the diagnostic methods, cardiac\nmagnetic resonance imaging (CMR) is increasingly used to diagnose, monitor the\ndisease, plan treatment and predict CVDs. Coupled with all the advantages of\nCMR data, CVDs diagnosis is challenging for physicians due to many slices of\ndata, low contrast, etc. To address these issues, deep learning (DL) techniques\nhave been employed to the diagnosis of CVDs using CMR data, and much research\nis currently being conducted in this field. This review provides an overview of\nthe studies performed in CVDs detection using CMR images and DL techniques. The\nintroduction section examined CVDs types, diagnostic methods, and the most\nimportant medical imaging techniques. In the following, investigations to\ndetect CVDs using CMR images and the most significant DL methods are presented.\nAnother section discussed the challenges in diagnosing CVDs from CMR data.\nNext, the discussion section discusses the results of this review, and future\nwork in CVDs diagnosis from CMR images and DL techniques are outlined. The most\nimportant findings of this study are presented in the conclusion section.",
    "descriptor": "",
    "authors": [
      "Mahboobeh Jafari",
      "Afshin Shoeibi",
      "Marjane Khodatars",
      "Navid Ghassemi",
      "Parisa Moridian",
      "Niloufar Delfan",
      "Roohallah Alizadehsani",
      "Abbas Khosravi",
      "Sai Ho Ling",
      "Yu-Dong Zhang",
      "Shui-Hua Wang",
      "Juan M. Gorriz",
      "Hamid Alinejad Rokny",
      "U. Rajendra Acharya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14909"
  },
  {
    "id": "arXiv:2210.14911",
    "title": "Quadratic approximation based heuristic for optimization-based  coordination of automated vehicles in confined areas",
    "abstract": "We investigate the problem of coordinating multiple automated vehicles (AVs)\nin confined areas. This problem can be formulated as an optimal control problem\n(OCP) where the motion of the AVs is optimized such that collisions are avoided\nin cross-intersections, merge crossings, and narrow roads. The problem is\ncombinatorial and solving it to optimality is prohibitively difficult for all\nbut trivial instances. For this reason, we propose a heuristic method to obtain\napproximate solutions. The heuristic comprises two stages: In the first stage,\na Mixed Integer Quadratic Program (MIQP), similar in construction to the\nQuadratic Programming (QP) sub-problems in Sequential Quadratic Programming\n(SQP), is solved for the combinatorial part of the solution. In the second\nstage, the combinatorial part of the solution is held fixed, and the optimal\nstate and control trajectories for the vehicles are obtained by solving a\nNonlinear Program (NLP). The performance of the algorithm is demonstrated by a\nsimulation of a non-trivial problem instance.",
    "descriptor": "\nComments: To be published in the 61st IEEE Conference on Decision and Control (CDC 2022). arXiv admin note: substantial text overlap with arXiv:2210.14738\n",
    "authors": [
      "Stefan Kojchev",
      "Robert Hult",
      "Jonas Fredriksson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.14911"
  },
  {
    "id": "arXiv:2210.14928",
    "title": "Towards an Automated Framework for Realizing Quantum Computing Solutions",
    "abstract": "Quantum computing is fast evolving as a technology due to recent advances in\nhardware, software, as well as the development of promising applications. To\nuse this technology for solving specific problems, a suitable quantum algorithm\nhas to be determined, the problem has to be encoded in a form suitable for the\nchosen algorithm, it has to be executed, and the result has to be decoded. To\ndate, each of these tedious and error-prone steps is conducted in a mostly\nmanual fashion. This creates a high entry barrier for using quantum computing\n-- especially for users with little to no expertise in that domain. In this\nwork, we envision a framework that aims to lower this entry barrier by allowing\nusers to employ quantum computing solutions in an automatic fashion. To this\nend, interfaces as similar as possible to classical solvers are provided, while\nthe quantum steps of the workflow are shielded from the user as much as\npossible by a fully automated backend. To demonstrate the feasibility and\nusability of such a framework, we provide proof-of-concept implementations for\ntwo different classes of problems which are publicly available on GitHub\n(https://github.com/cda-tum/MQTProblemSolver). By this, this work provides the\nfoundation for a low-threshold approach of realizing quantum computing\nsolutions with no or only moderate expertise in this technology.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Nils Quetschlich",
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.14928"
  },
  {
    "id": "arXiv:2210.14936",
    "title": "A super-polynomial quantum-classical separation for density modelling",
    "abstract": "Density modelling is the task of learning an unknown probability density\nfunction from samples, and is one of the central problems of unsupervised\nmachine learning. In this work, we show that there exists a density modelling\nproblem for which fault-tolerant quantum computers can offer a super-polynomial\nadvantage over classical learning algorithms, given standard cryptographic\nassumptions. Along the way, we provide a variety of additional results and\ninsights, of potential interest for proving future distribution learning\nseparations between quantum and classical learning algorithms. Specifically, we\n(a) provide an overview of the relationships between hardness results in\nsupervised learning and distribution learning, and (b) show that any weak\npseudo-random function can be used to construct a classically hard density\nmodelling problem. The latter result opens up the possibility of proving\nquantum-classical separations for density modelling based on weaker assumptions\nthan those necessary for pseudo-random functions.",
    "descriptor": "\nComments: 15 pages, one figure\n",
    "authors": [
      "Niklas Pirnay",
      "Ryan Sweke",
      "Jens Eisert",
      "Jean-Pierre Seifert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.14936"
  },
  {
    "id": "arXiv:2210.14942",
    "title": "The Art NFTs and Their Marketplaces",
    "abstract": "Non-Fungible Tokens (NFTs) are crypto assets with a unique digital identifier\nfor ownership, powered by blockchain technology. Technically speaking, anything\ndigital could be minted and sold as an NFT, which provides proof of ownership\nand authenticity of a digital file. For this reason, it helps us distinguish\nbetween the originals and their copies, making it possible to trade them. This\npaper focuses on art NFTs that change how artists can sell their products. It\nalso changes how the art trade market works since NFT technology cuts out the\nmiddleman. Recently, the utility of NFTs has become an essential issue in the\nNFT ecosystem, which refers to the owners' usefulness, profitability, and\nbenefits. Using recent major art NFT marketplace datasets, we summarize and\ninterpret the current market trends and patterns in a way that brings insight\ninto the future art market. Numerical examples are presented.",
    "descriptor": "",
    "authors": [
      "Lanqing Du",
      "Michelle Kim",
      "Jinwook Lee"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14942"
  },
  {
    "id": "arXiv:2210.14961",
    "title": "A Neural Network Based Automated IFT-20 Sensory Neuron Classifier for  Caenorhabditis elegans",
    "abstract": "Determining neuronal identity in imaging data is an essential task in\nneuroscience, facilitating the comparison of neural activity across organisms.\nCross-organism comparison, in turn, enables a wide variety of research\nincluding whole-brain analysis of functional networks and linking the activity\nof specific neurons to behavior or environmental stimuli. The recent\ndevelopment of three-dimensional, pan-neuronal imaging with single-cell\nresolution within Caenorhabditis elegans has brought neuron identification,\ntracking, and activity monitoring all within reach. The nematode C. elegans is\noften used as a model organism to study neuronal activity due to factors such\nas its transparency and well-understood nervous system. The principal barrier\nto high-accuracy neuron identification is that in adult C. elegans, the\nposition of neuronal cell bodies is not stereotyped. Existing approaches to\naddress this issue use genetically encoded markers as an additional identifying\nfeature. For example, the NeuroPAL strain uses multicolored fluorescent\nreporters. However, this approach has limited use due to the negative effects\nof excessive genetic modification. In this study, I propose an alternative\nneuronal identification technique using only single-color fluorescent images. I\ndesigned a novel neural network based classifier that automatically labels\nsensory neurons using an iterative, landmark-based neuron identification\nprocess inspired by the manual annotation procedures that humans employ. This\ndesign labels sensory neurons in C. elegans with 91.61% accuracy.",
    "descriptor": "\nComments: This work was presented at the Research Science Institute (RSI) at the Massachusetts Institute of Technology\n",
    "authors": [
      "Arvind Seshan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14961"
  },
  {
    "id": "arXiv:2210.14974",
    "title": "SINCO: A Novel structural regularizer for image compression using  implicit neural representations",
    "abstract": "Implicit neural representations (INR) have been recently proposed as deep\nlearning (DL) based solutions for image compression. An image can be compressed\nby training an INR model with fewer weights than the number of image pixels to\nmap the coordinates of the image to corresponding pixel values. While\ntraditional training approaches for INRs are based on enforcing pixel-wise\nimage consistency, we propose to further improve image quality by using a new\nstructural regularizer. We present structural regularization for INR\ncompression (SINCO) as a novel INR method for image compression. SINCO imposes\nstructural consistency of the compressed images to the groundtruth by using a\nsegmentation network to penalize the discrepancy of segmentation masks\npredicted from compressed images. We validate SINCO on brain MRI images by\nshowing that it can achieve better performance than some recent INR methods.",
    "descriptor": "",
    "authors": [
      "Harry Gao",
      "Weijie Gan",
      "Zhixin Sun",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14974"
  },
  {
    "id": "arXiv:2210.14980",
    "title": "Interstellar Object Accessibility and Mission Design",
    "abstract": "Interstellar objects (ISOs) are fascinating and under-explored celestial\nobjects, providing physical laboratories to understand the formation of our\nsolar system and probe the composition and properties of material formed in\nexoplanetary systems. This paper will discuss the accessibility of and mission\ndesign to ISOs with varying characteristics, including a discussion of state\ncovariance estimation over the course of a cruise, handoffs from traditional\nnavigation approaches to novel autonomous navigation for fast flyby regimes,\nand overall recommendations about preparing for the future in situ exploration\nof these targets. The lessons learned also apply to the fast flyby of other\nsmall bodies including long-period comets and potentially hazardous asteroids,\nwhich also require a tactical response with similar characteristics",
    "descriptor": "\nComments: Accepted at IEEE Aerospace Conference\n",
    "authors": [
      "Benjamin P. S. Donitz",
      "Declan Mages",
      "Hiroyasu Tsukamoto",
      "Peter Dixon",
      "Damon Landau",
      "Soon-Jo Chung",
      "Erica Bufanda",
      "Michel Ingham",
      "Julie Castillo-Rogez"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.14980"
  },
  {
    "id": "arXiv:2210.14982",
    "title": "LinearCoFold and LinearCoPartition: Linear-Time Algorithms for Secondary  Structure Prediction of Interacting RNA molecules",
    "abstract": "Many ncRNAs function through RNA-RNA interactions. Fast and reliable RNA\nstructure prediction with consideration of RNA-RNA interaction is useful. Some\nexisting tools are less accurate due to omitting the competing of\nintermolecular and intramolecular base pairs, or focus more on predicting the\nbinding region rather than predicting the complete secondary structure of two\ninteracting strands. Vienna RNAcofold, which reduces the problem into the\nclassical single sequence folding by concatenating two strands, scales in cubic\ntime against the combined sequence length, and is slow for long sequences. To\naddress these issues, we present LinearCoFold, which predicts the complete\nminimum free energy structure of two strands in linear runtime, and\nLinearCoPartition, which calculates the cofolding partition function and base\npairing probabilities in linear runtime. LinearCoFold and LinearCoPartition\nfollows the concatenation strategy of RNAcofold, but are orders of magnitude\nfaster than RNAcofold. For example, on a sequence pair with combined length of\n26,190 nt, LinearCoFold is 86.8x faster than RNAcofold MFE mode (0.6 minutes\nvs. 52.1 minutes), and LinearCoPartition is 642.3x faster than RNAcofold\npartition function mode (1.8 minutes vs. 1156.2 minutes). Different from the\nlocal algorithms, LinearCoFold and LinearCoPartition are global cofolding\nalgorithms without restriction on base pair length. Surprisingly, LinearCoFold\nand LinearCoPartition's predictions have higher PPV and sensitivity of\nintermolecular base pairs. Furthermore, we apply LinearCoFold to predict the\nRNA-RNA interaction between SARS-CoV-2 gRNA and human U4 snRNA, which has been\nexperimentally studied, and observe that LinearCoFold's prediction correlates\nbetter to the wet lab results.",
    "descriptor": "",
    "authors": [
      "He Zhang",
      "Sizhen Li",
      "Liang Zhang",
      "David H. Mathews",
      "Liang Huang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Data Structures and Algorithms (cs.DS)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.14982"
  },
  {
    "id": "arXiv:2210.14992",
    "title": "On the exactness of a stability test for Lur'e systems with  slope-restricted nonlinearities",
    "abstract": "In this note it is shown that the famous multiplier absolute stability test\nof R. O'Shea, G. Zames and P. Falb is necessary and sufficient if the set of\nLur'e interconnections is lifted to a Kronecker structure and an explicit\nmethod to construct the destabilizing static nonlinearity is presented.",
    "descriptor": "",
    "authors": [
      "Andrey Kharitenko",
      "Carsten W. Scherer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.14992"
  },
  {
    "id": "arXiv:2210.14995",
    "title": "Privacy-preserving Automatic Speaker Diarization",
    "abstract": "Automatic Speaker Diarization (ASD) is an enabling technology with numerous\napplications, which deals with recordings of multiple speakers, raising special\nconcerns in terms of privacy. In fact, in remote settings, where recordings are\nshared with a server, clients relinquish not only the privacy of their\nconversation, but also of all the information that can be inferred from their\nvoices. However, to the best of our knowledge, the development of\nprivacy-preserving ASD systems has been overlooked thus far. In this work, we\ntackle this problem using a combination of two cryptographic techniques, Secure\nMultiparty Computation (SMC) and Secure Modular Hashing, and apply them to the\ntwo main steps of a cascaded ASD system: speaker embedding extraction and\nagglomerative hierarchical clustering. Our system is able to achieve a\nreasonable trade-off between performance and efficiency, presenting real-time\nfactors of 1.1 and 1.6, for two different SMC security settings.",
    "descriptor": "",
    "authors": [
      "Francisco Teixeira",
      "Alberto Abad",
      "Bhiksha Raj",
      "Isabel Trancoso"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.14995"
  },
  {
    "id": "arXiv:2210.15001",
    "title": "Acoustically-Driven Phoneme Removal That Preserves Vocal Affect Cues",
    "abstract": "In this paper, we propose a method for removing linguistic information from\nspeech for the purpose of isolating paralinguistic indicators of affect. The\nimmediate utility of this method lies in clinical tests of sensitivity to vocal\naffect that are not confounded by language, which is impaired in a variety of\nclinical populations. The method is based on simultaneous recordings of speech\naudio and electroglottographic (EGG) signals. The speech audio signal is used\nto estimate the average vocal tract filter response and amplitude envelop. The\nEGG signal supplies a direct correlate of voice source activity that is mostly\nindependent of phonetic articulation. These signals are used to create a third\nsignal designed to capture as much paralinguistic information from the vocal\nproduction system as possible -- maximizing the retention of bioacoustic cues\nto affect -- while eliminating phonetic cues to verbal meaning. To evaluate the\nsuccess of this method, we studied the perception of corresponding speech audio\nand transformed EGG signals in an affect rating experiment with online\nlisteners. The results show a high degree of similarity in the perceived affect\nof matched signals, indicating that our method is effective.",
    "descriptor": "\nComments: Submitted to the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing\n",
    "authors": [
      "Camille Noufi",
      "Jonathan Berger",
      "Michael Frank",
      "Karen Parker",
      "Daniel L. Bowling"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15001"
  },
  {
    "id": "arXiv:2210.15022",
    "title": "Automatic Assessment of Infant Face and Upper-Body Symmetry as Early  Signs of Torticollis",
    "abstract": "We apply computer vision pose estimation techniques developed expressly for\nthe data-scarce infant domain to the study of torticollis, a common condition\nin infants for which early identification and treatment is critical.\nSpecifically, we use a combination of facial landmark and body joint estimation\ntechniques designed for infants to estimate a range of geometric measures\npertaining to face and upper body symmetry, drawn an array of sources in the\nphysical therapy and ophthalmology research literature in torticollis. We gauge\nperformance with a range of metrics and show that the estimates of most these\ngeometric measures are successful, yielding very strong to strong Spearman's\n$\\rho$ correlation with ground truth values. Furthermore, we show that these\nestimates derived from pose estimation neural networks designed for the infant\ndomain cleanly outperform estimates derived from more widely known networks\ndesigned for the adult domain.",
    "descriptor": "",
    "authors": [
      "Michael Wan",
      "Xiaofei Huang",
      "Bethany Tunik",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15022"
  },
  {
    "id": "arXiv:2210.15033",
    "title": "Multi-Scale Structural-aware Exposure Correction for Endoscopic Imaging",
    "abstract": "Endoscopy is the most widely used imaging technique for the diagnosis of\ncancerous lesions in hollow organs. However, endoscopic images are often\naffected by illumination artefacts: image parts may be over- or underexposed\naccording to the light source pose and the tissue orientation. These artifacts\nhave a strong negative impact on the performance of computer vision or AI-based\ndiagnosis tools. Although endoscopic image enhancement methods are greatly\nrequired, little effort has been devoted to over- and under-exposition\nenhancement in real-time. This contribution presents an extension to the\nobjective function of LMSPEC, a method originally introduced to enhance images\nfrom natural scenes. It is used here for the exposure correction in endoscopic\nimaging and the preservation of structural information. To the best of our\nknowledge, this contribution is the first one that addresses the enhancement of\nendoscopic images using deep learning (DL) methods. Tested on the Endo4IE\ndataset, the proposed implementation has yielded a significant improvement over\nLMSPEC reaching a SSIM increase of 4.40% and 4.21% for over- and underexposed\nimages, respectively.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Axel Garcia-Vega",
      "Ricardo Espinosa",
      "Luis Ramirez-Guzman",
      "Thomas Bazin",
      "Luis Falcon-Morales",
      "Gilberto Ochoa-Ruiz",
      "Dominique Lamarque",
      "Christian Daul"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15033"
  },
  {
    "id": "arXiv:2210.15044",
    "title": "Generative modeling of the enteric nervous system employing point  pattern analysis and graph construction",
    "abstract": "We describe a generative network model of the architecture of the enteric\nnervous system (ENS) in the colon employing data from images of human and mouse\ntissue samples obtained through confocal microscopy. Our models combine spatial\npoint pattern analysis with graph generation to characterize the spatial and\ntopological properties of the ganglia (clusters of neurons and glial cells),\nthe inter-ganglionic connections, and the neuronal organization within the\nganglia. We employ a hybrid hardcore-Strauss process for spatial patterns and a\nplanar random graph generation for constructing the spatially embedded network.\nWe show that our generative model may be helpful in both basic and\ntranslational studies, and it is sufficiently expressive to model the ENS\narchitecture of individuals who vary in age and health status. Increased\nunderstanding of the ENS connectome will enable the use of neuromodulation\nstrategies in treatment and clarify anatomic diagnostic criteria for people\nwith bowel motility disorders.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Abida Sanjana Shemonti",
      "Joshua D. Eisenberg",
      "Robert O. Heuckeroth",
      "Marthe J. Howard",
      "Alex Pothen",
      "Bartek Rajwa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.15044"
  },
  {
    "id": "arXiv:2210.15058",
    "title": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "abstract": "In this work we introduce a convolution operation over the tangent bundle of\nRiemannian manifolds exploiting the Connection Laplacian operator. We use the\nconvolution to define tangent bundle filters and tangent bundle neural networks\n(TNNs), novel continuous architectures operating on tangent bundle signals,\ni.e. vector fields over manifolds. We discretize TNNs both in space and time\ndomains, showing that their discrete counterpart is a principled variant of the\nrecently introduced Sheaf Neural Networks. We formally prove that this discrete\narchitecture converges to the underlying continuous TNN. We numerically\nevaluate the effectiveness of the proposed architecture on a denoising task of\na tangent vector field over the unit 2-sphere.",
    "descriptor": "",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15058"
  },
  {
    "id": "arXiv:2210.15073",
    "title": "Architecture representations for quantum convolutional neural networks",
    "abstract": "The Quantum Convolutional Neural Network (QCNN) is a quantum circuit model\ninspired by the architecture of Convolutional Neural Networks (CNNs). The\nsuccess of CNNs is largely due to its ability to learn high level features from\nraw data rather than requiring manual feature design. Neural Architecture\nSearch (NAS) continues this trend by learning network architecture, alleviating\nthe need for its manual construction and have been able to generate state of\nthe art models automatically. Search space design is a crucial step in NAS and\nthere is currently no formal framework through which it can be achieved for\nQCNNs. In this work we provide such a framework by utilizing techniques from\nNAS to create an architectural representation for QCNNs that facilitate search\nspace design and automatic model generation. This is done by specifying\nprimitive operations, such as convolutions and pooling, in such a way that they\ncan be dynamically stacked on top of each other to form different\narchitectures. This way, QCNN search spaces can be created by controlling the\nsequence and hyperparameters of stacked primitives, allowing the capture of\ndifferent design motifs. We show this by generating QCNNs that belong to a\npopular family of parametric quantum circuits, those resembling reverse binary\ntrees. We then benchmark this family of models on a music genre classification\ndataset, GTZAN. Showing that alternating architecture impact model performance\nmore than other modelling components such as choice of unitary ansatz and data\nencoding, resulting in a way to improve model performance without increasing\nits complexity. Finally we provide an open source python package that enable\ndynamic QCNN creation by system or hand, based off the work presented in this\npaper, facilitating search space design.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Matt Lourens",
      "Ilya Sinayskiy",
      "Daniel K. Park",
      "Carsten Blank",
      "Francesco Petruccione"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15073"
  },
  {
    "id": "arXiv:2210.15076",
    "title": "Tur\u00e1n graphs with bounded matching number",
    "abstract": "We determine the maximum possible number of edges of a graph with $n$\nvertices, matching number at most $s$ and clique number at most $k$ for all\nadmissible values of the parameters.",
    "descriptor": "",
    "authors": [
      "Noga Alon",
      "Peter Frankl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.15076"
  },
  {
    "id": "arXiv:2210.15081",
    "title": "Bayesian Hyperbolic Multidimensional Scaling",
    "abstract": "Multidimensional scaling (MDS) is a widely used approach to representing\nhigh-dimensional, dependent data. MDS works by assigning each observation a\nlocation on a low-dimensional geometric manifold, with distance on the manifold\nrepresenting similarity. We propose a Bayesian approach to multidimensional\nscaling when the low-dimensional manifold is hyperbolic. Using hyperbolic space\nfacilitates representing tree-like structure common in many settings (e.g. text\nor genetic data with hierarchical structure). A Bayesian approach provides\nregularization that minimizes the impact of uncertainty or measurement error in\nthe observed data. We also propose a case-control likelihood approximation that\nallows for efficient sampling from the posterior in larger data settings,\nreducing computational complexity from approximately $O(n^2)$ to $O(n)$. We\nevaluate the proposed method against state-of-the-art alternatives using\nsimulations, canonical reference datasets, and human gene expression data.",
    "descriptor": "",
    "authors": [
      "Bolun Liu",
      "Shane Lubold",
      "Adrian E. Raftery",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15081"
  },
  {
    "id": "arXiv:2210.15083",
    "title": "Deep Learning is Provably Robust to Symmetric Label Noise",
    "abstract": "Deep neural networks (DNNs) are capable of perfectly fitting the training\ndata, including memorizing noisy data. It is commonly believed that\nmemorization hurts generalization. Therefore, many recent works propose\nmitigation strategies to avoid noisy data or correct memorization. In this\nwork, we step back and ask the question: Can deep learning be robust against\nmassive label noise without any mitigation? We provide an affirmative answer\nfor the case of symmetric label noise: We find that certain DNNs, including\nunder-parameterized and over-parameterized models, can tolerate massive\nsymmetric label noise up to the information-theoretic threshold. By appealing\nto classical statistical theory and universal consistency of DNNs, we prove\nthat for multiclass classification, $L_1$-consistent DNN classifiers trained\nunder symmetric label noise can achieve Bayes optimality asymptotically if the\nlabel noise probability is less than $\\frac{K-1}{K}$, where $K \\ge 2$ is the\nnumber of classes. Our results show that for symmetric label noise, no\nmitigation is necessary for $L_1$-consistent estimators. We conjecture that for\ngeneral label noise, mitigation strategies that make use of the noisy data will\noutperform those that ignore the noisy data.",
    "descriptor": "",
    "authors": [
      "Carey E. Priebe",
      "Ningyuan Huang",
      "Soledad Villar",
      "Cong Mu",
      "Li Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15083"
  },
  {
    "id": "arXiv:2210.15148",
    "title": "Ranking Edges by their Impact on the Spectral Complexity of Information  Diffusion over Networks",
    "abstract": "Despite the numerous ways now available to quantify which parts or subsystems\nof a network are most important, there remains a lack of centrality measures\nthat are related to the complexity of information flows and are derived\ndirectly from entropy measures. Here, we introduce a ranking of edges based on\nhow each edge's removal would change a system's von Neumann entropy (VNE),\nwhich is a spectral-entropy measure that has been adapted from quantum\ninformation theory to quantify the complexity of information dynamics over\nnetworks. We show that a direct calculation of such rankings is computationally\ninefficient (or unfeasible) for large networks: e.g.\\ the scaling is\n$\\mathcal{O}(N^3)$ per edge for networks with $N$ nodes. To overcome this\nlimitation, we employ spectral perturbation theory to estimate VNE\nperturbations and derive an approximate edge-ranking algorithm that is accurate\nand fast to compute, scaling as $\\mathcal{O}(N)$ per edge. Focusing on a form\nof VNE that is associated with a transport operator $e^{-\\beta{ L}}$, where ${\nL}$ is a graph Laplacian matrix and $\\beta>0$ is a diffusion timescale\nparameter, we apply this approach to diverse applications including a network\nencoding polarized voting patterns of the 117th U.S. Senate, a multimodal\ntransportation system including roads and metro lines in London, and a\nmultiplex brain network encoding correlated human brain activity. Our\nexperiments highlight situations where the edges that are considered to be most\nimportant for information diffusion complexity can dramatically change as one\nconsiders short, intermediate and long timescales $\\beta$ for diffusion.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Jeremy Kazimer",
      "Manlio de Domenico",
      "Peter J. Mucha",
      "Dane Taylor"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15148"
  },
  {
    "id": "arXiv:2210.15149",
    "title": "Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study",
    "abstract": "Despite high global prevalence of hepatic steatosis, no automated diagnostics\ndemonstrated generalizability in detecting steatosis on multiple heterogeneous\npopulations. In this retrospective study, we externally validated a fully\nautomated artificial intelligence (AI) system to detect hepatic steatosis.\n1,014 non-contrast enhanced chest computed tomography (CT) scans were collected\nfrom eight distinct datasets: LIDC-IDRI, NSCLC-Lung1, RIDER, VESSEL12,\nRICORD-1A, RICORD-1B, COVID-19-Italy, and COVID-19-China. This three-step AI\nworkflow consists of the following: (i) 3D liver segmentation - a 3D U-Net deep\nlearning model developed for liver segmentation and applied externally without\nretraining. (ii) liver attenuation measurements by three automatic methods: AI\non regions of interest (AI-ROI), AI-3D, and AI-2D; (iii) hepatic steatosis\ndetection. The deep-learning segmentation achieved a mean dice coefficient of\n0.957. AI-ROI attenuation measurements showed no significant differences\ncompared to expert measurements (P > 0.05), but AI-3D and AI-2D were\nsignificantly different from the expert (P < 0.001). The area under the curve\n(AUC) of steatosis classification for AI-ROI, AI-3D, and AI-2D are 0.921 (95%\nCI: 0.883 - 0.959), 0.939 (95% CI: 0.903 - 0.973), and 0.894 (95% CI: 0.850 -\n0.938) respectively. If adopted for universal detection, this deep learning\nsystem could potentially allow early non-invasive, non-pharmacological\npreventative interventions for hepatic steatosis. 1,014 expert-annotated liver\nsegmentations of CT images can be downloaded here:\nhttps://drive.google.com/drive/folders/1-g_zJeAaZXYXGqL1OeF6pUjr6KB0igJX.",
    "descriptor": "",
    "authors": [
      "Zhongyi Zhang",
      "Guixia Li",
      "Ziqiang Wang",
      "Feng Xia",
      "Ning Zhao",
      "Huibin Nie",
      "Zezhong Ye",
      "Joshua Lin",
      "Yiyi Hui",
      "Xiangchun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15149"
  },
  {
    "id": "arXiv:2210.15158",
    "title": "Streaming Voice Conversion Via Intermediate Bottleneck Features And  Non-streaming Teacher Guidance",
    "abstract": "Streaming voice conversion (VC) is the task of converting the voice of one\nperson to another in real-time. Previous streaming VC methods use phonetic\nposteriorgrams (PPGs) extracted from automatic speech recognition (ASR) systems\nto represent speaker-independent information. However, PPGs lack the prosody\nand vocalization information of the source speaker, and streaming PPGs contain\nundesired leaked timbre of the source speaker. In this paper, we propose to use\nintermediate bottleneck features (IBFs) to replace PPGs. VC systems trained\nwith IBFs retain more prosody and vocalization information of the source\nspeaker. Furthermore, we propose a non-streaming teacher guidance (TG)\nframework that addresses the timbre leakage problem. Experiments show that our\nproposed IBFs and the TG framework achieve a state-of-the-art streaming VC\nnaturalness of 3.85, a content consistency of 3.77, and a timbre similarity of\n3.77 under a future receptive field of 160 ms which significantly outperform\nprevious streaming VC systems.",
    "descriptor": "\nComments: The paper has been submitted to ICASSP2023\n",
    "authors": [
      "Yuanzhe Chen",
      "Ming Tu",
      "Tang Li",
      "Xin Li",
      "Qiuqiang Kong",
      "Jiaxin Li",
      "Zhichao Wang",
      "Qiao Tian",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15158"
  },
  {
    "id": "arXiv:2210.15193",
    "title": "A framework of distributionally robust possibilistic optimization",
    "abstract": "In this paper, an optimization problem with uncertain constraint coefficients\nis considered. Possibility theory is used to model the uncertainty. Namely, a\njoint possibility distribution in constraint coefficient realizations, called\nscenarios, is specified. This possibility distribution induces a necessity\nmeasure in scenario set, which in turn describes an ambiguity set of\nprobability distributions in scenario set. The distributionally robust approach\nis then used to convert the imprecise constraints into deterministic\nequivalents. Namely, the left-hand side of an imprecise constraint is evaluated\nby using a risk measure with respect to the worst probability distribution that\ncan occur. In this paper, the Conditional Value at Risk is used as the risk\nmeasure, which generalizes the strict robust and expected value approaches,\ncommonly used in literature. A general framework for solving such a class of\nproblems is described. Some cases which can be solved in polynomial time are\nidentified.",
    "descriptor": "",
    "authors": [
      "Romain Guillaume",
      "Adam Kasperski",
      "Pawel Zielinski"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15193"
  },
  {
    "id": "arXiv:2210.15195",
    "title": "Masked Autoencoders Are Articulatory Learners",
    "abstract": "Articulatory recordings track the positions and motion of different\narticulators along the vocal tract and are widely used to study speech\nproduction and to develop speech technologies such as articulatory based speech\nsynthesizers and speech inversion systems. The University of Wisconsin X-Ray\nmicrobeam (XRMB) dataset is one of various datasets that provide articulatory\nrecordings synced with audio recordings. The XRMB articulatory recordings\nemploy pellets placed on a number of articulators which can be tracked by the\nmicrobeam. However, a significant portion of the articulatory recordings are\nmistracked, and have been so far unsuable. In this work, we present a deep\nlearning based approach using Masked Autoencoders to accurately reconstruct the\nmistracked articulatory recordings for 41 out of 47 speakers of the XRMB\ndataset. Our model is able to reconstruct articulatory trajectories that\nclosely match ground truth, even when three out of eight articulators are\nmistracked, and retrieve 3.28 out of 3.4 hours of previously unusable\nrecordings.",
    "descriptor": "",
    "authors": [
      "Ahmed Adel Attia",
      "Carol Espy-Wilson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15195"
  },
  {
    "id": "arXiv:2210.15196",
    "title": "HRTF Field: Unifying Measured HRTF Magnitude Representation with Neural  Fields",
    "abstract": "Head-related transfer functions (HRTFs) are a set of functions of frequency\ndescribing the spatial filtering effect of the outer ear (i.e., torso, head,\nand pinnae) onto sound sources at different azimuth and elevation angles. They\nare widely used in spatial audio rendering. While the azimuth and elevation\nangles are intrinsically continuous, measured HRTFs in existing datasets employ\ndifferent spatial sampling schemes, making it difficult to model HRTFs across\ndatasets. In this work, we propose to use neural fields, a differentiable\nrepresentation of functions through neural networks, to model HRTFs with\narbitrary spatial sampling schemes. Such representation is unified across\ndatasets with different spatial sampling schemes and HRTFs for arbitrary\nazimuth and elevation angles can be derived from this representation. We\nfurther introduce a generative model named HRTF field to learn a latent space\nof the HRTF neural fields. We demonstrate promising performance on HRTF\ninterpolation and generation tasks and point out potential future work.",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2023\n",
    "authors": [
      "You Zhang",
      "Yuxiang Wang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15196"
  },
  {
    "id": "arXiv:2210.15228",
    "title": "Solving Audio Inverse Problems with a Diffusion Model",
    "abstract": "This paper presents CQT-Diff, a data-driven generative audio model that can,\nonce trained, be used for solving various different audio inverse problems in a\nproblem-agnostic setting. CQT-Diff is a neural diffusion model with an\narchitecture that is carefully constructed to exploit pitch-equivariant\nsymmetries in music. This is achieved by preconditioning the model with an\ninvertible Constant-Q Transform (CQT), whose logarithmically-spaced frequency\naxis represents pitch equivariance as translation equivariance. The proposed\nmethod is evaluated with objective and subjective metrics in three different\nand varied tasks: audio bandwidth extension, inpainting, and declipping. The\nresults show that CQT-Diff outperforms the compared baselines and ablations in\naudio bandwidth extension and, without retraining, delivers competitive\nperformance against modern baselines in audio inpainting and declipping. This\nwork represents the first diffusion-based general framework for solving inverse\nproblems in audio processing.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Eloi Moliner",
      "Jaakko Lehtinen",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15228"
  },
  {
    "id": "arXiv:2210.15237",
    "title": "Seq2Seq-SC: End-to-End Semantic Communication Systems with Pre-trained  Language Model",
    "abstract": "While semantic communication is expected to bring unprecedented communication\nefficiency in comparison to classical communication, many challenges must be\nresolved to realize its potential. In this work, we provide a realistic\nsemantic network dubbed seq2seq-SC, which is compatible to 5G NR and can work\nwith generalized text dataset utilizing pre-trained language model. We also\nutilize a performance metric (SBERT) which can accurately measure semantic\nsimilarity and show that seq2seq-SC achieves superior performance while\nextracting semantically meaningful information.",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables\n",
    "authors": [
      "Ju-Hyung Lee",
      "Dong-Ho Lee",
      "Eunsoo Sheen",
      "Thomas Choi",
      "Jay Pujara",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15237"
  },
  {
    "id": "arXiv:2210.15258",
    "title": "Forecasting Graph Signals with Recursive MIMO Graph Filters",
    "abstract": "Forecasting time series on graphs is a fundamental problem in graph signal\nprocessing. When each entity of the network carries a vector of values for each\ntime stamp instead of a scalar one, existing approaches resort to the use of\nproduct graphs to combine this multidimensional information, at the expense of\ncreating a larger graph. In this paper, we show the limitations of such\napproaches, and propose extensions to tackle them. Then, we propose a recursive\nmultiple-input multiple-output graph filter which encompasses many already\nexisting models in the literature while being more flexible. Numerical\nsimulations on a real world data set show the effectiveness of the proposed\nmodels.",
    "descriptor": "",
    "authors": [
      "Jelmer van der Hoeven",
      "Alberto Natali",
      "Geert Leus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15258"
  },
  {
    "id": "arXiv:2210.15272",
    "title": "A Fast and Accurate Pitch Estimation Algorithm Based on the Pseudo  Wigner-Ville Distribution",
    "abstract": "Estimation of fundamental frequency (F0) in voiced segments of speech\nsignals, also known as pitch tracking, plays a crucial role in pitch\nsynchronous speech analysis, speech synthesis, and speech manipulation. In this\npaper, we capitalize on the high time and frequency resolution of the pseudo\nWigner-Ville distribution (PWVD) and propose a new PWVD-based pitch estimation\nmethod. We devise an efficient algorithm to compute PWVD faster and use\ncepstrum-based pre-filtering to avoid cross-term interference. Evaluating our\napproach on a database with speech and electroglottograph (EGG) recordings\nyields a state-of-the-art mean absolute error (MAE) of around 4Hz. Our approach\nis also effective at voiced/unvoiced classification and handling sudden\nfrequency changes.",
    "descriptor": "",
    "authors": [
      "Yisi Liu",
      "Peter Wu",
      "Alan W Black",
      "Gopala K. Anumanchipalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15272"
  },
  {
    "id": "arXiv:2210.15277",
    "title": "Implications of sparsity and high triangle density for graph  representation learning",
    "abstract": "Recent work has shown that sparse graphs containing many triangles cannot be\nreproduced using a finite-dimensional representation of the nodes, in which\nlink probabilities are inner products. Here, we show that such graphs can be\nreproduced using an infinite-dimensional inner product model, where the node\nrepresentations lie on a low-dimensional manifold. Recovering a global\nrepresentation of the manifold is impossible in a sparse regime. However, we\ncan zoom in on local neighbourhoods, where a lower-dimensional representation\nis possible. As our constructions allow the points to be uniformly distributed\non the manifold, we find evidence against the common perception that triangles\nimply community structure.",
    "descriptor": "",
    "authors": [
      "Hannah Sansford",
      "Alexander Modell",
      "Nick Whiteley",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15277"
  },
  {
    "id": "arXiv:2210.15282",
    "title": "Weight Averaging: A Simple Yet Effective Method to Overcome Catastrophic  Forgetting in Automatic Speech Recognition",
    "abstract": "Adapting a trained Automatic Speech Recognition (ASR) model to new tasks\nresults in catastrophic forgetting of old tasks, limiting the model's ability\nto learn continually and to be extended to new speakers, dialects, languages,\netc. Focusing on End-to-End ASR, in this paper, we propose a simple yet\neffective method to overcome catastrophic forgetting: weight averaging. By\nsimply taking the average of the previous and the adapted model, our method\nachieves high performance on both the old and new tasks. It can be further\nimproved by introducing a knowledge distillation loss during the adaptation. We\nillustrate the effectiveness of our method on both monolingual and multilingual\nASR. In both cases, our method strongly outperforms all baselines, even in its\nsimplest form.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. 5 pages\n",
    "authors": [
      "Steven Vander Eeckt",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15282"
  },
  {
    "id": "arXiv:2210.15286",
    "title": "Interplay between exogenous triggers and endogenous behavioral changes  in contagion processes on social networks",
    "abstract": "In recent years, statistical physics' methodologies have proven extremely\nsuccessful in offering insights into the mechanisms that govern social\ninteractions. However, the question of whether these models are able to capture\ntrends observed in real-world datasets is hardly addressed in the current\nliterature. With this work we aim at bridging the gap between theoretical\nmodeling and validation with data. In particular, we propose a model for\nopinion dynamics on a social network in the presence of external triggers,\nframing the interpretation of the model in the context of misbehavior\nspreading. We divide our population in aware, unaware and zealot/educated\nagents. Individuals change their status according to two competing dynamics,\nreferred to as behavioral dynamics and broadcasting. The former accounts for\ninformation spreading through contact among individuals whereas broadcasting\nplays the role of an external agent, modeling the effect of mainstream media\noutlets. Through both simulations and analytical computations we find that the\nstationary distribution of the fraction of unaware agents in the system\nundergoes a phase transition when an all-to-all approximation is considered.\nSurprisingly, such a phase transition disappears in the presence of a minimum\nfraction of educated agents. Finally, we validate our model using data\ncollected from the public discussion on Twitter, including millions of posts,\nabout the potential adverse effects of the AstraZeneca vaccine against\nCOVID-19. We show that the intervention of external agents, as accounted for in\nour model, is able to reproduce some key features that are found in this\nreal-world dataset.",
    "descriptor": "",
    "authors": [
      "Clara Eminente",
      "Oriol Artime",
      "Manlio De Domenico"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.15286"
  },
  {
    "id": "arXiv:2210.15297",
    "title": "Spatio-Temporal Hybrid Fusion of CAE and SWIn Transformers for Lung  Cancer Malignancy Prediction",
    "abstract": "The paper proposes a novel hybrid discovery Radiomics framework that\nsimultaneously integrates temporal and spatial features extracted from non-thin\nchest Computed Tomography (CT) slices to predict Lung Adenocarcinoma (LUAC)\nmalignancy with minimum expert involvement. Lung cancer is the leading cause of\nmortality from cancer worldwide and has various histologic types, among which\nLUAC has recently been the most prevalent. LUACs are classified as\npre-invasive, minimally invasive, and invasive adenocarcinomas. Timely and\naccurate knowledge of the lung nodules malignancy leads to a proper treatment\nplan and reduces the risk of unnecessary or late surgeries. Currently, chest CT\nscan is the primary imaging modality to assess and predict the invasiveness of\nLUACs. However, the radiologists' analysis based on CT images is subjective and\nsuffers from a low accuracy compared to the ground truth pathological reviews\nprovided after surgical resections. The proposed hybrid framework, referred to\nas the CAET-SWin, consists of two parallel paths: (i) The Convolutional\nAuto-Encoder (CAE) Transformer path that extracts and captures informative\nfeatures related to inter-slice relations via a modified Transformer\narchitecture, and; (ii) The Shifted Window (SWin) Transformer path, which is a\nhierarchical vision transformer that extracts nodules' related spatial features\nfrom a volumetric CT scan. Extracted temporal (from the CAET-path) and spatial\n(from the Swin path) are then fused through a fusion path to classify LUACs.\nExperimental results on our in-house dataset of 114 pathologically proven\nSub-Solid Nodules (SSNs) demonstrate that the CAET-SWin significantly improves\nreliability of the invasiveness prediction task while achieving an accuracy of\n82.65%, sensitivity of 83.66%, and specificity of 81.66% using 10-fold\ncross-validation.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.08721\n",
    "authors": [
      "Sadaf Khademi",
      "Shahin Heidarian",
      "Parnian Afshar",
      "Farnoosh Naderkhani",
      "Anastasia Oikonomou",
      "Konstantinos Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15297"
  },
  {
    "id": "arXiv:2210.15310",
    "title": "Learning Music Representations with wav2vec 2.0",
    "abstract": "Learning music representations that are general-purpose offers the\nflexibility to finetune several downstream tasks using smaller datasets. The\nwav2vec 2.0 speech representation model showed promising results in many\ndownstream speech tasks, but has been less effective when adapted to music. In\nthis paper, we evaluate whether pre-training wav2vec 2.0 directly on music data\ncan be a better solution instead of finetuning the speech model. We illustrate\nthat when pre-training on music data, the discrete latent representations are\nable to encode the semantic meaning of musical concepts such as pitch and\ninstrument. Our results show that finetuning wav2vec 2.0 pre-trained on music\ndata allows us to achieve promising results on music classification tasks that\nare competitive with prior work on audio representations. In addition, the\nresults are superior to the pre-trained model on speech embeddings,\ndemonstrating that wav2vec 2.0 pre-trained on music data can be a promising\nmusic representation model.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Alessandro Ragano",
      "Emmanouil Benetos",
      "Andrew Hines"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15310"
  },
  {
    "id": "arXiv:2210.15324",
    "title": "Robust Data2vec: Noise-robust Speech Representation Learning for ASR by  Combining Regression and Improved Contrastive Learning",
    "abstract": "Self-supervised pre-training methods based on contrastive learning or\nregression tasks can utilize more unlabeled data to improve the performance of\nautomatic speech recognition (ASR). However, the robustness impact of combining\nthe two pre-training tasks and constructing different negative samples for\ncontrastive learning still remains unclear. In this paper, we propose a\nnoise-robust data2vec for self-supervised speech representation learning by\njointly optimizing the contrastive learning and regression tasks in the\npre-training stage. Furthermore, we present two improved methods to facilitate\ncontrastive learning. More specifically, we first propose to construct\npatch-based non-semantic negative samples to boost the noise robustness of the\npre-training model, which is achieved by dividing the features into patches at\ndifferent sizes (i.e., so-called negative samples). Second, by analyzing the\ndistribution of positive and negative samples, we propose to remove the easily\ndistinguishable negative samples to improve the discriminative capacity for\npre-training models. Experimental results on the CHiME-4 dataset show that our\nmethod is able to improve the performance of the pre-trained model in noisy\nscenarios. We find that joint training of the contrastive learning and\nregression tasks can avoid the model collapse to some extent compared to only\ntraining the regression task.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Qiu-Shi Zhu",
      "Long Zhou",
      "Jie Zhang",
      "Shu-Jie Liu",
      "Yu-Chen Hu",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15324"
  },
  {
    "id": "arXiv:2210.15325",
    "title": "Geodesic packing in graphs",
    "abstract": "Given a graph $G$, a geodesic packing in $G$ is a set of vertex-disjoint\nmaximal geodesics, and the geodesic packing number of $G$, ${\\gpack}(G)$, is\nthe maximum cardinality of a geodesic packing in $G$. It is proved that the\ndecision version of the geodesic packing number is NP-complete. We also\nconsider the geodesic transversal number, ${\\gt}(G)$, which is the minimum\ncardinality of a set of vertices that hit all maximal geodesics in $G$. While\n$\\gt(G)\\ge \\gpack(G)$ in every graph $G$, the quotient ${\\rm gt}(G)/{\\rm\ngpack}(G)$ is investigated. By using the rook's graph, it is proved that there\ndoes not exist a constant $C < 3$ such that $\\frac{{\\rm gt}(G)}{{\\rm\ngpack}(G)}\\le C$ would hold for all graphs $G$. If $T$ is a tree, then it is\nproved that ${\\rm gpack}(T) = {\\rm gt}(T)$, and a linear algorithm for\ndetermining ${\\rm gpack}(T)$ is derived. The geodesic packing number is also\ndetermined for the strong product of paths.",
    "descriptor": "",
    "authors": [
      "Paul Manuel",
      "Bostjan Bresar",
      "Sandi Klavzar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.15325"
  },
  {
    "id": "arXiv:2210.15336",
    "title": "Multi-class Detection of Pathological Speech with Latent Features: How  does it perform on unseen data?",
    "abstract": "The detection of pathologies from speech features is usually defined as a\nbinary classification task with one class representing a specific pathology and\nthe other class representing healthy speech. In this work, we train neural\nnetworks, large margin classifiers, and tree boosting machines to distinguish\nbetween four different pathologies: Parkinson's disease, laryngeal cancer,\ncleft lip and palate, and oral squamous cell carcinoma. We demonstrate that\nlatent representations extracted at different layers of a pre-trained wav2vec\n2.0 system can be effectively used to classify these types of pathological\nvoices. We evaluate the robustness of our classifiers by adding room impulse\nresponses to the test data and by applying them to unseen speech corpora. Our\napproach achieves unweighted average F1-Scores between 74.1% and 96.4%,\ndepending on the model and the noise conditions used. The systems generalize\nand perform well on unseen data of healthy speakers sampled from a variety of\ndifferent sources.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Franziska Braun",
      "Sebastian P. Bayerl",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15336"
  },
  {
    "id": "arXiv:2210.15340",
    "title": "Sample-Specific Root Causal Inference with Latent Variables",
    "abstract": "Root causal analysis seeks to identify the set of initial perturbations that\ninduce an unwanted outcome. In prior work, we defined sample-specific root\ncauses of disease using exogenous error terms that predict a diagnosis in a\nstructural equation model. We rigorously quantified predictivity using Shapley\nvalues. However, the associated algorithms for inferring root causes assume no\nlatent confounding. We relax this assumption by permitting confounding among\nthe predictors. We then introduce a corresponding procedure called Extract\nErrors with Latents (EEL) for recovering the error terms up to contamination by\nvertices on certain paths under the linear non-Gaussian acyclic model. EEL also\nidentifies the smallest sets of dependent errors for fast computation of the\nShapley values. The algorithm bypasses the hard problem of estimating the\nunderlying causal graph in both cases. Experiments highlight the superior\naccuracy and robustness of EEL relative to its predecessors.",
    "descriptor": "",
    "authors": [
      "Eric V. Strobl",
      "Thomas A. Lasko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.15340"
  },
  {
    "id": "arXiv:2210.15345",
    "title": "PopArt: Efficient Sparse Regression and Experimental Design for Optimal  Sparse Linear Bandits",
    "abstract": "In sparse linear bandits, a learning agent sequentially selects an action and\nreceive reward feedback, and the reward function depends linearly on a few\ncoordinates of the covariates of the actions. This has applications in many\nreal-world sequential decision making problems. In this paper, we propose a\nsimple and computationally efficient sparse linear estimation method called\nPopArt that enjoys a tighter $\\ell_1$ recovery guarantee compared to Lasso\n(Tibshirani, 1996) in many problems. Our bound naturally motivates an\nexperimental design criterion that is convex and thus computationally efficient\nto solve. Based on our novel estimator and design criterion, we derive sparse\nlinear bandit algorithms that enjoy improved regret upper bounds upon the state\nof the art (Hao et al., 2020), especially w.r.t. the geometry of the given\naction set. Finally, we prove a matching lower bound for sparse linear bandits\nin the data-poor regime, which closes the gap between upper and lower bounds in\nprior work.",
    "descriptor": "\nComments: 10 pages, 1 figures, to be published in 2022 Conference on Neural Information Processing Systems\n",
    "authors": [
      "Kyoungseok Jang",
      "Chicheng Zhang",
      "Kwang-Sung Jun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15345"
  },
  {
    "id": "arXiv:2210.15366",
    "title": "Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification",
    "abstract": "Most existing deep learning-based acoustic scene classification (ASC)\napproaches directly utilize representations extracted from spectrograms to\nidentify target scenes. However, these approaches pay little attention to the\naudio events occurring in the scene despite they provide crucial semantic\ninformation. This paper conducts the first study to investigate whether\nreal-life acoustic scenes can be reliably recognized based only on the features\nthat describe a limited number of audio events. To model the task-specific\nrelationships between coarse-grained acoustic scenes and fine-grained audio\nevents, we propose an event relational graph representation learning (ERGL)\nframework for ASC. Specifically, the ERGL learns a graph representation of an\nacoustic scene from the input audio, where the embedding of each event is\ntreated as a node, while the relationship cues derived from each pair of event\nembeddings are described by a learned multi-dimensional edge feature.\nExperiments on a polyphonic acoustic scene dataset show that the proposed ERGL\nachieves competitive performance on ASC by using only a limited number of\nembeddings of audio events without any data augmentations. The validity of the\nproposed ERGL framework proves the feasibility of recognizing diverse acoustic\nscenes based on the event relational graph. Our code is available on project\nhomepage (https://github.com/Yuanbo2020/ERGL).",
    "descriptor": "",
    "authors": [
      "Yuanbo Hou",
      "Siyang Song",
      "Chuang Yu",
      "Yuxin Song",
      "Wenwu Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15366"
  },
  {
    "id": "arXiv:2210.15371",
    "title": "Meta-Learning Initializations for Interactive Medical Image Registration",
    "abstract": "We present a meta-learning framework for interactive medical image\nregistration. Our proposed framework comprises three components: a\nlearning-based medical image registration algorithm, a form of user interaction\nthat refines registration at inference, and a meta-learning protocol that\nlearns a rapidly adaptable network initialization. This paper describes a\nspecific algorithm that implements the registration, interaction and\nmeta-learning protocol for our exemplar clinical application: registration of\nmagnetic resonance (MR) imaging to interactively acquired, sparsely-sampled\ntransrectal ultrasound (TRUS) images. Our approach obtains comparable\nregistration error (4.26 mm) to the best-performing non-interactive\nlearning-based 3D-to-3D method (3.97 mm) while requiring only a fraction of the\ndata, and occurring in real-time during acquisition. Applying sparsely sampled\ndata to non-interactive methods yields higher registration errors (6.26 mm),\ndemonstrating the effectiveness of interactive MR-TRUS registration, which may\nbe applied intraoperatively given the real-time nature of the adaptation\nprocess.",
    "descriptor": "\nComments: 11 pages, 10 figures. Paper accepted to IEEE Transactions on Medical Imaging (October 26 2022)\n",
    "authors": [
      "Zachary M.C. Baum",
      "Yipeng Hu",
      "Dean Barratt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15371"
  },
  {
    "id": "arXiv:2210.15385",
    "title": "Self-Supervised Training of Speaker Encoder with Multi-Modal Diverse  Positive Pairs",
    "abstract": "We study a novel neural architecture and its training strategies of speaker\nencoder for speaker recognition without using any identity labels. The speaker\nencoder is trained to extract a fixed-size speaker embedding from a spoken\nutterance of various length. Contrastive learning is a typical self-supervised\nlearning technique. However, the quality of the speaker encoder depends very\nmuch on the sampling strategy of positive and negative pairs. It is common that\nwe sample a positive pair of segments from the same utterance. Unfortunately,\nsuch poor-man's positive pairs (PPP) lack necessary diversity for the training\nof a robust encoder. In this work, we propose a multi-modal contrastive\nlearning technique with novel sampling strategies. By cross-referencing between\nspeech and face data, we study a method that finds diverse positive pairs (DPP)\nfor contrastive learning, thus improving the robustness of the speaker encoder.\nWe train the speaker encoder on the VoxCeleb2 dataset without any speaker\nlabels, and achieve an equal error rate (EER) of 2.89\\%, 3.17\\% and 6.27\\%\nunder the proposed progressive clustering strategy, and an EER of 1.44\\%,\n1.77\\% and 3.27\\% under the two-stage learning strategy with pseudo labels, on\nthe three test sets of VoxCeleb1. This novel solution outperforms the\nstate-of-the-art self-supervised learning methods by a large margin, at the\nsame time, achieves comparable results with the supervised learning\ncounterpart. We also evaluate our self-supervised learning technique on LRS2\nand LRW datasets, where the speaker information is unknown. All experiments\nsuggest that the proposed neural architecture and sampling strategies are\nrobust across datasets.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ruijie Tao",
      "Kong Aik Lee",
      "Rohan Kumar Das",
      "Ville Hautam\u00e4ki",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15385"
  },
  {
    "id": "arXiv:2210.15393",
    "title": "Efficient Learning of Decision-Making Models: A Penalty Block Coordinate  Descent Algorithm for Data-Driven Inverse Optimization",
    "abstract": "Decision-making problems are commonly formulated as optimization problems,\nwhich are then solved to make optimal decisions. In this work, we consider the\ninverse problem where we use prior decision data to uncover the underlying\ndecision-making process in the form of a mathematical optimization model. This\nstatistical learning problem is referred to as data-driven inverse\noptimization. We focus on problems where the underlying decision-making process\nis modeled as a convex optimization problem whose parameters are unknown. We\nformulate the inverse optimization problem as a bilevel program and propose an\nefficient block coordinate descent-based algorithm to solve large problem\ninstances. Numerical experiments on synthetic datasets demonstrate the\ncomputational advantage of our method compared to standard commercial solvers.\nMoreover, the real-world utility of the proposed approach is highlighted\nthrough two realistic case studies in which we consider estimating risk\npreferences and learning local constraint parameters of agents in a multiplayer\nNash bargaining game.",
    "descriptor": "",
    "authors": [
      "Rishabh Gupta",
      "Qi Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15393"
  },
  {
    "id": "arXiv:2210.15396",
    "title": "Quantum security of subset cover problems",
    "abstract": "The subset cover problem for $k \\geq 1$ hash functions, which can be seen as\nan extension of the collision problem, was introduced in 2002 by Reyzin and\nReyzin to analyse the security of their hash-function based signature scheme\nHORS.\nThe security of many hash-based signature schemes relies on this problem or a\nvariant of this problem (e.g. HORS, SPHINCS, SPHINCS+, \\dots).\nRecently, Yuan, Tibouchi and Abe (2022) introduced a variant to the subset\ncover problem, called restricted subset cover, and proposed a quantum algorithm\nfor this problem. In this work, we prove that any quantum algorithm needs to\nmake $\\Omega\\left(k^{-\\frac{2^{k-1}}{2^k-1}}\\cdot\nN^{\\frac{2^{k-1}-1}{2^k-1}}\\right)$ queries to the underlying hash functions to\nsolve the restricted subset cover problem, which essentially matches the query\ncomplexity of the algorithm proposed by Yuan, Tibouchi and Abe.\nWe also analyze the security of the general $(r,k)$-subset cover problem,\nwhich is the underlying problem that implies the unforgeability of HORS under a\n$r$-chosen message attack (for $r \\geq 1$). We prove that a generic quantum\nalgorithm needs to make $\\Omega\\left(N^{k/5}\\right)$ queries to the underlying\nhash functions to find a $(1,k)$-subset cover.\nWe also propose a quantum algorithm that finds a $(r,k)$-subset cover making\n$O\\left(N^{k/(2+2r)}\\right)$ queries to the $k$ hash functions.",
    "descriptor": "",
    "authors": [
      "Samuel Bouaziz--Ermann",
      "Alex B. Grilo",
      "Damien Vergnaud"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15396"
  },
  {
    "id": "arXiv:2210.15407",
    "title": "Model Order Selection with Variational Autoencoding",
    "abstract": "Classical methods for model order selection often fail in scenarios with low\nSNR or few snapshots. Deep learning based methods are promising alternatives\nfor such challenging situations as they compensate lack of information in\nobservations with repeated training on large datasets. This manuscript proposes\nan approach that uses a variational autoencoder (VAE) for model order\nselection. The idea is to learn a parameterized conditional covariance matrix\nat the VAE decoder that approximates the true signal covariance matrix. The\nmethod itself is unsupervised and only requires a small representative dataset\nfor calibration purposes after training of the VAE. Numerical simulations show\nthat the proposed method clearly outperforms classical methods and even reaches\nor beats a supervised approach depending on the considered snapshots.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication\n",
    "authors": [
      "Michael Baur",
      "Franz Wei\u00dfer",
      "Benedikt B\u00f6ck",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15407"
  },
  {
    "id": "arXiv:2210.15425",
    "title": "HEiMDaL: Highly Efficient Method for Detection and Localization of  wake-words",
    "abstract": "Streaming keyword spotting is a widely used solution for activating voice\nassistants. Deep Neural Networks with Hidden Markov Model (DNN-HMM) based\nmethods have proven to be efficient and widely adopted in this space, primarily\nbecause of the ability to detect and identify the start and end of the wake-up\nword at low compute cost. However, such hybrid systems suffer from loss metric\nmismatch when the DNN and HMM are trained independently. Sequence\ndiscriminative training cannot fully mitigate the loss-metric mismatch due to\nthe inherent Markovian style of the operation. We propose an low footprint CNN\nmodel, called HEiMDaL, to detect and localize keywords in streaming conditions.\nWe introduce an alignment-based classification loss to detect the occurrence of\nthe keyword along with an offset loss to predict the start of the keyword.\nHEiMDaL shows 73% reduction in detection metrics along with equivalent\nlocalization accuracy and with the same memory footprint as existing DNN-HMM\nstyle models for a given wake-word.",
    "descriptor": "",
    "authors": [
      "Arnav Kundu",
      "Mohammad Samragh Razlighi",
      "Minsik Cho",
      "Priyanka Padmanabhan",
      "Devang Naik"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15425"
  },
  {
    "id": "arXiv:2210.15428",
    "title": "Time-Domain Based Embeddings for Spoofed Audio Representation",
    "abstract": "Anti-spoofing is the task of speech authentication. That is, identifying\ngenuine human speech compared to spoofed speech. The main focus of this paper\nis to suggest new representations for genuine and spoofed speech, based on the\nprobability mass function (PMF) estimation of the audio waveforms' amplitude.\nWe introduce a new feature extraction method for speech audio signals: unlike\ntraditional methods, our method is based on direct processing of time-domain\naudio samples. The PMF is utilized by designing a feature extractor based on\ndifferent PMF distances and similarity measures. As an additional step, we used\nfilter-bank preprocessing, which significantly affects the discriminative\ncharacteristics of the features and facilitates convenient visualization of\npossible clustering of spoofing attacks. Furthermore, we use diffusion maps to\nreveal the underlying manifold on which the data lies.\nThe suggested embeddings allow the use of simple linear separators to achieve\ndecent performance. In addition, we present a convenient way to visualize the\ndata, which helps to assess the efficiency of different spoofing techniques.\nThe experimental results show the potential of using multi-channel PMF based\nfeatures for the anti-spoofing task, in addition to the benefits of using\ndiffusion maps both as an analysis tool and as an embedding tool.",
    "descriptor": "",
    "authors": [
      "Matan Karo",
      "Arie Yeredor",
      "Itshak Lapidot"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15428"
  },
  {
    "id": "arXiv:2210.15435",
    "title": "Grokking phase transitions in learning local rules with gradient descent",
    "abstract": "We discuss two solvable grokking (generalisation beyond overfitting) models\nin a rule learning scenario. We show that grokking is a phase transition and\nfind exact analytic expressions for the critical exponents, grokking\nprobability, and grokking time distribution. Further, we introduce a\ntensor-network map that connects the proposed grokking setup with the standard\n(perceptron) statistical learning theory and show that grokking is a\nconsequence of the locality of the teacher model. As an example, we analyse the\ncellular automata learning task, numerically determine the critical exponent\nand the grokking time distributions and compare them with the prediction of the\nproposed grokking model. Finally, we numerically analyse the connection between\nstructure formation and grokking.",
    "descriptor": "\nComments: 31+10 pages, 22 figures\n",
    "authors": [
      "Bojan \u017dunkovi\u010d",
      "Enej Ilievski"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15435"
  },
  {
    "id": "arXiv:2210.15439",
    "title": "Learning versus Refutation in Noninteractive Local Differential Privacy",
    "abstract": "We study two basic statistical tasks in non-interactive local differential\nprivacy (LDP): learning and refutation. Learning requires finding a concept\nthat best fits an unknown target function (from labelled samples drawn from a\ndistribution), whereas refutation requires distinguishing between data\ndistributions that are well-correlated with some concept in the class, versus\ndistributions where the labels are random. Our main result is a complete\ncharacterization of the sample complexity of agnostic PAC learning for\nnon-interactive LDP protocols. We show that the optimal sample complexity for\nany concept class is captured by the approximate $\\gamma_2$~norm of a natural\nmatrix associated with the class. Combined with previous work [Edmonds, Nikolov\nand Ullman, 2019] this gives an equivalence between learning and refutation in\nthe agnostic setting.",
    "descriptor": "",
    "authors": [
      "Alexander Edmonds",
      "Aleksandar Nikolov",
      "Toniann Pitassi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15439"
  },
  {
    "id": "arXiv:2210.15445",
    "title": "Efficient Use of Large Pre-Trained Models for Low Resource ASR",
    "abstract": "Automatic speech recognition (ASR) has been established as a well-performing\ntechnique for many scenarios where lots of labeled data is available.\nAdditionally, unsupervised representation learning recently helped to tackle\ntasks with limited data. Following this, hardware limitations and applications\ngive rise to the question how to efficiently take advantage of large pretrained\nmodels and reduce their complexity for downstream tasks. In this work, we study\na challenging low resource conversational telephony speech corpus from the\nmedical domain in Vietnamese and German. We show the benefits of using\nunsupervised techniques beyond simple fine-tuning of large pre-trained models,\ndiscuss how to adapt them to a practical telephony task including bandwidth\ntransfer and investigate different data conditions for pre-training and\nfine-tuning. We outperform the project baselines by 22% relative using\npretraining techniques. Further gains of 29% can be achieved by refinements of\narchitecture and training and 6% by adding 0.8 h of in-domain adaptation data.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Peter Vieting",
      "Christoph L\u00fcscher",
      "Julian Dierkes",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15445"
  },
  {
    "id": "arXiv:2210.15448",
    "title": "KALMANBOT: KalmanNet-Aided Bollinger Bands for Pairs Trading",
    "abstract": "Pairs trading is a family of trading policies based on monitoring the\nrelationships between pairs of assets. A common pairs trading approach relies\non state space (SS) modeling, from which financial indicators can be obtained\nwith low complexity and latency using a Kalman filter (KF), and processed using\nclassic policies such as Bollinger bands (BB). However, such SS models are\ninherently approximated and mismatched, often degrading the revenue. In this\nwork we propose KalmanBOT, a data-aided policy that preserves the advantages of\nKF-aided BB policies while leveraging data to overcome the approximated nature\nof the SS model. We adopt the recent KalmanNet architecture, and approximate\nthe BB policy with a differentiable mapping, converting the policy into a\ntrainable model. We empirically demonstrate that KalmanBOT yields improved\nrewards compared with model-based and data-driven benchmarks.",
    "descriptor": "",
    "authors": [
      "Haoran Deng",
      "Guy Revach",
      "Hai Morgenstern",
      "Nir Shlezinger"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15448"
  },
  {
    "id": "arXiv:2210.15471",
    "title": "Adaptive Estimation of $\\text{MTP}_2$ Graphical Models",
    "abstract": "We consider the problem of estimating (diagonally dominant) M-matrices as\nprecision matrices in Gaussian graphical models. Such models have received\nincreasing attention in recent years, and have shown interesting properties,\ne.g., the maximum likelihood estimator exists with as little as two\nobservations regardless of the underlying dimension. In this paper, we propose\nan adaptive estimation method, which consists of multiple stages: In the first\nstage, we solve an $\\ell_1$-regularized maximum likelihood estimation problem,\nwhich leads to an initial estimate; in the subsequent stages, we iteratively\nrefine the initial estimate by solving a sequence of weighted\n$\\ell_1$-regularized problems. We further establish the theoretical guarantees\non the estimation error, which consists of optimization error and statistical\nerror. The optimization error decays to zero at a linear rate, indicating that\nthe estimate is refined iteratively in subsequent stages, and the statistical\nerror characterizes the statistical rate. The proposed method outperforms\nstate-of-the-art methods in estimating precision matrices and identifying graph\nedges, as evidenced by synthetic and financial time-series data sets.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Jiaxi Ying",
      "Jos\u00e9 Vin\u00edcius de M. Cardoso",
      "Daniel P. Palomar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15471"
  },
  {
    "id": "arXiv:2210.15493",
    "title": "Predicting Non-Fungible Token (NFT) Collections: A Contextual Generative  Approach",
    "abstract": "Non-fungible tokens (NFTs) are digital assets stored on a blockchain\nrepresenting real-world objects such as art or collectibles. It is a\nmultibillion-dollar market, where the number of NFT collections increased over\n100% in 2022; there are currently more than 80K collections on the Ethereum\nblockchain. Each collection, containing numerous tokens of a particular theme,\nhas its unique characteristics. In this paper, we take a contextual generative\napproach that learns these diverse characteristics of NFT collections and\ngenerates the potential market value predictions of newly minted ones. We model\nNFTs as a series of transactions. First, meaningful contexts capturing the\ncharacteristics of various collections are derived using unsupervised learning.\nNext, our generative approach leverages these contexts to learn better\ncharacterizations of established NFT collections with differing market\ncapitalization values. Finally, given a new collection in an early stage, the\napproach generates future transaction series for this emerging collection.\nComprehensive experiments demonstrate that our approach closely predicts the\npotential value of NFT collections.",
    "descriptor": "",
    "authors": [
      "Wesley Joon-Wie Tann",
      "Akhil Vuputuri",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15493"
  },
  {
    "id": "arXiv:2210.15499",
    "title": "Post trade allocation: how much are bunched orders costing your  performance?",
    "abstract": "Individual trade orders are often bunched into a block order for processing\nefficiency, where in post execution, they are allocated into individual\naccounts. Since Regulators have not mandated any specific post trade allocation\npractice or methodology, entities try to rigorously follow internal policies\nand procedures to meet the minimum Regulatory ask of being procedurally fair\nand equitable. However, as many have found over the years, there is no simple\nsolution for post trade allocation between accounts that results in a uniform\ndistribution of returns. Furthermore, in many instances, the divergences\nbetween returns do not dissipate with more transactions, and tend to increase\nin some cases. This paper is the first systematic treatment of trade allocation\nrisk. We shed light on the reasons for return divergence among accounts, and we\npresent a solution that supports uniform allocation of return irrespective of\nnumber of accounts and trade sizes.",
    "descriptor": "\nComments: 16 pages, 2 figures, 12 tables\n",
    "authors": [
      "Ali Hirsa",
      "Massoud Heidari"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15499"
  },
  {
    "id": "arXiv:2210.15506",
    "title": "Programming with Quantum Mechanics",
    "abstract": "Quantum computing is an emerging paradigm that opens a new era for\nexponential computational speedup. Still, quantum computers have yet to be\nready for commercial use. However, it is essential to train and qualify today\nthe workforce that will develop quantum acceleration solutions to get the\nquantum advantage in the future. This tutorial gives a broad view of quantum\ncomputing, abstracting most of the mathematical formalism and proposing a\nhands-on with the quantum programming language Ket. The target audience is\nundergraduate and graduate students starting in quantum computing -- no\nprerequisites for following this tutorial.",
    "descriptor": "",
    "authors": [
      "Evandro C. R. da Rosa",
      "Claudio Lima"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.15506"
  },
  {
    "id": "arXiv:2210.15509",
    "title": "On Tsirelson pairs of C*-algebras",
    "abstract": "We introduce the notion of a Tsirelson pair of C*-algebras, which is a pair\nof C*-algebras for which the space of quantum strategies obtained by using\nstates on the minimal tensor product of the pair and the space of quantum\nstrategies obtained by using states on the maximal tensor product of the pair\ncoincide. We exhibit a number of examples of such pairs that are ``nontrivial''\nin the sense that the minimal tensor product and the maximal tensor product of\nthe pair are not isomorphic. For example, we prove that any pair containing a\nC*-algebra with Kirchberg's QWEP property is a Tsirelson pair. We then\nintroduce the notion of a C*-algebra with the Tsirelson property (TP) and\nestablish a number of closure properties for this class. We also show that the\nclass of C*-algebras with the TP form an axiomatizable class (in the sense of\nmodel theory), but that this class admits no ``effective'' axiomatization.",
    "descriptor": "\nComments: 14 pages; first draft; comments welcome\n",
    "authors": [
      "Isaac Goldbring",
      "Bradd Hart"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15509"
  },
  {
    "id": "arXiv:2210.15512",
    "title": "Exploiting spatial information with the informed complex-valued spatial  autoencoder for target speaker extraction",
    "abstract": "In conventional multichannel audio signal enhancement, spatial and spectral\nfiltering are often performed sequentially. In contrast, it has been shown that\nfor neural spatial filtering a joint approach of spectro-spatial filtering is\nmore beneficial. In this contribution, we investigate the influence of the\ntraining target on the spatial selectivity of such a time-varying\nspectro-spatial filter. We extend the recently proposed complex-valued spatial\nautoencoder (COSPA) for target speaker extraction by leveraging its\ninterpretable structure and purposefully informing the network of the target\nspeaker's position. Consequently, this approach uses a multichannel\ncomplex-valued neural network architecture that is capable of processing\nspatial and spectral information rendering informed COSPA (iCOSPA) an effective\nneural spatial filtering method. We train iCOSPA for several training targets\nthat enforce different amounts of spatial processing and analyze the network's\nspatial filtering capacity. We find that the proposed architecture is indeed\ncapable of learning different spatial selectivity patterns to attain the\ndifferent training targets.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Rhodes Island, Greece. 5 pages, 3 figures\n",
    "authors": [
      "Annika Briegleb",
      "Mhd Modar Halimeh",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15512"
  },
  {
    "id": "arXiv:2210.15513",
    "title": "Lifelong Bandit Optimization: No Prior and No Regret",
    "abstract": "In practical applications, machine learning algorithms are often repeatedly\napplied to problems with similar structure over and over again. We focus on\nsolving a sequence of bandit optimization tasks and develop LiBO, an algorithm\nwhich adapts to the environment by learning from past experience and becoming\nmore sample-efficient in the process. We assume a kernelized structure where\nthe kernel is unknown but shared across all tasks. LiBO sequentially\nmeta-learns a kernel that approximates the true kernel and simultaneously\nsolves the incoming tasks with the latest kernel estimate. Our algorithm can be\npaired with any kernelized bandit algorithm and guarantees oracle optimal\nperformance, meaning that as more tasks are solved, the regret of LiBO on each\ntask converges to the regret of the bandit algorithm with oracle knowledge of\nthe true kernel. Naturally, if paired with a sublinear bandit algorithm, LiBO\nyields a sublinear lifelong regret. We also show that direct access to the data\nfrom each task is not necessary for attaining sublinear regret. The lifelong\nproblem can thus be solved in a federated manner, while keeping the data of\neach task private.",
    "descriptor": "\nComments: 32 pages, 6 figures, preprint\n",
    "authors": [
      "Felix Schur",
      "Parnian Kassraie",
      "Jonas Rothfuss",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15513"
  },
  {
    "id": "arXiv:2210.15539",
    "title": "Deep Convolutional Neural Networks for Multi-Target Tracking: A Transfer  Learning Approach",
    "abstract": "Multi-target tracking (MTT) is a traditional signal processing task, where\nthe goal is to estimate the states of an unknown number of moving targets from\nnoisy sensor measurements. In this paper, we revisit MTT from a deep learning\nperspective and propose convolutional neural network (CNN) architectures to\ntackle it. We represent the target states and sensor measurements as images.\nThereby we recast the problem as a image-to-image prediction task for which we\ntrain a fully convolutional model. This architecture is motivated by a novel\ntheoretical bound on the transferability error of CNN. The proposed CNN\narchitecture outperforms a GM-PHD filter on the MTT task with 10 targets. The\nCNN performance transfers without re-training to a larger MTT task with 250\ntargets with only a $13\\%$ increase in average OSPA.",
    "descriptor": "\nComments: 5 pages, 4 figures; submitted to Proc. ICASSP2023, June 04-09, 2023, Rhodes Island, Greece; Associated code is available at this https URL\n",
    "authors": [
      "Damian Owerko",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro",
      "Donald J. Bucci Jr",
      "Jennifer Bondarchuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15539"
  },
  {
    "id": "arXiv:2210.15566",
    "title": "UNet-2022: Exploring Dynamics in Non-isomorphic Architecture",
    "abstract": "Recent medical image segmentation models are mostly hybrid, which integrate\nself-attention and convolution layers into the non-isomorphic architecture.\nHowever, one potential drawback of these approaches is that they failed to\nprovide an intuitive explanation of why this hybrid combination manner is\nbeneficial, making it difficult for subsequent work to make improvements on top\nof them. To address this issue, we first analyze the differences between the\nweight allocation mechanisms of the self-attention and convolution. Based on\nthis analysis, we propose to construct a parallel non-isomorphic block that\ntakes the advantages of self-attention and convolution with simple\nparallelization. We name the resulting U-shape segmentation model as UNet-2022.\nIn experiments, UNet-2022 obviously outperforms its counterparts in a range\nsegmentation tasks, including abdominal multi-organ segmentation, automatic\ncardiac diagnosis, neural structures segmentation, and skin lesion\nsegmentation, sometimes surpassing the best performing baseline by 4%.\nSpecifically, UNet-2022 surpasses nnUNet, the most recognized segmentation\nmodel at present, by large margins. These phenomena indicate the potential of\nUNet-2022 to become the model of choice for medical image segmentation.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Jiansen Guo",
      "Hong-Yu Zhou",
      "Liansheng Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15566"
  },
  {
    "id": "arXiv:2210.15571",
    "title": "Full-scale Deeply Supervised Attention Network for Segmenting COVID-19  Lesions",
    "abstract": "Automated delineation of COVID-19 lesions from lung CT scans aids the\ndiagnosis and prognosis for patients. The asymmetric shapes and positioning of\nthe infected regions make the task extremely difficult. Capturing information\nat multiple scales will assist in deciphering features, at global and local\nlevels, to encompass lesions of variable size and texture. We introduce the\nFull-scale Deeply Supervised Attention Network (FuDSA-Net), for efficient\nsegmentation of corona-infected lung areas in CT images. The model considers\nactivation responses from all levels of the encoding path, encompassing\nmulti-scalar features acquired at different levels of the network. This helps\nsegment target regions (lesions) of varying shape, size and contrast.\nIncorporation of the entire gamut of multi-scalar characteristics into the\nnovel attention mechanism helps prioritize the selection of activation\nresponses and locations containing useful information. Determining robust and\ndiscriminatory features along the decoder path is facilitated with deep\nsupervision. Connections in the decoder arm are remodeled to handle the issue\nof vanishing gradient. As observed from the experimental results, FuDSA-Net\nsurpasses other state-of-the-art architectures; especially, when it comes to\ncharacterizing complicated geometries of the lesions.",
    "descriptor": "",
    "authors": [
      "Pallabi Dutta",
      "Sushmita Mitra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15571"
  },
  {
    "id": "arXiv:2210.15601",
    "title": "Discrete Bulk Reconstruction",
    "abstract": "According to the AdS/CFT correspondence, the geometries of certain spacetimes\nare fully determined by quantum states that live on their boundaries -- indeed,\nby the von Neumann entropies of portions of those boundary states. This work\ninvestigates to what extent the geometries can be reconstructed from the\nentropies in polynomial time. Bouland, Fefferman, and Vazirani (2019) argued\nthat the AdS/CFT map can be exponentially complex if one wants to reconstruct\nregions such as the interiors of black holes. Our main result provides a sort\nof converse: we show that, in the special case of a single 1D boundary, if the\ninput data consists of a list of entropies of contiguous boundary regions, and\nif the entropies satisfy a single inequality called Strong Subadditivity, then\nwe can construct a graph model for the bulk in linear time. Moreover, the bulk\ngraph is planar, it has $O(N^2)$ vertices (the information-theoretic minimum),\nand it's ``universal,'' with only the edge weights depending on the specific\nentropies in question. From a combinatorial perspective, our problem boils down\nto an ``inverse'' of the famous min-cut problem: rather than being given a\ngraph and asked to find a min-cut, here we're given the values of min-cuts\nseparating various sets of vertices, and need to find a weighted undirected\ngraph consistent with those values. Our solution to this problem relies on the\nnotion of a ``bulkless'' graph, which might be of independent interest for\nAdS/CFT. We also make initial progress on the case of multiple 1D boundaries --\nwhere the boundaries could be connected via wormholes -- including an upper\nbound of $O(N^4)$ vertices whenever a planar bulk graph exists (thus putting\nthe problem into the complexity class $\\mathsf{NP}$).",
    "descriptor": "\nComments: 41 pages, 18 figures; submitted to QIP 2023. Comments welcomed!\n",
    "authors": [
      "Scott Aaronson",
      "Jason Pollack"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2210.15601"
  },
  {
    "id": "arXiv:2210.15609",
    "title": "The formal verification of the ctm approach to forcing",
    "abstract": "We discuss some highlights of our computer-verified proof of the\nconstruction, given a countable transitive set-model $M$ of $\\mathit{ZFC}$, of\ngeneric extensions satisfying $\\mathit{ZFC}+\\neg\\mathit{CH}$ and\n$\\mathit{ZFC}+\\mathit{CH}$. Moreover, let $\\mathcal{R}$ be the set of instances\nof the Axiom of Replacement. We isolated a 21-element subset\n$\\Omega\\subseteq\\mathcal{R}$ and defined\n$\\mathcal{F}:\\mathcal{R}\\to\\mathcal{R}$ such that for every\n$\\Phi\\subseteq\\mathcal{R}$ and $M$-generic $G$, $M\\models \\mathit{ZC} \\cup\n\\mathcal{F}\\text{``}\\Phi \\cup \\Omega$ implies $M[G]\\models \\mathit{ZC} \\cup\n\\Phi \\cup \\{ \\neg \\mathit{CH} \\}$, where $\\mathit{ZC}$ is Zermelo set theory\nwith Choice.\nTo achieve this, we worked in the proof assistant Isabelle, basing our\ndevelopment on the Isabelle/ZF library by L. Paulson and others.",
    "descriptor": "\nComments: 20pp + 14pp in bibliography & appendices, 2 tables\n",
    "authors": [
      "Emmanuel Gunther",
      "Miguel Pagano",
      "Pedro S\u00e1nchez Terraf",
      "Mat\u00edas Steinberg"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.15609"
  },
  {
    "id": "arXiv:2210.15631",
    "title": "Exploring Effective Distillation of Self-Supervised Speech Models for  Automatic Speech Recognition",
    "abstract": "Recent years have witnessed great strides in self-supervised learning (SSL)\non the speech processing. The SSL model is normally pre-trained on a great\nvariety of unlabelled data and a large model size is preferred to increase the\nmodeling capacity. However, this might limit its potential applications due to\nthe expensive computation and memory costs introduced by the oversize model.\nMiniaturization for SSL models has become an important research direction of\npractical value. To this end, we explore the effective distillation of\nHuBERT-based SSL models for automatic speech recognition (ASR). First, in order\nto establish a strong baseline, a comprehensive study on different student\nmodel structures is conducted. On top of this, as a supplement to the\nregression loss widely adopted in previous works, a discriminative loss is\nintroduced for HuBERT to enhance the distillation performance, especially in\nlow-resource scenarios. In addition, we design a simple and effective algorithm\nto distill the front-end input from waveform to Fbank feature, resulting in 17%\nparameter reduction and doubling inference speed, at marginal performance\ndegradation.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yujin Wang",
      "Changli Tang",
      "Ziyang Ma",
      "Zhisheng Zheng",
      "Xie Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15631"
  },
  {
    "id": "arXiv:2210.15659",
    "title": "Revisiting the ACVI Method for Constrained Variational Inequalities",
    "abstract": "ACVI is a recently proposed first-order method for solving variational\ninequalities (VIs) with general constraints. Yang et al. (2022) showed that the\ngap function of the last iterate decreases at a rate of\n$\\mathcal{O}(\\frac{1}{\\sqrt{K}})$ when the operator is $L$-Lipschitz, monotone,\nand at least one constraint is active.\nIn this work, we show that the same guarantee holds when only assuming that\nthe operator is monotone.\nTo our knowledge, this is the first analytically derived last-iterate\nconvergence rate for general monotone VIs, and overall the only one that does\nnot rely on the assumption that the operator is $L$-Lipschitz.\nFurthermore, when the sub-problems of ACVI are solved approximately, we show\nthat by using a standard warm-start technique the convergence rate stays the\nsame, provided that the errors decrease at appropriate rates.\nWe further provide empirical analyses and insights on its implementation for\nthe latter case.",
    "descriptor": "",
    "authors": [
      "Tatjana Chavdarova",
      "Matteo Pagliardini",
      "Tong Yang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15659"
  },
  {
    "id": "arXiv:1810.00226",
    "title": "Toward single particle reconstruction without particle picking: Breaking  the detection limit",
    "abstract": "Comments: Older citations to this paper refer to version arXiv:1810.00226v1, parts of which now appear in: Tamir Bendory, Nicolas Boumal, William Leeb, Eitan Levin, and Amit Singer. \"Multi-target detection with application to cryo-electron microscopy.\" Inverse Problems 35, no. 10 (2019): 104003",
    "descriptor": "\nComments: Older citations to this paper refer to version arXiv:1810.00226v1, parts of which now appear in: Tamir Bendory, Nicolas Boumal, William Leeb, Eitan Levin, and Amit Singer. \"Multi-target detection with application to cryo-electron microscopy.\" Inverse Problems 35, no. 10 (2019): 104003\n",
    "authors": [
      "Tamir Bendory",
      "Nicolas Boumal",
      "William Leeb",
      "Eitan Levin",
      "Amit Singer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1810.00226"
  },
  {
    "id": "arXiv:1905.05655",
    "title": "Online Computation with Untrusted Advice",
    "abstract": "Online Computation with Untrusted Advice",
    "descriptor": "",
    "authors": [
      "Spyros Angelopoulos",
      "Christoph D\u00fcrr",
      "Shendan Jin",
      "Shahin Kamali",
      "Marc Renault"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1905.05655"
  },
  {
    "id": "arXiv:2003.00545",
    "title": "Simple Mechanisms for Agents with Non-linear Utilities",
    "abstract": "Simple Mechanisms for Agents with Non-linear Utilities",
    "descriptor": "",
    "authors": [
      "Yiding Feng",
      "Jason Hartline",
      "Yingkai Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2003.00545"
  },
  {
    "id": "arXiv:2005.07045",
    "title": "Efficient and Stable Algorithms to Extend Greville's Method to  Partitioned Matrices Based on Inverse Cholesky Factorization",
    "abstract": "Efficient and Stable Algorithms to Extend Greville's Method to  Partitioned Matrices Based on Inverse Cholesky Factorization",
    "descriptor": "",
    "authors": [
      "Hufei Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.07045"
  },
  {
    "id": "arXiv:2007.13140",
    "title": "Fully Bayesian Analysis of the Relevance Vector Machine Classification  for Imbalanced Data",
    "abstract": "Comments: The extended and final version of this paper has been published with open access modality in the CAAI Transactions on Intelligence Technology and can be found at link this https URL Please refer to the TRIT published version in your scientific papers",
    "descriptor": "\nComments: The extended and final version of this paper has been published with open access modality in the CAAI Transactions on Intelligence Technology and can be found at link this https URL Please refer to the TRIT published version in your scientific papers\n",
    "authors": [
      "Wenyang Wang",
      "Dongchu Sun",
      "Zhuoqiong He"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.13140"
  },
  {
    "id": "arXiv:2008.09682",
    "title": "DecoMine: A Compilation-Based Graph Pattern Mining System with Pattern  Decomposition",
    "abstract": "DecoMine: A Compilation-Based Graph Pattern Mining System with Pattern  Decomposition",
    "descriptor": "",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2008.09682"
  },
  {
    "id": "arXiv:2010.06154",
    "title": "An Analysis of Robustness of Non-Lipschitz Networks",
    "abstract": "Comments: 42 pages, 9 figures",
    "descriptor": "\nComments: 42 pages, 9 figures\n",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Dravyansh Sharma",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.06154"
  },
  {
    "id": "arXiv:2010.09091",
    "title": "Colourings of $(m, n)$-coloured mixed graphs",
    "abstract": "Comments: 7 pages, no figures",
    "descriptor": "\nComments: 7 pages, no figures\n",
    "authors": [
      "Gary MacGillivray",
      "Shahla Nasserasr",
      "Feiran Yang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2010.09091"
  },
  {
    "id": "arXiv:2011.01455",
    "title": "Distributed Machine Learning with Strategic Network Design: A  Game-Theoretic Perspective",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Shutian Liu",
      "Tao Li",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.01455"
  },
  {
    "id": "arXiv:2011.05466",
    "title": "Incorporating Causal Effects into Deep Learning Predictions on EHR Data",
    "abstract": "Comments: 10 pages, 8 figures, in process of SDM",
    "descriptor": "\nComments: 10 pages, 8 figures, in process of SDM\n",
    "authors": [
      "Jia Li",
      "Haoyu Yang",
      "Xiaowei Jia",
      "Vipin Kumar",
      "Michael Steinbach",
      "Gyorgy Simon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05466"
  },
  {
    "id": "arXiv:2012.12607",
    "title": "PTAS for Sparse General-Valued CSPs",
    "abstract": "Comments: Full version of a LICS 2021 paper",
    "descriptor": "\nComments: Full version of a LICS 2021 paper\n",
    "authors": [
      "Bal\u00e1zs F. Mezei",
      "Marcin Wrochna",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.12607"
  },
  {
    "id": "arXiv:2103.15960",
    "title": "Demonstrating Analog Inference on the BrainScaleS-2 Mobile System",
    "abstract": "Demonstrating Analog Inference on the BrainScaleS-2 Mobile System",
    "descriptor": "",
    "authors": [
      "Yannik Stradmann",
      "Sebastian Billaudelle",
      "Oliver Breitwieser",
      "Falk Leonard Ebert",
      "Arne Emmel",
      "Dan Husmann",
      "Joscha Ilmberger",
      "Eric M\u00fcller",
      "Philipp Spilger",
      "Johannes Weis",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.15960"
  },
  {
    "id": "arXiv:2104.06763",
    "title": "Oracle Complexity in Nonsmooth Nonconvex Optimization",
    "abstract": "Comments: Accepted to Journal of Machine Learning Research (JMLR); some minor edits following reviews",
    "descriptor": "\nComments: Accepted to Journal of Machine Learning Research (JMLR); some minor edits following reviews\n",
    "authors": [
      "Guy Kornowski",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06763"
  },
  {
    "id": "arXiv:2105.03789",
    "title": "Khuzdul: Efficient and Scalable Distributed Graph Pattern Mining Engine",
    "abstract": "Khuzdul: Efficient and Scalable Distributed Graph Pattern Mining Engine",
    "descriptor": "",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.03789"
  },
  {
    "id": "arXiv:2105.07703",
    "title": "The effect of algorithmic bias and network structure on coexistence,  consensus, and polarization of opinions",
    "abstract": "The effect of algorithmic bias and network structure on coexistence,  consensus, and polarization of opinions",
    "descriptor": "",
    "authors": [
      "Antonio F. Peralta",
      "Matteo Neri",
      "J\u00e1nos Kert\u00e9sz",
      "Gerardo I\u00f1iguez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.07703"
  },
  {
    "id": "arXiv:2105.08013",
    "title": "What makes you unique?",
    "abstract": "What makes you unique?",
    "descriptor": "",
    "authors": [
      "Benjamin B. Seiler",
      "Masayoshi Mase",
      "Art B. Owen"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08013"
  },
  {
    "id": "arXiv:2105.14016",
    "title": "Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs  with a Generative Model",
    "abstract": "Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs  with a Generative Model",
    "descriptor": "",
    "authors": [
      "Bingyan Wang",
      "Yuling Yan",
      "Jianqing Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14016"
  },
  {
    "id": "arXiv:2106.01008",
    "title": "Convergence and Complexity of an Adaptive Planewave Method for  Eigenvalue Computations",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Xiaoying Dai",
      "Yan Pan",
      "Bin Yang",
      "Aihui Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01008"
  },
  {
    "id": "arXiv:2106.04140",
    "title": "Broadcasted Residual Learning for Efficient Keyword Spotting",
    "abstract": "Comments: Proceedings of INTERSPEECH 2021",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2021\n",
    "authors": [
      "Byeonggeun Kim",
      "Simyung Chang",
      "Jinkyu Lee",
      "Dooyong Sung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.04140"
  },
  {
    "id": "arXiv:2106.06965",
    "title": "Contrastive Attention for Automatic Chest X-ray Report Generation",
    "abstract": "Comments: Appear in Findings of ACL 2021 (The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021))",
    "descriptor": "\nComments: Appear in Findings of ACL 2021 (The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021))\n",
    "authors": [
      "Xuewei Ma",
      "Fenglin Liu",
      "Changchang Yin",
      "Xian Wu",
      "Shen Ge",
      "Yuexian Zou",
      "Ping Zhang",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06965"
  },
  {
    "id": "arXiv:2106.15047",
    "title": "Benchmarking Knowledge-driven Zero-shot Learning",
    "abstract": "Comments: Published in Journal of Web Semantics, 2022. Final version please refer to our Github repository!",
    "descriptor": "\nComments: Published in Journal of Web Semantics, 2022. Final version please refer to our Github repository!\n",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Xiang Zhuang",
      "Zhuo Chen",
      "Jeff Z. Pan",
      "Juan Li",
      "Zonggang Yuan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15047"
  },
  {
    "id": "arXiv:2107.07110",
    "title": "Compact and Optimal Deep Learning with Recurrent Parameter Generators",
    "abstract": "Compact and Optimal Deep Learning with Recurrent Parameter Generators",
    "descriptor": "",
    "authors": [
      "Jiayun Wang",
      "Yubei Chen",
      "Stella X. Yu",
      "Brian Cheung",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07110"
  },
  {
    "id": "arXiv:2107.09249",
    "title": "Self-Supervised Aggregation of Diverse Experts for Test-Agnostic  Long-Tailed Recognition",
    "abstract": "Comments: NeurIPS 2022. Source code: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Source code: this https URL\n",
    "authors": [
      "Yifan Zhang",
      "Bryan Hooi",
      "Lanqing Hong",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09249"
  },
  {
    "id": "arXiv:2109.02903",
    "title": "IndicBART: A Pre-trained Model for Indic Natural Language Generation",
    "abstract": "Comments: Published at ACL 2022, 15 pages",
    "descriptor": "\nComments: Published at ACL 2022, 15 pages\n",
    "authors": [
      "Raj Dabre",
      "Himani Shrotriya",
      "Anoop Kunchukuttan",
      "Ratish Puduppully",
      "Mitesh M. Khapra",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02903"
  },
  {
    "id": "arXiv:2109.08079",
    "title": "Context-NER : Contextual Phrase Generation at Scale",
    "abstract": "Comments: 12 pages, 2 Figures, 1 Algorithm, 8 Tables. Accepted in NeurIPS 2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop",
    "descriptor": "\nComments: 12 pages, 2 Figures, 1 Algorithm, 8 Tables. Accepted in NeurIPS 2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop\n",
    "authors": [
      "Himanshu Gupta",
      "Shreyas Verma",
      "Swaroop Mishra",
      "Tamanna Agrawal",
      "Amogh Badugu",
      "Himanshu Sharad Bhatt"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08079"
  },
  {
    "id": "arXiv:2110.01005",
    "title": "Cerberus: Query-driven Scalable Vulnerability Detection in OAuth Service  Provider Implementations",
    "abstract": "Comments: ACM Conference on Computer and Communications Security (CCS 2022)",
    "descriptor": "\nComments: ACM Conference on Computer and Communications Security (CCS 2022)\n",
    "authors": [
      "Tamjid Al Rahat",
      "Yu Feng",
      "Yuan Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.01005"
  },
  {
    "id": "arXiv:2110.04993",
    "title": "On the energy landscape of symmetric quantum signal processing",
    "abstract": "Comments: 48 pages, 6 figures",
    "descriptor": "\nComments: 48 pages, 6 figures\n",
    "authors": [
      "Jiasu Wang",
      "Yulong Dong",
      "Lin Lin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04993"
  },
  {
    "id": "arXiv:2110.05668",
    "title": "NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks",
    "abstract": "Comments: NeurIPS 2022 Datasets and Benchmarks Track",
    "descriptor": "\nComments: NeurIPS 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Renbo Tu",
      "Nicholas Roberts",
      "Mikhail Khodak",
      "Junhong Shen",
      "Frederic Sala",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05668"
  },
  {
    "id": "arXiv:2110.05724",
    "title": "Query-Reward Tradeoffs in Multi-Armed Bandits",
    "abstract": "Query-Reward Tradeoffs in Multi-Armed Bandits",
    "descriptor": "",
    "authors": [
      "Nadav Merlis",
      "Yonathan Efroni",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05724"
  },
  {
    "id": "arXiv:2110.12255",
    "title": "Confidence-Aware Active Feedback for Interactive Instance Search",
    "abstract": "Comments: Accepted by IEEE Transactions on Multimedia",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Multimedia\n",
    "authors": [
      "Yue Zhang",
      "Chao Liang",
      "Longxiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.12255"
  },
  {
    "id": "arXiv:2111.03016",
    "title": "Graph neural network initialisation of quantum approximate optimisation",
    "abstract": "Comments: 12 pages, 8 Figures - publised version",
    "descriptor": "\nComments: 12 pages, 8 Figures - publised version\n",
    "authors": [
      "Nishant Jain",
      "Brian Coyle",
      "Elham Kashefi",
      "Niraj Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03016"
  },
  {
    "id": "arXiv:2111.09758",
    "title": "CSI Clustering with Variational Autoencoding",
    "abstract": "CSI Clustering with Variational Autoencoding",
    "descriptor": "",
    "authors": [
      "Michael Baur",
      "Michael W\u00fcrth",
      "Michael Koller",
      "Vlad-Costin Andrei",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09758"
  },
  {
    "id": "arXiv:2112.00792",
    "title": "Ideals, Determinants, and Straightening: Proving and Using Lower Bounds  for Polynomial Ideals",
    "abstract": "Comments: Abstract shortened to meet arXiv length requirement. v2: Improvements to hitting set generator construction and lower bound for the Ideal Proof System",
    "descriptor": "\nComments: Abstract shortened to meet arXiv length requirement. v2: Improvements to hitting set generator construction and lower bound for the Ideal Proof System\n",
    "authors": [
      "Robert Andrews",
      "Michael A. Forbes"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.00792"
  },
  {
    "id": "arXiv:2112.01502",
    "title": "Dimensions of Motion: Monocular Prediction through Flow Subspaces",
    "abstract": "Comments: Project page at this https URL",
    "descriptor": "\nComments: Project page at this https URL\n",
    "authors": [
      "Richard Strong Bowen",
      "Richard Tucker",
      "Ramin Zabih",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01502"
  },
  {
    "id": "arXiv:2112.05364",
    "title": "Human Guided Exploitation of Interpretable Attention Patterns in  Summarization and Topic Segmentation",
    "abstract": "Comments: 16 pages, 4 figures, Camera-Ready for EMNLP 2022 (Long Paper)",
    "descriptor": "\nComments: 16 pages, 4 figures, Camera-Ready for EMNLP 2022 (Long Paper)\n",
    "authors": [
      "Raymond Li",
      "Wen Xiao",
      "Linzi Xing",
      "Lanjun Wang",
      "Gabriel Murray",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.05364"
  },
  {
    "id": "arXiv:2112.07669",
    "title": "AI and extreme scale computing to learn and infer the physics of higher  order gravitational wave modes of quasi-circular, spinning, non-precessing  binary black hole mergers",
    "abstract": "Comments: 22 pages, 12 figures",
    "descriptor": "\nComments: 22 pages, 12 figures\n",
    "authors": [
      "Asad Khan",
      "E.A. Huerta",
      "Prayush Kumar"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2112.07669"
  },
  {
    "id": "arXiv:2112.08557",
    "title": "Protograph Bit-Interleaved Coded Modulation: A Bandwidth-Efficient  Design Paradigm for 6G Wireless Communications",
    "abstract": "Protograph Bit-Interleaved Coded Modulation: A Bandwidth-Efficient  Design Paradigm for 6G Wireless Communications",
    "descriptor": "",
    "authors": [
      "Yi Fang",
      "Pingping Chen",
      "Yong Liang Guan",
      "Francis C. M. Lau",
      "Yonghui Li",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08557"
  },
  {
    "id": "arXiv:2112.09596",
    "title": "Linguistic and Gender Variation in Speech Emotion Recognition using  Spectral Features",
    "abstract": "Comments: Presented at AICS 2021 Conference - Machine Learning for Time Series Section Published in CEUR Vol-3105 this http URL This publication has emanated from research supported in part by a Grant from Science Foundation Ireland under Grant number 18/CRT/6222 Associated source code this https URL 12 Pages, 5 Figures",
    "descriptor": "\nComments: Presented at AICS 2021 Conference - Machine Learning for Time Series Section Published in CEUR Vol-3105 this http URL This publication has emanated from research supported in part by a Grant from Science Foundation Ireland under Grant number 18/CRT/6222 Associated source code this https URL 12 Pages, 5 Figures\n",
    "authors": [
      "Zachary Dair",
      "Ryan Donovan",
      "Ruairi O'Reilly"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.09596"
  },
  {
    "id": "arXiv:2112.11832",
    "title": "Classifier Data Quality: A Geometric Complexity Based Method for  Automated Baseline And Insights Generation",
    "abstract": "Comments: Accepted to EDSMLS workshop at AAAI conference",
    "descriptor": "\nComments: Accepted to EDSMLS workshop at AAAI conference\n",
    "authors": [
      "George Kour",
      "Marcel Zalmanovici",
      "Orna Raz",
      "Samuel Ackerman",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11832"
  },
  {
    "id": "arXiv:2201.02475",
    "title": "Deep Domain Adversarial Adaptation for Photon-efficient Imaging",
    "abstract": "Deep Domain Adversarial Adaptation for Photon-efficient Imaging",
    "descriptor": "",
    "authors": [
      "Yiwei Chen",
      "Gongxin Yao",
      "Yong Liu",
      "Hongye Su",
      "Xiaomin Hu",
      "Yu Pan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.02475"
  },
  {
    "id": "arXiv:2201.03139",
    "title": "Differentially Private Generative Adversarial Networks with Model  Inversion",
    "abstract": "Comments: Best Student Paper Award of 13th IEEE International Workshop on Information Forensics and Security (WIFS 2021), Montpellier, France",
    "descriptor": "\nComments: Best Student Paper Award of 13th IEEE International Workshop on Information Forensics and Security (WIFS 2021), Montpellier, France\n",
    "authors": [
      "Dongjie Chen",
      "Sen-ching Samson Cheung",
      "Chen-Nee Chuah",
      "Sally Ozonoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.03139"
  },
  {
    "id": "arXiv:2201.09280",
    "title": "SpiroMask: Measuring Lung Function Using Consumer-Grade Masks",
    "abstract": "Comments: Accepted in the ACM Transactions on Computing for Healthcare (HEALTH)",
    "descriptor": "\nComments: Accepted in the ACM Transactions on Computing for Healthcare (HEALTH)\n",
    "authors": [
      "Rishiraj Adhikary",
      "Dhruvi Lodhavia",
      "Chris Francis",
      "Rohit Patil",
      "Tanmay Srivastava",
      "Prerna Khanna",
      "Nipun Batra",
      "Joe Breda",
      "Jacob Peplinski",
      "Shwetak Patel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09280"
  },
  {
    "id": "arXiv:2202.00109",
    "title": "Measuring poverty in India with machine learning and remote sensing",
    "abstract": "Measuring poverty in India with machine learning and remote sensing",
    "descriptor": "",
    "authors": [
      "Adel Daoud",
      "Felipe Jordan",
      "Makkunda Sharma",
      "Fredrik Johansson",
      "Devdatt Dubhashi",
      "Sourabh Paul",
      "Subhashis Banerjee"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00109"
  },
  {
    "id": "arXiv:2202.02651",
    "title": "Beyond Black Box Densities: Parameter Learning for the Deviated  Components",
    "abstract": "Comments: Accepted at NeurIPS 2022. Dat Do and Nhat Ho contributed equally to this work",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Dat Do and Nhat Ho contributed equally to this work\n",
    "authors": [
      "Dat Do",
      "Nhat Ho",
      "XuanLong Nguyen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02651"
  },
  {
    "id": "arXiv:2202.03519",
    "title": "Smoothed Online Optimization with Unreliable Predictions",
    "abstract": "Comments: 38 pages, 4 figures",
    "descriptor": "\nComments: 38 pages, 4 figures\n",
    "authors": [
      "Daan Rutten",
      "Nico Christianson",
      "Debankur Mukherjee",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.03519"
  },
  {
    "id": "arXiv:2202.04124",
    "title": "A Mini-Block Fisher Method for Deep Neural Networks",
    "abstract": "A Mini-Block Fisher Method for Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04124"
  },
  {
    "id": "arXiv:2202.04495",
    "title": "Data-driven Safe Control of Linear Systems Under Epistemic and Aleatory  Uncertainties",
    "abstract": "Data-driven Safe Control of Linear Systems Under Epistemic and Aleatory  Uncertainties",
    "descriptor": "",
    "authors": [
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04495"
  },
  {
    "id": "arXiv:2202.05100",
    "title": "Adaptively Exploiting d-Separators with Causal Bandits",
    "abstract": "Comments: 29 pages, 3 figures. Camera ready version",
    "descriptor": "\nComments: 29 pages, 3 figures. Camera ready version\n",
    "authors": [
      "Blair Bilodeau",
      "Linbo Wang",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05100"
  },
  {
    "id": "arXiv:2202.06382",
    "title": "Training with More Confidence: Mitigating Injected and Natural Backdoors  During Training",
    "abstract": "Training with More Confidence: Mitigating Injected and Natural Backdoors  During Training",
    "descriptor": "",
    "authors": [
      "Zhenting Wang",
      "Hailun Ding",
      "Juan Zhai",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06382"
  },
  {
    "id": "arXiv:2202.11844",
    "title": "First is Better Than Last for Language Data Influence",
    "abstract": "First is Better Than Last for Language Data Influence",
    "descriptor": "",
    "authors": [
      "Chih-Kuan Yeh",
      "Ankur Taly",
      "Mukund Sundararajan",
      "Frederick Liu",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.11844"
  },
  {
    "id": "arXiv:2203.00871",
    "title": "Dense Voxel Fusion for 3D Object Detection",
    "abstract": "Comments: Accepted in WACV 2023",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Anas Mahmoud",
      "Jordan S. K. Hu",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00871"
  },
  {
    "id": "arXiv:2203.01505",
    "title": "Large-scale Optimization of Partial AUC in a Range of False Positive  Rates",
    "abstract": "Large-scale Optimization of Partial AUC in a Range of False Positive  Rates",
    "descriptor": "",
    "authors": [
      "Yao Yao",
      "Qihang Lin",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01505"
  },
  {
    "id": "arXiv:2203.01633",
    "title": "Numerical method for feasible and approximately optimal solutions of  multi-marginal optimal transport beyond discrete measures",
    "abstract": "Numerical method for feasible and approximately optimal solutions of  multi-marginal optimal transport beyond discrete measures",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Qikun Xiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.01633"
  },
  {
    "id": "arXiv:2203.03597",
    "title": "Fast Rates for Noisy Interpolation Require Rethinking the Effects of  Inductive Bias",
    "abstract": "Fast Rates for Noisy Interpolation Require Rethinking the Effects of  Inductive Bias",
    "descriptor": "",
    "authors": [
      "Konstantin Donhauser",
      "Nicolo Ruggeri",
      "Stefan Stojanovic",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03597"
  },
  {
    "id": "arXiv:2203.05437",
    "title": "IndicNLG Benchmark: Multilingual Datasets for Diverse NLG Tasks in Indic  Languages",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Aman Kumar",
      "Himani Shrotriya",
      "Prachi Sahu",
      "Raj Dabre",
      "Ratish Puduppully",
      "Anoop Kunchukuttan",
      "Amogh Mishra",
      "Mitesh M. Khapra",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05437"
  },
  {
    "id": "arXiv:2203.07709",
    "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision  Avoidance in Complex Scenes",
    "abstract": "Comments: accepted by IROS2022",
    "descriptor": "\nComments: accepted by IROS2022\n",
    "authors": [
      "Shuaijun Wang",
      "Rui Gao",
      "Ruihua Han",
      "Shengduo Chen",
      "Chengyang Li",
      "Qi Hao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07709"
  },
  {
    "id": "arXiv:2203.09851",
    "title": "Convergence of a finite-volume scheme for a heat equation with a  multiplicative Lipschitz noise",
    "abstract": "Convergence of a finite-volume scheme for a heat equation with a  multiplicative Lipschitz noise",
    "descriptor": "",
    "authors": [
      "Caroline Bauzet",
      "Flore Nabet",
      "Kerstin Schmitz",
      "Aleksandra Zimmermann"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09851"
  },
  {
    "id": "arXiv:2203.11471",
    "title": "Ray3D: ray-based 3D human pose estimation for monocular absolute 3D  localization",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yu Zhan",
      "Fenghai Li",
      "Renliang Weng",
      "Wongun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11471"
  },
  {
    "id": "arXiv:2203.12024",
    "title": "Strategy Complexity of Reachability in Countable Stochastic 2-Player  Games",
    "abstract": "Strategy Complexity of Reachability in Countable Stochastic 2-Player  Games",
    "descriptor": "",
    "authors": [
      "Stefan Kiefer",
      "Richard Mayr",
      "Mahsa Shirmohammadi",
      "Patrick Totzke"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.12024"
  },
  {
    "id": "arXiv:2203.15277",
    "title": "Decomposed Temporal Dynamic CNN: Efficient Time-Adaptive Network for  Text-Independent Speaker Verification Explained with Speaker Activation Map",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Seong-Hu Kim",
      "Hyeonuk Nam",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15277"
  },
  {
    "id": "arXiv:2203.15410",
    "title": "Proximal-like algorithms for equilibrium seeking in mixed-integer Nash  equilibrium problems",
    "abstract": "Proximal-like algorithms for equilibrium seeking in mixed-integer Nash  equilibrium problems",
    "descriptor": "",
    "authors": [
      "Filippo Fabiani",
      "Barbara Franci",
      "Simone Sagratella",
      "Martin Schmidt",
      "Mathias Staudigl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15410"
  },
  {
    "id": "arXiv:2203.16223",
    "title": "Hypergraphon Mean Field Games",
    "abstract": "Comments: The following article has been accepted by Chaos",
    "descriptor": "\nComments: The following article has been accepted by Chaos\n",
    "authors": [
      "Kai Cui",
      "Wasiur R. KhudaBukhsh",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16223"
  },
  {
    "id": "arXiv:2203.17024",
    "title": "VQF: Highly Accurate IMU Orientation Estimation with Bias Estimation and  Magnetic Disturbance Rejection",
    "abstract": "Comments: Accepted manuscript",
    "descriptor": "\nComments: Accepted manuscript\n",
    "authors": [
      "Daniel Laidig",
      "Thomas Seel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.17024"
  },
  {
    "id": "arXiv:2203.17118",
    "title": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "abstract": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "descriptor": "",
    "authors": [
      "Harrie Oosterhuis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.17118"
  },
  {
    "id": "arXiv:2204.00004",
    "title": "Reproducibility Issues for BERT-based Evaluation Metrics",
    "abstract": "Comments: EMNLP 2022 Camera-Ready (captions fixed)",
    "descriptor": "\nComments: EMNLP 2022 Camera-Ready (captions fixed)\n",
    "authors": [
      "Yanran Chen",
      "Jonas Belouadi",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00004"
  },
  {
    "id": "arXiv:2204.00585",
    "title": "From Data to Knowledge Graphs: A Multi-Layered Method to Model User's  Visual Analytics Workflow for Analytical Purposes",
    "abstract": "Comments: 9 pgs, submitted to TVCG 2022",
    "descriptor": "\nComments: 9 pgs, submitted to TVCG 2022\n",
    "authors": [
      "Leonardo Christino",
      "Fernando V. Paulovich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.00585"
  },
  {
    "id": "arXiv:2204.04060",
    "title": "Deep-Learning-Based Identification of LPV Models for Nonlinear Systems",
    "abstract": "Comments: Accepted for presentation at the 61st IEEE Conference on Decision and Control",
    "descriptor": "\nComments: Accepted for presentation at the 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Chris Verhoek",
      "Gerben I. Beintema",
      "Sofie Haesaert",
      "Maarten Schoukens",
      "Roland T\u00f3 th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04060"
  },
  {
    "id": "arXiv:2204.05030",
    "title": "Assessing the communication gap between AI models and healthcare  professionals: explainability, utility and trust in AI-driven clinical  decision-making",
    "abstract": "Comments: supplementary information in the main pdf",
    "descriptor": "\nComments: supplementary information in the main pdf\n",
    "authors": [
      "Oskar Wysocki",
      "Jessica Katharine Davies",
      "Markel Vigo",
      "Anne Caroline Armstrong",
      "D\u00f3nal Landers",
      "Rebecca Lee",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05030"
  },
  {
    "id": "arXiv:2204.05070",
    "title": "Fine-grained Noise Control for Multispeaker Speech Synthesis",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Karolos Nikitaras",
      "Georgios Vamvoukakis",
      "Nikolaos Ellinas",
      "Konstantinos Klapsas",
      "Konstantinos Markopoulos",
      "Spyros Raptis",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05070"
  },
  {
    "id": "arXiv:2204.06754",
    "title": "RecurSeed and EdgePredictMix: Single-stage Learning is Sufficient for  Weakly-Supervised Semantic Segmentation",
    "abstract": "RecurSeed and EdgePredictMix: Single-stage Learning is Sufficient for  Weakly-Supervised Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Sanghyun Jo",
      "In-Jae Yu",
      "Kyungsu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.06754"
  },
  {
    "id": "arXiv:2204.07177",
    "title": "Active Learning for Regression by Inverse Distance Weighting",
    "abstract": "Comments: 21 pages, 9 figures. Submitted for publication",
    "descriptor": "\nComments: 21 pages, 9 figures. Submitted for publication\n",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07177"
  },
  {
    "id": "arXiv:2204.07667",
    "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language  Models",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Weiyan Shi",
      "Ryan Shea",
      "Si Chen",
      "Chiyuan Zhang",
      "Ruoxi Jia",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07667"
  },
  {
    "id": "arXiv:2204.08323",
    "title": "Experimental measurement-device-independent type quantum key  distribution with flawed and correlated sources",
    "abstract": "Comments: 16 pages, 7 figures, 6 tables. Comments are welcome!",
    "descriptor": "\nComments: 16 pages, 7 figures, 6 tables. Comments are welcome!\n",
    "authors": [
      "Jie Gu",
      "Xiao-Yu Cao",
      "Yao Fu",
      "Zong-Wu He",
      "Ze-Jie Yin",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08323"
  },
  {
    "id": "arXiv:2204.12569",
    "title": "A New Spin on Color Quantization",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Samy Lakhal",
      "Alexandre Darmon",
      "Michael Benzaquen"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2204.12569"
  },
  {
    "id": "arXiv:2205.01458",
    "title": "Frequency-Selective Geometry Upsampling of Point Clouds",
    "abstract": "Comments: 5 pages, 3 figures, International Conference on Image Processing (ICIP) 2022",
    "descriptor": "\nComments: 5 pages, 3 figures, International Conference on Image Processing (ICIP) 2022\n",
    "authors": [
      "Viktoria Heimann",
      "Andreas Spruck",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01458"
  },
  {
    "id": "arXiv:2205.01493",
    "title": "On the uncertainty principle of neural networks",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Jun-Jie Zhang",
      "Dong-Xiao Zhang",
      "Jian-Nan Chen",
      "Long-Gang Pang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01493"
  },
  {
    "id": "arXiv:2205.03076",
    "title": "Beyond backpropagation: bilevel optimization through implicit  differentiation and equilibrium propagation",
    "abstract": "Beyond backpropagation: bilevel optimization through implicit  differentiation and equilibrium propagation",
    "descriptor": "",
    "authors": [
      "Nicolas Zucchet",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.03076"
  },
  {
    "id": "arXiv:2205.09784",
    "title": "End-to-End Zero-Shot Voice Conversion with Location-Variable  Convolutions",
    "abstract": "End-to-End Zero-Shot Voice Conversion with Location-Variable  Convolutions",
    "descriptor": "",
    "authors": [
      "Wonjune Kang",
      "Mark Hasegawa-Johnson",
      "Deb Roy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.09784"
  },
  {
    "id": "arXiv:2205.10643",
    "title": "Self-Supervised Speech Representation Learning: A Review",
    "abstract": "Self-Supervised Speech Representation Learning: A Review",
    "descriptor": "",
    "authors": [
      "Abdelrahman Mohamed",
      "Hung-yi Lee",
      "Lasse Borgholt",
      "Jakob D. Havtorn",
      "Joakim Edin",
      "Christian Igel",
      "Katrin Kirchhoff",
      "Shang-Wen Li",
      "Karen Livescu",
      "Lars Maal\u00f8e",
      "Tara N. Sainath",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.10643"
  },
  {
    "id": "arXiv:2205.11568",
    "title": "Quasi Black-Box Variational Inference with Natural Gradients for  Bayesian Learning",
    "abstract": "Quasi Black-Box Variational Inference with Natural Gradients for  Bayesian Learning",
    "descriptor": "",
    "authors": [
      "Martin Magris",
      "Mostafa Shabani",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2205.11568"
  },
  {
    "id": "arXiv:2205.12538",
    "title": "Is a Question Decomposition Unit All We Need?",
    "abstract": "Comments: EMNLP 2022 (17 pages)",
    "descriptor": "\nComments: EMNLP 2022 (17 pages)\n",
    "authors": [
      "Pruthvi Patel",
      "Swaroop Mishra",
      "Mihir Parmar",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12538"
  },
  {
    "id": "arXiv:2205.13054",
    "title": "Scalable and Low-Latency Federated Learning with Cooperative Mobile Edge  Networking",
    "abstract": "Comments: accepted for publication in IEEE Transactions on Mobile Computing",
    "descriptor": "\nComments: accepted for publication in IEEE Transactions on Mobile Computing\n",
    "authors": [
      "Zhenxiao Zhang",
      "Zhidong Gao",
      "Yuanxiong Guo",
      "Yanmin Gong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13054"
  },
  {
    "id": "arXiv:2205.13648",
    "title": "A Unified Analysis of Federated Learning with Arbitrary Client  Participation",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Shiqiang Wang",
      "Mingyue Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13648"
  },
  {
    "id": "arXiv:2205.14459",
    "title": "CyCLIP: Cyclic Contrastive Language-Image Pretraining",
    "abstract": "Comments: 19 pages, 13 tables, 6 figures, Oral at NeuRIPS 2022",
    "descriptor": "\nComments: 19 pages, 13 tables, 6 figures, Oral at NeuRIPS 2022\n",
    "authors": [
      "Shashank Goel",
      "Hritik Bansal",
      "Sumit Bhatia",
      "Ryan A. Rossi",
      "Vishwa Vinay",
      "Aditya Grover"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14459"
  },
  {
    "id": "arXiv:2205.15223",
    "title": "Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained  Models",
    "abstract": "Comments: Accepted to EMNLP 2022; The code is available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022; The code is available at this https URL\n",
    "authors": [
      "Mengzhou Xia",
      "Mikel Artetxe",
      "Jingfei Du",
      "Danqi Chen",
      "Ves Stoyanov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15223"
  },
  {
    "id": "arXiv:2205.15294",
    "title": "Efficient Phi-Regret Minimization in Extensive-Form Games via Online  Mirror Descent",
    "abstract": "Efficient Phi-Regret Minimization in Extensive-Form Games via Online  Mirror Descent",
    "descriptor": "",
    "authors": [
      "Yu Bai",
      "Chi Jin",
      "Song Mei",
      "Ziang Song",
      "Tiancheng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15294"
  },
  {
    "id": "arXiv:2205.15680",
    "title": "Simulation-Based Inference with Waldo: Confidence Regions by Leveraging  Prediction Algorithms or Posterior Estimators for Inverse Problems",
    "abstract": "Comments: 15 pages, 10 figures",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Luca Masserano",
      "Tommaso Dorigo",
      "Rafael Izbicki",
      "Mikael Kuusela",
      "Ann B. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15680"
  },
  {
    "id": "arXiv:2206.00746",
    "title": "Residual Multiplicative Filter Networks for Multiscale Reconstruction",
    "abstract": "Comments: NeurIPS 2022, Project page: this https URL",
    "descriptor": "\nComments: NeurIPS 2022, Project page: this https URL\n",
    "authors": [
      "Shayan Shekarforoush",
      "David B. Lindell",
      "David J. Fleet",
      "Marcus A. Brubaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00746"
  },
  {
    "id": "arXiv:2206.02416",
    "title": "Embrace the Gap: VAEs Perform Independent Mechanism Analysis",
    "abstract": "Comments: 47 pages, accepted at NeurIPS2022",
    "descriptor": "\nComments: 47 pages, accepted at NeurIPS2022\n",
    "authors": [
      "Patrik Reizinger",
      "Luigi Gresele",
      "Jack Brady",
      "Julius von K\u00fcgelgen",
      "Dominik Zietlow",
      "Bernhard Sch\u00f6lkopf",
      "Georg Martius",
      "Wieland Brendel",
      "Michel Besserve"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02416"
  },
  {
    "id": "arXiv:2206.03064",
    "title": "A Simple and Efficient Pipeline to Build an End-to-End Spatial-Temporal  Action Detector",
    "abstract": "Comments: Accepted By WACV 2023",
    "descriptor": "\nComments: Accepted By WACV 2023\n",
    "authors": [
      "Lin Sui",
      "Chen-Lin Zhang",
      "Lixin Gu",
      "Feng Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03064"
  },
  {
    "id": "arXiv:2206.03213",
    "title": "Improving Students' Academic Performance with AI and Semantic  Technologies",
    "abstract": "Improving Students' Academic Performance with AI and Semantic  Technologies",
    "descriptor": "",
    "authors": [
      "Yixin Cheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03213"
  },
  {
    "id": "arXiv:2206.03375",
    "title": "Walking on Vertices and Edges by Continuous-Time Quantum Walk",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Caue F. T. Silva",
      "Daniel Posner",
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.03375"
  },
  {
    "id": "arXiv:2206.03674",
    "title": "Integrating Symmetry into Differentiable Planning with Steerable  Convolutions",
    "abstract": "Comments: Restructured main text and appendix. Renamed from \"Integrating Symmetry into Differentiable Planning\"",
    "descriptor": "\nComments: Restructured main text and appendix. Renamed from \"Integrating Symmetry into Differentiable Planning\"\n",
    "authors": [
      "Linfeng Zhao",
      "Xupeng Zhu",
      "Lingzhi Kong",
      "Robin Walters",
      "Lawson L.S. Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03674"
  },
  {
    "id": "arXiv:2206.04646",
    "title": "Minimax Optimal Algorithms for Fixed-Budget Best Arm Identification",
    "abstract": "Comments: NeurIPS 2022 version this https URL",
    "descriptor": "\nComments: NeurIPS 2022 version this https URL\n",
    "authors": [
      "Junpei Komiyama",
      "Taira Tsuchiya",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04646"
  },
  {
    "id": "arXiv:2206.04804",
    "title": "Theoretical Error Performance Analysis for Variational Quantum Circuit  Based Functional Regression",
    "abstract": "Comments: Preprint version. 16 pages",
    "descriptor": "\nComments: Preprint version. 16 pages\n",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Min-Hsiu Hsieh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.04804"
  },
  {
    "id": "arXiv:2206.05764",
    "title": "Mining Multi-Label Samples from Single Positive Labels",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Youngin Cho",
      "Daejin Kim",
      "Mohammad Azam Khan",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05764"
  },
  {
    "id": "arXiv:2206.06565",
    "title": "LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning  Tasks",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Tuan Dinh",
      "Yuchen Zeng",
      "Ruisu Zhang",
      "Ziqian Lin",
      "Michael Gira",
      "Shashank Rajput",
      "Jy-yong Sohn",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06565"
  },
  {
    "id": "arXiv:2206.07754",
    "title": "Novelty and Cultural Evolution in Modern Popular Music",
    "abstract": "Novelty and Cultural Evolution in Modern Popular Music",
    "descriptor": "",
    "authors": [
      "Katherine O'Toole",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.07754"
  },
  {
    "id": "arXiv:2206.07817",
    "title": "Low-Cost Superconducting Fan-Out with Repurposed Josephson Junctions",
    "abstract": "Comments: 11 pages, 20 figures, submitted to IEEE TAS",
    "descriptor": "\nComments: 11 pages, 20 figures, submitted to IEEE TAS\n",
    "authors": [
      "Jennifer Volk",
      "George Tzimpragos",
      "Alex Wynn",
      "Evan Golden",
      "Timothy Sherwood"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.07817"
  },
  {
    "id": "arXiv:2206.09303",
    "title": "The Framework For The Discipline Of Software Engineering in Connection  to Information Technology Discipline",
    "abstract": "The Framework For The Discipline Of Software Engineering in Connection  to Information Technology Discipline",
    "descriptor": "",
    "authors": [
      "Jones Yeboah",
      "Feifei Pang",
      "Hari Priya Ponnakanti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09303"
  },
  {
    "id": "arXiv:2206.11219",
    "title": "Understanding the Properties of Generated Corpora",
    "abstract": "Understanding the Properties of Generated Corpora",
    "descriptor": "",
    "authors": [
      "Naama Zwerdling",
      "Segev Shlomov",
      "Esther Goldbraich",
      "George Kour",
      "Boaz Carmeli",
      "Naama Tepper",
      "Inbal Ronen",
      "Vitaly Zabershinsky",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.11219"
  },
  {
    "id": "arXiv:2206.11488",
    "title": "On the Importance and Applicability of Pre-Training for Federated  Learning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Hong-You Chen",
      "Cheng-Hao Tu",
      "Ziwei Li",
      "Han-Wei Shen",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11488"
  },
  {
    "id": "arXiv:2206.14284",
    "title": "Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs",
    "abstract": "Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs",
    "descriptor": "",
    "authors": [
      "Florian Krach",
      "Marc N\u00fcbel",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.14284"
  },
  {
    "id": "arXiv:2207.00210",
    "title": "Neural Parameterization for Dynamic Human Head Editing",
    "abstract": "Comments: 15 pages, 18 figures",
    "descriptor": "\nComments: 15 pages, 18 figures\n",
    "authors": [
      "Li Ma",
      "Xiaoyu Li",
      "Jing Liao",
      "Xuan Wang",
      "Qi Zhang",
      "Jue Wang",
      "Pedro Sander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.00210"
  },
  {
    "id": "arXiv:2207.02916",
    "title": "Inter and Intra Signal Variance in Feature Extraction and Classification  of Affective State",
    "abstract": "Comments: Preprint for the AICS 2022 Conference This publication has emanated from research supported in part by a Grant from Science Foundation Ireland under Grant number 18/CRT/6222 Associated source code this https URL",
    "descriptor": "\nComments: Preprint for the AICS 2022 Conference This publication has emanated from research supported in part by a Grant from Science Foundation Ireland under Grant number 18/CRT/6222 Associated source code this https URL\n",
    "authors": [
      "Zachary Dair",
      "Samantha Dockray",
      "Ruairi O'Reilly"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.02916"
  },
  {
    "id": "arXiv:2207.03863",
    "title": "Maximum Weight b-Matchings in Random-Order Streams",
    "abstract": "Maximum Weight b-Matchings in Random-Order Streams",
    "descriptor": "",
    "authors": [
      "Chien-Chung Huang",
      "Fran\u00e7ois Sellier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.03863"
  },
  {
    "id": "arXiv:2207.04637",
    "title": "SIMC 2.0: Improved Secure ML Inference Against Malicious Clients",
    "abstract": "SIMC 2.0: Improved Secure ML Inference Against Malicious Clients",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Xingshuo Han",
      "Tianwei Zhang",
      "Shengmin Xu",
      "Jianting Ning",
      "Xinyi Huang",
      "Hongwei Li",
      "Robert H.Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04637"
  },
  {
    "id": "arXiv:2207.06017",
    "title": "Federated Multi-Task Learning for THz Wideband Channel and DoA  Estimation",
    "abstract": "Comments: submitted to an IEEE journal",
    "descriptor": "\nComments: submitted to an IEEE journal\n",
    "authors": [
      "Ahmet M. Elbir",
      "Wei Shi",
      "Kumar Vijay Mishra",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06017"
  },
  {
    "id": "arXiv:2207.07038",
    "title": "From Shapley back to Pearson: Hypothesis Testing via the Shapley Value",
    "abstract": "From Shapley back to Pearson: Hypothesis Testing via the Shapley Value",
    "descriptor": "",
    "authors": [
      "Jacopo Teneggi",
      "Beepul Bharti",
      "Yaniv Romano",
      "Jeremias Sulam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07038"
  },
  {
    "id": "arXiv:2207.08265",
    "title": "MLP-GAN for Brain Vessel Image Segmentation",
    "abstract": "Comments: Resubmit a conference",
    "descriptor": "\nComments: Resubmit a conference\n",
    "authors": [
      "Bin Xie",
      "Hao Tang",
      "Bin Duan",
      "Dawen Cai",
      "Yan Yan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08265"
  },
  {
    "id": "arXiv:2207.08437",
    "title": "Non-negative Least Squares via Overparametrization",
    "abstract": "Non-negative Least Squares via Overparametrization",
    "descriptor": "",
    "authors": [
      "Hung-Hsu Chou",
      "Johannes Maly",
      "Claudio Mayrink Verdun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.08437"
  },
  {
    "id": "arXiv:2207.09217",
    "title": "Contextual Similarity is More Valuable than Character Similarity: An  Empirical Study for Chinese Spell Checking",
    "abstract": "Comments: Submitted to ICASSP2023 (currently under review)",
    "descriptor": "\nComments: Submitted to ICASSP2023 (currently under review)\n",
    "authors": [
      "Ding Zhang",
      "Yinghui Li",
      "Qingyu Zhou",
      "Shirong Ma",
      "Yangning Li",
      "Yunbo Cao",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09217"
  },
  {
    "id": "arXiv:2207.09980",
    "title": "ReFactor GNNs: Revisiting Factorisation-based Models from a  Message-Passing Perspective",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yihong Chen",
      "Pushkar Mishra",
      "Luca Franceschi",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09980"
  },
  {
    "id": "arXiv:2207.10262",
    "title": "A Labelled Sequent Calculus for Public Announcement Logic",
    "abstract": "A Labelled Sequent Calculus for Public Announcement Logic",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Hans van Ditmarsch",
      "Jinsheng Chen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.10262"
  },
  {
    "id": "arXiv:2207.12252",
    "title": "Accessing and Interpreting OPC UA Event Traces based on Semantic Process  Descriptions",
    "abstract": "Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Tom Westermann",
      "Nemanja Hranisavljevic",
      "Alexander Fay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.12252"
  },
  {
    "id": "arXiv:2207.12297",
    "title": "TreeSketchNet: From Sketch To 3D Tree Parameters Generation",
    "abstract": "TreeSketchNet: From Sketch To 3D Tree Parameters Generation",
    "descriptor": "",
    "authors": [
      "Gilda Manfredi",
      "Nicola Capece",
      "Ugo Erra",
      "Monica Gruosso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.12297"
  },
  {
    "id": "arXiv:2207.14200",
    "title": "CrAM: A Compression-Aware Minimizer",
    "abstract": "Comments: 28 pages, 2 figures. This version contains important improvements to the initial method and results, experiments on language models and comparison with other methods",
    "descriptor": "\nComments: 28 pages, 2 figures. This version contains important improvements to the initial method and results, experiments on language models and comparison with other methods\n",
    "authors": [
      "Alexandra Peste",
      "Adrian Vladu",
      "Eldar Kurtic",
      "Christoph H. Lampert",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14200"
  },
  {
    "id": "arXiv:2208.00361",
    "title": "One for All: One-stage Referring Expression Comprehension with Dynamic  Reasoning",
    "abstract": "Comments: 27 pages, 6 figures",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Zhipeng Zhang",
      "Zhimin Wei",
      "Zhongzhen Huang",
      "Rui Niu",
      "Peng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.00361"
  },
  {
    "id": "arXiv:2208.01036",
    "title": "Face-to-Face Contrastive Learning for Social Intelligence  Question-Answering",
    "abstract": "Face-to-Face Contrastive Learning for Social Intelligence  Question-Answering",
    "descriptor": "",
    "authors": [
      "Alex Wilf",
      "Martin Q. Ma",
      "Paul Pu Liang",
      "Amir Zadeh",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.01036"
  },
  {
    "id": "arXiv:2208.02252",
    "title": "GROWN+UP: A Graph Representation Of a Webpage Network Utilizing  Pre-training",
    "abstract": "Comments: Submitted to CIKM '22",
    "descriptor": "\nComments: Submitted to CIKM '22\n",
    "authors": [
      "Benedict Yeoh",
      "Huijuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.02252"
  },
  {
    "id": "arXiv:2208.02999",
    "title": "Cryptoeconomic Security for Data Availability Committees",
    "abstract": "Comments: 35 pages, 1 figure",
    "descriptor": "\nComments: 35 pages, 1 figure\n",
    "authors": [
      "Ertem Nusret Tas",
      "Dan Boneh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.02999"
  },
  {
    "id": "arXiv:2208.03941",
    "title": "A high-resolution dynamical view on momentum methods for  over-parameterized neural networks",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Xin Liu",
      "Wei Tao",
      "Jun Wang",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.03941"
  },
  {
    "id": "arXiv:2208.04433",
    "title": "Peer Prediction for Learning Agents",
    "abstract": "Comments: 34 pages, 9 figures",
    "descriptor": "\nComments: 34 pages, 9 figures\n",
    "authors": [
      "Shi Feng",
      "Fang-Yi Yu",
      "Yiling Chen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.04433"
  },
  {
    "id": "arXiv:2208.05004",
    "title": "CoViT: Real-time phylogenetics for the SARS-CoV-2 pandemic using Vision  Transformers",
    "abstract": "Comments: 11 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables\n",
    "authors": [
      "Zuher Jahshan",
      "Can Alkan",
      "Leonid Yavits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.05004"
  },
  {
    "id": "arXiv:2208.09592",
    "title": "Transforming the Interactive Segmentation for Medical Imaging",
    "abstract": "Comments: Accepted to MICCAI 2022",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Wentao Liu",
      "Chaofan Ma",
      "Yuhuan Yang",
      "Weidi Xie",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09592"
  },
  {
    "id": "arXiv:2208.09658",
    "title": "A biologically-inspired multi-modal evaluation of molecular generative  machine learning",
    "abstract": "Comments: 59 pages, 26 figures Project GitHub repository, this https URL",
    "descriptor": "\nComments: 59 pages, 26 figures Project GitHub repository, this https URL\n",
    "authors": [
      "Elizaveta Vinogradova",
      "Abay Artykbayev",
      "Alisher Amanatay",
      "Mukhamejan Karatayev",
      "Maxim Mametkulov",
      "Albina Li",
      "Anuar Suleimenov",
      "Abylay Salimzhanov",
      "Karina Pats",
      "Rustam Zhumagambetov",
      "Ferdinand Moln\u00e1r",
      "Vsevolod Peshkov",
      "Siamac Fazli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.09658"
  },
  {
    "id": "arXiv:2208.10607",
    "title": "Individual Tree Detection in Large-Scale Urban Environments using  High-Resolution Multispectral Imagery",
    "abstract": "Individual Tree Detection in Large-Scale Urban Environments using  High-Resolution Multispectral Imagery",
    "descriptor": "",
    "authors": [
      "Jonathan Ventura",
      "Camille Pawlak",
      "Milo Honsberger",
      "Cameron Gonsalves",
      "Julian Rice",
      "Natalie L.R. Love",
      "Skyler Han",
      "Viet Nguyen",
      "Keilana Sugano",
      "Jacqueline Doremus",
      "G. Andrew Fricker",
      "Jenn Yost",
      "Matt Ritter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10607"
  },
  {
    "id": "arXiv:2208.11516",
    "title": "Adjoint Optimisation for Wind Farm Flow Control with a Free-Vortex Wake  Model",
    "abstract": "Comments: 32 pages, 12 figures, submitted to Renewable Energy, minor revisions after reviewer comments",
    "descriptor": "\nComments: 32 pages, 12 figures, submitted to Renewable Energy, minor revisions after reviewer comments\n",
    "authors": [
      "Maarten J. van den Broek",
      "Delphine De Tavernier",
      "Benjamin Sanderse",
      "Jan-Willem van Wingerden"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2208.11516"
  },
  {
    "id": "arXiv:2208.12025",
    "title": "Integrating Statistical and Machine Learning Approaches to Identify  Receptive Field Structure in Neural Populations",
    "abstract": "Integrating Statistical and Machine Learning Approaches to Identify  Receptive Field Structure in Neural Populations",
    "descriptor": "",
    "authors": [
      "Mehrad Sarmashghi",
      "Shantanu P. Jadhav",
      "Uri T. Eden"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.12025"
  },
  {
    "id": "arXiv:2208.12812",
    "title": "Speech Emotion Recognition using Supervised Deep Recurrent System for  Mental Health Monitoring",
    "abstract": "Comments: 6 pages, 5 figures, 3 tables, accepted in the IEEE WFIoT2022",
    "descriptor": "\nComments: 6 pages, 5 figures, 3 tables, accepted in the IEEE WFIoT2022\n",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Navid Asadizanjani",
      "Murat Ozer",
      "Ahmed Abdelgawad",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2208.12812"
  },
  {
    "id": "arXiv:2208.13471",
    "title": "How to Extend the Abstraction Refinement Model for Systems with Emergent  Behavior ?",
    "abstract": "How to Extend the Abstraction Refinement Model for Systems with Emergent  Behavior ?",
    "descriptor": "",
    "authors": [
      "Mohamed Toufik Ailane",
      "Christoph Knieke",
      "Andreas Rausch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.13471"
  },
  {
    "id": "arXiv:2208.14358",
    "title": "Convergence of Nonequilibrium Langevin Dynamics for Planar Flows",
    "abstract": "Comments: The proof of Lemma 9 in an early version of the manuscript is updated thanks to Gabriel Stoltz's helpful comments",
    "descriptor": "\nComments: The proof of Lemma 9 in an early version of the manuscript is updated thanks to Gabriel Stoltz's helpful comments\n",
    "authors": [
      "Matthew Dobson",
      "Abdel Kader Geraldo"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.14358"
  },
  {
    "id": "arXiv:2208.14923",
    "title": "Few-Shot Learning for Clinical Natural Language Processing Using Siamese  Neural Networks",
    "abstract": "Few-Shot Learning for Clinical Natural Language Processing Using Siamese  Neural Networks",
    "descriptor": "",
    "authors": [
      "David Oniani",
      "Sonish Sivarajkumar",
      "Yanshan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.14923"
  },
  {
    "id": "arXiv:2209.01766",
    "title": "Exploring the Verifiability of Code Generated by GitHub Copilot",
    "abstract": "Comments: HATRA workshop at SPLASH 2022",
    "descriptor": "\nComments: HATRA workshop at SPLASH 2022\n",
    "authors": [
      "Dakota Wong",
      "Austin Kothig",
      "Patrick Lam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.01766"
  },
  {
    "id": "arXiv:2209.07799",
    "title": "Quantum Transfer Learning for Real-World, Small, and High-Dimensional  Datasets",
    "abstract": "Comments: This article is submitted to IEEE TGRS. Hence, this version will be removed from ArXiv after published in this IEEE journal",
    "descriptor": "\nComments: This article is submitted to IEEE TGRS. Hence, this version will be removed from ArXiv after published in this IEEE journal\n",
    "authors": [
      "Soronzonbold Otgonbaatar",
      "Gottfried Schwarz",
      "Mihai Datcu",
      "Dieter Kranzlm\u00fcller"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.07799"
  },
  {
    "id": "arXiv:2209.08685",
    "title": "Meta-simulation for the Automated Design of Synthetic Overhead Imagery",
    "abstract": "Meta-simulation for the Automated Design of Synthetic Overhead Imagery",
    "descriptor": "",
    "authors": [
      "Handi Yu",
      "Simiao Ren",
      "Leslie M. Collins",
      "Jordan M. Malof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.08685"
  },
  {
    "id": "arXiv:2209.10137",
    "title": "Rank-Preserving Multidimensional Mechanisms",
    "abstract": "Rank-Preserving Multidimensional Mechanisms",
    "descriptor": "",
    "authors": [
      "Sushil Bikhchandani",
      "Debasis Mishra"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.10137"
  },
  {
    "id": "arXiv:2209.11745",
    "title": "Unified Algorithms for RL with Decision-Estimation Coefficients:  No-Regret, PAC, and Reward-Free Learning",
    "abstract": "Unified Algorithms for RL with Decision-Estimation Coefficients:  No-Regret, PAC, and Reward-Free Learning",
    "descriptor": "",
    "authors": [
      "Fan Chen",
      "Song Mei",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11745"
  },
  {
    "id": "arXiv:2209.11910",
    "title": "A Focused Study on Sequence Length for Dialogue Summarization",
    "abstract": "Comments: Preprint version - ICASSP submission",
    "descriptor": "\nComments: Preprint version - ICASSP submission\n",
    "authors": [
      "Bin Wang",
      "Chen Zhang",
      "Chengwei Wei",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.11910"
  },
  {
    "id": "arXiv:2209.12202",
    "title": "Multimodal Exponentially Modified Gaussian Oscillators",
    "abstract": "Comments: IEEE International Ultrasonic Symposium 2022",
    "descriptor": "\nComments: IEEE International Ultrasonic Symposium 2022\n",
    "authors": [
      "Christopher Hahne"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.12202"
  },
  {
    "id": "arXiv:2209.12473",
    "title": "Approximation in Hilbert spaces of the Gaussian and other weighted power  series kernels",
    "abstract": "Approximation in Hilbert spaces of the Gaussian and other weighted power  series kernels",
    "descriptor": "",
    "authors": [
      "Toni Karvonen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.12473"
  },
  {
    "id": "arXiv:2209.12702",
    "title": "End-to-End Lyrics Recognition with Self-supervised Learning",
    "abstract": "Comments: 4 pages, 2 figures, 3 tables",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables\n",
    "authors": [
      "Xiangyu Zhang",
      "Shuyue Stella Li",
      "Zhanhong He",
      "Roberto Togneri",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.12702"
  },
  {
    "id": "arXiv:2209.13343",
    "title": "Semigroup intersection problems in the Heisenberg groups",
    "abstract": "Comments: 18 pages including appendix, 2 figures",
    "descriptor": "\nComments: 18 pages including appendix, 2 figures\n",
    "authors": [
      "Ruiwen Dong"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.13343"
  },
  {
    "id": "arXiv:2209.14603",
    "title": "Dataset Distillation for Medical Dataset Sharing",
    "abstract": "Dataset Distillation for Medical Dataset Sharing",
    "descriptor": "",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.14603"
  },
  {
    "id": "arXiv:2209.14609",
    "title": "Dataset Distillation using Parameter Pruning",
    "abstract": "Dataset Distillation using Parameter Pruning",
    "descriptor": "",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14609"
  },
  {
    "id": "arXiv:2209.15214",
    "title": "Construction and Applications of Billion-Scale Pre-trained Multimodal  Business Knowledge Graph",
    "abstract": "Comments: OpenBG. Work in Progress",
    "descriptor": "\nComments: OpenBG. Work in Progress\n",
    "authors": [
      "Shumin Deng",
      "Chengming Wang",
      "Zhoubo Li",
      "Ningyu Zhang",
      "Zelin Dai",
      "Hehong Chen",
      "Feiyu Xiong",
      "Ming Yan",
      "Qiang Chen",
      "Mosha Chen",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Bryan Hooi",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.15214"
  },
  {
    "id": "arXiv:2210.00227",
    "title": "Attention Augmented ConvNeXt UNet For Rectal Tumour Segmentation",
    "abstract": "Comments: I plan to replace this article, and supplement and confirm the structure and experimental content of this article",
    "descriptor": "\nComments: I plan to replace this article, and supplement and confirm the structure and experimental content of this article\n",
    "authors": [
      "Hongwei Wu",
      "Junlin Wang",
      "Xin Wang",
      "Hui Nan",
      "Yaxin Wang",
      "Haonan Jing",
      "Kaixuan Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00227"
  },
  {
    "id": "arXiv:2210.01478",
    "title": "When to Make Exceptions: Exploring Language Models as Accounts of Human  Moral Judgment",
    "abstract": "Comments: NeurIPS 2022 Oral",
    "descriptor": "\nComments: NeurIPS 2022 Oral\n",
    "authors": [
      "Zhijing Jin",
      "Sydney Levine",
      "Fernando Gonzalez",
      "Ojasv Kamal",
      "Maarten Sap",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Josh Tenenbaum",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01478"
  },
  {
    "id": "arXiv:2210.01787",
    "title": "Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean  Function Perspective",
    "abstract": "Comments: 37 pages; to appear in NeurIPS 2022 (Oral)",
    "descriptor": "\nComments: 37 pages; to appear in NeurIPS 2022 (Oral)\n",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01787"
  },
  {
    "id": "arXiv:2210.01808",
    "title": "Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time  Guarantees",
    "abstract": "Comments: Accepte by NeurIPS 2022. arXiv admin note: text overlap with arXiv:2210.01282",
    "descriptor": "\nComments: Accepte by NeurIPS 2022. arXiv admin note: text overlap with arXiv:2210.01282\n",
    "authors": [
      "Siliang Zeng",
      "Chenliang Li",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01808"
  },
  {
    "id": "arXiv:2210.03221",
    "title": "PQLM -- Multilingual Decentralized Portable Quantum Language Model for  Privacy Protection",
    "abstract": "Comments: 5 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Shuyue Stella Li",
      "Xiangyu Zhang",
      "Shu Zhou",
      "Hongchao Shu",
      "Ruixing Liang",
      "Hexin Liu",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03221"
  },
  {
    "id": "arXiv:2210.05311",
    "title": "CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection",
    "abstract": "CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection",
    "descriptor": "",
    "authors": [
      "Wuti Xiong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05311"
  },
  {
    "id": "arXiv:2210.05598",
    "title": "Enriching Biomedical Knowledge for Vietnamese Low-resource Language  Through Large-Scale Translation",
    "abstract": "Enriching Biomedical Knowledge for Vietnamese Low-resource Language  Through Large-Scale Translation",
    "descriptor": "",
    "authors": [
      "Long Phan",
      "Tai Dang",
      "Hieu Tran",
      "Vy Phan",
      "Lam D. Chau",
      "Trieu H. Trinh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.05598"
  },
  {
    "id": "arXiv:2210.06866",
    "title": "Competition among Parallel Contests",
    "abstract": "Comments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)",
    "descriptor": "\nComments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)\n",
    "authors": [
      "Xiaotie Deng",
      "Ningyuan Li",
      "Weian Li",
      "Qi Qi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.06866"
  },
  {
    "id": "arXiv:2210.07323",
    "title": "HuBERT-TR: Reviving Turkish Automatic Speech Recognition with  Self-supervised Speech Representation Learning",
    "abstract": "Comments: Submitted to ICASSP2023",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Ali Safaya",
      "Engin Erzin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07323"
  },
  {
    "id": "arXiv:2210.08066",
    "title": "Optimizing Vision Transformers for Medical Image Segmentation",
    "abstract": "Optimizing Vision Transformers for Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Qianying Liu",
      "Chaitanya Kaul",
      "Jun Wang",
      "Christos Anagnostopoulos",
      "Roderick Murray-Smith",
      "Fani Deligianni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08066"
  },
  {
    "id": "arXiv:2210.08127",
    "title": "Reflections on trusting distributed trust",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Emma Dauterman",
      "Vivian Fang",
      "Natacha Crooks",
      "Raluca Ada Popa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08127"
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": "Comments: updated affiliations; improved references",
    "descriptor": "\nComments: updated affiliations; improved references\n",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08219"
  },
  {
    "id": "arXiv:2210.08323",
    "title": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning",
    "abstract": "Comments: Oral @ NeurIPS 2022, code at this https URL",
    "descriptor": "\nComments: Oral @ NeurIPS 2022, code at this https URL\n",
    "authors": [
      "Haoran Xu",
      "Li Jiang",
      "Jianxiong Li",
      "Xianyuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08323"
  },
  {
    "id": "arXiv:2210.08342",
    "title": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "abstract": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "descriptor": "",
    "authors": [
      "Philipp Scholl",
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08342"
  },
  {
    "id": "arXiv:2210.08545",
    "title": "D/M/1 Queue: Policies and Control",
    "abstract": "Comments: 14 pages; 2 figures",
    "descriptor": "\nComments: 14 pages; 2 figures\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2210.08545"
  },
  {
    "id": "arXiv:2210.08629",
    "title": "A Note On $\\ell$-Rauzy Graphs for the Infinite Fibonacci Word",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Rajavel Praveen M",
      "Rama R"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08629"
  },
  {
    "id": "arXiv:2210.08648",
    "title": "AttTrack: Online Deep Attention Transfer for Multi-object Tracking",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Keivan Nalaie",
      "Rong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08648"
  },
  {
    "id": "arXiv:2210.08809",
    "title": "Effective and Efficient Query-aware Snippet Extraction for Web Search",
    "abstract": "Comments: Accepted by EMNLP2022",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Jingwei Yi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Xiaolong Huang",
      "Binxing Jiao",
      "Guangzhong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08809"
  },
  {
    "id": "arXiv:2210.09505",
    "title": "CNT (Conditioning on Noisy Targets): A new Algorithm for Leveraging  Top-Down Feedback",
    "abstract": "CNT (Conditioning on Noisy Targets): A new Algorithm for Leveraging  Top-Down Feedback",
    "descriptor": "",
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Alex Lamb",
      "Vikas Verma",
      "Aniket Didolkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09505"
  },
  {
    "id": "arXiv:2210.09835",
    "title": "When Age-Invariant Face Recognition Meets Face Age Synthesis: A  Multi-Task Learning Framework and A New Benchmark",
    "abstract": "Comments: TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2103.01520",
    "descriptor": "\nComments: TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2103.01520\n",
    "authors": [
      "Zhizhong Huang",
      "Junping Zhang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09835"
  },
  {
    "id": "arXiv:2210.10335",
    "title": "WebtoonMe: A Data-Centric Approach for Full-Body Portrait Stylization",
    "abstract": "Comments: SIGGRAPH Asia 2022 Technical Communications",
    "descriptor": "\nComments: SIGGRAPH Asia 2022 Technical Communications\n",
    "authors": [
      "Jihye Back",
      "Seungkwon Kim",
      "Namhyuk Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10335"
  },
  {
    "id": "arXiv:2210.10570",
    "title": "Spoofed training data for speech spoofing countermeasure can be  efficiently created using neural vocoders",
    "abstract": "Comments: ICASSP 2023 submission",
    "descriptor": "\nComments: ICASSP 2023 submission\n",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.10570"
  },
  {
    "id": "arXiv:2210.10709",
    "title": "Schema-aware Reference as Prompt Improves Data-Efficient Relational  Triple and Event Extraction",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Yunzhi Yao",
      "Shengyu Mao",
      "Xiang Chen",
      "Ningyu Zhang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10709"
  },
  {
    "id": "arXiv:2210.10985",
    "title": "Large-scale learning of generalised representations for speaker  recognition",
    "abstract": "Comments: 5pages, 5 tables, submitted to ICASSP",
    "descriptor": "\nComments: 5pages, 5 tables, submitted to ICASSP\n",
    "authors": [
      "Jee-weon Jung",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "Jaesong Lee",
      "Hye-jin Shim",
      "Youngki Kwon",
      "Joon Son Chung",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10985"
  },
  {
    "id": "arXiv:2210.11674",
    "title": "WristSketcher: Creating Dynamic Sketches in AR with a Sensing Wristband",
    "abstract": "WristSketcher: Creating Dynamic Sketches in AR with a Sensing Wristband",
    "descriptor": "",
    "authors": [
      "Enting Ying",
      "Tianyang Xiong",
      "Shihui Guo",
      "Ming Qiu",
      "Yipeng Qin",
      "Hongbo Fu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11674"
  },
  {
    "id": "arXiv:2210.11684",
    "title": "Adaptive Control of Unknown Time Varying Dynamical Systems with Regret  Guarantees",
    "abstract": "Adaptive Control of Unknown Time Varying Dynamical Systems with Regret  Guarantees",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Ruijie Du",
      "Yanning Shen",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11684"
  },
  {
    "id": "arXiv:2210.12006",
    "title": "Integrated Brier Score based Survival Cobra -- A regression based  approach",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2209.11919",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.11919\n",
    "authors": [
      "Rahul Goswami",
      "Arabin Kumar Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.12006"
  },
  {
    "id": "arXiv:2210.12234",
    "title": "Imbalanced Classification in Medical Imaging via Regrouping",
    "abstract": "Imbalanced Classification in Medical Imaging via Regrouping",
    "descriptor": "",
    "authors": [
      "Le Peng",
      "Yash Travadi",
      "Rui Zhang",
      "Ying Cui",
      "Ju Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12234"
  },
  {
    "id": "arXiv:2210.12415",
    "title": "ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation",
    "abstract": "ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation",
    "descriptor": "",
    "authors": [
      "Zhiying Xu",
      "Jiafan Xu",
      "Hongding Peng",
      "Wei Wang",
      "Xiaoliang Wang",
      "Haoran Wan",
      "Haipeng Dai",
      "Yixu Xu",
      "Hao Cheng",
      "Kun Wang",
      "Guihai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.12415"
  },
  {
    "id": "arXiv:2210.12548",
    "title": "JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network  for Multi-contrast MRI",
    "abstract": "JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network  for Multi-contrast MRI",
    "descriptor": "",
    "authors": [
      "Lin Zhao",
      "Xiao Chen",
      "Eric Z. Chen",
      "Yikang Liu",
      "Dinggang Shen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12548"
  },
  {
    "id": "arXiv:2210.12551",
    "title": "The Schwarz alternating method for the seamless coupling of nonlinear  reduced order models and full order models",
    "abstract": "The Schwarz alternating method for the seamless coupling of nonlinear  reduced order models and full order models",
    "descriptor": "",
    "authors": [
      "Joshua Barnett",
      "Irina Tezaur",
      "Alejandro Mota"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.12551"
  },
  {
    "id": "arXiv:2210.12582",
    "title": "Language Model Pre-Training with Sparse Latent Typing",
    "abstract": "Comments: EMNLP 2022 (Oral)",
    "descriptor": "\nComments: EMNLP 2022 (Oral)\n",
    "authors": [
      "Liliang Ren",
      "Zixuan Zhang",
      "Han Wang",
      "Clare R. Voss",
      "Chengxiang Zhai",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12582"
  },
  {
    "id": "arXiv:2210.12692",
    "title": "Focus Is What You Need For Chinese Grammatical Error Correction",
    "abstract": "Comments: Submitted to ICASSP2023 (currently under review)",
    "descriptor": "\nComments: Submitted to ICASSP2023 (currently under review)\n",
    "authors": [
      "Jingheng Ye",
      "Yinghui Li",
      "Shirong Ma",
      "Rui Xie",
      "Wei Wu",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12692"
  },
  {
    "id": "arXiv:2210.12698",
    "title": "A class of models for random hypergraphs",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Marc Barthelemy"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.12698"
  },
  {
    "id": "arXiv:2210.12917",
    "title": "A Comparative Qualitative and Quantitative Analysis of the Performance  of Security Options for Message Protocols: Fog Computing Scenario",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Wesley dos Reis Bezerra",
      "Fernando Koch",
      "Carlos Becker Westphall"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.12917"
  },
  {
    "id": "arXiv:2210.13109",
    "title": "Domain Adaptive Segmentation of Electron Microscopy with Sparse Point  Annotations",
    "abstract": "Comments: Accepted by BIBM 2022: International Conference on Bioinformatics & Biomedicine",
    "descriptor": "\nComments: Accepted by BIBM 2022: International Conference on Bioinformatics & Biomedicine\n",
    "authors": [
      "Dafei Qiu",
      "Jiajin Yi",
      "Jialin Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13109"
  },
  {
    "id": "arXiv:2210.13206",
    "title": "Post-Selection Confidence Bounds for Prediction Performance",
    "abstract": "Comments: Changed title, changed layout of figures, added a number to equation 4, added more info to figure captions, added keywords",
    "descriptor": "\nComments: Changed title, changed layout of figures, added a number to equation 4, added more info to figure captions, added keywords\n",
    "authors": [
      "Pascal Rink",
      "Werner Brannath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13206"
  },
  {
    "id": "arXiv:2210.13248",
    "title": "Brouhaha: multi-task training for voice activity detection,  speech-to-noise ratio, and C50 room acoustics estimation",
    "abstract": "Brouhaha: multi-task training for voice activity detection,  speech-to-noise ratio, and C50 room acoustics estimation",
    "descriptor": "",
    "authors": [
      "Marvin Lavechin",
      "Marianne M\u00e9tais",
      "Hadrien Titeux",
      "Alodie Boissonnet",
      "Jade Copet",
      "Morgane Rivi\u00e8re",
      "Elika Bergelson",
      "Alejandrina Cristia",
      "Emmanuel Dupoux",
      "Herv\u00e9 Bredin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.13248"
  },
  {
    "id": "arXiv:2210.13277",
    "title": "Provably Doubly Accelerated Federated Learning: The First Theoretically  Successful Combination of Local Training and Compressed Communication",
    "abstract": "Provably Doubly Accelerated Federated Learning: The First Theoretically  Successful Combination of Local Training and Compressed Communication",
    "descriptor": "",
    "authors": [
      "Laurent Condat",
      "Ivan Agarsk\u00fd",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.13277"
  },
  {
    "id": "arXiv:2210.13318",
    "title": "Time-Domain Speech Enhancement for Robust Automatic Speech Recognition",
    "abstract": "Comments: The co-authors have not approved the current submission",
    "descriptor": "\nComments: The co-authors have not approved the current submission\n",
    "authors": [
      "Yufeng Yang",
      "Ashutosh Pandey",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.13318"
  },
  {
    "id": "arXiv:2210.13397",
    "title": "Development of Hybrid ASR Systems for Low Resource Medical Domain  Conversational Telephone Speech",
    "abstract": "Comments: ASR System Paper for HYKIST project",
    "descriptor": "\nComments: ASR System Paper for HYKIST project\n",
    "authors": [
      "Christoph L\u00fcscher",
      "Mohammad Zeineldeen",
      "Zijian Yang",
      "Peter Vieting",
      "Khai Le-Duc",
      "Weiyue Wang",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.13397"
  },
  {
    "id": "arXiv:2210.13591",
    "title": "Learning by Hallucinating: Vision-Language Pre-training with Weak  Supervision",
    "abstract": "Comments: Accepted to WACV'23. Please find supplementary material at this https URL",
    "descriptor": "\nComments: Accepted to WACV'23. Please find supplementary material at this https URL\n",
    "authors": [
      "Tzu-Jui Julius Wang",
      "Jorma Laaksonen",
      "Tomas Langer",
      "Heikki Arponen",
      "Tom E. Bishop"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13591"
  },
  {
    "id": "arXiv:2210.13722",
    "title": "ARENA: Towards Informative Alternative Query Plan Selection for Database  Education",
    "abstract": "Comments: Add a link to access our ARENA system on the third page",
    "descriptor": "\nComments: Add a link to access our ARENA system on the third page\n",
    "authors": [
      "Hu Wang",
      "Hui Li",
      "Sourav S Bhowmick"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.13722"
  },
  {
    "id": "arXiv:2210.13966",
    "title": "The Debate Over Understanding in AI's Large Language Models",
    "abstract": "Comments: Under submission as a Perspective article",
    "descriptor": "\nComments: Under submission as a Perspective article\n",
    "authors": [
      "Melanie Mitchell",
      "David C. Krakauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.13966"
  },
  {
    "id": "arXiv:2210.14016",
    "title": "Shortest Edit Path Crossover: A Theory-driven Solution to the  Permutation Problem in Evolutionary Neural Architecture Search",
    "abstract": "Comments: 17 pages, 6 figures",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14016"
  },
  {
    "id": "arXiv:2210.14077",
    "title": "Eigen Memory Tree",
    "abstract": "Comments: corrected an author name",
    "descriptor": "\nComments: corrected an author name\n",
    "authors": [
      "Mark Rucker",
      "Jordan T. Ash",
      "John Langford",
      "Paul Mineiro",
      "Ida Momennejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14077"
  },
  {
    "id": "arXiv:2210.14164",
    "title": "Model-Free Prediction of Adversarial Drop Points in 3D Point Clouds",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Hanieh Naderi",
      "Chinthaka Dinesh",
      "Ivan V. Bajic",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14164"
  },
  {
    "id": "arXiv:2210.14226",
    "title": "FedClassAvg: Local Representation Learning for Personalized Federated  Learning on Heterogeneous Neural Networks",
    "abstract": "Comments: Accepted to ICPP 2022. Code: this https URL",
    "descriptor": "\nComments: Accepted to ICPP 2022. Code: this https URL\n",
    "authors": [
      "Jaehee Jang",
      "Heonseok Ha",
      "Dahuin Jung",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.14226"
  },
  {
    "id": "arXiv:2210.14321",
    "title": "Artificial ASMR: A Cyber-Psychological Study",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zexin Fang",
      "Bin Han",
      "C. Clark Cao",
      "Hans. D. Schotten"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.14321"
  },
  {
    "id": "arXiv:2210.14389",
    "title": "Towards standardizing Korean Grammatical Error Correction: Datasets and  Annotation",
    "abstract": "Comments: Add affiliation and email address",
    "descriptor": "\nComments: Add affiliation and email address\n",
    "authors": [
      "Soyoung Yoon",
      "Sungjoon Park",
      "Gyuwan Kim",
      "Junhee Cho",
      "Kihyo Park",
      "Gyu Tae Kim",
      "Minjoon Seo",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14389"
  },
  {
    "id": "arXiv:2210.14404",
    "title": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "abstract": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "descriptor": "",
    "authors": [
      "Zhaoyuan Yang",
      "Zhiwei Xu",
      "Jing Zhang",
      "Richard Hartley",
      "Peter Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14404"
  },
  {
    "id": "arXiv:2210.14441",
    "title": "Towards Automatically Extracting UML Class Diagrams from Natural  Language Specifications",
    "abstract": "Comments: 8 pages, 7 tables, 9 figures, 2 algorithms, to be published in MODELS '22 Companion",
    "descriptor": "\nComments: 8 pages, 7 tables, 9 figures, 2 algorithms, to be published in MODELS '22 Companion\n",
    "authors": [
      "Song Yang",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.14441"
  },
  {
    "id": "arXiv:2210.14446",
    "title": "Smart Speech Segmentation using Acousto-Linguistic Features with  look-ahead",
    "abstract": "Smart Speech Segmentation using Acousto-Linguistic Features with  look-ahead",
    "descriptor": "",
    "authors": [
      "Piyush Behre",
      "Naveen Parihar",
      "Sharman Tan",
      "Amy Shah",
      "Eva Sharma",
      "Geoffrey Liu",
      "Shuangyu Chang",
      "Hosam Khalil",
      "Chris Basoglu",
      "Sayan Pathak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.14446"
  },
  {
    "id": "arXiv:2210.14461",
    "title": "TPFNet: A Novel Text In-painting Transformer for Text Removal",
    "abstract": "Comments: 10 pages, 5 figures, 5 tables, Neurips Proceedings",
    "descriptor": "\nComments: 10 pages, 5 figures, 5 tables, Neurips Proceedings\n",
    "authors": [
      "Onkar Susladkar",
      "Dhruv Makwana",
      "Gayatri Deshmukh",
      "Sparsh Mittal",
      "Sai Chandra Teja R",
      "Rekha Singhal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.14461"
  },
  {
    "id": "arXiv:2210.14509",
    "title": "Parallel Gated Neural Network With Attention Mechanism For Speech  Enhancement",
    "abstract": "Comments: 5 pages, 6 figures, references added",
    "descriptor": "\nComments: 5 pages, 6 figures, references added\n",
    "authors": [
      "Jianqiao Cui",
      "Stefan Bleeck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.14509"
  },
  {
    "id": "arXiv:2210.14534",
    "title": "Efficient Quantized Constant Envelope Precoding for Multiuser Downlink  Massive MIMO Systems",
    "abstract": "Comments: 5 pages, 5 figures, submitted for possible publication",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted for possible publication\n",
    "authors": [
      "Zheyu Wu",
      "Ya-Feng Liu",
      "Bo Jiang",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.14534"
  },
  {
    "id": "arXiv:2210.14543",
    "title": "Diversity Order Analysis for Quantized Constant Envelope Transmission",
    "abstract": "Comments: 9 pages, 3 figures, submitted for possible publication",
    "descriptor": "\nComments: 9 pages, 3 figures, submitted for possible publication\n",
    "authors": [
      "Zheyu Wu",
      "Jiageng Wu",
      "Wei-Kun Chen",
      "Ya-Feng Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.14543"
  },
  {
    "id": "arXiv:2210.14576",
    "title": "Uncertainty Sentence Sampling by Virtual Adversarial Perturbation",
    "abstract": "Uncertainty Sentence Sampling by Virtual Adversarial Perturbation",
    "descriptor": "",
    "authors": [
      "Hanshan Zhang",
      "Zhen Zhang",
      "Hongfei Jiang",
      "Yang Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14576"
  },
  {
    "id": "arXiv:2210.14633",
    "title": "Graph Filter Transfer via Probability Density Ratio Weighting",
    "abstract": "Comments: 5 pages, submitted to ICASSP 2023",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2023\n",
    "authors": [
      "Koki Yamada"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14633"
  },
  {
    "id": "arXiv:2210.14722",
    "title": "Online TSP with Known Locations",
    "abstract": "Online TSP with Known Locations",
    "descriptor": "",
    "authors": [
      "Evripidis Bampis",
      "Bruno Escoffier",
      "Niklas Hahn",
      "Michalis Xefteris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.14722"
  },
  {
    "id": "arXiv:2210.14760",
    "title": "A New Task: Deriving Semantic Class Targets for the Physical Sciences",
    "abstract": "Comments: 6 pages, 1 figure, Accepted at Fifth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2022), Neural Information Processing Systems 2022",
    "descriptor": "\nComments: 6 pages, 1 figure, Accepted at Fifth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2022), Neural Information Processing Systems 2022\n",
    "authors": [
      "Micah Bowles",
      "Hongming Tang",
      "Eleni Vardoulaki",
      "Emma L. Alexander",
      "Yan Luo",
      "Lawrence Rudnick",
      "Mike Walmsley",
      "Fiona Porter",
      "Anna M. M. Scaife",
      "Inigo Val Slijepcevic",
      "Gary Segal"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14760"
  },
  {
    "id": "arXiv:2210.14823",
    "title": "Visual Answer Localization with Cross-modal Mutual Knowledge Transfer",
    "abstract": "Comments: 4 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 4 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yixuan Weng",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14823"
  },
  {
    "id": "arXiv:2210.14862",
    "title": "Visual Semantic Parsing: From Images to Abstract Meaning Representation",
    "abstract": "Comments: published in CoNLL 2022",
    "descriptor": "\nComments: published in CoNLL 2022\n",
    "authors": [
      "Mohamed Ashraf Abdelsalam",
      "Zhan Shi",
      "Federico Fancellu",
      "Kalliopi Basioti",
      "Dhaivat J. Bhatt",
      "Vladimir Pavlovic",
      "Afsaneh Fazly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14862"
  },
  {
    "id": "arXiv:2210.14894",
    "title": "Learning to predict arbitrary quantum processes",
    "abstract": "Comments: 10 pages, 1 figure + 38-page appendix; v2: Added a figure and fixed a minor formatting issue",
    "descriptor": "\nComments: 10 pages, 1 figure + 38-page appendix; v2: Added a figure and fixed a minor formatting issue\n",
    "authors": [
      "Hsin-Yuan Huang",
      "Sitan Chen",
      "John Preskill"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14894"
  }
]
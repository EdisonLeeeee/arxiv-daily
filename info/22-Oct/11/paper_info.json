[
  {
    "id": "arXiv:2210.03734",
    "title": "T2CI-GAN: Text to Compressed Image generation using Generative  Adversarial Network",
    "abstract": "The problem of generating textual descriptions for the visual data has gained\nresearch attention in the recent years. In contrast to that the problem of\ngenerating visual data from textual descriptions is still very challenging,\nbecause it requires the combination of both Natural Language Processing (NLP)\nand Computer Vision techniques. The existing methods utilize the Generative\nAdversarial Networks (GANs) and generate the uncompressed images from textual\ndescription. However, in practice, most of the visual data are processed and\ntransmitted in the compressed representation. Hence, the proposed work attempts\nto generate the visual data directly in the compressed representation form\nusing Deep Convolutional GANs (DCGANs) to achieve the storage and computational\nefficiency. We propose GAN models for compressed image generation from text.\nThe first model is directly trained with JPEG compressed DCT images (compressed\ndomain) to generate the compressed images from text descriptions. The second\nmodel is trained with RGB images (pixel domain) to generate JPEG compressed DCT\nrepresentation from text descriptions. The proposed models are tested on an\nopen source benchmark dataset Oxford-102 Flower images using both RGB and JPEG\ncompressed versions, and accomplished the state-of-the-art performance in the\nJPEG compressed domain. The code will be publicly released at GitHub after\nacceptance of paper.",
    "descriptor": "\nComments: Accepted for publication at IAPR's 6th CVIP 2022\n",
    "authors": [
      "Bulla Rajesh",
      "Nandakishore Dusa",
      "Mohammed Javed",
      "Shiv Ram Dubey",
      "P. Nagabhushan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.03734"
  },
  {
    "id": "arXiv:2210.03735",
    "title": "\"Help Me Help the AI\": Understanding How Explainability Can Support  Human-AI Interaction",
    "abstract": "Despite the proliferation of explainable AI (XAI) methods, little is\nunderstood about end-users' explainability needs. This gap is critical, because\nend-users may have needs that XAI methods should but don't yet support. To\naddress this gap and contribute to understanding how explainability can support\nhuman-AI interaction, we conducted a study of a real-world AI application via\ninterviews with 20 end-users of Merlin, a bird-identification app. We found\nthat people express a need for practically useful information that can improve\ntheir collaboration with the AI system, and intend to use XAI explanations for\ncalibrating trust, improving their task skills, changing their behavior to\nsupply better inputs to the AI system, and giving constructive feedback to\ndevelopers. We also assessed end-users' perceptions of existing XAI approaches,\nfinding that they prefer part-based explanations. Finally, we discuss\nimplications of our findings and provide recommendations for future designs of\nXAI, specifically XAI for human-AI collaboration.",
    "descriptor": "",
    "authors": [
      "Sunnie S. Y. Kim",
      "Elizabeth Anne Watkins",
      "Olga Russakovsky",
      "Ruth Fong",
      "Andr\u00e9s Monroy-Hern\u00e1ndez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03735"
  },
  {
    "id": "arXiv:2210.03737",
    "title": "Exploring Effectiveness of Explanations for Appropriate Trust: Lessons  from Cognitive Psychology",
    "abstract": "The rapid development of Artificial Intelligence (AI) requires developers and\ndesigners of AI systems to focus on the collaboration between humans and\nmachines. AI explanations of system behavior and reasoning are vital for\neffective collaboration by fostering appropriate trust, ensuring understanding,\nand addressing issues of fairness and bias. However, various contextual and\nsubjective factors can influence an AI system explanation's effectiveness. This\nwork draws inspiration from findings in cognitive psychology to understand how\neffective explanations can be designed. We identify four components to which\nexplanation designers can pay special attention: perception, semantics, intent,\nand user & context. We illustrate the use of these four explanation components\nwith an example of estimating food calories by combining text with visuals,\nprobabilities with exemplars, and intent communication with both user and\ncontext in mind. We propose that the significant challenge for effective AI\nexplanations is an additional step between explanation generation using\nalgorithms not producing interpretable explanations and explanation\ncommunication. We believe this extra step will benefit from carefully\nconsidering the four explanation components outlined in our work, which can\npositively affect the explanation's effectiveness.",
    "descriptor": "\nComments: 2022 IEEE Workshop on TRust and EXpertise in Visual Analytics (TREX)\n",
    "authors": [
      "Ruben S. Verhagen",
      "Siddharth Mehrotra",
      "Mark A. Neerincx",
      "Catholijn M. Jonker",
      "Myrthe L. Tielman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03737"
  },
  {
    "id": "arXiv:2210.03740",
    "title": "Equivalent Circuit Modeling and Analysis of Metamaterial Based Wireless  Power Transfer",
    "abstract": "In this study, an equivalent circuit model is presented to emulate the\nbehavior of a metamaterial-based wireless power transfer system. For this\npurpose, the electromagnetic field simulation of the proposed system is\nconducted in ANSYS high frequency structure simulator. In addition, a numerical\nanalysis of the proposed structure is explored to evaluate its transfer\ncharacteristics. The power transfer efficiency of the proposed structure is\nrepresented by the transmission scattering parameter. While some methods,\nincluding interference theory and effective medium theory have been exploited\nto explain the physics mechanism of MM-based WPT systems, some of the reactive\nparameters and the basic physical interpretation have not been clearly\nexpounded. In contrast to existing theoretical model, the proposed approach\nfocuses on the effect of the system parameters and transfer coils on the system\ntransfer characteristics and its effectiveness in analyzing complex circuit.\nNumerical solution of the system transfer characteristics, including the\nscattering parameter and power transfer efficiency is conducted in Matlab. The\ncalculation results based on numerical estimation validates the full wave\nelectromagnetic simulation results, effectively verifying the accuracy of the\nanalytical model.",
    "descriptor": "\nComments: 12 figures, 7 pages, IEEE Electromagnetic Compatibility Conference\n",
    "authors": [
      "Webster Adepoju",
      "Indranil Bhattacharya",
      "Ismail Fidan",
      "Nasr Esfahani Ebrahim",
      "0latunji Abiodun",
      "Ranger Buchanan",
      "Trapa Banik",
      "Muhammad Enagi Bima"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03740"
  },
  {
    "id": "arXiv:2210.03741",
    "title": "Modeling and Analysis of Grid Tied Combined Ultracapacitor Fuel Cell for  Renewable Application",
    "abstract": "In this manuscript, the performance of an ultracapacitor fuel cell in grid\nconnected mode is investigated. Voltage regulation to the ultracapacitor was\nachieved with a three level bidirectional DC-DC converter while also achieving\npower flow from the grid to the ultra-capacitor via the bidirectional\nconverter. The choice of a bidirectional three level converter for voltage\nregulation is based on its inherently high efficiency, low harmonic profile and\ncompact size. Using the model equations of the converter and grid connected\ninverter derived using the switching function approach, the grid's direct and\nquadrature axes modulation indices, Md and Mq, respectively were simulated in\nMatlab for both lagging and leading power factors. Moreover, the values of Md\nand Mq were exploited in a PLECS based simulation of the proposed model to\ndetermine the effect of power factor correction on the current and power\ninjection to grid",
    "descriptor": "\nComments: 7 pages, 16 figures, IEEE conference on Electromagnetic Compatibility\n",
    "authors": [
      "Webster Adepoju",
      "Indranil Bhattacharya",
      "0lufunke Mary Sanyaolu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03741"
  },
  {
    "id": "arXiv:2210.03746",
    "title": "A deep learning approach to solve forward differential problems on  graphs",
    "abstract": "We propose a novel deep learning (DL) approach to solve one-dimensional\nnon-linear elliptic, parabolic, and hyperbolic problems on graphs. A system of\nphysics-informed neural network (PINN) models is used to solve the differential\nequations, by assigning each PINN model to a specific edge of the graph.\nKirkhoff-Neumann (KN) nodal conditions are imposed in a weak form by adding a\npenalization term to the training loss function. Through the penalization term\nthat imposes the KN conditions, PINN models associated with edges that share a\nnode coordinate with each other to ensure continuity of the solution and of its\ndirectional derivatives computed along the respective edges. Using individual\nPINN models for each edge of the graph allows our approach to fulfill necessary\nrequirements for parallelization by enabling different PINN models to be\ntrained on distributed compute resources. Numerical results show that the\nsystem of PINN models accurately approximate the solutions of the differential\nproblems across the entire graph for a broad set of graph topologies.",
    "descriptor": "\nComments: 40 pages, 27 figures\n",
    "authors": [
      "Yuanyuan Zhao",
      "Massimiliano Lupo Pasini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03746"
  },
  {
    "id": "arXiv:2210.03765",
    "title": "Visualize Before You Write: Imagination-Guided Open-Ended Text  Generation",
    "abstract": "Recent advances in text-to-image synthesis make it possible to visualize\nmachine imaginations for a given context. On the other hand, when generating\ntext, human writers are gifted at creative visualization, which enhances their\nwritings by forming imaginations as blueprints before putting down the stories\nin words. Inspired by such a cognitive process, we ask the natural question of\nwhether we can endow machines with the same ability to utilize visual\ninformation and construct a general picture of the context to guide text\ngeneration. In this work, we propose iNLG that uses machine-generated images to\nguide language models (LM) in open-ended text generation. The experiments and\nanalyses demonstrate the effectiveness of iNLG on open-ended text generation\ntasks, including text completion, story generation, and concept-to-text\ngeneration in few-shot scenarios. Both automatic metrics and human evaluations\nverify that the text snippets generated by our iNLG are coherent and\ninformative while displaying minor degeneration.",
    "descriptor": "",
    "authors": [
      "Wanrong Zhu",
      "An Yan",
      "Yujie Lu",
      "Wenda Xu",
      "Xin Eric Wang",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03765"
  },
  {
    "id": "arXiv:2210.03766",
    "title": "FedPC: Federated Learning for Language Generation with Personal and  Context Preference Embeddings",
    "abstract": "Federated learning is a training paradigm that learns from multiple\ndistributed users without aggregating data on a centralized server. Such a\nparadigm promises the ability to deploy machine-learning at-scale to a diverse\npopulation of end-users without first collecting a large, labeled dataset for\nall possible tasks. As federated learning typically averages learning updates\nacross a decentralized population, there is a growing need for personalization\nof federated learning systems (i.e conversational agents must be able to\npersonalize to a specific user's preferences). In this work, we propose a new\ndirection for personalization research within federated learning, leveraging\nboth personal embeddings and shared context embeddings. We also present an\napproach to predict these ``preference'' embeddings, enabling personalization\nwithout backpropagation. Compared to state-of-the-art personalization\nbaselines, our approach achieves a 50\\% improvement in test-time perplexity\nusing 0.001\\% of the memory required by baseline approaches, and achieving\ngreater sample- and compute-efficiency.",
    "descriptor": "\nComments: Andrew Silva and Pradyumna Tambwekar contributed equally towards this work\n",
    "authors": [
      "Andrew Silva",
      "Pradyumna Tambwekar",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03766"
  },
  {
    "id": "arXiv:2210.03768",
    "title": "xDBTagger: Explainable Natural Language Interface to Databases Using  Keyword Mappings and Schema Graph",
    "abstract": "Translating natural language queries (NLQ) into structured query language\n(SQL) in interfaces to relational databases is a challenging task that has been\nwidely studied by researchers from both the database and natural language\nprocessing communities. Numerous works have been proposed to attack the natural\nlanguage interfaces to databases (NLIDB) problem either as a conventional\npipeline-based or an end-to-end deep-learning-based solution. Nevertheless,\nregardless of the approach preferred, such solutions exhibit black-box nature,\nwhich makes it difficult for potential users targeted by these systems to\ncomprehend the decisions made to produce the translated SQL. To this end, we\npropose xDBTagger, an explainable hybrid translation pipeline that explains the\ndecisions made along the way to the user both textually and visually. We also\nevaluate xDBTagger quantitatively in three real-world relational databases. The\nevaluation results indicate that in addition to being fully interpretable,\nxDBTagger is effective in terms of accuracy and translates the queries more\nefficiently compared to other state-of-the-art pipeline-based systems up to\n10000 times.",
    "descriptor": "\nComments: 20 pages, 6 figures. This work is the extended version of arXiv:2101.04226 that appeared in PVLDB'21\n",
    "authors": [
      "Arif Usta",
      "Akifhan Karakayali",
      "\u00d6zg\u00fcr Ulusoy"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03768"
  },
  {
    "id": "arXiv:2210.03772",
    "title": "Traffic-Aware Autonomous Driving with Differentiable Traffic Simulation",
    "abstract": "While there have been advancements in autonomous driving control and traffic\nsimulation, there have been little to no works exploring the unification of\nboth with deep learning. Works in both areas seem to focus on entirely\ndifferent exclusive problems, yet traffic and driving have inherent semantic\nrelations in the real world. In this paper, we present a generalizable\ndistillation-style method for traffic-informed imitation learning that directly\noptimizes a autonomous driving policy for the overall benefit of faster traffic\nflow and lower energy consumption. We capitalize on improving the arbitrarily\ndefined supervision of speed control in imitation learning systems, as most\ndriving research focus on perception and steering. Moreover, our method\naddresses the lack of co-simulation between traffic and driving simulators and\nlays groundwork for directly involving traffic simulation with autonomous\ndriving in future work. Our results show that, with information from traffic\nsimulation involved in supervision of imitation learning methods, an autonomous\nvehicle can learn how to accelerate in a fashion that is beneficial for traffic\nflow and overall energy consumption for all nearby vehicles.",
    "descriptor": "",
    "authors": [
      "Laura Zheng",
      "Sanghyun Son",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03772"
  },
  {
    "id": "arXiv:2210.03773",
    "title": "In What Ways Are Deep Neural Networks Invariant and How Should We  Measure This?",
    "abstract": "It is often said that a deep learning model is \"invariant\" to some specific\ntype of transformation. However, what is meant by this statement strongly\ndepends on the context in which it is made. In this paper we explore the nature\nof invariance and equivariance of deep learning models with the goal of better\nunderstanding the ways in which they actually capture these concepts on a\nformal level. We introduce a family of invariance and equivariance metrics that\nallows us to quantify these properties in a way that disentangles them from\nother metrics such as loss or accuracy. We use our metrics to better understand\nthe two most popular methods used to build invariance into networks: data\naugmentation and equivariant layers. We draw a range of conclusions about\ninvariance and equivariance in deep learning models, ranging from whether\ninitializing a model with pretrained weights has an effect on a trained model's\ninvariance, to the extent to which invariance learned via training can\ngeneralize to out-of-distribution data.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Henry Kvinge",
      "Tegan H. Emerson",
      "Grayson Jorgenson",
      "Scott Vasquez",
      "Timothy Doster",
      "Jesse D. Lew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03773"
  },
  {
    "id": "arXiv:2210.03777",
    "title": "Optimal Energy Shaping Control for a Backdrivable Hip Exoskeleton",
    "abstract": "Task-dependent controllers widely used in exoskeletons track predefined\ntrajectories, which overly constrain the volitional motion of individuals with\nremnant voluntary mobility. Energy shaping, on the other hand, provides\ntask-invariant assistance by altering the human body's dynamic characteristics\nin the closed loop. While human-exoskeleton systems are often modeled using\nEuler-Lagrange equations, in our previous work we modeled the system as a\nport-controlled-Hamiltonian system, and a task-invariant controller was\ndesigned for a knee-ankle exoskeleton using interconnection-damping assignment\npassivity-based control. In this paper, we extend this framework to design a\ncontroller for a backdrivable hip exoskeleton to assist multiple tasks. A set\nof basis functions that contains information of kinematics is selected and\ncorresponding coefficients are optimized, which allows the controller to\nprovide torque that fits normative human torque for different activities of\ndaily life. Human-subject experiments with two able-bodied subjects\ndemonstrated the controller's capability to reduce muscle effort across\ndifferent tasks.",
    "descriptor": "",
    "authors": [
      "Jiefu Zhang",
      "Jianping Lin",
      "Vamsi Peddinti",
      "Robert D. Gregg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03777"
  },
  {
    "id": "arXiv:2210.03778",
    "title": "Optimal Gait Families using Lagrange Multiplier Method",
    "abstract": "The robotic locomotion community is interested in optimal gaits for control.\nBased on the optimization criterion, however, there could be a number of\npossible optimal gaits. For example, the optimal gait for maximizing\ndisplacement with respect to cost is quite different from the maximum\ndisplacement optimal gait. Beyond these two general optimal gaits, we believe\nthat the optimal gait should deal with various situations for high-resolution\nof motion planning, e.g., steering the robot or moving in \"baby steps.\" As the\nstep size or steering ratio increases or decreases, the optimal gaits will\nslightly vary by the geometric relationship and they will form the families of\ngaits. In this paper, we explored the geometrical framework across these\noptimal gaits having different step sizes in the family via the Lagrange\nmultiplier method. Based on the structure, we suggest an optimal locus\ngenerator that solves all related optimal gaits in the family instead of\noptimizing each gait respectively. By applying the optimal locus generator to\ntwo simplified swimmers in drag-dominated environments, we verify the behavior\nof the optimal locus generator.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jinwoo Choi",
      "Capprin Bass",
      "Ross L. Hatton"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03778"
  },
  {
    "id": "arXiv:2210.03780",
    "title": "LOCL: Learning Object-Attribute Composition using Localization",
    "abstract": "This paper describes LOCL (Learning Object Attribute Composition using\nLocalization) that generalizes composition zero shot learning to objects in\ncluttered and more realistic settings. The problem of unseen Object Attribute\n(OA) associations has been well studied in the field, however, the performance\nof existing methods is limited in challenging scenes. In this context, our key\ncontribution is a modular approach to localizing objects and attributes of\ninterest in a weakly supervised context that generalizes robustly to unseen\nconfigurations. Localization coupled with a composition classifier\nsignificantly outperforms state of the art (SOTA) methods, with an improvement\nof about 12% on currently available challenging datasets. Further, the\nmodularity enables the use of localized feature extractor to be used with\nexisting OA compositional learning methods to improve their overall\nperformance.",
    "descriptor": "\nComments: 20 pages, 7 figures, 11 tables, Accepted in British Machine Vision Conference 2022\n",
    "authors": [
      "Satish Kumar",
      "ASM Iftekhar",
      "Ekta Prashnani",
      "B.S.Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03780"
  },
  {
    "id": "arXiv:2210.03786",
    "title": "Evaluating the Performance of StyleGAN2-ADA on Medical Images",
    "abstract": "Although generative adversarial networks (GANs) have shown promise in medical\nimaging, they have four main limitations that impeded their utility:\ncomputational cost, data requirements, reliable evaluation measures, and\ntraining complexity. Our work investigates each of these obstacles in a novel\napplication of StyleGAN2-ADA to high-resolution medical imaging datasets. Our\ndataset is comprised of liver-containing axial slices from non-contrast and\ncontrast-enhanced computed tomography (CT) scans. Additionally, we utilized\nfour public datasets composed of various imaging modalities. We trained a\nStyleGAN2 network with transfer learning (from the Flickr-Faces-HQ dataset) and\ndata augmentation (horizontal flipping and adaptive discriminator\naugmentation). The network's generative quality was measured quantitatively\nwith the Fr\\'echet Inception Distance (FID) and qualitatively with a visual\nTuring test given to seven radiologists and radiation oncologists.\nThe StyleGAN2-ADA network achieved a FID of 5.22 ($\\pm$ 0.17) on our liver CT\ndataset. It also set new record FIDs of 10.78, 3.52, 21.17, and 5.39 on the\npublicly available SLIVER07, ChestX-ray14, ACDC, and Medical Segmentation\nDecathlon (brain tumors) datasets. In the visual Turing test, the clinicians\nrated generated images as real 42% of the time, approaching random guessing.\nOur computational ablation study revealed that transfer learning and data\naugmentation stabilize training and improve the perceptual quality of the\ngenerated images. We observed the FID to be consistent with human perceptual\nevaluation of medical images. Finally, our work found that StyleGAN2-ADA\nconsistently produces high-quality results without hyperparameter searches or\nretraining.",
    "descriptor": "\nComments: This preprint has not undergone post-submission improvements or corrections. The Version of Record of this contribution is published in LNCS, volume 13570, and is available online at this https URL\n",
    "authors": [
      "McKell Woodland",
      "John Wood",
      "Brian M. Anderson",
      "Suprateek Kundu",
      "Ethan Lin",
      "Eugene Koay",
      "Bruno Odisio",
      "Caroline Chung",
      "Hyunseon Christine Kang",
      "Aradhana M. Venkatesan",
      "Sireesha Yedururi",
      "Brian De",
      "Yuan-Mao Lin",
      "Ankit B. Patel",
      "Kristy K. Brock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03786"
  },
  {
    "id": "arXiv:2210.03787",
    "title": "Learning a Visually Grounded Memory Assistant",
    "abstract": "We introduce a novel interface for large scale collection of human memory and\nassistance. Using the 3D Matterport simulator we create a realistic indoor\nenvironments in which we have people perform specific embodied memory tasks\nthat mimic household daily activities. This interface was then deployed on\nAmazon Mechanical Turk allowing us to test and record human memory, navigation\nand needs for assistance at a large scale that was previously impossible. Using\nthe interface we collect the `The Visually Grounded Memory Assistant Dataset'\nwhich is aimed at developing our understanding of (1) the information people\nencode during navigation of 3D environments and (2) conditions under which\npeople ask for memory assistance. Additionally we experiment with with\npredicting when people will ask for assistance using models trained on\nhand-selected visual and semantic features. This provides an opportunity to\nbuild stronger ties between the machine-learning and cognitive-science\ncommunities through learned models of human perception, memory, and cognition.",
    "descriptor": "",
    "authors": [
      "Meera Hahn",
      "Kevin Carlberg",
      "Ruta Desai",
      "James Hillis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03787"
  },
  {
    "id": "arXiv:2210.03792",
    "title": "Self-Aligned Concave Curve: Illumination Enhancement for Unsupervised  Adaptation",
    "abstract": "Low light conditions not only degrade human visual experience, but also\nreduce the performance of downstream machine analytics. Although many works\nhave been designed for low-light enhancement or domain adaptive machine\nanalytics, the former considers less on high-level vision, while the latter\nneglects the potential of image-level signal adjustment. How to restore\nunderexposed images/videos from the perspective of machine vision has long been\noverlooked. In this paper, we are the first to propose a learnable illumination\nenhancement model for high-level vision. Inspired by real camera response\nfunctions, we assume that the illumination enhancement function should be a\nconcave curve, and propose to satisfy this concavity through discrete integral.\nWith the intention of adapting illumination from the perspective of machine\nvision without task-specific annotated data, we design an asymmetric\ncross-domain self-supervised training strategy. Our model architecture and\ntraining designs mutually benefit each other, forming a powerful unsupervised\nnormal-to-low light adaptation framework. Comprehensive experiments demonstrate\nthat our method surpasses existing low-light enhancement and adaptation methods\nand shows superior generalization on various low-light vision tasks, including\nclassification, detection, action recognition, and optical flow estimation.\nProject website: https://daooshee.github.io/SACC-Website/",
    "descriptor": "\nComments: This paper has been accepted by ACM Multimedia 2022\n",
    "authors": [
      "Wenjing Wang",
      "Zhengbo Xu",
      "Haofeng Huang",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03792"
  },
  {
    "id": "arXiv:2210.03794",
    "title": "SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained  Models",
    "abstract": "Vision-language models such as CLIP are pretrained on large volumes of\ninternet sourced image and text pairs, and have been shown to sometimes exhibit\nimpressive zero- and low-shot image classification performance. However, due to\ntheir size, fine-tuning these models on new datasets can be prohibitively\nexpensive, both in terms of the supervision and compute required. To combat\nthis, a series of light-weight adaptation methods have been proposed to\nefficiently adapt such models when limited supervision is available. In this\nwork, we show that while effective on internet-style datasets, even those\nremedies under-deliver on classification tasks with images that differ\nsignificantly from those commonly found online. To address this issue, we\npresent a new approach called SVL-Adapter that combines the complementary\nstrengths of both vision-language pretraining and self-supervised\nrepresentation learning. We report an average classification accuracy\nimprovement of 10% in the low-shot setting when compared to existing methods,\non a set of challenging visual classification tasks. Further, we present a\nfully automatic way of selecting an important blending hyperparameter for our\nmodel that does not require any held-out labeled validation data. Code for our\nproject is available here: https://github.com/omipan/svl_adapter.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Omiros Pantazis",
      "Gabriel Brostow",
      "Kate Jones",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03794"
  },
  {
    "id": "arXiv:2210.03797",
    "title": "Named Entity Recognition in Twitter: A Dataset and Analysis on  Short-Term Temporal Shifts",
    "abstract": "Recent progress in language model pre-training has led to important\nimprovements in Named Entity Recognition (NER). Nonetheless, this progress has\nbeen mainly tested in well-formatted documents such as news, Wikipedia, or\nscientific articles. In social media the landscape is different, in which it\nadds another layer of complexity due to its noisy and dynamic nature. In this\npaper, we focus on NER in Twitter, one of the largest social media platforms,\nand construct a new NER dataset, TweetNER7, which contains seven entity types\nannotated over 11,382 tweets from September 2019 to August 2021. The dataset\nwas constructed by carefully distributing the tweets over time and taking\nrepresentative trends as a basis. Along with the dataset, we provide a set of\nlanguage model baselines and perform an analysis on the language model\nperformance on the task, especially analyzing the impact of different time\nperiods. In particular, we focus on three important temporal aspects in our\nanalysis: short-term degradation of NER models over time, strategies to\nfine-tune a language model over different periods, and self-labeling as an\nalternative to lack of recently-labeled data. TweetNER7 is released publicly\n(https://huggingface.co/datasets/tner/tweetner7) along with the models\nfine-tuned on it (NER models have been integrated into TweetNLP and can be\nfound athttps://github.com/asahi417/tner/tree/master/examples/tweetner7_paper).",
    "descriptor": "\nComments: AACL 2022 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Leonardo Neves",
      "Vitor Silva",
      "Francesco Barbieri",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03797"
  },
  {
    "id": "arXiv:2210.03798",
    "title": "Computational performance of the MMOC in the inverse design of the  Doswell frontogenesis equation",
    "abstract": "Inverse design of transport equations can be addressed by using a\ngradient-adjoint methodology. In this methodology numerical schemes used for\nthe adjoint resolution determine the direction of descent in its iterative\nalgorithm, and consequently the CPU time consumed by the inverse design. As the\nCPU time constitutes a known bottleneck, it is important to employ light and\nquick schemes to the adjoint problem. In this regard, we proposed to use the\nModified Method of Characteristics (MMOC). Despite not preserving identity\nconservation, the MMOC is computationally competitive. In this work we\ninvestigated the advantage of using the MMOC in comparison with the\nLax-Friedrichs and Lax-Wendro? schemes for the inverse design problem. By\ntesting the Doswell frontogenesis equation, we observed that the MMOC can\nprovide more efficient and accurate computation under some simulation\nconditions.",
    "descriptor": "",
    "authors": [
      "Alexandre Francisco",
      "Umberto Biccari",
      "Enrique Zuazua"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03798"
  },
  {
    "id": "arXiv:2210.03799",
    "title": "Supervised and Unsupervised Learning of Audio Representations for Music  Understanding",
    "abstract": "In this work, we provide a broad comparative analysis of strategies for\npre-training audio understanding models for several tasks in the music domain,\nincluding labelling of genre, era, origin, mood, instrumentation, key, pitch,\nvocal characteristics, tempo and sonority. Specifically, we explore how the\ndomain of pre-training datasets (music or generic audio) and the pre-training\nmethodology (supervised or unsupervised) affects the adequacy of the resulting\naudio embeddings for downstream tasks.\nWe show that models trained via supervised learning on large-scale\nexpert-annotated music datasets achieve state-of-the-art performance in a wide\nrange of music labelling tasks, each with novel content and vocabularies. This\ncan be done in an efficient manner with models containing less than 100 million\nparameters that require no fine-tuning or reparameterization for downstream\ntasks, making this approach practical for industry-scale audio catalogs.\nWithin the class of unsupervised learning strategies, we show that the domain\nof the training dataset can significantly impact the performance of\nrepresentations learned by the model. We find that restricting the domain of\nthe pre-training dataset to music allows for training with smaller batch sizes\nwhile achieving state-of-the-art in unsupervised learning -- and in some cases,\nsupervised learning -- for music understanding.\nWe also corroborate that, while achieving state-of-the-art performance on\nmany tasks, supervised learning can cause models to specialize to the\nsupervised information provided, somewhat compromising a model's generality.",
    "descriptor": "",
    "authors": [
      "Matthew C. McCallum",
      "Filip Korzeniowski",
      "Sergio Oramas",
      "Fabien Gouyon",
      "Andreas F. Ehmann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03799"
  },
  {
    "id": "arXiv:2210.03800",
    "title": "Data Feel: Exploring Visual Effects in Video Games to Support  Sensemaking Tasks",
    "abstract": "This paper explores the use of visual effects common in video games that\nsupport a range of tasks that are similar in many ways to analysis tasks\nsupported in visual analytics tools. While some visual effects are meant to\nincrease engagement or to support a game's overall visual design, we find that\nin many games visual effects are used throughout gameplay in order to assist a\nplayer in reasoning about the game world. In this work, we survey popular games\nacross a range of categories (from casual games to \"Triple A\" games), focusing\nspecifically on visual effects that support a player's sensemaking within the\ngame world. Based on our analysis of these games, we identify a range of tasks\nthat could benefit from the use of \"data feel,\" and advocate for the continued\ninvestigation of visual effects and their application in data visualization\nsoftware tools.",
    "descriptor": "\nComments: 7 pages, 5 figures, VIS4DH 2022\n",
    "authors": [
      "Hongwei Zhou",
      "Angus G. Forbes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03800"
  },
  {
    "id": "arXiv:2210.03801",
    "title": "Augmentations in Hypergraph Contrastive Learning: Fabricated and  Generative",
    "abstract": "This paper targets at improving the generalizability of hypergraph neural\nnetworks in the low-label regime, through applying the contrastive learning\napproach from images/graphs (we refer to it as HyperGCL). We focus on the\nfollowing question: How to construct contrastive views for hypergraphs via\naugmentations? We provide the solutions in two folds. First, guided by domain\nknowledge, we fabricate two schemes to augment hyperedges with higher-order\nrelations encoded, and adopt three vertex augmentation strategies from\ngraph-structured data. Second, in search of more effective views in a\ndata-driven manner, we for the first time propose a hypergraph generative model\nto generate augmented views, and then an end-to-end differentiable pipeline to\njointly learn hypergraph augmentations and model parameters. Our technical\ninnovations are reflected in designing both fabricated and generative\naugmentations of hypergraphs. The experimental findings include: (i) Among\nfabricated augmentations in HyperGCL, augmenting hyperedges provides the most\nnumerical gains, implying that higher-order information in structures is\nusually more downstream-relevant; (ii) Generative augmentations do better in\npreserving higher-order information to further benefit generalizability; (iii)\nHyperGCL also boosts robustness and fairness in hypergraph representation\nlearning. Codes are released at https://github.com/weitianxin/HyperGCL.",
    "descriptor": "\nComments: NeurIPS 2022. Supplementary materials are available at this https URL\n",
    "authors": [
      "Tianxin Wei",
      "Yuning You",
      "Tianlong Chen",
      "Yang Shen",
      "Jingrui He",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03801"
  },
  {
    "id": "arXiv:2210.03802",
    "title": "Conservative Bayesian Model-Based Value Expansion for Offline Policy  Optimization",
    "abstract": "Offline reinforcement learning (RL) addresses the problem of learning a\nperformant policy from a fixed batch of data collected by following some\nbehavior policy. Model-based approaches are particularly appealing in the\noffline setting since they can extract more learning signals from the logged\ndataset by learning a model of the environment. However, the performance of\nexisting model-based approaches falls short of model-free counterparts, due to\nthe compounding of estimation errors in the learned model. Driven by this\nobservation, we argue that it is critical for a model-based method to\nunderstand when to trust the model and when to rely on model-free estimates,\nand how to act conservatively w.r.t. both. To this end, we derive an elegant\nand simple methodology called conservative Bayesian model-based value expansion\nfor offline policy optimization (CBOP), that trades off model-free and\nmodel-based estimates during the policy evaluation step according to their\nepistemic uncertainties, and facilitates conservatism by taking a lower bound\non the Bayesian posterior value estimate. On the standard D4RL continuous\ncontrol tasks, we find that our method significantly outperforms previous\nmodel-based approaches: e.g., MOPO by $116.4$%, MOReL by $23.2$% and COMBO by\n$23.7$%. Further, CBOP achieves state-of-the-art performance on $11$ out of\n$18$ benchmark datasets while doing on par on the remaining datasets.",
    "descriptor": "",
    "authors": [
      "Jihwan Jeong",
      "Xiaoyu Wang",
      "Michael Gimelfarb",
      "Hyunwoo Kim",
      "Baher Abdulhai",
      "Scott Sanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03802"
  },
  {
    "id": "arXiv:2210.03804",
    "title": "Understanding and Supporting Debugging Workflows in Multiverse Analysis",
    "abstract": "Multiverse analysis-a paradigm for statistical analysis that considers all\ncombinations of reasonable analysis choices in parallel-promises to improve\ntransparency and reproducibility. Although recent tools help analysts specify\nmultiverse analyses, they remain difficult to use in practice. In this work, we\nconduct a formative study with four multiverse researchers, which identifies\ndebugging as a key barrier. We find debugging is challenging because of the\nlatency between running analyses and detecting bugs, and the scale of metadata\nneeded to be processed to diagnose a bug. To address these challenges, we\nprototype a command-line interface tool, Multiverse Debugger, which helps\ndiagnose bugs in the multiverse and propagate fixes. In a second, focused study\n(n=13), we use Multiverse Debugger as a probe to develop a model of debugging\nworkflows and identify challenges, including the difficulty in understanding\nthe composition of a multiverse. We conclude with design implications for\nfuture multiverse analysis authoring systems.",
    "descriptor": "",
    "authors": [
      "Ken Gu",
      "Eunice Jun",
      "Tim Althoff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.03804"
  },
  {
    "id": "arXiv:2210.03809",
    "title": "Retrieval Augmented Visual Question Answering with Outside Knowledge",
    "abstract": "Outside-Knowledge Visual Question Answering (OK-VQA) is a challenging VQA\ntask that requires retrieval of external knowledge to answer questions about\nimages. Recent OK-VQA systems use Dense Passage Retrieval (DPR) to retrieve\ndocuments from external knowledge bases, such as Wikipedia, but with DPR\ntrained separately from answer generation, introducing a potential limit on the\noverall system performance. Instead, we propose a joint training scheme which\nincludes differentiable DPR integrated with answer generation so that the\nsystem can be trained in an end-to-end fashion. Our experiments show that our\nscheme outperforms recent OK-VQA systems with strong DPR for retrieval. We also\nintroduce new diagnostic metrics to analyze how retrieval and generation\ninteract. The strong retrieval ability of our model significantly reduces the\nnumber of retrieved documents needed in training, yielding significant benefits\nin answer quality and computation required for training.",
    "descriptor": "\nComments: Accepted to appear at the main conference of EMNLP 2022. The camera-ready version will be uploaded soon\n",
    "authors": [
      "Weizhe Lin",
      "Bill Byrne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03809"
  },
  {
    "id": "arXiv:2210.03811",
    "title": "An Approximation Algorithm for Distance-Constrained Vehicle Routing on  Trees",
    "abstract": "In the Distance-constrained Vehicle Routing Problem (DVRP), we are given a\ngraph with integer edge weights, a depot, a set of $n$ terminals, and a\ndistance constraint $D$. The goal is to find a minimum number of tours starting\nand ending at the depot such that those tours together cover all the terminals\nand the length of each tour is at most $D$.\nThe DVRP on trees is of independent interest, because it is equivalent to the\nvirtual machine packing problem on trees studied by Sindelar et al. [SPAA'11].\nWe design a simple and natural approximation algorithm for the tree DVRP,\nparameterized by $\\varepsilon >0$. We show that its approximation ratio is\n$\\alpha + \\varepsilon$, where $\\alpha \\approx 1.691$, and in addition, that our\nanalysis is essentially tight. The running time is polynomial in $n$ and $D$.\nThe approximation ratio improves on the ratio of 2 due to Nagarajan and Ravi\n[Networks'12].\nThe main novelty of this paper lies in the analysis of the algorithm. It\nrelies on a reduction from the tree DVRP to the bounded space online bin\npacking problem via a new notion of reduced length.",
    "descriptor": "",
    "authors": [
      "Marc Dufay",
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03811"
  },
  {
    "id": "arXiv:2210.03815",
    "title": "Scene-level Tracking and Reconstruction without Object Priors",
    "abstract": "We present the first real-time system capable of tracking and reconstructing,\nindividually, every visible object in a given scene, without any form of prior\non the rigidness of the objects, texture existence, or object category. In\ncontrast with previous methods such as Co-Fusion and MaskFusion that first\nsegment the scene into individual objects and then process each object\nindependently, the proposed method dynamically segments the non-rigid scene as\npart of the tracking and reconstruction process. When new measurements indicate\ntopology change, reconstructed models are updated in real-time to reflect that\nchange. Our proposed system can provide the live geometry and deformation of\nall visible objects in a novel scene in real-time, which makes it possible to\nbe integrated seamlessly into numerous existing robotics applications that rely\non object models for grasping and manipulation. The capabilities of the\nproposed system are demonstrated in challenging scenes that contain multiple\nrigid and non-rigid objects.",
    "descriptor": "\nComments: Accepted by IROS2022\n",
    "authors": [
      "Haonan Chang",
      "Abdeslam Boularias"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.03815"
  },
  {
    "id": "arXiv:2210.03820",
    "title": "The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks",
    "abstract": "In this work, we explore the maximum-margin bias of quasi-homogeneous neural\nnetworks trained with gradient flow on an exponential loss and past a point of\nseparability. We introduce the class of quasi-homogeneous models, which is\nexpressive enough to describe nearly all neural networks with homogeneous\nactivations, even those with biases, residual connections, and normalization\nlayers, while structured enough to enable geometric analysis of its gradient\ndynamics. Using this analysis, we generalize the existing results of\nmaximum-margin bias for homogeneous networks to this richer class of models. We\nfind that gradient flow implicitly favors a subset of the parameters, unlike in\nthe case of a homogeneous model where all parameters are treated equally. We\ndemonstrate through simple examples how this strong favoritism toward\nminimizing an asymmetric norm can degrade the robustness of quasi-homogeneous\nmodels. On the other hand, we conjecture that this norm-minimization discards,\nwhen possible, unnecessary higher-order parameters, reducing the model to a\nsparser parameterization. Lastly, by applying our theorem to sufficiently\nexpressive neural networks with normalization layers, we reveal a universal\nmechanism behind the empirical phenomenon of Neural Collapse.",
    "descriptor": "\nComments: 33 pages, 5 figures\n",
    "authors": [
      "Daniel Kunin",
      "Atsushi Yamamura",
      "Chao Ma",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03820"
  },
  {
    "id": "arXiv:2210.03821",
    "title": "In-Context Policy Iteration",
    "abstract": "This work presents In-Context Policy Iteration, an algorithm for performing\nReinforcement Learning (RL), in-context, using foundation models. While the\napplication of foundation models to RL has received considerable attention,\nmost approaches rely on either (1) the curation of expert demonstrations\n(either through manual design or task-specific pretraining) or (2) adaptation\nto the task of interest using gradient methods (either fine-tuning or training\nof adapter layers). Both of these techniques have drawbacks. Collecting\ndemonstrations is labor-intensive, and algorithms that rely on them do not\noutperform the experts from which the demonstrations were derived. All gradient\ntechniques are inherently slow, sacrificing the \"few-shot\" quality that made\nin-context learning attractive to begin with. In this work, we present an\nalgorithm, ICPI, that learns to perform RL tasks without expert demonstrations\nor gradients. Instead we present a policy-iteration method in which the prompt\ncontent is the entire locus of learning. ICPI iteratively updates the contents\nof the prompt from which it derives its policy through trial-and-error\ninteraction with an RL environment. In order to eliminate the role of\nin-weights learning (on which approaches like Decision Transformer rely\nheavily), we demonstrate our algorithm using Codex, a language model with no\nprior knowledge of the domains on which we evaluate it.",
    "descriptor": "\nComments: 10 pages, 4 figures, submitted to ICLR 2023\n",
    "authors": [
      "Ethan Brooks",
      "Logan Walls",
      "Richard L. Lewis",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03821"
  },
  {
    "id": "arXiv:2210.03822",
    "title": "Is margin all you need? An extensive empirical study of active learning  on tabular data",
    "abstract": "Given a labeled training set and a collection of unlabeled data, the goal of\nactive learning (AL) is to identify the best unlabeled points to label. In this\ncomprehensive study, we analyze the performance of a variety of AL algorithms\non deep neural networks trained on 69 real-world tabular classification\ndatasets from the OpenML-CC18 benchmark. We consider different data regimes and\nthe effect of self-supervised model pre-training. Surprisingly, we find that\nthe classical margin sampling technique matches or outperforms all others,\nincluding current state-of-art, in a wide range of experimental settings. To\nresearchers, we hope to encourage rigorous benchmarking against margin, and to\npractitioners facing tabular data labeling constraints that\nhyper-parameter-free margin may often be all they need.",
    "descriptor": "",
    "authors": [
      "Dara Bahri",
      "Heinrich Jiang",
      "Tal Schuster",
      "Afshin Rostamizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03822"
  },
  {
    "id": "arXiv:2210.03825",
    "title": "See, Plan, Predict: Language-guided Cognitive Planning with Video  Prediction",
    "abstract": "Cognitive planning is the structural decomposition of complex tasks into a\nsequence of future behaviors. In the computational setting, performing\ncognitive planning entails grounding plans and concepts in one or more\nmodalities in order to leverage them for low level control. Since real-world\ntasks are often described in natural language, we devise a cognitive planning\nalgorithm via language-guided video prediction. Current video prediction models\ndo not support conditioning on natural language instructions. Therefore, we\npropose a new video prediction architecture which leverages the power of\npre-trained transformers.The network is endowed with the ability to ground\nconcepts based on natural language input with generalization to unseen objects.\nWe demonstrate the effectiveness of this approach on a new simulation dataset,\nwhere each task is defined by a high-level action described in natural\nlanguage. Our experiments compare our method again stone video generation\nbaseline without planning or action grounding and showcase significant\nimprovements. Our ablation studies highlight an improved generalization to\nunseen objects that natural language embeddings offer to concept grounding\nability, as well as the importance of planning towards visual \"imagination\" of\na task.",
    "descriptor": "",
    "authors": [
      "Maria Attarian",
      "Advaya Gupta",
      "Ziyi Zhou",
      "Wei Yu",
      "Igor Gilitschenski",
      "Animesh Garg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03825"
  },
  {
    "id": "arXiv:2210.03826",
    "title": "An Analysis of the Effects of Decoding Algorithms on Fairness in  Open-Ended Language Generation",
    "abstract": "Several prior works have shown that language models (LMs) can generate text\ncontaining harmful social biases and stereotypes. While decoding algorithms\nplay a central role in determining properties of LM generated text, their\nimpact on the fairness of the generations has not been studied. We present a\nsystematic analysis of the impact of decoding algorithms on LM fairness, and\nanalyze the trade-off between fairness, diversity and quality. Our experiments\nwith top-$p$, top-$k$ and temperature decoding algorithms, in open-ended\nlanguage generation, show that fairness across demographic groups changes\nsignificantly with change in decoding algorithm's hyper-parameters. Notably,\ndecoding algorithms that output more diverse text also output more texts with\nnegative sentiment and regard. We present several findings and provide\nrecommendations on standardized reporting of decoding details in fairness\nevaluations and optimization of decoding algorithms for fairness alongside\nquality and diversity.",
    "descriptor": "\nComments: Accepted at IEEE SLT 2022\n",
    "authors": [
      "Jwala Dhamala",
      "Varun Kumar",
      "Rahul Gupta",
      "Kai-Wei Chang",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03826"
  },
  {
    "id": "arXiv:2210.03828",
    "title": "Sampling-Based Decomposition Algorithms for Arbitrary Tensor Networks",
    "abstract": "We show how to develop sampling-based alternating least squares (ALS)\nalgorithms for decomposition of tensors into any tensor network (TN) format.\nProvided the TN format satisfies certain mild assumptions, resulting algorithms\nwill have input sublinear per-iteration cost. Unlike most previous works on\nsampling-based ALS methods for tensor decomposition, the sampling in our\nframework is done according to the exact leverage score distribution of the\ndesign matrices in the ALS subproblems. We implement and test two tensor\ndecomposition algorithms that use our sampling framework in a feature\nextraction experiment where we compare them against a number of other\ndecomposition algorithms.",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Osman Asif Malik",
      "Vivek Bharadwaj",
      "Riley Murray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03828"
  },
  {
    "id": "arXiv:2210.03829",
    "title": "Early Detection of Bark Beetle Attack Using Remote Sensing and Machine  Learning: A Review",
    "abstract": "Bark beetle outbreaks can result in a devastating impact on forest ecosystem\nprocesses, biodiversity, forest structure and function, and economies. Accurate\nand timely detection of bark beetle infestations is crucial to mitigate further\ndamage, develop proactive forest management activities, and minimize economic\nlosses. Incorporating remote sensing (RS) data with machine learning (ML) (or\ndeep learning (DL)) can provide a great alternative to the current approaches\nthat rely on aerial surveys and field surveys, which are impractical over vast\ngeographical regions. This paper provides a comprehensive review of past and\ncurrent advances in the early detection of bark beetle-induced tree mortality\nfrom three key perspectives: bark beetle & host interactions, RS, and ML/DL. We\nparse recent literature according to bark beetle species & attack phases, host\ntrees, study regions, imagery platforms & sensors, spectral/spatial/temporal\nresolutions, spectral signatures, spectral vegetation indices (SVIs), ML\napproaches, learning schemes, task categories, models, algorithms,\nclasses/clusters, features, and DL networks & architectures. This review\nfocuses on challenging early detection, discussing current challenges and\npotential solutions. Our literature survey suggests that the performance of\ncurrent ML methods is limited (less than 80%) and depends on various factors,\nincluding imagery sensors & resolutions, acquisition dates, and employed\nfeatures & algorithms/networks. A more promising result from DL networks and\nthen the random forest (RF) algorithm highlighted the potential to detect\nsubtle changes in visible, thermal, and short-wave infrared (SWIR) spectral\nregions.",
    "descriptor": "\nComments: Under review, 33 pages, 5 figures, 8 Tables\n",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03829"
  },
  {
    "id": "arXiv:2210.03831",
    "title": "How to Make Your Approximation Algorithm Private: A Black-Box  Differentially-Private Transformation for Tunable Approximation Algorithms of  Functions with Low Sensitivity",
    "abstract": "We develop a framework for efficiently transforming certain approximation\nalgorithms into differentially-private variants, in a black-box manner. Our\nresults focus on algorithms A that output an approximation to a function f of\nthe form $(1-a)f(x)-k <= A(x) <= (1+a)f(x)+k$, where 0<=a <1 is a parameter\nthat can be``tuned\" to small-enough values while incurring only a poly blowup\nin the running time/space. We show that such algorithms can be made DP without\nsacrificing accuracy, as long as the function f has small global sensitivity.\nWe achieve these results by applying the smooth sensitivity framework developed\nby Nissim, Raskhodnikova, and Smith (STOC 2007).\nOur framework naturally applies to transform non-private FPRAS (resp. FPTAS)\nalgorithms into $(\\epsilon,\\delta)$-DP (resp. $\\epsilon$-DP) approximation\nalgorithms. We apply our framework in the context of sublinear-time and\nsublinear-space algorithms, while preserving the nature of the algorithm in\nmeaningful ranges of the parameters. Our results include the first (to the best\nof our knowledge) $(\\epsilon,\\delta)$-edge DP sublinear-time algorithm for\nestimating the number of triangles, the number of connected components, and the\nweight of a MST of a graph, as well as a more efficient algorithm (while\nsacrificing pure DP in contrast to previous results) for estimating the average\ndegree of a graph. In the area of streaming algorithms, our results include\n$(\\epsilon,\\delta)$-DP algorithms for estimating L_p-norms, distinct elements,\nand weighted MST for both insertion-only and turnstile streams. Our\ntransformation also provides a private version of the smooth histogram\nframework, which is commonly used for converting streaming algorithms into\nsliding window variants, and achieves a multiplicative approximation to many\nproblems, such as estimating L_p-norms, distinct elements, and the length of\nthe longest increasing subsequence.",
    "descriptor": "",
    "authors": [
      "Jeremiah Blocki",
      "Elena Grigorescu",
      "Tamalika Mukherjee",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03831"
  },
  {
    "id": "arXiv:2210.03836",
    "title": "Learning the Dynamics of Compliant Tool-Environment Interaction for  Visuo-Tactile Contact Servoing",
    "abstract": "Many manipulation tasks require the robot to control the contact between a\ngrasped compliant tool and the environment, e.g. scraping a frying pan with a\nspatula. However, modeling tool-environment interaction is difficult,\nespecially when the tool is compliant, and the robot cannot be expected to have\nthe full geometry and physical properties (e.g., mass, stiffness, and friction)\nof all the tools it must use. We propose a framework that learns to predict the\neffects of a robot's actions on the contact between the tool and the\nenvironment given visuo-tactile perception. Key to our framework is a novel\ncontact feature representation that consists of a binary contact value, the\nline of contact, and an end-effector wrench. We propose a method to learn the\ndynamics of these contact features from real world data that does not require\npredicting the geometry of the compliant tool. We then propose a controller\nthat uses this dynamics model for visuo-tactile contact servoing and show that\nit is effective at performing scraping tasks with a spatula, even in scenarios\nwhere precise contact needs to be made to avoid obstacles.",
    "descriptor": "\nComments: 6th Conference on Robotic Learning (CoRL 2022), Auckland, New Zealand. 8 pages + references + appendix\n",
    "authors": [
      "Mark Van der Merwe",
      "Dmitry Berenson",
      "Nima Fazeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03836"
  },
  {
    "id": "arXiv:2210.03838",
    "title": "Learning to embed semantic similarity for joint image-text retrieval",
    "abstract": "We present a deep learning approach for learning the joint semantic\nembeddings of images and captions in a Euclidean space, such that the semantic\nsimilarity is approximated by the L2 distances in the embedding space. For\nthat, we introduce a metric learning scheme that utilizes multitask learning to\nlearn the embedding of identical semantic concepts using a center loss. By\nintroducing a differentiable quantization scheme into the end-to-end trainable\nnetwork, we derive a semantic embedding of semantically similar concepts in\nEuclidean space. We also propose a novel metric learning formulation using an\nadaptive margin hinge loss, that is refined during the training phase. The\nproposed scheme was applied to the MS-COCO, Flicke30K and Flickr8K datasets,\nand was shown to compare favorably with contemporary state-of-the-art\napproaches.",
    "descriptor": "\nComments: in IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023\n",
    "authors": [
      "Noam Malali",
      "Yosi Keller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03838"
  },
  {
    "id": "arXiv:2210.03839",
    "title": "Edge deletion to tree-like graph classes",
    "abstract": "For a fixed property (graph class) $\\Pi$, given a graph $G$ and an integer\n$k$, the $\\Pi$-deletion problem consists in deciding if we can turn $G$ into a\ngraph with the property $\\Pi$ by deleting at most $k$ edges of $G$. The\n$\\Pi$-deletion problem is known to be NP-hard for most of the well-studied\ngraph classes (such as chordal, interval, bipartite, planar, comparability and\npermutation graphs, among others), with the notable exception of trees.\nMotivated by this fact, in this work we study the deletion problem for some\nclasses close to trees. We obtain NP-hardness results for several classes of\nsparse graphs, for which we prove that deletion is hard even when the input is\na bipartite graph. In addition, we give sufficient structural conditions for\nthe graph class $\\Pi$ for NP-hardness. In the case of deletion to cactus, we\nshow that the problem becomes tractable when the input is chordal, and we give\npolynomial-time algorithms for quasi-threshold graphs.",
    "descriptor": "\nComments: 12 pages, no figures\n",
    "authors": [
      "Ivo Koch",
      "Nina Pardal",
      "Vinicius Fernandes dos Santos"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.03839"
  },
  {
    "id": "arXiv:2210.03841",
    "title": "Breaking BERT: Evaluating and Optimizing Sparsified Attention",
    "abstract": "Transformers allow attention between all pairs of tokens, but there is reason\nto believe that most of these connections - and their quadratic time and memory\n- may not be necessary. But which ones? We evaluate the impact of\nsparsification patterns with a series of ablation experiments. First, we\ncompare masks based on syntax, lexical similarity, and token position to random\nconnections, and measure which patterns reduce performance the least. We find\nthat on three common finetuning tasks even using attention that is at least 78%\nsparse can have little effect on performance if applied at later transformer\nlayers, but that applying sparsity throughout the network reduces performance\nsignificantly. Second, we vary the degree of sparsity for three patterns\nsupported by previous work, and find that connections to neighbouring tokens\nare the most significant. Finally, we treat sparsity as an optimizable\nparameter, and present an algorithm to learn degrees of neighboring connections\nthat gives a fine-grained control over the accuracy-sparsity trade-off while\napproaching the performance of existing methods.",
    "descriptor": "\nComments: Shorter version accepted to SNN2021 workshop\n",
    "authors": [
      "Siddhartha Brahma",
      "Polina Zablotskaia",
      "David Mimno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03841"
  },
  {
    "id": "arXiv:2210.03842",
    "title": "Mutual Theory of Mind for Human-AI Communication",
    "abstract": "From navigation systems to smart assistants, we communicate with various AI\non a daily basis. At the core of such human-AI communication, we convey our\nunderstanding of the AI's capability to the AI through utterances with\ndifferent complexities, and the AI conveys its understanding of our needs and\ngoals to us through system outputs. However, this communication process is\nprone to failures for two reasons: the AI might have the wrong understanding of\nthe user and the user might have the wrong understanding of the AI. To enhance\nmutual understanding in human-AI communication, we posit the Mutual Theory of\nMind (MToM) framework, inspired by our basic human capability of \"Theory of\nMind.\" In this paper, we discuss the motivation of the MToM framework and its\nthree key components that continuously shape the mutual understanding during\nthree stages of human-AI communication. We then describe a case study inspired\nby the MToM framework to demonstrate the power of MToM framework to guide the\ndesign and understanding of human-AI communication.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Qiaosi Wang",
      "Ashok K. Goel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03842"
  },
  {
    "id": "arXiv:2210.03843",
    "title": "Differentially Private Deep Learning with ModelMix",
    "abstract": "Training large neural networks with meaningful/usable differential privacy\nsecurity guarantees is a demanding challenge. In this paper, we tackle this\nproblem by revisiting the two key operations in Differentially Private\nStochastic Gradient Descent (DP-SGD): 1) iterative perturbation and 2) gradient\nclipping. We propose a generic optimization framework, called {\\em ModelMix},\nwhich performs random aggregation of intermediate model states. It strengthens\nthe composite privacy analysis utilizing the entropy of the training trajectory\nand improves the $(\\epsilon, \\delta)$ DP security parameters by an order of\nmagnitude.\nWe provide rigorous analyses for both the utility guarantees and privacy\namplification of ModelMix. In particular, we present a formal study on the\neffect of gradient clipping in DP-SGD, which provides theoretical instruction\non how hyper-parameters should be selected. We also introduce a refined\ngradient clipping method, which can further sharpen the privacy loss in private\nlearning when combined with ModelMix.\nThorough experiments with significant privacy/utility improvement are\npresented to support our theory. We train a Resnet-20 network on CIFAR10 with\n$70.4\\%$ accuracy via ModelMix given $(\\epsilon=8, \\delta=10^{-5})$ DP-budget,\ncompared to the same performance but with $(\\epsilon=145.8,\\delta=10^{-5})$\nusing regular DP-SGD; assisted with additional public low-dimensional gradient\nembedding, one can further improve the accuracy to $79.1\\%$ with\n$(\\epsilon=6.1, \\delta=10^{-5})$ DP-budget, compared to the same performance\nbut with $(\\epsilon=111.2, \\delta=10^{-5})$ without ModelMix.",
    "descriptor": "",
    "authors": [
      "Hanshen Xiao",
      "Jun Wan",
      "Srinivas Devadas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03843"
  },
  {
    "id": "arXiv:2210.03844",
    "title": "Iterative Methods at Lower Precision",
    "abstract": "Since numbers in the computer are represented with a fixed number of bits,\nloss of accuracy during calculation is unavoidable. At high precision where\nmore bits (e.g. 64) are allocated to each number, round-off errors are\ntypically small. On the other hand, calculating at lower precision, such as\nhalf (16 bits), has the advantage of being much faster. This research focuses\non experimenting with arithmetic at different precision levels for large-scale\ninverse problems, which are represented by linear systems with ill-conditioned\nmatrices. We modified the Conjugate Gradient Method for Least Squares (CGLS)\nand the Chebyshev Semi-Iterative Method (CS) with Tikhonov regularization to do\narithmetic at lower precision using the MATLAB chop function, and we ran\nexperiments on applications from image processing and compared their\nperformance at different precision levels. We concluded that CGLS is a more\nstable algorithm, but overflows easily due to the computation of inner\nproducts, while CS is less likely to overflow but it has more erratic\nconvergence behavior. When the noise level is high, CS outperforms CGLS by\nbeing able to run more iterations before overflow occurs; when the noise level\nis close to zero, CS appears to be more susceptible to accumulation of\nround-off errors.",
    "descriptor": "",
    "authors": [
      "Yizhou Chen",
      "Xiaoyun Gong",
      "Xiang Ji"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03844"
  },
  {
    "id": "arXiv:2210.03849",
    "title": "ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational  Finance Question Answering",
    "abstract": "With the recent advance in large pre-trained language models, researchers\nhave achieved record performances in NLP tasks that mostly focus on language\npattern matching. The community is experiencing the shift of the challenge from\nhow to model language to the imitation of complex reasoning abilities like\nhuman beings. In this work, we investigate the application domain of finance\nthat involves real-world, complex numerical reasoning. We propose a new\nlarge-scale dataset, ConvFinQA, aiming to study the chain of numerical\nreasoning in conversational question answering. Our dataset poses great\nchallenge in modeling long-range, complex numerical reasoning paths in\nreal-world conversations. We conduct comprehensive experiments and analyses\nwith both the neural symbolic methods and the prompting-based methods, to\nprovide insights into the reasoning mechanisms of these two divisions. We\nbelieve our new dataset should serve as a valuable resource to push forward the\nexploration of real-world, complex reasoning tasks as the next research focus.\nOur dataset and code is publicly available at\nhttps://github.com/czyssrs/ConvFinQA.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhiyu Chen",
      "Shiyang Li",
      "Charese Smiley",
      "Zhiqiang Ma",
      "Sameena Shah",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03849"
  },
  {
    "id": "arXiv:2210.03850",
    "title": "Toward an Over-parameterized Direct-Fit Model of Visual Perception",
    "abstract": "In this paper, we revisit the problem of computational modeling of simple and\ncomplex cells for an over-parameterized and direct-fit model of visual\nperception. Unlike conventional wisdom, we highlight the difference in parallel\nand sequential binding mechanisms between simple and complex cells. A new\nproposal for abstracting them into space partitioning and composition is\ndeveloped as the foundation of our new hierarchical construction. Our\nconstruction can be interpreted as a product topology-based generalization of\nthe existing k-d tree, making it suitable for brute-force direct-fit in a\nhigh-dimensional space. The constructed model has been applied to several\nclassical experiments in neuroscience and psychology. We provide an anti-sparse\ncoding interpretation of the constructed vision model and show how it leads to\na dynamic programming (DP)-like approximate nearest-neighbor search based on\n$\\ell_{\\infty}$-optimization. We also briefly discuss two possible\nimplementations based on asymmetrical (decoder matters more) auto-encoder and\nspiking neural networks (SNN), respectively.",
    "descriptor": "",
    "authors": [
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03850"
  },
  {
    "id": "arXiv:2210.03851",
    "title": "Calibration: A Simple Trick for Wide-table Delta Analytics",
    "abstract": "Data analytics over normalized databases typically requires computing and\nmaterializing expensive joins (wide-tables). Factorized query execution models\nexecution as message passing between relations in the join graph and pushes\naggregations through joins to reduce intermediate result sizes. Although this\naccelerates query execution, it only optimizes a single wide-table query. In\ncontrast, wide-table analytics is usually interactive and users want to apply\ndelta to the initial query structure. For instance, users want to slice, dice\nand drill-down dimensions, update part of the tables and join with new tables\nfor enrichment. Such Wide-table Delta Analytics offers novel work-sharing\nopportunities. This work shows that carefully materializing messages during\nquery execution can accelerate Wide-table Delta Analytics by >10^5x as compared\nto factorized execution, and only incurs a constant factor overhead. The key\nchallenge is that messages are sensitive to the message passing ordering. To\naddress this challenge, we borrow the concept of calibration in probabilistic\ngraphical models to materialize sufficient messages to support any ordering. We\nmanifest these ideas in the novel Calibrated Junction Hypertree (CJT) data\nstructure, which is fast to build, aggressively re-uses messages to accelerate\nfuture queries, and is incrementally maintainable under updates. We further\nshow how CJTs benefit applications such as OLAP, query explanation, streaming\ndata, and data augmentation for ML. Our experiments evaluate three versions of\nthe CJT that run in a single-threaded custom engine, on cloud DBs, and in\nPandas, and show 30x - 10^5x improvements over state-of-the-art factorized\nexecution algorithms on the above applications.",
    "descriptor": "",
    "authors": [
      "Zezhou Huang",
      "Eugene Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.03851"
  },
  {
    "id": "arXiv:2210.03852",
    "title": "Learning Stackelberg Equilibria and Applications to Economic Design  Games",
    "abstract": "We study the use of reinforcement learning to learn the optimal leader's\nstrategy in Stackelberg games. Learning a leader's strategy has an innate\nstationarity problem -- when optimizing the leader's strategy, the followers'\nstrategies might shift. To circumvent this problem, we model the followers via\nno-regret dynamics to converge to a Bayesian Coarse-Correlated Equilibrium\n(B-CCE) of the game induced by the leader. We then embed the followers'\nno-regret dynamics in the leader's learning environment, which allows us to\nformulate our learning problem as a standard POMDP. We prove that the optimal\npolicy of this POMDP achieves the same utility as the optimal leader's strategy\nin our Stackelberg game. We solve this POMDP using actor-critic methods, where\nthe critic is given access to the joint information of all the agents. Finally,\nwe show that our methods are able to learn optimal leader strategies in a\nvariety of settings of increasing complexity, including indirect mechanisms\nwhere the leader's strategy is setting up the mechanism's rules.",
    "descriptor": "",
    "authors": [
      "Gianluca Brero",
      "Alon Eden",
      "Darshan Chakrabarti",
      "Matthias Gerstgrasser",
      "Vincent Li",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03852"
  },
  {
    "id": "arXiv:2210.03853",
    "title": "Revisiting Self-Supervised Contrastive Learning for Facial Expression  Recognition",
    "abstract": "The success of most advanced facial expression recognition works relies\nheavily on large-scale annotated datasets. However, it poses great challenges\nin acquiring clean and consistent annotations for facial expression datasets.\nOn the other hand, self-supervised contrastive learning has gained great\npopularity due to its simple yet effective instance discrimination training\nstrategy, which can potentially circumvent the annotation issue. Nevertheless,\nthere remain inherent disadvantages of instance-level discrimination, which are\neven more challenging when faced with complicated facial representations. In\nthis paper, we revisit the use of self-supervised contrastive learning and\nexplore three core strategies to enforce expression-specific representations\nand to minimize the interference from other facial attributes, such as identity\nand face styling. Experimental results show that our proposed method\noutperforms the current state-of-the-art self-supervised learning methods, in\nterms of both categorical and dimensional facial expression recognition tasks.",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Yuxuan Shu",
      "Xiao Gu",
      "Guang-Zhong Yang",
      "Benny Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03853"
  },
  {
    "id": "arXiv:2210.03855",
    "title": "Safety Embedded Stochastic Optimal Control of Networked Multi-Agent  Systems via Barrier States",
    "abstract": "This paper presents a safe stochastic optimal control method for networked\nmulti-agent systems (MASs) by using barrier states (BaSs) to embed the safety\nconstraints into the system dynamics. The networked multi-agent system (MAS) is\nfactorized into multiple subsystems, each of which is augmented with BaSs for\nthe central agent. The optimal control law is obtained by solving the joint\nHamilton-Jacobi-Bellman (HJB) equation on the augmented subsystem, which\nensures safety via the boundedness of the BaSs. The BaS-based optimal control\nmethod generates safe control actions and also preserves optimality. The safe\noptimal control solution is ultimately approximated with path integrals. We\nvalidate the efficacy of the proposed approach in numerical simulations on a\ncooperative UAV team in two different scenarios.",
    "descriptor": "",
    "authors": [
      "Lin Song",
      "Pan Zhao",
      "Neng Wan",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03855"
  },
  {
    "id": "arXiv:2210.03856",
    "title": "Disordered vectors in R: introduciong the disordR package",
    "abstract": "Objects in the {\\tt stl map} class of {\\tt C++} associate a value to each of\na set of keys. Accessing values or keys of such an object is problematic in the\nR programming language because the value-key pairs are not stored in a\nwell-defined order. This document motivates and discusses the concept of\n``disordered vector\" as implemented by the {\\tt disordR} package which\nfacilitates the handling of {\\tt map} objects. Values and keys of a map are\nstored in an implementation-specific way so certain extraction and replacement\noperations should be forbidden. For example, if values are real, then the\n``first\" value is implementation specific\\ldots but the maximum value has a\nwell-defined result. The {\\tt disordR} package makes forbidden operations\nimpossible while allowing transparent R idiom for permitted operations. An\nillustrative R session is given in which the package is used abstractly,\nwithout reference to any particular application, and then shows how it can be\nused to manipulate multivariate polynomials. The {\\tt disordR} package is a\ndependency of {\\tt clifford}, {\\tt freealg}, {\\tt hyper2}, {\\tt mvp}, {\\tt\nspray}, {\\tt stokes}, and {\\tt weyl}. The {\\tt disordR} package is available\non CRAN at \\url{https://CRAN.R-project.org/package=disordR}.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Robin K. S. Hankin"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.03856"
  },
  {
    "id": "arXiv:2210.03858",
    "title": "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of  Large-Scale Pre-Trained Language Models",
    "abstract": "There are growing interests in adapting large-scale language models using\nparameter-efficient fine-tuning methods. However, accelerating the model itself\nand achieving better inference efficiency through model compression has not\nbeen thoroughly explored yet. Model compression could provide the benefits of\nreducing memory footprints, enabling low-precision computations, and ultimately\nachieving cost-effective inference. To combine parameter-efficient adaptation\nand model compression, we propose AlphaTuning consisting of post-training\nquantization of the pre-trained language model and fine-tuning only some parts\nof quantized parameters for a target task. Specifically, AlphaTuning works by\nemploying binary-coding quantization, which factorizes the full-precision\nparameters into binary parameters and a separate set of scaling factors. During\nthe adaptation phase, the binary values are frozen for all tasks, while the\nscaling factors are fine-tuned for the downstream task. We demonstrate that\nAlphaTuning, when applied to GPT-2 and OPT, performs competitively with full\nfine-tuning on a variety of downstream tasks while achieving >10x compression\nratio under 4-bit quantization and >1,000x reduction in the number of trainable\nparameters.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Se Jung Kwon",
      "Jeonghoon Kim",
      "Jeongin Bae",
      "Kang Min Yoo",
      "Jin-Hwa Kim",
      "Baeseong Park",
      "Byeongwook Kim",
      "Jung-Woo Ha",
      "Nako Sung",
      "Dongsoo Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03858"
  },
  {
    "id": "arXiv:2210.03861",
    "title": "Towards Light Weight Object Detection System",
    "abstract": "Transformers are a popular choice for classification tasks and as backbones\nfor object detection tasks. However, their high latency brings challenges in\ntheir adaptation to lightweight object detection systems. We present an\napproximation of the self-attention layers used in the transformer\narchitecture. This approximation reduces the latency of the classification\nsystem while incurring minimal loss in accuracy. We also present a method that\nuses a transformer encoder layer for multi-resolution feature fusion. This\nfeature fusion improves the accuracy of the state-of-the-art lightweight object\ndetection system without significantly increasing the number of parameters.\nFinally, we provide an abstraction for the transformer architecture called\nGeneralized Transformer (gFormer) that can guide the design of novel\ntransformer-like architectures.",
    "descriptor": "",
    "authors": [
      "Dharma KC",
      "Venkata Ravi Kiran Dayana",
      "Meng-Lin Wu",
      "Venkateswara Rao Cherukuri",
      "Hau Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03861"
  },
  {
    "id": "arXiv:2210.03869",
    "title": "TAME: Task Agnostic Continual Learning using Multiple Experts",
    "abstract": "The goal of lifelong learning is to continuously learn from non-stationary\ndistributions, where the non-stationarity is typically imposed by a sequence of\ndistinct tasks. Prior works have mostly considered idealistic settings, where\nthe identity of tasks is known at least at training. In this paper we focus on\na fundamentally harder, so-called task-agnostic setting where the task\nidentities are not known and the learning machine needs to infer them from the\nobservations. Our algorithm, which we call TAME (Task-Agnostic continual\nlearning using Multiple Experts), automatically detects the shift in data\ndistributions and switches between task expert networks in an online manner. At\ntraining, the strategy for switching between tasks hinges on an extremely\nsimple observation that for each new coming task there occurs a\nstatistically-significant deviation in the value of the loss function that\nmarks the onset of this new task. At inference, the switching between experts\nis governed by the selector network that forwards the test sample to its\nrelevant expert network. The selector network is trained on a small subset of\ndata drawn uniformly at random. We control the growth of the task expert\nnetworks as well as selector network by employing online pruning. Our\nexperimental results show the efficacy of our approach on benchmark continual\nlearning data sets, outperforming the previous task-agnostic methods and even\nthe techniques that admit task identities at both training and testing, while\nat the same time using a comparable model size.",
    "descriptor": "",
    "authors": [
      "Haoran Zhu",
      "Maryam Majzoubi",
      "Arihant Jain",
      "Anna Choromanska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03869"
  },
  {
    "id": "arXiv:2210.03871",
    "title": "Data-Efficiency with a Single GPU: An Exploration of Transfer Methods  for Small Language Models",
    "abstract": "Multi-task learning (MTL), instruction tuning, and prompting have recently\nbeen shown to improve the generalizability of large language models to new\ntasks. However, the benefits of such methods are less well-documented in\nsmaller language models, with some studies finding contradictory results. In\nthis work, we explore and isolate the effects of (i) model size, (ii) general\npurpose MTL, (iii) in-domain MTL, (iv) instruction tuning, and (v) few-shot\nfine-tuning for models with fewer than 500 million parameters. Our experiments\nin the zero-shot setting demonstrate that models gain 31% relative improvement,\non average, from general purpose MTL, with an additional 37.6% relative gain\nfrom in-domain MTL. Contradictory to prior works on large models, we find that\ninstruction tuning provides a modest 2% performance improvement for small\nmodels.",
    "descriptor": "",
    "authors": [
      "Alon Albalak",
      "Akshat Shrivastava",
      "Chinnadhurai Sankar",
      "Adithya Sagar",
      "Mike Ross"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03871"
  },
  {
    "id": "arXiv:2210.03879",
    "title": "Improving Fine-Grain Segmentation via Interpretable Modifications: A  Case Study in Fossil Segmentation",
    "abstract": "Most interpretability research focuses on datasets containing thousands of\nimages of commonplace objects. However, many high-impact datasets, such as\nthose in medicine and the geosciences, contain fine-grain objects that require\ndomain-expert knowledge to recognize and are time-consuming to collect and\nannotate. As a result, these datasets contain few annotated images, and current\nmachine vision models cannot train intensively on them. Thus, adapting\ninterpretability techniques to maximize the amount of information that models\ncan learn from small, fine-grain datasets is an important endeavor.\nUsing a Mask R-CNN to segment ancient reef fossils in rock sample images, we\npresent a general paradigm for identifying and mitigating model weaknesses.\nSpecifically, we apply image perturbations to expose the Mask R-CNN's inability\nto distinguish between different classes of fossils and its inconsistency in\nsegmenting fossils with different textures. To address these shortcomings, we\nextend an existing model-editing method for correcting systematic mistakes in\nimage classification to image segmentation and introduce a novel application of\nthe technique: encouraging a greater separation between positive and negative\npixels for a given class. Through extensive experiments, we find that editing\nthe model by perturbing all pixels for a given class in one image is most\neffective (compared to using multiple images and/or fewer pixels). Our paradigm\nmay also generalize to other segmentation models trained on small, fine-grain\ndatasets.",
    "descriptor": "",
    "authors": [
      "Indu Panigrahi",
      "Ryan Manzuk",
      "Adam Maloof",
      "Ruth Fong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03879"
  },
  {
    "id": "arXiv:2210.03881",
    "title": "Fourier Neural Solver for large sparse linear algebraic systems",
    "abstract": "Large sparse linear algebraic systems can be found in a variety of scientific\nand engineering fields, and many scientists strive to solve them in an\nefficient and robust manner. In this paper, we propose an interpretable neural\nsolver, the Fourier Neural Solver (FNS), to address them. FNS is based on deep\nlearning and Fast Fourier transform. Because the error between the iterative\nsolution and the ground truth involves a wide range of frequency modes, FNS\ncombines a stationary iterative method and frequency space correction to\neliminate different components of the error. Local Fourier analysis reveals\nthat the FNS can pick up on the error components in frequency space that are\nchallenging to eliminate with stationary methods. Numerical experiments on the\nanisotropy diffusion equation, convection-diffusion equation, and Helmholtz\nequation show that FNS is more efficient and more robust than the\nstate-of-the-art neural solver.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Chen Cui",
      "Kai Jiang",
      "Yun Liu",
      "Shi Shu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03881"
  },
  {
    "id": "arXiv:2210.03883",
    "title": "Rethinking the Detection Head Configuration for Traffic Object Detection",
    "abstract": "Multi-scale detection plays an important role in object detection models.\nHowever, researchers usually feel blank on how to reasonably configure\ndetection heads combining multi-scale features at different input resolutions.\nWe find that there are different matching relationships between the object\ndistribution and the detection head at different input resolutions. Based on\nthe instructive findings, we propose a lightweight traffic object detection\nnetwork based on matching between detection head and object distribution,\ntermed as MHD-Net. It consists of three main parts. The first is the detection\nhead and object distribution matching strategy, which guides the rational\nconfiguration of detection head, so as to leverage multi-scale features to\neffectively detect objects at vastly different scales. The second is the\ncross-scale detection head configuration guideline, which instructs to replace\nmultiple detection heads with only two detection heads possessing of rich\nfeature representations to achieve an excellent balance between detection\naccuracy, model parameters, FLOPs and detection speed. The third is the\nreceptive field enlargement method, which combines the dilated convolution\nmodule with shallow features of backbone to further improve the detection\naccuracy at the cost of increasing model parameters very slightly. The proposed\nmodel achieves more competitive performance than other models on BDD100K\ndataset and our proposed ETFOD-v2 dataset. The code will be available.",
    "descriptor": "\nComments: 26 pages, 4 figures, 7 tables\n",
    "authors": [
      "Yi Shi",
      "Jiang Wu",
      "Shixuan Zhao",
      "Gangyao Gao",
      "Tao Deng",
      "Hongmei Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.03883"
  },
  {
    "id": "arXiv:2210.03884",
    "title": "Don't Lose Yourself! Empathetic Response Generation via Explicit  Self-Other Awareness",
    "abstract": "As a critical step to achieve human-like chatbots, empathetic response\ngeneration has attained increasing interests. Previous attempts are incomplete\nand not sufficient enough to elicit empathy because they only focus on the\ninitial aspect of empathy to automatically mimic the feelings and thoughts of\nthe user via other-awareness. However, they ignore to maintain and take the own\nviews of the system into account, which is a crucial process to achieve the\nempathy called self-other awareness. To this end, we propose to generate\nEmpathetic response with explicit Self-Other Awareness (EmpSOA). Specifically,\nthree stages, self-other differentiation, self-other modulation and self-other\ngeneration, are devised to clearly maintain, regulate and inject the self-other\naware information into the process of empathetic response generation. Both\nautomatic and human evaluations on the benchmark dataset demonstrate the\nsuperiority of EmpSOA to generate more empathetic responses.",
    "descriptor": "",
    "authors": [
      "Weixiang Zhao",
      "Yanyan Zhao",
      "Xin Lu",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03884"
  },
  {
    "id": "arXiv:2210.03885",
    "title": "Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from  Mixture-of-Experts",
    "abstract": "In this paper, we tackle the problem of domain shift. Most existing methods\nperform training on multiple source domains using a single model, and the same\ntrained model is used on all unseen target domains. Such solutions are\nsub-optimal as each target domain exhibits its own speciality, which is not\nadapted. Furthermore, expecting the single-model training to learn extensive\nknowledge from the multiple source domains is counterintuitive. The model is\nmore biased toward learning only domain-invariant features and may result in\nnegative knowledge transfer. In this work, we propose a novel framework for\nunsupervised test-time adaptation, which is formulated as a knowledge\ndistillation process to address domain shift. Specifically, we incorporate\nMixture-of-Experts (MoE) as teachers, where each expert is separately trained\non different source domains to maximize their speciality. Given a test-time\ntarget domain, a small set of unlabeled data is sampled to query the knowledge\nfrom MoE. As the source domains are correlated to the target domains, a\ntransformer-based aggregator then combines the domain knowledge by examining\nthe interconnection among them. The output is treated as a supervision signal\nto adapt a student prediction network toward the target domain. We further\nemploy meta-learning to enforce the aggregator to distill positive knowledge\nand the student network to achieve fast adaptation. Extensive experiments\ndemonstrate that the proposed method outperforms the state-of-the-art and\nvalidates the effectiveness of each proposed component. Our code is available\nat https://github.com/n3il666/Meta-DMoE.",
    "descriptor": "\nComments: Accepted at NeurIPS2022\n",
    "authors": [
      "Tao Zhong",
      "Zhixiang Chi",
      "Li Gu",
      "Yang Wang",
      "Yuanhao Yu",
      "Jin Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03885"
  },
  {
    "id": "arXiv:2210.03887",
    "title": "Improving End-to-End Text Image Translation From the Auxiliary Text  Translation Task",
    "abstract": "End-to-end text image translation (TIT), which aims at translating the source\nlanguage embedded in images to the target language, has attracted intensive\nattention in recent research. However, data sparsity limits the performance of\nend-to-end text image translation. Multi-task learning is a non-trivial way to\nalleviate this problem via exploring knowledge from complementary related\ntasks. In this paper, we propose a novel text translation enhanced text image\ntranslation, which trains the end-to-end model with text translation as an\nauxiliary task. By sharing model parameters and multi-task training, our model\nis able to take full advantage of easily-available large-scale text parallel\ncorpus. Extensive experimental results show our proposed method outperforms\nexisting end-to-end methods, and the joint multi-task learning with both text\ntranslation and recognition tasks achieves better results, proving translation\nand recognition auxiliary tasks are complementary.",
    "descriptor": "\nComments: Accepted at the 26TH International Conference on Pattern Recognition (ICPR 2022)\n",
    "authors": [
      "Cong Ma",
      "Yaping Zhang",
      "Mei Tu",
      "Xu Han",
      "Linghui Wu",
      "Yang Zhao",
      "Yu Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03887"
  },
  {
    "id": "arXiv:2210.03892",
    "title": "Hybrid Simulator for Space Docking and Robotic Proximity Operations",
    "abstract": "In this work, we present a hybrid simulator for space docking and robotic\nproximity operations methodology. This methodology also allows for the\nemulation of a target robot operating in a complex environment by using an\nactual robot. The emulation scheme aims to replicate the dynamic behavior of\nthe target robot interacting with the environment, without dealing with a\ncomplex calculation of the contact dynamics. This method forms a basis for the\ntask verification of a flexible space robot. The actual emulating robot is\nstructurally rigid, while the target robot can represent any class of robots,\ne.g., flexible, redundant, or space robots. Although the emulating robot is not\ndynamically equivalent to the target robot, the dynamical similarity can be\nachieved by using a control law developed herein. The effect of disturbances\nand actuator dynamics on the fidelity and the contact stability of the robot\nemulation is thoroughly analyzed.",
    "descriptor": "",
    "authors": [
      "Farhad Aghili"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03892"
  },
  {
    "id": "arXiv:2210.03893",
    "title": "An associative memory model with very high memory rate: Image storage by  sequential addition learning",
    "abstract": "In this paper, we present a neural network system related to about memory and\nrecall that consists of one neuron group (the \"cue ball\") and a one-layer\nneural net (the \"recall net\"). This system realizes the bidirectional\nmemorization learning between one cue neuron in the cue ball and the neurons in\nthe recall net. It can memorize many patterns and recall these patterns or\nthose that are similar at any time. Furthermore, the patterns are recalled at\nmost the same time. This model's recall situation seems to resemble human\nrecall of a variety of similar things almost simultaneously when one thing is\nrecalled. It is also possible for additional learning to occur in the system\nwithout affecting the patterns memorized in advance. Moreover, the memory rate\n(the number of memorized patterns / the total number of neurons) is close to\n100%; this system's rate is 0.987. Finally, pattern data constraints become an\nimportant aspect of this system.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Hiroshi Inazawa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.03893"
  },
  {
    "id": "arXiv:2210.03894",
    "title": "GRANITE: A Graph Neural Network Model for Basic Block Throughput  Estimation",
    "abstract": "Analytical hardware performance models yield swift estimation of desired\nhardware performance metrics. However, developing these analytical models for\nmodern processors with sophisticated microarchitectures is an extremely\nlaborious task and requires a firm understanding of target microarchitecture's\ninternal structure. In this paper, we introduce GRANITE, a new machine learning\nmodel that estimates the throughput of basic blocks across different\nmicroarchitectures. GRANITE uses a graph representation of basic blocks that\ncaptures both structural and data dependencies between instructions. This\nrepresentation is processed using a graph neural network that takes advantage\nof the relational information captured in the graph and learns a rich neural\nrepresentation of the basic block that allows more precise throughput\nestimation. Our results establish a new state-of-the-art for basic block\nperformance estimation with an average test error of 6.9% across a wide range\nof basic blocks and microarchitectures for the x86-64 target. Compared to\nrecent work, this reduced the error by 1.7% while improving training and\ninference throughput by approximately 3.0x. In addition, we propose the use of\nmulti-task learning with independent multi-layer feed forward decoder networks.\nOur results show that this technique further improves precision of all learned\nmodels while significantly reducing per-microarchitecture training costs. We\nperform an extensive set of ablation studies and comparisons with prior work,\nconcluding a set of methods to achieve high accuracy for basic block\nperformance estimation.",
    "descriptor": "\nComments: 13 pages; 5 figures; published at IISWC 2022;\n",
    "authors": [
      "Ondrej Sykora",
      "Phitchaya Mangpo Phothilimthana",
      "Charith Mendis",
      "Amir Yazdanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.03894"
  },
  {
    "id": "arXiv:2210.03895",
    "title": "ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial  Viewpoints",
    "abstract": "Recent studies have demonstrated that visual recognition models lack\nrobustness to distribution shift. However, current work mainly considers model\nrobustness to 2D image transformations, leaving viewpoint changes in the 3D\nworld less explored. In general, viewpoint changes are prevalent in various\nreal-world applications (e.g., autonomous driving), making it imperative to\nevaluate viewpoint robustness. In this paper, we propose a novel method called\nViewFool to find adversarial viewpoints that mislead visual recognition models.\nBy encoding real-world objects as neural radiance fields (NeRF), ViewFool\ncharacterizes a distribution of diverse adversarial viewpoints under an\nentropic regularizer, which helps to handle the fluctuations of the real camera\npose and mitigate the reality gap between the real objects and their neural\nrepresentations. Experiments validate that the common image classifiers are\nextremely vulnerable to the generated adversarial viewpoints, which also\nexhibit high cross-model transferability. Based on ViewFool, we introduce\nImageNet-V, a new out-of-distribution dataset for benchmarking viewpoint\nrobustness of image classifiers. Evaluation results on 40 classifiers with\ndiverse architectures, objective functions, and data augmentations reveal a\nsignificant drop in model performance when tested on ImageNet-V, which provides\na possibility to leverage ViewFool as an effective data augmentation strategy\nto improve viewpoint robustness.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yinpeng Dong",
      "Shouwei Ruan",
      "Hang Su",
      "Caixin Kang",
      "Xingxing Wei",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03895"
  },
  {
    "id": "arXiv:2210.03899",
    "title": "Multi-Scale Wavelet Transformer for Face Forgery Detection",
    "abstract": "Currently, many face forgery detection methods aggregate spatial and\nfrequency features to enhance the generalization ability and gain promising\nperformance under the cross-dataset scenario. However, these methods only\nleverage one level frequency information which limits their expressive ability.\nTo overcome these limitations, we propose a multi-scale wavelet transformer\nframework for face forgery detection. Specifically, to take full advantage of\nthe multi-scale and multi-frequency wavelet representation, we gradually\naggregate the multi-scale wavelet representation at different stages of the\nbackbone network. To better fuse the frequency feature with the spatial\nfeatures, frequency-based spatial attention is designed to guide the spatial\nfeature extractor to concentrate more on forgery traces. Meanwhile,\ncross-modality attention is proposed to fuse the frequency features with the\nspatial features. These two attention modules are calculated through a unified\ntransformer block for efficiency. A wide variety of experiments demonstrate\nthat the proposed method is efficient and effective for both within and cross\ndatasets.",
    "descriptor": "\nComments: The first two authors contributed equally to this work. Accepted to ACCV 2022 as oral presentation\n",
    "authors": [
      "Jie Liu",
      "Jingjing Wang",
      "Peng Zhang",
      "Chunmao Wang",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03899"
  },
  {
    "id": "arXiv:2210.03900",
    "title": "Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and  GPU",
    "abstract": "Dynamic graph neural network (DGNN) is becoming increasingly popular because\nof its widespread use in capturing dynamic features in the real world. A\nvariety of dynamic graph neural networks designed from algorithmic perspectives\nhave succeeded in incorporating temporal information into graph processing.\nDespite the promising algorithmic performance, deploying DGNNs on hardware\npresents additional challenges due to the model complexity, diversity, and the\nnature of the time dependency. Meanwhile, the differences between DGNNs and\nstatic graph neural networks make hardware-related optimizations for static\ngraph neural networks unsuitable for DGNNs. In this paper, we select eight\nprevailing DGNNs with different characteristics and profile them on both CPU\nand GPU. The profiling results are summarized and analyzed, providing in-depth\ninsights into the bottlenecks of DGNNs on hardware and identifying potential\noptimization opportunities for future DGNN acceleration. Followed by a\ncomprehensive survey, we provide a detailed analysis of DGNN performance\nbottlenecks on hardware, including temporal data dependency, workload\nimbalance, data movement, and GPU warm-up. We suggest several optimizations\nfrom both software and hardware perspectives. This paper is the first to\nprovide an in-depth analysis of the hardware performance of DGNN Code is\navailable at https://github.com/sharc-lab/DGNN_analysis.",
    "descriptor": "\nComments: 14 pages main text, 2 pages appendix, 10 figures, submitted to IISWC2022\n",
    "authors": [
      "Hanqiu Chen",
      "Yahya Alhinai",
      "Yihan Jiang",
      "Eunjee Na",
      "Cong Hao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03900"
  },
  {
    "id": "arXiv:2210.03901",
    "title": "A fairness assessment of mobility-based COVID-19 case prediction models",
    "abstract": "In light of the outbreak of COVID-19, analyzing and measuring human mobility\nhas become increasingly important. A wide range of studies have explored\nspatiotemporal trends over time, examined associations with other variables,\nevaluated non-pharmacologic interventions (NPIs), and predicted or simulated\nCOVID-19 spread using mobility data. Despite the benefits of publicly available\nmobility data, a key question remains unanswered: are models using mobility\ndata performing equitably across demographic groups? We hypothesize that bias\nin the mobility data used to train the predictive models might lead to unfairly\nless accurate predictions for certain demographic groups. To test our\nhypothesis, we applied two mobility-based COVID infection prediction models at\nthe county level in the United States using SafeGraph data, and correlated\nmodel performance with sociodemographic traits. Findings revealed that there is\na systematic bias in models performance toward certain demographic\ncharacteristics. Specifically, the models tend to favor large, highly educated,\nwealthy, young, urban, and non-black-dominated counties. We hypothesize that\nthe mobility data currently used by many predictive models tends to capture\nless information about older, poorer, non-white, and less educated regions,\nwhich in turn negatively impacts the accuracy of the COVID-19 prediction in\nthese regions. Ultimately, this study points to the need of improved data\ncollection and sampling approaches that allow for an accurate representation of\nthe mobility patterns across demographic groups.",
    "descriptor": "\nComments: 24 pages, 4 figures, 2 Tables\n",
    "authors": [
      "Abdolmajid Erfani",
      "Vanessa Frias-Martinez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03901"
  },
  {
    "id": "arXiv:2210.03903",
    "title": "Wholesale Market Participation of Storage with State-of-Charge Dependent  Bids",
    "abstract": "Wholesale market participation of storage with state-of-charge (SoC)\ndependent bids results in a non-convex cost in a multi-interval economic\ndispatch, which requires a mixed-integer linear program in the market clearing.\nWe show that the economic dispatch can be convexified to the standard linear\nprogram when the SoC-dependent bid satisfies the equal decremental-cost ratio\n(EDCR) condition. Such EDCR bids are shown to support individual rationalities\nof all market participants in both the day-ahead multi-interval economic\ndispatch under locational marginal pricing and the rolling-window look-ahead\ndispatch under temporal-locational marginal pricing in the real-time market. A\nnumerical example is presented to demonstrate a higher profit margin with an\nSoC-dependent bid over that from an SoC-independent bid.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2022 58th Allerton conference on communication, control, and computing\n",
    "authors": [
      "Cong Chen",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03903"
  },
  {
    "id": "arXiv:2210.03904",
    "title": "LW-ISP: A Lightweight Model with ISP and Deep Learning",
    "abstract": "The deep learning (DL)-based methods of low-level tasks have many advantages\nover the traditional camera in terms of hardware prospects, error accumulation\nand imaging effects. Recently, the application of deep learning to replace the\nimage signal processing (ISP) pipeline has appeared one after another; however,\nthere is still a long way to go towards real landing. In this paper, we show\nthe possibility of learning-based method to achieve real-time high-performance\nprocessing in the ISP pipeline. We propose LW-ISP, a novel architecture\ndesigned to implicitly learn the image mapping from RAW data to RGB image.\nBased on U-Net architecture, we propose the fine-grained attention module and a\nplug-and-play upsampling block suitable for low-level tasks. In particular, we\ndesign a heterogeneous distillation algorithm to distill the implicit features\nand reconstruction information of the clean image, so as to guide the learning\nof the student model. Our experiments demonstrate that LW-ISP has achieved a\n0.38 dB improvement in PSNR compared to the previous best method, while the\nmodel parameters and calculation have been reduced by 23 times and 81 times.\nThe inference efficiency has been accelerated by at least 15 times. Without\nbells and whistles, LW-ISP has achieved quite competitive results in ISP\nsubtasks including image denoising and enhancement.",
    "descriptor": "\nComments: 16 PAGES, ACCEPTED AS A CONFERENCE PAPER AT: BMVC 2022\n",
    "authors": [
      "Hongyang Chen",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.03904"
  },
  {
    "id": "arXiv:2210.03906",
    "title": "5G NR-LTE Coexistence: Opportunities, Challenges, and Solutions",
    "abstract": "5G New Radio (NR) promises to support diverse services such as enhanced\nmobile broadband (eMBB), ultra-reliable low-latency communication (URLLC), and\nmassive machine-type communication (mMTC). This requires spectrum, most of\nwhich is occupied by 4G Long Term Evolution (LTE). Hence, network operators are\nexpected to deploy 5G using the existing LTE infrastructure while migrating to\nNR. In addition, operators must support legacy LTE devices during the\nmigration, so LTE and NR systems will coexist for the foreseeable future. In\nthis article, we address LTE-NR coexistence starting with a review of both\nradio access technologies. We then describe the contributions by the 3rd\nGeneration Partnership Project (3GPP) to solving the coexistence issue and\ncatalog the major coexistence scenarios. Lastly, we introduce a novel spectrum\nsharing scheme that can be applied to the coexistence scenarios under study.",
    "descriptor": "",
    "authors": [
      "Sneihil Gopal",
      "David Griffith",
      "Richard A. Rouil",
      "Chunmei Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03906"
  },
  {
    "id": "arXiv:2210.03907",
    "title": "Learning the Network of Graphs for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have achieved great success in many scenarios\nwith graph-structured data. However, in many real applications, there are three\nissues when applying GNNs: graphs are unknown, nodes have noisy features, and\ngraphs contain noisy connections. Aiming at solving these problems, we propose\na new graph neural network named as GL-GNN. Our model includes multiple\nsub-modules, each sub-module selects important data features and learn the\ncorresponding key relation graph of data samples when graphs are unknown.\nGL-GNN further obtains the network of graphs by learning the network of\nsub-modules. The learned graphs are further fused using an aggregation method\nover the network of graphs. Our model solves the first issue by simultaneously\nlearning multiple relation graphs of data samples as well as a relation network\nof graphs, and solves the second and the third issue by selecting important\ndata features as well as important data sample relations. We compare our method\nwith 14 baseline methods on seven datasets when the graph is unknown and 11\nbaseline methods on two datasets when the graph is known. The results show that\nour method achieves better accuracies than the baseline methods and is capable\nof selecting important features and graph edges from the dataset. Our code will\nbe publicly available at \\url{https://github.com/Looomo/GL-GNN}.",
    "descriptor": "",
    "authors": [
      "Yixiang Shan",
      "Jielong Yang",
      "Xing Liu",
      "Yixing Gao",
      "Hechang Chen",
      "Shuzhi Sam Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03907"
  },
  {
    "id": "arXiv:2210.03908",
    "title": "Variability Analysis of Isolated Intersections Through Case Study",
    "abstract": "Population and economic growth of urban areas have led to intensive use of\nprivate vehicles, thereby increasing traffic volume and congestion on roads.\nThe traffic management in the city is a challenge for concerned authorities,\nand the signalized intersections are the primary interest of traffic\nmanagement. Interpreting traffic patterns and current traffic signal operations\ncan provide thorough insights to take appropriate actions. In this view, a\ncomprehensive study is conducted at selected intersections from Tumakuru\n(tier-2 city), Karnataka, India. Data estimates traffic parameters such as\nsaturation flow, composition, volume, and volume-to-capacity ratio. The\nstatistical results currently confirm the stable traffic condition but do not\nensure sustainability. The volume-to-capacity ratio is greater than 0.73 along\nthree major arterial roads of study intersections, indicating congestion in the\nfuture as the traffic volume is increasing gradually, as per the Directorate of\nUrban Land Use and Transportation, Government of Karnataka. The statistical\nresults obtained through the current study uphold the report. The empirical\nresults showed 40% of green time wastage at one of the study intersections,\nwhich results in additional waiting delays, thereby increasing fuel consumption\nand emissions. The overall service level of the study intersections is of class\nC based on computed delay and volume-to-capacity ratio. The study suggests\npossible treatments for improving the service level at the intersection\noperations and sustaining the city's stable traffic condition. The study\nsupports city traffic management authorities in identifying suitable treatment\nand implementing accordingly.",
    "descriptor": "",
    "authors": [
      "Savithramma R M",
      "R Sumathi",
      "Sudhira H S"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03908"
  },
  {
    "id": "arXiv:2210.03909",
    "title": "A Higher Purpose: Measuring Electricity Access Using High-Resolution  Daytime Satellite Imagery",
    "abstract": "Governments and international organizations the world over are investing\ntowards the goal of achieving universal energy access for improving\nsocio-economic development. However, in developing settings, monitoring\nelectrification efforts is typically inaccurate, infrequent, and expensive. In\nthis work, we develop and present techniques for high-resolution monitoring of\nelectrification progress at scale. Specifically, our 3 unique contributions\nare: (i) identifying areas with(out) electricity access, (ii) quantifying the\nextent of electrification in electrified areas (percentage/number of\nelectrified structures), and (iii) differentiating between customer types in\nelectrified regions (estimating the percentage/number of\nresidential/non-residential electrified structures). We combine high-resolution\n50 cm daytime satellite images with Convolutional Neural Networks (CNNs) to\ntrain a series of classification and regression models. We evaluate our models\nusing unique ground truth datasets on building locations, building types\n(residential/non-residential), and building electrification status. Our\nclassification models show a 92% accuracy in identifying electrified regions,\n85% accuracy in estimating percent of (low/high) electrified buildings within\nthe region, and 69% accuracy in differentiating between (low/high) percentage\nof electrified residential buildings. Our regressions show $R^2$ scores of 78%\nand 80% in estimating the number of electrified buildings and number of\nresidential electrified building in images respectively. We also demonstrate\nthe generalizability of our models in never-before-seen regions to assess their\npotential for consistent and high-resolution measurements of electrification in\nemerging economies, and conclude by highlighting opportunities for improvement.",
    "descriptor": "",
    "authors": [
      "Zeal Shah",
      "Simone Fobi",
      "Gabriel Cadamuro",
      "Jay Taneja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03909"
  },
  {
    "id": "arXiv:2210.03915",
    "title": "Short Text Pre-training with Extended Token Classification for  E-commerce Query Understanding",
    "abstract": "E-commerce query understanding is the process of inferring the shopping\nintent of customers by extracting semantic meaning from their search queries.\nThe recent progress of pre-trained masked language models (MLM) in natural\nlanguage processing is extremely attractive for developing effective query\nunderstanding models. Specifically, MLM learns contextual text embedding via\nrecovering the masked tokens in the sentences. Such a pre-training process\nrelies on the sufficient contextual information. It is, however, less effective\nfor search queries, which are usually short text. When applying masking to\nshort search queries, most contextual information is lost and the intent of the\nsearch queries may be changed. To mitigate the above issues for MLM\npre-training on search queries, we propose a novel pre-training task\nspecifically designed for short text, called Extended Token Classification\n(ETC). Instead of masking the input text, our approach extends the input by\ninserting tokens via a generator network, and trains a discriminator to\nidentify which tokens are inserted in the extended input. We conduct\nexperiments in an E-commerce store to demonstrate the effectiveness of ETC.",
    "descriptor": "",
    "authors": [
      "Haoming Jiang",
      "Tianyu Cao",
      "Zheng Li",
      "Chen Luo",
      "Xianfeng Tang",
      "Qingyu Yin",
      "Danqing Zhang",
      "Rahul Goutam",
      "Bing Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03915"
  },
  {
    "id": "arXiv:2210.03916",
    "title": "Low Error-Rate Approximate Multiplier Design for DNNs with  Hardware-Driven Co-Optimization",
    "abstract": "In this paper, two approximate 3*3 multipliers are proposed and the synthesis\nresults of the ASAP-7nm process library justify that they can reduce the area\nby 31.38% and 36.17%, and the power consumption by 36.73% and 35.66% compared\nwith the exact multiplier, respectively. They can be aggregated with a 2*2\nmultiplier to produce an 8*8 multiplier with low error rate based on the\ndistribution of DNN weights. We propose a hardware-driven software\nco-optimization method to improve the DNN accuracy by retraining. Based on the\nproposed two approximate 3-bit multipliers, three approximate 8-bit multipliers\nwith low error-rate are designed for DNNs. Compared with the exact 8-bit\nunsigned multiplier, our design can achieve a significant advantage over other\napproximate multipliers on the public dataset.",
    "descriptor": "\nComments: ISCAS 2022. 5pages, 1 figure\n",
    "authors": [
      "Yao Lu",
      "Jide Zhang",
      "Su Zheng",
      "Zhen Li",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03916"
  },
  {
    "id": "arXiv:2210.03918",
    "title": "Finding and Exploring Promising Search Space for the 0-1  Multidimensional Knapsack Problem",
    "abstract": "The 0-1 multidimensional knapsack problem(MKP) is a classical NP-hard\ncombinatorial optimization problem. In this paper, we propose a novel heuristic\nalgorithm simulating evolutionary computation and large neighbourhood search\nfor the MKP. It maintains a set of solutions and abstracts information from the\nsolution set to generate good partial assignments. To find high-quality\nsolutions, integer programming is employed to explore the promising search\nspace specified by the good partial assignments. Extensive experimentation with\ncommonly used benchmark sets shows that our approach outperforms the state of\nthe art heuristic algorithms, TPTEA and DQPSO, in solution quality. It finds\nnew lower bound for 8 large and hard instances",
    "descriptor": "",
    "authors": [
      "Hongbo Li",
      "Jitao Xu",
      "Minghao Yin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03918"
  },
  {
    "id": "arXiv:2210.03919",
    "title": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "abstract": "Recently introduced Contrastive Language-Image Pre-Training (CLIP) bridges\nimages and text by embedding them into a joint latent space. This opens the\ndoor to ample literature that aims to manipulate an input image by providing a\ntextual explanation. However, due to the discrepancy between image and text\nembeddings in the joint space, using text embeddings as the optimization target\noften introduces undesired artifacts in the resulting images. Disentanglement,\ninterpretability, and controllability are also hard to guarantee for\nmanipulation. To alleviate these problems, we propose to define corpus\nsubspaces spanned by relevant prompts to capture specific image\ncharacteristics. We introduce CLIP Projection-Augmentation Embedding (PAE) as\nan optimization target to improve the performance of text-guided image\nmanipulation. Our method is a simple and general paradigm that can be easily\ncomputed and adapted, and smoothly incorporated into any CLIP-based image\nmanipulation algorithm. To demonstrate the effectiveness of our method, we\nconduct several theoretical and empirical studies. As a case study, we utilize\nthe method for text-guided semantic face editing. We quantitatively and\nqualitatively demonstrate that PAE facilitates a more disentangled,\ninterpretable, and controllable image manipulation with state-of-the-art\nquality and accuracy.",
    "descriptor": "",
    "authors": [
      "Chenliang Zhou",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03919"
  },
  {
    "id": "arXiv:2210.03920",
    "title": "Detecting Label Errors in Token Classification Data",
    "abstract": "Mislabeled examples are a common issue in real-world data, particularly for\ntasks like token classification where many labels must be chosen on a\nfine-grained basis. Here we consider the task of finding sentences that contain\nlabel errors in token classification datasets. We study 11 different\nstraightforward methods that score tokens/sentences based on the predicted\nclass probabilities output by a (any) token classification model (trained via\nany procedure). In precision-recall evaluations based on real-world label\nerrors in entity recognition data from CoNLL-2003, we identify a simple and\neffective method that consistently detects those sentences containing label\nerrors when applied with different token classification models.",
    "descriptor": "",
    "authors": [
      "Wei-Chen Wang",
      "Jonas Mueller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03920"
  },
  {
    "id": "arXiv:2210.03921",
    "title": "Accurate Small Models using Adaptive Sampling",
    "abstract": "We highlight the utility of a certain property of model training: instead of\ndrawing training data from the same distribution as test data, learning a\ndifferent training distribution often improves accuracy, especially at small\nmodel sizes. This provides a way to build accurate small models, which are\nattractive for interpretability and resource-constrained environments. Here we\nempirically show that this principle is both general and effective: it may be\nused across tasks/model families, and it can augment prediction accuracy of\ntraditional models to the extent they are competitive with specialized\ntechniques. The tasks we consider are explainable clustering and\nprototype-based classification. We also look at Random Forests to illustrate\nhow this principle may be applied to accommodate multiple size constraints,\ne.g., number of trees and maximum depth per tree. Results using multiple\ndatasets are presented and are shown to be statistically significant.",
    "descriptor": "",
    "authors": [
      "Abhishek Ghose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03921"
  },
  {
    "id": "arXiv:2210.03923",
    "title": "Sparse Teachers Can Be Dense with Knowledge",
    "abstract": "Recent advances in distilling pretrained language models have discovered\nthat, besides the expressiveness of knowledge, the student-friendliness should\nbe taken into consideration to realize a truly knowledgable teacher. Based on a\npilot study, we find that over-parameterized teachers can produce expressive\nyet student-unfriendly knowledge, and are thus limited in overall\nknowledgableness. To remove the parameters that result in\nstudent-unfriendliness, we propose a sparse teacher trick under the guidance of\nan overall knowledgable score for each teacher parameter. The knowledgable\nscore is essentially an interpolation of the expressiveness and\nstudent-friendliness scores. The aim is to ensure that the expressive\nparameters are retained while the student-unfriendly ones are removed.\nExtensive experiments on the GLUE benchmark show that the proposed sparse\nteachers can be dense with knowledge and lead to students with compelling\nperformance in comparison with a series of competitive baselines.",
    "descriptor": "\nComments: 12 pages, 8 figures, 6 tables, accepted to EMNLP 2022. Code is available at this https URL\n",
    "authors": [
      "Yi Yang",
      "Chen Zhang",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03923"
  },
  {
    "id": "arXiv:2210.03925",
    "title": "Contextual Modeling for 3D Dense Captioning on Point Clouds",
    "abstract": "3D dense captioning, as an emerging vision-language task, aims to identify\nand locate each object from a set of point clouds and generate a distinctive\nnatural language sentence for describing each located object. However, the\nexisting methods mainly focus on mining inter-object relationship, while\nignoring contextual information, especially the non-object details and\nbackground environment within the point clouds, thus leading to low-quality\ndescriptions, such as inaccurate relative position information. In this paper,\nwe make the first attempt to utilize the point clouds clustering features as\nthe contextual information to supply the non-object details and background\nenvironment of the point clouds and incorporate them into the 3D dense\ncaptioning task. We propose two separate modules, namely the Global Context\nModeling (GCM) and Local Context Modeling (LCM), in a coarse-to-fine manner to\nperform the contextual modeling of the point clouds. Specifically, the GCM\nmodule captures the inter-object relationship among all objects with global\ncontextual information to obtain more complete scene information of the whole\npoint clouds. The LCM module exploits the influence of the neighboring objects\nof the target object and local contextual information to enrich the object\nrepresentations. With such global and local contextual modeling strategies, our\nproposed model can effectively characterize the object representations and\ncontextual information and thereby generate comprehensive and detailed\ndescriptions of the located objects. Extensive experiments on the ScanRefer and\nNr3D datasets demonstrate that our proposed method sets a new record on the 3D\ndense captioning task, and verify the effectiveness of our raised contextual\nmodeling of point clouds.",
    "descriptor": "",
    "authors": [
      "Yufeng Zhong",
      "Long Xu",
      "Jiebo Luo",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03925"
  },
  {
    "id": "arXiv:2210.03926",
    "title": "Secrecy Rate of the Cooperative RSMA-Aided UAV Downlink Relying on  Optimal Relay Selection",
    "abstract": "The Cooperative Rate-Splitting (CRS) scheme, proposed evolves from\nconventional Rate Splitting (RS) and relies on forwarding a portion of the RS\nmessage by the relaying users. In terms of secrecy enhancement, it has been\nshown that CRS outperforms its non-cooperative counterpart for a two-user\nMultiple Input Single Output (MISO) Broadcast Channel (BC). Given the massive\nconnectivity requirement of 6G, we have generalized the existing secure\ntwo-user CRS framework to the multi-user framework, where the highest-security\nusers must be selected as the relay nodes. This paper addresses the problem of\nmaximizing the Worst-Case Secrecy Rate (WCSR) in a UAV-aided downlink network\nwhere a multi-antenna UAV Base-Station (UAV-BS) serves a group of users in the\npresence of an external eavesdropper (Eve). We consider a practical scenario in\nwhich only imperfect channel state information of Eve is available at the\nUAV-BS. Accordingly, we conceive a robust and secure resource allocation\nalgorithm, which maximizes the WCSR by jointly optimizing both the Secure\nRelaying User Selection (SRUS) and the network parameter allocation problem,\nincluding the RS transmit precoders, message splitting variables, time slot\nsharing and power allocation. To circumvent the resultant non-convexity owing\nto the discrete variables imposed by SRUS, we propose a two-stage algorithm\nwhere the SRUS and network parameter allocation are accomplished in two\nconsecutive stages. With regard to the SRUS, we study both centralized and\ndistributed protocols. On the other hand, for jointly optimizing the network\nparameter allocation we resort to the Sequential Parametric Convex\nApproximation (SPCA) algorithm. Our numerical results show that the proposed\nsolution significantly outperforms the existing benchmarks for a wide range of\nnetwork loads in terms of the WCSR.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1910.07843 by other authors\n",
    "authors": [
      "Hamed Bastami",
      "Majid Moradikia",
      "Hamid Behroozi",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03926"
  },
  {
    "id": "arXiv:2210.03927",
    "title": "APE: Aligning Pretrained Encoders to Quickly Learn Aligned Multimodal  Representations",
    "abstract": "Recent advances in learning aligned multimodal representations have been\nprimarily driven by training large neural networks on massive, noisy\npaired-modality datasets. In this work, we ask whether it is possible to\nachieve similar results with substantially less training time and data. We\nachieve this by taking advantage of existing pretrained unimodal encoders and\ncareful curation of alignment data relevant to the downstream task of interest.\nWe study a natural approach to aligning existing encoders via small auxiliary\nfunctions, and we find that this method is competitive with (or outperforms)\nstate of the art in many settings while being less prone to overfitting, less\ncostly to train, and more robust to distribution shift. With a properly chosen\nalignment distribution, our method surpasses prior state of the art for\nImageNet zero-shot classification on public data while using two orders of\nmagnitude less time and data and training 77% fewer parameters.",
    "descriptor": "",
    "authors": [
      "Elan Rosenfeld",
      "Preetum Nakkiran",
      "Hadi Pouransari",
      "Oncel Tuzel",
      "Fartash Faghri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03927"
  },
  {
    "id": "arXiv:2210.03929",
    "title": "EgoTaskQA: Understanding Human Tasks in Egocentric Videos",
    "abstract": "Understanding human tasks through video observations is an essential\ncapability of intelligent agents. The challenges of such capability lie in the\ndifficulty of generating a detailed understanding of situated actions, their\neffects on object states (i.e., state changes), and their causal dependencies.\nThese challenges are further aggravated by the natural parallelism from\nmulti-tasking and partial observations in multi-agent collaboration. Most prior\nworks leverage action localization or future prediction as an indirect metric\nfor evaluating such task understanding from videos. To make a direct\nevaluation, we introduce the EgoTaskQA benchmark that provides a single home\nfor the crucial dimensions of task understanding through question-answering on\nreal-world egocentric videos. We meticulously design questions that target the\nunderstanding of (1) action dependencies and effects, (2) intents and goals,\nand (3) agents' beliefs about others. These questions are divided into four\ntypes, including descriptive (what status?), predictive (what will?),\nexplanatory (what caused?), and counterfactual (what if?) to provide diagnostic\nanalyses on spatial, temporal, and causal understandings of goal-oriented\ntasks. We evaluate state-of-the-art video reasoning models on our benchmark and\nshow their significant gaps between humans in understanding complex\ngoal-oriented egocentric videos. We hope this effort will drive the vision\ncommunity to move onward with goal-oriented video understanding and reasoning.",
    "descriptor": "\nComments: Published at NeurIPS Track on Datasets and Benchmarks 2022\n",
    "authors": [
      "Baoxiong Jia",
      "Ting Lei",
      "Song-Chun Zhu",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03929"
  },
  {
    "id": "arXiv:2210.03930",
    "title": "Hierarchical Graph Transformer with Adaptive Node Sampling",
    "abstract": "The Transformer architecture has achieved remarkable success in a number of\ndomains including natural language processing and computer vision. However,\nwhen it comes to graph-structured data, transformers have not achieved\ncompetitive performance, especially on large graphs. In this paper, we identify\nthe main deficiencies of current graph transformers:(1) Existing node sampling\nstrategies in Graph Transformers are agnostic to the graph characteristics and\nthe training process. (2) Most sampling strategies only focus on local\nneighbors and neglect the long-range dependencies in the graph. We conduct\nexperimental investigations on synthetic datasets to show that existing\nsampling strategies are sub-optimal. To tackle the aforementioned problems, we\nformulate the optimization strategies of node sampling in Graph Transformer as\nan adversary bandit problem, where the rewards are related to the attention\nweights and can vary in the training procedure. Meanwhile, we propose a\nhierarchical attention scheme with graph coarsening to capture the long-range\ninteractions while reducing computational complexity. Finally, we conduct\nextensive experiments on real-world datasets to demonstrate the superiority of\nour method over existing graph transformers and popular GNNs.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Zaixi Zhang",
      "Qi Liu",
      "Qingyong Hu",
      "Chee-Kong Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03930"
  },
  {
    "id": "arXiv:2210.03932",
    "title": "A Finite Algorithm for the Realizabilty of a Delaunay Triangulation",
    "abstract": "The \\emph{Delaunay graph} of a point set $P \\subseteq \\mathbb{R}^2$ is the\nplane graph with the vertex-set $P$ and the edge-set that contains $\\{p,p'\\}$\nif there exists a disc whose intersection with $P$ is exactly $\\{p,p'\\}$.\nAccordingly, a triangulated graph $G$ is \\emph{Delaunay realizable} if there\nexists a triangulation of the Delaunay graph of some $P \\subseteq\n\\mathbb{R}^2$, called a \\emph{Delaunay triangulation} of $P$, that is\nisomorphic to $G$. The objective of \\textsc{Delaunay Realization} is to compute\na point set $P \\subseteq \\mathbb{R}^2$ that realizes a given graph $G$ (if such\na $P$ exists). Known algorithms do not solve \\textsc{Delaunay Realization} as\nthey are non-constructive. Obtaining a constructive algorithm for\n\\textsc{Delaunay Realization} was mentioned as an open problem by Hiroshima et\nal.~\\cite{hiroshima2000}. We design an $n^{\\mathcal{O}(n)}$-time constructive\nalgorithm for \\textsc{Delaunay Realization}. In fact, our algorithm outputs\nsets of points with {\\em integer} coordinates.",
    "descriptor": "",
    "authors": [
      "Akanksha Agrawal",
      "Saket Saurabh",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.03932"
  },
  {
    "id": "arXiv:2210.03934",
    "title": "Automata Equipped with Auxiliary Data Structures and Regular  Realizability Problems",
    "abstract": "We consider general computational models: one-way and two-way finite\nautomata, and logarithmic space Turing machines, all equipped with an auxiliary\ndata structure (ADS). The definition of an ADS is based on the language of\nprotocols of work with the ADS. We describe the connection of automata-based\nmodels with ``Balloon automata'' that are another general formalization of\nautomata equipped with an ADS presented by Hopcroft and Ullman in 1967.\nThis definition establishes the connection between the non-emptiness problem\nfor one-way automata with ADS, languages recognizable by nondeterministic\nlog-space Turing machines equipped with the same ADS, and a regular\nrealizability problem (NRR) for the language of ADS' protocols. The NRR problem\nis to verify whether the regular language on the input has a non-empty\nintersection with the language of protocols. The computational complexity of\nthese problems (and languages) is the same up to log-space reductions.",
    "descriptor": "\nComments: 25 pages. An extended version of the conference paper (DCFS 2021), submitted to International Journal of Foundations of Computer Science\n",
    "authors": [
      "Alexander Rubtsov",
      "Mikhail Vyalyi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.03934"
  },
  {
    "id": "arXiv:2210.03935",
    "title": "Convergence and error analysis for pure collisional breakage equation",
    "abstract": "Collisional breakage in the particulate process has a lot of recent\ncuriosity. We study the pure collisional breakage equation which is nonlinear\nin nature accompanied by locally bounded breakage kernel and collision kernel.\nThe continuous equation is discretized using a finite volume scheme (FVS) and\nthe weak convergence of the approximated solution towards the exact solution is\nanalyzed for non-uniform mesh. The idea of the analysis is based on the weak\n$L^1$ compactness and a suitable stable condition on time step is introduced.\nFurthermore, theoretical error analysis is developed for a uniform mesh when\nkernels are taken in $W_{loc}^{1,\\infty}$ space. The scheme is shown to be\nfirst-order convergent which is verified numerically for three test examples of\nthe kernels.",
    "descriptor": "",
    "authors": [
      "Sanjiv Kumar Bariwal",
      "Ankik Kumar Giri",
      "Rajesh Kumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.03935"
  },
  {
    "id": "arXiv:2210.03936",
    "title": "Cloud Native Robotic Applications with GPU Sharing on Kubernetes",
    "abstract": "In this paper we discuss our experience in teaching the Robotic Applications\nProgramming course at ZHAW combining the use of a Kubernetes (k8s) cluster and\nreal, heterogeneous, robotic hardware. We discuss the main advantages of our\nsolutions in terms of seamless ``simulation to real'' experience for students\nand the main shortcomings we encountered with networking and sharing GPUs to\nsupport deep learning workloads. We describe the current and foreseen\nalternatives to avoid these drawbacks in future course editions and propose a\nmore cloud-native approach to deploying multiple robotics applications on a k8s\ncluster.",
    "descriptor": "\nComments: Submission accepted at the IROS'22 Cloud Robotics Workshop\n",
    "authors": [
      "Giovanni Toffetti",
      "Leonardo Militano",
      "Se\u00e1n Murphy",
      "Remo Maurer",
      "Mark Straub"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03936"
  },
  {
    "id": "arXiv:2210.03940",
    "title": "Hierarchical Few-Shot Object Detection: Problem, Benchmark and Method",
    "abstract": "Few-shot object detection (FSOD) is to detect objects with a few examples.\nHowever, existing FSOD methods do not consider hierarchical fine-grained\ncategory structures of objects that exist widely in real life. For example,\nanimals are taxonomically classified into orders, families, genera and species\netc. In this paper, we propose and solve a new problem called hierarchical\nfew-shot object detection (Hi-FSOD), which aims to detect objects with\nhierarchical categories in the FSOD paradigm. To this end, on the one hand, we\nbuild the first large-scale and high-quality Hi-FSOD benchmark dataset\nHiFSOD-Bird, which contains 176,350 wild-bird images falling to 1,432\ncategories. All the categories are organized into a 4-level taxonomy,\nconsisting of 32 orders, 132 families, 572 genera and 1,432 species. On the\nother hand, we propose the first Hi-FSOD method HiCLPL, where a hierarchical\ncontrastive learning approach is developed to constrain the feature space so\nthat the feature distribution of objects is consistent with the hierarchical\ntaxonomy and the model's generalization power is strengthened. Meanwhile, a\nprobabilistic loss is designed to enable the child nodes to correct the\nclassification errors of their parent nodes in the taxonomy. Extensive\nexperiments on the benchmark dataset HiFSOD-Bird show that our method HiCLPL\noutperforms the existing FSOD methods.",
    "descriptor": "\nComments: Accepted by ACM MM 2022\n",
    "authors": [
      "Lu Zhang",
      "Yang Wang",
      "Jiaogen Zhou",
      "Chenbo Zhang",
      "Yinglu Zhang",
      "Jihong Guan",
      "Yatao Bian",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03940"
  },
  {
    "id": "arXiv:2210.03941",
    "title": "Learning Fine-Grained Visual Understanding for Video Question Answering  via Decoupling Spatial-Temporal Modeling",
    "abstract": "While recent large-scale video-language pre-training made great progress in\nvideo question answering, the design of spatial modeling of video-language\nmodels is less fine-grained than that of image-language models; existing\npractices of temporal modeling also suffer from weak and noisy alignment\nbetween modalities. To learn fine-grained visual understanding, we decouple\nspatial-temporal modeling and propose a hybrid pipeline, Decoupled\nSpatial-Temporal Encoders, integrating an image- and a video-language encoder.\nThe former encodes spatial semantics from larger but sparsely sampled frames\nindependently of time, while the latter models temporal dynamics at lower\nspatial but higher temporal resolution. To help the video-language model learn\ntemporal relations for video QA, we propose a novel pre-training objective,\nTemporal Referring Modeling, which requires the model to identify temporal\npositions of events in video sequences. Extensive experiments demonstrate that\nour model outperforms previous work pre-trained on orders of magnitude larger\ndatasets.",
    "descriptor": "\nComments: BMVC 2022. Code is available at this https URL\n",
    "authors": [
      "Hsin-Ying Lee",
      "Hung-Ting Su",
      "Bing-Chen Tsai",
      "Tsung-Han Wu",
      "Jia-Fong Yeh",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03941"
  },
  {
    "id": "arXiv:2210.03942",
    "title": "Point Cloud Upsampling via Cascaded Refinement Network",
    "abstract": "Point cloud upsampling focuses on generating a dense, uniform and\nproximity-to-surface point set. Most previous approaches accomplish these\nobjectives by carefully designing a single-stage network, which makes it still\nchallenging to generate a high-fidelity point distribution. Instead, upsampling\npoint cloud in a coarse-to-fine manner is a decent solution. However, existing\ncoarse-to-fine upsampling methods require extra training strategies, which are\ncomplicated and time-consuming during the training. In this paper, we propose a\nsimple yet effective cascaded refinement network, consisting of three\ngeneration stages that have the same network architecture but achieve different\nobjectives. Specifically, the first two upsampling stages generate the dense\nbut coarse points progressively, while the last refinement stage further adjust\nthe coarse points to a better position. To mitigate the learning conflicts\nbetween multiple stages and decrease the difficulty of regressing new points,\nwe encourage each stage to predict the point offsets with respect to the input\nshape. In this manner, the proposed cascaded refinement network can be easily\noptimized without extra learning strategies. Moreover, we design a\ntransformer-based feature extraction module to learn the informative global and\nlocal shape context. In inference phase, we can dynamically adjust the model\nefficiency and effectiveness, depending on the available computational\nresources. Extensive experiments on both synthetic and real-scanned datasets\ndemonstrate that the proposed approach outperforms the existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: The first two authors contributed equally to this work. The code is publicly available at this https URL Accepted to ACCV 2022 as oral presentation\n",
    "authors": [
      "Hang Du",
      "Xuejun Yan",
      "Jingjing Wang",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03942"
  },
  {
    "id": "arXiv:2210.03945",
    "title": "Understanding HTML with Large Language Models",
    "abstract": "Large language models (LLMs) have shown exceptional performance on a variety\nof natural language tasks. Yet, their capabilities for HTML understanding --\ni.e., parsing the raw HTML of a webpage, with applications to automation of\nweb-based tasks, crawling, and browser-assisted retrieval -- have not been\nfully explored. We contribute HTML understanding models (fine-tuned LLMs) and\nan in-depth analysis of their capabilities under three tasks: (i) Semantic\nClassification of HTML elements, (ii) Description Generation for HTML inputs,\nand (iii) Autonomous Web Navigation of HTML pages. While previous work has\ndeveloped dedicated architectures and training procedures for HTML\nunderstanding, we show that LLMs pretrained on standard natural language\ncorpora transfer remarkably well to HTML understanding tasks. For instance,\nfine-tuned LLMs are 12% more accurate at semantic classification compared to\nmodels trained exclusively on the task dataset. Moreover, when fine-tuned on\ndata from the MiniWoB benchmark, LLMs successfully complete 50% more tasks\nusing 192x less data compared to the previous best supervised model. Out of the\nLLMs we evaluate, we show evidence that T5-based models are ideal due to their\nbidirectional encoder-decoder architecture. To promote further research on LLMs\nfor HTML understanding, we create and open-source a large-scale HTML dataset\ndistilled and auto-labeled from CommonCrawl.",
    "descriptor": "",
    "authors": [
      "Izzeddin Gur",
      "Ofir Nachum",
      "Yingjie Miao",
      "Mustafa Safdari",
      "Austin Huang",
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Noah Fiedel",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03945"
  },
  {
    "id": "arXiv:2210.03948",
    "title": "System-Level Modelling and Beamforming Design for RIS-assisted Cellular  Systems",
    "abstract": "Reconfigurable intelligent surface (RIS) is considered as key technology for\nimproving the coverage and network capacity of the next-generation cellular\nsystems. By changing the phase shifters at RIS, the effective channel between\nthe base station and user can be reconfigured to enhance the network capacity\nand coverage. However, the selection of phase shifters at RIS has a significant\nimpact on the achievable gains. In this letter, we propose a beamforming design\nfor the RIS-assisted cellular systems. We then present in detail the\nsystem-level modelling and formulate a 3-dimension channel model between the\nbase station, RIS, and user, to carry out system-level evaluations. We evaluate\nthe proposed beamforming design in the presence of ideal and discrete phase\nshifters at RIS and show that the proposed design achieves significant\nimprovements as compared to the state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Pavan Reddy M.",
      "SaiDhiraj Amuru",
      "Kiran Kuchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03948"
  },
  {
    "id": "arXiv:2210.03949",
    "title": "ConstGCN: Constrained Transmission-based Graph Convolutional Networks  for Document-level Relation Extraction",
    "abstract": "Document-level relation extraction with graph neural networks faces a\nfundamental graph construction gap between training and inference - the golden\ngraph structure only available during training, which causes that most methods\nadopt heuristic or syntactic rules to construct a prior graph as a pseudo\nproxy. In this paper, we propose $\\textbf{ConstGCN}$, a novel graph\nconvolutional network which performs knowledge-based information propagation\nbetween entities along with all specific relation spaces without any prior\ngraph construction. Specifically, it updates the entity representation by\naggregating information from all other entities along with each relation space,\nthus modeling the relation-aware spatial information. To control the\ninformation flow passing through the indeterminate relation spaces, we propose\nto constrain the propagation using transmitting scores learned from the Noise\nContrastive Estimation between fact triples. Experimental results show that our\nmethod outperforms the previous state-of-the-art (SOTA) approaches on the DocRE\ndataset.",
    "descriptor": "",
    "authors": [
      "Ji Qi",
      "Bin Xu",
      "Kaisheng Zeng",
      "Jinxin Liu",
      "Jifan Yu",
      "Qi Gao",
      "Juanzi Li",
      "Lei Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03949"
  },
  {
    "id": "arXiv:2210.03951",
    "title": "ArabSign: A Multi-modality Dataset and Benchmark for Continuous Arabic  Sign Language Recognition",
    "abstract": "Sign language recognition has attracted the interest of researchers in recent\nyears. While numerous approaches have been proposed for European and Asian sign\nlanguages recognition, very limited attempts have been made to develop similar\nsystems for the Arabic sign language (ArSL). This can be attributed partly to\nthe lack of a dataset at the sentence level. In this paper, we aim to make a\nsignificant contribution by proposing ArabSign, a continuous ArSL dataset. The\nproposed dataset consists of 9,335 samples performed by 6 signers. The total\ntime of the recorded sentences is around 10 hours and the average sentence's\nlength is 3.1 signs. ArabSign dataset was recorded using a Kinect V2 camera\nthat provides three types of information (color, depth, and skeleton joint\npoints) recorded simultaneously for each sentence. In addition, we provide the\nannotation of the dataset according to ArSL and Arabic language structures that\ncan help in studying the linguistic characteristics of ArSL. To benchmark this\ndataset, we propose an encoder-decoder model for Continuous ArSL recognition.\nThe model has been evaluated on the proposed dataset, and the obtained results\nshow that the encoder-decoder model outperformed the attention mechanism with\nan average word error rate (WER) of 0.50 compared with 0.62 with the attention\nmechanism. The data and code are available at github.com/Hamzah-Luqman/ArabSign",
    "descriptor": "\nComments: 8\n",
    "authors": [
      "Hamzah Luqman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03951"
  },
  {
    "id": "arXiv:2210.03952",
    "title": "Detaching and Boosting: Dual Engine for Scale-Invariant Self-Supervised  Monocular Depth Estimation",
    "abstract": "Monocular depth estimation (MDE) in the self-supervised scenario has emerged\nas a promising method as it refrains from the requirement of ground truth\ndepth. Despite continuous efforts, MDE is still sensitive to scale changes\nespecially when all the training samples are from one single camera. Meanwhile,\nit deteriorates further since camera movement results in heavy coupling between\nthe predicted depth and the scale change. In this paper, we present a\nscale-invariant approach for self-supervised MDE, in which scale-sensitive\nfeatures (SSFs) are detached away while scale-invariant features (SIFs) are\nboosted further. To be specific, a simple but effective data augmentation by\nimitating the camera zooming process is proposed to detach SSFs, making the\nmodel robust to scale changes. Besides, a dynamic cross-attention module is\ndesigned to boost SIFs by fusing multi-scale cross-attention features\nadaptively. Extensive experiments on the KITTI dataset demonstrate that the\ndetaching and boosting strategies are mutually complementary in MDE and our\napproach achieves new State-of-The-Art performance against existing works from\n0.097 to 0.090 w.r.t absolute relative error. The code will be made public\nsoon.",
    "descriptor": "\nComments: Accepted by IEEE Robotics and Automation Letters (RAL)\n",
    "authors": [
      "Peizhe Jiang",
      "Wei Yang",
      "Xiaoqing Ye",
      "Xiao Tan",
      "Meng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03952"
  },
  {
    "id": "arXiv:2210.03953",
    "title": "Non-Monotonic Latent Alignments for CTC-Based Non-Autoregressive Machine  Translation",
    "abstract": "Non-autoregressive translation (NAT) models are typically trained with the\ncross-entropy loss, which forces the model outputs to be aligned verbatim with\nthe target sentence and will highly penalize small shifts in word positions.\nLatent alignment models relax the explicit alignment by marginalizing out all\nmonotonic latent alignments with the CTC loss. However, they cannot handle\nnon-monotonic alignments, which is non-negligible as there is typically global\nword reordering in machine translation. In this work, we explore non-monotonic\nlatent alignments for NAT. We extend the alignment space to non-monotonic\nalignments to allow for the global word reordering and further consider all\nalignments that overlap with the target sentence. We non-monotonically match\nthe alignments to the target sentence and train the latent alignment model to\nmaximize the F1 score of non-monotonic matching. Extensive experiments on major\nWMT benchmarks show that our method substantially improves the translation\nperformance of CTC-based models. Our best model achieves 30.06 BLEU on WMT14\nEn-De with only one-iteration decoding, closing the gap between\nnon-autoregressive and autoregressive models.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Chenze Shao",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03953"
  },
  {
    "id": "arXiv:2210.03954",
    "title": "Contact-aware Human Motion Forecasting",
    "abstract": "In this paper, we tackle the task of scene-aware 3D human motion forecasting,\nwhich consists of predicting future human poses given a 3D scene and a past\nhuman motion. A key challenge of this task is to ensure consistency between the\nhuman and the scene, accounting for human-scene interactions. Previous attempts\nto do so model such interactions only implicitly, and thus tend to produce\nartifacts such as \"ghost motion\" because of the lack of explicit constraints\nbetween the local poses and the global motion. Here, by contrast, we propose to\nexplicitly model the human-scene contacts. To this end, we introduce\ndistance-based contact maps that capture the contact relationships between\nevery joint and every 3D scene point at each time instant. We then develop a\ntwo-stage pipeline that first predicts the future contact maps from the past\nones and the scene point cloud, and then forecasts the future human poses by\nconditioning them on the predicted contact maps. During training, we explicitly\nencourage consistency between the global motion and the local poses via a prior\ndefined using the contact maps and future poses. Our approach outperforms the\nstate-of-the-art human motion forecasting and human synthesis methods on both\nsynthetic and real datasets. Our code is available at\nhttps://github.com/wei-mao-2019/ContAwareMotionPred.",
    "descriptor": "\nComments: Accepted to NeurIPS2022\n",
    "authors": [
      "Wei Mao",
      "Miaomiao Liu",
      "Richard Hartley",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03954"
  },
  {
    "id": "arXiv:2210.03956",
    "title": "Robust Graph Structure Learning over Images via Multiple Statistical  Tests",
    "abstract": "Graph structure learning aims to learn connectivity in a graph from data. It\nis particularly important for many computer vision related tasks since no\nexplicit graph structure is available for images for most cases. A natural way\nto construct a graph among images is to treat each image as a node and assign\npairwise image similarities as weights to corresponding edges. It is well known\nthat pairwise similarities between images are sensitive to the noise in feature\nrepresentations, leading to unreliable graph structures. We address this\nproblem from the viewpoint of statistical tests. By viewing the feature vector\nof each node as an independent sample, the decision of whether creating an edge\nbetween two nodes based on their similarity in feature representation can be\nthought as a ${\\it single}$ statistical test. To improve the robustness in the\ndecision of creating an edge, multiple samples are drawn and integrated by\n${\\it multiple}$ statistical tests to generate a more reliable similarity\nmeasure, consequentially more reliable graph structure. The corresponding\nelegant matrix form named $\\mathcal{B}\\textbf{-Attention}$ is designed for\nefficiency. The effectiveness of multiple tests for graph structure learning is\nverified both theoretically and empirically on multiple clustering and ReID\nbenchmark datasets. Source codes are available at\nhttps://github.com/Thomas-wyh/B-Attention.",
    "descriptor": "\nComments: Accepted by the NeurIPS 2022. Homepage: this https URL\n",
    "authors": [
      "Yaohua Wang",
      "FangYi Zhang",
      "Ming Lin",
      "Senzhang Wang",
      "Xiuyu Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03956"
  },
  {
    "id": "arXiv:2210.03958",
    "title": "Online Schema Evolution is (Almost) Free for Snapshot Databases",
    "abstract": "Modern database applications often change their schemas to keep up with the\nchanging requirements. However, support for online and transactional schema\nevolution remains challenging in existing database systems. Specifically, prior\nwork often takes ad hoc approaches to schema evolution with 'patches' applied\nto existing systems, leading to many corner cases and often incomplete\nfunctionality. Applications therefore often have to carefully schedule\ndowntimes for schema changes, sacrificing availability.\nThis paper presents Tesseract, a new approach to online and transactional\nschema evolution without the aforementioned drawbacks. We design Tesseract\nbased on a key observation: in widely used multi-versioned database systems,\nschema evolution can be modeled as data modification operations that change the\nentire table, i.e., data-definition-as-modification (DDaM). This allows us to\nsupport schema almost 'for free' by leveraging the concurrency control\nprotocol. By simple tweaks to existing snapshot isolation protocols, on a\n40-core server we show that under a variety of workloads, Tesseract is able to\nprovide online, transactional schema evolution without service downtime, and\nretain high application performance when schema evolution is in progress.",
    "descriptor": "\nComments: To appear at Proceedings of the 2023 International Conference on Very Large Data Bases (VLDB 2023)\n",
    "authors": [
      "Tianxun Hu",
      "Tianzheng Wang",
      "Qingqing Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.03958"
  },
  {
    "id": "arXiv:2210.03961",
    "title": "Dynamic Tensor Product Regression",
    "abstract": "In this work, we initiate the study of \\emph{Dynamic Tensor Product\nRegression}. One has matrices $A_1\\in \\mathbb{R}^{n_1\\times d_1},\\ldots,A_q\\in\n\\mathbb{R}^{n_q\\times d_q}$ and a label vector $b\\in \\mathbb{R}^{n_1\\ldots\nn_q}$, and the goal is to solve the regression problem with the design matrix\n$A$ being the tensor product of the matrices $A_1, A_2, \\dots, A_q$ i.e.\n$\\min_{x\\in \\mathbb{R}^{d_1\\ldots d_q}}~\\|(A_1\\otimes \\ldots\\otimes\nA_q)x-b\\|_2$. At each time step, one matrix $A_i$ receives a sparse change, and\nthe goal is to maintain a sketch of the tensor product $A_1\\otimes\\ldots\n\\otimes A_q$ so that the regression solution can be updated quickly.\nRecomputing the solution from scratch for each round is very slow and so it is\nimportant to develop algorithms which can quickly update the solution with the\nnew design matrix. Our main result is a dynamic tree data structure where any\nupdate to a single matrix can be propagated quickly throughout the tree. We\nshow that our data structure can be used to solve dynamic versions of not only\nTensor Product Regression, but also Tensor Product Spline regression (which is\na generalization of ridge regression) and for maintaining Low Rank\nApproximations for the tensor product.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Aravind Reddy",
      "Zhao Song",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03961"
  },
  {
    "id": "arXiv:2210.03962",
    "title": "Low-Power Random Access for Timely Status Update: Packet-based or  Connection-based?",
    "abstract": "This paper investigates low-power random access protocols for timely status\nupdate systems with age of information (AoI) requirements. AoI characterizes\ninformation freshness, formally defined as the time elapsed since the\ngeneration of the last successfully received update. Considering an extensive\nnetwork, a fundamental problem is how to schedule massive transmitters to\naccess the wireless channel to achieve low network-wide AoI and high energy\nefficiency. In conventional packet-based random access protocols, transmitters\ncontend for the channel by sending the whole data packet. When the packet\nduration is long, the time and transmit power wasted due to packet collisions\nis considerable. In contrast, connection-based random access protocols first\nestablish connections with the receiver before the data packet is transmitted.\nIntuitively, from an information freshness perspective, there should be\nconditions favoring either side. This paper presents a comparative study of the\naverage AoI of packet-based and connection-based random access protocols, given\nan average transmit power budget. Specifically, we consider slotted Aloha (SA)\nand frame slotted Aloha (FSA) as representatives of packet-based random access\nand design a request-then-access (RTA) protocol to study the AoI of\nconnection-based random access. We derive closed-form average AoI and average\ntransmit power consumption formulas for different protocols. Our analyses\nindicate that the use of packet-based or connection-based protocols depends\nmainly on the payload size of update packets and the transmit power budget. In\nparticular, RTA saves power and reduces AoI significantly, especially when the\npayload size is large. Overall, our investigation provides insights into the\npractical design of random access protocols for low-power timely status update\nsystems.",
    "descriptor": "",
    "authors": [
      "Jian Feng",
      "Haoyuan Pan",
      "Tse-Tin Chan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03962"
  },
  {
    "id": "arXiv:2210.03963",
    "title": "SDA: Simple Discrete Augmentation for Contrastive Sentence  Representation Learning",
    "abstract": "Contrastive learning methods achieve state-of-the-art results in unsupervised\nsentence representation learning. Although playing essential roles in\ncontrastive learning, data augmentation methods applied on sentences have not\nbeen fully explored. Current SOTA method SimCSE utilizes a simple dropout\nmechanism as continuous augmentation which outperforms discrete augmentations\nsuch as cropping, word deletion and synonym replacement. To understand the\nunderlying rationales, we revisit existing approaches and attempt to\nhypothesize the desiderata of reasonable data augmentation methods: balance of\nsemantic consistency and expression diversity. Based on the hypothesis, we\npropose three simple yet effective discrete sentence augmentation methods,\ni.e., punctuation insertion, affirmative auxiliary and double negation. The\npunctuation marks, auxiliaries and negative words act as minimal noises in\nlexical level to produce diverse sentence expressions. Unlike traditional\naugmentation methods which randomly modify the sentence, our augmentation rules\nare well designed for generating semantically consistent and grammatically\ncorrect sentences. We conduct extensive experiments on both English and Chinese\nsemantic textual similarity datasets. The results show the robustness and\neffectiveness of the proposed methods.",
    "descriptor": "",
    "authors": [
      "Zhenyu Mao",
      "Dongsheng Zhu",
      "Jinghui Lu",
      "Rui Zhao",
      "Fei Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03963"
  },
  {
    "id": "arXiv:2210.03967",
    "title": "Asymptotically Unbiased Instance-wise Regularized Partial AUC  Optimization: Theory and Algorithm",
    "abstract": "The Partial Area Under the ROC Curve (PAUC), typically including One-way\nPartial AUC (OPAUC) and Two-way Partial AUC (TPAUC), measures the average\nperformance of a binary classifier within a specific false positive rate and/or\ntrue positive rate interval, which is a widely adopted measure when decision\nconstraints must be considered. Consequently, PAUC optimization has naturally\nattracted increasing attention in the machine learning community within the\nlast few years. Nonetheless, most of the existing methods could only optimize\nPAUC approximately, leading to inevitable biases that are not controllable.\nFortunately, a recent work presents an unbiased formulation of the PAUC\noptimization problem via distributional robust optimization. However, it is\nbased on the pair-wise formulation of AUC, which suffers from the limited\nscalability w.r.t. sample size and a slow convergence rate, especially for\nTPAUC. To address this issue, we present a simpler reformulation of the problem\nin an asymptotically unbiased and instance-wise manner. For both OPAUC and\nTPAUC, we come to a nonconvex strongly concave minimax regularized problem of\ninstance-wise functions. On top of this, we employ an efficient solver enjoys a\nlinear per-iteration computational complexity w.r.t. the sample size and a\ntime-complexity of $O(\\epsilon^{-1/3})$ to reach a $\\epsilon$ stationary point.\nFurthermore, we find that the minimax reformulation also facilitates the\ntheoretical analysis of generalization error as a byproduct. Compared with the\nexisting results, we present new error bounds that are much easier to prove and\ncould deal with hypotheses with real-valued outputs. Finally, extensive\nexperiments on several benchmark datasets demonstrate the effectiveness of our\nmethod.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Huiyang Shao",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Shilong Bao",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03967"
  },
  {
    "id": "arXiv:2210.03968",
    "title": "A Survey on Extreme Multi-label Learning",
    "abstract": "Multi-label learning has attracted significant attention from both academic\nand industry field in recent decades. Although existing multi-label learning\nalgorithms achieved good performance in various tasks, they implicitly assume\nthe size of target label space is not huge, which can be restrictive for\nreal-world scenarios. Moreover, it is infeasible to directly adapt them to\nextremely large label space because of the compute and memory overhead.\nTherefore, eXtreme Multi-label Learning (XML) is becoming an important task and\nmany effective approaches are proposed. To fully understand XML, we conduct a\nsurvey study in this paper. We first clarify a formal definition for XML from\nthe perspective of supervised learning. Then, based on different model\narchitectures and challenges of the problem, we provide a thorough discussion\nof the advantages and disadvantages of each category of methods. For the\nbenefit of conducting empirical studies, we collect abundant resources\nregarding XML, including code implementations, and useful tools. Lastly, we\npropose possible research directions in XML, such as new evaluation metrics,\nthe tail label problem, and weakly supervised XML.",
    "descriptor": "\nComments: A preliminary version\n",
    "authors": [
      "Tong Wei",
      "Zhen Mao",
      "Jiang-Xin Shi",
      "Yu-Feng Li",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03968"
  },
  {
    "id": "arXiv:2210.03969",
    "title": "Kernel-based Substructure Exploration for Next POI Recommendation",
    "abstract": "Point-of-Interest (POI) recommendation, which benefits from the proliferation\nof GPS-enabled devices and location-based social networks (LBSNs), plays an\nincreasingly important role in recommender systems. It aims to provide users\nwith the convenience to discover their interested places to visit based on\nprevious visits and current status. Most existing methods usually merely\nleverage recurrent neural networks (RNNs) to explore sequential influences for\nrecommendation. Despite the effectiveness, these methods not only neglect\ntopological geographical influences among POIs, but also fail to model\nhigh-order sequential substructures. To tackle the above issues, we propose a\nKernel-Based Graph Neural Network (KBGNN) for next POI recommendation, which\ncombines the characteristics of both geographical and sequential influences in\na collaborative way. KBGNN consists of a geographical module and a sequential\nmodule. On the one hand, we construct a geographical graph and leverage a\nmessage passing neural network to capture the topological geographical\ninfluences. On the other hand, we explore high-order sequential substructures\nin the user-aware sequential graph using a graph kernel neural network to\ncapture user preferences. Finally, a consistency learning framework is\nintroduced to jointly incorporate geographical and sequential information\nextracted from two separate graphs. In this way, the two modules effectively\nexchange knowledge to mutually enhance each other. Extensive experiments\nconducted on two real-world LBSN datasets demonstrate the superior performance\nof our proposed method over the state-of-the-arts. Our codes are available at\nhttps://github.com/Fang6ang/KBGNN.",
    "descriptor": "\nComments: Accepted by the IEEE International Conference on Data Mining (ICDM) 2022\n",
    "authors": [
      "Wei Ju",
      "Yifang Qin",
      "Ziyue Qiao",
      "Xiao Luo",
      "Yifan Wang",
      "Yanjie Fu",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03969"
  },
  {
    "id": "arXiv:2210.03970",
    "title": "KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text  Classification",
    "abstract": "Medical text learning has recently emerged as a promising area to improve\nhealthcare due to the wide adoption of electronic health record (EHR) systems.\nThe complexity of the medical text such as diverse length, mixed text types,\nand full of medical jargon, poses a great challenge for developing effective\ndeep learning models. BERT has presented state-of-the-art results in many NLP\ntasks, such as text classification and question answering. However, the\nstandalone BERT model cannot deal with the complexity of the medical text,\nespecially the lengthy clinical notes. Herein, we develop a new model called\nKG-MTT-BERT (Knowledge Graph Enhanced Multi-Type Text BERT) by extending the\nBERT model for long and multi-type text with the integration of the medical\nknowledge graph. Our model can outperform all baselines and other\nstate-of-the-art models in diagnosis-related group (DRG) classification, which\nrequires comprehensive medical text for accurate classification. We also\ndemonstrated that our model can effectively handle multi-type text and the\nintegration of medical knowledge graph can significantly improve the\nperformance.",
    "descriptor": "",
    "authors": [
      "Yong He",
      "Cheng Wang",
      "Shun Zhang",
      "Nan Li",
      "Zhaorong Li",
      "Zhenyu Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03970"
  },
  {
    "id": "arXiv:2210.03971",
    "title": "An Ordinal Latent Variable Model of Conflict Intensity",
    "abstract": "For the quantitative monitoring of international relations, political events\nare extracted from the news and parsed into \"who-did-what-to-whom\" patterns.\nThis has resulted in large data collections which require aggregate statistics\nfor analysis. The Goldstein Scale is an expert-based measure that ranks\nindividual events on a one-dimensional scale from conflictual to cooperative.\nHowever, the scale disregards fatality counts as well as perpetrator and victim\ntypes involved in an event. This information is typically considered in\nqualitative conflict assessment. To address this limitation, we propose a\nprobabilistic generative model over the full\nsubject-predicate-quantifier-object tuples associated with an event. We treat\nconflict intensity as an interpretable, ordinal latent variable that correlates\nconflictual event types with high fatality counts. Taking a Bayesian approach,\nwe learn a conflict intensity scale from data and find the optimal number of\nintensity classes. We evaluate the model by imputing missing data. Our scale\nproves to be more informative than the original Goldstein Scale in\nautoregressive forecasting and when compared with global online attention\ntowards armed conflicts.",
    "descriptor": "",
    "authors": [
      "Niklas Stoehr",
      "Lucas Torroba Hennigen",
      "Josef Valvoda",
      "Robert West",
      "Ryan Cotterell",
      "Aaron Schein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.03971"
  },
  {
    "id": "arXiv:2210.03974",
    "title": "FBNet: Feedback Network for Point Cloud Completion",
    "abstract": "The rapid development of point cloud learning has driven point cloud\ncompletion into a new era. However, the information flows of most existing\ncompletion methods are solely feedforward, and high-level information is rarely\nreused to improve low-level feature learning. To this end, we propose a novel\nFeedback Network (FBNet) for point cloud completion, in which present features\nare efficiently refined by rerouting subsequent fine-grained ones. Firstly,\npartial inputs are fed to a Hierarchical Graph-based Network (HGNet) to\ngenerate coarse shapes. Then, we cascade several Feedback-Aware Completion\n(FBAC) Blocks and unfold them across time recurrently. Feedback connections\nbetween two adjacent time steps exploit fine-grained features to improve\npresent shape generations. The main challenge of building feedback connections\nis the dimension mismatching between present and subsequent features. To\naddress this, the elaborately designed point Cross Transformer exploits\nefficient information from feedback features via cross attention strategy and\nthen refines present features with the enhanced feedback features. Quantitative\nand qualitative experiments on several datasets demonstrate the superiority of\nproposed FBNet compared to state-of-the-art methods on point completion task.",
    "descriptor": "\nComments: The first two authors contributed equally to this work. The source code and model are available at this https URL Accepted to ECCV 2022 as oral presentation\n",
    "authors": [
      "Xuejun Yan",
      "Hongyu Yan",
      "Jingjing Wang",
      "Hang Du",
      "Zhihong Wu",
      "Di Xie",
      "Shiliang Pu",
      "Li Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03974"
  },
  {
    "id": "arXiv:2210.03975",
    "title": "Self-organizing nest migration dynamics synthesis for ant colony systems",
    "abstract": "In this study, we synthesize a novel dynamical approach for ant colonies\nenabling them to migrate to new nest sites in a self-organizing fashion. In\nother words, we realize ant colony migration as a self-organizing\nphenotype-level collective behavior. For this purpose, we first segment the\nedges of the graph of ants' pathways. Then, each segment, attributed to its own\npheromone profile, may host an ant. So, multiple ants may occupy an edge at the\nsame time. Thanks to this segment-wise edge formulation, ants have more\nselection options in the course of their pathway determination, thereby\nincreasing the diversity of their colony's emergent behaviors. In light of the\ncontinuous pheromone dynamics of segments, each edge owns a spatio-temporal\npiece-wise continuous pheromone profile in which both deposit and evaporation\nprocesses are unified. The passive dynamics of the proposed migration mechanism\nis sufficiently rich so that an ant colony can migrate to the vicinity of a new\nnest site in a self-organizing manner without any external supervision. In\nparticular, we perform extensive simulations to test our migration dynamics\napplied to a colony including 500 ants traversing a pathway graph comprising\n200 nodes and 4000 edges which are segmented based on various resolutions. The\nobtained results exhibit the effectiveness of our strategy.",
    "descriptor": "",
    "authors": [
      "Matin Macktoobian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.03975"
  },
  {
    "id": "arXiv:2210.03980",
    "title": "Distilling Causal Effect from Miscellaneous Other-Class for Continual  Named Entity Recognition",
    "abstract": "Continual Learning for Named Entity Recognition (CL-NER) aims to learn a\ngrowing number of entity types over time from a stream of data. However, simply\nlearning Other-Class in the same way as new entity types amplifies the\ncatastrophic forgetting and leads to a substantial performance drop. The main\ncause behind this is that Other-Class samples usually contain old entity types,\nand the old knowledge in these Other-Class samples is not preserved properly.\nThanks to the causal inference, we identify that the forgetting is caused by\nthe missing causal effect from the old data. To this end, we propose a unified\ncausal framework to retrieve the causality from both new entity types and\nOther-Class. Furthermore, we apply curriculum learning to mitigate the impact\nof label noise and introduce a self-adaptive weight for balancing the causal\neffects between new entity types and Other-Class. Experimental results on three\nbenchmark datasets show that our method outperforms the state-of-the-art method\nby a large margin. Moreover, our method can be combined with the existing\nstate-of-the-art methods to improve the performance in CL-NER",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Junhao Zheng",
      "Zhanxian Liang",
      "Haibin Chen",
      "Qianli Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03980"
  },
  {
    "id": "arXiv:2210.03984",
    "title": "Ball-and-socket joint pose estimation using magnetic field",
    "abstract": "Roboy 3.0 is an open-source tendon-driven humanoid robot that mimics the\nmusculoskeletal system of the human body. Roboy 3.0 is being developed as a\nremote robotic body - or a robotic avatar - for humans to achieve remote\nphysical presence. Artificial muscles and tendons allow it to closely resemble\nhuman morphology with 3-DoF neck, shoulders and wrists. Roboy 3.0 3-DoF joints\nare implemented as ball-and-socket joints. While industry provides a clear\nsolution for 1-DoF joint pose sensing, it is not the case for the\nball-and-socket joint type. In this paper we present a custom solution to\nestimate the pose of a ball-and-socket joint. We embed an array of magnets into\nthe ball and an array of 3D magnetic sensors into the socket. We then, based on\nthe changes in the magnetic field as the joint rotates, are able to estimate\nthe orientation of the joint. We evaluate the performance of two neural network\napproaches using the LSTM and Bayesian-filter like DVBF. Results show that in\norder to achieve the same mean square error (MSE) DVBFs require significantly\nmore time training and hyperparameter tuning compared to LSTMs, while DVBF cope\nwith sensor noise better. Both methods are capable of real-time joint pose\nestimation at 37 Hz with MSE of around 0.03 rad for all three degrees of\nfreedom combined. The LSTM model is deployed and used for joint pose estimation\nof Roboy 3.0's shoulder and neck joints. The software implementation and PCB\ndesigns are open-sourced under\nhttps://github.com/Roboy/ball_and_socket_estimator",
    "descriptor": "\nComments: Accepted at the International Symposium on Robotics Research (ISRR) 2022\n",
    "authors": [
      "Tai Hoang",
      "Alona Kharchenko",
      "Simon Trendel",
      "Rafael Hostettler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03984"
  },
  {
    "id": "arXiv:2210.03985",
    "title": "Bird-Eye Transformers for Text Generation Models",
    "abstract": "Transformers have become an indispensable module for text generation models\nsince their great success in machine translation. Previous works attribute\nthe~success of transformers to the query-key-value dot-product attention, which\nprovides a robust inductive bias by the fully connected token graphs. However,\nwe found that self-attention has a severe limitation. When predicting the\n(i+1)-th token, self-attention only takes the i-th token as an information\ncollector, and it tends to give a high attention weight to those tokens similar\nto itself. Therefore, most of the historical information that occurred before\nthe i-th token is not taken into consideration. Based on this observation, in\nthis paper, we propose a new architecture, called bird-eye transformer(BET),\nwhich goes one step further to improve the performance of transformers by\nreweighting self-attention to encourage it to focus more on important\nhistorical information. We have conducted experiments on multiple text\ngeneration tasks, including machine translation (2 datasets) and language\nmodels (3 datasets). These experimental~results show that our proposed model\nachieves a better performance than the baseline transformer architectures\non~all~datasets. The code is released at:\n\\url{https://sites.google.com/view/bet-transformer/home}.",
    "descriptor": "",
    "authors": [
      "Lei Sha",
      "Yuhang Song",
      "Yordan Yordanov",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03985"
  },
  {
    "id": "arXiv:2210.03986",
    "title": "TransRepair: Context-aware Program Repair for Compilation Errors",
    "abstract": "Automatically fixing compilation errors can greatly raise the productivity of\nsoftware development, by guiding the novice or AI programmers to write and\ndebug code. Recently, learning-based program repair has gained extensive\nattention and became the state-of-the-art in practice. But it still leaves\nplenty of space for improvement. In this paper, we propose an end-to-end\nsolution TransRepair to locate the error lines and create the correct\nsubstitute for a C program simultaneously. Superior to the counterpart, our\napproach takes into account the context of erroneous code and diagnostic\ncompilation feedback. Then we devise a Transformer-based neural network to\nlearn the ways of repair from the erroneous code as well as its context and the\ndiagnostic feedback. To increase the effectiveness of TransRepair, we summarize\n5 types and 74 fine-grained sub-types of compilations errors from two\nreal-world program datasets and the Internet. Then a program corruption\ntechnique is developed to synthesize a large dataset with 1,821,275 erroneous C\nprograms. Through the extensive experiments, we demonstrate that TransRepair\noutperforms the state-of-the-art in both single repair accuracy and full repair\naccuracy. Further analysis sheds light on the strengths and weaknesses in the\ncontemporary solutions for future improvement.",
    "descriptor": "\nComments: 11 pages, accepted to ASE '22\n",
    "authors": [
      "Xueyang Li",
      "Shangqing Liu",
      "Ruitao Feng",
      "Guozhu Meng",
      "Xiaofei Xie",
      "Kai Chen",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.03986"
  },
  {
    "id": "arXiv:2210.03990",
    "title": "Weisfeiler--Lehman goes Dynamic: An Analysis of the Expressive Power of  Graph Neural Networks for Attributed and Dynamic Graphs",
    "abstract": "Graph Neural Networks (GNNs) are a large class of relational models for graph\nprocessing. Recent theoretical studies on the expressive power of GNNs have\nfocused on two issues. On the one hand, it has been proven that GNNs are as\npowerful as the Weisfeiler-Lehman test (1-WL) in their ability to distinguish\ngraphs. Moreover, it has been shown that the equivalence enforced by 1-WL\nequals unfolding equivalence. On the other hand, GNNs turned out to be\nuniversal approximators on graphs modulo the constraints enforced by\n1-WL/unfolding equivalence. However, these results only apply to Static\nUndirected Homogeneous Graphs with node attributes. In contrast, real-life\napplications often involve a variety of graph properties, such as, e.g.,\ndynamics or node and edge attributes. In this paper, we conduct a theoretical\nanalysis of the expressive power of GNNs for these two graph types that are\nparticularly of interest. Dynamic graphs are widely used in modern\napplications, and its theoretical analysis requires new approaches. The\nattributed type acts as a standard form for all graph types since it has been\nshown that all graph types can be transformed without loss to Static Undirected\nHomogeneous Graphs with attributes on nodes and edges (SAUHG). The study\nconsiders generic GNN models and proposes appropriate 1-WL tests for those\ndomains. Then, the results on the expressive power of GNNs are extended by\nproving that GNNs have the same capability as the 1-WL test in distinguishing\ndynamic and attributed graphs, the 1-WL equivalence equals unfolding\nequivalence and that GNNs are universal approximators modulo 1-WL/unfolding\nequivalence. Moreover, the proof of the approximation capability holds for\nSAUHGs, which include most of those used in practical applications, and it is\nconstructive in nature allowing to deduce hints on the architecture of GNNs\nthat can achieve the desired accuracy.",
    "descriptor": "",
    "authors": [
      "Silvia Beddar-Wiesing",
      "Giuseppe Alessio D'Inverno",
      "Caterina Graziani",
      "Veronica Lachi",
      "Alice Moallemy-Oureh",
      "Franco Scarselli",
      "Josephine Maria Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03990"
  },
  {
    "id": "arXiv:2210.03992",
    "title": "Generative Language Models for Paragraph-Level Question Generation",
    "abstract": "Powerful generative models have led to recent progress in question generation\n(QG). However, it is difficult to measure advances in QG research since there\nare no standardized resources that allow a uniform comparison among approaches.\nIn this paper, we introduce QG-Bench, a multilingual and multidomain benchmark\nfor QG that unifies existing question answering datasets by converting them to\na standard QG setting. It includes general-purpose datasets such as SQuAD for\nEnglish, datasets from ten domains and two styles, as well as datasets in eight\ndifferent languages. Using QG-Bench as a reference, we perform an extensive\nanalysis of the capabilities of language models for the task. First, we propose\nrobust QG baselines based on fine-tuning generative language models. Then, we\ncomplement automatic evaluation based on standard metrics with an extensive\nmanual evaluation, which in turn sheds light on the difficulty of evaluating QG\nmodels. Finally, we analyse both the domain adaptability of these models as\nwell as the effectiveness of multilingual models in languages other than\nEnglish. QG-Bench is released along with the fine-tuned models presented in the\npaper https://github.com/asahi417/lm-question-generation, which are also\navailable as a demo https://autoqg.net/.",
    "descriptor": "\nComments: EMNLP 2022 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Fernando Alva-Manchego",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03992"
  },
  {
    "id": "arXiv:2210.03994",
    "title": "Relational Message Passing for Fully Inductive Knowledge Graph  Completion",
    "abstract": "In knowledge graph completion (KGC), predicting triples involving emerging\nentities and/or relations, which are unseen when the KG embeddings are learned,\nhas become a critical challenge. Subgraph reasoning with message passing is a\npromising and popular solution. Some recent methods have achieved good\nperformance, but they (i) usually can only predict triples involving unseen\nentities alone, failing to address more realistic fully inductive situations\nwith both unseen entities and unseen relations, and (ii) often conduct message\npassing over the entities with the relation patterns not fully utilized. In\nthis study, we propose a new method named RMPI which uses a novel Relational\nMessage Passing network for fully Inductive KGC. It passes messages directly\nbetween relations to make full use of the relation patterns for subgraph\nreasoning with new techniques on graph transformation, graph pruning,\nrelation-aware neighborhood attention, addressing empty subgraphs, etc., and\ncan utilize the relation semantics defined in the ontological schema of KG.\nExtensive evaluation on multiple benchmarks has shown the effectiveness of\ntechniques involved in RMPI and its better performance compared with the\nexisting methods that support fully inductive KGC. RMPI is also comparable to\nthe state-of-the-art partially inductive KGC methods with very promising\nresults achieved. Our codes and data are available at\nhttps://github.com/zjukg/RMPI.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Wen Zhang",
      "Jeff Z. Pan",
      "Mingyang Chen",
      "Huajun Chen",
      "Song Jiang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03994"
  },
  {
    "id": "arXiv:2210.03998",
    "title": "Towards the Detection of Malicious Java Packages",
    "abstract": "Open-source software supply chain attacks aim at infecting downstream users\nby poisoning open-source packages. The common way of consuming such artifacts\nis through package repositories and the development of vetting strategies to\ndetect such attacks is ongoing research. Despite its popularity, the Java\necosystem is the less explored one in the context of supply chain attacks.\nIn this paper we present indicators of malicious behavior that can be\nobserved statically through the analysis of Java bytecode. Then we evaluate how\nsuch indicators and their combinations perform when detecting malicious code\ninjections. We do so by injecting three malicious payloads taken from\nreal-world examples into the Top-10 most popular Java libraries from\nlibraries.io.\nWe found that the analysis of strings in the constant pool and of sensitive\nAPIs in the bytecode instructions aid in the task of detecting malicious Java\npackages by significantly reducing the information, thus, making also manual\ntriage possible.",
    "descriptor": "",
    "authors": [
      "Piergiorgio Ladisa",
      "Henrik Plate",
      "Matias Martinez",
      "Olivier Barais",
      "Serena Elisa Ponta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03998"
  },
  {
    "id": "arXiv:2210.03999",
    "title": "ngram-OAXE: Phrase-Based Order-Agnostic Cross Entropy for  Non-Autoregressive Machine Translation",
    "abstract": "Recently, a new training oaxe loss has proven effective to ameliorate the\neffect of multimodality for non-autoregressive translation (NAT), which removes\nthe penalty of word order errors in the standard cross-entropy loss. Starting\nfrom the intuition that reordering generally occurs between phrases, we extend\noaxe by only allowing reordering between ngram phrases and still requiring a\nstrict match of word order within the phrases. Extensive experiments on NAT\nbenchmarks across language pairs and data scales demonstrate the effectiveness\nand universality of our approach. %Further analyses show that the proposed\nngram-oaxe alleviates the multimodality problem with a better modeling of\nphrase translation. Further analyses show that ngram-oaxe indeed improves the\ntranslation of ngram phrases, and produces more fluent translation with a\nbetter modeling of sentence structure.",
    "descriptor": "\nComments: COLING 2022 Oral. arXiv admin note: text overlap with arXiv:2106.05093\n",
    "authors": [
      "Cunxiao Du",
      "Zhaopeng Tu",
      "Longyue Wang",
      "Jing Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03999"
  },
  {
    "id": "arXiv:2210.04001",
    "title": "Don't Waste Data: Transfer Learning to Leverage All Data for  Machine-Learnt Climate Model Emulation",
    "abstract": "How can we learn from all available data when training machine-learnt climate\nmodels, without incurring any extra cost at simulation time? Typically, the\ntraining data comprises coarse-grained high-resolution data. But only keeping\nthis coarse-grained data means the rest of the high-resolution data is thrown\nout. We use a transfer learning approach, which can be applied to a range of\nmachine learning models, to leverage all the high-resolution data. We use three\nchaotic systems to show it stabilises training, gives improved generalisation\nperformance and results in better forecasting skill. Our anonymised code is at\nhttps://www.dropbox.com/sh/0o1pks1i90mix3q/AAAMGfyD7EyOkdnA_Hp5ZpiWa?dl=0",
    "descriptor": "\nComments: 8 pages. Submitted to NeurIPS 2022 Workshop: Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Raghul Parthipan",
      "Damon J. Wischik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2210.04001"
  },
  {
    "id": "arXiv:2210.04002",
    "title": "Dynamically meeting performance objectives for multiple services on a  service mesh",
    "abstract": "We present a framework that lets a service provider achieve end-to-end\nmanagement objectives under varying load. Dynamic control actions are performed\nby a reinforcement learning (RL) agent. Our work includes experimentation and\nevaluation on a laboratory testbed where we have implemented basic information\nservices on a service mesh supported by the Istio and Kubernetes platforms. We\ninvestigate different management objectives that include end-to-end delay\nbounds on service requests, throughput objectives, and service differentiation.\nThese objectives are mapped onto reward functions that an RL agent learns to\noptimize, by executing control actions, namely, request routing and request\nblocking. We compute the control policies not on the testbed, but in a\nsimulator, which speeds up the learning process by orders of magnitude. In our\napproach, the system model is learned on the testbed; it is then used to\ninstantiate the simulator, which produces near-optimal control policies for\nvarious management objectives. The learned policies are then evaluated on the\ntestbed using unseen load patterns.",
    "descriptor": "\nComments: Accepted at the 18th International Conference on Network and Service Management\n",
    "authors": [
      "Forough Shahab Samani",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04002"
  },
  {
    "id": "arXiv:2210.04006",
    "title": "(Fusionformer):Exploiting the Joint Motion Synergy with Fusion Network  Based On Transformer for 3D Human Pose Estimation",
    "abstract": "For the current 3D human pose estimation task, in order to improve the\nefficiency of pose sequence output, we try to further improve the prediction\nstability in low input video frame scenarios.Many previous methods lack the\nunderstanding of local joint information.\\cite{9878888}considers the temporal\nrelationship of a single joint in this work.However, we found that there is a\ncertain predictive correlation between the trajectories of different joints in\ntime.Therefore, our proposed \\textbf{Fusionformer} method introduces a\nself-trajectory module and a cross-trajectory module based on the\nspatio-temporal module.After that, the global spatio-temporal features and\nlocal joint trajectory features are fused through a linear network in a\nparallel manner.To eliminate the influence of bad 2D poses on 3D projections,\nfinally we also introduce a pose refinement network to balance the consistency\nof 3D projections.In addition, we evaluate the proposed method on two benchmark\ndatasets (Human3.6M, MPI-INF-3DHP). Comparing our method with the baseline\nmethod poseformer, the results show an improvement of 2.4\\% MPJPE and 4.3\\%\nP-MPJPE on the Human3.6M dataset, respectively.",
    "descriptor": "",
    "authors": [
      "Xinwei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04006"
  },
  {
    "id": "arXiv:2210.04008",
    "title": "A Moving Window Based Approach to Multi-scan Multi-Target Tracking",
    "abstract": "Multi-target state estimation refers to estimating the number of targets and\ntheir trajectories in a surveillance area using measurements contaminated with\nnoise and clutter. In the Bayesian paradigm, the most common approach to\nmulti-target estimation is by recursively propagating the multi-target\nfiltering density, updating it with current measurements set at each timestep.\nIn comparison, multi-target smoothing uses all measurements up to current\ntimestep and recursively propagates the entire history of multi-target state\nusing the multi-target posterior density. The recent Generalized Labeled\nMulti-Bernoulli (GLMB) smoother is an analytic recursion that propagate the\nlabeled multi-object posterior by recursively updating labels to measurement\nassociation maps from the beginning to current timestep. In this paper, we\npropose a moving window based solution for multi-target tracking using the GLMB\nsmoother, so that only those association maps in a window (consisting of latest\nmaps) get updated, resulting in an efficient approximate solution suitable for\npractical implementations.",
    "descriptor": "",
    "authors": [
      "Diluka Moratuwage",
      "Changbeom Shim",
      "Yuthika Punchihewa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.04008"
  },
  {
    "id": "arXiv:2210.04012",
    "title": "A Field Trial Study of 5G Quality of Service: A Case of BTS Skytrain  Station",
    "abstract": "This article aims to present the results from a study of the quality of\nservice of 5G networks provided by two major 5G network providers, using a\nfield trial approach within 60 BTS SkyTrain stations. The results obtained from\nthe tests using 4 applications on a 5G mobile phone showed that the performance\nof 5G networks provided by both operators are different. When calculated for\nthe average values, it was found both operators had the download speed of 240.3\nMbps and the upload speed of 87.3 Mbps. Besides these values, it was also found\nthe average latency, the average jitter and the average loss from both major\noperators that are 19 ms, 8 ms and 0.299 % respectively. Comparing the average\nvalues derived from the results of this study with the results of another study\nin the Asia-Pacific region that was undertaken during the similar period of\ntime, it was found that the Bangkok download speed is ranked in the 4th place,\nwhereas the upload speed is ranked in the 1st place. However, it is noted that\nthis study only covered the area of BTS SkyTrain stations. In the future, the\nstudy should be extended to cover other parts of the Bangkok metropolitan area,\nand other provinces. In addition, the study should be conducted by a credible\norganization.",
    "descriptor": "\nComments: In Thai language\n",
    "authors": [
      "Therdpong Daengsi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.04012"
  },
  {
    "id": "arXiv:2210.04013",
    "title": "Constrained Optimal Querying: Huffman Coding and Beyond",
    "abstract": "Huffman coding is well known to be useful in certain decision problems\ninvolving minimizing the average number of (freely chosen) queries to determine\nan unknown random variable. However, in problems where the queries are more\nconstrained, the original Huffman coding no longer works. In this paper, we\nproposed a general model to describe such problems and two code schemes: one is\nHuffman-based, and the other called GBSC (Greedy Binary Separation Coding). We\nproved the optimality of GBSC by induction on a binary decision tree, telling\nus that GBSC is at least as good as Shannon coding. We then compared the two\nalgorithms based on these two codes, by testing them with two problems: DNA\ndetection and 1-player Battleship, and found both to be decent approximating\nalgorithms, with Huffman-based algorithm giving an expected length 1.1 times\nthe true optimal in DNA detection problem, and GBSC yielding an average number\nof queries 1.4 times the theoretical optimal in 1-player Battleship.",
    "descriptor": "",
    "authors": [
      "Shuyuan Zhang",
      "Jichen Sun",
      "Shengkang Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04013"
  },
  {
    "id": "arXiv:2210.04014",
    "title": "AdaptivePose++: A Powerful Single-Stage Network for Multi-Person Pose  Regression",
    "abstract": "Multi-person pose estimation generally follows top-down and bottom-up\nparadigms. Both of them use an extra stage ($\\boldsymbol{e.g.,}$ human\ndetection in top-down paradigm or grouping process in bottom-up paradigm) to\nbuild the relationship between the human instance and corresponding keypoints,\nthus leading to the high computation cost and redundant two-stage pipeline. To\naddress the above issue, we propose to represent the human parts as adaptive\npoints and introduce a fine-grained body representation method. The novel body\nrepresentation is able to sufficiently encode the diverse pose information and\neffectively model the relationship between the human instance and corresponding\nkeypoints in a single-forward pass. With the proposed body representation, we\nfurther deliver a compact single-stage multi-person pose regression network,\ntermed as AdaptivePose. During inference, our proposed network only needs a\nsingle-step decode operation to form the multi-person pose without complex\npost-processes and refinements. We employ AdaptivePose for both 2D/3D\nmulti-person pose estimation tasks to verify the effectiveness of AdaptivePose.\nWithout any bells and whistles, we achieve the most competitive performance on\nMS COCO and CrowdPose in terms of accuracy and speed. Furthermore, the\noutstanding performance on MuCo-3DHP and MuPoTS-3D further demonstrates the\neffectiveness and generalizability on 3D scenes. Code is available at\nhttps://github.com/buptxyb666/AdaptivePose.",
    "descriptor": "\nComments: Submit to IEEE TCSVT; 11 pages. arXiv admin note: text overlap with arXiv:2112.13635\n",
    "authors": [
      "Yabo Xiao",
      "Xiaojuan Wang",
      "Dongdong Yu",
      "Kai Su",
      "Lei Jin",
      "Mei Song",
      "Shuicheng Yan",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04014"
  },
  {
    "id": "arXiv:2210.04017",
    "title": "Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous  Driving via Semantic Masked World Model",
    "abstract": "End-to-end autonomous driving provides a feasible way to automatically\nmaximize overall driving system performance by directly mapping the raw pixels\nfrom a front-facing camera to control signals. Recent advanced methods\nconstruct a latent world model to map the high dimensional observations into\ncompact latent space. However, the latent states embedded by the world model\nproposed in previous works may contain a large amount of task-irrelevant\ninformation, resulting in low sampling efficiency and poor robustness to input\nperturbations. Meanwhile, the training data distribution is usually unbalanced,\nand the learned policy is hard to cope with the corner cases during the driving\nprocess. To solve the above challenges, we present a semantic masked recurrent\nworld model (SEM2), which introduces a latent filter to extract key\ntask-relevant features and reconstruct a semantic mask via the filtered\nfeatures, and is trained with a multi-source data sampler, which aggregates\ncommon data and multiple corner case data in a single batch, to balance the\ndata distribution. Extensive experiments on CARLA show that our method\noutperforms the state-of-the-art approaches in terms of sample efficiency and\nrobustness to input permutations.",
    "descriptor": "\nComments: 11 pages, 7 figures, 1 table, submitted to Deep RL Workshop 2022\n",
    "authors": [
      "Zeyu Gao",
      "Yao Mu",
      "Ruoyan Shen",
      "Chen Chen",
      "Yangang Ren",
      "Jianyu Chen",
      "Shengbo Eben Li",
      "Ping Luo",
      "Yanfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04017"
  },
  {
    "id": "arXiv:2210.04018",
    "title": "STaSy: Score-based Tabular data Synthesis",
    "abstract": "Tabular data synthesis is a long-standing research topic in machine learning.\nMany different methods have been proposed over the past decades, ranging from\nstatistical methods to deep generative methods. However, it has not always been\nsuccessful due to the complicated nature of real-world tabular data. In this\npaper, we present a new model named Score-based Tabular data Synthesis (STaSy)\nand its training strategy based on the paradigm of score-based generative\nmodeling. Despite the fact that score-based generative models have resolved\nmany issues in generative models, there still exists room for improvement in\ntabular data synthesis. Our proposed training strategy includes a self-paced\nlearning technique and a fine-tuning strategy, which further increases the\nsampling quality and diversity by stabilizing the denoising score matching\ntraining. Furthermore, we also conduct rigorous experimental studies in terms\nof the generative task trilemma: sampling quality, diversity, and time. In our\nexperiments with 15 benchmark tabular datasets and 7 baselines, our method\noutperforms existing methods in terms of task-dependant evaluations and\ndiversity.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Jayoung Kim",
      "Chaejeong Lee",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04018"
  },
  {
    "id": "arXiv:2210.04020",
    "title": "Fast-ParC: Position Aware Global Kernel for ConvNets and ViTs",
    "abstract": "Transformer models have made tremendous progress in various fields in recent\nyears. In the field of computer vision, vision transformers (ViTs) also become\nstrong alternatives to convolutional neural networks (ConvNets), yet they have\nnot been able to replace ConvNets since both have their own merits. For\ninstance, ViTs are good at extracting global features with attention mechanisms\nwhile ConvNets are more efficient in modeling local relationships due to their\nstrong inductive bias. A natural idea that arises is to combine the strengths\nof both ConvNets and ViTs to design new structures. In this paper, we propose a\nnew basic neural network operator named position-aware circular convolution\n(ParC) and its accelerated version Fast-ParC. The ParC operator can capture\nglobal features by using a global kernel and circular convolution while keeping\nlocation sensitiveness by employing position embeddings. Our Fast-ParC further\nreduces the O(n2) time complexity of ParC to O(n log n) using Fast Fourier\nTransform. This acceleration makes it possible to use global convolution in the\nearly stages of models with large feature maps, yet still maintains the overall\ncomputational cost comparable with using 3x3 or 7x7 kernels. The proposed\noperation can be used in a plug-and-play manner to 1) convert ViTs to\npure-ConvNet architecture to enjoy wider hardware support and achieve higher\ninference speed; 2) replacing traditional convolutions in the deep stage of\nConvNets to improve accuracy by enlarging the effective receptive field.\nExperiment results show that our ParC op can effectively enlarge the receptive\nfield of traditional ConvNets, and adopting the proposed op benefits both ViTs\nand ConvNet models on all three popular vision tasks, image classification,\nobject",
    "descriptor": "\nComments: 19 pages, 8 figures, 11 tables. A preliminary version of this paper has been published in ECCV 2022 and it can be find in arXiv:2203.03952\n",
    "authors": [
      "Tao Yang",
      "Haokui Zhang",
      "Wenze Hu",
      "Changwen Chen",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04020"
  },
  {
    "id": "arXiv:2210.04022",
    "title": "A Computational Study on the Site and Power Assignment Problem in  Wireless Networks",
    "abstract": "In this work, we address the wireless network design problem, i.e., the\nproblem of configuring a set of transmitters to provide service coverage to a\nset of receivers. It is well-known that natural formulations of this problem\nare sources of numerical instabilities and make the optimal resolution\nchallenging for state-of-the-art solvers, even in small-sized instances. We\ntackle this limitation from a computational perspective by suggesting two\nimplementation procedures capable of speeding the resolution of the instances\nof this problem. The first one consists of the employment of an extremely\neffective branching rule for a compact reformulation of this problem. The\nsecond one is the use of presolve operations to manage numerical instability.\nThe approaches are validated using LTE instances kindly provided by Fondazione\nUgo Bordoni. The proposed implementation techniques have proved capable of\nsignificantly accelerating the resolution of the problem, beating the\nperformance of a standard resolution.",
    "descriptor": "",
    "authors": [
      "Pasquale Avella",
      "Alice Calamita",
      "Laura Palagi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.04022"
  },
  {
    "id": "arXiv:2210.04023",
    "title": "Multi-Task Dynamical Systems",
    "abstract": "Time series datasets are often composed of a variety of sequences from the\nsame domain, but from different entities, such as individuals, products, or\norganizations. We are interested in how time series models can be specialized\nto individual sequences (capturing the specific characteristics) while still\nretaining statistical power by sharing commonalities across the sequences. This\npaper describes the multi-task dynamical system (MTDS); a general methodology\nfor extending multi-task learning (MTL) to time series models. Our approach\nendows dynamical systems with a set of hierarchical latent variables which can\nmodulate all model parameters. To our knowledge, this is a novel development of\nMTL, and applies to time series both with and without control inputs. We apply\nthe MTDS to motion-capture data of people walking in various styles using a\nmulti-task recurrent neural network (RNN), and to patient drug-response data\nusing a multi-task pharmacodynamic model.",
    "descriptor": "\nComments: 52 pages, 17 figures\n",
    "authors": [
      "Alex Bird",
      "Christopher K. I. Williams",
      "Christopher Hawthorne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04023"
  },
  {
    "id": "arXiv:2210.04024",
    "title": "Demand Layering for Real-Time DNN Inference with Minimized Memory Usage",
    "abstract": "When executing a deep neural network (DNN), its model parameters are loaded\ninto GPU memory before execution, incurring a significant GPU memory burden.\nThere are studies that reduce GPU memory usage by exploiting CPU memory as a\nswap device. However, this approach is not applicable in most embedded systems\nwith integrated GPUs where CPU and GPU share a common memory. In this regard,\nwe present Demand Layering, which employs a fast solid-state drive (SSD) as a\nco-running partner of a GPU and exploits the layer-by-layer execution of DNNs.\nIn our approach, a DNN is loaded and executed in a layer-by-layer manner,\nminimizing the memory usage to the order of a single layer. Also, we developed\na pipeline architecture that hides most additional delays caused by the\ninterleaved parameter loadings alongside layer executions. Our implementation\nshows a 96.5% memory reduction with just 14.8% delay overhead on average for\nrepresentative DNNs. Furthermore, by exploiting the memory-delay tradeoff,\nnear-zero delay overhead (under 1 ms) can be achieved with a slightly increased\nmemory usage (still an 88.4% reduction), showing the great potential of Demand\nLayering.",
    "descriptor": "\nComments: 14 pages, 16 figures. Accepted to the 43rd IEEE Real-Time Systems Symposium (RTSS), 2022\n",
    "authors": [
      "Mingoo Ji",
      "Saehanseul Yi",
      "Changjin Koo",
      "Sol Ahn",
      "Dongjoo Seo",
      "Nikil Dutt",
      "Jong-Chan Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04024"
  },
  {
    "id": "arXiv:2210.04026",
    "title": "Enhancing Generalizable 6D Pose Tracking of an In-Hand Object with  Tactile Sensing",
    "abstract": "While holding and manipulating an object, humans track the object states\nthrough vision and touch so as to achieve complex tasks. However, nowadays the\nmajority of robot research perceives object states just from visual signals,\nhugely limiting the robotic manipulation abilities. This work presents a\ntactile-enhanced generalizable 6D pose tracking design named TEG-Track to track\npreviously unseen in-hand objects. TEG-Track extracts tactile kinematic cues of\nan in-hand object from consecutive tactile sensing signals. Such cues are\nincorporated into a geometric-kinematic optimization scheme to enhance existing\ngeneralizable visual trackers. To test our method in real scenarios and enable\nfuture studies on generalizable visual-tactile tracking, we collect a real\nvisual-tactile in-hand object pose tracking dataset. Experiments show that\nTEG-Track significantly improves state-of-the-art generalizable 6D pose\ntrackers in both synthetic and real cases.",
    "descriptor": "",
    "authors": [
      "Xiaomeng Xu",
      "Yun Liu",
      "Weihang Chen",
      "Haocheng Yuan",
      "He Wang",
      "Jing Xu",
      "Rui Chen",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04026"
  },
  {
    "id": "arXiv:2210.04029",
    "title": "EDU-level Extractive Summarization with Varying Summary Lengths",
    "abstract": "Extractive models usually formulate text summarization as extracting top-k\nimportant sentences from document as summary. Few work exploited extracting\nfiner-grained Elementary Discourse Unit (EDU) and there is little analysis and\njustification for the extractive unit selection. To fill such a gap, this paper\nfirstly conducts oracle analysis to compare the upper bound of performance for\nmodels based on EDUs and sentences. The analysis provides evidences from both\ntheoretical and experimental perspectives to justify that EDUs make more\nconcise and precise summary than sentences without losing salient information.\nThen, considering this merit of EDUs, this paper further proposes EDU-level\nextractive model with Varying summary Lengths (EDU-VL) and develops the\ncorresponding learning algorithm. EDU-VL learns to encode and predict\nprobabilities of EDUs in document, and encode EDU-level candidate summaries\nwith different lengths based on various $k$ values and select the best\ncandidate summary in an end-to-end training manner. Finally, the proposed and\ndeveloped approach is experimented on single and multi-document benchmark\ndatasets and shows the improved performances in comparison with the\nstate-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Yuping Wu",
      "Ching-Hsun Tseng",
      "Jiayu Shang",
      "Shengzhong Mao",
      "Goran Nenadic",
      "Xiao-Jun Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04029"
  },
  {
    "id": "arXiv:2210.04030",
    "title": "Dedicating Cellular Infrastructure for Aerial Users: Advantages and  Potential Impact on Ground Users",
    "abstract": "A new generation of aerial vehicles is hopeful to be the next frontier for\nthe transportation of people and goods, becoming even as important as ground\nusers in the communication systems. To enhance the coverage of aerial users,\nappropriate adjustments should be made to the existing cellular networks that\nmainly provide services for ground users by the down-tilted antennas of the\nterrestrial base stations (BSs). It is promising to up-tilt the antennas of a\nsubset of BSs for serving aerial users through the mainlobe. With this\nmotivation, in this work, we use tools from stochastic geometry to analyze the\ncoverage performance of the adjusted cellular network (consisting of the\nup-tilted BSs and the down-tilted BSs). Correspondingly, we present exact and\napproximate expressions of the signal-to-interference ratio (SIR)-based\ncoverage probabilities for users in the sky and on the ground, respectively.\nNumerical results verify the analysis accuracy and clarify the advantages of\nup-tilting BS antennas on the communication connectivity of aerial users\nwithout the potential adverse impact on the quality of service (QoS) of ground\nusers.",
    "descriptor": "",
    "authors": [
      "Lin Chen",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04030"
  },
  {
    "id": "arXiv:2210.04040",
    "title": "Reliability of fault-tolerant system architectures for automated driving  systems",
    "abstract": "Automated driving functions at high levels of autonomy operate without driver\nsupervision. The system itself must provide suitable responses in case of\nhardware element failures. This requires fault-tolerant approaches using domain\nECUs and multicore processors operating in lockstep mode. The selection of a\nsuitable architecture for fault-tolerant vehicle systems is currently\nchallenging. Lockstep CPUs enable the implementation of majority redundancy or\nM-out-of-N ($M$oo$N$) architectures. In addition to structural redundancy,\ndiversity redundancy in the ECU architecture is also relevant to fault\ntolerance. Two fault-tolerant ECU architecture groups exist: architectures with\none ECU (system on a chip) and architectures consisting of multiple\ncommunicating ECUs. The single-ECU systems achieve higher reliability, whereas\nthe multi-ECU systems are more robust against dependent failures, such as\ncommon-cause or cascading failures, due to their increased potential for\ndiversity redundancy. Yet, it remains not fully understood how different types\nof architectures influence the system reliability. The work aims to design\narchitectures with respect to CPU and sensor number, $M$oo$N$ expression, and\nhardware element reliability. The results enable a direct comparison of\ndifferent architecture types. We calculate their reliability and quantify the\neffort to achieve high safety requirements. Markov processes allow comparing\nsensor and CPU architectures by varying the number of components and failure\nrates. The objective is to evaluate systems' survival probability and fault\ntolerance and design suitable sensor-CPU architectures. The results show that\nthe system architecture strongly influences the reliability. However, a\nsuitable system architecture must have a trade-off between reliability and\nself-diagnostics that parallel systems without majority redundancies do not\nprovide.",
    "descriptor": "\nComments: 12 pages, 4 figures, ESREL2022 Conference\n",
    "authors": [
      "Tim Maurice Julitz",
      "Antoine Tordeux",
      "Manuel L\u00f6wer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.04040"
  },
  {
    "id": "arXiv:2210.04041",
    "title": "Almost-lossless compression of a low-rank random tensor",
    "abstract": "In this work, we establish an asymptotic limit of almost-lossless compression\nof a random, finite alphabet tensor which admits a low-rank canonical polyadic\ndecomposition.",
    "descriptor": "",
    "authors": [
      "Minh Thanh Vu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04041"
  },
  {
    "id": "arXiv:2210.04045",
    "title": "The FBHHRBNRSSSHK-Algorithm for Multiplication in  $\\mathbb{Z}_2^{5\\times5}$ is still not the end of the story 2",
    "abstract": "In response to a recent Nature article which announced an algorithm for\nmultiplying $5\\times5$-matrices over $\\mathbb{Z}_2$ with only 96\nmultiplications, two fewer than the previous record, we present an algorithm\nthat does the job with only 95 multiplications.",
    "descriptor": "",
    "authors": [
      "Manuel Kauers",
      "Jakob Moosbauer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.04045"
  },
  {
    "id": "arXiv:2210.04047",
    "title": "Motion Planning on Visual Manifolds",
    "abstract": "In this thesis, we propose an alternative characterization of the notion of\nConfiguration Space, which we call Visual Configuration Space (VCS). This new\ncharacterization allows an embodied agent (e.g., a robot) to discover its own\nbody structure and plan obstacle-free motions in its peripersonal space using a\nset of its own images in random poses. Here, we do not assume any knowledge of\ngeometry of the agent, obstacles or the environment. We demonstrate the\nusefulness of VCS in (a) building and working with geometry-free models for\nrobot motion planning, (b) explaining how a human baby might learn to reach\nobjects in its peripersonal space through motor babbling, and (c) automatically\ngenerating natural looking head motion animations for digital avatars in\nvirtual environments. This work is based on the formalism of manifolds and\nmanifold learning using the agent's images and hence we call it Motion Planning\non Visual Manifolds.",
    "descriptor": "\nComments: A PhD thesis submitted to and accepted by the Department of Computer Science & Engineering at the Indian Institute of Technology Kanpur\n",
    "authors": [
      "M Seetha Ramaiah"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.04047"
  },
  {
    "id": "arXiv:2210.04048",
    "title": "Formation Flight in Dense Environments",
    "abstract": "Formation flight has a vast potential for aerial robot swarms in various\napplications. However, existing methods lack the capability to achieve fully\nautonomous large-scale formation flight in dense environments. To bridge the\ngap, we present a complete formation flight system that effectively integrates\nreal-world constraints into aerial formation navigation. This paper proposes a\ndifferentiable graph-based metric to quantify the overall similarity error\nbetween formations. This metric is invariant to rotation, translation, and\nscaling, providing more freedom for formation coordination. We design a\ndistributed trajectory optimization framework that considers formation\nsimilarity, obstacle avoidance, and dynamic feasibility. The optimization is\ndecoupled to make large-scale formation flights computationally feasible. To\nimprove the elasticity of formation navigation in highly constrained scenes, we\npresent a swarm reorganization method which adaptively adjusts the formation\nparameters and task assignments by generating local navigation goals. A novel\nswarm agreement strategy called global-remap-local-replan and a formation-level\npath planner is proposed in this work to coordinate the swarm global planning\nand local trajectory optimizations efficiently. To validate the proposed\nmethod, we design comprehensive benchmarks and simulations with other\ncutting-edge works in terms of adaptability, predictability, elasticity,\nresilience, and efficiency. Finally, integrated with palm-sized swarm platforms\nwith onboard computers and sensors, the proposed method demonstrates its\nefficiency and robustness by achieving the largest scale formation flight in\ndense outdoor environments.",
    "descriptor": "\nComments: Submitted for IEEE Transactions on Robotics\n",
    "authors": [
      "Lun Quan",
      "Longji Yin",
      "Tingrui Zhang",
      "Mingyang Wang",
      "Ruilin Wang",
      "Sheng Zhong",
      "Yanjun Cao",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04048"
  },
  {
    "id": "arXiv:2210.04050",
    "title": "Multi-Modal Human Authentication Using Silhouettes, Gait and RGB",
    "abstract": "Whole-body-based human authentication is a promising approach for remote\nbiometrics scenarios. Current literature focuses on either body recognition\nbased on RGB images or gait recognition based on body shapes and walking\npatterns; both have their advantages and drawbacks. In this work, we propose\nDual-Modal Ensemble (DME), which combines both RGB and silhouette data to\nachieve more robust performances for indoor and outdoor whole-body based\nrecognition. Within DME, we propose GaitPattern, which is inspired by the\ndouble helical gait pattern used in traditional gait analysis. The GaitPattern\ncontributes to robust identification performance over a large range of viewing\nangles. Extensive experimental results on the CASIA-B dataset demonstrate that\nthe proposed method outperforms state-of-the-art recognition systems. We also\nprovide experimental results using the newly collected BRIAR dataset.",
    "descriptor": "",
    "authors": [
      "Yuxiang Guo",
      "Cheng Peng",
      "Chun Pong Lau",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04050"
  },
  {
    "id": "arXiv:2210.04051",
    "title": "Towards Joint Electricity and Data Trading: A Scalable Cooperative Game  Theoretic Approach",
    "abstract": "This paper, for the first time, proposes a joint electricity and data trading\nmechanism based on cooperative game theory. All prosumers first submit the\nparameters associated with both electricity and data to the market operator.\nThe operator utilizes the public and prosumers' private data to forecast the\ndistributed renewable generators (DRGs) and quantify the improvement driven by\nprosumers' private data in terms of reduced uncertainty set. Then, the operator\nmaximizes the grand coalition's total payoff considering the uncertain\ngeneration of DRGs and imputes the payoff to each prosumer based on their\ncontribution to electricity and data sharing. The mathematical formulation of\nthe grand coalition is developed and converted into a second order cone\nprogramming problem by using an affinepolicy based robust approach. The\nstability of such a grand coalition is mathematically proved, i.e., all\nprosumers are willing to cooperate. Furthermore, to address the scalability\nchallenge of existing payoff imputation methods in the cooperative game, a two\nstage optimization based approach is proposed, which is converted into a mixed\ninteger second order cone programming and solved by the Benders decomposition.\nCase studies illustrate all prosumers are motivated to trade electricity and\ndata under the joint trading framework and the proposed imputation method\nsignificantly enhances the scalability.",
    "descriptor": "",
    "authors": [
      "Mingyu Yan",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04051"
  },
  {
    "id": "arXiv:2210.04052",
    "title": "FedDef: Robust Federated Learning-based Network Intrusion Detection  Systems Against Gradient Leakage",
    "abstract": "Deep learning methods have been widely applied to anomaly-based network\nintrusion detection systems (NIDS) to detect malicious traffic. To expand the\nusage scenarios of DL-based methods, the federated learning (FL) framework\nallows intelligent techniques to jointly train a model by multiple individuals\non the basis of respecting individual data privacy. However, it has not yet\nbeen systematically evaluated how robust FL-based NIDSs are against existing\nprivacy attacks under existing defenses. To address this issue, in this paper\nwe propose two privacy evaluation metrics designed for FL-based NIDSs,\nincluding leveraging two reconstruction attacks to recover the training data to\nobtain the privacy score for traffic features, followed by Generative\nAdversarial Network (GAN) based attack that generates adversarial examples with\nthe reconstructed benign traffic to evaluate evasion rate against other NIDSs.\nWe conduct experiments to show that existing defenses provide little protection\nthat the corresponding adversarial traffic can even evade the SOTA NIDS\nKitsune. To build a more robust FL-based NIDS, we further propose a novel\noptimization-based input perturbation defense strategy with theoretical\nguarantee that achieves both high utility by minimizing the gradient distance\nand strong privacy protection by maximizing the input distance. We\nexperimentally evaluate four existing defenses on four datasets and show that\nour defense outperforms all the baselines with strong privacy guarantee while\nmaintaining model accuracy loss within 3% under optimal parameter combination.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Jiahui Chen",
      "Yi Zhao",
      "Qi Li",
      "Ke Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04052"
  },
  {
    "id": "arXiv:2210.04055",
    "title": "AI and ML Accelerator Survey and Trends",
    "abstract": "This paper updates the survey of AI accelerators and processors from past\nthree years. This paper collects and summarizes the current commercial\naccelerators that have been publicly announced with peak performance and power\nconsumption numbers. The performance and power values are plotted on a scatter\ngraph, and a number of dimensions and observations from the trends on this plot\nare again discussed and analyzed. Two new trends plots based on accelerator\nrelease dates are included in this year's paper, along with the additional\ntrends of some neuromorphic, photonic, and memristor-based inference\naccelerators.",
    "descriptor": "\nComments: 10 pages, 4 figures, 2022 IEEE High Performance Extreme Computing (HPEC) Conference. arXiv admin note: substantial text overlap with arXiv:2009.00993, arXiv:2109.08957\n",
    "authors": [
      "Albert Reuther",
      "Peter Michaleas",
      "Michael Jones",
      "Vijay Gadepally",
      "Siddharth Samsi",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.04055"
  },
  {
    "id": "arXiv:2210.04059",
    "title": "Order Selection Problems in Hiring Pipelines",
    "abstract": "Motivated by hiring pipelines, we study two order selection problems in which\napplicants for a finite set of positions must be interviewed or made offers\nsequentially. There is a finite time budget for interviewing or making offers,\nand a stochastic realization after each decision, leading to\ncomputationally-challenging problems. In the first problem we study sequential\ninterviewing, and show that a computationally-tractable, non-adaptive policy\nthat must make offers immediately after interviewing is approximately optimal,\nassuming offerees always accept their offers. In the second problem, we assume\nthat applicants have already been interviewed but only accept offers with some\nprobability; we develop a computationally-tractable policy that makes offers\nfor the different positions in parallel, which is approximately optimal even\nrelative to a policy that does not need to make parallel offers. Our two\nresults both generalize and improve the guarantees in the work of Purohit et\nal. on hiring algorithms, from 1/2 and 1/4 to approximation factors that are at\nleast 1-1/e.",
    "descriptor": "",
    "authors": [
      "Boris Epstein",
      "Will Ma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.04059"
  },
  {
    "id": "arXiv:2210.04061",
    "title": "A General Security Approach for Soft-information Decoding against Smart  Bursty Jammers",
    "abstract": "Malicious attacks such as jamming can cause significant disruption or\ncomplete denial of service (DoS) to wireless communication protocols. Moreover,\njamming devices are getting smarter, making them difficult to detect. Forward\nerror correction, which adds redundancy to data, is commonly deployed to\nprotect communications against the deleterious effects of channel noise.\nSoft-information error correction decoders obtain reliability information from\nthe receiver to inform their decoding, but in the presence of a jammer such\ninformation is misleading and results in degraded error correction performance.\nAs decoders assume noise occurs independently to each bit, a bursty jammer will\nlead to greater degradation in performance than a non-bursty one. Here we\nestablish, however, that such temporal dependencies can aid inferences on which\nbits have been subjected to jamming, thus enabling counter-measures. In\nparticular, we introduce a pre-decoding processing step that updates\nlog-likelihood ratio (LLR) reliability information to reflect inferences in the\npresence of a jammer, enabling improved decoding performance for any soft\ndetection decoder. The proposed method requires no alteration to the decoding\nalgorithm. Simulation results show that the method correctly infers a\nsignificant proportion of jamming in any received frame. Results with one\nparticular decoding algorithm, the recently introduced ORBGRAND, show that the\nproposed method reduces the block-error rate (BLER) by an order of magnitude\nfor a selection of codes, and prevents complete DoS at the receiver.",
    "descriptor": "\nComments: Accepted for GLOBECOM 2022 Workshops. Contains 7 pages and 7 figures\n",
    "authors": [
      "Furkan Ercan",
      "Kevin Galligan",
      "Ken R. Duffy",
      "Muriel Medard",
      "David Starobinski",
      "Rabia Tugce Yazicigil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04061"
  },
  {
    "id": "arXiv:2210.04062",
    "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code  Representation Learning",
    "abstract": "Speech is the surface form of a finite set of phonetic units, which can be\nrepresented by discrete codes. We propose the Code BERT (CoBERT) approach for\nself-supervised speech representation learning. The idea is to convert an\nutterance to a sequence of discrete codes, and perform code representation\nlearning, where we predict the code representations based on a masked view of\nthe original speech input. Unlike the prior self-distillation approaches of\nwhich the teacher and the student are of the same modality, our target model\npredicts representations from a different modality. CoBERT outperforms the most\nrecent state-of-the-art performance on the ASR task and brings significant\nimprovements on the SUPERB speech translation (ST) task.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chutong Meng",
      "Junyi Ao",
      "Tom Ko",
      "Mingxuan Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.04062"
  },
  {
    "id": "arXiv:2210.04064",
    "title": "Study and security analysis of the Spanish identity card",
    "abstract": "The National Identity Document is a fundamental piece of documentation for\nthe identification of citizens throughout the world. That is precisely the case\nof the DNI (Documento Nacional de Identidad) of Spain. Its importance has been\nenhanced in recent years with the addition of a chip for the authentication of\nusers within telematic administrative services. Thus, the document has since\nbeen called: electronic DNI or simply DNIe. Sensitive user information is\nstored in that integrated circuit, such as personal and biometric data, along\nwith signature and authentication certificates. Some of the functionalities of\nthe DNIe in its current version at the time of writing this work have been\nimplemented for years in the DNI 3.0 version launched in 2015, and therefore\nhave already been extensively studied. This work provides a theoretical and\npractical compilation study of some of the security mechanisms included in the\ncurrent DNIe and in some of the applications that require its use. It has been\ncarried out using only mobile devices and generic card readers, without having\nany type of privileged access to hardware, software or specific documentation\nfor the interception of packets between the DNIe and the destination\napplication. In other words, it is an exploratory analysis carried out with the\nintention of confirming with basic tools the level of robustness of this very\nimportant security token.",
    "descriptor": "",
    "authors": [
      "Javier Correa-Marichal",
      "Pino Caballero-Gil",
      "Carlos Rosa-Remedios",
      "Rames Sarwat-Shaker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04064"
  },
  {
    "id": "arXiv:2210.04066",
    "title": "Drowsiness detection in drivers with a smartwatch",
    "abstract": "The main objective of this work is to detect early if a driver shows symptoms\nof sleepiness that indicate that he/she is falling asleep and, in that case,\ngenerate an alert to wake him/her up. To solve this problem, an application has\nbeen designed that collects various parameters, through a smartwatch while\ndriving. First, the application detects the driving action. Then, it collects\ninformation about the most significant physiological variables of a person\nwhile driving. On the other hand, given the high level of sensitivity of the\ndata managed in the designed application, in this work special attention has\nbeen paid to the security of the implementation. The proposed solution improves\nroad safety, reducing the number of accidents caused by drowsiness while\ndriving.",
    "descriptor": "",
    "authors": [
      "Sonia D\u00edaz-Santos",
      "Pino Caballero-Gil"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04066"
  },
  {
    "id": "arXiv:2210.04067",
    "title": "VP-STO: Via-point-based Stochastic Trajectory Optimization for Reactive  Robot Behavior",
    "abstract": "Achieving reactive robot behavior in complex dynamic environments is still\nchallenging as it relies on being able to solve trajectory optimization\nproblems quickly enough, such that we can replan the future motion at\nfrequencies which are sufficiently high for the task at hand. We argue that\ncurrent limitations in Model Predictive Control (MPC) for robot manipulators\narise from inefficient, high-dimensional trajectory representations and the\nnegligence of time-optimality in the trajectory optimization process.\nTherefore, we propose a motion optimization framework that optimizes jointly\nover space and time, generating smooth and timing-optimal robot trajectories in\njoint-space. While being task-agnostic, our formulation can incorporate\nadditional task-specific requirements, such as collision avoidance, and yet\nmaintain real-time control rates, demonstrated in simulation and real-world\nrobot experiments on closed-loop manipulation.",
    "descriptor": "\nComments: *Authors contributed equally\n",
    "authors": [
      "Julius Jankowski",
      "Lara Bruderm\u00fcller",
      "Nick Hawes",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04067"
  },
  {
    "id": "arXiv:2210.04068",
    "title": "IcebergHT: High Performance PMEM Hash Tables Through Stability and Low  Associativity",
    "abstract": "Modern hash table designs strive to minimize space while maximizing speed.\nThe most important factor in speed is the number of cache lines accessed during\nupdates and queries. This is especially important on PMEM, which is slower than\nDRAM and in which writes are more expensive than reads. This paper proposes two\nstronger design objectives: stability and low-associativity. A stable hash\ntable doesn't move items around, and a hash table has low associativity if\nthere are only a few locations where an item can be stored. Low associativity\nensures that queries need to examine only a few memory locations, and stability\nensures that insertions write to very few cache lines. Stability also\nsimplifies scaling and crash safety.\nWe present IcebergHT, a fast, crash-safe, concurrent, and space-efficient\nhash table for PMEM based on the design principles of stability and low\nassociativity. IcebergHT combines in-memory metadata with a new hashing\ntechnique, iceberg hashing, that is (1) space efficient, (2) stable, and (3)\nsupports low associativity. In contrast, existing hash-tables either modify\nnumerous cache lines during insertions (e.g. cuckoo hashing), access numerous\ncache lines during queries (e.g. linear probing), or waste space (e.g.\nchaining). Moreover, the combination of (1)-(3) yields several emergent\nbenefits: IcebergHT scales better than other hash tables, supports\ncrash-safety, and has excellent performance on PMEM (where writes are\nparticularly expensive).",
    "descriptor": "",
    "authors": [
      "Prashant Pandey",
      "Michael A. Bender",
      "Alex Conway",
      "Mart\u00edn Farach-Colton",
      "William Kuszmaul",
      "Guido Tagliavini",
      "Rob Johnson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.04068"
  },
  {
    "id": "arXiv:2210.04072",
    "title": "Flow-based GAN for 3D Point Cloud Generation from a Single Image",
    "abstract": "Generating a 3D point cloud from a single 2D image is of great importance for\n3D scene understanding applications. To reconstruct the whole 3D shape of the\nobject shown in the image, the existing deep learning based approaches use\neither explicit or implicit generative modeling of point clouds, which,\nhowever, suffer from limited quality. In this work, we aim to alleviate this\nissue by introducing a hybrid explicit-implicit generative modeling scheme,\nwhich inherits the flow-based explicit generative models for sampling point\nclouds with arbitrary resolutions while improving the detailed 3D structures of\npoint clouds by leveraging the implicit generative adversarial networks (GANs).\nWe evaluate on the large-scale synthetic dataset ShapeNet, with the\nexperimental results demonstrating the superior performance of the proposed\nmethod. In addition, the generalization ability of our method is demonstrated\nby performing on cross-category synthetic images as well as by testing on real\nimages from PASCAL3D+ dataset.",
    "descriptor": "\nComments: 13 pages, 5 figures, accepted to BMVC2022\n",
    "authors": [
      "Yao Wei",
      "George Vosselman",
      "Michael Ying Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04072"
  },
  {
    "id": "arXiv:2210.04073",
    "title": "On Task-Adaptive Pretraining for Dialogue Response Selection",
    "abstract": "Recent advancements in dialogue response selection (DRS) are based on the\n\\textit{task-adaptive pre-training (TAP)} approach, by first initializing their\nmodel with BERT~\\cite{devlin-etal-2019-bert}, and adapt to dialogue data with\ndialogue-specific or fine-grained pre-training tasks. However, it is uncertain\nwhether BERT is the best initialization choice, or whether the proposed\ndialogue-specific fine-grained learning tasks are actually better than MLM+NSP.\nThis paper aims to verify assumptions made in previous works and understand the\nsource of improvements for DRS. We show that initializing with RoBERTa achieve\nsimilar performance as BERT, and MLM+NSP can outperform all previously proposed\nTAP tasks, during which we also contribute a new state-of-the-art on the Ubuntu\ncorpus. Additional analyses shows that the main source of improvements comes\nfrom the TAP step, and that the NSP task is crucial to DRS, different from\ncommon NLU tasks.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Tzu-Hsiang Lin",
      "Ta-Chung Chi",
      "Anna Rumshisky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04073"
  },
  {
    "id": "arXiv:2210.04074",
    "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection of  Events",
    "abstract": "Natural language often describes events in different granularities, such that\nmore coarse-grained (goal) events can often be decomposed into fine-grained\nsequences of (step) events. A critical but overlooked challenge in\nunderstanding an event process lies in the fact that the step events are not\nequally important to the central goal. In this paper, we seek to fill this gap\nby studying how well current models can understand the essentiality of\ndifferent step events towards a goal event. As discussed by cognitive studies,\nsuch an ability enables the machine to mimic human's commonsense reasoning\nabout preconditions and necessary efforts of daily-life tasks. Our work\ncontributes with a high-quality corpus of (goal, step) pairs from a community\nguideline website WikiHow, where the steps are manually annotated with their\nessentiality w.r.t. the goal. The high IAA indicates that humans have a\nconsistent understanding of the events. Despite evaluating various statistical\nand massive pre-trained NLU models, we observe that existing SOTA models all\nperform drastically behind humans, indicating the need for future investigation\nof this crucial yet challenging task.",
    "descriptor": "",
    "authors": [
      "Hongming Zhang",
      "Yueguan Wang",
      "Yuqian Deng",
      "Haoyu Wang",
      "Muhao Chen",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04074"
  },
  {
    "id": "arXiv:2210.04076",
    "title": "Robustness of Unsupervised Representation Learning without Labels",
    "abstract": "Unsupervised representation learning leverages large unlabeled datasets and\nis competitive with supervised learning. But non-robust encoders may affect\ndownstream task robustness. Recently, robust representation encoders have\nbecome of interest. Still, all prior work evaluates robustness using a\ndownstream classification task. Instead, we propose a family of unsupervised\nrobustness measures, which are model- and task-agnostic and label-free. We\nbenchmark state-of-the-art representation encoders and show that none dominates\nthe rest. We offer unsupervised extensions to the FGSM and PGD attacks. When\nused in adversarial training, they improve most unsupervised robustness\nmeasures, including certified robustness. We validate our results against a\nlinear probe and show that, for MOCOv2, adversarial training results in 3 times\nhigher certified accuracy, a 2-fold decrease in impersonation attack success\nrate and considerable improvements in certified robustness.",
    "descriptor": "",
    "authors": [
      "Aleksandar Petrov",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04076"
  },
  {
    "id": "arXiv:2210.04080",
    "title": "Delivery to Safety with Two Cooperating Robots",
    "abstract": "Two cooperating, autonomous mobile robots with arbitrary nonzero max speeds\nare placed at arbitrary initial positions in the plane. A remotely detonated\nbomb is discovered at some source location and must be moved to a safe distance\naway from its initial location as quickly as possible. In the Bomb Squad\nproblem, the robots cooperate by communicating face-to-face in order to pick up\nthe bomb from the source and carry it away to the boundary of a disk centered\nat the source in the shortest possible time. The goal is to specify\ntrajectories which define the robots' paths from start to finish and their\nmeeting points which enable face-to-face collaboration by exchanging\ninformation and passing the bomb from robot to robot.\nWe design algorithms reflecting the robots' knowledge about orientation and\neach other's speed and location. In the offline case, we design an optimal\nalgorithm. For the limited knowledge cases, we provide online algorithms which\nconsider robots' level of agreement on orientation as per OneAxis and NoAxis\nmodels, and knowledge of the boundary as per Visible, Discoverable, and\nInvisible. In all cases, we provide upper and lower bounds for the competitive\nratios of the online problems.",
    "descriptor": "",
    "authors": [
      "Jared Coleman",
      "Evangelos Kranakis",
      "Danny Krizanc",
      "Oscar Morales Ponce"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04080"
  },
  {
    "id": "arXiv:2210.04081",
    "title": "SlenderGNN: Accurate, Robust, and Interpretable GNN, and the Reasons for  its Success",
    "abstract": "Can we design a GNN that is accurate and interpretable at the same time?\nCould it also be robust to handle the case of homophily, heterophily, or even\nnoisy edges without network effects? We propose SlenderGNN that has all\ndesirable properties: (a) accurate, (b) robust, and (c) interpretable. For the\nreasons of its success, we had to dig deeper: The result is our GNNLin\nframework which highlights the fundamental differences among popular GNN models\n(e.g., feature combination, structural normalization, etc.) and thus reveals\nthe reasons for the success of our SlenderGNN, as well as the reasons for\noccasional failures of other GNN variants. Thanks to our careful design,\nSlenderGNN passes all the 'sanity checks' we propose, and it achieves the\nhighest overall accuracy on 9 real-world datasets of both homophily and\nheterophily graphs, when compared against 10 recent GNN models. Specifically,\nSlenderGNN exceeds the accuracy of linear GNNs and matches or exceeds the\naccuracy of nonlinear models with up to 64 times fewer parameters.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Jaemin Yoo",
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04081"
  },
  {
    "id": "arXiv:2210.04083",
    "title": "Unified Probabilistic Neural Architecture and Weight Ensembling Improves  Model Robustness",
    "abstract": "Robust machine learning models with accurately calibrated uncertainties are\ncrucial for safety-critical applications. Probabilistic machine learning and\nespecially the Bayesian formalism provide a systematic framework to incorporate\nrobustness through the distributional estimates and reason about uncertainty.\nRecent works have shown that approximate inference approaches that take the\nweight space uncertainty of neural networks to generate ensemble prediction are\nthe state-of-the-art. However, architecture choices have mostly been ad hoc,\nwhich essentially ignores the epistemic uncertainty from the architecture\nspace. To this end, we propose a Unified probabilistic architecture and weight\nensembling Neural Architecture Search (UraeNAS) that leverages advances in\nprobabilistic neural architecture search and approximate Bayesian inference to\ngenerate ensembles form the joint distribution of neural network architectures\nand weights. The proposed approach showed a significant improvement both with\nin-distribution (0.86% in accuracy, 42% in ECE) CIFAR-10 and\nout-of-distribution (2.43% in accuracy, 30% in ECE) CIFAR-10-C compared to the\nbaseline deterministic approach.",
    "descriptor": "",
    "authors": [
      "Sumegha Premchandar",
      "Sandeep Madireddy",
      "Sanket Jantre",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04083"
  },
  {
    "id": "arXiv:2210.04084",
    "title": "SpyHammer: Using RowHammer to Remotely Spy on Temperature",
    "abstract": "RowHammer is a DRAM vulnerability that can cause bit errors in a victim DRAM\nrow by just accessing its neighboring DRAM rows at a high-enough rate. Recent\nstudies demonstrate that new DRAM devices are becoming increasingly more\nvulnerable to RowHammer, and many works demonstrate system-level attacks for\nprivilege escalation or information leakage. In this work, we leverage two key\nobservations about RowHammer characteristics to spy on DRAM temperature: 1)\nRowHammer-induced bit error rate consistently increases (or decreases) as the\ntemperature increases, and 2) some DRAM cells that are vulnerable to RowHammer\ncause bit errors only at a particular temperature. Based on these observations,\nwe propose a new RowHammer attack, called SpyHammer, that spies on the\ntemperature of critical systems such as industrial production lines, vehicles,\nand medical systems. SpyHammer is the first practical attack that can spy on\nDRAM temperature. SpyHammer can spy on absolute temperature with an error of\nless than 2.5 {\\deg}C at the 90th percentile of tested temperature points, for\n12 real DRAM modules from 4 main manufacturers.",
    "descriptor": "",
    "authors": [
      "Lois Orosa",
      "Ulrich R\u00fchrmair",
      "A. Giray Yaglikci",
      "Haocong Luo",
      "Ataberk Olgun",
      "Patrick Jattke",
      "Minesh Patel",
      "Jeremie Kim",
      "Kaveh Razavi",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.04084"
  },
  {
    "id": "arXiv:2210.04085",
    "title": "Dual Pyramid Generative Adversarial Networks for Semantic Image  Synthesis",
    "abstract": "The goal of semantic image synthesis is to generate photo-realistic images\nfrom semantic label maps. It is highly relevant for tasks like content\ngeneration and image editing. Current state-of-the-art approaches, however,\nstill struggle to generate realistic objects in images at various scales. In\nparticular, small objects tend to fade away and large objects are often\ngenerated as collages of patches. In order to address this issue, we propose a\nDual Pyramid Generative Adversarial Network (DP-GAN) that learns the\nconditioning of spatially-adaptive normalization blocks at all scales jointly,\nsuch that scale information is bi-directionally used, and it unifies\nsupervision at different scales. Our qualitative and quantitative results show\nthat the proposed approach generates images where small and large objects look\nmore realistic compared to images generated by state-of-the-art methods.",
    "descriptor": "\nComments: BMVC2022\n",
    "authors": [
      "Shijie Li",
      "Ming-Ming Cheng",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04085"
  },
  {
    "id": "arXiv:2210.04087",
    "title": "Symmetry Subgroup Defense Against Adversarial Attacks",
    "abstract": "Adversarial attacks and defenses disregard the lack of invariance of\nconvolutional neural networks (CNNs), that is, the inability of CNNs to\nclassify samples and their symmetric transformations the same. The lack of\ninvariance of CNNs with respect to symmetry transformations is detrimental when\nclassifying transformed original samples but not necessarily detrimental when\nclassifying transformed adversarial samples. For original images, the lack of\ninvariance means that symmetrically transformed original samples are classified\ndifferently from their correct labels. However, for adversarial images, the\nlack of invariance means that symmetrically transformed adversarial images are\nclassified differently from their incorrect adversarial labels. Might the CNN\nlack of invariance revert symmetrically transformed adversarial samples to the\ncorrect classification? This paper answers this question affirmatively for a\nthreat model that ranges from zero-knowledge adversaries to perfect-knowledge\nadversaries. We base our defense against perfect-knowledge adversaries on\ndevising a Klein four symmetry subgroup that incorporates an additional\nartificial symmetry of pixel intensity inversion. The closure property of the\nsubgroup not only provides a framework for the accuracy evaluation but also\nconfines the transformations that an adaptive, perfect-knowledge adversary can\napply. We find that by using only symmetry defense, no adversarial samples, and\nby changing nothing in the model architecture and parameters, we can defend\nagainst white-box PGD adversarial attacks, surpassing the PGD adversarial\ntraining defense by up to ~50% even against a perfect-knowledge adversary for\nImageNet. The proposed defense also maintains and surpasses the classification\naccuracy for non-adversarial samples.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04087"
  },
  {
    "id": "arXiv:2210.04088",
    "title": "Collaborative Domain Blocking: Using federated NLP To Detect Malicious  Domains",
    "abstract": "Current content filtering and blocking methods are susceptible to various\ncircumvention techniques and are relatively slow in dealing with new threats.\nThis is due to these methods using shallow pattern recognition that is based on\nregular expression rules found in crowdsourced block lists. We propose a novel\nsystem that aims to remedy the aforementioned issues by examining deep textual\npatterns of network-oriented content relating to the domain being interacted\nwith. Moreover, we propose to use federated learning that allows users to take\nadvantage of each other's localized knowledge/experience regarding what should\nor should not be blocked on a network without compromising privacy. Our\nexperiments show the promise of our proposed approach in real world settings.\nWe also provide data-driven recommendations on how to best implement the\nproposed system.",
    "descriptor": "",
    "authors": [
      "Mohammad Ismail Daud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04088"
  },
  {
    "id": "arXiv:2210.04090",
    "title": "APUD(1,1) Recognition in Polynomial Time",
    "abstract": "A unit disk graph is the intersection graph of a set of disk of unit radius\nin the Euclidean plane. In 1998, Breu and Kirkpatrick showed that the\nrecognition problem for unit disk graphs is NP-hard. Given $k$ horizontal and\n$m$ vertical lines, an APUD($k,m$) is a unit disk graph such that each unit\ndisk is centered either on a given horizontal or vertical line.\n\\c{C}a\\u{g}{\\i}r{\\i}c{\\i} showed in 2020 that APUD($k,m$) recognition is\nNP-hard. In this paper, we show that APUD($1,1$) recognition is polynomial time\nsolvable.",
    "descriptor": "",
    "authors": [
      "Deniz A\u011fao\u011flu \u00c7a\u011f\u0131r\u0131c\u0131",
      "Onur \u00c7a\u011f\u0131r\u0131c\u0131"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.04090"
  },
  {
    "id": "arXiv:2210.04091",
    "title": "A Zero-Sum Game Framework for Optimal Sensor Placement in Uncertain  Networked Control Systems under Cyber-Attacks",
    "abstract": "This paper proposes a game-theoretic approach to address the problem of\noptimal sensor placement against an adversary in uncertain networked control\nsystems. The problem is formulated as a zero-sum game with two players, namely\na malicious adversary and a detector. Given a protected performance vertex, we\nconsider a detector, with uncertain system knowledge, that selects another\nvertex on which to place a sensor and monitors its output with the aim of\ndetecting the presence of the adversary. On the other hand, the adversary, also\nwith uncertain system knowledge, chooses a single vertex and conducts a\ncyber-attack on its input. The purpose of the adversary is to drive the attack\nvertex as to maximally disrupt the protected performance vertex while remaining\nundetected by the detector. As our first contribution, the game payoff of the\nabove-defined zero-sum game is formulated in terms of the Value-at-Risk of the\nadversary's impact. However, this game payoff corresponds to an intractable\noptimization problem. To tackle the problem, we adopt the scenario approach to\napproximately compute the game payoff. Then, the optimal monitor selection is\ndetermined by analyzing the equilibrium of the zero-sum game. The proposed\napproach is illustrated via a numerical example of a 10-vertex networked\ncontrol system.",
    "descriptor": "\nComments: 8 pages, 3 figues, Accepted to the 61st Conference on Decision and Control, Cancun, December 2022\n",
    "authors": [
      "Anh Tung Nguyen",
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04091"
  },
  {
    "id": "arXiv:2210.04092",
    "title": "Advancing Model Pruning via Bi-level Optimization",
    "abstract": "The deployment constraints in practical applications necessitate the pruning\nof large-scale deep learning models, i.e., promoting their weight sparsity. As\nillustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the\npotential of improving their generalization ability. At the core of LTH,\niterative magnitude pruning (IMP) is the predominant pruning method to\nsuccessfully find 'winning tickets'. Yet, the computation cost of IMP grows\nprohibitively as the targeted pruning ratio increases. To reduce the\ncomputation overhead, various efficient 'one-shot' pruning methods have been\ndeveloped, but these schemes are usually unable to find winning tickets as good\nas IMP. This raises the question of how to close the gap between pruning\naccuracy and pruning efficiency? To tackle it, we pursue the algorithmic\nadvancement of model pruning. Specifically, we formulate the pruning problem\nfrom a fresh and novel viewpoint, bi-level optimization (BLO). We show that the\nBLO interpretation provides a technically-grounded optimization base for an\nefficient implementation of the pruning-retraining learning paradigm used in\nIMP. We also show that the proposed bi-level optimization-oriented pruning\nmethod (termed BiP) is a special class of BLO problems with a bi-linear problem\nstructure. By leveraging such bi-linearity, we theoretically show that BiP can\nbe solved as easily as first-order optimization, thus inheriting the\ncomputation efficiency. Through extensive experiments on both structured and\nunstructured pruning with 5 model architectures and 4 data sets, we demonstrate\nthat BiP can find better winning tickets than IMP in most cases, and is\ncomputationally as efficient as the one-shot pruning schemes, demonstrating 2-7\ntimes speedup over IMP for the same level of model accuracy and sparsity.",
    "descriptor": "\nComments: Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yihua Zhang",
      "Yuguang Yao",
      "Parikshit Ram",
      "Pu Zhao",
      "Tianlong Chen",
      "Mingyi Hong",
      "Yanzhi Wang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04092"
  },
  {
    "id": "arXiv:2210.04095",
    "title": "How do you go where? Improving next location prediction by learning  travel mode information using transformers",
    "abstract": "Predicting the next visited location of an individual is a key problem in\nhuman mobility analysis, as it is required for the personalization and\noptimization of sustainable transport options. Here, we propose a transformer\ndecoder-based neural network to predict the next location an individual will\nvisit based on historical locations, time, and travel modes, which are\nbehaviour dimensions often overlooked in previous work. In particular, the\nprediction of the next travel mode is designed as an auxiliary task to help\nguide the network's learning. For evaluation, we apply this approach to two\nlarge-scale and long-term GPS tracking datasets involving more than 600\nindividuals. Our experiments show that the proposed method significantly\noutperforms other state-of-the-art next location prediction methods by a large\nmargin (8.05% and 5.60% relative increase in F1-score for the two datasets,\nrespectively). We conduct an extensive ablation study that quantifies the\ninfluence of considering temporal features, travel mode information, and the\nauxiliary task on the prediction results. Moreover, we experimentally determine\nthe performance upper bound when including the next mode prediction in our\nmodel. Finally, our analysis indicates that the performance of location\nprediction varies significantly with the chosen next travel mode by the\nindividual. These results show potential for a more systematic consideration of\nadditional dimensions of travel behaviour in human mobility prediction tasks.\nThe source code of our model and experiments is available at\nhttps://github.com/mie-lab/location-mode-prediction.",
    "descriptor": "\nComments: 10 pages, camera ready SIGSPATIAL '22\n",
    "authors": [
      "Ye Hong",
      "Henry Martin",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.04095"
  },
  {
    "id": "arXiv:2210.04096",
    "title": "PropertyDAG: Multi-objective Bayesian optimization of partially ordered,  mixed-variable properties for biological sequence design",
    "abstract": "Bayesian optimization offers a sample-efficient framework for navigating the\nexploration-exploitation trade-off in the vast design space of biological\nsequences. Whereas it is possible to optimize the various properties of\ninterest jointly using a multi-objective acquisition function, such as the\nexpected hypervolume improvement (EHVI), this approach does not account for\nobjectives with a hierarchical dependency structure. We consider a common use\ncase where some regions of the Pareto frontier are prioritized over others\naccording to a specified $\\textit{partial ordering}$ in the objectives. For\ninstance, when designing antibodies, we would like to maximize the binding\naffinity to a target antigen only if it can be expressed in live cell culture\n-- modeling the experimental dependency in which affinity can only be measured\nfor antibodies that can be expressed and thus produced in viable quantities. In\ngeneral, we may want to confer a partial ordering to the properties such that\neach property is optimized conditioned on its parent properties satisfying some\nfeasibility condition. To this end, we present PropertyDAG, a framework that\noperates on top of the traditional multi-objective BO to impose this desired\nordering on the objectives, e.g. expression $\\rightarrow$ affinity. We\ndemonstrate its performance over multiple simulated active learning iterations\non a penicillin production task, toy numerical problem, and a real-world\nantibody design task.",
    "descriptor": "\nComments: 9 pages, 7 figures. Submitted to NeurIPS 2022 AI4Science Workshop\n",
    "authors": [
      "Ji Won Park",
      "Samuel Stanton",
      "Saeed Saremi",
      "Andrew Watkins",
      "Henri Dwyer",
      "Vladimir Gligorijevic",
      "Richard Bonneau",
      "Stephen Ra",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.04096"
  },
  {
    "id": "arXiv:2210.04098",
    "title": "Controlling a Markov Decision Process with an Abrupt Change in the  Transition Kernel",
    "abstract": "We consider the control of a Markov decision process (MDP) that undergoes an\nabrupt change in its transition kernel (mode). We formulate the problem of\nminimizing regret under control-switching based on mode change detection,\ncompared to a mode-observing controller, as an optimal stopping problem. Using\na sequence of approximations, we reduce it to a quickest change detection (QCD)\nproblem with Markovian data, for which we characterize a state-dependent\nthreshold-type optimal change detection policy. Numerical experiments\nillustrate various properties of our control-switching policy.",
    "descriptor": "",
    "authors": [
      "Nathan Dahlin",
      "Subhonmesh Bose",
      "Venugopal V. Veeravalli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.04098"
  },
  {
    "id": "arXiv:2210.04099",
    "title": "Developable Quad Meshes",
    "abstract": "There are different ways to capture the property of a surface being\ndevelopable, i.e., it can be mapped to a planar domain without stretching or\ntearing. Contributions range from special parametrizations to\ndiscrete-isometric mappings. So far, a local criterion expressing the\ndevelopability of general quad meshes has been lacking. In this paper, we\npropose a new and efficient discrete developability criterion that is based on\na property well-known from differential geometry, namely a rank-deficient\nsecond fundamental form. This criterion is expressed in terms of the canonical\ncheckerboard patterns inscribed in a quad mesh which already was successful in\ndescribing discrete-isometric mappings. In combination with standard global\noptimization procedures, we are able to perform developable lofting,\napproximation, and design. The meshes we employ are combinatorially regular\nquad meshes with isolated singularities but are otherwise not required to\nfollow any special curves. They are thus easily embedded into a design workflow\ninvolving standard operations like re-meshing, trimming, and merging\noperations.",
    "descriptor": "",
    "authors": [
      "Victor Ceballos Inza",
      "Florian Rist",
      "Johannes Wallner",
      "Helmut Pottmann"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.04099"
  },
  {
    "id": "arXiv:2210.04104",
    "title": "Training Deep Learning Algorithms on Synthetic Forest Images for Tree  Detection",
    "abstract": "Vision-based segmentation in forested environments is a key functionality for\nautonomous forestry operations such as tree felling and forwarding. Deep\nlearning algorithms demonstrate promising results to perform visual tasks such\nas object detection. However, the supervised learning process of these\nalgorithms requires annotations from a large diversity of images. In this work,\nwe propose to use simulated forest environments to automatically generate 43 k\nrealistic synthetic images with pixel-level annotations, and use it to train\ndeep learning algorithms for tree detection. This allows us to address the\nfollowing questions: i) what kind of performance should we expect from deep\nlearning in harsh synthetic forest environments, ii) which annotations are the\nmost important for training, and iii) what modality should be used between RGB\nand depth. We also report the promising transfer learning capability of\nfeatures learned on our synthetic dataset by directly predicting bounding box,\nsegmentation masks and keypoints on real images. Code available on GitHub\n(https://github.com/norlab-ulaval/PercepTreeV1).",
    "descriptor": "\nComments: Work presented at ICRA 2022 Workshop in Innovation in Forestry Robotics: Research and Industry Adoption\n",
    "authors": [
      "Vincent Grondin",
      "Fran\u00e7ois Pomerleau",
      "Philippe Gigu\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04104"
  },
  {
    "id": "arXiv:2210.04105",
    "title": "KALM: Knowledge-Aware Integration of Local, Document, and Global  Contexts for Long Document Understanding",
    "abstract": "With the advent of pre-trained language models (LMs), increasing research\nefforts have been focusing on infusing commonsense and domain-specific\nknowledge to prepare LMs for downstream tasks. These works attempt to leverage\nknowledge graphs, the de facto standard of symbolic knowledge representation,\nalong with pre-trained LMs. While existing approaches leverage external\nknowledge, it remains an open question how to jointly incorporate knowledge\ngraphs representing varying contexts, from local (e.g., sentence), to\ndocument-level, to global knowledge, to enable knowledge-rich and interpretable\nexchange across these contexts. Such rich contextualization can be especially\nbeneficial for long document understanding tasks since standard pre-trained LMs\nare typically bounded by the input sequence length. In light of these\nchallenges, we propose KALM, a Knowledge-Aware Language Model that jointly\nleverages knowledge in local, document-level, and global contexts for long\ndocument understanding. KALM first encodes long documents and knowledge graphs\ninto the three knowledge-aware context representations. It then processes each\ncontext with context-specific layers, followed by a context fusion layer that\nfacilitates interpretable knowledge exchange to derive an overarching document\nrepresentation. Extensive experiments demonstrate that KALM achieves\nstate-of-the-art performance on three long document understanding tasks across\n6 datasets/settings. Further analyses reveal that the three knowledge-aware\ncontexts are complementary and they all contribute to model performance, while\nthe importance and information exchange patterns of different contexts vary\nwith respect to different tasks and datasets.",
    "descriptor": "",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Wenqian Zhang",
      "Zhenyu Lei",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04105"
  },
  {
    "id": "arXiv:2210.04106",
    "title": "The effect of variable labels on deep learning models trained to predict  breast density",
    "abstract": "Purpose: High breast density is associated with reduced efficacy of\nmammographic screening and increased risk of developing breast cancer. Accurate\nand reliable automated density estimates can be used for direct risk prediction\nand passing density related information to further predictive models. Expert\nreader assessments of density show a strong relationship to cancer risk but\nalso inter-reader variation. The effect of label variability on model\nperformance is important when considering how to utilise automated methods for\nboth research and clinical purposes. Methods: We utilise subsets of images with\ndensity labels to train a deep transfer learning model which is used to assess\nhow label variability affects the mapping from representation to prediction. We\nthen create two end-to-end deep learning models which allow us to investigate\nthe effect of label variability on the model representation formed. Results: We\nshow that the trained mappings from representations to labels are altered\nconsiderably by the variability of reader scores. Training on labels with\ndistribution variation removed causes the Spearman rank correlation\ncoefficients to rise from $0.751\\pm0.002$ to either $0.815\\pm0.006$ when\naveraging across readers or $0.844\\pm0.002$ when averaging across images.\nHowever, when we train different models to investigate the representation\neffect we see little difference, with Spearman rank correlation coefficients of\n$0.846\\pm0.006$ and $0.850\\pm0.006$ showing no statistically significant\ndifference in the quality of the model representation with regard to density\nprediction. Conclusions: We show that the mapping between representation and\nmammographic density prediction is significantly affected by label variability.\nHowever, the effect of the label variability on the model representation is\nlimited.",
    "descriptor": "",
    "authors": [
      "Steven Squires",
      "Elaine F. Harkness",
      "D. Gareth Evans",
      "Susan M. Astley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04106"
  },
  {
    "id": "arXiv:2210.04107",
    "title": "Comparing Computational Architectures for Automated Journalism",
    "abstract": "The majority of NLG systems have been designed following either a\ntemplate-based or a pipeline-based architecture. Recent neural models for\ndata-to-text generation have been proposed with an end-to-end deep learning\nflavor, which handles non-linguistic input in natural language without explicit\nintermediary representations. This study compares the most often employed\nmethods for generating Brazilian Portuguese texts from structured data. Results\nsuggest that explicit intermediate steps in the generation process produce\nbetter texts than the ones generated by neural end-to-end architectures,\navoiding data hallucination while better generalizing to unseen inputs. Code\nand corpus are publicly available.",
    "descriptor": "\nComments: Accepted at the 19th National Meeting on Artificial and Computational Intelligence (ENIAC 2022)\n",
    "authors": [
      "Yan V. Sym",
      "Jo\u00e3o Gabriel M. Campos",
      "Marcos M. Jos\u00e9",
      "Fabio G. Cozman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04107"
  },
  {
    "id": "arXiv:2210.04112",
    "title": "Leveraging progressive model and overfitting for efficient learned image  compression",
    "abstract": "Deep learning is overwhelmingly dominant in the field of computer vision and\nimage/video processing for the last decade. However, for image and video\ncompression, it lags behind the traditional techniques based on discrete cosine\ntransform (DCT) and linear filters. Built on top of an autoencoder\narchitecture, learned image compression (LIC) systems have drawn enormous\nattention in recent years. Nevertheless, the proposed LIC systems are still\ninferior to the state-of-the-art traditional techniques, for example, the\nVersatile Video Coding (VVC/H.266) standard, due to either their compression\nperformance or decoding complexity. Although claimed to outperform the\nVVC/H.266 on a limited bit rate range, some proposed LIC systems take over 40\nseconds to decode a 2K image on a GPU system. In this paper, we introduce a\npowerful and flexible LIC framework with multi-scale progressive (MSP)\nprobability model and latent representation overfitting (LOF) technique. With\ndifferent predefined profiles, the proposed framework can achieve various\nbalance points between compression efficiency and computational complexity.\nExperiments show that the proposed framework achieves 2.5%, 1.0%, and 1.3%\nBjontegaard delta bit rate (BD-rate) reduction over the VVC/H.266 standard on\nthree benchmark datasets on a wide bit rate range. More importantly, the\ndecoding complexity is reduced from O(n) to O(1) compared to many other LIC\nsystems, resulting in over 20 times speedup when decoding 2K images.",
    "descriptor": "",
    "authors": [
      "Honglei Zhang",
      "Francesco Cricri",
      "Hamed Rezazadegan Tavakoli",
      "Emre Aksu",
      "Miska M. Hannuksela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.04112"
  },
  {
    "id": "arXiv:2210.04114",
    "title": "Towards Real-Time Temporal Graph Learning",
    "abstract": "In recent years, graph representation learning has gained significant\npopularity, which aims to generate node embeddings that capture features of\ngraphs. One of the methods to achieve this is employing a technique called\nrandom walks that captures node sequences in a graph and then learns embeddings\nfor each node using a natural language processing technique called Word2Vec.\nThese embeddings are then used for deep learning on graph data for\nclassification tasks, such as link prediction or node classification. Prior\nwork operates on pre-collected temporal graph data and is not designed to\nhandle updates on a graph in real-time. Real world graphs change dynamically\nand their entire temporal updates are not available upfront. In this paper, we\npropose an end-to-end graph learning pipeline that performs temporal graph\nconstruction, creates low-dimensional node embeddings, and trains multi-layer\nneural network models in an online setting. The training of the neural network\nmodels is identified as the main performance bottleneck as it performs repeated\nmatrix operations on many sequentially connected low-dimensional kernels. We\npropose to unlock fine-grain parallelism in these low-dimensional kernels to\nboost performance of model training.",
    "descriptor": "",
    "authors": [
      "Deniz Gurevin",
      "Mohsin Shan",
      "Tong Geng",
      "Weiwen Jiang",
      "Caiwen Ding",
      "Omer Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04114"
  },
  {
    "id": "arXiv:2210.04120",
    "title": "MultiStyleGAN: Multiple One-shot Face Stylizations using a Single GAN",
    "abstract": "Image stylization aims at applying a reference style to arbitrary input\nimages. A common scenario is one-shot stylization, where only one example is\navailable for each reference style. A successful recent approach for one-shot\nface stylization is JoJoGAN, which fine-tunes a pre-trained StyleGAN2 generator\non a single style reference image. However, it cannot generate multiple\nstylizations without fine-tuning a new model for each style separately. In this\nwork, we present a MultiStyleGAN method that is capable of producing multiple\ndifferent face stylizations at once by fine-tuning a single generator. The key\ncomponent of our method is a learnable Style Transformation module that takes\nlatent codes as input and learns linear mappings to different regions of the\nlatent space to produce distinct codes for each style, resulting in a\nmultistyle space. Our model inherently mitigates overfitting since it is\ntrained on multiple styles, hence improving the quality of stylizations. Our\nmethod can learn upwards of $12$ image stylizations at once, bringing upto\n$8\\times$ improvement in training time. We support our results through user\nstudies that indicate meaningful improvements over existing methods.",
    "descriptor": "",
    "authors": [
      "Viraj Shah",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04120"
  },
  {
    "id": "arXiv:2210.04121",
    "title": "Cognitive Models as Simulators: The Case of Moral Decision-Making",
    "abstract": "To achieve desirable performance, current AI systems often require huge\namounts of training data. This is especially problematic in domains where\ncollecting data is both expensive and time-consuming, e.g., where AI systems\nrequire having numerous interactions with humans, collecting feedback from\nthem. In this work, we substantiate the idea of $\\textit{cognitive models as\nsimulators}$, which is to have AI systems interact with, and collect feedback\nfrom, cognitive models instead of humans, thereby making their training process\nboth less costly and faster. Here, we leverage this idea in the context of\nmoral decision-making, by having reinforcement learning (RL) agents learn about\nfairness through interacting with a cognitive model of the Ultimatum Game (UG),\na canonical task in behavioral and brain sciences for studying fairness.\nInterestingly, these RL agents learn to rationally adapt their behavior\ndepending on the emotional state of their simulated UG responder. Our work\nsuggests that using cognitive models as simulators of humans is an effective\napproach for training AI systems, presenting an important way for computational\ncognitive science to make contributions to AI.",
    "descriptor": "",
    "authors": [
      "Ardavan S. Nobandegani",
      "Thomas R. Shultz",
      "Irina Rish"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.04121"
  },
  {
    "id": "arXiv:2210.04123",
    "title": "DIMES: A Differentiable Meta Solver for Combinatorial Optimization  Problems",
    "abstract": "Recently, deep reinforcement learning (DRL) models have shown promising\nresults in solving NP-hard Combinatorial Optimization (CO) problems. However,\nmost DRL solvers can only scale to a few hundreds of nodes for combinatorial\noptimization problems on graphs, such as the Traveling Salesman Problem (TSP).\nThis paper addresses the scalability challenge in large-scale combinatorial\noptimization by proposing a novel approach, namely, DIMES. Unlike previous DRL\nmethods which suffer from costly autoregressive decoding or iterative\nrefinements of discrete solutions, DIMES introduces a compact continuous space\nfor parameterizing the underlying distribution of candidate solutions. Such a\ncontinuous space allows stable REINFORCE-based training and fine-tuning via\nmassively parallel sampling. We further propose a meta-learning framework to\nenable the effective initialization of model parameters in the fine-tuning\nstage. Extensive experiments show that DIMES outperforms recent DRL-based\nmethods on large benchmark datasets for Traveling Salesman Problems and Maximal\nIndependent Set problems.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ruizhong Qiu",
      "Zhiqing Sun",
      "Yiming Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.04123"
  },
  {
    "id": "arXiv:2210.04124",
    "title": "Generalized energy and gradient flow via graph framelets",
    "abstract": "In this work, we provide a theoretical understanding of the framelet-based\ngraph neural networks through the perspective of energy gradient flow. By\nviewing the framelet-based models as discretized gradient flows of some energy,\nwe show it can induce both low-frequency and high-frequency-dominated dynamics,\nvia the separate weight matrices for different frequency components. This\nsubstantiates its good empirical performance on both homophilic and\nheterophilic graphs. We then propose a generalized energy via framelet\ndecomposition and show its gradient flow leads to a novel graph neural network,\nwhich includes many existing models as special cases. We then explain how the\nproposed model generally leads to more flexible dynamics, thus potentially\nenhancing the representation power of graph neural networks.",
    "descriptor": "",
    "authors": [
      "Andi Han",
      "Dai Shi",
      "Zhiqi Shao",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04124"
  },
  {
    "id": "arXiv:2210.04126",
    "title": "HEGEL: Hypergraph Transformer for Long Document Summarization",
    "abstract": "Extractive summarization for long documents is challenging due to the\nextended structured input context. The long-distance sentence dependency\nhinders cross-sentence relations modeling, the critical step of extractive\nsummarization. This paper proposes HEGEL, a hypergraph neural network for long\ndocument summarization by capturing high-order cross-sentence relations. HEGEL\nupdates and learns effective sentence representations with hypergraph\ntransformer layers and fuses different types of sentence dependencies,\nincluding latent topics, keywords coreference, and section structure. We\nvalidate HEGEL by conducting extensive experiments on two benchmark datasets,\nand experimental results demonstrate the effectiveness and efficiency of HEGEL.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Haopeng Zhang",
      "Xiao Liu",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04126"
  },
  {
    "id": "arXiv:2210.04127",
    "title": "Towards Efficient Neural Scene Graphs by Learning Consistency Fields",
    "abstract": "Neural Radiance Fields (NeRF) achieves photo-realistic image rendering from\nnovel views, and the Neural Scene Graphs (NSG) \\cite{ost2021neural} extends it\nto dynamic scenes (video) with multiple objects. Nevertheless, computationally\nheavy ray marching for every image frame becomes a huge burden. In this paper,\ntaking advantage of significant redundancy across adjacent frames in videos, we\npropose a feature-reusing framework. From the first try of naively reusing the\nNSG features, however, we learn that it is crucial to disentangle\nobject-intrinsic properties consistent across frames from transient ones. Our\nproposed method, \\textit{Consistency-Field-based NSG (CF-NSG)}, reformulates\nneural radiance fields to additionally consider \\textit{consistency fields}.\nWith disentangled representations, CF-NSG takes full advantage of the\nfeature-reusing scheme and performs an extended degree of scene manipulation in\na more controllable manner. We empirically verify that CF-NSG greatly improves\nthe inference efficiency by using 85\\% less queries than NSG without notable\ndegradation in rendering quality. Code will be available at:\nhttps://github.com/ldynx/CF-NSG",
    "descriptor": "\nComments: BMVC 2022, 22 pages\n",
    "authors": [
      "Yeji Song",
      "Chaerin Kong",
      "Seoyoung Lee",
      "Nojun Kwak",
      "Joonseok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04127"
  },
  {
    "id": "arXiv:2210.04132",
    "title": "Performances of Symmetric Loss for Private Data from Exponential  Mechanism",
    "abstract": "This study explores the robustness of learning by symmetric loss on private\ndata. Specifically, we leverage exponential mechanism (EM) on private labels.\nFirst, we theoretically re-discussed properties of EM when it is used for\nprivate learning with symmetric loss. Then, we propose numerical guidance of\nprivacy budgets corresponding to different data scales and utility guarantees.\nFurther, we conducted experiments on the CIFAR-10 dataset to present the traits\nof symmetric loss. Since EM is a more generic differential privacy (DP)\ntechnique, it being robust has the potential for it to be generalized, and to\nmake other DP techniques more robust.",
    "descriptor": "\nComments: 14th International Workshop on Parallel and Distributed Algorithms and Applications (PDAA2022)\n",
    "authors": [
      "Jing Bi",
      "Vorapong Suppakitpaisarn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04132"
  },
  {
    "id": "arXiv:2210.04133",
    "title": "Adapting Pretrained Vision-Language Foundational Models to Medical  Imaging Domains",
    "abstract": "Multi-modal foundation models are typically trained on millions of pairs of\nnatural images and text captions, frequently obtained through web-crawling\napproaches. Although such models depict excellent generative capabilities, they\ndo not typically generalize well to specific domains such as medical images\nthat have fundamentally shifted distributions compared to natural images.\nBuilding generative models for medical images that faithfully depict clinical\ncontext may help alleviate the paucity of healthcare datasets. Thus, in this\nstudy, we seek to research and expand the representational capabilities of\nlarge pretrained foundation models to medical concepts, specifically for\nleveraging the Stable Diffusion model to generate domain specific images found\nin medical imaging. We explore the sub-components of the Stable Diffusion\npipeline (the variational autoencoder, the U-Net and the text-encoder) to\nfine-tune the model to generate medical images. We benchmark the efficacy of\nthese efforts using quantitative image quality metrics and qualitative\nradiologist-driven evaluations that accurately represent the clinical content\nof conditional text prompts. Our best-performing model improves upon the stable\ndiffusion baseline and can be conditioned to insert a realistic-looking\nabnormality on a synthetic radiology image, while maintaining a 95% accuracy on\na classifier trained to detect the abnormality.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Pierre Chambon",
      "Christian Bluethgen",
      "Curtis P. Langlotz",
      "Akshay Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04133"
  },
  {
    "id": "arXiv:2210.04135",
    "title": "VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature  Alignment",
    "abstract": "Vision-language pre-training (VLP) has recently proven highly effective for\nvarious uni- and multi-modal downstream applications. However, most existing\nend-to-end VLP methods use high-resolution image-text box data to perform well\non fine-grained region-level tasks, such as object detection, segmentation, and\nreferring expression comprehension. Unfortunately, such high-resolution images\nwith accurate bounding box annotations are expensive to collect and use for\nsupervision at scale. In this work, we propose VoLTA (Vision-Language\nTransformer with weakly-supervised local-feature Alignment), a new VLP paradigm\nthat only utilizes image-caption data but achieves fine-grained region-level\nimage understanding, eliminating the use of expensive box annotations. VoLTA\nadopts graph optimal transport-based weakly-supervised alignment on local image\npatches and text tokens to germinate an explicit, self-normalized, and\ninterpretable low-level matching criterion. In addition, VoLTA pushes\nmulti-modal fusion deep into the uni-modal backbones during pre-training and\nremoves fusion-specific transformer layers, further reducing memory\nrequirements. Extensive experiments on a wide range of vision- and\nvision-language downstream tasks demonstrate the effectiveness of VoLTA on\nfine-grained applications without compromising the coarse-grained downstream\nperformance, often outperforming methods using significantly more caption and\nbox annotations.",
    "descriptor": "",
    "authors": [
      "Shraman Pramanick",
      "Li Jing",
      "Sayan Nag",
      "Jiachen Zhu",
      "Hardik Shah",
      "Yann LeCun",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.04135"
  },
  {
    "id": "arXiv:2210.04137",
    "title": "Few-Shot Continual Active Learning by a Robot",
    "abstract": "In this paper, we consider a challenging but realistic continual learning\n(CL) problem, Few-Shot Continual Active Learning (FoCAL), where a CL agent is\nprovided with unlabeled data for a new or a previously learned task in each\nincrement and the agent only has limited labeling budget available. Towards\nthis, we build on the continual learning and active learning literature and\ndevelop a framework that can allow a CL agent to continually learn new object\nclasses from a few labeled training examples. Our framework represents each\nobject class using a uniform Gaussian mixture model (GMM) and uses\npseudo-rehearsal to mitigate catastrophic forgetting. The framework also uses\nuncertainty measures on the Gaussian representations of the previously learned\nclasses to find the most informative samples to be labeled in an increment. We\nevaluate our approach on the CORe-50 dataset and on a real humanoid robot for\nthe object classification task. The results show that our approach not only\nproduces state-of-the-art results on the dataset but also allows a real robot\nto continually learn unseen objects in a real environment with limited labeling\nsupervision provided by its user.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ali Ayub",
      "Carter Fendley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04137"
  },
  {
    "id": "arXiv:2210.04141",
    "title": "Cross-Align: Modeling Deep Cross-lingual Interactions for Word Alignment",
    "abstract": "Word alignment which aims to extract lexicon translation equivalents between\nsource and target sentences, serves as a fundamental tool for natural language\nprocessing. Recent studies in this area have yielded substantial improvements\nby generating alignments from contextualized embeddings of the pre-trained\nmultilingual language models. However, we find that the existing approaches\ncapture few interactions between the input sentence pairs, which degrades the\nword alignment quality severely, especially for the ambiguous words in the\nmonolingual context. To remedy this problem, we propose Cross-Align to model\ndeep interactions between the input sentence pairs, in which the source and\ntarget sentences are encoded separately with the shared self-attention modules\nin the shallow layers, while cross-lingual interactions are explicitly\nconstructed by the cross-attention modules in the upper layers. Besides, to\ntrain our model effectively, we propose a two-stage training framework, where\nthe model is trained with a simple Translation Language Modeling (TLM)\nobjective in the first stage and then finetuned with a self-supervised\nalignment objective in the second stage. Experiments show that the proposed\nCross-Align achieves the state-of-the-art (SOTA) performance on four out of\nfive language pairs.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Siyu Lai",
      "Zhen Yang",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04141"
  },
  {
    "id": "arXiv:2210.04142",
    "title": "Deep Clustering: A Comprehensive Survey",
    "abstract": "Cluster analysis plays an indispensable role in machine learning and data\nmining. Learning a good data representation is crucial for clustering\nalgorithms. Recently, deep clustering, which can learn clustering-friendly\nrepresentations using deep neural networks, has been broadly applied in a wide\nrange of clustering tasks. Existing surveys for deep clustering mainly focus on\nthe single-view fields and the network architectures, ignoring the complex\napplication scenarios of clustering. To address this issue, in this paper we\nprovide a comprehensive survey for deep clustering in views of data sources.\nWith different data sources and initial conditions, we systematically\ndistinguish the clustering methods in terms of methodology, prior knowledge,\nand architecture. Concretely, deep clustering methods are introduced according\nto four categories, i.e., traditional single-view deep clustering,\nsemi-supervised deep clustering, deep multi-view clustering, and deep transfer\nclustering. Finally, we discuss the open challenges and potential future\nopportunities in different fields of deep clustering.",
    "descriptor": "",
    "authors": [
      "Yazhou Ren",
      "Jingyu Pu",
      "Zhimeng Yang",
      "Jie Xu",
      "Guofeng Li",
      "Xiaorong Pu",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04142"
  },
  {
    "id": "arXiv:2210.04144",
    "title": "Adaptive Distribution Calibration for Few-Shot Learning with  Hierarchical Optimal Transport",
    "abstract": "Few-shot classification aims to learn a classifier to recognize unseen\nclasses during training, where the learned model can easily become over-fitted\nbased on the biased distribution formed by only a few training examples. A\nrecent solution to this problem is calibrating the distribution of these few\nsample classes by transferring statistics from the base classes with sufficient\nexamples, where how to decide the transfer weights from base classes to novel\nclasses is the key. However, principled approaches for learning the transfer\nweights have not been carefully studied. To this end, we propose a novel\ndistribution calibration method by learning the adaptive weight matrix between\nnovel samples and base classes, which is built upon a hierarchical Optimal\nTransport (H-OT) framework. By minimizing the high-level OT distance between\nnovel samples and base classes, we can view the learned transport plan as the\nadaptive weight information for transferring the statistics of base classes.\nThe learning of the cost function between a base class and novel class in the\nhigh-level OT leads to the introduction of the low-level OT, which considers\nthe weights of all the data samples in the base class. Experimental results on\nstandard benchmarks demonstrate that our proposed plug-and-play model\noutperforms competing approaches and owns desired cross-domain generalization\nability, indicating the effectiveness of the learned adaptive weights.",
    "descriptor": "",
    "authors": [
      "Dandan Guo",
      "Long Tian",
      "He Zhao",
      "Mingyuan Zhou",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04144"
  },
  {
    "id": "arXiv:2210.04145",
    "title": "Fine-grained Anomaly Detection in Sequential Data via Counterfactual  Explanations",
    "abstract": "Anomaly detection in sequential data has been studied for a long time because\nof its potential in various applications, such as detecting abnormal system\nbehaviors from log data. Although many approaches can achieve good performance\non anomalous sequence detection, how to identify the anomalous entries in\nsequences is still challenging due to a lack of information at the entry-level.\nIn this work, we propose a novel framework called CFDet for fine-grained\nanomalous entry detection. CFDet leverages the idea of interpretable machine\nlearning. Given a sequence that is detected as anomalous, we can consider\nanomalous entry detection as an interpretable machine learning task because\nidentifying anomalous entries in the sequence is to provide an interpretation\nto the detection result. We make use of the deep support vector data\ndescription (Deep SVDD) approach to detect anomalous sequences and propose a\nnovel counterfactual interpretation-based approach to identify anomalous\nentries in the sequences. Experimental results on three datasets show that\nCFDet can correctly detect anomalous entries.",
    "descriptor": "",
    "authors": [
      "He Cheng",
      "Depeng Xu",
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04145"
  },
  {
    "id": "arXiv:2210.04149",
    "title": "From Counter-intuitive Observations to a Fresh Look at Recommender  System",
    "abstract": "Recently, a few papers report counter-intuitive observations made from\nexperiments on recommender system (RecSys). One observation is that users who\nspend more time and users who have many interactions with a recommendation\nsystem receive poorer recommendations. Another observation is that models\ntrained by using only the more recent parts of a dataset show significant\nperformance improvement. In this opinion paper, we interpret these\ncounter-intuitive observations from two perspectives. First, the observations\nare made with respect to the global timeline of user-item interactions. Second,\nthe observations are considered counter-intuitive because they contradict our\nexpectation on a recommender: the more interactions a user has, the higher\nchance that the recommender better learns the user preference. For the first\nperspective, we discuss the importance of the global timeline by using the\nsimplest baseline Popularity as a starting point. We answer two questions: (i)\nwhy the simplest model popularity is often ill-defined in academic research?\nand (ii) why the popularity baseline is evaluated in this way? The questions\nlead to a detailed discussion on the data leakage issue in many offline\nevaluations. As the result, model accuracies reported in many academic papers\nare less meaningful and incomparable. For the second perspective, we try to\nanswer two more questions: (i) why models trained by using only the more recent\nparts of data demonstrate better performance? and (ii) why more interactions\nfrom users lead to poorer recommendations? The key to both questions is user\npreference modeling. We then propose to have a fresh look at RecSys. We discuss\nhow to conduct more practical offline evaluations and possible ways to\neffectively model user preferences. The discussion and opinions in this paper\nare on top-N recommendation only, not on rating prediction.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Aixin Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.04149"
  },
  {
    "id": "arXiv:2210.04150",
    "title": "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
    "abstract": "Open-vocabulary semantic segmentation aims to segment an image into semantic\nregions according to text descriptions, which may not have been seen during\ntraining. Recent two-stage methods first generate class-agnostic mask proposals\nand then leverage pre-trained vision-language models, e.g., CLIP, to classify\nmasked regions. We identify the performance bottleneck of this paradigm to be\nthe pre-trained CLIP model, since it does not perform well on masked images. To\naddress this, we propose to finetune CLIP on a collection of masked image\nregions and their corresponding text descriptions. We collect training data by\nmining an existing image-caption dataset (e.g., COCO Captions), using CLIP to\nmatch masked image regions to nouns in the image captions. Compared with the\nmore precise and manually annotated segmentation labels with fixed classes\n(e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain\nCLIP's generalization ability. Along with finetuning the entire model, we\nutilize the \"blank\" areas in masked images using a method we dub mask prompt\ntuning. Experiments demonstrate mask prompt tuning brings significant\nimprovement without modifying any weights of CLIP, and it can further improve a\nfully finetuned model. In particular, when trained on COCO and evaluated on\nADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the\nprevious state-of-the-art. For the first time, open-vocabulary generalist\nmodels match the performance of supervised specialist models in 2017 without\ndataset-specific adaptations.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Feng Liang",
      "Bichen Wu",
      "Xiaoliang Dai",
      "Kunpeng Li",
      "Yinan Zhao",
      "Hang Zhang",
      "Peizhao Zhang",
      "Peter Vajda",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04150"
  },
  {
    "id": "arXiv:2210.04152",
    "title": "A Contextual Bandit Approach for Value-oriented Prediction Interval  Forecasting",
    "abstract": "Prediction interval (PI) is an effective tool to quantify uncertainty and\nusually serves as an input to downstream robust optimization. Traditional\napproaches focus on improving the quality of PI in the view of statistical\nscores and assume the improvement in quality will lead to a higher value in the\npower systems operation. However, such an assumption cannot always hold in\npractice. In this paper, we propose a value-oriented PI forecasting approach,\nwhich aims at reducing operational costs in downstream operations. For that, it\nis required to issue PIs with the guidance of operational costs in robust\noptimization, which is addressed within the contextual bandit framework here.\nConcretely, the agent is used to select the optimal quantile proportion, while\nthe environment reveals the costs in operations as rewards to the agent. As\nsuch, the agent can learn the policy of quantile proportion selection for\nminimizing the operational cost. The numerical study regarding a two-timescale\noperation of a virtual power plant verifies the superiority of the proposed\napproach in terms of operational value. And it is especially evident in the\ncontext of extensive penetration of wind power.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Smart Grid\n",
    "authors": [
      "Yufan Zhang",
      "Honglin Wen",
      "Qiuwei Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.04152"
  },
  {
    "id": "arXiv:2210.04153",
    "title": "Stimulative Training of Residual Networks: A Social Psychology  Perspective of Loafing",
    "abstract": "Residual networks have shown great success and become indispensable in\ntoday's deep models. In this work, we aim to re-investigate the training\nprocess of residual networks from a novel social psychology perspective of\nloafing, and further propose a new training strategy to strengthen the\nperformance of residual networks. As residual networks can be viewed as\nensembles of relatively shallow networks (i.e., \\textit{unraveled view}) in\nprior works, we also start from such view and consider that the final\nperformance of a residual network is co-determined by a group of sub-networks.\nInspired by the social loafing problem of social psychology, we find that\nresidual networks invariably suffer from similar problem, where sub-networks in\na residual network are prone to exert less effort when working as part of the\ngroup compared to working alone. We define this previously overlooked problem\nas \\textit{network loafing}. As social loafing will ultimately cause the low\nindividual productivity and the reduced overall performance, network loafing\nwill also hinder the performance of a given residual network and its\nsub-networks. Referring to the solutions of social psychology, we propose\n\\textit{stimulative training}, which randomly samples a residual sub-network\nand calculates the KL-divergence loss between the sampled sub-network and the\ngiven residual network, to act as extra supervision for sub-networks and make\nthe overall goal consistent. Comprehensive empirical results and theoretical\nanalyses verify that stimulative training can well handle the loafing problem,\nand improve the performance of a residual network by improving the performance\nof its sub-networks. The code is available at\nhttps://github.com/Sunshine-Ye/NIPS22-ST .",
    "descriptor": "\nComments: NIPS2022 accept\n",
    "authors": [
      "Peng Ye",
      "Shengji Tang",
      "Baopu Li",
      "Tao Chen",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04153"
  },
  {
    "id": "arXiv:2210.04154",
    "title": "Self-supervised Video Representation Learning with Motion-Aware Masked  Autoencoders",
    "abstract": "Masked autoencoders (MAEs) have emerged recently as art self-supervised\nspatiotemporal representation learners. Inheriting from the image counterparts,\nhowever, existing video MAEs still focus largely on static appearance learning\nwhilst are limited in learning dynamic temporal information hence less\neffective for video downstream tasks. To resolve this drawback, in this work we\npresent a motion-aware variant -- MotionMAE. Apart from learning to reconstruct\nindividual masked patches of video frames, our model is designed to\nadditionally predict the corresponding motion structure information over time.\nThis motion information is available at the temporal difference of nearby\nframes. As a result, our model can extract effectively both static appearance\nand dynamic motion spontaneously, leading to superior spatiotemporal\nrepresentation learning capability. Extensive experiments show that our\nMotionMAE outperforms significantly both supervised learning baseline and\nstate-of-the-art MAE alternatives, under both domain-specific and\ndomain-generic pretraining-then-finetuning settings. In particular, when using\nViT-B as the backbone our MotionMAE surpasses the prior art model by a margin\nof 1.2% on Something-Something V2 and 3.2% on UCF101 in domain-specific\npretraining setting. Encouragingly, it also surpasses the competing MAEs by a\nlarge margin of over 3% on the challenging video object segmentation task. The\ncode is available at https://github.com/happy-hsy/MotionMAE.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Haosen Yang",
      "Deng Huang",
      "Bin Wen",
      "Jiannan Wu",
      "Hongxun Yao",
      "Yi Jiang",
      "Xiatian Zhu",
      "Zehuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04154"
  },
  {
    "id": "arXiv:2210.04155",
    "title": "Constrained Maximum Cross-Domain Likelihood for Domain Generalization",
    "abstract": "As a recent noticeable topic, domain generalization aims to learn a\ngeneralizable model on multiple source domains, which is expected to perform\nwell on unseen test domains. Great efforts have been made to learn\ndomain-invariant features by aligning distributions across domains. However,\nexisting works are often designed based on some relaxed conditions which are\ngenerally hard to satisfy and fail to realize the desired joint distribution\nalignment. In this paper, we propose a novel domain generalization method,\nwhich originates from an intuitive idea that a domain-invariant classifier can\nbe learned by minimizing the KL-divergence between posterior distributions from\ndifferent domains. To enhance the generalizability of the learned classifier,\nwe formalize the optimization objective as an expectation computed on the\nground-truth marginal distribution. Nevertheless, it also presents two obvious\ndeficiencies, one of which is the side-effect of entropy increase in\nKL-divergence and the other is the unavailability of ground-truth marginal\ndistributions. For the former, we introduce a term named maximum in-domain\nlikelihood to maintain the discrimination of the learned domain-invariant\nrepresentation space. For the latter, we approximate the ground-truth marginal\ndistribution with source domains under a reasonable convex hull assumption.\nFinally, a Constrained Maximum Cross-domain Likelihood (CMCL) optimization\nproblem is deduced, by solving which the joint distributions are naturally\naligned. An alternating optimization strategy is carefully designed to\napproximately solve this optimization problem. Extensive experiments on four\nstandard benchmark datasets, i.e., Digits-DG, PACS, Office-Home and\nminiDomainNet, highlight the superior performance of our method.",
    "descriptor": "",
    "authors": [
      "Jianxin Lin",
      "Yongqiang Tang",
      "Junping Wang",
      "Wensheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04155"
  },
  {
    "id": "arXiv:2210.04157",
    "title": "The Role of Coverage in Online Reinforcement Learning",
    "abstract": "Coverage conditions -- which assert that the data logging distribution\nadequately covers the state space -- play a fundamental role in determining the\nsample complexity of offline reinforcement learning. While such conditions\nmight seem irrelevant to online reinforcement learning at first glance, we\nestablish a new connection by showing -- somewhat surprisingly -- that the mere\nexistence of a data distribution with good coverage can enable sample-efficient\nonline RL. Concretely, we show that coverability -- that is, existence of a\ndata distribution that satisfies a ubiquitous coverage condition called\nconcentrability -- can be viewed as a structural property of the underlying\nMDP, and can be exploited by standard algorithms for sample-efficient\nexploration, even when the agent does not know said distribution. We complement\nthis result by proving that several weaker notions of coverage, despite being\nsufficient for offline RL, are insufficient for online RL. We also show that\nexisting complexity measures for online RL, including Bellman rank and\nBellman-Eluder dimension, fail to optimally capture coverability, and propose a\nnew complexity measure, the sequential extrapolation coefficient, to provide a\nunification.",
    "descriptor": "",
    "authors": [
      "Tengyang Xie",
      "Dylan J. Foster",
      "Yu Bai",
      "Nan Jiang",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04157"
  },
  {
    "id": "arXiv:2210.04161",
    "title": "Cross-strait Variations on Two Near-synonymous Loanwords xie2shang1 and  tan2pan4: A Corpus-based Comparative Study",
    "abstract": "This study attempts to investigate cross-strait variations on two typical\nsynonymous loanwords in Chinese, i.e. xie2shang1 and tan2pan4, drawn on MARVS\ntheory. Through a comparative analysis, the study found some distributional,\neventual, and contextual similarities and differences across Taiwan and\nMainland Mandarin. Compared with the underused tan2pan4, xie2shang1 is\nsignificantly overused in Taiwan Mandarin and vice versa in Mainland Mandarin.\nAdditionally, though both words can refer to an inchoative process in Mainland\nand Taiwan Mandarin, the starting point for xie2shang1 in Mainland Mandarin is\nsomewhat blurring compared with the usage in Taiwan Mandarin. Further on, in\nTaiwan Mandarin, tan2pan4 can be used in economic and diplomatic contexts,\nwhile xie2shang1 is used almost exclusively in political contexts. In Mainland\nMandarin, however, the two words can be used in a hybrid manner within\npolitical contexts; moreover, tan2pan4 is prominently used in diplomatic\ncontexts with less reference to economic activities, while xie2sahng1 can be\nfound in both political and legal contexts, emphasizing a role of mediation.",
    "descriptor": "\nComments: To appear in PACLIC 2022. 10 pages, 5 figures, 5 tables\n",
    "authors": [
      "Yueyue Huang",
      "Chu-Ren Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04161"
  },
  {
    "id": "arXiv:2210.04165",
    "title": "Neural Extended Kalman Filters for Learning and Predicting Dynamics of  Structural Systems",
    "abstract": "Accurate structural response prediction forms a main driver for structural\nhealth monitoring and control applications. This often requires the proposed\nmodel to adequately capture the underlying dynamics of complex structural\nsystems. In this work, we utilize a learnable Extended Kalman Filter (EKF),\nnamed the Neural Extended Kalman Filter (Neural EKF) throughout this paper, for\nlearning the latent evolution dynamics of complex physical systems. The Neural\nEKF is a generalized version of the conventional EKF, where the modeling of\nprocess dynamics and sensory observations can be parameterized by neural\nnetworks, therefore learned by end-to-end training. The method is implemented\nunder the variational inference framework with the EKF conducting inference\nfrom sensing measurements. Typically, conventional variational inference models\nare parameterized by neural networks independent of the latent dynamics models.\nThis characteristic makes the inference and reconstruction accuracy weakly\nbased on the dynamics models and renders the associated training inadequate. We\nhere show how the structure imposed by the Neural EKF is beneficial to the\nlearning process. We demonstrate the efficacy of the framework on both\nsimulated and real-world monitoring datasets, with the results indicating\nsignificant predictive capabilities of the proposed scheme.",
    "descriptor": "\nComments: This manuscript has been submitted to an international journal for review\n",
    "authors": [
      "Wei Liu",
      "Zhilu Lai",
      "Kiran Bacsa",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04165"
  },
  {
    "id": "arXiv:2210.04166",
    "title": "Test-time Recalibration of Conformal Predictors Under Distribution Shift  Based on Unlabeled Examples",
    "abstract": "Modern image classifiers achieve high predictive accuracy, but the\npredictions typically come without reliable uncertainty estimates. Conformal\nprediction algorithms provide uncertainty estimates by predicting a set of\nclasses based on the probability estimates of the classifier (for example, the\nsoftmax scores). To provide such sets, conformal prediction algorithms often\nrely on estimating a cutoff threshold for the probability estimates, and this\nthreshold is chosen based on a calibration set. Conformal prediction methods\nguarantee reliability only when the calibration set is from the same\ndistribution as the test set. Therefore, the methods need to be recalibrated\nfor new distributions. However, in practice, labeled data from new\ndistributions is rarely available, making calibration infeasible. In this work,\nwe consider the problem of predicting the cutoff threshold for a new\ndistribution based on unlabeled examples only. While it is impossible in\ngeneral to guarantee reliability when calibrating based on unlabeled examples,\nwe show that our method provides excellent uncertainty estimates under natural\ndistribution shifts, and provably works for a specific model of a distribution\nshift.",
    "descriptor": "",
    "authors": [
      "Fatih Furkan Yilmaz",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04166"
  },
  {
    "id": "arXiv:2210.04169",
    "title": "A State Feedback Controller for Mitigation of Continuous-Time Networked  SIS Epidemics",
    "abstract": "The paper considers continuous-time networked\nsusceptible-infected-susceptible (SIS) diseases spreading over a population.\nEach agent represents a sub-population and has its own healing rate and\ninfection rate; the state of the agent at a time instant denotes what fraction\nof the said sub-population is infected with the disease at the said time\ninstant. By taking account of the changes in behaviors of the agents in\nresponse to the infection rates in real-time, our goal is to devise a feedback\nstrategy such that the infection level for each agent strictly stays below a\npre-specified value. Furthermore, we are also interested in ensuring that the\nclosed-loop system converges either to the disease-free equilibrium or, when it\nexists, to the endemic equilibrium. The upshot of devising such a strategy is\nthat it allows health administration officials to ensure that there is\nsufficient capacity in the healthcare system to treat the most severe cases. We\ndemonstrate the effectiveness of our controller via numerical examples.",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Sebin Gracy",
      "C\u00e9sar A. Uribe",
      "Hideaki Ishii",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04169"
  },
  {
    "id": "arXiv:2210.04170",
    "title": "Multi-Objective Personalized Product Retrieval in Taobao Search",
    "abstract": "In large-scale e-commerce platforms like Taobao, it is a big challenge to\nretrieve products that satisfy users from billions of candidates. This has been\na common concern of academia and industry. Recently, plenty of works in this\ndomain have achieved significant improvements by enhancing embedding-based\nretrieval (EBR) methods, including the Multi-Grained Deep Semantic Product\nRetrieval (MGDSPR) model [16] in Taobao search engine. However, we find that\nMGDSPR still has problems of poor relevance and weak personalization compared\nto other retrieval methods in our online system, such as lexical matching and\ncollaborative filtering. These problems promote us to further strengthen the\ncapabilities of our EBR model in both relevance estimation and personalized\nretrieval. In this paper, we propose a novel Multi-Objective Personalized\nProduct Retrieval (MOPPR) model with four hierarchical optimization objectives:\nrelevance, exposure, click and purchase. We construct entire-space\nmulti-positive samples to train MOPPR, rather than the single-positive samples\nfor existing EBR models.We adopt a modified softmax loss for optimizing\nmultiple objectives. Results of extensive offline and online experiments show\nthat MOPPR outperforms the baseline MGDSPR on evaluation metrics of relevance\nestimation and personalized retrieval. MOPPR achieves 0.96% transaction and\n1.29% GMV improvements in a 28-day online A/B test. Since the Double-11\nshopping festival of 2021, MOPPR has been fully deployed in mobile Taobao\nsearch, replacing the previous MGDSPR. Finally, we discuss several advanced\ntopics of our deeper explorations on multi-objective retrieval and ranking to\ncontribute to the community.",
    "descriptor": "\nComments: 9 pages, 4 figures, submitted to the 28th ACM SIGKDD Conference on Knowledge Discovery & Data Mining\n",
    "authors": [
      "Yukun Zheng",
      "Jiang Bian",
      "Guanghao Meng",
      "Chao Zhang",
      "Honggang Wang",
      "Zhixuan Zhang",
      "Sen Li",
      "Tao Zhuang",
      "Qingwen Liu",
      "Xiaoyi Zeng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04170"
  },
  {
    "id": "arXiv:2210.04174",
    "title": "Grow and Merge: A Unified Framework for Continuous Categories Discovery",
    "abstract": "Although a number of studies are devoted to novel category discovery, most of\nthem assume a static setting where both labeled and unlabeled data are given at\nonce for finding new categories. In this work, we focus on the application\nscenarios where unlabeled data are continuously fed into the category discovery\nsystem. We refer to it as the {\\bf Continuous Category Discovery} ({\\bf CCD})\nproblem, which is significantly more challenging than the static setting. A\ncommon challenge faced by novel category discovery is that different sets of\nfeatures are needed for classification and category discovery: class\ndiscriminative features are preferred for classification, while rich and\ndiverse features are more suitable for new category mining. This challenge\nbecomes more severe for dynamic setting as the system is asked to deliver good\nperformance for known classes over time, and at the same time continuously\ndiscover new classes from unlabeled data. To address this challenge, we develop\na framework of {\\bf Grow and Merge} ({\\bf GM}) that works by alternating\nbetween a growing phase and a merging phase: in the growing phase, it increases\nthe diversity of features through a continuous self-supervised learning for\neffective category mining, and in the merging phase, it merges the grown model\nwith a static one to ensure satisfying performance for known classes. Our\nextensive studies verify that the proposed GM framework is significantly more\neffective than the state-of-the-art approaches for continuous category\ndiscovery.",
    "descriptor": "\nComments: This paper has already been accepted by 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Xinwei Zhang",
      "Jianwen Jiang",
      "Yutong Feng",
      "Zhi-Fan Wu",
      "Xibin Zhao",
      "Hai Wan",
      "Mingqian Tang",
      "Rong Jin",
      "Yue Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04174"
  },
  {
    "id": "arXiv:2210.04175",
    "title": "Safety Verification for Neural Networks Based on Set-boundary Analysis",
    "abstract": "Neural networks (NNs) are increasingly applied in safety-critical systems\nsuch as autonomous vehicles. However, they are fragile and are often\nill-behaved. Consequently, their behaviors should undergo rigorous guarantees\nbefore deployment in practice. In this paper we propose a set-boundary\nreachability method to investigate the safety verification problem of NNs from\na topological perspective. Given an NN with an input set and a safe set, the\nsafety verification problem is to determine whether all outputs of the NN\nresulting from the input set fall within the safe set. In our method, the\nhomeomorphism property of NNs is mainly exploited, which establishes a\nrelationship mapping boundaries to boundaries. The exploitation of this\nproperty facilitates reachability computations via extracting subsets of the\ninput set rather than the entire input set, thus controlling the wrapping\neffect in reachability analysis and facilitating the reduction of computation\nburdens for safety verification. The homeomorphism property exists in some\nwidely used NNs such as invertible NNs. Notable representations are invertible\nresidual networks (i-ResNets) and Neural ordinary differential equations\n(Neural ODEs). For these NNs, our set-boundary reachability method only needs\nto perform reachability analysis on the boundary of the input set. For NNs\nwhich do not feature this property with respect to the input set, we explore\nsubsets of the input set for establishing the local homeomorphism property, and\nthen abandon these subsets for reachability computations. Finally, some\nexamples demonstrate the performance of the proposed method.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Zhen Liang",
      "Dejin Ren",
      "Wanwei Liu",
      "Ji Wang",
      "Wenjing Yang",
      "Bai Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04175"
  },
  {
    "id": "arXiv:2210.04179",
    "title": "Oze: Decentralized Graph-based Concurrency Control for Real-world Long  Transactions on BoM Benchmark",
    "abstract": "In this paper, we propose Oze, a new concurrency control protocol that\nhandles heterogeneous workloads which include long-running update transactions.\nOze explores a large scheduling space using a fully precise multi-version\nserialization graph to reduce false positives. Oze manages the graph in a\ndecentralized manner to exploit many cores in modern servers. We also propose a\nnew OLTP benchmark, BoMB (Bill of Materials Benchmark), based on a use case in\nan actual manufacturing company. BoMB consists of one long-running update\ntransaction and five short transactions that conflict with each other.\nExperiments using BoMB show that Oze keeps the abort rate of the long-running\nupdate transaction at zero while reaching up to 1.7 Mtpm for short transactions\nwith near linear scalability, whereas state-of-the-art protocols cannot commit\nthe long transaction or experience performance degradation in short transaction\nthroughput.",
    "descriptor": "",
    "authors": [
      "Jun Nemoto",
      "Takashi Kambayashi",
      "Takashi Hoshino",
      "Hideyuki Kawashima"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.04179"
  },
  {
    "id": "arXiv:2210.04180",
    "title": "Coded Residual Transform for Generalizable Deep Metric Learning",
    "abstract": "A fundamental challenge in deep metric learning is the generalization\ncapability of the feature embedding network model since the embedding network\nlearned on training classes need to be evaluated on new test classes. To\naddress this challenge, in this paper, we introduce a new method called coded\nresidual transform (CRT) for deep metric learning to significantly improve its\ngeneralization capability. Specifically, we learn a set of diversified\nprototype features, project the feature map onto each prototype, and then\nencode its features using their projection residuals weighted by their\ncorrelation coefficients with each prototype. The proposed CRT method has the\nfollowing two unique characteristics. First, it represents and encodes the\nfeature map from a set of complimentary perspectives based on projections onto\ndiversified prototypes. Second, unlike existing transformer-based feature\nrepresentation approaches which encode the original values of features based on\nglobal correlation analysis, the proposed coded residual transform encodes the\nrelative differences between the original features and their projected\nprototypes. Embedding space density and spectral decay analysis show that this\nmulti-perspective projection onto diversified prototypes and coded residual\nrepresentation are able to achieve significantly improved generalization\ncapability in metric learning. Finally, to further enhance the generalization\nperformance, we propose to enforce the consistency on their feature similarity\nmatrices between coded residual transforms with different sizes of projection\nprototypes and embedding dimensions. Our extensive experimental results and\nablation studies demonstrate that the proposed CRT method outperform the\nstate-of-the-art deep metric learning methods by large margins and improving\nupon the current best method by up to 4.28% on the CUB dataset.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Shichao Kan",
      "Yixiong Liang",
      "Min Li",
      "Yigang Cen",
      "Jianxin Wang",
      "Zhihai He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04180"
  },
  {
    "id": "arXiv:2210.04182",
    "title": "Deep Span Representations for Named Entity Recognition",
    "abstract": "Span-based models are one of the most straightforward methods for named\nentity recognition (NER). Existing span-based NER systems shallowly aggregate\nthe token representations to span representations. However, this typically\nresults in significant ineffectiveness for long-span entities, a coupling\nbetween the representations of overlapping spans, and ultimately a performance\ndegradation. In this study, we propose DSpERT (Deep Span Encoder\nRepresentations from Transformers), which comprises a standard Transformer and\na span Transformer. The latter uses low-layered span representations as\nqueries, and aggregates the token representations as keys and values, layer by\nlayer from bottom to top. Thus, DSpERT produces span representations of deep\nsemantics.\nWith weight initialization from pretrained language models, DSpERT achieves\nperformance higher than or competitive with recent state-of-the-art systems on\neight NER benchmarks. Experimental results verify the importance of the depth\nfor span representations, and show that DSpERT performs particularly well on\nlong-span entities and nested structures. Further, the deep span\nrepresentations are well structured and easily separable in the feature space.",
    "descriptor": "",
    "authors": [
      "Enwei Zhu",
      "Yiyang Liu",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04182"
  },
  {
    "id": "arXiv:2210.04183",
    "title": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language  Representation Learning",
    "abstract": "Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.",
    "descriptor": "",
    "authors": [
      "Zijia Zhao",
      "Longteng Guo",
      "Xingjian He",
      "Shuai Shao",
      "Zehuan Yuan",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.04183"
  },
  {
    "id": "arXiv:2210.04185",
    "title": "Controllable Dialogue Simulation with In-Context Learning",
    "abstract": "Building dialogue systems requires a large corpus of annotated dialogues.\nSuch datasets are usually created via crowdsourcing, which is expensive and\ntime-consuming. In this paper, we propose a novel method for dialogue\nsimulation based on language model in-context learning, dubbed as\n\\textsc{Dialogic}. Seeded with a few annotated dialogues, \\textsc{Dialogic}\nautomatically selects in-context examples for demonstration and prompts GPT-3\nto generate new dialogues and their annotations in a controllable way.\nLeveraging the strong in-context learning ability of GPT-3, our method can be\nused to rapidly expand a small set of dialogue data without requiring\n\\textit{human involvement} or \\textit{parameter update}, and is thus much more\ncost-efficient and time-saving than crowdsourcing. Experimental results on the\nMultiWOZ dataset demonstrate that training a model on the simulated dialogues\nleads to even better performance than using the same amount of human-generated\ndialogues in the low-resource settings, with as few as 85 dialogues as the seed\ndata. Human evaluation results also show that our simulated dialogues has high\nlanguage fluency and annotation accuracy. The code and data are available at\n\\href{https://github.com/Leezekun/dialogic}{https://github.com/Leezekun/dialogic}.",
    "descriptor": "\nComments: EMNLP 2022 Findings, code and data are available at this https URL\n",
    "authors": [
      "Zekun Li",
      "Wenhu Chen",
      "Shiyang Li",
      "Hong Wang",
      "Jing Qian",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04185"
  },
  {
    "id": "arXiv:2210.04186",
    "title": "Analogy Generation by Prompting Large Language Models: A Case Study of  InstructGPT",
    "abstract": "We propose a novel application of prompting Pre-trained Language Models\n(PLMs) to generate analogies and study how to design effective prompts for two\ntask settings: generating a source concept analogous to a given target concept\n(aka Analogous Concept Generation or ACG), and generating an explanation of the\nsimilarity between a given pair of target concept and source concept (aka\nAnalogous Explanation Generation or AEG). We found that it is feasible to\nprompt InstructGPT to generate meaningful analogies and the best prompts tend\nto be precise imperative statements especially with a low temperature setting.\nWe also systematically analyzed the sensitivity of the InstructGPT model to\nprompt design, temperature, and injected spelling errors, and found that the\nmodel is particularly sensitive to certain variations (e.g., questions vs.\nimperative statements). Further, we conducted human evaluation on 1.4k of the\ngenerated analogies and found that the quality of generations varies\nsubstantially by model size. The largest InstructGPT model can achieve\nhuman-level performance at generating meaningful analogies for a given target\nwhile there is still room for improvement on the AEG task.",
    "descriptor": "",
    "authors": [
      "Bhavya Bhavya",
      "Jinjun Xiong",
      "Chengxiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04186"
  },
  {
    "id": "arXiv:2210.04191",
    "title": "CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text  Generation Models",
    "abstract": "We motivate and introduce CHARD: Clinical Health-Aware Reasoning across\nDimensions, to investigate the capability of text generation models to act as\nimplicit clinical knowledge bases and generate free-flow textual explanations\nabout various health-related conditions across several dimensions. We collect\nand present an associated dataset, CHARDat, consisting of explanations about 52\nhealth conditions across three clinical dimensions. We conduct extensive\nexperiments using BART and T5 along with data augmentation, and perform\nautomatic, human, and qualitative analyses. We show that while our models can\nperform decently, CHARD is very challenging with strong potential for further\nexploration.",
    "descriptor": "",
    "authors": [
      "Steven Y. Feng",
      "Vivek Khetan",
      "Bogdan Sacaleanu",
      "Anatole Gershman",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04191"
  },
  {
    "id": "arXiv:2210.04195",
    "title": "Online Training Through Time for Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient\nmodels. Recent progress in training methods has enabled successful deep SNNs on\nlarge-scale tasks with low latency. Particularly, backpropagation through time\n(BPTT) with surrogate gradients (SG) is popularly used to achieve high\nperformance in a very small number of time steps. However, it is at the cost of\nlarge memory consumption for training, lack of theoretical clarity for\noptimization, and inconsistency with the online property of biological learning\nand rules on neuromorphic hardware. Other works connect spike representations\nof SNNs with equivalent artificial neural network formulation and train SNNs by\ngradients from equivalent mappings to ensure descent directions. But they fail\nto achieve low latency and are also not online. In this work, we propose online\ntraining through time (OTTT) for SNNs, which is derived from BPTT to enable\nforward-in-time learning by tracking presynaptic activities and leveraging\ninstantaneous loss and gradients. Meanwhile, we theoretically analyze and prove\nthat gradients of OTTT can provide a similar descent direction for optimization\nas gradients based on spike representations under both feedforward and\nrecurrent conditions. OTTT only requires constant training memory costs\nagnostic to time steps, avoiding the significant memory costs of BPTT for GPU\ntraining. Furthermore, the update rule of OTTT is in the form of three-factor\nHebbian learning, which could pave a path for online on-chip learning. With\nOTTT, it is the first time that two mainstream supervised SNN training methods,\nBPTT with SG and spike representation-based training, are connected, and\nmeanwhile in a biologically plausible form. Experiments on CIFAR-10, CIFAR-100,\nImageNet, and CIFAR10-DVS demonstrate the superior performance of our method on\nlarge-scale static and neuromorphic datasets in small time steps.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Mingqing Xiao",
      "Qingyan Meng",
      "Zongpeng Zhang",
      "Di He",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04195"
  },
  {
    "id": "arXiv:2210.04200",
    "title": "Boosting Out-of-distribution Detection with Typical Features",
    "abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the\nreliability and safety of deep neural networks in real-world scenarios.\nDifferent from most previous OOD detection methods that focus on designing OOD\nscores or introducing diverse outlier examples to retrain the model, we delve\ninto the obstacle factors in OOD detection from the perspective of typicality\nand regard the feature's high-probability region of the deep model as the\nfeature's typical set. We propose to rectify the feature into its typical set\nand calculate the OOD score with the typical features to achieve reliable\nuncertainty estimation. The feature rectification can be conducted as a\n{plug-and-play} module with various OOD scores. We evaluate the superiority of\nour method on both the commonly used benchmark (CIFAR) and the more challenging\nhigh-resolution benchmark with large label space (ImageNet). Notably, our\napproach outperforms state-of-the-art methods by up to 5.11$\\%$ in the average\nFPR95 on the ImageNet benchmark.",
    "descriptor": "",
    "authors": [
      "Yao Zhu",
      "YueFeng Chen",
      "Chuanlong Xie",
      "Xiaodan Li",
      "Rong Zhang",
      "Hui Xue",
      "Xiang Tian",
      "bolun zheng",
      "Yaowu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04200"
  },
  {
    "id": "arXiv:2210.04202",
    "title": "What should a generic object be?",
    "abstract": "Jacobs has proposed definitions for (weak, strong, split) generic objects for\na fibered category; building on his definition of generic object and split\ngeneric object, Jacobs develops a menagerie of important fibrational structures\nwith applications to categorical logic and computer science, including higher\norder fibrations, polymorphic fibrations, $\\lambda2$-fibrations, triposes, and\nothers. We observe that a split generic object need not in particular be a\ngeneric object under the given definitions, and that the definitions of\npolymorphic fibrations, triposes, etc. are strict enough to rule out many\nfundamental examples: for instance, the fibered preorder induced by a partial\ncombinatory algebra in realizability is not a tripos in the sense of Jacobs. We\nargue for a new alignment of terminology that emphasizes the forms of generic\nobject that appear most commonly in nature, i.e. in the study of internal\ncategories, triposes, and the denotational semantics of polymorphic types. In\naddition, we propose a new class of acyclic generic objects inspired by recent\ndevelopments in the semantics of homotopy type theory, generalizing the\nrealignment property of universes to the setting of an arbitrary fibration.",
    "descriptor": "",
    "authors": [
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2210.04202"
  },
  {
    "id": "arXiv:2210.04204",
    "title": "Lasso trigonometric polynomial approximation for periodic function  recovery in equidistant points",
    "abstract": "In this paper, we propose a fully discrete soft thresholding trigonometric\npolynomial approximation on $[-\\pi,\\pi],$ named Lasso trigonometric\ninterpolation. This approximation is an $\\ell_1$-regularized discrete least\nsquares approximation under the same conditions of classical trigonometric\ninterpolation on an equidistant grid. Lasso trigonometric interpolation is\nsparse and meanwhile it is an efficient tool to deal with noisy data. We\ntheoretically analyze Lasso trigonometric interpolation for continuous periodic\nfunction. The principal results show that the $L_2$ error bound of Lasso\ntrigonometric interpolation is less than that of classical trigonometric\ninterpolation, which improved the robustness of trigonometric interpolation.\nThis paper also presents numerical results on Lasso trigonometric interpolation\non $[-\\pi,\\pi]$, with or without the presence of data errors.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Congpei An",
      "Mou Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04204"
  },
  {
    "id": "arXiv:2210.04206",
    "title": "Attention Diversification for Domain Generalization",
    "abstract": "Convolutional neural networks (CNNs) have demonstrated gratifying results at\nlearning discriminative features. However, when applied to unseen domains,\nstate-of-the-art models are usually prone to errors due to domain shift. After\ninvestigating this issue from the perspective of shortcut learning, we find the\ndevils lie in the fact that models trained on different domains merely bias to\ndifferent domain-specific features yet overlook diverse task-related features.\nUnder this guidance, a novel Attention Diversification framework is proposed,\nin which Intra-Model and Inter-Model Attention Diversification Regularization\nare collaborated to reassign appropriate attention to diverse task-related\nfeatures. Briefly, Intra-Model Attention Diversification Regularization is\nequipped on the high-level feature maps to achieve in-channel discrimination\nand cross-channel diversification via forcing different channels to pay their\nmost salient attention to different spatial locations. Besides, Inter-Model\nAttention Diversification Regularization is proposed to further provide\ntask-related attention diversification and domain-related attention\nsuppression, which is a paradigm of \"simulate, divide and assemble\": simulate\ndomain shift via exploiting multiple domain-specific models, divide attention\nmaps into task-related and domain-related groups, and assemble them within each\ngroup respectively to execute regularization. Extensive experiments and\nanalyses are conducted on various benchmarks to demonstrate that our method\nachieves state-of-the-art performance over other competing methods. Code is\navailable at https://github.com/hikvision-research/DomainGeneralization.",
    "descriptor": "\nComments: ECCV 2022. Code available at this https URL\n",
    "authors": [
      "Rang Meng",
      "Xianfeng Li",
      "Weijie Chen",
      "Shicai Yang",
      "Jie Song",
      "Xinchao Wang",
      "Lei Zhang",
      "Mingli Song",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04206"
  },
  {
    "id": "arXiv:2210.04208",
    "title": "Let Images Give You More:Point Cloud Cross-Modal Training for Shape  Analysis",
    "abstract": "Although recent point cloud analysis achieves impressive progress, the\nparadigm of representation learning from a single modality gradually meets its\nbottleneck. In this work, we take a step towards more discriminative 3D point\ncloud representation by fully taking advantages of images which inherently\ncontain richer appearance information, e.g., texture, color, and shade.\nSpecifically, this paper introduces a simple but effective point cloud\ncross-modality training (PointCMT) strategy, which utilizes view-images, i.e.,\nrendered or projected 2D images of the 3D object, to boost point cloud\nanalysis. In practice, to effectively acquire auxiliary knowledge from view\nimages, we develop a teacher-student framework and formulate the cross modal\nlearning as a knowledge distillation problem. PointCMT eliminates the\ndistribution discrepancy between different modalities through novel feature and\nclassifier enhancement criteria and avoids potential negative transfer\neffectively. Note that PointCMT effectively improves the point-only\nrepresentation without architecture modification. Sufficient experiments verify\nsignificant gains on various datasets using appealing backbones, i.e., equipped\nwith PointCMT, PointNet++ and PointMLP achieve state-of-the-art performance on\ntwo benchmarks, i.e., 94.4% and 86.7% accuracy on ModelNet40 and ScanObjectNN,\nrespectively. Code will be made available at\nhttps://github.com/ZhanHeshen/PointCMT.",
    "descriptor": "\nComments: To appear in NIPS2022\n",
    "authors": [
      "Xu Yan",
      "Heshen Zhan",
      "Chaoda Zheng",
      "Jiantao Gao",
      "Ruimao Zhang",
      "Shuguang Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04208"
  },
  {
    "id": "arXiv:2210.04209",
    "title": "Decomposed Mutual Information Optimization for Generalized Context in  Meta-Reinforcement Learning",
    "abstract": "Adapting to the changes in transition dynamics is essential in robotic\napplications. By learning a conditional policy with a compact context,\ncontext-aware meta-reinforcement learning provides a flexible way to adjust\nbehavior according to dynamics changes. However, in real-world applications,\nthe agent may encounter complex dynamics changes. Multiple confounders can\ninfluence the transition dynamics, making it challenging to infer accurate\ncontext for decision-making. This paper addresses such a challenge by\nDecomposed Mutual INformation Optimization (DOMINO) for context learning, which\nexplicitly learns a disentangled context to maximize the mutual information\nbetween the context and historical trajectories, while minimizing the state\ntransition prediction error. Our theoretical analysis shows that DOMINO can\novercome the underestimation of the mutual information caused by\nmulti-confounded challenges via learning disentangled context and reduce the\ndemand for the number of samples collected in various environments. Extensive\nexperiments show that the context learned by DOMINO benefits both model-based\nand model-free reinforcement learning algorithms for dynamics generalization in\nterms of sample efficiency and performance in unseen environments.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yao Mu",
      "Yuzheng Zhuang",
      "Fei Ni",
      "Bin Wang",
      "Jianyu Chen",
      "Jianye Hao",
      "Ping Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04209"
  },
  {
    "id": "arXiv:2210.04211",
    "title": "Adaptive Control of Unknown Pure Feedback Systems with Pure State  Constraints",
    "abstract": "This paper deals with the tracking control problem for a class of unknown\npure feedback system with pure state constraints on the state variables and\nunknown time-varying bounded disturbances. An adaptive controller is presented\nfor such systems for the very first time. The controller is designed using the\nbackstepping method. While designing it, Barrier Lyapunov Functions is used so\nthat the state variables do not contravene its constraints. In order to cope\nwith the unknown dynamics of the system, an online approximator is designed\nusing a neural network with a novel adaptive law for its weight update. In the\nstability analysis of the system, the time derivative of Lyapunov function\ninvolves known virtual control coefficient with unknown direction and to deal\nwith such problem Nussbaum gain is used to design the control law. Furthermore,\nto make the controller robust and computationally inexpensive, a novel\ndisturbance observer is designed to estimate the disturbance along with neural\nnetwork approximation error and the time derivative of virtual control input.\nThe effectiveness of the proposed approach is demonstrated through a simulation\nstudy on the third-order nonlinear system.",
    "descriptor": "",
    "authors": [
      "Pankaj Kumar Mishra",
      "Nishchal K Verma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04211"
  },
  {
    "id": "arXiv:2210.04212",
    "title": "Migrating from Microservices to Serverless: An IoT Platform Case Study",
    "abstract": "Microservice architecture is the common choice for developing cloud\napplications these days since each individual microservice can be independently\nmodified, replaced, and scaled. As a result, application development and\noperating cloud infrastructure were bundled together into what is now commonly\ncalled DevOps. However, with the increasing popularity of the serverless\ncomputing paradigm and its several advantages such as no infrastructure\nmanagement, a pay-per-use billing policy, and on-demand fine-grained\nautoscaling, there is a growing interest in utilizing FaaS and serverless CaaS\ntechnologies for refactoring microservices-based applications. Towards this, we\nmigrate a complex IoT platform application onto OpenWhisk (OW) and Google Cloud\nRun (GCR). We comprehensively evaluate the performance of the different\ndeployment strategies, i.e., Google Kubernetes Engine (GKE)-Standard, OW, and\nGCR for the IoT platform using different load testing scenarios. Results from\nour experiments show that while GKE standard performs best for most scenarios,\nGCR is always cheaper wrt costs.",
    "descriptor": "\nComments: ACM International Workshop on Serverless Computing 2022 (WoSC@Middleware 2022)\n",
    "authors": [
      "Mohak Chadha",
      "Victor Pacyna",
      "Anshul Jindal",
      "Jianfeng Gu",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04212"
  },
  {
    "id": "arXiv:2210.04213",
    "title": "Towards Understanding and Boosting Adversarial Transferability from a  Distribution Perspective",
    "abstract": "Transferable adversarial attacks against Deep neural networks (DNNs) have\nreceived broad attention in recent years. An adversarial example can be crafted\nby a surrogate model and then attack the unknown target model successfully,\nwhich brings a severe threat to DNNs. The exact underlying reasons for the\ntransferability are still not completely understood. Previous work mostly\nexplores the causes from the model perspective, e.g., decision boundary, model\narchitecture, and model capacity. adversarial attacks against Deep neural\nnetworks (DNNs) have received broad attention in recent years. An adversarial\nexample can be crafted by a surrogate model and then attack the unknown target\nmodel successfully, which brings a severe threat to DNNs. The exact underlying\nreasons for the transferability are still not completely understood. Previous\nwork mostly explores the causes from the model perspective. Here, we\ninvestigate the transferability from the data distribution perspective and\nhypothesize that pushing the image away from its original distribution can\nenhance the adversarial transferability. To be specific, moving the image out\nof its original distribution makes different models hardly classify the image\ncorrectly, which benefits the untargeted attack, and dragging the image into\nthe target distribution misleads the models to classify the image as the target\nclass, which benefits the targeted attack. Towards this end, we propose a novel\nmethod that crafts adversarial examples by manipulating the distribution of the\nimage. We conduct comprehensive transferable attacks against multiple DNNs to\ndemonstrate the effectiveness of the proposed method. Our method can\nsignificantly improve the transferability of the crafted attacks and achieves\nstate-of-the-art performance in both untargeted and targeted scenarios,\nsurpassing the previous best method by up to 40$\\%$ in some cases.",
    "descriptor": "\nComments: \\copyright 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Yao Zhu",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Kejiang Chen",
      "Yuan He",
      "Xiang Tian",
      "Bolun Zheng",
      "Yaowu Chen",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04213"
  },
  {
    "id": "arXiv:2210.04214",
    "title": "Data augmentation for NeRF: a geometric consistent solution based on  view morphing",
    "abstract": "NeRF aims to learn a continuous neural scene representation by using a finite\nset of input images taken from different viewpoints. The fewer the number of\nviewpoints, the higher the likelihood of overfitting on them. This paper\nmitigates such limitation by presenting a novel data augmentation approach to\ngenerate geometrically consistent image transitions between viewpoints using\nview morphing. View morphing is a highly versatile technique that does not\nrequires any prior knowledge about the 3D scene because it is based on general\nprinciples of projective geometry. A key novelty of our method is to use the\nvery same depths predicted by NeRF to generate the image transitions that are\nthen added to NeRF training. We experimentally show that this procedure enables\nNeRF to improve the quality of its synthesised novel views in the case of\ndatasets with few training viewpoints. We improve PSNR up to 1.8dB and 10.5dB\nwhen eight and four views are used for training, respectively. To the best of\nour knowledge, this is the first data augmentation strategy for NeRF that\nexplicitly synthesises additional new input images to improve the model\ngeneralisation.",
    "descriptor": "",
    "authors": [
      "Matteo Bortolon",
      "Alessio Del Bue",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.04214"
  },
  {
    "id": "arXiv:2210.04216",
    "title": "AMPose: Alternatively Mixed Global-Local Attention Model for 3D Human  Pose Estimation",
    "abstract": "The graph convolutional network has been applied to 3D human pose estimation.\nIn addition, the pure transformer model recently show the promising result in\nthe video-base method. However, the single-frame method still need to model the\nphysically connected relations among joints because the feature representation\ntransformed only by the global attention has the lack of the relationships of\nhuman skeleton. We propose a novel architecture to combine the physically\nconnected and global relations among joints in human.\nWe evaluate our method on Human3.6and compare with the state-of-the-art\nmodels. Our model show superior result over all other models. Our model has\nbetter generalization ability by cross-dataset comparison on MPI-INF-3DHP.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Hongxin Lin",
      "Yunwei Chiu",
      "Peiyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.04216"
  },
  {
    "id": "arXiv:2210.04217",
    "title": "Estimating Neural Reflectance Field from Radiance Field using Tree  Structures",
    "abstract": "We present a new method for estimating the Neural Reflectance Field (NReF) of\nan object from a set of posed multi-view images under unknown lighting. NReF\nrepresents 3D geometry and appearance of objects in a disentangled manner, and\nare hard to be estimated from images only. Our method solves this problem by\nexploiting the Neural Radiance Field (NeRF) as a proxy representation, from\nwhich we perform further decomposition. A high-quality NeRF decomposition\nrelies on good geometry information extraction as well as good prior terms to\nproperly resolve ambiguities between different components. To extract\nhigh-quality geometry information from radiance fields, we re-design a new\nray-casting based method for surface point extraction. To efficiently compute\nand apply prior terms, we convert different prior terms into different type of\nfilter operations on the surface extracted from radiance field. We then employ\ntwo type of auxiliary data structures, namely Gaussian KD-tree and octree, to\nsupport fast querying of surface points and efficient computation of surface\nfilters during training. Based on this, we design a multi-stage decomposition\noptimization pipeline for estimating neural reflectance field from neural\nradiance fields. Extensive experiments show our method outperforms other\nstate-of-the-art methods on different data, and enable high-quality free-view\nrelighting as well as material editing tasks.",
    "descriptor": "",
    "authors": [
      "Xiu Li",
      "Xiao Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04217"
  },
  {
    "id": "arXiv:2210.04218",
    "title": "Transformer-based Flood Scene Segmentation for Developing Countries",
    "abstract": "Floods are large-scale natural disasters that often induce a massive number\nof deaths, extensive material damage, and economic turmoil. The effects are\nmore extensive and longer-lasting in high-population and low-resource\ndeveloping countries. Early Warning Systems (EWS) constantly assess water\nlevels and other factors to forecast floods, to help minimize damage.\nPost-disaster, disaster response teams undertake a Post Disaster Needs\nAssessment (PDSA) to assess structural damage and determine optimal strategies\nto respond to highly affected neighbourhoods. However, even today in developing\ncountries, EWS and PDSA analysis of large volumes of image and video data is\nlargely a manual process undertaken by first responders and volunteers. We\npropose FloodTransformer, which to the best of our knowledge, is the first\nvisual transformer-based model to detect and segment flooded areas from aerial\nimages at disaster sites. We also propose a custom metric, Flood Capacity (FC)\nto measure the spatial extent of water coverage and quantify the segmented\nflooded area for EWS and PDSA analyses. We use the SWOC Flood segmentation\ndataset and achieve 0.93 mIoU, outperforming all other methods. We further show\nthe robustness of this approach by validating across unseen flood images from\nother flood data sources.",
    "descriptor": "\nComments: Presented at NeurIPS 2021 Workshop on Machine Learning for the Developing World\n",
    "authors": [
      "Ahan M R",
      "Roshan Roy",
      "Shreyas Sunil Kulkarni",
      "Vaibhav Soni",
      "Ashish Chittora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04218"
  },
  {
    "id": "arXiv:2210.04220",
    "title": "Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect  Category Detection",
    "abstract": "Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of\naspect-based sentiment analysis, which aims to detect aspect categories\naccurately with limited training instances. Recently, dominant works use the\nprototypical network to accomplish this task, and employ the attention\nmechanism to extract keywords of aspect category from the sentences to produce\nthe prototype for each aspect. However, they still suffer from serious noise\nproblems: (1) due to lack of sufficient supervised data, the previous methods\neasily catch noisy words irrelevant to the current aspect category, which\nlargely affects the quality of the generated prototype; (2) the\nsemantically-close aspect categories usually generate similar prototypes, which\nare mutually noisy and confuse the classifier seriously. In this paper, we\nresort to the label information of each aspect to tackle the above problems,\nalong with proposing a novel Label-Driven Denoising Framework (LDF). Extensive\nexperimental results show that our framework achieves better performance than\nother state-of-the-art methods.",
    "descriptor": "\nComments: Finding of EMNLP 2022 camera-ready\n",
    "authors": [
      "Fei Zhao",
      "Yuchen Shen",
      "Zhen Wu",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04220"
  },
  {
    "id": "arXiv:2210.04227",
    "title": "Dual-distribution discrepancy with self-supervised refinement for  anomaly detection in medical images",
    "abstract": "Medical anomaly detection is a crucial yet challenging task aiming at\nrecognizing abnormal images to assist diagnosis. Due to the high-cost\nannotations of abnormal images, most methods utilize only known normal images\nduring training and identify samples not conforming to the normal profile as\nanomalies in the testing phase. A large number of readily available unlabeled\nimages containing anomalies are thus ignored in the training phase, restricting\ntheir performance. To solve this problem, we propose the Dual-distribution\nDiscrepancy for Anomaly Detection (DDAD), utilizing both known normal images\nand unlabeled images. Two modules are designed to model the normative\ndistribution of normal images and the unknown distribution of both normal and\nunlabeled images, respectively, using ensembles of reconstruction networks.\nSubsequently, intra-discrepancy of the normative distribution module, and\ninter-discrepancy between the two modules are designed as anomaly scores.\nFurthermore, an Anormal Score Refinement Net (ASR-Net) trained via\nself-supervised learning is proposed to refine the two anomaly scores. For\nevaluation, five medical datasets including chest X-rays, brain MRIs and\nretinal fundus images are organized as benchmarks. Experiments on these\nbenchmarks demonstrate our method achieves significant gains and outperforms\nstate-of-the-art methods. Code and organized benchmarks will be available at\nhttps://github.com/caiyu6666/DDAD-ASR",
    "descriptor": "\nComments: Under consideration. arXiv admin note: text overlap with arXiv:2206.03935\n",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04227"
  },
  {
    "id": "arXiv:2210.04229",
    "title": "Learning on the Edge: Online Learning with Stochastic Feedback Graphs",
    "abstract": "The framework of feedback graphs is a generalization of sequential\ndecision-making with bandit or full information feedback. In this work, we\nstudy an extension where the directed feedback graph is stochastic, following a\ndistribution similar to the classical Erd\\H{o}s-R\\'enyi model. Specifically, in\neach round every edge in the graph is either realized or not with a distinct\nprobability for each edge. We prove nearly optimal regret bounds of order\n$\\min\\bigl\\{\\min_{\\varepsilon} \\sqrt{(\\alpha_\\varepsilon/\\varepsilon) T},\\,\n\\min_{\\varepsilon} (\\delta_\\varepsilon/\\varepsilon)^{1/3} T^{2/3}\\bigr\\}$\n(ignoring logarithmic factors), where $\\alpha_{\\varepsilon}$ and\n$\\delta_{\\varepsilon}$ are graph-theoretic quantities measured on the support\nof the stochastic feedback graph $\\mathcal{G}$ with edge probabilities\nthresholded at $\\varepsilon$. Our result, which holds without any preliminary\nknowledge about $\\mathcal{G}$, requires the learner to observe only the\nrealized out-neighborhood of the chosen action. When the learner is allowed to\nobserve the realization of the entire graph (but only the losses in the\nout-neighborhood of the chosen action), we derive a more efficient algorithm\nfeaturing a dependence on weighted versions of the independence and weak\ndomination numbers that exhibits improved bounds for some special cases.",
    "descriptor": "",
    "authors": [
      "Emmanuel Esposito",
      "Federico Fusco",
      "Dirk van der Hoeven",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.04229"
  },
  {
    "id": "arXiv:2210.04230",
    "title": "Random Access Protocol with Channel Oracle Enabled by a Reconfigurable  Intelligent Surface",
    "abstract": "The widespread adoption of Reconfigurable Intelligent Surfaces (RISs) in\nfuture practical wireless systems is critically dependent on the design and\nimplementation of efficient access protocols, an issue that has received less\nattention in the research literature. In this paper, we propose a grant-free\nrandom access (RA) protocol for a RIS-assisted wireless communication setting,\nwhere a massive number of users' equipment (UEs) try to access an access point\n(AP). The proposed protocol relies on a channel oracle, which enables the UEs\nto infer the best RIS configurations that provide opportunistic access to UEs.\nThe inference is based on a model created during a training phase with a\ngreatly reduced set of RIS configurations. Specifically, we consider a system\nwhose operation is divided into three blocks: i) a downlink training block,\nwhich trains the model used by the oracle, ii) an uplink access block, where\nthe oracle infers the best access slots, and iii) a downlink acknowledgment\nblock, which provides feedback to the UEs that were successfully decoded by the\nAP during access. Numerical results show that the proper integration of the RIS\ninto the protocol design is able to increase the expected end-to-end throughput\nby approximately 40% regarding the regular repetition slotted ALOHA protocol.",
    "descriptor": "\nComments: 30 pages, 7 figures, journal paper\n",
    "authors": [
      "Victor Croisfelt",
      "Fabio Saggese",
      "Israel Leyva-Mayorga",
      "Rados\u0142aw Kotaba",
      "Gabriele Gradoni",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04230"
  },
  {
    "id": "arXiv:2210.04231",
    "title": "Multi-Robot Trajectory Planning with Feasibility Guarantee and Deadlock  Resolution: An Obstacle-Dense Environment",
    "abstract": "This article presents a multi-robot trajectory planning method which\nguarantees optimization feasibility and resolves deadlocks in an obstacle-dense\nenvironment. The method is proposed via formulating an optimization problem,\nwhere the modified buffered Voronoi cell with warning band is utilized to avoid\nthe inter-robot collision and the deadlock is resolved by an adaptive\nright-hand rule. Meanwhile, a novel safe corridor derived from historical\nplanned trajectory is proposed to provide a proper space for obstacle avoidance\nin trajectory planning. Comparisons with state-of-the-art works are conducted\nto illustrate the safety and deadlock resolution in cluttered scenarios.\nAdditionally, hardware experiments are carried out to verify the performance of\nthe proposed method where eight nano-quadrotors fly through a 0.6m cubic\nframework.",
    "descriptor": "",
    "authors": [
      "Yuda Chen",
      "Chenghan Wang",
      "Zhongkui Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04231"
  },
  {
    "id": "arXiv:2210.04232",
    "title": "Revealing Patient-Reported Experiences in Healthcare from Social Media  using the DAPMAV Framework",
    "abstract": "Understanding patient experience in healthcare is increasingly important and\ndesired by medical professionals in a patient-centred care approach. Healthcare\ndiscourse on social media presents an opportunity to gain a unique perspective\non patient-reported experiences, complementing traditional survey data. These\nsocial media reports often appear as first-hand accounts of patients' journeys\nthrough the healthcare system, whose details extend beyond the confines of\nstructured surveys and at a far larger scale than focus groups. However, in\ncontrast with the vast presence of patient-experience data on social media and\nthe potential benefits the data offers, it attracts comparatively little\nresearch attention due to the technical proficiency required for text analysis.\nIn this paper, we introduce the Design-Acquire-Process-Model-Analyse-Visualise\n(DAPMAV) framework to equip non-technical domain experts with a structured\napproach that will enable them to capture patient-reported experiences from\nsocial media data. We apply this framework in a case study on prostate cancer\ndata from /r/ProstateCancer, demonstrate the framework's value in capturing\nspecific aspects of patient concern (such as sexual dysfunction), provide an\noverview of the discourse, and show narrative and emotional progression through\nthese stories. We anticipate this framework to apply to a wide variety of areas\nin healthcare, including capturing and differentiating experiences across\nminority groups, geographic boundaries, and types of illnesses.",
    "descriptor": "",
    "authors": [
      "Curtis Murray",
      "Lewis Mitchell",
      "Jonathan Tuke",
      "Mark Mackay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04232"
  },
  {
    "id": "arXiv:2210.04233",
    "title": "Robustifying the Multi-Scale Representation of Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) recently emerged as a new paradigm for object\nrepresentation from multi-view (MV) images. Yet, it cannot handle multi-scale\n(MS) images and camera pose estimation errors, which generally is the case with\nmulti-view images captured from a day-to-day commodity camera. Although\nrecently proposed Mip-NeRF could handle multi-scale imaging problems with NeRF,\nit cannot handle camera pose estimation error. On the other hand, the newly\nproposed BARF can solve the camera pose problem with NeRF but fails if the\nimages are multi-scale in nature. This paper presents a robust multi-scale\nneural radiance fields representation approach to simultaneously overcome both\nreal-world imaging issues. Our method handles multi-scale imaging effects and\ncamera-pose estimation problems with NeRF-inspired approaches by leveraging the\nfundamentals of scene rigidity. To reduce unpleasant aliasing artifacts due to\nmulti-scale images in the ray space, we leverage Mip-NeRF multi-scale\nrepresentation. For joint estimation of robust camera pose, we propose\ngraph-neural network-based multiple motion averaging in the neural volume\nrendering framework. We demonstrate, with examples, that for an accurate neural\nrepresentation of an object from day-to-day acquired multi-view images, it is\ncrucial to have precise camera-pose estimates. Without considering robustness\nmeasures in the camera pose estimation, modeling for multi-scale aliasing\nartifacts via conical frustum can be counterproductive. We present extensive\nexperiments on the benchmark datasets to demonstrate that our approach provides\nbetter results than the recent NeRF-inspired approaches for such realistic\nsettings.",
    "descriptor": "\nComments: Accepted for publication at British Machine Vision Conference (BMVC) 2022. Draft info: 13 pages, 3 Figures, and 4 Tables\n",
    "authors": [
      "Nishant Jain",
      "Suryansh Kumar",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04233"
  },
  {
    "id": "arXiv:2210.04234",
    "title": "Understanding and Improving Zero-shot Multi-hop Reasoning in Generative  Question Answering",
    "abstract": "Generative question answering (QA) models generate answers to questions\neither solely based on the parameters of the model (the closed-book setting) or\nadditionally retrieving relevant evidence (the open-book setting). Generative\nQA models can answer some relatively complex questions, but the mechanism\nthrough which they do so is still poorly understood. We perform several studies\naimed at better understanding the multi-hop reasoning capabilities of\ngenerative QA models. First, we decompose multi-hop questions into multiple\ncorresponding single-hop questions, and find marked inconsistency in QA models'\nanswers on these pairs of ostensibly identical question chains. Second, we find\nthat models lack zero-shot multi-hop reasoning ability: when trained only on\nsingle-hop questions, models generalize poorly to multi-hop questions. Finally,\nwe demonstrate that it is possible to improve models' zero-shot multi-hop\nreasoning capacity through two methods that approximate real multi-hop natural\nlanguage (NL) questions by training on either concatenation of single-hop\nquestions or logical forms (SPARQL). In sum, these results demonstrate that\nmulti-hop reasoning does not emerge naturally in generative QA models, but can\nbe encouraged by advances in training or modeling techniques.",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Zhengbao Jiang",
      "Jun Araki",
      "Haibo Ding",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04234"
  },
  {
    "id": "arXiv:2210.04236",
    "title": "Fusing Event-based Camera and Radar for SLAM Using Spiking Neural  Networks with Continual STDP Learning",
    "abstract": "This work proposes a first-of-its-kind SLAM architecture fusing an\nevent-based camera and a Frequency Modulated Continuous Wave (FMCW) radar for\ndrone navigation. Each sensor is processed by a bio-inspired Spiking Neural\nNetwork (SNN) with continual Spike-Timing-Dependent Plasticity (STDP) learning,\nas observed in the brain. In contrast to most learning-based SLAM systems%,\nwhich a) require the acquisition of a representative dataset of the environment\nin which navigation must be performed and b) require an off-line training\nphase, our method does not require any offline training phase, but rather the\nSNN continuously learns features from the input data on the fly via STDP. At\nthe same time, the SNN outputs are used as feature descriptors for loop closure\ndetection and map correction. We conduct numerous experiments to benchmark our\nsystem against state-of-the-art RGB methods and we demonstrate the robustness\nof our DVS-Radar SLAM approach under strong lighting variations.",
    "descriptor": "",
    "authors": [
      "Ali Safa",
      "Tim Verbelen",
      "Ilja Ocket",
      "Andr\u00e9 Bourdoux",
      "Hichem Sahli",
      "Francky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.04236"
  },
  {
    "id": "arXiv:2210.04240",
    "title": "Less is More: Facial Landmarks can Recognize a Spontaneous Smile",
    "abstract": "Smile veracity classification is a task of interpreting social interactions.\nBroadly, it distinguishes between spontaneous and posed smiles. Previous\napproaches used hand-engineered features from facial landmarks or considered\nraw smile videos in an end-to-end manner to perform smile classification tasks.\nFeature-based methods require intervention from human experts on feature\nengineering and heavy pre-processing steps. On the contrary, raw smile video\ninputs fed into end-to-end models bring more automation to the process with the\ncost of considering many redundant facial features (beyond landmark locations)\nthat are mainly irrelevant to smile veracity classification. It remains unclear\nto establish discriminative features from landmarks in an end-to-end manner. We\npresent a MeshSmileNet framework, a transformer architecture, to address the\nabove limitations. To eliminate redundant facial features, our landmarks input\nis extracted from Attention Mesh, a pre-trained landmark detector. Again, to\ndiscover discriminative features, we consider the relativity and trajectory of\nthe landmarks. For the relativity, we aggregate facial landmark that\nconceptually formats a curve at each frame to establish local spatial features.\nFor the trajectory, we estimate the movements of landmark composed features\nacross time by self-attention mechanism, which captures pairwise dependency on\nthe trajectory of the same landmark. This idea allows us to achieve\nstate-of-the-art performances on UVA-NEMO, BBC, MMI Facial Expression, and SPOS\ndatasets.",
    "descriptor": "",
    "authors": [
      "Md. Tahrim Faroque",
      "Yan Yang",
      "Md Zakir Hossain",
      "Sheikh Motahar Naim",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04240"
  },
  {
    "id": "arXiv:2210.04242",
    "title": "Improving Multi-turn Emotional Support Dialogue Generation with  Lookahead Strategy Planning",
    "abstract": "Providing Emotional Support (ES) to soothe people in emotional distress is an\nessential capability in social interactions. Most existing researches on\nbuilding ES conversation systems only considered single-turn interactions with\nusers, which was over-simplified. In comparison, multi-turn ES conversation\nsystems can provide ES more effectively, but face several new technical\nchallenges, including: (1) how to adopt appropriate support strategies to\nachieve the long-term dialogue goal of comforting the user's emotion; (2) how\nto dynamically model the user's state. In this paper, we propose a novel system\nMultiESC to address these issues. For strategy planning, drawing inspiration\nfrom the A* search algorithm, we propose lookahead heuristics to estimate the\nfuture user feedback after using particular strategies, which helps to select\nstrategies that can lead to the best long-term effects. For user state\nmodeling, MultiESC focuses on capturing users' subtle emotional expressions and\nunderstanding their emotion causes. Extensive experiments show that MultiESC\nsignificantly outperforms competitive baselines in both dialogue generation and\nstrategy planning. Our codes are available at\nhttps://github.com/lwgkzl/MultiESC.",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2022\n",
    "authors": [
      "Yi Cheng",
      "Wenge Liu",
      "Wenjie Li",
      "Jiashuo Wang",
      "Ruihui Zhao",
      "Bang Liu",
      "Xiaodan Liang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04242"
  },
  {
    "id": "arXiv:2210.04243",
    "title": "Fine-Tuning Pre-trained Transformers into Decaying Fast Weights",
    "abstract": "Autoregressive Transformers are strong language models but incur O(T)\ncomplexity during per-token generation due to the self-attention mechanism.\nRecent work proposes kernel-based methods to approximate causal self-attention\nby replacing it with recurrent formulations with various update rules and\nfeature maps to achieve O(1) time and memory complexity. We explore these\napproaches and find that they are unnecessarily complex, and propose a simple\nalternative - decaying fast weights - that runs fast on GPU, outperforms prior\nmethods, and retains 99% of attention's performance for GPT-2. We also show\ncompetitive performance on WikiText-103 against more complex attention\nsubstitutes.",
    "descriptor": "",
    "authors": [
      "Huanru Henry Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04243"
  },
  {
    "id": "arXiv:2210.04244",
    "title": "Text detection and recognition based on a lensless imaging system",
    "abstract": "Lensless cameras are characterized by several advantages (e.g.,\nminiaturization, ease of manufacture, and low cost) as compared with\nconventional cameras. However, they have not been extensively employed due to\ntheir poor image clarity and low image resolution, especially for tasks that\nhave high requirements on image quality and details such as text detection and\ntext recognition. To address the problem, a framework of deep-learning-based\npipeline structure was built to recognize text with three steps from raw data\ncaptured by employing lensless cameras. This pipeline structure consisted of\nthe lensless imaging model U-Net, the text detection model connectionist text\nproposal network (CTPN), and the text recognition model convolutional recurrent\nneural network (CRNN). Compared with the method focusing only on image\nreconstruction, UNet in the pipeline was able to supplement the imaging details\nby enhancing factors related to character categories in the reconstruction\nprocess, so the textual information can be more effectively detected and\nrecognized by CTPN and CRNN with fewer artifacts and high-clarity reconstructed\nlensless images. By performing experiments on datasets of different\ncomplexities, the applicability to text detection and recognition on lensless\ncameras was verified. This study reasonably demonstrates text detection and\nrecognition tasks in the lensless camera system,and develops a basic method for\nnovel applications.",
    "descriptor": "",
    "authors": [
      "Yinger Zhang",
      "Zhouyi Wu",
      "Peiying Lin",
      "Yuting Wu",
      "Lusong Wei",
      "Zhengjie Huang",
      "Jiangtao Huangfu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04244"
  },
  {
    "id": "arXiv:2210.04246",
    "title": "Improve Transformer Pre-Training with Decoupled Directional Relative  Position Encoding and Representation Differentiations",
    "abstract": "In this work, we revisit the Transformer-based pre-trained language models\nand identify two problems that may limit the expressiveness of the model.\nFirstly, existing relative position encoding models (e.g., T5 and DEBERTA)\nconfuse two heterogeneous information: relative distance and direction. It may\nmake the model unable to capture the associative semantics of the same\ndirection or the same distance, which in turn affects the performance of\ndownstream tasks. Secondly, we notice the pre-trained BERT with Mask Language\nModeling (MLM) pre-training objective outputs similar token representations and\nattention weights of different heads, which may impose difficulties in\ncapturing discriminative semantic representations. Motivated by the above\ninvestigation, we propose two novel techniques to improve pre-trained language\nmodels: Decoupled Directional Relative Position (DDRP) encoding and MTH\npre-training objective. DDRP decouples the relative distance features and the\ndirectional features in classical relative position encoding for better\nposition information understanding. MTH designs two novel auxiliary losses\nbesides MLM to enlarge the dissimilarities between (a) last hidden states of\ndifferent tokens, and (b) attention weights of different heads, alleviating\nhomogenization and anisotropic problem in representation learning for better\noptimization. Extensive experiments and ablation studies on GLUE benchmark\ndemonstrate the effectiveness of our proposed methods.",
    "descriptor": "",
    "authors": [
      "Haojie Zhang",
      "Mingfei Liang",
      "Ruobing Xie",
      "Zhenlong Sun",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04246"
  },
  {
    "id": "arXiv:2210.04249",
    "title": "Coresets for Relational Data and The Applications",
    "abstract": "A coreset is a small set that can approximately preserve the structure of the\noriginal input data set. Therefore we can run our algorithm on a coreset so as\nto reduce the total computational complexity. Conventional coreset techniques\nassume that the input data set is available to process explicitly. However,\nthis assumption may not hold in real-world scenarios. In this paper, we\nconsider the problem of coresets construction over relational data. Namely, the\ndata is decoupled into several relational tables, and it could be very\nexpensive to directly materialize the data matrix by joining the tables. We\npropose a novel approach called ``aggregation tree with pseudo-cube'' that can\nbuild a coreset from bottom to up. Moreover, our approach can neatly circumvent\nseveral troublesome issues of relational learning problems [Khamis et al., PODS\n2019]. Under some mild assumptions, we show that our coreset approach can be\napplied for the machine learning tasks, such as clustering, logistic regression\nand SVM.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Chen",
      "Qingyuan Yang",
      "Ruomin Huang",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04249"
  },
  {
    "id": "arXiv:2210.04251",
    "title": "State Advantage Weighting for Offline RL",
    "abstract": "We present state advantage weighting for offline reinforcement learning (RL).\nIn contrast to action advantage $A(s,a)$ that we commonly adopt in QSA\nlearning, we leverage state advantage $A(s,s^\\prime)$ and QSS learning for\noffline RL, hence decoupling the action from values. We expect the agent can\nget to the high-reward state and the action is determined by how the agent can\nget to that corresponding state. Experiments on D4RL datasets show that our\nproposed method can achieve remarkable performance against the common\nbaselines. Furthermore, our method shows good generalization capability when\ntransferring from offline to online.",
    "descriptor": "",
    "authors": [
      "Jiafei Lyu",
      "Aicheng Gong",
      "Le Wan",
      "Zongqing Lu",
      "Xiu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04251"
  },
  {
    "id": "arXiv:2210.04252",
    "title": "Precise Single-stage Detector",
    "abstract": "There are still two problems in SDD causing some inaccurate results: (1) In\nthe process of feature extraction, with the layer-by-layer acquisition of\nsemantic information, local information is gradually lost, resulting into less\nrepresentative feature maps; (2) During the Non-Maximum Suppression (NMS)\nalgorithm due to inconsistency in classification and regression tasks, the\nclassification confidence and predicted detection position cannot accurately\nindicate the position of the prediction boxes. Methods: In order to address\nthese aforementioned issues, we propose a new architecture, a modified version\nof Single Shot Multibox Detector (SSD), named Precise Single Stage Detector\n(PSSD). Firstly, we improve the features by adding extra layers to SSD.\nSecondly, we construct a simple and effective feature enhancement module to\nexpand the receptive field step by step for each layer and enhance its local\nand semantic information. Finally, we design a more efficient loss function to\npredict the IOU between the prediction boxes and ground truth boxes, and the\nthreshold IOU guides classification training and attenuates the scores, which\nare used by the NMS algorithm. Main Results: Benefiting from the above\noptimization, the proposed model PSSD achieves exciting performance in\nreal-time. Specifically, with the hardware of Titan Xp and the input size of\n320 pix, PSSD achieves 33.8 mAP at 45 FPS speed on MS COCO benchmark and 81.28\nmAP at 66 FPS speed on Pascal VOC 2007 outperforming state-of-the-art object\ndetection models. Besides, the proposed model performs significantly well with\nlarger input size. Under 512 pix, PSSD can obtain 37.2 mAP with 27 FPS on MS\nCOCO and 82.82 mAP with 40 FPS on Pascal VOC 2007. The experiment results prove\nthat the proposed model has a better trade-off between speed and accuracy.",
    "descriptor": "\nComments: We will submit it soon to the IEEE transaction. Due to characters limitation, we can not upload the full abstract. Please read the pdf file for more detail\n",
    "authors": [
      "Aisha Chandio",
      "Gong Gui",
      "Teerath Kumar",
      "Irfan Ullah",
      "Ramin Ranjbarzadeh",
      "Arunabha M Roy",
      "Akhtar Hussain",
      "Yao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04252"
  },
  {
    "id": "arXiv:2210.04255",
    "title": "Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma  Segmentation and Koos Grade Prediction based on Semi-Supervised Contrastive  Learning",
    "abstract": "Domain adaptation has been widely adopted to transfer styles across\nmulti-vendors and multi-centers, as well as to complement the missing\nmodalities. In this challenge, we proposed an unsupervised domain adaptation\nframework for cross-modality vestibular schwannoma (VS) and cochlea\nsegmentation and Koos grade prediction. We learn the shared representation from\nboth ceT1 and hrT2 images and recover another modality from the latent\nrepresentation, and we also utilize proxy tasks of VS segmentation and brain\nparcellation to restrict the consistency of image structures in domain\nadaptation. After generating missing modalities, the nnU-Net model is utilized\nfor VS and cochlea segmentation, while a semi-supervised contrastive learning\npre-train approach is employed to improve the model performance for Koos grade\nprediction. On CrossMoDA validation phase Leaderboard, our method received rank\n4 in task1 with a mean Dice score of 0.8394 and rank 2 in task2 with\nMacro-Average Mean Square Error of 0.3941. Our code is available at\nhttps://github.com/fiy2W/cmda2022.superpolymerization.",
    "descriptor": "",
    "authors": [
      "Luyi Han",
      "Yunzhi Huang",
      "Tao Tan",
      "Ritse Mann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04255"
  },
  {
    "id": "arXiv:2210.04258",
    "title": "A unit-based symbolic execution method for detecting memory corruption  vulnerabilities in executable codes",
    "abstract": "Memory corruption is a serious class of software vulnerabilities, which\nrequires careful attention to be detected and removed from applications before\ngetting exploited and harming the system users. Symbolic execution is a\nwell-known method for analyzing programs and detecting various vulnerabilities,\ne.g., memory corruption. Although this method is sound and complete in theory,\nit faces some challenges, such as path explosion, when applied to real-world\ncomplex programs. In this paper, we present a method for improving the\nefficiency of symbolic execution and detecting four classes of memory\ncorruption vulnerabilities in executable codes, i.e., heap-based buffer\noverflow, stack-based buffer overflow, use-after-free, and double-free. We\nperform symbolic execution only on test units rather than the whole program to\navoid path explosion. In our method, test units are considered parts of the\nprogram's code, which might contain vulnerable statements and are statically\nidentified based on the specifications of memory corruption vulnerabilities.\nThen, each test unit is symbolically executed to calculate path and\nvulnerability constraints of each statement of the unit, which determine the\nconditions on unit input data for executing that statement or activating\nvulnerabilities in it, respectively. Solving these constraints gives us input\nvalues for the test unit, which execute the desired statements and reveal\nvulnerabilities in them. Finally, we use machine learning to approximate the\ncorrelation between system and unit input data. Thereby, we generate system\ninputs that enter the program, reach vulnerable instructions in the desired\ntest unit, and reveal vulnerabilities in them. This method is implemented as a\nplugin for angr framework and evaluated using a group of benchmark programs.\nThe experiments show its superiority over similar tools in accuracy and\nperformance.",
    "descriptor": "",
    "authors": [
      "Sara Baradaran",
      "Mahdi Heidari",
      "Ali Kamali",
      "Maryam Mouzarani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04258"
  },
  {
    "id": "arXiv:2210.04260",
    "title": "Coresets for Wasserstein Distributionally Robust Optimization Problems",
    "abstract": "Wasserstein distributionally robust optimization (\\textsf{WDRO}) is a popular\nmodel to enhance the robustness of machine learning with ambiguous data.\nHowever, the complexity of \\textsf{WDRO} can be prohibitive in practice since\nsolving its ``minimax'' formulation requires a great amount of computation.\nRecently, several fast \\textsf{WDRO} training algorithms for some specific\nmachine learning tasks (e.g., logistic regression) have been developed.\nHowever, the research on designing efficient algorithms for general large-scale\n\\textsf{WDRO}s is still quite limited, to the best of our knowledge.\n\\textit{Coreset} is an important tool for compressing large dataset, and thus\nit has been widely applied to reduce the computational complexities for many\noptimization problems. In this paper, we introduce a unified framework to\nconstruct the $\\epsilon$-coreset for the general \\textsf{WDRO} problems. Though\nit is challenging to obtain a conventional coreset for \\textsf{WDRO} due to the\nuncertainty issue of ambiguous data, we show that we can compute a ``dual\ncoreset'' by using the strong duality property of \\textsf{WDRO}. Also, the\nerror introduced by the dual coreset can be theoretically guaranteed for the\noriginal \\textsf{WDRO} objective. To construct the dual coreset, we propose a\nnovel grid sampling approach that is particularly suitable for the dual\nformulation of \\textsf{WDRO}. Finally, we implement our coreset approach and\nillustrate its effectiveness for several \\textsf{WDRO} problems in the\nexperiments.",
    "descriptor": "",
    "authors": [
      "Ruomin Huang",
      "Jiawei Huang",
      "Wenjie Liu",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04260"
  },
  {
    "id": "arXiv:2210.04261",
    "title": "Noise-Robust De-Duplication at Scale",
    "abstract": "Identifying near duplicates within large, noisy text corpora has a myriad of\napplications that range from de-duplicating training datasets, reducing privacy\nrisk, and evaluating test set leakage, to identifying reproduced news articles\nand literature within large corpora. Across these diverse applications, the\noverwhelming majority of work relies on N-grams. Limited efforts have been made\nto evaluate how well N-gram methods perform, in part because it is unclear how\none could create an unbiased evaluation dataset for a massive corpus. This\nstudy uses the unique timeliness of historical news wires to create a 27,210\ndocument dataset, with 122,876 positive duplicate pairs, for studying\nnoise-robust de-duplication. The time-sensitivity of news makes comprehensive\nhand labelling feasible - despite the massive overall size of the corpus - as\nduplicates occur within a narrow date range. The study then develops and\nevaluates a range of de-duplication methods: hashing and N-gram overlap (which\npredominate in the literature), a contrastively trained bi-encoder, and a\nre-rank style approach combining a bi- and cross-encoder. The neural approaches\nsignificantly outperform hashing and N-gram overlap. We show that the\nbi-encoder scales well, de-duplicating a 10 million article corpus on a single\nGPU card in a matter of hours. The public release of our NEWS-COPY\nde-duplication dataset will facilitate further research and applications.",
    "descriptor": "",
    "authors": [
      "Emily Silcock",
      "Luca D'Amico-Wong",
      "Jinglin Yang",
      "Melissa Dell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04261"
  },
  {
    "id": "arXiv:2210.04264",
    "title": "CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds",
    "abstract": "We present a novel two-stage fully sparse convolutional 3D object detection\nframework, named CAGroup3D. Our proposed method first generates some\nhigh-quality 3D proposals by leveraging the class-aware local group strategy on\nthe object surface voxels with the same semantic predictions, which considers\nsemantic consistency and diverse locality abandoned in previous bottom-up\napproaches. Then, to recover the features of missed voxels due to incorrect\nvoxel-wise segmentation, we build a fully sparse convolutional RoI pooling\nmodule to directly aggregate fine-grained spatial information from backbone for\nfurther proposal refinement. It is memory-and-computation efficient and can\nbetter encode the geometry-specific features of each 3D proposal. Our model\nachieves state-of-the-art 3D detection performance with remarkable gains of\n+\\textit{3.6\\%} on ScanNet V2 and +\\textit{2.6}\\% on SUN RGB-D in term of\nmAP@0.25. Code will be available at https://github.com/Haiyang-W/CAGroup3D.",
    "descriptor": "\nComments: Accept by NeurIPS2022\n",
    "authors": [
      "Haiyang Wang",
      "Lihe Ding",
      "Shaocong Dong",
      "Shaoshuai Shi",
      "Aoxue Li",
      "Jianan Li",
      "Zhenguo Li",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04264"
  },
  {
    "id": "arXiv:2210.04265",
    "title": "3D Reconstruction of Sculptures from Single Images via Unsupervised  Domain Adaptation on Implicit Models",
    "abstract": "Acquiring the virtual equivalent of exhibits, such as sculptures, in virtual\nreality (VR) museums, can be labour-intensive and sometimes infeasible. Deep\nlearning based 3D reconstruction approaches allow us to recover 3D shapes from\n2D observations, among which single-view-based approaches can reduce the need\nfor human intervention and specialised equipment in acquiring 3D sculptures for\nVR museums. However, there exist two challenges when attempting to use the\nwell-researched human reconstruction methods: limited data availability and\ndomain shift. Considering sculptures are usually related to humans, we propose\nour unsupervised 3D domain adaptation method for adapting a single-view 3D\nimplicit reconstruction model from the source (real-world humans) to the target\n(sculptures) domain. We have compared the generated shapes with other methods\nand conducted ablation studies as well as a user study to demonstrate the\neffectiveness of our adaptation method. We also deploy our results in a VR\napplication.",
    "descriptor": "",
    "authors": [
      "Ziyi Chang",
      "George Alex Koulieris",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04265"
  },
  {
    "id": "arXiv:2210.04266",
    "title": "Does Thermal Really Always Matter for RGB-T Salient Object Detection?",
    "abstract": "In recent years, RGB-T salient object detection (SOD) has attracted\ncontinuous attention, which makes it possible to identify salient objects in\nenvironments such as low light by introducing thermal image. However, most of\nthe existing RGB-T SOD models focus on how to perform cross-modality feature\nfusion, ignoring whether thermal image is really always matter in SOD task.\nStarting from the definition and nature of this task, this paper rethinks the\nconnotation of thermal modality, and proposes a network named TNet to solve the\nRGB-T SOD task. In this paper, we introduce a global illumination estimation\nmodule to predict the global illuminance score of the image, so as to regulate\nthe role played by the two modalities. In addition, considering the role of\nthermal modality, we set up different cross-modality interaction mechanisms in\nthe encoding phase and the decoding phase. On the one hand, we introduce a\nsemantic constraint provider to enrich the semantics of thermal images in the\nencoding phase, which makes thermal modality more suitable for the SOD task. On\nthe other hand, we introduce a two-stage localization and complementation\nmodule in the decoding phase to transfer object localization cue and internal\nintegrity cue in thermal features to the RGB modality. Extensive experiments on\nthree datasets show that the proposed TNet achieves competitive performance\ncompared with 20 state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IEEE Trans. Multimedia 2022, 13 pages, 9 figures\n",
    "authors": [
      "Runmin Cong",
      "Kepu Zhang",
      "Chen Zhang",
      "Feng Zheng",
      "Yao Zhao",
      "Qingming Huang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04266"
  },
  {
    "id": "arXiv:2210.04267",
    "title": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "abstract": "Pre-training large neural language models, such as BERT, has led to\nimpressive gains on many natural language processing (NLP) tasks. Although this\nmethod has proven to be effective for many domains, it might not always provide\ndesirable benefits. In this paper we study the effects of hateful pre-training\non low resource hate speech classification tasks. While previous studies on\nEnglish language have emphasized its importance, we aim to to augment their\nobservations with some non-obvious insights. We evaluate different variations\nof tweet based BERT models pre-trained on hateful, non-hateful and mixed\nsubsets of 40M tweet dataset. This evaluation is carried for Indian languages\nHindi and Marathi. This paper is an empirical evidence that hateful\npre-training is not the best pre-training option for hate speech detection. We\nshow that pre-training on non-hateful text from target domain provides similar\nor better results. Further, we introduce HindTweetBERT and MahaTweetBERT, the\nfirst publicly available BERT models pre-trained on Hindi and Marathi tweets\nrespectively. We show that they provide state-of-the-art performance on hate\nspeech classification tasks. We also release a gold hate speech evaluation\nbenchmark HateEval-Hi and HateEval-Mr consisting of manually labeled 2000\ntweets each.",
    "descriptor": "",
    "authors": [
      "Shantanu Patankar",
      "Omkar Gokhale",
      "Aditya Kane",
      "Tanmay Chavan",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04267"
  },
  {
    "id": "arXiv:2210.04271",
    "title": "Sketched Multi-view Subspace Learning for Hyperspectral Anomalous Change  Detection",
    "abstract": "In recent years, multi-view subspace learning has been garnering increasing\nattention. It aims to capture the inner relationships of the data that are\ncollected from multiple sources by learning a unified representation. In this\nway, comprehensive information from multiple views is shared and preserved for\nthe generalization processes. As a special branch of temporal series\nhyperspectral image (HSI) processing, the anomalous change detection task\nfocuses on detecting very small changes among different temporal images.\nHowever, when the volume of datasets is very large or the classes are\nrelatively comprehensive, existing methods may fail to find those changes\nbetween the scenes, and end up with terrible detection results. In this paper,\ninspired by the sketched representation and multi-view subspace learning, a\nsketched multi-view subspace learning (SMSL) model is proposed for HSI\nanomalous change detection. The proposed model preserves major information from\nthe image pairs and improves computational complexity by using a sketched\nrepresentation matrix. Furthermore, the differences between scenes are\nextracted by utilizing the specific regularizer of the self-representation\nmatrices. To evaluate the detection effectiveness of the proposed SMSL model,\nexperiments are conducted on a benchmark hyperspectral remote sensing dataset\nand a natural hyperspectral dataset, and compared with other state-of-the art\napproaches.",
    "descriptor": "",
    "authors": [
      "Shizhen Chang",
      "Michael Kopp",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04271"
  },
  {
    "id": "arXiv:2210.04275",
    "title": "Research Software Engineers: Career Entry Points and Training Gaps",
    "abstract": "As software has become more essential to research across disciplines, and as\nthe recognition of this fact has grown, the importance of professionalizing the\ndevelopment and maintenance of this software has also increased. The community\nof software professionals who work on this software have come together under\nthe title Research Software Engineer (RSE) over the last decade. This has led\nto the formalization of RSE roles and organized RSE groups in universities,\nnational labs, and industry. This, in turn, has created the need to understand\nhow RSEs come into this profession and into these groups, how to further\npromote this career path to potential members, as well as the need to\nunderstand what training gaps need to be filled for RSEs coming from different\nentry points. We have categorized three main classifications of entry paths\ninto the RSE profession and identified key elements, both advantages and\ndisadvantages, that should be acknowledged and addressed by the broader\nresearch community in order to attract and retain a talented and diverse pool\nof future RSEs.",
    "descriptor": "\nComments: Submitted to IEEE Computing in Science & Engineering (CiSE): Special Issue on the Future of Research Software Engineers in the US\n",
    "authors": [
      "Ian A. Cosden",
      "Kenton McHenry",
      "Daniel S. Katz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04275"
  },
  {
    "id": "arXiv:2210.04277",
    "title": "Event-Driven Tactile Learning with Various Location Spiking Neurons",
    "abstract": "Tactile sensing is essential for a variety of daily tasks. New advances in\nevent-driven tactile sensors and Spiking Neural Networks (SNNs) spur the\nresearch in related fields. However, SNN-enabled event-driven tactile learning\nis still in its infancy due to the limited representation abilities of existing\nspiking neurons and high spatio-temporal complexity in the data. In this paper,\nto improve the representation capability of existing spiking neurons, we\npropose a novel neuron model called \"location spiking neuron\", which enables us\nto extract features of event-based data in a novel way. Specifically, based on\nthe classical Time Spike Response Model (TSRM), we develop the Location Spike\nResponse Model (LSRM). In addition, based on the most commonly-used Time Leaky\nIntegrate-and-Fire (TLIF) model, we develop the Location Leaky\nIntegrate-and-Fire (LLIF) model. By exploiting the novel location spiking\nneurons, we propose several models to capture the complex spatio-temporal\ndependencies in the event-driven tactile data. Extensive experiments\ndemonstrate the significant improvements of our models over other works on\nevent-driven tactile learning and show the superior energy efficiency of our\nmodels and location spiking neurons, which may unlock their potential on\nneuromorphic hardware.",
    "descriptor": "\nComments: under review. arXiv admin note: substantial text overlap with arXiv:2209.01080\n",
    "authors": [
      "Peng Kang",
      "Srutarshi Banerjee",
      "Henry Chopp",
      "Aggelos Katsaggelos",
      "Oliver Cossairt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04277"
  },
  {
    "id": "arXiv:2210.04284",
    "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency  of Adapters",
    "abstract": "Adapter Tuning, which freezes the pretrained language models (PLMs) and only\nfine-tunes a few extra modules, becomes an appealing efficient alternative to\nthe full model fine-tuning. Although computationally efficient, the recent\nAdapters often increase parameters (e.g. bottleneck dimension) for matching the\nperformance of full model fine-tuning, which we argue goes against their\noriginal intention. In this work, we re-examine the parameter-efficiency of\nAdapters through the lens of network pruning (we name such plug-in concept as\n\\texttt{SparseAdapter}) and find that SparseAdapter can achieve comparable or\nbetter performance than standard Adapters when the sparse ratio reaches up to\n80\\%. Based on our findings, we introduce an easy but effective setting\n``\\textit{Large-Sparse}'' to improve the model capacity of Adapters under the\nsame parameter budget. Experiments on five competitive Adapters upon three\nadvanced PLMs show that with proper sparse method (e.g. SNIP) and ratio (e.g.\n40\\%) SparseAdapter can consistently outperform their corresponding\ncounterpart. Encouragingly, with the \\textit{Large-Sparse} setting, we can\nobtain further appealing gains, even outperforming the full fine-tuning by a\nlarge margin. Our code will be released at:\n\\url{https://github.com/Shwai-He/SparseAdapter}.",
    "descriptor": "",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Miao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04284"
  },
  {
    "id": "arXiv:2210.04287",
    "title": "Learning to Decompose Visual Features with Latent Textual Prompts",
    "abstract": "Recent advances in pre-training vision-language models like CLIP have shown\ngreat potential in learning transferable visual representations. Nonetheless,\nfor downstream inference, CLIP-like models suffer from either 1) degraded\naccuracy and robustness in the case of inaccurate text descriptions during\nretrieval-based inference (the challenge for zero-shot protocol); or 2)\nbreaking the well-established vision-language alignment (the challenge for\nlinear probing). To address them, we propose Decomposed Feature Prompting\n(DeFo). DeFo leverages a flexible number of learnable embeddings as textual\ninput while maintaining the vision-language dual-model architecture, which\nenables the model to learn decomposed visual features with the help of\nfeature-level textual prompts. We further use an additional linear layer to\nperform classification, allowing a scalable size of language inputs. Our\nempirical study shows DeFo's significance in improving the vision-language\nmodels. For example, DeFo obtains 73.2% test accuracy on ImageNet with a\nResNet-50 backbone without tuning any pretrained weights of both the vision and\nlanguage encoder, outperforming zero-shot CLIP by a large margin of 15.0%, and\noutperforming state-of-the-art vision-language prompt tuning method by 7.6%.",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Manling Li",
      "Xudong Lin",
      "Hairong Lv",
      "Alexander G. Schwing",
      "Heng Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04287"
  },
  {
    "id": "arXiv:2210.04288",
    "title": "CoopHash: Cooperative Learning of Multipurpose Descriptor and  Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image  Hashing",
    "abstract": "Leveraging supervised information can lead to superior retrieval performance\nin the image hashing domain but the performance degrades significantly without\nenough labeled data. One effective solution to boost the performance is to\nemploy generative models, such as Generative Adversarial Networks (GANs), to\ngenerate synthetic data in an image hashing model. However, GAN-based methods\nare difficult to train and suffer from mode collapse issue, which prevents the\nhashing approaches from jointly training the generative models and the hash\nfunctions. This limitation results in sub-optimal retrieval performance. To\novercome this limitation, we propose a novel framework, the generative\ncooperative hashing network (CoopHash), which is based on the energy-based\ncooperative learning. CoopHash jointly learns a powerful generative\nrepresentation of the data and a robust hash function. CoopHash has two\ncomponents: a top-down contrastive pair generator that synthesizes contrastive\nimages and a bottom-up multipurpose descriptor that simultaneously represents\nthe images from multiple perspectives, including probability density, hash\ncode, latent code, and category. The two components are jointly learned via a\nnovel likelihood-based cooperative learning scheme. We conduct experiments on\nseveral real-world datasets and show that the proposed method outperforms the\ncompeting hashing supervised methods, achieving up to 10% relative improvement\nover the current state-of-the-art supervised hashing methods, and exhibits a\nsignificantly better performance in out-of-distribution retrieval.",
    "descriptor": "",
    "authors": [
      "Khoa D. Doan",
      "Jianwen Xie",
      "Yaxuan Zhu",
      "Yang Zhao",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04288"
  },
  {
    "id": "arXiv:2210.04290",
    "title": "Low Light Video Enhancement by Learning on Static Videos with  Cross-Frame Attention",
    "abstract": "The design of deep learning methods for low light video enhancement remains a\nchallenging problem owing to the difficulty in capturing low light and ground\ntruth video pairs. This is particularly hard in the context of dynamic scenes\nor moving cameras where a long exposure ground truth cannot be captured. We\napproach this problem by training a model on static videos such that the model\ncan generalize to dynamic videos. Existing methods adopting this approach\noperate frame by frame and do not exploit the relationships among neighbouring\nframes. We overcome this limitation through a selfcross dilated attention\nmodule that can effectively learn to use information from neighbouring frames\neven when dynamics between the frames are different during training and test\ntimes. We validate our approach through experiments on multiple datasets and\nshow that our method outperforms other state-of-the-art video enhancement\nalgorithms when trained only on static videos.",
    "descriptor": "",
    "authors": [
      "Shivam Chhirolya",
      "Sameer Malik",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04290"
  },
  {
    "id": "arXiv:2210.04294",
    "title": "Skeleton2Humanoid: Animating Simulated Characters for  Physically-plausible Motion In-betweening",
    "abstract": "Human motion synthesis is a long-standing problem with various applications\nin digital twins and the Metaverse. However, modern deep learning based motion\nsynthesis approaches barely consider the physical plausibility of synthesized\nmotions and consequently they usually produce unrealistic human motions. In\norder to solve this problem, we propose a system ``Skeleton2Humanoid'' which\nperforms physics-oriented motion correction at test time by regularizing\nsynthesized skeleton motions in a physics simulator. Concretely, our system\nconsists of three sequential stages: (I) test time motion synthesis network\nadaptation, (II) skeleton to humanoid matching and (III) motion imitation based\non reinforcement learning (RL). Stage I introduces a test time adaptation\nstrategy, which improves the physical plausibility of synthesized human\nskeleton motions by optimizing skeleton joint locations. Stage II performs an\nanalytical inverse kinematics strategy, which converts the optimized human\nskeleton motions to humanoid robot motions in a physics simulator, then the\nconverted humanoid robot motions can be served as reference motions for the RL\npolicy to imitate. Stage III introduces a curriculum residual force control\npolicy, which drives the humanoid robot to mimic complex converted reference\nmotions in accordance with the physical law. We verify our system on a typical\nhuman motion synthesis task, motion-in-betweening. Experiments on the\nchallenging LaFAN1 dataset show our system can outperform prior methods\nsignificantly in terms of both physical plausibility and accuracy. Code will be\nreleased for research purposes at:\nhttps://github.com/michaelliyunhao/Skeleton2Humanoid",
    "descriptor": "\nComments: Accepted by ACMMM2022\n",
    "authors": [
      "Yunhao Li",
      "Zhenbo Yu",
      "Yucheng Zhu",
      "Bingbing Ni",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04294"
  },
  {
    "id": "arXiv:2210.04296",
    "title": "Regularizing Score-based Models with Score Fokker-Planck Equations",
    "abstract": "Score-based generative models learn a family of noise-conditional score\nfunctions corresponding to the data density perturbed with increasingly large\namounts of noise. These pertubed data densities are tied together by the\nFokker-Planck equation (FPE), a PDE governing the spatial-temporal evolution of\na density undergoing a diffusion process. In this work, we derive a\ncorresponding equation characterizing the noise-conditional scores of the\nperturbed data densities (i.e., their gradients), termed the score FPE.\nSurprisingly, despite impressive empirical performance, we observe that scores\nlearned via denoising score matching (DSM) do not satisfy the underlying score\nFPE. We mathematically analyze two implications of satisfying the score FPE and\na potential explanation for why the score FPE is not satisfied in practice. At\nlast, we propose to regularize the DSM objective to enforce satisfaction of the\nscore FPE, and show its effectiveness on synthetic data and MNIST.",
    "descriptor": "",
    "authors": [
      "Chieh-Hsin Lai",
      "Yuhta Takida",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04296"
  },
  {
    "id": "arXiv:2210.04297",
    "title": "Optimal Control for Platooning in Vehicular Networks",
    "abstract": "Truck platooning has recently gained attention as the automotive industry\ndevelops toward autonomous driving systems and vehicular networks. Recent\nresearch in this area has focused on the aerodynamics, network stability, and\nlongitudinal control of platoons. However, the system aspects (e.g., platoon\ncoordination) are still not well explored. This paper studies a platooning\ncoordination problem that decides whether or not trucks waiting at an initial\nlocation (station) should wait for a platoon to arrive in order to leave.\nArrivals of trucks at the station and platoons by the station are independent,\nand Bernoulli distributed. We use the theory of Markov decision processes to\nformulate the dispatching control problem and derive the optimal policy to\ngovern the dispatching of trucks with platoons. It is shown that the policy\nthat minimizes the dispatching control at the station is a threshold policy.\nNumerical results for the average cost case are presented. They are consistent\nwith the theoretical ones.",
    "descriptor": "",
    "authors": [
      "Thiago S. Gomides",
      "Evangelos Kranakis",
      "Ioannis Lambadaris",
      "Yannis Viniotis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04297"
  },
  {
    "id": "arXiv:2210.04302",
    "title": "Equivalency of Optimality Criteria of Markov Decision Process and Model  Predictive Control",
    "abstract": "This paper shows that the optimal policy and value functions of a Markov\nDecision Process (MDP), either discounted or not, can be captured by a\nfinite-horizon undiscounted Optimal Control Problem (OCP), even if based on an\ninexact model. This can be achieved by selecting a proper stage cost and\nterminal cost for the OCP. A very useful particular case of OCP is a Model\nPredictive Control (MPC) scheme where a deterministic (possibly nonlinear)\nmodel is used to limit the computational complexity. In practice, Reinforcement\nLearning algorithms can then be used to tune the parameterized MPC scheme. We\nverify the proposed theorems analytically in an LQR case and we investigate\nsome other nonlinear examples in simulations.",
    "descriptor": "\nComments: 11 pages and 13 figures\n",
    "authors": [
      "Arash Bahari Kordabad",
      "Mario Zanon",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04302"
  },
  {
    "id": "arXiv:2210.04303",
    "title": "Are All Vision Models Created Equal? A Study of the Open-Loop to  Closed-Loop Causality Gap",
    "abstract": "There is an ever-growing zoo of modern neural network models that can\nefficiently learn end-to-end control from visual observations. These advanced\ndeep models, ranging from convolutional to patch-based networks, have been\nextensively tested on offline image classification and regression tasks. In\nthis paper, we study these vision architectures with respect to the open-loop\nto closed-loop causality gap, i.e., offline training followed by an online\nclosed-loop deployment. This causality gap typically emerges in robotics\napplications such as autonomous driving, where a network is trained to imitate\nthe control commands of a human. In this setting, two situations arise: 1)\nClosed-loop testing in-distribution, where the test environment shares\nproperties with those of offline training data. 2) Closed-loop testing under\ndistribution shifts and out-of-distribution. Contrary to recently reported\nresults, we show that under proper training guidelines, all vision models\nperform indistinguishably well on in-distribution deployment, resolving the\ncausality gap. In situation 2, We observe that the causality gap disrupts\nperformance regardless of the choice of the model architecture. Our results\nimply that the causality gap can be solved in situation one with our proposed\ntraining guideline with any modern network architecture, whereas achieving\nout-of-distribution generalization (situation two) requires further\ninvestigations, for instance, on data diversity rather than the model\narchitecture.",
    "descriptor": "",
    "authors": [
      "Mathias Lechner",
      "Ramin Hasani",
      "Alexander Amini",
      "Tsun-Hsuan Wang",
      "Thomas A. Henzinger",
      "Daniela Rus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04303"
  },
  {
    "id": "arXiv:2210.04307",
    "title": "KSAT: Knowledge-infused Self Attention Transformer -- Integrating  Multiple Domain-Specific Contexts",
    "abstract": "Domain-specific language understanding requires integrating multiple pieces\nof relevant contextual information. For example, we see both suicide and\ndepression-related behavior (multiple contexts) in the text ``I have a gun and\nfeel pretty bad about my life, and it wouldn't be the worst thing if I didn't\nwake up tomorrow''. Domain specificity in self-attention architectures is\nhandled by fine-tuning on excerpts from relevant domain specific resources\n(datasets and external knowledge - medical textbook chapters on mental health\ndiagnosis related to suicide and depression). We propose a modified\nself-attention architecture Knowledge-infused Self Attention Transformer (KSAT)\nthat achieves the integration of multiple domain-specific contexts through the\nuse of external knowledge sources. KSAT introduces knowledge-guided biases in\ndedicated self-attention layers for each knowledge source to accomplish this.\nIn addition, KSAT provides mechanics for controlling the trade-off between\nlearning from data and learning from knowledge. Our quantitative and\nqualitative evaluations show that (1) the KSAT architecture provides novel\nhuman-understandable ways to precisely measure and visualize the contributions\nof the infused domain contexts, and (2) KSAT performs competitively with other\nknowledge-infused baselines and significantly outperforms baselines that use\nfine-tuning for domain-specific tasks.",
    "descriptor": "",
    "authors": [
      "Kaushik Roy",
      "Yuxin Zi",
      "Vignesh Narayanan",
      "Manas Gaur",
      "Amit Sheth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04307"
  },
  {
    "id": "arXiv:2210.04308",
    "title": "Privacy-preserving Intelligent Resource Allocation for Federated Edge  Learning in Quantum Internet",
    "abstract": "Federated edge learning (FEL) is a promising paradigm of distributed machine\nlearning that can preserve data privacy while training the global model\ncollaboratively. However, FEL is still facing model confidentiality issues due\nto eavesdropping risks of exchanging cryptographic keys through traditional\nencryption schemes. Therefore, in this paper, we propose a hierarchical\narchitecture for quantum-secured FEL systems with ideal security based on the\nquantum key distribution (QKD) to facilitate public key and model encryption\nagainst eavesdropping attacks. Specifically, we propose a stochastic resource\nallocation model for efficient QKD to encrypt FEL keys and models. In FEL\nsystems, remote FEL workers are connected to cluster heads via quantum-secured\nchannels to train an aggregated global model collaboratively. However, due to\nthe unpredictable number of workers at each location, the demand for secret-key\nrates to support secure model transmission to the server is unpredictable. The\nproposed systems need to efficiently allocate limited QKD resources (i.e.,\nwavelengths) such that the total cost is minimized in the presence of\nstochastic demand by formulating the optimization problem for the proposed\narchitecture as a stochastic programming model. To this end, we propose a\nfederated reinforcement learning-based resource allocation scheme to solve the\nproposed model without complete state information. The proposed scheme enables\nQKD managers and controllers to train a global QKD resource allocation policy\nwhile keeping their private experiences local. Numerical results demonstrate\nthat the proposed schemes can successfully achieve the cost-minimizing\nobjective under uncertain demand while improving the training efficiency by\nabout 50\\% compared to state-of-the-art schemes.",
    "descriptor": "",
    "authors": [
      "Minrui Xu",
      "Dusit Niyato",
      "Zhaohui Yang",
      "Zehui Xiong",
      "Jiawen Kang",
      "Dong In Kim",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04308"
  },
  {
    "id": "arXiv:2210.04310",
    "title": "An Instance Selection Algorithm for Big Data in High imbalanced datasets  based on LSH",
    "abstract": "Training of Machine Learning (ML) models in real contexts often deals with\nbig data sets and high-class imbalance samples where the class of interest is\nunrepresented (minority class). Practical solutions using classical ML models\naddress the problem of large data sets using parallel/distributed\nimplementations of training algorithms, approximate model-based solutions, or\napplying instance selection (IS) algorithms to eliminate redundant information.\nHowever, the combined problem of big and high imbalanced datasets has been less\naddressed. This work proposes three new methods for IS to be able to deal with\nlarge and imbalanced data sets. The proposed methods use Locality Sensitive\nHashing (LSH) as a base clustering technique, and then three different sampling\nmethods are applied on top of the clusters (or buckets) generated by LSH. The\nalgorithms were developed in the Apache Spark framework, guaranteeing their\nscalability. The experiments carried out in three different datasets suggest\nthat the proposed IS methods can improve the performance of a base ML model\nbetween 5% and 19% in terms of the geometric mean.",
    "descriptor": "\nComments: 23 pages, 15 figures\n",
    "authors": [
      "Germ\u00e1n E. Melo-Acosta",
      "Freddy Duitama-Mu\u00f1oz",
      "Juli\u00e1n D. Arias-Londo\u00f1o"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.04310"
  },
  {
    "id": "arXiv:2210.04311",
    "title": "Pruning Adversarially Robust Neural Networks without Adversarial  Examples",
    "abstract": "Adversarial pruning compresses models while preserving robustness. Current\nmethods require access to adversarial examples during pruning. This\nsignificantly hampers training efficiency. Moreover, as new adversarial attacks\nand training methods develop at a rapid rate, adversarial pruning methods need\nto be modified accordingly to keep up. In this work, we propose a novel\nframework to prune a previously trained robust neural network while maintaining\nadversarial robustness, without further generating adversarial examples. We\nleverage concurrent self-distillation and pruning to preserve knowledge in the\noriginal model as well as regularizing the pruned model via the Hilbert-Schmidt\nInformation Bottleneck. We comprehensively evaluate our proposed framework and\nshow its superior performance in terms of both adversarial robustness and\nefficiency when pruning architectures trained on the MNIST, CIFAR-10, and\nCIFAR-100 datasets against five state-of-the-art attacks. Code is available at\nhttps://github.com/neu-spiral/PwoA/.",
    "descriptor": "\nComments: Published at ICDM 2022 as a conference paper\n",
    "authors": [
      "Tong Jian",
      "Zifeng Wang",
      "Yanzhi Wang",
      "Jennifer Dy",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04311"
  },
  {
    "id": "arXiv:2210.04313",
    "title": "On the Need of Analog Signals and Systems for Digital-Twin  Representations",
    "abstract": "We consider the task of converting different digital descriptions of analog\nbandlimited signals and systems into each other, with a rigorous application of\nmathematical computability theory. Albeit very fundamental, the problem appears\nin the scope of digital twinning, an emerging concept in the field of digital\nprocessing of analog information that is regularly mentioned as one of the key\nenablers for next-generation cyber-physical systems and their areas of\napplication. In this context, we prove that essential quantities such as the\npeak-to-average power ratio and the bounded-input/bounded-output norm, which\ndetermine the behavior of the real-world analog system, cannot generally be\ndetermined from the system's digital twin, depending on which of the\nabove-mentioned descriptions is chosen. As a main result, we characterize the\nalgorithmic strength of Shannon's sampling type representation as digital twin\nimplementation and also introduce a new digital twin implementation of analog\nsignals and systems. We show there exist two digital descriptions, both of\nwhich uniquely characterize a certain analog system, such that one description\ncan be algorithmically converted into the other, but not vice versa.",
    "descriptor": "",
    "authors": [
      "Holger Boche",
      "Ullrich J. M\u00f6nich",
      "Yannik N. B\u00f6ck",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04313"
  },
  {
    "id": "arXiv:2210.04317",
    "title": "A Spectral Approach to Item Response Theory",
    "abstract": "The Rasch model is one of the most fundamental models in \\emph{item response\ntheory} and has wide-ranging applications from education testing to\nrecommendation systems. In a universe with $n$ users and $m$ items, the Rasch\nmodel assumes that the binary response $X_{li} \\in \\{0,1\\}$ of a user $l$ with\nparameter $\\theta^*_l$ to an item $i$ with parameter $\\beta^*_i$ (e.g., a user\nlikes a movie, a student correctly solves a problem) is distributed as\n$\\Pr(X_{li}=1) = 1/(1 + \\exp{-(\\theta^*_l - \\beta^*_i)})$. In this paper, we\npropose a \\emph{new item estimation} algorithm for this celebrated model (i.e.,\nto estimate $\\beta^*$). The core of our algorithm is the computation of the\nstationary distribution of a Markov chain defined on an item-item graph. We\ncomplement our algorithmic contributions with finite-sample error guarantees,\nthe first of their kind in the literature, showing that our algorithm is\nconsistent and enjoys favorable optimality properties. We discuss practical\nmodifications to accelerate and robustify the algorithm that practitioners can\nadopt. Experiments on synthetic and real-life datasets, ranging from small\neducation testing datasets to large recommendation systems datasets show that\nour algorithm is scalable, accurate, and competitive with the most commonly\nused methods in the literature.",
    "descriptor": "",
    "authors": [
      "Duc Nguyen",
      "Anderson Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04317"
  },
  {
    "id": "arXiv:2210.04319",
    "title": "Dissecting adaptive methods in GANs",
    "abstract": "Adaptive methods are a crucial component widely used for training generative\nadversarial networks (GANs). While there has been some work to pinpoint the\n\"marginal value of adaptive methods\" in standard tasks, it remains unclear why\nthey are still critical for GAN training. In this paper, we formally study how\nadaptive methods help train GANs; inspired by the grafting method proposed in\narXiv:2002.11803 [cs.LG], we separate the magnitude and direction components of\nthe Adam updates, and graft them to the direction and magnitude of SGDA updates\nrespectively. By considering an update rule with the magnitude of the Adam\nupdate and the normalized direction of SGD, we empirically show that the\nadaptive magnitude of Adam is key for GAN training. This motivates us to have a\ncloser look at the class of normalized stochastic gradient descent ascent\n(nSGDA) methods in the context of GAN training. We propose a synthetic\ntheoretical framework to compare the performance of nSGDA and SGDA for GAN\ntraining with neural networks. We prove that in that setting, GANs trained with\nnSGDA recover all the modes of the true distribution, whereas the same networks\ntrained with SGDA (and any learning rate configuration) suffer from mode\ncollapse. The critical insight in our analysis is that normalizing the\ngradients forces the discriminator and generator to be updated at the same\npace. We also experimentally show that for several datasets, Adam's performance\ncan be recovered with nSGDA methods.",
    "descriptor": "",
    "authors": [
      "Samy Jelassi",
      "David Dobre",
      "Arthur Mensch",
      "Yuanzhi Li",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04319"
  },
  {
    "id": "arXiv:2210.04320",
    "title": "QAScore -- An Unsupervised Unreferenced Metric for the Question  Generation Evaluation",
    "abstract": "Question Generation (QG) aims to automate the task of composing questions for\na passage with a set of chosen answers found within the passage. In recent\nyears, the introduction of neural generation models has resulted in substantial\nimprovements of automatically generated questions in terms of quality,\nespecially compared to traditional approaches that employ manually crafted\nheuristics. However, the metrics commonly applied in QG evaluations have been\ncriticized for their low agreement with human judgement. We therefore propose a\nnew reference-free evaluation metric that has the potential to provide a better\nmechanism for evaluating QG systems, called QAScore. Instead of fine-tuning a\nlanguage model to maximize its correlation with human judgements, QAScore\nevaluates a question by computing the cross entropy according to the\nprobability that the language model can correctly generate the masked words in\nthe answer to that question. Furthermore, we conduct a new crowd-sourcing human\nevaluation experiment for the QG evaluation to investigate how QAScore and\nother metrics can correlate with human judgements. Experiments show that\nQAScore obtains a stronger correlation with the results of our proposed human\nevaluation method compared to existing traditional word-overlap-based metrics\nsuch as BLEU and ROUGE, as well as the existing pretrained-model-based metric\nBERTScore.",
    "descriptor": "\nComments: 19 pages, 5 figures, 7 tables\n",
    "authors": [
      "Tianbo Ji",
      "Chenyang Lyu",
      "Gareth Jones",
      "Liting Zhou",
      "Yvette Graham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04320"
  },
  {
    "id": "arXiv:2210.04321",
    "title": "A Nonlinear Heat Equation Arising from Automated-Vehicle Traffic Flow  Models",
    "abstract": "In this paper, a new nonlinear heat equation is studied that arises as a\nmodel of the collective behavior of automated vehicles. The properties of the\nsolutions of this equation are studied by introducing the appropriate notion of\na weak solution that requires certain entropy-like conditions. To obtain an\napproximation of the solution of the nonlinear heat equation, a new\nconservative first-order finite difference scheme is proposed that respects the\ncorresponding entropy conditions, and certain links between the weak solution\nand the numerical scheme are provided. Finally, a traffic simulation scenario\nand a comparison with the Lighthill-Witham-Richards (LWR) model are provided,\nillustrating the benefits of the use of automated vehicles.",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Dionysis Theodosis",
      "Iasson Karafyllis",
      "George Titakis",
      "Ioannis Papamichail",
      "Markos Papageorgiou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.04321"
  },
  {
    "id": "arXiv:2210.04323",
    "title": "Deep Learning Inference Frameworks Benchmark",
    "abstract": "Deep learning (DL) has been widely adopted those last years but they are\ncomputing-intensive method. Therefore, scientists proposed diverse optimization\nto accelerate their predictions for end-user applications. However, no single\ninference framework currently dominates in terms of performance. This paper\ntakes a holistic approach to conduct an empirical comparison and analysis of\nfour representative DL inference frameworks. First, given a selection of\nCPU-GPU configurations, we show that for a specific DL framework, different\nconfigurations of its settings may have a significant impact on the prediction\nspeed, memory, and computing power. Second, to the best of our knowledge, this\nstudy is the first to identify the opportunities for accelerating the ensemble\nof co-localized models in the same GPU. This measurement study provides an\nin-depth empirical comparison and analysis of four representative DL frameworks\nand offers practical guidance for service providers to deploy and deliver DL\npredictions.",
    "descriptor": "",
    "authors": [
      "Pierrick Pochelu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.04323"
  },
  {
    "id": "arXiv:2210.04325",
    "title": "ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models",
    "abstract": "Data-to-text generation is challenging due to the great variety of the input\ndata in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse\npredicates). Recent end-to-end neural methods thus require substantial training\nexamples to learn to disambiguate and describe the data. Yet, real-world\ndata-to-text problems often suffer from various data-scarce issues: one may\nhave access to only a handful of or no training examples, and/or have to rely\non examples in a different domain or schema. To fill this gap, we propose\nAny-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse\nsettings by making efficient use of any given (or no) examples. ASDOT consists\nof two steps, data disambiguation and sentence fusion, both of which are\namenable to be solved with off-the-shelf pretrained language models (LMs) with\noptional finetuning. In the data disambiguation stage, we employ the prompted\nGPT-3 model to understand possibly ambiguous triples from the input data and\nconvert each into a short sentence with reduced ambiguity. The sentence fusion\nstage then uses an LM like T5 to fuse all the resulting sentences into a\ncoherent paragraph as the final description. We evaluate extensively on various\ndatasets in different scenarios, including the zero-/few-/full-shot settings,\nand generalization to unseen predicates and out-of-domain data. Experimental\nresults show that ASDOT consistently achieves significant improvement over\nbaselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot\nsetting.",
    "descriptor": "\nComments: Findings of EMNLP 2020\n",
    "authors": [
      "Jiannan Xiang",
      "Zhengzhong Liu",
      "Yucheng Zhou",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04325"
  },
  {
    "id": "arXiv:2210.04328",
    "title": "seL4 Microkernel for virtualization use-cases: Potential directions  towards a standard VMM",
    "abstract": "Virtualization plays an essential role in providing security to computational\nsystems by isolating execution environments. Many software solutions, called\nhypervisors, have been proposed to provide virtualization capabilities.\nHowever, only a few were designed for being deployed at the edge of the\nnetwork, in devices with fewer computation resources when compared with servers\nin the Cloud. Among the few lightweight software that can play the hypervisor\nrole, seL4 stands out by providing a small Trusted Computing Base and formally\nverified components, enhancing its security. Despite today being more than a\ndecade with seL4 microkernel technology, its existing userland and tools are\nstill scarce and not very mature. Over the last few years, the main effort has\nbeen put into increasing the maturity of the kernel itself and not the tools\nand applications that can be hosted on top. Therefore, it currently lacks\nproper support for a full-featured userland Virtual Machine Monitor, and the\nexisting one is quite fragmented. This article discusses the potential\ndirections to a standard VMM by presenting our view of design principles and\nfeature set needed. This article does not intend to define a standard VMM, we\nintend to instigate this discussion through the seL4 community.",
    "descriptor": "",
    "authors": [
      "Everton de Matos",
      "Markku Ahvenj\u00e4rvi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.04328"
  },
  {
    "id": "arXiv:2210.04331",
    "title": "Students taught by multimodal teachers are superior action recognizers",
    "abstract": "The focal point of egocentric video understanding is modelling hand-object\ninteractions. Standard models -- CNNs, Vision Transformers, etc. -- which\nreceive RGB frames as input perform well, however, their performance improves\nfurther by employing additional modalities such as object detections, optical\nflow, audio, etc. as input. The added complexity of the required\nmodality-specific modules, on the other hand, makes these models impractical\nfor deployment. The goal of this work is to retain the performance of such\nmultimodal approaches, while using only the RGB images as input at inference\ntime. Our approach is based on multimodal knowledge distillation, featuring a\nmultimodal teacher (in the current experiments trained only using object\ndetections, optical flow and RGB frames) and a unimodal student (using only RGB\nframes as input). We present preliminary results which demonstrate that the\nresulting model -- distilled from a multimodal teacher -- significantly\noutperforms the baseline RGB model (trained without knowledge distillation), as\nwell as an omnivorous version of itself (trained on all modalities jointly), in\nboth standard and compositional action recognition.",
    "descriptor": "\nComments: Extended abstract accepted at the 2nd Ego4D Workshop @ ECCV 2022\n",
    "authors": [
      "Gorjan Radevski",
      "Dusan Grujicic",
      "Matthew Blaschko",
      "Marie-Francine Moens",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04331"
  },
  {
    "id": "arXiv:2210.04333",
    "title": "Hypergraph-based Multi-Robot Task and Motion Planning",
    "abstract": "We present a multi-robot task and motion planning method that, when applied\nto the rearrangement of objects by manipulators, produces solution times up to\nthree orders of magnitude faster than existing methods. We achieve this\nimprovement by decomposing the planning space into subspaces for independent\nmanipulators, objects, and manipulators holding objects. We represent this\ndecomposition with a hypergraph where vertices are substates and hyperarcs are\ntransitions between substates. Existing methods use graph-based representations\nwhere vertices are full states and edges are transitions between states. Using\nthe hypergraph reduces the size of the planning space-for multi-manipulator\nobject rearrangement, the number of hypergraph vertices scales linearly with\nthe number of either robots or objects, while the number of hyperarcs scales\nquadratically with the number of robots and linearly with the number of\nobjects. In contrast, the number of vertices and edges in graph-based\nrepresentations scale exponentially in the number of robots and objects.\nAdditionally, the hypergraph provides a structure to reason over varying levels\nof (de)coupled spaces and transitions between them enabling a hybrid search of\nthe planning space. We show that similar gains can be achieved for other\nmulti-robot task and motion planning problems.",
    "descriptor": "\nComments: This work has been submitted for review\n",
    "authors": [
      "James Motes",
      "Tan Chen",
      "Timothy Bretl",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.04333"
  },
  {
    "id": "arXiv:2210.04337",
    "title": "Quantifying Social Biases Using Templates is Unreliable",
    "abstract": "Recently, there has been an increase in efforts to understand how large\nlanguage models (LLMs) propagate and amplify social biases. Several works have\nutilized templates for fairness evaluation, which allow researchers to quantify\nsocial biases in the absence of test sets with protected attribute labels.\nWhile template evaluation can be a convenient and helpful diagnostic tool to\nunderstand model deficiencies, it often uses a simplistic and limited set of\ntemplates. In this paper, we study whether bias measurements are sensitive to\nthe choice of templates used for benchmarking. Specifically, we investigate the\ninstability of bias measurements by manually modifying templates proposed in\nprevious works in a semantically-preserving manner and measuring bias across\nthese modifications. We find that bias values and resulting conclusions vary\nconsiderably across template modifications on four tasks, ranging from an 81%\nreduction (NLI) to a 162% increase (MLM) in (task-specific) bias measurements.\nOur results indicate that quantifying fairness in LLMs, as done in current\npractice, can be brittle and needs to be approached with more care and caution.",
    "descriptor": "",
    "authors": [
      "Preethi Seshadri",
      "Pouya Pezeshkpour",
      "Sameer Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04337"
  },
  {
    "id": "arXiv:2210.04338",
    "title": "A Method for Computing Inverse Parametric PDE Problems with  Random-Weight Neural Networks",
    "abstract": "We present a method for computing the inverse parameters and the solution\nfield to inverse parametric PDEs based on randomized neural networks. This\nextends the local extreme learning machine technique originally developed for\nforward PDEs to inverse problems. We develop three algorithms for training the\nneural network to solve the inverse PDE problem. The first algorithm (NLLSQ)\ndetermines the inverse parameters and the trainable network parameters all\ntogether by the nonlinear least squares method with perturbations\n(NLLSQ-perturb). The second algorithm (VarPro-F1) eliminates the inverse\nparameters from the overall problem by variable projection to attain a reduced\nproblem about the trainable network parameters only. It solves the reduced\nproblem first by the NLLSQ-perturb algorithm for the trainable network\nparameters, and then computes the inverse parameters by the linear least\nsquares method. The third algorithm (VarPro-F2) eliminates the trainable\nnetwork parameters from the overall problem by variable projection to attain a\nreduced problem about the inverse parameters only. It solves the reduced\nproblem for the inverse parameters first, and then computes the trainable\nnetwork parameters afterwards. VarPro-F1 and VarPro-F2 are reciprocal to each\nother in a sense. The presented method produces accurate results for inverse\nPDE problems, as shown by the numerical examples herein. For noise-free data,\nthe errors for the inverse parameters and the solution field decrease\nexponentially as the number of collocation points or the number of trainable\nnetwork parameters increases, and can reach a level close to the machine\naccuracy. For noisy data, the accuracy degrades compared with the case of\nnoise-free data, but the method remains quite accurate. The presented method\nhas been compared with the physics-informed neural network method.",
    "descriptor": "\nComments: 40 pages, 8 figures, 34 tables\n",
    "authors": [
      "Suchuan Dong",
      "Yiran Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.04338"
  },
  {
    "id": "arXiv:2210.04341",
    "title": "ConTra: (Con)text (Tra)nsformer for Cross-Modal Video Retrieval",
    "abstract": "In this paper, we re-examine the task of cross-modal clip-sentence retrieval,\nwhere the clip is part of a longer untrimmed video. When the clip is short or\nvisually ambiguous, knowledge of its local temporal context (i.e. surrounding\nvideo segments) can be used to improve the retrieval performance. We propose\nContext Transformer (ConTra); an encoder architecture that models the\ninteraction between a video clip and its local temporal context in order to\nenhance its embedded representations. Importantly, we supervise the context\ntransformer using contrastive losses in the cross-modal embedding space. We\nexplore context transformers for video and text modalities. Results\nconsistently demonstrate improved performance on three datasets: YouCook2,\nEPIC-KITCHENS and a clip-sentence version of ActivityNet Captions. Exhaustive\nablation studies and context analysis show the efficacy of the proposed method.",
    "descriptor": "\nComments: Accepted in ACCV 2022\n",
    "authors": [
      "Adriano Fragomeni",
      "Michael Wray",
      "Dima Damen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04341"
  },
  {
    "id": "arXiv:2210.04345",
    "title": "LieGG: Studying Learned Lie Group Generators",
    "abstract": "Symmetries built into a neural network have appeared to be very beneficial\nfor a wide range of tasks as it saves the data to learn them. We depart from\nthe position that when symmetries are not built into a model a priori, it is\nadvantageous for robust networks to learn symmetries directly from the data to\nfit a task function. In this paper, we present a method to extract symmetries\nlearned by a neural network and to evaluate the degree to which a network is\ninvariant to them. With our method, we are able to explicitly retrieve learned\ninvariances in a form of the generators of corresponding Lie-groups without\nprior knowledge of symmetries in the data. We use the proposed method to study\nhow symmetrical properties depend on a neural network's parameterization and\nconfiguration. We found that the ability of a network to learn symmetries\ngeneralizes over a range of architectures. However, the quality of learned\nsymmetries depends on the depth and the number of parameters.",
    "descriptor": "",
    "authors": [
      "Artem Moskalev",
      "Anna Sepliarskaia",
      "Ivan Sosnovik",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04345"
  },
  {
    "id": "arXiv:2210.04349",
    "title": "Nonlinear Sufficient Dimension Reduction with a Stochastic Neural  Network",
    "abstract": "Sufficient dimension reduction is a powerful tool to extract core information\nhidden in the high-dimensional data and has potentially many important\napplications in machine learning tasks. However, the existing nonlinear\nsufficient dimension reduction methods often lack the scalability necessary for\ndealing with large-scale data. We propose a new type of stochastic neural\nnetwork under a rigorous probabilistic framework and show that it can be used\nfor sufficient dimension reduction for large-scale data. The proposed\nstochastic neural network is trained using an adaptive stochastic gradient\nMarkov chain Monte Carlo algorithm, whose convergence is rigorously studied in\nthe paper as well. Through extensive experiments on real-world classification\nand regression problems, we show that the proposed method compares favorably\nwith the existing state-of-the-art sufficient dimension reduction methods and\nis computationally more efficient for large-scale data.",
    "descriptor": "",
    "authors": [
      "Siqi Liang",
      "Yan Sun",
      "Faming Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04349"
  },
  {
    "id": "arXiv:2210.04351",
    "title": "California Test System (CATS): A Geographically Accurate Test System  based on the California Grid",
    "abstract": "This paper presents the California Test System (CATS), a synthetic\ntransmission grid in California that can be used by the public for power\nsystems research without revealing any critical energy information. The\nproposed synthetic grid combines publicly available geographic data of\nCalifornia's electric infrastructure, such as the actual location of\ntransmission corridors, with invented topology and transmission line parameters\nthat are \"realistic but not real\". The result is a test system that is suitable\nfor power flow and optimal power flow analysis. The methods used to develop and\nevaluate the CATS grid are documented in detail in this report.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Sofia Taylor",
      "Aditya Rangarajan",
      "Noah Rhodes",
      "Jonathan Snodgrass",
      "Bernie Lesieutre",
      "Line A. Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04351"
  },
  {
    "id": "arXiv:2210.04359",
    "title": "FairGer: Using NLP to Measure Support for Women and Migrants in 155  Years of German Parliamentary Debates",
    "abstract": "We measure support with women and migrants in German political debates over\nthe last 155 years. To do so, we (1) provide a gold standard of 1205 text\nsnippets in context, annotated for support with our target groups, (2) train a\nBERT model on our annotated data, with which (3) we infer large-scale trends.\nThese show that support with women is stronger than support with migrants, but\nboth have steadily increased over time. While we hardly find any direct\nanti-support with women, there is more polarization when it comes to migrants.\nWe also discuss the difficulty of annotation as a result of ambiguity in\npolitical discourse and indirectness, i.e., politicians' tendency to relate\nstances attributed to political opponents. Overall, our results indicate that\nGerman society, as measured from its political elite, has become fairer over\ntime.",
    "descriptor": "",
    "authors": [
      "Dominik Beese",
      "Ole P\u00fctz",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04359"
  },
  {
    "id": "arXiv:2210.04365",
    "title": "ELIGN: Expectation Alignment as a Multi-Agent Intrinsic Reward",
    "abstract": "Modern multi-agent reinforcement learning frameworks rely on centralized\ntraining and reward shaping to perform well. However, centralized training and\ndense rewards are not readily available in the real world. Current multi-agent\nalgorithms struggle to learn in the alternative setup of decentralized training\nor sparse rewards. To address these issues, we propose a self-supervised\nintrinsic reward ELIGN - expectation alignment - inspired by the\nself-organization principle in Zoology. Similar to how animals collaborate in a\ndecentralized manner with those in their vicinity, agents trained with\nexpectation alignment learn behaviors that match their neighbors' expectations.\nThis allows the agents to learn collaborative behaviors without any external\nreward or centralized training. We demonstrate the efficacy of our approach\nacross 6 tasks in the multi-agent particle and the complex Google Research\nfootball environments, comparing ELIGN to sparse and curiosity-based intrinsic\nrewards. When the number of agents increases, ELIGN scales well in all\nmulti-agent tasks except for one where agents have different capabilities. We\nshow that agent coordination improves through expectation alignment because\nagents learn to divide tasks amongst themselves, break coordination symmetries,\nand confuse adversaries. These results identify tasks where expectation\nalignment is a more useful strategy than curiosity-driven exploration for\nmulti-agent coordination, enabling agents to do zero-shot coordination.",
    "descriptor": "\nComments: This paper will be published in Neurips 2022\n",
    "authors": [
      "Zixian Ma",
      "Rose Wang",
      "Li Fei-Fei",
      "Michael Bernstein",
      "Ranjay Krishna"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04365"
  },
  {
    "id": "arXiv:2210.04366",
    "title": "Computational Choreography using Human Motion Synthesis",
    "abstract": "Should deep learning models be trained to analyze human performance art? To\nhelp answer this question, we explore an application of deep neural networks to\nsynthesize artistic human motion. Problem tasks in human motion synthesis can\ninclude predicting the motions of humans in-the-wild, as well as generating new\nsequences of motions based on said predictions. We will discuss the potential\nof a less traditional application, where learning models are applied to\npredicting dance movements. There have been notable, recent efforts to analyze\ndance movements in a computational light, such as the Everybody Dance Now (EDN)\nlearning model and a recent Cal Poly master's thesis, Take The Lead (TTL). We\nhave effectively combined these two works along with our own deep neural\nnetwork to produce a new system for dance motion prediction, image-to-image\ntranslation, and video generation.",
    "descriptor": "\nComments: 6 pages, 7 figures, to be submitted to CVPR 2023\n",
    "authors": [
      "Patrick Perrine",
      "Trevor Kirkby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04366"
  },
  {
    "id": "arXiv:2210.04367",
    "title": "Unsupervised RGB-to-Thermal Domain Adaptation via Multi-Domain Attention  Network",
    "abstract": "This work presents a new method for unsupervised thermal image classification\nand semantic segmentation by transferring knowledge from the RGB domain using a\nmulti-domain attention network. Our method does not require any thermal\nannotations or co-registered RGB-thermal pairs, enabling robots to perform\nvisual tasks at night and in adverse weather conditions without incurring\nadditional costs of data labeling and registration. Current unsupervised domain\nadaptation methods look to align global images or features across domains.\nHowever, when the domain shift is significantly larger for cross-modal data,\nnot all features can be transferred. We solve this problem by using a shared\nbackbone network that promotes generalization, and domain-specific attention\nthat reduces negative transfer by attending to domain-invariant and\neasily-transferable features. Our approach outperforms the state-of-the-art\nRGB-to-thermal adaptation method in classification benchmarks, and is\nsuccessfully applied to thermal river scene segmentation using only synthetic\nRGB images. Our code is made publicly available at\nhttps://github.com/ganlumomo/thermal-uda-attention.",
    "descriptor": "",
    "authors": [
      "Lu Gan",
      "Connor Lee",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04367"
  },
  {
    "id": "arXiv:2210.04369",
    "title": "A Differentiable Distance Approximation for Fairer Image Classification",
    "abstract": "Naively trained AI models can be heavily biased. This can be particularly\nproblematic when the biases involve legally or morally protected attributes\nsuch as ethnic background, age or gender. Existing solutions to this problem\ncome at the cost of extra computation, unstable adversarial optimisation or\nhave losses on the feature space structure that are disconnected from fairness\nmeasures and only loosely generalise to fairness. In this work we propose a\ndifferentiable approximation of the variance of demographics, a metric that can\nbe used to measure the bias, or unfairness, in an AI model. Our approximation\ncan be optimised alongside the regular training objective which eliminates the\nneed for any extra models during training and directly improves the fairness of\nthe regularised models. We demonstrate that our approach improves the fairness\nof AI models in varied task and dataset scenarios, whilst still maintaining a\nhigh level of classification accuracy. Code is available at\nhttps://bitbucket.org/nelliottrosa/base_fairness.",
    "descriptor": "",
    "authors": [
      "Nicholas Rosa",
      "Tom Drummond",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04369"
  },
  {
    "id": "arXiv:2210.04370",
    "title": "Propagation Stability Concepts for Network Synchronization Processes",
    "abstract": "A notion of disturbance propagation stability is defined for dynamical\nnetwork processes, in terms of decrescence of an input-output energy metric\nalong cutsets away from the disturbance source. A characterization of the\ndisturbance propagation notion is developed for a canonical model for\nsynchronization of linearly-coupled homogeneous subsystems. Specifically,\npropagation stability is equivalenced with the frequency response of a certain\nlocal closed-loop model, which is defined from the subsystem model and local\nnetwork connections, being sub-unity gain. For the case where the subsystem is\nsingle-input single-output (SISO), a further simplification in terms of the\nsubsystem's open loop Nyquist plot is obtained. An extension of the disturbance\npropagation stability concept toward imperviousness of subnetworks to\ndisturbances is briefly developed, and an example focused on networks with\nplanar subsystems is considered.",
    "descriptor": "",
    "authors": [
      "Sandip Roy",
      "Subir Sarker",
      "Mengran Xue"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04370"
  },
  {
    "id": "arXiv:2210.04373",
    "title": "Contrastive Representation Learning for Conversational Question  Answering over Knowledge Graphs",
    "abstract": "This paper addresses the task of conversational question answering (ConvQA)\nover knowledge graphs (KGs). The majority of existing ConvQA methods rely on\nfull supervision signals with a strict assumption of the availability of gold\nlogical forms of queries to extract answers from the KG. However, creating such\na gold logical form is not viable for each potential question in a real-world\nscenario. Hence, in the case of missing gold logical forms, the existing\ninformation retrieval-based approaches use weak supervision via heuristics or\nreinforcement learning, formulating ConvQA as a KG path ranking problem.\nDespite missing gold logical forms, an abundance of conversational contexts,\nsuch as entire dialog history with fluent responses and domain information, can\nbe incorporated to effectively reach the correct KG path. This work proposes a\ncontrastive representation learning-based approach to rank KG paths\neffectively. Our approach solves two key challenges. Firstly, it allows weak\nsupervision-based learning that omits the necessity of gold annotations.\nSecond, it incorporates the conversational context (entire dialog history and\ndomain information) to jointly learn its homogeneous representation with KG\npaths to improve contrastive representations for effective path ranking. We\nevaluate our approach on standard datasets for ConvQA, on which it\nsignificantly outperforms existing baselines on all domains and overall.\nSpecifically, in some cases, the Mean Reciprocal Rank (MRR) and Hit@5 ranking\nmetrics improve by absolute 10 and 18 points, respectively, compared to the\nstate-of-the-art performance.",
    "descriptor": "\nComments: 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)\n",
    "authors": [
      "Endri Kacupaj",
      "Kuldeep Singh",
      "Maria Maleshkova",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04373"
  },
  {
    "id": "arXiv:2210.04377",
    "title": "DCVQE: A Hierarchical Transformer for Video Quality Assessment",
    "abstract": "The explosion of user-generated videos stimulates a great demand for\nno-reference video quality assessment (NR-VQA). Inspired by our observation on\nthe actions of human annotation, we put forward a Divide and Conquer Video\nQuality Estimator (DCVQE) for NR-VQA. Starting from extracting the frame-level\nquality embeddings (QE), our proposal splits the whole sequence into a number\nof clips and applies Transformers to learn the clip-level QE and update the\nframe-level QE simultaneously; another Transformer is introduced to combine the\nclip-level QE to generate the video-level QE. We call this hierarchical\ncombination of Transformers as a Divide and Conquer Transformer (DCTr) layer.\nAn accurate video quality feature extraction can be achieved by repeating the\nprocess of this DCTr layer several times. Taking the order relationship among\nthe annotated data into account, we also propose a novel correlation loss term\nfor model training. Experiments on various datasets confirm the effectiveness\nand robustness of our DCVQE model.",
    "descriptor": "\nComments: Accepted by ACCV2022\n",
    "authors": [
      "Zutong Li",
      "Lei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04377"
  },
  {
    "id": "arXiv:2210.04379",
    "title": "Unsupervised Domain Adaptive Fundus Image Segmentation with Few Labeled  Source Data",
    "abstract": "Deep learning-based segmentation methods have been widely employed for\nautomatic glaucoma diagnosis and prognosis. In practice, fundus images obtained\nby different fundus cameras vary significantly in terms of illumination and\nintensity. Although recent unsupervised domain adaptation (UDA) methods enhance\nthe models' generalization ability on the unlabeled target fundus datasets,\nthey always require sufficient labeled data from the source domain, bringing\nauxiliary data acquisition and annotation costs. To further facilitate the data\nefficiency of the cross-domain segmentation methods on the fundus images, we\nexplore UDA optic disc and cup segmentation problems using few labeled source\ndata in this work. We first design a Searching-based Multi-style Invariant\nMechanism to diversify the source data style as well as increase the data\namount. Next, a prototype consistency mechanism on the foreground objects is\nproposed to facilitate the feature alignment for each kind of tissue under\ndifferent image styles. Moreover, a cross-style self-supervised learning stage\nis further designed to improve the segmentation performance on the target\nimages. Our method has outperformed several state-of-the-art UDA segmentation\nmethods under the UDA fundus segmentation with few labeled source data.",
    "descriptor": "\nComments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Qianbi Yu",
      "Dongnan Liu",
      "Chaoyi Zhang",
      "Xinwen Zhang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04379"
  },
  {
    "id": "arXiv:2210.04382",
    "title": "Parameter-Efficient Tuning with Special Token Adaptation",
    "abstract": "Parameter-efficient tuning aims at updating only a small subset of parameters\nwhen adapting a pretrained model to downstream tasks. In this work, we\nintroduce PASTA, in which we only modify the special token representations\n(e.g., [SEP] and [CLS] in BERT) before the self-attention module at each layer\nin Transformer-based models. PASTA achieves comparable performance to\nfine-tuning in natural language understanding tasks including text\nclassification and NER with up to only 0.029% of total parameters trained. Our\nwork not only provides a simple yet effective way of parameter-efficient\ntuning, which has a wide range of practical applications when deploying\nfinetuned models for multiple tasks, but also demonstrates the pivotal role of\nspecial tokens in pretrained language models.",
    "descriptor": "",
    "authors": [
      "Xiaoocong Yang",
      "James Y. Huang",
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04382"
  },
  {
    "id": "arXiv:2210.04384",
    "title": "Numerical Analysis of Computing Quasiperiodic Systems",
    "abstract": "Quasiperiodic systems, related to irrational numbers, are important\nspace-filling ordered structures, without decay and translational invariance.\nThere are some efficient numerical algorithms, such as the projection method\n(PM) [J. Comput. Phys., 256: 428, 2014], have been proposed to compute\nquasiperiodic systems. However, there is also a lack of theoretical analysis of\nthese numerical methods. In this paper, we first establish a mathematical\nframework for the quasiperiodic function and its high-dimensional periodic\nfunction based on Birkhoff's ergodic theorem. Then we give a theoretical\nanalysis of PM and quasiperiodic spectral method (QSM). Results demonstrate\nthat PM and QSM both have exponential decay. Further, we find that QSM (PM) is\na generalization of the conventional Fourier (pseudo) spectral method. And the\nPM can use fast Fourier transform to treat nonlinear problems and cross terms\nwith an almost optimal computational amount. Finally, we use the quasiperiodic\nSchr\\\"odinger equation as an example to verify our theoretical results.",
    "descriptor": "",
    "authors": [
      "Kai Jiang",
      "ShiFeng Li",
      "Pingwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04384"
  },
  {
    "id": "arXiv:2210.04388",
    "title": "Semi-supervised Semantic Segmentation with Prototype-based Consistency  Regularization",
    "abstract": "Semi-supervised semantic segmentation requires the model to effectively\npropagate the label information from limited annotated images to unlabeled\nones. A challenge for such a per-pixel prediction task is the large intra-class\nvariation, i.e., regions belonging to the same class may exhibit a very\ndifferent appearance even in the same picture. This diversity will make the\nlabel propagation hard from pixels to pixels. To address this problem, we\npropose a novel approach to regularize the distribution of within-class\nfeatures to ease label propagation difficulty. Specifically, our approach\nencourages the consistency between the prediction from a linear predictor and\nthe output from a prototype-based predictor, which implicitly encourages\nfeatures from the same pseudo-class to be close to at least one within-class\nprototype while staying far from the other between-class prototypes. By further\nincorporating CutMix operations and a carefully-designed prototype maintenance\nstrategy, we create a semi-supervised semantic segmentation algorithm that\ndemonstrates superior performance over the state-of-the-art methods from\nextensive experimental evaluation on both Pascal VOC and Cityscapes benchmarks.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Hai-Ming Xu",
      "Lingqiao Liu",
      "Qiuchen Bian",
      "Zhen Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04388"
  },
  {
    "id": "arXiv:2210.04393",
    "title": "LAPFormer: A Light and Accurate Polyp Segmentation Transformer",
    "abstract": "Polyp segmentation is still known as a difficult problem due to the large\nvariety of polyp shapes, scanning and labeling modalities. This prevents deep\nlearning model to generalize well on unseen data. However, Transformer-based\napproach recently has achieved some remarkable results on performance with the\nability of extracting global context better than CNN-based architecture and yet\nlead to better generalization. To leverage this strength of Transformer, we\npropose a new model with encoder-decoder architecture named LAPFormer, which\nuses a hierarchical Transformer encoder to better extract global feature and\ncombine with our novel CNN (Convolutional Neural Network) decoder for capturing\nlocal appearance of the polyps. Our proposed decoder contains a progressive\nfeature fusion module designed for fusing feature from upper scales and lower\nscales and enable multi-scale features to be more correlative. Besides, we also\nuse feature refinement module and feature selection module for processing\nfeature. We test our model on five popular benchmark datasets for polyp\nsegmentation, including Kvasir, CVC-Clinic DB, CVC-ColonDB, CVC-T, and\nETIS-Larib",
    "descriptor": "\nComments: 7 pages, 7 figures, ACL 2023 underreview\n",
    "authors": [
      "Mai Nguyen",
      "Tung Thanh Bui",
      "Quan Van Nguyen",
      "Thanh Tung Nguyen",
      "Toan Van Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04393"
  },
  {
    "id": "arXiv:2210.04397",
    "title": "Energy-efficient Reactive and Predictive Connected Cruise Control",
    "abstract": "In this paper, we propose a framework for the longitudinal control of\nconnected and automated vehicles traveling in mixed traffic consisting of\nconnected and non-connected human-driven vehicles. Reactive and predictive\ncontrollers are proposed. Reactive controllers are given by explicit feedback\ncontrol laws. In predictive controllers, the control input is optimized in a\nreceding-horizon fashion, which depends on the predictions of motions of\npreceding vehicles. Beyond-line-of-sight information is obtained via\nvehicle-to-vehicle (V2V) communication, and is utilized in the proposed\nreactive and predictive controllers. Simulations utilizing real traffic data\nare used to show that connectivity can bring significant energy savings.",
    "descriptor": "\nComments: 18 pages, 12 figures, submitted to Transportation Research Part C: Emerging Technologies\n",
    "authors": [
      "Minghao Shen",
      "R. Austin Dollar",
      "Tamas G. Molnar",
      "Chaozhe R. He",
      "Ardalan Vahidi",
      "Gabor Orosz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04397"
  },
  {
    "id": "arXiv:2210.04398",
    "title": "Scaling Up Probabilistic Circuits by Latent Variable Distillation",
    "abstract": "Probabilistic Circuits (PCs) are a unified framework for tractable\nprobabilistic models that support efficient computation of various\nprobabilistic queries (e.g., marginal probabilities). One key challenge is to\nscale PCs to model large and high-dimensional real-world datasets: we observe\nthat as the number of parameters in PCs increases, their performance\nimmediately plateaus. This phenomenon suggests that the existing optimizers\nfail to exploit the full expressive power of large PCs. We propose to overcome\nsuch bottleneck by latent variable distillation: we leverage the less tractable\nbut more expressive deep generative models to provide extra supervision over\nthe latent variables of PCs. Specifically, we extract information from\nTransformer-based generative models to assign values to latent variables of\nPCs, providing guidance to PC optimizers. Experiments on both image and\nlanguage modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent\nvariable distillation substantially boosts the performance of large PCs\ncompared to their counterparts without latent variable distillation. In\nparticular, on the image modeling benchmarks, PCs achieve competitive\nperformance against some of the widely-used deep generative models, including\nvariational autoencoders and flow-based models, opening up new avenues for\ntractable generative modeling.",
    "descriptor": "",
    "authors": [
      "Anji Liu",
      "Honghua Zhang",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04398"
  },
  {
    "id": "arXiv:2210.04399",
    "title": "Deep Learning for Logo Detection: A Survey",
    "abstract": "When logos are increasingly created, logo detection has gradually become a\nresearch hotspot across many domains and tasks. Recent advances in this area\nare dominated by deep learning-based solutions, where many datasets, learning\nstrategies, network architectures, etc. have been employed. This paper reviews\nthe advance in applying deep learning techniques to logo detection. Firstly, we\ndiscuss a comprehensive account of public datasets designed to facilitate\nperformance evaluation of logo detection algorithms, which tend to be more\ndiverse, more challenging, and more reflective of real life. Next, we perform\nan in-depth analysis of the existing logo detection strategies and the\nstrengths and weaknesses of each learning strategy. Subsequently, we summarize\nthe applications of logo detection in various fields, from intelligent\ntransportation and brand monitoring to copyright and trademark compliance.\nFinally, we analyze the potential challenges and present the future directions\nfor the development of logo detection to complete this survey.",
    "descriptor": "",
    "authors": [
      "Sujuan Hou",
      "Jiacheng Li",
      "Weiqing Min",
      "Qiang Hou",
      "Yanna Zhao",
      "Yuanjie Zheng",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04399"
  },
  {
    "id": "arXiv:2210.04400",
    "title": "Focus Plus: Detect Learner's Distraction by Web Camera in Distance  Teaching",
    "abstract": "Distance teaching has become popular these years because of the COVID-19\nepidemic. However, both students and teachers face several challenges in\ndistance teaching, like being easy to distract. We proposed Focus+, a system\ndesigned to detect learners' status with the latest AI technology from their\nweb camera to solve such challenges. By doing so, teachers can know students'\nstatus, and students can regulate their learning experience. In this research,\nwe will discuss the expected model's design for training and evaluating the AI\ndetection model of Focus+.",
    "descriptor": "\nComments: 5 Pages, 4 Figures, 2021 National Chair Professorship Academic Series: Teaching and Learning in Pandemic Era\n",
    "authors": [
      "Eason Chen",
      "Yuen Hsien Tseng",
      "Kuo-Ping Lo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04400"
  },
  {
    "id": "arXiv:2210.04402",
    "title": "Contrastive Bayesian Analysis for Deep Metric Learning",
    "abstract": "Recent methods for deep metric learning have been focusing on designing\ndifferent contrastive loss functions between positive and negative pairs of\nsamples so that the learned feature embedding is able to pull positive samples\nof the same class closer and push negative samples from different classes away\nfrom each other. In this work, we recognize that there is a significant\nsemantic gap between features at the intermediate feature layer and class\nlabels at the final output layer. To bridge this gap, we develop a contrastive\nBayesian analysis to characterize and model the posterior probabilities of\nimage labels conditioned by their features similarity in a contrastive learning\nsetting. This contrastive Bayesian analysis leads to a new loss function for\ndeep metric learning. To improve the generalization capability of the proposed\nmethod onto new classes, we further extend the contrastive Bayesian loss with a\nmetric variance constraint. Our experimental results and ablation studies\ndemonstrate that the proposed contrastive Bayesian metric learning method\nsignificantly improves the performance of deep metric learning in both\nsupervised and pseudo-supervised scenarios, outperforming existing methods by a\nlarge margin.",
    "descriptor": "\nComments: Minor revision version from IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Shichao Kan",
      "Zhiquan He",
      "Yigang Cen",
      "Yang Li",
      "Mladenovic Vladimir",
      "Zhihai He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04402"
  },
  {
    "id": "arXiv:2210.04404",
    "title": "Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor  Decomposition",
    "abstract": "Graphs emerge in almost every real-world application domain, ranging from\nonline social networks all the way to health data and movie viewership\npatterns. Typically, such real-world graphs are big and dynamic, in the sense\nthat they evolve over time. Furthermore, graphs usually contain multi-aspect\ninformation i.e. in a social network, we can have the \"means of communication\"\nbetween nodes, such as who messages whom, who calls whom, and who comments on\nwhose timeline and so on.\nHow can we model and mine useful patterns, such as communities of nodes in\nthat graph, from such multi-aspect graphs? How can we identify dynamic patterns\nin those graphs, and how can we deal with streaming data, when the volume of\ndata to be processed is very large? In order to answer those questions, in this\nthesis, we propose novel tensor-based methods for mining static and dynamic\nmulti-aspect graphs. In general, a tensor is a higher-order generalization of a\nmatrix that can represent high-dimensional multi-aspect data such as\ntime-evolving networks, collaboration networks, and spatio-temporal data like\nElectroencephalography (EEG) brain measurements.\nThe thesis is organized in two synergistic thrusts: First, we focus on static\nmulti-aspect graphs, where the goal is to identify coherent communities and\npatterns between nodes by leveraging the tensor structure in the data. Second,\nas our graphs evolve dynamically, we focus on handling such streaming updates\nin the data without having to re-compute the decomposition, but incrementally\nupdate the existing results.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Ekta Gujral"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04404"
  },
  {
    "id": "arXiv:2210.04406",
    "title": "Predicting Blossom Date of Cherry Tree With Support Vector Machine and  Recurrent Neural Network",
    "abstract": "Our project probes the relationship between temperatures and the blossom date\nof cherry trees. Through modeling, future flowering will become predictive,\nhelping the public plan travels and avoid pollen season. To predict the date\nwhen the cherry trees will blossom exactly could be viewed as a multiclass\nclassification problem, so we applied the multi-class Support Vector Classifier\n(SVC) and Recurrent Neural Network (RNN), particularly Long Short-term Memory\n(LSTM), to formulate the problem. In the end, we evaluate and compare the\nperformance of these approaches to find out which one might be more applicable\nin reality.",
    "descriptor": "\nComments: 6 Pages, 6 Figures\n",
    "authors": [
      "Hongyi Zheng",
      "Yanyu Chen",
      "Zihan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04406"
  },
  {
    "id": "arXiv:2210.04410",
    "title": "Seamless Service Provisioning for Mobile Crowdsensing: Towards  Integrating Forward and Spot Trading Markets",
    "abstract": "The challenge of exchanging and processing of big data over Mobile\nCrowdsensing (MCS) networks calls for the new design of responsive and seamless\nservice provisioning as well as proper incentive mechanisms. Although\nconventional onsite spot trading of resources based on real-time network\nconditions and decisions can facilitate the data sharing over MCS networks, it\noften suffers from prohibitively long service provisioning delays and\nunavoidable trading failures due to its reliance on timely analysis of complex\nand dynamic MCS environments. These limitations motivate us to investigate an\nintegrated forward and spot trading mechanism (iFAST), which entails a new\nhybrid service trading protocol over the MCS network architecture. In iFAST,\nthe sellers (i.e., mobile users with sensing resources) can provide long-term\nor temporary sensing services to the buyers (i.e., sensing task owners). iFast\nenables signing long-term contracts in advance of future transactions through a\nforward trading mode, via analyzing historical statistics of the market, for\nwhich the notion of overbooking is introduced and promoted. iFAST further\nenables the buyers with unsatisfying service quality to recruit temporary\nsellers through a spot trading mode, upon considering the current\nmarket/network conditions. We analyze the fundamental blocks of iFAST, and\nprovide a case study to demonstrate its superior performance as compared to\nexisting methods. Finally, future research directions on reliable service\nprovisioning for next-generation MCS networks are summarized.",
    "descriptor": "",
    "authors": [
      "Minghui Liwang",
      "Seyyedali Hosseinalipour",
      "Zhibin Gao",
      "Zhipeng Cheng",
      "Yuhan Su",
      "Xianbin Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04410"
  },
  {
    "id": "arXiv:2210.04413",
    "title": "Asynchronous Collaborative Autoscanning with Mode Switching for  Multi-Robot Scene Reconstruction",
    "abstract": "When conducting autonomous scanning for the online reconstruction of unknown\nindoor environments, robots have to be competent at exploring scene structure\nand reconstructing objects with high quality. Our key observation is that\ndifferent tasks demand specialized scanning properties of robots: rapid moving\nspeed and far vision for global exploration and slow moving speed and narrow\nvision for local object reconstruction, which are referred as two different\nscanning modes: explorer and reconstructor, respectively. When requiring\nmultiple robots to collaborate for efficient exploration and fine-grained\nreconstruction, the questions on when to generate and how to assign those tasks\nshould be carefully answered. Therefore, we propose a novel asynchronous\ncollaborative autoscanning method with mode switching, which generates two\nkinds of scanning tasks with associated scanning modes, i.e., exploration task\nwith explorer mode and reconstruction task with reconstructor mode, and assign\nthem to the robots to execute in an asynchronous collaborative manner to highly\nboost the scanning efficiency and reconstruction quality. The task assignment\nis optimized by solving a modified Multi-Depot Multiple Traveling Salesman\nProblem (MDMTSP). Moreover, to further enhance the collaboration and increase\nthe efficiency, we propose a task-flow model that actives the task generation\nand assignment process immediately when any of the robots finish all its tasks\nwith no need to wait for all other robots to complete the tasks assigned in the\nprevious iteration. Extensive experiments have been conducted to show the\nimportance of each key component of our method and the superiority over\nprevious methods in scanning efficiency and reconstruction quality.",
    "descriptor": "\nComments: 13pages, 12 figures, Conference: SIGGRAPH Asia 2022\n",
    "authors": [
      "Junfu Guo",
      "Changhao Li",
      "Xi Xia",
      "Ruizhen Hu",
      "Ligang Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.04413"
  },
  {
    "id": "arXiv:2210.04417",
    "title": "Self-explaining Hierarchical Model for Intraoperative Time Series",
    "abstract": "Major postoperative complications are devastating to surgical patients. Some\nof these complications are potentially preventable via early predictions based\non intraoperative data. However, intraoperative data comprise long and\nfine-grained multivariate time series, prohibiting the effective learning of\naccurate models. The large gaps associated with clinical events and protocols\nare usually ignored. Moreover, deep models generally lack transparency.\nNevertheless, the interpretability is crucial to assist clinicians in planning\nfor and delivering postoperative care and timely interventions. Towards this\nend, we propose a hierarchical model combining the strength of both attention\nand recurrent models for intraoperative time series. We further develop an\nexplanation module for the hierarchical model to interpret the predictions by\nproviding contributions of intraoperative data in a fine-grained manner.\nExperiments on a large dataset of 111,888 surgeries with multiple outcomes and\nan external high-resolution ICU dataset show that our model can achieve strong\npredictive performance (i.e., high accuracy) and offer robust interpretations\n(i.e., high transparency) for predicted outcomes based on intraoperative time\nseries.",
    "descriptor": "",
    "authors": [
      "Dingwen Li",
      "Bing Xue",
      "Christopher King",
      "Bradley Fritz",
      "Michael Avidan",
      "Joanna Abraham",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04417"
  },
  {
    "id": "arXiv:2210.04427",
    "title": "Asymmetric Temperature Scaling Makes Larger Networks Teach Well Again",
    "abstract": "Knowledge Distillation (KD) aims at transferring the knowledge of a\nwell-performed neural network (the {\\it teacher}) to a weaker one (the {\\it\nstudent}). A peculiar phenomenon is that a more accurate model doesn't\nnecessarily teach better, and temperature adjustment can neither alleviate the\nmismatched capacity. To explain this, we decompose the efficacy of KD into\nthree parts: {\\it correct guidance}, {\\it smooth regularization}, and {\\it\nclass discriminability}. The last term describes the distinctness of {\\it wrong\nclass probabilities} that the teacher provides in KD. Complex teachers tend to\nbe over-confident and traditional temperature scaling limits the efficacy of\n{\\it class discriminability}, resulting in less discriminative wrong class\nprobabilities. Therefore, we propose {\\it Asymmetric Temperature Scaling\n(ATS)}, which separately applies a higher/lower temperature to the\ncorrect/wrong class. ATS enlarges the variance of wrong class probabilities in\nthe teacher's label and makes the students grasp the absolute affinities of\nwrong classes to the target class as discriminative as possible. Both\ntheoretical analysis and extensive experimental results demonstrate the\neffectiveness of ATS. The demo developed in Mindspore is available at\n\\url{https://gitee.com/lxcnju/ats-mindspore}.",
    "descriptor": "\nComments: Accepted By NeurIPS 2022\n",
    "authors": [
      "Xin-Chun Li",
      "Wen-Shu Fan",
      "Shaoming Song",
      "Yinchuan Li",
      "Bingshuai Li",
      "Yunfeng Shao",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04427"
  },
  {
    "id": "arXiv:2210.04428",
    "title": "A Simple Baseline that Questions the Use of Pretrained-Models in  Continual Learning",
    "abstract": "With the success of pretraining techniques in representation learning, a\nnumber of continual learning methods based on pretrained models have been\nproposed. Some of these methods design continual learning mechanisms on the\npre-trained representations and only allow minimum updates or even no updates\nof the backbone models during the training of continual learning. In this\npaper, we question whether the complexity of these models is needed to achieve\ngood performance by comparing them to a simple baseline that we designed. We\nargue that the pretrained feature extractor itself can be strong enough to\nachieve a competitive or even better continual learning performance on\nSplit-CIFAR100 and CoRe 50 benchmarks. To validate this, we conduct a very\nsimple baseline that 1) use the frozen pretrained model to extract image\nfeatures for every class encountered during the continual learning stage and\ncompute their corresponding mean features on training data, and 2) predict the\nclass of the input based on the nearest neighbor distance between test samples\nand mean features of the classes; i.e., Nearest Mean Classifier (NMC). This\nbaseline is single-headed, exemplar-free, and can be task-free (by updating the\nmeans continually). This baseline achieved 88.53% on 10-Split-CIFAR-100,\nsurpassing most state-of-the-art continual learning methods that are all\ninitialized using the same pretrained transformer model. We hope our baseline\nmay encourage future progress in designing learning systems that can\ncontinually add quality to the learning representations even if they started\nfrom some pretrained weights.",
    "descriptor": "\nComments: 6 pages, Under review , Code available at this https URL\n",
    "authors": [
      "Paul Janson",
      "Wenxuan Zhang",
      "Rahaf Aljundi",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04428"
  },
  {
    "id": "arXiv:2210.04432",
    "title": "Spectral Geometric Verification: Re-Ranking Point Cloud Retrieval for  Metric Localization",
    "abstract": "Although re-ranking methods are widely used in many retrieval tasks to\nimprove performance, they haven't been studied in the context of point cloud\nretrieval for metric localization. In this letter, we introduce Spectral\nGeometric Verification (SpectralGV), for the re-ranking of retrieved point\nclouds. We demonstrate how the optimal inter-cluster score of the\ncorrespondence compatibility graph of two point clouds can be used as a robust\nfitness score representing their geometric compatibility, hence allowing\ngeometric verification without registration. Compared to the baseline geometric\nverification based re-ranking methods which first register all retrieved point\nclouds with the query and then sort retrievals based on the inlier-ratio after\nregistration, our method is considerably more efficient and provides a\ndeterministic re-ranking solution while remaining robust to outliers. We\ndemonstrate how our method boosts the performance of several\ncorrespondence-based architectures across 5 different large-scale point cloud\ndatasets. We also achieve state-of-the-art results for both place recognition\nand metric-localization on these datasets. To the best of our knowledge, this\nletter is also the first to explore re-ranking in the point cloud retrieval\ndomain for the task of metric localization. The open-source implementation will\nbe made available at: https://github.com/csiro-robotics/SpectralGV.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Kavisha Vidanapathirana",
      "Peyman Moghadam",
      "Sridha Sridharan",
      "Clinton Fookes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04432"
  },
  {
    "id": "arXiv:2210.04434",
    "title": "Improving Code Review with GitHub Issue Tracking",
    "abstract": "Software quality is an important problem for technology companies, since it\nsubstantially impacts the efficiency, usefulness, and maintainability of the\nfinal product; hence, code review is a must-do activity for software\ndevelopers. During the code review process, senior engineers monitor other\ndevelopers' work to spot possible problems and enforce coding standards. One of\nthe most widely used open-source software platforms, GitHub, attracts millions\nof developers who use it to store their projects. This study aims to analyze\ncode quality on GitHub from the standpoint of code reviews. We examined the\ncode review process using GitHub's Issues Tracker, which allows team members to\nevaluate, discuss, and share their opinions on the proposed code before it is\napproved. Based on our analysis, we present a novel approach for improving the\ncode review process by promoting regularity and community involvement.",
    "descriptor": "\nComments: To appear in the International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2022)\n",
    "authors": [
      "Abduljaleel Al-Rubaye",
      "Gita Sukthankar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04434"
  },
  {
    "id": "arXiv:2210.04435",
    "title": "Creating a Dynamic Quadrupedal Robotic Goalkeeper with Reinforcement  Learning",
    "abstract": "We present a reinforcement learning (RL) framework that enables quadrupedal\nrobots to perform soccer goalkeeping tasks in the real world. Soccer\ngoalkeeping using quadrupeds is a challenging problem, that combines highly\ndynamic locomotion with precise and fast non-prehensile object (ball)\nmanipulation. The robot needs to react to and intercept a potentially flying\nball using dynamic locomotion maneuvers in a very short amount of time, usually\nless than one second. In this paper, we propose to address this problem using a\nhierarchical model-free RL framework. The first component of the framework\ncontains multiple control policies for distinct locomotion skills, which can be\nused to cover different regions of the goal. Each control policy enables the\nrobot to track random parametric end-effector trajectories while performing one\nspecific locomotion skill, such as jump, dive, and sidestep. These skills are\nthen utilized by the second part of the framework which is a high-level planner\nto determine a desired skill and end-effector trajectory in order to intercept\na ball flying to different regions of the goal. We deploy the proposed\nframework on a Mini Cheetah quadrupedal robot and demonstrate the effectiveness\nof our framework for various agile interceptions of a fast-moving ball in the\nreal world.",
    "descriptor": "\nComments: First two authors contributed equally. Accompanying video is at this https URL\n",
    "authors": [
      "Xiaoyu Huang",
      "Zhongyu Li",
      "Yanzhen Xiang",
      "Yiming Ni",
      "Yufeng Chi",
      "Yunhao Li",
      "Lizhi Yang",
      "Xue Bin Peng",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04435"
  },
  {
    "id": "arXiv:2210.04441",
    "title": "Fault-Tolerant Strassen-Like Matrix Multiplication",
    "abstract": "In this study, we propose a simple method for fault-tolerant Strassen-like\nmatrix multiplications. The proposed method is based on using two distinct\nStrassen-like algorithms instead of replicating a given one. We have realized\nthat using two different algorithms, new check relations arise resulting in\nmore local computations. These local computations are found using computer\naided search. To improve performance, special parity (extra) sub-matrix\nmultiplications (PSMMs) are generated (two of them) at the expense of\nincreasing communication/computation cost of the system. Our preliminary\nresults demonstrate that the proposed method outperforms a Strassen-like\nalgorithm with two copies and secures a very close performance to three copy\nversion using only 2 PSMMs, reducing the total number of compute nodes by\naround 24\\% i.e., from 21 to 16.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Osman B. Guney",
      "Suayb S. Arslan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04441"
  },
  {
    "id": "arXiv:2210.04442",
    "title": "Towards Training Graph Neural Networks with Node-Level Differential  Privacy",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in mining\ngraph-structured data. Despite the superior performance of GNNs in learning\ngraph representations, serious privacy concerns have been raised for the\ntrained models which could expose the sensitive information of graphs. We\nconduct the first formal study of training GNN models to ensure utility while\nsatisfying the rigorous node-level differential privacy considering the private\ninformation of both node features and edges. We adopt the training framework\nutilizing personalized PageRank to decouple the message-passing process from\nfeature aggregation during training GNN models and propose differentially\nprivate PageRank algorithms to protect graph topology information formally.\nFurthermore, we analyze the privacy degradation caused by the sampling process\ndependent on the differentially private PageRank results during model training\nand propose a differentially private GNN (DPGNN) algorithm to further protect\nnode features and achieve rigorous node-level differential privacy. Extensive\nexperiments on real-world graph datasets demonstrate the effectiveness of the\nproposed algorithms for providing node-level differential privacy while\npreserving good model utility.",
    "descriptor": "",
    "authors": [
      "Qiuchen Zhang",
      "Jing Ma",
      "Jian Lou",
      "Carl Yang",
      "Li Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04442"
  },
  {
    "id": "arXiv:2210.04443",
    "title": "Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue",
    "abstract": "Embodied dialogue instruction following requires an agent to complete a\ncomplex sequence of tasks from a natural language exchange. The recent\nintroduction of benchmarks (Padmakumar et al., 2022) raises the question of how\nbest to train and evaluate models for this multi-turn, multi-agent,\nlong-horizon task. This paper contributes to that conversation, by arguing that\nimitation learning (IL) and related low-level metrics are actually misleading\nand do not align with the goals of embodied dialogue research and may hinder\nprogress. We provide empirical comparisons of metrics, analysis of three\nmodels, and make suggestions for how the field might best progress. First, we\nobserve that models trained with IL take spurious actions during evaluation.\nSecond, we find that existing models fail to ground query utterances, which are\nessential for task completion. Third, we argue evaluation should focus on\nhigher-level semantic goals.",
    "descriptor": "\nComments: To Appear in the Proceedings of EMNLP 2022\n",
    "authors": [
      "So Yeon Min",
      "Hao Zhu",
      "Ruslan Salakhutdinov",
      "Yonatan Bisk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04443"
  },
  {
    "id": "arXiv:2210.04446",
    "title": "Dimensional synthesis of spatial manipulators for velocity and force  transmission for operation around a specified task point",
    "abstract": "Dimensional synthesis refers to design of the dimensions of manipulators by\noptimising different kinds of performance indices. The motivation of this study\nis to perform dimensional synthesis for a wide set of spatial manipulators by\noptimising the manipulability of each manipulator around a pre-defined task\npoint in the workspace and to finally give a prescription of manipulators along\nwith their dimensions optimised for velocity and force transmission. A\nsystematic method to formulate Jacobian matrix of a manipulator is presented.\nOptimisation of manipulability is performed for manipulation of the\nend-effector around a chosen task point for 96 1-DOF manipulators, 645 2-DOF\nmanipulators, 8 3-DOF manipulators and 15 4-DOF manipulators taken from the\nresult of enumeration of manipulators that is done in its companion paper\ndevoted to enumeration of possible manipulators up to a number of links.\nPrescriptions for these sets of manipulators are presented along with their\nscaled condition numbers and their ordered indices. This gives the designer a\nprescription of manipulators with their optimised dimensions that reflects the\nperformance of the end-effector around the given task point for velocity and\nforce transmission.",
    "descriptor": "",
    "authors": [
      "Akkarapakam Suneesh Jacob",
      "Bhaskar Dasgupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04446"
  },
  {
    "id": "arXiv:2210.04447",
    "title": "CrowdChecked: Detecting Previously Fact-Checked Claims in Social Media",
    "abstract": "While there has been substantial progress in developing systems to automate\nfact-checking, they still lack credibility in the eyes of the users. Thus, an\ninteresting approach has emerged: to perform automatic fact-checking by\nverifying whether an input claim has been previously fact-checked by\nprofessional fact-checkers and to return back an article that explains their\ndecision. This is a sensible approach as people trust manual fact-checking, and\nas many claims are repeated multiple times. Yet, a major issue when building\nsuch systems is the small number of known tweet--verifying article pairs\navailable for training. Here, we aim to bridge this gap by making use of crowd\nfact-checking, i.e., mining claims in social media for which users have\nresponded with a link to a fact-checking article. In particular, we mine a\nlarge-scale collection of 330,000 tweets paired with a corresponding\nfact-checking article. We further propose an end-to-end framework to learn from\nthis noisy data based on modified self-adaptive training, in a distant\nsupervision scenario. Our experiments on the CLEF'21 CheckThat! test set show\nimprovements over the state of the art by two points absolute. Our code and\ndatasets are available at https://github.com/mhardalov/crowdchecked-claims",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022 (Main Conference)\n",
    "authors": [
      "Momchil Hardalov",
      "Anton Chernyavskiy",
      "Ivan Koychev",
      "Dmitry Ilvovsky",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04447"
  },
  {
    "id": "arXiv:2210.04449",
    "title": "RTSDF: Generating Signed Distance Fields in Real Time for Soft Shadow  Rendering",
    "abstract": "Signed Distance Fields (SDFs) for surface representation are commonly\ngenerated offline and subsequently loaded into interactive applications like\ngames. Since they are not updated every frame, they only provide a rigid\nsurface representation. While there are methods to generate them quickly on\nGPU, the efficiency of these approaches is limited at high resolutions. This\npaper showcases a novel technique that combines jump flooding and ray tracing\nto generate approximate SDFs in real-time for soft shadow approximation,\nachieving prominent shadow penumbras while maintaining interactive frame rates.",
    "descriptor": "",
    "authors": [
      "Yu Wei Tan",
      "Nicholas Chua",
      "Clarence Koh",
      "Anand Bhojan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.04449"
  },
  {
    "id": "arXiv:2210.04451",
    "title": "Self-move and Other-move: Quantum Categorical Foundations of Japanese",
    "abstract": "The purpose of this work is to contribute toward the larger goal of creating\na Quantum Natural Language Processing (QNLP) translator program. This work\ncontributes original diagrammatic representations of the Japanese language\nbased on prior work that accomplished on the English language based on category\ntheory. The germane differences between the English and Japanese languages are\nemphasized to help address English language bias in the current body of\nresearch. Additionally, topological principles of these diagrams and many\npotential avenues for further research are proposed. Why is this endeavor\nimportant? Hundreds of languages have developed over the course of millennia\ncoinciding with the evolution of human interaction across time and geographic\nlocation. These languages are foundational to human survival, experience,\nflourishing, and living the good life. They are also, however, the strongest\nbarrier between people groups. Over the last several decades, advancements in\nNatural Language Processing (NLP) have made it easier to bridge the gap between\nindividuals who do not share a common language or culture. Tools like Google\nTranslate and DeepL make it easier than ever before to share our experiences\nwith people globally. Nevertheless, these tools are still inadequate as they\nfail to convey our ideas across the language barrier fluently, leaving people\nfeeling anxious and embarrassed. This is particularly true of languages born\nout of substantially different cultures, such as English and Japanese. Quantum\ncomputers offer the best chance to achieve translation fluency in that they are\nbetter suited to simulating the natural world and natural phenomenon such as\nnatural speech.\nKeywords: category theory, DisCoCat, DisCoCirc, Japanese grammar, English\ngrammar, translation, topology, Quantum Natural Language Processing, Natural\nLanguage Processing",
    "descriptor": "\nComments: 104 pages; 31 figures; 9 tables\n",
    "authors": [
      "Ryder Dale Walton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04451"
  },
  {
    "id": "arXiv:2210.04456",
    "title": "The Guilty (Silicon) Mind: Blameworthiness and Liability in  Human-Machine Teaming",
    "abstract": "As human science pushes the boundaries towards the development of artificial\nintelligence (AI), the sweep of progress has caused scholars and policymakers\nalike to question the legality of applying or utilising AI in various human\nendeavours. For example, debate has raged in international scholarship about\nthe legitimacy of applying AI to weapon systems to form lethal autonomous\nweapon systems (LAWS). Yet the argument holds true even when AI is applied to a\nmilitary autonomous system that is not weaponised: how does one hold a machine\naccountable for a crime? What about a tort? Can an artificial agent understand\nthe moral and ethical content of its instructions? These are thorny questions,\nand in many cases these questions have been answered in the negative, as\nartificial entities lack any contingent moral agency. So what if the AI is not\nalone, but linked with or overseen by a human being, with their own moral and\nethical understandings and obligations? Who is responsible for any malfeasance\nthat may be committed? Does the human bear the legal risks of unethical or\nimmoral decisions by an AI? These are some of the questions this manuscript\nseeks to engage with.",
    "descriptor": "",
    "authors": [
      "Dr Brendan Walker-Munro",
      "Dr Zena Assaad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04456"
  },
  {
    "id": "arXiv:2210.04457",
    "title": "XPrompt: Exploring the Extreme of Prompt Tuning",
    "abstract": "Prompt tuning learns soft prompts to condition frozen Pre-trained Language\nModels (PLMs) for performing downstream tasks in a parameter-efficient manner.\nWhile prompt tuning has gradually reached the performance level of fine-tuning\nas the model scale increases, there is still a large performance gap between\nprompt tuning and fine-tuning for models of moderate and small scales\n(typically less than 11B parameters). In this paper, we empirically show that\nthe trained prompt tokens can have a negative impact on a downstream task and\nthus degrade its performance. To bridge the gap, we propose a novel Prompt\ntuning model with an eXtremely small scale (XPrompt) under the regime of\nlottery tickets hypothesis. Specifically, XPrompt eliminates the negative\nprompt tokens at different granularity levels through a hierarchical structured\npruning, yielding a more parameter-efficient prompt yet with a competitive\nperformance. Comprehensive experiments are carried out on SuperGLUE tasks, and\nthe extensive results indicate that XPrompt is able to close the performance\ngap at smaller model scales.",
    "descriptor": "\nComments: 15 pages, accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Fang Ma",
      "Chen Zhang",
      "Lei Ren",
      "Jingang Wang",
      "Qifan Wang",
      "Wei Wu",
      "Xiaojun Quan",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04457"
  },
  {
    "id": "arXiv:2210.04458",
    "title": "OGC: Unsupervised 3D Object Segmentation from Rigid Dynamics of Point  Clouds",
    "abstract": "In this paper, we study the problem of 3D object segmentation from raw point\nclouds. Unlike all existing methods which usually require a large amount of\nhuman annotations for full supervision, we propose the first unsupervised\nmethod, called OGC, to simultaneously identify multiple 3D objects in a single\nforward pass, without needing any type of human annotations. The key to our\napproach is to fully leverage the dynamic motion patterns over sequential point\nclouds as supervision signals to automatically discover rigid objects. Our\nmethod consists of three major components, 1) the object segmentation network\nto directly estimate multi-object masks from a single point cloud frame, 2) the\nauxiliary self-supervised scene flow estimator, and 3) our core object geometry\nconsistency component. By carefully designing a series of loss functions, we\neffectively take into account the multi-object rigid consistency and the object\nshape invariance in both temporal and spatial scales. This allows our method to\ntruly discover the object geometry even in the absence of annotations. We\nextensively evaluate our method on five datasets, demonstrating the superior\nperformance for object part instance segmentation and general object\nsegmentation in both indoor and the challenging outdoor scenarios.",
    "descriptor": "\nComments: NeurIPS 2022. Code and data are available at: this https URL\n",
    "authors": [
      "Ziyang Song",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04458"
  },
  {
    "id": "arXiv:2210.04466",
    "title": "Investigating the Failure Modes of the AUC metric and Exploring  Alternatives for Evaluating Systems in Safety Critical Applications",
    "abstract": "With the increasing importance of safety requirements associated with the use\nof black box models, evaluation of selective answering capability of models has\nbeen critical. Area under the curve (AUC) is used as a metric for this purpose.\nWe find limitations in AUC; e.g., a model having higher AUC is not always\nbetter in performing selective answering. We propose three alternate metrics\nthat fix the identified limitations. On experimenting with ten models, our\nresults using the new metrics show that newer and larger pre-trained models do\nnot necessarily show better performance in selective answering. We hope our\ninsights will help develop better models tailored for safety-critical\napplications.",
    "descriptor": "",
    "authors": [
      "Swaroop Mishra",
      "Anjana Arunkumar",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04466"
  },
  {
    "id": "arXiv:2210.04468",
    "title": "Distill the Image to Nowhere: Inversion Knowledge Distillation for  Multimodal Machine Translation",
    "abstract": "Past works on multimodal machine translation (MMT) elevate bilingual setup by\nincorporating additional aligned vision information. However, an image-must\nrequirement of the multimodal dataset largely hinders MMT's development --\nnamely that it demands an aligned form of [image, source text, target text].\nThis limitation is generally troublesome during the inference phase especially\nwhen the aligned image is not provided as in the normal NMT setup. Thus, in\nthis work, we introduce IKD-MMT, a novel MMT framework to support the\nimage-free inference phase via an inversion knowledge distillation scheme. In\nparticular, a multimodal feature generator is executed with a knowledge\ndistillation module, which directly generates the multimodal feature from\n(only) source texts as the input. While there have been a few prior works\nentertaining the possibility to support image-free inference for machine\ntranslation, their performances have yet to rival the image-must translation.\nIn our experiments, we identify our method as the first image-free approach to\ncomprehensively rival or even surpass (almost) all image-must frameworks, and\nachieved the state-of-the-art result on the often-used Multi30k benchmark. Our\ncode and data are available at: https://github.com/pengr/IKD-mmt/tree/master..",
    "descriptor": "\nComments: Long paper accepted by EMNLP2022 main conference\n",
    "authors": [
      "Ru Peng",
      "Yawen Zeng",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04468"
  },
  {
    "id": "arXiv:2210.04470",
    "title": "Actor-Critic or Critic-Actor? A Tale of Two Time Scales",
    "abstract": "We revisit the standard formulation of tabular actor-critic algorithm as a\ntwo time-scale stochastic approximation with value function computed on a\nfaster time-scale and policy computed on a slower time-scale. This emulates\npolicy iteration. We begin by observing that reversal of the time scales will\nin fact emulate value iteration and is a legitimate algorithm. We compare the\ntwo empirically with and without function approximation (with both linear and\nnonlinear function approximators) and observe that our proposed critic-actor\nalgorithm performs better empirically though with a marginal increase in the\ncomputational cost.",
    "descriptor": "",
    "authors": [
      "Shalabh Bhatnagar",
      "Vivek S. Borkar",
      "Soumyajit Guin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04470"
  },
  {
    "id": "arXiv:2210.04471",
    "title": "Generalized Unique Reconstruction from Substrings",
    "abstract": "This paper introduces a new family of reconstruction codes which is motivated\nby applications in DNA data storage and sequencing. In such applications, DNA\nstrands are sequenced by reading some subset of their substrings. While\nprevious works considered two extreme cases in which all substrings of\npre-defined lengths are read or substrings are read with no overlap for the\nsingle string case, this work studies two extensions of this paradigm. The\nfirst extension considers the setup in which consecutive substrings are read\nwith some given minimum overlap. First, an upper bound is provided on the\nattainable rates of codes that guarantee unique reconstruction. Then, efficient\nconstructions of codes that asymptotically meet that upper bound are presented.\nIn the second extension, we study the setup where multiple strings are\nreconstructed together. Given the number of strings and their length, we first\nderive a lower bound on the read substrings' length $\\ell$ that is necessary\nfor the existence of multi-strand reconstruction codes with non-vanishing\nrates. We then present two constructions of such codes and show that their\nrates approach 1 for values of $\\ell$ that asymptotically behave like the lower\nbound.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.03933\n",
    "authors": [
      "Yonatan Yehezkeally",
      "Daniella Bar-Lev",
      "Sagi Marcovich",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04471"
  },
  {
    "id": "arXiv:2210.04472",
    "title": "Uncertainty-aware LiDAR Panoptic Segmentation",
    "abstract": "Modern autonomous systems often rely on LiDAR scanners, in particular for\nautonomous driving scenarios. In this context, reliable scene understanding is\nindispensable. Current learning-based methods typically try to achieve maximum\nperformance for this task, while neglecting a proper estimation of the\nassociated uncertainties. In this work, we introduce a novel approach for\nsolving the task of uncertainty-aware panoptic segmentation using LiDAR point\nclouds. Our proposed EvLPSNet network is the first to solve this task\nefficiently in a sampling-free manner. It aims to predict per-point semantic\nand instance segmentations, together with per-point uncertainty estimates.\nMoreover, it incorporates methods for improving the performance by employing\nthe predicted uncertainties. We provide several strong baselines combining\nstate-of-the-art panoptic segmentation networks with sampling-free uncertainty\nestimation techniques. Extensive evaluations show that we achieve the best\nperformance on uncertainty-aware panoptic segmentation quality and calibration\ncompared to these baselines. We make our code available at:\n\\url{https://github.com/kshitij3112/EvLPSNet}",
    "descriptor": "",
    "authors": [
      "Kshitij Sirohi",
      "Sajad Marvi",
      "Daniel B\u00fcscher",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04472"
  },
  {
    "id": "arXiv:2210.04473",
    "title": "Leveraging Key Information Modeling to Improve Less-Data Constrained  News Headline Generation via Duality Fine-Tuning",
    "abstract": "Recent language generative models are mostly trained on large-scale datasets,\nwhile in some real scenarios, the training datasets are often expensive to\nobtain and would be small-scale. In this paper we investigate the challenging\ntask of less-data constrained generation, especially when the generated news\nheadlines are short yet expected by readers to keep readable and informative\nsimultaneously. We highlight the key information modeling task and propose a\nnovel duality fine-tuning method by formally defining the probabilistic duality\nconstraints between key information prediction and headline generation tasks.\nThe proposed method can capture more information from limited data, build\nconnections between separate tasks, and is suitable for less-data constrained\ngeneration tasks. Furthermore, the method can leverage various pre-trained\ngenerative regimes, e.g., autoregressive and encoder-decoder models. We conduct\nextensive experiments to demonstrate that our method is effective and efficient\nto achieve improved performance in terms of language modeling metric and\ninformativeness correctness metric on two public datasets.",
    "descriptor": "\nComments: Accepted by AACL-IJCNLP 2022 main conference\n",
    "authors": [
      "Zhuoxuan Jiang",
      "Lingfeng Qiao",
      "Di Yin",
      "Shanshan Feng",
      "Bo Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04473"
  },
  {
    "id": "arXiv:2210.04474",
    "title": "Rethinking Wireless Communication Security in Semantic Internet of  Things",
    "abstract": "Semantic communication is an important participant in the next generation of\nwireless communications. Enabled by this novel paradigm, the conventional\nInternet-of-Things (IoT) is evolving toward the semantic IoT (SIoT) to achieve\nsignificant system performance improvements. However, traditional wireless\ncommunication security techniques for bit transmission cannot be applied\ndirectly to the SIoT that focuses on semantic information transmission. One key\nreason is the lack of new security performance indicators. Thus, we have to\nrethink the wireless communication security in the SIoT. As such, in the paper,\nwe analyze and compare classical security techniques, i.e., physical layer\nsecurity, covert communications, and encryption, from the perspective of\nsemantic information security. We highlight the differences among these\nsecurity techniques when applied to the SIoT. Novel performance indicators such\nas semantic secrecy outage probability (for physical layer security techniques)\nand detection error expectation (for covert communication techniques) are\nproposed. Considering that semantic communications can raise new security\nissues, we then review attack and defense methods at the semantic level.\nFinally, we present several promising directions for future secure SIoT\nresearch.",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Mohsen Guizani",
      "Dong In Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.04474"
  },
  {
    "id": "arXiv:2210.04475",
    "title": "Optimal Hybrid Multiplexed AC-DC-AC converters",
    "abstract": "The flexibility of multi-terminal AC-DC-AC converters connected in\ndistribution networks can be increased by changing the sizes of the individual\nAC-DC converter stages and connecting the AC side of those converters to\nelectromechanical switches (multiplexers) to allow reconfiguration within the\nnetwork. The combinations of real powers that can be transferred by such a\ndesign can be described using a capability chart. In this work, it is proposed\nthat the area of these capability charts is a meaningful metric for describing\nthe flexibility of such a device. These capability chart areas are calculated\nin closed form for a three-terminal AC-DC-AC device consisting of three AC-DC\nconverters of arbitrary sizes, allowing the optimal AC-DC converter sizing to\nbe determined to maximise this area. It is shown that this optimal design\nyields a capability chart area that is 64% larger than the equivalent area from\na conventional equally-sized AC-DC-AC converter. Converters which are optimal\nin other senses are discussed, such as a design with 10% increased per-feeder\nreal power transfer, albeit with an 8% area reduction. It is concluded that the\ncapability chart area is an intuitive and informative approach for describing\nthe increased flexibility of multiplexed AC-DC-AC converters.",
    "descriptor": "\nComments: Submitted to ACDC conference 2023 (Glasgow, UK)\n",
    "authors": [
      "Matthew Deakin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04475"
  },
  {
    "id": "arXiv:2210.04476",
    "title": "Using Both Demonstrations and Language Instructions to Efficiently Learn  Robotic Tasks",
    "abstract": "Demonstrations and natural language instructions are two common ways to\nspecify and teach robots novel tasks. However, for many complex tasks, a\ndemonstration or language instruction alone contains ambiguities, preventing\ntasks from being specified clearly. In such cases, a combination of both a\ndemonstration and an instruction more concisely and effectively conveys the\ntask to the robot than either modality alone. To instantiate this problem\nsetting, we train a single multi-task policy on a few hundred challenging\nrobotic pick-and-place tasks and propose DeL-TaCo (Joint Demo-Language Task\nConditioning), a method for conditioning a robotic policy on task embeddings\ncomprised of two components: a visual demonstration and a language instruction.\nBy allowing these two modalities to mutually disambiguate and clarify each\nother during novel task specification, DeL-TaCo (1) substantially decreases the\nteacher effort needed to specify a new task and (2) achieves better\ngeneralization performance on novel objects and instructions over previous\ntask-conditioning methods. To our knowledge, this is the first work to show\nthat simultaneously conditioning a multi-task robotic manipulation policy on\nboth demonstration and language embeddings improves sample efficiency and\ngeneralization over conditioning on either modality alone. See additional\nmaterials at https://sites.google.com/view/del-taco-learning",
    "descriptor": "\nComments: 20 pages, 9 figures. Project website at this https URL\n",
    "authors": [
      "Albert Yu",
      "Raymond J. Mooney"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04476"
  },
  {
    "id": "arXiv:2210.04477",
    "title": "HiCo: Hierarchical Contrastive Learning for Ultrasound Video Model  Pretraining",
    "abstract": "The self-supervised ultrasound (US) video model pretraining can use a small\namount of labeled data to achieve one of the most promising results on US\ndiagnosis. However, it does not take full advantage of multi-level knowledge\nfor learning deep neural networks (DNNs), and thus is difficult to learn\ntransferable feature representations. This work proposes a hierarchical\ncontrastive learning (HiCo) method to improve the transferability for the US\nvideo model pretraining. HiCo introduces both peer-level semantic alignment and\ncross-level semantic alignment to facilitate the interaction between different\nsemantic levels, which can effectively accelerate the convergence speed,\nleading to better generalization and adaptation of the learned model.\nAdditionally, a softened objective function is implemented by smoothing the\nhard labels, which can alleviate the negative effect caused by local\nsimilarities of images between different classes. Experiments with HiCo on five\ndatasets demonstrate its favorable results over state-of-the-art approaches.\nThe source code of this work is publicly available at\n\\url{https://github.com/983632847/HiCo}.",
    "descriptor": "\nComments: Paper accepted in ACCV 2022\n",
    "authors": [
      "Chunhui Zhang",
      "Yixiong Chen",
      "Li Liu",
      "Qiong Liu",
      "Xi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04477"
  },
  {
    "id": "arXiv:2210.04480",
    "title": "Adaptive shape optimization with NURBS designs and PHT-splines for  solution approximation in time-harmonic acoustics",
    "abstract": "Geometry Independent Field approximaTion (GIFT) was proposed as a\ngeneralization of Isogeometric analysis (IGA), where different types of splines\nare used for the parameterization of the computational domain and approximation\nof the unknown solution. GIFT with Non-Uniform Rational B-Splines (NUBRS) for\nthe geometry and PHT-splines for the solution approximation were successfully\napplied to problems of time-harmonic acoustics, where it was shown that in some\ncases, adaptive PHT-spline mesh yields highly accurate solutions at lower\ncomputational cost than methods with uniform refinement. Therefore, it is of\ninterest to investigate performance of GIFT for shape optimization problems,\nwhere NURBS are used to model the boundary with their control points being the\ndesign variables and PHT-splines are used to approximate the solution\nadaptively to the boundary changes during the optimization process.\nIn this work we demonstrate the application of GIFT for 2D acoustic shape\noptimization problems and, using three benchmark examples, we show that the\nmethod yields accurate solutions with significant computational savings in\nterms of the number of degrees of freedom and computational time.",
    "descriptor": "",
    "authors": [
      "Javier Videla",
      "Ahmed Mostafa Shaaban",
      "Elena Atroshchenko"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.04480"
  },
  {
    "id": "arXiv:2210.04483",
    "title": "Auxilio: A Sensor-Based Wireless Head-Mounted Mouse for People with  Upper Limb Disability",
    "abstract": "Upper limb disability may be caused either due to accidents, neurological\ndisorders, or even birth defects, imposing limitations and restrictions on the\ninteraction with a computer for the concerned individuals using a generic\noptical mouse. Our work proposes the design and development of a working\nprototype of a sensor-based wireless head-mounted Assistive Mouse Controller\n(AMC), Auxilio, facilitating interaction with a computer for people with upper\nlimb disability. Combining commercially available, low-cost motion and infrared\nsensors, Auxilio solely utilizes head and cheek movements for mouse control.\nIts performance has been juxtaposed with that of a generic optical mouse in\ndifferent pointing tasks as well as in typing tasks, using a virtual keyboard.\nFurthermore, our work also analyzes the usability of Auxilio, featuring the\nSystem Usability Scale. The results of different experiments reveal the\npracticality and effectiveness of Auxilio as a head-mounted AMC for empowering\nthe upper limb disabled community.",
    "descriptor": "\nComments: 28 pages, 9 figures, 5 tables\n",
    "authors": [
      "Mohammad Ridwan Kabir",
      "Mohammad Ishrak Abedin",
      "Rizvi Ahmed",
      "Saad Bin Ashraf",
      "Hasan Mahmud",
      "Md. Kamrul Hasan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04483"
  },
  {
    "id": "arXiv:2210.04484",
    "title": "The Easiest Way of Turning your Relational Database into a Blockchain --  and the Cost of Doing So",
    "abstract": "Blockchain systems essentially consist of two levels: The network level has\nthe responsibility of distributing an ordered stream of transactions to all\nnodes of the network in exactly the same way, even in the presence of a certain\namount of malicious parties (byzantine fault tolerance). On the node level,\neach node then receives this ordered stream of transactions and executes it\nwithin some sort of transaction processing system, typically to alter some kind\nof state. This clear separation into two levels as well as drastically\ndifferent application requirements have led to the materialization of the\nnetwork level in form of so-called blockchain frameworks. While providing all\nthe \"blockchain features\", these frameworks leave the node level backend\nflexible or even left to be implemented depending on the specific needs of the\napplication.\nIn the following paper, we present how to integrate a highly versatile\ntransaction processing system, namely a relational DBMS, into such a blockchain\nframework. As framework, we use the popular Tendermint Core, now part of the\nIgnite/Cosmos eco-system, which can run both public and permissioned networks\nand combine it with relational DBMSs as the backend. This results in a\n\"relational blockchain\", which is able to run deterministic SQL on a fully\nreplicated relational database. Apart from presenting the integration and its\npitfalls, we will carefully evaluate the performance implications of such\ncombinations, in particular, the throughput and latency overhead caused by the\nblockchain layer on top of the DBMS. As a result, we give recommendations on\nhow to run such a systems combination efficiently in practice.",
    "descriptor": "",
    "authors": [
      "Felix Schuhknecht",
      "Simon J\u00f6rz"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.04484"
  },
  {
    "id": "arXiv:2210.04485",
    "title": "A Memory Transformer Network for Incremental Learning",
    "abstract": "We study class-incremental learning, a training setup in which new classes of\ndata are observed over time for the model to learn from. Despite the\nstraightforward problem formulation, the naive application of classification\nmodels to class-incremental learning results in the \"catastrophic forgetting\"\nof previously seen classes. One of the most successful existing methods has\nbeen the use of a memory of exemplars, which overcomes the issue of\ncatastrophic forgetting by saving a subset of past data into a memory bank and\nutilizing it to prevent forgetting when training future tasks. In our paper, we\npropose to enhance the utilization of this memory bank: we not only use it as a\nsource of additional training data like existing works but also integrate it in\nthe prediction process explicitly.Our method, the Memory Transformer Network\n(MTN), learns how to combine and aggregate the information from the nearest\nneighbors in the memory with a transformer to make more accurate predictions.\nWe conduct extensive experiments and ablations to evaluate our approach. We\nshow that MTN achieves state-of-the-art performance on the challenging\nImageNet-1k and Google-Landmarks-1k incremental learning benchmarks.",
    "descriptor": "",
    "authors": [
      "Ahmet Iscen",
      "Thomas Bird",
      "Mathilde Caron",
      "Alireza Fathi",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04485"
  },
  {
    "id": "arXiv:2210.04487",
    "title": "Quasi-cyclic Hermitian construction of binary quantum codes",
    "abstract": "In this paper, we propose a sufficient condition for a family of 2-generator\nself-orthogonal quasi-cyclic codes with respect to Hermitian inner product.\nSupported in the Hermitian construction, we show algebraic constructions of\ngood quantum codes. 30 new binary quantum codes with good parameters improving\nthe best-known lower bounds on minimum distance in Grassl's code tables\n\\cite{Grassl:codetables} are constructed.",
    "descriptor": "",
    "authors": [
      "Liangdong Lu",
      "Chaofeng Guan",
      "Ruihu Li",
      "Yuezhen Ren"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04487"
  },
  {
    "id": "arXiv:2210.04490",
    "title": "Semantic Framework based Query Generation for Temporal Question  Answering over Knowledge Graphs",
    "abstract": "Answering factual questions with temporal intent over knowledge graphs\n(temporal KGQA) attracts rising attention in recent years. In the generation of\ntemporal queries, existing KGQA methods ignore the fact that some intrinsic\nconnections between events can make them temporally related, which may limit\ntheir capability. We systematically analyze the possible interpretation of\ntemporal constraints and conclude the interpretation structures as the Semantic\nFramework of Temporal Constraints, SF-TCons. Based on the semantic framework,\nwe propose a temporal question answering method, SF-TQA, which generates query\ngraphs by exploring the relevant facts of mentioned entities, where the\nexploring process is restricted by SF-TCons. Our evaluations show that SF-TQA\nsignificantly outperforms existing methods on two benchmarks over different\nknowledge graphs.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Weantao Ding",
      "Hao Chen",
      "Huayu Li",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04490"
  },
  {
    "id": "arXiv:2210.04491",
    "title": "A survey of Identification and mitigation of Machine Learning  algorithmic biases in Image Analysis",
    "abstract": "The problem of algorithmic bias in machine learning has gained a lot of\nattention in recent years due to its concrete and potentially hazardous\nimplications in society. In much the same manner, biases can also alter modern\nindustrial and safety-critical applications where machine learning are based on\nhigh dimensional inputs such as images. This issue has however been mostly left\nout of the spotlight in the machine learning literature. Contrarily to societal\napplications where a set of proxy variables can be provided by the common sense\nor by regulations to draw the attention on potential risks, industrial and\nsafety-critical applications are most of the times sailing blind. The variables\nrelated to undesired biases can indeed be indirectly represented in the input\ndata, or can be unknown, thus making them harder to tackle. This raises serious\nand well-founded concerns towards the commercial deployment of AI-based\nsolutions, especially in a context where new regulations clearly address the\nissues opened by undesired biases in AI. Consequently, we propose here to make\nan overview of recent advances in this area, firstly by presenting how such\nbiases can demonstrate themselves, then by exploring different ways to bring\nthem to light, and by probing different possibilities to mitigate them. We\nfinally present a practical remote sensing use-case of industrial Fairness.",
    "descriptor": "",
    "authors": [
      "Laurent Risser",
      "Agustin Picard",
      "Lucas Hervier",
      "Jean-Michel Loubes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04491"
  },
  {
    "id": "arXiv:2210.04492",
    "title": "Unified Detoxifying and Debiasing in Language Generation via  Inference-time Adaptive Optimization",
    "abstract": "Warning: this paper contains model outputs exhibiting offensiveness and\nbiases. Recently pre-trained language models (PLMs) have prospered in various\nnatural language generation (NLG) tasks due to their ability to generate fairly\nfluent text. Nevertheless, these models are observed to capture and reproduce\nharmful contents in training corpora, typically toxic language and social\nbiases, raising severe moral issues. Prior works on ethical NLG tackle\ndetoxifying and debiasing separately, which is problematic since we find\ndebiased models still exhibit toxicity while detoxified ones even exacerbate\nbiases. To address such a challenge, we propose the first unified framework of\ndetoxifying and debiasing called UDDIA, which jointly formalizes these two\nproblems as rectifying the output space. We theoretically interpret our\nframework as learning a text distribution mixing weighted attributes. Besides,\nUDDIA conducts adaptive optimization of only a few parameters during decoding\nbased on a parameter-efficient tuning schema without any training data. This\nleads to minimal generation quality loss and improved rectification performance\nwith acceptable computational cost. Experimental results demonstrate that\ncompared to several strong baselines, UDDIA achieves debiasing and detoxifying\nsimultaneously and better balances efficiency and effectiveness, taking a\nfurther step towards practical ethical NLG.",
    "descriptor": "\nComments: Work in Progress. Preprint\n",
    "authors": [
      "Zonghan Yang",
      "Xiaoyuan Yi",
      "Peng Li",
      "Yang Liu",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04492"
  },
  {
    "id": "arXiv:2210.04497",
    "title": "Learning Robust Representations for Continual Relation Extraction via  Adversarial Class Augmentation",
    "abstract": "Continual relation extraction (CRE) aims to continually learn new relations\nfrom a class-incremental data stream. CRE model usually suffers from\ncatastrophic forgetting problem, i.e., the performance of old relations\nseriously degrades when the model learns new relations. Most previous work\nattributes catastrophic forgetting to the corruption of the learned\nrepresentations as new relations come, with an implicit assumption that the CRE\nmodels have adequately learned the old relations. In this paper, through\nempirical studies we argue that this assumption may not hold, and an important\nreason for catastrophic forgetting is that the learned representations do not\nhave good robustness against the appearance of analogous relations in the\nsubsequent learning process. To address this issue, we encourage the model to\nlearn more precise and robust representations through a simple yet effective\nadversarial class augmentation mechanism (ACA), which is easy to implement and\nmodel-agnostic. Experimental results show that ACA can consistently improve the\nperformance of state-of-the-art CRE models on two popular benchmarks.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Peiyi Wang",
      "Yifan Song",
      "Tianyu Liu",
      "Binghuai Lin",
      "Yunbo Cao",
      "Sujian Li",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04497"
  },
  {
    "id": "arXiv:2210.04505",
    "title": "A Survey on Heterogeneous Federated Learning",
    "abstract": "Federated learning (FL) has been proposed to protect data privacy and\nvirtually assemble the isolated data silos by cooperatively training models\namong organizations without breaching privacy and security. However, FL faces\nheterogeneity from various aspects, including data space, statistical, and\nsystem heterogeneity. For example, collaborative organizations without conflict\nof interest often come from different areas and have heterogeneous data from\ndifferent feature spaces. Participants may also want to train heterogeneous\npersonalized local models due to non-IID and imbalanced data distribution and\nvarious resource-constrained devices. Therefore, heterogeneous FL is proposed\nto address the problem of heterogeneity in FL. In this survey, we\ncomprehensively investigate the domain of heterogeneous FL in terms of data\nspace, statistical, system, and model heterogeneity. We first give an overview\nof FL, including its definition and categorization. Then, We propose a precise\ntaxonomy of heterogeneous FL settings for each type of heterogeneity according\nto the problem setting and learning objective. We also investigate the transfer\nlearning methodologies to tackle the heterogeneity in FL. We further present\nthe applications of heterogeneous FL. Finally, we highlight the challenges and\nopportunities and envision promising future research directions toward new\nframework design and trustworthy approaches.",
    "descriptor": "\nComments: 46 pages, 10 figures, 10 tables\n",
    "authors": [
      "Dashan Gao",
      "Xin Yao",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04505"
  },
  {
    "id": "arXiv:2210.04506",
    "title": "Bridging CLIP and StyleGAN through Latent Alignment for Image Editing",
    "abstract": "Text-driven image manipulation is developed since the vision-language model\n(CLIP) has been proposed. Previous work has adopted CLIP to design a text-image\nconsistency-based objective to address this issue. However, these methods\nrequire either test-time optimization or image feature cluster analysis for\nsingle-mode manipulation direction. In this paper, we manage to achieve\ninference-time optimization-free diverse manipulation direction mining by\nbridging CLIP and StyleGAN through Latent Alignment (CSLA). More specifically,\nour efforts consist of three parts: 1) a data-free training strategy to train\nlatent mappers to bridge the latent space of CLIP and StyleGAN; 2) for more\nprecise mapping, temporal relative consistency is proposed to address the\nknowledge distribution bias problem among different latent spaces; 3) to refine\nthe mapped latent in s space, adaptive style mixing is also proposed. With this\nmapping scheme, we can achieve GAN inversion, text-to-image generation and\ntext-driven image manipulation. Qualitative and quantitative comparisons are\nmade to demonstrate the effectiveness of our method.",
    "descriptor": "\nComments: 20 pages, 23 figures\n",
    "authors": [
      "Wanfeng Zheng",
      "Qiang Li",
      "Xiaoyan Guo",
      "Pengfei Wan",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04506"
  },
  {
    "id": "arXiv:2210.04510",
    "title": "Multi-Modal Fusion Transformer for Visual Question Answering in Remote  Sensing",
    "abstract": "With the new generation of satellite technologies, the archives of remote\nsensing (RS) images are growing very fast. To make the intrinsic information of\neach RS image easily accessible, visual question answering (VQA) has been\nintroduced in RS. VQA allows a user to formulate a free-form question\nconcerning the content of RS images to extract generic information. It has been\nshown that the fusion of the input modalities (i.e., image and text) is crucial\nfor the performance of VQA systems. Most of the current fusion approaches use\nmodality-specific representations in their fusion modules instead of joint\nrepresentation learning. However, to discover the underlying relation between\nboth the image and question modality, the model is required to learn the joint\nrepresentation instead of simply combining (e.g., concatenating, adding, or\nmultiplying) the modality-specific representations. We propose a multi-modal\ntransformer-based architecture to overcome this issue. Our proposed\narchitecture consists of three main modules: i) the feature extraction module\nfor extracting the modality-specific features; ii) the fusion module, which\nleverages a user-defined number of multi-modal transformer layers of the\nVisualBERT model (VB); and iii) the classification module to obtain the answer.\nExperimental results obtained on the RSVQAxBEN and RSVQA-LR datasets (which are\nmade up of RGB bands of Sentinel-2 images) demonstrate the effectiveness of\nVBFusion for VQA tasks in RS. To analyze the importance of using other spectral\nbands for the description of the complex content of RS images in the framework\nof VQA, we extend the RSVQAxBEN dataset to include all the spectral bands of\nSentinel-2 images with 10m and 20m spatial resolution.",
    "descriptor": "\nComments: Accepted in SPIE Remote Sensing (ESI22R)\n",
    "authors": [
      "Tim Siebert",
      "Kai Norman Clasen",
      "Mahdyar Ravanbakhsh",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04510"
  },
  {
    "id": "arXiv:2210.04512",
    "title": "Numerical stability and efficiency of response property calculations in  density functional theory",
    "abstract": "Response calculations in density functional theory aim at computing the\nchange in ground-state density induced by an external perturbation. At finite\ntemperature these are usually performed by computing variations of orbitals,\nwhich involve the iterative solution of potentially badly-conditioned linear\nsystems, the Sternheimer equations. Since many sets of variations of orbitals\nyield the same variation of density matrix this involves a choice of gauge.\nTaking a numerical analysis point of view we present the various gauge choices\nproposed in the literature in a common framework and study their stability.\nBeyond existing methods we propose a new approach, based on a Schur complement\nusing extra orbitals from the self-consistent-field calculations, to improve\nthe stability and efficiency of the iterative solution of Sternheimer\nequations. We show the success of this strategy on nontrivial examples of\npractical interest, such as Heusler transition metal alloy compounds, where\nsavings of around 40% in the number of required cost-determining Hamiltonian\napplications have been achieved.",
    "descriptor": "",
    "authors": [
      "Eric Canc\u00e8s",
      "Michael F Herbst",
      "Gaspard Kemlin",
      "Antoine Levitt",
      "Benjamin Stamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2210.04512"
  },
  {
    "id": "arXiv:2210.04513",
    "title": "Improving Continual Relation Extraction through Prototypical Contrastive  Learning",
    "abstract": "Continual relation extraction (CRE) aims to extract relations towards the\ncontinuous and iterative arrival of new data, of which the major challenge is\nthe catastrophic forgetting of old tasks. In order to alleviate this critical\nproblem for enhanced CRE performance, we propose a novel Continual Relation\nExtraction framework with Contrastive Learning, namely CRECL, which is built\nwith a classification network and a prototypical contrastive network to achieve\nthe incremental-class learning of CRE. Specifically, in the contrastive network\na given instance is contrasted with the prototype of each candidate relations\nstored in the memory module. Such contrastive learning scheme ensures the data\ndistributions of all tasks more distinguishable, so as to alleviate the\ncatastrophic forgetting further. Our experiment results not only demonstrate\nour CRECL's advantage over the state-of-the-art baselines on two public\ndatasets, but also verify the effectiveness of CRECL's contrastive learning on\nimproving CRE performance.",
    "descriptor": "",
    "authors": [
      "Chengwei Hu",
      "Deqing Yang",
      "Haoliang Jin",
      "Zhen Chen",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.04513"
  },
  {
    "id": "arXiv:2210.04514",
    "title": "Self-Supervised 3D Human Pose Estimation in Static Video Via Neural  Rendering",
    "abstract": "Inferring 3D human pose from 2D images is a challenging and long-standing\nproblem in the field of computer vision with many applications including motion\ncapture, virtual reality, surveillance or gait analysis for sports and\nmedicine. We present preliminary results for a method to estimate 3D pose from\n2D video containing a single person and a static background without the need\nfor any manual landmark annotations. We achieve this by formulating a simple\nyet effective self-supervision task: our model is required to reconstruct a\nrandom frame of a video given a frame from another timepoint and a rendered\nimage of a transformed human shape template. Crucially for optimisation, our\nray casting based rendering pipeline is fully differentiable, enabling end to\nend training solely based on the reconstruction task.",
    "descriptor": "\nComments: CV4Metaverse Workshop @ ECCV 2022\n",
    "authors": [
      "Luca Schmidtke",
      "Benjamin Hou",
      "Athanasios Vlontzos",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.04514"
  },
  {
    "id": "arXiv:2210.04522",
    "title": "HORIZON: A High-Resolution Panorama Synthesis Framework",
    "abstract": "Panorama synthesis aims to generate a visual scene with all 360-degree views\nand enables an immersive virtual world. If the panorama synthesis process can\nbe semantically controlled, we can then build an interactive virtual world and\nform an unprecedented human-computer interaction experience. Existing panoramic\nsynthesis methods mainly focus on dealing with the inherent challenges brought\nby panoramas' spherical structure such as the projection distortion and the\nin-continuity problem when stitching edges, but is hard to effectively control\nsemantics. The recent success of visual synthesis like DALL.E generates\npromising 2D flat images with semantic control, however, it is hard to directly\nbe applied to panorama synthesis which inevitably generates distorted content.\nBesides, both of the above methods can not effectively synthesize\nhigh-resolution panoramas either because of quality or inference speed. In this\nwork, we propose a new generation framework for high-resolution panorama\nimages. The contributions include 1) alleviating the spherical distortion and\nedge in-continuity problem through spherical modeling, 2) supporting semantic\ncontrol through both image and text hints, and 3) effectively generating\nhigh-resolution panoramas through parallel decoding. Our experimental results\non a large-scale high-resolution Street View dataset validated the superiority\nof our approach quantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Kun Yan",
      "Lei Ji",
      "Chenfei Wu",
      "Jian Liang",
      "Ming Zhou",
      "Nan Duan",
      "Shuai Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04522"
  },
  {
    "id": "arXiv:2210.04524",
    "title": "Margin-Based Few-Shot Class-Incremental Learning with Class-Level  Overfitting Mitigation",
    "abstract": "Few-shot class-incremental learning (FSCIL) is designed to incrementally\nrecognize novel classes with only few training samples after the (pre-)training\non base classes with sufficient samples, which focuses on both base-class\nperformance and novel-class generalization. A well known modification to the\nbase-class training is to apply a margin to the base-class classification.\nHowever, a dilemma exists that we can hardly achieve both good base-class\nperformance and novel-class generalization simultaneously by applying the\nmargin during the base-class training, which is still under explored. In this\npaper, we study the cause of such dilemma for FSCIL. We first interpret this\ndilemma as a class-level overfitting (CO) problem from the aspect of pattern\nlearning, and then find its cause lies in the easily-satisfied constraint of\nlearning margin-based patterns. Based on the analysis, we propose a novel\nmargin-based FSCIL method to mitigate the CO problem by providing the pattern\nlearning process with extra constraint from the margin-based patterns\nthemselves. Extensive experiments on CIFAR100, Caltech-USCD Birds-200-2011\n(CUB200), and miniImageNet demonstrate that the proposed method effectively\nmitigates the CO problem and achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Yixiong Zou",
      "Shanghang Zhang",
      "Yuhua Li",
      "Ruixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04524"
  },
  {
    "id": "arXiv:2210.04525",
    "title": "SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup  Training",
    "abstract": "The conventional success of textual classification relies on annotated data,\nand the new paradigm of pre-trained language models (PLMs) still requires a few\nlabeled data for downstream tasks. However, in real-world applications, label\nnoise inevitably exists in training data, damaging the effectiveness,\nrobustness, and generalization of the models constructed on such data.\nRecently, remarkable achievements have been made to mitigate this dilemma in\nvisual data, while only a few explore textual data. To fill this gap, we\npresent SelfMix, a simple yet effective method, to handle label noise in text\nclassification tasks. SelfMix uses the Gaussian Mixture Model to separate\nsamples and leverages semi-supervised learning. Unlike previous works requiring\nmultiple models, our method utilizes the dropout mechanism on a single model to\nreduce the confirmation bias in self-training and introduces a textual-level\nmixup training strategy. Experimental results on three text classification\nbenchmarks with different types of text show that the performance of our\nproposed method outperforms these strong baselines designed for both textual\nand visual data under different noise ratios and noise types. Our anonymous\ncode is available at \\url{https://github.com/noise-learning/SelfMix}.",
    "descriptor": "\nComments: COLING-2022, oral presentation\n",
    "authors": [
      "Dan Qiao",
      "Chenchen Dai",
      "Yuyang Ding",
      "Juntao Li",
      "Qiang Chen",
      "Wenliang Chen",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04525"
  },
  {
    "id": "arXiv:2210.04527",
    "title": "A policy gradient approach for Finite Horizon Constrained Markov  Decision Processes",
    "abstract": "The infinite horizon setting is widely adopted for problems of reinforcement\nlearning (RL). These invariably result in stationary policies that are optimal.\nIn many situations, finite horizon control problems are of interest and for\nsuch problems, the optimal policies are time-varying in general. Another\nsetting that has become popular in recent times is of Constrained Reinforcement\nLearning, where the agent maximizes its rewards while also aims to satisfy\ncertain constraint criteria. However, this setting has only been studied in the\ncontext of infinite horizon MDPs where stationary policies are optimal. We\npresent, for the first time, an algorithm for constrained RL in the Finite\nHorizon Setting where the horizon terminates after a fixed (finite) time. We\nuse function approximation in our algorithm which is essential when the state\nand action spaces are large or continuous and use the policy gradient method to\nfind the optimal policy. The optimal policy that we obtain depends on the stage\nand so is time-dependent. To the best of our knowledge, our paper presents the\nfirst policy gradient algorithm for the finite horizon setting with\nconstraints. We show the convergence of our algorithm to an optimal policy. We\nfurther present a sample complexity result for our algorithm in the\nunconstrained (i.e., the regular finite horizon MDP) setting. We also compare\nand analyze the performance of our algorithm through experiments and show that\nour algorithm performs better than other well known algorithms.",
    "descriptor": "",
    "authors": [
      "Soumyajit Guin",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04527"
  },
  {
    "id": "arXiv:2210.04530",
    "title": "Do Children Texts Hold The Key To Commonsense Knowledge?",
    "abstract": "Compiling comprehensive repositories of commonsense knowledge is a\nlong-standing problem in AI. Many concerns revolve around the issue of\nreporting bias, i.e., that frequency in text sources is not a good proxy for\nrelevance or truth. This paper explores whether children's texts hold the key\nto commonsense knowledge compilation, based on the hypothesis that such content\nmakes fewer assumptions on the reader's knowledge, and therefore spells out\ncommonsense more explicitly. An analysis with several corpora shows that\nchildren's texts indeed contain much more, and more typical commonsense\nassertions. Moreover, experiments show that this advantage can be leveraged in\npopular language-model-based commonsense knowledge extraction settings, where\ntask-unspecific fine-tuning on small amounts of children texts (childBERT)\nalready yields significant improvements. This provides a refreshing perspective\ndifferent from the common trend of deriving progress from ever larger models\nand corpora.",
    "descriptor": "\nComments: 6 pages, 10 tables\n",
    "authors": [
      "Julien Romero",
      "Simon Razniewski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04530"
  },
  {
    "id": "arXiv:2210.04532",
    "title": "Training Spiking Neural Networks with Local Tandem Learning",
    "abstract": "Spiking neural networks (SNNs) are shown to be more biologically plausible\nand energy efficient over their predecessors. However, there is a lack of an\nefficient and generalized training method for deep SNNs, especially for\ndeployment on analog computing substrates. In this paper, we put forward a\ngeneralized learning rule, termed Local Tandem Learning (LTL). The LTL rule\nfollows the teacher-student learning approach by mimicking the intermediate\nfeature representations of a pre-trained ANN. By decoupling the learning of\nnetwork layers and leveraging highly informative supervisor signals, we\ndemonstrate rapid network convergence within five training epochs on the\nCIFAR-10 dataset while having low computational complexity. Our experimental\nresults have also shown that the SNNs thus trained can achieve comparable\naccuracies to their teacher ANNs on CIFAR-10, CIFAR-100, and Tiny ImageNet\ndatasets. Moreover, the proposed LTL rule is hardware friendly. It can be\neasily implemented on-chip to perform fast parameter calibration and provide\nrobustness against the notorious device non-ideality issues. It, therefore,\nopens up a myriad of opportunities for training and deployment of SNN on\nultra-low-power mixed-signal neuromorphic computing chips.10",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Qu Yang",
      "Jibin Wu",
      "Malu Zhang",
      "Yansong Chua",
      "Xinchao Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.04532"
  },
  {
    "id": "arXiv:2210.04533",
    "title": "Local Interpretable Model Agnostic Shap Explanations for machine  learning models",
    "abstract": "With the advancement of technology for artificial intelligence (AI) based\nsolutions and analytics compute engines, machine learning (ML) models are\ngetting more complex day by day. Most of these models are generally used as a\nblack box without user interpretability. Such complex ML models make it more\ndifficult for people to understand or trust their predictions. There are\nvariety of frameworks using explainable AI (XAI) methods to demonstrate\nexplainability and interpretability of ML models to make their predictions more\ntrustworthy. In this manuscript, we propose a methodology that we define as\nLocal Interpretable Model Agnostic Shap Explanations (LIMASE). This proposed ML\nexplanation technique uses Shapley values under the LIME paradigm to achieve\nthe following (a) explain prediction of any model by using a locally faithful\nand interpretable decision tree model on which the Tree Explainer is used to\ncalculate the shapley values and give visually interpretable explanations. (b)\nprovide visually interpretable global explanations by plotting local\nexplanations of several data points. (c) demonstrate solution for the\nsubmodular optimization problem. (d) also bring insight into regional\ninterpretation e) faster computation compared to use of kernel explainer.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "P. Sai Ram Aditya",
      "Mayukha Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04533"
  },
  {
    "id": "arXiv:2210.04535",
    "title": "Belief functions on ordered frames of discernment",
    "abstract": "Most questionnaires offer ordered responses whose order is poorly studied via\nbelief functions. In this paper, we study the consequences of a frame of\ndiscernment consisting of ordered elements on belief functions. This leads us\nto redefine the power space and the union of ordered elements for the\ndisjunctive combination. We also study distances on ordered elements and their\nuse. In particular, from a membership function, we redefine the cardinality of\nthe intersection of ordered elements, considering them fuzzy.",
    "descriptor": "",
    "authors": [
      "Arnaud Martin",
      "Camilles No\u00fbs"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04535"
  },
  {
    "id": "arXiv:2210.04536",
    "title": "Fully discrete Heterogeneous Multiscale Method for parabolic problems  with multiple spatial and temporal scales",
    "abstract": "The aim of this work is the numerical homogenization of a parabolic problem\nwith several time and spatial scales using the heterogeneous multiscale method.\nWe replace the actual cell problem with an alternate one, using Dirichlet\nboundary and initial values instead of periodic boundary and time conditions.\nFurther, we give a detailed a priori error analysis of the fully discretized,\ni.e., in space and time for both the macroscopic and the cell problem, method.\nNumerical experiments illustrate the theoretical convergence rates.",
    "descriptor": "",
    "authors": [
      "Daniel Eckhardt",
      "Barbara Verf\u00fcrth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04536"
  },
  {
    "id": "arXiv:2210.04537",
    "title": "Towards an efficient and risk aware strategy for guiding farmers in  identifying best crop management",
    "abstract": "Identification of best performing fertilizer practices among a set of\ncontrasting practices with field trials is challenging as crop losses are\ncostly for farmers. To identify best management practices, an ''intuitive\nstrategy'' would be to set multi-year field trials with equal proportion of\neach practice to test. Our objective was to provide an identification strategy\nusing a bandit algorithm that was better at minimizing farmers' losses\noccurring during the identification, compared with the ''intuitive strategy''.\nWe used a modification of the Decision Support Systems for Agro-Technological\nTransfer (DSSAT) crop model to mimic field trial responses, with a case-study\nin Southern Mali. We compared fertilizer practices using a risk-aware measure,\nthe Conditional Value-at-Risk (CVaR), and a novel agronomic metric, the Yield\nExcess (YE). YE accounts for both grain yield and agronomic nitrogen use\nefficiency. The bandit-algorithm performed better than the intuitive strategy:\nit increased, in most cases, farmers' protection against worst outcomes. This\nstudy is a methodological step which opens up new horizons for risk-aware\nensemble identification of the performance of contrasting crop management\npractices in real conditions.",
    "descriptor": "",
    "authors": [
      "Romain Gautron",
      "Dorian Baudry",
      "Myriam Adam",
      "Gatien N Falconnier",
      "Marc Corbeels"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04537"
  },
  {
    "id": "arXiv:2210.04541",
    "title": "A Systematic Literature Review of the Tension between the GDPR and  Public Blockchain Systems",
    "abstract": "The blockchain technology has been rapidly growing since Bitcoin was invented\nin 2008. The most common type of blockchain systems, public (permisionless)\nblockchain systems have some unique features that lead to a tension with\nEuropean Union's General Data Protection Regulation (GDPR) and other similar\ndata protection laws. In this paper, we report the results of a systematic\nliterature review (SLR) on 114 research papers discussing and/or addressing\nsuch a tension. To be the best of our know, our SLR is the most comprehensive\nreview of this topic, leading a more in-depth and broader analysis of related\nresearch work on this important topic. Our results revealed that three main\ntypes of issues: (i) difficulties in exercising data subjects' rights such as\nthe `right to be forgotten' (RTBF) due to the immutable nature of public\nblockchains; (ii) difficulties in identifying roles and responsibilities in the\npublic blockchain data processing ecosystem (particularly on the identification\nof data controllers and data processors); (iii) ambiguities regarding the\napplication of the relevant law(s) due to the distributed nature of\nblockchains. Our work also led to a better understanding of solutions for\nimproving the GDPR compliance of public blockchain systems. Our work can help\ninform not only blockchain researchers and developers, but also policy makers\nand law markers to consider how to reconcile the tension between public\nblockchain systems and data protection laws (the GDPR and beyond).",
    "descriptor": "",
    "authors": [
      "Rahime Belen-Saglam",
      "Enes Altuncu",
      "Yang Lu",
      "Shujun Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04541"
  },
  {
    "id": "arXiv:2210.04542",
    "title": "DALE: Differential Accumulated Local Effects for efficient and accurate  global explanations",
    "abstract": "Accumulated Local Effect (ALE) is a method for accurately estimating feature\neffects, overcoming fundamental failure modes of previously-existed methods,\nsuch as Partial Dependence Plots. However, ALE's approximation, i.e. the method\nfor estimating ALE from the limited samples of the training set, faces two\nweaknesses. First, it does not scale well in cases where the input has high\ndimensionality, and, second, it is vulnerable to out-of-distribution (OOD)\nsampling when the training set is relatively small. In this paper, we propose a\nnovel ALE approximation, called Differential Accumulated Local Effects (DALE),\nwhich can be used in cases where the ML model is differentiable and an\nauto-differentiable framework is accessible. Our proposal has significant\ncomputational advantages, making feature effect estimation applicable to\nhigh-dimensional Machine Learning scenarios with near-zero computational\noverhead. Furthermore, DALE does not create artificial points for calculating\nthe feature effect, resolving misleading estimations due to OOD sampling.\nFinally, we formally prove that, under some hypotheses, DALE is an unbiased\nestimator of ALE and we present a method for quantifying the standard error of\nthe explanation. Experiments using both synthetic and real datasets demonstrate\nthe value of the proposed approach.",
    "descriptor": "\nComments: 16 pages, to be published in Asian Conference of Machine Learning (ACML) 2023\n",
    "authors": [
      "Vasilis Gkolemis",
      "Theodore Dalamagas",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04542"
  },
  {
    "id": "arXiv:2210.04543",
    "title": "Sparse Semantic Map-Based Monocular Localization in Traffic Scenes Using  Learned 2D-3D Point-Line Correspondences",
    "abstract": "Vision-based localization in a prior map is of crucial importance for\nautonomous vehicles. Given a query image, the goal is to estimate the camera\npose corresponding to the prior map, and the key is the registration problem of\ncamera images within the map. While autonomous vehicles drive on the road under\nocclusion (e.g., car, bus, truck) and changing environment appearance (e.g.,\nillumination changes, seasonal variation), existing approaches rely heavily on\ndense point descriptors at the feature level to solve the registration problem,\nentangling features with appearance and occlusion. As a result, they often fail\nto estimate the correct poses. To address these issues, we propose a sparse\nsemantic map-based monocular localization method, which solves 2D-3D\nregistration via a well-designed deep neural network. Given a sparse semantic\nmap that consists of simplified elements (e.g., pole lines, traffic sign\nmidpoints) with multiple semantic labels, the camera pose is then estimated by\nlearning the corresponding features between the 2D semantic elements from the\nimage and the 3D elements from the sparse semantic map. The proposed sparse\nsemantic map-based localization approach is robust against occlusion and\nlong-term appearance changes in the environments. Extensive experimental\nresults show that the proposed method outperforms the state-of-the-art\napproaches.",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Jianru Xue",
      "Shanmin Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04543"
  },
  {
    "id": "arXiv:2210.04545",
    "title": "Automatic Evaluation and Analysis of Idioms in Neural Machine  Translation",
    "abstract": "A major open problem in neural machine translation (NMT) is the translation\nof idiomatic expressions, such as \"under the weather\". The meaning of these\nexpressions is not composed by the meaning of their constituent words, and NMT\nmodels tend to translate them literally (i.e., word-by-word), which leads to\nconfusing and nonsensical translations. Research on idioms in NMT is limited\nand obstructed by the absence of automatic methods for quantifying these\nerrors. In this work, first, we propose a novel metric for automatically\nmeasuring the frequency of literal translation errors without human\ninvolvement. Equipped with this metric, we present controlled translation\nexperiments with models trained in different conditions (with/without the\ntest-set idioms) and across a wide range of (global and targeted) metrics and\ntest sets. We explore the role of monolingual pretraining and find that it\nyields substantial targeted improvements, even without observing any\ntranslation examples of the test-set idioms. In our analysis, we probe the role\nof idiom context. We find that the randomly initialized models are more local\nor \"myopic\" as they are relatively unaffected by variations of the idiom\ncontext, unlike the pretrained ones.",
    "descriptor": "",
    "authors": [
      "Christos Baziotis",
      "Prashant Mathur",
      "Eva Hasler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04545"
  },
  {
    "id": "arXiv:2210.04553",
    "title": "SiNeRF: Sinusoidal Neural Radiance Fields for Joint Pose Estimation and  Scene Reconstruction",
    "abstract": "NeRFmm is the Neural Radiance Fields (NeRF) that deal with Joint Optimization\ntasks, i.e., reconstructing real-world scenes and registering camera parameters\nsimultaneously. Despite NeRFmm producing precise scene synthesis and pose\nestimations, it still struggles to outperform the full-annotated baseline on\nchallenging scenes. In this work, we identify that there exists a systematic\nsub-optimality in joint optimization and further identify multiple potential\nsources for it. To diminish the impacts of potential sources, we propose\nSinusoidal Neural Radiance Fields (SiNeRF) that leverage sinusoidal activations\nfor radiance mapping and a novel Mixed Region Sampling (MRS) for selecting ray\nbatch efficiently. Quantitative and qualitative results show that compared to\nNeRFmm, SiNeRF achieves comprehensive significant improvements in image\nsynthesis quality and pose estimation accuracy. Codes are available at\nhttps://github.com/yitongx/sinerf.",
    "descriptor": "\nComments: Accepted yet not published by BMVC2022\n",
    "authors": [
      "Yitong Xia",
      "Hao Tang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04553"
  },
  {
    "id": "arXiv:2210.04554",
    "title": "Comparing the carbon costs and benefits of low-resource solar nowcasting",
    "abstract": "Solar PV yield nowcasting is used to help anticipate peaks and troughs in\ndemand to support grid integration. This paper compares multiple low-resource\napproaches to nowcasting solar PV yield, using a dataset of UK satellite\nimagery and solar PV energy readings over a 1 to 4-hour time range. The paper\nalso estimates the carbon emissions generated and averted by deploying models,\nand finds that even small models that could be deployable in low-resource\nsettings may have a benefit several orders of magnitude greater than its carbon\ncost. The paper also examines prediction errors and the activations in a CNN.",
    "descriptor": "",
    "authors": [
      "Ben Dixon",
      "Mar\u00eda P\u00e9rez-Ortiz",
      "Jacob Bieker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04554"
  },
  {
    "id": "arXiv:2210.04555",
    "title": "Everything is Varied: The Surprising Impact of Individual Variation on  ML Robustness in Medicine",
    "abstract": "In medical settings, Individual Variation (IV) refers to variation that is\ndue not to population differences or errors, but rather to within-subject\nvariation, that is the intrinsic and characteristic patterns of variation\npertaining to a given instance or the measurement process. While taking into\naccount IV has been deemed critical for proper analysis of medical data, this\nsource of uncertainty and its impact on robustness have so far been neglected\nin Machine Learning (ML). To fill this gap, we look at how IV affects ML\nperformance and generalization and how its impact can be mitigated.\nSpecifically, we provide a methodological contribution to formalize the problem\nof IV in the statistical learning framework and, through an experiment based on\none of the largest real-world laboratory medicine datasets for the problem of\nCOVID-19 diagnosis, we show that: 1) common state-of-the-art ML models are\nseverely impacted by the presence of IV in data; and 2) advanced learning\nstrategies, based on data augmentation and data imprecisiation, and proper\nstudy designs can be effective at improving robustness to IV. Our findings\ndemonstrate the critical relevance of correctly accounting for IV to enable\nsafe deployment of ML in clinical settings.",
    "descriptor": "",
    "authors": [
      "Andra Campagner",
      "Lorenzo Famiglini",
      "Anna Carobene",
      "Federico Cabitza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04555"
  },
  {
    "id": "arXiv:2210.04556",
    "title": "Common Randomness Generation from Sources with Countable Alphabet",
    "abstract": "We study the problem of common randomness (CR) generation in the basic\ntwo-party communication setting in which the sender and the receiver aim to\nagree on a common random variable with high probability by observing\nindependent and identically distributed (i.i.d.) samples of correlated sources\non countably infinite alphabet and while communicating as little as possible\nover a noisy memoryless channel. We completely solve the problem by giving a\nsingle-letter characterization of the CR capacity for the proposed model and by\nproviding rigorous proof of it. This is a challenging scenario because some of\nthe finite alphabet properties, namely of the entropy can not be extended to\nthe countably infinite case. Notably, it is known that the Shannon entropy is\nin fact discontinuous at all probability distributions with countably infinite\nsupport.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2201.11078, arXiv:2205.04594\n",
    "authors": [
      "Wafa Labidi",
      "Rami Ezzine",
      "Christian Deppe",
      "Moritz Wiese",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04556"
  },
  {
    "id": "arXiv:2210.04559",
    "title": "CLIP-Diffusion-LM: Apply Diffusion Model on Image Captioning",
    "abstract": "Image captioning task has been extensively researched by previous work.\nHowever, limited experiments focus on generating captions based on\nnon-autoregressive text decoder. Inspired by the recent success of the\ndenoising diffusion model on image synthesis tasks, we apply denoising\ndiffusion probabilistic models to text generation in image captioning tasks. We\nshow that our CLIP-Diffusion-LM is capable of generating image captions using\nsignificantly fewer inference steps than autoregressive models. On the Flickr8k\ndataset, the model achieves 0.1876 BLEU-4 score. By training on the combined\nFlickr8k and Flickr30k dataset, our model achieves 0.2470 BLEU-4 score. Our\ncode is available at https://github.com/xu-shitong/diffusion-image-captioning.",
    "descriptor": "",
    "authors": [
      "Shitong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04559"
  },
  {
    "id": "arXiv:2210.04560",
    "title": "Visually Similar Products Retrieval for Shopsy",
    "abstract": "Visual search is of great assistance in reseller commerce, especially for\nnon-tech savvy users with affinity towards regional languages. It allows\nresellers to accurately locate the products that they seek, unlike textual\nsearch which recommends products from head brands. Product attributes available\nin e-commerce have a great potential for building better visual search systems\nas they capture fine grained relations between data points. In this work, we\ndesign a visual search system for reseller commerce using a multi-task learning\napproach. We also highlight and address the challenges like image compression,\ncropping, scribbling on the image, etc, faced in reseller commerce. Our model\nconsists of three different tasks: attribute classification, triplet ranking\nand variational autoencoder (VAE). Masking technique is used for designing the\nattribute classification. Next, we introduce an offline triplet mining\ntechnique which utilizes information from multiple attributes to capture\nrelative order within the data. This technique displays a better performance\ncompared to the traditional triplet mining baseline, which uses single\nlabel/attribute information. We also compare and report incremental gain\nachieved by our unified multi-task model over each individual task separately.\nThe effectiveness of our method is demonstrated using the in-house dataset of\nproduct images from the Lifestyle business-unit of Flipkart, India's largest\ne-commerce company. To efficiently retrieve the images in production, we use\nthe Approximate Nearest Neighbor (ANN) index. Finally, we highlight our\nproduction environment constraints and present the design choices and\nexperiments conducted to select a suitable ANN index.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Prajit Nadkarni",
      "Narendra Varma Dasararaju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04560"
  },
  {
    "id": "arXiv:2210.04561",
    "title": "A Comprehensive Survey of Data Augmentation in Visual Reinforcement  Learning",
    "abstract": "Visual reinforcement learning (RL), which makes decisions directly from\nhigh-dimensional visual inputs, has demonstrated significant potential in\nvarious domains. However, deploying visual RL techniques in the real world\nremains challenging due to their low sample efficiency and large generalization\ngaps. To tackle these obstacles, data augmentation (DA) has become a widely\nused technique in visual RL for acquiring sample-efficient and generalizable\npolicies by diversifying the training data. This survey aims to provide a\ntimely and essential review of DA techniques in visual RL in recognition of the\nthriving development in this field. In particular, we propose a unified\nframework for analyzing visual RL and understanding the role of DA in it. We\nthen present a principled taxonomy of the existing augmentation techniques used\nin visual RL and conduct an in-depth discussion on how to better leverage\naugmented data in different scenarios. Moreover, we report a systematic\nempirical evaluation of DA-based techniques in visual RL and conclude by\nhighlighting the directions for future research. As the first comprehensive\nsurvey of DA in visual RL, this work is expected to offer valuable guidance to\nthis emerging field.",
    "descriptor": "\nComments: A well-classified paper list that will be continuously updated can be found at this https URL\n",
    "authors": [
      "Guozheng Ma",
      "Zhen Wang",
      "Zhecheng Yuan",
      "Xueqian Wang",
      "Bo Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04561"
  },
  {
    "id": "arXiv:2210.04562",
    "title": "Using Detection, Tracking and Prediction in Visual SLAM to Achieve  Real-time Semantic Mapping of Dynamic Scenarios",
    "abstract": "In this paper, we propose a lightweight system, RDS-SLAM, based on ORB-SLAM2,\nwhich can accurately estimate poses and build semantic maps at object level for\ndynamic scenarios in real time using only one commonly used Intel Core i7 CPU.\nIn RDS-SLAM, three major improvements, as well as major architectural\nmodifications, are proposed to overcome the limitations of ORB-SLAM2. Firstly,\nit adopts a lightweight object detection neural network in key frames.\nSecondly, an efficient tracking and prediction mechanism is embedded into the\nsystem to remove the feature points belonging to movable objects in all\nincoming frames. Thirdly, a semantic octree map is built by probabilistic\nfusion of detection and tracking results, which enables a robot to maintain a\nsemantic description at object level for potential interactions in dynamic\nscenarios. We evaluate RDS-SLAM in TUM RGB-D dataset, and experimental results\nshow that RDS-SLAM can run with 30.3 ms per frame in dynamic scenarios using\nonly an Intel Core i7 CPU, and achieves comparable accuracy compared with the\nstate-of-the-art SLAM systems which heavily rely on both Intel Core i7 CPUs and\npowerful GPUs.",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Jianru Xue",
      "Jianwu Fang",
      "Yuxin Pan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04562"
  },
  {
    "id": "arXiv:2210.04563",
    "title": "Towards Robust Visual Question Answering: Making the Most of Biased  Samples via Contrastive Learning",
    "abstract": "Models for Visual Question Answering (VQA) often rely on the spurious\ncorrelations, i.e., the language priors, that appear in the biased samples of\ntraining set, which make them brittle against the out-of-distribution (OOD)\ntest data. Recent methods have achieved promising progress in overcoming this\nproblem by reducing the impact of biased samples on model training. However,\nthese models reveal a trade-off that the improvements on OOD data severely\nsacrifice the performance on the in-distribution (ID) data (which is dominated\nby the biased samples). Therefore, we propose a novel contrastive learning\napproach, MMBS, for building robust VQA models by Making the Most of Biased\nSamples. Specifically, we construct positive samples for contrastive learning\nby eliminating the information related to spurious correlation from the\noriginal training samples and explore several strategies to use the constructed\npositive samples for training. Instead of undermining the importance of biased\nsamples in model training, our approach precisely exploits the biased samples\nfor unbiased information that contributes to reasoning. The proposed method is\ncompatible with various VQA backbones. We validate our contributions by\nachieving competitive performance on the OOD dataset VQA-CP v2 while preserving\nrobust performance on the ID dataset VQA v2.",
    "descriptor": "\nComments: Findings of EMNLP-2022\n",
    "authors": [
      "Qingyi Si",
      "Yuanxin Liu",
      "Fandong Meng",
      "Zheng Lin",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04563"
  },
  {
    "id": "arXiv:2210.04565",
    "title": "Data Synchronization: A Complete Theoretical Solution for Filesystems",
    "abstract": "Data reconciliation in general, and filesystem synchronization in particular,\nlacks rigorous theoretical foundation. This paper presents, for the first time,\na complete analysis of synchronization for two replicas of a theoretical\nfilesystem. Synchronization has two main stages: identifying the conflicts, and\nresolving them. All existing (both theoretical and practical) synchronizers are\noperation-based: they define, using some rationale or heuristics, how conflicts\nare to be resolved without considering the effect of the resolution on\nsubsequent conflicts. Instead, our approach is declaration-based: we define\nwhat constitutes the resolution of all conflicts, and for each possible\nscenario we prove the existence of sequences of operations / commands which\nconvert the replicas into a common synchronized state. These sequences consist\nof operations rolling back some local changes, followed by operations performed\non the other replica. The set of rolled-back operations provides the user with\nclear and intuitive information on the proposed changes, so she can easily\ndecide whether to accept them or ask for other alternatives. All possible\nsynchronized states are described by specifying a set of conflicts, a partial\norder on the conflicts describing the order in which they need to be resolved,\nas well as the effect of each decision on subsequent conflicts. Using this\nclassification, the outcomes of different conflict resolution policies can be\ninvestigated easily.",
    "descriptor": "",
    "authors": [
      "Elod P. Csirmaz",
      "Laszlo Csirmaz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04565"
  },
  {
    "id": "arXiv:2210.04567",
    "title": "BoundaryFace: A mining framework with noise label self-correction for  Face Recognition",
    "abstract": "Face recognition has made tremendous progress in recent years due to the\nadvances in loss functions and the explosive growth in training sets size. A\nproperly designed loss is seen as key to extract discriminative features for\nclassification. Several margin-based losses have been proposed as alternatives\nof softmax loss in face recognition. However, two issues remain to consider: 1)\nThey overlook the importance of hard sample mining for discriminative learning.\n2) Label noise ubiquitously exists in large-scale datasets, which can seriously\ndamage the model's performance. In this paper, starting from the perspective of\ndecision boundary, we propose a novel mining framework that focuses on the\nrelationship between a sample's ground truth class center and its nearest\nnegative class center. Specifically, a closed-set noise label self-correction\nmodule is put forward, making this framework work well on datasets containing a\nlot of label noise. The proposed method consistently outperforms SOTA methods\nin various face recognition benchmarks. Training code has been released at\nhttps://github.com/SWJTU-3DVision/BoundaryFace.",
    "descriptor": "\nComments: ECCV 2022. Code available at this https URL\n",
    "authors": [
      "Shijie Wu",
      "Xun Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04567"
  },
  {
    "id": "arXiv:2210.04569",
    "title": "Systematic Evaluation and User Study of Privacy of Default Apps in  Apple's Mobile Ecosystem",
    "abstract": "Users need to configure default apps when they first start using their\ndevices. The privacy configurations of the default apps do not always match\nwhat users think they have initially enabled. We first systematically evaluated\nthe privacy configurations of default apps. We discovered serious issues with\nthe documentation of the default apps. Based on these findings, we explored\nusers' experiences with an interview study (N=15). Our findings from both\nstudies show that: the instructions of setting privacy configurations of\ndefault apps are vague and lack required steps; users were unable to disable\ndefault apps from accessing their personal information; users assumed they were\nbeing tracked by some default apps; default apps may cause tensions in family\nrelationships because of information sharing. Our results illuminate on the\nprivacy and security implications of configuring the privacy of default apps\nand how users perceive and understand the mobile ecosystem.",
    "descriptor": "\nComments: 23 pages, 1 Figure\n",
    "authors": [
      "Amel Bourdoucen",
      "Janne Lindqvist"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04569"
  },
  {
    "id": "arXiv:2210.04570",
    "title": "The Eyecandies Dataset for Unsupervised Multimodal Anomaly Detection and  Localization",
    "abstract": "We present Eyecandies, a novel synthetic dataset for unsupervised anomaly\ndetection and localization. Photo-realistic images of procedurally generated\ncandies are rendered in a controlled environment under multiple lightning\nconditions, also providing depth and normal maps in an industrial conveyor\nscenario. We make available anomaly-free samples for model training and\nvalidation, while anomalous instances with precise ground-truth annotations are\nprovided only in the test set. The dataset comprises ten classes of candies,\neach showing different challenges, such as complex textures, self-occlusions\nand specularities. Furthermore, we achieve large intra-class variation by\nrandomly drawing key parameters of a procedural rendering pipeline, which\nenables the creation of an arbitrary number of instances with photo-realistic\nappearance. Likewise, anomalies are injected into the rendering graph and\npixel-wise annotations are automatically generated, overcoming human-biases and\npossible inconsistencies.\nWe believe this dataset may encourage the exploration of original approaches\nto solve the anomaly detection task, e.g. by combining color, depth and normal\nmaps, as they are not provided by most of the existing datasets. Indeed, in\norder to demonstrate how exploiting additional information may actually lead to\nhigher detection performance, we show the results obtained by training a deep\nconvolutional autoencoder to reconstruct different combinations of inputs.",
    "descriptor": "\nComments: 14 pages, 6 figures. To be published in ACCV 2022. For the website and download links see this https URL\n",
    "authors": [
      "Luca Bonfiglioli",
      "Marco Toschi",
      "Davide Silvestri",
      "Nicola Fioraio",
      "Daniele De Gregorio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04570"
  },
  {
    "id": "arXiv:2210.04571",
    "title": "Modular Multi-Copter Structure Control for Cooperative Aerial Cargo  Transportation",
    "abstract": "The control problem of a multi-copter swarm, mechanically coupled through a\nmodular lattice structure of connecting rods, is considered in this article.\nThe system's structural elasticity is considered in deriving the system's\ndynamics. The devised controller is robust against the induced flexibilities,\nwhile an inherent adaptation scheme allows for the control of asymmetrical\nconfigurations and the transportation of unknown payloads. Certain optimization\nmetrics are introduced for solving the individual agent thrust allocation\nproblem while achieving maximum system flight time, resulting in a\nplatform-independent control implementation. Experimental studies are offered\nto illustrate the efficiency of the suggested controller under typical flight\nconditions, increased rod elasticities and payload transportation.",
    "descriptor": "",
    "authors": [
      "Dimitris Chaikalis",
      "Nikolaos Evangeliou",
      "Anthony Tzes",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04571"
  },
  {
    "id": "arXiv:2210.04572",
    "title": "Floorplan-Aware Camera Poses Refinement",
    "abstract": "Processing large indoor scenes is a challenging task, as scan registration\nand camera trajectory estimation methods accumulate errors across time. As a\nresult, the quality of reconstructed scans is insufficient for some\napplications, such as visual-based localization and navigation, where the\ncorrect position of walls is crucial.\nFor many indoor scenes, there exists an image of a technical floorplan that\ncontains information about the geometry and main structural elements of the\nscene, such as walls, partitions, and doors. We argue that such a floorplan is\na useful source of spatial information, which can guide a 3D model\noptimization.\nThe standard RGB-D 3D reconstruction pipeline consists of a tracking module\napplied to an RGB-D sequence and a bundle adjustment (BA) module that takes the\nposed RGB-D sequence and corrects the camera poses to improve consistency. We\npropose a novel optimization algorithm expanding conventional BA that leverages\nthe prior knowledge about the scene structure in the form of a floorplan. Our\nexperiments on the Redwood dataset and our self-captured data demonstrate that\nutilizing floorplan improves accuracy of 3D reconstructions.",
    "descriptor": "\nComments: IROS 2022\n",
    "authors": [
      "Anna Sokolova",
      "Filipp Nikitin",
      "Anna Vorontsova",
      "Anton Konushin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04572"
  },
  {
    "id": "arXiv:2210.04573",
    "title": "HumSet: Dataset of Multilingual Information Extraction and  Classification for Humanitarian Crisis Response",
    "abstract": "Timely and effective response to humanitarian crises requires quick and\naccurate analysis of large amounts of text data - a process that can highly\nbenefit from expert - assisted NLP systems trained on validated and annotated\ndata in the humanitarian response domain. To enable creation of such NLP\nsystems, we introduce and release HumSet, a novel and rich multilingual dataset\nof humanitarian response documents annotated by experts in the humanitarian\nresponse community. The dataset provides documents in three languages (English,\nFrench, Spanish) and covers a variety of humanitarian crises from 2018 to 2021\nacross the globe. For each document, HumSet provides selected snippets\n(entries) as well as assigned classes to each entry annotated using common\nhumanitarian information analysis frameworks. HumSet also provides novel and\nchallenging entry extraction and multi-label entry classification tasks. In\nthis paper, we take a first step towards approaching these tasks and conduct a\nset of experiments on Pre-trained Language Models (PLM) to establish strong\nbaselines for future research in this domain. The dataset is available at The\ndataset is available at https: //blog.thedeep.io/humset/.",
    "descriptor": "",
    "authors": [
      "Selim Fekih",
      "Nicol\u00f2 Tamagnone",
      "Benjamin Minixhofer",
      "Ranjan Shrestha",
      "Ximena Contla",
      "Ewan Oglethorpe",
      "Navid Rekabsaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04573"
  },
  {
    "id": "arXiv:2210.04574",
    "title": "ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object  Detection",
    "abstract": "Deep neural networks tend to reciprocate the bias of their training dataset.\nIn object detection, the bias exists in the form of various imbalances such as\nclass, background-foreground, and object size. In this paper, we denote size of\nan object as the number of pixels it covers in an image and size imbalance as\nthe over-representation of certain sizes of objects in a dataset. We aim to\naddress the problem of size imbalance in drone-based aerial image datasets.\nExisting methods for solving size imbalance are based on architectural changes\nthat utilize multiple scales of images or feature maps for detecting objects of\ndifferent sizes. We, on the other hand, propose a novel ARchitectUre-agnostic\nBAlanced Loss (ARUBA) that can be applied as a plugin on top of any object\ndetection model. It follows a neighborhood-driven approach inspired by the\nordinality of object size. We evaluate the effectiveness of our approach\nthrough comprehensive experiments on aerial datasets such as HRSC2016,\nDOTAv1.0, DOTAv1.5 and VisDrone and obtain consistent improvement in\nperformance.",
    "descriptor": "",
    "authors": [
      "Rebbapragada V C Sairam",
      "Monish Keswani",
      "Uttaran Sinha",
      "Nishit Shah",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04574"
  },
  {
    "id": "arXiv:2210.04576",
    "title": "The Rectilinear Steiner Forest Arborescence problem",
    "abstract": "Let $r$ be a point in the first quadrant $Q_1$ of the plane $\\mathbb{R}^2$\nand let $P \\subset Q_1$ be a set of points such that for any $p \\in P$, its\n$x$- and $y$-coordinate is at least as that of $r$. A rectilinear Steiner\narborescence for $P$ with the root $r$ is a rectilinear Steiner tree $T$ for $P\n\\cup \\{r\\}$ such that for each point $p \\in P$, the length of the (unique) path\nin $T$ from $p$ to the root $r$ equals $({\\rm x}(p)-{\\rm x}(r))+({\\rm\ny}(p))-({\\rm y}(r))$, where ${\\rm x}(q)$ and ${\\rm y}(q)$ denote the $x$- and\n$y$-coordinate, respectively, of point $q \\in P \\cup \\{r\\}$. Given two point\nsets $P$ and $R$ lying in the first quadrant $Q_1$ and such that $(0,0) \\in R$,\nthe Rectilinear Steiner Forest Arborescence (RSFA) problem is to find the\nminimum-length spanning forest $F$ such that each connected component $F$ is a\nrectilinear Steiner arborescence rooted at some root in $R$. The RSFA problem\nis a natural generalization of the Rectilinear Steiner Arborescence problem,\nwhere $R=\\{(0,0)\\}$, and thus it is NP-hard. In this paper, we provide a simple\nexact exponential time algorithm for the RSFA problem, design a polynomial time\napproximation scheme as well as a fixed-parameter algorithm.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "\u0141ukasz Mielewczyk",
      "Leonidas Palios",
      "Pawe\u0142 \u017byli\u0144ski"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.04576"
  },
  {
    "id": "arXiv:2210.04578",
    "title": "Is your noise correction noisy? PLS: Robustness to label noise with two  stage detection",
    "abstract": "Designing robust algorithms capable of training accurate neural networks on\nuncurated datasets from the web has been the subject of much research as it\nreduces the need for time consuming human labor. The focus of many previous\nresearch contributions has been on the detection of different types of label\nnoise; however, this paper proposes to improve the correction accuracy of noisy\nsamples once they have been detected. In many state-of-the-art contributions, a\ntwo phase approach is adopted where the noisy samples are detected before\nguessing a corrected pseudo-label in a semi-supervised fashion. The guessed\npseudo-labels are then used in the supervised objective without ensuring that\nthe label guess is likely to be correct. This can lead to confirmation bias,\nwhich reduces the noise robustness. Here we propose the pseudo-loss, a simple\nmetric that we find to be strongly correlated with pseudo-label correctness on\nnoisy samples. Using the pseudo-loss, we dynamically down weight\nunder-confident pseudo-labels throughout training to avoid confirmation bias\nand improve the network accuracy. We additionally propose to use a confidence\nguided contrastive objective that learns robust representation on an\ninterpolated objective between class bound (supervised) for confidently\ncorrected samples and unsupervised representation for under-confident label\ncorrections. Experiments demonstrate the state-of-the-art performance of our\nPseudo-Loss Selection (PLS) algorithm on a variety of benchmark datasets\nincluding curated data synthetically corrupted with in-distribution and\nout-of-distribution noise, and two real world web noise datasets. Our\nexperiments are fully reproducible [github coming soon]",
    "descriptor": "\nComments: 9 pages 4 figures\n",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Tarun Kirshna",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04578"
  },
  {
    "id": "arXiv:2210.04582",
    "title": "ParaDime: A Framework for Parametric Dimensionality Reduction",
    "abstract": "ParaDime is a framework for parametric dimensionality reduction (DR). In\nparametric DR, neural networks are trained to embed high-dimensional data items\nin a low-dimensional space while minimizing an objective function. ParaDime\nbuilds on the idea that the objective functions of several modern DR techniques\nresult from transformed inter-item relationships. It provides a common\ninterface to specify the way these relations and transformations are computed\nand how they are used within the losses that govern the training process.\nThrough this interface, ParaDime unifies parametric versions of DR techniques\nsuch as metric MDS, t-SNE, and UMAP. Furthermore, it allows users to fully\ncustomize each aspect of the DR process. We show how this ease of customization\nmakes ParaDime suitable for experimenting with interesting techniques, such as\nhybrid classification/embedding models or supervised DR, which opens up new\npossibilities for visualizing high-dimensional data.",
    "descriptor": "",
    "authors": [
      "Andreas Hinterreiter",
      "Christina Humer",
      "Bernhard Kainz",
      "Marc Streit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04582"
  },
  {
    "id": "arXiv:2210.04590",
    "title": "The Small Solution Hypothesis for MAPF on Directed Graphs Is True",
    "abstract": "The determination of the computational complexity of multi-agent pathfinding\non directed graphs has been an open problem for many years. Only recently, it\nhas been established that the problem is NP-hard. Further, it has been proved\nthat it is in NP, provided the short solution hypothesis for strongly connected\ndigraphs holds. In this paper, it is shown that this hypothesis is indeed true.",
    "descriptor": "",
    "authors": [
      "Bernhard Nebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.04590"
  },
  {
    "id": "arXiv:2210.04591",
    "title": "Universal Adversarial Perturbations: Efficiency on a small image dataset",
    "abstract": "Although neural networks perform very well on the image classification task,\nthey are still vulnerable to adversarial perturbations that can fool a neural\nnetwork without visibly changing an input image. A paper has shown the\nexistence of Universal Adversarial Perturbations which when added to any image\nwill fool the neural network with a very high probability. In this paper we\nwill try to reproduce the experience of the Universal Adversarial Perturbations\npaper, but on a smaller neural network architecture and training set, in order\nto be able to study the efficiency of the computed perturbation.",
    "descriptor": "",
    "authors": [
      "Waris Radji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04591"
  },
  {
    "id": "arXiv:2210.04595",
    "title": "SampleHST: Efficient On-the-Fly Selection of Distributed Traces",
    "abstract": "Since only a small number of traces generated from distributed tracing helps\nin troubleshooting, its storage requirement can be significantly reduced by\nbiasing the selection towards anomalous traces. To aid in this scenario, we\npropose SampleHST, a novel approach to sample on-the-fly from a stream of\ntraces in an unsupervised manner. SampleHST adjusts the storage quota of normal\nand anomalous traces depending on the size of its budget. Initially, it\nutilizes a forest of Half Space Trees (HSTs) for trace scoring. This is based\non the distribution of the mass scores across the trees, which characterizes\nthe probability of observing different traces. The mass distribution from HSTs\nis subsequently used to cluster the traces online leveraging a variant of the\nmean-shift algorithm. This trace-cluster association eventually drives the\nsampling decision. We have compared the performance of SampleHST with a\nrecently suggested method using data from a cloud data center and demonstrated\nthat SampleHST improves sampling performance up to by 9.5x.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Alim Ul Gias",
      "Yicheng Gao",
      "Matthew Sheldon",
      "Jos\u00e9 A. Perusqu\u00eda",
      "Owen O'Brien",
      "Giuliano Casale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04595"
  },
  {
    "id": "arXiv:2210.04597",
    "title": "DeepVenn -- a web application for the creation of area-proportional Venn  diagrams using the deep learning framework Tensorflow.js",
    "abstract": "Motivation: The Venn diagram is one of the most popular methods to visualize\nthe overlap and differences between data sets. It is especially useful when it\nis are 'area-proportional'; i.e. the sizes of the circles and the overlaps are\nproportional to the sizes of the data sets. There are some tools available that\ncan generate area-proportional Venn Diagrams, but most of them are limited to\ntwo or three circles, and others are not available as a web application or\naccept only numbers and not lists of IDs as input. Some existing solutions also\nhave limited accuracy because of outdated algorithms to calculate the optimal\nplacement of the circles. The latest machine learning and deep learning\nframeworks can offer a solution to this problem. Results: The DeepVenn web\napplication can create area-proportional Venn diagrams of up to ten sets.\nBecause of an algorithm implemented with the deep learning framework\nTensorflow.js, DeepVenn automatically finds the optimal solution in which the\noverlap between the circles corresponds to the sizes of the overlap as much as\npossible. The only required input is two to ten lists of IDs. Optional\nparameters include the main title, the subtitle, the set titles and colours of\nthe circles and the background. The user can choose to display absolute numbers\nor percentages in the final diagram. The image can be saved as a PNG file by\nright-clicking on it and choosing \"Save image as\". The right side of the\ninterface also shows the numbers and contents of all intersections.\nAvailability: DeepVenn is available at https://www.deepvenn.com. Contact:\ntim.hulsen@philips.com",
    "descriptor": "\nComments: 2 pages, 1 figure\n",
    "authors": [
      "Tim Hulsen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04597"
  },
  {
    "id": "arXiv:2210.04598",
    "title": "Temporal Vectorization: A Compiler Approach to Automatic Multi-Pumping",
    "abstract": "The multi-pumping resource sharing technique can overcome the limitations\ncommonly found in single-clocked FPGA designs by allowing hardware components\nto operate at a higher clock frequency than the surrounding system. However,\nthis optimization cannot be expressed in high levels of abstraction, such as\nHLS, requiring the use of hand-optimized RTL. In this paper we show how to\nleverage multiple clock domains for computational subdomains on reconfigurable\ndevices through data movement analysis on high-level programs. We offer a novel\nview on multi-pumping as a compiler optimization - a superclass of traditional\nvectorization. As multiple data elements are fed and consumed, the computations\nare packed temporally rather than spatially. The optimization is applied\nautomatically using an intermediate representation that maps high-level code to\nHLS. Internally, the optimization injects modules into the generated designs,\nincorporating RTL for fine-grained control over the clock domains. We obtain a\nreduction of resource consumption by up to 50% on critical components and 23%\non average. For scalable designs, this can enable further parallelism,\nincreasing overall performance.",
    "descriptor": "",
    "authors": [
      "Carl-Johannes Johnsen",
      "Tiziano De Matteis",
      "Tal Ben-Nun",
      "Johannes de Fine Licht",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.04598"
  },
  {
    "id": "arXiv:2210.04599",
    "title": "Technical Report: Analytical Modeling and Throughput Computation of  Blockchain Sharding",
    "abstract": "Sharding has shown great potential to scale out blockchains. It divides nodes\ninto smaller groups which allow for partial transaction processing, relaying\nand storage. Hence, instead of running one blockchain, we will run multiple\nblockchains in parallel, and call each one a shard. Sharding can be applied to\naddress shortcomings due to compulsory duplication of three resources in\nblockchains, i.e., computation, communication and storage. The most pressing\nissue in blockchains today is throughput. Hence, usually the main focus is to\nshard computation which leads to concurrent transaction processing. In this\nreport, we propose new queueing-theoretic models to derive the maximum\nthroughput of sharded blockchains. We consider two cases, a fully sharded\nblockchain and a computation sharding. In the former nodes are exclusive to\neach shard in terms of their responsibilities, i.e., block production, relaying\nand storage. In the latter though, only block production is exclusive and nodes\nrelay and store every piece of information. We model each with a queueing\nnetwork that exploits signals to account for block production as well as\nmulti-destination cross-shard transactions. We make sure quasi-reversibility\nfor every queue in our models is satisfied so that they fall into the category\nof product-form queueing networks. We then obtain a closed-form solution for\nthe maximum stable throughput of these systems with respect to block size,\nblock rate, number of destinations in transactions and the number of shards.\nComparing the results obtained from the two introduced sharding systems, we\nconclude that the extent of sharding in different domains plays a significant\nrole in scalability.",
    "descriptor": "",
    "authors": [
      "Pourya Soltani",
      "Farid Ashtiani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04599"
  },
  {
    "id": "arXiv:2210.04600",
    "title": "YFACC: A Yor\u00f9b\u00e1 speech-image dataset for cross-lingual keyword  localisation through visual grounding",
    "abstract": "Visually grounded speech (VGS) models are trained on images paired with\nunlabelled spoken captions. Such models could be used to build speech systems\nin settings where it is impossible to get labelled data, e.g. for documenting\nunwritten languages. However, most VGS studies are in English or other\nhigh-resource languages. This paper attempts to address this shortcoming. We\ncollect and release a new single-speaker dataset of audio captions for 6k\nFlickr images in Yor\\`ub\\'a -- a real low-resource language spoken in Nigeria.\nWe train an attention-based VGS model where images are automatically tagged\nwith English visual labels and paired with Yor\\`ub\\'a utterances. This enables\ncross-lingual keyword localisation: a written English query is detected and\nlocated in Yor\\`ub\\'a speech. To quantify the effect of the smaller dataset, we\ncompare to English systems trained on similar and more data. We hope that this\nnew dataset will stimulate research in the use of VGS models for real\nlow-resource languages.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Kayode Olaleye",
      "Dan Oneata",
      "Herman Kamper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.04600"
  },
  {
    "id": "arXiv:2210.04604",
    "title": "Actor-Critic Network for O-RAN Resource Allocation: xApp Design,  Deployment, and Analysis",
    "abstract": "Open Radio Access Network (O-RAN) has introduced an emerging RAN architecture\nthat enables openness, intelligence, and automated control. The RAN Intelligent\nController (RIC) provides the platform to design and deploy RAN controllers.\nxApps are the applications which will take this responsibility by leveraging\nmachine learning (ML) algorithms and acting in near-real time. Despite the\nopportunities provided by this new architecture, the progress of practical\nartificial intelligence (AI)-based solutions for network control and automation\nhas been slow. This is mostly because of the lack of an endto-end solution for\ndesigning, deploying, and testing AI-based xApps fully executable in real O-RAN\nnetwork. In this paper we introduce an end-to-end O-RAN design and evaluation\nprocedure and provide a detailed discussion of developing a Reinforcement\nLearning (RL) based xApp by using two different RL approaches and considering\nthe latest released O-RAN architecture and interfaces.",
    "descriptor": "\nComments: This article has been accepted for publication in IEEE GLOBECOM 2022\n",
    "authors": [
      "Mohammadreza Kouchaki",
      "Vuk Marojevic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04604"
  },
  {
    "id": "arXiv:2210.04606",
    "title": "Integrating Digital Twin and Advanced Intelligent Technologies to  Realize the Metaverse",
    "abstract": "The advances in Artificial Intelligence (AI) have led to technological\nadvancements in a plethora of domains. Healthcare, education, and smart city\nservices are now enriched with AI capabilities. These technological\nadvancements would not have been realized without the assistance of fast,\nsecure, and fault-tolerant communication media. Traditional processing,\ncommunication and storage technologies cannot maintain high levels of\nscalability and user experience for immersive services. The metaverse is an\nimmersive three-dimensional (3D) virtual world that integrates fantasy and\nreality into a virtual environment using advanced virtual reality (VR) and\naugmented reality (AR) devices. Such an environment is still being developed\nand requires extensive research in order for it to be realized to its highest\nattainable levels. In this article, we discuss some of the key issues required\nin order to attain realization of metaverse services. We propose a framework\nthat integrates digital twin (DT) with other advanced technologies such as the\nsixth generation (6G) communication network, blockchain, and AI, to maintain\ncontinuous end-to-end metaverse services. This article also outlines\nrequirements for an integrated, DT-enabled metaverse framework and provides a\nlook ahead into the evolving topic.",
    "descriptor": "\nComments: 7 pages, 2 figures, Accepted for publication, IEEE Consumer Electronics Magazine\n",
    "authors": [
      "Moayad Aloqaily",
      "Ouns Bouachir",
      "Fakhri Karray",
      "Ismaeel Al Ridhawi",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04606"
  },
  {
    "id": "arXiv:2210.04607",
    "title": "A Snapshot of the Frontiers of Client Selection in Federated Learning",
    "abstract": "Federated learning (FL) has been proposed as a privacy-preserving approach in\ndistributed machine learning. A federated learning architecture consists of a\ncentral server and a number of clients that have access to private, potentially\nsensitive data. Clients are able to keep their data in their local machines and\nonly share their locally trained model's parameters with a central server that\nmanages the collaborative learning process. FL has delivered promising results\nin real-life scenarios, such as healthcare, energy, and finance. However, when\nthe number of participating clients is large, the overhead of managing the\nclients slows down the learning. Thus, client selection has been introduced as\na strategy to limit the number of communicating parties at every step of the\nprocess. Since the early na\\\"{i}ve random selection of clients, several client\nselection methods have been proposed in the literature. Unfortunately, given\nthat this is an emergent field, there is a lack of a taxonomy of client\nselection methods, making it hard to compare approaches. In this paper, we\npropose a taxonomy of client selection in Federated Learning that enables us to\nshed light on current progress in the field and identify potential areas of\nfuture research in this promising area of machine learning.",
    "descriptor": "\nComments: 17 pages, 3 figures, 1 appendix, submitted to TMLR\n",
    "authors": [
      "Gergely D\u00e1niel N\u00e9meth",
      "Miguel \u00c1ngel Lozano",
      "Novi Quadrianto",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04607"
  },
  {
    "id": "arXiv:2210.04610",
    "title": "Red-Teaming the Stable Diffusion Safety Filter",
    "abstract": "Stable Diffusion is a recent open-source image generation model comparable to\nproprietary models such as DALLE, Imagen, or Parti. Stable Diffusion comes with\na safety filter that aims to prevent generating explicit images. Unfortunately,\nthe filter is obfuscated and poorly documented. This makes it hard for users to\nprevent misuse in their applications, and to understand the filter's\nlimitations and improve it. We first show that it is easy to generate\ndisturbing content that bypasses the safety filter. We then reverse-engineer\nthe filter and find that while it aims to prevent sexual content, it ignores\nviolence, gore, and other similarly disturbing content. Based on our analysis,\nwe argue safety measures in future model releases should strive to be fully\nopen and properly documented to stimulate security contributions from the\ncommunity.",
    "descriptor": "",
    "authors": [
      "Javier Rando",
      "Daniel Paleka",
      "David Lindner",
      "Lennard Heim",
      "Florian Tram\u00e8r"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04610"
  },
  {
    "id": "arXiv:2210.04612",
    "title": "When Infodemic Meets Epidemic: a Systematic Literature Review",
    "abstract": "Epidemics and outbreaks present arduous challenges requiring both individual\nand communal efforts. Social media offer significant amounts of data that can\nbe leveraged for bio-surveillance. They also provide a platform to quickly and\nefficiently reach a sizeable percentage of the population, hence their\npotential impact on various aspects of epidemic mitigation. The general\nobjective of this systematic literature review is to provide a methodical\noverview of the integration of social media in different epidemic-related\ncontexts. Three research questions were conceptualized for this review,\nresulting in over 10000 publications collected in the first PRISMA stage, 129\nof which were selected for inclusion. A thematic method-oriented synthesis was\nundertaken and identified 5 main themes related to social media enabled\nepidemic surveillance, misinformation management, and mental health. Findings\nuncover a need for more robust applications of the lessons learned from\nepidemic post-mortem documentation. A vast gap exists between retrospective\nanalysis of epidemic management and result integration in prospective studies.\nHarnessing the full potential of social media in epidemic related tasks\nrequires streamlining the results of epidemic forecasting, public opinion\nunderstanding and misinformation propagation, all while keeping abreast of\npotential mental health implications. Pro-active prevention has thus become\nvital for epidemic curtailment and containment.",
    "descriptor": "",
    "authors": [
      "Chaimae Asaad",
      "Imane Khaouja",
      "Mounir Ghogho",
      "Karim Ba\u00efna"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04612"
  },
  {
    "id": "arXiv:2210.04613",
    "title": "Fine-grained Object Categorization for Service Robots",
    "abstract": "A robot working in a human-centered environment is frequently confronted with\nfine-grained objects that must be distinguished from one another. Fine-grained\nvisual classification (FGVC) still remains a challenging problem due to large\nintra-category dissimilarity and small inter-category dissimilarity.\nFurthermore, flaws such as the influence of illumination and information\ninadequacy persist in fine-grained RGB datasets. We propose a novel deep mixed\nmulti-modality approach based on Vision Transformer (ViT) and Convolutional\nNeural Network (CNN) to improve the performance of FGVC. Furthermore, we\ngenerate two synthetic fine-grained RGB-D datasets consisting of 13 car objects\nwith 720 views and 120 shoes with 7200 sample views. Finally, to assess the\nperformance of the proposed approach, we conducted several experiments using\nfine-grained RGB-D datasets. Experimental results show that our method\noutperformed other baselines in terms of recognition accuracy, and achieved\n93.40 $\\%$ and 91.67 $\\%$ recognition accuracy on shoe and car dataset\nrespectively. We made the fine-grained RGB-D datasets publicly available for\nthe benefit of research communities.",
    "descriptor": "",
    "authors": [
      "Songsong Xiong",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04613"
  },
  {
    "id": "arXiv:2210.04614",
    "title": "Joint Multi-grained Popularity-aware Graph Convolution Collaborative  Filtering for Recommendation",
    "abstract": "Graph Convolution Networks (GCNs), with their efficient ability to capture\nhigh-order connectivity in graphs, have been widely applied in recommender\nsystems. Stacking multiple neighbor aggregation is the major operation in GCNs.\nIt implicitly captures popularity features because the number of neighbor nodes\nreflects the popularity of a node. However, existing GCN-based methods ignore a\nuniversal problem: users' sensitivity to item popularity is differentiated, but\nthe neighbor aggregations in GCNs actually fix this sensitivity through Graph\nLaplacian Normalization, leading to suboptimal personalization.\nIn this work, we propose to model multi-grained popularity features and\njointly learn them together with high-order connectivity, to match the\ndifferentiation of user preferences exhibited in popularity features.\nSpecifically, we develop a Joint Multi-grained Popularity-aware Graph\nConvolution Collaborative Filtering model, short for JMP-GCF, which uses a\npopularity-aware embedding generation to construct multi-grained popularity\nfeatures, and uses the idea of joint learning to capture the signals within and\nbetween different granularities of popularity features that are relevant for\nmodeling user preferences. Additionally, we propose a multistage stacked\ntraining strategy to speed up model convergence. We conduct extensive\nexperiments on three public datasets to show the state-of-the-art performance\nof JMP-GCF.",
    "descriptor": "",
    "authors": [
      "Kang Liu",
      "Feng Xue",
      "Xiangnan He",
      "Dan Guo",
      "Richang Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.04614"
  },
  {
    "id": "arXiv:2210.04615",
    "title": "EmbryosFormer: Deformable Transformer and Collaborative  Encoding-Decoding for Embryos Stage Development Classification",
    "abstract": "The timing of cell divisions in early embryos during the In-Vitro\nFertilization (IVF) process is a key predictor of embryo viability. However,\nobserving cell divisions in Time-Lapse Monitoring (TLM) is a time-consuming\nprocess and highly depends on experts. In this paper, we propose EmbryosFormer,\na computational model to automatically detect and classify cell divisions from\noriginal time-lapse images. Our proposed network is designed as an\nencoder-decoder deformable transformer with collaborative heads. The\ntransformer contracting path predicts per-image labels and is optimized by a\nclassification head. The transformer expanding path models the temporal\ncoherency between embryo images to ensure monotonic non-decreasing constraint\nand is optimized by a segmentation head. Both contracting and expanding paths\nare synergetically learned by a collaboration head. We have benchmarked our\nproposed EmbryosFormer on two datasets: a public dataset with mouse embryos\nwith 8-cell stage and an in-house dataset with human embryos with 4-cell stage.\nSource code: https://github.com/UARK-AICV/Embryos.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Tien-Phat Nguyen",
      "Trong-Thang Pham",
      "Tri Nguyen",
      "Hieu Le",
      "Dung Nguyen",
      "Hau Lam",
      "Phong Nguyen",
      "Jennifer Fowler",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04615"
  },
  {
    "id": "arXiv:2210.04620",
    "title": "FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in  Realistic Healthcare Settings",
    "abstract": "Federated Learning (FL) is a novel approach enabling several clients holding\nsensitive data to collaboratively train machine learning models, without\ncentralizing data. The cross-silo FL setting corresponds to the case of few\n($2$--$50$) reliable clients, each holding medium to large datasets, and is\ntypically found in applications such as healthcare, finance, or industry. While\nprevious works have proposed representative datasets for cross-device FL, few\nrealistic healthcare cross-silo FL datasets exist, thereby slowing algorithmic\nresearch in this critical application. In this work, we propose a novel\ncross-silo dataset suite focused on healthcare, FLamby (Federated Learning\nAMple Benchmark of Your cross-silo strategies), to bridge the gap between\ntheory and practice of cross-silo FL. FLamby encompasses 7 healthcare datasets\nwith natural splits, covering multiple tasks, modalities, and data volumes,\neach accompanied with baseline training code. As an illustration, we\nadditionally benchmark standard FL algorithms on all datasets. Our flexible and\nmodular suite allows researchers to easily download datasets, reproduce results\nand re-use the different components for their research. FLamby is available\nat~\\url{www.github.com/owkin/flamby}.",
    "descriptor": "\nComments: Accepted to NeurIPS, Datasets and Benchmarks Track\n",
    "authors": [
      "Jean Ogier du Terrail",
      "Samy-Safwan Ayed",
      "Edwige Cyffers",
      "Felix Grimberg",
      "Chaoyang He",
      "Regis Loeb",
      "Paul Mangold",
      "Tanguy Marchand",
      "Othmane Marfoq",
      "Erum Mushtaq",
      "Boris Muzellec",
      "Constantin Philippenko",
      "Santiago Silva",
      "Maria Tele\u0144czuk",
      "Shadi Albarqouni",
      "Salman Avestimehr",
      "Aur\u00e9lien Bellet",
      "Aymeric Dieuleveut",
      "Martin Jaggi",
      "Sai Praneeth Karimireddy",
      "Marco Lorenzi",
      "Giovanni Neglia",
      "Marc Tommasi",
      "Mathieu Andreux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04620"
  },
  {
    "id": "arXiv:2210.04623",
    "title": "DeltaFS: Pursuing Zero Update Overhead via Metadata-Enabled Delta  Compression for Log-structured File System on Mobile Devices",
    "abstract": "Data compression has been widely adopted to release mobile devices from\nintensive write pressure. Delta compression is particularly promising for its\nhigh compression efficacy over conventional compression methods. However, this\nmethod suffers from non-trivial system overheads incurred by delta maintenance\nand read penalty, which prevents its applicability on mobile devices. To this\nend, this paper proposes DeltaFS, a metadata-enabled Delta compression on\nlog-structured File System for mobile devices, to achieve utmost compressing\nefficiency and zero hardware costs. DeltaFS smartly exploits the out-of-place\nupdating ability of Log-structured File System (LFS) to alleviate the problems\nof write amplification, which is the key bottleneck for delta compression\nimplementation. Specifically, DeltaFS utilizes the inline area in file inodes\nfor delta maintenance with zero hardware cost, and integrates an inline area\nmanage strategy to improve the utilization of constrained inline area.\nMoreover, a complimentary delta maintenance strategy is incorporated, which\nselectively maintains delta chunks in the main data area to break through the\nlimitation of constrained inline area. Experimental results show that DeltaFS\nsubstantially reduces write traffics by up to 64.8\\%, and improves the I/O\nperformance by up to 37.3\\%.",
    "descriptor": "",
    "authors": [
      "Chao Wu",
      "Cheng Ji",
      "Geng Yuan",
      "Riwei Pan",
      "Weichao Guo",
      "Chao Yu",
      "Zongwei Zhu",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.04623"
  },
  {
    "id": "arXiv:2210.04624",
    "title": "WebCrowds: An Authoring Tool for Crowd Simulation",
    "abstract": "Crowd simulation is an area of research largely used in the game industry.\nFrom the movement of a single NPC to the movement of an entire army, crowd\nsimulation methods can be used to move agents through the environment while\navoiding collisions with obstacles and between each other. Thus, it is\nimportant that game developers have access to crowd simulation tools that are\nboth powerful and easy to use. In this paper, we present WebCrowds, an\nauthoring tool for crowd simulation which can be used by anyone to build\nenvironments and simulate the movement of agents. The results achieved by our\nresearch suggest that WebCrowds is easy to use, delivers trustworthy simulation\nresults, and can be used as an authoring tool for game developers who need to\nsimulate crowds in their games.",
    "descriptor": "\nComments: 7 pages, 4 figures, conference\n",
    "authors": [
      "Gabriel Silva",
      "Paulo Knob",
      "Rubens Montanha",
      "Soraia Musse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04624"
  },
  {
    "id": "arXiv:2210.04625",
    "title": "Robustness Certification of Visual Perception Models via Camera Motion  Smoothing",
    "abstract": "A vast literature shows that the learning-based visual perception model is\nsensitive to adversarial noises but few works consider the robustness of\nrobotic perception models under widely-existing camera motion perturbations. To\nthis end, we study the robustness of the visual perception model under camera\nmotion perturbations to investigate the influence of camera motion on robotic\nperception. Specifically, we propose a motion smoothing technique for arbitrary\nimage classification models, whose robustness under camera motion perturbations\ncould be certified. The proposed robustness certification framework based on\ncamera motion smoothing provides tight and scalable robustness guarantees for\nvisual perception modules so that they are applicable to wide robotic\napplications. As far as we are aware, this is the first work to provide the\nrobustness certification for the deep perception module against camera motions,\nwhich improves the trustworthiness of robotic perception. A realistic indoor\nrobotic dataset with the dense point cloud map for the entire room, MetaRoom,\nis introduced for the challenging certifiable robust perception task. We\nconduct extensive experiments to validate the certification approach via motion\nsmoothing against camera motion perturbations. Our framework guarantees the\ncertified accuracy of 81.7% against camera translation perturbation along depth\ndirection within -0.1m ` 0.1m. We also validate the effectiveness of our method\non the real-world robot by conducting hardware experiment on the robotic arm\nwith an eye-in-hand camera. The code is available on\nhttps://github.com/HanjiangHu/camera-motion-smoothing.",
    "descriptor": "\nComments: CoRL 2022, 20 pages, 7 figures, 8 tables\n",
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Linyi Li",
      "Jiacheng Zhu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04625"
  },
  {
    "id": "arXiv:2210.04626",
    "title": "On Parallel or Distributed Asynchronous Iterations with Unbounded Delays  and Possible Out of Order Messages or Flexible Communication for Convex  Optimization Problems and Machine Learning",
    "abstract": "We describe several features of parallel or distributed asynchronous\niterative algorithms such as unbounded delays, possible out of order messages\nor flexible communication. We concentrate on the concept of macroiteration\nsequence which was introduced in order to study the convergence or termination\nof asynchronous iterations. A survey of asynchronous iterations for convex\noptimization problems is also presented. Finally, a new result of convergence\nfor parallel or distributed asynchronous iterative algorithms with flexible\ncommunication for convex optimization problems and machine learning is\nproposed.",
    "descriptor": "",
    "authors": [
      "Didier El Baz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.04626"
  },
  {
    "id": "arXiv:2210.04628",
    "title": "Novel View Synthesis with Diffusion Models",
    "abstract": "We present 3DiM, a diffusion model for 3D novel view synthesis, which is able\nto translate a single input view into consistent and sharp completions across\nmany views. The core component of 3DiM is a pose-conditional image-to-image\ndiffusion model, which takes a source view and its pose as inputs, and\ngenerates a novel view for a target pose as output. 3DiM can generate multiple\nviews that are 3D consistent using a novel technique called stochastic\nconditioning. The output views are generated autoregressively, and during the\ngeneration of each novel view, one selects a random conditioning view from the\nset of available views at each denoising step. We demonstrate that stochastic\nconditioning significantly improves the 3D consistency of a naive sampler for\nan image-to-image diffusion model, which involves conditioning on a single\nfixed view. We compare 3DiM to prior work on the SRN ShapeNet dataset,\ndemonstrating that 3DiM's generated completions from a single view achieve much\nhigher fidelity, while being approximately 3D consistent. We also introduce a\nnew evaluation methodology, 3D consistency scoring, to measure the 3D\nconsistency of a generated object by training a neural field on the model's\noutput views. 3DiM is geometry free, does not rely on hyper-networks or\ntest-time optimization for novel view synthesis, and allows a single model to\neasily scale to a large number of scenes.",
    "descriptor": "",
    "authors": [
      "Daniel Watson",
      "William Chan",
      "Ricardo Martin-Brualla",
      "Jonathan Ho",
      "Andrea Tagliasacchi",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04628"
  },
  {
    "id": "arXiv:2210.04631",
    "title": "A Prospective Analysis of Security Vulnerabilities within Link  Traversal-Based Query Processing (Extended Version)",
    "abstract": "The societal and economical consequences surrounding Big Data-driven\nplatforms have increased the call for decentralized solutions. However,\nretrieving and querying data in more decentralized environments requires\nfundamentally different approaches, whose properties are not yet well\nunderstood. Link Traversal-based Query Processing (LTQP) is a technique for\nquerying over decentralized data networks, in which a client-side query engine\ndiscovers data by traversing links between documents. Since decentralized\nenvironments are potentially unsafe due to their non-centrally controlled\nnature, there is a need for client-side LTQP query engines to be resistant\nagainst security threats aimed at the query engine's host machine or the query\ninitiator's personal data. As such, we have performed an analysis of potential\nsecurity vulnerabilities of LTQP. This article provides an overview of security\nthreats in related domains, which are used as inspiration for the\nidentification of 10 LTQP security threats. Each threat is explained, together\nwith an example, and one or more avenues for mitigations are proposed. We\nconclude with several concrete recommendations for LTQP query engine developers\nand data publishers as a first step to mitigate some of these issues. With this\nwork, we start filling the unknowns for enabling querying over decentralized\nenvironments. Aside from future work on security, wider research is needed to\nuncover missing building blocks for enabling true decentralization.",
    "descriptor": "\nComments: This is an extended version of an article with the same title published in the proceedings of the QuWeDa workshop at ISWC 2022. Next to more details in the related work and conclusions sections, this extension introduces concrete mitigations of each vulnerability\n",
    "authors": [
      "Ruben Taelman",
      "Ruben Verborgh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.04631"
  },
  {
    "id": "arXiv:2210.04633",
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models  for Programming Language Attend Code Structure",
    "abstract": "Code pre-trained models (CodePTMs) have recently demonstrated significant\nsuccess in code intelligence. To interpret these models, some probing methods\nhave been applied. However, these methods fail to consider the inherent\ncharacteristics of codes. In this paper, to address the problem, we propose a\nnovel probing method CAT-probing to quantitatively interpret how CodePTMs\nattend code structure. We first denoise the input code sequences based on the\ntoken types pre-defined by the compilers to filter those tokens whose attention\nscores are too small. After that, we define a new metric CAT-score to measure\nthe commonality between the token-level attention scores generated in CodePTMs\nand the pair-wise distances between corresponding AST nodes. The higher the\nCAT-score, the stronger ability of CodePTMs to capture code structure. We\nconduct extensive experiments to integrate CAT-probing with representative\nCodePTMs for different programming languages. Experimental results show the\neffectiveness of CAT-probing in CodePTM interpretation. Our codes and data are\npublicly available at https://github.com/nchen909/CodeAttention.",
    "descriptor": "\nComments: To appear in EMNLP 2022\n",
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.04633"
  },
  {
    "id": "arXiv:2210.04637",
    "title": "Association Graph Learning for Multi-Task Classification with Category  Shifts",
    "abstract": "In this paper, we focus on multi-task classification, where related\nclassification tasks share the same label space and are learned simultaneously.\nIn particular, we tackle a new setting, which is more realistic than currently\naddressed in the literature, where categories shift from training to test data.\nHence, individual tasks do not contain complete training data for the\ncategories in the test set. To generalize to such test data, it is crucial for\nindividual tasks to leverage knowledge from related tasks. To this end, we\npropose learning an association graph to transfer knowledge among tasks for\nmissing classes. We construct the association graph with nodes representing\ntasks, classes and instances, and encode the relationships among the nodes in\nthe edges to guide their mutual knowledge transfer. By message passing on the\nassociation graph, our model enhances the categorical information of each\ninstance, making it more discriminative. To avoid spurious correlations between\ntask and class nodes in the graph, we introduce an assignment entropy\nmaximization that encourages each class node to balance its edge weights. This\nenables all tasks to fully utilize the categorical information from related\ntasks. An extensive evaluation on three general benchmarks and a medical\ndataset for skin lesion classification reveals that our method consistently\nperforms better than representative baselines.",
    "descriptor": "",
    "authors": [
      "Jiayi Shen",
      "Zehao Xiao",
      "Xiantong Zhen",
      "Cees G. M. Snoek",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04637"
  },
  {
    "id": "arXiv:2210.04642",
    "title": "Exploration via Planning for Information about the Optimal Trajectory",
    "abstract": "Many potential applications of reinforcement learning (RL) are stymied by the\nlarge numbers of samples required to learn an effective policy. This is\nespecially true when applying RL to real-world control tasks, e.g. in the\nsciences or robotics, where executing a policy in the environment is costly. In\npopular RL algorithms, agents typically explore either by adding stochasticity\nto a reward-maximizing policy or by attempting to gather maximal information\nabout environment dynamics without taking the given task into account. In this\nwork, we develop a method that allows us to plan for exploration while taking\nboth the task and the current knowledge about the dynamics into account. The\nkey insight to our approach is to plan an action sequence that maximizes the\nexpected information gain about the optimal trajectory for the task at hand. We\ndemonstrate that our method learns strong policies with 2x fewer samples than\nstrong exploration baselines and 200x fewer samples than model free methods on\na diverse set of low-to-medium dimensional control tasks in both the open-loop\nand closed-loop control settings.",
    "descriptor": "\nComments: Conference paper at Neurips 2022. Code available at this https URL arXiv admin note: text overlap with arXiv:2112.05244\n",
    "authors": [
      "Viraj Mehta",
      "Ian Char",
      "Joseph Abbate",
      "Rory Conlin",
      "Mark D. Boyer",
      "Stefano Ermon",
      "Jeff Schneider",
      "Willie Neiswanger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04642"
  },
  {
    "id": "arXiv:2210.04643",
    "title": "Critical Learning Periods for Multisensory Integration in Deep Networks",
    "abstract": "We show that the ability of a neural network to integrate information from\ndiverse sources hinges critically on being exposed to properly correlated\nsignals during the early phases of training. Interfering with the learning\nprocess during this initial stage can permanently impair the development of a\nskill, both in artificial and biological systems where the phenomenon is known\nas critical learning period. We show that critical periods arise from the\ncomplex and unstable early transient dynamics, which are decisive of final\nperformance of the trained system and their learned representations. This\nevidence challenges the view, engendered by analysis of wide and shallow\nnetworks, that early learning dynamics of neural networks are simple, akin to\nthose of a linear model. Indeed, we show that even deep linear networks exhibit\ncritical learning periods for multi-source integration, while shallow networks\ndo not. To better understand how the internal representations change according\nto disturbances or sensory deficits, we introduce a new measure of source\nsensitivity, which allows us to track the inhibition and integration of sources\nduring training. Our analysis of inhibition suggests cross-source\nreconstruction as a natural auxiliary training objective, and indeed we show\nthat architectures trained with cross-sensor reconstruction objectives are\nremarkably more resilient to critical periods. Our findings suggest that the\nrecent success in self-supervised multi-modal training compared to previous\nsupervised efforts may be in part due to more robust learning dynamics and not\nsolely due to better architectures and/or more data.",
    "descriptor": "",
    "authors": [
      "Michael Kleinman",
      "Alessandro Achille",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.04643"
  },
  {
    "id": "arXiv:2210.04644",
    "title": "Enabling Cost-Effective Blockchain Applications via Workload-Adaptive  Transaction Execution",
    "abstract": "As transaction fees skyrocket today, blockchains become increasingly\nexpensive, hurting their adoption in broader applications.\nThis work tackles the saving of transaction fees for economic blockchain\napplications. The key insight is that other than the existing \"default\" mode to\nexecute application logic fully on-chain, i.e., in smart contracts, and in fine\ngranularity, i.e., user request per transaction, there are alternative\nexecution modes with advantages in cost-effectiveness.\nOn Ethereum, we propose a holistic middleware platform supporting flexible\nand secure transaction executions, including off-chain states and batching of\nuser requests. Furthermore, we propose control-plane schemes to adapt the\nexecution mode to the current workload for optimal runtime cost.\nWe present a case study on the institutional accounts (e.g., coinbase.com)\nintensively sending Ether on Ethereum blockchains. By collecting real-life\ntransactions, we construct workload benchmarks and show that our work saves 18%\n~ 47% per invocation than the default baseline while introducing 1.81 ~ 16.59\nblocks delay.",
    "descriptor": "",
    "authors": [
      "Yibo Wang",
      "Yuzhe Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04644"
  },
  {
    "id": "arXiv:2210.04655",
    "title": "A CNN Based Approach for the Point-Light Photometric Stereo Problem",
    "abstract": "Reconstructing the 3D shape of an object using several images under different\nlight sources is a very challenging task, especially when realistic assumptions\nsuch as light propagation and attenuation, perspective viewing geometry and\nspecular light reflection are considered. Many of works tackling Photometric\nStereo (PS) problems often relax most of the aforementioned assumptions.\nEspecially they ignore specular reflection and global illumination effects. In\nthis work, we propose a CNN-based approach capable of handling these realistic\nassumptions by leveraging recent improvements of deep neural networks for\nfar-field Photometric Stereo and adapt them to the point light setup. We\nachieve this by employing an iterative procedure of point-light PS for shape\nestimation which has two main steps. Firstly we train a per-pixel CNN to\npredict surface normals from reflectance samples. Secondly, we compute the\ndepth by integrating the normal field in order to iteratively estimate light\ndirections and attenuation which is used to compensate the input images to\ncompute reflectance samples for the next iteration.\nOur approach sigificantly outperforms the state-of-the-art on the DiLiGenT\nreal world dataset. Furthermore, in order to measure the performance of our\napproach for near-field point-light source PS data, we introduce LUCES the\nfirst real-world 'dataset for near-fieLd point light soUrCe photomEtric Stereo'\nof 14 objects of different materials were the effects of point light sources\nand perspective viewing are a lot more significant. Our approach also\noutperforms the competition on this dataset as well. Data and test code are\navailable at the project page.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.05792\n",
    "authors": [
      "Fotios Logothetis",
      "Roberto Mecca",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04655"
  },
  {
    "id": "arXiv:2210.04656",
    "title": "Communication between agents in dynamic epistemic logic",
    "abstract": "This manuscript studies actions of communication between epistemic logic\nagents. It starts by looking into actions through which all/some agents share\nall their information, defining the model operation that transforms the model,\ndiscussing its properties, introducing a modality for describing it and\nproviding an axiom system for the latter. The main part of the manuscript\nfocuses on an action through which some agents share part of their information:\nthey share all that they know about a topic defined by a given formula. Once\nagain, the manuscript defines the model operation that transforms the model,\ndiscusses its properties, introduces a modality for describing it and provides\nan axiom system for the latter.",
    "descriptor": "",
    "authors": [
      "Fernando R. Vel\u00e1zquez-Quesada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.04656"
  },
  {
    "id": "arXiv:2210.04665",
    "title": "Towards Developing and Analysing Metric-Based Software Defect Severity  Prediction Model",
    "abstract": "In a critical software system, the testers have to spend an enormous amount\nof time and effort to maintain the software due to the continuous occurrence of\ndefects. Among such defects, some severe defects may adversely affect the\nsoftware. To reduce the time and effort of a tester, many machine learning\nmodels have been proposed in the literature, which use the documented defect\nreports to automatically predict the severity of the defective software\nmodules. In contrast to the traditional approaches, in this work we propose a\nmetric-based software defect severity prediction (SDSP) model that uses a\nself-training semi-supervised learning approach to classify the severity of the\ndefective software modules. The approach is constructed on a mixture of\nunlabelled and labelled defect severity data. The self-training works on the\nbasis of a decision tree classifier to assign the pseudo-class labels to the\nunlabelled instances. The predictions are promising since the self-training\nsuccessfully assigns the suitable class labels to the unlabelled instances.\nOn the other hand, numerous research studies have covered proposing\nprediction approaches as well as the methodological aspects of defect severity\nprediction models, the gap in estimating project attributes from the prediction\nmodel remains unresolved. To bridge the gap, we propose five project specific\nmeasures such as the Risk-Factor (RF), the Percent of Saved Budget (PSB), the\nLoss in the Saved Budget (LSB), the Remaining Service Time (RST) and Gratuitous\nService Time (GST) to capture project outcomes from the predictions. Similar to\nthe traditional measures, these measures are also calculated from the observed\nconfusion matrix. These measures are used to analyse the impact that the\nprediction model has on the software project.",
    "descriptor": "",
    "authors": [
      "Umamaheswara Sharma B",
      "Ravichandra Sadam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04665"
  },
  {
    "id": "arXiv:2210.04671",
    "title": "Evaluating Point Cloud Quality via Transformational Complexity",
    "abstract": "Full-reference point cloud quality assessment (FR-PCQA) aims to infer the\nquality of distorted point clouds with available references. Merging the\nresearch of cognitive science and intuition of the human visual system (HVS),\nthe difference between the expected perceptual result and the practical\nperception reproduction in the visual center of the cerebral cortex indicates\nthe subjective quality degradation. Therefore in this paper, we try to derive\nthe point cloud quality by measuring the complexity of transforming the\ndistorted point cloud back to its reference, which in practice can be\napproximated by the code length of one point cloud when the other is given. For\nthis purpose, we first segment the reference and the distorted point cloud into\na series of local patch pairs based on one 3D Voronoi diagram. Next, motivated\nby the predictive coding theory, we utilize one space-aware vector\nautoregressive (SA-VAR) model to encode the geometry and color channels of each\nreference patch in cases with and without the distorted patch, respectively.\nSpecifically, supposing that the residual errors follow the multi-variate\nGaussian distributions, we calculate the self-complexity of the reference and\nthe transformational complexity between the reference and the distorted sample\nvia covariance matrices. Besides the complexity terms, the prediction terms\ngenerated by SA-VAR are introduced as one auxiliary feature to promote the\nfinal quality prediction. Extensive experiments on five public point cloud\nquality databases demonstrate that the transformational complexity based\ndistortion metric (TCDM) produces state-of-the-art (SOTA) results, and ablation\nstudies have further shown that our metric can be generalized to various\nscenarios with consistent performance by examining its key modules and\nparameters.",
    "descriptor": "",
    "authors": [
      "Yujie Zhang",
      "Qi Yang",
      "Yifei Zhou",
      "Xiaozhong Xu",
      "Le Yang",
      "Yiling Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.04671"
  },
  {
    "id": "arXiv:2210.04672",
    "title": "Exploiting map information for self-supervised learning in motion  forecasting",
    "abstract": "Inspired by recent developments regarding the application of self-supervised\nlearning (SSL), we devise an auxiliary task for trajectory prediction that\ntakes advantage of map-only information such as graph connectivity with the\nintent of improving map comprehension and generalization. We apply this\nauxiliary task through two frameworks - multitasking and pretraining. In either\nframework we observe significant improvement of our baseline in metrics such as\n$\\mathrm{minFDE}_6$ (as much as 20.3%) and $\\mathrm{MissRate}_6$ (as much as\n33.3%), as well as a richer comprehension of map features demonstrated by\ndifferent training configurations. The results obtained were consistent in all\nthree data sets used for experiments: Argoverse, Interaction and NuScenes. We\nalso submit our new pretrained model's results to the Interaction challenge and\nachieve $\\textit{1st}$ place with respect to $\\mathrm{minFDE}_6$ and\n$\\mathrm{minADE}_6$.",
    "descriptor": "",
    "authors": [
      "Caio Azevedo",
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04672"
  },
  {
    "id": "arXiv:2210.04675",
    "title": "A Survey of Methods for Addressing Class Imbalance in Deep-Learning  Based Natural Language Processing",
    "abstract": "Many natural language processing (NLP) tasks are naturally imbalanced, as\nsome target categories occur much more frequently than others in the real\nworld. In such scenarios, current NLP models still tend to perform poorly on\nless frequent classes. Addressing class imbalance in NLP is an active research\ntopic, yet, finding a good approach for a particular task and imbalance\nscenario is difficult.\nWith this survey, the first overview on class imbalance in deep-learning\nbased NLP, we provide guidance for NLP researchers and practitioners dealing\nwith imbalanced data. We first discuss various types of controlled and\nreal-world class imbalance. Our survey then covers approaches that have been\nexplicitly proposed for class-imbalanced NLP tasks or, originating in the\ncomputer vision community, have been evaluated on them. We organize the methods\nby whether they are based on sampling, data augmentation, choice of loss\nfunction, staged learning, or model design. Finally, we discuss open problems\nsuch as dealing with multi-label scenarios, and propose systematic benchmarking\nand reporting in order to move forward on this problem as a community.",
    "descriptor": "",
    "authors": [
      "Sophie Henning",
      "William H. Beluch",
      "Alexander Fraser",
      "Annemarie Friedrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04675"
  },
  {
    "id": "arXiv:2210.04676",
    "title": "Learning \"O\" Helps for Learning More: Handling the Concealed Entity  Problem for Class-incremental NER",
    "abstract": "As the categories of named entities rapidly increase in real-world\napplications, class-incremental learning for NER is in demand, which\ncontinually learns new entity classes while maintaining the old knowledge. Due\nto privacy concerns and storage constraints, the model is required to update\nwithout any annotations of the old entity classes. However, in each step on\nstreaming data, the \"O\" class in each step might contain unlabeled entities\nfrom the old classes, or potential entities from the incoming classes. In this\nwork, we first carry out an empirical study to investigate the concealed entity\nproblem in class-incremental NER. We find that training with \"O\" leads to\nsevere confusion of \"O\" and concealed entity classes, and harms the\nseparability of potential classes. Based on this discovery, we design a\nrehearsal-based representation learning approach for appropriately learning the\n\"O\" class for both old and potential entity classes. Additionally, we provide a\nmore realistic and challenging benchmark for class-incremental NER which\nintroduces multiple categories in each step. Experimental results verify our\nfindings and show the effectiveness of the proposed method on the new\nbenchmark.",
    "descriptor": "",
    "authors": [
      "Ruotian Ma",
      "Xuanting Chen",
      "Lin Zhang",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04676"
  },
  {
    "id": "arXiv:2210.04677",
    "title": "UAV Placement for Real-time Video Acquisition: A Tradeoff between  Resolution and Delay",
    "abstract": "Recently, UAVs endowed with high mobility, low cost, and remote control have\npromoted the development of UAV-assisted real-time video/image acquisition\napplications, which have a high demand for both transmission rate and image\nresolution. However, in conventional vertical photography model, the UAV should\nfly to the top of ground targets (GTs) to capture images, thus enlarge the\ntransmission delay. In this paper, we propose an oblique photography model,\nwhich allows the UAV to capture images of GTs from a far distance while still\nsatisfying the predetermined resolution requirement. Based on the proposed\noblique photography model, we further study the UAV placement problem in the\ncellular-connected UAV-assisted image acquisition system, which aims at\nminimizing the data transmission delay under the condition of satisfying the\npredetermined image resolution requirement. Firstly, the proposed scheme is\nfirst formulated as an intractable non-convex optimization problem. Then, the\noriginal problem is simplified to obtain a tractable suboptimal solution with\nthe help of the block coordinate descent and the successive convex\napproximation techniques. Finally, the numerical results are presented to show\nthe effectiveness of the proposed scheme. The numerical results have shown that\nthe proposed scheme can largely save the transmission time as compared to the\nconventional vertical photography model.",
    "descriptor": "\nComments: submitted to ieee for possible publication. arXiv admin note: text overlap with arXiv:2006.14438 by other authors\n",
    "authors": [
      "Tang Xiao-Wei",
      "Huang Xin-Lin Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.04677"
  },
  {
    "id": "arXiv:2210.04683",
    "title": "End-to-End QoS for the Open Source Safety-Relevant RISC-V SELENE  Platform",
    "abstract": "This paper presents the end-to-end QoS approach to provide performance\nguarantees followed in the SELENE platform, a high-performance RISC-V based\nheterogeneous SoC for safety-related real-time systems. Our QoS approach\nincludes smart interconnect solutions for buses and NoCs, along with multicore\ninterference-aware statistics units to, cooperatively, achieve end-to-end QoS.",
    "descriptor": "\nComments: 4 pages, 3 figures, work presented on FORECAST workshop of HIPEAC 2022\n",
    "authors": [
      "Pablo Andreu",
      "Carles Hernandez",
      "Tomas Picornell",
      "Pedro Lopez",
      "Sergi Alcaide",
      "Francisco Bas",
      "Pedro Benedicte",
      "Guillem Cabo",
      "Feng Chang",
      "Francisco Fuentes",
      "Jaume Abella"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.04683"
  },
  {
    "id": "arXiv:2210.04686",
    "title": "Utilizing Explainable AI for improving the Performance of Neural  Networks",
    "abstract": "Nowadays, deep neural networks are widely used in a variety of fields that\nhave a direct impact on society. Although those models typically show\noutstanding performance, they have been used for a long time as black boxes. To\naddress this, Explainable Artificial Intelligence (XAI) has been developing as\na field that aims to improve the transparency of the model and increase their\ntrustworthiness. We propose a retraining pipeline that consistently improves\nthe model predictions starting from XAI and utilizing state-of-the-art\ntechniques. To do that, we use the XAI results, namely SHapley Additive\nexPlanations (SHAP) values, to give specific training weights to the data\nsamples. This leads to an improved training of the model and, consequently,\nbetter performance. In order to benchmark our method, we evaluate it on both\nreal-life and public datasets. First, we perform the method on a radar-based\npeople counting scenario. Afterward, we test it on the CIFAR-10, a public\nComputer Vision dataset. Experiments using the SHAP-based retraining approach\nachieve a 4% more accuracy w.r.t. the standard equal weight retraining for\npeople counting tasks. Moreover, on the CIFAR-10, our SHAP-based weighting\nstrategy ends up with a 3% accuracy rate than the training procedure with equal\nweighted samples.",
    "descriptor": "\nComments: accepted at ICMLA 2022\n",
    "authors": [
      "Huawei Sun",
      "Lorenzo Servadei",
      "Hao Feng",
      "Michael Stephan",
      "Robert Wille",
      "Avik Santra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04686"
  },
  {
    "id": "arXiv:2210.04688",
    "title": "Mind Your Data! Hiding Backdoors in Offline Reinforcement Learning  Datasets",
    "abstract": "A growing body of research works has focused on the Offline Reinforcement\nLearning (RL) paradigm. Data providers share large pre-collected datasets on\nwhich others can train high-quality agents without interacting with the\nenvironments. Such an offline RL paradigm has demonstrated effectiveness in\nmany critical tasks, including robot control, autonomous driving, etc. A\nwell-trained agent can be regarded as a software system. However, less\nattention is paid to investigating the security threats to the offline RL\nsystem. In this paper, we focus on a critical security threat: backdoor\nattacks. Given normal observations, an agent implanted with backdoors takes\nactions leading to high rewards. However, the same agent takes actions that\nlead to low rewards if the observations are injected with triggers that can\nactivate the backdoor. In this paper, we propose Baffle (Backdoor Attack for\nOffline Reinforcement Learning) and evaluate how different Offline RL\nalgorithms react to this attack. Our experiments conducted on four tasks and\nfour offline RL algorithms expose a disquieting fact: none of the existing\noffline RL algorithms is immune to such a backdoor attack. More specifically,\nBaffle modifies $10\\%$ of the datasets for four tasks (3 robotic controls and 1\nautonomous driving). Agents trained on the poisoned datasets perform well in\nnormal settings. However, when triggers are presented, the agents' performance\ndecreases drastically by $63.6\\%$, $57.8\\%$, $60.8\\%$ and $44.7\\%$ in the four\ntasks on average. The backdoor still persists after fine-tuning poisoned agents\non clean datasets. We further show that the inserted backdoor is also hard to\nbe detected by a popular defensive method. This paper calls attention to\ndeveloping more effective protection for the open-source offline RL dataset.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Chen Gong",
      "Zhou Yang",
      "Yunpeng Bai",
      "Junda He",
      "Jieke Shi",
      "Arunesh Sinha",
      "Bowen Xu",
      "Xinwen Hou",
      "Guoliang Fan",
      "David Lo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04688"
  },
  {
    "id": "arXiv:2210.04689",
    "title": "Time Minimization in Hierarchical Federated Learning",
    "abstract": "Federated Learning is a modern decentralized machine learning technique where\nuser equipments perform machine learning tasks locally and then upload the\nmodel parameters to a central server. In this paper, we consider a 3-layer\nhierarchical federated learning system which involves model parameter exchanges\nbetween the cloud and edge servers, and the edge servers and user equipment. In\na hierarchical federated learning model, delay in communication and computation\nof model parameters has a great impact on achieving a predefined global model\naccuracy. Therefore, we formulate a joint learning and communication\noptimization problem to minimize total model parameter communication and\ncomputation delay, by optimizing local iteration counts and edge iteration\ncounts. To solve the problem, an iterative algorithm is proposed. After that, a\ntime-minimized UE-to-edge association algorithm is presented where the maximum\nlatency of the system is reduced. Simulation results show that the global model\nconverges faster under optimal edge server and local iteration counts. The\nhierarchical federated learning latency is minimized with the proposed\nUE-to-edge association strategy.",
    "descriptor": "\nComments: This paper appears in the Proceedings of 2022 ACM/IEEE Symposium on Edge Computing (SEC). Please feel free to contact us for questions or remarks\n",
    "authors": [
      "Chang Liu",
      "Terence Jie Chua",
      "Jun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04689"
  },
  {
    "id": "arXiv:2210.04692",
    "title": "Language Prior Is Not the Only Shortcut: A Benchmark for Shortcut  Learning in VQA",
    "abstract": "Visual Question Answering (VQA) models are prone to learn the shortcut\nsolution formed by dataset biases rather than the intended solution. To\nevaluate the VQA models' reasoning ability beyond shortcut learning, the VQA-CP\nv2 dataset introduces a distribution shift between the training and test set\ngiven a question type. In this way, the model cannot use the training set\nshortcut (from question type to answer) to perform well on the test set.\nHowever, VQA-CP v2 only considers one type of shortcut and thus still cannot\nguarantee that the model relies on the intended solution rather than a solution\nspecific to this shortcut. To overcome this limitation, we propose a new\ndataset that considers varying types of shortcuts by constructing different\ndistribution shifts in multiple OOD test sets. In addition, we overcome the\nthree troubling practices in the use of VQA-CP v2, e.g., selecting models using\nOOD test sets, and further standardize OOD evaluation procedure. Our benchmark\nprovides a more rigorous and comprehensive testbed for shortcut learning in\nVQA. We benchmark recent methods and find that methods specifically designed\nfor particular shortcuts fail to simultaneously generalize to our varying OOD\ntest sets. We also systematically study the varying shortcuts and provide\nseveral valuable findings, which may promote the exploration of shortcut\nlearning in VQA.",
    "descriptor": "\nComments: Fingdings of EMNLP-2022\n",
    "authors": [
      "Qingyi Si",
      "Fandong Meng",
      "Mingyu Zheng",
      "Zheng Lin",
      "Yuanxin Liu",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04692"
  },
  {
    "id": "arXiv:2210.04695",
    "title": "Language Models Are Poor Learners of Directional Inference",
    "abstract": "We examine LMs' competence of directional predicate entailments by supervised\nfine-tuning with prompts. Our analysis shows that contrary to their apparent\nsuccess on standard NLI, LMs show limited ability to learn such directional\ninference; moreover, existing datasets fail to test directionality, and/or are\ninfested by artefacts that can be learnt as proxy for entailments, yielding\nover-optimistic results. In response, we present BoOQA (Boolean Open QA), a\nrobust multi-lingual evaluation benchmark for directional predicate\nentailments, extrinsic to existing training sets. On BoOQA, we establish\nbaselines and show evidence of existing LM-prompting models being incompetent\ndirectional entailment learners, in contrast to entailment graphs, however\nlimited by sparsity.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tianyi Li",
      "Mohammad Javad Hosseini",
      "Sabine Weber",
      "Mark Steedman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04695"
  },
  {
    "id": "arXiv:2210.04699",
    "title": "FedBA: Non-IID Federated Learning Framework in UAV Networks",
    "abstract": "With the development and progress of science and technology, the Internet of\nThings(IoT) has gradually entered people's lives, bringing great convenience to\nour lives and improving people's work efficiency. Specifically, the IoT can\nreplace humans in jobs that they cannot perform. As a new type of IoT vehicle,\nthe current status and trend of research on Unmanned Aerial Vehicle(UAV) is\ngratifying, and the development prospect is very promising. However, privacy\nand communication are still very serious issues in drone applications. This is\nbecause most drones still use centralized cloud-based data processing, which\nmay lead to leakage of data collected by drones. At the same time, the large\namount of data collected by drones may incur greater communication overhead\nwhen transferred to the cloud. Federated learning as a means of privacy\nprotection can effectively solve the above two problems. However, federated\nlearning when applied to UAV networks also needs to consider the heterogeneity\nof data, which is caused by regional differences in UAV regulation. In\nresponse, this paper proposes a new algorithm FedBA to optimize the global\nmodel and solves the data heterogeneity problem. In addition, we apply the\nalgorithm to some real datasets, and the experimental results show that the\nalgorithm outperforms other algorithms and improves the accuracy of the local\nmodel for UAVs.",
    "descriptor": "",
    "authors": [
      "Pei Li",
      "Zhijun Liu",
      "Luyi Chang",
      "Jialiang Peng",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04699"
  },
  {
    "id": "arXiv:2210.04700",
    "title": "Bio-inspired Algorithms in the Optimisation of Wireless Sensor Networks",
    "abstract": "WSN are a growing technology in industrial and personal use fields. The\nQuality of Service (QoS) of WSN is associated to the architecture of WSN nodes\nand network design. In this work, the composition of the nodes and network is\nanalysed. The success of WSN is related to the maximisation of the lifetime and\ncoverage of the device, allied to the minimisation of energy consumption and\nnumber of nodes, guaranteeing a good network connectivity and high\ntransmission. The most common WSN issues are presented and reviewed. The most\nsuitable optimisation technique is Multi-objective (MOO) which is exemplified\nin this work from complex multi-objective functions which include several WSN\nproblems. The second part of this review focus on bio-inspired algorithms in\nWSN optimisation: Genetic Algorithms (GA), Particles Swarm Optimisation (PSO)\nand Ant Colony Optimisation (ACO). Other less common methods are also present\nand related to WSN issues.",
    "descriptor": "",
    "authors": [
      "Joana Matos",
      "Carine M. Rebello",
      "Erbet A. Costa",
      "Luana P. Queiroz",
      "Maria Joao B. Regufe",
      "Idelfonso B.R. Nogueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.04700"
  },
  {
    "id": "arXiv:2210.04705",
    "title": "Readability Controllable Biomedical Document Summarization",
    "abstract": "Different from general documents, it is recognised that the ease with which\npeople can understand a biomedical text is eminently varied, owing to the\nhighly technical nature of biomedical documents and the variance of readers'\ndomain knowledge. However, existing biomedical document summarization systems\nhave paid little attention to readability control, leaving users with summaries\nthat are incompatible with their levels of expertise. In recognition of this\nurgent demand, we introduce a new task of readability controllable\nsummarization for biomedical documents, which aims to recognise users'\nreadability demands and generate summaries that better suit their needs:\ntechnical summaries for experts and plain language summaries (PLS) for laymen.\nTo establish this task, we construct a corpus consisting of biomedical papers\nwith technical summaries and PLSs written by the authors, and benchmark\nmultiple advanced controllable abstractive and extractive summarization models\nbased on pre-trained language models (PLMs) with prevalent controlling and\ngeneration techniques. Moreover, we propose a novel masked language model (MLM)\nbased metric and its variant to effectively evaluate the readability\ndiscrepancy between lay and technical summaries. Experimental results from\nautomated and human evaluations show that though current control techniques\nallow for a certain degree of readability adjustment during generation, the\nperformance of existing controllable summarization methods is far from\ndesirable in this task.",
    "descriptor": "\nComments: accepted to the Findings of EMNLP 2022\n",
    "authors": [
      "Zheheng Luo",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04705"
  },
  {
    "id": "arXiv:2210.04708",
    "title": "GTAV-NightRain: Photometric Realistic Large-scale Dataset for Night-time  Rain Streak Removal",
    "abstract": "Rain is transparent, which reflects and refracts light in the scene to the\ncamera. In outdoor vision, rain, especially rain streaks degrade visibility and\ntherefore need to be removed. In existing rain streak removal datasets,\nalthough density, scale, direction and intensity have been considered,\ntransparency is not fully taken into account. This problem is particularly\nserious in night scenes, where the appearance of rain largely depends on the\ninteraction with scene illuminations and changes drastically on different\npositions within the image. This is problematic, because unrealistic dataset\ncauses serious domain bias. In this paper, we propose GTAV-NightRain dataset,\nwhich is a large-scale synthetic night-time rain streak removal dataset. Unlike\nexisting datasets, by using 3D computer graphic platform (namely GTA V), we are\nallowed to infer the three dimensional interaction between rain and\nilluminations, which insures the photometric realness. Current release of the\ndataset contains 12,860 HD rainy images and 1,286 corresponding HD ground truth\nimages in diversified night scenes. A systematic benchmark and analysis are\nprovided along with the dataset to inspire further research.",
    "descriptor": "",
    "authors": [
      "Fan Zhang",
      "Shaodi You",
      "Yu Li",
      "Ying Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04708"
  },
  {
    "id": "arXiv:2210.04709",
    "title": "Error analysis of a backward Euler positive preserving stabilized scheme  for a Chemotaxis system",
    "abstract": "We consider the Keller-Segel model of chemotaxis on a bounded domain\n$\\Omega\\subset{\\mathbb{R}^2}$. Assuming appropriate conditions in order to have\nbounded solutions for all times, we discretize the spatial variable with the\nstandard finite element method and the temporal variable with implicit Euler.\nOur aim is to prove results conserving the non-negativity and the mass\nconservation of the stabilized schemes which are introduced in (R.Strehl et al\n2010). Moreover, under suitable smoothness assumptions on the solution and\nusing standard techniques, we derive error estimates in $L_2$ and $H^1-$norm in\nspace and $L_\\infty$ and $L_2$ in time, respectively, for the stabilisation\nschemes which have been proposed in (R.Strehl et al 2010).",
    "descriptor": "",
    "authors": [
      "Panagiotis Chatzipandelidis",
      "Christos Pervolianakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04709"
  },
  {
    "id": "arXiv:2210.04710",
    "title": "Empowering the Fact-checkers! Automatic Identification of Claim Spans on  Twitter",
    "abstract": "The widespread diffusion of medical and political claims in the wake of\nCOVID-19 has led to a voluminous rise in misinformation and fake news. The\ncurrent vogue is to employ manual fact-checkers to efficiently classify and\nverify such data to combat this avalanche of claim-ridden misinformation.\nHowever, the rate of information dissemination is such that it vastly outpaces\nthe fact-checkers' strength. Therefore, to aid manual fact-checkers in\neliminating the superfluous content, it becomes imperative to automatically\nidentify and extract the snippets of claim-worthy (mis)information present in a\npost. In this work, we introduce the novel task of Claim Span Identification\n(CSI). We propose CURT, a large-scale Twitter corpus with token-level claim\nspans on more than 7.5k tweets. Furthermore, along with the standard token\nclassification baselines, we benchmark our dataset with DABERTa, an\nadapter-based variation of RoBERTa. The experimental results attest that\nDABERTa outperforms the baseline systems across several evaluation metrics,\nimproving by about 1.5 points. We also report detailed error analysis to\nvalidate the model's performance along with the ablation studies. Lastly, we\nrelease our comprehensive span annotation guidelines for public use.",
    "descriptor": "\nComments: Accepted at EMNLP22. 16 pages including Appendix\n",
    "authors": [
      "Megha Sundriyal",
      "Atharva Kulkarni",
      "Vaibhav Pulastya",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04710"
  },
  {
    "id": "arXiv:2210.04714",
    "title": "Uncertainty Quantification with Pre-trained Language Models: A  Large-Scale Empirical Analysis",
    "abstract": "Pre-trained language models (PLMs) have gained increasing popularity due to\ntheir compelling prediction performance in diverse natural language processing\n(NLP) tasks. When formulating a PLM-based prediction pipeline for NLP tasks, it\nis also crucial for the pipeline to minimize the calibration error, especially\nin safety-critical applications. That is, the pipeline should reliably indicate\nwhen we can trust its predictions. In particular, there are various\nconsiderations behind the pipeline: (1) the choice and (2) the size of PLM, (3)\nthe choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and\nmany more. Although prior work has looked into some of these considerations,\nthey usually draw conclusions based on a limited scope of empirical studies.\nThere still lacks a holistic analysis on how to compose a well-calibrated\nPLM-based prediction pipeline. To fill this void, we compare a wide range of\npopular options for each consideration based on three prevalent NLP\nclassification tasks and the setting of domain shift. In response, we recommend\nthe following: (1) use ELECTRA for PLM encoding, (2) use larger PLMs if\npossible, (3) use Temp Scaling as the uncertainty quantifier, and (4) use Focal\nLoss for fine-tuning.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (Findings)\n",
    "authors": [
      "Yuxin Xiao",
      "Paul Pu Liang",
      "Umang Bhatt",
      "Willie Neiswanger",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04714"
  },
  {
    "id": "arXiv:2210.04716",
    "title": "A two-stage approach for table extraction in invoices",
    "abstract": "The automated analysis of administrative documents is an important field in\ndocument recognition that is studied for decades. Invoices are key documents\namong these huge amounts of documents available in companies and public\nservices. Invoices contain most of the time data that are presented in tables\nthat should be clearly identified to extract suitable information. In this\npaper, we propose an approach that combines an image processing based\nestimation of the shape of the tables with a graph-based representation of the\ndocument, which is used to identify complex tables precisely. We propose an\nexperimental evaluation using a real case application.",
    "descriptor": "",
    "authors": [
      "Thomas Saout",
      "Fr\u00e9d\u00e9ric Lardeux",
      "Fr\u00e9d\u00e9ric Saubion"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.04716"
  },
  {
    "id": "arXiv:2210.04722",
    "title": "Semantics-Consistent Cross-domain Summarization via Optimal Transport  Alignment",
    "abstract": "Multimedia summarization with multimodal output (MSMO) is a recently explored\napplication in language grounding. It plays an essential role in real-world\napplications, i.e., automatically generating cover images and titles for news\narticles or providing introductions to online videos. However, existing methods\nextract features from the whole video and article and use fusion methods to\nselect the representative one, thus usually ignoring the critical structure and\nvarying semantics. In this work, we propose a Semantics-Consistent Cross-domain\nSummarization (SCCS) model based on optimal transport alignment with visual and\ntextual segmentation. In specific, our method first decomposes both video and\narticle into segments in order to capture the structural semantics,\nrespectively. Then SCCS follows a cross-domain alignment objective with optimal\ntransport distance, which leverages multimodal interaction to match and select\nthe visual and textual summary. We evaluated our method on three recent\nmultimodal datasets and demonstrated the effectiveness of our method in\nproducing high-quality multimodal summaries.",
    "descriptor": "",
    "authors": [
      "Jielin Qiu",
      "Jiacheng Zhu",
      "Mengdi Xu",
      "Franck Dernoncourt",
      "Trung Bui",
      "Zhaowen Wang",
      "Bo Li",
      "Ding Zhao",
      "Hailin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04722"
  },
  {
    "id": "arXiv:2210.04723",
    "title": "Experiential Explanations for Reinforcement Learning",
    "abstract": "Reinforcement Learning (RL) approaches are becoming increasingly popular in\nvarious key disciplines, including robotics and healthcare. However, many of\nthese systems are complex and non-interpretable, making it challenging for\nnon-AI experts to understand or intervene. One of the challenges of explaining\nRL agent behavior is that, when learning to predict future expected reward,\nagents discard contextual information about their experiences when training in\nan environment and rely solely on expected utility. We propose a technique,\nExperiential Explanations, for generating local counterfactual explanations\nthat can answer users' why-not questions by explaining qualitatively the\neffects of the various environmental rewards on the agent's behavior. We\nachieve this by training additional modules alongside the policy. These models,\ncalled influence predictors, model how different reward sources influence the\nagent's policy, thus restoring lost contextual information about how the policy\nreflects the environment. To generate explanations, we use these models in\naddition to the policy to contrast between the agent's intended behavior\ntrajectory and a counterfactual trajectory suggested by the user.",
    "descriptor": "",
    "authors": [
      "Amal Alabdulkarim",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.04723"
  },
  {
    "id": "arXiv:2210.04726",
    "title": "Knowledge Prompts: Injecting World Knowledge into Language Models  through Soft Prompts",
    "abstract": "Soft prompts have been recently proposed as a tool for adapting large frozen\nlanguage models (LMs) to new tasks. In this work, we repurpose soft prompts to\nthe task of injecting world knowledge into LMs. We introduce a method to train\nsoft prompts via self-supervised learning on data from knowledge bases. The\nresulting soft knowledge prompts (KPs) are task independent and work as an\nexternal memory of the LMs. We perform qualitative and quantitative experiments\nand demonstrate that: (1) KPs can effectively model the structure of the\ntraining data; (2) KPs can be used to improve the performance of LMs in\ndifferent knowledge intensive tasks.",
    "descriptor": "",
    "authors": [
      "Cicero Nogueira dos Santos",
      "Zhe Dong",
      "Daniel Cer",
      "John Nham",
      "Siamak Shakeri",
      "Jianmo Ni",
      "Yun-hsuan Sung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04726"
  },
  {
    "id": "arXiv:2210.04728",
    "title": "PyHopper -- Hyperparameter optimization",
    "abstract": "Hyperparameter tuning is a fundamental aspect of machine learning research.\nSetting up the infrastructure for systematic optimization of hyperparameters\ncan take a significant amount of time. Here, we present PyHopper, a black-box\noptimization platform designed to streamline the hyperparameter tuning workflow\nof machine learning researchers. PyHopper's goal is to integrate with existing\ncode with minimal effort and run the optimization process with minimal\nnecessary manual oversight. With simplicity as the primary theme, PyHopper is\npowered by a single robust Markov-chain Monte-Carlo optimization algorithm that\nscales to millions of dimensions. Compared to existing tuning packages,\nfocusing on a single algorithm frees the user from having to decide between\nseveral algorithms and makes PyHopper easily customizable. PyHopper is publicly\navailable under the Apache-2.0 license at https://github.com/PyHopper/PyHopper.",
    "descriptor": "",
    "authors": [
      "Mathias Lechner",
      "Ramin Hasani",
      "Philipp Neubauer",
      "Sophie Neubauer",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04728"
  },
  {
    "id": "arXiv:2210.04729",
    "title": "The Foil: Capture-Avoiding Substitution With No Sharp Edges",
    "abstract": "Correctly manipulating program terms in a compiler is surprisingly difficult\nbecause of the need to avoid name capture. The rapier from \"Secrets of the\nGlasgow Haskell Compiler inliner\" is a cutting-edge technique for fast,\nstateless capture-avoiding substitution for expressions represented with\nexplicit names. It is, however, a sharp tool: its invariants are tricky and\nneed to be maintained throughout the whole compiler that uses it. We describe\nthe foil, an elaboration of the rapier that uses Haskell's type system to\nenforce the rapier's invariants statically, preventing a class of hard-to-find\nbugs, but without adding any run-time overheads.",
    "descriptor": "\nComments: Presented at IFL 2022\n",
    "authors": [
      "Dougal Maclaurin",
      "Alexey Radul",
      "Adam Paszke"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.04729"
  },
  {
    "id": "arXiv:2210.04733",
    "title": "A Privacy Preserving IoT Data Marketplace Using IOTA Smart Contracts",
    "abstract": "In recent years, the volume of data generated by IoT devices has increased\ndramatically. Using this data can improve decision-making in the public and\nprivate sectors and increase productivity. Many attempts have been made to\nenhance and adapt businesses to exploit this IoT data. Among these, IoT data\ntrading is the most popular approach. To this end, ongoing projects are\ncurrently focused on developing decentralized data marketplaces for IoT using\nblockchain and cryptocurrencies. Here we explore how a decentralized data\nmarketplace could be created using IOTA tangle and IOTA smart contract chains\n(SC chains). We also consider the advantages of such architecture in terms of\ncost, scalability, and privacy over current designs and introduce the various\nelements it should have.",
    "descriptor": "\nComments: 7 pages, 2 figurea\n",
    "authors": [
      "Hadi Farahani",
      "Hamid Reza Shahriari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04733"
  },
  {
    "id": "arXiv:2210.04735",
    "title": "Edge Device Deployment of Multi-Tasking Network for Self-Driving  Operations",
    "abstract": "A safe and robust autonomous driving system relies on accurate perception of\nthe environment for application-oriented scenarios. This paper proposes\ndeployment of the three most crucial tasks (i.e., object detection, drivable\narea segmentation and lane detection tasks) on embedded system for self-driving\noperations. To achieve this research objective, multi-tasking network is\nutilized with a simple encoder-decoder architecture. Comprehensive and\nextensive comparisons for two models based on different backbone networks are\nperformed. All training experiments are performed on server while Nvidia Jetson\nXavier NX is chosen as deployment device.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1908.08926 by other authors\n",
    "authors": [
      "Shokhrukh Miraliev",
      "Shakhboz Abdigapporov",
      "Jumabek Alikhanov",
      "Vijay Kakani",
      "Hakil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04735"
  },
  {
    "id": "arXiv:2210.04738",
    "title": "A dynamic programming algorithm for span-based nested named-entity  recognition in O(n^2)",
    "abstract": "Span-based nested named-entity recognition (NER) has a cubic-time complexity\nusing a variant of the CYK algorithm. We show that by adding a supplementary\nstructural constraint on the search space, nested NER has a quadratic-time\ncomplexity, that is the same asymptotic complexity than the non-nested case.\nThe proposed algorithm covers a large part of three standard English benchmarks\nand delivers comparable experimental results.",
    "descriptor": "",
    "authors": [
      "Caio Corro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04738"
  },
  {
    "id": "arXiv:2210.04742",
    "title": "Over-the-Air Split Machine Learning in Wireless MIMO Networks",
    "abstract": "In split machine learning (ML), different partitions of a neural network (NN)\nare executed by different computing nodes, requiring a large amount of\ncommunication cost. To ease communication burden, over-the-air computation\n(OAC) can efficiently implement all or part of the computation at the same time\nof communication. Based on the proposed system, the system implementation over\nwireless network is introduced and we provide the problem formulation. In\nparticular, we show that the inter-layer connection in a NN of any size can be\nmathematically decomposed into a set of linear precoding and combining\ntransformations over MIMO channels. Therefore, the precoding matrix at the\ntransmitter and the combining matrix at the receiver of each MIMO link, as well\nas the channel matrix itself, can jointly serve as a fully connected layer of\nthe NN. The generalization of the proposed scheme to the conventional NNs is\nalso introduced. Finally, we extend the proposed scheme to the widely used\nconvolutional neural networks and demonstrate its effectiveness under both the\nstatic and quasi-static memory channel conditions with comprehensive\nsimulations. In such a split ML system, the precoding and combining matrices\nare regarded as trainable parameters, while MIMO channel matrix is regarded as\nunknown (implicit) parameters.",
    "descriptor": "\nComments: 15 pages, 13 figures, journal paper\n",
    "authors": [
      "Yuzhi Yang",
      "Zhaoyang Zhang",
      "Yuqing Tian",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Caijun Zhong",
      "Kai-Kit Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04742"
  },
  {
    "id": "arXiv:2210.04747",
    "title": "An NLoS-based Enhanced Sensing Method for MmWave Communication System",
    "abstract": "The millimeter-wave (mmWave)-based Wi-Fi sensing technology has recently\nattracted extensive attention since it provides a possibility to realize higher\nsensing accuracy. However, current works mainly concentrate on sensing\nscenarios where the line-of-sight (LoS) path exists, which significantly limits\ntheir applications. To address the problem, we propose an enhanced mmWave\nsensing algorithm in the 3D non-line-of-sight environment (mm3NLoS), aiming to\nsense the direction and distance of the target when the LoS path is weak or\nblocked. Specifically, we first adopt the directional beam to estimate the\nazimuth/elevation angle of arrival (AoA) and angle of departure (AoD) of the\nreflection path. Then, the distance of the related path is measured by the fine\ntiming measurement protocol. Finally, we transform the AoA and AoD of the\nmultiple non-line-of-sight (NLoS) paths into the direction vector and then\nobtain the information of targets based on the geometric relationship. The\nsimulation results demonstrate that mm3NLoS can achieve a centimeter-level\nerror with a 2m spacing. Compared to the prior work, it can significantly\nreduce the performance degradation under the NLoS condition.",
    "descriptor": "",
    "authors": [
      "Shiwen He",
      "Kangli Cai",
      "Shiyue Huang",
      "Zhenyu Anz",
      "Wei Huang",
      "Ning Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04747"
  },
  {
    "id": "arXiv:2210.04754",
    "title": "LSEH: Semantically Enhanced Hard Negatives for Cross-modal Information  Retrieval",
    "abstract": "Visual Semantic Embedding (VSE) aims to extract the semantics of images and\ntheir descriptions, and embed them into the same latent space for cross-modal\ninformation retrieval. Most existing VSE networks are trained by adopting a\nhard negatives loss function which learns an objective margin between the\nsimilarity of relevant and irrelevant image-description embedding pairs.\nHowever, the objective margin in the hard negatives loss function is set as a\nfixed hyperparameter that ignores the semantic differences of the irrelevant\nimage-description pairs. To address the challenge of measuring the optimal\nsimilarities between image-description pairs before obtaining the trained VSE\nnetworks, this paper presents a novel approach that comprises two main parts:\n(1) finds the underlying semantics of image descriptions; and (2) proposes a\nnovel semantically enhanced hard negatives loss function, where the learning\nobjective is dynamically determined based on the optimal similarity scores\nbetween irrelevant image-description pairs. Extensive experiments were carried\nout by integrating the proposed methods into five state-of-the-art VSE networks\nthat were applied to three benchmark datasets for cross-modal information\nretrieval tasks. The results revealed that the proposed methods achieved the\nbest performance and can also be adopted by existing and future VSE networks.",
    "descriptor": "",
    "authors": [
      "Yan Gong",
      "Georgina Cosma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.04754"
  },
  {
    "id": "arXiv:2210.04756",
    "title": "Masked Metaphor Modeling To Transfer Literal to Metaphorical Text",
    "abstract": "This study presents a new approach to metaphorical paraphrase generation by\nmasking literal tokens of literal sentences and unmasking them with\nmetaphorical language models. Unlike similar studies, the proposed algorithm is\nnot limited to the replacement of verbs, but also of nouns and adjectives.\nDespite the fact that the transfer rate for the former is the highest (56%),\nthe transfer of the latter is feasible (24% and 31%). Human evaluation showed\nthat our system-generated metaphors are considered more creative and\nmetaphorical than human-generated ones. Additionally, when using our\ntransferred metaphors for data augmentation we show that state of the art\nmetaphorical sentence classification improves by 3% in F1.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Giorgio Ottolina",
      "John Pavlopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04756"
  },
  {
    "id": "arXiv:2210.04763",
    "title": "On the Forward Invariance of Neural ODEs",
    "abstract": "To ensure robust and trustworthy decision-making, it is highly desirable to\nenforce constraints over a neural network's parameters and its inputs\nautomatically by back-propagating output specifications. This way, we can\nguarantee that the network makes reliable decisions under perturbations. Here,\nwe propose a new method for achieving a class of specification guarantees for\nneural Ordinary Differentiable Equations (ODEs) by using invariance set\npropagation. An invariance of a neural ODE is defined as an output\nspecification, such as to satisfy mathematical formulae, physical laws, and\nsystem safety. We use control barrier functions to specify the invariance of a\nneural ODE on the output layer and propagate it back to the input layer.\nThrough the invariance backpropagation, we map output specifications onto\nconstraints on the neural ODE parameters or its input. The satisfaction of the\ncorresponding constraints implies the satisfaction of output specifications.\nThis allows us to achieve output specification guarantees by changing the input\nor parameters while maximally preserving the model performance. We demonstrate\nthe invariance propagation on a comprehensive series of representation learning\ntasks, including spiral curve regression, autoregressive modeling of joint\nphysical dynamics, convexity portrait of a function, and safe neural control of\ncollision avoidance for autonomous vehicles.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Wei Xiao",
      "Tsun-Hsuan Wang",
      "Ramin Hasani",
      "Mathias Lechner",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04763"
  },
  {
    "id": "arXiv:2210.04764",
    "title": "End-to-end verifiable voting for developing countries -- what's hard in  Lausanne is harder still in Lahore",
    "abstract": "In recent years end-to-end verifiable voting (E2EVV) has emerged as a\npromising new paradigm to conduct evidence-based elections. However, E2EVV\nsystems thus far have primarily been designed for the developed world and the\nfundamental assumptions underlying the design of these systems do not readily\ntranslate to the developing world, and may even act as potential barriers to\nadoption of these systems. This is unfortunate because developing countries\naccount for 80\\% of the global population, and given their economic and\nsocio-political dilemmas and their track record of contentious elections, these\ncountries arguably stand to benefit most from this exciting new paradigm. In\nthis paper, we highlight various limitations and challenges in adapting E2EVV\nsystems to these environments, broadly classed across social, political,\ntechnical, operational, and human dimensions. We articulate corresponding\nresearch questions and identify significant literature gaps in these\ncategories. We also suggest relevant strategies to aid researchers,\npractitioners, and policymakers in visualizing and exploring solutions that\nalign with the context and unique ground realities in these environments. Our\ngoal is to outline a broader research agenda for the community to successfully\nadapt E2EVV voting systems to developing countries.",
    "descriptor": "",
    "authors": [
      "Hina Binte Haq",
      "Syed Taha Ali",
      "Ronan McDermott"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.04764"
  },
  {
    "id": "arXiv:2210.04766",
    "title": "Hierarchical Learning in Euclidean Neural Networks",
    "abstract": "Equivariant machine learning methods have shown wide success at 3D learning\napplications in recent years. These models explicitly build in the reflection,\ntranslation and rotation symmetries of Euclidean space and have facilitated\nlarge advances in accuracy and data efficiency for a range of applications in\nthe physical sciences. An outstanding question for equivariant models is why\nthey achieve such larger-than-expected advances in these applications. To probe\nthis question, we examine the role of higher order (non-scalar) features in\nEuclidean Neural Networks (\\texttt{e3nn}). We focus on the previously studied\napplication of \\texttt{e3nn} to the problem of electron density prediction,\nwhich allows for a variety of non-scalar outputs, and examine whether the\nnature of the output (scalar $l=0$, vector $l=1$, or higher order $l>1$) is\nrelevant to the effectiveness of non-scalar hidden features in the network.\nFurther, we examine the behavior of non-scalar features throughout training,\nfinding a natural hierarchy of features by $l$, reminiscent of a multipole\nexpansion. We aim for our work to ultimately inform design principles and\nchoices of domain applications for {\\tt e3nn} networks.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Joshua A. Rackers",
      "Pranav Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.04766"
  },
  {
    "id": "arXiv:2210.04772",
    "title": "An Ontology for Defect Detection in Metal Additive Manufacturing",
    "abstract": "A key challenge for Industry 4.0 applications is to develop control systems\nfor automated manufacturing services that are capable of addressing both data\nintegration and semantic interoperability issues, as well as monitoring and\ndecision making tasks. To address such an issue in advanced manufacturing\nsystems, principled knowledge representation approaches based on formal\nontologies have been proposed as a foundation to information management and\nmaintenance in presence of heterogeneous data sources. In addition, ontologies\nprovide reasoning and querying capabilities to aid domain experts and end users\nin the context of constraint validation and decision making. Finally,\nontology-based approaches to advanced manufacturing services can support the\nexplainability and interpretability of the behaviour of monitoring, control,\nand simulation systems that are based on black-box machine learning algorithms.\nIn this work, we provide a novel ontology for the classification of\nprocess-induced defects known from the metal additive manufacturing literature.\nTogether with a formal representation of the characterising features and\nsources of defects, we integrate our knowledge base with state-of-the-art\nontologies in the field. Our knowledge base aims at enhancing the modelling\ncapabilities of additive manufacturing ontologies by adding further defect\nanalysis terminology and diagnostic inference features.",
    "descriptor": "",
    "authors": [
      "Massimo Carraturo",
      "Andrea Mazzullo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.04772"
  },
  {
    "id": "arXiv:2210.04776",
    "title": "Contrastive Learning Approach for Semi-Supervised Seismic Facies  Identification Using High-Confidence Representations",
    "abstract": "The labeling of seismic facies relies heavily on the experience of seismic\ninterpreters, and the distribution of seismic facies in adjacent locations is\nvery similar, which means that much of the labeling is costly repetitive work.\nHowever, we found that training the model with only a few evenly sampled\nlabeled slices still suffers from severe classification confusion, that is,\nmisidentifying one class of seismic facies as another. To address this issue,\nwe propose a semi-supervised seismic facies identification method using\nfeatures from unlabeled data for contrastive learning. We sample features in\nregions with high classification confidence, and use an pixel-level instance\ndiscrimination task to narrow the intra-class distance and increase the\ninter-class distance. Instance discrimination encourages the latent space to\nproduce more distinguishable decision boundaries and reduces the bias in the\nfeatures of the same class.Our method only needs to extend one branch to\ncompute the contrastive loss without extensive changes to the network\nstructure. We have conducted experiments on two public seismic surveys, SEAM AI\nand Netherlands F3, and the proposed model achieves an IOU score of more than\n90 using only 1% of the annotations in the F3 survey. We have made our codes\nand pre-trained models publicly available: www.github.com/upcliuwenlong/CONSS",
    "descriptor": "",
    "authors": [
      "Kewen Li",
      "Wenlong Liu",
      "Yimin Dou",
      "Zhifeng Xu",
      "Hongjie Duan",
      "Ruilin Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.04776"
  },
  {
    "id": "arXiv:2210.04777",
    "title": "mPSAuth: Privacy-Preserving and Scalable Authentication for Mobile Web  Applications",
    "abstract": "As nowadays most web application requests originate from mobile devices,\nauthentication of mobile users is essential in terms of security\nconsiderations. To this end, recent approaches rely on machine learning\ntechniques to analyze various aspects of user behavior as a basis for\nauthentication decisions. These approaches face two challenges: first,\nexamining behavioral data raises significant privacy concerns, and second,\napproaches must scale to support a large number of users. Existing approaches\ndo not address these challenges sufficiently. We propose mPSAuth, an approach\nfor continuously tracking various data sources reflecting user behavior (e.g.,\ntouchscreen interactions, sensor data) and estimating the likelihood of the\ncurrent user being legitimate based on machine learning techniques. With\nmPSAuth, both the authentication protocol and the machine learning models\noperate on homomorphically encrypted data to ensure the users' privacy.\nFurthermore, the number of machine learning models used by mPSAuth is\nindependent of the number of users, thus providing adequate scalability. In an\nextensive evaluation based on real-world data from a mobile application, we\nillustrate that mPSAuth can provide high accuracy with low encryption and\ncommunication overhead, while the effort for the inference is increased to a\ntolerable extent.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "David Monschein",
      "Oliver P. Waldhorst"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04777"
  },
  {
    "id": "arXiv:2210.04782",
    "title": "Robustification of Multilingual Language Models to Real-world Noise with  Robust Contrastive Pretraining",
    "abstract": "Advances in neural modeling have achieved state-of-the-art (SOTA) results on\npublic natural language processing (NLP) benchmarks, at times surpassing human\nperformance. However, there is a gap between public benchmarks and real-world\napplications where noise such as typos or grammatical mistakes is abundant,\nresulting in degraded performance. Unfortunately, works that assess the\nrobustness of neural models on noisy data and suggest improvements are limited\nto the English language. Upon analyzing noise in different languages, we\nobserve that noise types vary across languages and thus require their own\ninvestigation. Thus, to benchmark the performance of pretrained multilingual\nmodels, we construct noisy datasets covering five languages and four NLP tasks.\nWe see a gap in performance between clean and noisy data. After investigating\nways to boost the zero-shot cross-lingual robustness of multilingual pretrained\nmodels, we propose Robust Contrastive Pretraining (RCP). RCP combines data\naugmentation with a contrastive loss term at the pretraining stage and achieves\nlarge improvements on noisy (& original test data) across two sentence-level\nclassification (+3.2%) and two sequence-labeling (+10 F1-score) multilingual\ntasks.",
    "descriptor": "",
    "authors": [
      "Asa Cooper Stickland",
      "Sailik Sengupta",
      "Jason Krone",
      "Saab Mansour",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04782"
  },
  {
    "id": "arXiv:2210.04783",
    "title": "On the Importance of Calibration in Semi-supervised Learning",
    "abstract": "State-of-the-art (SOTA) semi-supervised learning (SSL) methods have been\nhighly successful in leveraging a mix of labeled and unlabeled data by\ncombining techniques of consistency regularization and pseudo-labeling. During\npseudo-labeling, the model's predictions on unlabeled data are used for\ntraining and thus, model calibration is important in mitigating confirmation\nbias. Yet, many SOTA methods are optimized for model performance, with little\nfocus directed to improve model calibration. In this work, we empirically\ndemonstrate that model calibration is strongly correlated with model\nperformance and propose to improve calibration via approximate Bayesian\ntechniques. We introduce a family of new SSL models that optimizes for\ncalibration and demonstrate their effectiveness across standard vision\nbenchmarks of CIFAR-10, CIFAR-100 and ImageNet, giving up to 15.9% improvement\nin test accuracy. Furthermore, we also demonstrate their effectiveness in\nadditional realistic and challenging problems, such as class-imbalanced\ndatasets and in photonics science.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Charlotte Loh",
      "Rumen Dangovski",
      "Shivchander Sudalairaj",
      "Seungwook Han",
      "Ligong Han",
      "Leonid Karlinsky",
      "Marin Soljacic",
      "Akash Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.04783"
  },
  {
    "id": "arXiv:2210.04787",
    "title": "LMQFormer: A Laplace-Prior-Guided Mask Query Transformer for Lightweight  Snow Removal",
    "abstract": "Snow removal aims to locate snow areas and recover clean images without\nrepairing traces. Unlike the regularity and semitransparency of rain, snow with\nvarious patterns and degradations seriously occludes the background. As a\nresult, the state-of-the-art snow removal methods usually retains a large\nparameter size. In this paper, we propose a lightweight but high-efficient snow\nremoval network called Laplace Mask Query Transformer (LMQFormer). Firstly, we\npresent a Laplace-VQVAE to generate a coarse mask as prior knowledge of snow.\nInstead of using the mask in dataset, we aim at reducing both the information\nentropy of snow and the computational cost of recovery. Secondly, we design a\nMask Query Transformer (MQFormer) to remove snow with the coarse mask, where we\nuse two parallel encoders and a hybrid decoder to learn extensive snow features\nunder lightweight requirements. Thirdly, we develop a Duplicated Mask Query\nAttention (DMQA) that converts the coarse mask into a specific number of\nqueries, which constraint the attention areas of MQFormer with reduced\nparameters. Experimental results in popular datasets have demonstrated the\nefficiency of our proposed model, which achieves the state-of-the-art snow\nremoval quality with significantly reduced parameters and the lowest running\ntime.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Junhong Lin",
      "Nanfeng Jiang",
      "Zhentao Zhang",
      "Weiling Chen",
      "Tiesong Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04787"
  },
  {
    "id": "arXiv:2210.04791",
    "title": "Tango or Square Dance? How Tightly Should we Integrate Network  Functionality in Browsers?",
    "abstract": "The question at which layer network functionality is presented or abstracted\nremains a research challenge. Traditionally, network functionality was either\nplaced into the core network, middleboxes, or into the operating system -- but\nrecent developments have expanded the design space to directly introduce\nfunctionality into the application (and in particular into the browser) as a\nway to expose it to the user.\nGiven the context of emerging path-aware networking technology, an\ninteresting question arises: which layer should handle the new features? We\nargue that the browser is becoming a powerful platform for network innovation,\nwhere even user-driven properties can be implemented in an OS-agnostic fashion.\nWe demonstrate the feasibility of geo-fenced browsing using a prototype browser\nextension, realized by the SCION path-aware networking architecture, without\nintroducing any significant performance overheads.",
    "descriptor": "\nComments: 1 table, 6 figures\n",
    "authors": [
      "Alex Davidson",
      "Matthias Frei",
      "Marten Gartner",
      "Hamed Haddadi",
      "Jordi Subir\u00e0 Nieto",
      "Adrian Perrig",
      "Philipp Winter",
      "Fran\u00e7ois Wirz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.04791"
  },
  {
    "id": "arXiv:2210.04794",
    "title": "Towards a case-based learning approach to support software architecture  education",
    "abstract": "Software architecture education remains challenging for instructors,\nstudents, and software industry professionals. Several initiatives have been\nproposed to mitigate the inherent challenges, including games, supporting\ntools, collaborative courses, and hands-on projects. Case-based learning has\nbeen introduced in software architecture, and its benefits are recognized.\nHowever, choosing the right cases that cover the stated learning objectives and\ndeveloping learning activities to achieve high-order learning are also\nchallenging. The main goal of this paper is to present a case-based learning\napproach that guides the development of learning objectives, the finding and\nselection of real-world software architecture cases, and the design of\ninstructional activities. We applied our approach in software architecture\nrelated courses during the past few years. The results show that it can\nleverage the ways to adequately explore cases for educational purposes while\nalso motivating instructors and students to the software architecture\neducation.",
    "descriptor": "",
    "authors": [
      "Brauner R. N. Oliveira",
      "Elisa Y. Nakagawa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.04794"
  },
  {
    "id": "arXiv:2210.04795",
    "title": "TensorFlow as a DSL for stencil-based computation on the Cerebras Wafer  Scale Engine",
    "abstract": "The Cerebras Wafer Scale Engine (WSE) is an accelerator that combines\nhundreds of thousands of AI-cores onto a single chip. Whilst this technology\nhas been designed for machine learning workloads, the significant amount of\navailable raw compute means that it is also a very interesting potential target\nfor accelerating traditional HPC computational codes. Many of these algorithms\nare stencil-based, where update operations involve contributions from\nneighbouring elements, and in this paper we explore the suitability of this\ntechnology for such codes from the perspective of an early adopter of the\ntechnology, compared to CPUs and GPUs. Using TensorFlow as the interface, we\nexplore the performance and demonstrate that, whilst there is still work to be\ndone around exposing the programming interface to users, performance of the WSE\nis impressive as it out performs four V100 GPUs by two and a half times and two\nIntel Xeon Platinum CPUs by around 114 times in our experiments. There is\nsignificant potential therefore for this technology to play an important role\nin accelerating HPC codes on future exascale supercomputers.",
    "descriptor": "\nComments: This preprint has not undergone any post-submission improvements or corrections. Preprint of paper submitted to Euro-Par DSL-HPC workshop\n",
    "authors": [
      "Nick Brown",
      "Brandon Echols",
      "Justs Zarins",
      "Tobias Grosser"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.04795"
  },
  {
    "id": "arXiv:2210.04801",
    "title": "4D Unsupervised Object Discovery",
    "abstract": "Object discovery is a core task in computer vision. While fast progresses\nhave been made in supervised object detection, its unsupervised counterpart\nremains largely unexplored. With the growth of data volume, the expensive cost\nof annotations is the major limitation hindering further study. Therefore,\ndiscovering objects without annotations has great significance. However, this\ntask seems impractical on still-image or point cloud alone due to the lack of\ndiscriminative information. Previous studies underlook the crucial temporal\ninformation and constraints naturally behind multi-modal inputs. In this paper,\nwe propose 4D unsupervised object discovery, jointly discovering objects from\n4D data -- 3D point clouds and 2D RGB images with temporal information. We\npresent the first practical approach for this task by proposing a ClusterNet on\n3D point clouds, which is jointly iteratively optimized with a 2D localization\nnetwork. Extensive experiments on the large-scale Waymo Open Dataset suggest\nthat the localization network and ClusterNet achieve competitive performance on\nboth class-agnostic 2D object detection and 3D instance segmentation, bridging\nthe gap between unsupervised methods and full supervised ones. Codes and models\nwill be made available at https://github.com/Robertwyq/LSMOL.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. 17 pages, 6 figures\n",
    "authors": [
      "Yuqi Wang",
      "Yuntao Chen",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04801"
  },
  {
    "id": "arXiv:2210.04802",
    "title": "SimSCOOD: Systematic Analysis of Out-of-Distribution Behavior of Source  Code Models",
    "abstract": "While large code datasets have become available in recent years, acquiring\nrepresentative training data with full coverage of general code distribution\nremains challenging due to the compositional nature of code and the complexity\nof software. This leads to the out-of-distribution (OOD) issues with unexpected\nmodel inference behaviors that have not been systematically studied yet. We\ncontribute the first systematic approach that simulates various OOD scenarios\nalong different dimensions of data properties and investigates the model\nbehaviors in such scenarios. Our extensive studies on six state-of-the-art\nmodels for three code generation tasks expose several failure modes caused by\nthe out-of-distribution issues. It thereby provides insights and sheds light\nfor future research in terms of generalization, robustness, and inductive\nbiases of source code models.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Hossein Hajipour",
      "Ning Yu",
      "Cristian-Alexandru Staicu",
      "Mario Fritz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.04802"
  },
  {
    "id": "arXiv:2210.04803",
    "title": "Using Whole Slide Image Representations from Self-Supervised Contrastive  Learning for Melanoma Concordance Regression",
    "abstract": "Although melanoma occurs more rarely than several other skin cancers,\npatients' long term survival rate is extremely low if the diagnosis is missed.\nDiagnosis is complicated by a high discordance rate among pathologists when\ndistinguishing between melanoma and benign melanocytic lesions. A tool that\nprovides potential concordance information to healthcare providers could help\ninform diagnostic, prognostic, and therapeutic decision-making for challenging\nmelanoma cases. We present a melanoma concordance regression deep learning\nmodel capable of predicting the concordance rate of invasive melanoma or\nmelanoma in-situ from digitized Whole Slide Images (WSIs). The salient features\ncorresponding to melanoma concordance were learned in a self-supervised manner\nwith the contrastive learning method, SimCLR. We trained a SimCLR feature\nextractor with 83,356 WSI tiles randomly sampled from 10,895 specimens\noriginating from four distinct pathology labs. We trained a separate melanoma\nconcordance regression model on 990 specimens with available concordance ground\ntruth annotations from three pathology labs and tested the model on 211\nspecimens. We achieved a Root Mean Squared Error (RMSE) of 0.28 +/- 0.01 on the\ntest set. We also investigated the performance of using the predicted\nconcordance rate as a malignancy classifier, and achieved a precision and\nrecall of 0.85 +/- 0.05 and 0.61 +/- 0.06, respectively, on the test set. These\nresults are an important first step for building an artificial intelligence\n(AI) system capable of predicting the results of consulting a panel of experts\nand delivering a score based on the degree to which the experts would agree on\na particular diagnosis. Such a system could be used to suggest additional\ntesting or other action such as ordering additional stains or genetic tests.",
    "descriptor": "\nComments: Accepted at ECCV 2022 AIMIA Workshop. arXiv admin note: text overlap with arXiv:2109.07554\n",
    "authors": [
      "Sean Grullon",
      "Vaughn Spurrier",
      "Jiayi Zhao",
      "Corey Chivers",
      "Yang Jiang",
      "Kiran Motaparthi",
      "Michael Bonham",
      "Julianna Ianni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.04803"
  },
  {
    "id": "arXiv:2210.04806",
    "title": "Generating image captions with external encyclopedic knowledge",
    "abstract": "Accurately reporting what objects are depicted in an image is largely a\nsolved problem in automatic caption generation. The next big challenge on the\nway to truly humanlike captioning is being able to incorporate the context of\nthe image and related real world knowledge. We tackle this challenge by\ncreating an end-to-end caption generation system that makes extensive use of\nimage-specific encyclopedic data. Our approach includes a novel way of using\nimage location to identify relevant open-domain facts in an external knowledge\nbase, with their subsequent integration into the captioning pipeline at both\nthe encoding and decoding stages. Our system is trained and tested on a new\ndataset with naturally produced knowledge-rich captions, and achieves\nsignificant improvements over multiple baselines. We empirically demonstrate\nthat our approach is effective for generating contextualized captions with\nencyclopedic knowledge that is both factually accurate and relevant to the\nimage.",
    "descriptor": "",
    "authors": [
      "Sofia Nikiforova",
      "Tejaswini Deoskar",
      "Denis Paperno",
      "Yoad Winter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04806"
  },
  {
    "id": "arXiv:2210.04807",
    "title": "Efficient NTK using Dimensionality Reduction",
    "abstract": "Recently, neural tangent kernel (NTK) has been used to explain the dynamics\nof learning parameters of neural networks, at the large width limit.\nQuantitative analyses of NTK give rise to network widths that are often\nimpractical and incur high costs in time and energy in both training and\ndeployment. Using a matrix factorization technique, we show how to obtain\nsimilar guarantees to those obtained by a prior analysis while reducing\ntraining and inference resource costs. The importance of our result further\nincreases when the input points' data dimension is in the same order as the\nnumber of input points. More generally, our work suggests how to analyze large\nwidth networks in which dense linear layers are replaced with a low complexity\nfactorization, thus reducing the heavy dependence on the large width.",
    "descriptor": "",
    "authors": [
      "Nir Ailon",
      "Supratim Shit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04807"
  },
  {
    "id": "arXiv:2210.04813",
    "title": "Stochastic Robustness Interval for Motion Planning with Signal Temporal  Logic",
    "abstract": "In this work, we present a novel robustness measure for continuous-time\nstochastic trajectories with respect to Signal Temporal Logic (STL)\nspecifications. We show the soundness of the measure and develop a monitor for\nreasoning about partial trajectories. Using this monitor, we introduce an STL\nsampling-based motion planning algorithm for robots under uncertainty. Given a\nminimum robustness requirement, this algorithm finds satisfying motion plans;\nalternatively, the algorithm also optimizes for the measure. We prove\nprobabilistic completeness and asymptotic optimality, and demonstrate the\neffectiveness of our approach on several case studies.",
    "descriptor": "",
    "authors": [
      "Roland B. Ilyes",
      "Qi Heng Ho",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04813"
  },
  {
    "id": "arXiv:2210.04816",
    "title": "Ensemble Learning using Transformers and Convolutional Networks for  Masked Face Recognition",
    "abstract": "Wearing a face mask is one of the adjustments we had to follow to reduce the\nspread of the coronavirus. Having our faces covered by masks constantly has\ndriven the need to understand and investigate how this behavior affects the\nrecognition capability of face recognition systems. Current face recognition\nsystems have extremely high accuracy when dealing with unconstrained general\nface recognition cases but do not generalize well with occluded masked faces.\nIn this work, we propose a system for masked face recognition. The proposed\nsystem comprises two Convolutional Neural Network (CNN) models and two\nTransformer models. The CNN models have been fine-tuned on FaceNet pre-trained\nmodel. We ensemble the predictions of the four models using the majority voting\ntechnique to identify the person with the mask. The proposed system has been\nevaluated on a synthetically masked LFW dataset created in this work. The best\naccuracy is obtained using the ensembled models with an accuracy of 92%. This\nrecognition rate outperformed the accuracy of other models and it shows the\ncorrectness and robustness of the proposed model for recognizing masked faces.\nThe code and data are available at https://github.com/Hamzah-Luqman/MFR",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Mohammed R. Al-Sinan",
      "Aseel F. Haneef",
      "Hamzah Luqman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04816"
  },
  {
    "id": "arXiv:2210.04817",
    "title": "Do you pay for Privacy in Online learning?",
    "abstract": "Online learning, in the mistake bound model, is one of the most fundamental\nconcepts in learning theory. Differential privacy, instead, is the most widely\nused statistical concept of privacy in the machine learning community. It is\nthus clear that defining learning problems that are online differentially\nprivately learnable is of great interest. In this paper, we pose the question\non if the two problems are equivalent from a learning perspective, i.e., is\nprivacy for free in the online learning framework?",
    "descriptor": "\nComments: This is an updated version with i) clearer problem statements especially in proposed Theorem 1 and ii) clearer discussion of existing work especially Golowich and Livni (2021). Conference on Learning Theory. PMLR, 2022\n",
    "authors": [
      "Amartya Sanyal",
      "Giorgia Ramponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04817"
  },
  {
    "id": "arXiv:2210.04819",
    "title": "Efficient Learning of Locomotion Skills through the Discovery of Diverse  Environmental Trajectory Generator Priors",
    "abstract": "Data-driven learning based methods have recently been particularly successful\nat learning robust locomotion controllers for a variety of unstructured\nterrains. Prior work has shown that incorporating good locomotion priors in the\nform of trajectory generators (TGs) is effective at efficiently learning\ncomplex locomotion skills. However, defining a good, single TG as\ntasks/environments become increasingly more complex remains a challenging\nproblem as it requires extensive tuning and risks reducing the effectiveness of\nthe prior. In this paper, we present Evolved Environmental Trajectory\nGenerators (EETG), a method that learns a diverse set of specialised locomotion\npriors using Quality-Diversity algorithms while maintaining a single policy\nwithin the Policies Modulating TG (PMTG) architecture. The results demonstrate\nthat EETG enables a quadruped robot to successfully traverse a wide range of\nenvironments, such as slopes, stairs, rough terrain, and balance beams. Our\nexperiments show that learning a diverse set of specialized TG priors is\nsignificantly (5 times) more efficient than using a single, fixed prior when\ndealing with a wide range of environments.",
    "descriptor": "",
    "authors": [
      "Shikha Surana",
      "Bryan Lim",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04819"
  },
  {
    "id": "arXiv:2210.04820",
    "title": "Long N-step Surrogate Stage Reward to Reduce Variances of Deep  Reinforcement Learning in Complex Problems",
    "abstract": "High variances in reinforcement learning have shown impeding successful\nconvergence and hurting task performance. As reward signal plays an important\nrole in learning behavior, multi-step methods have been considered to mitigate\nthe problem, and are believed to be more effective than single step methods.\nHowever, there is a lack of comprehensive and systematic study on this\nimportant aspect to demonstrate the effectiveness of multi-step methods in\nsolving highly complex continuous control problems. In this study, we introduce\na new long $N$-step surrogate stage (LNSS) reward approach to effectively\naccount for complex environment dynamics while previous methods are usually\nfeasible for limited number of steps. The LNSS method is simple, low\ncomputational cost, and applicable to value based or policy gradient\nreinforcement learning. We systematically evaluate LNSS in OpenAI Gym and\nDeepMind Control Suite to address some complex benchmark environments that have\nbeen challenging to obtain good results by DRL in general. We demonstrate\nperformance improvement in terms of total reward, convergence speed, and\ncoefficient of variation (CV) by LNSS. We also provide analytical insights on\nhow LNSS exponentially reduces the upper bound on the variances of Q value from\na respective single step method",
    "descriptor": "",
    "authors": [
      "Junmin Zhong",
      "Ruofan Wu",
      "Jennie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04820"
  },
  {
    "id": "arXiv:2210.04826",
    "title": "Data types as a more ergonomic frontend for Grammar-Guided Genetic  Programming",
    "abstract": "Genetic Programming (GP) is an heuristic method that can be applied to many\nMachine Learning, Optimization and Engineering problems. In particular, it has\nbeen widely used in Software Engineering for Test-case generation, Program\nSynthesis and Improvement of Software (GI).\nGrammar-Guided Genetic Programming (GGGP) approaches allow the user to refine\nthe domain of valid program solutions. Backus Normal Form is the most popular\ninterface for describing Context-Free Grammars (CFG) for GGGP. BNF and its\nderivatives have the disadvantage of interleaving the grammar language and the\ntarget language of the program.\nWe propose to embed the grammar as an internal Domain-Specific Language in\nthe host language of the framework. This approach has the same expressive power\nas BNF and EBNF while using the host language type-system to take advantage of\nall the existing tooling: linters, formatters, type-checkers, autocomplete, and\nlegacy code support. These tools have a practical utility in designing software\nin general, and GP systems in particular.\nWe also present Meta-Handlers, user-defined overrides of the tree-generation\nsystem. This technique extends our object-oriented encoding with more\npracticability and expressive power than existing CFG approaches, achieving the\nsame expressive power of Attribute Grammars, but without the grammar vs target\nlanguage duality.\nFurthermore, we evidence that this approach is feasible, showing an example\nPython implementation as proof. We also compare our approach against textual\nBNF-representations w.r.t. expressive power and ergonomics. These advantages do\nnot come at the cost of performance, as shown by our empirical evaluation on 5\nbenchmarks of our example implementation against PonyGE2. We conclude that our\napproach has better ergonomics with the same expressive power and performance\nof textual BNF-based grammar encodings.",
    "descriptor": "",
    "authors": [
      "Guilherme Espada",
      "Leon Ingelse",
      "Paulo Canelas",
      "Pedro Barbosa",
      "Alcides Fonseca"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.04826"
  },
  {
    "id": "arXiv:2210.04828",
    "title": "Assessing Neural Referential Form Selectors on a Realistic Multilingual  Dataset",
    "abstract": "Previous work on Neural Referring Expression Generation (REG) all uses\nWebNLG, an English dataset that has been shown to reflect a very limited range\nof referring expression (RE) use. To tackle this issue, we build a dataset\nbased on the OntoNotes corpus that contains a broader range of RE use in both\nEnglish and Chinese (a language that uses zero pronouns). We build neural\nReferential Form Selection (RFS) models accordingly, assess them on the dataset\nand conduct probing experiments. The experiments suggest that, compared to\nWebNLG, OntoNotes is better for assessing REG/RFS models. We compare English\nand Chinese RFS and confirm that, in line with linguistic theories, Chinese RFS\ndepends more on discourse context than English.",
    "descriptor": "\nComments: Eval4NLP workshop\n",
    "authors": [
      "Guanyi Chen",
      "Fahime Same",
      "Kees van Deemter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04828"
  },
  {
    "id": "arXiv:2210.04829",
    "title": "Hierarchical3D Adapters for Long Video-to-text Summarization",
    "abstract": "In this paper, we focus on video-to-text summarization and investigate how to\nbest utilize multimodal information for summarizing long inputs (e.g., an\nhour-long TV show) into long outputs (e.g., a multi-sentence summary). We\nextend SummScreen (Chen et al., 2021), a dialogue summarization dataset\nconsisting of transcripts of TV episodes with reference summaries, and create a\nmultimodal variant by collecting corresponding full-length videos. We\nincorporate multimodal information into a pre-trained textual summarizer\nefficiently using adapter modules augmented with a hierarchical structure while\ntuning only 3.8\\% of model parameters. Our experiments demonstrate that\nmultimodal information offers superior performance over more memory-heavy and\nfully fine-tuned textual summarization methods.",
    "descriptor": "",
    "authors": [
      "Pinelopi Papalampidi",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04829"
  },
  {
    "id": "arXiv:2210.04831",
    "title": "Visual Prompt Tuning for Test-time Domain Adaptation",
    "abstract": "Models should have the ability to adapt to unseen data during test-time to\navoid performance drop caused by inevitable distribution shifts in real-world\ndeployment scenarios. In this work, we tackle the practical yet challenging\ntest-time adaptation (TTA) problem, where a model adapts to the target domain\nwithout accessing the source data. We propose a simple recipe called\ndata-efficient prompt tuning (DePT) with two key ingredients. First, DePT plugs\nvisual prompts into the vision Transformer and only tunes these\nsource-initialized prompts during adaptation. We find such parameter-efficient\nfinetuning can efficiently adapt the model representation to the target domain\nwithout overfitting to the noise in the learning objective. Second, DePT\nbootstraps the source representation to the target domain by memory bank-based\nonline pseudo labeling. A hierarchical self-supervised regularization specially\ndesigned for prompts is jointly optimized to alleviate error accumulation\nduring self-training. With much fewer tunable parameters, DePT demonstrates not\nonly state-of-the-art performance on major adaptation benchmarks, but also\nsuperior data efficiency, i.e., adaptation with only 1\\% or 10\\% data without\nmuch performance degradation compared to 100\\% data. In addition, DePT is also\nversatile to be extended to online or multi-source TTA settings.",
    "descriptor": "",
    "authors": [
      "Yunhe Gao",
      "Xingjian Shi",
      "Yi Zhu",
      "Hao Wang",
      "Zhiqiang Tang",
      "Xiong Zhou",
      "Mu Li",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04831"
  },
  {
    "id": "arXiv:2210.04834",
    "title": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU  Tasks",
    "abstract": "Teacher-student knowledge distillation is a popular technique for compressing\ntoday's prevailing large language models into manageable sizes that fit\nlow-latency downstream applications. Both the teacher and the choice of\ntransfer set used for distillation are crucial ingredients in creating a high\nquality student. Yet, the generic corpora used to pretrain the teacher and the\ncorpora associated with the downstream target domain are often significantly\ndifferent, which raises a natural question: should the student be distilled\nover the generic corpora, so as to learn from high-quality teacher predictions,\nor over the downstream task corpora to align with finetuning? Our study\ninvestigates this trade-off using Domain Classification (DC) and Intent\nClassification/Named Entity Recognition (ICNER) as downstream tasks. We distill\nseveral multilingual students from a larger multilingual LM with varying\nproportions of generic and task-specific datasets, and report their performance\nafter finetuning on DC and ICNER. We observe significant improvements across\ntasks and test sets when only task-specific corpora is used. We also report on\nhow the impact of adding task-specific data to the transfer set correlates with\nthe similarity between generic and task-specific data. Our results clearly\nindicate that, while distillation from a generic LM benefits downstream tasks,\nstudents learn better using target domain data even if it comes at the price of\nnoisier teacher predictions. In other words, target domain data still trumps\nteacher knowledge.",
    "descriptor": "\nComments: 7 pages, 2 figures, 2 tables (+ 4 tables in Appendix), Accepted to EMNLP 2022 (industry track)\n",
    "authors": [
      "Charith Peris",
      "Lizhen Tan",
      "Thomas Gueudre",
      "Turan Gojayev",
      "Vivi Wei",
      "Gokmen Oz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04834"
  },
  {
    "id": "arXiv:2210.04839",
    "title": "Benchmarking Reinforcement Learning Techniques for Autonomous Navigation",
    "abstract": "Deep reinforcement learning (RL) has brought many successes for autonomous\nrobot navigation. However, there still exists important limitations that\nprevent real-world use of RL-based navigation systems. For example, most\nlearning approaches lack safety guarantees; and learned navigation systems may\nnot generalize well to unseen environments. Despite a variety of recent\nlearning techniques to tackle these challenges in general, a lack of an\nopen-source benchmark and reproducible learning methods specifically for\nautonomous navigation makes it difficult for roboticists to choose what\nlearning methods to use for their mobile robots and for learning researchers to\nidentify current shortcomings of general learning methods for autonomous\nnavigation. In this paper, we identify four major desiderata of applying deep\nRL approaches for autonomous navigation: (D1) reasoning under uncertainty, (D2)\nsafety, (D3) learning from limited trial-and-error data, and (D4)\ngeneralization to diverse and novel environments. Then, we explore four major\nclasses of learning techniques with the purpose of achieving one or more of the\nfour desiderata: memory-based neural network architectures (D1), safe RL (D2),\nmodel-based RL (D2, D3), and domain randomization (D4). By deploying these\nlearning techniques in a new open-source large-scale navigation benchmark and\nreal-world environments, we perform a comprehensive study aimed at establishing\nto what extent can these techniques achieve these desiderata for RL-based\nnavigation systems.",
    "descriptor": "",
    "authors": [
      "Zifan Xu",
      "Bo Liu",
      "Xuesu Xiao",
      "Anirudh Nair",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04839"
  },
  {
    "id": "arXiv:2210.04843",
    "title": "Multi-Modal Fusion by Meta-Initialization",
    "abstract": "When experience is scarce, models may have insufficient information to adapt\nto a new task. In this case, auxiliary information - such as a textual\ndescription of the task - can enable improved task inference and adaptation. In\nthis work, we propose an extension to the Model-Agnostic Meta-Learning\nalgorithm (MAML), which allows the model to adapt using auxiliary information\nas well as task experience. Our method, Fusion by Meta-Initialization (FuMI),\nconditions the model initialization on auxiliary information using a\nhypernetwork, rather than learning a single, task-agnostic initialization.\nFurthermore, motivated by the shortcomings of existing multi-modal few-shot\nlearning benchmarks, we constructed iNat-Anim - a large-scale image\nclassification dataset with succinct and visually pertinent textual class\ndescriptions. On iNat-Anim, FuMI significantly outperforms uni-modal baselines\nsuch as MAML in the few-shot regime. The code for this project and a dataset\nexploration tool for iNat-Anim are publicly available at\nhttps://github.com/s-a-malik/multi-few .",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Matthew T. Jackson",
      "Shreshth A. Malik",
      "Michael T. Matthews",
      "Yousuf Mohamed-Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04843"
  },
  {
    "id": "arXiv:2210.04845",
    "title": "FS-DETR: Few-Shot DEtection TRansformer with prompting and without  re-training",
    "abstract": "This paper is on Few-Shot Object Detection (FSOD), where given a few\ntemplates (examples) depicting a novel class (not seen during training), the\ngoal is to detect all of its occurrences within a set of images. From a\npractical perspective, an FSOD system must fulfil the following desiderata: (a)\nit must be used as is, without requiring any fine-tuning at test time, (b) it\nmust be able to process an arbitrary number of novel objects concurrently while\nsupporting an arbitrary number of examples from each class and (c) it must\nachieve accuracy comparable to a closed system. While there are (relatively)\nfew systems that support (a), to our knowledge, there is no system supporting\n(b) and (c). In this work, we make the following contributions: We introduce,\nfor the first time, a simple, yet powerful, few-shot detection transformer\n(FS-DETR) that can address both desiderata (a) and (b). Our system builds upon\nthe DETR framework, extending it based on two key ideas: (1) feed the provided\nvisual templates of the novel classes as visual prompts during test time, and\n(2) ``stamp'' these prompts with pseudo-class embeddings, which are then\npredicted at the output of the decoder. Importantly, we show that our system is\nnot only more flexible than existing methods, but also, making a step towards\nsatisfying desideratum (c), it is more accurate, matching and outperforming the\ncurrent state-of-the-art on the most well-established benchmarks (PASCAL VOC &\nMSCOCO) for FSOD. Code will be made available.",
    "descriptor": "",
    "authors": [
      "Adrian Bulat",
      "Ricardo Guerrero",
      "Brais Martinez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04845"
  },
  {
    "id": "arXiv:2210.04847",
    "title": "NerfAcc: A General NeRF Acceleration Toolbox",
    "abstract": "We propose NerfAcc, a toolbox for efficient volumetric rendering of radiance\nfields. We build on the techniques proposed in Instant-NGP, and extend these\ntechniques to not only support bounded static scenes, but also for dynamic\nscenes and unbounded scenes. NerfAcc comes with a user-friendly Python API, and\nis ready for plug-and-play acceleration of most NeRFs. Various examples are\nprovided to show how to use this toolbox. Code can be found here:\nhttps://github.com/KAIR-BAIR/nerfacc.",
    "descriptor": "\nComments: Webpage: this https URL\n",
    "authors": [
      "Ruilong Li",
      "Matthew Tancik",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.04847"
  },
  {
    "id": "arXiv:2210.04852",
    "title": "Learning Real-world Autonomous Navigation by Self-Supervised Environment  Synthesis",
    "abstract": "Machine learning approaches have recently enabled autonomous navigation for\nmobile robots in a data-driven manner. Since most existing learning-based\nnavigation systems are trained with data generated in artificially created\ntraining environments, during real-world deployment at scale, it is inevitable\nthat robots will encounter unseen scenarios, which are out of the training\ndistribution and therefore lead to poor real-world performance. On the other\nhand, directly training in the real world is generally unsafe and inefficient.\nTo address this issue, we introduce Self-supervised Environment Synthesis\n(SES), in which, after real-world deployment with safety and efficiency\nrequirements, autonomous mobile robots can utilize experience from the\nreal-world deployment, reconstruct navigation scenarios, and synthesize\nrepresentative training environments in simulation. Training in these\nsynthesized environments leads to improved future performance in the real\nworld. The effectiveness of SES at synthesizing representative simulation\nenvironments and improving real-world navigation performance is evaluated via a\nlarge-scale deployment in a high-fidelity, realistic simulator and a\nsmall-scale deployment on a physical robot.",
    "descriptor": "",
    "authors": [
      "Zifan Xu",
      "Anirudh Nair",
      "Xuesu Xiao",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04852"
  },
  {
    "id": "arXiv:2210.04860",
    "title": "Second-order regression models exhibit progressive sharpening to the  edge of stability",
    "abstract": "Recent studies of gradient descent with large step sizes have shown that\nthere is often a regime with an initial increase in the largest eigenvalue of\nthe loss Hessian (progressive sharpening), followed by a stabilization of the\neigenvalue near the maximum value which allows convergence (edge of stability).\nThese phenomena are intrinsically non-linear and do not happen for models in\nthe constant Neural Tangent Kernel (NTK) regime, for which the predictive\nfunction is approximately linear in the parameters. As such, we consider the\nnext simplest class of predictive models, namely those that are quadratic in\nthe parameters, which we call second-order regression models. For quadratic\nobjectives in two dimensions, we prove that this second-order regression model\nexhibits progressive sharpening of the NTK eigenvalue towards a value that\ndiffers slightly from the edge of stability, which we explicitly compute. In\nhigher dimensions, the model generically shows similar behavior, even without\nthe specific structure of a neural network, suggesting that progressive\nsharpening and edge-of-stability behavior aren't unique features of neural\nnetworks, and could be a more general property of discrete learning algorithms\nin high-dimensional non-linear models.",
    "descriptor": "",
    "authors": [
      "Atish Agarwala",
      "Fabian Pedregosa",
      "Jeffrey Pennington"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.04860"
  },
  {
    "id": "arXiv:2210.04864",
    "title": "Transformer-based Localization from Embodied Dialog with Large-scale  Pre-training",
    "abstract": "We address the challenging task of Localization via Embodied Dialog (LED).\nGiven a dialog from two agents, an Observer navigating through an unknown\nenvironment and a Locator who is attempting to identify the Observer's\nlocation, the goal is to predict the Observer's final location in a map. We\ndevelop a novel LED-Bert architecture and present an effective pretraining\nstrategy. We show that a graph-based scene representation is more effective\nthan the top-down 2D maps used in prior works. Our approach outperforms\nprevious baselines.",
    "descriptor": "",
    "authors": [
      "Meera Hahn",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04864"
  },
  {
    "id": "arXiv:2210.04865",
    "title": "Tracking changes using Kullback-Leibler divergence for the continual  learning",
    "abstract": "Recently, continual learning has received a lot of attention. One of the\nsignificant problems is the occurrence of \\emph{concept drift}, which consists\nof changing probabilistic characteristics of the incoming data. In the case of\nthe classification task, this phenomenon destabilizes the model's performance\nand negatively affects the achieved prediction quality. Most current methods\napply statistical learning and similarity analysis over the raw data. However,\nsimilarity analysis in streaming data remains a complex problem due to time\nlimitation, non-precise values, fast decision speed, scalability, etc. This\narticle introduces a novel method for monitoring changes in the probabilistic\ndistribution of multi-dimensional data streams. As a measure of the rapidity of\nchanges, we analyze the popular Kullback-Leibler divergence. During the\nexperimental study, we show how to use this metric to predict the concept drift\noccurrence and understand its nature. The obtained results encourage further\nwork on the proposed methods and its application in the real tasks where the\nprediction of the future appearance of concept drift plays a crucial role, such\nas predictive maintenance.",
    "descriptor": "\nComments: Accepted manuscript in SMC 2022, it will be published in the IEEE digital library\n",
    "authors": [
      "Sebasti\u00e1n Basterrech",
      "Michal Wo\u017aniak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04865"
  },
  {
    "id": "arXiv:2210.04866",
    "title": "PoGaIN: Poisson-Gaussian Image Noise Modeling from Paired Samples",
    "abstract": "Image noise can often be accurately fitted to a Poisson-Gaussian\ndistribution. However, estimating the distribution parameters from only a noisy\nimage is a challenging task. Here, we study the case when paired noisy and\nnoise-free samples are available. No method is currently available to exploit\nthe noise-free information, which holds the promise of achieving more accurate\nestimates. To fill this gap, we derive a novel, cumulant-based, approach for\nPoisson-Gaussian noise modeling from paired image samples. We show its improved\nperformance over different baselines with special emphasis on MSE, effect of\noutliers, image dependence and bias, and additionally derive the log-likelihood\nfunction for further insight and discuss real-world applicability.",
    "descriptor": "\nComments: 5 pages, 4 figures, and 3 tables. Code is available at this https URL\n",
    "authors": [
      "Nicolas B\u00e4hler",
      "Majed El Helou",
      "\u00c9tienne Objois",
      "Kaan Okumu\u015f",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.04866"
  },
  {
    "id": "arXiv:2210.04868",
    "title": "Deep object detection for waterbird monitoring using aerial imagery",
    "abstract": "Monitoring of colonial waterbird nesting islands is essential to tracking\nwaterbird population trends, which are used for evaluating ecosystem health and\ninforming conservation management decisions. Recently, unmanned aerial\nvehicles, or drones, have emerged as a viable technology to precisely monitor\nwaterbird colonies. However, manually counting waterbirds from hundreds, or\npotentially thousands, of aerial images is both difficult and time-consuming.\nIn this work, we present a deep learning pipeline that can be used to precisely\ndetect, count, and monitor waterbirds using aerial imagery collected by a\ncommercial drone. By utilizing convolutional neural network-based object\ndetectors, we show that we can detect 16 classes of waterbird species that are\ncommonly found in colonial nesting islands along the Texas coast. Our\nexperiments using Faster R-CNN and RetinaNet object detectors give mean\ninterpolated average precision scores of 67.9% and 63.1% respectively.",
    "descriptor": "\nComments: Longer version of accepted short paper at 21st IEEE International Conference on Machine Learning and Applications (ICMLA'22). 7 pages, 5 figures\n",
    "authors": [
      "Krish Kabra",
      "Alexander Xiong",
      "Wenbin Li",
      "Minxuan Luo",
      "William Lu",
      "Raul Garcia",
      "Dhananjay Vijay",
      "Jiahui Yu",
      "Maojie Tang",
      "Tianjiao Yu",
      "Hank Arnold",
      "Anna Vallery",
      "Richard Gibbons",
      "Arko Barman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04868"
  },
  {
    "id": "arXiv:2210.04870",
    "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge  Graph Link Prediction",
    "abstract": "Link prediction is the task of inferring missing links between entities in\nknowledge graphs. Embedding-based methods have shown effectiveness in\naddressing this problem by modeling relational patterns in triples. However,\nthe link prediction task often requires contextual information in entity\nneighborhoods, while most existing embedding-based methods fail to capture it.\nAdditionally, little attention is paid to the diversity of entity\nrepresentations in different contexts, which often leads to false prediction\nresults. In this situation, we consider that the schema of knowledge graph\ncontains the specific contextual information, and it is beneficial for\npreserving the consistency of entities across contexts. In this paper, we\npropose a novel schema-augmented multi-level contrastive learning framework\n(SMiLE) to conduct knowledge graph link prediction. Specifically, we first\nexploit network schema as the prior constraint to sample negatives and\npre-train our model by employing a multi-level contrastive learning method to\nyield both prior schema and contextual information. Then we fine-tune our model\nunder the supervision of individual triples to learn subtler representations\nfor link prediction. Extensive experimental results on four knowledge graph\ndatasets with thorough analysis of each component demonstrate the effectiveness\nof our proposed framework against state-of-the-art baselines.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Qianqian Xie",
      "Wenjie Xu",
      "Hua Wang",
      "Min Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04870"
  },
  {
    "id": "arXiv:2210.04871",
    "title": "Certified Training: Small Boxes are All You Need",
    "abstract": "We propose the novel certified training method, SABR, which outperforms\nexisting methods across perturbation magnitudes on MNIST, CIFAR-10, and\nTinyImageNet, in terms of both standard and certifiable accuracies. The key\ninsight behind SABR is that propagating interval bounds for a small but\ncarefully selected subset of the adversarial input region is sufficient to\napproximate the worst-case loss over the whole region while significantly\nreducing approximation errors. SABR does not only establish a new\nstate-of-the-art in all commonly used benchmarks but more importantly, points\nto a new class of certified training methods promising to overcome the\nrobustness-accuracy trade-off.",
    "descriptor": "",
    "authors": [
      "Mark Niklas M\u00fcller",
      "Franziska Eckert",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.04871"
  },
  {
    "id": "arXiv:2210.04873",
    "title": "CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation",
    "abstract": "Counterfactual data augmentation (CDA) -- i.e., adding minimally perturbed\ninputs during training -- helps reduce model reliance on spurious correlations\nand improves generalization to out-of-distribution (OOD) data. Prior work on\ngenerating counterfactuals only considered restricted classes of perturbations,\nlimiting their effectiveness. We present COunterfactual Generation via\nRetrieval and Editing (CORE), a retrieval-augmented generation framework for\ncreating diverse counterfactual perturbations for CDA. For each training\nexample, CORE first performs a dense retrieval over a task-related unlabeled\ntext corpus using a learned bi-encoder and extracts relevant counterfactual\nexcerpts. CORE then incorporates these into prompts to a large language model\nwith few-shot learning capabilities, for counterfactual editing. Conditioning\nlanguage model edits on naturally occurring data results in diverse\nperturbations. Experiments on natural language inference and sentiment analysis\nbenchmarks show that CORE counterfactuals are more effective at improving\ngeneralization to OOD data compared to other DA approaches. We also show that\nthe CORE retrieval framework can be used to encourage diversity in manually\nauthored perturbations",
    "descriptor": "\nComments: Findings EMNLP 2022\n",
    "authors": [
      "Tanay Dixit",
      "Bhargavi Paranjape",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04873"
  },
  {
    "id": "arXiv:2210.04878",
    "title": "Translate First Reorder Later: Leveraging Monotonicity in Semantic  Parsing",
    "abstract": "Prior work in semantic parsing has shown that conventional seq2seq models\nfail at compositional generalization tasks. This limitation led to a resurgence\nof methods that model alignments between sentences and their corresponding\nmeaning representations, either implicitly through latent variables or\nexplicitly by taking advantage of alignment annotations. We take the second\ndirection and propose TPol, a two-step approach that first translates input\nsentences monotonically and then reorders them to obtain the correct output.\nThis is achieved with a modular framework comprising a Translator and a\nReorderer component. We test our approach on two popular semantic parsing\ndatasets. Our experiments show that by means of the monotonic translations,\nTPol can learn reliable lexico-logical patterns from aligned data,\nsignificantly improving compositional generalization both over conventional\nseq2seq models, as well as over a recently proposed approach that exploits gold\nalignments.",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables\n",
    "authors": [
      "Francesco Cazzaro",
      "Davide Locatelli",
      "Ariadna Quattoni",
      "Xavier Carreras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04878"
  },
  {
    "id": "arXiv:2210.04880",
    "title": "Obvious Independence of Clones",
    "abstract": "The Independence of Clones (IoC) criterion for social choice functions\n(voting rules) measures a function's robustness to strategic nomination.\nHowever, prior literature has established empirically that individuals cannot\nalways recognize whether or not a mechanism is strategy-proof and may still\nsubmit costly, distortionary misreports even in strategy-proof settings. The\nintersection of these issues motivates the search for mechanisms which are\nObviously Independent of Clones (OIoC): where strategic nomination or strategic\nexiting of clones obviously have no effect on the outcome of the election. We\nexamine three IoC ranked-choice voting mechanisms and the pre-existing proofs\nthat they are independent of clones: Single Transferable Vote (STV), Ranked\nPairs, and the Schulze method. We construct a formal definition of a voting\nsystem being Obviously Independent of Clones based on a reduction to a clocked\nelection by considering a bounded agent. Finally, we show that STV and Ranked\nPairs are OIoC, whereas we prove an impossibility result for the Schulze method\nshowing that this voting system is not OIoC.",
    "descriptor": "",
    "authors": [
      "Ratip Emin Berker",
      "S\u00edlvia Casacuberta",
      "Christopher Ong",
      "Isaac Robinson"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.04880"
  },
  {
    "id": "arXiv:2210.04882",
    "title": "Layer Ensembles",
    "abstract": "Deep Ensembles, as a type of Bayesian Neural Networks, can be used to\nestimate uncertainty on the prediction of multiple neural networks by\ncollecting votes from each network and computing the difference in those\npredictions. In this paper, we introduce a novel method for uncertainty\nestimation called Layer Ensembles that considers a set of independent\ncategorical distributions for each layer of the network, giving many more\npossible samples with overlapped layers, than in the regular Deep Ensembles. We\nfurther introduce Optimized Layer Ensembles with an inference procedure that\nreuses common layer outputs, achieving up to 19x speed up and quadratically\nreducing memory usage. We also show that Layer Ensembles can be further\nimproved by ranking samples, resulting in models that require less memory and\ntime to run while achieving higher uncertainty quality than Deep Ensembles.",
    "descriptor": "\nComments: 5 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Illia Oleksiienko",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04882"
  },
  {
    "id": "arXiv:2210.04883",
    "title": "SCAM! Transferring humans between images with Semantic Cross Attention  Modulation",
    "abstract": "A large body of recent work targets semantically conditioned image\ngeneration. Most such methods focus on the narrower task of pose transfer and\nignore the more challenging task of subject transfer that consists in not only\ntransferring the pose but also the appearance and background. In this work, we\nintroduce SCAM (Semantic Cross Attention Modulation), a system that encodes\nrich and diverse information in each semantic region of the image (including\nforeground and background), thus achieving precise generation with emphasis on\nfine details. This is enabled by the Semantic Attention Transformer Encoder\nthat extracts multiple latent vectors for each semantic region, and the\ncorresponding generator that exploits these multiple latents by using semantic\ncross attention modulation. It is trained only using a reconstruction setup,\nwhile subject transfer is performed at test time. Our analysis shows that our\nproposed architecture is successful at encoding the diversity of appearance in\neach semantic region. Extensive experiments on the iDesigner and CelebAMask-HD\ndatasets show that SCAM outperforms SEAN and SPADE; moreover, it sets the new\nstate of the art on subject transfer.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Nicolas Dufour",
      "David Picard",
      "Vicky Kalogeiton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04883"
  },
  {
    "id": "arXiv:2210.04885",
    "title": "What the DAAM: Interpreting Stable Diffusion Using Cross Attention",
    "abstract": "Large-scale diffusion neural networks represent a substantial milestone in\ntext-to-image generation, with some performing similar to real photographs in\nhuman evaluation. However, they remain poorly understood, lacking\nexplainability and interpretability analyses, largely due to their proprietary,\nclosed-source nature. In this paper, to shine some much-needed light on\ntext-to-image diffusion models, we perform a text-image attribution analysis on\nStable Diffusion, a recently open-sourced large diffusion model. To produce\npixel-level attribution maps, we propose DAAM, a novel method based on\nupscaling and aggregating cross-attention activations in the latent denoising\nsubnetwork. We support its correctness by evaluating its unsupervised instance\nsegmentation quality on its own generated imagery, compared to supervised\nsegmentation models. We show that DAAM performs strongly on COCO\ncaption-generated images, achieving an average precision (AP) of 61.0, and it\noutperforms supervised models on full-vocabulary segmentation, for an AP of\n51.5. We further find that certain parts of speech, like punctuation and\nconjunctions, influence the generated imagery most, which agrees with the prior\nliterature, while determiners and numerals the least, suggesting poor numeracy.\nTo our knowledge, we are the first to propose and study word--pixel attribution\nfor large-scale text-to-image diffusion models. Our code and data are at\nhttps://github.com/castorini/daam",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Raphael Tang",
      "Akshat Pandey",
      "Zhiying Jiang",
      "Gefei Yang",
      "Karun Kumar",
      "Jimmy Lin",
      "Ferhan Ture"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04885"
  },
  {
    "id": "arXiv:2210.04886",
    "title": "Revisiting adapters with adversarial training",
    "abstract": "While adversarial training is generally used as a defense mechanism, recent\nworks show that it can also act as a regularizer. By co-training a neural\nnetwork on clean and adversarial inputs, it is possible to improve\nclassification accuracy on the clean, non-adversarial inputs. We demonstrate\nthat, contrary to previous findings, it is not necessary to separate batch\nstatistics when co-training on clean and adversarial inputs, and that it is\nsufficient to use adapters with few domain-specific parameters for each type of\ninput. We establish that using the classification token of a Vision Transformer\n(ViT) as an adapter is enough to match the classification performance of dual\nnormalization layers, while using significantly less additional parameters.\nFirst, we improve upon the top-1 accuracy of a non-adversarially trained\nViT-B16 model by +1.12% on ImageNet (reaching 83.76% top-1 accuracy). Second,\nand more importantly, we show that training with adapters enables model soups\nthrough linear combinations of the clean and adversarial tokens. These model\nsoups, which we call adversarial model soups, allow us to trade-off between\nclean and robust accuracy without sacrificing efficiency. Finally, we show that\nwe can easily adapt the resulting models in the face of distribution shifts.\nOur ViT-B16 obtains top-1 accuracies on ImageNet variants that are on average\n+4.00% better than those obtained with Masked Autoencoders.",
    "descriptor": "",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Francesco Croce",
      "Sven Gowal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04886"
  },
  {
    "id": "arXiv:2210.04887",
    "title": "In-Hand Object Rotation via Rapid Motor Adaptation",
    "abstract": "Generalized in-hand manipulation has long been an unsolved challenge of\nrobotics. As a small step towards this grand goal, we demonstrate how to design\nand learn a simple adaptive controller to achieve in-hand object rotation using\nonly fingertips. The controller is trained entirely in simulation on only\ncylindrical objects, which then - without any fine-tuning - can be directly\ndeployed to a real robot hand to rotate dozens of objects with diverse sizes,\nshapes, and weights over the z-axis. This is achieved via rapid online\nadaptation of the controller to the object properties using only proprioception\nhistory. Furthermore, natural and stable finger gaits automatically emerge from\ntraining the control policy via reinforcement learning. Code and more videos\nare available at https://haozhi.io/hora",
    "descriptor": "\nComments: CoRL 2022. Code and Website: this https URL\n",
    "authors": [
      "Haozhi Qi",
      "Ashish Kumar",
      "Roberto Calandra",
      "Yi Ma",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04887"
  },
  {
    "id": "arXiv:2210.04888",
    "title": "EVA3D: Compositional 3D Human Generation from 2D Image Collections",
    "abstract": "Inverse graphics aims to recover 3D models from 2D observations. Utilizing\ndifferentiable rendering, recent 3D-aware generative models have shown\nimpressive results of rigid object generation using 2D images. However, it\nremains challenging to generate articulated objects, like human bodies, due to\ntheir complexity and diversity in poses and appearances. In this work, we\npropose, EVA3D, an unconditional 3D human generative model learned from 2D\nimage collections only. EVA3D can sample 3D humans with detailed geometry and\nrender high-quality images (up to 512x256) without bells and whistles (e.g.\nsuper resolution). At the core of EVA3D is a compositional human NeRF\nrepresentation, which divides the human body into local parts. Each part is\nrepresented by an individual volume. This compositional representation enables\n1) inherent human priors, 2) adaptive allocation of network parameters, 3)\nefficient training and rendering. Moreover, to accommodate for the\ncharacteristics of sparse 2D human image collections (e.g. imbalanced pose\ndistribution), we propose a pose-guided sampling strategy for better GAN\nlearning. Extensive experiments validate that EVA3D achieves state-of-the-art\n3D human generation performance regarding both geometry and texture quality.\nNotably, EVA3D demonstrates great potential and scalability to\n\"inverse-graphics\" diverse human bodies with a clean framework.",
    "descriptor": "\nComments: Project Page at this https URL\n",
    "authors": [
      "Fangzhou Hong",
      "Zhaoxi Chen",
      "Yushi Lan",
      "Liang Pan",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04888"
  },
  {
    "id": "arXiv:2210.04889",
    "title": "Turbo Training with Token Dropout",
    "abstract": "The objective of this paper is an efficient training method for video tasks.\nWe make three contributions: (1) We propose Turbo training, a simple and\nversatile training paradigm for Transformers on multiple video tasks. (2) We\nillustrate the advantages of Turbo training on action classification,\nvideo-language representation learning, and long-video activity classification,\nshowing that Turbo training can largely maintain competitive performance while\nachieving almost 4X speed-up and significantly less memory consumption. (3)\nTurbo training enables long-schedule video-language training and end-to-end\nlong-video training, delivering competitive or superior performance than\nprevious works, which were infeasible to train under limited resources.",
    "descriptor": "\nComments: BMVC2022\n",
    "authors": [
      "Tengda Han",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04889"
  },
  {
    "id": "arXiv:2210.03736",
    "title": "Trustworthy clinical AI solutions: a unified review of uncertainty  quantification in deep learning models for medical image analysis",
    "abstract": "The full acceptance of Deep Learning (DL) models in the clinical field is\nrather low with respect to the quantity of high-performing solutions reported\nin the literature. Particularly, end users are reluctant to rely on the rough\npredictions of DL models. Uncertainty quantification methods have been proposed\nin the literature as a potential response to reduce the rough decision provided\nby the DL black box and thus increase the interpretability and the\nacceptability of the result by the final user. In this review, we propose an\noverview of the existing methods to quantify uncertainty associated to DL\npredictions. We focus on applications to medical image analysis, which present\nspecific challenges due to the high dimensionality of images and their quality\nvariability, as well as constraints associated to real-life clinical routine.\nWe then discuss the evaluation protocols to validate the relevance of\nuncertainty estimates. Finally, we highlight the open challenges of uncertainty\nquantification in the medical field.",
    "descriptor": "",
    "authors": [
      "Benjamin Lambert",
      "Florence Forbes",
      "Alan Tucholka",
      "Senan Doyle",
      "Harmonie Dehaene",
      "Michel Dojat"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03736"
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": "Accurate segmentation of mandibular canals in lower jaws is important in\ndental implantology, in which the implant position and dimensions are currently\ndetermined manually from 3D CT images by medical experts to avoid damaging the\nmandibular nerve inside the canal. In this paper, we propose a novel dual-stage\ndeep learning based scheme for automatic detection of mandibular canal.\nParticularly, we first we enhance the CBCT scans by employing the novel\nhistogram-based dynamic windowing scheme which improves the visibility of\nmandibular canals. After enhancement, we design 3D deeply supervised attention\nU-Net architecture for localize the volume of interest (VOI) which contains the\nmandibular canals (i.e., left and right canals). Finally, we employed the\nmulti-scale input residual U-Net architecture (MS-R-UNet) to accurately segment\nthe mandibular canals. The proposed method has been rigorously evaluated on 500\nscans and results demonstrate that our technique out performs the existing\nstate-of-the-art methods in term of segmentation performance as well as\nrobustness.",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03739"
  },
  {
    "id": "arXiv:2210.03743",
    "title": "Single Image Super-Resolution Based on Capsule Neural Networks",
    "abstract": "Single image super-resolution (SISR) is the process of obtaining one\nhigh-resolution version of a low-resolution image by increasing the number of\npixels per unit area. This method has been actively investigated by the\nresearch community, due to the wide variety of real-world problems where it can\nbe applied, from aerial and satellite imaging to compressed image and video\nenhancement. Despite the improvements achieved by deep learning in the field,\nthe vast majority of the used networks are based on traditional convolutions,\nwith the solutions focusing on going deeper and/or wider, and innovations\ncoming from jointly employing successful concepts from other fields. In this\nwork, we decided to step up from the traditional convolutions and adopt the\nconcept of capsules. Since their overwhelming results both in image\nclassification and segmentation problems, we question how suitable they are for\nSISR. We also verify that different solutions share most of their\nconfigurations, and argue that this trend leads to fewer explorations of\nnetwork varieties. During our experiments, we check various strategies to\nimprove results, ranging from new and different loss functions to changes in\nthe capsule layers. Our network achieved good results with fewer\nconvolutional-based layers, showing that capsules might be a concept worth\napplying in the image super-resolution problem.",
    "descriptor": "\nComments: 19 pages, 13 figures\n",
    "authors": [
      "George Corr\u00eaa de Ara\u00fajo",
      "Helio Pedrini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03743"
  },
  {
    "id": "arXiv:2210.03745",
    "title": "ProGReST: Prototypical Graph Regression Soft Trees for Molecular  Property Prediction",
    "abstract": "In this work, we propose the novel Prototypical Graph Regression\nSelf-explainable Trees (ProGReST) model, which combines prototype learning,\nsoft decision trees, and Graph Neural Networks. In contrast to other works, our\nmodel can be used to address various challenging tasks, including compound\nproperty prediction. In ProGReST, the rationale is obtained along with\nprediction due to the model's built-in interpretability. Additionally, we\nintroduce a new graph prototype projection to accelerate model training.\nFinally, we evaluate PRoGReST on a wide range of chemical datasets for\nmolecular property prediction and perform in-depth analysis with chemical\nexperts to evaluate obtained interpretations. Our method achieves competitive\nresults against state-of-the-art methods.",
    "descriptor": "\nComments: In the review process\n",
    "authors": [
      "Dawid Rymarczyk",
      "Daniel Dobrowolski",
      "Tomasz Danel"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03745"
  },
  {
    "id": "arXiv:2210.03762",
    "title": "Trustworthiness of Laser-Induced Breakdown Spectroscopy Predictions via  Simulation-based Synthetic Data Augmentation and Multitask Learning",
    "abstract": "We consider quantitative analyses of spectral data using laser-induced\nbreakdown spectroscopy. We address the small size of training data available,\nand the validation of the predictions during inference on unknown data. For the\npurpose, we build robust calibration models using deep convolutional multitask\nlearning architectures to predict the concentration of the analyte, alongside\nadditional spectral information as auxiliary outputs. These secondary\npredictions can be used to validate the trustworthiness of the model by taking\nadvantage of the mutual dependencies of the parameters of the multitask neural\nnetworks. Due to the experimental lack of training samples, we introduce a\nsimulation-based data augmentation process to synthesise an arbitrary number of\nspectra, statistically representative of the experimental data. Given the\nnature of the deep learning model, no dimensionality reduction or data\nselection processes are required. The procedure is an end-to-end pipeline\nincluding the process of synthetic data augmentation, the construction of a\nsuitable robust, homoscedastic, deep learning model, and the validation of its\npredictions. In the article, we compare the performance of the multitask model\nwith traditional univariate and multivariate analyses, to highlight the\nseparate contributions of each element introduced in the process.",
    "descriptor": "\nComments: 35 pages, appendix with supplementary material\n",
    "authors": [
      "Riccardo Finotello",
      "Daniel L'Hermite",
      "Celine Qu\u00e9r\u00e9",
      "Benjamin Rouge",
      "Mohamed Tamaazousti",
      "Jean-Baptiste Sirven"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03762"
  },
  {
    "id": "arXiv:2210.03779",
    "title": "MRI-based classification of IDH mutation and 1p/19q codeletion status of  gliomas using a 2.5D hybrid multi-task convolutional neural network",
    "abstract": "Isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion status are\nimportant prognostic markers for glioma. Currently, they are determined using\ninvasive procedures. Our goal was to develop artificial intelligence-based\nmethods to non-invasively determine these molecular alterations from MRI. For\nthis purpose, pre-operative MRI scans of 2648 patients with gliomas (grade\nII-IV) were collected from Washington University School of Medicine (WUSM; n =\n835) and publicly available datasets viz. Brain Tumor Segmentation (BraTS; n =\n378), LGG 1p/19q (n = 159), Ivy Glioblastoma Atlas Project (Ivy GAP; n = 41),\nThe Cancer Genome Atlas (TCGA; n = 461), and the Erasmus Glioma Database (EGD;\nn = 774). A 2.5D hybrid convolutional neural network was proposed to\nsimultaneously localize the tumor and classify its molecular status by\nleveraging imaging features from MR scans and prior knowledge features from\nclinical records and tumor location. The models were tested on one internal\n(TCGA) and two external (WUSM and EGD) test sets. For IDH, the best-performing\nmodel achieved areas under the receiver operating characteristic (AUROC) of\n0.925, 0.874, 0.933 and areas under the precision-recall curves (AUPRC) of\n0.899, 0.702, 0.853 on the internal, WUSM, and EGD test sets, respectively. For\n1p/19q, the best model achieved AUROCs of 0.782, 0.754, 0.842, and AUPRCs of\n0.588, 0.713, 0.782, on those three data-splits, respectively. The high\naccuracy of the model on unseen data showcases its generalization capabilities\nand suggests its potential to perform a 'virtual biopsy' for tailoring\ntreatment planning and overall clinical management of gliomas.",
    "descriptor": "",
    "authors": [
      "Satrajit Chakrabarty",
      "Pamela LaMontagne",
      "Joshua Shimony",
      "Daniel S. Marcus",
      "Aristeidis Sotiras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03779"
  },
  {
    "id": "arXiv:2210.03813",
    "title": "MOS: A Mathematical Optimization Service",
    "abstract": "We introduce MOS, a software application designed to facilitate the\ndeployment, integration, management, and analysis of mathematical optimization\nmodels. MOS approaches mathematical optimization at a higher level of\nabstraction than existing optimization modeling systems, enabling its use with\nall of them. The sole requirement to harness MOS is a simple annotation of the\ncode specifying the formulation of an optimization model. With this, the model\nbecomes accessible to humans through the automatic generation of a user\ninterface, and to machines through an associated API and client libraries. All\nthis is achieved while avoiding the ad hoc code typically required to obtain\nsuch features.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "James Hubert Merrick",
      "Tom\u00e1s Tinoco De Rubira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2210.03813"
  },
  {
    "id": "arXiv:2210.03837",
    "title": "Self-Supervised Deep Equilibrium Models for Inverse Problems with  Theoretical Guarantees",
    "abstract": "Deep equilibrium models (DEQ) have emerged as a powerful alternative to deep\nunfolding (DU) for image reconstruction. DEQ models-implicit neural networks\nwith effectively infinite number of layers-were shown to achieve\nstate-of-the-art image reconstruction without the memory complexity associated\nwith DU. While the performance of DEQ has been widely investigated, the\nexisting work has primarily focused on the settings where groundtruth data is\navailable for training. We present self-supervised deep equilibrium model\n(SelfDEQ) as the first self-supervised reconstruction framework for training\nmodel-based implicit networks from undersampled and noisy MRI measurements. Our\ntheoretical results show that SelfDEQ can compensate for unbalanced sampling\nacross multiple acquisitions and match the performance of fully supervised DEQ.\nOur numerical results on in-vivo MRI data show that SelfDEQ leads to\nstate-of-the-art performance using only undersampled and noisy training data.",
    "descriptor": "",
    "authors": [
      "Weijie Gan",
      "Chunwei Ying",
      "Parna Eshraghi",
      "Tongyao Wang",
      "Cihat Eldeniz",
      "Yuyang Hu",
      "Jiaming Liu",
      "Yasheng Chen",
      "Hongyu An",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03837"
  },
  {
    "id": "arXiv:2210.03859",
    "title": "Spectrally-Corrected and Regularized Linear Discriminant Analysis for  Spiked Covariance Model",
    "abstract": "In this paper, we propose an improved linear discriminant analysis, called\nspectrally-corrected and regularized linear discriminant analysis (SCRLDA).\nThis method integrates the design ideas of the sample spectrally-corrected\ncovariance matrix and the regularized discriminant analysis. The SCRLDA method\nis specially designed for classification problems under the assumption that the\ncovariance matrix follows a spiked model. Through the real and simulated data\nanalysis, it is shown that our proposed classifier outperforms the classical\nR-LDA and can be as competitive as the KNN, SVM classifiers while requiring\nlower computational complexity.",
    "descriptor": "",
    "authors": [
      "Hua Li",
      "Wenya Luo",
      "Zhidong Bai",
      "Huanchao Zhou",
      "Zhangni Pu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03859"
  },
  {
    "id": "arXiv:2210.03882",
    "title": "Investigation of Applying Quantum Neural Network of Early-Stage Breast  Cancer Detection",
    "abstract": "Due to the heavy burden on medical institutes and computer-aided image\ndiagnostics (CAD) have been gaining importance in diagnostic medicine to aid\nthe medical staff to attain better service for the patients. Breast cancer is a\nfatal disease that can be treated successfully if it is detected early. Quantum\nneural network (QNN) has been introduced by many researchers around the world\nand presented recently by research corporations such as Microsoft, Google, and\nIBM. In this paper, we are trying to answer the question of: whether can the\nQNN be an effective method for mass-scale early breast cancer detection. This\npaper is dedicated to drawing a baseline for examining QNN, and the results\nshowed a promising opportunity to use it for mass-scale screening using a fully\nfunctional quantum computer.",
    "descriptor": "",
    "authors": [
      "Musaddiq Al Ali",
      "Amjad Y. Sahib",
      "Muazez Al Ali"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Information Theory (cs.IT)",
      "Quantum Algebra (math.QA)"
    ],
    "url": "https://arxiv.org/abs/2210.03882"
  },
  {
    "id": "arXiv:2210.03886",
    "title": "Locality and stability for phase retrieval",
    "abstract": "A frame $(x_j)_{j\\in J}$ for a Hilbert space $H$ is said to do phase\nretrieval if for all distinct vectors $x,y\\in H$ the magnitude of the frame\ncoefficients $(|\\langle x, x_j\\rangle|)_{j\\in J}$ and $(|\\langle y,\nx_j\\rangle|)_{j\\in J}$ distinguish $x$ from $y$ (up to a unimodular scalar). We\nconsider the weaker condition where the magnitude of the frame coefficients\ndistinguishes $x$ from every vector $y$ in a small neighborhood of $x$ (up to a\nunimodular scalar). We prove that some of the important theorems for phase\nretrieval hold for this local condition, where as some theorems are completely\ndifferent. We prove as well that when considering stability of phase retrieval,\nthe worst stability inequality is always witnessed at orthogonal vectors. This\nallows for much simpler calculations when considering optimization problems for\nphase retrieval.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Wedad Alharbi",
      "Salah Alshabhi",
      "Daniel Freeman",
      "Dorsa Ghoreishi"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03886"
  },
  {
    "id": "arXiv:2210.03888",
    "title": "Accelerated and Deep Expectation Maximization for One-Bit MIMO-OFDM  Detection",
    "abstract": "In this paper we study the expectation maximization (EM) technique for\none-bit MIMO-OFDM detection (OMOD). Arising from the recent interest in massive\nMIMO with one-bit analog-to-digital converters, OMOD is a massive-scale\nproblem. EM is an iterative method that can exploit the OFDM structure to\nprocess the problem in a per-iteration efficient fashion. In this study we\nanalyze the convergence rate of EM for a class of approximate\nmaximum-likelihood OMOD formulations, or, in a broader sense, a class of\nproblems involving regression from quantized data. We show how the SNR and\nchannel conditions can have an impact on the convergence rate. We do so by\nmaking a connection between the EM and the proximal gradient methods in the\ncontext of OMOD. This connection also gives us insight to build new accelerated\nand/or inexact EM schemes. The accelerated scheme has faster convergence in\ntheory, and the inexact scheme provides us with the flexibility to implement EM\nmore efficiently, with convergence guarantee. Furthermore we develop a deep EM\nalgorithm, wherein we take the structure of our inexact EM algorithm and apply\ndeep unfolding to train an efficient structured deep net. Simulation results\nshow that our accelerated exact/inexact EM algorithms run much faster than\ntheir standard EM counterparts, and that the deep EM algorithm gives promising\ndetection and runtime performances.",
    "descriptor": "",
    "authors": [
      "Mingjie Shao",
      "Wing-Kin Ma",
      "Junbin Liu",
      "Zihao Huang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03888"
  },
  {
    "id": "arXiv:2210.03911",
    "title": "Signal Detection in MIMO Systems with Hardware Imperfections: Message  Passing on Neural Networks",
    "abstract": "In this paper, we investigate signal detection in\nmultiple-input-multiple-output (MIMO) communication systems with hardware\nimpairments, such as power amplifier nonlinearity and in-phase/quadrature\nimbalance. To deal with the complex combined effects of hardware imperfections,\nneural network (NN) techniques, in particular deep neural networks (DNNs), have\nbeen studied to directly compensate for the impact of hardware impairments.\nHowever, it is difficult to train a DNN with limited pilot signals, hindering\nits practical applications. In this work, we investigate how to achieve\nefficient Bayesian signal detection in MIMO systems with hardware\nimperfections. Characterizing combined hardware imperfections often leads to\ncomplicated signal models, making Bayesian signal detection challenging. To\naddress this issue, we first train an NN to \"model\" the MIMO system with\nhardware imperfections and then perform Bayesian inference based on the trained\nNN. Modelling the MIMO system with NN enables the design of NN architectures\nbased on the signal flow of the MIMO system, minimizing the number of NN layers\nand parameters, which is crucial to achieving efficient training with limited\npilot signals. We then represent the trained NN with a factor graph, and design\nan efficient message passing based Bayesian signal detector, leveraging the\nunitary approximate message passing (UAMP) algorithm. The implementation of a\nturbo receiver with the proposed Bayesian detector is also investigated.\nExtensive simulation results demonstrate that the proposed technique delivers\nremarkably better performance than state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Dawei Gao",
      "Qinghua Guo",
      "Guisheng Liao",
      "Yonina C. Eldar",
      "Yonghui Li",
      "Yanguang Yu",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03911"
  },
  {
    "id": "arXiv:2210.03964",
    "title": "An Efficient and Continuous Voronoi Density Estimator",
    "abstract": "We introduce a non-parametric density estimator deemed Radial Voronoi Density\nEstimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and\nas such benefits from local geometric adaptiveness and broad convergence\nproperties. Due to its radial definition RVDE is moreover continuous and\ncomputable in linear time with respect to the dataset size. This amends for the\nmain shortcomings of previously studied VDEs, which are highly discontinuous\nand computationally expensive. We provide a theoretical study of the modes of\nRVDE as well as an empirical investigation of its performance on\nhigh-dimensional data. Results show that RVDE outperforms other non-parametric\ndensity estimators, including recently introduced VDEs.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Giovanni Luca Marchetti",
      "Vladislav Polianskii",
      "Anastasiia Varava",
      "Florian T. Pokorny",
      "Danica Kragic"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.03964"
  },
  {
    "id": "arXiv:2210.03996",
    "title": "Some Tribonacci Conjectures",
    "abstract": "In a recent talk of Robbert Fokkink, some conjectures related to the infinite\nTribonacci word were stated by the speaker and the audience. In this note we\nshow how to prove (or disprove) the claims easily in a \"purely mechanical\"\nfashion, using the Walnut theorem-prover.",
    "descriptor": "",
    "authors": [
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.03996"
  },
  {
    "id": "arXiv:2210.04011",
    "title": "Compartmental limit of discrete Bass models on networks",
    "abstract": "We introduce a new method for proving the convergence and the rate of\nconvergence of discrete Bass models on various networks to their respective\ncompartmental Bass models, as the population size $M$ becomes infinite. In this\nmethod, the full set of master equations is reduced to a smaller system of\nequations, which is closed and exact. The reduced finite system is embedded\ninto an infinite system, and the convergence of that system to the infinite\nlimit system is proved using standard ODE estimates. Finally, an ansatz\nprovides an exact closure of the infinite limit system, which reduces that\nsystem to the compartmental model.\nUsing this method, we show that when the network is complete and homogeneous,\nthe discrete Bass model converges to the original 1969 compartmental Bass\nmodel, at the rate of $1/M$. When the network is circular, however, the\ncompartmental limit is different, and the rate of convergence is exponential in\n$M$. In the case of a heterogeneous network that consists of $K$ homogeneous\ngroups, the limit is given by a heterogeneous compartmental Bass model, and the\nrate of convergence is $1/M$. Using this compartmental model, we show that when\nthe heterogeneity in the external and internal influence parameters among the\n$K$ groups is positively monotonically related, heterogeneity slows down the\ndiffusion.",
    "descriptor": "\nComments: 28 pages, 5 figures\n",
    "authors": [
      "Gadi Fibich",
      "Amit Golan",
      "Steve Schochet"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04011"
  },
  {
    "id": "arXiv:2210.04108",
    "title": "Visual Looming from Motion Field and Surface Normals",
    "abstract": "Looming, traditionally defined as the relative expansion of objects in the\nobserver's retina, is a fundamental visual cue for perception of threat and can\nbe used to accomplish collision free navigation. In this paper we derive novel\nsolutions for obtaining visual looming quantitatively from the 2D motion field\nresulting from a six-degree-of-freedom motion of an observer relative to a\nlocal surface in 3D. We also show the relationship between visual looming and\nsurface normals. We present novel methods to estimate visual looming from\nspatial derivatives of optical flow without the need for knowing range.\nSimulation results show that estimations of looming are very close to ground\ntruth looming under some assumptions of surface orientations. In addition, we\npresent results of visual looming using real data from the KITTI dataset.\nAdvantages and limitations of the methods are discussed as well.",
    "descriptor": "",
    "authors": [
      "Juan Yepes",
      "Daniel Raviv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04108"
  },
  {
    "id": "arXiv:2210.04118",
    "title": "Convergence of the Backward Deep BSDE Method with Applications to  Optimal Stopping Problems",
    "abstract": "The optimal stopping problem is one of the core problems in financial\nmarkets, with broad applications such as pricing American and Bermudan options.\nThe deep BSDE method [Han, Jentzen and E, PNAS, 115(34):8505-8510, 2018] has\nshown great power in solving high-dimensional forward-backward stochastic\ndifferential equations (FBSDEs), and inspired many applications. However, the\nmethod solves backward stochastic differential equations (BSDEs) in a forward\nmanner, which can not be used for optimal stopping problems that in general\nrequire running BSDE backwardly. To overcome this difficulty, a recent paper\n[Wang, Chen, Sudjianto, Liu and Shen, arXiv:1807.06622, 2018] proposed the\nbackward deep BSDE method to solve the optimal stopping problem. In this paper,\nwe provide the rigorous theory for the backward deep BSDE method. Specifically,\n1. We derive the a posteriori error estimation, i.e., the error of the\nnumerical solution can be bounded by the training loss function; and; 2. We\ngive an upper bound of the loss function, which can be sufficiently small\nsubject to universal approximations. We give two numerical examples, which\npresent consistent performance with the proved theory.",
    "descriptor": "",
    "authors": [
      "Chengfan Gao",
      "Siping Gao",
      "Ruimeng Hu",
      "Zimu Zhu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04118"
  },
  {
    "id": "arXiv:2210.04122",
    "title": "Inferring Line-of-Sight Velocities and Doppler Widths from Stokes  Profiles of GST/NIRIS Using Stacked Deep Neural Networks",
    "abstract": "Obtaining high-quality magnetic and velocity fields through Stokes inversion\nis crucial in solar physics. In this paper, we present a new deep learning\nmethod, named Stacked Deep Neural Networks (SDNN), for inferring line-of-sight\n(LOS) velocities and Doppler widths from Stokes profiles collected by the Near\nInfraRed Imaging Spectropolarimeter (NIRIS) on the 1.6 m Goode Solar Telescope\n(GST) at the Big Bear Solar Observatory (BBSO). The training data of SDNN is\nprepared by a Milne-Eddington (ME) inversion code used by BBSO. We\nquantitatively assess SDNN, comparing its inversion results with those obtained\nby the ME inversion code and related machine learning (ML) algorithms such as\nmultiple support vector regression, multilayer perceptrons and a pixel-level\nconvolutional neural network. Major findings from our experimental study are\nsummarized as follows. First, the SDNN-inferred LOS velocities are highly\ncorrelated to the ME-calculated ones with the Pearson product-moment\ncorrelation coefficient being close to 0.9 on average. Second, SDNN is faster,\nwhile producing smoother and cleaner LOS velocity and Doppler width maps, than\nthe ME inversion code. Third, the maps produced by SDNN are closer to ME's maps\nthan those from the related ML algorithms, demonstrating the better learning\ncapability of SDNN than the ML algorithms. Finally, comparison between the\ninversion results of ME and SDNN based on GST/NIRIS and those from the\nHelioseismic and Magnetic Imager on board the Solar Dynamics Observatory in\nflare-prolific active region NOAA 12673 is presented. We also discuss\nextensions of SDNN for inferring vector magnetic fields with empirical\nevaluation.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Haodi Jiang",
      "Qin Li",
      "Yan Xu",
      "Wynne Hsu",
      "Kwangsu Ahn",
      "Wenda Cao",
      "Jason T. L. Wang",
      "Haimin Wang"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04122"
  },
  {
    "id": "arXiv:2210.04143",
    "title": "Strong Gravitational Lensing Parameter Estimation with Vision  Transformer",
    "abstract": "Quantifying the parameters and corresponding uncertainties of hundreds of\nstrongly lensed quasar systems holds the key to resolving one of the most\nimportant scientific questions: the Hubble constant ($H_{0}$) tension. The\ncommonly used Markov chain Monte Carlo (MCMC) method has been too\ntime-consuming to achieve this goal, yet recent work has shown that convolution\nneural networks (CNNs) can be an alternative with seven orders of magnitude\nimprovement in speed. With 31,200 simulated strongly lensed quasar images, we\nexplore the usage of Vision Transformer (ViT) for simulated strong\ngravitational lensing for the first time. We show that ViT could reach\ncompetitive results compared with CNNs, and is specifically good at some\nlensing parameters, including the most important mass-related parameters such\nas the center of lens $\\theta_{1}$ and $\\theta_{2}$, the ellipticities $e_1$\nand $e_2$, and the radial power-law slope $\\gamma'$. With this promising\npreliminary result, we believe the ViT (or attention-based) network\narchitecture can be an important tool for strong lensing science for the next\ngeneration of surveys. The open source of our code and data is in\n\\url{https://github.com/kuanweih/strong_lensing_vit_resnet}.",
    "descriptor": "\nComments: Accepted by ECCV 2022 AI for Space Workshop\n",
    "authors": [
      "Kuan-Wei Huang",
      "Geoff Chih-Fan Chen",
      "Po-Wen Chang",
      "Sheng-Chieh Lin",
      "Chia-Jung Hsu",
      "Vishal Thengane",
      "Joshua Yao-Yu Lin"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04143"
  },
  {
    "id": "arXiv:2210.04156",
    "title": "Optimal Distributed Fault-Tolerant Sensor Fusion: Fundamental Limits and  Efficient Algorithms",
    "abstract": "Distributed estimation is a fundamental problem in signal processing which\nfinds applications in a variety of scenarios of interest including distributed\nsensor networks, robotics, group decision problems, and monitoring and\nsurveillance applications. The problem considers a scenario where distributed\nagents are given a set of measurements, and are tasked with estimating a target\nvariable. This work considers distributed estimation in the context of sensor\nnetworks, where a subset of sensor measurements are faulty and the distributed\nagents are agnostic to these faulty sensor measurements. The objective is to\nminimize i) the mean square error in estimating the target variable at each\nnode (accuracy objective), and ii) the mean square distance between the\nestimates at each pair of nodes (consensus objective). It is shown that there\nis an inherent tradeoff between satisfying the former and latter objectives.\nThe tradeoff is explicitly characterized and the fundamental performance limits\nare derived under specific statistical assumptions on the sensor output\nstatistics. Assuming a general stochastic model, the sensor fusion algorithm\noptimizing this tradeoff is characterized through a computable optimization\nproblem. Finding the optimal sensor fusion algorithm is computationally\ncomplex. To address this, a general class of low-complexity Brooks-Iyengar\nAlgorithms are introduced, and their performance, in terms of accuracy and\nconsensus objectives, is compared to that of optimal linear estimators through\ncase study simulations of various scenarios.",
    "descriptor": "",
    "authors": [
      "Marian Temprana Alonso",
      "Farhad Shirani",
      "S. Sitharama Iyengar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04156"
  },
  {
    "id": "arXiv:2210.04158",
    "title": "HVS Revisited: A Comprehensive Video Quality Assessment Framework",
    "abstract": "Video quality is a primary concern for video service providers. In recent\nyears, the techniques of video quality assessment (VQA) based on deep\nconvolutional neural networks (CNNs) have been developed rapidly. Although\nexisting works attempt to introduce the knowledge of the human visual system\n(HVS) into VQA, there still exhibit limitations that prevent the full\nexploitation of HVS, including an incomplete model by few characteristics and\ninsufficient connections among these characteristics. To overcome these\nlimitations, this paper revisits HVS with five representative characteristics,\nand further reorganizes their connections. Based on the revisited HVS, a\nno-reference VQA framework called HVS-5M (NRVQA framework with five modules\nsimulating HVS with five characteristics) is proposed. It works in a\ndomain-fusion design paradigm with advanced network structures. On the side of\nthe spatial domain, the visual saliency module applies SAMNet to obtain a\nsaliency map. And then, the content-dependency and the edge masking modules\nrespectively utilize ConvNeXt to extract the spatial features, which have been\nattentively weighted by the saliency map for the purpose of highlighting those\nregions that human beings may be interested in. On the other side of the\ntemporal domain, to supplement the static spatial features, the motion\nperception module utilizes SlowFast to obtain the dynamic temporal features.\nBesides, the temporal hysteresis module applies TempHyst to simulate the memory\nmechanism of human beings, and comprehensively evaluates the quality score\naccording to the fusion features from the spatial and temporal domains.\nExtensive experiments show that our HVS-5M outperforms the state-of-the-art VQA\nmethods. Ablation studies are further conducted to verify the effectiveness of\neach module towards the proposed framework.",
    "descriptor": "\nComments: 13 pages, 5 figures, Journal paper\n",
    "authors": [
      "Ao-Xiang Zhang",
      "Yuan-Gen Wang",
      "Weixuan Tang",
      "Leida Li",
      "Sam Kwong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04158"
  },
  {
    "id": "arXiv:2210.04168",
    "title": "Galaxy Spin Classification I: Z-wise vs S-wise Spirals With Chirality  Equivariant Residual Network",
    "abstract": "The angular momentum of galaxies (galaxy spin) contains rich information\nabout the initial condition of the Universe, yet it is challenging to\nefficiently measure the spin direction for the tremendous amount of galaxies\nthat are being mapped by the ongoing and forthcoming cosmological surveys. We\npresent a machine learning based classifier for the Z-wise vs S-wise spirals,\nwhich can help to break the degeneracy in the galaxy spin direction\nmeasurement. The proposed Chirality Equivariant Residual Network (CE-ResNet) is\nmanifestly equivariant under a reflection of the input image, which guarantees\nthat there is no inherent asymmetry between the Z-wise and S-wise probability\nestimators. We train the model with Sloan Digital Sky Survey (SDSS) images,\nwith the training labels given by the Galaxy Zoo 1 (GZ1) project. A combination\nof data augmentation tricks are used during the training, making the model more\nrobust to be applied to other surveys. We find a $\\sim\\!30\\%$ increase of both\ntypes of spirals when Dark Energy Spectroscopic Instrument (DESI) images are\nused for classification, due to the better imaging quality of DESI. We verify\nthat the $\\sim\\!7\\sigma$ difference between the numbers of Z-wise and S-wise\nspirals is due to human bias, since the discrepancy drops to $<\\!1.8\\sigma$\nwith our CE-ResNet classification results. We discuss the potential systematics\nthat are relevant to the future cosmological applications.",
    "descriptor": "\nComments: 13+4 pages, 11 figures, 2 tables, to be submitted to ApJ\n",
    "authors": [
      "He Jia",
      "Hong-Ming Zhu",
      "Ue-Li Pen"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04168"
  },
  {
    "id": "arXiv:2210.04172",
    "title": "A Transformer-based deep neural network model for SSVEP classification",
    "abstract": "Steady-state visual evoked potential (SSVEP) is one of the most commonly used\ncontrol signal in the brain-computer interface (BCI) systems. However, the\nconventional spatial filtering methods for SSVEP classification highly depend\non the subject-specific calibration data. The need for the methods that can\nalleviate the demand for the calibration data become urgent. In recent years,\ndeveloping the methods that can work in inter-subject classification scenario\nhas become a promising new direction. As the popular deep learning model\nnowadays, Transformer has excellent performance and has been used in EEG signal\nclassification tasks. Therefore, in this study, we propose a deep learning\nmodel for SSVEP classification based on Transformer structure in inter-subject\nclassification scenario, termed as SSVEPformer, which is the first application\nof the transformer to the classification of SSVEP. Inspired by previous\nstudies, the model adopts the frequency spectrum of SSVEP data as input, and\nexplores the spectral and spatial domain information for classification.\nFurthermore, to fully utilize the harmonic information, an extended SSVEPformer\nbased on the filter bank technology (FB-SSVEPformer) is proposed to further\nimprove the classification performance. Experiments were conducted using two\nopen datasets (Dataset 1: 10 subjects, 12-class task; Dataset 2: 35 subjects,\n40-class task) in the inter-subject classification scenario. The experimental\nresults show that the proposed models could achieve better results in terms of\nclassification accuracy and information transfer rate, compared with other\nbaseline methods. The proposed model validates the feasibility of deep learning\nmodels based on Transformer structure for SSVEP classification task, and could\nserve as a potential model to alleviate the calibration procedure in the\npractical application of SSVEP-based BCI systems.",
    "descriptor": "",
    "authors": [
      "Jianbo Chen",
      "Yangsong Zhang",
      "Yudong Pan",
      "Peng Xu",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04172"
  },
  {
    "id": "arXiv:2210.04188",
    "title": "Invertible Rescaling Network and Its Extensions",
    "abstract": "Image rescaling is a commonly used bidirectional operation, which first\ndownscales high-resolution images to fit various display screens or to be\nstorage- and bandwidth-friendly, and afterward upscales the corresponding\nlow-resolution images to recover the original resolution or the details in the\nzoom-in images. However, the non-injective downscaling mapping discards\nhigh-frequency contents, leading to the ill-posed problem for the inverse\nrestoration task. This can be abstracted as a general image\ndegradation-restoration problem with information loss. In this work, we propose\na novel invertible framework to handle this general problem, which models the\nbidirectional degradation and restoration from a new perspective, i.e.\ninvertible bijective transformation. The invertibility enables the framework to\nmodel the information loss of pre-degradation in the form of distribution,\nwhich could mitigate the ill-posed problem during post-restoration. To be\nspecific, we develop invertible models to generate valid degraded images and\nmeanwhile transform the distribution of lost contents to the fixed distribution\nof a latent variable during the forward degradation. Then restoration is made\ntractable by applying the inverse transformation on the generated degraded\nimage together with a randomly-drawn latent variable. We start from image\nrescaling and instantiate the model as Invertible Rescaling Network (IRN),\nwhich can be easily extended to the similar decolorization-colorization task.\nWe further propose to combine the invertible framework with existing\ndegradation methods such as image compression for wider applications.\nExperimental results demonstrate the significant improvement of our model over\nexisting methods in terms of both quantitative and qualitative evaluations of\nupscaling and colorizing reconstruction from downscaled and decolorized images,\nand rate-distortion of image compression.",
    "descriptor": "\nComments: Accepted by IJCV\n",
    "authors": [
      "Mingqing Xiao",
      "Shuxin Zheng",
      "Chang Liu",
      "Zhouchen Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04188"
  },
  {
    "id": "arXiv:2210.04193",
    "title": "Quasi-Monolithic Graph Neural Network for Fluid-Structure Interaction",
    "abstract": "Using convolutional neural networks, deep learning-based reduced-order models\nhave demonstrated great potential in accelerating the simulations of coupled\nfluid-structure systems for downstream optimization and control tasks. However,\nthese networks have to operate on a uniform Cartesian grid due to the inherent\nrestriction of convolutions, leading to difficulties in extracting fine\nphysical details along a fluid-structure interface without excessive\ncomputational burden. In this work, we present a quasi-monolithic graph neural\nnetwork framework for the reduced-order modelling of fluid-structure\ninteraction systems. With the aid of an arbitrary Lagrangian-Eulerian\nformulation, the mesh and fluid states are evolved temporally with two\nsub-networks. The movement of the mesh is reduced to the evolution of several\ncoefficients via proper orthogonal decomposition, and these coefficients are\npropagated through time via a multi-layer perceptron. A graph neural network is\nemployed to predict the evolution of the fluid state based on the state of the\nwhole system. The structural state is implicitly modelled by the movement of\nthe mesh on the fluid-structure boundary; hence it makes the proposed\ndata-driven methodology quasi-monolithic. The effectiveness of the proposed\nquasi-monolithic graph neural network architecture is assessed on a\nprototypical fluid-structure system of the flow around an elastically-mounted\ncylinder. We use the full-order flow snapshots and displacements as target\nphysical data to learn and infer coupled fluid-structure dynamics. The proposed\nframework tracks the interface description and provides the state predictions\nduring roll-out with acceptable accuracy. We also directly extract the lift and\ndrag forces from the predicted fluid and mesh states, in contrast to existing\nconvolution-based architectures.",
    "descriptor": "",
    "authors": [
      "Rui Gao",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04193"
  },
  {
    "id": "arXiv:2210.04194",
    "title": "Reap the Harvest on Blockchain: A Survey of Yield Farming Protocols",
    "abstract": "Yield farming represents an immensely popular asset management activity in\ndecentralized finance (DeFi). It involves supplying, borrowing, or staking\ncrypto assets to earn an income in forms of transaction fees, interest, or\nparticipation rewards at different DeFi marketplaces. In this systematic\nsurvey, we present yield farming protocols as an aggregation-layer constituent\nof the wider DeFi ecosystem that interact with primitive-layer protocols such\nas decentralized exchanges (DEXs) and protocols for loanable funds (PLFs). We\nexamine the yield farming mechanism by first studying the operations encoded in\nthe yield farming smart contracts, and then performing stylized, parameterized\nsimulations on various yield farming strategies. We conduct a thorough\nliterature review on related work, and establish a framework for yield farming\nprotocols that takes into account pool structure, accepted token types, and\nimplemented strategies. Using our framework, we characterize major yield\naggregators in the market including Yearn Finance, Beefy, and Badger DAO.\nMoreover, we discuss anecdotal attacks against yield aggregators and generalize\na number of risks associated with yield farming.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.13891\n",
    "authors": [
      "Jiahua Xu",
      "Yebo Feng"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2210.04194"
  },
  {
    "id": "arXiv:2210.04198",
    "title": "Super-Resolution by Predicting Offsets: An Ultra-Efficient  Super-Resolution Network for Rasterized Images",
    "abstract": "Rendering high-resolution (HR) graphics brings substantial computational\ncosts. Efficient graphics super-resolution (SR) methods may achieve HR\nrendering with small computing resources and have attracted extensive research\ninterests in industry and research communities. We present a new method for\nreal-time SR for computer graphics, namely Super-Resolution by Predicting\nOffsets (SRPO). Our algorithm divides the image into two parts for processing,\ni.e., sharp edges and flatter areas. For edges, different from the previous SR\nmethods that take the anti-aliased images as inputs, our proposed SRPO takes\nadvantage of the characteristics of rasterized images to conduct SR on the\nrasterized images. To complement the residual between HR and low-resolution\n(LR) rasterized images, we train an ultra-efficient network to predict the\noffset maps to move the appropriate surrounding pixels to the new positions.\nFor flat areas, we found simple interpolation methods can already generate\nreasonable output. We finally use a guided fusion operation to integrate the\nsharp edges generated by the network and flat areas by the interpolation method\nto get the final SR image. The proposed network only contains 8,434 parameters\nand can be accelerated by network quantization. Extensive experiments show that\nthe proposed SRPO can achieve superior visual effects at a smaller\ncomputational cost than the existing state-of-the-art methods.",
    "descriptor": "\nComments: This article has been accepted by ECCV2022\n",
    "authors": [
      "Jinjin Gu",
      "Haoming Cai",
      "Chenyu Dong",
      "Ruofan Zhang",
      "Yulun Zhang",
      "Wenming Yang",
      "Chun Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04198"
  },
  {
    "id": "arXiv:2210.04219",
    "title": "Rational cross-sections, bounded generation and orders on groups",
    "abstract": "We provide new examples of groups without rational cross-sections (also\ncalled regular normal forms), using connections with bounded generation and\nrational orders on groups. Specifically, our examples are extensions of\ninfinite torsion groups, groups of Grigorchuk type, wreath products similar to\n$C_2\\wr(C_2\\wr \\mathbb Z)$ and $\\mathbb Z\\wr F_2$, a group of permutations of\n$\\mathbb Z$, and a finitely presented HNN extension of the first Grigorchuk\ngroup. This last group is the first example of finitely presented group with\nsolvable word problem and without rational cross-sections. It is also not\nautostackable, and has no left-regular complete rewriting system.",
    "descriptor": "\nComments: Comments are welcome! 38 pages, 23 figures\n",
    "authors": [
      "Corentin Bodart"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.04219"
  },
  {
    "id": "arXiv:2210.04221",
    "title": "The Elliptical Quartic Exponential Distribution: An Annular Distribution  Obtained via Maximum Entropy",
    "abstract": "This paper describes the Elliptical Quartic Exponential distribution in\n$\\mathbb{R}^D$, obtained via a maximum entropy construction by imposing second\nand fourth moment constraints. I discuss relationships to related work,\nanalytical expressions for the normalization constant and the entropy, and the\nconditional and marginal distributions.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Christopher K I Williams"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.04221"
  },
  {
    "id": "arXiv:2210.04222",
    "title": "Correlative Information Maximization Based Biologically Plausible Neural  Networks for Correlated Source Separation",
    "abstract": "The brain effortlessly extracts latent causes of stimuli, but how it does\nthis at the network level remains unknown. Most prior attempts at this problem\nproposed neural networks that implement independent component analysis which\nworks under the limitation that latent causes are mutually independent. Here,\nwe relax this limitation and propose a biologically plausible neural network\nthat extracts correlated latent sources by exploiting information about their\ndomains. To derive this network, we choose maximum correlative information\ntransfer from inputs to outputs as the separation objective under the\nconstraint that the outputs are restricted to their presumed sets. The online\nformulation of this optimization problem naturally leads to neural networks\nwith local learning rules. Our framework incorporates infinitely many source\ndomain choices and flexibly models complex latent structures. Choices of\nsimplex or polytopic source domains result in networks with piecewise-linear\nactivation functions. We provide numerical examples to demonstrate the superior\ncorrelated source separation capability for both synthetic and natural sources.",
    "descriptor": "\nComments: Preprint, 32 pages\n",
    "authors": [
      "Bariscan Bozkurt",
      "Ates Isfendiyaroglu",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04222"
  },
  {
    "id": "arXiv:2210.04223",
    "title": "Market Directional Information Derived From (Time, Execution Price,  Shares Traded) Sequence of Transactions. On The Impact From The Future",
    "abstract": "An attempt to obtain market directional information from non-stationary\nsolution of the dynamic equation: \"future price tends to the value maximizing\nthe number of shares traded per unit time\" is presented. A remarkable feature\nof the approach is an automatic time scale selection. It is determined from the\nstate of maximal execution flow calculated on past transactions. Both lagging\nand advancing prices are calculated.",
    "descriptor": "",
    "authors": [
      "Vladislav Gennadievich Malyshkin",
      "Mikhail Gennadievich Belov"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Numerical Analysis (math.NA)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2210.04223"
  },
  {
    "id": "arXiv:2210.04248",
    "title": "Residual Neural Networks for the Prediction of Planetary Collision  Outcomes",
    "abstract": "Fast and accurate treatment of collisions in the context of modern N-body\nplanet formation simulations remains a challenging task due to inherently\ncomplex collision processes. We aim to tackle this problem with machine\nlearning (ML), in particular via residual neural networks. Our model is\nmotivated by the underlying physical processes of the data-generating process\nand allows for flexible prediction of post-collision states. We demonstrate\nthat our model outperforms commonly used collision handling methods such as\nperfect inelastic merging and feed-forward neural networks in both prediction\naccuracy and out-of-distribution generalization. Our model outperforms the\ncurrent state of the art in 20/24 experiments. We provide a dataset that\nconsists of 10164 Smooth Particle Hydrodynamics (SPH) simulations of pairwise\nplanetary collisions. The dataset is specifically suited for ML research to\nimprove computational aspects for collision treatment and for studying\nplanetary collisions in general. We formulate the ML task as a multi-task\nregression problem, allowing simple, yet efficient training of ML models for\ncollision treatment in an end-to-end manner. Our models can be easily\nintegrated into existing N-body frameworks and can be used within our chosen\nparameter space of initial conditions, i.e. where similar-sized collisions\nduring late-stage terrestrial planet formation typically occur.",
    "descriptor": "\nComments: 13 pages, 7 figures, 7 tables\n",
    "authors": [
      "Philip M. Winter",
      "Christoph Burger",
      "Sebastian Lehner",
      "Johannes Kofler",
      "Thomas I. Maindl",
      "Christoph M. Sch\u00e4fer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04248"
  },
  {
    "id": "arXiv:2210.04253",
    "title": "A Concentration Bound for Distributed Stochastic Approximation",
    "abstract": "We revisit the classical model of Tsitsiklis, Bertsekas and Athans for\ndistributed stochastic approximation with consensus. The main result is an\nanalysis of this scheme using the ODE approach to stochastic approximation,\nleading to a high probability bound for the tracking error between suitably\ninterpolated iterates and the limiting differential equation. Several future\ndirections will also be highlighted.",
    "descriptor": "",
    "authors": [
      "Harsh Dolhare",
      "Vivek Borkar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.04253"
  },
  {
    "id": "arXiv:2210.04257",
    "title": "Memristive Ising Circuits",
    "abstract": "The Ising model is of prime importance in the field of statistical mechanics.\nHere we show that Ising-type interactions can be realized in\nperiodically-driven circuits of stochastic binary resistors with memory. A key\nfeature of our realization is the simultaneous co-existence of ferromagnetic\nand antiferromagnetic interactions between two neighboring spins -- an\nextraordinary property not available in nature. We demonstrate that the\nstatistics of circuit states may perfectly match the ones found in the Ising\nmodel with ferromagnetic or antiferromagnetic interactions, and, importantly,\nthe corresponding Ising model parameters can be extracted from the\nprobabilities of circuit states. Using this finding, the Ising Hamiltonian is\nre-constructed in several model cases, and it is shown that different types of\ninteraction can be realized in circuits of stochastic memristors.",
    "descriptor": "",
    "authors": [
      "V. J. Dowling",
      "Y. V. Pershin"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.04257"
  },
  {
    "id": "arXiv:2210.04269",
    "title": "Data-driven framework for input/output lookup tables reduction -- with  application to hypersonic flows in chemical non-equilibrium",
    "abstract": "In this paper, we present a novel model-agnostic machine learning technique\nto extract a reduced thermochemical model for reacting hypersonic flows\nsimulation. A first simulation gathers all relevant thermodynamic states and\nthe corresponding gas properties via a given model. The states are embedded in\na low-dimensional space and clustered to identify regions with different levels\nof thermochemical (non)-equilibrium. Then, a surrogate surface from the reduced\ncluster-space to the output space is generated using radial-basis-function\nnetworks. The method is validated and benchmarked on a simulation of a\nhypersonic flat-plate boundary layer with finite-rate chemistry. The gas\nproperties of the reactive air mixture are initially modeled using the\nopen-source Mutation++ library. Substituting Mutation++ with the light-weight,\nmachine-learned alternative improves the performance of the solver by 50% while\nmaintaining overall accuracy.",
    "descriptor": "\nComments: 24 pages, 16 figures, 2 tables\n",
    "authors": [
      "Cl\u00e9ment Scherding",
      "Georgios Rigas",
      "Denis Sipp",
      "Peter J. Schmid",
      "Taraneh Sayadi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04269"
  },
  {
    "id": "arXiv:2210.04285",
    "title": "Improved Abdominal Multi-Organ Segmentation via 3D Boundary-Constrained  Deep Neural Networks",
    "abstract": "Quantitative assessment of the abdominal region from clinically acquired CT\nscans requires the simultaneous segmentation of abdominal organs. Thanks to the\navailability of high-performance computational resources, deep learning-based\nmethods have resulted in state-of-the-art performance for the segmentation of\n3D abdominal CT scans. However, the complex characterization of organs with\nfuzzy boundaries prevents the deep learning methods from accurately segmenting\nthese anatomical organs. Specifically, the voxels on the boundary of organs are\nmore vulnerable to misprediction due to the highly-varying intensity of\ninter-organ boundaries. This paper investigates the possibility of improving\nthe abdominal image segmentation performance of the existing 3D encoder-decoder\nnetworks by leveraging organ-boundary prediction as a complementary task. To\naddress the problem of abdominal multi-organ segmentation, we train the 3D\nencoder-decoder network to simultaneously segment the abdominal organs and\ntheir corresponding boundaries in CT scans via multi-task learning. The network\nis trained end-to-end using a loss function that combines two task-specific\nlosses, i.e., complete organ segmentation loss and boundary prediction loss. We\nexplore two different network topologies based on the extent of weights shared\nbetween the two tasks within a unified multi-task framework. To evaluate the\nutilization of complementary boundary prediction task in improving the\nabdominal multi-organ segmentation, we use three state-of-the-art\nencoder-decoder networks: 3D UNet, 3D UNet++, and 3D Attention-UNet. The\neffectiveness of utilizing the organs' boundary information for abdominal\nmulti-organ segmentation is evaluated on two publically available abdominal CT\ndatasets. A maximum relative improvement of 3.5% and 3.6% is observed in Mean\nDice Score for Pancreas-CT and BTCV datasets, respectively.",
    "descriptor": "\nComments: 15 pages, 16 figures, journal paper\n",
    "authors": [
      "Samra Irshad",
      "Douglas P.S. Gomes",
      "Seong Tae Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04285"
  },
  {
    "id": "arXiv:2210.04295",
    "title": "Absolute Minima of Potentials of Certain Regular Spherical  Configurations",
    "abstract": "We use methods of approximation theory to find the absolute minima on the\nsphere of the potential of spherical $(2m-3)$-designs with a non-trivial index\n$2m$ that are contained in a union of $m$ parallel hyperplanes, $m\\geq 2$,\nwhose locations satisfy certain additional assumptions. The interaction between\npoints is described by a function of the dot product, which has positive\nderivatives of orders $2m-2$, $2m-1$, and $2m$. This includes the case of the\nclassical Coulomb, Riesz, and logarithmic potentials as well as a completely\nmonotone potential of the distance squared. We illustrate this result by\nshowing that the absolute minimum of the potential of the set of vertices of\nthe icosahedron on the unit sphere $S^2$ in $\\mathbb R^3$ is attained at the\nvertices of the dual dodecahedron and the one for the set of vertices of the\ndodecahedron is attained at the vertices of the dual icosahedron. The absolute\nminimum of the potential of the configuration of $240$ minimal vectors of $E_8$\nroot lattice normalized to lie on the unit sphere $S^7$ in $\\mathbb R^8$ is\nattained at a set of $2160$ points on $S^7$ which we describe.",
    "descriptor": "",
    "authors": [
      "Sergiy Borodachov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04295"
  },
  {
    "id": "arXiv:2210.04318",
    "title": "Prediction interval for neural network models using weighted asymmetric  loss functions",
    "abstract": "We develop a novel and simple method to produce prediction intervals (PIs)\nfor fitting and forecasting exercises. It finds the lower and upper bound of\nthe intervals by minimising a weighted asymmetric loss function, where the\nweight depends on the width of the interval. We give a short mathematical\nproof. As a corollary of our proof, we find PIs for values restricted to a\nparameterised function and argue why the method works for predicting PIs of\ndependent variables. The results of applying the method on a neural network\ndeployed in a real-world forecasting task prove the validity of its practical\nimplementation in complex machine learning setups.",
    "descriptor": "\nComments: 14 pages, 4 figures, not submitted for conference yet as of 09-10-2022\n",
    "authors": [
      "Milo Grillo",
      "Agnieszka Werpachowska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04318"
  },
  {
    "id": "arXiv:2210.04334",
    "title": "QuTE: decentralized multiple testing on sensor networks with false  discovery rate control",
    "abstract": "This paper designs methods for decentralized multiple hypothesis testing on\ngraphs that are equipped with provable guarantees on the false discovery rate\n(FDR). We consider the setting where distinct agents reside on the nodes of an\nundirected graph, and each agent possesses p-values corresponding to one or\nmore hypotheses local to its node. Each agent must individually decide whether\nto reject one or more of its local hypotheses by only communicating with its\nneighbors, with the joint aim that the global FDR over the entire graph must be\ncontrolled at a predefined level. We propose a simple decentralized family of\nQuery-Test-Exchange (QuTE) algorithms and prove that they can control FDR under\nindependence or positive dependence of the p-values. Our algorithm reduces to\nthe Benjamini-Hochberg (BH) algorithm when after graph-diameter rounds of\ncommunication, and to the Bonferroni procedure when no communication has\noccurred or the graph is empty. To avoid communicating real-valued p-values, we\ndevelop a quantized BH procedure, and extend it to a quantized QuTE procedure.\nQuTE works seamlessly in streaming data settings, where anytime-valid p-values\nmay be continually updated at each node. Last, QuTE is robust to arbitrary\ndropping of packets, or a graph that changes at every step, making it\nparticularly suitable to mobile sensor networks involving drones or other\nmulti-agent systems. We study the power of our procedure using a simulation\nsuite of different levels of connectivity and communication on a variety of\ngraph structures, and also provide an illustrative real-world example.",
    "descriptor": "\nComments: This paper appeared in the IEEE CDC'17 conference proceedings. The last two sections were then developed in 2018, and it is now being put on arXiv simply for easier access\n",
    "authors": [
      "Aaditya Ramdas",
      "Jianbo Chen",
      "Martin J. Wainwright",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.04334"
  },
  {
    "id": "arXiv:2210.04339",
    "title": "Seller-buyer networks in NFT art are driven by preferential ties",
    "abstract": "Non-Fungible Tokens (NFTs) have recently surged to mainstream attention by\nallowing the exchange of digital assets via blockchains. NFTs have also been\nadopted by artists to sell digital art. One of the promises of NFTs is\nbroadening participation to the arts market, a traditionally closed and opaque\nsystem, to sustain a wider and more diverse set of artists and collectors. A\nkey sign of this effect would be the disappearance or at least reduction in\nimportance of seller-buyer preferential ties, whereby the success of an artist\nis strongly dependent on the patronage of a single collector. We investigate\nNFT art seller-buyer networks considering several galleries and a large set of\nnearly 40,000 sales for over 230M USD in total volume. We find that NFT art is\na highly concentrated market driven by few successful sellers and even fewer\nsystematic buyers. High concentration is present in both the number of sales\nand, even more strongly, in their priced volume. Furthermore, we show that,\nwhile a broader-participation market was present in the early phase of NFT art\nadoption, preferential ties have dominated during market growth, peak and\nrecent decline. We consistently find that the top buyer accounts on average for\nover 80% of buys for a given seller. Similar trends apply to buyers and their\ntop seller. We conclude that NFT art constitutes, at the present, a highly\nconcentrated market driven by preferential seller-buyer ties.",
    "descriptor": "",
    "authors": [
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04339"
  },
  {
    "id": "arXiv:2210.04361",
    "title": "Iterative Convex Optimization for Model Predictive Control with  Discrete-Time High-Order Control Barrier Functions",
    "abstract": "Safety is one of the fundamental challenges in control theory. Recently,\nmulti-step optimal control problems for discrete-time dynamical systems were\nformulated to enforce stability, while subject to input constraints as well as\nsafety-critical requirements using discrete-time control barrier functions\nwithin a model predictive control (MPC) framework. Existing work usually focus\non the feasibility or the safety for the optimization problem, and the majority\nof the existing work restrict the discussions to relative-degree one for\ncontrol barrier function. Additionally, the real-time computation is\nchallenging when a large horizon is considered in the MPC problem for\nrelative-degree one or high-order control barrier functions. In this paper, we\npropose a framework that solves the safety-critical MPC problem in an iterative\noptimization, which is applicable for any relative-degree control barrier\nfunctions. In the proposed formulation, the nonlinear system dynamics as well\nas the safety constraints modeled as discrete-time high-order control barrier\nfunctions (DHOCBF) are linearized at each time step. Our formulation is\ngenerally valid for any control barrier function with an arbitrary\nrelative-degree. The advantages of fast computational performance with safety\nguarantee are analyzed and validated with numerical results.",
    "descriptor": "",
    "authors": [
      "Shuo Liu",
      "Jun Zeng",
      "Koushil Sreenath",
      "Calin A. Belta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.04361"
  },
  {
    "id": "arXiv:2210.04371",
    "title": "A Detailed Study of Interpretability of Deep Neural Network based Top  Taggers",
    "abstract": "Recent developments in the methods of explainable AI (xAI) methods allow us\nto explore the inner workings of deep neural networks (DNNs), revealing crucial\ninformation about input-output relationships and realizing how data connects\nwith machine learning models. In this paper we explore interpretability of DNN\nmodels designed for identifying jets coming from top quark decay in the high\nenergy proton-proton collisions at the Large Hadron Collider (LHC). We review a\nsubset of existing such top tagger models and explore different quantitative\nmethods to identify which features play the most important roles in identifying\nthe top jets. We also investigate how and why feature importance varies across\ndifferent xAI metrics, how feature correlations impact their explainability,\nand how latent space representations encode information as well as correlate\nwith physically meaningful quantities. Our studies uncover some major pitfalls\nof existing xAI methods and illustrate how they can be overcome to obtain\nconsistent and meaningful interpretation of these models. We additionally\nillustrate the activity of hidden layers as Neural Activation Pattern (NAP)\ndiagrams and demonstrate how they can be used to understand how DNNs relay\ninformation across the layers and how this understanding can help us to make\nsuch models significantly simpler by allowing effective model reoptimization\nand hyperparameter tuning. While the primary focus of this work remains a\ndetailed study of interpretability of DNN-based top tagger models, it also\nfeatures state-of-the art performance obtained from modified implementation of\nexisting networks.",
    "descriptor": "\nComments: Repository: this https URL\n",
    "authors": [
      "Ayush Khot",
      "Mark S. Neubauer",
      "Avik Roy"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04371"
  },
  {
    "id": "arXiv:2210.04389",
    "title": "DeepMed: Semiparametric Causal Mediation Analysis with Debiased Deep  Learning",
    "abstract": "Causal mediation analysis can unpack the black box of causality and is\ntherefore a powerful tool for disentangling causal pathways in biomedical and\nsocial sciences, and also for evaluating machine learning fairness. To reduce\nbias for estimating Natural Direct and Indirect Effects in mediation analysis,\nwe propose a new method called DeepMed that uses deep neural networks (DNNs) to\ncross-fit the infinite-dimensional nuisance functions in the efficient\ninfluence functions. We obtain novel theoretical results that our DeepMed\nmethod (1) can achieve semiparametric efficiency bound without imposing\nsparsity constraints on the DNN architecture and (2) can adapt to certain low\ndimensional structures of the nuisance functions, significantly advancing the\nexisting literature on DNN-based semiparametric causal inference. Extensive\nsynthetic experiments are conducted to support our findings and also expose the\ngap between theory and practice. As a proof of concept, we apply DeepMed to\nanalyze two real datasets on machine learning fairness and reach conclusions\nconsistent with previous findings.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Siqi Xu",
      "Lin Liu",
      "Zhonghua Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.04389"
  },
  {
    "id": "arXiv:2210.04422",
    "title": "Expertise diversity of teams predicts originality and long-term impact  in science and technology",
    "abstract": "Despite the growing importance of teams in producing innovative and\nhigh-impact science and technology, it remains unclear how expertise diversity\namong team members relates to the originality and impact of the work they\nproduce. Here, we develop a new method to quantify the expertise distance of\nresearchers based on their prior career histories and apply it to 23 million\nscientific publications and 4 million patents. We find that across science and\ntechnology, expertise-diverse teams tend to produce work with greater\noriginality. Teams with more diverse expertise have no significant impact\nadvantage in the short- (2 years) or mid-term (5 years). Instead, they exhibit\nsubstantially higher long-term impact (10 years), increasingly attracting\nlarger cross-disciplinary influence. This impact premium of expertise diversity\namong team members becomes especially pronounced when other dimensions of team\ndiversity are missing, as teams within the same institution or country appear\nto disproportionately reap the benefits of expertise diversity. While\ngender-diverse teams have relatively higher impact on average, teams with\nvaried levels of gender diversity all seem to benefit from increased expertise\ndiversity. Given the growing knowledge demands on individual researchers,\nimplementation of incentives for original research, and the tradeoffs between\nshort-term and long-term impacts, these results may have implications for\nfunding, assembling, and retaining teams with originality and long-lasting\nimpacts.",
    "descriptor": "\nComments: 31 pages, 5 figures\n",
    "authors": [
      "Hongwei Zheng",
      "Weihua Li",
      "Dashun Wang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.04422"
  },
  {
    "id": "arXiv:2210.04429",
    "title": "DeepHS-HDRVideo: Deep High Speed High Dynamic Range Video Reconstruction",
    "abstract": "Due to hardware constraints, standard off-the-shelf digital cameras suffers\nfrom low dynamic range (LDR) and low frame per second (FPS) outputs. Previous\nworks in high dynamic range (HDR) video reconstruction uses sequence of\nalternating exposure LDR frames as input, and align the neighbouring frames\nusing optical flow based networks. However, these methods often result in\nmotion artifacts in challenging situations. This is because, the alternate\nexposure frames have to be exposure matched in order to apply alignment using\noptical flow. Hence, over-saturation and noise in the LDR frames results in\ninaccurate alignment. To this end, we propose to align the input LDR frames\nusing a pre-trained video frame interpolation network. This results in better\nalignment of LDR frames, since we circumvent the error-prone exposure matching\nstep, and directly generate intermediate missing frames from the same exposure\ninputs. Furthermore, it allows us to generate high FPS HDR videos by\nrecursively interpolating the intermediate frames. Through this work, we\npropose to use video frame interpolation for HDR video reconstruction, and\npresent the first method to generate high FPS HDR videos. Experimental results\ndemonstrate the efficacy of the proposed framework against optical flow based\nalignment methods, with an absolute improvement of 2.4 PSNR value on standard\nHDR video datasets [1], [2] and further benchmark our method for high FPS HDR\nvideo generation.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Zeeshan Khan",
      "Parth Shettiwar",
      "Mukul Khanna",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04429"
  },
  {
    "id": "arXiv:2210.04431",
    "title": "Scientific Machine Learning for Modeling and Simulating Complex Fluids",
    "abstract": "The formulation of rheological constitutive equations -- models that relate\ninternal stresses and deformations in complex fluids -- is a critical step in\nthe engineering of systems involving soft materials. While data-driven models\nprovide accessible alternatives to expensive first-principles models and less\naccurate empirical models in many engineering disciplines, the development of\nsimilar models for complex fluids has lagged. The diversity of techniques for\ncharacterizing non-Newtonian fluid dynamics creates a challenge for classical\nmachine learning approaches, which require uniformly structured training data.\nConsequently, early machine learning constitutive equations have not been\nportable between different deformation protocols or mechanical observables.\nHere, we present a data-driven framework that resolves such issues, allowing\nrheologists to construct learnable models that incorporate essential physical\ninformation, while remaining agnostic to details regarding particular\nexperimental protocols or flow kinematics. These scientific machine learning\nmodels incorporate a universal approximator within a materially objective\ntensorial constitutive framework. By construction, these models respect\nphysical constraints, such as frame-invariance and tensor symmetry, required by\ncontinuum mechanics. We demonstrate that this framework facilitates the rapid\ndiscovery of accurate constitutive equations from limited data, and that the\nlearned models may be used to describe more kinematically complex flows. This\ninherent flexibility admits the application of these 'digital fluid twins' to a\nrange of material systems and engineering problems. We illustrate this\nflexibility by deploying a trained model within a multidimensional\ncomputational fluid dynamics simulation -- a task that is not achievable using\nany previously developed data-driven rheological equation of state.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Kyle R. Lennon",
      "Gareth H. McKinley",
      "James W. Swan"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04431"
  },
  {
    "id": "arXiv:2210.04433",
    "title": "Taming \"McKinsey-like\" formula: An Extended Correspondence and  Completeness Theory for Hybrid Logic H(@)",
    "abstract": "In the present article, we extend the fragment of inductive formulas for the\nhybrid language L(@) in [8] including a McKinsey-like formula, and show that\nevery formula in the extended class has a first-order correspondent, by\nmodifying the algorithm hybrid-ALBA in [8]. We also identify a subclass of this\nextended inductive fragment, namely the extended skeletal formulas, which\nextend the class of skeletal formulas in [8], each formula in which axiomatize\na complete hybrid logic. Our proof method here is proof-theoretic, following\n[10, 19] and [3, Chapter 14], in contrast to the algebraic proof in [8].",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.01288\n",
    "authors": [
      "Zhiguang Zhao"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.04433"
  },
  {
    "id": "arXiv:2210.04502",
    "title": "A Reunion of Godel, Tarski, Carnap, and Rosser",
    "abstract": "We unify Godel's First Incompleteness Theorem (1931), Tarski's Undefinability\nTheorem (1933), Godel-Carnap's Diagonal Lemma (1934), and Rosser's\n(strengthening of Godel's first) Incompleteness Theorem (1936), whose proofs\nresemble much and use almost the same technique.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Saeed Salehi"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.04502"
  },
  {
    "id": "arXiv:2210.04508",
    "title": "Scale Equivariant U-Net",
    "abstract": "In neural networks, the property of being equivariant to transformations\nimproves generalization when the corresponding symmetry is present in the data.\nIn particular, scale-equivariant networks are suited to computer vision tasks\nwhere the same classes of objects appear at different scales, like in most\nsemantic segmentation tasks. Recently, convolutional layers equivariant to a\nsemigroup of scalings and translations have been proposed. However, the\nequivariance of subsampling and upsampling has never been explicitly studied\neven though they are necessary building blocks in some segmentation\narchitectures. The U-Net is a representative example of such architectures,\nwhich includes the basic elements used for state-of-the-art semantic\nsegmentation. Therefore, this paper introduces the Scale Equivariant U-Net\n(SEU-Net), a U-Net that is made approximately equivariant to a semigroup of\nscales and translations through careful application of subsampling and\nupsampling layers and the use of aforementioned scale-equivariant layers.\nMoreover, a scale-dropout is proposed in order to improve generalization to\ndifferent scales in approximately scale-equivariant architectures. The proposed\nSEU-Net is trained for semantic segmentation of the Oxford Pet IIIT and the\nDIC-C2DH-HeLa dataset for cell segmentation. The generalization metric to\nunseen scales is dramatically improved in comparison to the U-Net, even when\nthe U-Net is trained with scale jittering, and to a scale-equivariant\narchitecture that does not perform upsampling operators inside the equivariant\npipeline. The scale-dropout induces better generalization on the\nscale-equivariant models in the Pet experiment, but not on the cell\nsegmentation experiment.",
    "descriptor": "",
    "authors": [
      "Mateus Sangalli",
      "Samy Blusseau",
      "Santiago Velasco-Forero",
      "Jesus Angulo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04508"
  },
  {
    "id": "arXiv:2210.04520",
    "title": "Continual task learning in natural and artificial agents",
    "abstract": "How do humans and other animals learn new tasks? A wave of brain recording\nstudies has investigated how neural representations change during task\nlearning, with a focus on how tasks can be acquired and coded in ways that\nminimise mutual interference. We review recent work that has explored the\ngeometry and dimensionality of neural task representations in neocortex, and\ncomputational models that have exploited these findings to understand how the\nbrain may partition knowledge between tasks. We discuss how ideas from machine\nlearning, including those that combine supervised and unsupervised learning,\nare helping neuroscientists understand how natural tasks are learned and coded\nin biological brains.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Timo Flesch",
      "Andrew Saxe",
      "Christopher Summerfield"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04520"
  },
  {
    "id": "arXiv:2210.04621",
    "title": "Calibrating AI Models for Few-Shot Demodulation via Conformal Prediction",
    "abstract": "AI tools can be useful to address model deficits in the design of\ncommunication systems. However, conventional learning-based AI algorithms yield\npoorly calibrated decisions, unabling to quantify their outputs uncertainty.\nWhile Bayesian learning can enhance calibration by capturing epistemic\nuncertainty caused by limited data availability, formal calibration guarantees\nonly hold under strong assumptions about the ground-truth, unknown, data\ngeneration mechanism. We propose to leverage the conformal prediction framework\nto obtain data-driven set predictions whose calibration properties hold\nirrespective of the data distribution. Specifically, we investigate the design\nof baseband demodulators in the presence of hard-to-model nonlinearities such\nas hardware imperfections, and propose set-based demodulators based on\nconformal prediction. Numerical results confirm the theoretical validity of the\nproposed demodulators, and bring insights into their average prediction set\nsize efficiency.",
    "descriptor": "\nComments: Submitted for a conference publication\n",
    "authors": [
      "Kfir M. Cohen",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.04621"
  },
  {
    "id": "arXiv:2210.04629",
    "title": "Investigation of inverse design of multilayer thin-films with  conditional invertible Neural Networks",
    "abstract": "The task of designing optical multilayer thin-films regarding a given target\nis currently solved using gradient-based optimization in conjunction with\nmethods that can introduce additional thin-film layers. Recently, Deep Learning\nand Reinforcement Learning have been been introduced to the task of designing\nthin-films with great success, however a trained network is usually only able\nto become proficient for a single target and must be retrained if the optical\ntargets are varied. In this work, we apply conditional Invertible Neural\nNetworks (cINN) to inversely designing multilayer thin-films given an optical\ntarget. Since the cINN learns the energy landscape of all thin-film\nconfigurations within the training dataset, we show that cINNs can generate a\nstochastic ensemble of proposals for thin-film configurations that that are\nreasonably close to the desired target depending only on random variables. By\nrefining the proposed configurations further by a local optimization, we show\nthat the generated thin-films reach the target with significantly greater\nprecision than comparable state-of-the art approaches. Furthermore, we tested\nthe generative capabilities on samples which are outside the training data\ndistribution and found that the cINN was able to predict thin-films for\nout-of-distribution targets, too. The results suggest that in order to improve\nthe generative design of thin-films, it is instructive to use established and\nnew machine learning methods in conjunction in order to obtain the most\nfavorable results.",
    "descriptor": "",
    "authors": [
      "Alexander Luce",
      "Ali Mahdavi",
      "Heribert Wankerl",
      "Florian Marquardt"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04629"
  },
  {
    "id": "arXiv:2210.04635",
    "title": "FaDIn: Fast Discretized Inference for Hawkes Processes with General  Parametric Kernels",
    "abstract": "Temporal point processes (TPP) are a natural tool for modeling event-based\ndata. Among all TPP models, Hawkes processes have proven to be the most widely\nused, mainly due to their simplicity and computational ease when considering\nexponential or non-parametric kernels. Although non-parametric kernels are an\noption, such models require large datasets. While exponential kernels are more\ndata efficient and relevant for certain applications where events immediately\ntrigger more events, they are ill-suited for applications where latencies need\nto be estimated, such as in neuroscience. This work aims to offer an efficient\nsolution to TPP inference using general parametric kernels with finite support.\nThe developed solution consists of a fast L2 gradient-based solver leveraging a\ndiscretized version of the events. After supporting the use of discretization\ntheoretically, the statistical and computational efficiency of the novel\napproach is demonstrated through various numerical experiments. Finally, the\neffectiveness of the method is evaluated by modeling the occurrence of\nstimuli-induced patterns from brain signals recorded with\nmagnetoencephalography (MEG). Given the use of general parametric kernels,\nresults show that the proposed approach leads to a more plausible estimation of\npattern latency compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "C\u00e9dric Allain",
      "Alexandre Gramfort",
      "Thomas Moreau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04635"
  },
  {
    "id": "arXiv:2210.04636",
    "title": "Classifying topoi in synthetic guarded domain theory",
    "abstract": "Several different topoi have played an important role in the development and\napplications of synthetic guarded domain theory (SGDT), a new kind of synthetic\ndomain theory that abstracts the concept of guarded recursion frequently\nemployed in the semantics of programming languages. In order to unify the\naccounts of guarded recursion and coinduction, several authors have enriched\nSGDT with multiple \"clocks\" parameterizing different time-streams, leading to\nmore complex and difficult to understand topos models. Until now these topoi\nhave been understood very concretely qua categories of presheaves, and the\nlogico-geometrical question of what theories these topoi classify has remained\nopen. We show that several important topos models of SGDT classify very simple\ngeometric theories, and that the passage to various forms of multi-clock\nguarded recursion can be rephrased more compositionally in terms of the lower\nbagtopos construction of Vickers and variations thereon due to Johnstone. We\ncontribute to the consolidation of SGDT by isolating the universal property of\nmulti-clock guarded recursion as a modular construction that applies to any\ntopos model of single-clock guarded recursion.",
    "descriptor": "\nComments: To appear in the proceedings of the 38th International Conference on Mathematical Foundations of Programming Semantics (MFPS 2022)\n",
    "authors": [
      "Daniele Palombi",
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.04636"
  },
  {
    "id": "arXiv:2210.04649",
    "title": "Locally irregular edge-coloring of subcubic graphs",
    "abstract": "A graph is {\\em locally irregular} if no two adjacent vertices have the same\ndegree. A {\\em locally irregular edge-coloring} of a graph $G$ is such an\n(improper) edge-coloring that the edges of any fixed color induce a locally\nirregular graph. Among the graphs admitting a locally irregular edge-coloring,\ni.e., {\\em decomposable graphs}, only one is known to require $4$ colors, while\nfor all the others it is believed that $3$ colors suffice. In this paper, we\nprove that decomposable claw-free graphs with maximum degree $3$, all cycle\npermutation graphs, and all generalized Petersen graphs admit a locally\nirregular edge-coloring with at most $3$ colors. We also discuss when $2$\ncolors suffice for a locally irregular edge-coloring of cubic graphs and\npresent an infinite family of cubic graphs of girth $4$ which require $3$\ncolors.",
    "descriptor": "",
    "authors": [
      "Borut Lu\u017ear",
      "M\u00e1ria Macekov\u00e1",
      "Simona Rindo\u0161ov\u00e1",
      "Roman Sot\u00e1k",
      "Katar\u00edna Srokov\u00e1",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.04649"
  },
  {
    "id": "arXiv:2210.04653",
    "title": "Rejecting noise in Baikal-GVD data with neural networks",
    "abstract": "Baikal-GVD is a large ($\\sim$ 1 km$^3$) underwater neutrino telescope\ninstalled in the fresh waters of Lake Baikal. The deep lake water environment\nis pervaded by background light, which produces detectable signals in the\nBaikal-GVD photosensors. We introduce a neural network for an efficient\nseparation of these noise hits from the signal ones, stemming from the\npropagation of relativistic particles through the detector. The neural network\nhas a U-net like architecture and employs temporal (causal) structure of\nevents. On Monte-Carlo simulated data, it reaches 99% signal purity (precision)\nand 98% survival efficiency (recall). The benefits of using neural network for\ndata analysis are discussed, and other possible architectures of neural\nnetworks, including graph based, are examined.",
    "descriptor": "",
    "authors": [
      "I. Kharuk",
      "G. Rubtsov",
      "G. Safronov"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04653"
  },
  {
    "id": "arXiv:2210.04664",
    "title": "Depth-First Grover Search Algorithm on Hybrid Quantum-Classical Computer",
    "abstract": "We demonstrated the detailed construction of the hybrid quantum-classical\ncomputer. Based on this architecture, the useful concept of amplitude\ninterception is illustrated. It is then embedded into a combination of\nDepth-First Search and Grover's algorithm to generate a novel approach, the\nDepth-First Grover Search(DFGS), to handle multi-solution searching problems on\nunstructured databases with an unknown number of solutions. Our new algorithm\nattains an average complexity of $\\mathcal{O}(m\\sqrt{N})$ which performs as\nefficient as a normal Grover Search, and a $\\mathcal{O}(\\sqrt{p}N)$ complexity\nwith a manually determined constant $p$ for the case with all elements are\nsolutions, where a normal Grover Search will degenerate to\n$\\mathcal{O}(N\\sqrt{N})$. The DFGS algorithm is more robust and stable in\ncomparison.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Haoxiang Guo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.04664"
  },
  {
    "id": "arXiv:2210.04669",
    "title": "Spanning trees of smallest maximum degree in subdivisions of graphs",
    "abstract": "\\newcommand{\\subdG}[1][G]{#1^\\star}\nGiven a graph $G$ and a positive integer $k$, we study the question whether\n$G^\\star$ has a spanning tree of maximum degree at most $k$ where $G^\\star$ is\nthe graph that is obtained from $G$ by subdividing every edge once. Using\nmatroid intersection, we obtain a polynomial algorithm for this problem and a\ncharacterization of its positive instances. We use this characterization to\nshow that $G^\\star$ has a spanning tree of bounded maximum degree if $G$ is\ncontained in some particular graph class. We study the class of 3-connected\ngraphs which are embeddable in a fixed surface and the class of\n$(p-1)$-connected $K_p$-minor-free graphs for a fixed integer $p$. We also give\ntightness examples for most of these classes.",
    "descriptor": "",
    "authors": [
      "Christoph Brause",
      "Jochen Harant",
      "Florian H\u00f6rsch",
      "Samuel Mohr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.04669"
  },
  {
    "id": "arXiv:2210.04757",
    "title": "On the Performance of Gradient Tracking with Local Updates",
    "abstract": "We study the decentralized optimization problem where a network of $n$ agents\nseeks to minimize the average of a set of heterogeneous non-convex cost\nfunctions distributedly. State-of-the-art decentralized algorithms like Exact\nDiffusion~(ED) and Gradient Tracking~(GT) involve communicating every\niteration. However, communication is expensive, resource intensive, and slow.\nIn this work, we analyze a locally updated GT method (LU-GT), where agents\nperform local recursions before interacting with their neighbors. While local\nupdates have been shown to reduce communication overhead in practice, their\ntheoretical influence has not been fully characterized. We show LU-GT has the\nsame communication complexity as the Federated Learning setting but allows\narbitrary network topologies. In addition, we prove that the number of local\nupdates does not degrade the quality of the solution achieved by LU-GT.\nNumerical examples reveal that local updates can lower communication costs in\ncertain regimes (e.g., well-connected graphs).",
    "descriptor": "\nComments: 8 pages, 1 figure, submitted to ACC\n",
    "authors": [
      "Edward Duc Hien Nguyen",
      "Sulaiman A. Alghunaim",
      "Kun Yuan",
      "C\u00e9sar A. Uribe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04757"
  },
  {
    "id": "arXiv:2210.04767",
    "title": "Deep Learning Mixture-of-Experts Approach for Cytotoxic Edema Assessment  in Infants and Children",
    "abstract": "This paper presents a deep learning framework for image classification aimed\nat increasing predictive performance for Cytotoxic Edema (CE) diagnosis in\ninfants and children. The proposed framework includes two 3D network\narchitectures optimized to learn from two types of clinical MRI data , a trace\nDiffusion Weighted Image (DWI) and the calculated Apparent Diffusion\nCoefficient map (ADC). This work proposes a robust and novel solution based on\nvolumetric analysis of 3D images (using pixels from time slices) and 3D\nconvolutional neural network (CNN) models. While simple in architecture, the\nproposed framework shows significant quantitative results on the domain\nproblem. We use a dataset curated from a Childrens Hospital Colorado (CHCO)\npatient registry to report a predictive performance F1 score of 0.91 at\ndistinguishing CE patients from children with severe neurologic injury without\nCE. In addition, we perform analysis of our systems output to determine the\nassociation of CE with Abusive Head Trauma (AHT) , a type of traumatic brain\ninjury (TBI) associated with abuse , and overall functional outcome and in\nhospital mortality of infants and young children. We used two clinical\nvariables, AHT diagnosis and Functional Status Scale (FSS) score, to arrive at\nthe conclusion that CE is highly correlated with overall outcome and that\nfurther study is needed to determine whether CE is a biomarker of AHT. With\nthat, this paper introduces a simple yet powerful deep learning based solution\nfor automated CE classification. This solution also enables an indepth analysis\nof progression of CE and its correlation to AHT and overall neurologic outcome,\nwhich in turn has the potential to empower experts to diagnose and mitigate AHT\nduring early stages of a childs life.",
    "descriptor": "\nComments: 7 figures\n",
    "authors": [
      "Henok Ghebrechristos",
      "Stence Nicholas",
      "David Mirsky",
      "Gita Alaghband",
      "Manh Huynh",
      "Zackary Kromer",
      "Ligia Batista",
      "Brent ONeill",
      "Steven Moulton",
      "Daniel M.Lindberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04767"
  },
  {
    "id": "arXiv:2210.04797",
    "title": "DeepVol: Volatility Forecasting from High-Frequency Data with Dilated  Causal Convolutions",
    "abstract": "Volatility forecasts play a central role among equity risk measures. Besides\ntraditional statistical models, modern forecasting techniques, based on machine\nlearning, can readily be employed when treating volatility as a univariate,\ndaily time-series. However, econometric studies have shown that increasing the\nnumber of daily observations with high-frequency intraday data helps to improve\npredictions. In this work, we propose DeepVol, a model based on Dilated Causal\nConvolutions to forecast day-ahead volatility by using high-frequency data. We\nshow that the dilated convolutional filters are ideally suited to extract\nrelevant information from intraday financial data, thereby naturally mimicking\n(via a data-driven approach) the econometric models which incorporate realised\nmeasures of volatility into the forecast. This allows us to take advantage of\nthe abundance of intraday observations, helping us to avoid the limitations of\nmodels that use daily data, such as model misspecification or manually designed\nhandcrafted features, whose devise involves optimising the trade-off between\naccuracy and computational efficiency and makes models prone to lack of\nadaptation into changing circumstances. In our analysis, we use two years of\nintraday data from NASDAQ-100 to evaluate DeepVol's performance. The reported\nempirical results suggest that the proposed deep learning-based approach learns\nglobal features from high-frequency data, achieving more accurate predictions\nthan traditional methodologies, yielding to more appropriate risk measures.",
    "descriptor": "",
    "authors": [
      "Fernando Moreno-Pino",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2210.04797"
  },
  {
    "id": "arXiv:2210.04810",
    "title": "Towards a Theoretical Foundation of Policy Optimization for Learning  Control Policies",
    "abstract": "Gradient-based methods have been widely used for system design and\noptimization in diverse application domains. Recently, there has been a renewed\ninterest in studying theoretical properties of these methods in the context of\ncontrol and reinforcement learning. This article surveys some of the recent\ndevelopments on policy optimization, a gradient-based iterative approach for\nfeedback control synthesis, popularized by successes of reinforcement learning.\nWe take an interdisciplinary perspective in our exposition that connects\ncontrol theory, reinforcement learning, and large-scale optimization. We review\na number of recently-developed theoretical results on the optimization\nlandscape, global convergence, and sample complexity of gradient-based methods\nfor various continuous control problems such as the linear quadratic regulator\n(LQR), $\\mathcal{H}_\\infty$ control, risk-sensitive control, linear quadratic\nGaussian (LQG) control, and output feedback synthesis. In conjunction with\nthese optimization results, we also discuss how direct policy optimization\nhandles stability and robustness concerns in learning-based control, two main\ndesiderata in control engineering. We conclude the survey by pointing out\nseveral challenges and opportunities at the intersection of learning and\ncontrol.",
    "descriptor": "\nComments: To Appear in Annual Review of Control, Robotics, and Autonomous Systems\n",
    "authors": [
      "Bin Hu",
      "Kaiqing Zhang",
      "Na Li",
      "Mehran Mesbahi",
      "Maryam Fazel",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04810"
  },
  {
    "id": "arXiv:2210.04815",
    "title": "Truncated proposals for scalable and hassle-free simulation-based  inference",
    "abstract": "Simulation-based inference (SBI) solves statistical inverse problems by\nrepeatedly running a stochastic simulator and inferring posterior distributions\nfrom model-simulations. To improve simulation efficiency, several inference\nmethods take a sequential approach and iteratively adapt the proposal\ndistributions from which model simulations are generated. However, many of\nthese sequential methods are difficult to use in practice, both because the\nresulting optimisation problems can be challenging and efficient diagnostic\ntools are lacking. To overcome these issues, we present Truncated Sequential\nNeural Posterior Estimation (TSNPE). TSNPE performs sequential inference with\ntruncated proposals, sidestepping the optimisation issues of alternative\napproaches. In addition, TSNPE allows to efficiently perform coverage tests\nthat can scale to complex models with many parameters. We demonstrate that\nTSNPE performs on par with previous methods on established benchmark tasks. We\nthen apply TSNPE to two challenging problems from neuroscience and show that\nTSNPE can successfully obtain the posterior distributions, whereas previous\nmethods fail. Overall, our results demonstrate that TSNPE is an efficient,\naccurate, and robust inference method that can scale to challenging scientific\nmodels.",
    "descriptor": "",
    "authors": [
      "Michael Deistler",
      "Pedro J Goncalves",
      "Jakob H Macke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04815"
  },
  {
    "id": "arXiv:2210.04840",
    "title": "Rieoptax: Riemannian Optimization in JAX",
    "abstract": "We present Rieoptax, an open source Python library for Riemannian\noptimization in JAX. We show that many differential geometric primitives, such\nas Riemannian exponential and logarithm maps, are usually faster in Rieoptax\nthan existing frameworks in Python, both on CPU and GPU. We support various\nrange of basic and advanced stochastic optimization solvers like Riemannian\nstochastic gradient, stochastic variance reduction, and adaptive gradient\nmethods. A distinguishing feature of the proposed toolbox is that we also\nsupport differentially private optimization on Riemannian manifolds.",
    "descriptor": "",
    "authors": [
      "Saiteja Utpala",
      "Andi Han",
      "Pratik Jawanpuria",
      "Bamdev Mishra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2210.04840"
  },
  {
    "id": "arXiv:2210.04856",
    "title": "A Posteriori Error Estimate and Adaptivity for QM/MM Models of  Crystalline Defects",
    "abstract": "Hybrid quantum/molecular mechanics models (QM/MM methods) are widely used in\nmaterial and molecular simulations when pure MM models cannot ensure adequate\naccuracy but pure QM models are computationally prohibitive. Adaptive QM/MM\ncoupling methods feature on-the-fly classification of atoms, allowing the QM\nand MM subsystems to be updated as needed. The state-of-art \"machine-learned\ninteratomic potentials (MLIPs)\" can be applied as the MM models for consistent\nQM/MM methods with rigorously justified accuracy. In this work, we propose a\nrobust adaptive QM/MM method for practical material defect simulation, which is\nbased on a developed residual-based error estimator. The error estimator\nprovides both upper and lower bounds for the approximation error, demonstrating\nits reliability and efficiency. In particular, we introduce three minor\napproximations such that the error estimator can be evaluated efficiently\nwithout losing much accuracy. To update the QM/MM partitions anisotropically, a\nnovel adaptive algorithm is proposed, where a free interface motion problem\nbased on the proposed error estimator is solved by employing the fast marching\nmethod. We implement and validate the robustness of the adaptive algorithm on\nnumerical simulations for various complex crystalline defects.",
    "descriptor": "",
    "authors": [
      "Yangshuai Wang",
      "James R. Kermode",
      "Christoph Ortner",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04856"
  },
  {
    "id": "arXiv:2210.04872",
    "title": "Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models",
    "abstract": "We introduce Sequential Neural Posterior Score Estimation (SNPSE) and\nSequential Neural Likelihood Score Estimation (SNLSE), two new score-based\nmethods for Bayesian inference in simulator-based models. Our methods, inspired\nby the success of score-based methods in generative modelling, leverage\nconditional score-based diffusion models to generate samples from the posterior\ndistribution of interest. These models can be trained using one of two possible\nobjective functions, one of which approximates the score of the intractable\nlikelihood, while the other directly estimates the score of the posterior. We\nembed these models into a sequential training procedure, which guides\nsimulations using the current approximation of the posterior at the observation\nof interest, thereby reducing the simulation cost. We validate our methods, as\nwell as their amortised, non-sequential variants, on several numerical\nexamples, demonstrating comparable or superior performance to existing\nstate-of-the-art methods such as Sequential Neural Posterior Estimation (SNPE)\nand Sequential Neural Likelihood Estimation (SNLE).",
    "descriptor": "",
    "authors": [
      "Louis Sharrock",
      "Jack Simons",
      "Song Liu",
      "Mark Beaumont"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04872"
  },
  {
    "id": "arXiv:1906.11443",
    "title": "Region Refinement Network for Salient Object Detection",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Zhuotao Tian",
      "Hengshuang Zhao",
      "Michelle Shu",
      "Jiaze Wang",
      "Ruiyu Li",
      "Xiaoyong Shen",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.11443"
  },
  {
    "id": "arXiv:1907.05914",
    "title": "Direct/iterative hybrid solver for scattering by inhomogeneous media",
    "abstract": "Direct/iterative hybrid solver for scattering by inhomogeneous media",
    "descriptor": "",
    "authors": [
      "Oscar P. Bruno",
      "Ambuj Pandey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1907.05914"
  },
  {
    "id": "arXiv:1908.06504",
    "title": "Graphs with large total angular resolution",
    "abstract": "Comments: Some parts appeared in the Proceedings of the 27th International Symposium on Graph Drawing and Network Visualization (GD 2019)",
    "descriptor": "\nComments: Some parts appeared in the Proceedings of the 27th International Symposium on Graph Drawing and Network Visualization (GD 2019)\n",
    "authors": [
      "Oswin Aichholzer",
      "Matias Korman",
      "Yoshio Okamoto",
      "Irene Parada",
      "Daniel Perz",
      "Andr\u00e9 van Renssen",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1908.06504"
  },
  {
    "id": "arXiv:1909.08549",
    "title": "Knowledge representation and diagnostic inference using Bayesian  networks in the medical discourse",
    "abstract": "Knowledge representation and diagnostic inference using Bayesian  networks in the medical discourse",
    "descriptor": "",
    "authors": [
      "Sebastian Fl\u00fcgge",
      "Sandra Zimmer",
      "Uwe Petersohn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1909.08549"
  },
  {
    "id": "arXiv:1911.00426",
    "title": "Cali-Sketch: Stroke Calibration and Completion for High-Quality Face  Image Generation from Human-Like Sketches",
    "abstract": "Comments: Accepted to Neurocomputing",
    "descriptor": "\nComments: Accepted to Neurocomputing\n",
    "authors": [
      "Weihao Xia",
      "Yujiu Yang",
      "Jing-Hao Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.00426"
  },
  {
    "id": "arXiv:1911.04209",
    "title": "Privacy-Preserving Gradient Boosting Decision Trees",
    "abstract": "Privacy-Preserving Gradient Boosting Decision Trees",
    "descriptor": "",
    "authors": [
      "Qinbin Li",
      "Zhaomin Wu",
      "Zeyi Wen",
      "Bingsheng He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.04209"
  },
  {
    "id": "arXiv:1912.07325",
    "title": "On the Convergence of Numerical Integration as a Finite Matrix  Approximation to Multiplication Operator",
    "abstract": "Comments: 41 pages, 10 figures",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Juha Sarmavuori",
      "Simo S\u00e4rkk\u00e4"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/1912.07325"
  },
  {
    "id": "arXiv:2001.01600",
    "title": "Improving Few-shot Learning by Spatially-aware Matching and  CrossTransformer",
    "abstract": "Comments: Asian Conference on Computer Vision 2022",
    "descriptor": "\nComments: Asian Conference on Computer Vision 2022\n",
    "authors": [
      "Hongguang Zhang",
      "Philip H. S. Torr",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.01600"
  },
  {
    "id": "arXiv:2005.01350",
    "title": "A Finite Time Analysis of Two Time-Scale Actor Critic Methods",
    "abstract": "Comments: 39 pages. In NeurIPS 2020",
    "descriptor": "\nComments: 39 pages. In NeurIPS 2020\n",
    "authors": [
      "Yue Wu",
      "Weitong Zhang",
      "Pan Xu",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.01350"
  },
  {
    "id": "arXiv:2006.06618",
    "title": "CoinPress: Practical Private Mean and Covariance Estimation",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Sourav Biswas",
      "Yihe Dong",
      "Gautam Kamath",
      "Jonathan Ullman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2006.06618"
  },
  {
    "id": "arXiv:2008.04980",
    "title": "Robust Output Feedback MPC with Reduced Conservatism under Ellipsoidal  Uncertainty",
    "abstract": "Comments: Accepted at CDC 2022",
    "descriptor": "\nComments: Accepted at CDC 2022\n",
    "authors": [
      "Tianchen Ji",
      "Junyi Geng",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.04980"
  },
  {
    "id": "arXiv:2008.06952",
    "title": "A Functional Perspective on Learning Symmetric Functions with Neural  Networks",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.06952"
  },
  {
    "id": "arXiv:2009.06606",
    "title": "Adaptive KL-UCB based Bandit Algorithms for Markovian and i.i.d.  Settings",
    "abstract": "Adaptive KL-UCB based Bandit Algorithms for Markovian and i.i.d.  Settings",
    "descriptor": "",
    "authors": [
      "Arghyadip Roy",
      "Sanjay Shakkottai",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.06606"
  },
  {
    "id": "arXiv:2010.08784",
    "title": "DIFER: Differentiable Automated Feature Engineering",
    "abstract": "Comments: Accept by 1st AutoML.cc",
    "descriptor": "\nComments: Accept by 1st AutoML.cc\n",
    "authors": [
      "Guanghui Zhu",
      "Zhuoer Xu",
      "Xu Guo",
      "Chunfeng Yuan",
      "Yihua Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2010.08784"
  },
  {
    "id": "arXiv:2011.05988",
    "title": "Maximum sampled conditional likelihood for informative subsampling",
    "abstract": "Maximum sampled conditional likelihood for informative subsampling",
    "descriptor": "",
    "authors": [
      "HaiYing Wang",
      "Jae Kwang Kim"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2011.05988"
  },
  {
    "id": "arXiv:2011.13356",
    "title": "A Unified Mixture-View Framework for Unsupervised Representation  Learning",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Xiangxiang Chu",
      "Xiaohang Zhan",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13356"
  },
  {
    "id": "arXiv:2012.02456",
    "title": "Characterization of Excess Risk for Locally Strongly Convex Population  Risk",
    "abstract": "Comments: The first two authors contribute equally to this paper",
    "descriptor": "\nComments: The first two authors contribute equally to this paper\n",
    "authors": [
      "Mingyang Yi",
      "Ruoyu Wang",
      "Zhi-Ming Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02456"
  },
  {
    "id": "arXiv:2012.06746",
    "title": "Periocular Embedding Learning with Consistent Knowledge Distillation  from Face",
    "abstract": "Comments: Submitted to IEEE TIP. The first two authors have contributed equally",
    "descriptor": "\nComments: Submitted to IEEE TIP. The first two authors have contributed equally\n",
    "authors": [
      "Yoon Gyo Jung",
      "Jaewoo Park",
      "Cheng Yaw Low",
      "Jacky Chen Long Chai",
      "Leslie Ching Ow Tiong",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.06746"
  },
  {
    "id": "arXiv:2102.00654",
    "title": "DPIVE: A Regionalized Location Obfuscation Scheme with Personalized  Privacy Levels",
    "abstract": "Comments: 26 pages, 15 figures",
    "descriptor": "\nComments: 26 pages, 15 figures\n",
    "authors": [
      "Shun Zhang",
      "Pengfei Lan",
      "Benfei Duan",
      "Zhili Chen",
      "Hong Zhong",
      "Neal N. Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.00654"
  },
  {
    "id": "arXiv:2102.03509",
    "title": "Robust normalizing flows using Bernstein-type polynomials",
    "abstract": "Robust normalizing flows using Bernstein-type polynomials",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Kasun Fernando",
      "Salman Khan",
      "Nick Barnes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03509"
  },
  {
    "id": "arXiv:2102.05013",
    "title": "Spherical Message Passing for 3D Molecular Graphs",
    "abstract": "Comments: The paper has been accepted by ICLR 2022. You can also cite the conference version",
    "descriptor": "\nComments: The paper has been accepted by ICLR 2022. You can also cite the conference version\n",
    "authors": [
      "Yi Liu",
      "Limei Wang",
      "Meng Liu",
      "Xuan Zhang",
      "Bora Oztekin",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05013"
  },
  {
    "id": "arXiv:2102.07622",
    "title": "Depth lower bounds in Stabbing Planes for combinatorial principles",
    "abstract": "Depth lower bounds in Stabbing Planes for combinatorial principles",
    "descriptor": "",
    "authors": [
      "Stefan Dantchev",
      "Nicola Galesi",
      "Abdul Ghani",
      "Barnaby Martin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2102.07622"
  },
  {
    "id": "arXiv:2102.09796",
    "title": "A GAN-Based Input-Size Flexibility Model for Single Image Dehazing",
    "abstract": "Comments: Published on Signal Processing-Image Communication",
    "descriptor": "\nComments: Published on Signal Processing-Image Communication\n",
    "authors": [
      "Shichao Kan",
      "Yue Zhang",
      "Fanghui Zhang",
      "Yigang Cen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09796"
  },
  {
    "id": "arXiv:2102.10359",
    "title": "Regression Filtration with Resetting to Provide Exponential Convergence  of MRAC for Plants with Jump Change of Unknown Parameters",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Vladislav Petrov",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.10359"
  },
  {
    "id": "arXiv:2102.10476",
    "title": "Contextual Standard Auctions with Budgets: Revenue Equivalence and  Efficiency Guarantees",
    "abstract": "Contextual Standard Auctions with Budgets: Revenue Equivalence and  Efficiency Guarantees",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Christian Kroer",
      "Rachitesh Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2102.10476"
  },
  {
    "id": "arXiv:2102.12332",
    "title": "Interactive Power to Frequency Dynamics Between Grid-Forming Inverters  and Synchronous Generators in Power Electronics-Dominated Power Systems",
    "abstract": "Comments: 14 pages, 20 figures",
    "descriptor": "\nComments: 14 pages, 20 figures\n",
    "authors": [
      "Rick Wallace Kenyon",
      "Amirhossein Sajadi",
      "Matt Bossart",
      "Andy Hoke",
      "Bri-Mathias Hodge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12332"
  },
  {
    "id": "arXiv:2103.00558",
    "title": "Is Simple Uniform Sampling Effective for Center-Based Clustering with  Outliers: When and Why?",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1905.10143",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1905.10143\n",
    "authors": [
      "Jiawei Huang",
      "Wenjie Liu",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2103.00558"
  },
  {
    "id": "arXiv:2103.12711",
    "title": "A Pseudo-Metric between Probability Distributions based on Depth-Trimmed  Regions",
    "abstract": "A Pseudo-Metric between Probability Distributions based on Depth-Trimmed  Regions",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "Pierre Colombo",
      "St\u00e9phan Cl\u00e9men\u00e7on",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12711"
  },
  {
    "id": "arXiv:2103.14029",
    "title": "Causal Inference Under Unmeasured Confounding With Negative Controls: A  Minimax Learning Approach",
    "abstract": "Causal Inference Under Unmeasured Confounding With Negative Controls: A  Minimax Learning Approach",
    "descriptor": "",
    "authors": [
      "Nathan Kallus",
      "Xiaojie Mao",
      "Masatoshi Uehara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2103.14029"
  },
  {
    "id": "arXiv:2103.17104",
    "title": "Deep Image Harmonization by Bridging the Reality Gap",
    "abstract": "Comments: Accepted by BMVC2022",
    "descriptor": "\nComments: Accepted by BMVC2022\n",
    "authors": [
      "Junyan Cao",
      "Wenyan Cong",
      "Li Niu",
      "Jianfu Zhang",
      "Xuesong Gao",
      "Zhiwei Tang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.17104"
  },
  {
    "id": "arXiv:2105.01165",
    "title": "Explicit formulas for the inverses of Toeplitz matrices, with  applications",
    "abstract": "Comments: Probability Theory and Related Fields, published online. Open Access",
    "descriptor": "\nComments: Probability Theory and Related Fields, published online. Open Access\n",
    "authors": [
      "Akihiko Inoue"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.01165"
  },
  {
    "id": "arXiv:2105.05502",
    "title": "Probabilistic modeling of rational communication with conditionals",
    "abstract": "Probabilistic modeling of rational communication with conditionals",
    "descriptor": "",
    "authors": [
      "Britta Grusdt",
      "Daniel Lassiter",
      "Michael Franke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.05502"
  },
  {
    "id": "arXiv:2105.13508",
    "title": "Reduced Complexity Neural Network Equalizers for Two-dimensional  Magnetic Recording",
    "abstract": "Comments: This paper has been accepted for publication in IEEE Transactions on Magnetics. Part of this paper was presented in the 33rd magnetic recording conference (TMRC) 2022, on August 29, 2022",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE Transactions on Magnetics. Part of this paper was presented in the 33rd magnetic recording conference (TMRC) 2022, on August 29, 2022\n",
    "authors": [
      "Ahmed Aboutaleb",
      "Nitin Nangare"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13508"
  },
  {
    "id": "arXiv:2106.03097",
    "title": "Preservation of the Global Knowledge by Not-True Distillation in  Federated Learning",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Yongjin Shin",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03097"
  },
  {
    "id": "arXiv:2106.03366",
    "title": "Spectral Independence via Stability and Applications to Holant-Type  Problems",
    "abstract": "Spectral Independence via Stability and Applications to Holant-Type  Problems",
    "descriptor": "",
    "authors": [
      "Zongchen Chen",
      "Kuikui Liu",
      "Eric Vigoda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.03366"
  },
  {
    "id": "arXiv:2106.04028",
    "title": "Deep Learning Statistical Arbitrage",
    "abstract": "Deep Learning Statistical Arbitrage",
    "descriptor": "",
    "authors": [
      "Jorge Guijarro-Ordonez",
      "Markus Pelger",
      "Greg Zanotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2106.04028"
  },
  {
    "id": "arXiv:2106.05124",
    "title": "PCNet: A Structure Similarity Enhancement Method for Multispectral and  Multimodal Image Registration",
    "abstract": "Comments: 33 pages, 16 figures",
    "descriptor": "\nComments: 33 pages, 16 figures\n",
    "authors": [
      "Si-Yuan Cao",
      "Beinan Yu",
      "Lun Luo",
      "Shu-Jie Chen",
      "Chunguang Li",
      "Hui-Liang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05124"
  },
  {
    "id": "arXiv:2106.14986",
    "title": "Multitask Learning for Scalable and Dense Multilayer Bayesian Map  Inference",
    "abstract": "Multitask Learning for Scalable and Dense Multilayer Bayesian Map  Inference",
    "descriptor": "",
    "authors": [
      "Lu Gan",
      "Youngji Kim",
      "Jessy W. Grizzle",
      "Jeffrey M. Walls",
      "Ayoung Kim",
      "Ryan M. Eustice",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.14986"
  },
  {
    "id": "arXiv:2106.15217",
    "title": "Digging Errors in NMT: Evaluating and Understanding Model Errors from  Partial Hypothesis Space",
    "abstract": "Comments: To be appeared as a main conference paper at EMNLP 2022",
    "descriptor": "\nComments: To be appeared as a main conference paper at EMNLP 2022\n",
    "authors": [
      "Jianhao Yan",
      "Chenming Wu",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15217"
  },
  {
    "id": "arXiv:2106.15249",
    "title": "Convergence analysis for forward and inverse problems in singularly  perturbed time-dependent reaction-advection-diffusion equations",
    "abstract": "Convergence analysis for forward and inverse problems in singularly  perturbed time-dependent reaction-advection-diffusion equations",
    "descriptor": "",
    "authors": [
      "Dmitrii Chaikovskii",
      "Ye Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15249"
  },
  {
    "id": "arXiv:2107.02780",
    "title": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy",
    "abstract": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Rahul Singh"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02780"
  },
  {
    "id": "arXiv:2107.02823",
    "title": "Deep Learning for Micro-expression Recognition: A Survey",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Yante Li",
      "Jinsheng Wei",
      "Yang Liu",
      "Janne Kauttonen",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.02823"
  },
  {
    "id": "arXiv:2107.08574",
    "title": "A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues",
    "abstract": "A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues",
    "descriptor": "",
    "authors": [
      "Mohamed Abdelhack",
      "Jiaming Zhang",
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Daniel Felsky",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.08574"
  },
  {
    "id": "arXiv:2107.13864",
    "title": "Continuation Newton methods with deflation techniques and quasi-genetic  evolution for global optimization problems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2103.05829",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.05829\n",
    "authors": [
      "Xin-long Luo",
      "Hang Xiao",
      "Sen Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.13864"
  },
  {
    "id": "arXiv:2108.00794",
    "title": "Improved Efficiency of Multilevel Monte Carlo for Stochastic PDE through  Strong Pairwise Coupling",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Neil K. Chada",
      "H\u00e5kon Hoel",
      "Ajay Jasra",
      "Georgios E. Zouraris"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2108.00794"
  },
  {
    "id": "arXiv:2108.01335",
    "title": "Where do Models go Wrong? Parameter-Space Saliency Maps for  Explainability",
    "abstract": "Where do Models go Wrong? Parameter-Space Saliency Maps for  Explainability",
    "descriptor": "",
    "authors": [
      "Roman Levin",
      "Manli Shu",
      "Eitan Borgnia",
      "Furong Huang",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01335"
  },
  {
    "id": "arXiv:2108.10218",
    "title": "Modeling chronic pain experiences from online reports using the Reddit  Reports of Chronic Pain dataset",
    "abstract": "Comments: 25 pages, 26 figures, 9 tables",
    "descriptor": "\nComments: 25 pages, 26 figures, 9 tables\n",
    "authors": [
      "Diogo A.P. Nunes",
      "Joana Ferreira Gomes",
      "Fani Neto",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2108.10218"
  },
  {
    "id": "arXiv:2108.13658",
    "title": "Automatic Rule Generation for Time Expression Normalization",
    "abstract": "Comments: Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Wentao Ding",
      "Jianhao Chen",
      "Jinmao Li",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13658"
  },
  {
    "id": "arXiv:2109.03148",
    "title": "Congruency-Constrained TU Problems Beyond the Bimodular Case",
    "abstract": "Congruency-Constrained TU Problems Beyond the Bimodular Case",
    "descriptor": "",
    "authors": [
      "Martin N\u00e4gele",
      "Richard Santiago",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.03148"
  },
  {
    "id": "arXiv:2109.08833",
    "title": "TVStoryGen: A Dataset for Generating Stories with Character Descriptions",
    "abstract": "TVStoryGen: A Dataset for Generating Stories with Character Descriptions",
    "descriptor": "",
    "authors": [
      "Mingda Chen",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08833"
  },
  {
    "id": "arXiv:2109.13595",
    "title": "The Fragility of Optimized Bandit Algorithms",
    "abstract": "The Fragility of Optimized Bandit Algorithms",
    "descriptor": "",
    "authors": [
      "Lin Fan",
      "Peter W. Glynn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.13595"
  },
  {
    "id": "arXiv:2109.15268",
    "title": "Blazing a Trail via Matrix Multiplications: A Faster Algorithm for  Non-shortest Induced Paths",
    "abstract": "Comments: 18 pages, 6 figures, a preliminary version appeared in STACS 2022",
    "descriptor": "\nComments: 18 pages, 6 figures, a preliminary version appeared in STACS 2022\n",
    "authors": [
      "Yung-Chung Chiu",
      "Hsueh-I Lu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.15268"
  },
  {
    "id": "arXiv:2110.01230",
    "title": "Efficient Identification of Butterfly Sparse Matrix Factorizations",
    "abstract": "Efficient Identification of Butterfly Sparse Matrix Factorizations",
    "descriptor": "",
    "authors": [
      "L\u00e9on Zheng",
      "Elisa Riccietti",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01230"
  },
  {
    "id": "arXiv:2110.01663",
    "title": "Global Convergence and Stability of Stochastic Gradient Descent",
    "abstract": "Global Convergence and Stability of Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Vivak Patel",
      "Shushu Zhang",
      "Bowen Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.01663"
  },
  {
    "id": "arXiv:2110.04398",
    "title": "The Role of Masks in Mitigating Viral Spread on Networks",
    "abstract": "The Role of Masks in Mitigating Viral Spread on Networks",
    "descriptor": "",
    "authors": [
      "Yurun Tian",
      "Anirudh Sridhar",
      "Chai Wah Wu",
      "Simon A. Levin",
      "Kathleen M. Carley",
      "H.Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04398"
  },
  {
    "id": "arXiv:2110.04729",
    "title": "Humans' Assessment of Robots as Moral Regulators: Importance of  Perceived Fairness and Legitimacy",
    "abstract": "Comments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Boyoung Kim",
      "Elizabeth Phillips"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04729"
  },
  {
    "id": "arXiv:2110.05286",
    "title": "Learning from Ambiguous Demonstrations with Self-Explanation Guided  Reinforcement Learning",
    "abstract": "Learning from Ambiguous Demonstrations with Self-Explanation Guided  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Yantian Zha",
      "Lin Guan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05286"
  },
  {
    "id": "arXiv:2110.06356",
    "title": "Poncelet Parabola Pirouettes",
    "abstract": "Comments: 24 pages, 23 figures",
    "descriptor": "\nComments: 24 pages, 23 figures\n",
    "authors": [
      "Dan Reznik",
      "Ronaldo Garcia"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06356"
  },
  {
    "id": "arXiv:2110.10007",
    "title": "Gradient-Based Mixed Planning with Symbolic and Numeric Action  Parameters",
    "abstract": "Comments: 41 pages, 22 figures. Accepted by Artificial Intelligence",
    "descriptor": "\nComments: 41 pages, 22 figures. Accepted by Artificial Intelligence\n",
    "authors": [
      "Kebing Jin",
      "Hankz Hankui Zhuo",
      "Zhanhao Xiao",
      "Hai Wan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10007"
  },
  {
    "id": "arXiv:2110.11729",
    "title": "FakeNewsLab: Experimental Study on Biases and Pitfalls Preventing us  from Distinguishing True from False News",
    "abstract": "Comments: 18 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: 18 pages, 12 figures, 3 tables\n",
    "authors": [
      "Giancarlo Ruffo",
      "Alfonso Semeraro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11729"
  },
  {
    "id": "arXiv:2110.12942",
    "title": "DocTr: Document Image Transformer for Geometric Unwarping and  Illumination Correction",
    "abstract": "Comments: This paper has been accepted by ACM Multimedia 2021",
    "descriptor": "\nComments: This paper has been accepted by ACM Multimedia 2021\n",
    "authors": [
      "Hao Feng",
      "Yuechen Wang",
      "Wengang Zhou",
      "Jiajun Deng",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12942"
  },
  {
    "id": "arXiv:2111.00539",
    "title": "Cross-Domain Reasoning via Template Filling",
    "abstract": "Cross-Domain Reasoning via Template Filling",
    "descriptor": "",
    "authors": [
      "Dheeraj Rajagopal",
      "Vivek Khetan",
      "Bogdan Sacaleanu",
      "Anatole Gershman",
      "Andrew Fano",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00539"
  },
  {
    "id": "arXiv:2111.00701",
    "title": "Discourse Comprehension: A Question Answering Framework to Represent  Sentence Connections",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Wei-Jen Ko",
      "Cutter Dalton",
      "Mark Simmons",
      "Eliza Fisher",
      "Greg Durrett",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00701"
  },
  {
    "id": "arXiv:2111.01566",
    "title": "Strategyproof and Proportionally Fair Facility Location",
    "abstract": "Strategyproof and Proportionally Fair Facility Location",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Alexander Lam",
      "Barton E. Lee",
      "Toby Walsh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.01566"
  },
  {
    "id": "arXiv:2111.01813",
    "title": "Spatial regionalization based on optimal information compression",
    "abstract": "Spatial regionalization based on optimal information compression",
    "descriptor": "",
    "authors": [
      "Alec Kirkley"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.01813"
  },
  {
    "id": "arXiv:2111.03543",
    "title": "Empirical analysis of representation learning and exploration in neural  kernel bandits",
    "abstract": "Comments: Extended version. Added a major experiment comparing NK distribution w.r.t. exploration and exploitation. Submitted to ICLR 2023",
    "descriptor": "\nComments: Extended version. Added a major experiment comparing NK distribution w.r.t. exploration and exploitation. Submitted to ICLR 2023\n",
    "authors": [
      "Michal Lisicki",
      "Arash Afkanpour",
      "Graham W. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.03543"
  },
  {
    "id": "arXiv:2111.03820",
    "title": "Distributed stochastic proximal algorithm with random reshuffling for  non-smooth finite-sum optimization",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Xia Jiang",
      "Xianlin Zeng",
      "Jian Sun",
      "Jie Chen",
      "Lihua Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03820"
  },
  {
    "id": "arXiv:2111.05223",
    "title": "A quantitative and qualitative open citation analysis of retracted  articles in the humanities",
    "abstract": "A quantitative and qualitative open citation analysis of retracted  articles in the humanities",
    "descriptor": "",
    "authors": [
      "Ivan Heibi",
      "Silvio Peroni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.05223"
  },
  {
    "id": "arXiv:2111.06078",
    "title": "Solving time-dependent parametric PDEs by multiclass  classification-based reduced order model",
    "abstract": "Comments: 20 pages, 16 figures",
    "descriptor": "\nComments: 20 pages, 16 figures\n",
    "authors": [
      "Chen Cui",
      "Kai Jiang",
      "Shi Shu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.06078"
  },
  {
    "id": "arXiv:2111.06195",
    "title": "Towards Domain-Independent and Real-Time Gesture Recognition Using  mmWave Signal",
    "abstract": "Comments: This paper has been accepted by IEEE Transactions on Mobile Computing (2022)",
    "descriptor": "\nComments: This paper has been accepted by IEEE Transactions on Mobile Computing (2022)\n",
    "authors": [
      "Yadong Li",
      "Dongheng Zhang",
      "Jinbo Chen",
      "Jinwei Wan",
      "Dong Zhang",
      "Yang Hu",
      "Qibin Sun",
      "Yan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06195"
  },
  {
    "id": "arXiv:2111.07011",
    "title": "An explicit predictor/multicorrector time marching with automatic  adaptivity for finite-strain elastodynamics",
    "abstract": "Comments: Journal of Computational Physics (accepted)",
    "descriptor": "\nComments: Journal of Computational Physics (accepted)\n",
    "authors": [
      "Nicolas A. Labanda",
      "Pouria Behnoudfar",
      "Victor M. Calo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.07011"
  },
  {
    "id": "arXiv:2111.07495",
    "title": "Distribution-Free Model for Community Detection",
    "abstract": "Comments: 21 pages, 9 figures, 1 table, comments are welcome",
    "descriptor": "\nComments: 21 pages, 9 figures, 1 table, comments are welcome\n",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.07495"
  },
  {
    "id": "arXiv:2111.08493",
    "title": "ELBD: Efficient score algorithm for feature selection on latent  variables of VAE",
    "abstract": "Comments: 16 pages 7 figures",
    "descriptor": "\nComments: 16 pages 7 figures\n",
    "authors": [
      "Yiran Dong",
      "Chuanhou Gao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08493"
  },
  {
    "id": "arXiv:2111.10409",
    "title": "The Acrobatics of BQP",
    "abstract": "Comments: 64 pages. V2: various writing improvements. V3: minor fixes to spelling and references",
    "descriptor": "\nComments: 64 pages. V2: various writing improvements. V3: minor fixes to spelling and references\n",
    "authors": [
      "Scott Aaronson",
      "DeVon Ingram",
      "William Kretschmer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.10409"
  },
  {
    "id": "arXiv:2111.11398",
    "title": "Why Do Self-Supervised Models Transfer? Investigating the Impact of  Invariance on Downstream Tasks",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Linus Ericsson",
      "Henry Gouk",
      "Timothy M. Hospedales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11398"
  },
  {
    "id": "arXiv:2111.13415",
    "title": "ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision  Medicine",
    "abstract": "Comments: 23 pages, 12 figures",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Ilker Demirel",
      "Ahmet Alparslan Celik",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13415"
  },
  {
    "id": "arXiv:2111.13420",
    "title": "Confounder Identification-free Causal Visual Feature Learning",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Xin Li",
      "Zhizheng Zhang",
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13420"
  },
  {
    "id": "arXiv:2111.15050",
    "title": "AssistSR: Task-oriented Video Segment Retrieval for Personal AI  Assistant",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Stan Weixian Lei",
      "Difei Gao",
      "Yuxuan Wang",
      "Dongxing Mao",
      "Zihan Liang",
      "Lingmin Ran",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15050"
  },
  {
    "id": "arXiv:2111.15187",
    "title": "HyperPCA: a Powerful Tool to Extract Elemental Maps from Noisy Data  Obtained in LIBS Mapping of Materials",
    "abstract": "Comments: 20 pages, 8 pages of supplementary material; references added, additional explanations, details and figures; supplementary material better organised in appendices, updated references",
    "descriptor": "\nComments: 20 pages, 8 pages of supplementary material; references added, additional explanations, details and figures; supplementary material better organised in appendices, updated references\n",
    "authors": [
      "Riccardo Finotello",
      "Mohamed Tamaazousti",
      "Jean-Baptiste Sirven"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.15187"
  },
  {
    "id": "arXiv:2112.01036",
    "title": "GANSeg: Learning to Segment by Unsupervised Hierarchical Image  Generation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01036"
  },
  {
    "id": "arXiv:2112.02504",
    "title": "A Novel Sequential Coreset Method for Gradient Descent Algorithms",
    "abstract": "A Novel Sequential Coreset Method for Gradient Descent Algorithms",
    "descriptor": "",
    "authors": [
      "Jiawei Huang",
      "Ruomin Huang",
      "Wenjie Liu",
      "Nikolaos M. Freris",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.02504"
  },
  {
    "id": "arXiv:2112.04389",
    "title": "Mixed Membership Distribution-Free Model",
    "abstract": "Comments: 23 pages, 14 figures, 3 tabels, comments are welcome",
    "descriptor": "\nComments: 23 pages, 14 figures, 3 tabels, comments are welcome\n",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04389"
  },
  {
    "id": "arXiv:2112.04489",
    "title": "Learn2Reg: comprehensive multi-task medical image registration  challenge, dataset and evaluation in the era of deep learning",
    "abstract": "Learn2Reg: comprehensive multi-task medical image registration  challenge, dataset and evaluation in the era of deep learning",
    "descriptor": "",
    "authors": [
      "Alessa Hering",
      "Lasse Hansen",
      "Tony C. W. Mok",
      "Albert C. S. Chung",
      "Hanna Siebert",
      "Stephanie H\u00e4ger",
      "Annkristin Lange",
      "Sven Kuckertz",
      "Stefan Heldmann",
      "Wei Shao",
      "Sulaiman Vesal",
      "Mirabela Rusu",
      "Geoffrey Sonn",
      "Th\u00e9o Estienne",
      "Maria Vakalopoulou",
      "Luyi Han",
      "Yunzhi Huang",
      "Pew-Thian Yap",
      "Mikael Brudfors",
      "Ya\u00ebl Balbastre",
      "Samuel Joutard",
      "Marc Modat",
      "Gal Lifshitz",
      "Dan Raviv",
      "Jinxin Lv",
      "Qiang Li",
      "Vincent Jaouen",
      "Dimitris Visvikis",
      "Constance Fourcade",
      "Mathieu Rubeaux",
      "Wentao Pan",
      "Zhe Xu",
      "Bailiang Jian",
      "Francesca De Benetti",
      "Marek Wodzinski",
      "Niklas Gunnarsson",
      "Jens Sj\u00f6lund",
      "Daniel Grzech",
      "Huaqi Qiu",
      "Zeju Li",
      "Alexander Thorley",
      "Jinming Duan",
      "Christoph Gro\u00dfbr\u00f6hmer",
      "Andrew Hoopes",
      "Ingerid Reinertsen",
      "Yiming Xiao",
      "Bennett Landman",
      "Yuankai Huo",
      "Keelin Murphy",
      "Nikolas Lessmann",
      "Bram van Ginneken"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04489"
  },
  {
    "id": "arXiv:2112.04559",
    "title": "Achieving Reliable Coordination of Residential Plug-in Electric Vehicle  Charging: A Pilot Study",
    "abstract": "Comments: 19 pages, 12 figures",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Polina Alexeenko",
      "Eilyan Bitar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04559"
  },
  {
    "id": "arXiv:2112.05682",
    "title": "Self-attention Does Not Need $O(n^2)$ Memory",
    "abstract": "Self-attention Does Not Need $O(n^2)$ Memory",
    "descriptor": "",
    "authors": [
      "Markus N. Rabe",
      "Charles Staats"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05682"
  },
  {
    "id": "arXiv:2112.05851",
    "title": "Short and Long Range Relation Based Spatio-Temporal Transformer for  Micro-Expression Recognition",
    "abstract": "Comments: 13 pages, 9 figures",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Liangfei Zhang",
      "Xiaopeng Hong",
      "Ognjen Arandjelovic",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05851"
  },
  {
    "id": "arXiv:2112.07225",
    "title": "Margin Calibration for Long-Tailed Visual Recognition",
    "abstract": "Comments: Accepted by Asian Conference on Machine Learning (ACML) 2022; 16 pages",
    "descriptor": "\nComments: Accepted by Asian Conference on Machine Learning (ACML) 2022; 16 pages\n",
    "authors": [
      "Yidong Wang",
      "Bowen Zhang",
      "Wenxin Hou",
      "Zhen Wu",
      "Jindong Wang",
      "Takahiro Shinozaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07225"
  },
  {
    "id": "arXiv:2112.10373",
    "title": "Advances of Proof Scores in CafeOBJ",
    "abstract": "Comments: 54 pages, accepted for publication in Science of Computer Programming; every Section except Section 1 has been considerably revised, especially Subsection 2.6 and Subsubsection 5.4.1 are significantly revised",
    "descriptor": "\nComments: 54 pages, accepted for publication in Science of Computer Programming; every Section except Section 1 has been considerably revised, especially Subsection 2.6 and Subsubsection 5.4.1 are significantly revised\n",
    "authors": [
      "Kokichi Futatsugi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.10373"
  },
  {
    "id": "arXiv:2112.12310",
    "title": "Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art",
    "abstract": "Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art",
    "descriptor": "",
    "authors": [
      "Xiang Ling",
      "Lingfei Wu",
      "Jiangyu Zhang",
      "Zhenqing Qu",
      "Wei Deng",
      "Xiang Chen",
      "Yaguan Qian",
      "Chunming Wu",
      "Shouling Ji",
      "Tianyue Luo",
      "Jingzheng Wu",
      "Yanjun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12310"
  },
  {
    "id": "arXiv:2112.12542",
    "title": "How Much Space Has Been Explored? Measuring the Chemical Space Covered  by Databases and Machine-Generated Molecules",
    "abstract": "How Much Space Has Been Explored? Measuring the Chemical Space Covered  by Databases and Machine-Generated Molecules",
    "descriptor": "",
    "authors": [
      "Yutong Xie",
      "Ziqiao Xu",
      "Jiaqi Ma",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12542"
  },
  {
    "id": "arXiv:2112.14397",
    "title": "EvoMoE: An Evolutional Mixture-of-Experts Training Framework via  Dense-To-Sparse Gate",
    "abstract": "EvoMoE: An Evolutional Mixture-of-Experts Training Framework via  Dense-To-Sparse Gate",
    "descriptor": "",
    "authors": [
      "Xiaonan Nie",
      "Xupeng Miao",
      "Shijie Cao",
      "Lingxiao Ma",
      "Qibin Liu",
      "Jilong Xue",
      "Youshan Miao",
      "Yi Liu",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14397"
  },
  {
    "id": "arXiv:2201.02084",
    "title": "Active Terminal Identification, Channel Estimation, and Signal Detection  for Grant-Free NOMA-OTFS in LEO Satellite Internet-of-Things",
    "abstract": "Comments: 20 pages, 9 figures, accepted by IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 20 pages, 9 figures, accepted by IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Xingyu Zhou",
      "Keke Ying",
      "Zhen Gao",
      "Yongpeng Wu",
      "Zhenyu Xiao",
      "Symeon Chatzinotas",
      "Jinhong Yuan",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.02084"
  },
  {
    "id": "arXiv:2201.03742",
    "title": "Explaining Predictive Uncertainty by Looking Back at Model Explanations",
    "abstract": "Explaining Predictive Uncertainty by Looking Back at Model Explanations",
    "descriptor": "",
    "authors": [
      "Hanjie Chen",
      "Wanyu Du",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.03742"
  },
  {
    "id": "arXiv:2201.06225",
    "title": "Interactive Contrastive Learning for Self-supervised Entity Alignment",
    "abstract": "Comments: Accepted by CIKM 2022",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Kaisheng Zeng",
      "Zhenhao Dong",
      "Lei Hou",
      "Yixin Cao",
      "Minghao Hu",
      "Jifan Yu",
      "Xin Lv",
      "Juanzi Li",
      "Ling Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06225"
  },
  {
    "id": "arXiv:2201.07666",
    "title": "Microeconomic Foundations of Decentralised Organisations",
    "abstract": "Comments: 9 pages, 7 figures, pre-final version, submitted to conference",
    "descriptor": "\nComments: 9 pages, 7 figures, pre-final version, submitted to conference\n",
    "authors": [
      "Mauricio Jacobo Romero",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2201.07666"
  },
  {
    "id": "arXiv:2201.07984",
    "title": "AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees",
    "abstract": "AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees",
    "descriptor": "",
    "authors": [
      "Rong Liang",
      "Tiehua Zhang",
      "Yujie Lu",
      "Yuze Liu",
      "Zhen Huang",
      "Xin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07984"
  },
  {
    "id": "arXiv:2201.08131",
    "title": "GeoFill: Reference-Based Image Inpainting with Better Geometric  Understanding",
    "abstract": "Comments: Accepted to WACV 2023",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Yunhan Zhao",
      "Connelly Barnes",
      "Yuqian Zhou",
      "Eli Shechtman",
      "Sohrab Amirghodsi",
      "Charless Fowlkes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08131"
  },
  {
    "id": "arXiv:2201.09531",
    "title": "Communication-Efficient Stochastic Zeroth-Order Optimization for  Federated Learning",
    "abstract": "Comments: This work was accepted to Transaction on Signal Processing",
    "descriptor": "\nComments: This work was accepted to Transaction on Signal Processing\n",
    "authors": [
      "Wenzhi Fang",
      "Ziyi Yu",
      "Yuning Jiang",
      "Yuanming Shi",
      "Colin N. Jones",
      "Yong Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.09531"
  },
  {
    "id": "arXiv:2201.10280",
    "title": "The Trusted Computing Base of the CompCert Verified Compiler",
    "abstract": "The Trusted Computing Base of the CompCert Verified Compiler",
    "descriptor": "",
    "authors": [
      "David Monniaux",
      "Sylvain Boulm\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.10280"
  },
  {
    "id": "arXiv:2201.10394",
    "title": "Capturing Temporal Information in a Single Frame: Channel Sampling  Strategies for Action Recognition",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Kiyoon Kim",
      "Shreyank N Gowda",
      "Oisin Mac Aodha",
      "Laura Sevilla-Lara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10394"
  },
  {
    "id": "arXiv:2201.12096",
    "title": "Mask-based Latent Reconstruction for Reinforcement Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Tao Yu",
      "Zhizheng Zhang",
      "Cuiling Lan",
      "Yan Lu",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12096"
  },
  {
    "id": "arXiv:2201.13320",
    "title": "BEER: Fast $O(1/T)$ Rate for Decentralized Nonconvex Optimization with  Communication Compression",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Haoyu Zhao",
      "Boyue Li",
      "Zhize Li",
      "Peter Richt\u00e1rik",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13320"
  },
  {
    "id": "arXiv:2201.13329",
    "title": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Hongxin Wei",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.13329"
  },
  {
    "id": "arXiv:2202.01258",
    "title": "Accelerated Quality-Diversity through Massive Parallelism",
    "abstract": "Accelerated Quality-Diversity through Massive Parallelism",
    "descriptor": "",
    "authors": [
      "Bryan Lim",
      "Maxime Allard",
      "Luca Grillotti",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01258"
  },
  {
    "id": "arXiv:2202.01582",
    "title": "A Psychoacoustic Quality Criterion for Path-Traced Sound Propagation",
    "abstract": "Comments: 12 pages, 10 figures. To be published in IEEE TVCG",
    "descriptor": "\nComments: 12 pages, 10 figures. To be published in IEEE TVCG\n",
    "authors": [
      "Chunxiao Cao",
      "Zili An",
      "Zhong Ren",
      "Dinesh Manocha",
      "Kun Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01582"
  },
  {
    "id": "arXiv:2202.02056",
    "title": "Unsupervised Behaviour Analysis of News Consumption in Turkish Media",
    "abstract": "Comments: Submitted to Big Data Research",
    "descriptor": "\nComments: Submitted to Big Data Research\n",
    "authors": [
      "Didem Makaroglu",
      "Altan Cakir",
      "Behcet Ugur Toreyin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02056"
  },
  {
    "id": "arXiv:2202.02067",
    "title": "An exponentially convergent discretization for space-time fractional  parabolic equations using $hp$-FEM",
    "abstract": "An exponentially convergent discretization for space-time fractional  parabolic equations using $hp$-FEM",
    "descriptor": "",
    "authors": [
      "Jens Markus Melenk",
      "Alexander Rieder"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02067"
  },
  {
    "id": "arXiv:2202.02842",
    "title": "Evaluating natural language processing models with generalization  metrics that do not need access to any training or testing data",
    "abstract": "Evaluating natural language processing models with generalization  metrics that do not need access to any training or testing data",
    "descriptor": "",
    "authors": [
      "Yaoqing Yang",
      "Ryan Theisen",
      "Liam Hodgkinson",
      "Joseph E. Gonzalez",
      "Kannan Ramchandran",
      "Charles H. Martin",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02842"
  },
  {
    "id": "arXiv:2202.02976",
    "title": "Measuring and Reducing Model Update Regression in Structured Prediction  for NLP",
    "abstract": "Comments: NeurIPS2022",
    "descriptor": "\nComments: NeurIPS2022\n",
    "authors": [
      "Deng Cai",
      "Elman Mansimov",
      "Yi-An Lai",
      "Yixuan Su",
      "Lei Shu",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02976"
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02989"
  },
  {
    "id": "arXiv:2202.03738",
    "title": "Conflict-free incidence coloring of outer-1-planar graphs",
    "abstract": "Comments: This paper is acccepted for publication in Acta Mathematicae Applicatae Sinica (English Series) under the current title as a reviewer suggested",
    "descriptor": "\nComments: This paper is acccepted for publication in Acta Mathematicae Applicatae Sinica (English Series) under the current title as a reviewer suggested\n",
    "authors": [
      "Mengke Qi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.03738"
  },
  {
    "id": "arXiv:2202.03800",
    "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the  Structure Space",
    "abstract": "Comments: Accepted by the ICLR 2022. Homepage: this https URL",
    "descriptor": "\nComments: Accepted by the ICLR 2022. Homepage: this https URL\n",
    "authors": [
      "Yaohua Wang",
      "Yaobin Zhang",
      "Fangyi Zhang",
      "Ming Lin",
      "YuQi Zhang",
      "Senzhang Wang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03800"
  },
  {
    "id": "arXiv:2202.05211",
    "title": "Behavior-Semantic Scenery Description (BSSD) of Road Networks for  Automated Driving",
    "abstract": "Comments: 13 pages, 3 figures, 3 tables, submitted to IEEE Access",
    "descriptor": "\nComments: 13 pages, 3 figures, 3 tables, submitted to IEEE Access\n",
    "authors": [
      "Moritz Lippert",
      "Felix Glatzki",
      "Hermann Winner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05211"
  },
  {
    "id": "arXiv:2202.06503",
    "title": "Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos",
    "abstract": "Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos",
    "descriptor": "",
    "authors": [
      "Congqi Cao",
      "Xin Zhang",
      "Shizhou Zhang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06503"
  },
  {
    "id": "arXiv:2202.08238",
    "title": "A multi-reconstruction study of breast density estimation using Deep  Learning",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Vikash Gupta",
      "Mutlu Demirer",
      "Robert W. Maxwell",
      "Richard D. White",
      "Barbaros Selnur Erdal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08238"
  },
  {
    "id": "arXiv:2202.08479",
    "title": "On the Evaluation Metrics for Paraphrase Generation",
    "abstract": "On the Evaluation Metrics for Paraphrase Generation",
    "descriptor": "",
    "authors": [
      "Lingfeng Shen",
      "Lemao Liu",
      "Haiyun Jiang",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08479"
  },
  {
    "id": "arXiv:2202.09673",
    "title": "A Behavior Regularized Implicit Policy for Offline Reinforcement  Learning",
    "abstract": "Comments: 33 pages, 3 figures, and 8 tables",
    "descriptor": "\nComments: 33 pages, 3 figures, and 8 tables\n",
    "authors": [
      "Shentao Yang",
      "Zhendong Wang",
      "Huangjie Zheng",
      "Yihao Feng",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09673"
  },
  {
    "id": "arXiv:2202.10670",
    "title": "From Optimization Dynamics to Generalization Bounds via \u0141ojasiewicz  Gradient Inequality",
    "abstract": "Comments: Transactions on Machine Learning Research 2022",
    "descriptor": "\nComments: Transactions on Machine Learning Research 2022\n",
    "authors": [
      "Fusheng Liu",
      "Haizhao Yang",
      "Soufiane Hayou",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10670"
  },
  {
    "id": "arXiv:2202.10939",
    "title": "Single-Leg Revenue Management with Advice",
    "abstract": "Single-Leg Revenue Management with Advice",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Christian Kroer",
      "Rachitesh Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10939"
  },
  {
    "id": "arXiv:2202.13665",
    "title": "Restless Multi-Armed Bandits under Exogenous Global Markov Process",
    "abstract": "Comments: Accepted for presentation at IEEE ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2112.09484",
    "descriptor": "\nComments: Accepted for presentation at IEEE ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2112.09484\n",
    "authors": [
      "Tomer Gafni",
      "Michal Yemini",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.13665"
  },
  {
    "id": "arXiv:2203.00328",
    "title": "BERT-LID: Leveraging BERT to Improve Spoken Language Identification",
    "abstract": "Comments: accepted by ISCSLP 2022",
    "descriptor": "\nComments: accepted by ISCSLP 2022\n",
    "authors": [
      "Yuting Nie",
      "Junhong Zhao",
      "Wei-Qiang Zhang",
      "Jinfeng Bai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.00328"
  },
  {
    "id": "arXiv:2203.00614",
    "title": "Side-effects of Learning from Low Dimensional Data Embedded in an  Euclidean Space",
    "abstract": "Comments: 52 pages (11 pages for Appendix), 21 figures",
    "descriptor": "\nComments: 52 pages (11 pages for Appendix), 21 figures\n",
    "authors": [
      "Juncai He",
      "Richard Tsai",
      "Rachel Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.00614"
  },
  {
    "id": "arXiv:2203.01104",
    "title": "Parameter-Efficient Mixture-of-Experts Architecture for Pre-trained  Language Models",
    "abstract": "Comments: 11 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 2 figures, 2 tables\n",
    "authors": [
      "Ze-Feng Gao",
      "Peiyu Liu",
      "Wayne Xin Zhao",
      "Zhong-Yi Lu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.01104"
  },
  {
    "id": "arXiv:2203.01294",
    "title": "Providing Insights for Open-Response Surveys via End-to-End  Context-Aware Clustering",
    "abstract": "Providing Insights for Open-Response Surveys via End-to-End  Context-Aware Clustering",
    "descriptor": "",
    "authors": [
      "Soheil Esmaeilzadeh",
      "Brian Williams",
      "Davood Shamsi",
      "Onar Vikingstad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.01294"
  },
  {
    "id": "arXiv:2203.01695",
    "title": "Unfolding-Aided Bootstrapped Phase Retrieval in Optical Imaging",
    "abstract": "Comments: 13 pages, 11 figures, 1 table",
    "descriptor": "\nComments: 13 pages, 11 figures, 1 table\n",
    "authors": [
      "Samuel Pinilla",
      "Kumar Vijay Mishra",
      "Igor Shevkunov",
      "Mojtaba Soltanalian",
      "Vladimir Katkovnik",
      "Karen Egiazarian"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.01695"
  },
  {
    "id": "arXiv:2203.02035",
    "title": "Baba is Y'all 2.0: Design and Investigation of a Collaborative  Mixed-Initiative System",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "M Charity",
      "Isha Dave",
      "Ahmed Khalifa",
      "Julian Togelius"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.02035"
  },
  {
    "id": "arXiv:2203.02693",
    "title": "Better Approximation Guarantees for the NSGA-II by Using the Current  Crowding Distance",
    "abstract": "Comments: Conference version with complete proofs",
    "descriptor": "\nComments: Conference version with complete proofs\n",
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.02693"
  },
  {
    "id": "arXiv:2203.03695",
    "title": "Learning to Bound: A Generative Cram\u00e9r-Rao Bound",
    "abstract": "Learning to Bound: A Generative Cram\u00e9r-Rao Bound",
    "descriptor": "",
    "authors": [
      "Hai Victor Habi",
      "Hagit Messer",
      "Yoram Bresler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03695"
  },
  {
    "id": "arXiv:2203.03966",
    "title": "GaitStrip: Gait Recognition via Effective Strip-based Feature  Representations and Multi-Level Framework",
    "abstract": "Comments: Accepted to ACCV2022",
    "descriptor": "\nComments: Accepted to ACCV2022\n",
    "authors": [
      "Ming Wang",
      "Beibei Lin",
      "Xianda Guo",
      "Lincheng Li",
      "Zheng Zhu",
      "Jiande Sun",
      "Shunli Zhang",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03966"
  },
  {
    "id": "arXiv:2203.06215",
    "title": "Can I see an Example? Active Learning the Long Tail of Attributes and  Relations",
    "abstract": "Comments: To appear in the British Machine Vision Conference (BMVC-2022)",
    "descriptor": "\nComments: To appear in the British Machine Vision Conference (BMVC-2022)\n",
    "authors": [
      "Tyler L. Hayes",
      "Maximilian Nickel",
      "Christopher Kanan",
      "Ludovic Denoyer",
      "Arthur Szlam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06215"
  },
  {
    "id": "arXiv:2203.06371",
    "title": "Varying Coefficient Linear Discriminant Analysis for Dynamic Data",
    "abstract": "Varying Coefficient Linear Discriminant Analysis for Dynamic Data",
    "descriptor": "",
    "authors": [
      "Yajie Bao",
      "Yuyang Liu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06371"
  },
  {
    "id": "arXiv:2203.06378",
    "title": "MarkBERT: Marking Word Boundaries Improves Chinese BERT",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Linyang Li",
      "Yong Dai",
      "Duyu Tang",
      "Xipeng Qiu",
      "Zenglin Xu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.06378"
  },
  {
    "id": "arXiv:2203.06552",
    "title": "Mathematically Quantifying Non-responsiveness of the 2021 Georgia  Congressional Districting Plan",
    "abstract": "Comments: 29 pages, 20 figures, oral presentation at ACM conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 2022",
    "descriptor": "\nComments: 29 pages, 20 figures, oral presentation at ACM conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 2022\n",
    "authors": [
      "Zhanzhan Zhao",
      "Cyrus Hettle",
      "Swati Gupta",
      "Jonathan Mattingly",
      "Dana Randall",
      "Gregory Herschlag"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.06552"
  },
  {
    "id": "arXiv:2203.06875",
    "title": "Improved Universal Sentence Embeddings with Prompt-based Contrastive  Learning and Energy-based Learning",
    "abstract": "Comments: 15 pages, 3 figures, Findings of EMNLP 2022",
    "descriptor": "\nComments: 15 pages, 3 figures, Findings of EMNLP 2022\n",
    "authors": [
      "Yuxin Jiang",
      "Linhan Zhang",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.06875"
  },
  {
    "id": "arXiv:2203.09179",
    "title": "Maximum Likelihood Estimation in Gaussian Process Regression is  Ill-Posed",
    "abstract": "Maximum Likelihood Estimation in Gaussian Process Regression is  Ill-Posed",
    "descriptor": "",
    "authors": [
      "Toni Karvonen",
      "Chris J. Oates"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09179"
  },
  {
    "id": "arXiv:2203.09268",
    "title": "Progressive Subsampling for Oversampled Data -- Application to  Quantitative MRI",
    "abstract": "Comments: Accepted In: Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022",
    "descriptor": "\nComments: Accepted In: Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022\n",
    "authors": [
      "Stefano B. Blumberg",
      "Hongxiang Lin",
      "Francesco Grussu",
      "Yukun Zhou",
      "Matteo Figini",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.09268"
  },
  {
    "id": "arXiv:2203.10030",
    "title": "Nonnegative-Constrained Joint Collaborative Representation with Union  Dictionary for Hyperspectral Anomaly Detection",
    "abstract": "Nonnegative-Constrained Joint Collaborative Representation with Union  Dictionary for Hyperspectral Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Shizhen Chang",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10030"
  },
  {
    "id": "arXiv:2203.10465",
    "title": "Inspection-L: Self-Supervised GNN Node Embeddings for Money Laundering  Detection in Bitcoin",
    "abstract": "Inspection-L: Self-Supervised GNN Node Embeddings for Money Laundering  Detection in Bitcoin",
    "descriptor": "",
    "authors": [
      "Wai Weng Lo",
      "Gayan K. Kulatilleke",
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.10465"
  },
  {
    "id": "arXiv:2203.10591",
    "title": "Policy Gradients using Variational Quantum Circuits",
    "abstract": "Policy Gradients using Variational Quantum Circuits",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Sequeira",
      "Luis Paulo Santos",
      "Lu\u00eds Soares Barbosa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10591"
  },
  {
    "id": "arXiv:2203.10929",
    "title": "General and Domain Adaptive Chinese Spelling Check with Error Consistent  Pretraining",
    "abstract": "General and Domain Adaptive Chinese Spelling Check with Error Consistent  Pretraining",
    "descriptor": "",
    "authors": [
      "Qi Lv",
      "Ziqiang Cao",
      "Lei Geng",
      "Chunhui Ai",
      "Xu Yan",
      "Guohong Fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.10929"
  },
  {
    "id": "arXiv:2203.11092",
    "title": "Automated Clinical Coding: What, Why, and Where We Are?",
    "abstract": "Comments: accepted for npj Digital Medicine",
    "descriptor": "\nComments: accepted for npj Digital Medicine\n",
    "authors": [
      "Hang Dong",
      "Mat\u00fa\u0161 Falis",
      "William Whiteley",
      "Beatrice Alex",
      "Joshua Matterson",
      "Shaoxiong Ji",
      "Jiaoyan Chen",
      "Honghan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11092"
  },
  {
    "id": "arXiv:2203.11184",
    "title": "A discontinuous Galerkin spectral element method for a nonconservative  compressible multicomponent flow model",
    "abstract": "A discontinuous Galerkin spectral element method for a nonconservative  compressible multicomponent flow model",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Abgrall",
      "Pratik Rai",
      "Florent Renac"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11184"
  },
  {
    "id": "arXiv:2203.12577",
    "title": "Minimax Regret for Cascading Bandits",
    "abstract": "Minimax Regret for Cascading Bandits",
    "descriptor": "",
    "authors": [
      "Daniel Vial",
      "Sujay Sanghavi",
      "Sanjay Shakkottai",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.12577"
  },
  {
    "id": "arXiv:2203.14619",
    "title": "Data-driven micromobility network planning for demand and safety",
    "abstract": "Comments: Main text: 16 pages, 5 figures, SI: 12 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: Main text: 16 pages, 5 figures, SI: 12 pages, 9 figures, 4 tables\n",
    "authors": [
      "Pietro Folco",
      "Laetitia Gauvin",
      "Michele Tizzoni",
      "Michael Szell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.14619"
  },
  {
    "id": "arXiv:2203.15335",
    "title": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "abstract": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "descriptor": "",
    "authors": [
      "Danial Ebrat",
      "Farzad Didehvar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15335"
  },
  {
    "id": "arXiv:2203.16406",
    "title": "PerfectDou: Dominating DouDizhu with Perfect Information Distillation",
    "abstract": "Comments: 23 pages, 8 figures, 13 tables. Published at NeurIPS 2022. The first two authors contribute equally. Project page at this https URL",
    "descriptor": "\nComments: 23 pages, 8 figures, 13 tables. Published at NeurIPS 2022. The first two authors contribute equally. Project page at this https URL\n",
    "authors": [
      "Guan Yang",
      "Minghuan Liu",
      "Weijun Hong",
      "Weinan Zhang",
      "Fei Fang",
      "Guangjun Zeng",
      "Yue Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16406"
  },
  {
    "id": "arXiv:2203.16757",
    "title": "Exploiting Single-Channel Speech for Multi-Channel End-to-End Speech  Recognition: A Comparative Study",
    "abstract": "Comments: Accepted by ISCSLP 2022. arXiv admin note: substantial text overlap with arXiv:2107.02670",
    "descriptor": "\nComments: Accepted by ISCSLP 2022. arXiv admin note: substantial text overlap with arXiv:2107.02670\n",
    "authors": [
      "Keyu An",
      "Ji Xiao",
      "Zhijian Ou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16757"
  },
  {
    "id": "arXiv:2203.17010",
    "title": "Consistency of randomized integration methods",
    "abstract": "Comments: 17 pages. The main results have been improved and an error has been corrected",
    "descriptor": "\nComments: 17 pages. The main results have been improved and an error has been corrected\n",
    "authors": [
      "Julian Hofstadler",
      "Daniel Rudolf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17010"
  },
  {
    "id": "arXiv:2204.00903",
    "title": "Safety Verification of Neural Feedback Systems Based on Constrained  Zonotopes",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Yuhao Zhang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00903"
  },
  {
    "id": "arXiv:2204.01005",
    "title": "Frequency and Multi-Scale Selective Kernel Attention for Speaker  Verification",
    "abstract": "Comments: Accepted by IEEE SLT 2022. 7 pages, 4 figures, 1 table. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE SLT 2022. 7 pages, 4 figures, 1 table. Code is available at this https URL\n",
    "authors": [
      "Sung Hwan Mun",
      "Jee-weon Jung",
      "Min Hyun Han",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01005"
  },
  {
    "id": "arXiv:2204.01713",
    "title": "Exemplar Learning for Medical Image Segmentation",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Qing En",
      "Yuhong Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01713"
  },
  {
    "id": "arXiv:2204.01936",
    "title": "Hall-type theorems for fast dynamic matching and applications",
    "abstract": "Comments: This version is a major improvement of the previous one. The case of full dynamic matching is now covered. The title has been changed to reflect this. Abstract abridged to conform to arxiv requirements",
    "descriptor": "\nComments: This version is a major improvement of the previous one. The case of full dynamic matching is now covered. The title has been changed to reflect this. Abstract abridged to conform to arxiv requirements\n",
    "authors": [
      "Bruno Bauwens",
      "Marius Zimand"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.01936"
  },
  {
    "id": "arXiv:2204.02329",
    "title": "Can language models learn from explanations in context?",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Andrew K. Lampinen",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Kory Matthewson",
      "Michael Henry Tessler",
      "Antonia Creswell",
      "James L. McClelland",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02329"
  },
  {
    "id": "arXiv:2204.02350",
    "title": "Information-Theoretic Policy Learning from Partial Observations with  Fully Informed Decision Makers",
    "abstract": "Information-Theoretic Policy Learning from Partial Observations with  Fully Informed Decision Makers",
    "descriptor": "",
    "authors": [
      "Tom Lefebvre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02350"
  },
  {
    "id": "arXiv:2204.02662",
    "title": "Accelerating Backward Aggregation in GCN Training with Execution Path  Preparing on GPUs",
    "abstract": "Accelerating Backward Aggregation in GCN Training with Execution Path  Preparing on GPUs",
    "descriptor": "",
    "authors": [
      "Shaoxian Xu",
      "Zhiyuan Shao",
      "Ci Yang",
      "Xiaofei Liao",
      "Hai Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02662"
  },
  {
    "id": "arXiv:2204.04875",
    "title": "Learning to Induce Causal Structure",
    "abstract": "Learning to Induce Causal Structure",
    "descriptor": "",
    "authors": [
      "Nan Rosemary Ke",
      "Silvia Chiappa",
      "Jane Wang",
      "Anirudh Goyal",
      "Jorg Bornschein",
      "Melanie Rey",
      "Theophane Weber",
      "Matthew Botvinic",
      "Michael Mozer",
      "Danilo Jimenez Rezende"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04875"
  },
  {
    "id": "arXiv:2204.05928",
    "title": "Dynamic Dialogue Policy for Continual Reinforcement Learning",
    "abstract": "Dynamic Dialogue Policy for Continual Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Christian Geishauser",
      "Carel van Niekerk",
      "Nurul Lubis",
      "Michael Heck",
      "Hsien-Chin Lin",
      "Shutong Feng",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05928"
  },
  {
    "id": "arXiv:2204.07554",
    "title": "Efficient Architecture Search for Diverse Tasks",
    "abstract": "Comments: NeurIPS 2022 Camera-Ready; code available at this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Camera-Ready; code available at this https URL\n",
    "authors": [
      "Junhong Shen",
      "Mikhail Khodak",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07554"
  },
  {
    "id": "arXiv:2204.07723",
    "title": "Local multiscale model reduction using discontinuous Galerkin coupling  for elasticity problems",
    "abstract": "Local multiscale model reduction using discontinuous Galerkin coupling  for elasticity problems",
    "descriptor": "",
    "authors": [
      "Zhongqian Wang",
      "Shubin Fu",
      "Eric Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07723"
  },
  {
    "id": "arXiv:2204.08110",
    "title": "Language Contamination Helps Explain the Cross-lingual Capabilities of  English Pretrained Models",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Terra Blevins",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08110"
  },
  {
    "id": "arXiv:2204.08329",
    "title": "A Comprehensive Survey on Data-Efficient GANs in Image Generation",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ziqiang Li",
      "Beihao Xia",
      "Jing Zhang",
      "Chaoyue Wang",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08329"
  },
  {
    "id": "arXiv:2204.09819",
    "title": "Extensible Database Simulator for Fast Prototyping In-Database  Algorithms",
    "abstract": "Comments: Accepted by CIKM 2022",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Yifan Wang",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.09819"
  },
  {
    "id": "arXiv:2204.09957",
    "title": "Self-paced Multi-grained Cross-modal Interaction Modeling for Referring  Expression Comprehension",
    "abstract": "Self-paced Multi-grained Cross-modal Interaction Modeling for Referring  Expression Comprehension",
    "descriptor": "",
    "authors": [
      "Peihan Miao",
      "Wei Su",
      "Gaoang Wang",
      "Xuewei Li",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.09957"
  },
  {
    "id": "arXiv:2204.12985",
    "title": "Quantum Linear Optics via String Diagrams",
    "abstract": "Comments: Accepted at QPL2022",
    "descriptor": "\nComments: Accepted at QPL2022\n",
    "authors": [
      "Giovanni de Felice",
      "Bob Coecke"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.12985"
  },
  {
    "id": "arXiv:2204.13413",
    "title": "HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification",
    "abstract": "Comments: First two authors contribute equally. Accepted by EMNLP 2022",
    "descriptor": "\nComments: First two authors contribute equally. Accepted by EMNLP 2022\n",
    "authors": [
      "Zihan Wang",
      "Peiyi Wang",
      "Tianyu Liu",
      "Binghuai Lin",
      "Yunbo Cao",
      "Zhifang Sui",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.13413"
  },
  {
    "id": "arXiv:2205.00160",
    "title": "Elucidating Meta-Structures of Noisy Labels in Semantic Segmentation by  Deep Neural Networks",
    "abstract": "Elucidating Meta-Structures of Noisy Labels in Semantic Segmentation by  Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Yaoru Luo",
      "Guole Liu",
      "Yuanhao Guo",
      "Ge Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00160"
  },
  {
    "id": "arXiv:2205.00305",
    "title": "AdapterBias: Parameter-efficient Token-dependent Representation Shift  for Adapters in NLP Tasks",
    "abstract": "Comments: Findings of NAACL 2022",
    "descriptor": "\nComments: Findings of NAACL 2022\n",
    "authors": [
      "Chin-Lun Fu",
      "Zih-Ching Chen",
      "Yun-Ru Lee",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00305"
  },
  {
    "id": "arXiv:2205.00970",
    "title": "LIDER: An Efficient High-dimensional Learned Index for Large-scale Dense  Passage Retrieval",
    "abstract": "Comments: Accepted by VLDB 2023",
    "descriptor": "\nComments: Accepted by VLDB 2023\n",
    "authors": [
      "Yifan Wang",
      "Haodi Ma",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.00970"
  },
  {
    "id": "arXiv:2205.01536",
    "title": "BiOcularGAN: Bimodal Synthesis and Annotation of Ocular Images",
    "abstract": "Comments: 13 pages, 14 figures",
    "descriptor": "\nComments: 13 pages, 14 figures\n",
    "authors": [
      "Darian Toma\u0161evi\u0107",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01536"
  },
  {
    "id": "arXiv:2205.01920",
    "title": "Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial  View Object Classification",
    "abstract": "Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial  View Object Classification",
    "descriptor": "",
    "authors": [
      "Jun Yu",
      "Hao Chang",
      "Keda Lu",
      "Liwen Zhang",
      "Shenshen Du",
      "Zhong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01920"
  },
  {
    "id": "arXiv:2205.05131",
    "title": "UL2: Unifying Language Learning Paradigms",
    "abstract": "Comments: Updated Q4 2022 with new authors and experiments",
    "descriptor": "\nComments: Updated Q4 2022 with new authors and experiments\n",
    "authors": [
      "Yi Tay",
      "Mostafa Dehghani",
      "Vinh Q. Tran",
      "Xavier Garcia",
      "Jason Wei",
      "Xuezhi Wang",
      "Hyung Won Chung",
      "Dara Bahri",
      "Tal Schuster",
      "Huaixiu Steven Zheng",
      "Denny Zhou",
      "Neil Houlsby",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05131"
  },
  {
    "id": "arXiv:2205.05177",
    "title": "ConfLab: A Data Collection Concept, Dataset, and Benchmark for Machine  Analysis of Free-Standing Social Interactions in the Wild",
    "abstract": "Comments: In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS D&B)",
    "descriptor": "\nComments: In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS D&B)\n",
    "authors": [
      "Chirag Raman",
      "Jose Vargas-Quiros",
      "Stephanie Tan",
      "Ashraful Islam",
      "Ekin Gedik",
      "Hayley Hung"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05177"
  },
  {
    "id": "arXiv:2205.05461",
    "title": "Making Pretrained Language Models Good Long-tailed Learners",
    "abstract": "Comments: 15 pages, 4 figures, 10 tables, accepted to EMNLP 2022. Code is available at this https URL",
    "descriptor": "\nComments: 15 pages, 4 figures, 10 tables, accepted to EMNLP 2022. Code is available at this https URL\n",
    "authors": [
      "Chen Zhang",
      "Lei Ren",
      "Jingang Wang",
      "Wei Wu",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05461"
  },
  {
    "id": "arXiv:2205.06664",
    "title": "NN-EUCLID: deep-learning hyperelasticity without stress data",
    "abstract": "Comments: 31 pages, 17 figures",
    "descriptor": "\nComments: 31 pages, 17 figures\n",
    "authors": [
      "Prakash Thakolkaran",
      "Akshay Joshi",
      "Yiwen Zheng",
      "Moritz Flaschel",
      "Laura De Lorenzis",
      "Siddhant Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.06664"
  },
  {
    "id": "arXiv:2205.06971",
    "title": "Design of a Reconfigurable Intelligent Surface-Assisted FM-DCSK-SWIPT  Scheme with Non-linear Energy Harvesting Model",
    "abstract": "Design of a Reconfigurable Intelligent Surface-Assisted FM-DCSK-SWIPT  Scheme with Non-linear Energy Harvesting Model",
    "descriptor": "",
    "authors": [
      "Yi Fang",
      "Yiwei Tao",
      "Huan Ma",
      "Yonghui Li",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.06971"
  },
  {
    "id": "arXiv:2205.06983",
    "title": "RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model  for Text-to-SQL",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Jiexing Qi",
      "Jingyao Tang",
      "Ziwei He",
      "Xiangpeng Wan",
      "Yu Cheng",
      "Chenghu Zhou",
      "Xinbing Wang",
      "Quanshi Zhang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06983"
  },
  {
    "id": "arXiv:2205.07493",
    "title": "Multi-scale Attention Flow for Probabilistic Time Series Forecasting",
    "abstract": "Multi-scale Attention Flow for Probabilistic Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Shibo Feng",
      "Ke Xu",
      "Jiaxiang Wu",
      "Pengcheng Wu",
      "Fan Lin",
      "Peilin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.07493"
  },
  {
    "id": "arXiv:2205.09332",
    "title": "Accelerated Training of Physics-Informed Neural Networks (PINNs) using  Meshless Discretizations",
    "abstract": "Comments: Accepted at the 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted at the 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09332"
  },
  {
    "id": "arXiv:2205.09546",
    "title": "Closing the gap: Exact maximum likelihood training of generative  autoencoders using invertible layers",
    "abstract": "Closing the gap: Exact maximum likelihood training of generative  autoencoders using invertible layers",
    "descriptor": "",
    "authors": [
      "Gianluigi Silvestri",
      "Daan Roos",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09546"
  },
  {
    "id": "arXiv:2205.10636",
    "title": "AutoLink: Self-supervised Learning of Human Skeletons and Object  Outlines by Linking Keypoints",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10636"
  },
  {
    "id": "arXiv:2205.10683",
    "title": "Scalable and Efficient Training of Large Convolutional Neural Networks  with Differential Privacy",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Zhiqi Bu",
      "Jialin Mao",
      "Shiyun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10683"
  },
  {
    "id": "arXiv:2205.10715",
    "title": "Policy-based Primal-Dual Methods for Convex Constrained Markov Decision  Processes",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Donghao Ying",
      "Mengzi Amy Guo",
      "Yuhao Ding",
      "Javad Lavaei",
      "Zuo-Jun Max Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.10715"
  },
  {
    "id": "arXiv:2205.10920",
    "title": "Test-Time Robust Personalization for Federated Learning",
    "abstract": "Comments: LJ and TL contribute equally",
    "descriptor": "\nComments: LJ and TL contribute equally\n",
    "authors": [
      "Liangze Jiang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10920"
  },
  {
    "id": "arXiv:2205.11048",
    "title": "GBA: A Tuning-free Approach to Switch between Synchronous and  Asynchronous Training for Recommendation Model",
    "abstract": "GBA: A Tuning-free Approach to Switch between Synchronous and  Asynchronous Training for Recommendation Model",
    "descriptor": "",
    "authors": [
      "Wenbo Su",
      "Yuanxing Zhang",
      "Yufeng Cai",
      "Kaixu Ren",
      "Pengjie Wang",
      "Huimin Yi",
      "Yue Song",
      "Jing Chen",
      "Hongbo Deng",
      "Jian Xu",
      "Lin Qu",
      "Bo zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.11048"
  },
  {
    "id": "arXiv:2205.11393",
    "title": "Generic bounds on the approximation error for physics-informed (and)  operator learning",
    "abstract": "Generic bounds on the approximation error for physics-informed (and)  operator learning",
    "descriptor": "",
    "authors": [
      "Tim De Ryck",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.11393"
  },
  {
    "id": "arXiv:2205.11443",
    "title": "Unsupervised Tokenization Learning",
    "abstract": "Comments: 16 pages, 9 figures, paper accepted for EMNLP 2022 conference",
    "descriptor": "\nComments: 16 pages, 9 figures, paper accepted for EMNLP 2022 conference\n",
    "authors": [
      "Anton Kolonin",
      "Vignav Ramesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.11443"
  },
  {
    "id": "arXiv:2205.12156",
    "title": "Not too little, not too much: a theoretical analysis of graph  (over)smoothing",
    "abstract": "Not too little, not too much: a theoretical analysis of graph  (over)smoothing",
    "descriptor": "",
    "authors": [
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12156"
  },
  {
    "id": "arXiv:2205.12404",
    "title": "FLUTE: Figurative Language Understanding through Textual Explanations",
    "abstract": "Comments: EMNLP 2022 Main Conference (Long Paper)",
    "descriptor": "\nComments: EMNLP 2022 Main Conference (Long Paper)\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Arkadiy Saakyan",
      "Debanjan Ghosh",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12404"
  },
  {
    "id": "arXiv:2205.12522",
    "title": "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ashish V. Thapliyal",
      "Jordi Pont-Tuset",
      "Xi Chen",
      "Radu Soricut"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12522"
  },
  {
    "id": "arXiv:2205.12662",
    "title": "DFM: Dialogue Foundation Model for Universal Large-Scale  Dialogue-Oriented Task Learning",
    "abstract": "Comments: Work in Progress",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Zhi Chen",
      "Jijia Bao",
      "Lu Chen",
      "Yuncong Liu",
      "Da Ma",
      "Bei Chen",
      "Mengyue Wu",
      "Su Zhu",
      "Xin Dong",
      "Fujiang Ge",
      "Qingliang Miao",
      "Jian-Guang Lou",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12662"
  },
  {
    "id": "arXiv:2205.12850",
    "title": "A Universal Error Measure for Input Predictions Applied to Online Graph  Problems",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Giulia Bernardini",
      "Alexander Lindermayr",
      "Alberto Marchetti-Spaccamela",
      "Nicole Megow",
      "Leen Stougie",
      "Michelle Sweering"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12850"
  },
  {
    "id": "arXiv:2205.13479",
    "title": "Learning to Reconstruct Missing Data from Spatiotemporal Graphs with  Sparse Observations",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ivan Marisca",
      "Andrea Cini",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13479"
  },
  {
    "id": "arXiv:2205.13599",
    "title": "VectorAdam for Rotation Equivariant Geometry Optimization",
    "abstract": "Comments: 10 pages, 9 figures",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Selena Ling",
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.13599"
  },
  {
    "id": "arXiv:2205.13603",
    "title": "Tensor Program Optimization with Probabilistic Programs",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Junru Shao",
      "Xiyou Zhou",
      "Siyuan Feng",
      "Bohan Hou",
      "Ruihang Lai",
      "Hongyi Jin",
      "Wuwei Lin",
      "Masahiro Masuda",
      "Cody Hao Yu",
      "Tianqi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13603"
  },
  {
    "id": "arXiv:2205.13679",
    "title": "SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching",
    "abstract": "SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching",
    "descriptor": "",
    "authors": [
      "Liren Yu",
      "Jiaming Xu",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13679"
  },
  {
    "id": "arXiv:2205.14173",
    "title": "Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal  Attention, and Optimal Transport",
    "abstract": "Comments: Comments are welcome",
    "descriptor": "\nComments: Comments are welcome\n",
    "authors": [
      "Lingkai Kong",
      "Yuqing Wang",
      "Molei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14173"
  },
  {
    "id": "arXiv:2205.14258",
    "title": "On the Symmetries of Deep Learning Models and their Internal  Representations",
    "abstract": "Comments: CG and DB contributed equally. V2: clarified relationship between metric $\\mu_{\\mathrm{CKA}}$ and existing instances of CKA. V3: expanded experiment suite (LASSO stitching, stitching with a small ViT, dissimilarity measures for a constant channel width CNN, more runs across the board), alternative stitching layer capacity comparison, calculation of GeLU intertwiner group",
    "descriptor": "\nComments: CG and DB contributed equally. V2: clarified relationship between metric $\\mu_{\\mathrm{CKA}}$ and existing instances of CKA. V3: expanded experiment suite (LASSO stitching, stitching with a small ViT, dissimilarity measures for a constant channel width CNN, more runs across the board), alternative stitching layer capacity comparison, calculation of GeLU intertwiner group\n",
    "authors": [
      "Charles Godfrey",
      "Davis Brown",
      "Tegan Emerson",
      "Henry Kvinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14258"
  },
  {
    "id": "arXiv:2205.14410",
    "title": "Multi-Source Transfer Learning for Deep Model-Based Reinforcement  Learning",
    "abstract": "Comments: 15 pages, 6 figures, 8 tables. arXiv admin note: text overlap with arXiv:2108.06526",
    "descriptor": "\nComments: 15 pages, 6 figures, 8 tables. arXiv admin note: text overlap with arXiv:2108.06526\n",
    "authors": [
      "Remo Sasso",
      "Matthia Sabatelli",
      "Marco A. Wiering"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14410"
  },
  {
    "id": "arXiv:2205.14484",
    "title": "Happenstance: Utilizing Semantic Search to Track Russian State Media  Narratives about the Russo-Ukrainian War On Reddit",
    "abstract": "Comments: Accepted to ICWSM 2023",
    "descriptor": "\nComments: Accepted to ICWSM 2023\n",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14484"
  },
  {
    "id": "arXiv:2205.14523",
    "title": "Risk of Stochastic Systems for Temporal Logic Specifications",
    "abstract": "Risk of Stochastic Systems for Temporal Logic Specifications",
    "descriptor": "",
    "authors": [
      "Lars Lindemann",
      "Lejun Jiang",
      "Nikolai Matni",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.14523"
  },
  {
    "id": "arXiv:2205.14871",
    "title": "You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer  for Image Enhancement and Exposure Correction",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Ziteng Cui",
      "Kunchang Li",
      "Lin Gu",
      "Shenghan Su",
      "Peng Gao",
      "Zhengkai Jiang",
      "Yu Qiao",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14871"
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15117"
  },
  {
    "id": "arXiv:2205.15288",
    "title": "Self-Supervised Visual Representation Learning with Semantic Grouping",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Xin Wen",
      "Bingchen Zhao",
      "Anlin Zheng",
      "Xiangyu Zhang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15288"
  },
  {
    "id": "arXiv:2205.15367",
    "title": "Non-Markovian Reward Modelling from Trajectory Labels via Interpretable  Multiple Instance Learning",
    "abstract": "Comments: 27 pages (10 main content; 2 references; 1 checklist; 14 appendix). 14 figures (9 main content; 5 appendix). Published at NeurIPS 2022. Revisions: v2) Updated to NeurIPS camera ready version (extra experiments)",
    "descriptor": "\nComments: 27 pages (10 main content; 2 references; 1 checklist; 14 appendix). 14 figures (9 main content; 5 appendix). Published at NeurIPS 2022. Revisions: v2) Updated to NeurIPS camera ready version (extra experiments)\n",
    "authors": [
      "Joseph Early",
      "Tom Bewley",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15367"
  },
  {
    "id": "arXiv:2205.15860",
    "title": "A Reduction to Binary Approach for Debiasing Multiclass Datasets",
    "abstract": "Comments: 18 pages, 5 figures",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Jessica Schrouff",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15860"
  },
  {
    "id": "arXiv:2206.00416",
    "title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Amir Feder",
      "Guy Horowitz",
      "Yoav Wald",
      "Roi Reichart",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00416"
  },
  {
    "id": "arXiv:2206.01201",
    "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual  Question Answering",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yuanze Lin",
      "Yujia Xie",
      "Dongdong Chen",
      "Yichong Xu",
      "Chenguang Zhu",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01201"
  },
  {
    "id": "arXiv:2206.02016",
    "title": "Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network?",
    "abstract": "Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network?",
    "descriptor": "",
    "authors": [
      "Chuwei Wang",
      "Shanda Li",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02016"
  },
  {
    "id": "arXiv:2206.02147",
    "title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for  Text-to-Speech",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Ziyue Jiang",
      "Su Zhe",
      "Zhou Zhao",
      "Qian Yang",
      "Yi Ren",
      "Jinglin Liu",
      "Zhenhui Ye"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02147"
  },
  {
    "id": "arXiv:2206.02262",
    "title": "Diffusion-GAN: Training GANs with Diffusion",
    "abstract": "Comments: Project homepage: this https URL",
    "descriptor": "\nComments: Project homepage: this https URL\n",
    "authors": [
      "Zhendong Wang",
      "Huangjie Zheng",
      "Pengcheng He",
      "Weizhu Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02262"
  },
  {
    "id": "arXiv:2206.02369",
    "title": "Learning to Break the Loop: Analyzing and Mitigating Repetitions for  Neural Text Generation",
    "abstract": "Comments: Accepted by NeurIPS 2022. Code is released at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Code is released at this https URL\n",
    "authors": [
      "Jin Xu",
      "Xiaojiang Liu",
      "Jianhao Yan",
      "Deng Cai",
      "Huayang Li",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02369"
  },
  {
    "id": "arXiv:2206.02628",
    "title": "HYCEDIS: HYbrid Confidence Engine for Deep Document Intelligence System",
    "abstract": "Comments: Document Intelligence @ KDD 2021 Workshop",
    "descriptor": "\nComments: Document Intelligence @ KDD 2021 Workshop\n",
    "authors": [
      "Bao-Sinh Nguyen",
      "Quang-Bach Tran",
      "Tuan-Anh Nguyen Dang",
      "Duc Nguyen",
      "Hung Le"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02628"
  },
  {
    "id": "arXiv:2206.02953",
    "title": "Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax  Optimization",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Aniket Das",
      "Bernhard Sch\u00f6lkopf",
      "Michael Muehlebach"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02953"
  },
  {
    "id": "arXiv:2206.03287",
    "title": "NeMF: Neural Motion Fields for Kinematic Animation",
    "abstract": "Comments: Accepted to NeurIPS 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Project page: this https URL\n",
    "authors": [
      "Chengan He",
      "Jun Saito",
      "James Zachary",
      "Holly Rushmeier",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.03287"
  },
  {
    "id": "arXiv:2206.03413",
    "title": "Deep Learning based Direct Segmentation Assisted by Deformable Image  Registration for Cone-Beam CT based Auto-Segmentation for Adaptive  Radiotherapy",
    "abstract": "Deep Learning based Direct Segmentation Assisted by Deformable Image  Registration for Cone-Beam CT based Auto-Segmentation for Adaptive  Radiotherapy",
    "descriptor": "",
    "authors": [
      "Xiao Liang",
      "Howard Morgan",
      "Ti Bai",
      "Michael Dohopolski",
      "Dan Nguyen",
      "Steve Jiang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03413"
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "descriptor": "",
    "authors": [
      "Adrien Raison",
      "Pascal Bourdon",
      "David Helbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03491"
  },
  {
    "id": "arXiv:2206.04525",
    "title": "Large-Scale Crosstalk-Corrected Thermo-Optic Phase Shifter Arrays in  Silicon Photonics",
    "abstract": "Comments: 12 pages and 19 figures",
    "descriptor": "\nComments: 12 pages and 19 figures\n",
    "authors": [
      "Volkan Gurses",
      "Reza Fatemi",
      "Aroutin Khachaturian",
      "Ali Hajimiri"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.04525"
  },
  {
    "id": "arXiv:2206.04745",
    "title": "Mildly Conservative Q-Learning for Offline Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jiafei Lyu",
      "Xiaoteng Ma",
      "Xiu Li",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04745"
  },
  {
    "id": "arXiv:2206.06119",
    "title": "Satellite-based high-resolution maps of cocoa for C\u00f4te d'Ivoire and  Ghana",
    "abstract": "Satellite-based high-resolution maps of cocoa for C\u00f4te d'Ivoire and  Ghana",
    "descriptor": "",
    "authors": [
      "Nikolai Kalischek",
      "Nico Lang",
      "C\u00e9cile Renier",
      "Rodrigo Caye Daudt",
      "Thomas Addoah",
      "William Thompson",
      "Wilma J. Blaser-Hart",
      "Rachael Garrett",
      "Konrad Schindler",
      "Jan D. Wegner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06119"
  },
  {
    "id": "arXiv:2206.06122",
    "title": "Singular Value Fine-tuning: Few-shot Segmentation requires  Few-parameters Fine-tuning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Yanpeng Sun",
      "Qiang Chen",
      "Xiangyu He",
      "Jian Wang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding",
      "Jian Cheng",
      "Zechao Li",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06122"
  },
  {
    "id": "arXiv:2206.06282",
    "title": "Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement  Learning for Robotic Manipulation Tasks",
    "abstract": "Comments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022",
    "descriptor": "\nComments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Josip Josifovski",
      "Mohammadhossein Malmir",
      "Noah Klarmann",
      "Bare Luka \u017dagar",
      "Nicol\u00e1s Navarro-Guerrero",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06282"
  },
  {
    "id": "arXiv:2206.06758",
    "title": "Universally Expressive Communication in Multi-Agent Reinforcement  Learning",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Matthew Morris",
      "Thomas D. Barrett",
      "Arnu Pretorius"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06758"
  },
  {
    "id": "arXiv:2206.07243",
    "title": "Closed-form Approximation for Performance Bound of Finite Blocklength  Massive MIMO Transmission",
    "abstract": "Closed-form Approximation for Performance Bound of Finite Blocklength  Massive MIMO Transmission",
    "descriptor": "",
    "authors": [
      "Xiaohu You",
      "Bin Sheng",
      "Yongming Huang",
      "Wei Xu",
      "Chuan Zhang",
      "Dongming Wang",
      "Pengcheng Zhu",
      "Chen Ji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.07243"
  },
  {
    "id": "arXiv:2206.07267",
    "title": "Rethinking Generalization in Few-Shot Classification",
    "abstract": "Comments: Accepted at NeurIPS 2022. Code available at this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Code available at this https URL\n",
    "authors": [
      "Markus Hiller",
      "Rongkai Ma",
      "Mehrtash Harandi",
      "Tom Drummond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07267"
  },
  {
    "id": "arXiv:2206.07594",
    "title": "Robust and Sparse Estimation of Linear Regression Coefficients with  Heavy-tailed Noises and Covariates",
    "abstract": "Comments: Some mistakes are corrected, and one assumption is added to the main theorem",
    "descriptor": "\nComments: Some mistakes are corrected, and one assumption is added to the main theorem\n",
    "authors": [
      "Takeyuki Sasai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07594"
  },
  {
    "id": "arXiv:2206.07824",
    "title": "Large-Scale Differentiable Causal Discovery of Factor Graphs",
    "abstract": "Comments: 33 pages, 12 figures",
    "descriptor": "\nComments: 33 pages, 12 figures\n",
    "authors": [
      "Romain Lopez",
      "Jan-Christian H\u00fctter",
      "Jonathan K. Pritchard",
      "Aviv Regev"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.07824"
  },
  {
    "id": "arXiv:2206.07837",
    "title": "Modeling the Data-Generating Process is Necessary for  Out-of-Distribution Generalization",
    "abstract": "Modeling the Data-Generating Process is Necessary for  Out-of-Distribution Generalization",
    "descriptor": "",
    "authors": [
      "Jivat Neet Kaur",
      "Emre Kiciman",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07837"
  },
  {
    "id": "arXiv:2206.07989",
    "title": "Double Check Your State Before Trusting It: Confidence-Aware  Bidirectional Offline Model-Based Imagination",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jiafei Lyu",
      "Xiu Li",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07989"
  },
  {
    "id": "arXiv:2206.08155",
    "title": "Zero-Shot Video Question Answering via Frozen Bidirectional Language  Models",
    "abstract": "Comments: NeurIPS 2022 Camera-Ready; Project Webpage: this https URL; 25 pages; 5 figures",
    "descriptor": "\nComments: NeurIPS 2022 Camera-Ready; Project Webpage: this https URL; 25 pages; 5 figures\n",
    "authors": [
      "Antoine Yang",
      "Antoine Miech",
      "Josef Sivic",
      "Ivan Laptev",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08155"
  },
  {
    "id": "arXiv:2206.08644",
    "title": "A Hybrid Modelling Approach for Aerial Manipulators",
    "abstract": "Comments: 26 pages, 12 figures, published in the Journal of Intelligent and Robotic Systems (JINT/Springer); corrected affiliations and typos",
    "descriptor": "\nComments: 26 pages, 12 figures, published in the Journal of Intelligent and Robotic Systems (JINT/Springer); corrected affiliations and typos\n",
    "authors": [
      "Paul Kremer",
      "Jose Luis Sanchez-Lopez",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08644"
  },
  {
    "id": "arXiv:2206.10991",
    "title": "Graph Neural Networks as Gradient Flows: understanding graph  convolutions via energy",
    "abstract": "Comments: First two authors equal contribution; 39 pages",
    "descriptor": "\nComments: First two authors equal contribution; 39 pages\n",
    "authors": [
      "Francesco Di Giovanni",
      "James Rowbottom",
      "Benjamin P. Chamberlain",
      "Thomas Markovich",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10991"
  },
  {
    "id": "arXiv:2206.12411",
    "title": "Sample Efficiency Matters: A Benchmark for Practical Molecular  Optimization",
    "abstract": "Sample Efficiency Matters: A Benchmark for Practical Molecular  Optimization",
    "descriptor": "",
    "authors": [
      "Wenhao Gao",
      "Tianfan Fu",
      "Jimeng Sun",
      "Connor W. Coley"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2206.12411"
  },
  {
    "id": "arXiv:2206.12797",
    "title": "Impact of Channel Memory on the Data Freshness",
    "abstract": "Impact of Channel Memory on the Data Freshness",
    "descriptor": "",
    "authors": [
      "Qixing Guan",
      "Xiaoli Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12797"
  },
  {
    "id": "arXiv:2206.12839",
    "title": "Repository-Level Prompt Generation for Large Language Models of Code",
    "abstract": "Repository-Level Prompt Generation for Large Language Models of Code",
    "descriptor": "",
    "authors": [
      "Disha Shrivastava",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.12839"
  },
  {
    "id": "arXiv:2206.13594",
    "title": "Cyber Network Resilience against Self-Propagating Malware Attacks",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Alesia Chernikova",
      "Nicol\u00f2 Gozzi",
      "Simona Boboila",
      "Priyanka Angadi",
      "John Loughner",
      "Matthew Wilden",
      "Nicola Perra",
      "Tina Eliassi-Rad",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.13594"
  },
  {
    "id": "arXiv:2206.14504",
    "title": "GERNERMED++: Transfer Learning in German Medical NLP",
    "abstract": "GERNERMED++: Transfer Learning in German Medical NLP",
    "descriptor": "",
    "authors": [
      "Johann Frei",
      "Ludwig Frei-Stuber",
      "Frank Kramer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14504"
  },
  {
    "id": "arXiv:2206.14604",
    "title": "Mining Seasonal Temporal Patterns in Big Time Series",
    "abstract": "Mining Seasonal Temporal Patterns in Big Time Series",
    "descriptor": "",
    "authors": [
      "Van Long Ho",
      "Nguyen Ho",
      "Torben Bach Pedersen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.14604"
  },
  {
    "id": "arXiv:2206.14719",
    "title": "Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using  Self-Supervision",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14719"
  },
  {
    "id": "arXiv:2206.14797",
    "title": "3D-Aware Video Generation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Sherwin Bahmani",
      "Jeong Joon Park",
      "Despoina Paschalidou",
      "Hao Tang",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14797"
  },
  {
    "id": "arXiv:2206.14911",
    "title": "Minimum Weight Euclidean $(1+\\varepsilon)$-Spanners",
    "abstract": "Comments: 27 pages, 9 figures. An extended abstract appears in the Proceedings of WG 2022",
    "descriptor": "\nComments: 27 pages, 9 figures. An extended abstract appears in the Proceedings of WG 2022\n",
    "authors": [
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.14911"
  },
  {
    "id": "arXiv:2206.15055",
    "title": "Efficient Collective Action for Tackling Time-Critical Cybersecurity  Threats",
    "abstract": "Comments: 23 pages, 3 figures. Presented at the 21st Workshop on the Economics of Information Security (WEIS), 2022, Tulsa, USA",
    "descriptor": "\nComments: 23 pages, 3 figures. Presented at the 21st Workshop on the Economics of Information Security (WEIS), 2022, Tulsa, USA\n",
    "authors": [
      "S\u00e9bastien Gillard",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Thomas Maillart"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.15055"
  },
  {
    "id": "arXiv:2206.15374",
    "title": "Verification and search algorithms for causal DAGs",
    "abstract": "Verification and search algorithms for causal DAGs",
    "descriptor": "",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15374"
  },
  {
    "id": "arXiv:2206.15474",
    "title": "Forecasting Future World Events with Neural Networks",
    "abstract": "Comments: NeurIPS 2022; our dataset is available at this https URL",
    "descriptor": "\nComments: NeurIPS 2022; our dataset is available at this https URL\n",
    "authors": [
      "Andy Zou",
      "Tristan Xiao",
      "Ryan Jia",
      "Joe Kwon",
      "Mantas Mazeika",
      "Richard Li",
      "Dawn Song",
      "Jacob Steinhardt",
      "Owain Evans",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15474"
  },
  {
    "id": "arXiv:2207.00614",
    "title": "Integral Probability Metrics PAC-Bayes Bounds",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Ron Amit",
      "Baruch Epstein",
      "Shay Moran",
      "Ron Meir"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00614"
  },
  {
    "id": "arXiv:2207.00879",
    "title": "Tree ensemble kernels for Bayesian optimization with known constraints  over mixed-feature spaces",
    "abstract": "Comments: 27 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 27 pages, 9 figures, 4 tables\n",
    "authors": [
      "Alexander Thebelt",
      "Calvin Tsay",
      "Robert M. Lee",
      "Nathan Sudermann-Merx",
      "David Walz",
      "Behrang Shafei",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.00879"
  },
  {
    "id": "arXiv:2207.01472",
    "title": "Deep Contrastive One-Class Time Series Anomaly Detection",
    "abstract": "Deep Contrastive One-Class Time Series Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Chongwei Liu",
      "Xudong Mou",
      "Kai Gao",
      "Xiaohui Guo",
      "Pin Liu",
      "Tianyu Wo",
      "Xudong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01472"
  },
  {
    "id": "arXiv:2207.03337",
    "title": "Factorizing Knowledge in Neural Networks",
    "abstract": "Comments: ECCV2022 Camera Ready Version",
    "descriptor": "\nComments: ECCV2022 Camera Ready Version\n",
    "authors": [
      "Xingyi Yang",
      "Jingwen Ye",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03337"
  },
  {
    "id": "arXiv:2207.03694",
    "title": "HTRON:Efficient Outdoor Navigation with Sparse Rewards via Heavy Tailed  Adaptive Reinforce Algorithm",
    "abstract": "HTRON:Efficient Outdoor Navigation with Sparse Rewards via Heavy Tailed  Adaptive Reinforce Algorithm",
    "descriptor": "",
    "authors": [
      "Kasun Weerakoon",
      "Souradip Chakraborty",
      "Nare Karapetyan",
      "Adarsh Jagan Sathyamoorthy",
      "Amrit Singh Bedi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.03694"
  },
  {
    "id": "arXiv:2207.05372",
    "title": "Diversity-aware social robots meet people: beyond context-aware embodied  AI",
    "abstract": "Comments: The article has been presented during the Roundtable \"AI in holistic care and healing practices: the caring encounter beyond COVID-19\", Anthropology, AI and the Future of Human Society, 6-10 June 2022, Royal Anthropological Institute",
    "descriptor": "\nComments: The article has been presented during the Roundtable \"AI in holistic care and healing practices: the caring encounter beyond COVID-19\", Anthropology, AI and the Future of Human Society, 6-10 June 2022, Royal Anthropological Institute\n",
    "authors": [
      "Carmine Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.05372"
  },
  {
    "id": "arXiv:2207.05899",
    "title": "Neural Topological Ordering for Computation Graphs",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Mukul Gagrani",
      "Corrado Rainone",
      "Yang Yang",
      "Harris Teague",
      "Wonseok Jeon",
      "Herke Van Hoof",
      "Weiliang Will Zeng",
      "Piero Zappi",
      "Christopher Lott",
      "Roberto Bondesan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05899"
  },
  {
    "id": "arXiv:2207.06474",
    "title": "Dynamic State Estimation for Load Bus Protection on Inverter-Interfaced  Microgrids",
    "abstract": "Comments: 5 pages. 3 figures. 1 tables",
    "descriptor": "\nComments: 5 pages. 3 figures. 1 tables\n",
    "authors": [
      "Arthur K. Barnes",
      "Adam Mate",
      "Jean Marie V. Bikorimana",
      "Ricardo J. Castillo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.06474"
  },
  {
    "id": "arXiv:2207.06968",
    "title": "PR-DARTS: Pruning-Based Differentiable Architecture Search",
    "abstract": "Comments: 18 pages with 11 figures",
    "descriptor": "\nComments: 18 pages with 11 figures\n",
    "authors": [
      "Hamid Mousavi",
      "Mohammad Loni",
      "Mina Alibeigi",
      "Masoud Daneshtalab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06968"
  },
  {
    "id": "arXiv:2207.07719",
    "title": "Temporal Forward-Backward Consistency, Not Residual Error, Measures the  Prediction Accuracy of Extended Dynamic Mode Decomposition",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Masih Haseli",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.07719"
  },
  {
    "id": "arXiv:2207.08445",
    "title": "Automatic universal taxonomies for multi-domain semantic segmentation",
    "abstract": "Comments: 8 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Petra Bevandi\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08445"
  },
  {
    "id": "arXiv:2207.08494",
    "title": "Rethinking Alignment in Video Super-Resolution Transformers",
    "abstract": "Comments: This paper has been accepted for NeurIPS 2022",
    "descriptor": "\nComments: This paper has been accepted for NeurIPS 2022\n",
    "authors": [
      "Shuwei Shi",
      "Jinjin Gu",
      "Liangbin Xie",
      "Xintao Wang",
      "Yujiu Yang",
      "Chao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08494"
  },
  {
    "id": "arXiv:2207.08822",
    "title": "Is Integer Arithmetic Enough for Deep Learning Training?",
    "abstract": "Is Integer Arithmetic Enough for Deep Learning Training?",
    "descriptor": "",
    "authors": [
      "Alireza Ghaffari",
      "Marzieh S. Tahaei",
      "Mohammadreza Tayaranian",
      "Masoud Asgharian",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.08822"
  },
  {
    "id": "arXiv:2207.09847",
    "title": "Correspondences between word learning in children and captioning models",
    "abstract": "Correspondences between word learning in children and captioning models",
    "descriptor": "",
    "authors": [
      "Sunayana Rane",
      "Mira L. Nencheva",
      "Zeyu Wang",
      "Casey Lew-Williams",
      "Olga Russakovsky",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09847"
  },
  {
    "id": "arXiv:2207.10075",
    "title": "Is an Object-Centric Video Representation Beneficial for Transfer?",
    "abstract": "Comments: Accepted to ACCV 2022",
    "descriptor": "\nComments: Accepted to ACCV 2022\n",
    "authors": [
      "Chuhan Zhang",
      "Ankush Gupta",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10075"
  },
  {
    "id": "arXiv:2207.10751",
    "title": "Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization",
    "abstract": "Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization",
    "descriptor": "",
    "authors": [
      "Yankun Huang",
      "Qihang Lin",
      "Nick Street",
      "Stephen Baek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10751"
  },
  {
    "id": "arXiv:2207.11478",
    "title": "Overloaded Pilot Assignment with Pilot Decontamination for Cell-Free  Systems",
    "abstract": "Comments: 7 pages, 2 figures, this paper was submitted to IEEE WCNC 2023",
    "descriptor": "\nComments: 7 pages, 2 figures, this paper was submitted to IEEE WCNC 2023\n",
    "authors": [
      "Noboru Osawa",
      "Fabian G\u00f6ttsch",
      "Issei Kanno",
      "Takeo Ohseki",
      "Yoshiaki Amano",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.11478"
  },
  {
    "id": "arXiv:2207.13799",
    "title": "Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods",
    "abstract": "Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods",
    "descriptor": "",
    "authors": [
      "Ruben Interian",
      "Ruslan G. Marzo",
      "Isela Mendoza",
      "Celso C. Ribeiro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.13799"
  },
  {
    "id": "arXiv:2207.14526",
    "title": "Leveraging Explanations in Interactive Machine Learning: An Overview",
    "abstract": "Leveraging Explanations in Interactive Machine Learning: An Overview",
    "descriptor": "",
    "authors": [
      "Stefano Teso",
      "\u00d6znur Alkan",
      "Wolfang Stammer",
      "Elizabeth Daly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14526"
  },
  {
    "id": "arXiv:2207.14550",
    "title": "Best-of-Both-Worlds Algorithms for Partial Monitoring",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Taira Tsuchiya",
      "Shinji Ito",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.14550"
  },
  {
    "id": "arXiv:2208.00287",
    "title": "Simplex Clustering via sBeta with Applications to Online Adjustment of  Black-Box Predictions",
    "abstract": "Simplex Clustering via sBeta with Applications to Online Adjustment of  Black-Box Predictions",
    "descriptor": "",
    "authors": [
      "Florent Chiaroni",
      "Malik Boudiaf",
      "Amar Mitiche",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.00287"
  },
  {
    "id": "arXiv:2208.00543",
    "title": "ERC-20R and ERC-721R: Reversible Transactions on Ethereum",
    "abstract": "ERC-20R and ERC-721R: Reversible Transactions on Ethereum",
    "descriptor": "",
    "authors": [
      "Kaili Wang",
      "Qinchen Wang",
      "Dan Boneh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.00543"
  },
  {
    "id": "arXiv:2208.01436",
    "title": "Predicting Future Mosquito Larval Habitats Using Time Series Climate  Forecasting and Deep Learning",
    "abstract": "Comments: 2022 MIT IEEE Undergraduate Research Technology Conference",
    "descriptor": "\nComments: 2022 MIT IEEE Undergraduate Research Technology Conference\n",
    "authors": [
      "Christopher Sun",
      "Jay Nimbalkar",
      "Ravnoor Bedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01436"
  },
  {
    "id": "arXiv:2208.01813",
    "title": "TAG: Boosting Text-VQA via Text-aware Visual Question-answer Generation",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Jun Wang",
      "Mingfei Gao",
      "Yuqian Hu",
      "Ramprasaath R. Selvaraju",
      "Chetan Ramaiah",
      "Ran Xu",
      "Joseph F. JaJa",
      "Larry S. Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.01813"
  },
  {
    "id": "arXiv:2208.02567",
    "title": "Constructing Balance from Imbalance for Long-tailed Image Recognition",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Yue Xu",
      "Yong-Lu Li",
      "Jiefeng Li",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02567"
  },
  {
    "id": "arXiv:2208.03726",
    "title": "Human Perception as a Phenomenon of Quantization",
    "abstract": "Comments: 28 pages, 8 figures",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Diederik Aerts",
      "Jonito Aerts Argu\u00eblles"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.03726"
  },
  {
    "id": "arXiv:2208.05066",
    "title": "The Relative Importance of Depth Cues and Semantic Edges for Indoor  Mobility Using Simulated Prosthetic Vision in Immersive Virtual Reality",
    "abstract": "The Relative Importance of Depth Cues and Semantic Edges for Indoor  Mobility Using Simulated Prosthetic Vision in Immersive Virtual Reality",
    "descriptor": "",
    "authors": [
      "Alex Rasla",
      "Michael Beyeler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.05066"
  },
  {
    "id": "arXiv:2208.05232",
    "title": "Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for  Patients with Cerebral Palsy",
    "abstract": "Comments: 7 pages, 4 figures; supplemental material 9 pages, 8 figures; to be published in the proceedings of the 2022 IEEE Workshop on TRust and EXpertise in Visual Analytics (TREX)",
    "descriptor": "\nComments: 7 pages, 4 figures; supplemental material 9 pages, 8 figures; to be published in the proceedings of the 2022 IEEE Workshop on TRust and EXpertise in Visual Analytics (TREX)\n",
    "authors": [
      "Alexander Rind",
      "Djordje Slijep\u010devi\u0107",
      "Matthias Zeppelzauer",
      "Fabian Unglaube",
      "Andreas Kranzl",
      "Brian Horsak"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.05232"
  },
  {
    "id": "arXiv:2208.05732",
    "title": "New Non-Equivalent (Self-Dual) MDS Codes From Elliptic Curves",
    "abstract": "Comments: 28 pages, new non-equivalent MDS codes from higher genus curves are discussed",
    "descriptor": "\nComments: 28 pages, new non-equivalent MDS codes from higher genus curves are discussed\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.05732"
  },
  {
    "id": "arXiv:2208.05767",
    "title": "Distributionally Robust Model-Based Offline Reinforcement Learning with  Near-Optimal Sample Complexity",
    "abstract": "Distributionally Robust Model-Based Offline Reinforcement Learning with  Near-Optimal Sample Complexity",
    "descriptor": "",
    "authors": [
      "Laixi Shi",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.05767"
  },
  {
    "id": "arXiv:2208.06479",
    "title": "Design and Validation of an Open-Source Closed-Loop Testbed for  Artificial Pancreas Systems",
    "abstract": "Comments: 12 pages, 12 figures, to appear in the IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE), 2022",
    "descriptor": "\nComments: 12 pages, 12 figures, to appear in the IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE), 2022\n",
    "authors": [
      "Xugui Zhou",
      "Maxfield Kouzel",
      "Haotian Ren",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.06479"
  },
  {
    "id": "arXiv:2208.06553",
    "title": "Happiness Maximizing Sets under Group Fairness Constraints (Technical  Report)",
    "abstract": "Comments: Technical report, a shorter version to appear in PVLDB 16(2)",
    "descriptor": "\nComments: Technical report, a shorter version to appear in PVLDB 16(2)\n",
    "authors": [
      "Jiping Zheng",
      "Yuan Ma",
      "Wei Ma",
      "Yanhao Wang",
      "Xiaoyang Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.06553"
  },
  {
    "id": "arXiv:2208.06810",
    "title": "Generic Go to Go: Dictionary-Passing, Monomorphisation, and Hybrid",
    "abstract": "Comments: Full version of paper submitted to OOPSLA '22",
    "descriptor": "\nComments: Full version of paper submitted to OOPSLA '22\n",
    "authors": [
      "Stephen Ellis",
      "Shuofei Zhu",
      "Nobuko Yoshida",
      "Linhai Song"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.06810"
  },
  {
    "id": "arXiv:2208.06995",
    "title": "On a Mechanism Framework of Autoencoders",
    "abstract": "Comments: v2:lemma 9 modified",
    "descriptor": "\nComments: v2:lemma 9 modified\n",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06995"
  },
  {
    "id": "arXiv:2208.07362",
    "title": "Look Both Ways: Bidirectional Visual Sensing for Automatic Multi-Camera  Registration",
    "abstract": "Look Both Ways: Bidirectional Visual Sensing for Automatic Multi-Camera  Registration",
    "descriptor": "",
    "authors": [
      "Subodh Mishra",
      "Sushruth Nagesh",
      "Sagar Manglani",
      "Graham Mills",
      "Punarjay Chakravarty",
      "Gaurav Pandey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.07362"
  },
  {
    "id": "arXiv:2208.07498",
    "title": "Universal Solutions of Feedforward ReLU Networks for Interpolations",
    "abstract": "Comments: v2:minor revision; v3:proposition 5 modified",
    "descriptor": "\nComments: v2:minor revision; v3:proposition 5 modified\n",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.07498"
  },
  {
    "id": "arXiv:2208.07592",
    "title": "Multi-Point Integrated Sensing and Communication: Fusion Model and  Functionality Selection",
    "abstract": "Comments: 7 pages, 4 figures, to appear in IEEE Wireless Communications Letters",
    "descriptor": "\nComments: 7 pages, 4 figures, to appear in IEEE Wireless Communications Letters\n",
    "authors": [
      "Guoliang Li",
      "Shuai Wang",
      "Kejiang Ye",
      "Miaowen Wen",
      "Derrick Wing Kwan Ng",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.07592"
  },
  {
    "id": "arXiv:2208.08058",
    "title": "Semi-supervised Learning with Deterministic Labeling and Large Margin  Projection",
    "abstract": "Comments: 12 pages, ready to submit to a journal",
    "descriptor": "\nComments: 12 pages, ready to submit to a journal\n",
    "authors": [
      "Ji Xu",
      "Gang Ren",
      "Yao Xiao",
      "Shaobo Li",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08058"
  },
  {
    "id": "arXiv:2208.09821",
    "title": "On The Robustness of Channel Allocation in Joint Radar And Communication  Systems: An Auction Approach",
    "abstract": "On The Robustness of Channel Allocation in Joint Radar And Communication  Systems: An Auction Approach",
    "descriptor": "",
    "authors": [
      "Ismail Lotfi",
      "Hongyang Du",
      "Dusit Niyato",
      "Sumei Sun",
      "Dong In Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.09821"
  },
  {
    "id": "arXiv:2208.10627",
    "title": "Targeted Advertising on Social Networks Using Online Variational Tensor  Regression",
    "abstract": "Comments: 18 pages, 7 figures",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Tsuyoshi Id\u00e9",
      "Keerthiram Murugesan",
      "Djallel Bouneffouf",
      "Naoki Abe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10627"
  },
  {
    "id": "arXiv:2208.10768",
    "title": "A Lightweight Universal Gripper with Low Activation Force for Aerial  Grasping",
    "abstract": "Comments: 21 pages, 19 figures; corrected affiliations",
    "descriptor": "\nComments: 21 pages, 19 figures; corrected affiliations\n",
    "authors": [
      "Paul Kremer",
      "Hamed Rahimi Nohooji",
      "Jose Luis Sanchez-Lopez",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10768"
  },
  {
    "id": "arXiv:2208.11150",
    "title": "Direct Optimisation of $\\boldsymbol\u03bb$ for HDR Content Adaptive  Transcoding in AV1",
    "abstract": "Comments: SPIE2022:Applications of Digital Image Processing XLV accepted manuscript",
    "descriptor": "\nComments: SPIE2022:Applications of Digital Image Processing XLV accepted manuscript\n",
    "authors": [
      "Vibhoothi",
      "Fran\u00e7ois Piti\u00e9",
      "Angeliki Katsenou",
      "Daniel Joseph Ringis",
      "Yeping Su",
      "Neil Birkbeck",
      "Jessie Lin",
      "Balu Adsumilli",
      "Anil Kokaram"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.11150"
  },
  {
    "id": "arXiv:2208.11727",
    "title": "Hyperparameter Optimization for Unsupervised Outlier Detection",
    "abstract": "Hyperparameter Optimization for Unsupervised Outlier Detection",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.11727"
  },
  {
    "id": "arXiv:2208.11985",
    "title": "Learning to Prune Instances of Steiner Tree Problem in Graphs",
    "abstract": "Learning to Prune Instances of Steiner Tree Problem in Graphs",
    "descriptor": "",
    "authors": [
      "Jiwei Zhang",
      "Deepak Ajwani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.11985"
  },
  {
    "id": "arXiv:2208.12880",
    "title": "Neuromorphic Visual Scene Understanding with Resonator Networks",
    "abstract": "Comments: 15 pages, 6 figures, minor changes",
    "descriptor": "\nComments: 15 pages, 6 figures, minor changes\n",
    "authors": [
      "Alpha Renner",
      "Lazar Supic",
      "Andreea Danielescu",
      "Giacomo Indiveri",
      "Bruno A. Olshausen",
      "Yulia Sandamirskaya",
      "Friedrich T. Sommer",
      "E. Paxon Frady"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.12880"
  },
  {
    "id": "arXiv:2208.13146",
    "title": "Generative Modelling of the Ageing Heart with Cross-Sectional Imaging  and Clinical Data",
    "abstract": "Generative Modelling of the Ageing Heart with Cross-Sectional Imaging  and Clinical Data",
    "descriptor": "",
    "authors": [
      "Mengyun Qiao",
      "Berke Doga Basaran",
      "Huaqi Qiu",
      "Shuo Wang",
      "Yi Guo",
      "Yuanyuan Wang",
      "Paul M. Matthews",
      "Daniel Rueckert",
      "Wenjia Bai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.13146"
  },
  {
    "id": "arXiv:2208.13343",
    "title": "IoT Droplocks: Wireless Fingerprint Theft Using Hacked Smart Locks",
    "abstract": "Comments: Submitted and accepted into 2022 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress. Submitted version: 10 pages, 8 figures",
    "descriptor": "\nComments: Submitted and accepted into 2022 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress. Submitted version: 10 pages, 8 figures\n",
    "authors": [
      "Steve Kerrison"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.13343"
  },
  {
    "id": "arXiv:2208.13721",
    "title": "CounTR: Transformer-based Generalised Visual Counting",
    "abstract": "Comments: Accepted by BMVC2022",
    "descriptor": "\nComments: Accepted by BMVC2022\n",
    "authors": [
      "Chang Liu",
      "Yujie Zhong",
      "Andrew Zisserman",
      "Weidi Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13721"
  },
  {
    "id": "arXiv:2208.14722",
    "title": "Combinatorial Algorithms for Subsequence Matching: A Survey",
    "abstract": "Comments: This is a revised version of the paper with the same title which appeared in the Proceedings of NCMA 2022, EPTCS 367, 2022, pp. 11-27 (DOI: 10.4204/EPTCS.367.2). The revision consists in citing a series of relevant references which were not covered in the initial version, and commenting on how they relate to the results we survey. arXiv admin note: text overlap with arXiv:2206.13896",
    "descriptor": "\nComments: This is a revised version of the paper with the same title which appeared in the Proceedings of NCMA 2022, EPTCS 367, 2022, pp. 11-27 (DOI: 10.4204/EPTCS.367.2). The revision consists in citing a series of relevant references which were not covered in the initial version, and commenting on how they relate to the results we survey. arXiv admin note: text overlap with arXiv:2206.13896\n",
    "authors": [
      "Maria Kosche",
      "Tore Ko\u00df",
      "Florin Manea",
      "Stefan Siemer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.14722"
  },
  {
    "id": "arXiv:2209.02000",
    "title": "Neuromorphic Visual Odometry with Resonator Networks",
    "abstract": "Comments: 14 pages, 5 figures, minor changes",
    "descriptor": "\nComments: 14 pages, 5 figures, minor changes\n",
    "authors": [
      "Alpha Renner",
      "Lazar Supic",
      "Andreea Danielescu",
      "Giacomo Indiveri",
      "E. Paxon Frady",
      "Friedrich T. Sommer",
      "Yulia Sandamirskaya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.02000"
  },
  {
    "id": "arXiv:2209.02332",
    "title": "Ecosystem for Demand-side Flexibility Revisited: The Danish Solution",
    "abstract": "Ecosystem for Demand-side Flexibility Revisited: The Danish Solution",
    "descriptor": "",
    "authors": [
      "Peter Alexander Vistar Gade",
      "Trygve Skj\u00f8tskift",
      "Henrik W. Bindner",
      "Jalal Kazempour"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.02332"
  },
  {
    "id": "arXiv:2209.03042",
    "title": "Graph Neural Networks for Low-Energy Event Classification &  Reconstruction in IceCube",
    "abstract": "Comments: Prepared for submission to JINST",
    "descriptor": "\nComments: Prepared for submission to JINST\n",
    "authors": [
      "R. Abbasi",
      "M. Ackermann",
      "J. Adams",
      "N. Aggarwal",
      "J. A. Aguilar",
      "M. Ahlers",
      "M. Ahrens",
      "J.M. Alameddine",
      "A. A. Alves Jr.",
      "N. M. Amin",
      "K. Andeen",
      "T. Anderson",
      "G. Anton",
      "C. Arg\u00fcelles",
      "Y. Ashida",
      "S. Athanasiadou",
      "S. Axani",
      "X. Bai",
      "A. Balagopal V.",
      "M. Baricevic",
      "S. W. Barwick",
      "V. Basu",
      "R. Bay",
      "J. J. Beatty",
      "K.-H. Becker",
      "J. Becker Tjus",
      "J. Beise",
      "C. Bellenghi",
      "S. Benda",
      "S. BenZvi",
      "D. Berley",
      "E. Bernardini",
      "D. Z. Besson",
      "G. Binder",
      "D. Bindig",
      "E. Blaufuss",
      "S. Blot",
      "F. Bontempo",
      "J. Y. Book",
      "J. Borowka",
      "C. Boscolo Meneguolo",
      "S. B\u00f6ser",
      "O. Botner",
      "J. B\u00f6ttcher",
      "E. Bourbeau",
      "J. Braun",
      "B. Brinson",
      "J. Brostean-Kaiser",
      "R. T. Burley",
      "R. S. Busse",
      "M. A. Campana",
      "E. G. Carnie-Bronca",
      "C. Chen",
      "Z. Chen",
      "D. Chirkin",
      "K. Choi",
      "B. A. Clark",
      "L. Classen",
      "A. Coleman",
      "G. H. Collin",
      "A. Connolly",
      "J. M. Conrad"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2209.03042"
  },
  {
    "id": "arXiv:2209.03704",
    "title": "Kernel-Segregated Transpose Convolution Operation",
    "abstract": "Kernel-Segregated Transpose Convolution Operation",
    "descriptor": "",
    "authors": [
      "Vijay Srinivas Tida",
      "Sai Venkatesh Chilukoti",
      "Xiali Hei",
      "Sonya Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03704"
  },
  {
    "id": "arXiv:2209.04154",
    "title": "SUPER-Rec: SUrrounding Position-Enhanced Representation for  Recommendation",
    "abstract": "Comments: There was a testing environment issue so it is required to re-conduct the model evaluation",
    "descriptor": "\nComments: There was a testing environment issue so it is required to re-conduct the model evaluation\n",
    "authors": [
      "Taejun Lim",
      "Siqu Long",
      "Josiah Poon",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04154"
  },
  {
    "id": "arXiv:2209.04445",
    "title": "Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection",
    "abstract": "Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection",
    "descriptor": "",
    "authors": [
      "Vijay Srinivas Tida Sai Venkatesh Chilukoti",
      "Sonya Hsu",
      "Xiali Hei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.04445"
  },
  {
    "id": "arXiv:2209.04561",
    "title": "Deep Baseline Network for Time Series Modeling and Anomaly Detection",
    "abstract": "Deep Baseline Network for Time Series Modeling and Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Cheng Ge",
      "Xi Chen",
      "Ming Wang",
      "Jin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04561"
  },
  {
    "id": "arXiv:2209.04807",
    "title": "Exact Algorithms for Computing Generalized Eigenspaces of Matrices via  Annihilating Polynomials",
    "abstract": "Exact Algorithms for Computing Generalized Eigenspaces of Matrices via  Annihilating Polynomials",
    "descriptor": "",
    "authors": [
      "Shinichi Tajima",
      "Katsuyoshi Ohara",
      "Akira Terui"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2209.04807"
  },
  {
    "id": "arXiv:2209.05281",
    "title": "Modeling Dependent Structure for Utterances in ASR Evaluation",
    "abstract": "Modeling Dependent Structure for Utterances in ASR Evaluation",
    "descriptor": "",
    "authors": [
      "Zhe Liu",
      "Fuchun Peng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.05281"
  },
  {
    "id": "arXiv:2209.05722",
    "title": "GrASPE: Graph based Multimodal Fusion for Robot Navigation in  Unstructured Outdoor Environments",
    "abstract": "GrASPE: Graph based Multimodal Fusion for Robot Navigation in  Unstructured Outdoor Environments",
    "descriptor": "",
    "authors": [
      "Kasun Weerakoon",
      "Adarsh Jagan Sathyamoorthy",
      "Jing Liang",
      "Tianrui Guan",
      "Utsav Patel",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.05722"
  },
  {
    "id": "arXiv:2209.06049",
    "title": "Pre-training Transformers on Indian Legal Text",
    "abstract": "Pre-training Transformers on Indian Legal Text",
    "descriptor": "",
    "authors": [
      "Shounak Paul",
      "Arpan Mandal",
      "Pawan Goyal",
      "Saptarshi Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06049"
  },
  {
    "id": "arXiv:2209.06353",
    "title": "Label Refinement Network from Synthetic Error Augmentation for Medical  Image Segmentation",
    "abstract": "Label Refinement Network from Synthetic Error Augmentation for Medical  Image Segmentation",
    "descriptor": "",
    "authors": [
      "Shuai Chen",
      "Antonio Garcia-Uceda",
      "Jiahang Su",
      "Gijs van Tulder",
      "Lennard Wolff",
      "Theo van Walsum",
      "Marleen de Bruijne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06353"
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": "Sketch of a novel approach to a neural model",
    "descriptor": "",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2209.06865"
  },
  {
    "id": "arXiv:2209.07695",
    "title": "Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation",
    "abstract": "Comments: Accepted at NeurIPS2022",
    "descriptor": "\nComments: Accepted at NeurIPS2022\n",
    "authors": [
      "Lin Chen",
      "Zhixiang Wei",
      "Xin Jin",
      "Huaian Chen",
      "Miao Zheng",
      "Kai Chen",
      "Yi Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07695"
  },
  {
    "id": "arXiv:2209.07924",
    "title": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks",
    "abstract": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Xiaoqi Wang",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07924"
  },
  {
    "id": "arXiv:2209.08483",
    "title": "Honor of Kings Arena: an Environment for Generalization in Competitive  Reinforcement Learning",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Hua Wei",
      "Jingxiao Chen",
      "Xiyang Ji",
      "Hongyang Qin",
      "Minwen Deng",
      "Siqin Li",
      "Liang Wang",
      "Weinan Zhang",
      "Yong Yu",
      "Lin Liu",
      "Lanxiao Huang",
      "Deheng Ye",
      "Qiang Fu",
      "Wei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.08483"
  },
  {
    "id": "arXiv:2209.08503",
    "title": "Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast  Solution",
    "abstract": "Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast  Solution",
    "descriptor": "",
    "authors": [
      "Bangyan Liao",
      "Delin Qu",
      "Yifei Xue",
      "Huiqing Zhang",
      "Yizhen Lao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.08503"
  },
  {
    "id": "arXiv:2209.08902",
    "title": "Improving Fake News Detection of Influential Domain via Domain- and  Instance-Level Transfer",
    "abstract": "Comments: Accepted by COLING 2022. The 29th International Conference on Computational Linguistics, Gyeongju, Republic of Korea",
    "descriptor": "\nComments: Accepted by COLING 2022. The 29th International Conference on Computational Linguistics, Gyeongju, Republic of Korea\n",
    "authors": [
      "Qiong Nan",
      "Danding Wang",
      "Yongchun Zhu",
      "Qiang Sheng",
      "Yuhui Shi",
      "Juan Cao",
      "Jintao Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.08902"
  },
  {
    "id": "arXiv:2209.08911",
    "title": "Universal Proof Theory: Constructive Rules and Feasible Admissibility",
    "abstract": "Universal Proof Theory: Constructive Rules and Feasible Admissibility",
    "descriptor": "",
    "authors": [
      "Amirhossein Akbar Tabatabai",
      "Raheleh Jalali"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.08911"
  },
  {
    "id": "arXiv:2209.08928",
    "title": "UMIX: Improving Importance Weighting for Subpopulation Shift via  Uncertainty-Aware Mixup",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zongbo Han",
      "Zhipeng Liang",
      "Fan Yang",
      "Liu Liu",
      "Lanqing Li",
      "Yatao Bian",
      "Peilin Zhao",
      "Bingzhe Wu",
      "Changqing Zhang",
      "Jianhua Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08928"
  },
  {
    "id": "arXiv:2209.08932",
    "title": "OPR-Miner: Order-preserving rule mining for time series",
    "abstract": "OPR-Miner: Order-preserving rule mining for time series",
    "descriptor": "",
    "authors": [
      "Youxi Wu",
      "Xiaoqian Zhao",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Philippe Fournier-Viger",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.08932"
  },
  {
    "id": "arXiv:2209.10700",
    "title": "Self-adversarial Multi-scale Contrastive Learning for Semantic  Segmentation of Thermal Facial Images",
    "abstract": "Comments: Accepted at the British Machine Vision Conference (BMVC), 2022",
    "descriptor": "\nComments: Accepted at the British Machine Vision Conference (BMVC), 2022\n",
    "authors": [
      "Jitesh Joshi",
      "Nadia Bianchi-Berthouze",
      "Youngjun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10700"
  },
  {
    "id": "arXiv:2209.11347",
    "title": "A second moment proof of the spread lemma",
    "abstract": "Comments: Corrected a mistake in the proof of Theorem 2.1. and updated the literature review",
    "descriptor": "\nComments: Corrected a mistake in the proof of Theorem 2.1. and updated the literature review\n",
    "authors": [
      "Elchanan Mossel",
      "Jonathan Niles-Weed",
      "Nike Sun",
      "Ilias Zadik"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.11347"
  },
  {
    "id": "arXiv:2209.11887",
    "title": "Whodunit? Learning to Contrast for Authorship Attribution",
    "abstract": "Comments: camera-ready version, AACL-IJCNLP 2022",
    "descriptor": "\nComments: camera-ready version, AACL-IJCNLP 2022\n",
    "authors": [
      "Bo Ai",
      "Yuchen Wang",
      "Yugin Tan",
      "Samson Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11887"
  },
  {
    "id": "arXiv:2209.11919",
    "title": "Concordance based Survival Cobra with regression type weak learners",
    "abstract": "Concordance based Survival Cobra with regression type weak learners",
    "descriptor": "",
    "authors": [
      "Rahul Goswami",
      "Arabin Kumar Dey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.11919"
  },
  {
    "id": "arXiv:2209.11924",
    "title": "Interventional Causal Representation Learning",
    "abstract": "Interventional Causal Representation Learning",
    "descriptor": "",
    "authors": [
      "Kartik Ahuja",
      "Yixin Wang",
      "Divyat Mahajan",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11924"
  },
  {
    "id": "arXiv:2209.12993",
    "title": "Device Tracking via Linux's New TCP Source Port Selection Algorithm  (Extended Version)",
    "abstract": "Comments: This is an extended version of a paper with the same name that will be presented in the 32nd Usenix Security Symposium (USENIX 2023). UPDATE (2022-10-08): We revised some bibliography entries and clarified some aspects of the mathematical analysis",
    "descriptor": "\nComments: This is an extended version of a paper with the same name that will be presented in the 32nd Usenix Security Symposium (USENIX 2023). UPDATE (2022-10-08): We revised some bibliography entries and clarified some aspects of the mathematical analysis\n",
    "authors": [
      "Moshe Kol",
      "Amit Klein",
      "Yossi Gilad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.12993"
  },
  {
    "id": "arXiv:2209.13226",
    "title": "Optimization of Annealed Importance Sampling Hyperparameters",
    "abstract": "Optimization of Annealed Importance Sampling Hyperparameters",
    "descriptor": "",
    "authors": [
      "Shirin Goshtasbpour",
      "Fernando Perez-Cruz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13226"
  },
  {
    "id": "arXiv:2209.13791",
    "title": "TRBoost: A Generic Gradient Boosting Machine based on Trust-region  Method",
    "abstract": "TRBoost: A Generic Gradient Boosting Machine based on Trust-region  Method",
    "descriptor": "",
    "authors": [
      "Jiaqi Luo",
      "Zihao Wei",
      "Junkai Man",
      "Shixin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13791"
  },
  {
    "id": "arXiv:2209.14065",
    "title": "LL-GNN: Low Latency Graph Neural Networks on FPGAs for Particle  Detectors",
    "abstract": "Comments: 13 pages and 12 figures",
    "descriptor": "\nComments: 13 pages and 12 figures\n",
    "authors": [
      "Zhiqiang Que",
      "Hongxiang Fan",
      "Marcus Loo",
      "Michaela Blott",
      "Maurizio Pierini",
      "Alexander D Tapper",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2209.14065"
  },
  {
    "id": "arXiv:2209.14575",
    "title": "Correcting the Sub-optimal Bit Allocation",
    "abstract": "Correcting the Sub-optimal Bit Allocation",
    "descriptor": "",
    "authors": [
      "Tongda Xu",
      "Han Gao",
      "Yuanyuan Wang",
      "Hongwei Qin",
      "Yan Wang",
      "Jingjing Liu",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.14575"
  },
  {
    "id": "arXiv:2209.14738",
    "title": "Optimal Stopping with Gaussian Processes",
    "abstract": "Optimal Stopping with Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Kshama Dwarakanath",
      "Danial Dervovic",
      "Peyman Tavallali",
      "Svitlana S Vyetrenko",
      "Tucker Balch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14738"
  },
  {
    "id": "arXiv:2209.14826",
    "title": "Towards Lightweight Black-Box Attacks against Deep Neural Networks",
    "abstract": "Towards Lightweight Black-Box Attacks against Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Chenghao Sun",
      "Yonggang Zhang",
      "Wan Chaoqun",
      "Qizhou Wang",
      "Ya Li",
      "Tongliang Liu",
      "Bo Han",
      "Xinmei Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.14826"
  },
  {
    "id": "arXiv:2209.15108",
    "title": "How to tackle an emerging topic? Combining strong and weak labels for  Covid news NER",
    "abstract": "Comments: AACL-IJCNLP 2022",
    "descriptor": "\nComments: AACL-IJCNLP 2022\n",
    "authors": [
      "Aleksander Ficek",
      "Fangyu Liu",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15108"
  },
  {
    "id": "arXiv:2209.15501",
    "title": "A Closer Look at Temporal Ordering in the Segmentation of Instructional  Videos",
    "abstract": "Comments: Accepted at BMVC 2022",
    "descriptor": "\nComments: Accepted at BMVC 2022\n",
    "authors": [
      "Anil Batra",
      "Shreyank N Gowda",
      "Frank Keller",
      "Laura Sevilla-Lara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15501"
  },
  {
    "id": "arXiv:2210.00055",
    "title": "MaskTune: Mitigating Spurious Correlations by Forcing to Explore",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Saeid Asgari Taghanaki",
      "Aliasghar Khani",
      "Fereshte Khani",
      "Ali Gholami",
      "Linh Tran",
      "Ali Mahdavi-Amiri",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00055"
  },
  {
    "id": "arXiv:2210.00279",
    "title": "Failure-informed adaptive sampling for PINNs",
    "abstract": "Comments: 21 pages, 18 figures",
    "descriptor": "\nComments: 21 pages, 18 figures\n",
    "authors": [
      "Zhiwei Gao",
      "Liang Yan",
      "Tao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00279"
  },
  {
    "id": "arXiv:2210.00383",
    "title": "Conditions for minimally tough graphs",
    "abstract": "Conditions for minimally tough graphs",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Blas Fern\u00e1ndez",
      "Gyula Y. Katona",
      "Martin Milani\u010d",
      "Kitti Varga"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.00383"
  },
  {
    "id": "arXiv:2210.00421",
    "title": "Multiple Access Channel in Massive Multi-User MIMO Using Group Testing",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "George Vershinin",
      "Asaf Cohen",
      "Omer Gurewitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00421"
  },
  {
    "id": "arXiv:2210.00453",
    "title": "Neural Graphical Models",
    "abstract": "Neural Graphical Models",
    "descriptor": "",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00453"
  },
  {
    "id": "arXiv:2210.00471",
    "title": "OCD: Learning to Overfit with Conditional Diffusion Models",
    "abstract": "OCD: Learning to Overfit with Conditional Diffusion Models",
    "descriptor": "",
    "authors": [
      "Shahar Lutati",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00471"
  },
  {
    "id": "arXiv:2210.00538",
    "title": "Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation",
    "abstract": "Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation",
    "descriptor": "",
    "authors": [
      "Yuecen Wei",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Jia Wu",
      "Jinyan Wang",
      "Xianxian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00538"
  },
  {
    "id": "arXiv:2210.00553",
    "title": "ALT: A software for readability analysis of Portuguese-language texts",
    "abstract": "Comments: 21 pages, 13 figures, see software in this https URL",
    "descriptor": "\nComments: 21 pages, 13 figures, see software in this https URL\n",
    "authors": [
      "Gleice Carvalho de Lima Moreno",
      "Marco P. M. de Souza",
      "Nelson Hein",
      "Adriana Kroenke Hein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00553"
  },
  {
    "id": "arXiv:2210.00802",
    "title": "DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm",
    "abstract": "DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm",
    "descriptor": "",
    "authors": [
      "Kyriakos Schwarz",
      "Alicia Pliego-Mendieta",
      "Lara Planas-Paz",
      "Chantal Pauli",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.00802"
  },
  {
    "id": "arXiv:2210.00901",
    "title": "On the Salient Limitations of the Methods of Assembly Theory and their  Classification of Molecular Biosignatures",
    "abstract": "Comments: 32 pages with the appendix, 3 figures",
    "descriptor": "\nComments: 32 pages with the appendix, 3 figures\n",
    "authors": [
      "Abicumaran Uthamacumaran",
      "Felipe S. Abrah\u00e3o",
      "Narsis A. Kiani",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00901"
  },
  {
    "id": "arXiv:2210.01154",
    "title": "M-LIO: Multi-lidar, multi-IMU odometry with sensor dropout tolerance",
    "abstract": "Comments: For associated video check this https URL",
    "descriptor": "\nComments: For associated video check this https URL\n",
    "authors": [
      "Sandipan Das",
      "Navid Mahabadi",
      "Maurice Fallon",
      "Saikat Chatterjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01154"
  },
  {
    "id": "arXiv:2210.01202",
    "title": "SinGRAV: Learning a Generative Radiance Volume from a Single Natural  Scene",
    "abstract": "SinGRAV: Learning a Generative Radiance Volume from a Single Natural  Scene",
    "descriptor": "",
    "authors": [
      "Yujie Wang",
      "Xuelin Chen",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01202"
  },
  {
    "id": "arXiv:2210.01252",
    "title": "Estimating productivity gains in digital automation",
    "abstract": "Comments: 11 pages and 9 figures",
    "descriptor": "\nComments: 11 pages and 9 figures\n",
    "authors": [
      "Mauricio Jacobo-Romero",
      "Danilo S. Carvalho",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.01252"
  },
  {
    "id": "arXiv:2210.01515",
    "title": "Automatic Generation of Product Concepts from Positive Examples, with an  Application to Music Streaming",
    "abstract": "Comments: 17 Pages, Conference: BNAIC 2022",
    "descriptor": "\nComments: 17 Pages, Conference: BNAIC 2022\n",
    "authors": [
      "Kshitij Goyal",
      "Wannes Meert",
      "Hendrik Blockeel",
      "Elia Van Wolputte",
      "Koen Vanderstraeten",
      "Wouter Pijpops",
      "Kurt Jaspers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.01515"
  },
  {
    "id": "arXiv:2210.01784",
    "title": "COARSE3D: Class-Prototypes for Contrastive Learning in Weakly-Supervised  3D Point Cloud Segmentation",
    "abstract": "COARSE3D: Class-Prototypes for Contrastive Learning in Weakly-Supervised  3D Point Cloud Segmentation",
    "descriptor": "",
    "authors": [
      "Rong Li",
      "Anh-Quan Cao",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01784"
  },
  {
    "id": "arXiv:2210.01860",
    "title": "ProtoBandit: Efficient Prototype Selection via Multi-Armed Bandits",
    "abstract": "Comments: ACML 2022",
    "descriptor": "\nComments: ACML 2022\n",
    "authors": [
      "Arghya Roy Chaudhuri",
      "Pratik Jawanpuria",
      "Bamdev Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01860"
  },
  {
    "id": "arXiv:2210.01911",
    "title": "Grounding Language with Visual Affordances over Unstructured Data",
    "abstract": "Comments: Project website: this http URL",
    "descriptor": "\nComments: Project website: this http URL\n",
    "authors": [
      "Oier Mees",
      "Jessica Borja-Diaz",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01911"
  },
  {
    "id": "arXiv:2210.02018",
    "title": "InterFace:Adjustable Angular Margin Inter-class Loss for Deep Face  Recognition",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2109.09416 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.09416 by other authors\n",
    "authors": [
      "Meng Sang",
      "Jiaxuan Chen",
      "Mengzhen Li",
      "Pan Tan",
      "Anning Pan",
      "Shan Zhao",
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02018"
  },
  {
    "id": "arXiv:2210.02040",
    "title": "GT-GAN: General Purpose Time Series Synthesis with Generative  Adversarial Networks",
    "abstract": "Comments: NeurIPs 2022",
    "descriptor": "\nComments: NeurIPs 2022\n",
    "authors": [
      "Jinsung Jeon",
      "Jeonghak Kim",
      "Haryong Song",
      "Seunghyeon Cho",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02040"
  },
  {
    "id": "arXiv:2210.02102",
    "title": "An Architectural Approach to Creating a Cloud Application for Developing  Microservices",
    "abstract": "Comments: It is not completed properly yet, I want to withdraw it as an author",
    "descriptor": "\nComments: It is not completed properly yet, I want to withdraw it as an author\n",
    "authors": [
      "A. N. M. Sajedul Alam",
      "Junaid Bin Kibria",
      "Al Hasib Mahamud",
      "Arnob Kumar Dey",
      "Hasan Muhammed Zahidul Amin",
      "Md Sabbir Hossain",
      "Annajiat Alim Rasel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.02102"
  },
  {
    "id": "arXiv:2210.02127",
    "title": "Visual-Inertial and Leg Odometry Fusion for Dynamic Locomotion",
    "abstract": "Comments: Submitted to IEEE International Conference on Robotics and Automation (ICRA), 2023",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA), 2023\n",
    "authors": [
      "Victor Dh\u00e9din",
      "Haolong Li",
      "Shahram Khorshidi",
      "Lukas Mack",
      "Adithya Kumar Chinnakkonda Ravi",
      "Avadesh Meduri",
      "Paarth Shah",
      "Felix Grimminger",
      "Ludovic Righetti",
      "Majid Khadiv",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.02127"
  },
  {
    "id": "arXiv:2210.02192",
    "title": "Are All Losses Created Equal: A Neural Collapse Perspective",
    "abstract": "Comments: 32 page, 10 figures, NeurIPS 2022",
    "descriptor": "\nComments: 32 page, 10 figures, NeurIPS 2022\n",
    "authors": [
      "Jinxin Zhou",
      "Chong You",
      "Xiao Li",
      "Kangning Liu",
      "Sheng Liu",
      "Qing Qu",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02192"
  },
  {
    "id": "arXiv:2210.02541",
    "title": "Inserting or Stretching Points in Finite Difference Discretizations",
    "abstract": "Inserting or Stretching Points in Finite Difference Discretizations",
    "descriptor": "",
    "authors": [
      "Jherek Healy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.02541"
  },
  {
    "id": "arXiv:2210.02724",
    "title": "Leveraging Instance Features for Label Aggregation in Programmatic Weak  Supervision",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jieyu Zhang",
      "Linxin Song",
      "Alexander Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02724"
  },
  {
    "id": "arXiv:2210.02742",
    "title": "Towards the Multiple Constant Multiplication at Minimal Hardware Cost",
    "abstract": "Comments: 10 pages, 3 tables, 6 figures, journal submission",
    "descriptor": "\nComments: 10 pages, 3 tables, 6 figures, journal submission\n",
    "authors": [
      "R\u00e9mi Garcia",
      "Anastasia Volkova"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.02742"
  },
  {
    "id": "arXiv:2210.02757",
    "title": "Learning Consistency-Aware Unsigned Distance Functions Progressively  from Raw Point Clouds",
    "abstract": "Comments: Accepted by NeurIPS 2022. Project page:this https URL Code:this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Project page:this https URL Code:this https URL\n",
    "authors": [
      "Junsheng Zhou",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Yi Fang",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02757"
  },
  {
    "id": "arXiv:2210.02795",
    "title": "Why Should I Choose You? AutoXAI: A Framework for Selecting and Tuning  eXplainable AI Solutions",
    "abstract": "Comments: 16 pages, 7 figures, to be published in CIKM2022",
    "descriptor": "\nComments: 16 pages, 7 figures, to be published in CIKM2022\n",
    "authors": [
      "Robin Cugny",
      "Julien Aligon",
      "Max Chevalier",
      "Geoffrey Roman Jimenez",
      "Olivier Teste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02795"
  },
  {
    "id": "arXiv:2210.02933",
    "title": "Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question  Answering",
    "abstract": "Comments: Findings of EMNLP2022",
    "descriptor": "\nComments: Findings of EMNLP2022\n",
    "authors": [
      "Mingxuan Ju",
      "Wenhao Yu",
      "Tong Zhao",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02933"
  },
  {
    "id": "arXiv:2210.02999",
    "title": "NLTS Hamiltonians from classical LTCs",
    "abstract": "Comments: This note is withdrawn due to an uncorrectable error. A detailed explanation on the withdrawal is hosted on my website at this https URL",
    "descriptor": "\nComments: This note is withdrawn due to an uncorrectable error. A detailed explanation on the withdrawal is hosted on my website at this https URL\n",
    "authors": [
      "Zhiyang He",
      "Chinmay Nirkhe"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.02999"
  },
  {
    "id": "arXiv:2210.03022",
    "title": "Stateful active facilitator: Coordination and Environmental  Heterogeneity in Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "Stateful active facilitator: Coordination and Environmental  Heterogeneity in Cooperative Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Dianbo Liu",
      "Vedant Shah",
      "Oussama Boussif",
      "Cristian Meo",
      "Anirudh Goyal",
      "Tianmin Shu",
      "Michael Mozer",
      "Nicolas Heess",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03022"
  },
  {
    "id": "arXiv:2210.03050",
    "title": "State-of-the-art generalisation research in NLP: a taxonomy and review",
    "abstract": "Comments: 35 pages of content + 53 pages of references",
    "descriptor": "\nComments: 35 pages of content + 53 pages of references\n",
    "authors": [
      "Dieuwke Hupkes",
      "Mario Giulianelli",
      "Verna Dankers",
      "Mikel Artetxe",
      "Yanai Elazar",
      "Tiago Pimentel",
      "Christos Christodoulopoulos",
      "Karim Lasri",
      "Naomi Saphra",
      "Arabella Sinclair",
      "Dennis Ulmer",
      "Florian Schottmann",
      "Khuyagbaatar Batsuren",
      "Kaiser Sun",
      "Koustuv Sinha",
      "Leila Khalatbari",
      "Maria Ryskina",
      "Rita Frieske",
      "Ryan Cotterell",
      "Zhijing Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03050"
  },
  {
    "id": "arXiv:2210.03093",
    "title": "Edge-Varying Fourier Graph Networks for Multivariate Time Series  Forecasting",
    "abstract": "Edge-Varying Fourier Graph Networks for Multivariate Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Kun Yi",
      "Qi Zhang",
      "Liang Hu",
      "Hui He",
      "Ning An",
      "LongBing Cao",
      "ZhenDong Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03093"
  },
  {
    "id": "arXiv:2210.03150",
    "title": "Towards Out-of-Distribution Adversarial Robustness",
    "abstract": "Comments: Under review ICLR 2023",
    "descriptor": "\nComments: Under review ICLR 2023\n",
    "authors": [
      "Adam Ibrahim",
      "Charles Guille-Escuret",
      "Ioannis Mitliagkas",
      "Irina Rish",
      "David Krueger",
      "Pouya Bashivan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03150"
  },
  {
    "id": "arXiv:2210.03154",
    "title": "Comparison of Missing Data Imputation Methods using the Framingham Heart  study dataset",
    "abstract": "Comments: 2022 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)",
    "descriptor": "\nComments: 2022 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)\n",
    "authors": [
      "Konstantinos Psychogyios",
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03154"
  },
  {
    "id": "arXiv:2210.03205",
    "title": "Synthetic Dataset Generation for Privacy-Preserving Machine Learning",
    "abstract": "Synthetic Dataset Generation for Privacy-Preserving Machine Learning",
    "descriptor": "",
    "authors": [
      "Efstathia Soufleri",
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03205"
  },
  {
    "id": "arXiv:2210.03360",
    "title": "The PerspectiveLiberator -- an upmixing 6DoF rendering plugin for  single-perspective Ambisonic room impulse responses",
    "abstract": "Comments: 4 pages, submitted to conference: DAGA 2021, Vienna, Austria, 2021",
    "descriptor": "\nComments: 4 pages, submitted to conference: DAGA 2021, Vienna, Austria, 2021\n",
    "authors": [
      "Kaspar M\u00fcller",
      "Franz Zotter"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03360"
  },
  {
    "id": "arXiv:2210.03419",
    "title": "Event Extraction: A Survey",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Viet Dac Lai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03419"
  },
  {
    "id": "arXiv:2210.03526",
    "title": "A Unified Hard-Constraint Framework for Solving Geometrically Complex  PDEs",
    "abstract": "Comments: 10 pages, 5 figures, NeurIPS 2022",
    "descriptor": "\nComments: 10 pages, 5 figures, NeurIPS 2022\n",
    "authors": [
      "Songming Liu",
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03526"
  },
  {
    "id": "arXiv:2210.03659",
    "title": "Spatio-temporal Tendency Reasoning for Human Body Pose and Shape  Estimation from Videos",
    "abstract": "Comments: Accepted by BMVC2022",
    "descriptor": "\nComments: Accepted by BMVC2022\n",
    "authors": [
      "Boyang Zhang",
      "SuPing Wu",
      "Hu Cao",
      "Kehua Ma",
      "Pan Li",
      "Lei Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03659"
  },
  {
    "id": "arXiv:2210.03664",
    "title": "Bi-directional Weakly Supervised Knowledge Distillation for Whole Slide  Image Classification",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Linhao Qu",
      "Xiaoyuan Luo",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03664"
  },
  {
    "id": "arXiv:2210.03675",
    "title": "Koopman Neural Forecaster for Time Series with Temporal Distribution  Shifts",
    "abstract": "Koopman Neural Forecaster for Time Series with Temporal Distribution  Shifts",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Yihe Dong",
      "Sercan \u00d6. Arik",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03675"
  }
]
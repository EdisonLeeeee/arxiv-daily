[
  {
    "id": "arXiv:2210.03119",
    "title": "Evaluating k-NN in the Classification of Data Streams with Concept Drift",
    "abstract": "Data streams are often defined as large amounts of data flowing continuously\nat high speed. Moreover, these data are likely subject to changes in data\ndistribution, known as concept drift. Given all the reasons mentioned above,\nlearning from streams is often online and under restrictions of memory\nconsumption and run-time. Although many classification algorithms exist, most\nof the works published in the area use Naive Bayes (NB) and Hoeffding Trees\n(HT) as base learners in their experiments. This article proposes an in-depth\nevaluation of k-Nearest Neighbors (k-NN) as a candidate for classifying data\nstreams subjected to concept drift. It also analyses the complexity in time and\nthe two main parameters of k-NN, i.e., the number of nearest neighbors used for\npredictions (k), and window size (w). We compare different parameter values for\nk-NN and contrast it to NB and HT both with and without a drift detector (RDDM)\nin many datasets. We formulated and answered 10 research questions which led to\nthe conclusion that k-NN is a worthy candidate for data stream classification,\nespecially when the run-time constraint is not too restrictive.",
    "descriptor": "\nComments: 25 pages, 10 tables, 7 figures + 30 pages appendix\n",
    "authors": [
      "Roberto Souto Maior de Barros",
      "Silas Garrido Teixeira de Carvalho Santos",
      "Jean Paul Barddal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03119"
  },
  {
    "id": "arXiv:2210.03120",
    "title": "GBSVM: Granular-ball Support Vector Machine",
    "abstract": "GBSVM (Granular-ball Support Vector Machine) is an important attempt to use\nthe coarse granularity of a granular-ball as the input to construct a\nclassifier instead of a data point. It is the first classifier whose input\ncontains no points, i.e., $x_i$, in the history of machine learning. However,\non the one hand, its dual model is not derived, and the algorithm has not been\nimplemented and can not be applied. On the other hand, there are some errors in\nits existing model. To address these problems, this paper has fixed the errors\nof the original model of GBSVM, and derived its dual model. Furthermore, an\nalgorithm is designed using particle swarm optimization algorithm to solve the\ndual model. The experimental results on the UCI benchmark datasets demonstrate\nthat GBSVM has good robustness and efficiency.",
    "descriptor": "",
    "authors": [
      "Shuyin Xia",
      "Guoyin Wang",
      "Xinbo Gao",
      "Xiaoli Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03120"
  },
  {
    "id": "arXiv:2210.03122",
    "title": "Temporal Spatial Decomposition and Fusion Network for Time Series  Forecasting",
    "abstract": "Feature engineering is required to obtain better results for time series\nforecasting, and decomposition is a crucial one. One decomposition approach\noften cannot be used for numerous forecasting tasks since the standard time\nseries decomposition lacks flexibility and robustness. Traditional feature\nselection relies heavily on preexisting domain knowledge, has no generic\nmethodology, and requires a lot of labor. However, most time series prediction\nmodels based on deep learning typically suffer from interpretability issue, so\nthe \"black box\" results lead to a lack of confidence. To deal with the above\nissues forms the motivation of the thesis. In the paper we propose TSDFNet as a\nneural network with self-decomposition mechanism and an attentive feature\nfusion mechanism, It abandons feature engineering as a preprocessing convention\nand creatively integrates it as an internal module with the deep model. The\nself-decomposition mechanism empowers TSDFNet with extensible and adaptive\ndecomposition capabilities for any time series, users can choose their own\nbasis functions to decompose the sequence into temporal and generalized spatial\ndimensions. Attentive feature fusion mechanism has the ability to capture the\nimportance of external variables and the causality with target variables. It\ncan automatically suppress the unimportant features while enhancing the\neffective ones, so that users do not have to struggle with feature selection.\nMoreover, TSDFNet is easy to look into the \"black box\" of the deep neural\nnetwork by feature visualization and analyze the prediction results. We\ndemonstrate performance improvements over existing widely accepted models on\nmore than a dozen datasets, and three experiments showcase the interpretability\nof TSDFNet.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Liwang Zhou",
      "Jing Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03122"
  },
  {
    "id": "arXiv:2210.03123",
    "title": "Enhancing Mixup-Based Graph Learning for Language Processing via Hybrid  Pooling",
    "abstract": "Graph neural networks (GNNs) have recently been popular in natural language\nand programming language processing, particularly in text and source code\nclassification. Graph pooling which processes node representation into the\nentire graph representation, which can be used for multiple downstream tasks,\ne.g., graph classification, is a crucial component of GNNs. Recently, to\nenhance graph learning, Manifold Mixup, a data augmentation strategy that mixes\nthe graph data vector after the pooling layer, has been introduced. However,\nsince there are a series of graph pooling methods, how they affect the\neffectiveness of such a Mixup approach is unclear. In this paper, we take the\nfirst step to explore the influence of graph pooling methods on the\neffectiveness of the Mixup-based data augmentation approach. Specifically, 9\ntypes of hybrid pooling methods are considered in the study, e.g.,\n$\\mathcal{M}_{sum}(\\mathcal{P}_{att},\\mathcal{P}_{max})$. The experimental\nresults on both natural language datasets (Gossipcop, Politifact) and\nprogramming language datasets (Java250, Python800) demonstrate that hybrid\npooling methods are more suitable for Mixup than the standard max pooling and\nthe state-of-the-art graph multiset transformer (GMT) pooling, in terms of\nmetric accuracy and robustness.",
    "descriptor": "",
    "authors": [
      "Zeming Dong",
      "Qiang Hu",
      "Yuejun Guo",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03123"
  },
  {
    "id": "arXiv:2210.03124",
    "title": "Learning Transfer Operators by Kernel Density Estimation",
    "abstract": "Inference of transfer operators from data is often formulated as a classical\nproblem that hinges on the Ulam method. The usual description, which we will\ncall the Ulam-Galerkin method, is in terms of projection onto basis functions\nthat are characteristic functions supported over a fine grid of rectangles. In\nthese terms, the usual Ulam-Galerkin approach can be understood as density\nestimation by the histogram method. Here we show that the problem can be recast\nin statistical density estimation formalism. This recasting of the classical\nproblem, is a perspective that allows for an explicit and rigorous analysis of\nbias and variance, and therefore toward a discussion of the mean square error.\nKeywords: Transfer Operators; Frobenius-Perron operator; probability density\nestimation; Ulam-Galerkin method;Kernel Density Estimation.",
    "descriptor": "",
    "authors": [
      "Sudam Surasinghe",
      "Jeremie Fish",
      "Erik M. Bollt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.03124"
  },
  {
    "id": "arXiv:2210.03137",
    "title": "Deep Inventory Management",
    "abstract": "We present a Deep Reinforcement Learning approach to solving a periodic\nreview inventory control system with stochastic vendor lead times, lost sales,\ncorrelated demand, and price matching. While this dynamic program has\nhistorically been considered intractable, we show that several policy learning\napproaches are competitive with or outperform classical baseline approaches. In\norder to train these algorithms, we develop novel techniques to convert\nhistorical data into a simulator. We also present a model-based reinforcement\nlearning procedure (Direct Backprop) to solve the dynamic periodic review\ninventory control problem by constructing a differentiable simulator. Under a\nvariety of metrics Direct Backprop outperforms model-free RL and newsvendor\nbaselines, in both simulations and real-world deployments.",
    "descriptor": "",
    "authors": [
      "Dhruv Madeka",
      "Kari Torkkola",
      "Carson Eisenach",
      "Dean Foster",
      "Anna Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03137"
  },
  {
    "id": "arXiv:2210.03142",
    "title": "On Distillation of Guided Diffusion Models",
    "abstract": "Classifier-free guided diffusion models have recently been shown to be highly\neffective at high-resolution image generation, and they have been widely used\nin large-scale diffusion frameworks including DALL-E 2, GLIDE and Imagen.\nHowever, a downside of classifier-free guided diffusion models is that they are\ncomputationally expensive at inference time since they require evaluating two\ndiffusion models, a class-conditional model and an unconditional model,\nhundreds of times. To deal with this limitation, we propose an approach to\ndistilling classifier-free guided diffusion models into models that are fast to\nsample from: Given a pre-trained classifier-free guided model, we first learn a\nsingle model to match the output of the combined conditional and unconditional\nmodels, and then progressively distill that model to a diffusion model that\nrequires much fewer sampling steps. On ImageNet 64x64 and CIFAR-10, our\napproach is able to generate images visually comparable to that of the original\nmodel using as few as 4 sampling steps, achieving FID/IS scores comparable to\nthat of the original model while being up to 256 times faster to sample from.",
    "descriptor": "",
    "authors": [
      "Chenlin Meng",
      "Ruiqi Gao",
      "Diederik P. Kingma",
      "Stefano Ermon",
      "Jonathan Ho",
      "Tim Salimans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03142"
  },
  {
    "id": "arXiv:2210.03150",
    "title": "Towards Out-of-Distribution Adversarial Robustness",
    "abstract": "Adversarial robustness continues to be a major challenge for deep learning. A\ncore issue is that robustness to one type of attack often fails to transfer to\nother attacks. While prior work establishes a theoretical trade-off in\nrobustness against different $L_p$ norms, we show that there is potential for\nimprovement against many commonly used attacks by adopting a domain\ngeneralisation approach. Concretely, we treat each type of attack as a domain,\nand apply the Risk Extrapolation method (REx), which promotes similar levels of\nrobustness against all training attacks. Compared to existing methods, we\nobtain similar or superior worst-case adversarial robustness on attacks seen\nduring training. Moreover, we achieve superior performance on families or\ntunings of attacks only encountered at test time. On ensembles of attacks, our\napproach improves the accuracy from 3.4% the best existing baseline to 25.9% on\nMNIST, and from 16.9% to 23.5% on CIFAR10.",
    "descriptor": "\nComments: Under review ICLR 2023\n",
    "authors": [
      "Adam Ibrahim",
      "Charles Guille-Escuret",
      "Ioannis Mitliagkas",
      "Irina Rish",
      "David Krueger",
      "Pouya Bashivan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03150"
  },
  {
    "id": "arXiv:2210.03154",
    "title": "Comparison of Missing Data Imputation Methods using the Framingham Heart  study dataset",
    "abstract": "Cardiovascular disease (CVD) is a class of diseases that involve the heart or\nblood vessels and according to World Health Organization is the leading cause\nof death worldwide. EHR data regarding this case, as well as medical cases in\ngeneral, contain missing values very frequently. The percentage of missingness\nmay vary and is linked with instrument errors, manual data entry procedures,\netc. Even though the missing rate is usually significant, in many cases the\nmissing value imputation part is handled poorly either with case-deletion or\nwith simple statistical approaches such as mode and median imputation. These\nmethods are known to introduce significant bias, since they do not account for\nthe relationships between the dataset's variables. Within the medical\nframework, many datasets consist of lab tests or patient medical tests, where\nthese relationships are present and strong. To address these limitations, in\nthis paper we test and modify state-of-the-art missing value imputation methods\nbased on Generative Adversarial Networks (GANs) and Autoencoders. The\nevaluation is accomplished for both the tasks of data imputation and\npost-imputation prediction. Regarding the imputation task, we achieve\nimprovements of 0.20, 7.00% in normalised Root Mean Squared Error (RMSE) and\nArea Under the Receiver Operating Characteristic Curve (AUROC) respectively. In\nterms of the post-imputation prediction task, our models outperform the\nstandard approaches by 2.50% in F1-score.",
    "descriptor": "\nComments: 2022 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)\n",
    "authors": [
      "Konstantinos Psychogyios",
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03154"
  },
  {
    "id": "arXiv:2210.03158",
    "title": "Neural Volumetric Mesh Generator",
    "abstract": "Deep generative models have shown success in generating 3D shapes with\ndifferent representations. In this work, we propose Neural Volumetric Mesh\nGenerator(NVMG) which can generate novel and high-quality volumetric meshes.\nUnlike the previous 3D generative model for point cloud, voxel, and implicit\nsurface, the volumetric mesh representation is a ready-to-use representation in\nindustry with details on both the surface and interior. Generating this such\nhighly-structured data thus brings a significant challenge. We first propose a\ndiffusion-based generative model to tackle this problem by generating voxelized\nshapes with close-to-reality outlines and structures. We can simply obtain a\ntetrahedral mesh as a template with the voxelized shape. Further, we use a\nvoxel-conditional neural network to predict the smooth implicit surface\nconditioned on the voxels, and progressively project the tetrahedral mesh to\nthe predicted surface under regularizations. The regularization terms are\ncarefully designed so that they can (1) get rid of the defects like flipping\nand high distortion; (2) force the regularity of the interior and surface\nstructure during the deformation procedure for a high-quality final mesh. As\nshown in the experiments, our pipeline can generate high-quality artifact-free\nvolumetric and surface meshes from random noise or a reference image without\nany post-processing. Compared with the state-of-the-art voxel-to-mesh\ndeformation method, we show more robustness and better performance when taking\ngenerated voxels as input.",
    "descriptor": "",
    "authors": [
      "Yan Zheng",
      "Lemeng Wu",
      "Xingchao Liu",
      "Zhen Chen",
      "Qiang Liu",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03158"
  },
  {
    "id": "arXiv:2210.03162",
    "title": "Prompt Compression and Contrastive Conditioning for Controllability and  Toxicity Reduction in Language Models",
    "abstract": "We explore the idea of compressing the prompts used to condition language\nmodels, and show that compressed prompts can retain a substantive amount of\ninformation about the original prompt. For severely compressed prompts, while\nfine-grained information is lost, abstract information and general sentiments\ncan be retained with surprisingly few parameters, which can be useful in the\ncontext of decode-time algorithms for controllability and toxicity reduction.\nWe explore contrastive conditioning to steer language model generation towards\ndesirable text and away from undesirable text, and find that some complex\nprompts can be effectively compressed into a single token to guide generation.\nWe also show that compressed prompts are largely compositional, and can be\nconstructed such that they can be used to control independent aspects of\ngenerated text.",
    "descriptor": "\nComments: Empirical Methods in Natural Language Processing, 2022 (Main-Long Paper)\n",
    "authors": [
      "David Wingate",
      "Mohammad Shoeybi",
      "Taylor Sorensen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03162"
  },
  {
    "id": "arXiv:2210.03163",
    "title": "Brief Introduction to Contrastive Learning Pretext Tasks for Visual  Representation",
    "abstract": "To improve performance in visual feature representation from photos or videos\nfor practical applications, we generally require large-scale human-annotated\nlabeled data while training deep neural networks. However, the cost of\ngathering and annotating human-annotated labeled data is expensive. Given that\nthere is a lot of unlabeled data in the actual world, it is possible to\nintroduce self-defined pseudo labels as supervisions to prevent this issue.\nSelf-supervised learning, specifically contrastive learning, is a subset of\nunsupervised learning methods that has grown popular in computer vision,\nnatural language processing, and other domains. The purpose of contrastive\nlearning is to embed augmented samples from the same sample near to each other\nwhile pushing away those that are not. In the following sections, we will\nintroduce the regular formulation among different learnings. In the next\nsections, we will discuss the regular formulation of various learnings.\nFurthermore, we offer some strategies from contrastive learning that have\nrecently been published and are focused on pretext tasks for visual\nrepresentation.",
    "descriptor": "",
    "authors": [
      "Zhenyuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03163"
  },
  {
    "id": "arXiv:2210.03164",
    "title": "InfoOT: Information Maximizing Optimal Transport",
    "abstract": "Optimal transport aligns samples across distributions by minimizing the\ntransportation cost between them, e.g., the geometric distances. Yet, it\nignores coherence structure in the data such as clusters, does not handle\noutliers well, and cannot integrate new data points. To address these\ndrawbacks, we propose InfoOT, an information-theoretic extension of optimal\ntransport that maximizes the mutual information between domains while\nminimizing geometric distances. The resulting objective can still be formulated\nas a (generalized) optimal transport problem, and can be efficiently solved by\nprojected gradient descent. This formulation yields a new projection method\nthat is robust to outliers and generalizes to unseen samples. Empirically,\nInfoOT improves the quality of alignments across benchmarks in domain\nadaptation, cross-domain retrieval, and single-cell alignment.",
    "descriptor": "",
    "authors": [
      "Ching-Yao Chuang",
      "Stefanie Jegelka",
      "David Alvarez-Melis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03164"
  },
  {
    "id": "arXiv:2210.03165",
    "title": "A Theory of Dynamic Benchmarks",
    "abstract": "Dynamic benchmarks interweave model fitting and data collection in an attempt\nto mitigate the limitations of static benchmarks. In contrast to an extensive\ntheoretical and empirical study of the static setting, the dynamic counterpart\nlags behind due to limited empirical studies and no apparent theoretical\nfoundation to date. Responding to this deficit, we initiate a theoretical study\nof dynamic benchmarking. We examine two realizations, one capturing current\npractice and the other modeling more complex settings. In the first model,\nwhere data collection and model fitting alternate sequentially, we prove that\nmodel performance improves initially but can stall after only three rounds.\nLabel noise arising from, for instance, annotator disagreement leads to even\nstronger negative results. Our second model generalizes the first to the case\nwhere data collection and model fitting have a hierarchical dependency\nstructure. We show that this design guarantees strictly more progress than the\nfirst, albeit at a significant increase in complexity. We support our\ntheoretical analysis by simulating dynamic benchmarks on two popular datasets.\nThese results illuminate the benefits and practical limitations of dynamic\nbenchmarking, providing both a theoretical foundation and a causal explanation\nfor observed bottlenecks in empirical work.",
    "descriptor": "",
    "authors": [
      "Ali Shirali",
      "Rediet Abebe",
      "Moritz Hardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03165"
  },
  {
    "id": "arXiv:2210.03166",
    "title": "The Power of Greedy for Online Minimum Cost Matching on the Line",
    "abstract": "We consider the online minimum cost matching problem on the line, in which\nthere are $n$ servers and, at each of $n$ time steps, a request arrives and\nmust be irrevocably matched to a server that has not yet been matched to, with\nthe goal of minimizing the sum of the distances between the matched pairs.\nDespite achieving a worst-case competitive ratio that is exponential in $n$,\nthe simple greedy algorithm, which matches each request to its nearest\navailable free server, performs very well in practice. A major question is thus\nto explain greedy's strong empirical performance. In this paper, we aim to\nunderstand the performance of greedy over instances that are at least partially\nrandom. When both the requests and the servers are drawn uniformly and\nindependently from $[0,1]$, we show that greedy is constant competitive, which\nimproves over the previously best-known $O(\\sqrt{n})$ bound. We extend this\nconstant competitive ratio to a setting with a linear excess of servers, which\nimproves over the previously best-known $O(\\log^3{n})$ bound. We moreover show\nthat in the semi-random model where the requests are still drawn uniformly and\nindependently but where the servers are chosen adversarially, greedy achieves\nan $O(\\log{n})$ competitive ratio. When the requests arrive in a random order\nbut are chosen adversarially, it was previously known that greedy is\n$O(n)$-competitive. Even though this one-sided randomness allows a large\nimprovement in greedy's competitive ratio compared to the model where requests\nare adversarial and arrive in a random order, we show that it is not sufficient\nto obtain a constant competitive ratio by giving a tight $\\Omega(\\log{n})$\nlower bound. These results invite further investigation about how much\nrandomness is necessary and sufficient to obtain strong theoretical guarantees\nfor the greedy algorithm for online minimum cost matching, on the line and\nbeyond.",
    "descriptor": "",
    "authors": [
      "Eric Balkanksi",
      "Yuri Faenza",
      "Noemie Perivier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03166"
  },
  {
    "id": "arXiv:2210.03167",
    "title": "FAST: Improving Controllability for Text Generation with Feedback Aware  Self-Training",
    "abstract": "Controllable text generation systems often leverage control codes to direct\nvarious properties of the output like style and length. Inspired by recent work\non causal inference for NLP, this paper reveals a previously overlooked flaw in\nthese control code-based conditional text generation algorithms. Spurious\ncorrelations in the training data can lead models to incorrectly rely on parts\nof the input other than the control code for attribute selection, significantly\nundermining downstream generation quality and controllability. We demonstrate\nthe severity of this issue with a series of case studies and then propose two\nsimple techniques to reduce these correlations in training sets. The first\ntechnique is based on resampling the data according to an example's propensity\ntowards each linguistic attribute (IPS). The second produces multiple\ncounterfactual versions of each example and then uses an additional feedback\nmechanism to remove noisy examples (feedback aware self-training, FAST). We\nevaluate on 3 tasks -- news headline, meta review, and search ads generation --\nand demonstrate that FAST can significantly improve the controllability and\nlanguage quality of generated outputs when compared to state-of-the-art\ncontrollable text generation approaches.",
    "descriptor": "",
    "authors": [
      "Junyi Chai",
      "Reid Pryzant",
      "Victor Ye Dong",
      "Konstantin Golobokov",
      "Chenguang Zhu",
      "Yi Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03167"
  },
  {
    "id": "arXiv:2210.03168",
    "title": "Gastrointestinal Disorder Detection with a Transformer Based Approach",
    "abstract": "Accurate disease categorization using endoscopic images is a significant\nproblem in Gastroenterology. This paper describes a technique for assisting\nmedical diagnosis procedures and identifying gastrointestinal tract disorders\nbased on the categorization of characteristics taken from endoscopic pictures\nusing a vision transformer and transfer learning model. Vision transformer has\nshown very promising results on difficult image classification tasks. In this\npaper, we have suggested a vision transformer based approach to detect\ngastrointestianl diseases from wireless capsule endoscopy (WCE) curated images\nof colon with an accuracy of 95.63\\%. We have compared this transformer based\napproach with pretrained convolutional neural network (CNN) model DenseNet201\nand demonstrated that vision transformer surpassed DenseNet201 in various\nquantitative performance evaluation metrics.",
    "descriptor": "",
    "authors": [
      "A.K.M. Salman Hosain",
      "Mynul islam",
      "Md Humaion Kabir Mehedi",
      "Irteza Enan Kabir",
      "Zarin Tasnim Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03168"
  },
  {
    "id": "arXiv:2210.03170",
    "title": "WfBench: Automated Generation of Scientific Workflow Benchmarks",
    "abstract": "The prevalence of scientific workflows with high computational demands calls\nfor their execution on various distributed computing platforms, including\nlarge-scale leadership-class high-performance computing (HPC) clusters. To\nhandle the deployment, monitoring, and optimization of workflow executions,\nmany workflow systems have been developed over the past decade. There is a need\nfor workflow benchmarks that can be used to evaluate the performance of\nworkflow systems on current and future software stacks and hardware platforms.\nWe present a generator of realistic workflow benchmark specifications that\ncan be translated into benchmark code to be executed with current workflow\nsystems. Our approach generates workflow tasks with arbitrary performance\ncharacteristics (CPU, memory, and I/O usage) and with realistic task dependency\nstructures based on those seen in production workflows. We present experimental\nresults that show that our approach generates benchmarks that are\nrepresentative of production workflows, and conduct a case study to demonstrate\nthe use and usefulness of our generated benchmarks to evaluate the performance\nof workflow systems under different configuration scenarios.",
    "descriptor": "",
    "authors": [
      "Tain\u00e3 Coleman",
      "Henri Casanova",
      "Ketan Maheshwari",
      "Lo\u00efc Pottier",
      "Sean R. Wilkinson",
      "Justin Wozniak",
      "Fr\u00e9d\u00e9ric Suter",
      "Mallikarjun Shankar",
      "Rafael Ferreira da Silva"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.03170"
  },
  {
    "id": "arXiv:2210.03173",
    "title": "CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration",
    "abstract": "Robot grasping is an actively studied area in robotics, mainly focusing on\nthe quality of generated grasps for object manipulation. However, despite\nadvancements, these methods do not consider the human-robot collaboration\nsettings where robots and humans will have to grasp the same objects\nconcurrently. Therefore, generating robot grasps compatible with human\npreferences of simultaneously holding an object becomes necessary to ensure a\nsafe and natural collaboration experience. In this paper, we propose a novel,\ndeep neural network-based method called CoGrasp that generates human-aware\nrobot grasps by contextualizing human preference models of object grasping into\nthe robot grasp selection process. We validate our approach against existing\nstate-of-the-art robot grasping methods through simulated and real-robot\nexperiments and user studies. In real robot experiments, our method achieves\nabout 88\\% success rate in producing stable grasps that also allow humans to\ninteract and grasp objects simultaneously in a socially compliant manner.\nFurthermore, our user study with 10 independent participants indicated our\napproach enables a safe, natural, and socially-aware human-robot objects'\nco-grasping experience compared to a standard robot grasping technique.",
    "descriptor": "",
    "authors": [
      "Abhinav K. Keshari",
      "Hanwen Ren",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03173"
  },
  {
    "id": "arXiv:2210.03175",
    "title": "Evaluating Fairness Without Sensitive Attributes: A Framework Using Only  Auxiliary Models",
    "abstract": "Although the volume of literature and public attention on machine learning\nfairness has been growing significantly, in practice some tasks as basic as\nmeasuring fairness, which is the first step in studying and promoting fairness,\ncan be challenging. This is because sensitive attributes are often unavailable\ndue to privacy regulations. The straightforward solution is to use auxiliary\nmodels to predict the missing sensitive attributes. However, our theoretical\nanalyses show that the estimation error of the directly measured fairness\nmetrics is proportional to the error rates of auxiliary models' predictions.\nExisting works that attempt to reduce the estimation error often require strong\nassumptions, e.g. access to the ground-truth sensitive attributes or some form\nof conditional independence. In this paper, we drop those assumptions and\npropose a framework that uses only off-the-shelf auxiliary models. The main\nchallenge is how to reduce the negative impact of imperfectly predicted\nsensitive attributes on the fairness metrics without knowing the ground-truth\nsensitive attributes. Inspired by the noisy label learning literature, we first\nderive a closed-form relationship between the directly measured fairness\nmetrics and their corresponding ground-truth metrics. And then we estimate some\nkey statistics (most importantly transition matrix in the noisy label\nliterature), which we use, together with the derived relationship, to calibrate\nthe fairness metrics. In addition, we theoretically prove the upper bound of\nthe estimation error in our calibrated metrics and show our method can\nsubstantially decrease the estimation error especially when auxiliary models\nare inaccurate or the target model is highly biased. Experiments on COMPAS and\nCelebA validate our theoretical analyses and show our method can measure\nfairness significantly more accurately than baselines under favorable\ncircumstances.",
    "descriptor": "",
    "authors": [
      "Zhaowei Zhu",
      "Yuanshun Yao",
      "Jiankai Sun",
      "Yang Liu",
      "Hang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03175"
  },
  {
    "id": "arXiv:2210.03177",
    "title": "SCORE: A Second-Order Conic Initialization for Range-Aided SLAM",
    "abstract": "We present a novel initialization technique for the range-aided simultaneous\nlocalization and mapping (RA-SLAM) problem. In RA-SLAM we consider measurements\nof point-to-point distances in addition to measurements of rigid\ntransformations to landmark or pose variables. Standard formulations of RA-SLAM\napproach the problem as non-convex optimization, which requires a good\ninitialization to obtain quality results. The initialization technique proposed\nhere relaxes the RA-SLAM problem to a convex problem which is then solved to\ndetermine an initialization for the original, non-convex problem. The\nrelaxation is a second-order cone program (SOCP), which is derived from a\nquadratically constrained quadratic program (QCQP) formulation of the RA-SLAM\nproblem. As a SOCP, the method is highly scalable. We name this relaxation\nSecond-order COnic RElaxation for RA-SLAM (SCORE). To our knowledge, this work\nrepresents the first convex relaxation for RA-SLAM. We present real-world and\nsimulated experiments which show SCORE initialization permits the efficient\nrecovery of quality solutions for a variety of challenging single- and\nmulti-robot RA-SLAM problems with thousands of poses and range measurements.",
    "descriptor": "\nComments: 9 pages, 8 figures, extended version of paper submitted to ICRA 2023\n",
    "authors": [
      "Alan Papalia",
      "Joseph Morales",
      "Kevin J. Doherty",
      "David M. Rosen",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03177"
  },
  {
    "id": "arXiv:2210.03179",
    "title": "Optimal Chebyshev Smoothers and One-sided V-cycles",
    "abstract": "The solution to the Poisson equation arising from the spectral element\ndiscretization of the incompressible Navier-Stokes equation requires robust\npreconditioning strategies. One such strategy is multigrid. To realize the\npotential of multigrid methods, effective smoothing strategies are needed.\nChebyshev polynomial smoothing proves to be an effective smoother. However,\nthere are several improvements to be made, especially at the cost of symmetry.\nFor the same cost per iteration, a full V-cycle with $k$ order Chebyshev\npolynomial smoothing may be substituted with a half V-cycle with order $2k$\nChebyshev polynomial smoothing, wherein the smoother is omitted on the up-leg\nof the V-cycle. The choice of omitting the post-smoother in favor of higher\norder Chebyshev pre-smoothing is shown to be advantageous in cases where the\nmultigrid approximation property constant, $C$, is large. Results utilizing\nLottes's fourth-kind Chebyshev polynomial smoother are shown. These methods\ndemonstrate substantial improvement over the standard Chebyshev polynomial\nsmoother. The authors demonstrate the effectiveness of this scheme in\n$p$-geometric multigrid, as well as a 2D model problem with finite differences.",
    "descriptor": "\nComments: 35 pages, 27 figures, 5 tables (including supplementary materials)\n",
    "authors": [
      "Malachi Phillips",
      "Paul Fischer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03179"
  },
  {
    "id": "arXiv:2210.03183",
    "title": "Compositional Generalisation with Structured Reordering and Fertility  Layers",
    "abstract": "Seq2seq models have been shown to struggle with compositional generalisation,\ni.e. generalising to new and potentially more complex structures than seen\nduring training. Taking inspiration from grammar-based models that excel at\ncompositional generalisation, we present a flexible end-to-end differentiable\nneural model that composes two structural operations: a fertility step, which\nwe introduce in this work, and a reordering step based on previous work (Wang\net al., 2021). Our model outperforms seq2seq models by a wide margin on\nchallenging compositional splits of realistic semantic parsing tasks that\nrequire generalisation to longer examples. It also compares favourably to other\nmodels targeting compositional generalisation.",
    "descriptor": "",
    "authors": [
      "Matthias Lindemann",
      "Alexander Koller",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03183"
  },
  {
    "id": "arXiv:2210.03187",
    "title": "Active Localization using Bernstein Distribution Functions",
    "abstract": "In this work, we present a framework that enables a vehicle to autonomously\nlocalize a target based on noisy range measurements computed from RSSI data. To\nachieve the mission objectives, we develop a control scheme composed of two\nmain parts: an estimator and a motion planner. At each time step, new estimates\nof the target's position are computed and used to generate and update\ndistribution functions using Bernstein polynomials. A metric of the efficiency\nof the estimator is derived based on the Fisher Information Matrix. Finally,\nthe motion planning problem is formulated to react in real time to new\ninformation about the target and improve the estimator's performance.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Camilla Tabasso",
      "Venanzio Cichella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03187"
  },
  {
    "id": "arXiv:2210.03197",
    "title": "Modeling Memory Imprints Induced by Interactions in Social Networks",
    "abstract": "Memory imprints of the significance of relationships are constantly evolving.\nThey are boosted by social interactions among people involved in relationships,\nand decay between such events, causing the relationships to change. Despite the\nimportance of the evolution of relationships in social networks, there is\nlittle work exploring how interactions over extended periods correlate with\npeople's memory imprints of relationship importance. In this paper, we\nrepresent memory dynamics by adapting a well-known cognitive science model.\nUsing two unique longitudinal datasets, we fit the model's parameters to\nmaximize agreement of the memory imprints of relationship strengths of a node\npredicted from call detail records with the ground-truth list of relationships\nof this node ordered by their strength. We find that this model, trained on one\npopulation, predicts not only on this population but also on a different one,\nsuggesting the universality of memory imprints of social interactions among\nunrelated individuals. This paper lays the foundation for studying the modeling\nof social interactions as memory imprints, and its potential use as an\nunobtrusive tool to early detection of individuals with memory malfunctions.",
    "descriptor": "\nComments: 11 pages, 2 tables\n",
    "authors": [
      "James Flamino",
      "Ross DeVito",
      "Omar Lizardo",
      "Boleslaw K. Szymanski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03197"
  },
  {
    "id": "arXiv:2210.03202",
    "title": "Designing Virtual Environments for Social Engagement in Older Adults",
    "abstract": "Virtual reality (VR) is increasingly used as a platform for social\ninteraction, including as a means for older adults to maintain engagement.\nHowever, there has been limited research to examine the features of social VR\nthat are most relevant to older adults experiences. The current study was\nconducted to qualitatively analyze the behavior of older adults in a\ncollaborative VR environment and evaluate aspects of design that affected their\nengagement outcomes. We paired 36 participants over the age of 60, from three\ndiverse geographic locations, and asked them to interact in collaborative VR\nmodules. Video-based observation methods and thematic analyses were used to\nstudy the resulting interactions. The results indicated a strong link between\nperceived spatial presence in the VR and social engagement, while also\nhighlighting the importance of individual personality and compatibility. The\nstudy provides new insights into design guidelines that could improve social VR\nprograms for older adults.",
    "descriptor": "",
    "authors": [
      "Tong Bill Xu",
      "Armin Mostafavi",
      "Benjamin Kim",
      "Angella Lee",
      "Walter Boot",
      "Sara Czaja",
      "Saleh Kalantari"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03202"
  },
  {
    "id": "arXiv:2210.03204",
    "title": "Enabling Deep Learning on Edge Devices",
    "abstract": "Deep neural networks (DNNs) have succeeded in many different perception\ntasks, e.g., computer vision, natural language processing, reinforcement\nlearning, etc. The high-performed DNNs heavily rely on intensive resource\nconsumption. For example, training a DNN requires high dynamic memory, a\nlarge-scale dataset, and a large number of computations (a long training time);\neven inference with a DNN also demands a large amount of static storage,\ncomputations (a long inference time), and energy. Therefore, state-of-the-art\nDNNs are often deployed on a cloud server with a large number of\nsuper-computers, a high-bandwidth communication bus, a shared storage\ninfrastructure, and a high power supplement.\nRecently, some new emerging intelligent applications, e.g., AR/VR, mobile\nassistants, Internet of Things, require us to deploy DNNs on\nresource-constrained edge devices. Compare to a cloud server, edge devices\noften have a rather small amount of resources. To deploy DNNs on edge devices,\nwe need to reduce the size of DNNs, i.e., we target a better trade-off between\nresource consumption and model accuracy.\nIn this dissertation, we studied four edge intelligence scenarios, i.e.,\nInference on Edge Devices, Adaptation on Edge Devices, Learning on Edge\nDevices, and Edge-Server Systems, and developed different methodologies to\nenable deep learning in each scenario. Since current DNNs are often\nover-parameterized, our goal is to find and reduce the redundancy of the DNNs\nin each scenario.",
    "descriptor": "\nComments: PhD thesis at ETH Zurich\n",
    "authors": [
      "Zhongnan Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03204"
  },
  {
    "id": "arXiv:2210.03205",
    "title": "Synthetic Dataset Generation for Privacy-Preserving Machine Learning",
    "abstract": "Machine Learning (ML) has achieved enormous success in solving a variety of\nproblems in computer vision, speech recognition, object detection, to name a\nfew. The principal reason for this success is the availability of huge datasets\nfor training deep neural networks (DNNs). However, datasets cannot be publicly\nreleased if they contain sensitive information such as medical records, and\ndata privacy becomes a major concern. Encryption methods could be a possible\nsolution, however their deployment on ML applications seriously impacts\nclassification accuracy and results in substantial computational overhead.\nAlternatively, obfuscation techniques could be used, but maintaining a good\ntrade-off between visual privacy and accuracy is challenging. In this paper, we\npropose a method to generate secure synthetic datasets from the original\nprivate datasets. Given a network with Batch Normalization (BN) layers\npretrained on the original dataset, we first record the class-wise BN layer\nstatistics. Next, we generate the synthetic dataset by optimizing random noise\nsuch that the synthetic data match the layer-wise statistical distribution of\noriginal images. We evaluate our method on image classification datasets\n(CIFAR10, ImageNet) and show that synthetic data can be used in place of the\noriginal CIFAR10/ImageNet data for training networks from scratch, producing\ncomparable classification performance. Further, to analyze visual privacy\nprovided by our method, we use Image Quality Metrics and show high degree of\nvisual dissimilarity between the original and synthetic images. Moreover, we\nshow that our proposed method preserves data-privacy under various\nprivacy-leakage attacks including Gradient Matching Attack, Model Memorization\nAttack, and GAN-based Attack.",
    "descriptor": "",
    "authors": [
      "Efstathia Soufleri",
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03205"
  },
  {
    "id": "arXiv:2210.03206",
    "title": "Self-Supervised Monocular Depth Underwater",
    "abstract": "Depth estimation is critical for any robotic system. In the past years\nestimation of depth from monocular images have shown great improvement,\nhowever, in the underwater environment results are still lagging behind due to\nappearance changes caused by the medium. So far little effort has been invested\non overcoming this. Moreover, underwater, there are more limitations for using\nhigh resolution depth sensors, this makes generating ground truth for learning\nmethods another enormous obstacle. So far unsupervised methods that tried to\nsolve this have achieved very limited success as they relied on domain transfer\nfrom dataset in air. We suggest training using subsequent frames\nself-supervised by a reprojection loss, as was demonstrated successfully above\nwater. We suggest several additions to the self-supervised framework to cope\nwith the underwater environment and achieve state-of-the-art results on a\nchallenging forward-looking underwater dataset.",
    "descriptor": "",
    "authors": [
      "Shlomi Amitai",
      "Itzik Klein",
      "Tali Treibitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03206"
  },
  {
    "id": "arXiv:2210.03207",
    "title": "Threat Repair with Optimization Modulo Theories",
    "abstract": "We propose a model-based procedure for automatically preventing security\nthreats using formal models. We encode system models and potential threats as\nsatisfiability modulo theory (SMT) formulas. This model allows us to ask\nsecurity questions as satisfiability queries. We formulate threat prevention as\nan optimization problem over the same formulas. The outcome of our threat\nprevention procedure is a suggestion of model attribute repair that eliminates\nthreats. Whenever threat prevention fails, we automatically explain why the\nthreat happens. We implement our approach using the state-of-the-art Z3 SMT\nsolver and interface it with the threat analysis tool THREATGET. We demonstrate\nthe value of our procedure in two case studies from automotive and smart home\ndomains, including an industrial-strength example.",
    "descriptor": "",
    "authors": [
      "Thorsten Tarrach",
      "Masoud Ebrahimi",
      "Sandra K\u00f6nig",
      "Christoph Schmittner",
      "Roderick Bloem",
      "Dejan Nickovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.03207"
  },
  {
    "id": "arXiv:2210.03209",
    "title": "Self-Adaptive Driving in Nonstationary Environments through Conjectural  Online Lookahead Adaptation",
    "abstract": "Powered by deep representation learning, reinforcement learning (RL) provides\nan end-to-end learning framework capable of solving self-driving (SD) tasks\nwithout manual designs. However, time-varying nonstationary environments cause\nproficient but specialized RL policies to fail at execution time. For example,\nan RL-based SD policy trained under sunny days does not generalize well to\nrainy weather. Even though meta learning enables the RL agent to adapt to new\ntasks/environments, its offline operation fails to equip the agent with online\nadaptation ability when facing nonstationary environments. This work proposes\nan online meta reinforcement learning algorithm based on the \\emph{conjectural\nonline lookahead adaptation} (COLA). COLA determines the online adaptation at\nevery step by maximizing the agent's conjecture of the future performance in a\nlookahead horizon. Experimental results demonstrate that under dynamically\nchanging weather and lighting conditions, the COLA-based self-adaptive driving\noutperforms the baseline policies in terms of online adaptability. A demo\nvideo, source code, and appendixes are available at {\\tt\nhttps://github.com/Panshark/COLA}",
    "descriptor": "\nComments: 10 pages with appendices\n",
    "authors": [
      "Tao Li",
      "Haozhe Lei",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03209"
  },
  {
    "id": "arXiv:2210.03211",
    "title": "LazyFox: Fast and parallelized overlapping community detection in large  graphs",
    "abstract": "The detection of communities in graph datasets provides insight about a\ngraph's underlying structure and is an important tool for various domains such\nas social sciences, marketing, traffic forecast, and drug discovery. While most\nexisting algorithms provide fast approaches for community detection, their\nresults usually contain strictly separated communities. However, most datasets\nwould semantically allow for or even require overlapping communities that can\nonly be determined at much higher computational cost. We build on an efficient\nalgorithm, Fox, that detects such overlapping communities. Fox measures the\ncloseness of a node to a community by approximating the count of triangles\nwhich that node forms with that community. We propose LazyFox, a multi-threaded\nversion of the Fox algorithm, which provides even faster detection without an\nimpact on community quality. This allows for the analyses of significantly\nlarger and more complex datasets. LazyFox enables overlapping community\ndetection on complex graph datasets with millions of nodes and billions of\nedges in days instead of weeks. As part of this work, LazyFox's implementation\nwas published and is available as a tool under an MIT licence at\nhttps://github.com/TimGarrels/LazyFox.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Tim Garrels",
      "Athar Khodabakhsh",
      "Bernhard Y. Renard",
      "Katharina Baum"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03211"
  },
  {
    "id": "arXiv:2210.03214",
    "title": "On the Resilience of Traffic Networks under Non-Equilibrium Learning",
    "abstract": "We investigate the resilience of learning-based \\textit{Intelligent\nNavigation Systems} (INS) to informational flow attacks, which exploit the\nvulnerabilities of IT infrastructure and manipulate traffic condition data. To\nthis end, we propose the notion of \\textit{Wardrop Non-Equilibrium Solution}\n(WANES), which captures the finite-time behavior of dynamic traffic flow\nadaptation under a learning process. The proposed non-equilibrium solution,\ncharacterized by target sets and measurement functions, evaluates the outcome\nof learning under a bounded number of rounds of interactions, and it pertains\nto and generalizes the concept of approximate equilibrium. Leveraging\nfinite-time analysis methods, we discover that under the mirror descent (MD)\nonline-learning framework, the traffic flow trajectory is capable of restoring\nto the Wardrop non-equilibrium solution after a bounded INS attack. The\nresulting performance loss is of order $\\tilde{\\mathcal{O}}(T^{\\beta})$\n($-\\frac{1}{2} \\leq \\beta < 0 )$), with a constant dependent on the size of the\ntraffic network, indicating the resilience of the MD-based INS. We corroborate\nthe results using an evacuation case study on a Sioux-Fall transportation\nnetwork.",
    "descriptor": "\nComments: 8 pages, 3 figures, with a technical appendix\n",
    "authors": [
      "Yunian Pan",
      "Tao Li",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03214"
  },
  {
    "id": "arXiv:2210.03216",
    "title": "Beyond the shortest path: the path length index as a distribution",
    "abstract": "The traditional complex network approach considers only the shortest paths\nfrom one node to another, not taking into account several other possible paths.\nThis limitation is significant, for example, in urban mobility studies. In this\nshort report, as the first steps, we present an exhaustive approach to address\nthat problem and show we can go beyond the shortest path, but we do not need to\ngo so far: we present an interactive procedure and an early stop possibility.\nAfter presenting some fundamental concepts in graph theory, we presented an\nanalytical solution for the problem of counting the number of possible paths\nbetween two nodes in complete graphs, and a depth-limited approach to get all\npossible paths between each pair of nodes in a general graph (an NP-hard\nproblem). We do not collapse the distribution of path lengths between a pair of\nnodes into a scalar number, we look at the distribution itself - taking all\npaths up to a pre-defined path length (considering a truncated distribution),\nand show the impact of that approach on the most straightforward distance-based\ngraph index: the walk/path length.",
    "descriptor": "",
    "authors": [
      "Leonardo B. L. Santos",
      "Luiz Max Carvalho",
      "Giovanni G. Soares",
      "Leonardo N. Ferreira",
      "Igor M. Sokolov"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.03216"
  },
  {
    "id": "arXiv:2210.03217",
    "title": "Genetic algorithm formulation and tuning with use of test functions",
    "abstract": "This work discusses single-objective constrained genetic algorithm with\nfloating-point, integer, binary and permutation representation. Floating-point\ngenetic algorithm tuning with use of test functions is done and leads to a\nparameterization with comparatively outstanding performance.",
    "descriptor": "\nComments: 10 pages, 1 figure, 2 tables. For associated software repository, see this https URL\n",
    "authors": [
      "Tomasz Tarkowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.03217"
  },
  {
    "id": "arXiv:2210.03221",
    "title": "Q-LSTM Language Model -- Decentralized Quantum Multilingual Pre-Trained  Language Model for Privacy Protection",
    "abstract": "Large-scale language models are trained on a massive amount of natural\nlanguage data that might encode or reflect our private information. With\ncareful manipulation, malicious agents can reverse engineer the training data\neven if data sanitation and differential privacy algorithms were involved in\nthe pre-training process. In this work, we propose a decentralized training\nframework to address privacy concerns in training large-scale language models.\nThe framework consists of a cloud quantum language model built with Variational\nQuantum Classifiers (VQC) for sentence embedding and a local Long-Short Term\nMemory (LSTM) model. We use both intrinsic evaluation (loss, perplexity) and\nextrinsic evaluation (downstream sentiment analysis task) to evaluate the\nperformance of our quantum language model. Our quantum model was comparable to\nits classical counterpart on all the above metrics. We also perform ablation\nstudies to look into the effect of the size of VQC and the size of training\ndata on the performance of the model. Our approach solves privacy concerns\nwithout sacrificing downstream task performance. The intractability of quantum\noperations on classical hardware ensures the confidentiality of the training\ndata and makes it impossible to be recovered by any adversary.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Shuyue Stella Li",
      "Xiangyu Zhang",
      "Shu Zhou",
      "Hongchao Shu",
      "Ruixing Liang",
      "Hexin Liu",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03221"
  },
  {
    "id": "arXiv:2210.03230",
    "title": "NAS-Bench-Suite-Zero: Accelerating Research on Zero Cost Proxies",
    "abstract": "Zero-cost proxies (ZC proxies) are a recent architecture performance\nprediction technique aiming to significantly speed up algorithms for neural\narchitecture search (NAS). Recent work has shown that these techniques show\ngreat promise, but certain aspects, such as evaluating and exploiting their\ncomplementary strengths, are under-studied. In this work, we create\nNAS-Bench-Suite: we evaluate 13 ZC proxies across 28 tasks, creating by far the\nlargest dataset (and unified codebase) for ZC proxies, enabling\norders-of-magnitude faster experiments on ZC proxies, while avoiding\nconfounding factors stemming from different implementations. To demonstrate the\nusefulness of NAS-Bench-Suite, we run a large-scale analysis of ZC proxies,\nincluding a bias analysis, and the first information-theoretic analysis which\nconcludes that ZC proxies capture substantial complementary information.\nMotivated by these findings, we present a procedure to improve the performance\nof ZC proxies by reducing biases such as cell size, and we also show that\nincorporating all 13 ZC proxies into the surrogate models used by NAS\nalgorithms can improve their predictive performance by up to 42%. Our code and\ndatasets are available at https://github.com/automl/naslib/tree/zerocost.",
    "descriptor": "\nComments: NeurIPS Datasets and Benchmarks Track 2022\n",
    "authors": [
      "Arjun Krishnakumar",
      "Colin White",
      "Arber Zela",
      "Renbo Tu",
      "Mahmoud Safari",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03230"
  },
  {
    "id": "arXiv:2210.03233",
    "title": "Dominance-based Rough Set Approach, basic ideas and main trends",
    "abstract": "Dominance-based Rough Approach (DRSA) has been proposed as a machine learning\nand knowledge discovery methodology to handle Multiple Criteria Decision Aiding\n(MCDA). Due to its capacity of asking the decision maker (DM) for simple\npreference information and supplying easily understandable and explainable\nrecommendations, DRSA gained much interest during the years and it is now one\nof the most appreciated MCDA approaches. In fact, it has been applied also\nbeyond MCDA domain, as a general knowledge discovery and data mining\nmethodology for the analysis of monotonic (and also non-monotonic) data. In\nthis contribution, we recall the basic principles and the main concepts of\nDRSA, with a general overview of its developments and software. We present also\na historical reconstruction of the genesis of the methodology, with a specific\nfocus on the contribution of Roman S{\\l}owi\\'nski.",
    "descriptor": "\nComments: This research was partially supported by TAILOR, a project funded by European Union (EU) Horizon 2020 research and innovation programme under GA No 952215. This submission is a preprint of a book chapter accepted by Springer, with very few minor differences of just technical nature\n",
    "authors": [
      "Jerzy B\u0142aszczy\u0144ski",
      "Salvatore Greco",
      "Benedetto Matarazzo",
      "Marcin Szel\u0105g"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03233"
  },
  {
    "id": "arXiv:2210.03234",
    "title": "Swarm of UAVs for Network Management in 6G: A Technical Review",
    "abstract": "Fifth-generation (5G) cellular networks have led to the implementation of\nbeyond 5G (B5G) networks, which are capable of incorporating autonomous\nservices to swarm of unmanned aerial vehicles (UAVs). They provide capacity\nexpansion strategies to address massive connectivity issues and guarantee\nultra-high throughput and low latency, especially in extreme or emergency\nsituations where network density, bandwidth, and traffic patterns fluctuate. On\nthe one hand, 6G technology integrates AI/ML, IoT, and blockchain to establish\nultra-reliable, intelligent, secure, and ubiquitous UAV networks. 6G networks,\non the other hand, rely on new enabling technologies such as air interface and\ntransmission technologies, as well as a unique network design, posing new\nchallenges for the swarm of UAVs. Keeping these challenges in mind, this\narticle focuses on the security and privacy, intelligence, and\nenergy-efficiency issues faced by swarms of UAVs operating in 6G mobile\nnetworks. In this state-of-the-art review, we integrated blockchain and AI/ML\nwith UAV networks utilizing the 6G ecosystem. The key findings are then\npresented, and potential research challenges are identified. We conclude the\nreview by shedding light on future research in this emerging field of research.",
    "descriptor": "\nComments: 19, 9\n",
    "authors": [
      "Muhammad Asghar Khan",
      "Neeraj Kumar",
      "Syed Agha Hassnain Mohsan",
      "Wali Ullah Khan",
      "Moustafa M. Nasralla",
      "Mohammed H. Alsharif",
      "Justyna ywioek",
      "Insaf Ullah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03234"
  },
  {
    "id": "arXiv:2210.03235",
    "title": "Improving Large-scale Paraphrase Acquisition and Generation",
    "abstract": "This paper addresses the quality issues in existing Twitter-based paraphrase\ndatasets, and discusses the necessity of using two separate definitions of\nparaphrase for identification and generation tasks. We present a new\nMulti-Topic Paraphrase in Twitter (MultiPIT) corpus that consists of a total of\n130k sentence pairs with crowdsoursing (MultiPIT_crowd) and expert\n(MultiPIT_expert) annotations using two different paraphrase definitions for\nparaphrase identification, in addition to a multi-reference test set\n(MultiPIT_NMR) and a large automatically constructed training set\n(MultiPIT_Auto) for paraphrase generation. With improved data annotation\nquality and task-specific paraphrase definition, the best pre-trained language\nmodel fine-tuned on our dataset achieves the state-of-the-art performance of\n84.2 F1 for automatic paraphrase identification. Furthermore, our empirical\nresults also demonstrate that the paraphrase generation models trained on\nMultiPIT_Auto generate more diverse and high-quality paraphrases compared to\ntheir counterparts fine-tuned on other corpora such as Quora, MSCOCO, and\nParaNMT.",
    "descriptor": "\nComments: The project webpage is at this http URL\n",
    "authors": [
      "Yao Dou",
      "Chao Jiang",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03235"
  },
  {
    "id": "arXiv:2210.03239",
    "title": "Bad Citrus: Reducing Adversarial Costs with Model Distances",
    "abstract": "Recent work by Jia et al., showed the possibility of effectively computing\npairwise model distances in weight space, using a model explanation technique\nknown as LIME. This method requires query-only access to the two models under\nexamination. We argue this insight can be leveraged by an adversary to reduce\nthe net cost (number of queries) of launching an evasion campaign against a\ndeployed model. We show that there is a strong negative correlation between the\nsuccess rate of adversarial transfer and the distance between the victim model\nand the surrogate used to generate the evasive samples. Thus, we propose and\nevaluate a method to reduce adversarial costs by finding the closest surrogate\nmodel for adversarial transfer.",
    "descriptor": "",
    "authors": [
      "Giorgio Severi",
      "Will Pearce",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03239"
  },
  {
    "id": "arXiv:2210.03241",
    "title": "A Step Towards Uncovering The Structure of Multistable Neural Networks",
    "abstract": "We study the structure of multistable recurrent neural networks. The\nactivation function is simplified by a nonsmooth Heaviside step function. This\nnonlinearity partitions the phase space into regions with different, yet linear\ndynamics. We derive how multistability is encoded within the network\narchitecture. Stable states are identified by their semipositivity constraints\non the synaptic weight matrix. The restrictions can be separated by their\neffects on the signs or the strengths of the connections. Exact results on\nnetwork topology, sign stability, weight matrix factorization, pattern\ncompletion and pattern coupling are derived and proven. These may lay the\nfoundation of more complex recurrent neural networks and neurocomputing.",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "Magnus Tournoy",
      "Brent Doiron"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.03241"
  },
  {
    "id": "arXiv:2210.03246",
    "title": "HealthE: Classifying Entities in Online Textual Health Advice",
    "abstract": "The processing of entities in natural language is essential to many medical\nNLP systems. Unfortunately, existing datasets vastly under-represent the\nentities required to model public health relevant texts such as health advice\noften found on sites like WebMD. People rely on such information for personal\nhealth management and clinically relevant decision making. In this work, we\nrelease a new annotated dataset, HealthE, consisting of 6,756 health advice.\nHealthE has a more granular label space compared to existing medical NER\ncorpora and contains annotation for diverse health phrases. Additionally, we\nintroduce a new health entity classification model, EP S-BERT, which leverages\ntextual context patterns in the classification of entity classes. EP S-BERT\nprovides a 4-point increase in F1 score over the nearest baseline and a\n34-point increase in F1 when compared to off-the-shelf medical NER tools\ntrained to extract disease and medication mentions from clinical texts. All\ncode and data are publicly available on Github.",
    "descriptor": "",
    "authors": [
      "Joseph Gatto",
      "Parker Seegmiller",
      "Garrett Johnston",
      "Sarah M. Preum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03246"
  },
  {
    "id": "arXiv:2210.03249",
    "title": "Joint Protection Scheme for Deep Neural Network Hardware Accelerators  and Models",
    "abstract": "Deep neural networks (DNNs) are utilized in numerous image processing, object\ndetection, and video analysis tasks and need to be implemented using hardware\naccelerators to achieve practical speed. Logic locking is one of the most\npopular methods for preventing chip counterfeiting. Nevertheless, existing\nlogic-locking schemes need to sacrifice the number of input patterns leading to\nwrong output under incorrect keys to resist the powerful satisfiability\n(SAT)-attack. Furthermore, DNN model inference is fault-tolerant. Hence, using\na wrong key for those SAT-resistant logic-locking schemes may not affect the\naccuracy of DNNs. This makes the previous SAT-resistant logic-locking scheme\nineffective on protecting DNN accelerators. Besides, to prevent DNN models from\nbeing illegally used, the models need to be obfuscated by the designers before\nthey are provided to end-users. Previous obfuscation methods either require\nlong time to retrain the model or leak information about the model. This paper\nproposes a joint protection scheme for DNN hardware accelerators and models.\nThe DNN accelerator is modified using a hardware key (Hkey) and a model key\n(Mkey). Different from previous logic locking, the Hkey, which is used to\nprotect the accelerator, does not affect the output when it is wrong. As a\nresult, the SAT attack can be effectively resisted. On the other hand, a wrong\nHkey leads to substantial increase in memory accesses, inference time, and\nenergy consumption and makes the accelerator unusable. A correct Mkey can\nrecover the DNN model that is obfuscated by the proposed method. Compared to\nprevious model obfuscation schemes, our proposed method avoids model retraining\nand does not leak model information.",
    "descriptor": "",
    "authors": [
      "Jingbo Zhou",
      "Xinmiao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03249"
  },
  {
    "id": "arXiv:2210.03250",
    "title": "Unsupervised Domain Adaptation for COVID-19 Information Service with  Contrastive Adversarial Domain Mixup",
    "abstract": "In the real-world application of COVID-19 misinformation detection, a\nfundamental challenge is the lack of the labeled COVID data to enable\nsupervised end-to-end training of the models, especially at the early stage of\nthe pandemic. To address this challenge, we propose an unsupervised domain\nadaptation framework using contrastive learning and adversarial domain mixup to\ntransfer the knowledge from an existing source data domain to the target\nCOVID-19 data domain. In particular, to bridge the gap between the source\ndomain and the target domain, our method reduces a radial basis function (RBF)\nbased discrepancy between these two domains. Moreover, we leverage the power of\ndomain adversarial examples to establish an intermediate domain mixup, where\nthe latent representations of the input text from both domains could be mixed\nduring the training process. Extensive experiments on multiple real-world\ndatasets suggest that our method can effectively adapt misinformation detection\nsystems to the unseen COVID-19 target domain with significant improvements\ncompared to the state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Huimin Zeng",
      "Zhenrui Yue",
      "Ziyi Kou",
      "Lanyu Shang",
      "Yang Zhang",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03250"
  },
  {
    "id": "arXiv:2210.03251",
    "title": "Small Character Models Match Large Word Models for Autocomplete Under  Memory Constraints",
    "abstract": "Autocomplete is a task where the user inputs a piece of text, termed prompt,\nwhich is conditioned by the model to generate semantically coherent\ncontinuation. Existing works for this task have primarily focused on datasets\n(e.g., email, chat) with high frequency user prompt patterns (or focused\nprompts) where word-based language models have been quite effective. In this\nwork, we study the more challenging setting consisting of low frequency user\nprompt patterns (or broad prompts, e.g., prompt about 93rd academy awards) and\ndemonstrate the effectiveness of character-based language models. We study this\nproblem under memory-constrained settings (e.g., edge devices and smartphones),\nwhere character-based representation is effective in reducing the overall model\nsize (in terms of parameters). We use WikiText-103 benchmark to simulate broad\nprompts and demonstrate that character models rival word models in exact match\naccuracy for the autocomplete task, when controlled for the model size. For\ninstance, we show that a 20M parameter character model performs similar to an\n80M parameter word model in the vanilla setting. We further propose novel\nmethods to improve character models by incorporating inductive bias in the form\nof compositional information and representation transfer from large word\nmodels.",
    "descriptor": "",
    "authors": [
      "Ganesh Jawahar",
      "Subhabrata Mukherjee",
      "Debadeepta Dey",
      "Muhammad Abdul-Mageed",
      "Laks V.S. Lakshmanan",
      "Caio Cesar Teodoro Mendes",
      "Gustavo Henrique de Rosa",
      "Shital Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03251"
  },
  {
    "id": "arXiv:2210.03253",
    "title": "Fast Automatic Bayesian Cubature Using Matching Kernels and Designs",
    "abstract": "Automatic cubatures approximate integrals to user-specified error tolerances.\nFor high dimensional problems, it is difficult to adaptively change the\nsampling pattern to focus on peaks because peaks can hide more easily in high\ndimensional space. But, one can automatically determine the sample size, $n$,\ngiven a reasonable, fixed sampling pattern. This approach is pursued in\nJagadeeswaran and Hickernell, Stat.\\ Comput., 29:1214-1229, 2019, where a\nBayesian perspective is used to construct a credible interval for the integral,\nand the computation is terminated when the half-width of the interval is no\ngreater than the required error tolerance. Our earlier work employs integration\nlattice sampling, and the computations are expedited by the fast Fourier\ntransform because the covariance kernels for the Gaussian process prior on the\nintegrand are chosen to be shift-invariant. In this chapter, we extend our fast\nautomatic Bayesian cubature to digital net sampling via \\emph{digitally}\nshift-invariant covariance kernels and fast Walsh transforms.\nOur algorithm is implemented in the MATLAB Guaranteed Automatic Integration\nLibrary (GAIL) and the QMCPy Python library.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Jagadeeswaran Rathinavel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03253"
  },
  {
    "id": "arXiv:2210.03254",
    "title": "Network Intrusion Detection System in a Light Bulb",
    "abstract": "Internet of Things (IoT) devices are progressively being utilised in a\nvariety of edge applications to monitor and control home and industry\ninfrastructure. Due to the limited compute and energy resources, active\nsecurity protections are usually minimal in many IoT devices. This has created\na critical security challenge that has attracted researchers' attention in the\nfield of network security. Despite a large number of proposed Network Intrusion\nDetection Systems (NIDSs), there is limited research into practical IoT\nimplementations, and to the best of our knowledge, no edge-based NIDS has been\ndemonstrated to operate on common low-power chipsets found in the majority of\nIoT devices, such as the ESP8266. This research aims to address this gap by\npushing the boundaries on low-power Machine Learning (ML) based NIDSs. We\npropose and develop an efficient and low-power ML-based NIDS, and demonstrate\nits applicability for IoT edge applications by running it on a typical smart\nlight bulb. We also evaluate our system against other proposed edge-based NIDSs\nand show that our model has a higher detection performance, and is\nsignificantly faster and smaller, and therefore more applicable to a wider\nrange of IoT edge devices.",
    "descriptor": "",
    "authors": [
      "Liam Daly Manocchio",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03254"
  },
  {
    "id": "arXiv:2210.03255",
    "title": "Damage Control During Domain Adaptation for Transducer Based Automatic  Speech Recognition",
    "abstract": "Automatic speech recognition models are often adapted to improve their\naccuracy in a new domain. A potential drawback of model adaptation to new\ndomains is catastrophic forgetting, where the Word Error Rate on the original\ndomain is significantly degraded. This paper addresses the situation when we\nwant to simultaneously adapt automatic speech recognition models to a new\ndomain and limit the degradation of accuracy on the original domain without\naccess to the original training dataset. We propose several techniques such as\na limited training strategy and regularized adapter modules for the Transducer\nencoder, prediction, and joiner network. We apply these methods to the Google\nSpeech Commands and to the UK and Ireland English Dialect speech data set and\nobtain strong results on the new target domain while limiting the degradation\non the original domain.",
    "descriptor": "\nComments: To appear in Proc. SLT 2022, Jan 09-12, 2023, Doha, Qatar\n",
    "authors": [
      "Somshubra Majumdar",
      "Shantanu Acharya",
      "Vitaly Lavrukhin",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03255"
  },
  {
    "id": "arXiv:2210.03256",
    "title": "Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal  Negation",
    "abstract": "Negation is poorly captured by current language models, although the extent\nof this problem is not widely understood. We introduce a natural language\ninference (NLI) test suite to enable probing the capabilities of NLP methods,\nwith the aim of understanding sub-clausal negation. The test suite contains\npremise--hypothesis pairs where the premise contains sub-clausal negation and\nthe hypothesis is constructed by making minimal modifications to the premise in\norder to reflect different possible interpretations. Aside from adopting\nstandard NLI labels, our test suite is systematically constructed under a\nrigorous linguistic framework. It includes annotation of negation types and\nconstructions grounded in linguistic theory, as well as the operations used to\nconstruct hypotheses. This facilitates fine-grained analysis of model\nperformance. We conduct experiments using pre-trained language models to\ndemonstrate that our test suite is more challenging than existing benchmarks\nfocused on negation, and show how our annotation supports a deeper\nunderstanding of the current NLI capabilities in terms of negation and\nquantification.",
    "descriptor": "\nComments: AACL-ICJNLP 2022\n",
    "authors": [
      "Hung Thinh Truong",
      "Yulia Otmakhova",
      "Timothy Baldwin",
      "Trevor Cohn",
      "Karin Verspoor",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03256"
  },
  {
    "id": "arXiv:2210.03258",
    "title": "Interpreting County Level COVID-19 Infection and Feature Sensitivity  using Deep Learning Time Series Models",
    "abstract": "Interpretable machine learning plays a key role in healthcare because it is\nchallenging in understanding feature importance in deep learning model\npredictions. We propose a novel framework that uses deep learning to study\nfeature sensitivity for model predictions. This work combines sensitivity\nanalysis with heterogeneous time-series deep learning model prediction, which\ncorresponds to the interpretations of spatio-temporal features. We forecast\ncounty-level COVID-19 infection using the Temporal Fusion Transformer. We then\nuse the sensitivity analysis extending Morris Method to see how sensitive the\noutputs are with respect to perturbation to our static and dynamic input\nfeatures. The significance of the work is grounded in a real-world COVID-19\ninfection prediction with highly non-stationary, finely granular, and\nheterogeneous data. 1) Our model can capture the detailed daily changes of\ntemporal and spatial model behaviors and achieves high prediction performance\ncompared to a PyTorch baseline. 2) By analyzing the Morris sensitivity indices\nand attention patterns, we decipher the meaning of feature importance with\nobservational population and dynamic model changes. 3) We have collected 2.5\nyears of socioeconomic and health features over 3142 US counties, such as\nobserved cases and deaths, and a number of static (age distribution, health\ndisparity, and industry) and dynamic features (vaccination, disease spread,\ntransmissible cases, and social distancing). Using the proposed framework, we\nconduct extensive experiments and show our model can learn complex interactions\nand perform predictions for daily infection at the county level. Being able to\nmodel the disease infection with a hybrid prediction and description accuracy\nmeasurement with Morris index at the county level is a central idea that sheds\nlight on individual feature interpretation via sensitivity analysis.",
    "descriptor": "",
    "authors": [
      "Md Khairul Islam",
      "Di Zhu",
      "Yingzheng Liu",
      "Andrej Erkelens",
      "Nick Daniello",
      "Judy Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03258"
  },
  {
    "id": "arXiv:2210.03259",
    "title": "Considerations for Task Allocation in Human-Robot Teams",
    "abstract": "In human-robot teams where agents collaborate together, there needs to be a\nclear allocation of tasks to agents. Task allocation can aid in achieving the\npresumed benefits of human-robot teams, such as improved team performance. Many\ntask allocation methods have been proposed that include factors such as agent\ncapability, availability, workload, fatigue, and task and domain-specific\nparameters. In this paper, selected work on task allocation is reviewed. In\naddition, some areas for continued and further consideration in task allocation\nare discussed. These areas include level of collaboration, novel tasks, unknown\nand dynamic agent capabilities, negotiation and fairness, and ethics. Where\napplicable, we also mention some of our work on task allocation. Through\ncontinued efforts and considerations in task allocation, human-robot teaming\ncan be improved.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2022 (arXiv:2209.14292)\n",
    "authors": [
      "Arsha Ali",
      "Dawn M. Tilbury",
      "Lionel P. Robert Jr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03259"
  },
  {
    "id": "arXiv:2210.03261",
    "title": "Adversarial Lagrangian Integrated Contrastive Embedding for Limited Size  Datasets",
    "abstract": "Certain datasets contain a limited number of samples with highly various\nstyles and complex structures. This study presents a novel adversarial\nLagrangian integrated contrastive embedding (ALICE) method for small-sized\ndatasets. First, the accuracy improvement and training convergence of the\nproposed pre-trained adversarial transfer are shown on various subsets of\ndatasets with few samples. Second, a novel adversarial integrated contrastive\nmodel using various augmentation techniques is investigated. The proposed\nstructure considers the input samples with different appearances and generates\na superior representation with adversarial transfer contrastive training.\nFinally, multi-objective augmented Lagrangian multipliers encourage the\nlow-rank and sparsity of the presented adversarial contrastive embedding to\nadaptively estimate the coefficients of the regularizers automatically to the\noptimum weights. The sparsity constraint suppresses less representative\nelements in the feature space. The low-rank constraint eliminates trivial and\nredundant components and enables superior generalization. The performance of\nthe proposed model is verified by conducting ablation studies by using\nbenchmark datasets for scenarios with small data samples.",
    "descriptor": "\nComments: Submitted to Neural Networks Journal: 36 pages, 6 figures\n",
    "authors": [
      "Amin Jalali",
      "Minho Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03261"
  },
  {
    "id": "arXiv:2210.03264",
    "title": "Unsupervised Neural Stylistic Text Generation using Transfer learning  and Adapters",
    "abstract": "Research has shown that personality is a key driver to improve engagement and\nuser experience in conversational systems. Conversational agents should also\nmaintain a consistent persona to have an engaging conversation with a user.\nHowever, text generation datasets are often crowd sourced and thereby have an\naveraging effect where the style of the generation model is an average style of\nall the crowd workers that have contributed to the dataset. While one can\ncollect persona-specific datasets for each task, it would be an expensive and\ntime consuming annotation effort. In this work, we propose a novel transfer\nlearning framework which updates only $0.3\\%$ of model parameters to learn\nstyle specific attributes for response generation. For the purpose of this\nstudy, we tackle the problem of stylistic story ending generation using the ROC\nstories Corpus. We learn style specific attributes from the\nPERSONALITY-CAPTIONS dataset. Through extensive experiments and evaluation\nmetrics we show that our novel training procedure can improve the style\ngeneration by 200 over Encoder-Decoder baselines while maintaining on-par\ncontent relevance metrics with",
    "descriptor": "",
    "authors": [
      "Vinayshekhar Bannihatti Kumar",
      "Rashmi Gangadharaiah",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03264"
  },
  {
    "id": "arXiv:2210.03265",
    "title": "Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision  Tasks",
    "abstract": "Adapting large-scale pretrained models to various downstream tasks via\nfine-tuning is a standard method in machine learning. Recently,\nparameter-efficient fine-tuning methods show promise in adapting a pretrained\nmodel to different tasks while training only a few parameters. Despite their\nsuccess, most existing methods are proposed in Natural Language Processing\ntasks with language Transformers, and adaptation to Computer Vision tasks with\nVision Transformers remains under-explored, especially for dense vision tasks.\nFurther, in multi-task settings, individually fine-tuning and storing separate\nmodels for different tasks is inefficient. In this work, we provide an\nextensive multi-task parameter-efficient benchmark and examine existing\nparameter-efficient fine-tuning NLP methods for vision tasks. Our results on\nfour different dense vision tasks showed that existing methods cannot be\nefficiently integrated due to the hierarchical nature of the Hierarchical\nVision Transformers. To overcome this issue, we propose Polyhistor and\nPolyhistor-Lite, consisting of Decomposed HyperNetworks and Layer-wise Scaling\nKernels, to share information across different tasks with a few trainable\nparameters. This leads to favorable performance improvements against existing\nparameter-efficient methods while using fewer trainable parameters.\nSpecifically, Polyhistor achieves competitive accuracy compared to the\nstate-of-the-art while only using ~10% of their trainable parameters.\nFurthermore, our methods show larger performance gains when large networks and\nmore pretraining data are used.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022; Project Page is at this https URL\n",
    "authors": [
      "Yen-Cheng Liu",
      "Chih-Yao Ma",
      "Junjiao Tian",
      "Zijian He",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03265"
  },
  {
    "id": "arXiv:2210.03269",
    "title": "Multi-agent Deep Covering Option Discovery",
    "abstract": "The use of options can greatly accelerate exploration in reinforcement\nlearning, especially when only sparse reward signals are available. While\noption discovery methods have been proposed for individual agents, in\nmulti-agent reinforcement learning settings, discovering collaborative options\nthat can coordinate the behavior of multiple agents and encourage them to visit\nthe under-explored regions of their joint state space has not been considered.\nIn this case, we propose Multi-agent Deep Covering Option Discovery, which\nconstructs the multi-agent options through minimizing the expected cover time\nof the multiple agents' joint state space. Also, we propose a novel framework\nto adopt the multi-agent options in the MARL process. In practice, a\nmulti-agent task can usually be divided into some sub-tasks, each of which can\nbe completed by a sub-group of the agents. Therefore, our algorithm framework\nfirst leverages an attention mechanism to find collaborative agent sub-groups\nthat would benefit most from coordinated actions. Then, a hierarchical\nalgorithm, namely HA-MSAC, is developed to learn the multi-agent options for\neach sub-group to complete their sub-tasks first, and then to integrate them\nthrough a high-level policy as the solution of the whole task. This\nhierarchical option construction allows our framework to strike a balance\nbetween scalability and effective collaboration among the agents. The\nevaluation based on multi-agent collaborative tasks shows that the proposed\nalgorithm can effectively capture the agent interactions with the attention\nmechanism, successfully identify multi-agent options, and significantly\noutperforms prior works using single-agent options or no options, in terms of\nboth faster exploration and higher task rewards.",
    "descriptor": "\nComments: This paper was presented in part at the ICML Reinforcement Learning for Real Life Workshop, July 2021\n",
    "authors": [
      "Jiayu Chen",
      "Marina Haliem",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03269"
  },
  {
    "id": "arXiv:2210.03270",
    "title": "TRADE: Object Tracking with 3D Trajectory and Ground Depth Estimates for  UAVs",
    "abstract": "We propose TRADE for robust tracking and 3D localization of a moving target\nin cluttered environments, from UAVs equipped with a single camera. Ultimately\nTRADE enables 3d-aware target following.\nTracking-by-detection approaches are vulnerable to target switching,\nespecially between similar objects. Thus, TRADE predicts and incorporates the\ntarget 3D trajectory to select the right target from the tracker's response\nmap. Unlike static environments, depth estimation of a moving target from a\nsingle camera is a ill-posed problem. Therefore we propose a novel 3D\nlocalization method for ground targets on complex terrain. It reasons about\nscene geometry by combining ground plane segmentation, depth-from-motion and\nsingle-image depth estimation. The benefits of using TRADE are demonstrated as\ntracking robustness and depth accuracy on several dynamic scenes simulated in\nthis work. Additionally, we demonstrate autonomous target following using a\nthermal camera by running TRADE on a quadcopter's board computer.",
    "descriptor": "",
    "authors": [
      "Pedro F. Proen\u00e7a",
      "Patrick Spieler",
      "Robert A. Hewitt",
      "Jeff Delaune"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03270"
  },
  {
    "id": "arXiv:2210.03273",
    "title": "A Unified Encoder-Decoder Framework with Entity Memory",
    "abstract": "Entities, as important carriers of real-world knowledge, play a key role in\nmany NLP tasks. We focus on incorporating entity knowledge into an\nencoder-decoder framework for informative text generation. Existing approaches\ntried to index, retrieve, and read external documents as evidence, but they\nsuffered from a large computational overhead. In this work, we propose an\nencoder-decoder framework with an entity memory, namely EDMem. The entity\nknowledge is stored in the memory as latent representations, and the memory is\npre-trained on Wikipedia along with encoder-decoder parameters. To precisely\ngenerate entity names, we design three decoding methods to constrain entity\ngeneration by linking entities in the memory. EDMem is a unified framework that\ncan be used on various entity-intensive question answering and generation\ntasks. Extensive experimental results show that EDMem outperforms both\nmemory-based auto-encoder models and non-memory encoder-decoder models.",
    "descriptor": "\nComments: Accepted by the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)\n",
    "authors": [
      "Zhihan Zhang",
      "Wenhao Yu",
      "Chenguang Zhu",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03273"
  },
  {
    "id": "arXiv:2210.03274",
    "title": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "abstract": "Explaining deep learning models is of vital importance for understanding\nartificial intelligence systems, improving safety, and evaluating fairness. To\nbetter understand and control the CNN model, many methods for\ntransparency-interpretability have been proposed. However, most of these works\nare less intuitive for human understanding and have insufficient human control\nover the CNN model. We propose a novel method, Transparent and Controllable\nNetwork Learning (TCNL), to overcome such challenges. Towards the goal of\nimproving transparency-interpretability, in TCNL, we define some concepts for\nspecific classification tasks through scientific human-intuition study and\nincorporate concept information into the CNN model. In TCNL, the shallow\nfeature extractor gets preliminary features first. Then several concept feature\nextractors are built right after the shallow feature extractor to learn\nhigh-dimensional concept representations. The concept feature extractor is\nencouraged to encode information related to the predefined concepts. We also\nbuild the concept mapper to visualize features extracted by the concept\nextractor in a human-intuitive way. TCNL provides a generalizable approach to\ntransparency-interpretability. Researchers can define concepts corresponding to\ncertain classification tasks and encourage the model to encode specific concept\ninformation, which to a certain extent improves transparency-interpretability\nand the controllability of the CNN model. The datasets (with concept sets) for\nour experiments will also be released (https://github.com/bupt-ai-cz/TCNL).",
    "descriptor": "",
    "authors": [
      "Zhihao Wang",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03274"
  },
  {
    "id": "arXiv:2210.03275",
    "title": "Out-of-Distribution Generalization in Algorithmic Reasoning Through  Curriculum Learning",
    "abstract": "Out-of-distribution generalization (OODG) is a longstanding challenge for\nneural networks, and is quite apparent in tasks with well-defined variables and\nrules, where explicit use of the rules can solve problems independently of the\nparticular values of the variables. Large transformer-based language models\nhave pushed the boundaries on how well neural networks can generalize to novel\ninputs, but their complexity obfuscates they achieve such robustness. As a step\ntoward understanding how transformer-based systems generalize, we explore the\nquestion of OODG in smaller scale transformers. Using a reasoning task based on\nthe puzzle Sudoku, we show that OODG can occur on complex problems if the\ntraining set includes examples sampled from the whole distribution of simpler\ncomponent tasks.",
    "descriptor": "",
    "authors": [
      "Andrew J. Nam",
      "Mustafa Abdool",
      "Trevor Maxfield",
      "James L. McClelland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03275"
  },
  {
    "id": "arXiv:2210.03277",
    "title": "Rethinking Normalization Methods in Federated Learning",
    "abstract": "Federated learning (FL) is a popular distributed learning framework that can\nreduce privacy risks by not explicitly sharing private data. In this work, we\nexplicitly uncover external covariate shift problem in FL, which is caused by\nthe independent local training processes on different devices. We demonstrate\nthat external covariate shifts will lead to the obliteration of some devices'\ncontributions to the global model. Further, we show that normalization layers\nare indispensable in FL since their inherited properties can alleviate the\nproblem of obliterating some devices' contributions. However, recent works have\nshown that batch normalization, which is one of the standard components in many\ndeep neural networks, will incur accuracy drop of the global model in FL. The\nessential reason for the failure of batch normalization in FL is poorly\nstudied. We unveil that external covariate shift is the key reason why batch\nnormalization is ineffective in FL. We also show that layer normalization is a\nbetter choice in FL which can mitigate the external covariate shift and improve\nthe performance of the global model. We conduct experiments on CIFAR10 under\nnon-IID settings. The results demonstrate that models with layer normalization\nconverge fastest and achieve the best or comparable accuracy for three\ndifferent model architectures.",
    "descriptor": "\nComments: Submitted to DistributedML'22 workshop\n",
    "authors": [
      "Zhixu Du",
      "Jingwei Sun",
      "Ang Li",
      "Pin-Yu Chen",
      "Jianyi Zhang",
      "Hai \"Helen\" Li",
      "Yiran Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03277"
  },
  {
    "id": "arXiv:2210.03280",
    "title": "Real-Time Navigation for Bipedal Robots in Dynamic Environments",
    "abstract": "The popularity of mobile robots has been steadily growing, with these robots\nbeing increasingly utilized to execute tasks previously completed by human\nworkers. For bipedal robots to see this same success, robust autonomous\nnavigation systems need to be developed that can execute in real-time and\nrespond to dynamic environments. These systems can be divided into three\nstages: perception, planning, and control. A holistic navigation framework for\nbipedal robots must successfully integrate all three components of the\nautonomous navigation problem to enable robust real-world navigation. In this\npaper, we present a real-time navigation framework for bipedal robots in\ndynamic environments. The proposed system addresses all components of the\nnavigation problem: We introduce a depth-based perception system for obstacle\ndetection, mapping, and localization. A two-stage planner is developed to\ngenerate collision-free trajectories robust to unknown and dynamic\nenvironments. And execute trajectories on the Digit bipedal robot's walking\ngait controller. The navigation framework is validated through a series of\nsimulation and hardware experiments that contain unknown environments and\ndynamic obstacles.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Robotics and Automation (ICRA). For associated experiment recordings see this https URL\n",
    "authors": [
      "Octavian A. Donca",
      "Chayapol Beokhaimook",
      "Ayonga Hereid"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03280"
  },
  {
    "id": "arXiv:2210.03281",
    "title": "Automatic Prediction of Rejected Edits in Stack Overflow",
    "abstract": "The content quality of shared knowledge in Stack Overflow (SO) is crucial in\nsupporting software developers with their programming problems. Thus, SO allows\nits users to suggest edits to improve the quality of a post (i.e., question and\nanswer). However, existing research shows that many suggested edits in SO are\nrejected due to undesired contents/formats or violating edit guidelines. Such a\nscenario frustrates or demotivates users who would like to conduct good-quality\nedits. Therefore, our research focuses on assisting SO users by offering them\nsuggestions on how to improve their editing of posts. First, we manually\ninvestigate 764 (382 questions + 382 answers) rejected edits by rollbacks and\nproduce a catalog of 19 rejection reasons. Second, we extract 15 texts and\nuser-based features to capture those rejection reasons. Third, we develop four\nmachine learning models using those features. Our best-performing model can\npredict rejected edits with 69.1% precision, 71.2% recall, 70.1% F1-score, and\n69.8% overall accuracy. Fourth, we introduce an online tool named EditEx that\nworks with the SO edit system. EditEx can assist users while editing posts by\nsuggesting the potential causes of rejections. We recruit 20 participants to\nassess the effectiveness of EditEx. Half of the participants (i.e., treatment\ngroup) use EditEx and another half (i.e., control group) use the SO standard\nedit system to edit posts. According to our experiment, EditEx can support SO\nstandard edit system to prevent 49% of rejected edits, including the commonly\nrejected ones. However, it can prevent 12% rejections even in free-form regular\nedits. The treatment group finds the potential rejection reasons identified by\nEditEx influential. Furthermore, the median workload suggesting edits using\nEditEx is half compared to the SO edit system.",
    "descriptor": "\nComments: Accepted for publication in Empirical Software Engineering (EMSE) journal\n",
    "authors": [
      "Saikat Mondal",
      "Gias Uddin",
      "Chanchal Roy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.03281"
  },
  {
    "id": "arXiv:2210.03282",
    "title": "Set2Box: Similarity Preserving Representation Learning of Sets",
    "abstract": "Sets have been used for modeling various types of objects (e.g., a document\nas the set of keywords in it and a customer as the set of the items that she\nhas purchased). Measuring similarity (e.g., Jaccard Index) between sets has\nbeen a key building block of a wide range of applications, including,\nplagiarism detection, recommendation, and graph compression. However, as sets\nhave grown in numbers and sizes, the computational cost and storage required\nfor set similarity computation have become substantial, and this has led to the\ndevelopment of hashing and sketching based solutions. In this work, we propose\nSet2Box, a learning-based approach for compressed representations of sets from\nwhich various similarity measures can be estimated accurately in constant time.\nThe key idea is to represent sets as boxes to precisely capture overlaps of\nsets. Additionally, based on the proposed box quantization scheme, we design\nSet2Box+, which yields more concise but more accurate box representations of\nsets. Through extensive experiments on 8 real-world datasets, we show that,\ncompared to baseline approaches, Set2Box+ is (a) Accurate: achieving up to\n40.8X smaller estimation error while requiring 60% fewer bits to encode sets,\n(b) Concise: yielding up to 96.8X more concise representations with similar\nestimation error, and (c) Versatile: enabling the estimation of four\nset-similarity measures from a single representation of each set.",
    "descriptor": "\nComments: Accepted by ICDM 2022\n",
    "authors": [
      "Geon Lee",
      "Chanyoung Park",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03282"
  },
  {
    "id": "arXiv:2210.03283",
    "title": "Design Amortization for Bayesian Optimal Experimental Design",
    "abstract": "Bayesian optimal experimental design is a sub-field of statistics focused on\ndeveloping methods to make efficient use of experimental resources. Any\npotential design is evaluated in terms of a utility function, such as the\n(theoretically well-justified) expected information gain (EIG); unfortunately\nhowever, under most circumstances the EIG is intractable to evaluate. In this\nwork we build off of successful variational approaches, which optimize a\nparameterized variational model with respect to bounds on the EIG. Past work\nfocused on learning a new variational model from scratch for each new design\nconsidered. Here we present a novel neural architecture that allows\nexperimenters to optimize a single variational model that can estimate the EIG\nfor potentially infinitely many designs. To further improve computational\nefficiency, we also propose to train the variational model on a significantly\ncheaper-to-evaluate lower bound, and show empirically that the resulting model\nprovides an excellent guide for more accurate, but expensive to evaluate bounds\non the EIG. We demonstrate the effectiveness of our technique on generalized\nlinear models, a class of statistical models that is widely used in the\nanalysis of controlled experiments. Experiments show that our method is able to\ngreatly improve accuracy over existing approximation strategies, and achieve\nthese results with far better sample efficiency.",
    "descriptor": "",
    "authors": [
      "Noble Kennamer",
      "Steven Walton",
      "Alexander Ihler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.03283"
  },
  {
    "id": "arXiv:2210.03286",
    "title": "Perspectives on a 6G Architecture",
    "abstract": "Mobile communications have been undergoing a generational change every ten\nyears. Whilst we are just beginning to roll out 5G networks, significant\nefforts are planned to standardize 6G that is expected to be commercially\nintroduced by 2030. This paper looks at the use cases for 6G and their impact\non the network architecture to meet the anticipated performance requirements.\nThe new architecture is based on integrating various network functions in\nvirtual cloud environments, leveraging the advancement of artificial\nintelligence in all domains, integrating different sub-networks constituting\nthe 6G system, and on enhanced means of exposing data and services to third\nparties.",
    "descriptor": "\nComments: 7 pages, 5 figures, one table\n",
    "authors": [
      "Rainer Liebhart",
      "Mansoor Shafi",
      "Gajan Shivanandan",
      "Devaki Chandramouli",
      "Laurent Thiebaut"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03286"
  },
  {
    "id": "arXiv:2210.03288",
    "title": "Scientific Paper Classification Based on Graph Neural Network with  Hypergraph Self-attention Mechanism",
    "abstract": "The number of scientific papers has increased rapidly in recent years. How to\nmake good use of scientific papers for research is very important. Through the\nhigh-quality classification of scientific papers, researchers can quickly find\nthe resource content they need from the massive scientific resources. The\nclassification of scientific papers will effectively help researchers filter\nredundant information, obtain search results quickly and accurately, and\nimprove the search quality, which is necessary for scientific resource\nmanagement. This paper proposed a science-technique paper classification method\nbased on hypergraph neural network(SPHNN). In the heterogeneous information\nnetwork of scientific papers, the repeated high-order subgraphs are modeled as\nhyperedges composed of multiple related nodes. Then the whole heterogeneous\ninformation network is transformed into a hypergraph composed of different\nhyperedges. The graph convolution operation is carried out on the hypergraph\nstructure, and the hyperedges self-attention mechanism is introduced to\naggregate different types of nodes in the hypergraph, so that the final node\nrepresentation can effectively maintain high-order nearest neighbor\nrelationships and complex semantic information. Finally, by comparing with\nother methods, we proved that the model proposed in this paper has improved its\nperformance.",
    "descriptor": "",
    "authors": [
      "Jiashun Liu",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03288"
  },
  {
    "id": "arXiv:2210.03289",
    "title": "Scalable Self-Supervised Representation Learning from Spatiotemporal  Motion Trajectories for Multimodal Computer Vision",
    "abstract": "Self-supervised representation learning techniques utilize large datasets\nwithout semantic annotations to learn meaningful, universal features that can\nbe conveniently transferred to solve a wide variety of downstream supervised\ntasks. In this work, we propose a self-supervised method for learning\nrepresentations of geographic locations from unlabeled GPS trajectories to\nsolve downstream geospatial computer vision tasks. Tiles resulting from a\nraster representation of the earth's surface are modeled as nodes on a graph or\npixels of an image. GPS trajectories are modeled as allowed Markovian paths on\nthese nodes. A scalable and distributed algorithm is presented to compute\nimage-like representations, called reachability summaries, of the spatial\nconnectivity patterns between tiles and their neighbors implied by the observed\nMarkovian paths. A convolutional, contractive autoencoder is trained to learn\ncompressed representations, called reachability embeddings, of reachability\nsummaries for every tile. Reachability embeddings serve as task-agnostic,\nfeature representations of geographic locations. Using reachability embeddings\nas pixel representations for five different downstream geospatial tasks, cast\nas supervised semantic segmentation problems, we quantitatively demonstrate\nthat reachability embeddings are semantically meaningful representations and\nresult in 4-23% gain in performance, as measured using area under the\nprecision-recall curve (AUPRC) metric, when compared to baseline models that\nuse pixel representations that do not account for the spatial connectivity\nbetween tiles. Reachability embeddings transform sequential, spatiotemporal\nmobility data into semantically meaningful tensor representations that can be\ncombined with other sources of imagery and are designed to facilitate\nmultimodal learning in geospatial computer vision.",
    "descriptor": "\nComments: Extended abstract accepted for presentation at BayLearn 2022. 3 pages, 2 figures, 1 table. Abstract based on IEEE MDM 2022 research track paper: arXiv:2110.12521\n",
    "authors": [
      "Swetava Ganguli",
      "C. V. Krishnakumar Iyer",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03289"
  },
  {
    "id": "arXiv:2210.03290",
    "title": "Embedding Representation of Academic Heterogeneous Information Networks  Based on Federated Learning",
    "abstract": "Academic networks in the real world can usually be portrayed as heterogeneous\ninformation networks (HINs) with multi-type, universally connected nodes and\nmulti-relationships. Some existing studies for the representation learning of\nhomogeneous information networks cannot be applicable to heterogeneous\ninformation networks because of the lack of ability to issue heterogeneity. At\nthe same time, data has become a factor of production, playing an increasingly\nimportant role. Due to the closeness and blocking of businesses among different\nenterprises, there is a serious phenomenon of data islands. To solve the above\nchallenges, aiming at the data information of scientific research teams closely\nrelated to science and technology, we proposed an academic heterogeneous\ninformation network embedding representation learning method based on federated\nlearning (FedAHE), which utilizes node attention and meta path attention\nmechanism to learn low-dimensional, dense and real-valued vector\nrepresentations while preserving the rich topological information and\nmeta-path-based semantic information of nodes in network. Moreover, we combined\nfederated learning with the representation learning of HINs composed of\nscientific research teams and put forward a federal training mechanism based on\ndynamic weighted aggregation of parameters (FedDWA) to optimize the node\nembeddings of HINs. Through sufficient experiments, the efficiency, accuracy\nand feasibility of our proposed framework are demonstrated.",
    "descriptor": "",
    "authors": [
      "Junfu Wang",
      "Yawen Li",
      "Meiyu Liang",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03290"
  },
  {
    "id": "arXiv:2210.03291",
    "title": "A Relational Triple Extraction Method Based on Feature Reasoning for  Technological Patents",
    "abstract": "The relation triples extraction method based on table filling can address the\nissues of relation overlap and bias propagation. However, most of them only\nestablish separate table features for each relationship, which ignores the\nimplicit relationship between different entity pairs and different relationship\nfeatures. Therefore, a feature reasoning relational triple extraction method\nbased on table filling for technological patents is proposed to explore the\nintegration of entity recognition and entity relationship, and to extract\nentity relationship triples from multi-source scientific and technological\npatents data. Compared with the previous methods, the method we proposed for\nrelational triple extraction has the following advantages: 1) The table filling\nmethod that saves more running space enhances the speed and efficiency of the\nmodel. 2) Based on the features of existing token pairs and table relations,\nreasoning the implicit relationship features, and improve the accuracy of\ntriple extraction. On five benchmark datasets, we evaluated the model we\nsuggested. The result suggest that our model is advanced and effective, and it\nperformed well on most of these datasets.",
    "descriptor": "",
    "authors": [
      "Runze Fang",
      "Junping Du",
      "Yingxia Shao",
      "Zeli Guan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03291"
  },
  {
    "id": "arXiv:2210.03292",
    "title": "Unsupervised Semantic Representation Learning of Scientific Literature  Based on Graph Attention Mechanism and Maximum Mutual Information",
    "abstract": "Since most scientific literature data are unlabeled, this makes unsupervised\ngraph-based semantic representation learning crucial. Therefore, an\nunsupervised semantic representation learning method of scientific literature\nbased on graph attention mechanism and maximum mutual information (GAMMI) is\nproposed. By introducing a graph attention mechanism, the weighted summation of\nnearby node features make the weights of adjacent node features entirely depend\non the node features. Depending on the features of the nearby nodes, different\nweights can be applied to each node in the graph. Therefore, the correlations\nbetween vertex features can be better integrated into the model. In addition,\nan unsupervised graph contrastive learning strategy is proposed to solve the\nproblem of being unlabeled and scalable on large-scale graphs. By comparing the\nmutual information between the positive and negative local node representations\non the latent space and the global graph representation, the graph neural\nnetwork can capture both local and global information. Experimental results\ndemonstrate competitive performance on various node classification benchmarks,\nachieving good results and sometimes even surpassing the performance of\nsupervised learning.",
    "descriptor": "",
    "authors": [
      "Hongrui Gao",
      "Yawen Li",
      "Meiyu Liang",
      "Zeli Guan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03292"
  },
  {
    "id": "arXiv:2210.03293",
    "title": "PeF: Poisson's Equation Based Large-Scale Fixed-Outline Floorplanning",
    "abstract": "Floorplanning is the first stage of VLSI physical design. An effective\nfloorplanning engine definitely has positive impact on chip design speed,\nquality and performance. In this paper, we present a novel mathematical model\nto characterize non-overlapping of modules, and propose a flat fixed-outline\nfloorplanning algorithm based on the VLSI global placement approach using\nPoisson's equation. The algorithm consists of global floorplanning and\nlegalization phases. In global floorplanning, we redefine the potential energy\nof each module based on the novel mathematical model for characterizing\nnon-overlapping of modules and an analytical solution of Poisson's equation. In\nthis scheme, the widths of soft modules appear as variables in the energy\nfunction and can be optimized. Moreover, we design a fast approximate\ncomputation scheme for partial derivatives of the potential energy. In\nlegalization, based on the defined horizontal and vertical constraint graphs,\nwe eliminate overlaps between modules remained after global floorplanning, by\nmodifying relative positions of modules. Experiments on the MCNC, GSRC, HB+ and\nami49\\_x benchmarks show that, our algorithm improves the average wirelength by\nat least 2\\% and 5\\% on small and large scale benchmarks with certain\nwhitespace, respectively, compared to state-of-the-art floorplanners.",
    "descriptor": "",
    "authors": [
      "Ximeng Li",
      "Keyu Peng",
      "Fuxing Huang",
      "Wenxing Zhu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.03293"
  },
  {
    "id": "arXiv:2210.03294",
    "title": "Understanding Edge-of-Stability Training Dynamics with a Minimalist  Example",
    "abstract": "Recently, researchers observed that gradient descent for deep neural networks\noperates in an ``edge-of-stability'' (EoS) regime: the sharpness (maximum\neigenvalue of the Hessian) is often larger than stability threshold 2/$\\eta$\n(where $\\eta$ is the step size). Despite this, the loss oscillates and\nconverges in the long run, and the sharpness at the end is just slightly below\n$2/\\eta$. While many other well-understood nonconvex objectives such as matrix\nfactorization or two-layer networks can also converge despite large sharpness,\nthere is often a larger gap between sharpness of the endpoint and $2/\\eta$. In\nthis paper, we study EoS phenomenon by constructing a simple function that has\nthe same behavior. We give rigorous analysis for its training dynamics in a\nlarge local region and explain why the final converging point has sharpness\nclose to $2/\\eta$. Globally we observe that the training dynamics for our\nexample has an interesting bifurcating behavior, which was also observed in the\ntraining of neural nets.",
    "descriptor": "\nComments: 53 pages, 19 figures\n",
    "authors": [
      "Xingyu Zhu",
      "Zixuan Wang",
      "Xiang Wang",
      "Mo Zhou",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03294"
  },
  {
    "id": "arXiv:2210.03295",
    "title": "Scientific and Technological News Recommendation Based on Knowledge  Graph with User Perception",
    "abstract": "Existing research usually utilizes side information such as social network or\nitem attributes to improve the performance of collaborative filtering-based\nrecommender systems. In this paper, the knowledge graph with user perception is\nused to acquire the source of side information. We proposed KGUPN to address\nthe limitations of existing embedding-based and path-based knowledge\ngraph-aware recommendation methods, an end-to-end framework that integrates\nknowledge graph and user awareness into scientific and technological news\nrecommendation systems. KGUPN contains three main layers, which are the\npropagation representation layer, the contextual information layer and\ncollaborative relation layer. The propagation representation layer improves the\nrepresentation of an entity by recursively propagating embeddings from its\nneighbors (which can be users, news, or relationships) in the knowledge graph.\nThe contextual information layer improves the representation of entities by\nencoding the behavioral information of entities appearing in the news. The\ncollaborative relation layer complements the relationship between entities in\nthe news knowledge graph. Experimental results on real-world datasets show that\nKGUPN significantly outperforms state-of-the-art baselines in scientific and\ntechnological news recommendation.",
    "descriptor": "",
    "authors": [
      "Yuyao Zeng",
      "Junping Du",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03295"
  },
  {
    "id": "arXiv:2210.03296",
    "title": "GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of  Scene Flow",
    "abstract": "Scene flow is the collection of each point motion information in the 3D point\nclouds. It is a vital tool applied to many tasks, such as autonomous driving\nand augmented reality. However, there are always occlusion points between two\nconsecutive point clouds, whether from the sparsity data sampling or real-world\nocclusion. In this paper, we focus on addressing occlusion issues in scene flow\nby self-similarity and local consistency of moving objects. We propose a GMA3D\nmodule based on the transformer framework, which utilizes local and global\nsimilarity to infer the motion information of occluded points from the motion\ninformation of local and global non-occluded points respectively, and then uses\nan offset generator to aggregate them. Our module is the first to apply the\ntransformer-based architecture to gauge the scene flow occlusion problem on\npoint clouds. Experiments show that our GMA3D can solve the occlusion problem\nin the scene flow, especially in the real scene. We evaluate the proposed\nmethod on the occluded version datasets and get state-of-the-art results on the\nreal scene KITTI. To testify that GMA3D is still beneficial for non-occluded\nscene flow, we also conducted experiments on non-occluded version datasets and\nachieved state-of-the-art results on FlyThings3D and KITTI. The code is\navailable at https://github.com/O-VIGIA/GMA3D.",
    "descriptor": "\nComments: 8 pages, 4 figures, conference\n",
    "authors": [
      "Zhiyang Lu",
      "Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03296"
  },
  {
    "id": "arXiv:2210.03297",
    "title": "Preprocessors Matter! Realistic Decision-Based Attacks on Machine  Learning Systems",
    "abstract": "Decision-based adversarial attacks construct inputs that fool a\nmachine-learning model into making targeted mispredictions by making only\nhard-label queries. For the most part, these attacks have been applied directly\nto isolated neural network models. However, in practice, machine learning\nmodels are just a component of a much larger system. By adding just a single\npreprocessor in front of a classifier, we find that state-of-the-art\nquery-based attacks are as much as seven times less effective at attacking a\nprediction pipeline than attacking the machine learning model alone. Hence,\nattacks that are unaware of this invariance inevitably waste a large number of\nqueries to re-discover or overcome it. We, therefore, develop techniques to\nfirst reverse-engineer the preprocessor and then use this extracted information\nto attack the end-to-end system. Our extraction method requires only a few\nhundred queries to learn the preprocessors used by most publicly available\nmodel pipelines, and our preprocessor-aware attacks recover the same efficacy\nas just attacking the model alone. The code can be found at\nhttps://github.com/google-research/preprocessor-aware-black-box-attack.",
    "descriptor": "\nComments: Code can be found at this https URL\n",
    "authors": [
      "Chawin Sitawarin",
      "Florian Tram\u00e8r",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03297"
  },
  {
    "id": "arXiv:2210.03299",
    "title": "Topology-Preserving Segmentation Network",
    "abstract": "Medical image segmentation aims to automatically extract anatomical or\npathological structures in the human body. Most objects or regions of interest\nare of similar patterns. For example, the relative location and the relative\nsize of the lung and the kidney differ little among subjects. Incorporating\nthese morphology rules as prior knowledge into the segmentation model is\nbelieved to be an effective way to enhance the accuracy of the segmentation\nresults. Motivated by this, we propose in this work the Topology-Preserving\nSegmentation Network (TPSN) which can predict segmentation masks with the same\ntopology prescribed for specific tasks. TPSN is a deformation-based model that\nyields a deformation map through an encoder-decoder architecture to warp the\ntemplate masks into a target shape approximating the region to segment.\nComparing to the segmentation framework based on pixel-wise classification,\ndeformation-based segmentation models that warp a template to enclose the\nregions are more convenient to enforce geometric constraints. In our framework,\nwe carefully design the ReLU Jacobian regularization term to enforce the\nbijectivity of the deformation map. As such, the predicted mask by TPSN has the\nsame topology as that of the template prior mask.",
    "descriptor": "",
    "authors": [
      "Han Zhang",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03299"
  },
  {
    "id": "arXiv:2210.03300",
    "title": "Multi-Robot Localization and Target Tracking with Connectivity  Maintenance and Collision Avoidance",
    "abstract": "We study the problem that requires a team of robots to perform joint\nlocalization and target tracking task while ensuring team connectivity and\ncollision avoidance. The problem can be formalized as a nonlinear, non-convex\noptimization program, which is typically hard to solve. To this end, we design\na two-staged approach that utilizes a greedy algorithm to optimize the joint\nlocalization and target tracking performance and applies control barrier\nfunctions to ensure safety constraints, i.e., maintaining connectivity of the\nrobot team and preventing inter-robot collisions. Simulated Gazebo experiments\nverify the effectiveness of the proposed approach. We further compare our\ngreedy algorithm to a non-linear optimization solver and a random algorithm, in\nterms of the joint localization and tracking quality as well as the computation\ntime. The results demonstrate that our greedy algorithm achieves high task\nquality and runs efficiently.",
    "descriptor": "",
    "authors": [
      "Rahul Zahroof",
      "Jiazhen Liu",
      "Lifeng Zhou",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03300"
  },
  {
    "id": "arXiv:2210.03303",
    "title": "Data-driven Approach to Differentiating between Depression and Dementia  from Noisy Speech and Language Data",
    "abstract": "A significant number of studies apply acoustic and linguistic characteristics\nof human speech as prominent markers of dementia and depression. However,\nstudies on discriminating depression from dementia are rare. Co-morbid\ndepression is frequent in dementia and these clinical conditions share many\noverlapping symptoms, but the ability to distinguish between depression and\ndementia is essential as depression is often curable. In this work, we\ninvestigate the ability of clustering approaches in distinguishing between\ndepression and dementia from human speech. We introduce a novel aggregated\ndataset, which combines narrative speech data from multiple conditions, i.e.,\nAlzheimer's disease, mild cognitive impairment, healthy control, and\ndepression. We compare linear and non-linear clustering approaches and show\nthat non-linear clustering techniques distinguish better between distinct\ndisease clusters. Our interpretability analysis shows that the main\ndifferentiating symptoms between dementia and depression are acoustic\nabnormality, repetitiveness (or circularity) of speech, word finding\ndifficulty, coherence impairment, and differences in lexical complexity and\nrichness.",
    "descriptor": "\nComments: W-NUT at COLING 2022\n",
    "authors": [
      "Malikeh Ehghaghi",
      "Frank Rudzicz",
      "Jekaterina Novikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03303"
  },
  {
    "id": "arXiv:2210.03304",
    "title": "Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD  Coding",
    "abstract": "Automatic International Classification of Diseases (ICD) coding aims to\nassign multiple ICD codes to a medical note with average length of 3,000+\ntokens. This task is challenging due to a high-dimensional space of multi-label\nassignment (tens of thousands of ICD codes) and the long-tail challenge: only a\nfew codes (common diseases) are frequently assigned while most codes (rare\ndiseases) are infrequently assigned. This study addresses the long-tail\nchallenge by adapting a prompt-based fine-tuning technique with label\nsemantics, which has been shown to be effective under few-shot setting. To\nfurther enhance the performance in medical domain, we propose a\nknowledge-enhanced longformer by injecting three domain-specific knowledge:\nhierarchy, synonym, and abbreviation with additional pretraining using\ncontrastive learning. Experiments on MIMIC-III-full, a benchmark dataset of\ncode assignment, show that our proposed method outperforms previous\nstate-of-the-art method in 14.5% in marco F1 (from 10.3 to 11.8, P<0.001). To\nfurther test our model on few-shot setting, we created a new rare diseases\ncoding dataset, MIMIC-III-rare50, on which our model improves marco F1 from\n17.1 to 30.4 and micro F1 from 17.2 to 32.6 compared to previous method.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022, code will be available here: this https URL\n",
    "authors": [
      "Zhichao Yang",
      "Shufan Wang",
      "Bhanu Pratap Singh Rawat",
      "Avijit Mitra",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03304"
  },
  {
    "id": "arXiv:2210.03305",
    "title": "How Do Data Science Workers Communicate Intermediate Results?",
    "abstract": "Data science workers increasingly collaborate on large-scale projects before\ncommunicating insights to a broader audience in the form of visualization.\nWhile prior work has modeled how data science teams, oftentimes with distinct\nroles and work processes, communicate knowledge to outside stakeholders, we\nhave little knowledge of how data science workers communicate intermediately\nbefore delivering the final products. In this work, we contribute a nuanced\ndescription of the intermediate communication process within data science\nteams. By analyzing interview data with 8 self-identified data science workers,\nwe characterized the data science intermediate communication process with four\nfactors, including the types of audience, communication goals, shared\nartifacts, and mode of communication. We also identified overarching challenges\nin the current communication process. We also discussed design implications\nthat might inform better tools that facilitate intermediate communication\nwithin data science teams.",
    "descriptor": "\nComments: This paper was accepted for presentation as part of the eighth Symposium on Visualization in Data Science (VDS) at ACM KDD 2022 as well as IEEE VIS 2022. this http URL\n",
    "authors": [
      "Rock Yuren Pang",
      "Ruotong Wang",
      "Joely Nelson",
      "Leilani Battle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.03305"
  },
  {
    "id": "arXiv:2210.03308",
    "title": "Generative Augmented Flow Networks",
    "abstract": "The Generative Flow Network is a probabilistic framework where an agent\nlearns a stochastic policy for object generation, such that the probability of\ngenerating an object is proportional to a given reward function. Its\neffectiveness has been shown in discovering high-quality and diverse solutions,\ncompared to reward-maximizing reinforcement learning-based methods.\nNonetheless, GFlowNets only learn from rewards of the terminal states, which\ncan limit its applicability. Indeed, intermediate rewards play a critical role\nin learning, for example from intrinsic motivation to provide intermediate\nfeedback even in particularly challenging sparse reward tasks. Inspired by\nthis, we propose Generative Augmented Flow Networks (GAFlowNets), a novel\nlearning framework to incorporate intermediate rewards into GFlowNets. We\nspecify intermediate rewards by intrinsic motivation to tackle the exploration\nproblem in sparse reward environments. GAFlowNets can leverage edge-based and\nstate-based intrinsic rewards in a joint way to improve exploration. Based on\nextensive experiments on the GridWorld task, we demonstrate the effectiveness\nand efficiency of GAFlowNet in terms of convergence, performance, and diversity\nof solutions. We further show that GAFlowNet is scalable to a more complex and\nlarge-scale molecule generation domain, where it achieves consistent and\nsignificant performance improvement.",
    "descriptor": "",
    "authors": [
      "Ling Pan",
      "Dinghuai Zhang",
      "Aaron Courville",
      "Longbo Huang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03308"
  },
  {
    "id": "arXiv:2210.03310",
    "title": "Scaling Forward Gradient With Local Losses",
    "abstract": "Forward gradient learning computes a noisy directional gradient and is a\nbiologically plausible alternative to backprop for learning deep neural\nnetworks. However, the standard forward gradient algorithm, when applied\nnaively, suffers from high variance when the number of parameters to be learned\nis large. In this paper, we propose a series of architectural and algorithmic\nmodifications that together make forward gradient learning practical for\nstandard deep learning benchmark tasks. We show that it is possible to\nsubstantially reduce the variance of the forward gradient estimator by applying\nperturbations to activations rather than weights. We further improve the\nscalability of forward gradient by introducing a large number of local greedy\nloss functions, each of which involves only a small number of learnable\nparameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more\nsuitable for local learning. Our approach matches backprop on MNIST and\nCIFAR-10 and significantly outperforms previously proposed backprop-free\nalgorithms on ImageNet.",
    "descriptor": "\nComments: 30 pages, tech report\n",
    "authors": [
      "Mengye Ren",
      "Simon Kornblith",
      "Renjie Liao",
      "Geoffrey Hinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.03310"
  },
  {
    "id": "arXiv:2210.03312",
    "title": "Distillation-Resistant Watermarking for Model Protection in NLP",
    "abstract": "How can we protect the intellectual property of trained NLP models? Modern\nNLP models are prone to stealing by querying and distilling from their publicly\nexposed APIs. However, existing protection methods such as watermarking only\nwork for images but are not applicable to text. We propose\nDistillation-Resistant Watermarking (DRW), a novel technique to protect NLP\nmodels from being stolen via distillation. DRW protects a model by injecting\nwatermarks into the victim's prediction probability corresponding to a secret\nkey and is able to detect such a key by probing a suspect model. We prove that\na protected model still retains the original accuracy within a certain bound.\nWe evaluate DRW on a diverse set of NLP tasks including text classification,\npart-of-speech tagging, and named entity recognition. Experiments show that DRW\nprotects the original model and detects stealing suspects at 100% mean average\nprecision for all four tasks while the prior method fails on two.",
    "descriptor": "",
    "authors": [
      "Xuandong Zhao",
      "Lei Li",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03312"
  },
  {
    "id": "arXiv:2210.03314",
    "title": "Uniformly convex neural networks and non-stationary iterated network  Tikhonov (iNETT) method",
    "abstract": "We propose a non-stationary iterated network Tikhonov (iNETT) method for the\nsolution of ill-posed inverse problems. The iNETT employs deep neural networks\nto build a data-driven regularizer, and it avoids the difficult task of\nestimating the optimal regularization parameter. To achieve the theoretical\nconvergence of iNETT, we introduce uniformly convex neural networks to build\nthe data-driven regularizer. Rigorous theories and detailed algorithms are\nproposed for the construction of convex and uniformly convex neural networks.\nIn particular, given a general neural network architecture, we prescribe\nsufficient conditions to achieve a trained neural network which is\ncomponent-wise convex or uniformly convex; moreover, we provide concrete\nexamples of realizing convexity and uniform convexity in the modern U-net\narchitecture. With the tools of convex and uniformly convex neural networks,\nthe iNETT algorithm is developed and a rigorous convergence analysis is\nprovided. Lastly, we show applications of the iNETT algorithm in 2D\ncomputerized tomography, where numerical examples illustrate the efficacy of\nthe proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Davide Bianchi",
      "Guanghao Lai",
      "Wenbin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03314"
  },
  {
    "id": "arXiv:2210.03319",
    "title": "Robust Unsupervised Cross-Lingual Word Embedding using Domain Flow  Interpolation",
    "abstract": "This paper investigates an unsupervised approach towards deriving a\nuniversal, cross-lingual word embedding space, where words with similar\nsemantics from different languages are close to one another. Previous\nadversarial approaches have shown promising results in inducing cross-lingual\nword embedding without parallel data. However, the training stage shows\ninstability for distant language pairs. Instead of mapping the source language\nspace directly to the target language space, we propose to make use of a\nsequence of intermediate spaces for smooth bridging. Each intermediate space\nmay be conceived as a pseudo-language space and is introduced via simple linear\ninterpolation. This approach is modeled after domain flow in computer vision,\nbut with a modified objective function. Experiments on intrinsic Bilingual\nDictionary Induction tasks show that the proposed approach can improve the\nrobustness of adversarial models with comparable and even better precision.\nFurther experiments on the downstream task of Cross-Lingual Natural Language\nInference show that the proposed model achieves significant performance\nimprovement for distant language pairs in downstream tasks compared to\nstate-of-the-art adversarial and non-adversarial models.",
    "descriptor": "",
    "authors": [
      "Liping Tang",
      "Zhen Li",
      "Zhiquan Luo",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03319"
  },
  {
    "id": "arXiv:2210.03324",
    "title": "AutoML for Climate Change: A Call to Action",
    "abstract": "The challenge that climate change poses to humanity has spurred a rapidly\ndeveloping field of artificial intelligence research focused on climate change\napplications. The climate change AI (CCAI) community works on a diverse,\nchallenging set of problems which often involve physics-constrained ML or\nheterogeneous spatiotemporal data. It would be desirable to use automated\nmachine learning (AutoML) techniques to automatically find high-performing\narchitectures and hyperparameters for a given dataset. In this work, we\nbenchmark popular AutoML libraries on three high-leverage CCAI applications:\nclimate modeling, wind power forecasting, and catalyst discovery. We find that\nout-of-the-box AutoML libraries currently fail to meaningfully surpass the\nperformance of human-designed CCAI models. However, we also identify a few key\nweaknesses, which stem from the fact that most AutoML techniques are tailored\nto computer vision and NLP applications. For example, while dozens of search\nspaces have been designed for image and language data, none have been designed\nfor spatiotemporal data. Addressing these key weaknesses can lead to the\ndiscovery of novel architectures that yield substantial performance gains\nacross numerous CCAI applications. Therefore, we present a call to action to\nthe AutoML community, since there are a number of concrete, promising\ndirections for future work in the space of AutoML for CCAI. We release our code\nand a list of resources at\nhttps://github.com/climate-change-automl/climate-change-automl.",
    "descriptor": "",
    "authors": [
      "Renbo Tu",
      "Nicholas Roberts",
      "Vishak Prasad",
      "Sibasis Nayak",
      "Paarth Jain",
      "Frederic Sala",
      "Ganesh Ramakrishnan",
      "Ameet Talwalkar",
      "Willie Neiswanger",
      "Colin White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03324"
  },
  {
    "id": "arXiv:2210.03325",
    "title": "Elastic Step DQN: A novel multi-step algorithm to alleviate  overestimation in Deep QNetworks",
    "abstract": "Deep Q-Networks algorithm (DQN) was the first reinforcement learning\nalgorithm using deep neural network to successfully surpass human level\nperformance in a number of Atari learning environments. However, divergent and\nunstable behaviour have been long standing issues in DQNs. The unstable\nbehaviour is often characterised by overestimation in the $Q$-values, commonly\nreferred to as the overestimation bias. To address the overestimation bias and\nthe divergent behaviour, a number of heuristic extensions have been proposed.\nNotably, multi-step updates have been shown to drastically reduce unstable\nbehaviour while improving agent's training performance. However, agents are\noften highly sensitive to the selection of the multi-step update horizon ($n$),\nand our empirical experiments show that a poorly chosen static value for $n$\ncan in many cases lead to worse performance than single-step DQN. Inspired by\nthe success of $n$-step DQN and the effects that multi-step updates have on\noverestimation bias, this paper proposes a new algorithm that we call `Elastic\nStep DQN' (ES-DQN). It dynamically varies the step size horizon in multi-step\nupdates based on the similarity of states visited. Our empirical evaluation\nshows that ES-DQN out-performs $n$-step with fixed $n$ updates, Double DQN and\nAverage DQN in several OpenAI Gym environments while at the same time\nalleviating the overestimation bias.",
    "descriptor": "",
    "authors": [
      "Adrian Ly",
      "Richard Dazeley",
      "Peter Vamplew",
      "Francisco Cruz",
      "Sunil Aryal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03325"
  },
  {
    "id": "arXiv:2210.03327",
    "title": "Enumeration of spatial manipulators by using the concept of Adjacency  Matrix",
    "abstract": "This study is on the enumeration of spatial robotic manipulators, which is an\nessential basis for a companion study on dimensional synthesis, both of which\ntogether present a wider utility in manipulator synthesis. The enumeration of\nmanipulators is done by using adjacency matrix concept. In this paper, a novel\nway of applying adjacency matrix to spatial manipulators with four types of\njoints, namely revolute, prismatic, cylindrical and spherical joints, is\npresented. The limitations of the applicability of the concept to 3D\nmanipulators are discussed. 1-DOF (Degree Of Freedom) manipulators of four\nlinks and 2-DOF, 3-DOF and 4-DOF manipulators of three links, four links and\nfive links, are enumerated based on a set of conventions and some assumptions.\nFinally, 96 1-DOF manipulators of four links, 641 2-DOF manipulators of 5\nlinks, 4 2-DOF manipulators of three links, 8 3-DOF manipulators of four links\nand 15 4-DOF manipulators of five links are presented.",
    "descriptor": "",
    "authors": [
      "Akkarapakam Suneesh Jacob",
      "Bhaskar Dasgupta",
      "Rituparna Datta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03327"
  },
  {
    "id": "arXiv:2210.03329",
    "title": "Calibrating Factual Knowledge in Pretrained Language Models",
    "abstract": "Previous literature has proved that Pretrained Language Models (PLMs) can\nstore factual knowledge. However, we find that facts stored in the PLMs are not\nalways correct. It motivates us to explore a fundamental question: How do we\ncalibrate factual knowledge in PLMs without re-training from scratch? In this\nwork, we propose a simple and lightweight method CaliNet to achieve this goal.\nTo be specific, we first detect whether PLMs can learn the right facts via a\ncontrastive score between right and fake facts. If not, we then use a\nlightweight method to add and adapt new parameters to specific factual texts.\nExperiments on the knowledge probing task show the calibration effectiveness\nand efficiency. In addition, through closed-book question answering, we find\nthat the calibrated PLM possesses knowledge generalization ability after\nfine-tuning. Beyond the calibration performance, we further investigate and\nvisualize the knowledge calibration mechanism.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Qingxiu Dong",
      "Damai Dai",
      "Yifan Song",
      "Jingjing Xu",
      "Zhifang Sui",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03329"
  },
  {
    "id": "arXiv:2210.03331",
    "title": "Resolving Class Imbalance for LiDAR-based Object Detector by Dynamic  Weight Average and Contextual Ground Truth Sampling",
    "abstract": "An autonomous driving system requires a 3D object detector, which must\nperceive all present road agents reliably to navigate an environment safely.\nHowever, real-world driving datasets often suffer from the problem of data\nimbalance, which causes difficulties in training a model that works well across\nall classes, resulting in an undesired imbalanced sub-optimal performance. In\nthis work, we propose a method to address this data imbalance problem. Our\nmethod consists of two main components: (i) a LiDAR-based 3D object detector\nwith per-class multiple detection heads where losses from each head are\nmodified by dynamic weight average to be balanced. (ii) Contextual ground truth\n(GT) sampling, where we improve conventional GT sampling techniques by\nleveraging semantic information to augment point cloud with sampled ground\ntruth GT objects. Our experiment with KITTI and nuScenes datasets confirms our\nproposed method's effectiveness in dealing with the data imbalance problem,\nproducing better detection accuracy compared to existing approaches.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Daeun Lee",
      "Jongwon Park",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03331"
  },
  {
    "id": "arXiv:2210.03332",
    "title": "Explainable AI based Glaucoma Detection using Transfer Learning and LIME",
    "abstract": "Glaucoma is the second driving reason for partial or complete blindness among\nall the visual deficiencies which mainly occurs because of excessive pressure\nin the eye due to anxiety or depression which damages the optic nerve and\ncreates complications in vision. Traditional glaucoma screening is a\ntime-consuming process that necessitates the medical professionals' constant\nattention, and even so time to time due to the time constrains and pressure\nthey fail to classify correctly that leads to wrong treatment. Numerous efforts\nhave been made to automate the entire glaucoma classification procedure\nhowever, these existing models in general have a black box characteristics that\nprevents users from understanding the key reasons behind the prediction and\nthus medical practitioners generally can not rely on these system. In this\narticle after comparing with various pre-trained models, we propose a transfer\nlearning model that is able to classify Glaucoma with 94.71\\% accuracy. In\naddition, we have utilized Local Interpretable Model-Agnostic\nExplanations(LIME) that introduces explainability in our system. This\nimprovement enables medical professionals obtain important and comprehensive\ninformation that aid them in making judgments. It also lessen the opacity and\nfragility of the traditional deep learning models.",
    "descriptor": "",
    "authors": [
      "Touhidul Islam Chayan",
      "Anita Islam",
      "Eftykhar Rahman",
      "Md. Tanzim Reza",
      "Tasnim Sakib Apon",
      "MD. Golam Rabiul Alam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03332"
  },
  {
    "id": "arXiv:2210.03335",
    "title": "A Keypoint Based Enhancement Method for Audio Driven Free View Talking  Head Synthesis",
    "abstract": "Audio driven talking head synthesis is a challenging task that attracts\nincreasing attention in recent years. Although existing methods based on 2D\nlandmarks or 3D face models can synthesize accurate lip synchronization and\nrhythmic head pose for arbitrary identity, they still have limitations, such as\nthe cut feeling in the mouth mapping and the lack of skin highlights. The\nmorphed region is blurry compared to the surrounding face. A Keypoint Based\nEnhancement (KPBE) method is proposed for audio driven free view talking head\nsynthesis to improve the naturalness of the generated video. Firstly, existing\nmethods were used as the backend to synthesize intermediate results. Then we\nused keypoint decomposition to extract video synthesis controlling parameters\nfrom the backend output and the source image. After that, the controlling\nparameters were composited to the source keypoints and the driving keypoints. A\nmotion field based method was used to generate the final image from the\nkeypoint representation. With keypoint representation, we overcame the cut\nfeeling in the mouth mapping and the lack of skin highlights. Experiments show\nthat our proposed enhancement method improved the quality of talking-head\nvideos in terms of mean opinion score.",
    "descriptor": "",
    "authors": [
      "Yichen Han",
      "Ya Li",
      "Yingming Gao",
      "Jinlong Xue",
      "Songpo Wang",
      "Lei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03335"
  },
  {
    "id": "arXiv:2210.03337",
    "title": "A Unified Framework for Multi-intent Spoken Language Understanding with  prompting",
    "abstract": "Multi-intent Spoken Language Understanding has great potential for widespread\nimplementation. Jointly modeling Intent Detection and Slot Filling in it\nprovides a channel to exploit the correlation between intents and slots.\nHowever, current approaches are apt to formulate these two sub-tasks\ndifferently, which leads to two issues: 1) It hinders models from effective\nextraction of shared features. 2) Pretty complicated structures are involved to\nenhance expression ability while causing damage to the interpretability of\nframeworks. In this work, we describe a Prompt-based Spoken Language\nUnderstanding (PromptSLU) framework, to intuitively unify two sub-tasks into\nthe same form by offering a common pre-trained Seq2Seq model. In detail, ID and\nSF are completed by concisely filling the utterance into task-specific prompt\ntemplates as input, and sharing output formats of key-value pairs sequence.\nFurthermore, variable intents are predicted first, then naturally embedded into\nprompts to guide slot-value pairs inference from a semantic perspective.\nFinally, we are inspired by prevalent multi-task learning to introduce an\nauxiliary sub-task, which helps to learn relationships among provided labels.\nExperiment results show that our framework outperforms several state-of-the-art\nbaselines on two public datasets.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Feifan Song",
      "Lianzhe Huang",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03337"
  },
  {
    "id": "arXiv:2210.03338",
    "title": "On Routing Optimization in Networks with Embedded Computational Services",
    "abstract": "Modern communication networks are increasingly equipped with in-network\ncomputational capabilities and services. Routing in such networks is\nsignificantly more complicated than the traditional routing. A legitimate route\nfor a flow not only needs to have enough communication and computation\nresources, but also has to conform to various application-specific routing\nconstraints. This paper presents a comprehensive study on routing optimization\nproblems in networks with embedded computational services. We develop a set of\nrouting optimization models and derive low-complexity heuristic routing\nalgorithms for diverse computation scenarios. For dynamic demands, we also\ndevelop an online routing algorithm with performance guarantees. Through\nevaluations over emerging applications on real topologies, we demonstrate that\nour models can be flexibly customized to meet the diverse routing requirements\nof different computation applications. Our proposed heuristic algorithms\nsignificantly outperform baseline algorithms and can achieve close-to-optimal\nperformance in various scenarios.",
    "descriptor": "\nComments: 16 figures\n",
    "authors": [
      "Lifan Mei",
      "Jinrui Gou",
      "Jingrui Yang",
      "Yujin Cai",
      "Yong Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03338"
  },
  {
    "id": "arXiv:2210.03339",
    "title": "Dual Clustering Co-teaching with Consistent Sample Mining for  Unsupervised Person Re-Identification",
    "abstract": "In unsupervised person Re-ID, peer-teaching strategy leveraging two networks\nto facilitate training has been proven to be an effective method to deal with\nthe pseudo label noise. However, training two networks with a set of noisy\npseudo labels reduces the complementarity of the two networks and results in\nlabel noise accumulation. To handle this issue, this paper proposes a novel\nDual Clustering Co-teaching (DCCT) approach. DCCT mainly exploits the features\nextracted by two networks to generate two sets of pseudo labels separately by\nclustering with different parameters. Each network is trained with the pseudo\nlabels generated by its peer network, which can increase the complementarity of\nthe two networks to reduce the impact of noises. Furthermore, we propose dual\nclustering with dynamic parameters (DCDP) to make the network adaptive and\nrobust to dynamically changing clustering parameters. Moreover, Consistent\nSample Mining (CSM) is proposed to find the samples with unchanged pseudo\nlabels during training for potential noisy sample removal. Extensive\nexperiments demonstrate the effectiveness of the proposed method, which\noutperforms the state-of-the-art unsupervised person Re-ID methods by a\nconsiderable margin and surpasses most methods utilizing camera information.",
    "descriptor": "",
    "authors": [
      "Zeqi Chen",
      "Zhichao Cui",
      "Chi Zhang",
      "Jiahuan Zhou",
      "Yuehu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03339"
  },
  {
    "id": "arXiv:2210.03340",
    "title": "A Novel Graph-based Motion Planner of Multi-Mobile Robot Systems with  Formation and Obstacle Constraints",
    "abstract": "Multi-mobile robot systems show great advantages over one single robot in\nmany applications. However, the robots are required to form desired\ntask-specified formations, making feasible motions decrease significantly.\nThus, it is challenging to determine whether the robots can pass through an\nobstructed environment under formation constraints, especially in an\nobstacle-rich environment. Furthermore, is there an optimal path for the\nrobots? To deal with the two problems, a novel graphbased motion planner is\nproposed in this paper. A mapping between workspace and configuration space of\nmulti-mobile robot systems is first built, where valid configurations can be\nacquired to satisfy both formation constraints and collision avoidance. Then,\nan undirected graph is generated by verifying connectivity between valid\nconfigurations. The breadth-first search method is employed to answer the\nquestion of whether there is a feasible path on the graph. Finally, an optimal\npath will be planned on the updated graph, considering the cost of path length\nand formation preference. Simulation results show that the planner can be\napplied to get optimal motions of robots under formation constraints in\nobstacle-rich environments. Additionally, different constraints are considered.",
    "descriptor": "",
    "authors": [
      "Wenhang Liu",
      "Jiawei Hu",
      "Heng Zhang",
      "Michael Yu Wang",
      "Zhenhua Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03340"
  },
  {
    "id": "arXiv:2210.03343",
    "title": "Boolean symmetric vs. functional PCSP dichotomy",
    "abstract": "Given a 3-uniform hypergraph $(V,E)$ that is promised to admit a\n$\\{0,1\\}$-colouring such that every edge contains exactly one $1$, can one find\na $d$-colouring $h:V\\to \\{0,1,\\ldots,d-1\\}$ such that $h(e)\\in R$ for every\n$e\\in E$? This can be cast as a promise constraint satisfaction problem (PCSP)\nof the form $\\operatorname{PCSP}(1-in-3,\\mathbf{B})$, where $\\mathbf{B}$\ndefines the relation $R$, and is an example of\n$\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})$, where $\\mathbf{A}$ (and thus wlog\nalso $\\mathbf{B}$) is symmetric. The computational complexity of such problems\nis understood for $\\mathbf{A}$ and $\\mathbf{B}$ on Boolean domains by the work\nof Ficak, Kozik, Ol\\v{s}\\'{a}k, and Stankiewicz [ICALP'19].\nAs our first result, we establish a dichotomy for\n$\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})$, where $\\mathbf{A}$ is Boolean and\nsymmetric and $\\mathbf{B}$ is functional (on a domain of any size); i.e, all\nbut one element of any tuple in a relation in $\\mathbf{B}$ determine the last\nelement. This includes PCSPs of the form\n$\\operatorname{PCSP}(q-in-r,\\mathbf{B})$, where $\\mathbf{B}$ is functional,\nthus making progress towards a classification of\n$\\operatorname{PCSP}(1-in-3,\\mathbf{B})$, which were studied by Barto,\nBattistelli, and Berg [STACS'21] for $\\mathbf{B}$ on three-element domains.\nAs our second result, we show that for\n$\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})$, where $\\mathbf{A}$ contains a\nsingle Boolean symmetric relation and $\\mathbf{B}$ is arbitrary (and thus not\nnecessarily functional), the combined basic linear programmin relaxation (BLP)\nand the affine integer programming relaxation (AIP) of Brakensiek et al.\n[SICOMP'20] is no more powerful than the (in general strictly weaker) AIP\nrelaxation of Brakensiek and Guruswami [SICOMP'21].",
    "descriptor": "",
    "authors": [
      "Tamio-Vesa Nakajima",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03343"
  },
  {
    "id": "arXiv:2210.03345",
    "title": "Hierarchical Codebook-based Beam Training for Extremely Large-Scale  Massive MIMO",
    "abstract": "Extremely large-scale multiple-input multiple-output (XL-MIMO) promises to\nprovide ultrahigh data rates in millimeter-wave (mmWave) and Terahertz (THz)\nspectrum. However, the spherical-wavefront wireless transmission caused by\nlarge aperture array presents huge challenges for channel state information\n(CSI) acquisition and beamforming. Two independent parameters (physical angles\nand transmission distance) should be simultaneously considered in XL-MIMO\nbeamforming, which brings severe overhead consumption and beamforming\ndegradation. To address this problem, we exploit the near-field channel\ncharacteristic and propose two low-overhead hierarchical beam training schemes\nfor near-field XL-MIMO system. Firstly, we project near-field channel into\nspatial-angular domain and slope-intercept domain to capture detailed\nrepresentations. Then we point out three critical criteria for XL-MIMO\nhierarchical beam training. Secondly, a novel spatial-chirp beam-aided codebook\nand corresponding hierarchical update policy are proposed. Thirdly, given the\nimperfect coverage and overlapping of spatial-chirp beams, we further design an\nenhanced hierarchical training codebook via manifold optimization and\nalternative minimization. Theoretical analyses and numerical simulations are\nalso displayed to verify the superior performances on beamforming and training\noverhead.",
    "descriptor": "\nComments: This work has been submitted to the IEEE journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Xu Shi",
      "Jintao Wang",
      "Zhi Sun",
      "Jian Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03345"
  },
  {
    "id": "arXiv:2210.03347",
    "title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language  Understanding",
    "abstract": "Visually-situated language is ubiquitous -- sources range from textbooks with\ndiagrams to web pages with images and tables, to mobile apps with buttons and\nforms. Perhaps due to this diversity, previous work has typically relied on\ndomain-specific recipes with limited sharing of the underlying data, model\narchitectures, and objectives. We present Pix2Struct, a pretrained\nimage-to-text model for purely visual language understanding, which can be\nfinetuned on tasks containing visually-situated language. Pix2Struct is\npretrained by learning to parse masked screenshots of web pages into simplified\nHTML. The web, with its richness of visual elements cleanly reflected in the\nHTML structure, provides a large source of pretraining data well suited to the\ndiversity of downstream tasks. Intuitively, this objective subsumes common\npretraining signals such as OCR, language modeling, image captioning. In\naddition to the novel pretraining strategy, we introduce a variable-resolution\ninput representation and a more flexible integration of language and vision\ninputs, where language prompts such as questions are rendered directly on top\nof the input image. For the first time, we show that a single pretrained model\ncan achieve state-of-the-art results in six out of nine tasks across four\ndomains: documents, illustrations, user interfaces, and natural images.",
    "descriptor": "",
    "authors": [
      "Kenton Lee",
      "Mandar Joshi",
      "Iulia Turc",
      "Hexiang Hu",
      "Fangyu Liu",
      "Julian Eisenschlos",
      "Urvashi Khandelwal",
      "Peter Shaw",
      "Ming-Wei Chang",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03347"
  },
  {
    "id": "arXiv:2210.03349",
    "title": "Game-Theoretic Understanding of Misclassification",
    "abstract": "This paper analyzes various types of image misclassification from a\ngame-theoretic view. Particularly, we consider the misclassification of clean,\nadversarial, and corrupted images and characterize it through the distribution\nof multi-order interactions. We discover that the distribution of multi-order\ninteractions varies across the types of misclassification. For example,\nmisclassified adversarial images have a higher strength of high-order\ninteractions than correctly classified clean images, which indicates that\nadversarial perturbations create spurious features that arise from complex\ncooperation between pixels. By contrast, misclassified corrupted images have a\nlower strength of low-order interactions than correctly classified clean\nimages, which indicates that corruptions break the local cooperation between\npixels. We also provide the first analysis of Vision Transformers using\ninteractions. We found that Vision Transformers show a different tendency in\nthe distribution of interactions from that in CNNs, and this implies that they\nexploit the features that CNNs do not use for the prediction. Our study\ndemonstrates that the recent game-theoretic analysis of deep learning models\ncan be broadened to analyze various malfunctions of deep learning models\nincluding Vision Transformers by using the distribution, order, and sign of\ninteractions.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Kosuke Sumiyasu",
      "Kazuhiko Kawamoto",
      "Hiroshi Kera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03349"
  },
  {
    "id": "arXiv:2210.03350",
    "title": "Measuring and Narrowing the Compositionality Gap in Language Models",
    "abstract": "We investigate the ability of language models to perform compositional\nreasoning tasks where the overall solution depends on correctly composing the\nanswers to sub-problems. We measure how often models can correctly answer all\nsub-problems but not generate the overall solution, a ratio we call the\ncompositionality gap. We evaluate this ratio by asking multi-hop questions with\nanswers that require composing multiple facts unlikely to have been observed\ntogether during pretraining. In the GPT-3 family of models, as model size\nincreases we show that the single-hop question answering performance improves\nfaster than the multi-hop performance does, therefore the compositionality gap\ndoes not decrease. This surprising result suggests that while more powerful\nmodels memorize and recall more factual knowledge, they show no corresponding\nimprovement in their ability to perform this kind of compositional reasoning.\nWe then demonstrate how elicitive prompting (such as chain of thought)\nnarrows the compositionality gap by reasoning explicitly instead of implicitly.\nWe present a new method, self-ask, that further improves on chain of thought.\nIn our method, the model explicitly asks itself (and then answers) follow-up\nquestions before answering the initial question. We finally show that\nself-ask's structured prompting lets us easily plug in a search engine to\nanswer the follow-up questions, which additionally improves accuracy.",
    "descriptor": "",
    "authors": [
      "Ofir Press",
      "Muru Zhang",
      "Sewon Min",
      "Ludwig Schmidt",
      "Noah A. Smith",
      "Mike Lewis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03350"
  },
  {
    "id": "arXiv:2210.03352",
    "title": "The Ethical Risks of Analyzing Crisis Events on Social Media with  Machine Learning",
    "abstract": "Social media platforms provide a continuous stream of real-time news\nregarding crisis events on a global scale. Several machine learning methods\nutilize the crowd-sourced data for the automated detection of crises and the\ncharacterization of their precursors and aftermaths. Early detection and\nlocalization of crisis-related events can help save lives and economies. Yet,\nthe applied automation methods introduce ethical risks worthy of investigation\n- especially given their high-stakes societal context. This work identifies and\ncritically examines ethical risk factors of social media analyses of crisis\nevents focusing on machine learning methods. We aim to sensitize researchers\nand practitioners to the ethical pitfalls and promote fairer and more reliable\ndesigns.",
    "descriptor": "\nComments: Accepted to D2R2'22: International Workshop on Data-driven Resilience Research\n",
    "authors": [
      "Angelie Kraft",
      "Ricardo Usbeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03352"
  },
  {
    "id": "arXiv:2210.03353",
    "title": "The Lifecycle of \"Facts\": A Survey of Social Bias in Knowledge Graphs",
    "abstract": "Knowledge graphs are increasingly used in a plethora of downstream tasks or\nin the augmentation of statistical models to improve factuality. However,\nsocial biases are engraved in these representations and propagate downstream.\nWe conducted a critical analysis of literature concerning biases at different\nsteps of a knowledge graph lifecycle. We investigated factors introducing bias,\nas well as the biases that are rendered by knowledge graphs and their embedded\nversions afterward. Limitations of existing measurement and mitigation\nstrategies are discussed and paths forward are proposed.",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Angelie Kraft",
      "Ricardo Usbeck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03353"
  },
  {
    "id": "arXiv:2210.03355",
    "title": "Multiple Object Tracking from appearance by hierarchically clustering  tracklets",
    "abstract": "Current approaches in Multiple Object Tracking (MOT) rely on the\nspatio-temporal coherence between detections combined with object appearance to\nmatch objects from consecutive frames. In this work, we explore MOT using\nobject appearances as the main source of association between objects in a\nvideo, using spatial and temporal priors as weighting factors. We form initial\ntracklets by leveraging on the idea that instances of an object that are close\nin time should be similar in appearance, and build the final object tracks by\nfusing the tracklets in a hierarchical fashion. We conduct extensive\nexperiments that show the effectiveness of our method over three different MOT\nbenchmarks, MOT17, MOT20, and DanceTrack, being competitive in MOT17 and MOT20\nand establishing state-of-the-art results in DanceTrack.",
    "descriptor": "\nComments: To be published in BMVC 2022\n",
    "authors": [
      "Andreu Girbau",
      "Ferran Marqu\u00e9s",
      "Shin'ichi Satoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03355"
  },
  {
    "id": "arXiv:2210.03356",
    "title": "Two Iterative algorithms for the matrix sign function based on the  adaptive filtering technology",
    "abstract": "In this paper, two new efficient algorithms for calculating the sign function\nof the large-scale sparse matrix are proposed by combining filtering algorithm\nwith Newton method and Newton Schultz method respectively. Through the\ntheoretical analysis of the error diffusion in the iterative process, we\ndesigned an adaptive filtering threshold, which can ensure that the filtering\nhas little impact on the iterative process and the calculation result.\nNumerical experiments are consistent with our theoretical analysis, which shows\nthat the computational efficiency of our method is much better than that of\nNewton method and Newton Schultz method, and the computational error is of the\nsame order of magnitude as that of the two methods.",
    "descriptor": "\nComments: 18 pages,12 figures\n",
    "authors": [
      "Feng Wu",
      "Keqi Ye",
      "Li Zhu",
      "Yueling Zhao",
      "Jiqiang Hu",
      "Wanxie Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03356"
  },
  {
    "id": "arXiv:2210.03360",
    "title": "The PerspectiveLiberator -- an upmixing 6DoF rendering plugin for  single-perspective Ambisonic room impulse responses",
    "abstract": "Nowadays, virtual reality interfaces allow the user to change perspectives in\nsix degrees of freedom (6DoF) virtually, and consistently with the visual part,\nthe acoustic perspective needs to be updated interactively. Single-perspective\nrendering with dynamic head rotation already works quite reliably with upmixed\nfirst-order Ambisonic room impulse responses (ASDM, SIRR, etc.). This\ncontribution presents a plugin to free the virtual perspective from the\nmeasured one by real-time perspective extrapolation: The PerspectiveLiberator.\nThe plugin permits selecting between two different algorithms for directional\nresolution enhancement (ASDM, 4DE). And for its main task of convolution-based\n6DoF rendering, the plugin detects and localizes prominent directional sound\nevents in the early Ambisonic room impulse response and re-encodes them with\ndirection, time of arrival, and level adapted to the variable perspective of\nthe virtual listener. The diffuse residual is enhanced in directional\nresolution but remains unaffected by translatory movement to preserve as much\nof the original room impression as possible.",
    "descriptor": "\nComments: 4 pages, submitted to conference: DAGA 2021, Vienna, Austria, 2021\n",
    "authors": [
      "Kaspar M\u00fcller",
      "Franz Zotter"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03360"
  },
  {
    "id": "arXiv:2210.03363",
    "title": "Model-based estimation of in-car-communication feedback applied to  speech zone detection",
    "abstract": "Modern cars provide versatile tools to enhance speech communication. While an\nin-car communication (ICC) system aims at enhancing communication between the\npassengers by playing back desired speech via loudspeakers in the car, these\nloudspeaker signals may disturb a speech enhancement system required for\nhands-free telephony and automatic speech recognition. In this paper, we focus\non speech zone detection, i.e. detecting which passenger in the car is\nspeaking, which is a crucial component of the speech enhancement system. We\npropose a model-based feedback estimation method to improve robustness of\nspeech zone detection against ICC feedback. Specifically, since the zone\ndetection system typically does not have access to the ICC loudspeaker signals,\nthe proposed method estimates the feedback signal from the observed microphone\nsignals based on a free-field propagation model between the loudspeakers and\nthe microphones as well as the ICC gain. We propose an efficient recursive\nimplementation in the short-time Fourier transform domain using convolutive\ntransfer functions. A realistic simulation study indicates that the proposed\nmethod allows to increase the ICC gain by about 6dB while still achieving\nrobust speech zone detection results.",
    "descriptor": "\nComments: 5 pages, submitted to International Workshop on Acoustic Signal Enhancement (IWAENC), Bamberg, Germany, 2022\n",
    "authors": [
      "Kaspar M\u00fcller",
      "Simon Doclo",
      "Jan \u00d8stergaard",
      "Tobias Wolff"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03363"
  },
  {
    "id": "arXiv:2210.03368",
    "title": "Decentralized event-triggered estimation of nonlinear systems",
    "abstract": "We investigate the scenario where a perturbed nonlinear system transmits its\noutput measurements to a remote observer via a packet-based communication\nnetwork. The sensors are grouped into N nodes and each of these nodes decides\nwhen its measured data is transmitted over the network independently. The\nobjective is to design both the observer and the local transmission policies in\norder to obtain accurate state estimates, while only sporadically using the\ncommunication network. In particular, given a general nonlinear observer\ndesigned in continuous-time satisfying an input-to-state stability property, we\nexplain how to systematically design a dynamic event-triggering rule for each\nsensor node that avoids the use of a copy of the observer, thereby keeping\nlocal calculation simple. We prove the practical convergence property of the\nestimation error to the origin and we show that there exists a uniform strictly\npositive minimum inter-event time for each local triggering rule under mild\nconditions on the plant. The efficiency of the proposed techniques is\nillustrated on a numerical case study of a flexible robotic arm.",
    "descriptor": "",
    "authors": [
      "E. Petri",
      "R. Postoyan",
      "D. Astolfi",
      "D. Ne\u0161i\u0107",
      "W.P.M.H. Heemels"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03368"
  },
  {
    "id": "arXiv:2210.03370",
    "title": "GNM: A General Navigation Model to Drive Any Robot",
    "abstract": "Learning provides a powerful tool for vision-based navigation, but the\ncapabilities of learning-based policies are constrained by limited training\ndata. If we could combine data from all available sources, including multiple\nkinds of robots, we could train more powerful navigation models. In this paper,\nwe study how a general goal-conditioned model for vision-based navigation can\nbe trained on data obtained from many distinct but structurally similar robots,\nand enable broad generalization across environments and embodiments. We analyze\nthe necessary design decisions for effective data sharing across robots,\nincluding the use of temporal context and standardized action spaces, and\ndemonstrate that an omnipolicy trained from heterogeneous datasets outperforms\npolicies trained on any single dataset. We curate 60 hours of navigation\ntrajectories from 6 distinct robots, and deploy the trained GNM on a range of\nnew robots, including an underactuated quadrotor. We find that training on\ndiverse data leads to robustness against degradation in sensing and actuation.\nUsing a pre-trained navigation model with broad generalization capabilities can\nbootstrap applications on novel robots going forward, and we hope that the GNM\nrepresents a step in that direction. For more information on the datasets,\ncode, and videos, please check out\nthis http URL",
    "descriptor": "",
    "authors": [
      "Dhruv Shah",
      "Ajay Sridhar",
      "Arjun Bhorkar",
      "Noriaki Hirose",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03370"
  },
  {
    "id": "arXiv:2210.03372",
    "title": "Pre-trained Adversarial Perturbations",
    "abstract": "Self-supervised pre-training has drawn increasing attention in recent years\ndue to its superior performance on numerous downstream tasks after fine-tuning.\nHowever, it is well-known that deep learning models lack the robustness to\nadversarial examples, which can also invoke security issues to pre-trained\nmodels, despite being less explored. In this paper, we delve into the\nrobustness of pre-trained models by introducing Pre-trained Adversarial\nPerturbations (PAPs), which are universal perturbations crafted for the\npre-trained models to maintain the effectiveness when attacking fine-tuned ones\nwithout any knowledge of the downstream tasks. To this end, we propose a\nLow-Level Layer Lifting Attack (L4A) method to generate effective PAPs by\nlifting the neuron activations of low-level layers of the pre-trained models.\nEquipped with an enhanced noise augmentation strategy, L4A is effective at\ngenerating more transferable PAPs against fine-tuned models. Extensive\nexperiments on typical pre-trained vision models and ten downstream tasks\ndemonstrate that our method improves the attack success rate by a large margin\ncompared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yuanhao Ban",
      "Yinpeng Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03372"
  },
  {
    "id": "arXiv:2210.03378",
    "title": "UU-Tax at SemEval-2022 Task 3: Improving the generalizability of  language models for taxonomy classification through data augmentation",
    "abstract": "This paper presents our strategy to address the SemEval-2022 Task 3 PreTENS:\nPresupposed Taxonomies Evaluating Neural Network Semantics. The goal of the\ntask is to identify if a sentence is deemed acceptable or not, depending on the\ntaxonomic relationship that holds between a noun pair contained in the\nsentence. For sub-task 1 -- binary classification -- we propose an effective\nway to enhance the robustness and the generalizability of language models for\nbetter classification on this downstream task. We design a two-stage\nfine-tuning procedure on the ELECTRA language model using data augmentation\ntechniques. Rigorous experiments are carried out using multi-task learning and\ndata-enriched fine-tuning. Experimental results demonstrate that our proposed\nmodel, UU-Tax, is indeed able to generalize well for our downstream task. For\nsub-task 2 -- regression -- we propose a simple classifier that trains on\nfeatures obtained from Universal Sentence Encoder (USE). In addition to\ndescribing the submitted systems, we discuss other experiments that employ\npre-trained language models and data augmentation techniques. For both\nsub-tasks, we perform error analysis to further understand the behaviour of the\nproposed models. We achieved a global F1_Binary score of 91.25% in sub-task 1\nand a rho score of 0.221 in sub-task 2.",
    "descriptor": "",
    "authors": [
      "Injy Sarhan",
      "Pablo Mosteiro",
      "Marco Spruit"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03378"
  },
  {
    "id": "arXiv:2210.03380",
    "title": "Zero-shot stance detection based on cross-domain feature enhancement by  contrastive learning",
    "abstract": "Zero-shot stance detection is challenging because it requires detecting the\nstance of previously unseen targets in the inference phase. The ability to\nlearn transferable target-invariant features is critical for zero-shot stance\ndetection. In this work, we propose a stance detection approach that can\nefficiently adapt to unseen targets, the core of which is to capture\ntarget-invariant syntactic expression patterns as transferable knowledge.\nSpecifically, we first augment the data by masking the topic words of\nsentences, and then feed the augmented data to an unsupervised contrastive\nlearning module to capture transferable features. Then, to fit a specific\ntarget, we encode the raw texts as target-specific features. Finally, we adopt\nan attention mechanism, which combines syntactic expression patterns with\ntarget-specific features to obtain enhanced features for predicting previously\nunseen targets. Experiments demonstrate that our model outperforms competitive\nbaselines on four benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Xuechen Zhao",
      "Jiaying Zou",
      "Zhong Zhang",
      "Feng Xie",
      "Bin Zhou",
      "Lei Tian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03380"
  },
  {
    "id": "arXiv:2210.03382",
    "title": "Temporal Feature Alignment in Contrastive Self-Supervised Learning for  Human Activity Recognition",
    "abstract": "Automated Human Activity Recognition has long been a problem of great\ninterest in human-centered and ubiquitous computing. In the last years, a\nplethora of supervised learning algorithms based on deep neural networks has\nbeen suggested to address this problem using various modalities. While every\nmodality has its own limitations, there is one common challenge. Namely,\nsupervised learning requires vast amounts of annotated data which is\npractically hard to collect. In this paper, we benefit from the self-supervised\nlearning paradigm (SSL) that is typically used to learn deep feature\nrepresentations from unlabeled data. Moreover, we upgrade a contrastive SSL\nframework, namely SimCLR, widely used in various applications by introducing a\ntemporal feature alignment procedure for Human Activity Recognition.\nSpecifically, we propose integrating a dynamic time warping (DTW) algorithm in\na latent space to force features to be aligned in a temporal dimension.\nExtensive experiments have been conducted for the unimodal scenario with\ninertial modality as well as in multimodal settings using inertial and skeleton\ndata. According to the obtained results, the proposed approach has a great\npotential in learning robust feature representations compared to the recent SSL\nbaselines, and clearly outperforms supervised models in semi-supervised\nlearning. The code for the unimodal case is available via the following link:\nhttps://github.com/bulatkh/csshar_tfa.",
    "descriptor": "\nComments: Accepted to IJCB 2022\n",
    "authors": [
      "Bulat Khaertdinov",
      "Stylianos Asteriadis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.03382"
  },
  {
    "id": "arXiv:2210.03388",
    "title": "Towards Automatic Model Completion: from Requirements to SysML State  Machines",
    "abstract": "Even if model-driven techniques have been enabled the centrality of the\nmodels in automated development processes, the majority of the industrial\nsettings does not embrace such a paradigm due to the procedural complexity of\nmanaging model life cycle. This paper proposes a semi-automatic approach for\nthe completion of high-level models of critical systems. The proposal suggests\na specification guidelines that starts from a partial SysML (Systems Modeling\nLanguage) model of a system and on a set of requirements, expressed in the\nwell-known Behaviour-Driven Design paradigm. On the base of such requirements,\nthe approach enables the automatic generation of SysML state machines\nfragments. Once completed, the approach also enables the modeller to check the\nresults improving the quality of the model and avoiding errors both coming from\nthe mis-interpretation of the tool and from the modeller himself/herself. An\nexample taken from the railway domain shows the approach.",
    "descriptor": "\nComments: Editor: Ib\\'eria Medeiros. 18th European Dependable Computing Conference (EDCC 2022), September 12-15, 2022, Zaragoza, Spain. Student Forum Proceedings - EDCC 2022\n",
    "authors": [
      "Maria Stella de Biase",
      "Stefano Marrone",
      "Angelo Palladino"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.03388"
  },
  {
    "id": "arXiv:2210.03389",
    "title": "Efficient Adaptive Stochastic Collocation Strategies for  Advection-Diffusion Problems with Uncertain Inputs",
    "abstract": "Physical models with uncertain inputs are commonly represented as parametric\npartial differential equations (PDEs). That is, PDEs with inputs that are\nexpressed as functions of parameters with an associated probability\ndistribution. Developing efficient and accurate solution strategies that\naccount for errors on the space, time and parameter domains simultaneously is\nhighly challenging. Indeed, it is well known that standard polynomial-based\napproximations on the parameter domain can incur errors that grow in time. In\nthis work, we focus on advection-diffusion problems with parameter-dependent\nwind fields. A novel adaptive solution strategy is proposed that allows users\nto combine stochastic collocation on the parameter domain with off-the-shelf\nadaptive timestepping algorithms with local error control. This is a\nnon-intrusive strategy that builds a polynomial-based surrogate that is adapted\nsequentially in time. The algorithm is driven by a so-called hierarchical\nestimator for the parametric error and balances this against an estimate for\nthe global timestepping error which is derived from a scaling argument.",
    "descriptor": "\nComments: 29 pages, 14 figures\n",
    "authors": [
      "Benjamin M. Kent",
      "Catherine E. Powell",
      "David J. Silvester",
      "Ma\u0142gorzata J. Zimo\u0144"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03389"
  },
  {
    "id": "arXiv:2210.03392",
    "title": "Latent Matrices for Tensor Network Decomposition and to Tensor  Completion",
    "abstract": "The prevalent fully-connected tensor network (FCTN) has achieved excellent\nsuccess to compress data. However, the FCTN decomposition suffers from slow\ncomputational speed when facing higher-order and large-scale data. Naturally,\nthere arises an interesting question: can a new model be proposed that\ndecomposes the tensor into smaller ones and speeds up the computation of the\nalgorithm? This work gives a positive answer by formulating a novel\nhigher-order tensor decomposition model that utilizes latent matrices based on\nthe tensor network structure, which can decompose a tensor into smaller-scale\ndata than the FCTN decomposition, hence we named it Latent Matrices for Tensor\nNetwork Decomposition (LMTN). Furthermore, three optimization algorithms,\nLMTN-PAM, LMTN-SVD and LMTN-AR, have been developed and applied to the\ntensor-completion task. In addition, we provide proofs of theoretical\nconvergence and complexity analysis for these algorithms. Experimental results\nshow that our algorithm has the effectiveness in both deep learning dataset\ncompression and higher-order tensor completion, and that our LMTN-SVD algorithm\nis 3-6 times faster than the FCTN-PAM algorithm and only a 1.8 points accuracy\ndrop.",
    "descriptor": "",
    "authors": [
      "Peilin Yang",
      "Weijun Sun",
      "Qinbin Zhao",
      "Guoxu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03392"
  },
  {
    "id": "arXiv:2210.03393",
    "title": "Optimal Thermal Management and Charging of Battery Electric Vehicles  over Long Trips",
    "abstract": "This paper studies optimal thermal management and charging of a battery\nelectric vehicle driving over long distance trips. The focus is on the\npotential benefits of including a heat pump in the thermal management system\nfor waste heat recovery, and charging point planning, in a way to achieve\noptimality in time, energy, or their trade-off. An optimal control problem is\nformulated, in which the objective function includes the energy delivered by\nthe charger(s), and the total charging time including the actual charging time\nand the detour time to and from the charging stop. To reduce the computational\ncomplexity, the formulated problem is then transformed into a hybrid dynamical\nsystem, where charging dynamics are modelled in the domain of normalized\ncharging time. Driving dynamics can be modelled in either of the trip time or\ntravel distance domains, as the vehicle speed is assumed to be known a priori,\nand the vehicle is only stopping at charging locations. Within the hybrid\ndynamical system, a binary variable is introduced for each charging location,\nin order to decide to use or skip a charger. This problem is solved\nnumerically, and simulations are performed to evaluate the performance in terms\nof energy efficiency and time. The simulation results indicate that the time\nrequired for charging and total energy consumption are reduced up to 30.6% and\n19.4%, respectively, by applying the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Ahad Hamednia",
      "Victor Hanson",
      "Jiaming Zhao",
      "Nikolce Murgovski",
      "Jimmy Forsman",
      "Mitra Pourabdollah",
      "Viktor Larsson",
      "Jonas Fredriksson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03393"
  },
  {
    "id": "arXiv:2210.03398",
    "title": "Mars Rover Localization Based on A2G Obstacle Distribution Pattern  Matching",
    "abstract": "Rover localization is one of the perquisites for large scale rover\nexploration. In NASA's Mars 2020 mission, the Ingenuity helicopter is carried\ntogether with the rover, which is capable of obtaining high-resolution imagery\nof Mars terrain, and it is possible to perform localization based on\naerial-to-ground (A2G) imagery correspondence. However, considering the\nlow-texture nature of the Mars terrain, and large perspective changes between\nUAV and rover imagery, traditional image matching methods will struggle to\nobtain valid image correspondence. In this paper we propose a novel pipeline\nfor Mars rover localization. An algorithm combing image-based rock detection\nand rock distribution pattern matching is used to acquire A2G imagery\ncorrespondence, thus establishing the rover position in a UAV-generated ground\nmap. Feasibility of this method is evaluated on sample data from a Mars\nanalogue environment. The proposed method can serve as a reliable assist in\nfuture Mars missions.",
    "descriptor": "\nComments: 8 pages, in Chinese language, 9 figures\n",
    "authors": [
      "Lang Zhou",
      "Zhitai Zhang",
      "Hongliang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03398"
  },
  {
    "id": "arXiv:2210.03400",
    "title": "Computational imaging with the human brain",
    "abstract": "Brain-computer interfaces (BCIs) are enabling a range of new possibilities\nand routes for augmenting human capability. Here, we propose BCIs as a route\ntowards forms of computation, i.e. computational imaging, that blend the brain\nwith external silicon processing. We demonstrate ghost imaging of a hidden\nscene using the human visual system that is combined with an adaptive\ncomputational imaging scheme. This is achieved through a projection pattern\n`carving' technique that relies on real-time feedback from the brain to modify\npatterns at the light projector, thus enabling more efficient and higher\nresolution imaging. This brain-computer connectivity demonstrates a form of\naugmented human computation that could in the future extend the sensing range\nof human vision and provide new approaches to the study of the neurophysics of\nhuman perception. As an example, we illustrate a simple experiment whereby\nimage reconstruction quality is affected by simultaneous conscious processing\nand readout of the perceived light intensities.",
    "descriptor": "",
    "authors": [
      "Gao Wang",
      "Daniele Faccio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.03400"
  },
  {
    "id": "arXiv:2210.03402",
    "title": "Research on Self-adaptive Online Vehicle Velocity Prediction Strategy  Considering Traffic Information Fusion",
    "abstract": "In order to increase the prediction accuracy of the online vehicle velocity\nprediction (VVP) strategy, a self-adaptive velocity prediction algorithm fused\nwith traffic information was presented for the multiple scenarios. Initially,\ntraffic scenarios were established inside the co-simulation environment. In\naddition, the algorithm of a general regressive neural network (GRNN) paired\nwith datasets of the ego-vehicle, the front vehicle, and traffic lights was\nused in traffic scenarios, which increasingly improved the prediction accuracy.\nTo ameliorate the robustness of the algorithm, then the strategy was optimized\nby particle swarm optimization (PSO) and k-fold cross-validation to find the\noptimal parameters of the neural network in real-time, which constructed a\nself-adaptive online PSO-GRNN VVP strategy with multi-information fusion to\nadapt with different operating situations. The self-adaptive online PSO-GRNN\nVVP strategy was then deployed to a variety of simulated scenarios to test its\nefficacy under various operating situations. Finally, the simulation results\nreveal that in urban and highway scenarios, the prediction accuracy is\nseparately increased by 27.8% and 54.5% when compared to the traditional GRNN\nVVP strategy with fixed parameters utilizing only the historical ego-vehicle\nvelocity dataset.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Ziyan Zhang",
      "Junhao Shen",
      "Dongwei Yao",
      "Feng Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.03402"
  },
  {
    "id": "arXiv:2210.03403",
    "title": "TAN without a burn: Scaling Laws of DP-SGD",
    "abstract": "Differentially Private methods for training Deep Neural Networks (DNNs) have\nprogressed recently, in particular with the use of massive batches and\naggregated data augmentations for a large number of steps. These techniques\nrequire much more compute than their non-private counterparts, shifting the\ntraditional privacy-accuracy trade-off to a privacy-accuracy-compute trade-off\nand making hyper-parameter search virtually impossible for realistic scenarios.\nIn this work, we decouple privacy analysis and experimental behavior of noisy\ntraining to explore the trade-off with minimal computational requirements. We\nfirst use the tools of R\\'enyi Differential Privacy (RDP) to show that the\nprivacy budget, when not overcharged, only depends on the total amount of noise\n(TAN) injected throughout training. We then derive scaling laws for training\nmodels with DP-SGD to optimize hyper-parameters with more than a 100 reduction\nin computational budget. We apply the proposed method on CIFAR-10 and ImageNet\nand, in particular, strongly improve the state-of-the-art on ImageNet with a +9\npoints gain in accuracy for a privacy budget epsilon=8.",
    "descriptor": "",
    "authors": [
      "Tom Sander",
      "Pierre Stock",
      "Alexandre Sablayrolles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03403"
  },
  {
    "id": "arXiv:2210.03404",
    "title": "Quantifying Political Bias in News Articles",
    "abstract": "Search bias analysis is getting more attention in recent years since search\nresults could affect In this work, we aim to establish an automated model for\nevaluating ideological bias in online news articles. The dataset is composed of\nnews articles in search results as well as the newspaper articles. The current\nautomated model results show that model capability is not sufficient to be\nexploited for annotating the documents automatically, thereby computing bias in\nsearch results.",
    "descriptor": "",
    "authors": [
      "Gizem Gezici"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03404"
  },
  {
    "id": "arXiv:2210.03405",
    "title": "PARAGEN : A Parallel Generation Toolkit",
    "abstract": "PARAGEN is a PyTorch-based NLP toolkit for further development on parallel\ngeneration. PARAGEN provides thirteen types of customizable plugins, helping\nusers to experiment quickly with novel ideas across model architectures,\noptimization, and learning strategies. We implement various features, such as\nunlimited data loading and automatic model selection, to enhance its industrial\nusage. ParaGen is now deployed to support various research and industry\napplications at ByteDance. PARAGEN is available at\nhttps://github.com/bytedance/ParaGen.",
    "descriptor": "\nComments: 9 pages, 1 figure, 6 tables\n",
    "authors": [
      "Jiangtao Feng",
      "Yi Zhou",
      "Jun Zhang",
      "Xian Qian",
      "Liwei Wu",
      "Zhexi Zhang",
      "Yanming Liu",
      "Mingxuan Wang",
      "Lei Li",
      "Hao Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03405"
  },
  {
    "id": "arXiv:2210.03413",
    "title": "Removing Qualified Names in Modular Languages",
    "abstract": "Although the notion of qualified names is popular in module systems, it\ncauses severe complications. In this paper, we propose an alternative to\nqualified names. The key idea is to import the declarations in other modules to\nthe current module before they are used. In this way, all the declarations can\nbe accessed locally. However, this approach is not efficient in memory usage.\nOur contribution is the {\\it module weakening} scheme which allows us to import\nthe minimal parts. As an example of this approach, we propose a module system\nfor functional languages.",
    "descriptor": "",
    "authors": [
      "Keehang Kwon",
      "Daeseong Kang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.03413"
  },
  {
    "id": "arXiv:2210.03416",
    "title": "Detailed Annotations of Chest X-Rays via CT Projection for Report  Understanding",
    "abstract": "In clinical radiology reports, doctors capture important information about\nthe patient's health status. They convey their observations from raw medical\nimaging data about the inner structures of a patient. As such, formulating\nreports requires medical experts to possess wide-ranging knowledge about\nanatomical regions with their normal, healthy appearance as well as the ability\nto recognize abnormalities. This explicit grasp on both the patient's anatomy\nand their appearance is missing in current medical image-processing systems as\nannotations are especially difficult to gather. This renders the models to be\nnarrow experts e.g. for identifying specific diseases. In this work, we recover\nthis missing link by adding human anatomy into the mix and enable the\nassociation of content in medical reports to their occurrence in associated\nimagery (medical phrase grounding). To exploit anatomical structures in this\nscenario, we present a sophisticated automatic pipeline to gather and integrate\nhuman bodily structures from computed tomography datasets, which we incorporate\nin our PAXRay: A Projected dataset for the segmentation of Anatomical\nstructures in X-Ray data. Our evaluation shows that methods that take advantage\nof anatomical information benefit heavily in visually grounding radiologists'\nfindings, as our anatomical segmentations allow for up to absolute 50% better\ngrounding results on the OpenI dataset as compared to commonly used region\nproposals. The PAXRay dataset is available at\nhttps://constantinseibold.github.io/paxray/.",
    "descriptor": "\nComments: 33rd British Machine Vision Conference (BMVC 2022)\n",
    "authors": [
      "Constantin Seibold",
      "Simon Rei\u00df",
      "Saquib Sarfraz",
      "Matthias A. Fink",
      "Victoria Mayer",
      "Jan Sellner",
      "Moon Sung Kim",
      "Klaus H. Maier-Hein",
      "Jens Kleesiek",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03416"
  },
  {
    "id": "arXiv:2210.03417",
    "title": "A Simple Plugin for Transforming Images to Arbitrary Scales",
    "abstract": "Existing models on super-resolution often specialized for one scale,\nfundamentally limiting their use in practical scenarios. In this paper, we aim\nto develop a general plugin that can be inserted into existing super-resolution\nmodels, conveniently augmenting their ability towards Arbitrary Resolution\nImage Scaling, thus termed ARIS. We make the following contributions: (i) we\npropose a transformer-based plugin module, which uses spatial coordinates as\nquery, iteratively attend the low-resolution image feature through\ncross-attention, and output visual feature for the queried spatial location,\nresembling an implicit representation for images; (ii) we introduce a novel\nself-supervised training scheme, that exploits consistency constraints to\neffectively augment the model's ability for upsampling images towards unseen\nscales, i.e. ground-truth high-resolution images are not available; (iii)\nwithout loss of generality, we inject the proposed ARIS plugin module into\nseveral existing models, namely, IPT, SwinIR, and HAT, showing that the\nresulting models can not only maintain their original performance on fixed\nscale factor but also extrapolate to unseen scales, substantially outperforming\nexisting any-scale super-resolution models on standard benchmarks, e.g.\nUrban100, DIV2K, etc.",
    "descriptor": "",
    "authors": [
      "Qinye Zhou",
      "Ziyi Li",
      "Weidi Xie",
      "Xiaoyun Zhang",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03417"
  },
  {
    "id": "arXiv:2210.03418",
    "title": "Data-driven probability density forecast for stochastic dynamical  systems",
    "abstract": "In this paper, a data-driven nonparametric approach is presented for\nforecasting the probability density evolution of stochastic dynamical systems.\nThe method is based on stochastic Koopman operator and extended dynamic mode\ndecomposition (EDMD) framework. To approximate the finite-dimensional\neigendecomposition of the stochastic Koopman operator, EDMD is applied to the\ntraining data set sampled from the stationary distribution of the underlying\nstochastic dynamical system. The family of the Koopman operators form a\nsemigroup, which is generated by the infinitesimal generator of the underlying\nstochastic dynamic system. A significant connection between the generator and\nFokker-Planck operator provides a way to construct an orthonormal basis of a\nweighted Hilbert space. A spectral decomposition of the probability density\nfunction is accomplished in this weighted space. This approach is a data-driven\nmethod and used to predict the probability density evolution and real-time\nmoment estimation. In the limit of the large number of snapshots and\nobservables, the data-driven probability density approximation converges to the\nGalerkin projection of the semigroup solution of Fokker-Planck equation on a\nbasis adapted to an invariant measure. The proposed method shares the similar\nidea to diffusion forecast, but renders more accurate probability density than\nthe diffusion forecast does. A few numerical examples are presented to\nillustrate the performance of the data-driven probability density forecast.",
    "descriptor": "\nComments: submitted to Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Meng Zhao",
      "Lijian Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.03418"
  },
  {
    "id": "arXiv:2210.03419",
    "title": "Event Extraction: A Survey",
    "abstract": "Extracting the reported events from text is one of the key research themes in\nnatural language processing. This process includes several tasks such as event\ndetection, argument extraction, role labeling. As one of the most important\ntopics in natural language processing and natural language understanding, the\napplications of event extraction spans across a wide range of domains such as\nnewswire, biomedical domain, history and humanity, and cyber security. This\nreport presents a comprehensive survey for event detection from textual\ndocuments. In this report, we provide the task definition, the evaluation\nmethod, as well as the benchmark datasets and a taxonomy of methodologies for\nevent extraction. We also present our vision of future research direction in\nevent detection.",
    "descriptor": "",
    "authors": [
      "Viet Dac Lai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03419"
  },
  {
    "id": "arXiv:2210.03422",
    "title": "SpaceQA: Answering Questions about the Design of Space Missions and  Space Craft Concepts",
    "abstract": "We present SpaceQA, to the best of our knowledge the first open-domain QA\nsystem in Space mission design. SpaceQA is part of an initiative by the\nEuropean Space Agency (ESA) to facilitate the access, sharing and reuse of\ninformation about Space mission design within the agency and with the public.\nWe adopt a state-of-the-art architecture consisting of a dense retriever and a\nneural reader and opt for an approach based on transfer learning rather than\nfine-tuning due to the lack of domain-specific annotated data. Our evaluation\non a test set produced by ESA is largely consistent with the results originally\nreported by the evaluated retrievers and confirms the need of fine tuning for\nreading comprehension. As of writing this paper, ESA is piloting SpaceQA\ninternally.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Silva",
      "Cristian Berr\u00edo",
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez",
      "Jos\u00e9 Antonio Mart\u00ednez-Heras",
      "Alessandro Donati",
      "Ilaria Roma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03422"
  },
  {
    "id": "arXiv:2210.03423",
    "title": "When is Spring coming? A Security Analysis of Avalanche Consensus",
    "abstract": "Avalanche is a blockchain consensus protocol with exceptionally low latency\nand high throughput. This has swiftly established the corresponding token as a\ntop-tier cryptocurrency. Avalanche achieves such remarkable metrics by\nsubstituting proof of work with a random sampling mechanism. The protocol also\ndiffers from Bitcoin, Ethereum, and many others by forming a directed acyclic\ngraph (DAG) instead of a chain. It does not totally order all transactions,\nestablishes a partial order among them, and accepts transactions in the DAG\nthat satisfy specific properties. Such parallelism is widely regarded as a\ntechnique that increases the efficiency of consensus.\nDespite its success, Avalanche consensus lacks a complete abstract\nspecification and a matching formal analysis. To address this drawback, this\nwork provides first a detailed formulation of Avalanche through pseudocode.\nThis includes features that are omitted from the original whitepaper or are\nonly vaguely explained in the documentation. Second, the paper gives an\nanalysis of the formal properties fulfilled by Avalanche in the sense of a\ngeneric broadcast protocol that only orders related transactions. Last but not\nleast, the analysis reveals a vulnerability that affects the liveness of the\nprotocol. A possible solution that addresses the problem is also proposed.",
    "descriptor": "",
    "authors": [
      "Ignacio Amores-Sesar",
      "Christian Cachin",
      "Enrico Tedeschi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.03423"
  },
  {
    "id": "arXiv:2210.03424",
    "title": "Kalman-Bucy-Informed Neural Network for System Identification",
    "abstract": "Identifying parameters in a system of nonlinear, ordinary differential\nequations is vital for designing a robust controller. However, if the system is\nstochastic in its nature or if only noisy measurements are available, standard\noptimization algorithms for system identification usually fail. We present a\nnew approach that combines the recent advances in physics-informed neural\nnetworks and the well-known achievements of Kalman filters in order to find\nparameters in a continuous-time system with noisy measurements. In doing so,\nour approach allows estimating the parameters together with the mean value and\ncovariance matrix of the system's state vector. We show that the method works\nfor complex systems by identifying the parameters of a double pendulum.",
    "descriptor": "\nComments: 6 pages, 5 figures, Conference on Decision and Control 2022\n",
    "authors": [
      "Tobias Nagel",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03424"
  },
  {
    "id": "arXiv:2210.03426",
    "title": "Certified machine learning: Rigorous a posteriori error bounds for PDE  defined PINNs",
    "abstract": "Prediction error quantification in machine learning has been left out of most\nmethodological investigations of neural networks, for both purely data-driven\nand physics-informed approaches. Beyond statistical investigations and generic\nresults on the approximation capabilities of neural networks, we present a\nrigorous upper bound on the prediction error of physics-informed neural\nnetworks. This bound can be calculated without the knowledge of the true\nsolution and only with a priori available information about the characteristics\nof the underlying dynamical system governed by a partial differential equation.\nWe apply this a posteriori error bound exemplarily to four problems: the\ntransport equation, the heat equation, the Navier-Stokes equation and the\nKlein-Gordon equation.",
    "descriptor": "",
    "authors": [
      "Birgit Hillebrecht",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03426"
  },
  {
    "id": "arXiv:2210.03427",
    "title": "Generating Quizzes to Support Training on Quality Management and  Assurance in Space Science and Engineering",
    "abstract": "Quality management and assurance is key for space agencies to guarantee the\nsuccess of space missions, which are high-risk and extremely costly. In this\npaper, we present a system to generate quizzes, a common resource to evaluate\nthe effectiveness of training sessions, from documents about quality assurance\nprocedures in the Space domain. Our system leverages state of the art\nauto-regressive models like T5 and BART to generate questions, and a RoBERTa\nmodel to extract answers for such questions, thus verifying their suitability.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Silva",
      "Cristian Berr\u00edo",
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03427"
  },
  {
    "id": "arXiv:2210.03428",
    "title": "Missing Modality meets Meta Sampling (M3S): An Efficient Universal  Approach for Multimodal Sentiment Analysis with Missing Modality",
    "abstract": "Multimodal sentiment analysis (MSA) is an important way of observing mental\nactivities with the help of data captured from multiple modalities. However,\ndue to the recording or transmission error, some modalities may include\nincomplete data. Most existing works that address missing modalities usually\nassume a particular modality is completely missing and seldom consider a\nmixture of missing across multiple modalities. In this paper, we propose a\nsimple yet effective meta-sampling approach for multimodal sentiment analysis\nwith missing modalities, namely Missing Modality-based Meta Sampling (M3S). To\nbe specific, M3S formulates a missing modality sampling strategy into the modal\nagnostic meta-learning (MAML) framework. M3S can be treated as an efficient\nadd-on training component on existing models and significantly improve their\nperformances on multimodal data with a mixture of missing modalities. We\nconduct experiments on IEMOCAP, SIMS and CMU-MOSI datasets, and superior\nperformance is achieved compared with recent state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Haozhe Chi",
      "Minghua Yang",
      "Junhao Zhu",
      "Guanhong Wang",
      "Gaoang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03428"
  },
  {
    "id": "arXiv:2210.03429",
    "title": "Adversarially Robust Prototypical Few-shot Segmentation with Neural-ODEs",
    "abstract": "Few-shot Learning (FSL) methods are being adopted in settings where data is\nnot abundantly available. This is especially seen in medical domains where the\nannotations are expensive to obtain. Deep Neural Networks have been shown to be\nvulnerable to adversarial attacks. This is even more severe in the case of FSL\ndue to the lack of a large number of training examples. In this paper, we\nprovide a framework to make few-shot segmentation models adversarially robust\nin the medical domain where such attacks can severely impact the decisions made\nby clinicians who use them. We propose a novel robust few-shot segmentation\nframework, Prototypical Neural Ordinary Differential Equation (PNODE), that\nprovides defense against gradient-based adversarial attacks. We show that our\nframework is more robust compared to traditional adversarial defense mechanisms\nsuch as adversarial training. Adversarial training involves increased training\ntime and shows robustness to limited types of attacks depending on the type of\nadversarial examples seen during training. Our proposed framework generalises\nwell to common adversarial attacks like FGSM, PGD and SMIA while having the\nmodel parameters comparable to the existing few-shot segmentation models. We\nshow the effectiveness of our proposed approach on three publicly available\nmulti-organ segmentation datasets in both in-domain and cross-domain settings\nby attacking the support and query sets without the need for ad-hoc adversarial\ntraining.",
    "descriptor": "\nComments: MICCAI 2022. arXiv admin note: substantial text overlap with arXiv:2208.12428\n",
    "authors": [
      "Prashant Pandey",
      "Aleti Vardhan",
      "Mustafa Chasmai",
      "Tanuj Sur",
      "Brejesh Lall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03429"
  },
  {
    "id": "arXiv:2210.03431",
    "title": "High Resolution Spatio-Temporal Model for Room-Level Airborne Pandemic  Spread",
    "abstract": "Airborne pandemics have caused millions of deaths worldwide, large-scale\neconomic losses, and catastrophic sociological shifts in human history.\nResearchers have developed multiple mathematical models and computational\nframeworks to investigate and predict the pandemic spread on various levels and\nscales such as countries, cities, large social events, and even buildings.\nHowever, modeling attempts of airborne pandemic dynamics on the smallest scale,\na single room, have been mostly neglected. As time indoors increases due to\nglobal urbanization processes, more infections occur in shared rooms. In this\nstudy, a high-resolution spatio-temporal epidemiological model with airflow\ndynamics to evaluate airborne pandemic spread is proposed. The model is\nimplemented using high-resolution 3D data obtained using a light detection and\nranging (LiDAR) device and computing the model based on the Computational Fluid\nDynamics (CFD) model for the airflow and the Susceptible-Exposed-Infected (SEI)\nmodel for the epidemiological dynamics. The pandemic spread is evaluated in\nfour types of rooms, showing significant differences even for a short exposure\nduration. We show that the room's topology and individual distribution in the\nroom define the ability of air ventilation to reduce pandemic spread throughout\nbreathing zone infection.",
    "descriptor": "",
    "authors": [
      "Teddy Lazebnik",
      "Ariel Alexi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03431"
  },
  {
    "id": "arXiv:2210.03432",
    "title": "Femto-Containers: Lightweight Virtualization and Fault Isolation For  Small Software Functions on Low-Power IoT Microcontrollers",
    "abstract": "Low-power operating system runtimes used on IoT microcontrollers typically\nprovide rudimentary APIs, basic connectivity and, sometimes, a (secure)\nfirmware update mechanism. In contrast, on less constrained hardware, networked\nsoftware has entered the age of serverless, microservices and agility. With a\nview to bridge this gap, in the paper we design Femto-Containers, a new\nmiddleware runtime which can be embedded on heterogeneous low-power IoT\ndevices. Femto-Containers enable the secure deployment, execution and isolation\nof small virtual software functions on low-power IoT devices, over the network.\nWe implement Femto-Containers, and provide integration in RIOT, a popular open\nsource IoT operating system. We then evaluate the performance of our\nimplementation, which was formally verified for fault-isolation, guaranteeing\nthat RIOT is shielded from logic loaded and executed in a Femto-Container. Our\nexperiments on various popular microcontroller architectures (Arm Cortex-M,\nESP32 and RISC-V) show that Femto-Containers offer an attractive trade-off in\nterms of memory footprint overhead, energy consumption, and security",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.12553\n",
    "authors": [
      "Koen Zandberg",
      "Emmanuel Baccelli",
      "Shenghao Yuan",
      "Fr\u00e9d\u00e9ric Besson",
      "Jean-Pierre Talpin"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.03432"
  },
  {
    "id": "arXiv:2210.03433",
    "title": "PS-ARM: An End-to-End Attention-aware Relation Mixer Network for Person  Search",
    "abstract": "Person search is a challenging problem with various real-world applications,\nthat aims at joint person detection and re-identification of a query person\nfrom uncropped gallery images. Although, the previous study focuses on rich\nfeature information learning, it is still hard to retrieve the query person due\nto the occurrence of appearance deformations and background distractors. In\nthis paper, we propose a novel attention-aware relation mixer (ARM) module for\nperson search, which exploits the global relation between different local\nregions within RoI of a person and make it robust against various appearance\ndeformations and occlusion. The proposed ARM is composed of a relation mixer\nblock and a spatio-channel attention layer. The relation mixer block introduces\na spatially attended spatial mixing and a channel-wise attended channel mixing\nfor effectively capturing discriminative relation features within an RoI. These\ndiscriminative relation features are further enriched by introducing a\nspatio-channel attention where the foreground and background discriminability\nis empowered in a joint spatio-channel space. Our ARM module is generic and it\ndoes not rely on fine-grained supervision or topological assumptions, hence\nbeing easily integrated into any Faster R-CNN based person search methods.\nComprehensive experiments are performed on two challenging benchmark datasets:\nCUHKSYSU and PRW. Our PS-ARM achieves state-of-the-art performance on both\ndatasets. On the challenging PRW dataset, our PS-ARM achieves an absolute gain\nof 5 in the mAP score over SeqNet, while operating at a comparable speed.",
    "descriptor": "\nComments: Paper accepted in ACCV 2022\n",
    "authors": [
      "Mustansar Fiaz",
      "Hisham Cholakkal",
      "Sanath Narayan",
      "Rao Muhammad Anwer",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03433"
  },
  {
    "id": "arXiv:2210.03435",
    "title": "IDPL: Intra-subdomain adaptation adversarial learning segmentation  method based on Dynamic Pseudo Labels",
    "abstract": "Unsupervised domain adaptation(UDA) has been applied to image semantic\nsegmentation to solve the problem of domain offset. However, in some difficult\ncategories with poor recognition accuracy, the segmentation effects are still\nnot ideal. To this end, in this paper, Intra-subdomain adaptation adversarial\nlearning segmentation method based on Dynamic Pseudo Labels(IDPL) is proposed.\nThe whole process consists of 3 steps: Firstly, the instance-level pseudo label\ndynamic generation module is proposed, which fuses the class matching\ninformation in global classes and local instances, thus adaptively generating\nthe optimal threshold for each class, obtaining high-quality pseudo labels.\nSecondly, the subdomain classifier module based on instance confidence is\nconstructed, which can dynamically divide the target domain into easy and\ndifficult subdomains according to the relative proportion of easy and difficult\ninstances. Finally, the subdomain adversarial learning module based on\nself-attention is proposed. It uses multi-head self-attention to confront the\neasy and difficult subdomains at the class level with the help of generated\nhigh-quality pseudo labels, so as to focus on mining the features of difficult\ncategories in the high-entropy region of target domain images, which promotes\nclass-level conditional distribution alignment between the subdomains,\nimproving the segmentation performance of difficult categories. For the\ndifficult categories, the experimental results show that the performance of\nIDPL is significantly improved compared with other latest mainstream methods.",
    "descriptor": "\nComments: Accepted at The 29th International Conference on Neural Information Processing (ICONIP 2022)\n",
    "authors": [
      "Xuewei Li",
      "Weilun Zhang",
      "Mankun Zhao",
      "Ming Li",
      "Yang Yan",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03435"
  },
  {
    "id": "arXiv:2210.03436",
    "title": "Trans2k: Unlocking the Power of Deep Models for Transparent Object  Tracking",
    "abstract": "Visual object tracking has focused predominantly on opaque objects, while\ntransparent object tracking received very little attention. Motivated by the\nuniqueness of transparent objects in that their appearance is directly affected\nby the background, the first dedicated evaluation dataset has emerged recently.\nWe contribute to this effort by proposing the first transparent object tracking\ntraining dataset Trans2k that consists of over 2k sequences with 104,343 images\noverall, annotated by bounding boxes and segmentation masks. Noting that\ntransparent objects can be realistically rendered by modern renderers, we\nquantify domain-specific attributes and render the dataset containing visual\nattributes and tracking situations not covered in the existing object training\ndatasets. We observe a consistent performance boost (up to 16%) across a\ndiverse set of modern tracking architectures when trained using Trans2k, and\nshow insights not previously possible due to the lack of appropriate training\nsets. The dataset and the rendering engine will be publicly released to unlock\nthe power of modern learning-based trackers and foster new designs in\ntransparent object tracking.",
    "descriptor": "\nComments: Accepted to BMVC 2022. Project page: this https URL\n",
    "authors": [
      "Alan Lukezic",
      "Ziga Trojer",
      "Jiri Matas",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03436"
  },
  {
    "id": "arXiv:2210.03437",
    "title": "KRF: Keypoint Refinement with Fusion Network for 6D Pose Estimation",
    "abstract": "Existing refinement methods gradually lose their ability to further improve\npose estimation methods' accuracy. In this paper, we propose a new refinement\npipeline, Keypoint Refinement with Fusion Network (KRF), for 6D pose\nestimation, especially for objects with serious occlusion. The pipeline\nconsists of two steps. It first completes the input point clouds via a novel\npoint completion network. The network uses both local and global features,\nconsidering the pose information during point completion. Then, it registers\nthe completed object point cloud with corresponding target point cloud by Color\nsupported Iterative KeyPoint (CIKP). The CIKP method introduces color\ninformation into registration and registers point cloud around each keypoint to\nincrease stability. The KRF pipeline can be integrated with existing popular 6D\npose estimation methods, e.g. the full flow bidirectional fusion network, to\nfurther improved their pose estimation accuracy. Experiments show that our\nmethod outperforms the state-of-the-art method from 93.9\\% to 94.4\\% on\nYCB-Video dataset and from 64.4\\% to 66.8\\% on Occlusion LineMOD dataset. Our\nsource code is available at https://github.com/zhanhz/KRF.",
    "descriptor": "",
    "authors": [
      "Irvin Haozhe Zhan",
      "Yiheng Han",
      "Yu-Ping Wang",
      "Long Zeng",
      "Yong-Jin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03437"
  },
  {
    "id": "arXiv:2210.03441",
    "title": "Decentralized Vision-Based Byzantine Agent Detection in Multi-Robot  Systems with IOTA Smart Contracts",
    "abstract": "Multiple opportunities lie at the intersection of multi-robot systems and\ndistributed ledger technologies (DLTs). In this work, we investigate the\npotential of new DLT solutions such as IOTA, for detecting anomalies and\nbyzantine agents in multi-robot systems in a decentralized manner. Traditional\nblockchain approaches are not applicable to real-world networked and\ndecentralized robotic systems where connectivity conditions are not ideal. To\naddress this, we leverage recent advances in partition-tolerant and\nbyzantine-tolerant collaborative decision-making processes with IOTA smart\ncontracts. We show how our work in vision-based anomaly and change detection\ncan be applied to detecting byzantine agents within multiple robots operating\nin the same environment. We show that IOTA smart contracts add a low\ncomputational overhead while allowing to build trust within the multi-robot\nsystem. The proposed approach effectively enables byzantine robot detection\nbased on the comparison of images submitted by the different robots and\ndetection of anomalies and changes between them.",
    "descriptor": "",
    "authors": [
      "Sahar Salimpour",
      "Farhad Keramat",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03441"
  },
  {
    "id": "arXiv:2210.03442",
    "title": "Contact Optimization for Non-Prehensile Loco-Manipulation via  Hierarchical Model Predictive Control",
    "abstract": "Recent studies on quadruped robots have focused on either locomotion or\nmobile manipulation using a robotic arm. Legged robots can manipulate heavier\nand larger objects using non-prehensile manipulation primitives, such as planar\npushing, to drive the object to the desired location. In this paper, we present\na novel hierarchical model predictive control (MPC) for contact optimization of\nthe manipulation task. Using two cascading MPCs, we split the loco-manipulation\nproblem into two parts: the first to optimize both contact force and contact\nlocation between the robot and the object, and the second to regulate the\ndesired interaction force through the robot locomotion. Our method is\nsuccessfully validated in both simulation and hardware experiments. While the\nbaseline locomotion MPC fails to follow the desired trajectory of the object,\nour proposed approach can effectively control both object's position and\norientation with minimal tracking error. This capability also allows us to\nperform obstacle avoidance for both the robot and the object during the\nloco-manipulation task.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Alberto Rigo",
      "Yiyu Chen",
      "Satyandra K. Gupta",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03442"
  },
  {
    "id": "arXiv:2210.03444",
    "title": "Depersonalized Federated Learning: Tackling Statistical Heterogeneity by  Alternating Stochastic Gradient Descent",
    "abstract": "Federated learning (FL) has gained increasing attention recently, which\nenables distributed devices to train a common machine learning (ML) model for\nintelligent inference cooperatively without data sharing.\nHowever, the raw data held by various involved participators are always\nnon-independent-and-identically-distributed (non-i.i.d), which results in slow\nconvergence of the FL training process.\nTo address this issue, we propose a new FL method that can significantly\nmitigate statistical heterogeneity by the depersonalized mechanism.\nParticularly, we decouple the global and local objectives optimized by\nperforming stochastic gradient descent alternately to reduce the accumulated\nvariance on the global model (generated in local update phases) hence\naccelerating the FL convergence.\nThen we analyze the proposed method detailedly to show the proposed method\nconverging at a sublinear speed in the general non-convex setting.\nFinally, extensive numerical results are conducted with experiments on public\ndatasets to verify the effectiveness of our proposed method.",
    "descriptor": "",
    "authors": [
      "Yujie Zhou",
      "Zhidu Li",
      "Songyang He",
      "Tong Tang",
      "Ruyan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03444"
  },
  {
    "id": "arXiv:2210.03450",
    "title": "Total stability and integral action for discrete-time nonlinear systems",
    "abstract": "Robustness guarantees are important properties to be looked for during\ncontrol design. They ensure stability of closed-loop systems in face of\nuncertainties, unmodeled effects and bounded disturbances. While the theory on\nrobust stability is well established in the continuous-time nonlinear\nframework, the same cannot be stated for its discrete-time counterpart. In this\npaper, we propose the discrete-time parallel of total stability results for\ncontinuous-time nonlinear system. This enables the analysis of robustness\nproperties via simple model difference in the discrete-time context. First, we\nstudy how existence of equilibria for a nominal model transfers to sufficiently\nsimilar ones. Then, we provide results on the",
    "descriptor": "",
    "authors": [
      "Samuele Zoboli",
      "Daniele Astolfi",
      "Vincent Andrieu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03450"
  },
  {
    "id": "arXiv:2210.03453",
    "title": "Key Information Extraction in Purchase Documents using Deep Learning and  Rule-based Corrections",
    "abstract": "Deep Learning (DL) is dominating the fields of Natural Language Processing\n(NLP) and Computer Vision (CV) in the recent times. However, DL commonly relies\non the availability of large data annotations, so other alternative or\ncomplementary pattern-based techniques can help to improve results. In this\npaper, we build upon Key Information Extraction (KIE) in purchase documents\nusing both DL and rule-based corrections. Our system initially trusts on\nOptical Character Recognition (OCR) and text understanding based on entity\ntagging to identify purchase facts of interest (e.g., product codes,\ndescriptions, quantities, or prices). These facts are then linked to a same\nproduct group, which is recognized by means of line detection and some grouping\nheuristics. Once these DL approaches are processed, we contribute several\nmechanisms consisting of rule-based corrections for improving the baseline DL\npredictions. We prove the enhancements provided by these rule-based corrections\nover the baseline DL results in the presented experiments for purchase\ndocuments from public and NielsenIQ datasets.",
    "descriptor": "\nComments: Conference on Computational Linguistics (COLING 2022). PAN-DL Workshop\n",
    "authors": [
      "Roberto Arroyo",
      "Javier Yebes",
      "Elena Mart\u00ednez",
      "H\u00e9ctor Corrales",
      "Javier Lorenzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03453"
  },
  {
    "id": "arXiv:2210.03454",
    "title": "DABERT: Dual Attention Enhanced BERT for Semantic Matching",
    "abstract": "Transformer-based pre-trained language models such as BERT have achieved\nremarkable results in Semantic Sentence Matching. However, existing models\nstill suffer from insufficient ability to capture subtle differences. Minor\nnoise like word addition, deletion, and modification of sentences may cause\nflipped predictions. To alleviate this problem, we propose a novel Dual\nAttention Enhanced BERT (DABERT) to enhance the ability of BERT to capture\nfine-grained differences in sentence pairs. DABERT comprises (1) Dual Attention\nmodule, which measures soft word matches by introducing a new dual channel\nalignment mechanism to model affinity and difference attention. (2) Adaptive\nFusion module, this module uses attention to learn the aggregation of\ndifference and affinity features, and generates a vector describing the\nmatching details of sentence pairs. We conduct extensive experiments on\nwell-studied semantic matching and robustness test datasets, and the\nexperimental results show the effectiveness of our proposed method.",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Sirui Wang",
      "Di Liang",
      "Jian Song",
      "Yuntao Li",
      "Wei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03454"
  },
  {
    "id": "arXiv:2210.03455",
    "title": "Advice Conformance Verification by Reinforcement Learning agents for  Human-in-the-Loop",
    "abstract": "Human-in-the-loop (HiL) reinforcement learning is gaining traction in domains\nwith large action and state spaces, and sparse rewards by allowing the agent to\ntake advice from HiL. Beyond advice accommodation, a sequential decision-making\nagent must be able to express the extent to which it was able to utilize the\nhuman advice. Subsequently, the agent should provide a means for the HiL to\ninspect parts of advice that it had to reject in favor of the overall\nenvironment objective. We introduce the problem of Advice-Conformance\nVerification which requires reinforcement learning (RL) agents to provide\nassurances to the human in the loop regarding how much of their advice is being\nconformed to. We then propose a Tree-based lingua-franca to support this\ncommunication, called a Preference Tree. We study two cases of good and bad\nadvice scenarios in MuJoCo's Humanoid environment. Through our experiments, we\nshow that our method can provide an interpretable means of solving the\nAdvice-Conformance Verification problem by conveying whether or not the agent\nis using the human's advice. Finally, we present a human-user study with 20\nparticipants that validates our method.",
    "descriptor": "\nComments: Accepted at IROS-RLCONFORM 2022\n",
    "authors": [
      "Mudit Verma",
      "Ayush Kharkwal",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03455"
  },
  {
    "id": "arXiv:2210.03458",
    "title": "PAC Security: Automatic Privacy Measurement and Control of Data  Processing",
    "abstract": "We propose and study a new privacy definition, termed Probably Approximately\nCorrect (PAC) Security. PAC security characterizes the information-theoretic\nhardness to recover sensitive data given arbitrary information\ndisclosure/leakage during/after any processing. Unlike the classic\ncryptographic definition and Differential Privacy (DP), which consider the\nadversarial (input-independent) worst case}, PAC security is a simulatable\nmetric that accommodates priors and quantifies the instance-based impossibility\nof inference. A fully automatic analysis and proof generation framework is\nproposed, where security parameters can be produced with arbitrarily high\nconfidence via Monte-Carlo simulation for any black-box data processing oracle.\nThis appealing automation property enables analysis of complicated data\nprocessing, where the worst-case proof in the classic privacy regime could be\nloose or even intractable. Furthermore, we show that the magnitude of\n(necessary) perturbation required in PAC security is not explicitly dependent\non dimensionality, which is in contrast to the worst-case information-theoretic\nlower bound. We also include practical applications of PAC security with\ncomparisons.",
    "descriptor": "",
    "authors": [
      "Hanshen Xiao",
      "Srinivas Devadas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03458"
  },
  {
    "id": "arXiv:2210.03461",
    "title": "FastCLIPStyler: Towards fast text-based image style transfer using style  representation",
    "abstract": "Artistic style transfer is usually performed between two images, a style\nimage and a content image. Recently, a model named CLIPStyler demonstrated that\na natural language description of style could replace the necessity of a\nreference style image. They achieved this by taking advantage of the CLIP\nmodel, which can compute the similarity between a text phrase and an image. In\nthis work, we demonstrate how combining CLIPStyler with a pre-trained, purely\nvision-based style transfer model can significantly reduce the inference time\nof CLIPStyler. We call this model FastCLIPStyler. We do a qualitative\nexploration of the stylised images from both models and argue that our model\nalso has merits in terms of the visual aesthetics of the generated images.\nFinally, we also point out how FastCLIPStyler can be used to further extend\nthis line of research to create a generalised text-to-style model that does not\nrequire optimisation at inference time, which both CLIPStyler and\nFastCLIPStyler do currently.",
    "descriptor": "",
    "authors": [
      "Ananda Padhmanabhan Suresh",
      "Sanjana Jain",
      "Pavit Noinongyao",
      "Ankush Ganguly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03461"
  },
  {
    "id": "arXiv:2210.03465",
    "title": "Physics inspired compact modelling of BiFeO$_3$ based memristors for  hardware security applications",
    "abstract": "With the advent of the Internet of Things, nanoelectronic devices or\nmemristors have been the subject of significant interest for use as new\nhardware security primitives. Among the several available memristors, BiFe$\\rm\nO_{3}$ (BFO)-based electroforming-free memristors have attracted considerable\nattention due to their excellent properties, such as long retention time,\nself-rectification, intrinsic stochasticity, and fast switching. They have been\nactively investigated for use in physical unclonable function (PUF) key storage\nmodules, artificial synapses in neural networks, nonvolatile resistive\nswitches, and reconfigurable logic applications. In this work, we present a\nphysics-inspired 1D compact model of a BFO memristor to understand its\nimplementation for such applications (mainly PUFs) and perform circuit\nsimulations. The resistive switching based on electric field-driven vacancy\nmigration and intrinsic stochastic behaviour of the BFO memristor are modelled\nusing the cloud-in-a-cell scheme. The experimental current-voltage\ncharacteristics of the BFO memristor are successfully reproduced. The response\nof the BFO memristor to changes in electrical properties, environmental\nproperties (such as temperature) and stress are analyzed and consistent with\nexperimental results.",
    "descriptor": "\nComments: 13 pages and 8 figures\n",
    "authors": [
      "Sahitya Yarragolla",
      "Nan Du",
      "Torben Hemke",
      "Xianyue Zhao",
      "Ziang Chen",
      "Ilia Polian",
      "Thomas Mussenbrock"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Cryptography and Security (cs.CR)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03465"
  },
  {
    "id": "arXiv:2210.03466",
    "title": "Latent Neural ODEs with Sparse Bayesian Multiple Shooting",
    "abstract": "Training dynamic models, such as neural ODEs, on long trajectories is a hard\nproblem that requires using various tricks, such as trajectory splitting, to\nmake model training work in practice. These methods are often heuristics with\npoor theoretical justifications, and require iterative manual tuning. We\npropose a principled multiple shooting technique for neural ODEs that splits\nthe trajectories into manageable short segments, which are optimised in\nparallel, while ensuring probabilistic control on continuity over consecutive\nsegments. We derive variational inference for our shooting-based latent neural\nODE models and propose amortized encodings of irregularly sampled trajectories\nwith a transformer-based recognition network with temporal attention and\nrelative positional encoding. We demonstrate efficient and stable training, and\nstate-of-the-art performance on multiple large-scale benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Valerii Iakovlev",
      "Cagatay Yildiz",
      "Markus Heinonen",
      "Harri L\u00e4hdesm\u00e4ki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03466"
  },
  {
    "id": "arXiv:2210.03469",
    "title": "Algorithmic Trading Using Continuous Action Space Deep Reinforcement  Learning",
    "abstract": "Price movement prediction has always been one of the traders' concerns in\nfinancial market trading. In order to increase their profit, they can analyze\nthe historical data and predict the price movement. The large size of the data\nand complex relations between them lead us to use algorithmic trading and\nartificial intelligence. This paper aims to offer an approach using\nTwin-Delayed DDPG (TD3) and the daily close price in order to achieve a trading\nstrategy in the stock and cryptocurrency markets. Unlike previous studies using\na discrete action space reinforcement learning algorithm, the TD3 is\ncontinuous, offering both position and the number of trading shares. Both the\nstock (Amazon) and cryptocurrency (Bitcoin) markets are addressed in this\nresearch to evaluate the performance of the proposed algorithm. The achieved\nstrategy using the TD3 is compared with some algorithms using technical\nanalysis, reinforcement learning, stochastic, and deterministic strategies\nthrough two standard metrics, Return and Sharpe ratio. The results indicate\nthat employing both position and the number of trading shares can improve the\nperformance of a trading system based on the mentioned metrics.",
    "descriptor": "",
    "authors": [
      "Naseh Majidi",
      "Mahdi Shamsi",
      "Farokh Marvasti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2210.03469"
  },
  {
    "id": "arXiv:2210.03475",
    "title": "Population-Based Reinforcement Learning for Combinatorial Optimization",
    "abstract": "Applying reinforcement learning (RL) to combinatorial optimization problems\nis attractive as it removes the need for expert knowledge or pre-solved\ninstances. However, it is unrealistic to expect an agent to solve these (often\nNP-)hard problems in a single shot at inference due to their inherent\ncomplexity. Thus, leading approaches often implement additional search\nstrategies, from stochastic sampling and beam-search to explicit fine-tuning.\nIn this paper, we argue for the benefits of learning a population of\ncomplementary policies, which can be simultaneously rolled out at inference. To\nthis end, we introduce Poppy, a simple theoretically grounded training\nprocedure for populations. Instead of relying on a predefined or hand-crafted\nnotion of diversity, Poppy induces an unsupervised specialization targeted\nsolely at maximizing the performance of the population. We show that Poppy\nproduces a set of complementary policies, and obtains state-of-the-art RL\nresults on three popular NP-hard problems: the traveling salesman (TSP), the\ncapacitated vehicle routing (CVRP), and 0-1 knapsack (KP) problems. On TSP\nspecifically, Poppy outperforms the previous state-of-the-art, dividing the\noptimality gap by 5 while reducing the inference time by more than an order of\nmagnitude.",
    "descriptor": "",
    "authors": [
      "Nathan Grinsztajn",
      "Daniel Furelos-Blanco",
      "Thomas D. Barrett"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03475"
  },
  {
    "id": "arXiv:2210.03477",
    "title": "IDa-Det: An Information Discrepancy-aware Distillation for 1-bit  Detectors",
    "abstract": "Knowledge distillation (KD) has been proven to be useful for training compact\nobject detection models. However, we observe that KD is often effective when\nthe teacher model and student counterpart share similar proposal information.\nThis explains why existing KD methods are less effective for 1-bit detectors,\ncaused by a significant information discrepancy between the real-valued teacher\nand the 1-bit student. This paper presents an Information Discrepancy-aware\nstrategy (IDa-Det) to distill 1-bit detectors that can effectively eliminate\ninformation discrepancies and significantly reduce the performance gap between\na 1-bit detector and its real-valued counterpart. We formulate the distillation\nprocess as a bi-level optimization formulation. At the inner level, we select\nthe representative proposals with maximum information discrepancy. We then\nintroduce a novel entropy distillation loss to reduce the disparity based on\nthe selected proposals. Extensive experiments demonstrate IDa-Det's superiority\nover state-of-the-art 1-bit detectors and KD methods on both PASCAL VOC and\nCOCO datasets. IDa-Det achieves a 76.9% mAP for a 1-bit Faster-RCNN with\nResNet-18 backbone. Our code is open-sourced on\nhttps://github.com/SteveTsui/IDa-Det.",
    "descriptor": "",
    "authors": [
      "Sheng Xu",
      "Yanjing Li",
      "Bohan Zeng",
      "Teli ma",
      "Baochang Zhang",
      "Xianbin Cao",
      "Peng Gao",
      "Jinhu Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03477"
  },
  {
    "id": "arXiv:2210.03478",
    "title": "On the extended randomized multiple row method for solving linear  least-squares problems",
    "abstract": "The randomized row method is a popular representative of the iterative\nalgorithm because of its efficiency in solving the overdetermined and\nconsistent systems of linear equations. In this paper, we present an extended\nrandomized multiple row method to solve a given overdetermined and inconsistent\nlinear system and analyze its computational complexities at each iteration. We\nprove that the proposed method can linearly converge in the mean square to the\nleast-squares solution with a minimum Euclidean norm. Several numerical studies\nare presented to corroborate our theoretical findings. The real-world\napplications, such as image reconstruction and large noisy data fitting in\ncomputer-aided geometric design, are also presented for illustration purposes.",
    "descriptor": "",
    "authors": [
      "Nian-Ci Wu",
      "Chengzhi Liu",
      "Yatian Wang",
      "Qian Zuo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03478"
  },
  {
    "id": "arXiv:2210.03479",
    "title": "Hate Speech and Offensive Language Detection in Bengali",
    "abstract": "Social media often serves as a breeding ground for various hateful and\noffensive content. Identifying such content on social media is crucial due to\nits impact on the race, gender, or religion in an unprejudiced society.\nHowever, while there is extensive research in hate speech detection in English,\nthere is a gap in hateful content detection in low-resource languages like\nBengali. Besides, a current trend on social media is the use of Romanized\nBengali for regular interactions. To overcome the existing research's\nlimitations, in this study, we develop an annotated dataset of 10K Bengali\nposts consisting of 5K actual and 5K Romanized Bengali tweets. We implement\nseveral baseline models for the classification of such hateful posts. We\nfurther explore the interlingual transfer mechanism to boost classification\nperformance. Finally, we perform an in-depth error analysis by looking into the\nmisclassified posts by the models. While training actual and Romanized datasets\nseparately, we observe that XLM-Roberta performs the best. Further, we witness\nthat on joint training and few-shot training, MuRIL outperforms other models by\ninterpreting the semantic expressions better. We make our code and dataset\npublic for others.",
    "descriptor": "\nComments: Accepted at AACL-IJCNLP 2022\n",
    "authors": [
      "Mithun Das",
      "Somnath Banerjee",
      "Punyajoy Saha",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03479"
  },
  {
    "id": "arXiv:2210.03481",
    "title": "Neighbor Regularized Bayesian Optimization for Hyperparameter  Optimization",
    "abstract": "Bayesian Optimization (BO) is a common solution to search optimal\nhyperparameters based on sample observations of a machine learning model.\nExisting BO algorithms could converge slowly even collapse when the potential\nobservation noise misdirects the optimization. In this paper, we propose a\nnovel BO algorithm called Neighbor Regularized Bayesian Optimization (NRBO) to\nsolve the problem. We first propose a neighbor-based regularization to smooth\neach sample observation, which could reduce the observation noise efficiently\nwithout any extra training cost. Since the neighbor regularization highly\ndepends on the sample density of a neighbor area, we further design a\ndensity-based acquisition function to adjust the acquisition reward and obtain\nmore stable statistics. In addition, we design a adjustment mechanism to ensure\nthe framework maintains a reasonable regularization strength and density reward\nconditioned on remaining computation resources. We conduct experiments on the\nbayesmark benchmark and important computer vision benchmarks such as ImageNet\nand COCO. Extensive experiments demonstrate the effectiveness of NRBO and it\nconsistently outperforms other state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by BMVC 2022\n",
    "authors": [
      "Lei Cui",
      "Yangguang Li",
      "Xin Lu",
      "Dong An",
      "Fenggang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03481"
  },
  {
    "id": "arXiv:2210.03482",
    "title": "CLAD: A realistic Continual Learning benchmark for Autonomous Driving",
    "abstract": "In this paper we describe the design and the ideas motivating a new Continual\nLearning benchmark for Autonomous Driving (CLAD), that focuses on the problems\nof object classification and object detection. The benchmark utilises SODA10M,\na recently released large-scale dataset that concerns autonomous driving\nrelated problems. First, we review and discuss existing continual learning\nbenchmarks, how they are related, and show that most are extreme cases of\ncontinual learning. To this end, we survey the benchmarks used in continual\nlearning papers at three highly ranked computer vision conferences. Next, we\nintroduce CLAD-C, an online classification benchmark realised through a\nchronological data stream that poses both class and domain incremental\nchallenges; and CLAD-D, a domain incremental continual object detection\nbenchmark. We examine the inherent difficulties and challenges posed by the\nbenchmark, through a survey of the techniques and methods used by the top-3\nparticipants in a CLAD-challenge workshop at ICCV 2021. We conclude with\npossible pathways to improve the current continual learning state of the art,\nand which directions we deem promising for future research.",
    "descriptor": "",
    "authors": [
      "Eli Verwimp",
      "Kuo Yang",
      "Sarah Parisot",
      "Hong Lanqing",
      "Steven McDonagh",
      "Eduardo P\u00e9rez-Pellitero",
      "Matthias De Lange",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03482"
  },
  {
    "id": "arXiv:2210.03485",
    "title": "Gradient-based optimisation of the conditional-value-at-risk using the  multi-level Monte Carlo method",
    "abstract": "In this work, we tackle the problem of minimising the\nConditional-Value-at-Risk (CVaR) of output quantities of complex differential\nmodels with random input data, using gradient-based approaches in combination\nwith the Multi-Level Monte Carlo (MLMC) method. In particular, we consider the\nframework of multi-level Monte Carlo for parametric expectations and propose\nmodifications of the MLMC estimator, error estimation procedure, and adaptive\nMLMC parameter selection to ensure the estimation of the CVaR and sensitivities\nfor a given design with a prescribed accuracy. We then propose combining the\nMLMC framework with an alternating inexact minimisation-gradient descent\nalgorithm, for which we prove exponential convergence in the optimisation\niterations under the assumptions of strong convexity and Lipschitz continuity\nof the gradient of the objective function. We demonstrate the performance of\nour approach on two numerical examples of practical relevance, which evidence\nthe same optimal asymptotic cost-tolerance behaviour as standard MLMC methods\nfor fixed design computations of output expectations.",
    "descriptor": "\nComments: 26 pages, 18 figures, 1 table, Related to arXiv:2208.07252\n",
    "authors": [
      "Sundar Ganesh",
      "Fabio Nobile"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03485"
  },
  {
    "id": "arXiv:2210.03493",
    "title": "Automatic Chain of Thought Prompting in Large Language Models",
    "abstract": "Large language models (LLMs) can perform complex reasoning by generating\nintermediate reasoning steps. Providing these steps for prompting\ndemonstrations is called chain-of-thought (CoT) prompting. CoT prompting has\ntwo major paradigms. One leverages a simple prompt like \"Let's think step by\nstep\" to facilitate step-by-step thinking before answering a question. The\nother uses a few manual demonstrations one by one, each composed of a question\nand a reasoning chain that leads to an answer. The superior performance of the\nsecond paradigm hinges on the hand-crafting of task-specific demonstrations one\nby one. We show that such manual efforts may be eliminated by leveraging LLMs\nwith the \"Let's think step by step\" prompt to generate reasoning chains for\ndemonstrations one by one, i.e., let's think not just step by step, but also\none by one. However, these generated chains often come with mistakes. To\nmitigate the effect of such mistakes, we find that diversity matters for\nautomatically constructing demonstrations. We propose an automatic CoT\nprompting method: Auto-CoT. It samples questions with diversity and generates\nreasoning chains to construct demonstrations. On ten public benchmark reasoning\ntasks with GPT-3, Auto-CoT consistently matches or exceeds the performance of\nthe CoT paradigm that requires manual designs of demonstrations. Code is\navailable at https://github.com/amazon-research/auto-cot",
    "descriptor": "",
    "authors": [
      "Zhuosheng Zhang",
      "Aston Zhang",
      "Mu Li",
      "Alex Smola"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03493"
  },
  {
    "id": "arXiv:2210.03495",
    "title": "Total Variation-Based Reconstruction and Phase Retrieval for Diffraction  Tomography with an Arbitrarily Moving Object",
    "abstract": "We consider the imaging problem of the reconstruction of a three-dimensional\nobject via optical diffraction tomography under the assumptions of the Born\napproximation. Our focus lies in the situation that a rigid object performs an\nirregular, time-dependent rotation under acoustical or optical forces. In this\nstudy, we compare reconstruction algorithms in case i) that two-dimensional\nimages of the complex-valued wave are known, or ii) that only the intensity\n(absolute value) of these images can be measured, which is the case in many\npractical setups. The latter phase-retrieval problem can be solved by an\nall-at-once approach based utilizing a hybrid input-output scheme with TV\nregularization.",
    "descriptor": "",
    "authors": [
      "Robert Beinert",
      "Michael Quellmalz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03495"
  },
  {
    "id": "arXiv:2210.03496",
    "title": "PCAE: A Framework of Plug-in Conditional Auto-Encoder for Controllable  Text Generation",
    "abstract": "Controllable text generation has taken a gigantic step forward these days.\nYet existing methods are either constrained in a one-off pattern or not\nefficient enough for receiving multiple conditions at every generation stage.\nWe propose a model-agnostic framework Plug-in Conditional Auto-Encoder for\nControllable Text Generation (PCAE) towards flexible and semi-supervised text\ngeneration. Our framework is \"plug-and-play\" with partial parameters to be\nfine-tuned in the pre-trained model (less than a half). Crucial to the success\nof PCAE is the proposed broadcasting label fusion network for navigating the\nglobal latent code to a specified local and confined space. Visualization of\nthe local latent prior well confirms the primary devotion in hidden space of\nthe proposed model. Moreover, extensive experiments across five related\ngeneration tasks (from 2 conditions up to 10 conditions) on both RNN- based and\npre-trained BART [26] based auto-encoders reveal the high capability of PCAE,\nwhich enables generation that is highly manipulable, syntactically diverse and\ntime-saving with minimum labeled samples. We will release our code at\nhttps://github.com/ImKeTT/pcae.",
    "descriptor": "\nComments: Knowledge-Based Systems\n",
    "authors": [
      "Haoqin Tu",
      "Zhongliang Yang",
      "Jinshuai Yang",
      "Siyu Zhang",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03496"
  },
  {
    "id": "arXiv:2210.03497",
    "title": "When one Logic is Not Enough: Integrating First-order Annotations in OWL  Ontologies",
    "abstract": "In ontology development, there is a gap between domain ontologies which\nmostly use the web ontology language, OWL, and foundational ontologies written\nin first-order logic, FOL. To bridge this gap, we present Gavel, a tool that\nsupports the development of heterogeneous 'FOWL' ontologies that extend OWL\nwith FOL annotations, and is able to reason over the combined set of axioms.\nSince FOL annotations are stored in OWL annotations, FOWL ontologies remain\ncompatible with the existing OWL infrastructure. We show that for the OWL\ndomain ontology OBI, the stronger integration with its FOL top-level ontology\nBFO via our approach enables us to detect several inconsistencies. Furthermore,\nexisting OWL ontologies can benefit from FOL annotations. We illustrate this\nwith FOWL ontologies containing mereotopological axioms that enable new\nmeaningful inferences. Finally, we show that even for large domain ontologies\nsuch as ChEBI, automatic reasoning with FOL annotations can be used to detect\npreviously unnoticed errors in the classification.",
    "descriptor": "",
    "authors": [
      "Simon Fl\u00fcgel",
      "Martin Glauer",
      "Fabian Neuhaus",
      "Janna Hastings"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.03497"
  },
  {
    "id": "arXiv:2210.03499",
    "title": "How reliable are unsupervised author disambiguation algorithms in the  assessment of research organization performance?",
    "abstract": "The paper examines extent of bias in the performance rankings of research\norganisations when the assessments are based on unsupervised author-name\ndisambiguation algorithms. It compares the outcomes of a research performance\nevaluation exercise of Italian universities using the unsupervised approach by\nCaron and van Eck (2014) for derivation of the universities' research staff,\nwith those of a benchmark using the supervised algorithm of D'Angelo,\nGiuffrida, and Abramo (2011), which avails of input data. The methodology\ndeveloped could be replicated for comparative analyses in other frameworks of\nnational or international interest, meaning that practitioners would have a\nprecise measure of the extent of distortions inherent in any evaluation\nexercises using unsupervised algorithms. This could in turn be useful in\ninforming policy-makers' decisions on whether to invest in building national\nresearch staff databases, instead of settling for the unsupervised approaches\nwith their measurement biases.",
    "descriptor": "",
    "authors": [
      "Giovanni Abramo",
      "Ciriaco Andrea D'Angelo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.03499"
  },
  {
    "id": "arXiv:2210.03501",
    "title": "Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity  Modeling with Knowledge Enhancement",
    "abstract": "Sarcasm is a linguistic phenomenon indicating a discrepancy between literal\nmeanings and implied intentions. Due to its sophisticated nature, it is usually\nchallenging to be detected from the text itself. As a result, multi-modal\nsarcasm detection has received more attention in both academia and industries.\nHowever, most existing techniques only modeled the atomic-level inconsistencies\nbetween the text input and its accompanying image, ignoring more complex\ncompositions for both modalities. Moreover, they neglected the rich information\ncontained in external knowledge, e.g., image captions. In this paper, we\npropose a novel hierarchical framework for sarcasm detection by exploring both\nthe atomic-level congruity based on multi-head cross attention mechanism and\nthe composition-level congruity based on graph neural networks, where a post\nwith low congruity can be identified as sarcasm. In addition, we exploit the\neffect of various knowledge resources for sarcasm detection. Evaluation results\non a public multi-modal sarcasm detection dataset based on Twitter demonstrate\nthe superiority of our proposed model.",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03501"
  },
  {
    "id": "arXiv:2210.03505",
    "title": "Private and Efficient Meta-Learning with Low Rank and Sparse  Decomposition",
    "abstract": "Meta-learning is critical for a variety of practical ML systems -- like\npersonalized recommendations systems -- that are required to generalize to new\ntasks despite a small number of task-specific training points. Existing\nmeta-learning techniques use two complementary approaches of either learning a\nlow-dimensional representation of points for all tasks, or task-specific\nfine-tuning of a global model trained using all the tasks. In this work, we\npropose a novel meta-learning framework that combines both the techniques to\nenable handling of a large number of data-starved tasks. Our framework models\nnetwork weights as a sum of low-rank and sparse matrices. This allows us to\ncapture information from multiple domains together in the low-rank part while\nstill allowing task specific personalization using the sparse part. We\ninstantiate and study the framework in the linear setting, where the problem\nreduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse\nmatrix using a small number of linear measurements. We propose an alternating\nminimization method with hard thresholding -- AMHT-LRS -- to learn the low-rank\nand sparse part effectively and efficiently. For the realizable, Gaussian data\nsetting, we show that AMHT-LRS indeed solves the problem efficiently with\nnearly optimal samples. We extend AMHT-LRS to ensure that it preserves privacy\nof each individual user in the dataset, while still ensuring strong\ngeneralization with nearly optimal number of samples. Finally, on multiple\ndatasets, we demonstrate that the framework allows personalized models to\nobtain superior performance in the data-scarce regime.",
    "descriptor": "\nComments: 97 pages, 3 figures\n",
    "authors": [
      "Soumyabrata Pal",
      "Prateek Varshney",
      "Prateek Jain",
      "Abhradeep Guha Thakurta",
      "Gagan Madan",
      "Gaurav Aggarwal",
      "Pradeep Shenoy",
      "Gaurav Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03505"
  },
  {
    "id": "arXiv:2210.03506",
    "title": "What Do End-Users Really Want? Investigation of Human-Centered XAI for  Mobile Health Apps",
    "abstract": "In healthcare, AI systems support clinicians and patients in diagnosis,\ntreatment, and monitoring, but many systems' poor explainability remains\nchallenging for practical application. Overcoming this barrier is the goal of\nexplainable AI (XAI). However, an explanation can be perceived differently and,\nthus, not solve the black-box problem for everyone. The domain of\nHuman-Centered AI deals with this problem by adapting AI to users. We present a\nuser-centered persona concept to evaluate XAI and use it to investigate\nend-users preferences for various explanation styles and contents in a mobile\nhealth stress monitoring application. The results of our online survey show\nthat users' demographics and personality, as well as the type of explanation,\nimpact explanation preferences, indicating that these are essential features\nfor XAI design. We subsumed the results in three prototypical user personas:\npower-, casual-, and privacy-oriented users. Our insights bring an interactive,\nhuman-centered XAI closer to practical application.",
    "descriptor": "",
    "authors": [
      "Katharina Weitz",
      "Alexander Zellner",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03506"
  },
  {
    "id": "arXiv:2210.03510",
    "title": "Learning to Learn and Sample BRDFs",
    "abstract": "We propose a method to accelerate the joint process of physically acquiring\nand learning neural Bi-directional Reflectance Distribution Function (BRDF)\nmodels. While BRDF learning alone can be accelerated by meta-learning,\nacquisition remains slow as it relies on a mechanical process. We show that\nmeta-learning can be extended to optimize the physical sampling pattern, too.\nAfter our method has been meta-trained for a set of fully-sampled BRDFs, it is\nable to quickly train on new BRDFs with up to five orders of magnitude fewer\nphysical acquisition samples at similar quality. Our approach also extends to\nother linear and non-linear BRDF models, which we show in an extensive\nevaluation.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Michael Fischer",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03510"
  },
  {
    "id": "arXiv:2210.03512",
    "title": "Inferring Smooth Control: Monte Carlo Posterior Policy Iteration with  Gaussian Processes",
    "abstract": "Monte Carlo methods have become increasingly relevant for control of\nnon-differentiable systems, approximate dynamics models and learning from data.\nThese methods scale to high-dimensional spaces and are effective at the\nnon-convex optimizations often seen in robot learning. We look at sample-based\nmethods from the perspective of inference-based control, specifically posterior\npolicy iteration. From this perspective, we highlight how Gaussian noise priors\nproduce rough control actions that are unsuitable for physical robot\ndeployment. Considering smoother Gaussian process priors, as used in episodic\nreinforcement learning and motion planning, we demonstrate how smoother model\npredictive control can be achieved using online sequential inference. This\ninference is realized through an efficient factorization of the action\ndistribution and a novel means of optimizing the likelihood temperature to\nimprove importance sampling accuracy. We evaluate this approach on several\nhigh-dimensional robot control tasks, matching the sample efficiency of prior\nheuristic methods while also ensuring smoothness. Simulation results can be\nseen at https://monte-carlo-ppi.github.io/.",
    "descriptor": "\nComments: 43 pages, 37 figures. Conference on Robot Learning 2022\n",
    "authors": [
      "Joe Watson",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03512"
  },
  {
    "id": "arXiv:2210.03515",
    "title": "Spiking neural network for nonlinear regression",
    "abstract": "Spiking neural networks, also often referred to as the third generation of\nneural networks, carry the potential for a massive reduction in memory and\nenergy consumption over traditional, second-generation neural networks.\nInspired by the undisputed efficiency of the human brain, they introduce\ntemporal and neuronal sparsity, which can be exploited by next-generation\nneuromorphic hardware. To open the pathway toward engineering applications, we\nintroduce this exciting technology in the context of continuum mechanics.\nHowever, the nature of spiking neural networks poses a challenge for regression\nproblems, which frequently arise in the modeling of engineering sciences. To\novercome this problem, a framework for regression using spiking neural networks\nis proposed. In particular, a network topology for decoding binary spike trains\nto real numbers is introduced, utilizing the membrane potential of spiking\nneurons. As the aim of this contribution is a concise introduction to this new\nmethodology, several different spiking neural architectures, ranging from\nsimple spiking feed-forward to complex spiking long short-term memory neural\nnetworks, are derived. Several numerical experiments directed towards\nregression of linear and nonlinear, history-dependent material models are\ncarried out. A direct comparison with counterparts of traditional neural\nnetworks shows that the proposed framework is much more efficient while\nretaining precision and generalizability. All code has been made publicly\navailable in the interest of reproducibility and to promote continued\nenhancement in this new domain.",
    "descriptor": "",
    "authors": [
      "Alexander Henkes",
      "Jason K. Eshraghian",
      "Henning Wessels"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03515"
  },
  {
    "id": "arXiv:2210.03516",
    "title": "Neuroevolution is a Competitive Alternative to Reinforcement Learning  for Skill Discovery",
    "abstract": "Deep Reinforcement Learning (RL) has emerged as a powerful paradigm for\ntraining neural policies to solve complex control tasks. However, these\npolicies tend to be overfit to the exact specifications of the task and\nenvironment they were trained on, and thus do not perform well when conditions\ndeviate slightly or when composed hierarchically to solve even more complex\ntasks. Recent work has shown that training a mixture of policies, as opposed to\na single one, that are driven to explore different regions of the state-action\nspace can address this shortcoming by generating a diverse set of behaviors,\nreferred to as skills, that can be collectively used to great effect in\nadaptation tasks or for hierarchical planning. This is typically realized by\nincluding a diversity term - often derived from information theory - in the\nobjective function optimized by RL. However these approaches often require\ncareful hyperparameter tuning to be effective. In this work, we demonstrate\nthat less widely-used neuroevolution methods, specifically Quality Diversity\n(QD), are a competitive alternative to information-theory-augmented RL for\nskill discovery. Through an extensive empirical evaluation comparing eight\nstate-of-the-art methods on the basis of (i) metrics directly evaluating the\nskills' diversity, (ii) the skills' performance on adaptation tasks, and (iii)\nthe skills' performance when used as primitives for hierarchical planning; QD\nmethods are found to provide equal, and sometimes improved, performance whilst\nbeing less sensitive to hyperparameters and more scalable. As no single method\nis found to provide near-optimal performance across all environments, there is\na rich scope for further research which we support by proposing future\ndirections and providing optimized open-source implementations.",
    "descriptor": "",
    "authors": [
      "Felix Chalumeau",
      "Raphael Boige",
      "Bryan Lim",
      "Valentin Mac\u00e9",
      "Maxime Allard",
      "Arthur Flajolet",
      "Antoine Cully",
      "Thomas Pierrot"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03516"
  },
  {
    "id": "arXiv:2210.03517",
    "title": "Fairness in generative modeling",
    "abstract": "We design general-purpose algorithms for addressing fairness issues and mode\ncollapse in generative modeling. More precisely, to design fair algorithms for\nas many sensitive variables as possible, including variables we might not be\naware of, we assume no prior knowledge of sensitive variables: our algorithms\nuse unsupervised fairness only, meaning no information related to the sensitive\nvariables is used for our fairness-improving methods. All images of faces (even\ngenerated ones) have been removed to mitigate legal risks.",
    "descriptor": "",
    "authors": [
      "Mariia Zameshina",
      "Olivier Teytaud",
      "Fabien Teytaud",
      "Vlad Hosu",
      "Nathanael Carraz",
      "Laurent Najman",
      "Markus Wagner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03517"
  },
  {
    "id": "arXiv:2210.03518",
    "title": "LGTBIDS: Layer-wise Graph Theory Based Intrusion Detection System in  Beyond 5G",
    "abstract": "The advancement in wireless communication technologies is becoming more\ndemanding and pervasive. One of the fundamental parameters that limit the\nefficiency of the network are the security challenges. The communication\nnetwork is vulnerable to security attacks such as spoofing attacks and signal\nstrength attacks. Intrusion detection signifies a central approach to ensuring\nthe security of the communication network. In this paper, an Intrusion\nDetection System based on the framework of graph theory is proposed. A\nLayerwise Graph Theory-Based Intrusion Detection System (LGTBIDS) algorithm is\ndesigned to detect the attacked node. The algorithm performs the layer-wise\nanalysis to extract the vulnerable nodes and ultimately the attacked node(s).\nFor each layer, every node is scanned for the possibility of susceptible\nnode(s). The strategy of the IDS is based on the analysis of energy efficiency\nand secrecy rate. The nodes with the energy efficiency and secrecy rate beyond\nthe range of upper and lower thresholds are detected as the nodes under attack.\nFurther, detected node(s) are transmitted with a random sequence of bits\nfollowed by the process of re-authentication. The obtained results validate the\nbetter performance, low time computations, and low complexity. Finally, the\nproposed approach is compared with the conventional solution of intrusion\ndetection.",
    "descriptor": "\nComments: in IEEE Transactions on Network and Service Management, 2022\n",
    "authors": [
      "Misbah Shafi",
      "Rakesh Kumar Jha",
      "Sanjeev Jain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03518"
  },
  {
    "id": "arXiv:2210.03519",
    "title": "An Empirical Studies on How the Developers Discussed about Pandas Topics",
    "abstract": "Pandas is defined as a software library which is used for data analysis in\nPython programming language. As pandas is a fast, easy and open source data\nanalysis tool, it is rapidly used in different software engineering projects\nlike software development, machine learning, computer vision, natural language\nprocessing, robotics, and others. So a huge interests are shown in software\ndevelopers regarding pandas and a huge number of discussions are now becoming\ndominant in online developer forums, like Stack Overflow (SO). Such discussions\ncan help to understand the popularity of pandas library and also can help to\nunderstand the importance, prevalence, difficulties of pandas topics. The main\naim of this research paper is to find the popularity and difficulty of pandas\ntopics. For this regard, SO posts are collected which are related to pandas\ntopic discussions. Topic modeling are done on the textual contents of the\nposts. We found 26 topics which we further categorized into 5 board categories.\nWe observed that developers discuss variety of pandas topics in SO related to\nerror and excepting handling, visualization, External support, dataframe, and\noptimization. In addition, a trend chart is generated according to the\ndiscussion of topics in a predefined time series. The finding of this paper can\nprovide a path to help the developers, educators and learners. For example,\nbeginner developers can learn most important topics in pandas which are\nessential for develop any model. Educators can understand the topics which seem\nhard to learners and can build different tutorials which can make that pandas\ntopic understandable. From this empirical study it is possible to understand\nthe preferences of developers in pandas topic by processing their SO posts",
    "descriptor": "",
    "authors": [
      "Sajib Kumar Saha Joy",
      "Farzad Ahmed",
      "Al Hasib Mahamud",
      "Nibir Chandra Mandal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03519"
  },
  {
    "id": "arXiv:2210.03520",
    "title": "Exploring the Relationships between Privacy by Design Schemes and  Privacy Laws: A Comparative Analysis",
    "abstract": "Internet of Things (IoT) applications have the potential to derive sensitive\ninformation about individuals. Therefore, developers must exercise due\ndiligence to make sure that data are managed according to the privacy\nregulations and data protection laws. However, doing so can be a difficult and\nchallenging task. Recent research has revealed that developers typically face\ndifficulties when complying with regulations. One key reason is that, at times,\nregulations are vague, and could be challenging to extract and enact such legal\nrequirements. In our research paper, we have conducted a systematic analysis of\nthe data protection laws that are used across different continents, namely: (i)\nGeneral Data Protection Regulations (GDPR), (ii) the Personal Information\nProtection and Electronic Documents Act (PIPEDA), (iii) the California Consumer\nPrivacy Act (CCPA), (iv) Australian Privacy Principles (APPs), and (v) New\nZealand's Privacy Act 1993. In this technical report, we presented the detailed\nresults of the conducted framework analysis method to attain a comprehensive\nview of different data protection laws and highlighted the disparities, in\norder to assist developers in adhering to the regulations across different\nregions, along with creating a Combined Privacy Law Framework (CPLF). After\nthat, we gave an overview of various Privacy by Design (PbD) schemes developed\npreviously by different researchers. Then, the key principles and individuals'\nrights of the CPLF were mapped with the privacy principles, strategies,\nguidelines, and patterns of the Privacy by Design (PbD) schemes in order to\ninvestigate the gaps in existing schemes.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Atheer Aljeraisy",
      "Masoud Barati",
      "Omer Rana",
      "Charith Perera"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03520"
  },
  {
    "id": "arXiv:2210.03521",
    "title": "HetSyn: Speeding Up Local SGD with Heterogeneous Synchronization",
    "abstract": "Synchronous local stochastic gradient descent (local SGD) suffers from some\nworkers being idle and random delays due to slow and straggling workers, as it\nwaits for the workers to complete the same amount of local updates. In this\npaper, to mitigate stragglers and improve communication efficiency, a novel\nlocal SGD strategy, named HetSyn, is developed. The key point is to keep all\nthe workers computing continually at each synchronization round, and make full\nuse of any effective (completed) local update of each worker regardless of\nstragglers. An analysis of the average wall-clock time, average number of local\nupdates and average number of uploading workers per round is provided to gauge\nthe performance of HetSyn. The convergence of HetSyn is also rigorously\nestablished even when the objective function is nonconvex. Experimental results\nshow the superiority of the proposed HetSyn against state-of-the-art schemes\nthrough utilization of additional effective local updates at each worker, and\nthe influence of system parameters is studied. By allowing heterogeneous\nsynchronization with different numbers of local updates across workers, HetSyn\nprovides substantial improvements both in time and communication efficiency.",
    "descriptor": "\nComments: 12 pages, 10 figures, submitted for transaction publication\n",
    "authors": [
      "Feng Zhu",
      "Jingjing Zhang",
      "Xin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03521"
  },
  {
    "id": "arXiv:2210.03523",
    "title": "Truncation Error-Based Anisotropic $p$-Adaptation for Unsteady Flows for  High-Order Discontinuous Galerkin Methods",
    "abstract": "In this work, we extend the $\\tau$-estimation method to unsteady problems and\nuse it to adapt the polynomial degree for high-order discontinuous Galerkin\nsimulations of unsteady flows. The adaptation is local and anisotropic and\nallows capturing relevant unsteady flow features while enhancing the accuracy\nof time evolving functionals (e.g., lift, drag). To achieve an efficient and\nunsteady truncation error-based $p$-adaptation scheme, we first revisit the\ndefinition of the truncation error, studying the effect of the treatment of the\nmass matrix arising from the temporal term. Secondly, we extend the\n$\\tau$-estimation strategy to unsteady problems. Finally, we present and\ncompare two adaptation strategies for unsteady problems: the dynamic and static\n$p$-adaptation methods. In the first one (dynamic) the error is measured\nperiodically during a simulation and the polynomial degree is adapted\nimmediately after every estimation procedure. In the second one (static) the\nerror is also measured periodically, but only one $p$-adaptation process is\nperformed after several estimation stages, using a combination of the periodic\nerror measures. The static $p$-adaptation strategy is suitable for\ntime-periodic flows, while the dynamic one can be generalized to any flow\nevolution.\nWe consider two test cases to evaluate the efficiency of the proposed\n$p$-adaptation strategies. The first one considers the compressible Euler\nequations to simulate the advection of a density pulse. The second one solves\nthe compressible Navier-Stokes equations to simulate the flow around a cylinder\nat Re=100. The local and anisotropic adaptation enables significant reductions\nin the number of degrees of freedom with respect to uniform refinement, leading\nto speed-ups of up to $\\times4.5$ for the Euler test case and $\\times2.2$ for\nthe Navier-Stokes test case.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s M. Rueda-Ram\u00edrez",
      "Gerasimos Ntoukas",
      "Gonzalo Rubio",
      "Eusebio Valero",
      "Esteban Ferrer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.03523"
  },
  {
    "id": "arXiv:2210.03524",
    "title": "Variability in electricity consumption by category of consumer: the  impact on electricity load profiles",
    "abstract": "Residential electrification of transport and heat is changing consumption and\nits characteristics significantly. Previous studies have demonstrated the\nimpact of socio-techno-economic determinants on residential consumption.\nHowever, they fail to capture the distributional characteristics of such\nconsumer groups, which impact network planning and flexibility assessment.\nUsing actual residential electricity consumption profile data for 720,000\nhouseholds in Denmark, we demonstrate that heat pumps are more likely to\ninfluence aggregated peak consumption than electric vehicles. At the same time,\nother socio-economic factors, such as occupancy, dwelling area and income, show\nlittle impact. Comparing the extrapolation of a comprehensive rollout of heat\npumps or electric vehicles indicates that the most common consumer category\ndeploying heat pumps has 14% more maximum consumption during peak load hours,\n46% more average consumption and twice the higher median compared to households\nowning an electric vehicle. Electric vehicle show already flexibility with\ncoincidence factors that ranges between 5-15% with a maximum of 17% whereas\nheat pumps are mostly baseload. The detailed and holistic outcomes of this\nstudy support flexibility assessment and grid planning in future studies but\nalso the operation of flexible technologies.",
    "descriptor": "\nComments: 37 pages, 18 figures, journal article\n",
    "authors": [
      "Philipp Andreas Gunkel",
      "Henrik Klinge Jacobsen",
      "Claire-Marie Bergaentzl\u00e9",
      "Fabian Scheller",
      "Frits M\u00f8ller Andersen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03524"
  },
  {
    "id": "arXiv:2210.03525",
    "title": "Polytopal templates for the formulation of semi-continuous vectorial  finite elements of arbitrary order",
    "abstract": "The Hilbert spaces $H(\\mathrm{curl})$ and $H(\\mathrm{div})$ are needed for\nvariational problems formulated in the context of the de Rham complex in order\nto guarantee well-posedness. Consequently, the construction of conforming\nsubspaces is a crucial step in the formulation of viable numerical solutions.\nAlternatively to the standard definition of a finite element as per Ciarlet,\ngiven by the triplet of a domain, a polynomial space and degrees of freedom,\nthis work aims to introduce a novel, simple method of directly constructing\nsemi-continuous vectorial base functions on the reference element via polytopal\ntemplates and an underlying $H^1$-conforming polynomial subspace. The base\nfunctions are then mapped from the reference element to the element in the\nphysical domain via consistent Piola transformations. The method is defined in\nsuch a way, that the underlying $H^1$-conforming subspace can be chosen\nindependently, thus allowing for constructions of arbitrary polynomial order.\nThe base functions arise by multiplication of the basis with template vectors\ndefined for each polytope of the reference element. We prove a unisolvent\nconstruction of N\\'ed\\'elec elements of the first and second type,\nBrezzi-Douglas-Marini elements, and Raviart-Thomas elements. An application for\nthe method is demonstrated with two examples in the relaxed micromorphic model",
    "descriptor": "",
    "authors": [
      "Adam Sky",
      "Ingo Muench"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03525"
  },
  {
    "id": "arXiv:2210.03526",
    "title": "A Unified Hard-Constraint Framework for Solving Geometrically Complex  PDEs",
    "abstract": "We present a unified hard-constraint framework for solving geometrically\ncomplex PDEs with neural networks, where the most commonly used Dirichlet,\nNeumann, and Robin boundary conditions (BCs) are considered. Specifically, we\nfirst introduce the \"extra fields\" from the mixed finite element method to\nreformulate the PDEs so as to equivalently transform the three types of BCs\ninto linear forms. Based on the reformulation, we derive the general solutions\nof the BCs analytically, which are employed to construct an ansatz that\nautomatically satisfies the BCs. With such a framework, we can train the neural\nnetworks without adding extra loss terms and thus efficiently handle\ngeometrically complex PDEs, alleviating the unbalanced competition between the\nloss terms corresponding to the BCs and PDEs. We theoretically demonstrate that\nthe \"extra fields\" can stabilize the training process. Experimental results on\nreal-world geometrically complex PDEs showcase the effectiveness of our method\ncompared with state-of-the-art baselines.",
    "descriptor": "\nComments: 10 pages, 5 figures, NeurIPS 2022\n",
    "authors": [
      "Songming Liu",
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03526"
  },
  {
    "id": "arXiv:2210.03527",
    "title": "Do We Need Explainable AI in Companies? Investigation of Challenges,  Expectations, and Chances from Employees' Perspective",
    "abstract": "By using AI, companies want to improve their business success and innovation\nchances. However, in doing so, they (companies and their employees) are faced\nwith new requirements. In particular, legal regulations call for transparency\nand comprehensibility of AI systems. The field of XAI deals with these issues.\nCurrently, the results are mostly obtained in lab studies, while the transfer\nto real-world applications is lacking. This includes considering employees'\nneeds and attributes, which may differ from end-users in the lab. Therefore,\nthis project report paper provides initial insights into employees' specific\nneeds and attitudes towards (X)AI. For this, the results of a project's online\nsurvey are reported that investigate two employees' perspectives (i.e., company\nlevel and employee level) on (X)AI to create a holistic view of challenges,\nrisks, and needs of employees. Our findings suggest that AI and XAI are\nwell-known terms perceived as important for employees. This is a first step for\nXAI to be a potential driver to foster the successful usage of AI by providing\ntransparent and comprehensible insights into AI technologies. To benefit from\n(X)AI technologies, supportive employees on the management level are valuable\ncatalysts. This work contributes to the ongoing demand for XAI research to\ndevelop human-centered and domain-specific XAI designs.",
    "descriptor": "\nComments: Project report\n",
    "authors": [
      "Katharina Weitz",
      "Chi Tai Dang",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03527"
  },
  {
    "id": "arXiv:2210.03528",
    "title": "Tractable Optimality in Episodic Latent MABs",
    "abstract": "We consider a multi-armed bandit problem with $M$ latent contexts, where an\nagent interacts with the environment for an episode of $H$ time steps.\nDepending on the length of the episode, the learner may not be able to estimate\naccurately the latent context. The resulting partial observation of the\nenvironment makes the learning task significantly more challenging. Without any\nadditional structural assumptions, existing techniques to tackle partially\nobserved settings imply the decision maker can learn a near-optimal policy with\n$O(A)^H$ episodes, but do not promise more. In this work, we show that learning\nwith {\\em polynomial} samples in $A$ is possible. We achieve this by using\ntechniques from experiment design. Then, through a method-of-moments approach,\nwe design a procedure that provably learns a near-optimal policy with\n$O(\\texttt{poly}(A) + \\texttt{poly}(M,H)^{\\min(M,H)})$ interactions. In\npractice, we show that we can formulate the moment-matching via maximum\nlikelihood estimation. In our experiments, this significantly outperforms the\nworst-case guarantees, as well as existing practical methods.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jeongyeol Kwon",
      "Yonathan Efroni",
      "Constantine Caramanis",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03528"
  },
  {
    "id": "arXiv:2210.03529",
    "title": "Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces",
    "abstract": "Recent advances in synthesizing realistic faces have shown that synthetic\ntraining data can replace real data for various face-related computer vision\ntasks. A question arises: how important is realism? Is the pursuit of\nphotorealism excessive? In this work, we show otherwise. We boost the realism\nof our synthetic faces by introducing dynamic skin wrinkles in response to\nfacial expressions and observe significant performance improvements in\ndownstream computer vision tasks. Previous approaches for producing such\nwrinkles either required prohibitive artist effort to scale across identities\nand expressions or were not capable of reconstructing high-frequency skin\ndetails with sufficient fidelity. Our key contribution is an approach that\nproduces realistic wrinkles across a large and diverse population of digital\nhumans. Concretely, we formalize the concept of mesh-tension and use it to\naggregate possible wrinkles from high-quality expression scans into albedo and\ndisplacement texture maps. At synthesis, we use these maps to produce wrinkles\neven for expressions not represented in the source scans. Additionally, to\nprovide a more nuanced indicator of model performance under deformations\nresulting from compressed expressions, we introduce the 300W-winks evaluation\nsubset and the Pexels dataset of closed eyes and winks.",
    "descriptor": "\nComments: In Proceedings of the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Chirag Raman",
      "Charlie Hewitt",
      "Erroll Wood",
      "Tadas Baltrusaitis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.03529"
  },
  {
    "id": "arXiv:2210.03534",
    "title": "A Quantitative Theory of Bottleneck Structures for Data Networks",
    "abstract": "The conventional view of the congestion control problem in data networks is\nbased on the principle that a flow's performance is uniquely determined by the\nstate of its bottleneck link, regardless of the topological properties of the\nnetwork. However, recent work has shown that the behavior of\ncongestion-controlled networks is better explained by models that account for\nthe interactions between bottleneck links. These interactions are captured by a\nlatent \\textit{bottleneck structure}, a model describing the complex ripple\neffects that changes in one part of the network exert on the other parts. In\nthis paper, we present a \\textit{quantitative} theory of bottleneck structures\n(QTBS), a mathematical and engineering framework comprising a family of\npolynomial-time algorithms that can be used to reason about a wide variety of\nnetwork optimization problems, including routing, capacity planning and flow\ncontrol. QTBS can contribute to traffic engineering by making clear predictions\nabout the relative performance of alternative flow routes, and by providing\nnumerical recommendations for the optimal rate settings of traffic shapers. A\nparticularly novel result in the domain of capacity planning indicates that\npreviously established rules for the design of folded-Clos networks are\nsuboptimal when flows are congestion controlled. We show that QTBS can be used\nto derive the optimal rules for this important class of topologies, and\nempirically demonstrate the correctness and efficacy of these results using the\nBBR and Cubic congestion-control algorithms.",
    "descriptor": "",
    "authors": [
      "Jordi Ros-Giralt",
      "Noah Amsel",
      "Sruthi Yellamraju",
      "James Ezick",
      "Richard Lethin",
      "Yuang Jiang",
      "Aosong Feng",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.03534"
  },
  {
    "id": "arXiv:2210.03535",
    "title": "From plane crashes to algorithmic harm: applicability of safety  engineering frameworks for responsible ML",
    "abstract": "Inappropriate design and deployment of machine learning (ML) systems leads to\nnegative downstream social and ethical impact -- described here as social and\nethical risks -- for users, society and the environment. Despite the growing\nneed to regulate ML systems, current processes for assessing and mitigating\nrisks are disjointed and inconsistent. We interviewed 30 industry practitioners\non their current social and ethical risk management practices, and collected\ntheir first reactions on adapting safety engineering frameworks into their\npractice -- namely, System Theoretic Process Analysis (STPA) and Failure Mode\nand Effects Analysis (FMEA). Our findings suggest STPA/FMEA can provide\nappropriate structure toward social and ethical risk assessment and mitigation\nprocesses. However, we also find nontrivial challenges in integrating such\nframeworks in the fast-paced culture of the ML industry. We call on the ML\nresearch community to strengthen existing frameworks and assess their efficacy,\nensuring that ML systems are safer for all people.",
    "descriptor": "",
    "authors": [
      "Shalaleh Rismani",
      "Renee Shelby",
      "Andrew Smart",
      "Edgar Jatho",
      "Joshua Kroll",
      "AJung Moon",
      "Negar Rostamzadeh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03535"
  },
  {
    "id": "arXiv:2210.03537",
    "title": "Punctured Binary Simplex Codes as LDPC codes",
    "abstract": "Digital data transfer can be protected by means of suitable error correcting\ncodes. Among the families of state-of-the-art codes, LDPC (Low Density\nParity-Check) codes have received a great deal of attention recently, because\nof their performance and flexibility of operation, in wireless and mobile radio\nchannels, as well as in cable transmission systems. In this paper, we present a\nclass of rate-adaptive LDPC codes, obtained as properly punctured simplex\ncodes. These codes allow for the use of an efficient soft-decision decoding\nalgorithm, provided that a condition called row-column constraint is satisfied.\nThis condition is tested on small-length codes, and then extended to\nmedium-length codes. The puncturing operations we apply do not influence the\nsatisfaction of the row-column constraint, assuring that a wide range of code\nrates can be obtained. We can reach code rates remarkably higher than those\nobtainable by the original simplex code, and the price in terms of minimum\ndistance turns out to be relatively small, leading to interesting trade-offs in\nthe resulting asymptotic coding gain.",
    "descriptor": "",
    "authors": [
      "Massimo Battaglioni",
      "Giovanni Cancellieri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03537"
  },
  {
    "id": "arXiv:2210.03538",
    "title": "An Overview of Affective Speech Synthesis and Conversion in the Deep  Learning Era",
    "abstract": "Speech is the fundamental mode of human communication, and its synthesis has\nlong been a core priority in human-computer interaction research. In recent\nyears, machines have managed to master the art of generating speech that is\nunderstandable by humans. But the linguistic content of an utterance\nencompasses only a part of its meaning. Affect, or expressivity, has the\ncapacity to turn speech into a medium capable of conveying intimate thoughts,\nfeelings, and emotions -- aspects that are essential for engaging and\nnaturalistic interpersonal communication. While the goal of imparting\nexpressivity to synthesised utterances has so far remained elusive, following\nrecent advances in text-to-speech synthesis, a paradigm shift is well under way\nin the fields of affective speech synthesis and conversion as well. Deep\nlearning, as the technology which underlies most of the recent advances in\nartificial intelligence, is spearheading these efforts. In the present\noverview, we outline ongoing trends and summarise state-of-the-art approaches\nin an attempt to provide a comprehensive overview of this exciting field.",
    "descriptor": "\nComments: Submitted to the Proceedings of IEEE\n",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Bj\u00f6rn W. Schuller",
      "G\u00f6k\u00e7e \u0130ymen",
      "Metin Sezgin",
      "Xiangheng He",
      "Zijiang Yang",
      "Panagiotis Tzirakis",
      "Shuo Liu",
      "Silvan Mertes",
      "Elisabeth Andr\u00e9",
      "Ruibo Fu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03538"
  },
  {
    "id": "arXiv:2210.03539",
    "title": "Robotic Control Using Model Based Meta Adaption",
    "abstract": "In machine learning, meta-learning methods aim for fast adaptability to\nunknown tasks using prior knowledge. Model-based meta-reinforcement learning\ncombines reinforcement learning via world models with Meta Reinforcement\nLearning (MRL) for increased sample efficiency. However, adaption to unknown\ntasks does not always result in preferable agent behavior. This paper\nintroduces a new Meta Adaptation Controller (MAC) that employs MRL to apply a\npreferred robot behavior from one task to many similar tasks. To do this, MAC\naims to find actions an agent has to take in a new task to reach a similar\noutcome as in a learned task. As a result, the agent will adapt quickly to the\nchange in the dynamic and behave appropriately without the need to construct a\nreward function that enforces the preferred behavior.",
    "descriptor": "",
    "authors": [
      "Karam Daaboul",
      "Joel Ikels",
      "Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03539"
  },
  {
    "id": "arXiv:2210.03540",
    "title": "Multi-Agent Systems for Computational Economics and Finance",
    "abstract": "In this article we survey the main research topics of our group at the\nUniversity of Essex. Our research interests lie at the intersection of\ntheoretical computer science, artificial intelligence, and economic theory. In\nparticular, we focus on the design and analysis of mechanisms for systems\ninvolving multiple strategic agents, both from a theoretical and an applied\nperspective. We present an overview of our group's activities, as well as its\nmembers, and then discuss in detail past, present, and future work in\nmulti-agent systems.",
    "descriptor": "",
    "authors": [
      "Michael Kampouridis",
      "Panagiotis Kanellopoulos",
      "Maria Kyropoulou",
      "Themistoklis Melissourgos",
      "Alexandros A. Voudouris"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.03540"
  },
  {
    "id": "arXiv:2210.03543",
    "title": "A2: Efficient Automated Attacker for Boosting Adversarial Training",
    "abstract": "Based on the significant improvement of model robustness by AT (Adversarial\nTraining), various variants have been proposed to further boost the\nperformance. Well-recognized methods have focused on different components of AT\n(e.g., designing loss functions and leveraging additional unlabeled data). It\nis generally accepted that stronger perturbations yield more robust models.\nHowever, how to generate stronger perturbations efficiently is still missed. In\nthis paper, we propose an efficient automated attacker called A2 to boost AT by\ngenerating the optimal perturbations on-the-fly during training. A2 is a\nparameterized automated attacker to search in the attacker space for the best\nattacker against the defense model and examples. Extensive experiments across\ndifferent datasets demonstrate that A2 generates stronger perturbations with\nlow extra cost and reliably improves the robustness of various AT methods\nagainst different attacks.",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Zhuoer Xu",
      "Guanghui Zhu",
      "Changhua Meng",
      "Shiwen Cui",
      "Zhenzhe Ying",
      "Weiqiang Wang",
      "Ming GU",
      "Yihua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03543"
  },
  {
    "id": "arXiv:2210.03546",
    "title": "Time-Space Transformers for Video Panoptic Segmentation",
    "abstract": "We propose a novel solution for the task of video panoptic segmentation, that\nsimultaneously predicts pixel-level semantic and instance segmentation and\ngenerates clip-level instance tracks. Our network, named VPS-Transformer, with\na hybrid architecture based on the state-of-the-art panoptic segmentation\nnetwork Panoptic-DeepLab, combines a convolutional architecture for\nsingle-frame panoptic segmentation and a novel video module based on an\ninstantiation of the pure Transformer block. The Transformer, equipped with\nattention mechanisms, models spatio-temporal relations between backbone output\nfeatures of current and past frames for more accurate and consistent panoptic\nestimates. As the pure Transformer block introduces large computation overhead\nwhen processing high resolution images, we propose a few design changes for a\nmore efficient compute. We study how to aggregate information more effectively\nover the space-time volume and we compare several variants of the Transformer\nblock with different attention schemes. Extensive experiments on the\nCityscapes-VPS dataset demonstrate that our best model improves the temporal\nconsistency and video panoptic quality by a margin of 2.2%, with little extra\ncomputation.",
    "descriptor": "",
    "authors": [
      "Andra Petrovai",
      "Sergiu Nedevschi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03546"
  },
  {
    "id": "arXiv:2210.03551",
    "title": "Instance Segmentation of Dense and Overlapping Objects via Layering",
    "abstract": "Instance segmentation aims to delineate each individual object of interest in\nan image. State-of-the-art approaches achieve this goal by either partitioning\nsemantic segmentations or refining coarse representations of detected objects.\nIn this work, we propose a novel approach to solve the problem via object\nlayering, i.e. by distributing crowded, even overlapping objects into different\nlayers. By grouping spatially separated objects in the same layer, instances\ncan be effortlessly isolated by extracting connected components in each layer.\nIn comparison to previous methods, our approach is not affected by complex\nobject shapes or object overlaps. With minimal post-processing, our method\nyields very competitive results on a diverse line of datasets: C. elegans\n(BBBC), Overlapping Cervical Cells (OCC) and cultured neuroblastoma cells\n(CCDB). The source code is publicly available.",
    "descriptor": "",
    "authors": [
      "Long Chen",
      "Yuli Wu",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03551"
  },
  {
    "id": "arXiv:2210.03553",
    "title": "Treewidth-aware Reductions of Normal ASP to SAT -- Is Normal ASP Harder  than SAT after All?",
    "abstract": "Answer Set Programming (ASP) is a paradigm for modeling and solving problems\nfor knowledge representation and reasoning. There are plenty of results\ndedicated to studying the hardness of (fragments of) ASP. So far, these studies\nresulted in characterizations in terms of computational complexity as well as\nin fine-grained insights presented in form of dichotomy-style results, lower\nbounds when translating to other formalisms like propositional satisfiability\n(SAT), and even detailed parameterized complexity landscapes. A generic\nparameter in parameterized complexity originating from graph theory is the\nso-called treewidth, which in a sense captures structural density of a program.\nRecently, there was an increase in the number of treewidth-based solvers\nrelated to SAT. While there are translations from (normal) ASP to SAT, no\nreduction that preserves treewidth or at least keeps track of the treewidth\nincrease is known. In this paper we propose a novel reduction from normal ASP\nto SAT that is aware of the treewidth, and guarantees that a slight increase of\ntreewidth is indeed sufficient. Further, we show a new result establishing\nthat, when considering treewidth, already the fragment of normal ASP is\nslightly harder than SAT (under reasonable assumptions in computational\ncomplexity). This also confirms that our reduction probably cannot be\nsignificantly improved and that the slight increase of treewidth is\nunavoidable. Finally, we present an empirical study of our novel reduction from\nnormal ASP to SAT, where we compare treewidth upper bounds that are obtained\nvia known decomposition heuristics. Overall, our reduction works better with\nthese heuristics than existing translations.",
    "descriptor": "",
    "authors": [
      "Markus Hecher"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.03553"
  },
  {
    "id": "arXiv:2210.03555",
    "title": "In-situ Model Downloading to Realize Versatile Edge AI in 6G Mobile  Networks",
    "abstract": "The sixth-generation (6G) mobile networks are expected to feature the\nubiquitous deployment of machine learning and AI algorithms at the network\nedge. With rapid advancements in edge AI, the time has come to realize\nintelligence downloading onto edge devices (e.g., smartphones and sensors). To\nmaterialize this version, we propose a novel technology in this article, called\nin-situ model downloading, that aims to achieve transparent and real-time\nreplacement of on-device AI models by downloading from an AI library in the\nnetwork. Its distinctive feature is the adaptation of downloading to\ntime-varying situations (e.g., application, location, and time), devices'\nheterogeneous storage-and-computing capacities, and channel states. A key\ncomponent of the presented framework is a set of techniques that dynamically\ncompress a downloaded model at the depth-level, parameter-level, or bit-level\nto support adaptive model downloading. We further propose a virtualized 6G\nnetwork architecture customized for deploying in-situ model downloading with\nthe key feature of a three-tier (edge, local, and central) AI library.\nFurthermore, experiments are conducted to quantify 6G connectivity requirements\nand research opportunities pertaining to the proposed technology are discussed.",
    "descriptor": "\nComments: The paper has been submitted to IEEE for possible publication\n",
    "authors": [
      "Kaibin Huang",
      "Hai Wu",
      "Zhiyan Liu",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03555"
  },
  {
    "id": "arXiv:2210.03558",
    "title": "A deep learning approach for detection and localization of leaf  anomalies",
    "abstract": "The detection and localization of possible diseases in crops are usually\nautomated by resorting to supervised deep learning approaches. In this work, we\ntackle these goals with unsupervised models, by applying three different types\nof autoencoders to a specific open-source dataset of healthy and unhealthy\npepper and cherry leaf images. CAE, CVAE and VQ-VAE autoencoders are deployed\nto screen unlabeled images of such a dataset, and compared in terms of image\nreconstruction, anomaly removal, detection and localization. The\nvector-quantized variational architecture turns out to be the best performing\none with respect to all these targets.",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Davide Calabr\u00f2",
      "Massimiliano Lupo Pasini",
      "Nicola Ferro",
      "Simona Perotto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03558"
  },
  {
    "id": "arXiv:2210.03561",
    "title": "Empowering Graph Representation Learning with Test-Time Graph  Transformation",
    "abstract": "As powerful tools for representation learning on graphs, graph neural\nnetworks (GNNs) have facilitated various applications from drug discovery to\nrecommender systems. Nevertheless, the effectiveness of GNNs is immensely\nchallenged by issues related to data quality, such as distribution shift,\nabnormal features and adversarial attacks. Recent efforts have been made on\ntackling these issues from a modeling perspective which requires additional\ncost of changing model architectures or re-training model parameters. In this\nwork, we provide a data-centric view to tackle these issues and propose a graph\ntransformation framework named GTrans which adapts and refines graph data at\ntest time to achieve better performance. We provide theoretical analysis on the\ndesign of the framework and discuss why adapting graph data works better than\nadapting the model. Extensive experiments have demonstrated the effectiveness\nof GTrans on three distinct scenarios for eight benchmark datasets where\nsuboptimal data is presented. Remarkably, GTrans performs the best in most\ncases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on\nthree experimental settings.",
    "descriptor": "",
    "authors": [
      "Wei Jin",
      "Tong Zhao",
      "Jiayuan Ding",
      "Yozen Liu",
      "Jiliang Tang",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03561"
  },
  {
    "id": "arXiv:2210.03568",
    "title": "How Large Language Models are Transforming Machine-Paraphrased  Plagiarism",
    "abstract": "The recent success of large language models for text generation poses a\nsevere threat to academic integrity, as plagiarists can generate realistic\nparaphrases indistinguishable from original work. However, the role of large\nautoregressive transformers in generating machine-paraphrased plagiarism and\ntheir detection is still developing in the literature. This work explores T5\nand GPT-3 for machine-paraphrase generation on scientific articles from arXiv,\nstudent theses, and Wikipedia. We evaluate the detection performance of six\nautomated solutions and one commercial plagiarism detection software and\nperform a human study with 105 participants regarding their detection\nperformance and the quality of generated examples. Our results suggest that\nlarge models can rewrite text humans have difficulty identifying as\nmachine-paraphrased (53% mean acc.). Human experts rate the quality of\nparaphrases generated by GPT-3 as high as original texts (clarity 4.0/5,\nfluency 4.2/5, coherence 3.8/5). The best-performing detection model (GPT-3)\nachieves a 66% F1-score in detecting paraphrases.",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Frederic Kirstein",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03568"
  },
  {
    "id": "arXiv:2210.03570",
    "title": "AI-Driven Road Maintenance Inspection v2: Reducing Data Dependency &  Quantifying Road Damage",
    "abstract": "Road infrastructure maintenance inspection is typically a labor-intensive and\ncritical task to ensure the safety of all road users. Existing state-of-the-art\ntechniques in Artificial Intelligence (AI) for object detection and\nsegmentation help automate a huge chunk of this task given adequate annotated\ndata. However, annotating videos from scratch is cost-prohibitive. For\ninstance, it can take an annotator several days to annotate a 5-minute video\nrecorded at 30 FPS. Hence, we propose an automated labelling pipeline by\nleveraging techniques like few-shot learning and out-of-distribution detection\nto generate labels for road damage detection. In addition, our pipeline\nincludes a risk factor assessment for each damage by instance quantification to\nprioritize locations for repairs which can lead to optimal deployment of road\nmaintenance machinery. We show that the AI models trained with these techniques\ncan not only generalize better to unseen real-world data with reduced\nrequirement for human annotation but also provide an estimate of maintenance\nurgency, thereby leading to safer roads.",
    "descriptor": "\nComments: Accepted at IRF Global R2T Conference & Exhibition 2022\n",
    "authors": [
      "Haris Iqbal",
      "Hemang Chawla",
      "Arnav Varma",
      "Terence Brouns",
      "Ahmed Badar",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03570"
  },
  {
    "id": "arXiv:2210.03573",
    "title": "Numerical relaxation limit and outgoing edges in a central scheme for  networked conservation laws",
    "abstract": "A recently introduced scheme for networked conservation laws is analyzed in\nvarious experiments. The scheme makes use of a novel relaxation approach that\ngoverns the coupling conditions of the network and does not require a solution\nof the Riemann problem at the nodes. We numerically compare the dynamics of the\nsolution obtained by the scheme to solutions obtained using a classical\ncoupling condition. In particular, we investigate the case of two outgoing\nedges in the Lighthill-Whitham-Richards model of traffic flow and in the\nBuckley-Leverett model of two phase flow. Moreover, we numerically study the\nasymptotic preserving property of the scheme by comparing it to its preliminary\nform before the relaxation limit in a 1-to-1 network.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Niklas Kolbe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03573"
  },
  {
    "id": "arXiv:2210.03575",
    "title": "Are Representations Built from the Ground Up? An Empirical Examination  of Local Composition in Language Models",
    "abstract": "Compositionality, the phenomenon where the meaning of a phrase can be derived\nfrom its constituent parts, is a hallmark of human language. At the same time,\nmany phrases are non-compositional, carrying a meaning beyond that of each part\nin isolation. Representing both of these types of phrases is critical for\nlanguage understanding, but it is an open question whether modern language\nmodels (LMs) learn to do so; in this work we examine this question. We first\nformulate a problem of predicting the LM-internal representations of longer\nphrases given those of their constituents. We find that the representation of a\nparent phrase can be predicted with some accuracy given an affine\ntransformation of its children. While we would expect the predictive accuracy\nto correlate with human judgments of semantic compositionality, we find this is\nlargely not the case, indicating that LMs may not accurately distinguish\nbetween compositional and non-compositional phrases. We perform a variety of\nanalyses, shedding light on when different varieties of LMs do and do not\ngenerate compositional representations, and discuss implications for future\nmodeling work.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Emmy Liu",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03575"
  },
  {
    "id": "arXiv:2210.03580",
    "title": "Cloud-based Automatic Speech Recognition Systems for Southeast Asian  Languages",
    "abstract": "This paper provides an overall introduction of our Automatic Speech\nRecognition (ASR) systems for Southeast Asian languages. As not much existing\nwork has been carried out on such regional languages, a few difficulties should\nbe addressed before building the systems: limitation on speech and text\nresources, lack of linguistic knowledge, etc. This work takes Bahasa Indonesia\nand Thai as examples to illustrate the strategies of collecting various\nresources required for building ASR systems.",
    "descriptor": "\nComments: Published by the 2017 IEEE International Conference on Orange Technologies (ICOT 2017)\n",
    "authors": [
      "Lei Wang",
      "Rong Tong",
      "Cheung Chi Leung",
      "Sunil Sivadas",
      "Chongjia Ni",
      "Bin Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03580"
  },
  {
    "id": "arXiv:2210.03582",
    "title": "Learning Social Navigation from Demonstrations with Conditional Neural  Processes",
    "abstract": "Sociability is essential for modern robots to increase their acceptability in\nhuman environments. Traditional techniques use manually engineered utility\nfunctions inspired by observing pedestrian behaviors to achieve social\nnavigation. However, social aspects of navigation are diverse, changing across\ndifferent types of environments, societies, and population densities, making it\nunrealistic to use hand-crafted techniques in each domain. This paper presents\na data-driven navigation architecture that uses state-of-the-art neural\narchitectures, namely Conditional Neural Processes, to learn global and local\ncontrollers of the mobile robot from observations. Additionally, we leverage a\nstate-of-the-art, deep prediction mechanism to detect situations not similar to\nthe trained ones, where reactive controllers step in to ensure safe navigation.\nOur results demonstrate that the proposed framework can successfully carry out\nnavigation tasks regarding social norms in the data. Further, we showed that\nour system produces fewer personal-zone violations, causing less discomfort.",
    "descriptor": "",
    "authors": [
      "Yigit Yildirim",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03582"
  },
  {
    "id": "arXiv:2210.03585",
    "title": "A numerical approach for fluid deformable surfaces with conserved  enclosed volume",
    "abstract": "We consider surface finite elements and a semi-implicit time stepping scheme\nto simulate fluid deformable surfaces. Such surfaces are modeled by\nincompressible surface Navier-Stokes equations with bending forces. We here\nconsider closed surfaces and enforce conservation of the enclosed volume. The\nnumerical approach builds on higher order surface parameterizations, a\nTaylor-Hood element for the surface Navier-Stokes part, appropriate\napproximations of the geometric quantities of the surface and a Lagrange\nmultiplier for the constraint. The considered computational examples highlight\nthe solid-fluid duality of fluid deformable surfaces and demonstrate\nconvergence properties, partly known to be optimal for different sub-problems.",
    "descriptor": "",
    "authors": [
      "Veit Krause",
      "Axel Voigt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03585"
  },
  {
    "id": "arXiv:2210.03586",
    "title": "An Investigation into Whitening Loss for Self-supervised Learning",
    "abstract": "A desirable objective in self-supervised learning (SSL) is to avoid feature\ncollapse. Whitening loss guarantees collapse avoidance by minimizing the\ndistance between embeddings of positive pairs under the conditioning that the\nembeddings from different views are whitened. In this paper, we propose a\nframework with an informative indicator to analyze whitening loss, which\nprovides a clue to demystify several interesting phenomena as well as a\npivoting point connecting to other SSL methods. We reveal that batch whitening\n(BW) based methods do not impose whitening constraints on the embedding, but\nthey only require the embedding to be full-rank. This full-rank constraint is\nalso sufficient to avoid dimensional collapse. Based on our analysis, we\npropose channel whitening with random group partition (CW-RGP), which exploits\nthe advantages of BW-based methods in preventing collapse and avoids their\ndisadvantages requiring large batch size. Experimental results on ImageNet\nclassification and COCO object detection reveal that the proposed CW-RGP\npossesses a promising potential for learning good representations. The code is\navailable at https://github.com/winci-ai/CW-RGP.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. The Code is available at: this https URL\n",
    "authors": [
      "Xi Weng",
      "Lei Huang",
      "Lei Zhao",
      "Rao Muhammad Anwer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03586"
  },
  {
    "id": "arXiv:2210.03588",
    "title": "Understanding Transformer Memorization Recall Through Idioms",
    "abstract": "To produce accurate predictions, language models (LMs) must balance between\ngeneralization and memorization. Yet, little is known about the mechanism by\nwhich transformer LMs employ their memorization capacity. When does a model\ndecide to output a memorized phrase, and how is this phrase then retrieved from\nmemory? In this work, we offer the first methodological framework for probing\nand characterizing recall of memorized sequences in transformer LMs. First, we\nlay out criteria for detecting model inputs that trigger memory recall, and\npropose idioms as inputs that fulfill these criteria. Next, we construct a\ndataset of English idioms and use it to compare model behavior on memorized vs.\nnon-memorized inputs. Specifically, we analyze the internal prediction\nconstruction process by interpreting the model's hidden representations as a\ngradual refinement of the output probability distribution. We find that across\ndifferent model sizes and architectures, memorized predictions are a two-step\nprocess: early layers promote the predicted token to the top of the output\ndistribution, and upper layers increase model confidence. This suggests that\nmemorized information is stored and retrieved in the early layers of the\nnetwork. Last, we demonstrate the utility of our methodology beyond idioms in\nmemorized factual statements. Overall, our work makes a first step towards\nunderstanding memory recall, and provides a methodological basis for future\nstudies of transformer memorization.",
    "descriptor": "",
    "authors": [
      "Adi Haviv",
      "Ido Cohen",
      "Jacob Gidron",
      "Roei Schuster",
      "Yoav Goldberg",
      "Mor Geva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03588"
  },
  {
    "id": "arXiv:2210.03589",
    "title": "Tracing, Ranking and Pricing DER Flexibility in Active Distribution  Networks",
    "abstract": "This paper presents a framework for analysing the aggregated flexibility of\nactive distribution networks (ADNs) with distributed energy resources (DER).\nThe analysis takes a different perspective than existing studies, which focus\non characterising flexibility as the limits of the flexible power provision,\ni.e., the set of the network feasible operating points in the P-Q space.\nInstead, this work aims to estimate the contributions of different flexible\nunits to the aggregated flexibility, which is essential for flexible power\nranking and pricing. The proposed framework exploits cost-minimising OPF models\ncomplemented with cooperative game formulations that are able to capture the\ncombinatorial nature of activating multiple flexible units. Moreover, in\ncontrast to existing studies that imply perfect coordination of units, the\nproposed framework specifies the actions needed to reach feasible operating\npoints, reflecting the nonlinearities of the network flexibility model.\nExtensive simulations are performed for different flexibility metrics to\ndemonstrate the applicability of the framework. Depending on the metric\nselected (capacity, cost, or economic surplus of flexibility), distribution\nsystem operators (DSOs) can identify the most critical flexible units or\nremunerate units for participating in flexibility services provision.",
    "descriptor": "",
    "authors": [
      "Andrey Churkin",
      "Wangwei Kong",
      "Jose N. Melchor Gutierrez",
      "Eduardo A. Mart\u00ednez Cese\u00f1a",
      "Pierluigi Mancarella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03589"
  },
  {
    "id": "arXiv:2210.03590",
    "title": "Machine Learning Meets The Herbrand Universe",
    "abstract": "The appearance of strong CDCL-based propositional (SAT) solvers has greatly\nadvanced several areas of automated reasoning (AR). One of the directions in AR\nis thus to apply SAT solvers to expressive formalisms such as first-order\nlogic, for which large corpora of general mathematical problems exist today.\nThis is possible due to Herbrand's theorem, which allows reduction of\nfirst-order problems to propositional problems by instantiation. The core\nchallenge is choosing the right instances from the typically infinite Herbrand\nuniverse. In this work, we develop the first machine learning system targeting\nthis task, addressing its combinatorial and invariance properties. In\nparticular, we develop a GNN2RNN architecture based on an invariant graph\nneural network (GNN) that learns from problems and their solutions\nindependently of symbol names (addressing the abundance of skolems), combined\nwith a recurrent neural network (RNN) that proposes for each clause its\ninstantiations. The architecture is then trained on a corpus of mathematical\nproblems and their instantiation-based proofs, and its performance is evaluated\nin several ways. We show that the trained system achieves high accuracy in\npredicting the right instances, and that it is capable of solving many problems\nby educated guessing when combined with a ground solver. To our knowledge, this\nis the first convincing use of machine learning in synthesizing relevant\nelements from arbitrary Herbrand universes.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Jelle Piepenbrock",
      "Josef Urban",
      "Konstantin Korovin",
      "Miroslav Ol\u0161\u00e1k",
      "Tom Heskes",
      "Mikola\u0161 Janota"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.03590"
  },
  {
    "id": "arXiv:2210.03591",
    "title": "Modeling Inter-Class and Intra-Class Constraints in Novel Class  Discovery",
    "abstract": "Novel class discovery (NCD) aims at learning a model that transfers the\ncommon knowledge from a class-disjoint labelled dataset to another unlabelled\ndataset and discovers new classes (clusters) within it. Many methods have been\nproposed as well as elaborate training pipelines and appropriate objectives and\nconsiderably boosted the performance on NCD tasks. Despite all this, we find\nthat the existing methods do not sufficiently take advantage of the essence of\nthe NCD setting. To this end, in this paper, we propose to model both\ninter-class and intra-class constraints in NCD based on the symmetric\nKullback-Leibler divergence (sKLD). Specifically, we propose an inter-class\nsKLD constraint to effectively exploit the disjoint relationship between\nlabelled and unlabelled classes, enforcing the separability for different\nclasses in the embedding space. In addition, we present an intra-class sKLD\nconstraint to explicitly constrain the intra-relationship between samples and\ntheir augmentations and ensure the stability of the training process at the\nsame time. We conduct extensive experiments on the popular CIFAR10, CIFAR100\nand ImageNet benchmarks and successfully demonstrate that our method can\nestablish a new state of the art and can achieve significantly performance\nimprovements, e.g., $3.6\\%$/$7.9\\%$ clustering accuracy improvements on\nCIFAR100-50 under the task-aware/-agnostic evaluation protocol, over previous\nstate-of-the-art methods.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Wenbin Li",
      "Zhichen Fan",
      "Jing Huo",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03591"
  },
  {
    "id": "arXiv:2210.03592",
    "title": "Specialized Re-Ranking: A Novel Retrieval-Verification Framework for  Cloth Changing Person Re-Identification",
    "abstract": "Cloth changing person re-identification(Re-ID) can work under more\ncomplicated scenarios with higher security than normal Re-ID and biometric\ntechniques and is therefore extremely valuable in applications. Meanwhile,\nhigher flexibility in appearance always leads to more similar-looking confusing\nimages, which is the weakness of the widely used retrieval methods. In this\nwork, we shed light on how to handle these similar images. Specifically, we\npropose a novel retrieval-verification framework. Given an image, the retrieval\nmodule can search for similar images quickly. Our proposed verification network\nwill then compare the input image and the candidate images by contrasting those\nlocal details and give a similarity score. An innovative ranking strategy is\nalso introduced to take a good balance between retrieval and verification\nresults. Comprehensive experiments are conducted to show the effectiveness of\nour framework and its capability in improving the state-of-the-art methods\nremarkably on both synthetic and realistic datasets.",
    "descriptor": "\nComments: Accepted by Pattern Recognition\n",
    "authors": [
      "Renjie Zhang",
      "Yu Fang",
      "Huaxin Song",
      "Fangbin Wan",
      "Yanwei Fu",
      "Hirokazu Kato",
      "Yang Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03592"
  },
  {
    "id": "arXiv:2210.03593",
    "title": "Fitting ODE models of tear film breakup",
    "abstract": "Several elements are developed to quantitatively determine the contribution\nof different physical and chemical effects to tear breakup (TBU) in normal\nsubjects. Fluorescence (FL) imaging is employed to visualize the tear film and\nto determine tear film (TF) thinning and potential TBU. An automated system\nusing a convolutional neural network was trained and deployed to identify\nmultiple TBU instances in each trial. Once identified, extracted FL intensity\ndata was fit by mathematical models that included tangential flow along the\neye, evaporation, osmosis and FL intensity of emission from the tear film.\nOptimizing the fit of the models to the FL intensity data determined the\nmechanism(s) driving each instance of TBU and produced an estimate of the\nosmolarity within TBU. Initial estimates for FL concentration and initial TF\nthickness agree well with prior results. Fits were produced for $N=467$\ninstances of potential TBU from 15 normal subjects. The results showed a\ndistribution of causes of TBU in these normal subjects, as reflected by\nestimated flow and evaporation rates, which appear to agree well with\npreviously published data. Final osmolarity depended strongly on the TBU\nmechanism, generally increasing with evaporation rate but complicated by the\ndependence on flow. The method has the potential to classify TBU instances\nbased on the mechanism and dynamics and to estimate the final osmolarity at the\nTBU locus. The results suggest that it might be possible to classify individual\nsubjects and provide a baseline for comparison and potential classification of\ndry eye disease subjects.",
    "descriptor": "",
    "authors": [
      "Tobin A. Driscoll",
      "Richard J. Braun",
      "Rayanne A. Luke",
      "Dominick Sinopoli",
      "Aashish Phatak",
      "Julianna Dorsch",
      "Carolyn G. Begley",
      "Deborah Awisi-Gyau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03593"
  },
  {
    "id": "arXiv:2210.03594",
    "title": "Label Propagation with Weak Supervision",
    "abstract": "Semi-supervised learning and weakly supervised learning are important\nparadigms that aim to reduce the growing demand for labeled data in current\nmachine learning applications. In this paper, we introduce a novel analysis of\nthe classical label propagation algorithm (LPA) (Zhu & Ghahramani, 2002) that\nmoreover takes advantage of useful prior information, specifically\nprobabilistic hypothesized labels on the unlabeled data. We provide an error\nbound that exploits both the local geometric properties of the underlying graph\nand the quality of the prior information. We also propose a framework to\nincorporate multiple sources of noisy information. In particular, we consider\nthe setting of weak supervision, where our sources of information are weak\nlabelers. We demonstrate the ability of our approach on multiple benchmark\nweakly supervised classification tasks, showing improvements upon existing\nsemi-supervised and weakly supervised methods.",
    "descriptor": "\nComments: 26 pages, 2 figures\n",
    "authors": [
      "Rattana Pukdee",
      "Dylan Sam",
      "Maria-Florina Balcan",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03594"
  },
  {
    "id": "arXiv:2210.03595",
    "title": "Unsupervised Few-shot Learning via Deep Laplacian Eigenmaps",
    "abstract": "Learning a new task from a handful of examples remains an open challenge in\nmachine learning. Despite the recent progress in few-shot learning, most\nmethods rely on supervised pretraining or meta-learning on labeled\nmeta-training data and cannot be applied to the case where the pretraining data\nis unlabeled. In this study, we present an unsupervised few-shot learning\nmethod via deep Laplacian eigenmaps. Our method learns representation from\nunlabeled data by grouping similar samples together and can be intuitively\ninterpreted by random walks on augmented training data. We analytically show\nhow deep Laplacian eigenmaps avoid collapsed representation in unsupervised\nlearning without explicit comparison between positive and negative samples. The\nproposed method significantly closes the performance gap between supervised and\nunsupervised few-shot learning. Our method also achieves comparable performance\nto current state-of-the-art self-supervised learning methods under linear\nevaluation protocol.",
    "descriptor": "",
    "authors": [
      "Kuilin Chen",
      "Chi-Guhn Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03595"
  },
  {
    "id": "arXiv:2210.03599",
    "title": "RIS-Aided Localization under Position and Orientation Offsets in the  Near and Far Field",
    "abstract": "This paper presents a rigorous Bayesian analysis of the information in the\nsignal (consisting of both the line-of-sight (LOS) path and reflections from\nmultiple RISs) that originate from a single base station (BS) and is received\nby a user equipment (UE). For a comprehensive Bayesian analysis, both near and\nfar field regimes are considered. The Bayesian analysis views both the location\nof the RISs and previous information about the UE as {\\em a priori} information\nfor UE localization. With outdated {\\em a priori} information, the position and\norientation offsets of the RISs become parameters that need to be estimated and\nfed back to the BS for correction. We first show that when the RIS elements\nhave a half wavelength spacing, this RIS orientation offset is a factor in the\npathloss of the RIS paths. Subsequently, we show through the Bayesian\nequivalent FIM (EFIM) for the channel parameters that the RIS orientation\noffset cannot be corrected when there is an unknown phase offset in the\nreceived signal in the far-field regime. However, the corresponding EFIM for\nthe channel parameters in the received signal observed in the near-field shows\nthat this unknown phase offset does not hinder the estimation of the RIS\norientation offset when the UE has more than one receive antenna. Furthermore,\nwe use the EFIM for the UE location parameters to present bounds for UE\nlocalization in the presence of RIS uncertainty. We rigorously show that\nregardless of size and propagation regime, the RISs are only helpful for\nlocalization when there is {\\em a priori} information about the location of the\nRISs. Finally, through numerical analysis of the EFIM and its smallest\neigenvalue, we demonstrate the loss in information when the far-field model is\n{\\em incorrectly} applied to the signals received at a UE experiencing\nnear-field propagation.",
    "descriptor": "",
    "authors": [
      "Don-Roberts Emenonye",
      "Harpreet S. Dhillon",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.03599"
  },
  {
    "id": "arXiv:2210.03600",
    "title": "BlanketSet -- A clinical real word action recognition and qualitative  semi-synchronised MoCap dataset",
    "abstract": "Recent advancements in computer vision, particularly by making use of deep\nlearning, have drastically improved human motion analysis in videos. However,\nthese improvements have not yet fully translated into improved performance in\nclinical in-bed scenarios due to the lack of public datasets representative of\nthis scenario. To address this issue, we introduce BlanketSet, an RGB-IR-D\naction recognition dataset of sequences performed in a hospital bed. This\ndataset has the potential to help bridge the improvements attained in general\nuse cases to these clinical scenarios. The data that support the findings of\nthis study and BlanketSet are available on request from the corresponding\nauthor, J.P.S.C.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Jo\u00e3o Carmona",
      "Tam\u00e1s Kar\u00e1csony",
      "Jo\u00e3o Paulo Silva Cunha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03600"
  },
  {
    "id": "arXiv:2210.03603",
    "title": "Pronunciation Modeling of Foreign Words for Mandarin ASR by Considering  the Effect of Language Transfer",
    "abstract": "One of the challenges in automatic speech recognition is foreign words\nrecognition. It is observed that a speaker's pronunciation of a foreign word is\ninfluenced by his native language knowledge, and such phenomenon is known as\nthe effect of language transfer. This paper focuses on examining the phonetic\neffect of language transfer in automatic speech recognition. A set of lexical\nrules is proposed to convert an English word into Mandarin phonetic\nrepresentation. In this way, a Mandarin lexicon can be augmented by including\nEnglish words. Hence, the Mandarin ASR system becomes capable to recognize\nEnglish words without retraining or re-estimation of the acoustic model\nparameters. Using the lexicon that derived from the proposed rules, the ASR\nperformance of Mandarin English mixed speech is improved without harming the\naccuracy of Mandarin only speech. The proposed lexical rules are generalized\nand they can be directly applied to unseen English words.",
    "descriptor": "\nComments: Published by INTERSPEECH 2014\n",
    "authors": [
      "Lei Wang",
      "Rong Tong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03603"
  },
  {
    "id": "arXiv:2210.03604",
    "title": "Uncertainty-aware Flexibility Envelope Prediction in Buildings with  Controller-agnostic Battery Models",
    "abstract": "Buildings are a promising source of flexibility for the application of demand\nresponse. In this work, we introduce a novel battery model formulation to\ncapture the state evolution of a single building. Being fully data-driven, the\nbattery model identification requires one dataset from a period of nominal\ncontroller operation, and one from a period with flexibility requests, without\nmaking any assumptions on the underlying controller structure. We consider\nparameter uncertainty in the model formulation and show how to use risk\nmeasures to encode risk preferences of the user in robust uncertainty sets.\nFinally, we demonstrate the uncertainty-aware prediction of flexibility\nenvelopes for a building simulation model from the Python library Energym.",
    "descriptor": "\nComments: 7 pages, 3 figures. Submitted to the 2023 American Control Conference (ACC)\n",
    "authors": [
      "Paul Scharnhorst",
      "Baptiste Schubnel",
      "Rafael E. Carrillo",
      "Pierre-Jean Alet",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03604"
  },
  {
    "id": "arXiv:2210.03618",
    "title": "The $(1+(\u03bb,\u03bb))$ Global SEMO Algorithm",
    "abstract": "The $(1+(\\lambda,\\lambda))$ genetic algorithm is a recently proposed\nsingle-objective evolutionary algorithm with several interesting properties. We\nshow that its main working principle, mutation with a high rate and crossover\nas repair mechanism, can be transported also to multi-objective evolutionary\ncomputation. We define the $(1+(\\lambda,\\lambda))$ global SEMO algorithm, a\nvariant of the classic global SEMO algorithm, and prove that it optimizes the\nOneMinMax benchmark asymptotically faster than the global SEMO. Following the\nsingle-objective example, we design a one-fifth rule inspired dynamic parameter\nsetting (to the best of our knowledge for the first time in discrete\nmulti-objective optimization) and prove that it further improves the runtime to\n$O(n^2)$, whereas the best runtime guarantee for the global SEMO is only $O(n^2\n\\log n)$.",
    "descriptor": "\nComments: Author generated version of a paper at GECCO 2022\n",
    "authors": [
      "Benjamin Doerr",
      "Omar El Hadri",
      "Adrien Pinard"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03618"
  },
  {
    "id": "arXiv:2210.03623",
    "title": "Efficient Computation of Map-scale Continuous Mutual Information on Chip  in Real Time",
    "abstract": "Exploration tasks are essential to many emerging robotics applications,\nranging from search and rescue to space exploration. The planning problem for\nexploration requires determining the best locations for future measurements\nthat will enhance the fidelity of the map, for example, by reducing its total\nentropy. A widely-studied technique involves computing the Mutual Information\n(MI) between the current map and future measurements, and utilizing this MI\nmetric to decide the locations for future measurements. However, computing MI\nfor reasonably-sized maps is slow and power hungry, which has been a bottleneck\ntowards fast and efficient robotic exploration. In this paper, we introduce a\nnew hardware accelerator architecture for MI computation that features a\nlow-latency, energy-efficient MI compute core and an optimized memory subsystem\nthat provides sufficient bandwidth to keep the cores fully utilized. The core\nemploys interleaving to counter the recursive algorithm, and workload balancing\nand numerical approximations to reduce latency and energy consumption. We\ndemonstrate this optimized architecture with a Field-Programmable Gate Array\n(FPGA) implementation, which can compute MI for all cells in an entire\n201-by-201 occupancy grid ({\\em e.g.}, representing a 20.1m-by-20.1m map at\n0.1m resolution) in 1.55 ms while consuming 1.7 mJ of energy, thus finally\nrendering MI computation for the whole map real time and at a fraction of the\nenergy cost of traditional compute platforms. For comparison, this particular\nFPGA implementation running on the Xilinx Zynq-7000 platform is two orders of\nmagnitude faster and consumes three orders of magnitude less energy per MI map\ncompute, when compared to a baseline GPU implementation running on an NVIDIA\nGeForce GTX 980 platform. The improvements are more pronounced when compared to\nCPU implementations of equivalent algorithms.",
    "descriptor": "",
    "authors": [
      "Keshav Gupta",
      "Peter Zhi Xuan Li",
      "Sertac Karaman",
      "Vivienne Sze"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03623"
  },
  {
    "id": "arXiv:2210.03624",
    "title": "KAST: Knowledge Aware Adaptive Session Multi-Topic Network for  Click-Through Rate Prediction",
    "abstract": "Capturing the evolving trends of user interest is important for both\nrecommendation systems and advertising systems, and user behavior sequences\nhave been successfully used in Click-Through-Rate(CTR) prediction problems.\nHowever, if the user interest is learned on the basis of item-level behaviors,\nthe performance may be affected by the following two issues. Firstly, some\ncasual outliers might be included in the behavior sequences as user behaviors\nare likely to be diverse. Secondly, the span of time intervals between user\nbehaviors is random and irregular, for which a RNN-based module employed from\nNLP is not perfectly adaptive. To handle these two issues, we propose the\nKnowledge aware Adaptive Session multi-Topic network(KAST). It can adaptively\nsegment user sessions from the whole user behavior sequence, and maintain\nsimilar intents in the same session. Furthermore, in order to improve the\nquality of session segmentation and representation, a knowledge-aware module is\nintroduced so that the structural information from the user-item interaction\ncan be extracted in an end-to-end manner, and a marginal based loss with these\ninformation is merged into the major loss. Through extensive experiments on\npublic benchmarks, we demonstrate that KAST can achieve superior performance\nthan state-of-the-art methods for CTR prediction, and key modules and\nhyper-parameters are also evaluated.",
    "descriptor": "",
    "authors": [
      "Dike Sun",
      "Kai Liu",
      "ShengKai Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.03624"
  },
  {
    "id": "arXiv:2210.03625",
    "title": "C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual  Text-Video Retrieval",
    "abstract": "Multilingual text-video retrieval methods have improved significantly in\nrecent years, but the performance for other languages lags behind English. We\npropose a Cross-Lingual Cross-Modal Knowledge Distillation method to improve\nmultilingual text-video retrieval. Inspired by the fact that English text-video\nretrieval outperforms other languages, we train a student model using input\ntext in different languages to match the cross-modal predictions from teacher\nmodels using input text in English. We propose a cross entropy based objective\nwhich forces the distribution over the student's text-video similarity scores\nto be similar to those of the teacher models. We introduce a new multilingual\nvideo dataset, Multi-YouCook2, by translating the English captions in the\nYouCook2 video dataset to 8 other languages. Our method improves multilingual\ntext-video retrieval performance on Multi-YouCook2 and several other datasets\nsuch as Multi-MSRVTT and VATEX. We also conducted an analysis on the\neffectiveness of different multilingual text models as teachers.",
    "descriptor": "",
    "authors": [
      "Andrew Rouditchenko",
      "Yung-Sung Chuang",
      "Nina Shvetsova",
      "Samuel Thomas",
      "Rogerio Feris",
      "Brian Kingsbury",
      "Leonid Karlinsky",
      "David Harwath",
      "Hilde Kuehne",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.03625"
  },
  {
    "id": "arXiv:2210.03627",
    "title": "Pose Guided Human Image Synthesis with Partially Decoupled GAN",
    "abstract": "Pose Guided Human Image Synthesis (PGHIS) is a challenging task of\ntransforming a human image from the reference pose to a target pose while\npreserving its style. Most existing methods encode the texture of the whole\nreference human image into a latent space, and then utilize a decoder to\nsynthesize the image texture of the target pose. However, it is difficult to\nrecover the detailed texture of the whole human image. To alleviate this\nproblem, we propose a method by decoupling the human body into several parts\n(\\eg, hair, face, hands, feet, \\etc) and then using each of these parts to\nguide the synthesis of a realistic image of the person, which preserves the\ndetailed information of the generated images. In addition, we design a\nmulti-head attention-based module for PGHIS. Because most convolutional neural\nnetwork-based methods have difficulty in modeling long-range dependency due to\nthe convolutional operation, the long-range modeling capability of attention\nmechanism is more suitable than convolutional neural networks for pose transfer\ntask, especially for sharp pose deformation. Extensive experiments on\nMarket-1501 and DeepFashion datasets reveal that our method almost outperforms\nother existing state-of-the-art methods in terms of both qualitative and\nquantitative metrics.",
    "descriptor": "\nComments: 16 pages, 14th Asian Conference on Machine Learning conference\n",
    "authors": [
      "Jianhan Wu",
      "Jianzong Wang",
      "Shijing Si",
      "Xiaoyang Qu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03627"
  },
  {
    "id": "arXiv:2210.03628",
    "title": "GraspCaps: Capsule Networks Are All You Need for Grasping Familiar  Objects",
    "abstract": "As robots become more accessible outside of industrial settings, the need for\nreliable object grasping and manipulation grows significantly. In such dynamic\nenvironments it is expected that the robot is capable of reliably grasping and\nmanipulating novel objects in different situations. In this work we present\nGraspCaps: a novel architecture based on Capsule Networks for generating\nper-point grasp configurations for familiar objects. In our work, the\nactivation vector of each capsule in the deepest capsule layer corresponds to\none specific class of object. This way, the network is able to extract a rich\nfeature vector of the objects present in the point cloud input, which is then\nused for generating per-point grasp vectors. This approach should allow the\nnetwork to learn specific grasping strategies for each of the different object\ncategories. Along with GraspCaps we present a method for generating a large\nobject grasping dataset using simulated annealing. The obtained dataset is then\nused to train the GraspCaps network. We performed an extensive set of\nexperiments to assess the performance of the proposed approach regarding\nfamiliar object recognition accuracy and grasp success rate on challenging real\nand simulated scenarios.",
    "descriptor": "\nComments: Submitted to ICRA 2023, Supplementary video: this https URL\n",
    "authors": [
      "Tomas van der Velde",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03628"
  },
  {
    "id": "arXiv:2210.03629",
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "abstract": "While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.",
    "descriptor": "",
    "authors": [
      "Shunyu Yao",
      "Jeffrey Zhao",
      "Dian Yu",
      "Nan Du",
      "Izhak Shafran",
      "Karthik Narasimhan",
      "Yuan Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03629"
  },
  {
    "id": "arXiv:2210.03630",
    "title": "Boundaries, Extensions, and Challenges of Visualization for Humanities  Data: Reflections on Three Cases",
    "abstract": "This paper discusses problems of visualizing humanities data of various\nforms, such as video data, archival data, and numeric-oriented social science\ndata, with three distinct case studies. By describing the visualization\npractices and the issues that emerged from the process, this paper uses the\nthree cases to each identify a pertinent question for reflection. More\nspecifically, I reflect on the difficulty, thoughts, and considerations of\nchoosing the most effective and sufficient forms of visualization to enhance\nthe expression of specific cultural and humanities data in the projects.\nDiscussions in this paper concern some questions, such as, how do the\nmulti-modality of humanities and cultural data challenge the understanding,\nroles, and functions of visualizations, and more broadly, visual\nrepresentations in humanities research? What do we lose of the original data by\nvisualizing them in those projects? How to balance the benefits and\ndisadvantages of visual technologies to display complex, unique, and often\nculturally saturated humanities datasets",
    "descriptor": "",
    "authors": [
      "Rongqian Ma"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.03630"
  },
  {
    "id": "arXiv:2210.03638",
    "title": "Demystifying Quantum Blockchain for Healthcare",
    "abstract": "The application of blockchain technology can be beneficial in the field of\nhealthcare as well as in the fight against the COVID-19 epidemic. In this work,\nthe importance of blockchain is analyzed and it is observed that blockchain\ntechnology and the processes associated with it will be utilised in the\nhealthcare systems of the future for data acquisition from sensors, automatic\npatient monitoring, and secure data storage. This technology substantially\nsimplifies the process of carrying out operations because it can store a\nsubstantial quantity of data in a dispersed and secure manner, as well as\nenable access whenever and wherever it is required to do so. With the\nassistance of quantum blockchain, the benefits of quantum computing, such as\nthe capability to acquire thermal imaging based on quantum computing and the\nspeed with which patients may be located and monitored, can all be exploited to\ntheir full potential. Quantum blockchain is another tool that can be utilised\nto maintain the confidentiality, authenticity, and accessibility of data\nrecords. The processing of medical records could potentially benefit from\ngreater speed and privacy if it combines quantum computing and blockchain\ntechnology. The authors of this paper investigate the possible benefits and\napplications of blockchain and quantum technologies in the field of medicine,\npharmacy and healthcare systems. In this context, this work explored and\ncompared quantum technologies and blockchain-based technologies in conjunction\nwith other cutting-edge information and communications technologies such as\nratification intelligence, machine learning, drones, and so on.",
    "descriptor": "",
    "authors": [
      "Keshav Kaushik",
      "Adarsh Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.03638"
  },
  {
    "id": "arXiv:2210.03640",
    "title": "Artificial Intelligence and Natural Language Processing and  Understanding in Space: Four ESA Case Studies",
    "abstract": "The European Space Agency is well known as a powerful force for scientific\ndiscovery in numerous areas related to Space. The amount and depth of the\nknowledge produced throughout the different missions carried out by ESA and\ntheir contribution to scientific progress is enormous, involving large\ncollections of documents like scientific publications, feasibility studies,\ntechnical reports, and quality management procedures, among many others.\nThrough initiatives like the Open Space Innovation Platform, ESA also acts as a\nhub for new ideas coming from the wider community across different challenges,\ncontributing to a virtuous circle of scientific discovery and innovation.\nHandling such wealth of information, of which large part is unstructured text,\nis a colossal task that goes beyond human capabilities, hence requiring\nautomation. In this paper, we present a methodological framework based on\nartificial intelligence and natural language processing and understanding to\nautomatically extract information from Space documents, generating value from\nit, and illustrate such framework through several case studies implemented\nacross different functional areas of ESA, including Mission Design, Quality\nAssurance, Long-Term Data Preservation, and the Open Space Innovation Platform.\nIn doing so, we demonstrate the value of these technologies in several tasks\nranging from effortlessly searching and recommending Space information to\nautomatically determining how innovative an idea can be, answering questions\nabout Space, and generating quizzes regarding quality procedures. Each of these\naccomplishments represents a step forward in the application of increasingly\nintelligent AI systems in Space, from structuring and facilitating information\naccess to intelligent systems capable to understand and reason with such\ninformation.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez",
      "Andr\u00e9s Garc\u00eda-Silva",
      "Rosemarie Leone",
      "Mirko Albani",
      "Moritz Fontaine",
      "Charles Poncet",
      "Leopold Summerer",
      "Alessandro Donati",
      "Ilaria Roma",
      "Stefano Scaglioni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03640"
  },
  {
    "id": "arXiv:2210.03646",
    "title": "Leveraging Structure from Motion to Localize Inaccessible Bus Stops",
    "abstract": "The detection of hazardous conditions near public transit stations is\nnecessary for ensuring the safety and accessibility of public transit. Smart\ncity infrastructures aim to facilitate this task among many others through the\nuse of computer vision. However, most state-of-the-art computer vision models\nrequire thousands of images in order to perform accurate detection, and there\nexist few images of hazardous conditions as they are generally rare. In this\npaper, we examine the detection of snow-covered sidewalks along bus routes.\nPrevious work has focused on detecting other vehicles in heavy snowfall or\nsimply detecting the presence of snow. However, our application has an added\ncomplication of determining if the snow covers areas of importance and can\ncause falls or other accidents (e.g. snow covering a sidewalk) or simply covers\nsome background area (e.g. snow on a neighboring field). This problem involves\nlocalizing the positions of the areas of importance when they are not\nnecessarily visible.\nWe introduce a method that utilizes Structure from Motion (SfM) rather than\nadditional annotated data to address this issue. Specifically, our method\nlearns the locations of sidewalks in a given scene by applying a segmentation\nmodel and SfM to images from bus cameras during clear weather. Then, we use the\nlearned locations to detect if and where the sidewalks become obscured with\nsnow. After evaluating across various threshold parameters, we identify an\noptimal range at which our method consistently classifies different categories\nof sidewalk images correctly. Although we demonstrate an application for snow\ncoverage along bus routes, this method can extend to other hazardous conditions\nas well. Code for this project is available at\nhttps://github.com/ind1010/SfM_for_BusEdge.",
    "descriptor": "",
    "authors": [
      "Indu Panigrahi",
      "Tom Bu",
      "Christoph Mertz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03646"
  },
  {
    "id": "arXiv:2210.03647",
    "title": "Learnware: Small Models Do Big",
    "abstract": "There are complaints about current machine learning techniques such as the\nrequirement of a huge amount of training data and proficient training skills,\nthe difficulty of continual learning, the risk of catastrophic forgetting, the\nleaking of data privacy/proprietary, etc. Most research efforts have been\nfocusing on one of those concerned issues separately, paying less attention to\nthe fact that most issues are entangled in practice. The prevailing big model\nparadigm, which has achieved impressive results in natural language processing\nand computer vision applications, has not yet addressed those issues, whereas\nbecoming a serious source of carbon emissions. This article offers an overview\nof the learnware paradigm, which attempts to enable users not need to build\nmachine learning models from scratch, with the hope of reusing small models to\ndo things even beyond their original purposes, where the key ingredient is the\nspecification which enables a trained model to be adequately identified to\nreuse according to the requirement of future users who know nothing about the\nmodel in advance.",
    "descriptor": "",
    "authors": [
      "Zhi-Hua Zhou",
      "Zhi-Hao Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03647"
  },
  {
    "id": "arXiv:2210.03649",
    "title": "How to Enable Uncertainty Estimation in Proximal Policy Optimization",
    "abstract": "While deep reinforcement learning (RL) agents have showcased strong results\nacross many domains, a major concern is their inherent opaqueness and the\nsafety of such systems in real-world use cases. To overcome these issues, we\nneed agents that can quantify their uncertainty and detect out-of-distribution\n(OOD) states. Existing uncertainty estimation techniques, like Monte-Carlo\nDropout or Deep Ensembles, have not seen widespread adoption in on-policy deep\nRL. We posit that this is due to two reasons: concepts like uncertainty and OOD\nstates are not well defined compared to supervised learning, especially for\non-policy RL methods. Secondly, available implementations and comparative\nstudies for uncertainty estimation methods in RL have been limited. To overcome\nthe first gap, we propose definitions of uncertainty and OOD for Actor-Critic\nRL algorithms, namely, proximal policy optimization (PPO), and present possible\napplicable measures. In particular, we discuss the concepts of value and policy\nuncertainty. The second point is addressed by implementing different\nuncertainty estimation methods and comparing them across a number of\nenvironments. The OOD detection performance is evaluated via a custom\nevaluation benchmark of in-distribution (ID) and OOD states for various RL\nenvironments. We identify a trade-off between reward and OOD detection\nperformance. To overcome this, we formulate a Pareto optimization problem in\nwhich we simultaneously optimize for reward and OOD detection performance. We\nshow experimentally that the recently proposed method of Masksembles strikes a\nfavourable balance among the survey methods, enabling high-quality uncertainty\nestimation and OOD detection while matching the performance of original RL\nagents.",
    "descriptor": "",
    "authors": [
      "Eugene Bykovets",
      "Yannick Metz",
      "Mennatallah El-Assady",
      "Daniel A. Keim",
      "Joachim M. Buhmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03649"
  },
  {
    "id": "arXiv:2210.03650",
    "title": "Longtonotes: OntoNotes with Longer Coreference Chains",
    "abstract": "Ontonotes has served as the most important benchmark for coreference\nresolution. However, for ease of annotation, several long documents in\nOntonotes were split into smaller parts. In this work, we build a corpus of\ncoreference-annotated documents of significantly longer length than what is\ncurrently available. We do so by providing an accurate, manually-curated,\nmerging of annotations from documents that were split into multiple parts in\nthe original Ontonotes annotation process. The resulting corpus, which we call\nLongtoNotes contains documents in multiple genres of the English language with\nvarying lengths, the longest of which are up to 8x the length of documents in\nOntonotes, and 2x those in Litbank. We evaluate state-of-the-art neural\ncoreference systems on this new corpus, analyze the relationships between model\narchitectures/hyperparameters and document length on performance and efficiency\nof the models, and demonstrate areas of improvement in long-document\ncoreference modeling revealed by our new corpus. Our data and code is available\nat: https://github.com/kumar-shridhar/LongtoNotes.",
    "descriptor": "",
    "authors": [
      "Kumar Shridhar",
      "Nicholas Monath",
      "Raghuveer Thirukovalluru",
      "Alessandro Stolfo",
      "Manzil Zaheer",
      "Andrew McCallum",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03650"
  },
  {
    "id": "arXiv:2210.03651",
    "title": "Understanding the Covariance Structure of Convolutional Filters",
    "abstract": "Neural network weights are typically initialized at random from univariate\ndistributions, controlling just the variance of individual weights even in\nhighly-structured operations like convolutions. Recent ViT-inspired\nconvolutional networks such as ConvMixer and ConvNeXt use large-kernel\ndepthwise convolutions whose learned filters have notable structure; this\npresents an opportunity to study their empirical covariances. In this work, we\nfirst observe that such learned filters have highly-structured covariance\nmatrices, and moreover, we find that covariances calculated from small networks\nmay be used to effectively initialize a variety of larger networks of different\ndepths, widths, patch sizes, and kernel sizes, indicating a degree of\nmodel-independence to the covariance structure. Motivated by these findings, we\nthen propose a learning-free multivariate initialization scheme for\nconvolutional filters using a simple, closed-form construction of their\ncovariance. Models using our initialization outperform those using traditional\nunivariate initializations, and typically meet or exceed the performance of\nthose initialized from the covariances of learned filters; in some cases, this\nimprovement can be achieved without training the depthwise convolutional\nfilters at all.",
    "descriptor": "",
    "authors": [
      "Asher Trockman",
      "Devin Willmott",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03651"
  },
  {
    "id": "arXiv:2210.03655",
    "title": "Numerical Solution of an Extra-wide Angle Parabolic Equation through  Diagonalization of a 1-D Indefinite Schr\u00f6dinger Operator with a Piecewise  Constant Potential",
    "abstract": "We present a numerical method for computing the solution of a partial\ndifferential equation (PDE) for modeling acoustic pressure, known as an\nextra-wide angle parabolic equation, that features the square root of a\ndifferential operator. The differential operator is the negative of an\nindefinite Schr\\\"{o}dinger operator with a piecewise constant potential. This\nwork primarily deals with the 3-piece case; however, a generalization is made\nthe case of an arbitrary number of pieces. Through restriction to a judiciously\nchosen lower-dimensional subspace, approximate eigenfunctions are used to\nobtain estimates for the eigenvalues of the operator. Then, the estimated\neigenvalues are used as initial guesses for the Secant Method to find the exact\neigenvalues, up to roundoff error. An eigenfunction expansion of the solution\nis then constructed. The computational expense of obtaining each eigenpair is\nindependent of the grid size. The accuracy, efficiency, and scalability of this\nmethod is shown through numerical experiments and comparisons with other\nmethods.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Sarah D. Wright",
      "James V. Lambers"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03655"
  },
  {
    "id": "arXiv:2210.03659",
    "title": "Spatio-temporal Tendency Reasoning for Human Body Pose and Shape  Estimation from Videos",
    "abstract": "In this paper, we present a spatio-temporal tendency reasoning (STR) network\nfor recovering human body pose and shape from videos. Previous approaches have\nfocused on how to extend 3D human datasets and temporal-based learning to\npromote accuracy and temporal smoothing. Different from them, our STR aims to\nlearn accurate and natural motion sequences in an unconstrained environment\nthrough temporal and spatial tendency and to fully excavate the spatio-temporal\nfeatures of existing video data. To this end, our STR learns the representation\nof features in the temporal and spatial dimensions respectively, to concentrate\non a more robust representation of spatio-temporal features. More specifically,\nfor efficient temporal modeling, we first propose a temporal tendency reasoning\n(TTR) module. TTR constructs a time-dimensional hierarchical residual\nconnection representation within a video sequence to effectively reason\ntemporal sequences' tendencies and retain effective dissemination of human\ninformation. Meanwhile, for enhancing the spatial representation, we design a\nspatial tendency enhancing (STE) module to further learns to excite spatially\ntime-frequency domain sensitive features in human motion information\nrepresentations. Finally, we introduce integration strategies to integrate and\nrefine the spatio-temporal feature representations. Extensive experimental\nfindings on large-scale publically available datasets reveal that our STR\nremains competitive with the state-of-the-art on three datasets. Our code are\navailable at https://github.com/Changboyang/STR.git.",
    "descriptor": "\nComments: Accepted by BMVC2022\n",
    "authors": [
      "Boyang Zhang",
      "SuPing Wu",
      "Hu Cao",
      "Kehua Ma",
      "Pan Li",
      "Lei Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03659"
  },
  {
    "id": "arXiv:2210.03661",
    "title": "Inertia constants for individual power plants",
    "abstract": "Keeping the power system stable is becoming more challenging with the growing\nshare of renewable energy sources of low or negligible inertia. Inertia\nconstants for individual power plants are generally not known and are roughly\nestimated by considering the type of power generation technology and the\nnameplate capacity of plants. More accurate knowledge of inertia constants of\nindividual power plants would give greater transparency to decisions of the\ntransmission system operator (TSO) and to auctions for the procurement of\ninertia services. Additionally, a more accurate forecast or estimation of\nsystem inertia would improve the price signals to the power market well in\nadvance of balancing actions taken by the TSO. We develop methods based on a\ncombination of mathematical optimisation and machine learning that\nreverse-engineer the inertia constants of individual power plants from the\nhistorical values of their power production and from aggregate values of\ninertia in a power system. We demonstrate the methods for the power system of\nGreat Britain (GB), where historical values for aggregate inertia are published\nby the TSO. We show that the recovered inertia data is crucial in understanding\ncertain individual balancing decisions by the TSO. We use the\nreverse-engineered inertia constants to predict system inertia which gives\nvaluable information to the power market.",
    "descriptor": "\nComments: accepted to European Energy Markets 2022 conference\n",
    "authors": [
      "David Kraljic",
      "Blaz Sobocan",
      "Jernej Katanec",
      "Matej Logar",
      "Miha Troha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03661"
  },
  {
    "id": "arXiv:2210.03662",
    "title": "Learning High Speed Precision Table Tennis on a Physical Robot",
    "abstract": "Learning goal conditioned control in the real world is a challenging open\nproblem in robotics. Reinforcement learning systems have the potential to learn\nautonomously via trial-and-error, but in practice the costs of manual reward\ndesign, ensuring safe exploration, and hyperparameter tuning are often enough\nto preclude real world deployment. Imitation learning approaches, on the other\nhand, offer a simple way to learn control in the real world, but typically\nrequire costly curated demonstration data and lack a mechanism for continuous\nimprovement. Recently, iterative imitation techniques have been shown to learn\ngoal directed control from undirected demonstration data, and improve\ncontinuously via self-supervised goal reaching, but results thus far have been\nlimited to simulated environments. In this work, we present evidence that\niterative imitation learning can scale to goal-directed behavior on a real\nrobot in a dynamic setting: high speed, precision table tennis (e.g. \"land the\nball on this particular target\"). We find that this approach offers a\nstraightforward way to do continuous on-robot learning, without complexities\nsuch as reward design or sim-to-real transfer. It is also scalable -- sample\nefficient enough to train on a physical robot in just a few hours. In real\nworld evaluations, we find that the resulting policy can perform on par or\nbetter than amateur humans (with players sampled randomly from a robotics lab)\nat the task of returning the ball to specific targets on the table. Finally, we\nanalyze the effect of an initial undirected bootstrap dataset size on\nperformance, finding that a modest amount of unstructured demonstration data\nprovided up-front drastically speeds up the convergence of a general purpose\ngoal-reaching policy. See https://sites.google.com/view/goals-eye for videos.",
    "descriptor": "",
    "authors": [
      "Tianli Ding",
      "Laura Graesser",
      "Saminda Abeyruwan",
      "David B. D'Ambrosio",
      "Anish Shankar",
      "Pierre Sermanet",
      "Pannag R. Sanketi",
      "Corey Lynch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03662"
  },
  {
    "id": "arXiv:2210.03664",
    "title": "Bi-directional Weakly Supervised Knowledge Distillation for Whole Slide  Image Classification",
    "abstract": "Computer-aided pathology diagnosis based on the classification of Whole Slide\nImage (WSI) plays an important role in clinical practice, and it is often\nformulated as a weakly-supervised Multiple Instance Learning (MIL) problem.\nExisting methods solve this problem from either a bag classification or an\ninstance classification perspective. In this paper, we propose an end-to-end\nweakly supervised knowledge distillation framework (WENO) for WSI\nclassification, which integrates a bag classifier and an instance classifier in\na knowledge distillation framework to mutually improve the performance of both\nclassifiers. Specifically, an attention-based bag classifier is used as the\nteacher network, which is trained with weak bag labels, and an instance\nclassifier is used as the student network, which is trained using the\nnormalized attention scores obtained from the teacher network as soft pseudo\nlabels for the instances in positive bags. An instance feature extractor is\nshared between the teacher and the student to further enhance the knowledge\nexchange between them. In addition, we propose a hard positive instance mining\nstrategy based on the output of the student network to force the teacher\nnetwork to keep mining hard positive instances. WENO is a plug-and-play\nframework that can be easily applied to any existing attention-based bag\nclassification methods. Extensive experiments on five datasets demonstrate the\nefficiency of WENO. Code is available at https://github.com/miccaiif/WENO.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Linhao Qu",
      "Xiaoyuan Luo",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03664"
  },
  {
    "id": "arXiv:2210.03671",
    "title": "A Closer Look at Hardware-Friendly Weight Quantization",
    "abstract": "Quantizing a Deep Neural Network (DNN) model to be used on a custom\naccelerator with efficient fixed-point hardware implementations, requires\nsatisfying many stringent hardware-friendly quantization constraints to train\nthe model. We evaluate the two main classes of hardware-friendly quantization\nmethods in the context of weight quantization: the traditional Mean Squared\nQuantization Error (MSQE)-based methods and the more recent gradient-based\nmethods. We study the two methods on MobileNetV1 and MobileNetV2 using multiple\nempirical metrics to identify the sources of performance differences between\nthe two classes, namely, sensitivity to outliers and convergence instability of\nthe quantizer scaling factor. Using those insights, we propose various\ntechniques to improve the performance of both quantization methods - they fix\nthe optimization instability issues present in the MSQE-based methods during\nquantization of MobileNet models and allow us to improve validation performance\nof the gradient-based methods by 4.0% and 3.3% for MobileNetV1 and MobileNetV2\non ImageNet respectively.",
    "descriptor": "",
    "authors": [
      "Sungmin Bae",
      "Piotr Zielinski",
      "Satrajit Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03671"
  },
  {
    "id": "arXiv:2210.03672",
    "title": "To tree or not to tree? Assessing the impact of smoothing the decision  boundaries",
    "abstract": "When analyzing a dataset, it can be useful to assess how smooth the decision\nboundaries need to be for a model to better fit the data. This paper addresses\nthis question by proposing the quantification of how much should the 'rigid'\ndecision boundaries, produced by an algorithm that naturally finds such\nsolutions, be relaxed to obtain a performance improvement. The approach we\npropose starts with the rigid decision boundaries of a seed Decision Tree (seed\nDT), which is used to initialize a Neural DT (NDT). The initial boundaries are\nchallenged by relaxing them progressively through training the NDT. During this\nprocess, we measure the NDT's performance and decision agreement to its seed\nDT. We show how these two measures can help the user in figuring out how\nexpressive his model should be, before exploring it further via model\nselection. The validity of our approach is demonstrated with experiments on\nsimulated and benchmark datasets.",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables. arXiv admin note: text overlap with arXiv:2006.11458\n",
    "authors": [
      "Anthea M\u00e9rida",
      "Argyris Kalogeratos",
      "Mathilde Mougeot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03672"
  },
  {
    "id": "arXiv:2210.03674",
    "title": "Reinforcement Learning Approach for Multi-Agent Flexible Scheduling  Problems",
    "abstract": "Scheduling plays an important role in automated production. Its impact can be\nfound in various fields such as the manufacturing industry, the service\nindustry and the technology industry. A scheduling problem (NP-hard) is a task\nof finding a sequence of job assignments on a given set of machines with the\ngoal of optimizing the objective defined. Methods such as Operation Research,\nDispatching Rules, and Combinatorial Optimization have been applied to\nscheduling problems but no solution guarantees to find the optimal solution.\nThe recent development of Reinforcement Learning has shown success in\nsequential decision-making problems. This research presents a Reinforcement\nLearning approach for scheduling problems. In particular, this study delivers\nan OpenAI gym environment with search-space reduction for Job Shop Scheduling\nProblems and provides a heuristic-guided Q-Learning solution with\nstate-of-the-art performance for Multi-agent Flexible Job Shop Problems.",
    "descriptor": "",
    "authors": [
      "Hongjian Zhou",
      "Boyang Gu",
      "Chenghao Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.03674"
  },
  {
    "id": "arXiv:2210.03675",
    "title": "Koopman Neural Forecaster for Time Series with Temporal Distribution  Shifts",
    "abstract": "Temporal distributional shifts, with underlying dynamics changing over time,\nfrequently occur in real-world time series, and pose a fundamental challenge\nfor deep neural networks (DNNs). In this paper, we propose a novel deep\nsequence model based on the Koopman theory for time series forecasting: Koopman\nNeural Forecaster (KNF) that leverages DNNs to learn the linear Koopman space\nand the coefficients of chosen measurement functions. KNF imposes appropriate\ninductive biases for improved robustness against distributional shifts,\nemploying both a global operator to learn shared characteristics, and a local\noperator to capture changing dynamics, as well as a specially-designed feedback\nloop to continuously update the learnt operators over time for rapidly varying\nbehaviors. To the best of our knowledge, this is the first time that Koopman\ntheory is applied to real-world chaotic time series without known governing\nlaws. We demonstrate that KNF achieves the superior performance compared to the\nalternatives, on multiple time series datasets that are shown to suffer from\ndistribution shifts.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Yihe Dong",
      "Sercan O Arik",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03675"
  },
  {
    "id": "arXiv:2210.03676",
    "title": "IronDepth: Iterative Refinement of Single-View Depth using Surface  Normal and its Uncertainty",
    "abstract": "Single image surface normal estimation and depth estimation are closely\nrelated problems as the former can be calculated from the latter. However, the\nsurface normals computed from the output of depth estimation methods are\nsignificantly less accurate than the surface normals directly estimated by\nnetworks. To reduce such discrepancy, we introduce a novel framework that uses\nsurface normal and its uncertainty to recurrently refine the predicted\ndepth-map. The depth of each pixel can be propagated to a query pixel, using\nthe predicted surface normal as guidance. We thus formulate depth refinement as\na classification of choosing the neighboring pixel to propagate from. Then, by\npropagating to sub-pixel points, we upsample the refined, low-resolution\noutput. The proposed method shows state-of-the-art performance on NYUv2 and\niBims-1 - both in terms of depth and normal. Our refinement module can also be\nattached to the existing depth estimation methods to improve their accuracy. We\nalso show that our framework, only trained for depth estimation, can also be\nused for depth completion. The code is available at\nhttps://github.com/baegwangbin/IronDepth.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Gwangbin Bae",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03676"
  },
  {
    "id": "arXiv:2210.03682",
    "title": "Novice Type Error Diagnosis with Natural Language Models",
    "abstract": "Strong static type systems help programmers eliminate many errors without\nmuch burden of supplying type annotations. However, this flexibility makes it\nhighly non-trivial to diagnose ill-typed programs, especially for novice\nprogrammers. Compared to classic constraint solving and optimization-based\napproaches, the data-driven approach has shown great promise in identifying the\nroot causes of type errors with higher accuracy. Instead of relying on\nhand-engineered features, this work explores natural language models for type\nerror localization, which can be trained in an end-to-end fashion without\nrequiring any features. We demonstrate that, for novice type error diagnosis,\nthe language model-based approach significantly outperforms the previous\nstate-of-the-art data-driven approach. Specifically, our model could predict\ntype errors correctly 62% of the time, outperforming the state-of-the-art\nNate's data-driven model by 11%, in a more rigorous accuracy metric.\nFurthermore, we also apply structural probes to explain the performance\ndifference between different language models.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Chuqin Geng",
      "Haolin Ye",
      "Yixuan Li",
      "Tianyu Han",
      "Brigitte Pientka",
      "Xujie Si"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03682"
  },
  {
    "id": "arXiv:2210.03683",
    "title": "Quantitative Metrics for Evaluating Explanations of Video DeepFake  Detectors",
    "abstract": "The proliferation of DeepFake technology is a rising challenge in today's\nsociety, owing to more powerful and accessible generation methods. To counter\nthis, the research community has developed detectors of ever-increasing\naccuracy. However, the ability to explain the decisions of such models to users\nis lacking behind and is considered an accessory in large-scale benchmarks,\ndespite being a crucial requirement for the correct deployment of automated\ntools for content moderation. We attribute the issue to the reliance on\nqualitative comparisons and the lack of established metrics. We describe a\nsimple set of metrics to evaluate the visual quality and informativeness of\nexplanations of video DeepFake classifiers from a human-centric perspective.\nWith these metrics, we compare common approaches to improve explanation quality\nand discuss their effect on both classification and explanation performance on\nthe recent DFDC and DFD datasets.",
    "descriptor": "\nComments: Accepted at BMVC 2022, code repository at this https URL\n",
    "authors": [
      "Federico Baldassarre",
      "Quentin Debard",
      "Gonzalo Fiz Pontiveros",
      "Tri Kurniawan Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03683"
  },
  {
    "id": "arXiv:2210.03686",
    "title": "Humans need not label more humans: Occlusion Copy & Paste for Occluded  Human Instance Segmentation",
    "abstract": "Modern object detection and instance segmentation networks stumble when\npicking out humans in crowded or highly occluded scenes. Yet, these are often\nscenarios where we require our detectors to work well. Many works have\napproached this problem with model-centric improvements. While they have been\nshown to work to some extent, these supervised methods still need sufficient\nrelevant examples (i.e. occluded humans) during training for the improvements\nto be maximised. In our work, we propose a simple yet effective data-centric\napproach, Occlusion Copy & Paste, to introduce occluded examples to models\nduring training - we tailor the general copy & paste augmentation approach to\ntackle the difficult problem of same-class occlusion. It improves instance\nsegmentation performance on occluded scenarios for \"free\" just by leveraging on\nexisting large-scale datasets, without additional data or manual labelling\nneeded. In a principled study, we show whether various proposed add-ons to the\ncopy & paste augmentation indeed contribute to better performance. Our\nOcclusion Copy & Paste augmentation is easily interoperable with any models: by\nsimply applying it to a recent generic instance segmentation model without\nexplicit model architectural design to tackle occlusion, we achieve\nstate-of-the-art instance segmentation performance on the very challenging\nOCHuman dataset. Source code is available at\nhttps://github.com/levan92/occlusion-copy-paste.",
    "descriptor": "\nComments: 13 pages, 5 figures, BMVC 2022\n",
    "authors": [
      "Evan Ling",
      "Dezhao Huang",
      "Minhoe Hur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03686"
  },
  {
    "id": "arXiv:2210.03688",
    "title": "A Wolf in Sheep's Clothing: Spreading Deadly Pathogens Under the  Disguise of Popular Music",
    "abstract": "A Negative Pressure Room (NPR) is an essential requirement by the Bio-Safety\nLevels (BSLs) in biolabs or infectious-control hospitals to prevent deadly\npathogens from being leaked from the facility. An NPR maintains a negative\npressure inside with respect to the outside reference space so that microbes\nare contained inside of an NPR. Nowadays, differential pressure sensors (DPSs)\nare utilized by the Building Management Systems (BMSs) to control and monitor\nthe negative pressure in an NPR. This paper demonstrates a non-invasive and\nstealthy attack on NPRs by spoofing a DPS at its resonant frequency. Our\ncontributions are: (1) We show that DPSs used in NPRs typically have resonant\nfrequencies in the audible range. (2) We use this finding to design malicious\nmusic to create resonance in DPSs, resulting in an overshooting in the DPS's\nnormal pressure readings. (3) We show how the resonance in DPSs can fool the\nBMSs so that the NPR turns its negative pressure to a positive one, causing a\npotential \\textit{leak} of deadly microbes from NPRs. We do experiments on 8\nDPSs from 5 different manufacturers to evaluate their resonant frequencies\nconsidering the sampling tube length and find resonance in 6 DPSs. We can\nachieve a 2.5 Pa change in negative pressure from a $\\sim$7 cm distance when a\nsampling tube is not present and from a $\\sim$2.5 cm distance for a 1 m\nsampling tube length. We also introduce an interval-time variation approach for\nan adversarial control over the negative pressure and show that the\n\\textit{forged} pressure can be varied within 12 - 33 Pa. Our attack is also\ncapable of attacking multiple NPRs simultaneously. Moreover, we demonstrate our\nattack at a real-world NPR located in an anonymous bioresearch facility, which\nis FDA approved and follows CDC guidelines. We also provide countermeasures to\nprevent the attack.",
    "descriptor": "",
    "authors": [
      "Anomadarshi Barua",
      "Yonatan Gizachew Achamyeleh",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03688"
  },
  {
    "id": "arXiv:2210.03690",
    "title": "Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of  In-Context Experts",
    "abstract": "Anaphora resolution is an important task for information extraction across a\nrange of languages, text genres, and domains, motivating the need for methods\nthat do not require large annotated datasets. In-context learning has emerged\nas a promising approach, yet there are a number of challenges in applying\nin-context learning to resolve anaphora. For example, encoding a single\nin-context demonstration that consists of: an anaphor, a paragraph-length\ncontext, and a list of corresponding antecedents, requires conditioning a\nlanguage model on a long sequence of tokens, limiting the number of\ndemonstrations per prompt. In this paper, we present MICE (Mixtures of\nIn-Context Experts), which we demonstrate is effective for few-shot anaphora\nresolution in scientific protocols (Tamari et al., 2021). Given only a handful\nof training examples, MICE combines the predictions of hundreds of in-context\nexperts, yielding a 30% increase in F1 score over a competitive prompt\nretrieval baseline. Furthermore, we show MICE can be used to train compact\nstudent models without sacrificing performance. As far as we are aware, this is\nthe first work to present experimental results demonstrating the effectiveness\nof in-context learning on the task of few-shot anaphora resolution in\nscientific protocols.",
    "descriptor": "",
    "authors": [
      "Nghia T. Le",
      "Fan Bai",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03690"
  },
  {
    "id": "arXiv:2210.03692",
    "title": "Compressing Video Calls using Synthetic Talking Heads",
    "abstract": "We leverage the modern advancements in talking head generation to propose an\nend-to-end system for talking head video compression. Our algorithm transmits\npivot frames intermittently while the rest of the talking head video is\ngenerated by animating them. We use a state-of-the-art face reenactment network\nto detect key points in the non-pivot frames and transmit them to the receiver.\nA dense flow is then calculated to warp a pivot frame to reconstruct the\nnon-pivot ones. Transmitting key points instead of full frames leads to\nsignificant compression. We propose a novel algorithm to adaptively select the\nbest-suited pivot frames at regular intervals to provide a smooth experience.\nWe also propose a frame-interpolater at the receiver's end to improve the\ncompression levels further. Finally, a face enhancement network improves\nreconstruction quality, significantly improving several aspects like the\nsharpness of the generations. We evaluate our method both qualitatively and\nquantitatively on benchmark datasets and compare it with multiple compression\ntechniques. We release a demo video and additional information at\nhttps://cvit.iiit.ac.in/research/projects/cvit-projects/talking-video-compression.",
    "descriptor": "\nComments: British Machine Vision Conference (BMVC), 2022\n",
    "authors": [
      "Madhav Agarwal",
      "Anchit Gupta",
      "Rudrabha Mukhopadhyay",
      "Vinay P. Namboodiri",
      "C V Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03692"
  },
  {
    "id": "arXiv:2210.03693",
    "title": "Multi-Frequency-Aware Patch Adversarial Learning for Neural Point Cloud  Rendering",
    "abstract": "We present a neural point cloud rendering pipeline through a novel\nmulti-frequency-aware patch adversarial learning framework. The proposed\napproach aims to improve the rendering realness by minimizing the spectrum\ndiscrepancy between real and synthesized images, especially on the\nhigh-frequency localized sharpness information which causes image blur\nvisually. Specifically, a patch multi-discriminator scheme is proposed for the\nadversarial learning, which combines both spectral domain (Fourier Transform\nand Discrete Wavelet Transform) discriminators as well as the spatial (RGB)\ndomain discriminator to force the generator to capture global and local\nspectral distributions of the real images. The proposed multi-discriminator\nscheme not only helps to improve rendering realness, but also enhance the\nconvergence speed and stability of adversarial learning. Moreover, we introduce\na noise-resistant voxelisation approach by utilizing both the appearance\ndistance and spatial distance to exclude the spatial outlier points caused by\ndepth noise. Our entire architecture is fully differentiable and can be learned\nin an end-to-end fashion. Extensive experiments show that our method produces\nstate-of-the-art results for neural point cloud rendering by a significant\nmargin. Our source code will be made public at a later date.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Jay Karhade",
      "Haiyue Zhu",
      "Ka-Shing Chung",
      "Rajesh Tripathy",
      "Wei Lin",
      "Marcelo H. Ang Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.03693"
  },
  {
    "id": "arXiv:2210.03696",
    "title": "NMTSloth: Understanding and Testing Efficiency Degradation of Neural  Machine Translation Systems",
    "abstract": "Neural Machine Translation (NMT) systems have received much recent attention\ndue to their human-level accuracy. While existing works mostly focus on either\nimproving accuracy or testing accuracy robustness, the computation efficiency\nof NMT systems, which is of paramount importance due to often vast translation\ndemands and real-time requirements, has surprisingly received little attention.\nIn this paper, we make the first attempt to understand and test potential\ncomputation efficiency robustness in state-of-the-art NMT systems. By analyzing\nthe working mechanism and implementation of 1455 public-accessible NMT systems,\nwe observe a fundamental property in NMT systems that could be manipulated in\nan adversarial manner to reduce computation efficiency significantly. Our key\nmotivation is to generate test inputs that could sufficiently delay the\ngeneration of EOS such that NMT systems would have to go through enough\niterations to satisfy the pre-configured threshold. We present NMTSloth, which\ndevelops a gradient-guided technique that searches for a minimal and\nunnoticeable perturbation at character-level, token-level, and structure-level,\nwhich sufficiently delays the appearance of EOS and forces these inputs to\nreach the naturally-unreachable threshold. To demonstrate the effectiveness of\nNMTSloth, we conduct a systematic evaluation on three public-available NMT\nsystems: Google T5, AllenAI WMT14, and Helsinki-NLP translators. Experimental\nresults show that NMTSloth can increase NMT systems' response latency and\nenergy consumption by 85% to 3153% and 86% to 3052%, respectively, by\nperturbing just one character or token in the input sentence. Our case study\nshows that inputs generated by NMTSloth significantly affect the battery power\nin real-world mobile devices (i.e., drain more than 30 times battery power than\nnormal inputs).",
    "descriptor": "\nComments: This paper has been accepted to ESEC/FSE 2022\n",
    "authors": [
      "Simin Chen",
      "Cong Liu",
      "Mirazul Haque",
      "Zihe Song",
      "Wei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.03696"
  },
  {
    "id": "arXiv:2210.03699",
    "title": "Corrected Trapezoidal Rule-IBIM for linearized Poisson-Boltzmann  equation",
    "abstract": "In this paper, we solve the linearized Poisson-Boltzmann equation, used to\nmodel the electric potential of macromolecules in a solvent. We derive a\ncorrected trapezoidal rule with improved accuracy for a boundary integral\nformulation of the linearized Poisson-Boltzmann equation. More specifically, in\ncontrast to the typical boundary integral formulations, the corrected\ntrapezoidal rule is applied to integrate a system of compacted supported\nsingular integrals using uniform Cartesian grids in $\\mathbb{R}^3$, without\nexplicit surface parameterization. A Krylov method, accelerated by a fast\nmultipole method, is used to invert the resulting linear system. We study the\nefficacy of the proposed method, and compare it to an existing, lower order\nmethod. We then apply the method to the computation of electrostatic potential\nof macromolecules immersed in solvent. The solvent excluded surfaces, defined\nby a common approach, are merely piecewise smooth, and we study the\neffectiveness of the method for such surfaces.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Federico Izzo",
      "Yimin Zhong",
      "Olof Runborg",
      "Richard Tsai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03699"
  },
  {
    "id": "arXiv:2210.03701",
    "title": "VIRDO++: Real-World, Visuo-tactile Dynamics and Perception of Deformable  Objects",
    "abstract": "Deformable objects manipulation can benefit from representations that\nseamlessly integrate vision and touch while handling occlusions. In this work,\nwe present a novel approach for, and real-world demonstration of, multimodal\nvisuo-tactile state-estimation and dynamics prediction for deformable objects.\nOur approach, VIRDO++, builds on recent progress in multimodal neural implicit\nrepresentations for deformable object state-estimation [1] via a new\nformulation for deformation dynamics and a complementary state-estimation\nalgorithm that (i) maintains a belief over deformations, and (ii) enables\npractical real-world application by removing the need for privileged contact\ninformation. In the context of two real-world robotic tasks, we show:(i)\nhigh-fidelity cross-modal state-estimation and prediction of deformable objects\nfrom partial visuo-tactile feedback, and (ii) generalization to unseen objects\nand contact formations.",
    "descriptor": "",
    "authors": [
      "Youngsun Wi",
      "Andy Zeng",
      "Pete Florence",
      "Nima Fazeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03701"
  },
  {
    "id": "arXiv:2210.03704",
    "title": "Safe Path Planning for Polynomial Shape Obstacles via Control Barrier  Functions and Logistic Regression",
    "abstract": "Safe path planning is critical for bipedal robots to operate in\nsafety-critical environments. Common path planning algorithms, such as RRT or\nRRT*, typically use geometric or kinematic collision check algorithms to ensure\ncollision-free paths toward the target position. However, such approaches may\ngenerate non-smooth paths that do not comply with the dynamics constraints of\nwalking robots. It has been shown that the control barrier function (CBF) can\nbe integrated with RRT/RRT* to synthesize dynamically feasible collision-free\npaths. Yet, existing work has been limited to simple circular or elliptical\nshape obstacles due to the challenging nature of constructing appropriate\nbarrier functions to represent irregular-shaped obstacles. In this paper, we\npresent a CBF-based RRT* algorithm for bipedal robots to generate a\ncollision-free path through complex space with polynomial-shaped obstacles. In\nparticular, we used logistic regression to construct polynomial barrier\nfunctions from a grid map of the environment to represent arbitrarily shaped\nobstacles. Moreover, we developed a multi-step CBF steering controller to\nensure the efficiency of free space exploration. The proposed approach was\nfirst validated in simulation for a differential drive model, and then\nexperimentally evaluated with a 3D humanoid robot, Digit, in a lab setting with\nrandomly placed obstacles.",
    "descriptor": "\nComments: 7 pages, 8 figures. Supplemental Video: this https URL\n",
    "authors": [
      "Chengyang Peng",
      "Octavian Donca",
      "Ayonga Hereid"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03704"
  },
  {
    "id": "arXiv:2210.03709",
    "title": "Understanding Practices, Challenges, and Opportunities for User-Driven  Algorithm Auditing in Industry Practice",
    "abstract": "Recent years have seen growing interest among both researchers and\npractitioners in user-driven approaches to algorithm auditing, which directly\nengage users in detecting problematic behaviors in algorithmic systems.\nHowever, we know little about industry practitioners' current practices and\nchallenges around user-driven auditing, nor what opportunities exist for them\nto better leverage such approaches in practice. To investigate, we conducted a\nseries of interviews and iterative co-design activities with practitioners who\nemploy user-driven auditing approaches in their work. Our findings reveal\nseveral challenges practitioners face in appropriately recruiting and\nincentivizing user auditors, scaffolding user audits, and deriving actionable\ninsights from user-driven audit reports. Furthermore, practitioners shared\norganizational obstacles to user-driven auditing, surfacing a complex\nrelationship between practitioners and user auditors. Based on these findings,\nwe discuss opportunities for future HCI research to help realize the potential\n(and mitigate risks) of user-driven auditing in industry practice.",
    "descriptor": "\nComments: Pre-print in double-column format\n",
    "authors": [
      "Wesley Hanwen Deng",
      "Bill Boyuan Guo",
      "Alicia Devos",
      "Hong Shen",
      "Motahhare Eslami",
      "Kenneth Holstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03709"
  },
  {
    "id": "arXiv:2210.03713",
    "title": "Integration of Riemannian Motion Policy and Whole-Body Control for  Dynamic Legged Locomotion",
    "abstract": "In this paper, we present a novel Riemannian Motion Policy (RMP)flow-based\nwhole-body control framework for improved dynamic legged locomotion. RMPflow is\na differential geometry-inspired algorithm for fusing multiple task-space\npolicies (RMPs) into a configuration space policy in a geometrically consistent\nmanner. RMP-based approaches are especially suited for designing simultaneous\ntracking and collision avoidance behaviors and have been successfully deployed\non serial manipulators. However, one caveat of RMPflow is that it is designed\nwith fully actuated systems in mind. In this work, we, for the first time,\nextend it to the domain of dynamic-legged systems, which have unforgiving\nunder-actuation and limited control input. Thorough push recovery experiments\nare conducted in simulation to validate the overall framework. We show that\nexpanding the valid stepping region with an RMP-based collision-avoidance swing\nleg controller improves balance robustness against external disturbances by up\nto $53\\%$ compared to a baseline approach using a restricted stepping region.\nFurthermore, a point-foot biped robot is purpose-built for experimental studies\nof dynamic biped locomotion. A preliminary unassisted in-place stepping\nexperiment is conducted to show the viability of the control framework and\nhardware.",
    "descriptor": "",
    "authors": [
      "Daniel Marew",
      "Misha Lvovsky",
      "Shangqun Yu",
      "Shotaro Sessions",
      "Donghyun Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03713"
  },
  {
    "id": "arXiv:2210.03714",
    "title": "Parallel Computation of functions of matrices and their action on  vectors",
    "abstract": "We present a novel class of methods to compute functions of matrices or their\naction on vectors that are suitable for parallel programming. Solving\nappropriate simple linear systems of equations in parallel (or computing the\ninverse of several matrices) and with a proper linear combination of the\nresults, allows us to obtain new high order approximations to the desired\nfunctions of matrices. An error analysis to obtain forward and backward error\nbounds is presented. The coefficients of each method, which depends on the\nnumber of processors, can be adjusted to improve the accuracy, the stability or\nto reduce round off errors of the methods. We illustrate this procedure by\nexplicitly constructing some methods which are then tested on several numerical\nexamples.",
    "descriptor": "",
    "authors": [
      "Sergio Blanes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03714"
  },
  {
    "id": "arXiv:2210.03718",
    "title": "Integration of Skyline Queries into Spark SQL",
    "abstract": "Skyline queries are frequently used in data analytics and multi-criteria\ndecision support applications to filter relevant information from big amounts\nof data. Apache Spark is a popular framework for processing big, distributed\ndata. The framework even provides a convenient SQL-like interface via the Spark\nSQL module. However, skyline queries are not natively supported and require\ntedious rewriting to fit the SQL standard or Spark's SQL-like language. The\ngoal of our work is to fill this gap. We thus provide a full-fledged\nintegration of the skyline operator into Spark SQL. This allows for a simple\nand easy to use syntax to input skyline queries. Moreover, our empirical\nresults show that this integrated solution of skyline queries by far\noutperforms a solution based on rewriting into standard SQL.",
    "descriptor": "",
    "authors": [
      "Lukas Grasmann",
      "Reinhard Pichler",
      "Alexander Selzer"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.03718"
  },
  {
    "id": "arXiv:2210.03719",
    "title": "BayesImposter: Bayesian Estimation Based .bss Imposter Attack on  Industrial Control Systems",
    "abstract": "Over the last six years, several papers used memory deduplication to trigger\nvarious security issues, such as leaking heap-address and causing bit-flip in\nthe physical memory. The most essential requirement for successful memory\ndeduplication is to provide identical copies of a physical page. Recent works\nuse a brute-force approach to create identical copies of a physical page that\nis an inaccurate and time-consuming primitive from the attacker's perspective.\nOur work begins to fill this gap by providing a domain-specific structured\nway to duplicate a physical page in cloud settings in the context of industrial\ncontrol systems (ICSs). Here, we show a new attack primitive -\n\\textit{BayesImposter}, which points out that the attacker can duplicate the\n.bss section of the target control DLL file of cloud protocols using the\n\\textit{Bayesian estimation} technique. Our approach results in less memory\n(i.e., 4 KB compared to GB) and time (i.e., 13 minutes compared to hours)\ncompared to the brute-force approach used in recent works. We point out that\nICSs can be expressed as state-space models; hence, the \\textit{Bayesian\nestimation} is an ideal choice to be combined with memory deduplication for a\nsuccessful attack in cloud settings. To demonstrate the strength of\n\\textit{BayesImposter}, we create a real-world automation platform using a\nscaled-down automated high-bay warehouse and industrial-grade SIMATIC S7-1500\nPLC from Siemens as a target ICS. We demonstrate that \\textit{BayesImposter}\ncan predictively inject false commands into the PLC that can cause possible\nequipment damage with machine failure in the target ICS. Moreover, we show that\n\\textit{BayesImposter} is capable of adversarial control over the target ICS\nresulting in severe consequences, such as killing a person but making it looks\nlike an accident. Therefore, we also provide countermeasures to prevent the\nattack.",
    "descriptor": "",
    "authors": [
      "Anomadarshi Barua",
      "Lelin Pan",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03719"
  },
  {
    "id": "arXiv:2210.03724",
    "title": "PMT: Power Measurement Toolkit",
    "abstract": "Efficient use of energy is essential for today's supercomputing systems, as\nenergy cost is generally a major component of their operational cost. Research\ninto \"green computing\" is needed to reduce the environmental impact of running\nthese systems. As such, several scientific communities are evaluating the\ntrade-off between time-to-solution and energy-to-solution. While the runtime of\nan application is typically easy to measure, power consumption is not.\nTherefore, we present the Power Measurement Toolkit (PMT), a high-level\nsoftware library capable of collecting power consumption measurements on\nvarious hardware. The library provides a standard interface to easily measure\nthe energy use of devices such as CPUs and GPUs in critical application\nsections.",
    "descriptor": "",
    "authors": [
      "Stefano Corda",
      "Bram Veenboer",
      "Emma Tolley"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.03724"
  },
  {
    "id": "arXiv:2210.03728",
    "title": "Atomized Deep Learning Models",
    "abstract": "Deep learning models often tackle the intra-sample structure, such as the\norder of words in a sentence and pixels in an image, but have not pay much\nattention to the inter-sample relationship. In this paper, we show that\nexplicitly modeling the inter-sample structure to be more discretized can\npotentially help model's expressivity. We propose a novel method, Atom\nModeling, that can discretize a continuous latent space by drawing an analogy\nbetween a data point and an atom, which is naturally spaced away from other\natoms with distances depending on their intra structures. Specifically, we\nmodel each data point as an atom composed of electrons, protons, and neutrons\nand minimize the potential energy caused by the interatomic force among data\npoints. Through experiments with qualitative analysis in our proposed Atom\nModeling on synthetic and real datasets, we find that Atom Modeling can improve\nthe performance by maintaining the inter-sample relation and can capture an\ninterpretable intra-sample relation by mapping each component in a data point\nto electron/proton/neutron.",
    "descriptor": "",
    "authors": [
      "Yi-Lin Tuan",
      "Zih-Yun Chiu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03728"
  },
  {
    "id": "arXiv:2210.03729",
    "title": "Knowledge-Grounded Reinforcement Learning",
    "abstract": "Receiving knowledge, abiding by laws, and being aware of regulations are\ncommon behaviors in human society. Bearing in mind that reinforcement learning\n(RL) algorithms benefit from mimicking humanity, in this work, we propose that\nan RL agent can act on external guidance in both its learning process and model\ndeployment, making the agent more socially acceptable. We introduce the\nconcept, Knowledge-Grounded RL (KGRL), with a formal definition that an agent\nlearns to follow external guidelines and develop its own policy. Moving towards\nthe goal of KGRL, we propose a novel actor model with an embedding-based\nattention mechanism that can attend to either a learnable internal policy or\nexternal knowledge. The proposed method is orthogonal to training algorithms,\nand the external knowledge can be flexibly recomposed, rearranged, and reused\nin both training and inference stages. Through experiments on tasks with\ndiscrete and continuous action space, our KGRL agent is shown to be more sample\nefficient and generalizable, and it has flexibly rearrangeable knowledge\nembeddings and interpretable behaviors.",
    "descriptor": "",
    "authors": [
      "Zih-Yun Chiu",
      "Yi-Lin Tuan",
      "William Yang Wang",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03729"
  },
  {
    "id": "arXiv:2210.03730",
    "title": "SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder  Based Speech-Text Pre-training",
    "abstract": "The rapid development of single-modal pre-training has prompted researchers\nto pay more attention to cross-modal pre-training methods. In this paper, we\npropose a unified-modal speech-unit-text pre-training model, SpeechUT, to\nconnect the representations of a speech encoder and a text decoder with a\nshared unit encoder. Leveraging hidden-unit as an interface to align speech and\ntext, we can decompose the speech-to-text model into a speech-to-unit model and\na unit-to-text model, which can be jointly pre-trained with unpaired speech and\ntext data respectively. Our proposed SpeechUT is fine-tuned and evaluated on\nautomatic speech recognition (ASR) and speech translation (ST) tasks.\nExperimental results show that SpeechUT gets substantial improvements over\nstrong baselines, and achieves state-of-the-art performance on both the\nLibriSpeech ASR and MuST-C ST tasks. To better understand the proposed\nSpeechUT, detailed analyses are conducted. The code and pre-trained models are\navailable at https://aka.ms/SpeechUT.",
    "descriptor": "\nComments: 14 pages, accepted by EMNLP 2022\n",
    "authors": [
      "Ziqiang Zhang",
      "Long Zhou",
      "Junyi Ao",
      "Shujie Liu",
      "Lirong Dai",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.03730"
  },
  {
    "id": "arXiv:2210.03731",
    "title": "Demystifying Map Space Exploration for NPUs",
    "abstract": "Map Space Exploration is the problem of finding optimized mappings of a Deep\nNeural Network (DNN) model on an accelerator. It is known to be extremely\ncomputationally expensive, and there has been active research looking at both\nheuristics and learning-based methods to make the problem computationally\ntractable. However, while there are dozens of mappers out there (all\nempirically claiming to find better mappings than others), the research\ncommunity lacks systematic insights on how different search techniques navigate\nthe map-space and how different mapping axes contribute to the accelerator's\nperformance and efficiency. Such insights are crucial to developing mapping\nframeworks for emerging DNNs that are increasingly irregular (due to neural\narchitecture search) and sparse, making the corresponding map spaces much more\ncomplex. In this work, rather than proposing yet another mapper, we do a\nfirst-of-its-kind apples-to-apples comparison of search techniques leveraged by\ndifferent mappers. Next, we extract the learnings from our study and propose\ntwo new techniques that can augment existing mappers -- warm-start and\nsparsity-aware -- that demonstrate speedups, scalability, and robustness across\ndiverse DNN models.",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Angshuman Parashar",
      "Po-An Tsai",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.03731"
  },
  {
    "id": "arXiv:2210.02595",
    "title": "Exploration of A Self-Supervised Speech Model: A Study on Emotional  Corpora",
    "abstract": "Self-supervised speech models have grown fast during the past few years and\nhave proven feasible for use in various downstream tasks. Some recent work has\nstarted to look at the characteristics of these models, yet many concerns have\nnot been fully addressed. In this work, we conduct a study on emotional corpora\nto explore a popular self-supervised model -- wav2vec 2.0. Via a set of\nquantitative analysis, we mainly demonstrate that: 1) wav2vec 2.0 appears to\ndiscard paralinguistic information that is less useful for word recognition\npurposes; 2) for emotion recognition, representations from the middle layer\nalone perform as well as those derived from layer averaging, while the final\nlayer results in the worst performance in some cases; 3) current\nself-supervised models may not be the optimal solution for downstream tasks\nthat make use of non-lexical features. Our work provides novel findings that\nwill aid future research in this area and theoretical basis for the use of\nexisting models.",
    "descriptor": "\nComments: Accepted for SLT 2022\n",
    "authors": [
      "Yuanchao Li",
      "Yumnah Mohamied",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.02595"
  },
  {
    "id": "arXiv:2210.03151",
    "title": "Integrative Imaging Informatics for Cancer Research: Workflow Automation  for Neuro-oncology (I3CR-WANO)",
    "abstract": "Efforts to utilize growing volumes of clinical imaging data to generate tumor\nevaluations continue to require significant manual data wrangling owing to the\ndata heterogeneity. Here, we propose an artificial intelligence-based solution\nfor the aggregation and processing of multisequence neuro-oncology MRI data to\nextract quantitative tumor measurements. Our end-to-end framework i) classifies\nMRI sequences using an ensemble classifier, ii) preprocesses the data in a\nreproducible manner, iii) delineates tumor tissue subtypes using convolutional\nneural networks, and iv) extracts diverse radiomic features. Moreover, it is\nrobust to missing sequences and adopts an expert-in-the-loop approach, where\nthe segmentation results may be manually refined by radiologists. Following the\nimplementation of the framework in Docker containers, it was applied to two\nretrospective glioma datasets collected from the Washington University School\nof Medicine (WUSM; n = 384) and the M.D. Anderson Cancer Center (MDA; n = 30)\ncomprising preoperative MRI scans from patients with pathologically confirmed\ngliomas. The scan-type classifier yielded an accuracy of over 99%, correctly\nidentifying sequences from 380/384 and 30/30 sessions from the WUSM and MDA\ndatasets, respectively. Segmentation performance was quantified using the Dice\nSimilarity Coefficient between the predicted and expert-refined tumor masks.\nMean Dice scores were 0.882 ($\\pm$0.244) and 0.977 ($\\pm$0.04) for whole tumor\nsegmentation for WUSM and MDA, respectively. This streamlined framework\nautomatically curated, processed, and segmented raw MRI data of patients with\nvarying grades of gliomas, enabling the curation of large-scale neuro-oncology\ndatasets and demonstrating a high potential for integration as an assistive\ntool in clinical practice.",
    "descriptor": "",
    "authors": [
      "Satrajit Chakrabarty",
      "Syed Amaan Abidi",
      "Mina Mousa",
      "Mahati Mokkarala",
      "Isabelle Hren",
      "Divya Yadav",
      "Matthew Kelsey",
      "Pamela LaMontagne",
      "John Wood",
      "Michael Adams",
      "Yuzhuo Su",
      "Sherry Thorpe",
      "Caroline Chung",
      "Aristeidis Sotiras",
      "Daniel S. Marcus"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03151"
  },
  {
    "id": "arXiv:2210.03155",
    "title": "Understanding Neural Coding on Latent Manifolds by Sharing Features and  Dividing Ensembles",
    "abstract": "Systems neuroscience relies on two complementary views of neural data,\ncharacterized by single neuron tuning curves and analysis of population\nactivity. These two perspectives combine elegantly in neural latent variable\nmodels that constrain the relationship between latent variables and neural\nactivity, modeled by simple tuning curve functions. This has recently been\ndemonstrated using Gaussian processes, with applications to realistic and\ntopologically relevant latent manifolds. Those and previous models, however,\nmissed crucial shared coding properties of neural populations. We propose\nfeature sharing across neural tuning curves, which significantly improves\nperformance and leads to better-behaved optimization. We also propose a\nsolution to the problem of ensemble detection, whereby different groups of\nneurons, i.e., ensembles, can be modulated by different latent manifolds. This\nis achieved through a soft clustering of neurons during training, thus allowing\nfor the separation of mixed neural populations in an unsupervised manner. These\ninnovations lead to more interpretable models of neural population activity\nthat train well and perform better even on mixtures of complex latent\nmanifolds. Finally, we apply our method on a recently published grid cell\ndataset, recovering distinct ensembles, inferring toroidal latents and\npredicting neural tuning curves all in a single integrated modeling framework.",
    "descriptor": "",
    "authors": [
      "Martin Bjerke",
      "Lukas Schott",
      "Kristopher T. Jensen",
      "Claudia Battistin",
      "David A. Klindt",
      "Benjamin A. Dunn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.03155"
  },
  {
    "id": "arXiv:2210.03178",
    "title": "Probabilistic Model Incorporating Auxiliary Covariates to Control FDR",
    "abstract": "Controlling False Discovery Rate (FDR) while leveraging the side information\nof multiple hypothesis testing is an emerging research topic in modern data\nscience. Existing methods rely on the test-level covariates while ignoring\nmetrics about test-level covariates. This strategy may not be optimal for\ncomplex large-scale problems, where indirect relations often exist among\ntest-level covariates and auxiliary metrics or covariates. We incorporate\nauxiliary covariates among test-level covariates in a deep Black-Box framework\ncontrolling FDR (named as NeurT-FDR) which boosts statistical power and\ncontrols FDR for multiple-hypothesis testing. Our method parametrizes the\ntest-level covariates as a neural network and adjusts the auxiliary covariates\nthrough a regression framework, which enables flexible handling of\nhigh-dimensional features as well as efficient end-to-end optimization. We show\nthat NeurT-FDR makes substantially more discoveries in three real datasets\ncompared to competitive baselines.",
    "descriptor": "\nComments: Short Version of NeurT-FDR, accepted at CIKM 2022. arXiv admin note: substantial text overlap with arXiv:2101.09809\n",
    "authors": [
      "Lin Qiu",
      "Nils Murrugarra-Llerena",
      "V\u00edtor Silva",
      "Lin Lin",
      "Vernon M. Chinchilli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03178"
  },
  {
    "id": "arXiv:2210.03180",
    "title": "A ResNet is All You Need? Modeling A Strong Baseline for Detecting  Referable Diabetic Retinopathy in Fundus Images",
    "abstract": "Deep learning is currently the state-of-the-art for automated detection of\nreferable diabetic retinopathy (DR) from color fundus photographs (CFP). While\nthe general interest is put on improving results through methodological\ninnovations, it is not clear how good these approaches perform compared to\nstandard deep classification models trained with the appropriate settings. In\nthis paper we propose to model a strong baseline for this task based on a\nsimple and standard ResNet-18 architecture. To this end, we built on top of\nprior art by training the model with a standard preprocessing strategy but\nusing images from several public sources and an empirically calibrated data\naugmentation setting. To evaluate its performance, we covered multiple\nclinically relevant perspectives, including image and patient level DR\nscreening, discriminating responses by input quality and DR grade, assessing\nmodel uncertainties and analyzing its results in a qualitative manner. With no\nother methodological innovation than a carefully designed training, our ResNet\nmodel achieved an AUC = 0.955 (0.953 - 0.956) on a combined test set of 61007\ntest images from different public datasets, which is in line or even better\nthan what other more complex deep learning models reported in the literature.\nSimilar AUC values were obtained in 480 images from two separate in-house\ndatabases specially prepared for this study, which emphasize its generalization\nability. This confirms that standard networks can still be strong baselines for\nthis task if properly trained.",
    "descriptor": "\nComments: Accepted for publication at the 18th International Symposium on Medical Information Processing and Analysis (SIPAIM 2022)\n",
    "authors": [
      "Tom\u00e1s Castilla",
      "Marcela S. Mart\u00ednez",
      "Mercedes Legu\u00eda",
      "Ignacio Larrabide",
      "Jos\u00e9 Ignacio Orlando"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03180"
  },
  {
    "id": "arXiv:2210.03189",
    "title": "FocalUNETR: A Focal Transformer for Boundary-aware Segmentation of CT  Images",
    "abstract": "Computed Tomography (CT) based precise prostate segmentation for treatment\nplanning is challenging due to (1) the unclear boundary of prostate derived\nfrom CTs poor soft tissue contrast, and (2) the limitation of convolutional\nneural network based models in capturing long-range global context. Here we\npropose a focal transformer based image segmentation architecture to\neffectively and efficiently extract local visual features and global context\nfrom CT images. Furthermore, we design a main segmentation task and an\nauxiliary boundary-induced label regression task as regularization to\nsimultaneously optimize segmentation results and mitigate the unclear boundary\neffect, particularly in unseen data set. Extensive experiments on a large data\nset of 400 prostate CT scans demonstrate the superior performance of our focal\ntransformer to the competing methods on the prostate segmentation task.",
    "descriptor": "\nComments: 13 pages, 3 figures, 2 tables\n",
    "authors": [
      "Chengyin Li",
      "Hassan Bagher-Ebadian",
      "Vikram Goddla",
      "Indrin J. Chetty",
      "Dongxiao Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03189"
  },
  {
    "id": "arXiv:2210.03192",
    "title": "Memory-Efficient Recursive Evaluation of 3-Center Gaussian Integrals",
    "abstract": "To improve the efficiency of Gaussian integral evaluation on modern\naccelerated architectures FLOP-efficient Obara-Saika-based recursive evaluation\nschemes are optimized for the memory footprint. For the 3-center 2-particle\nintegrals that are key for the evaluation of Coulomb and other 2-particle\ninteractions in the density-fitting approximation the use of multi-quantal\nrecurrences (in which multiple quanta are created or transferred at once) is\nshown to produce significant memory savings. Other innovation include\nleveraging register memory for reduced memory footprint and direct compile-time\ngeneration of optimized kernels (instead of custom code generation) with\ncompile-time features of modern C++/CUDA. High efficiency of the CPU- and\nCUDA-based implementation of the proposed schemes is demonstrated for both the\nindividual batches of integrals involving up to Gaussians with low and high\nangular momenta (up to $L=6$) and contraction degrees, as well as for the\ndensity-fitting-based evaluation of the Coulomb potential. The computer\nimplementation is available in the open-source LibintX library.",
    "descriptor": "\nComments: 37 pages, 2 figures, 6 tables\n",
    "authors": [
      "Andrey Asadchev",
      "Edward F. Valeev"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Mathematical Software (cs.MS)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03192"
  },
  {
    "id": "arXiv:2210.03232",
    "title": "Decentralized Constrained Optimization, Double Averaging and Gradient  Projection",
    "abstract": "We consider a generic decentralized constrained optimization problem over\nstatic, directed communication networks, where each agent has exclusive access\nto only one convex, differentiable, local objective term and one convex\nconstraint set. For this setup, we propose a novel decentralized algorithm,\ncalled DAGP (Double Averaging and Gradient Projection), based on local\ngradients, projection onto local constraints, and local averaging. We achieve\nglobal optimality through a novel distributed tracking technique we call\ndistributed null projection. Further, we show that DAGP can also be used to\nsolve unconstrained problems with non-differentiable objective terms, by\nemploying the so-called epigraph projection operators (EPOs). In this regard,\nwe introduce a new fast algorithm for evaluating EPOs. We study the convergence\nof DAGP and establish $\\mathcal{O}(1/\\sqrt{K})$ convergence in terms of\nfeasibility, consensus, and optimality. For this reason, we forego the\ndifficulties of selecting Lyapunov functions by proposing a new methodology of\nconvergence analysis in optimization problems, which we refer to as aggregate\nlower-bounding. To demonstrate the generality of this method, we also provide\nan alternative convergence proof for the gradient descent algorithm for smooth\nfunctions. Finally, we present numerical results demonstrating the\neffectiveness of our proposed method in both constrained and unconstrained\nproblems.",
    "descriptor": "",
    "authors": [
      "Firooz Shahriari-Mehr",
      "Ashkan Panahi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.03232"
  },
  {
    "id": "arXiv:2210.03242",
    "title": "Disentangling Mixtures of Unknown Causal Interventions",
    "abstract": "In many real-world scenarios, such as gene knockout experiments, targeted\ninterventions are often accompanied by unknown interventions at off-target\nsites. Moreover, different units can get randomly exposed to different unknown\ninterventions, thereby creating a mixture of interventions. Identifying\ndifferent components of this mixture can be very valuable in some applications.\nMotivated by such situations, in this work, we study the problem of identifying\nall components present in a mixture of interventions on a given causal Bayesian\nNetwork. We construct an example to show that, in general, the components are\nnot identifiable from the mixture distribution. Next, assuming that the given\nnetwork satisfies a positivity condition, we show that, if the set of mixture\ncomponents satisfy a mild exclusion assumption, then they can be uniquely\nidentified. Our proof gives an efficient algorithm to recover these targets\nfrom the exponentially large search space of possible targets. In the more\nrealistic scenario, where distributions are given via finitely many samples, we\nconduct a simulation study to analyze the performance of an algorithm derived\nfrom our identifiability proof.",
    "descriptor": "",
    "authors": [
      "Abhinav Kumar",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03242"
  },
  {
    "id": "arXiv:2210.03266",
    "title": "Maximum Likelihood-based Gridless DoA Estimation Using Structured  Covariance Matrix Recovery and SBL with Grid Refinement",
    "abstract": "We consider the parametric data model employed in applications such as line\nspectral estimation and direction-of-arrival estimation. We focus on the\nstochastic maximum likelihood estimation (MLE) framework and offer approaches\nto estimate the parameter of interest in a gridless manner, overcoming the\nmodel complexities of the past. This progress is enabled by the modern trend of\nreparameterization of the objective and exploiting the sparse Bayesian learning\n(SBL) approach. The latter is shown to be a correlation-aware method, and for\nthe underlying problem it is identified as a grid-based technique for\nrecovering a structured covariance matrix of the measurements. For the case\nwhen the structured matrix is expressible as a sampled Toeplitz matrix, such as\nwhen measurements are sampled in time or space at regular intervals, additional\nconstraints and reparameterization of the SBL objective leads to the proposed\nstructured matrix recovery technique based on MLE. The proposed optimization\nproblem is non-convex, and we propose a majorization-minimization based\niterative procedure to estimate the structured matrix; each iteration solves a\nsemidefinite program. We recover the parameter of interest in a gridless manner\nby appealing to the Caratheodory-Fejer result on decomposition of PSD Toeplitz\nmatrices. For the general case of irregularly spaced time or spatial samples,\nwe propose an iterative SBL procedure that refines grid points to increase\nresolution near potential source locations, while maintaining a low per\niteration complexity. We provide numerical results to evaluate and compare the\nperformance of the proposed techniques with other gridless techniques, and the\nCRB. The proposed correlation-aware approach is more robust to\nenvironmental/system effects such as low number of snapshots, correlated\nsources, small separation between source locations and improves sources\nidentifiability.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Signal Processing (Previous submission date: 29-Oct-2021)\n",
    "authors": [
      "Rohan R. Pote",
      "Bhaskar D. Rao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03266"
  },
  {
    "id": "arXiv:2210.03279",
    "title": "Extended water wave systems of Boussinesq equations on a finite  interval: Theory and numerical analysis",
    "abstract": "Considered here is a class of Boussinesq systems of Nwogu type. Such systems\ndescribe propagation of nonlinear and dispersive water waves of significant\ninterest such as solitary and tsunami waves. The initial-boundary value problem\non a finite interval for this family of systems is studied both theoretically\nand numerically. First, the linearization of a certain generalized Nwogu system\nis solved analytically via the unified transform of Fokas. The corresponding\nanalysis reveals two types of admissible boundary conditions, thereby\nsuggesting appropriate boundary conditions for the nonlinear Nwogu system on a\nfinite interval. Then, well-posedness is established, both in the weak and in\nthe classical sense, for a regularized Nwogu system in the context of an\ninitial-boundary value problem that describes the dynamics of water waves in a\nbasin with wall-boundary conditions. In addition, a new modified Galerkin\nmethod is suggested for the numerical discretization of this regularized system\nin time, and its convergence is proved along with optimal error estimates.\nFinally, numerical experiments illustrating the effect of the boundary\nconditions on the reflection of solitary waves by a vertical wall are also\nprovided.",
    "descriptor": "",
    "authors": [
      "Dionyssios Mantzavinos",
      "Dimitrios Mitsotakis"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03279"
  },
  {
    "id": "arXiv:2210.03298",
    "title": "Simulation of Transients in Natural Gas Networks via A Semi-analytical  Solution Approach",
    "abstract": "Simulation and control of the transient flow in natural gas networks involve\nsolving partial differential equations (PDEs). This paper proposes a\nsemi-analytical solutions (SAS) approach for fast and accurate simulation of\nthe natural gas transients. The region of interest is divided into a grid, and\nan SAS is derived for each grid cell in the form of the multivariate\npolynomials, of which the coefficients are identified according to the initial\nvalue and boundary value conditions. The solutions are solved in a\n``time-stepping'' manner; that is, within one time step, the coefficients of\nthe SAS are identified and the initial value of the next time step is\nevaluated. This approach achieves a much larger grid cell than the widely used\nfinite difference method, and thus enhances the computational efficiency\nsignificantly. To further reduce the computation burden, the nonlinear terms in\nthe model are simplified, which induces another SAS scheme that can greatly\nreduce the time consumption and have minor impact on accuracy. The simulation\nresults on a single pipeline case and a 6-node network case validate the\nadvantages of the proposed SAS approach in accuracy and computational\nefficiency.",
    "descriptor": "",
    "authors": [
      "Xin Xu",
      "Rui Yao",
      "Kai Sun",
      "Feng Qiu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03298"
  },
  {
    "id": "arXiv:2210.03301",
    "title": "GOLLIC: Learning Global Context beyond Patches for Lossless  High-Resolution Image Compression",
    "abstract": "Neural-network-based approaches recently emerged in the field of data\ncompression and have already led to significant progress in image compression,\nespecially in achieving a higher compression ratio. In the lossless image\ncompression scenario, however, existing methods often struggle to learn a\nprobability model of full-size high-resolution images due to the limitation of\nthe computation source. The current strategy is to crop high-resolution images\ninto multiple non-overlapping patches and process them independently. This\nstrategy ignores long-term dependencies beyond patches, thus limiting modeling\nperformance. To address this problem, we propose a hierarchical latent variable\nmodel with a global context to capture the long-term dependencies of\nhigh-resolution images. Besides the latent variable unique to each patch, we\nintroduce shared latent variables between patches to construct the global\ncontext. The shared latent variables are extracted by a self-supervised\nclustering module inside the model's encoder. This clustering module assigns\neach patch the confidence that it belongs to any cluster. Later, shared latent\nvariables are learned according to latent variables of patches and their\nconfidence, which reflects the similarity of patches in the same cluster and\nbenefits the global context modeling. Experimental results show that our global\ncontext model improves compression ratio compared to the engineered codecs and\ndeep learning models on three benchmark high-resolution image datasets, DIV2K,\nCLIC.pro, and CLIC.mobile.",
    "descriptor": "",
    "authors": [
      "Yuan Lan",
      "Liang Qin",
      "Zhaoyi Sun",
      "Yang Xiang",
      "Jie Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03301"
  },
  {
    "id": "arXiv:2210.03354",
    "title": "Adversarial network training using higher-order moments in a modified  Wasserstein distance",
    "abstract": "Generative-adversarial networks (GANs) have been used to produce data closely\nresembling example data in a compressed, latent space that is close to\nsufficient for reconstruction in the original vector space. The Wasserstein\nmetric has been used as an alternative to binary cross-entropy, producing more\nnumerically stable GANs with greater mode covering behavior. Here, a\ngeneralization of the Wasserstein distance, using higher-order moments than the\nmean, is derived. Training a GAN with this higher-order Wasserstein metric is\ndemonstrated to exhibit superior performance, even when adjusted for slightly\nhigher computational cost. This is illustrated generating synthetic antibody\nsequences.",
    "descriptor": "",
    "authors": [
      "Oliver Serang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03354"
  },
  {
    "id": "arXiv:2210.03379",
    "title": "Geomagnetic Survey Interpolation with the Machine Learning Approach",
    "abstract": "This paper portrays the method of UAV magnetometry survey data interpolation.\nThe method accommodates the fact that this kind of data has a spatial\ndistribution of the samples along a series of straight lines (similar to\nmaritime tacks), which is a prominent characteristic of many kinds of UAV\nsurveys. The interpolation relies on the very basic Nearest Neighbours\nalgorithm, although augmented with a Machine Learning approach. Such an\napproach enables the error of less than 5 percent by intelligently adjusting\nthe Nearest Neighbour algorithm parameters. The method was pilot tested on\ngeomagnetic data with Borok Geomagnetic Observatory UAV aeromagnetic survey\ndata.",
    "descriptor": "",
    "authors": [
      "Igor Aleshin",
      "Kirill Kholodkov",
      "Ivan Malygin",
      "Roman Shevchuk",
      "Roman Sidorov"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03379"
  },
  {
    "id": "arXiv:2210.03394",
    "title": "One-Wayness in Quantum Cryptography",
    "abstract": "The existence of one-way functions is one of the most fundamental assumptions\nin classical cryptography. In the quantum world, on the other hand, there are\nevidences that some cryptographic primitives can exist even if one-way\nfunctions do not exist. We therefore have the following important open problem\nin quantum cryptography: What is the most fundamental element in quantum\ncryptography? In this direction, Brakerski, Canetti, and Qian recently defined\na notion called EFI pairs, which are pairs of efficiently generatable states\nthat are statistically distinguishable but computationally indistinguishable,\nand showed its equivalence with some cryptographic primitives including\ncommitments, oblivious transfer, and general multi-party computations. However,\ntheir work focuses on decision-type primitives and does not cover search-type\nprimitives like quantum money and digital signatures. In this paper, we study\nproperties of one-way state generators (OWSGs), which are a quantum analogue of\none-way functions. We first revisit the definition of OWSGs and generalize it\nby allowing mixed output states. Then we show the following results. (1) We\ndefine a weaker version of OWSGs, weak OWSGs, and show that they are equivalent\nto OWSGs. (2) Quantum digital signatures are equivalent to OWSGs. (3)\nPrivate-key quantum money schemes (with pure money states) imply OWSGs. (4)\nQuantum pseudo one-time pad schemes imply both OWSGs and EFI pairs. (5) We\nintroduce an incomparable variant of OWSGs, which we call secretly-verifiable\nand statistically-invertible OWSGs, and show that they are equivalent to EFI\npairs.",
    "descriptor": "\nComments: 39 pages, 1 figure\n",
    "authors": [
      "Tomoyuki Morimae",
      "Takashi Yamakawa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03394"
  },
  {
    "id": "arXiv:2210.03410",
    "title": "Majority of Majorities on Regular Graphs with Loops",
    "abstract": "In this paper, we study the following problem. Consider a setting where a\nproposal is offered to the vertices of a given network $G$, and the vertices\nmust conduct a vote and decide whether to accept the proposal or reject it.\nEach vertex $v$ has its own valuation of the proposal; we say that $v$ is\n\"happy\" if its valuation is positive (i.e., it expects to gain from adopting\nthe proposal) and \"sad\" if its valuation is negative. However, vertices do not\nbase their vote merely on their own valuation. Rather, a vertex $v$ is a\nproponent of the proposal if a majority of its neighbors are happy with it and\nan opponent in the opposite case. At the end of the vote, the network\ncollectively accepts the proposal whenever a majority of its vertices are\nproponents. We study this problem on regular graphs with loops. Specifically,\nwe consider the class ${\\mathcal G}_{n|d|h}$ of $d$-regular graphs of odd order\n$n$ with all $n$ loops and $h$ happy vertices. We are interested in\nestablishing necessary and sufficient conditions for the class ${\\mathcal\nG}_{n|d|h}$ to contain a labeled graph accepting the proposal, as well as\nconditions to contain a graph rejecting the proposal. We also discuss\nconnections to the existing literature and investigate some properties of the\nobtained conditions.",
    "descriptor": "\nComments: 28 pages, 8 figures, submitted to a SIAM journal\n",
    "authors": [
      "Pavel Chebotarev",
      "David Peleg"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03410"
  },
  {
    "id": "arXiv:2210.03430",
    "title": "Monitoring MBE substrate deoxidation via RHEED image-sequence analysis  by deep learning",
    "abstract": "Reflection high-energy electron diffraction (RHEED) is a powerful tool in\nmolecular beam epitaxy (MBE), but RHEED images are often difficult to\ninterpret, requiring experienced operators. We present an approach for\nautomated surveillance of GaAs substrate deoxidation in MBE using deep learning\nbased RHEED image-sequence classification. Our approach consists of an\nnon-supervised auto-encoder (AE) for feature extraction, combined with a\nsupervised convolutional classifier network. We demonstrate that our\nlightweight network model can accurately identify the exact deoxidation moment.\nFurthermore we show that the approach is very robust and allows accurate\ndeoxidation detection during months without requiring re-training. The main\nadvantage of the approach is that it can be applied to raw RHEED images without\nrequiring further information such as the rotation angle, temperature, etc.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Abdourahman Khaireh-Walieh",
      "Alexandre Arnoult",
      "S\u00e9bastien Plissard",
      "Peter R. Wiecha"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03430"
  },
  {
    "id": "arXiv:2210.03459",
    "title": "Mutual Learning of Single- and Multi-Channel End-to-End Neural  Diarization",
    "abstract": "Due to the high performance of multi-channel speech processing, we can use\nthe outputs from a multi-channel model as teacher labels when training a\nsingle-channel model with knowledge distillation. To the contrary, it is also\nknown that single-channel speech data can benefit multi-channel models by\nmixing it with multi-channel speech data during training or by using it for\nmodel pretraining. This paper focuses on speaker diarization and proposes to\nconduct the above bi-directional knowledge transfer alternately. We first\nintroduce an end-to-end neural diarization model that can handle both single-\nand multi-channel inputs. Using this model, we alternately conduct i) knowledge\ndistillation from a multi-channel model to a single-channel model and ii)\nfinetuning from the distilled single-channel model to a multi-channel model.\nExperimental results on two-speaker data show that the proposed method mutually\nimproved single- and multi-channel speaker diarization performances.",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Shota Horiguchi",
      "Yuki Takashima",
      "Shinji Watanabe",
      "Paola Garcia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.03459"
  },
  {
    "id": "arXiv:2210.03460",
    "title": "Flexible Alignment Super-Resolution Network for Multi-Contrast MRI",
    "abstract": "Magnetic resonance images play an essential role in clinical diagnosis by\nacquiring the structural information of biological tissue. However, during\nacquiring magnetic resonance images, patients have to endure physical and\npsychological discomfort, including irritating noise and acute anxiety. To make\nthe patient feel cozier, technically, it will reduce the retention time that\npatients stay in the strong magnetic field at the expense of image quality.\nTherefore, Super-Resolution plays a crucial role in preprocessing the\nlow-resolution images for more precise medical analysis. In this paper, we\npropose the Flexible Alignment Super-Resolution Network (FASR-Net) for\nmulti-contrast magnetic resonance images Super-Resolution. The core of\nmulti-contrast SR is to match the patches of low-resolution and reference\nimages. However, the inappropriate foreground scale and patch size of\nmulti-contrast MRI sometimes lead to the mismatch of patches. To tackle this\nproblem, the Flexible Alignment module is proposed to endow receptive fields\nwith flexibility. Flexible Alignment module contains two parts: (1) The\nSingle-Multi Pyramid Alignmet module serves for low-resolution and reference\nimage with different scale. (2) The Multi-Multi Pyramid Alignment module serves\nfor low-resolution and reference image with the same scale. Extensive\nexperiments on the IXI and FastMRI datasets demonstrate that the FASR-Net\noutperforms the existing state-of-the-art approaches. In addition, by comparing\nthe reconstructed images with the counterparts obtained by the existing\nalgorithms, our method could retain more textural details by leveraging\nmulti-contrast images.",
    "descriptor": "",
    "authors": [
      "Yiming Liu",
      "Mengxi Zhang",
      "Weiqin Zhang",
      "Bo Hou",
      "Dan Liu",
      "Heqing Lian",
      "Bo Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03460"
  },
  {
    "id": "arXiv:2210.03484",
    "title": "Multi-objective and multi-fidelity Bayesian optimization of laser-plasma  acceleration",
    "abstract": "Beam parameter optimization in accelerators involves multiple, sometimes\ncompeting objectives. Condensing these multiple objectives into a single\nobjective unavoidably results in bias towards particular outcomes that do not\nnecessarily represent the best possible outcome for the operator in terms of\nparameter optimization. A more versatile approach is multi-objective\noptimization, which establishes the trade-off curve or Pareto front between\nobjectives. Here we present first results on multi-objective Bayesian\noptimization of a simulated laser-plasma accelerator. We find that\nmulti-objective optimization is equal or even superior in performance to its\nsingle-objective counterparts, and that it is more resilient to different\nstatistical descriptions of objectives.\nAs a second major result of our paper, we significantly reduce the\ncomputational costs of the optimization by choosing the resolution and box size\nof the simulations dynamically. This is relevant since even with the use of\nBayesian statistics, performing such optimizations on a multi-dimensional\nsearch space may require hundreds or thousands of simulations. Our algorithm\ntranslates information gained from fast, low-resolution runs with lower\nfidelity to high-resolution data, thus requiring fewer actual simulations at\nhighest computational cost.\nThe techniques demonstrated in this paper can be translated to many different\nuse cases, both computational and experimental.",
    "descriptor": "",
    "authors": [
      "Faran Irshad",
      "Stefan Karsch",
      "Andreas D\u00f6pp"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03484"
  },
  {
    "id": "arXiv:2210.03488",
    "title": "AlphaFold Distillation for Improved Inverse Protein Folding",
    "abstract": "Inverse protein folding, i.e., designing sequences that fold into a given\nthree-dimensional structure, is one of the fundamental design challenges in\nbio-engineering and drug discovery. Traditionally, inverse folding mainly\ninvolves learning from sequences that have an experimentally resolved\nstructure. However, the known structures cover only a tiny space of the protein\nsequences, imposing limitations on the model learning. Recently proposed\nforward folding models, e.g., AlphaFold, offer unprecedented opportunity for\naccurate estimation of the structure given a protein sequence. Naturally,\nincorporating a forward folding model as a component of an inverse folding\napproach offers the potential of significantly improving the inverse folding,\nas the folding model can provide a feedback on any generated sequence in the\nform of the predicted protein structure or a structural confidence metric.\nHowever, at present, these forward folding models are still prohibitively slow\nto be a part of the model optimization loop during training. In this work, we\npropose to perform knowledge distillation on the folding model's confidence\nmetrics, e.g., pTM or pLDDT scores, to obtain a smaller, faster and end-to-end\ndifferentiable distilled model, which then can be included as part of the\nstructure consistency regularized inverse folding model training. Moreover, our\nregularization technique is general enough and can be applied in other design\ntasks, e.g., sequence-based protein infilling. Extensive experiments show a\nclear benefit of our method over the non-regularized baselines. For example, in\ninverse folding design problems we observe up to 3% improvement in sequence\nrecovery and up to 45% improvement in protein diversity, while still preserving\nstructural consistency of the generated sequences.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Igor Melnyk",
      "Aurelie Lozano",
      "Payel Das",
      "Vijil Chenthamarakshan"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03488"
  },
  {
    "id": "arXiv:2210.03566",
    "title": "Automated segmentation and morphological characterization of placental  histology images based on a single labeled image",
    "abstract": "In this study, a novel method of data augmentation has been presented for the\nsegmentation of placental histological images when the labeled data are scarce.\nThis method generates new realizations of the placenta intervillous morphology\nwhile maintaining the general textures and orientations. As a result, a\ndiversified artificial dataset of images is generated that can be used for\ntraining deep learning segmentation models. We have observed that on average\nthe presented method of data augmentation led to a 42% decrease in the binary\ncross-entropy loss of the validation dataset compared to the common approach in\nthe literature. Additionally, the morphology of the intervillous space is\nstudied under the effect of the proposed image reconstruction technique, and\nthe diversity of the artificially generated population is quantified. Due to\nthe high resemblance of the generated images to the real ones, the applications\nof the proposed method may not be limited to placental histological images, and\nit is recommended that other types of tissues be investigated in future\nstudies.",
    "descriptor": "",
    "authors": [
      "Arash Rabbani",
      "Masoud Babaei",
      "Masoumeh Gharib"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03566"
  },
  {
    "id": "arXiv:2210.03581",
    "title": "Synthetic Voice Detection and Audio Splicing Detection using  SE-Res2Net-Conformer Architecture",
    "abstract": "Synthetic voice and splicing audio clips have been generated to spoof\nInternet users and artificial intelligence (AI) technologies such as voice\nauthentication. Existing research work treats spoofing countermeasures as a\nbinary classification problem: bonafide vs. spoof. This paper extends the\nexisting Res2Net by involving the recent Conformer block to further exploit the\nlocal patterns on acoustic features. Experimental results on ASVspoof 2019\ndatabase show that the proposed SE-Res2Net-Conformer architecture is able to\nimprove the spoofing countermeasures performance for the logical access\nscenario.\nIn addition, this paper also proposes to re-formulate the existing audio\nsplicing detection problem. Instead of identifying the complete splicing\nsegments, it is more useful to detect the boundaries of the spliced segments.\nMoreover, a deep learning approach can be used to solve the problem, which is\ndifferent from the previous signal processing techniques.",
    "descriptor": "\nComments: Accepted by the 13th International Symposium on Chinese Spoken Language Processing (ISCSLP 2022)\n",
    "authors": [
      "Lei Wang",
      "Benedict Yeoh",
      "Jun Wah Ng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03581"
  },
  {
    "id": "arXiv:2210.03612",
    "title": "1st ICLR International Workshop on Privacy, Accountability,  Interpretability, Robustness, Reasoning on Structured Data (PAIR^2Struct)",
    "abstract": "Recent years have seen advances on principles and guidance relating to\naccountable and ethical use of artificial intelligence (AI) spring up around\nthe globe. Specifically, Data Privacy, Accountability, Interpretability,\nRobustness, and Reasoning have been broadly recognized as fundamental\nprinciples of using machine learning (ML) technologies on decision-critical\nand/or privacy-sensitive applications. On the other hand, in tremendous\nreal-world applications, data itself can be well represented as various\nstructured formalisms, such as graph-structured data (e.g., networks),\ngrid-structured data (e.g., images), sequential data (e.g., text), etc. By\nexploiting the inherently structured knowledge, one can design plausible\napproaches to identify and use more relevant variables to make reliable\ndecisions, thereby facilitating real-world deployments.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Wanyu Lin",
      "Hao He",
      "Di Wang",
      "Chengzhi Mao",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03612"
  },
  {
    "id": "arXiv:2210.03667",
    "title": "CommsVAE: Learning the brain's macroscale communication dynamics using  coupled sequential VAEs",
    "abstract": "Communication within or between complex systems is commonplace in the natural\nsciences and fields such as graph neural networks. The brain is a perfect\nexample of such a complex system, where communication between brain regions is\nconstantly being orchestrated. To analyze communication, the brain is often\nsplit up into anatomical regions that each perform certain computations. These\nregions must interact and communicate with each other to perform tasks and\nsupport higher-level cognition. On a macroscale, these regions communicate\nthrough signal propagation along the cortex and along white matter tracts over\nlonger distances. When and what types of signals are communicated over time is\nan unsolved problem and is often studied using either functional or structural\ndata. In this paper, we propose a non-linear generative approach to\ncommunication from functional data. We address three issues with common\nconnectivity approaches by explicitly modeling the directionality of\ncommunication, finding communication at each timestep, and encouraging\nsparsity. To evaluate our model, we simulate temporal data that has sparse\ncommunication between nodes embedded in it and show that our model can uncover\nthe expected communication dynamics. Subsequently, we apply our model to\ntemporal neural data from multiple tasks and show that our approach models\ncommunication that is more specific to each task. The specificity of our method\nmeans it can have an impact on the understanding of psychiatric disorders,\nwhich are believed to be related to highly specific communication between brain\nregions compared to controls. In sum, we propose a general model for dynamic\ncommunication learning on graphs, and show its applicability to a subfield of\nthe natural sciences, with potential widespread scientific impact.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Eloy Geenjaar",
      "Noah Lewis",
      "Amrit Kashyap",
      "Robyn Miller",
      "Vince Calhoun"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03667"
  },
  {
    "id": "arXiv:2210.03689",
    "title": "GENHOP: An Image Generation Method Based on Successive Subspace Learning",
    "abstract": "Being different from deep-learning-based (DL-based) image generation methods,\na new image generative model built upon successive subspace learning principle\nis proposed and named GenHop (an acronym of Generative PixelHop) in this work.\nGenHop consists of three modules: 1) high-to-low dimension reduction, 2) seed\nimage generation, and 3) low-to-high dimension expansion. In the first module,\nit builds a sequence of high-to-low dimensional subspaces through a sequence of\nwhitening processes, each of which contains samples of joint-spatial-spectral\nrepresentation. In the second module, it generates samples in the lowest\ndimensional subspace. In the third module, it finds a proper high-dimensional\nsample for a seed image by adding details back via locally linear embedding\n(LLE) and a sequence of coloring processes. Experiments show that GenHop can\ngenerate visually pleasant images whose FID scores are comparable or even\nbetter than those of DL-based generative models for MNIST, Fashion-MNIST and\nCelebA datasets.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted by ISCAS 2022\n",
    "authors": [
      "Xuejing Lei",
      "Wei Wang",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03689"
  },
  {
    "id": "arXiv:2210.03691",
    "title": "The Park-Pham Theorem with Optimal Convergence Rate",
    "abstract": "Park and Pham's recent proof of the Kahn--Kalai conjecture was a major\nbreakthrough in the field of graph and hypergraph thresholds. Their result\ngives an upper bound on the threshold at which a probabilistic construction has\na $1-\\epsilon$ chance of achieving a given monotone property. While their bound\nin other parameters is optimal up to constant factors for any fixed $\\epsilon$,\nit does not have the optimal dependence on $\\epsilon$ as $\\epsilon\\rightarrow\n0$. In this short paper, we prove a version of the Park--Pham Theorem with\noptimal $\\epsilon$-dependence.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tolson Bell"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.03691"
  },
  {
    "id": "arXiv:2210.03700",
    "title": "The incomplete Analytic Hierarchy Process and Bradley-Terry model:  (in)consistency and information retrieval",
    "abstract": "Several methods of preference modeling, ranking, voting and multi-criteria\ndecision making include pairwise comparisons. It is usually simpler to compare\ntwo objects at a time, furthermore, some relations (e.g., the outcome of sports\nmatches) are naturally known for pairs. This paper investigates and compares\npairwise comparison models and the stochastic Bradley-Terry model. It is proved\nthat they provide the same priority vectors for consistent (complete or\nincomplete) comparisons. For incomplete comparisons, all filling in levels are\nconsidered. Recent results identified the optimal subsets and sequences of\nmultiplicative/additive/reciprocal pairwise comparisons for small sizes of\nitems (up to n = 6). Simulations of this paper show that the same subsets and\nsequences are optimal in case of the Bradley-Terry and the Thurstone models as\nwell. This, somehow surprising, coincidence suggests the existence of a more\ngeneral result. Further models of information and preference theory are subject\nto future investigation in order to identify optimal subsets of input data.",
    "descriptor": "",
    "authors": [
      "L\u00e1szl\u00f3 Gyarmati",
      "\u00c9va Orb\u00e1n-Mih\u00e1lyk\u00f3",
      "Csaba Mih\u00e1lyk\u00f3",
      "S\u00e1ndor Boz\u00f3ki",
      "Zsombor Sz\u00e1doczki"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.03700"
  },
  {
    "id": "arXiv:2210.03702",
    "title": "Class-wise and reduced calibration methods",
    "abstract": "For many applications of probabilistic classifiers it is important that the\npredicted confidence vectors reflect true probabilities (one says that the\nclassifier is calibrated). It has been shown that common models fail to satisfy\nthis property, making reliable methods for measuring and improving calibration\nimportant tools. Unfortunately, obtaining these is far from trivial for\nproblems with many classes. We propose two techniques that can be used in\ntandem. First, a reduced calibration method transforms the original problem\ninto a simpler one. We prove for several notions of calibration that solving\nthe reduced problem minimizes the corresponding notion of miscalibration in the\nfull problem, allowing the use of non-parametric recalibration methods that\nfail in higher dimensions. Second, we propose class-wise calibration methods,\nbased on intuition building on a phenomenon called neural collapse and the\nobservation that most of the accurate classifiers found in practice can be\nthought of as a union of K different functions which can be recalibrated\nseparately, one for each class. These typically out-perform their non\nclass-wise counterparts, especially for classifiers trained on imbalanced data\nsets. Applying the two methods together results in class-wise reduced\ncalibration algorithms, which are powerful tools for reducing the prediction\nand per-class calibration errors. We demonstrate our methods on real and\nsynthetic datasets and release all code as open source at\nhttps://github.com/appliedAI-Initiative",
    "descriptor": "\nComments: Accepted at the 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022\n",
    "authors": [
      "Michael Panchenko",
      "Anes Benmerzoug",
      "Miguel de Benito Delgado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03702"
  },
  {
    "id": "arXiv:2210.03726",
    "title": "A $\u03b4f$ PIC method with auxiliary Forward-Backward Lagrangian  reconstructions",
    "abstract": "In this note we describe a $\\delta f$ particle method where the bulk density\nis periodically remapped on a coarse spline grid using a Forward-Backward\nLagrangian (FBL) approach. We describe the method in the case of an\nelectrostatic PIC scheme and validate its qualitative properties using a\nclassical two-stream instability subject to a uniform oscillating drive.",
    "descriptor": "",
    "authors": [
      "Martin Campos Pinto",
      "Merlin Pelz",
      "Pierre-Henri Tournier"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03726"
  },
  {
    "id": "arXiv:1806.07722",
    "title": "Stylized innovation: generating timelines by interrogating incrementally  available randomised dictionaries",
    "abstract": "Comments: 12 pages. Note: some pdf viewers have trouble rendering some of the figures perfectly",
    "descriptor": "\nComments: 12 pages. Note: some pdf viewers have trouble rendering some of the figures perfectly\n",
    "authors": [
      "Paul Kinsler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1806.07722"
  },
  {
    "id": "arXiv:1808.03884",
    "title": "A Basic Compositional Model for Spiking Neural Networks",
    "abstract": "A Basic Compositional Model for Spiking Neural Networks",
    "descriptor": "",
    "authors": [
      "Nancy Lynch",
      "Cameron Musco"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1808.03884"
  },
  {
    "id": "arXiv:1811.09537",
    "title": "On three domination-based identification problems in block graphs",
    "abstract": "On three domination-based identification problems in block graphs",
    "descriptor": "",
    "authors": [
      "Dipayan Chakraborty",
      "Florent Foucaud",
      "Aline Parreau",
      "Annegret K. Wagler"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1811.09537"
  },
  {
    "id": "arXiv:1903.10699",
    "title": "On the Theory of Dynamic Graph Regression Problem",
    "abstract": "Comments: Accepted in Computational and Applied Mathematics (this https URL)",
    "descriptor": "\nComments: Accepted in Computational and Applied Mathematics (this https URL)\n",
    "authors": [
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1903.10699"
  },
  {
    "id": "arXiv:1905.11963",
    "title": "Sublinear Update Time Randomized Algorithms for Dynamic Graph Regression",
    "abstract": "Sublinear Update Time Randomized Algorithms for Dynamic Graph Regression",
    "descriptor": "",
    "authors": [
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11963"
  },
  {
    "id": "arXiv:1910.07421",
    "title": "Deep Reinforcement Learning meets Graph Neural Networks: exploring a  routing optimization use case",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Paul Almasan",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Krzysztof Rusek",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.07421"
  },
  {
    "id": "arXiv:1912.12566",
    "title": "Experiments with mmWave Automotive Radar Test-bed",
    "abstract": "Comments: 6 pages, 2019 Asilomar conference",
    "descriptor": "\nComments: 6 pages, 2019 Asilomar conference\n",
    "authors": [
      "Xiangyu Gao",
      "Guanbin Xing",
      "Sumit Roy",
      "Hui Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.12566"
  },
  {
    "id": "arXiv:2005.05210",
    "title": "Interpretable Deep Representation Learning from Temporal Multi-view Data",
    "abstract": "Comments: Accepted at ACML 2022",
    "descriptor": "\nComments: Accepted at ACML 2022\n",
    "authors": [
      "Lin Qiu",
      "Vernon M. Chinchilli",
      "Lin Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.05210"
  },
  {
    "id": "arXiv:2006.06573",
    "title": "Spectral Image Segmentation with Global Appearance Modeling",
    "abstract": "Spectral Image Segmentation with Global Appearance Modeling",
    "descriptor": "",
    "authors": [
      "Jeova F. S. Rocha Neto",
      "Pedro F. Felzenszwalb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2006.06573"
  },
  {
    "id": "arXiv:2007.14462",
    "title": "Anomaly Awareness",
    "abstract": "Comments: 12 pages, 17 figures",
    "descriptor": "\nComments: 12 pages, 17 figures\n",
    "authors": [
      "Charanjit K. Khosa",
      "Veronica Sanz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.14462"
  },
  {
    "id": "arXiv:2010.05779",
    "title": "Sparse universal graphs for planarity",
    "abstract": "Comments: v3: revised following referee's comments. v2: added new result about induced-universal graphs",
    "descriptor": "\nComments: v3: revised following referee's comments. v2: added new result about induced-universal graphs\n",
    "authors": [
      "Louis Esperet",
      "Gwena\u00ebl Joret",
      "Pat Morin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.05779"
  },
  {
    "id": "arXiv:2011.08559",
    "title": "Normalized Weighting Schemes for Image Interpolation Algorithms",
    "abstract": "Comments: 15 pages, 15 figures, 2 Tables",
    "descriptor": "\nComments: 15 pages, 15 figures, 2 Tables\n",
    "authors": [
      "Olivier Rukundo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08559"
  },
  {
    "id": "arXiv:2101.00522",
    "title": "Domain Adaptation for the Segmentation of Confidential Medical Images",
    "abstract": "Domain Adaptation for the Segmentation of Confidential Medical Images",
    "descriptor": "",
    "authors": [
      "Serban Stan",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.00522"
  },
  {
    "id": "arXiv:2103.14829",
    "title": "Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using  Spatial and Temporal Transformers",
    "abstract": "Comments: This paper has been accepted as a Regular Paper in an upcoming issue of the Transactions on Pattern Analysis and Machine Intelligence (Tpami)",
    "descriptor": "\nComments: This paper has been accepted as a Regular Paper in an upcoming issue of the Transactions on Pattern Analysis and Machine Intelligence (Tpami)\n",
    "authors": [
      "Tianyu Zhu",
      "Markus Hiller",
      "Mahsa Ehsanpour",
      "Rongkai Ma",
      "Tom Drummond",
      "Ian Reid",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14829"
  },
  {
    "id": "arXiv:2104.09289",
    "title": "Towards realistic statistical models of the grid frequency",
    "abstract": "Comments: accepted to TPWRS",
    "descriptor": "\nComments: accepted to TPWRS\n",
    "authors": [
      "David Kraljic"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.09289"
  },
  {
    "id": "arXiv:2105.02570",
    "title": "Capturing the diversity of multilingual societies",
    "abstract": "Comments: Main text: 12 pages, 6 figures, 51 references. Supplementary Information: 27 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: Main text: 12 pages, 6 figures, 51 references. Supplementary Information: 27 pages, 16 figures, 2 tables\n",
    "authors": [
      "Thomas Louf",
      "David Sanchez",
      "Jose J. Ramasco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.02570"
  },
  {
    "id": "arXiv:2105.03697",
    "title": "Quantum Proofs of Proximity",
    "abstract": "Comments: In TQC 2021",
    "descriptor": "\nComments: In TQC 2021\n",
    "authors": [
      "Marcel Dall'Agnol",
      "Tom Gur",
      "Subhayan Roy Moulik",
      "Justin Thaler"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.03697"
  },
  {
    "id": "arXiv:2105.10559",
    "title": "Hyper-Convolution Networks for Biomedical Image Segmentation",
    "abstract": "Comments: WACV 2022",
    "descriptor": "\nComments: WACV 2022\n",
    "authors": [
      "Tianyu Ma",
      "Adrian V. Dalca",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10559"
  },
  {
    "id": "arXiv:2105.13859",
    "title": "A GAN-based Reduced Order Model for Prediction, Data Assimilation and  Uncertainty Quantification",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.07729",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.07729\n",
    "authors": [
      "Vinicius L. S. Silva",
      "Claire E. Heaney",
      "Christopher C. Pain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13859"
  },
  {
    "id": "arXiv:2105.14799",
    "title": "Resultant-based Elimination in Ore Algebra",
    "abstract": "Comments: An updated (and shorter) version published in the SYNASC '21 proceedings (IEEE CS) with the title \"Resultant-based Elimination for Skew Polynomials\"",
    "descriptor": "\nComments: An updated (and shorter) version published in the SYNASC '21 proceedings (IEEE CS) with the title \"Resultant-based Elimination for Skew Polynomials\"\n",
    "authors": [
      "Raqeeb Rasheed"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.14799"
  },
  {
    "id": "arXiv:2106.08647",
    "title": "Exponential Approximation of Band-limited Functions from Nonuniform  Sampling by Regularization Methods",
    "abstract": "Exponential Approximation of Band-limited Functions from Nonuniform  Sampling by Regularization Methods",
    "descriptor": "",
    "authors": [
      "Yunfei Yang",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08647"
  },
  {
    "id": "arXiv:2106.09256",
    "title": "Seeing Differently, Acting Similarly: Heterogeneously Observable  Imitation Learning",
    "abstract": "Seeing Differently, Acting Similarly: Heterogeneously Observable  Imitation Learning",
    "descriptor": "",
    "authors": [
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Zi-Xuan Chen",
      "Yuan Jiang",
      "Masashi Sugiyama",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09256"
  },
  {
    "id": "arXiv:2106.13201",
    "title": "DROID: Driver-centric Risk Object Identification",
    "abstract": "Comments: Submitted to TPAMI",
    "descriptor": "\nComments: Submitted to TPAMI\n",
    "authors": [
      "Chengxi Li",
      "Stanley H. Chan",
      "Yi-Ting Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13201"
  },
  {
    "id": "arXiv:2107.08195",
    "title": "Sparse Bayesian Learning with Diagonal Quasi-Newton Method for Large  Scale Classification",
    "abstract": "Comments: 11 pages,5 figures",
    "descriptor": "\nComments: 11 pages,5 figures\n",
    "authors": [
      "Jiahua Luo",
      "Chi-Man Vong",
      "Chi-Man Wong",
      "Jie Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.08195"
  },
  {
    "id": "arXiv:2108.09418",
    "title": "Technical Report: Using Static Analysis to Compute Benefit of Tolerating  Consistency",
    "abstract": "Technical Report: Using Static Analysis to Compute Benefit of Tolerating  Consistency",
    "descriptor": "",
    "authors": [
      "Duong Nguyen",
      "Arya Tanmay Gupta",
      "Sandeep S. Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.09418"
  },
  {
    "id": "arXiv:2109.06956",
    "title": "A fast, high-order numerical method for the simulation of  single-excitation states in quantum optics",
    "abstract": "A fast, high-order numerical method for the simulation of  single-excitation states in quantum optics",
    "descriptor": "",
    "authors": [
      "Jeremy Hoskins",
      "Jason Kaye",
      "Manas Rachh",
      "John C. Schotland"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06956"
  },
  {
    "id": "arXiv:2109.13273",
    "title": "Design of quantum optical experiments with logic artificial intelligence",
    "abstract": "Comments: 10 pages + appendices, 4 figures",
    "descriptor": "\nComments: 10 pages + appendices, 4 figures\n",
    "authors": [
      "Alba Cervera-Lierta",
      "Mario Krenn",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.13273"
  },
  {
    "id": "arXiv:2110.00075",
    "title": "Noise2Recon: Enabling Joint MRI Reconstruction and Denoising with  Semi-Supervised and Self-Supervised Learning",
    "abstract": "Noise2Recon: Enabling Joint MRI Reconstruction and Denoising with  Semi-Supervised and Self-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Arjun D Desai",
      "Batu M Ozturkler",
      "Christopher M Sandino",
      "Robert Boutin",
      "Marc Willis",
      "Shreyas Vasanawala",
      "Brian A Hargreaves",
      "Christopher M R\u00e9",
      "John M Pauly",
      "Akshay S Chaudhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00075"
  },
  {
    "id": "arXiv:2110.02474",
    "title": "Can an AI agent hit a moving target?",
    "abstract": "Can an AI agent hit a moving target?",
    "descriptor": "",
    "authors": [],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02474"
  },
  {
    "id": "arXiv:2110.05044",
    "title": "Biometric Template Protection for Neural-Network-based Face Recognition  Systems: A Survey of Methods and Evaluation Techniques",
    "abstract": "Comments: Main additions to Version 3 include a new table (Table I) summarising the studied BTP works + an explanation of how this survey differs from other BTP surveys. Consists of: 29 pages, 2 figures, 10 tables. Under review in IEEE TIFS journal",
    "descriptor": "\nComments: Main additions to Version 3 include a new table (Table I) summarising the studied BTP works + an explanation of how this survey differs from other BTP surveys. Consists of: 29 pages, 2 figures, 10 tables. Under review in IEEE TIFS journal\n",
    "authors": [
      "Vedrana Krivoku\u0107a Hahn",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05044"
  },
  {
    "id": "arXiv:2110.07238",
    "title": "On the difficulty of learning chaotic dynamics with RNNs",
    "abstract": "On the difficulty of learning chaotic dynamics with RNNs",
    "descriptor": "",
    "authors": [
      "Jonas M. Mikhaeil",
      "Zahra Monfared",
      "Daniel Durstewitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07238"
  },
  {
    "id": "arXiv:2110.07477",
    "title": "RecInDial: A Unified Framework for Conversational Recommendation with  Pretrained Language Models",
    "abstract": "Comments: Accepted by AACL 2022",
    "descriptor": "\nComments: Accepted by AACL 2022\n",
    "authors": [
      "Lingzhi Wang",
      "Huang Hu",
      "Lei Sha",
      "Can Xu",
      "Kam-Fai Wong",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07477"
  },
  {
    "id": "arXiv:2110.08934",
    "title": "On the Effect of Selfie Beautification Filters on Face Detection and  Recognition",
    "abstract": "Comments: Published at Pattern Recognition Letters, 2022",
    "descriptor": "\nComments: Published at Pattern Recognition Letters, 2022\n",
    "authors": [
      "Pontus Hedman",
      "Vasilios Skepetzis",
      "Kevin Hernandez-Diaz",
      "Josef Bigun",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08934"
  },
  {
    "id": "arXiv:2110.12118",
    "title": "Bandits with Dynamic Arm-acquisition Costs",
    "abstract": "Bandits with Dynamic Arm-acquisition Costs",
    "descriptor": "",
    "authors": [
      "Anand Kalvit",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12118"
  },
  {
    "id": "arXiv:2110.15188",
    "title": "The magnitude vector of images",
    "abstract": "The magnitude vector of images",
    "descriptor": "",
    "authors": [
      "Michael F. Adamer",
      "Edward De Brouwer",
      "Leslie O'Bray",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.15188"
  },
  {
    "id": "arXiv:2111.04637",
    "title": "A hemispheric two-channel code accounts for binaural unmasking in humans",
    "abstract": "A hemispheric two-channel code accounts for binaural unmasking in humans",
    "descriptor": "",
    "authors": [
      "J\u00f6rg Encke",
      "Mathias Dietz"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.04637"
  },
  {
    "id": "arXiv:2111.04880",
    "title": "User Centered Design (VI): Human Factors Approaches for Intelligent  Human-Computer Interaction",
    "abstract": "Comments: in Chinese language",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Wei Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.04880"
  },
  {
    "id": "arXiv:2111.08460",
    "title": "Enabling human-centered AI: A new junction and shared journey between AI  and HCI communities",
    "abstract": "Enabling human-centered AI: A new junction and shared journey between AI  and HCI communities",
    "descriptor": "",
    "authors": [
      "Wei Xu",
      "Marvin Dainoff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.08460"
  },
  {
    "id": "arXiv:2111.09254",
    "title": "Universal Inference Meets Random Projections: A Scalable Test for  Log-concavity",
    "abstract": "Universal Inference Meets Random Projections: A Scalable Test for  Log-concavity",
    "descriptor": "",
    "authors": [
      "Robin Dunn",
      "Aditya Gangrade",
      "Larry Wasserman",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.09254"
  },
  {
    "id": "arXiv:2111.10625",
    "title": "Explainable Biomedical Recommendations via Reinforcement Learning  Reasoning on Knowledge Graphs",
    "abstract": "Explainable Biomedical Recommendations via Reinforcement Learning  Reasoning on Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Gavin Edwards",
      "Sebastian Nilsson",
      "Benedek Rozemberczki",
      "Eliseo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.10625"
  },
  {
    "id": "arXiv:2111.11288",
    "title": "SSR: An Efficient and Robust Framework for Learning with Unknown Label  Noise",
    "abstract": "Comments: Accepted to BMVC2022",
    "descriptor": "\nComments: Accepted to BMVC2022\n",
    "authors": [
      "Chen Feng",
      "Georgios Tzimiropoulos",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11288"
  },
  {
    "id": "arXiv:2111.12460",
    "title": "ViCE: Improving Dense Representation Learning by Superpixelization and  Contrasting Cluster Assignment",
    "abstract": "Comments: Accepted for BMVC 2022",
    "descriptor": "\nComments: Accepted for BMVC 2022\n",
    "authors": [
      "Robin Karlsson",
      "Tomoki Hayashi",
      "Keisuke Fujii",
      "Alexander Carballo",
      "Kento Ohtani",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12460"
  },
  {
    "id": "arXiv:2112.00459",
    "title": "Information Theoretic Representation Distillation",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Roy Miles",
      "Adrian Lopez Rodriguez",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00459"
  },
  {
    "id": "arXiv:2112.06283",
    "title": "Bayesian Persuasion for Algorithmic Recourse",
    "abstract": "Comments: In the thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: In the thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Keegan Harris",
      "Valerie Chen",
      "Joon Sik Kim",
      "Ameet Talwalkar",
      "Hoda Heidari",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06283"
  },
  {
    "id": "arXiv:2112.07658",
    "title": "AdaViT: Adaptive Tokens for Efficient Vision Transformer",
    "abstract": "Comments: CVPR'22 oral acceptance",
    "descriptor": "\nComments: CVPR'22 oral acceptance\n",
    "authors": [
      "Hongxu Yin",
      "Arash Vahdat",
      "Jose Alvarez",
      "Arun Mallya",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07658"
  },
  {
    "id": "arXiv:2112.08159",
    "title": "One size does not fit all: Investigating strategies for  differentially-private learning across NLP tasks",
    "abstract": "Comments: Accepted to EMNLP 2022; not a final camera-ready version",
    "descriptor": "\nComments: Accepted to EMNLP 2022; not a final camera-ready version\n",
    "authors": [
      "Manuel Senge",
      "Timour Igamberdiev",
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08159"
  },
  {
    "id": "arXiv:2112.08907",
    "title": "Inherently Explainable Reinforcement Learning in Natural Language",
    "abstract": "Inherently Explainable Reinforcement Learning in Natural Language",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Mark O. Riedl",
      "Prithviraj Ammanabrolu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08907"
  },
  {
    "id": "arXiv:2112.11873",
    "title": "FLoBC: A Decentralized Blockchain-Based Federated Learning Framework",
    "abstract": "Comments: BSc Computer Engineering Thesis [AUC, Spring 21]",
    "descriptor": "\nComments: BSc Computer Engineering Thesis [AUC, Spring 21]\n",
    "authors": [
      "Mohamed Ghanem",
      "Fadi Dawoud",
      "Habiba Gamal",
      "Eslam Soliman",
      "Hossam Sharara",
      "Tamer El-Batt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.11873"
  },
  {
    "id": "arXiv:2112.12579",
    "title": "NeRD++: Improved 3D-mirror symmetry learning from a single image",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Yancong Lin",
      "Silvia-Laura Pintea",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12579"
  },
  {
    "id": "arXiv:2112.14381",
    "title": "COTReg:Coupled Optimal Transport based Point Cloud Registration",
    "abstract": "COTReg:Coupled Optimal Transport based Point Cloud Registration",
    "descriptor": "",
    "authors": [
      "Guofeng Mei",
      "Xiaoshui Huang",
      "Litao Yu",
      "Jian Zhang",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14381"
  },
  {
    "id": "arXiv:2112.14468",
    "title": "Challenges and Approaches for Mitigating Byzantine Attacks in Federated  Learning",
    "abstract": "Comments: The paper has been accepted by the 21st IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom-22)",
    "descriptor": "\nComments: The paper has been accepted by the 21st IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom-22)\n",
    "authors": [
      "Junyu Shi",
      "Wei Wan",
      "Shengshan Hu",
      "Jianrong Lu",
      "Leo Yu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.14468"
  },
  {
    "id": "arXiv:2201.03303",
    "title": "An open tool based on lifex for myofibers generation in cardiac  computational models",
    "abstract": "An open tool based on lifex for myofibers generation in cardiac  computational models",
    "descriptor": "",
    "authors": [
      "Pasquale C. Africa",
      "Roberto Piersanti",
      "Marco Fedele",
      "Luca Dede'",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.03303"
  },
  {
    "id": "arXiv:2201.08895",
    "title": "On the Satisfaction Probability of $k$-CNF Formulas",
    "abstract": "Comments: 43 pages, version updated after the presentation of the results at the CCC 2022 conference",
    "descriptor": "\nComments: 43 pages, version updated after the presentation of the results at the CCC 2022 conference\n",
    "authors": [
      "Till Tantau"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.08895"
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Adversarial Transformers for Medical Image Segmentation",
    "abstract": "Class-Aware Adversarial Transformers for Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Siyuan Dong",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.10737"
  },
  {
    "id": "arXiv:2202.03799",
    "title": "What are the best systems? New perspectives on NLP Benchmarking",
    "abstract": "What are the best systems? New perspectives on NLP Benchmarking",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Nathan Noiry",
      "Ekhine Irurozki",
      "Stephan Clemencon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03799"
  },
  {
    "id": "arXiv:2202.04108",
    "title": "A Lagrangian Duality Approach to Active Learning",
    "abstract": "A Lagrangian Duality Approach to Active Learning",
    "descriptor": "",
    "authors": [
      "Juan Elenter",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04108"
  },
  {
    "id": "arXiv:2202.04173",
    "title": "Exploring the Limits of Domain-Adaptive Training for Detoxifying  Large-Scale Language Models",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Boxin Wang",
      "Wei Ping",
      "Chaowei Xiao",
      "Peng Xu",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bo Li",
      "Anima Anandkumar",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04173"
  },
  {
    "id": "arXiv:2202.06997",
    "title": "Cross-Modality Neuroimage Synthesis: A Survey",
    "abstract": "Cross-Modality Neuroimage Synthesis: A Survey",
    "descriptor": "",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Yawen Huang",
      "Yefeng Zheng",
      "Ke Lu",
      "Yaochu Jin",
      "Feng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06997"
  },
  {
    "id": "arXiv:2202.10209",
    "title": "Degree-Preserving Randomized Response for Graph Neural Networks under  Local Differential Privacy",
    "abstract": "Degree-Preserving Randomized Response for Graph Neural Networks under  Local Differential Privacy",
    "descriptor": "",
    "authors": [
      "Seira Hidano",
      "Takao Murakami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10209"
  },
  {
    "id": "arXiv:2202.10558",
    "title": "GAN-DUF: Hierarchical Deep Generative Models for Design Under Free-Form  Geometric Uncertainty",
    "abstract": "Comments: Accepted by Journal and Mechanical Design and ASME 2022 International Design Engineering Technical Conferences & Computers and Information in Engineering Conference (IDETC-CIE 2022). arXiv admin note: substantial text overlap with arXiv:2112.08919",
    "descriptor": "\nComments: Accepted by Journal and Mechanical Design and ASME 2022 International Design Engineering Technical Conferences & Computers and Information in Engineering Conference (IDETC-CIE 2022). arXiv admin note: substantial text overlap with arXiv:2112.08919\n",
    "authors": [
      "Wei Wayne Chen",
      "Doksoo Lee",
      "Oluwaseyi Balogun",
      "Wei Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10558"
  },
  {
    "id": "arXiv:2203.01222",
    "title": "Chance-Constrained Iterative Linear-Quadratic Stochastic Games",
    "abstract": "Chance-Constrained Iterative Linear-Quadratic Stochastic Games",
    "descriptor": "",
    "authors": [
      "Hai Zhong",
      "Yutaka Shimizu",
      "Jianyu Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01222"
  },
  {
    "id": "arXiv:2203.01437",
    "title": "MUAD: Multiple Uncertainties for Autonomous Driving, a benchmark for  multiple uncertainty types and tasks",
    "abstract": "Comments: Accepted at BMVC 2022",
    "descriptor": "\nComments: Accepted at BMVC 2022\n",
    "authors": [
      "Gianni Franchi",
      "Xuanlong Yu",
      "Andrei Bursuc",
      "Angel Tena",
      "R\u00e9mi Kazmierczak",
      "S\u00e9verine Dubuisson",
      "Emanuel Aldea",
      "David Filliat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01437"
  },
  {
    "id": "arXiv:2203.02205",
    "title": "Evaluating the Consequences of Object (mis)Detection from a Safety and  Reliability Perspective: Discussion and Measures",
    "abstract": "Comments: paper currently submitted -- under review GITHUB: this https URL",
    "descriptor": "\nComments: paper currently submitted -- under review GITHUB: this https URL\n",
    "authors": [
      "Andrea Ceccarelli",
      "Leonardo Montecchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02205"
  },
  {
    "id": "arXiv:2203.04592",
    "title": "Mapping global dynamics of benchmark creation and saturation in  artificial intelligence",
    "abstract": "Comments: This version includes more recent data and additional analyses",
    "descriptor": "\nComments: This version includes more recent data and additional analyses\n",
    "authors": [
      "Simon Ott",
      "Adriano Barbosa-Silva",
      "Kathrin Blagec",
      "Jan Brauner",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04592"
  },
  {
    "id": "arXiv:2203.10143",
    "title": "Characterizing Alternative Monetization Strategies on YouTube",
    "abstract": "Comments: Published at CSCW'22, please cite accordingly",
    "descriptor": "\nComments: Published at CSCW'22, please cite accordingly\n",
    "authors": [
      "Yiqing Hua",
      "Manoel Horta Ribeiro",
      "Robert West",
      "Thomas Ristenpart",
      "Mor Naaman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.10143"
  },
  {
    "id": "arXiv:2203.12074",
    "title": "Optimistic Mirror Descent Either Converges to Nash or to Strong Coarse  Correlated Equilibria in Bimatrix Games",
    "abstract": "Comments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback",
    "descriptor": "\nComments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback\n",
    "authors": [
      "Ioannis Anagnostides",
      "Gabriele Farina",
      "Ioannis Panageas",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.12074"
  },
  {
    "id": "arXiv:2203.12694",
    "title": "The Carleman contraction mapping method for quasilinear elliptic  equations with over-determined boundary data",
    "abstract": "The Carleman contraction mapping method for quasilinear elliptic  equations with over-determined boundary data",
    "descriptor": "",
    "authors": [
      "Loc Hoang Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.12694"
  },
  {
    "id": "arXiv:2204.01407",
    "title": "Re-examining Distillation For Continual Object Detection",
    "abstract": "Comments: Accepted at BMVC '22",
    "descriptor": "\nComments: Accepted at BMVC '22\n",
    "authors": [
      "Eli Verwimp",
      "Kuo Yang",
      "Sarah Parisot",
      "Hong Lanqing",
      "Steven McDonagh",
      "Eduardo P\u00e9rez-Pellitero",
      "Matthias De Lange",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01407"
  },
  {
    "id": "arXiv:2204.01802",
    "title": "Generalized Triangular Dynamical System: An Algebraic System for  Constructing Cryptographic Permutations over Finite Fields",
    "abstract": "Generalized Triangular Dynamical System: An Algebraic System for  Constructing Cryptographic Permutations over Finite Fields",
    "descriptor": "",
    "authors": [
      "Arnab Roy",
      "Matthias Steiner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.01802"
  },
  {
    "id": "arXiv:2204.02585",
    "title": "SqueezeNeRF: Further factorized FastNeRF for memory-efficient inference",
    "abstract": "Comments: 9 pages, 3 figures, 5 tables. Presented in the \"5th Efficient Deep Learning for Computer Vision\" CVPR 2022 Workshop\"",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables. Presented in the \"5th Efficient Deep Learning for Computer Vision\" CVPR 2022 Workshop\"\n",
    "authors": [
      "Krishna Wadhwani",
      "Tamaki Kojima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02585"
  },
  {
    "id": "arXiv:2204.10293",
    "title": "A Hierarchical N-Gram Framework for Zero-Shot Link Prediction",
    "abstract": "Comments: Published as a conference paper at EMNLP Findings 2022",
    "descriptor": "\nComments: Published as a conference paper at EMNLP Findings 2022\n",
    "authors": [
      "Mingchen Li",
      "Junfan Chen",
      "Samuel Mensah",
      "Nikolaos Aletras",
      "Xiulong Yang",
      "Yang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10293"
  },
  {
    "id": "arXiv:2204.10516",
    "title": "Implicit Object Mapping With Noisy Data",
    "abstract": "Implicit Object Mapping With Noisy Data",
    "descriptor": "",
    "authors": [
      "Jad Abou-Chakra",
      "Feras Dayoub",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.10516"
  },
  {
    "id": "arXiv:2204.11399",
    "title": "Efficient Neural Neighborhood Search for Pickup and Delivery Problems",
    "abstract": "Comments: Accepted at IJCAI 2022 (short oral)",
    "descriptor": "\nComments: Accepted at IJCAI 2022 (short oral)\n",
    "authors": [
      "Yining Ma",
      "Jingwen Li",
      "Zhiguang Cao",
      "Wen Song",
      "Hongliang Guo",
      "Yuejiao Gong",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.11399"
  },
  {
    "id": "arXiv:2205.00394",
    "title": "Neural Network Optimal Feedback Control with Guaranteed Local Stability",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2109.07466",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.07466\n",
    "authors": [
      "Tenavi Nakamura-Zimmerer",
      "Qi Gong",
      "Wei Kang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.00394"
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "Comments: 30 pages, 7 figures, draft NeurIPS version",
    "descriptor": "\nComments: 30 pages, 7 figures, draft NeurIPS version\n",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01663"
  },
  {
    "id": "arXiv:2205.03589",
    "title": "Learning Disentangled Textual Representations via Statistical Measures  of Similarity",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Pierre Colombo",
      "Guillaume Staerman",
      "Nathan Noiry",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.03589"
  },
  {
    "id": "arXiv:2205.07480",
    "title": "Analyzing FreeRTOS Scheduling Behaviors with the Spin Model Checker",
    "abstract": "Analyzing FreeRTOS Scheduling Behaviors with the Spin Model Checker",
    "descriptor": "",
    "authors": [
      "Chen-Kai Lin",
      "Bow-Yaw Wang"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2205.07480"
  },
  {
    "id": "arXiv:2205.09738",
    "title": "AIGenC: AI generalisation via creativity",
    "abstract": "AIGenC: AI generalisation via creativity",
    "descriptor": "",
    "authors": [
      "Corina Catarau-Cotutiu",
      "Esther Mondragon",
      "Eduardo Alonso"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09738"
  },
  {
    "id": "arXiv:2205.10019",
    "title": "Translating Hanja historical documents to understandable Korean and  English",
    "abstract": "Translating Hanja historical documents to understandable Korean and  English",
    "descriptor": "",
    "authors": [
      "Juhee Son",
      "Jiho Jin",
      "Haneul Yoo",
      "JinYeong Bak",
      "Kyunghyun Cho",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10019"
  },
  {
    "id": "arXiv:2205.10370",
    "title": "Diversity vs. Recognizability: Human-like generalization in one-shot  generative models",
    "abstract": "Diversity vs. Recognizability: Human-like generalization in one-shot  generative models",
    "descriptor": "",
    "authors": [
      "Victor Boutin",
      "Lakshya Singhal",
      "Xavier Thomas",
      "Thomas Serre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10370"
  },
  {
    "id": "arXiv:2205.10425",
    "title": "\"Nudes? Shouldn't I charge for these?\" : Motivations of New Sexual  Content Creators on OnlyFans",
    "abstract": "\"Nudes? Shouldn't I charge for these?\" : Motivations of New Sexual  Content Creators on OnlyFans",
    "descriptor": "",
    "authors": [
      "Vaughn Hamilton",
      "Ananta Soneji",
      "Allison McDonald",
      "Elissa Redmiles"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.10425"
  },
  {
    "id": "arXiv:2205.11266",
    "title": "What You See is What You Classify: Black Box Attributions",
    "abstract": "What You See is What You Classify: Black Box Attributions",
    "descriptor": "",
    "authors": [
      "Steven Stalder",
      "Nathana\u00ebl Perraudin",
      "Radhakrishna Achanta",
      "Fernando Perez-Cruz",
      "Michele Volpi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11266"
  },
  {
    "id": "arXiv:2205.11779",
    "title": "Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative  Machine Learning",
    "abstract": "Comments: 14 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 14 pages, 8 figures, 2 tables\n",
    "authors": [
      "Hideya Ochiai",
      "Yuwei Sun",
      "Qingzhe Jin",
      "Nattanon Wongwiwatchai",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.11779"
  },
  {
    "id": "arXiv:2205.11874",
    "title": "Approximation speed of quantized vs. unquantized ReLU neural networks  and beyond",
    "abstract": "Approximation speed of quantized vs. unquantized ReLU neural networks  and beyond",
    "descriptor": "",
    "authors": [
      "Antoine Gonon",
      "Nicolas Brisebarre",
      "R\u00e9mi Gribonval",
      "Elisa Riccietti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.11874"
  },
  {
    "id": "arXiv:2205.15449",
    "title": "Posterior and Computational Uncertainty in Gaussian Processes",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Marvin Pf\u00f6rtner",
      "Philipp Hennig",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15449"
  },
  {
    "id": "arXiv:2206.02139",
    "title": "Early Stage Convergence and Global Convergence of Training Mildly  Parameterized Neural Networks",
    "abstract": "Early Stage Convergence and Global Convergence of Training Mildly  Parameterized Neural Networks",
    "descriptor": "",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02139"
  },
  {
    "id": "arXiv:2206.03305",
    "title": "Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate  Model Predictive Trajectory Tracking",
    "abstract": "Comments: Video: this https URL",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Alessandro Saviolo",
      "Guanrui Li",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.03305"
  },
  {
    "id": "arXiv:2206.06544",
    "title": "A Survey of Automated Data Augmentation Algorithms for Deep  Learning-based Image Classification Tasks",
    "abstract": "Comments: 68 pages, 9 figures. Submitted to Knowledge and Information Systems (KAIS)",
    "descriptor": "\nComments: 68 pages, 9 figures. Submitted to Knowledge and Information Systems (KAIS)\n",
    "authors": [
      "Zihan Yang",
      "Richard O. Sinnott",
      "James Bailey",
      "Qiuhong Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06544"
  },
  {
    "id": "arXiv:2206.06662",
    "title": "Learning Best Combination for Efficient N:M Sparsity",
    "abstract": "Comments: Accepted by 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted by 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Zhihang Lin",
      "Yiting Luo",
      "Ke Li",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06662"
  },
  {
    "id": "arXiv:2206.07375",
    "title": "Knowledge4COVID-19: A Semantic-based Approach for Constructing a  COVID-19 related Knowledge Graph from Various Sources and Analysing  Treatments' Toxicities",
    "abstract": "Knowledge4COVID-19: A Semantic-based Approach for Constructing a  COVID-19 related Knowledge Graph from Various Sources and Analysing  Treatments' Toxicities",
    "descriptor": "",
    "authors": [
      "Ahmad Sakor",
      "Samaneh Jozashoori",
      "Emetis Niazmand",
      "Ariam Rivas",
      "Kostantinos Bougiatiotis",
      "Fotis Aisopos",
      "Enrique Iglesias",
      "Philipp D. Rohde",
      "Trupti Padiya",
      "Anastasia Krithara",
      "Georgios Paliouras",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.07375"
  },
  {
    "id": "arXiv:2206.08171",
    "title": "K-Radar: 4D Radar Object Detection for Autonomous Driving in Various  Weather Conditions",
    "abstract": "Comments: Accepted at NeurIPS 2022 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Dong-Hee Paek",
      "Seung-Hyun Kong",
      "Kevin Tirta Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08171"
  },
  {
    "id": "arXiv:2206.11886",
    "title": "On the Generalizability and Predictability of Recommender Systems",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Duncan McElfresh",
      "Sujay Khandagale",
      "Jonathan Valverde",
      "John P. Dickerson",
      "Colin White"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11886"
  },
  {
    "id": "arXiv:2206.12065",
    "title": "Eco-driving for Electric Connected Vehicles at Signalized Intersections:  A Parameterized Reinforcement Learning approach",
    "abstract": "Eco-driving for Electric Connected Vehicles at Signalized Intersections:  A Parameterized Reinforcement Learning approach",
    "descriptor": "",
    "authors": [
      "Xia Jiang",
      "Jian Zhang",
      "Dan Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12065"
  },
  {
    "id": "arXiv:2206.12272",
    "title": "Physically Consistent Learning of Conservative Lagrangian Systems with  Gaussian Processes",
    "abstract": "Comments: Accepted by IEEE for publication",
    "descriptor": "\nComments: Accepted by IEEE for publication\n",
    "authors": [
      "Giulio Evangelisti",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12272"
  },
  {
    "id": "arXiv:2206.12728",
    "title": "Learning Preconditions of Hybrid Force-Velocity Controllers for  Contact-Rich Manipulation",
    "abstract": "Learning Preconditions of Hybrid Force-Velocity Controllers for  Contact-Rich Manipulation",
    "descriptor": "",
    "authors": [
      "Jacky Liang",
      "Xianyi Cheng",
      "Oliver Kroemer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12728"
  },
  {
    "id": "arXiv:2206.13035",
    "title": "A General Recipe for Likelihood-free Bayesian Optimization",
    "abstract": "Comments: ICML 2022. This version fixes a typo in eq 33",
    "descriptor": "\nComments: ICML 2022. This version fixes a typo in eq 33\n",
    "authors": [
      "Jiaming Song",
      "Lantao Yu",
      "Willie Neiswanger",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13035"
  },
  {
    "id": "arXiv:2207.03586",
    "title": "CausalAgents: A Robustness Benchmark for Motion Forecasting using Causal  Relationships",
    "abstract": "Comments: Rebecca Roelofs and Liting Sun are equally contributed to the work",
    "descriptor": "\nComments: Rebecca Roelofs and Liting Sun are equally contributed to the work\n",
    "authors": [
      "Rebecca Roelofs",
      "Liting Sun",
      "Ben Caine",
      "Khaled S. Refaat",
      "Ben Sapp",
      "Scott Ettinger",
      "Wei Chai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.03586"
  },
  {
    "id": "arXiv:2207.04825",
    "title": "Forward Error Correction applied to JPEG-XS codestreams",
    "abstract": "Forward Error Correction applied to JPEG-XS codestreams",
    "descriptor": "",
    "authors": [
      "Antoine Legrand",
      "Beno\u00eet Macq",
      "Christophe De Vleeschouwer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04825"
  },
  {
    "id": "arXiv:2207.06572",
    "title": "i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight  Human-Robot Interaction Loops",
    "abstract": "Comments: 8+21 pages",
    "descriptor": "\nComments: 8+21 pages\n",
    "authors": [
      "Saminda Abeyruwan",
      "Laura Graesser",
      "David B. D'Ambrosio",
      "Avi Singh",
      "Anish Shankar",
      "Alex Bewley",
      "Deepali Jain",
      "Krzysztof Choromanski",
      "Pannag R. Sanketi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.06572"
  },
  {
    "id": "arXiv:2207.08349",
    "title": "Retweet-BERT: Political Leaning Detection Using Language Features and  Information Diffusion on Social Networks",
    "abstract": "Comments: 11 pages, 3 figures, 4 tables. arXiv admin note: text overlap with arXiv:2103.10979",
    "descriptor": "\nComments: 11 pages, 3 figures, 4 tables. arXiv admin note: text overlap with arXiv:2103.10979\n",
    "authors": [
      "Julie Jiang",
      "Xiang Ren",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.08349"
  },
  {
    "id": "arXiv:2207.09081",
    "title": "Generalizing Goal-Conditioned Reinforcement Learning with Variational  Causal Reasoning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2207.09081"
  },
  {
    "id": "arXiv:2207.11428",
    "title": "MISO: Exploiting Multi-Instance GPU Capability on Multi-Tenant Systems  for Machine Learning",
    "abstract": "MISO: Exploiting Multi-Instance GPU Capability on Multi-Tenant Systems  for Machine Learning",
    "descriptor": "",
    "authors": [
      "Baolin Li",
      "Tirthak Patel",
      "Siddarth Samsi",
      "Vijay Gadepally",
      "Devesh Tiwari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2207.11428"
  },
  {
    "id": "arXiv:2207.11906",
    "title": "Learning a Dual-Mode Speech Recognition Model via Self-Pruning",
    "abstract": "Comments: 7 pages, 1 figure. Accepted for publication at IEEE Spoken Language Technology Workshop (SLT), 2022",
    "descriptor": "\nComments: 7 pages, 1 figure. Accepted for publication at IEEE Spoken Language Technology Workshop (SLT), 2022\n",
    "authors": [
      "Chunxi Liu",
      "Yuan Shangguan",
      "Haichuan Yang",
      "Yangyang Shi",
      "Raghuraman Krishnamoorthi",
      "Ozlem Kalinli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.11906"
  },
  {
    "id": "arXiv:2208.00458",
    "title": "A heuristic technique for decomposing multisets of non-negative integers  according to the Minkowski sum",
    "abstract": "A heuristic technique for decomposing multisets of non-negative integers  according to the Minkowski sum",
    "descriptor": "",
    "authors": [
      "Luciano Margara"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.00458"
  },
  {
    "id": "arXiv:2208.01003",
    "title": "What can be learnt with wide convolutional neural networks?",
    "abstract": "What can be learnt with wide convolutional neural networks?",
    "descriptor": "",
    "authors": [
      "Francesco Cagnetta",
      "Alessandro Favero",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01003"
  },
  {
    "id": "arXiv:2208.05238",
    "title": "A broken FEEC framework for electromagnetic problems on mapped  multipatch domains",
    "abstract": "A broken FEEC framework for electromagnetic problems on mapped  multipatch domains",
    "descriptor": "",
    "authors": [
      "Yaman G\u00fc\u00e7l\u00fc",
      "Said Hadjout",
      "Martin Campos Pinto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.05238"
  },
  {
    "id": "arXiv:2208.07400",
    "title": "SynKB: Semantic Search for Synthetic Procedures",
    "abstract": "Comments: Accepted to EMNLP 2022 Demo track",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Demo track\n",
    "authors": [
      "Fan Bai",
      "Alan Ritter",
      "Peter Madrid",
      "Dayne Freitag",
      "John Niekrasz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.07400"
  },
  {
    "id": "arXiv:2208.09818",
    "title": "Rate-Splitting Multiple Access for Intelligent Reflecting Surface-Aided  Secure Transmission",
    "abstract": "Comments: 5 pages, 6 figures, submitted to IEEE journal for possible publication",
    "descriptor": "\nComments: 5 pages, 6 figures, submitted to IEEE journal for possible publication\n",
    "authors": [
      "Ying Gao",
      "Qingqing Wu",
      "Wen Chen",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.09818"
  },
  {
    "id": "arXiv:2208.11173",
    "title": "The Alberta Plan for AI Research",
    "abstract": "The Alberta Plan for AI Research",
    "descriptor": "",
    "authors": [
      "Richard S. Sutton",
      "Michael Bowling",
      "Patrick M. Pilarski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.11173"
  },
  {
    "id": "arXiv:2208.11407",
    "title": "A Multi-Bennett 8R Mechanism Obtained From Factorization of Bivariate  Motion Polynomials",
    "abstract": "A Multi-Bennett 8R Mechanism Obtained From Factorization of Bivariate  Motion Polynomials",
    "descriptor": "",
    "authors": [
      "Johanna Frischauf",
      "Martin Pfurner",
      "Daniel F. Scharler",
      "Hans-Peter Schr\u00f6cker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2208.11407"
  },
  {
    "id": "arXiv:2208.11644",
    "title": "A Slightly Improved Bound for the KLS Constant",
    "abstract": "Comments: minor revision fixing typos",
    "descriptor": "\nComments: minor revision fixing typos\n",
    "authors": [
      "Arun Jambulapati",
      "Yin Tat Lee",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2208.11644"
  },
  {
    "id": "arXiv:2208.12268",
    "title": "FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning  in Federated Learning",
    "abstract": "FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning  in Federated Learning",
    "descriptor": "",
    "authors": [
      "Haodong Zhao",
      "Wei Du",
      "Fangqi Li",
      "Peixuan Li",
      "Gongshen Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.12268"
  },
  {
    "id": "arXiv:2208.13070",
    "title": "Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets",
    "abstract": "Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets",
    "descriptor": "",
    "authors": [
      "Usman Muhammad",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13070"
  },
  {
    "id": "arXiv:2208.14585",
    "title": "The Glass Ceiling of Automatic Evaluation in Natural Language Generation",
    "abstract": "The Glass Ceiling of Automatic Evaluation in Natural Language Generation",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Maxime Peyrard",
      "Nathan Noiry",
      "Robert West",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.14585"
  },
  {
    "id": "arXiv:2209.00641",
    "title": "Seq-UPS: Sequential Uncertainty-aware Pseudo-label Selection for  Semi-Supervised Text Recognition",
    "abstract": "Comments: Accepted at WACV 2023",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Gaurav Patel",
      "Jan Allebach",
      "Qiang Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.00641"
  },
  {
    "id": "arXiv:2209.01198",
    "title": "Estimation of Correlation Matrices from Limited time series Data using  Machine Learning",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Nikhil Easaw",
      "Woo Seok Lee",
      "Prashant Singh Lohiya",
      "Sarika Jalan",
      "Priodyuti Pradhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.01198"
  },
  {
    "id": "arXiv:2209.03265",
    "title": "Quadratic sequences with prime power discriminators",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Sajed Haque"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.03265"
  },
  {
    "id": "arXiv:2209.04836",
    "title": "Git Re-Basin: Merging Models modulo Permutation Symmetries",
    "abstract": "Git Re-Basin: Merging Models modulo Permutation Symmetries",
    "descriptor": "",
    "authors": [
      "Samuel K. Ainsworth",
      "Jonathan Hayase",
      "Siddhartha Srinivasa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04836"
  },
  {
    "id": "arXiv:2209.06764",
    "title": "Collision-Free 6-DoF Trajectory Generation for Omnidirectional  Multi-rotor Aerial Vehicle",
    "abstract": "Comments: 8 pages, 10 figures",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Peiyan Liu",
      "Fengyu Quan",
      "Yueqian Liu",
      "Haoyao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06764"
  },
  {
    "id": "arXiv:2209.09078",
    "title": "NIERT: Accurate Numerical Interpolation through Unifying Scattered Data  Representations using Transformer Encoder",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Shizhe Ding",
      "Dongbo Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.09078"
  },
  {
    "id": "arXiv:2209.10367",
    "title": "Electromagnetic Field Exposure Avoidance thanks to Non-Intended User  Equipment and RIS",
    "abstract": "Comments: 6 pages, 6 figures. Accepted in Globecom 2022 Workshop",
    "descriptor": "\nComments: 6 pages, 6 figures. Accepted in Globecom 2022 Workshop\n",
    "authors": [
      "Hao Guo",
      "Dinh-Thuy Phan-Huy",
      "Tommy Svensson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.10367"
  },
  {
    "id": "arXiv:2209.10385",
    "title": "Long-Lived Accurate Keypoints in Event Streams",
    "abstract": "Long-Lived Accurate Keypoints in Event Streams",
    "descriptor": "",
    "authors": [
      "Philippe Chiberre",
      "Etienne Perot",
      "Amos Sironi",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10385"
  },
  {
    "id": "arXiv:2209.11404",
    "title": "Towards Frame Rate Agnostic Multi-Object Tracking",
    "abstract": "Comments: 21 pages; Author version",
    "descriptor": "\nComments: 21 pages; Author version\n",
    "authors": [
      "Weitao Feng",
      "Lei Bai",
      "Yongqiang Yao",
      "Fengwei Yu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11404"
  },
  {
    "id": "arXiv:2209.11429",
    "title": "News Category Dataset",
    "abstract": "Comments: correction of a missing citation",
    "descriptor": "\nComments: correction of a missing citation\n",
    "authors": [
      "Rishabh Misra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.11429"
  },
  {
    "id": "arXiv:2209.12588",
    "title": "A Collaborative, Interactive and Context-Aware Drawing Agent for  Co-Creative Design",
    "abstract": "A Collaborative, Interactive and Context-Aware Drawing Agent for  Co-Creative Design",
    "descriptor": "",
    "authors": [
      "Francisco Ibarrola",
      "Tomas Lawton",
      "Kazjon Grace"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.12588"
  },
  {
    "id": "arXiv:2209.13492",
    "title": "Taking a Respite from Representation Learning for Molecular Property  Prediction",
    "abstract": "Taking a Respite from Representation Learning for Molecular Property  Prediction",
    "descriptor": "",
    "authors": [
      "Jianyuan Deng",
      "Zhibo Yang",
      "Hehe Wang",
      "Iwao Ojima",
      "Dimitris Samaras",
      "Fusheng Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13492"
  },
  {
    "id": "arXiv:2209.15200",
    "title": "An efficient encoder-decoder architecture with top-down attention for  speech separation",
    "abstract": "Comments: 13 pages, 4 figures",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Kai Li",
      "Runxuan Yang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.15200"
  },
  {
    "id": "arXiv:2209.15220",
    "title": "Assortment Optimization Under the Multivariate MNL Model",
    "abstract": "Assortment Optimization Under the Multivariate MNL Model",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Jiachun Li",
      "Menglong Li",
      "Tiancheng Zhao",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.15220"
  },
  {
    "id": "arXiv:2210.00100",
    "title": "Image-Based Detection of Modifications in Gas Pump PCBs with Deep  Convolutional Autoencoders",
    "abstract": "Image-Based Detection of Modifications in Gas Pump PCBs with Deep  Convolutional Autoencoders",
    "descriptor": "",
    "authors": [
      "Diulhio Candido de Oliveira",
      "Bogdan Tomoyuki Nassu",
      "Marco Aurelio Wehrmeister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00100"
  },
  {
    "id": "arXiv:2210.00380",
    "title": "Causal Knowledge Transfer from Task Affinity",
    "abstract": "Causal Knowledge Transfer from Task Affinity",
    "descriptor": "",
    "authors": [
      "Ahmed Aloui",
      "Juncheng Dong",
      "Cat P. Le",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00380"
  },
  {
    "id": "arXiv:2210.00545",
    "title": "Seeing Through The Noisy Dark: Toward Real-world Low-Light Image  Enhancement and Denoising",
    "abstract": "Seeing Through The Noisy Dark: Toward Real-world Low-Light Image  Enhancement and Denoising",
    "descriptor": "",
    "authors": [
      "Jiahuan Ren",
      "Zhao Zhang",
      "Richang Hong",
      "Mingliang Xu",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00545"
  },
  {
    "id": "arXiv:2210.00943",
    "title": "Simple Pooling Front-ends For Efficient Audio Classification",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xubo Liu",
      "Haohe Liu",
      "Qiuqiang Kong",
      "Xinhao Mei",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00943"
  },
  {
    "id": "arXiv:2210.01461",
    "title": "In the realm of hybrid Brain: Human Brain and AI",
    "abstract": "Comments: 41 Pages, 10 Figures,",
    "descriptor": "\nComments: 41 Pages, 10 Figures,\n",
    "authors": [
      "Hoda Fares",
      "Margherita Ronchini",
      "Milad Zamani",
      "Hooman Farkhani",
      "Farshad Moradi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.01461"
  },
  {
    "id": "arXiv:2210.01869",
    "title": "Memory in humans and deep language models: Linking hypotheses for model  augmentation",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Omri Raccah",
      "Phoebe Chen",
      "Ted L. Willke",
      "David Poeppel",
      "Vy A. Vo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01869"
  },
  {
    "id": "arXiv:2210.01918",
    "title": "Non-Parametric and Regularized Dynamical Wasserstein Barycenters for  Time-Series Analysis",
    "abstract": "Non-Parametric and Regularized Dynamical Wasserstein Barycenters for  Time-Series Analysis",
    "descriptor": "",
    "authors": [
      "Kevin C. Cheng",
      "Shuchin Aeron",
      "Michael C. Hughes",
      "Eric L. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.01918"
  },
  {
    "id": "arXiv:2210.02068",
    "title": "Contextualized Generative Retrieval",
    "abstract": "Contextualized Generative Retrieval",
    "descriptor": "",
    "authors": [
      "Hyunji Lee",
      "Jaeyoung Kim",
      "Hoyeon Chang",
      "Hanseok Oh",
      "Sohee Yang",
      "Vlad Karpukhin",
      "Yi Lu",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02068"
  },
  {
    "id": "arXiv:2210.02297",
    "title": "Multiclass Learnability Beyond the PAC Framework: Universal Rates and  Partial Concept Classes",
    "abstract": "Multiclass Learnability Beyond the PAC Framework: Universal Rates and  Partial Concept Classes",
    "descriptor": "",
    "authors": [
      "Alkis Kalavasis",
      "Grigoris Velegkas",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02297"
  },
  {
    "id": "arXiv:2210.02368",
    "title": "Spatio-Temporal Learnable Proposals for End-to-End Video Object  Detection",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Khurram Azeem Hashmi",
      "Didier Stricker",
      "Muhammamd Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02368"
  },
  {
    "id": "arXiv:2210.02658",
    "title": "Learning functional sections in medical conversations: iterative  pseudo-labeling and human-in-the-loop approach",
    "abstract": "Comments: Changed the github link as it was invalid",
    "descriptor": "\nComments: Changed the github link as it was invalid\n",
    "authors": [
      "Mengqian Wang",
      "Ilya Valmianski",
      "Xavier Amatriain",
      "Anitha Kannan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02658"
  },
  {
    "id": "arXiv:2210.02660",
    "title": "Representing Marginalized Populations: Challenges in Anthropographics",
    "abstract": "Representing Marginalized Populations: Challenges in Anthropographics",
    "descriptor": "",
    "authors": [
      "Priya Dhawka",
      "Helen Ai He",
      "Wesley Willett"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.02660"
  },
  {
    "id": "arXiv:2210.02695",
    "title": "Different Perspectives on FLP Impossibility",
    "abstract": "Different Perspectives on FLP Impossibility",
    "descriptor": "",
    "authors": [
      "Ivan Klianev"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.02695"
  },
  {
    "id": "arXiv:2210.02729",
    "title": "Join-Chain Network: A Logical Reasoning View of the Multi-head Attention  in Transformer",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Jianyi Zhang",
      "Yiran Chen",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02729"
  },
  {
    "id": "arXiv:2210.02989",
    "title": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using  Synthetic Data",
    "abstract": "SynBench: Task-Agnostic Benchmarking of Pretrained Representations using  Synthetic Data",
    "descriptor": "",
    "authors": [
      "Ching-Yun Ko",
      "Pin-Yu Chen",
      "Jeet Mohapatra",
      "Payel Das",
      "Luca Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02989"
  },
  {
    "id": "arXiv:2210.03055",
    "title": "Lattice Linear Problems vs Algorithms",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2209.14703",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.14703\n",
    "authors": [
      "Arya Tanmay Gupta",
      "Sandeep S Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.03055"
  },
  {
    "id": "arXiv:2210.03092",
    "title": "Adaptive Ranking-based Sample Selection for Weakly Supervised  Class-imbalanced Text Classification",
    "abstract": "Adaptive Ranking-based Sample Selection for Weakly Supervised  Class-imbalanced Text Classification",
    "descriptor": "",
    "authors": [
      "Linxin Song",
      "Jieyu Zhang",
      "Tianxiang Yang",
      "Masayuki Goto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03092"
  }
]
[
  {
    "id": "arXiv:2210.15666",
    "title": "Simulation of continuous dynamic recrystallization using a level-set  method",
    "abstract": "Dynamic recrystallization is one of the main phenomena responsible for\nmicrostructure evolutions during hot forming. Consequently, getting a better\nunderstanding of DRX mechanisms and being able to predict them is crucial. This\npaper proposes a full-field numerical framework to predict the evolution of\nsubgrain structures upon grain growth, continuous dynamic and post-dynamic\nrecrystallization. The microstructure representation into the numerical\nenvironment is presented. The developments made to improve substructure\ndescription are detailed extensively. Using these simulation tools, simulation\nof grain growth of a fully substructured microstructure are run. The influence\nof microstructure topology, of subgrain parameters and of some remaining stored\nenergy due to plastic deformation is discussed. An analysis of the criterion\nfor discrimination of recrystallized grains is proposed. Finally, the ability\nof the framework to model continuous dynamic and post-dynamic recrystallization\nis assessed upon a case study. The influence of grain boundary properties and\nof nucleation rules are studied. The representativity of the results in regards\nof experimental data will be discussed in an upcoming article.",
    "descriptor": "",
    "authors": [
      "Victor Grand",
      "Baptiste Flipon",
      "Alexis Gaillac",
      "Marc Bernacki"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2210.15666"
  },
  {
    "id": "arXiv:2210.15667",
    "title": "Probabilistic Prediction of Coalescence Flutter Using Measurements:  Application to the Flutter Margin Method",
    "abstract": "Zimmerman and Weissenburger's flutter margin method is widely used to\nestimate the aeroelastic coalescence flutter speed. In contrast to aeroelastic\ndecay rates, the flutter margin exhibits monotonic decay with respect to\nairspeed redering it effective in extrapolating the flutter speed using flight\ntest data conducted at pre-flutter airspeeds. This paper reports the\ngeneralization of the Bayesian formulation of the flutter margin method by\nKhalil et al. developed to tackle measurement and modeling uncertainties. This\npaper improves the predictive performance of the previous algorithm by\nincorporating the joint prior of aeroelastic modal frequencies and decay rates\namong airspeeds in order to better estimate the joint posterior of modal\nparameters using observational data. The modal parameter prior is constructed\nusing the classical two-degree-of-freedom pitch-plunge aeroelastic model whose\nsystem matrices (e.g. structural stiffness and damping matrices) vary randomly.\nSuch joint modal parameter prior enforces statistical dependence among\nposteriors of modal parameters and the associated flutter margins across\nairspeeds. Numerical studies demonstrate a considerable reduction of\nuncertainties on the predicted flutter speed obtained from the generalized\nBayesian flutter margin method. This improved algorithm can cut cost by\nreducing the number of flight tests and better assess the uncertainty against\naeroelastic flutter.",
    "descriptor": "",
    "authors": [
      "Sandip Chajjed",
      "Mohammad Khalil",
      "Dominique Poirel",
      "Chris Pettit",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.15667"
  },
  {
    "id": "arXiv:2210.15668",
    "title": "FerroX : A GPU-accelerated, 3D Phase-Field Simulation Framework for  Modeling Ferroelectric Devices",
    "abstract": "We present a massively parallel, 3D phase-field simulation framework for\nmodeling ferro-electric materials based scalable logic devices. We\nself-consistently solve the time-dependent Ginzburg Landau (TDGL) equation for\nferroelectric polarization, Poisson equation for electric potential, and charge\nequation for carrier densities in semiconductor regions. The algorithm is\nimplemented using the AMReX software framework, which provides effective\nscalability on manycore and GPU-based supercomputing architectures. We\ndemonstrate the performance of the algorithm with excellent scaling results on\nNERSC multicore and GPU systems, with a significant (15x) speedup on the GPU\nusing a node-by-node comparison. We further demonstrate the applicability of\nthe code in simulations of ferroelectric domain-wall induced negative\ncapacitance (NC) effect in Metal-Ferroelectric-Insulator-Metal (MFIM) and\nMetal-Ferroelectric-Insulator-Semiconductor-Metal (MFISM) devices. The charge\n(Q) v.s. applied voltage (V) responses for these structures clearly indicates\nstabilized negative capacitance.",
    "descriptor": "",
    "authors": [
      "Prabhat Kumar",
      "Andrew Nonaka",
      "Revathi Jambunathan",
      "Girish Pahwa",
      "Sayeef Salahuddin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.15668"
  },
  {
    "id": "arXiv:2210.15669",
    "title": "On Catalan Constant Continued Fractions",
    "abstract": "The Ramanujan Machine project detects new expressions related to constants of\ninterests, such as $\\zeta$ function values, $\\gamma$ and algebraic numbers (to\nname a few). In particular the project lists a number of conjectures concerning\nthe Catalan constant $G= 0.91596559\\ldots$. We show how to generate infinitely\nmany. We used an ad hoc software toolchain and rather tedious mathematical\ndevelopments.",
    "descriptor": "",
    "authors": [
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2210.15669"
  },
  {
    "id": "arXiv:2210.15670",
    "title": "Knowledge-Guided Exploration in Deep Reinforcement Learning",
    "abstract": "This paper proposes a new method to drastically speed up deep reinforcement\nlearning (deep RL) training for problems that have the property of state-action\npermissibility (SAP). Two types of permissibility are defined under SAP. The\nfirst type says that after an action $a_t$ is performed in a state $s_t$ and\nthe agent has reached the new state $s_{t+1}$, the agent can decide whether\n$a_t$ is permissible or not permissible in $s_t$. The second type says that\neven without performing $a_t$ in $s_t$, the agent can already decide whether\n$a_t$ is permissible or not in $s_t$. An action is not permissible in a state\nif the action can never lead to an optimal solution and thus should not be\ntried (over and over again). We incorporate the proposed SAP property and\nencode action permissibility knowledge into two state-of-the-art deep RL\nalgorithms to guide their state-action exploration together with a virtual\nstopping strategy. Results show that the SAP-based guidance can markedly speed\nup RL training.",
    "descriptor": "\nComments: This paper is an extended and revised version of the work: \"Action permissibility in deep reinforcement learning and application to autonomous driving\", KDD'18 Deep Learning Day (2018)\n",
    "authors": [
      "Sahisnu Mazumder",
      "Bing Liu",
      "Shuai Wang",
      "Yingxuan Zhu",
      "Xiaotian Yin",
      "Lifeng Liu",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15670"
  },
  {
    "id": "arXiv:2210.15672",
    "title": "Average Age of Information Penalty of Short-Packet Communications with  Packet Management",
    "abstract": "In this paper, we analyze the non-linear age of information (AoI) performance\nin a point-to-point short packet communication system, where a transmitter\ngenerates packets based on status updates and transmits the packets to a\nreceiver. Specifically, we investigate three packet management strategies,\nnamely, the non-preemption with no buffer strategy, the non-preemption with one\nbuffer strategy, and the preemption strategy. To characterize the level of the\nreceiver's dissatisfaction on outdated data, we adopt a generalized\n\\alpha-\\beta AoI penalty function into the analysis and derive closed-form\nexpressions for the average AoI penalty achieved by the three packet management\nstrategies. Simulation results are used to corroborate our analysis and\nexplicitly evaluate the impact of various system parameters, such as the coding\nrate and status update generation rate, on the AoI performance. Additionally,\nwe find that the value of \\alpha reflects the system transmission reliability.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.15078\n",
    "authors": [
      "Zhifeng Tang",
      "Nan Yang",
      "Xiangyun Zhou",
      "Jemin Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15672"
  },
  {
    "id": "arXiv:2210.15674",
    "title": "Reverse Survival Model (RSM): A Pipeline for Explaining Predictions of  Deep Survival Models",
    "abstract": "The aim of survival analysis in healthcare is to estimate the probability of\noccurrence of an event, such as a patient's death in an intensive care unit\n(ICU). Recent developments in deep neural networks (DNNs) for survival analysis\nshow the superiority of these models in comparison with other well-known models\nin survival analysis applications. Ensuring the reliability and explainability\nof deep survival models deployed in healthcare is a necessity. Since DNN models\noften behave like a black box, their predictions might not be easily trusted by\nclinicians, especially when predictions are contrary to a physician's opinion.\nA deep survival model that explains and justifies its decision-making process\ncould potentially gain the trust of clinicians. In this research, we propose\nthe reverse survival model (RSM) framework that provides detailed insights into\nthe decision-making process of survival models. For each patient of interest,\nRSM can extract similar patients from a dataset and rank them based on the most\nrelevant features that deep survival models rely on for their predictions.",
    "descriptor": "",
    "authors": [
      "Mohammad R. Rezaei",
      "Reza Saadati Fard",
      "Ebrahim Pourjafari",
      "Navid Ziaei",
      "Amir Sameizadeh",
      "Mohammad Shafiee",
      "Mohammad Alavinia",
      "Mansour Abolghasemian",
      "Nick Sajadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15674"
  },
  {
    "id": "arXiv:2210.15675",
    "title": "Feature Necessity & Relevancy in ML Classifier Explanations",
    "abstract": "Given a machine learning (ML) model and a prediction, explanations can be\ndefined as sets of features which are sufficient for the prediction. In some\napplications, and besides asking for an explanation, it is also critical to\nunderstand whether sensitive features can occur in some explanation, or whether\na non-interesting feature must occur in all explanations. This paper starts by\nrelating such queries respectively with the problems of relevancy and necessity\nin logic-based abduction. The paper then proves membership and hardness results\nfor several families of ML classifiers. Afterwards the paper proposes concrete\nalgorithms for two classes of classifiers. The experimental results confirm the\nscalability of the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Xuanxiang Huang",
      "Martin C. Cooper",
      "Antonio Morgado",
      "Jordi Planes",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15675"
  },
  {
    "id": "arXiv:2210.15676",
    "title": "Deepening Neural Networks Implicitly and Locally via Recurrent Attention  Strategy",
    "abstract": "More and more empirical and theoretical evidence shows that deepening neural\nnetworks can effectively improve their performance under suitable training\nsettings. However, deepening the backbone of neural networks will inevitably\nand significantly increase computation and parameter size. To mitigate these\nproblems, we propose a simple-yet-effective Recurrent Attention Strategy (RAS),\nwhich implicitly increases the depth of neural networks with lightweight\nattention modules by local parameter sharing. The extensive experiments on\nthree widely-used benchmark datasets demonstrate that RAS can improve the\nperformance of neural networks at a slight addition of parameter size and\ncomputation, performing favorably against other existing well-known attention\nmodules.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Shanshan Zhong",
      "Wushao Wen",
      "Jinghui Qin",
      "Zhongzhan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15676"
  },
  {
    "id": "arXiv:2210.15677",
    "title": "ITVOLT: An Iterative Solver for Volterra Integral Equations with  Application to the Time-Dependent Schr\u00f6dinger Equation",
    "abstract": "We present a novel iterative method for solving Volterra integral equations\nof the second kind. Based on global Lagrange interpolation, the method is\nsimple to implement and applicable to a wide variety of problems. Here, we\npresent the method in detail and discuss several applications, emphasizing in\nparticular its use on the time-dependent Schr\\\"odinger equation.",
    "descriptor": "\nComments: 20 pages, 9 tables, 5 figures\n",
    "authors": [
      "Ryan Schneider",
      "Heman Gharibnejad",
      "Barry I. Schneider"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15677"
  },
  {
    "id": "arXiv:2210.15678",
    "title": "Prototype-Based Layered Federated Cross-Modal Hashing",
    "abstract": "Recently, deep cross-modal hashing has gained increasing attention. However,\nin many practical cases, data are distributed and cannot be collected due to\nprivacy concerns, which greatly reduces the cross-modal hashing performance on\neach client. And due to the problems of statistical heterogeneity, model\nheterogeneity, and forcing each client to accept the same parameters, applying\nfederated learning to cross-modal hash learning becomes very tricky. In this\npaper, we propose a novel method called prototype-based layered federated\ncross-modal hashing. Specifically, the prototype is introduced to learn the\nsimilarity between instances and classes on server, reducing the impact of\nstatistical heterogeneity (non-IID) on different clients. And we monitor the\ndistance between local and global prototypes to further improve the\nperformance. To realize personalized federated learning, a hypernetwork is\ndeployed on server to dynamically update different layers' weights of local\nmodel. Experimental results on benchmark datasets show that our method\noutperforms state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jiale Liu",
      "Yu-Wei Zhan",
      "Xin Luo",
      "Zhen-Duo Chen",
      "Yongxin Wang",
      "Xin-Shun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15678"
  },
  {
    "id": "arXiv:2210.15696",
    "title": "COMET-QE and Active Learning for Low-Resource Machine Translation",
    "abstract": "Active learning aims to deliver maximum benefit when resources are scarce. We\nuse COMET-QE, a reference-free evaluation metric, to select sentences for\nlow-resource neural machine translation. Using Swahili, Kinyarwanda and Spanish\nfor our experiments, we show that COMET-QE significantly outperforms two\nvariants of Round Trip Translation Likelihood (RTTL) and random sentence\nselection by up to 5 BLEU points for 20k sentences selected by Active Learning\non a 30k baseline. This suggests that COMET-QE is a powerful tool for sentence\nselection in the very low-resource limit.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Everlyn Asiko Chimoto",
      "Bruce A. Bassett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15696"
  },
  {
    "id": "arXiv:2210.15700",
    "title": "TAD: Transfer Learning-based Multi-Adversarial Detection of Evasion  Attacks against Network Intrusion Detection Systems",
    "abstract": "Nowadays, intrusion detection systems based on deep learning deliver\nstate-of-the-art performance. However, recent research has shown that specially\ncrafted perturbations, called adversarial examples, are capable of\nsignificantly reducing the performance of these intrusion detection systems.\nThe objective of this paper is to design an efficient transfer learning-based\nadversarial detector and then to assess the effectiveness of using multiple\nstrategically placed adversarial detectors compared to a single adversarial\ndetector for intrusion detection systems. In our experiments, we implement\nexisting state-of-the-art models for intrusion detection. We then attack those\nmodels with a set of chosen evasion attacks. In an attempt to detect those\nadversarial attacks, we design and implement multiple transfer learning-based\nadversarial detectors, each receiving a subset of the information passed\nthrough the IDS. By combining their respective decisions, we illustrate that\ncombining multiple detectors can further improve the detectability of\nadversarial traffic compared to a single detector in the case of a parallel IDS\ndesign.",
    "descriptor": "\nComments: This is a preprint of an already published journal paper\n",
    "authors": [
      "Islam Debicha",
      "Richard Bauwens",
      "Thibault Debatty",
      "Jean-Michel Dricot",
      "Tayeb Kenaza",
      "Wim Mees"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15700"
  },
  {
    "id": "arXiv:2210.15701",
    "title": "Do Pre-trained Models Benefit Equally in Continual Learning?",
    "abstract": "Existing work on continual learning (CL) is primarily devoted to developing\nalgorithms for models trained from scratch. Despite their encouraging\nperformance on contrived benchmarks, these algorithms show dramatic performance\ndrops in real-world scenarios. Therefore, this paper advocates the systematic\nintroduction of pre-training to CL, which is a general recipe for transferring\nknowledge to downstream tasks but is substantially missing in the CL community.\nOur investigation reveals the multifaceted complexity of exploiting pre-trained\nmodels for CL, along three different axes, pre-trained models, CL algorithms,\nand CL scenarios. Perhaps most intriguingly, improvements in CL algorithms from\npre-training are very inconsistent an underperforming algorithm could become\ncompetitive and even state-of-the-art when all algorithms start from a\npre-trained model. This indicates that the current paradigm, where all CL\nmethods are compared in from-scratch training, is not well reflective of the\ntrue CL objective and desired progress. In addition, we make several other\nimportant observations, including that CL algorithms that exert less\nregularization benefit more from a pre-trained model; and that a stronger\npre-trained model such as CLIP does not guarantee a better improvement. Based\non these findings, we introduce a simple yet effective baseline that employs\nminimum regularization and leverages the more beneficial pre-trained model,\ncoupled with a two-stage training pipeline. We recommend including this strong\nbaseline in the future development of CL algorithms, due to its demonstrated\nstate-of-the-art performance.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Kuan-Ying Lee",
      "Yuanyi Zhong",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15701"
  },
  {
    "id": "arXiv:2210.15707",
    "title": "FedAudio: A Federated Learning Benchmark for Audio Tasks",
    "abstract": "Federated learning (FL) has gained substantial attention in recent years due\nto the data privacy concerns related to the pervasiveness of consumer devices\nthat continuously collect data from users. While a number of FL benchmarks have\nbeen developed to facilitate FL research, none of them include audio data and\naudio-related tasks. In this paper, we fill this critical gap by introducing a\nnew FL benchmark for audio tasks which we refer to as FedAudio. FedAudio\nincludes four representative and commonly used audio datasets from three\nimportant audio tasks that are well aligned with FL use cases. In particular, a\nunique contribution of FedAudio is the introduction of data noises and label\nerrors to the datasets to emulate challenges when deploying FL systems in\nreal-world settings. FedAudio also includes the benchmark results of the\ndatasets and a PyTorch library with the objective of facilitating researchers\nto fairly compare their algorithms. We hope FedAudio could act as a catalyst to\ninspire new FL research for audio tasks and thus benefit the acoustic and\nspeech research community. The datasets and benchmark results can be accessed\nat https://github.com/zhang-tuo pdf/FedAudio.",
    "descriptor": "",
    "authors": [
      "Tuo Zhang",
      "Tiantian Feng",
      "Samiul Alam",
      "Sunwoo Lee",
      "Mi Zhang",
      "Shrikanth S. Narayanan",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15707"
  },
  {
    "id": "arXiv:2210.15711",
    "title": "Re-looking at the View Update Problem",
    "abstract": "Relational databases have always had a means for creating a pseudo-table,\ncalled a view, defined by a query. Views are like tables in most ways, except\nthat they are read-only and cannot be updated. The problem of how to update\nviews has attracted a lot of attention in the 1980s but is unsolved.\nThe best approach from that time was by Bancilhon and Spyratos. I use one of\ntheir overlooked theorems and find a number of simple solutions for common\nrelational operators.",
    "descriptor": "",
    "authors": [
      "Terry Brennan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.15711"
  },
  {
    "id": "arXiv:2210.15714",
    "title": "List Agreement Expansion from Coboundary Expansion",
    "abstract": "One of the key components in PCP constructions are agreement tests. In\nagreement test the tester is given access to subsets of fixed size of some set,\neach equipped with an assignment. The tester is then tasked with testing\nwhether these local assignments agree with some global assignment over the\nentire set. One natural generalization of this concept is the case where,\ninstead of a single assignment to each local view, the tester is given access\nto $l$ different assignments for every subset. The tester is then tasked with\ntesting whether there exist $l$ global functions that agree with all of the\nassignments of all of the local views.\nIn this work we present sufficient condition for a set system to exhibit this\ngeneralized definition of list agreement expansion. This is, to our knowledge,\nthe first work to consider this natural generalization of agreement testing.\nDespite initially appearing very similar to agreement expansion, list agreement\nexpansion seem to require a different set of techniques. This is due to the\nfact that the natural extension of agreement testing does not suffice when\ntesting for list agreement, as list agreement crucially relies on a global\nstructure. It follows that if a local assignments satisfy list agreement they\nmust not only agree locally but also exhibit some additional structure. In\norder to test for the existence of this additional structure we use a\nconnection between covering spaces of a high dimensional complex and its\ncoboundaries. We use this connection as a form of ``decoupling''.\nMoreover, we show that any set system that exhibits list agreement expansion\nalso supports direct sum testing. This is the first scheme for direct sum\ntesting that works regardless of the parity of the sizes of the local sets.\nPrior to our work the schemes for direct sum testing were based on the parity\nof the sizes of the local tests.",
    "descriptor": "",
    "authors": [
      "Roy Gotlib",
      "Tali Kaufman"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.15714"
  },
  {
    "id": "arXiv:2210.15718",
    "title": "QUILL: Query Intent with Large Language Models using Retrieval  Augmentation and Multi-stage Distillation",
    "abstract": "Large Language Models (LLMs) have shown impressive results on a variety of\ntext understanding tasks. Search queries though pose a unique challenge, given\ntheir short-length and lack of nuance or context. Complicated feature\nengineering efforts do not always lead to downstream improvements as their\nperformance benefits may be offset by increased complexity of knowledge\ndistillation. Thus, in this paper we make the following contributions: (1) We\ndemonstrate that Retrieval Augmentation of queries provides LLMs with valuable\nadditional context enabling improved understanding. While Retrieval\nAugmentation typically increases latency of LMs (thus hurting distillation\nefficacy), (2) we provide a practical and effective way of distilling Retrieval\nAugmentation LLMs. Specifically, we use a novel two-stage distillation approach\nthat allows us to carry over the gains of retrieval augmentation, without\nsuffering the increased compute typically associated with it. (3) We\ndemonstrate the benefits of the proposed approach (QUILL) on a billion-scale,\nreal-world query understanding system resulting in huge gains. Via extensive\nexperiments, including on public benchmarks, we believe this work offers a\nrecipe for practical use of retrieval-augmented query understanding.",
    "descriptor": "\nComments: EMNLP 2022 Industry Track\n",
    "authors": [
      "Krishna Srinivasan",
      "Karthik Raman",
      "Anupam Samanta",
      "Lingrui Liao",
      "Luca Bertelli",
      "Mike Bendersky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15718"
  },
  {
    "id": "arXiv:2210.15721",
    "title": "GraphMAD: Graph Mixup for Data Augmentation using Data-Driven Convex  Clustering",
    "abstract": "We develop a novel data-driven nonlinear mixup mechanism for graph data\naugmentation and present different mixup functions for sample pairs and their\nlabels. Mixup is a data augmentation method to create new training data by\nlinearly interpolating between pairs of data samples and their labels. Mixup of\ngraph data is challenging since the interpolation between graphs of potentially\ndifferent sizes is an ill-posed operation. Hence, a promising approach for\ngraph mixup is to first project the graphs onto a common latent feature space\nand then explore linear and nonlinear mixup strategies in this latent space. In\nthis context, we propose to (i) project graphs onto the latent space of\ncontinuous random graph models known as graphons, (ii) leverage convex\nclustering in this latent space to generate nonlinear data-driven mixup\nfunctions, and (iii) investigate the use of different mixup functions for\nlabels and data samples. We evaluate our graph data augmentation performance on\nbenchmark datasets and demonstrate that nonlinear data-driven mixup functions\ncan significantly improve graph classification.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables, submitted to ICASSP 2023\n",
    "authors": [
      "Madeline Navarro",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15721"
  },
  {
    "id": "arXiv:2210.15722",
    "title": "PatchRot: A Self-Supervised Technique for Training Vision Transformers",
    "abstract": "Vision transformers require a huge amount of labeled data to outperform\nconvolutional neural networks. However, labeling a huge dataset is a very\nexpensive process. Self-supervised learning techniques alleviate this problem\nby learning features similar to supervised learning in an unsupervised way. In\nthis paper, we propose a self-supervised technique PatchRot that is crafted for\nvision transformers. PatchRot rotates images and image patches and trains the\nnetwork to predict the rotation angles. The network learns to extract both\nglobal and local features from an image. Our extensive experiments on different\ndatasets showcase PatchRot training learns rich features which outperform\nsupervised learning and compared baseline.",
    "descriptor": "\nComments: NeurIPS Workshop on Vision Transformers: Theory and Applications (VTTA)\n",
    "authors": [
      "Sachin Chhabra",
      "Prabal Bijoy Dutta",
      "Hemanth Venkateswara",
      "Baoxin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15722"
  },
  {
    "id": "arXiv:2210.15723",
    "title": "Birdwatch: Crowd Wisdom and Bridging Algorithms can Inform Understanding  and Reduce the Spread of Misinformation",
    "abstract": "We present an approach for selecting objectively informative and subjectively\nhelpful annotations to social media posts. We draw on data from on an online\nenvironment where contributors annotate misinformation and simultaneously rate\nthe contributions of others. Our algorithm uses a matrix-factorization (MF)\nbased approach to identify annotations that appeal broadly across heterogeneous\nuser groups - sometimes referred to as \"bridging-based ranking.\" We pair these\ndata with a survey experiment in which individuals are randomly assigned to see\nannotations to posts. We find that annotations selected by the algorithm\nimprove key indicators compared with overall average and crowd-generated\nbaselines. Further, when deployed on Twitter, people who saw annotations\nselected through this bridging-based approach were significantly less likely to\nreshare social media posts than those who did not see the annotations.",
    "descriptor": "",
    "authors": [
      "Stefan Wojcik",
      "Sophie Hilgard",
      "Nick Judd",
      "Delia Mocanu",
      "Stephen Ragain",
      "M.B. Fallin Hunzaker",
      "Keith Coleman",
      "Jay Baxter"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.15723"
  },
  {
    "id": "arXiv:2210.15727",
    "title": "The sample complexity of sparse multi-reference alignment and  single-particle cryo-electron microscopy",
    "abstract": "Multi-reference alignment (MRA) is the problem of recovering a signal from\nits multiple noisy copies, each acted upon by a random group element. MRA is\nmainly motivated by single-particle cryo-electron microscopy (cryo-EM) that has\nrecently joined X-ray crystallography as one of the two leading technologies to\nreconstruct biological molecular structures. Previous papers have shown that in\nthe high noise regime, the sample complexity of MRA and cryo-EM is\n$n=\\omega(\\sigma^{2d})$, where $n$ is the number of observations, $\\sigma^2$ is\nthe variance of the noise, and $d$ is the lowest-order moment of the\nobservations that uniquely determines the signal. In particular, it was shown\nthat in many cases, $d=3$ for generic signals, and thus the sample complexity\nis $n=\\omega(\\sigma^6)$.\nIn this paper, we analyze the second moment of the MRA and cryo-EM models.\nFirst, we show that in both models the second moment determines the signal up\nto a set of unitary matrices, whose dimension is governed by the decomposition\nof the space of signals into irreducible representations of the group. Second,\nwe derive sparsity conditions under which a signal can be recovered from the\nsecond moment, implying sample complexity of $n=\\omega(\\sigma^4)$. Notably, we\nshow that the sample complexity of cryo-EM is $n=\\omega(\\sigma^4)$ if at most\none third of the coefficients representing the molecular structure are\nnon-zero; this bound is near-optimal. The analysis is based on tools from\nrepresentation theory and algebraic geometry. We also derive bounds on\nrecovering a sparse signal from its power spectrum, which is the main\ncomputational problem of X-ray crystallography.",
    "descriptor": "",
    "authors": [
      "Tamir Bendory",
      "Dan Edidin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15727"
  },
  {
    "id": "arXiv:2210.15731",
    "title": "Beyond Homophily with Graph Echo State Networks",
    "abstract": "Graph Echo State Networks (GESN) have already demonstrated their efficacy and\nefficiency in graph classification tasks. However, semi-supervised node\nclassification brought out the problem of over-smoothing in end-to-end trained\ndeep models, which causes a bias towards high homophily graphs. We evaluate for\nthe first time GESN on node classification tasks with different degrees of\nhomophily, analyzing also the impact of the reservoir radius. Our experiments\nshow that reservoir models are able to achieve better or comparable accuracy\nwith respect to fully trained deep models that implement ad hoc variations in\nthe architectural bias, with a gain in terms of efficiency.",
    "descriptor": "\nComments: Accepted for oral presentation at ESANN 2022\n",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15731"
  },
  {
    "id": "arXiv:2210.15734",
    "title": "Token-level Sequence Labeling for Spoken Language Understanding using  Compositional End-to-End Models",
    "abstract": "End-to-end spoken language understanding (SLU) systems are gaining popularity\nover cascaded approaches due to their simplicity and ability to avoid error\npropagation. However, these systems model sequence labeling as a sequence\nprediction task causing a divergence from its well-established token-level\ntagging formulation. We build compositional end-to-end SLU systems that\nexplicitly separate the added complexity of recognizing spoken mentions in SLU\nfrom the NLU task of sequence labeling. By relying on intermediate decoders\ntrained for ASR, our end-to-end systems transform the input modality from\nspeech to token-level representations that can be used in the traditional\nsequence labeling framework. This composition of ASR and NLU formulations in\nour end-to-end SLU system offers direct compatibility with pre-trained ASR and\nNLU systems, allows performance monitoring of individual components and enables\nthe use of globally normalized losses like CRF, making them attractive in\npractical scenarios. Our models outperform both cascaded and direct end-to-end\nmodels on a labeling task of named entity recognition across SLU benchmarks.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Findings. Our code and models will be publicly available as part of the ESPnet-SLU toolkit: this https URL and the release can be followed here: this https URL\n",
    "authors": [
      "Siddhant Arora",
      "Siddharth Dalmia",
      "Brian Yan",
      "Florian Metze",
      "Alan W Black",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15734"
  },
  {
    "id": "arXiv:2210.15740",
    "title": "Formal Semantics for the Halide Language",
    "abstract": "We present the first formalization and metatheory of language soundness for a\nuser-schedulable language, the widely used array processing language Halide.\nUser-schedulable languages strike a balance between abstraction and control in\nhigh-performance computing by separating the specification of what a program\nshould compute from a schedule for how to compute it. In the process, they make\na novel language soundness claim: the result of a program should always be the\nsame, regardless of how it is scheduled. This soundness guarantee is tricky to\nprovide in the presence of schedules that introduce redundant recomputation and\ncomputation on uninitialized data, rather than simply reordering statements. In\naddition, Halide ensures memory safety through a compile-time bounds inference\nengine that determines safe sizes for every buffer and loop in the generated\ncode, presenting a novel challenge: formalizing and analyzing a language\nspecification that depends on the results of unreliable program synthesis\nalgorithms. Our formalization has revealed flaws and led to improvements in the\npractical Halide system, and we believe it provides a foundation for the design\nof new languages and tools that apply programmer-controlled scheduling to other\ndomains.",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Alex Reinking",
      "Gilbert Louis Bernstein",
      "Jonathan Ragan-Kelley"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.15740"
  },
  {
    "id": "arXiv:2210.15741",
    "title": "Spatio-temporal predictive tasks for abnormal event detection in videos",
    "abstract": "Abnormal event detection in videos is a challenging problem, partly due to\nthe multiplicity of abnormal patterns and the lack of their corresponding\nannotations. In this paper, we propose new constrained pretext tasks to learn\nobject level normality patterns. Our approach consists in learning a mapping\nbetween down-scaled visual queries and their corresponding normal appearance\nand motion characteristics at the original resolution. The proposed tasks are\nmore challenging than reconstruction and future frame prediction tasks which\nare widely used in the literature, since our model learns to jointly predict\nspatial and temporal features rather than reconstructing them. We believe that\nmore constrained pretext tasks induce a better learning of normality patterns.\nExperiments on several benchmark datasets demonstrate the effectiveness of our\napproach to localize and track anomalies as it outperforms or reaches the\ncurrent state-of-the-art on spatio-temporal evaluation metrics.",
    "descriptor": "\nComments: Accepted at the 18th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2022\n",
    "authors": [
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15741"
  },
  {
    "id": "arXiv:2210.15745",
    "title": "DICTION: DynamIC robusT whIte bOx watermarkiNg scheme",
    "abstract": "Deep neural network (DNN) watermarking is a suitable method for protecting\nthe ownership of deep learning (DL) models derived from computationally\nintensive processes and painstakingly compiled and annotated datasets. It\nsecretly embeds an identifier (watermark) within the model, which can be\nretrieved by the owner to prove ownership. In this paper, we first provide a\nunified framework for white box DNN watermarking schemes. It includes current\nstate-of-the art methods outlining their theoretical inter-connections. In\nsecond, we introduce DICTION, a new white-box Dynamic Robust watermarking\nscheme, we derived from this framework. Its main originality stands on a\ngenerative adversarial network (GAN) strategy where the watermark extraction\nfunction is a DNN trained as a GAN discriminator, and the target model to\nwatermark as a GAN generator taking a GAN latent space as trigger set input.\nDICTION can be seen as a generalization of DeepSigns which, to the best of\nknowledge, is the only other Dynamic white-box watermarking scheme from the\nliterature. Experiments conducted on the same model test set as Deepsigns\ndemonstrate that our scheme achieves much better performance. Especially, and\ncontrarily to DeepSigns, with DICTION one can increase the watermark capacity\nwhile preserving at best the model accuracy and ensuring simultaneously a\nstrong robustness against a wide range of watermark removal and detection\nattacks.",
    "descriptor": "\nComments: 18 pages, 5 figures, PrePrint\n",
    "authors": [
      "Reda Bellafqira",
      "Gouenou Coatrieux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15745"
  },
  {
    "id": "arXiv:2210.15748",
    "title": "DESSERT: An Efficient Algorithm for Vector Set Search with Vector Set  Queries",
    "abstract": "We study the problem of \\emph{vector set search} with \\emph{vector set\nqueries}. This task is analogous to traditional near-neighbor search, with the\nexception that both the query and each element in the collection are\n\\textit{sets} of vectors. We identify this problem as a core subroutine for\nmany web applications and find that existing solutions are unacceptably slow.\nTowards this end, we present a new approximate search algorithm, DESSERT ({\\bf\nD}ESSERT {\\bf E}ffeciently {\\bf S}earches {\\bf S}ets of {\\bf E}mbeddings via\n{\\bf R}etrieval {\\bf T}ables). DESSERT is a general tool with strong\ntheoretical guarantees and excellent empirical performance. When we integrate\nDESSERT into ColBERT, a highly optimized state-of-the-art semantic search\nmethod, we find a 2-5x speedup on the MSMarco passage ranking task with minimal\nloss in recall, underscoring the effectiveness and practical applicability of\nour proposal.",
    "descriptor": "\nComments: Code available, this https URL\n",
    "authors": [
      "Joshua Engels",
      "Benjamin Coleman",
      "Vihan Lakshman",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15748"
  },
  {
    "id": "arXiv:2210.15750",
    "title": "One-Shot Acoustic Matching Of Audio Signals -- Learning to Hear Music In  Any Room/ Concert Hall",
    "abstract": "The acoustic space in which a sound is created and heard plays an essential\nrole in how that sound is perceived by affording a unique sense of\n\\textit{presence}. Every sound we hear results from successive convolution\noperations intrinsic to the sound source and external factors such as\nmicrophone characteristics and room impulse responses. Typically, researchers\nuse an excitation such as a pistol shot or balloon pop as an impulse signal\nwith which an auralization can be created. The room \"impulse\" responses\nconvolved with the signal of interest can transform the input sound into the\nsound played in the acoustic space of interest. Here we propose a novel\narchitecture that can transform a sound of interest into any other acoustic\nspace(room or hall) of interest by using arbitrary audio recorded as a proxy\nfor a balloon pop. The architecture is grounded in simple signal processing\nideas to learn residual signals from a learned acoustic signature and the input\nsignal. Our framework allows a neural network to adjust gains of every point in\nthe time-frequency representation, giving sound qualitative and quantitative\nresults.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Prateek Verma",
      "Chris Chafe",
      "Jonathan Berger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15750"
  },
  {
    "id": "arXiv:2210.15751",
    "title": "Planning with Spatial-Temporal Abstraction from Point Clouds for  Deformable Object Manipulation",
    "abstract": "Effective planning of long-horizon deformable object manipulation requires\nsuitable abstractions at both the spatial and temporal levels. Previous methods\ntypically either focus on short-horizon tasks or make strong assumptions that\nfull-state information is available, which prevents their use on deformable\nobjects. In this paper, we propose PlAnning with Spatial-Temporal Abstraction\n(PASTA), which incorporates both spatial abstraction (reasoning about objects\nand their relations to each other) and temporal abstraction (reasoning over\nskills instead of low-level actions). Our framework maps high-dimension 3D\nobservations such as point clouds into a set of latent vectors and plans over\nskill sequences on top of the latent set representation. We show that our\nmethod can effectively perform challenging sequential deformable object\nmanipulation tasks in the real world, which require combining multiple tool-use\nskills such as cutting with a knife, pushing with a pusher, and spreading the\ndough with a roller.",
    "descriptor": "",
    "authors": [
      "Xingyu Lin",
      "Carl Qi",
      "Yunchu Zhang",
      "Zhiao Huang",
      "Katerina Fragkiadaki",
      "Yunzhu Li",
      "Chuang Gan",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15751"
  },
  {
    "id": "arXiv:2210.15755",
    "title": "Confident Approximate Policy Iteration for Efficient Local Planning in  $q^\u03c0$-realizable MDPs",
    "abstract": "We consider approximate dynamic programming in $\\gamma$-discounted Markov\ndecision processes and apply it to approximate planning with linear\nvalue-function approximation. Our first contribution is a new variant of\nApproximate Policy Iteration (API), called Confident Approximate Policy\nIteration (CAPI), which computes a deterministic stationary policy with an\noptimal error bound scaling linearly with the product of the effective horizon\n$H$ and the worst-case approximation error $\\epsilon$ of the action-value\nfunctions of stationary policies. This improvement over API (whose error scales\nwith $H^2$) comes at the price of an $H$-fold increase in memory cost. Unlike\nScherrer and Lesner [2012], who recommended computing a non-stationary policy\nto achieve a similar improvement (with the same memory overhead), we are able\nto stick to stationary policies. This allows for our second contribution, the\napplication of CAPI to planning with local access to a simulator and\n$d$-dimensional linear function approximation. As such, we design a planning\nalgorithm that applies CAPI to obtain a sequence of policies with successively\nrefined accuracies on a dynamically evolving set of states. The algorithm\noutputs an $\\tilde O(\\sqrt{d}H\\epsilon)$-optimal policy after issuing $\\tilde\nO(dH^4/\\epsilon^2)$ queries to the simulator, simultaneously achieving the\noptimal accuracy bound and the best known query complexity bound, while earlier\nalgorithms in the literature achieve only one of them. This query complexity is\nshown to be tight in all parameters except $H$. These improvements come at the\nexpense of a mild (polynomial) increase in memory and computational costs of\nboth the algorithm and its output policy.",
    "descriptor": "",
    "authors": [
      "Gell\u00e9rt Weisz",
      "Andr\u00e1s Gy\u00f6rgy",
      "Tadashi Kozuno",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15755"
  },
  {
    "id": "arXiv:2210.15759",
    "title": "Self-supervised language learning from raw audio: Lessons from the Zero  Resource Speech Challenge",
    "abstract": "Recent progress in self-supervised or unsupervised machine learning has\nopened the possibility of building a full speech processing system from raw\naudio without using any textual representations or expert labels such as\nphonemes, dictionaries or parse trees. The contribution of the Zero Resource\nSpeech Challenge series since 2015 has been to break down this long-term\nobjective into four well-defined tasks -- Acoustic Unit Discovery, Spoken Term\nDiscovery, Discrete Resynthesis, and Spoken Language Modeling -- and introduce\nassociated metrics and benchmarks enabling model comparison and cumulative\nprogress. We present an overview of the six editions of this challenge series\nsince 2015, discuss the lessons learned, and outline the areas which need more\nwork or give puzzling results.",
    "descriptor": "",
    "authors": [
      "Ewan Dunbar",
      "Nicolas Hamilakis",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15759"
  },
  {
    "id": "arXiv:2210.15760",
    "title": "Towards Improving Workers' Safety and Progress Monitoring of  Construction Sites Through Construction Site Understanding",
    "abstract": "An important component of computer vision research is object detection. In\nrecent years, there has been tremendous progress in the study of construction\nsite images. However, there are obvious problems in construction object\ndetection, including complex backgrounds, varying-sized objects, and poor\nimaging quality. In the state-of-the-art approaches, elaborate attention\nmechanisms are developed to handle space-time features, but rarely address the\nimportance of channel-wise feature adjustments. We propose a lightweight\nOptimized Positioning (OP) module to improve channel relation based on global\nfeature affinity association, which can be used to determine the Optimized\nweights adaptively for each channel. OP first computes the intermediate\noptimized position by comparing each channel with the remaining channels for a\ngiven set of feature maps. A weighted aggregation of all the channels will then\nbe used to represent each channel. The OP-Net module is a general deep neural\nnetwork module that can be plugged into any deep neural network. Algorithms\nthat utilize deep learning have demonstrated their ability to identify a wide\nrange of objects from images nearly in real time. Machine intelligence can\npotentially benefit the construction industry by automatically analyzing\nproductivity and monitoring safety using algorithms that are linked to\nconstruction images. The benefits of on-site automatic monitoring are immense\nwhen it comes to hazard prevention. Construction monitoring tasks can also be\nautomated once construction objects have been correctly recognized. Object\ndetection task in construction site images is experimented with extensively to\ndemonstrate its efficacy and effectiveness. A benchmark test using SODA\ndemonstrated that our OP-Net was capable of achieving new state-of-the-art\nperformance in accuracy while maintaining a reasonable computational overhead.",
    "descriptor": "",
    "authors": [
      "Mahdi Bonyani",
      "Maryam Soleymani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15760"
  },
  {
    "id": "arXiv:2210.15762",
    "title": "Nearest Neighbor Language Models for Stylistic Controllable Generation",
    "abstract": "Recent language modeling performance has been greatly improved by the use of\nexternal memory. This memory encodes the context so that similar contexts can\nbe recalled during decoding. This similarity depends on how the model learns to\nencode context, which can be altered to include other attributes, such as\nstyle. We construct and evaluate an architecture for this purpose, using\ncorpora annotated for politeness, formality, and toxicity. Through extensive\nexperiments and human evaluation we demonstrate the potential of our method to\ngenerate text while controlling style. We find that style-specific datastores\nimprove generation performance, though results vary greatly across styles, and\nthe effect of pretraining data and specific styles should be explored in future\nwork.",
    "descriptor": "\nComments: Accepted to GEM workshop at EMNLP 2022\n",
    "authors": [
      "Severino Trotta",
      "Lucie Flek",
      "Charles Welch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15762"
  },
  {
    "id": "arXiv:2210.15764",
    "title": "Noise Injection Node Regularization for Robust Learning",
    "abstract": "We introduce Noise Injection Node Regularization (NINR), a method of\ninjecting structured noise into Deep Neural Networks (DNN) during the training\nstage, resulting in an emergent regularizing effect. We present theoretical and\nempirical evidence for substantial improvement in robustness against various\ntest data perturbations for feed-forward DNNs when trained under NINR. The\nnovelty in our approach comes from the interplay of adaptive noise injection\nand initialization conditions such that noise is the dominant driver of\ndynamics at the start of training. As it simply requires the addition of\nexternal nodes without altering the existing network structure or optimization\nalgorithms, this method can be easily incorporated into many standard problem\nspecifications. We find improved stability against a number of data\nperturbations, including domain shifts, with the most dramatic improvement\nobtained for unstructured noise, where our technique outperforms other existing\nmethods such as Dropout or $L_2$ regularization, in some cases. We further show\nthat desirable generalization properties on clean data are generally\nmaintained.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Noam Levi",
      "Itay M. Bloch",
      "Marat Freytsis",
      "Tomer Volansky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15764"
  },
  {
    "id": "arXiv:2210.15765",
    "title": "An Adversarial Active Sampling-based Data Augmentation Framework for  Manufacturable Chip Design",
    "abstract": "Lithography modeling is a crucial problem in chip design to ensure a chip\ndesign mask is manufacturable. It requires rigorous simulations of optical and\nchemical models that are computationally expensive. Recent developments in\nmachine learning have provided alternative solutions in replacing the\ntime-consuming lithography simulations with deep neural networks. However, the\nconsiderable accuracy drop still impedes its industrial adoption. Most\nimportantly, the quality and quantity of the training dataset directly affect\nthe model performance. To tackle this problem, we propose a litho-aware data\naugmentation (LADA) framework to resolve the dilemma of limited data and\nimprove the machine learning model performance. First, we pretrain the neural\nnetworks for lithography modeling and a gradient-friendly StyleGAN2 generator.\nWe then perform adversarial active sampling to generate informative and\nsynthetic in-distribution mask designs. These synthetic mask images will\naugment the original limited training dataset used to finetune the lithography\nmodel for improved performance. Experimental results demonstrate that LADA can\nsuccessfully exploits the neural network capacity by narrowing down the\nperformance gap between the training and testing data instances.",
    "descriptor": "",
    "authors": [
      "Mingjie Liu",
      "Haoyu Yang",
      "Zongyi Li",
      "Kumara Sastry",
      "Saumyadip Mukhopadhyay",
      "Selim Dogru",
      "Anima Anandkumar",
      "David Z. Pan",
      "Brucek Khailany",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15765"
  },
  {
    "id": "arXiv:2210.15767",
    "title": "Gathering Strength, Gathering Storms: The One Hundred Year Study on  Artificial Intelligence (AI100) 2021 Study Panel Report",
    "abstract": "In September 2021, the \"One Hundred Year Study on Artificial Intelligence\"\nproject (AI100) issued the second report of its planned long-term periodic\nassessment of artificial intelligence (AI) and its impact on society. It was\nwritten by a panel of 17 study authors, each of whom is deeply rooted in AI\nresearch, chaired by Michael Littman of Brown University. The report, entitled\n\"Gathering Strength, Gathering Storms,\" answers a set of 14 questions probing\ncritical areas of AI development addressing the major risks and dangers of AI,\nits effects on society, its public perception and the future of the field. The\nreport concludes that AI has made a major leap from the lab to people's lives\nin recent years, which increases the urgency to understand its potential\nnegative effects. The questions were developed by the AI100 Standing Committee,\nchaired by Peter Stone of the University of Texas at Austin, consisting of a\ngroup of AI leaders with expertise in computer science, sociology, ethics,\neconomics, and other disciplines.",
    "descriptor": "\nComments: 82 pages, this https URL\n",
    "authors": [
      "Michael L. Littman",
      "Ifeoma Ajunwa",
      "Guy Berger",
      "Craig Boutilier",
      "Morgan Currie",
      "Finale Doshi-Velez",
      "Gillian Hadfield",
      "Michael C. Horowitz",
      "Charles Isbell",
      "Hiroaki Kitano",
      "Karen Levy",
      "Terah Lyons",
      "Melanie Mitchell",
      "Julie Shah",
      "Steven Sloman",
      "Shannon Vallor",
      "Toby Walsh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15767"
  },
  {
    "id": "arXiv:2210.15769",
    "title": "Fully-attentive and interpretable: vision and video vision transformers  for pain detection",
    "abstract": "Pain is a serious and costly issue globally, but to be treated, it must first\nbe detected. Vision transformers are a top-performing architecture in computer\nvision, with little research on their use for pain detection. In this paper, we\npropose the first fully-attentive automated pain detection pipeline that\nachieves state-of-the-art performance on binary pain detection from facial\nexpressions. The model is trained on the UNBC-McMaster dataset, after faces are\n3D-registered and rotated to the canonical frontal view. In our experiments we\nidentify important areas of the hyperparameter space and their interaction with\nvision and video vision transformers, obtaining 3 noteworthy models. We analyse\nthe attention maps of one of our models, finding reasonable interpretations for\nits predictions. We also evaluate Mixup, an augmentation technique, and\nSharpness-Aware Minimization, an optimizer, with no success. Our presented\nmodels, ViT-1 (F1 score 0.55 +- 0.15), ViViT-1 (F1 score 0.55 +- 0.13), and\nViViT-2 (F1 score 0.49 +- 0.04), all outperform earlier works, showing the\npotential of vision transformers for pain detection. Code is available at\nhttps://github.com/IPDTFE/ViT-McMaster",
    "descriptor": "\nComments: 9 pages (12 with references), 10 figures, VTTA2022\n",
    "authors": [
      "Giacomo Fiorentini",
      "Itir Onal Ertugrul",
      "Albert Ali Salah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15769"
  },
  {
    "id": "arXiv:2210.15773",
    "title": "Data-driven anomaly detection in large battery packs",
    "abstract": "Early detection and tracing of anomalous operation in battery packs are\ncritical to improving performance and ensuring safety. This paper presents a\ndata-driven approach for online anomaly detection in battery packs that uses\nreal-time voltage and temperature data from multiple Li-ion battery cells.\nMean-based residuals are generated for cell groups and evaluated using\nPrincipal Component Analysis (PCA). The evaluated residuals are then\nthresholded using a cumulative sum control chart to detect anomalies. A\nstatistical testing of the proposed approach is performed on experimental data\nfrom a battery electric locomotive injected with model-based anomalies. The\nproposed anomaly detection approach has low false positive rate and accurately\ndetects and traces the synthetic voltage and temperature anomalies. The\nperformance of the proposed approach, compared with direct thresholding of\nmean-based residuals, shows 56% faster detection time, 42% less false\nnegatives, and 60% fewer missed anomalies, while maintaining a comparable false\npositive rate. The mild external short circuits associated with cell balancing\nare detected in the voltage signals and necessitate voltage retraining after\nbalancing. Temperature residuals prove to be critical, enabling anomaly\ndetection of module balancing events within 14 minutes that are unobservable\nfrom voltage residuals.",
    "descriptor": "",
    "authors": [
      "Kiran Bhaskar",
      "Ajith Kumar",
      "James Bunce",
      "Jacob Pressman",
      "Neil Burkell",
      "Christopher D. Rahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15773"
  },
  {
    "id": "arXiv:2210.15775",
    "title": "Evaluating context-invariance in unsupervised speech representations",
    "abstract": "Unsupervised speech representations have taken off, with benchmarks (SUPERB,\nZeroSpeech) demonstrating major progress on semi-supervised speech recognition,\nspeech synthesis, and speech-only language modelling. Inspiration comes from\nthe promise of ``discovering the phonemes'' of a language or a similar\nlow-bitrate encoding. However, one of the critical properties of phoneme\ntranscriptions is context-invariance: the phonetic context of a speech sound\ncan have massive influence on the way it is pronounced, while the text remains\nstable. This is what allows tokens of the same word to have the same\ntranscriptions -- key to language understanding. Current benchmarks do not\nmeasure context-invariance. We develop a new version of the ZeroSpeech ABX\nbenchmark that measures context-invariance, and apply it to recent\nself-supervised representations. We demonstrate that the context-independence\nof representations is predictive of the stability of word-level\nrepresentations. We suggest research concentrate on improving\ncontext-independence of self-supervised and unsupervised representations.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Mark Hallap",
      "Emmanuel Dupoux",
      "Ewan Dunbar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15775"
  },
  {
    "id": "arXiv:2210.15777",
    "title": "Reinforced Question Rewriting for Conversational Question Answering",
    "abstract": "Conversational Question Answering (CQA) aims to answer questions contained\nwithin dialogues, which are not easily interpretable without context.\nDeveloping a model to rewrite conversational questions into self-contained ones\nis an emerging solution in industry settings as it allows using existing\nsingle-turn QA systems to avoid training a CQA model from scratch. Previous\nwork trains rewriting models using human rewrites as supervision. However, such\nobjectives are disconnected with QA models and therefore more human-like\nrewrites do not guarantee better QA performance. In this paper we propose using\nQA feedback to supervise the rewriting model with reinforcement learning.\nExperiments show that our approach can effectively improve QA performance over\nbaselines for both extractive and retrieval QA. Furthermore, human evaluation\nshows that our method can generate more accurate and detailed rewrites when\ncompared to human annotations.",
    "descriptor": "\nComments: Accepted in EMNLP 2022 (Industry Track)\n",
    "authors": [
      "Zhiyu Chen",
      "Jie Zhao",
      "Anjie Fang",
      "Besnik Fetahu",
      "Oleg Rokhlenko",
      "Shervin Malmasi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15777"
  },
  {
    "id": "arXiv:2210.15779",
    "title": "Adapting Neural Models with Sequential Monte Carlo Dropout",
    "abstract": "The ability to adapt to changing environments and settings is essential for\nrobots acting in dynamic and unstructured environments or working alongside\nhumans with varied abilities or preferences. This work introduces an extremely\nsimple and effective approach to adapting neural models in response to changing\nsettings. We first train a standard network using dropout, which is analogous\nto learning an ensemble of predictive models or distribution over predictions.\nAt run-time, we use a particle filter to maintain a distribution over dropout\nmasks to adapt the neural model to changing settings in an online manner.\nExperimental results show improved performance in control problems requiring\nboth online and look-ahead prediction, and showcase the interpretability of the\ninferred masks in a human behaviour modelling task for drone teleoperation.",
    "descriptor": "\nComments: CoRL 2022\n",
    "authors": [
      "Pamela Carreno-Medrano",
      "Dana Kuli\u0107",
      "Michael Burke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15779"
  },
  {
    "id": "arXiv:2210.15784",
    "title": "Motion Primitives based Path Planning with Rapidly-exploring Random Tree",
    "abstract": "We present an approach that generates kinodynamically feasible paths for\nrobots using Rapidly-exploring Random Tree (RRT). We leverage motion primitives\nas a way to capture the dynamics of the robot and use these motion primitives\nto build branches of the tree with RRT. Since every branch is built using the\nrobot's motion primitives that doesn't lead to collision with obstacles, the\nresulting path is guaranteed to satisfy the robot's kinodynamic constraints and\nthus be feasible for navigation without any post-processing on the generated\ntrajectory. We demonstrate the effectiveness of our approach in simulated 2D\nenvironments using simple robot models with a variety of motion primitives.",
    "descriptor": "\nComments: 4 pages, 9 figures\n",
    "authors": [
      "Abhishek Paudel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15784"
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": "In this letter we present tables of convolutional codes with an optimum\nbidirectional distance profile (OBDP), defined as the minimum of the distance\nprofiles of the code and its corresponding \"reverse\" code. Such codes minimize\nthe average complexity of bidirectional sequential decoding algorithms. The\ncomputer search is accelerated by the facts that optimum distance profile (ODP)\ncodes of larger memory must have ODP codes of smaller memory as their\n\"prefixes\", and that OBDP codes can be obtained by \"concatenating\" ODP and\nreverse ODP codes of smaller memory.",
    "descriptor": "",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15787"
  },
  {
    "id": "arXiv:2210.15790",
    "title": "BI AVAN: Brain inspired Adversarial Visual Attention Network",
    "abstract": "Visual attention is a fundamental mechanism in the human brain, and it\ninspires the design of attention mechanisms in deep neural networks. However,\nmost of the visual attention studies adopted eye-tracking data rather than the\ndirect measurement of brain activity to characterize human visual attention. In\naddition, the adversarial relationship between the attention-related objects\nand attention-neglected background in the human visual system was not fully\nexploited. To bridge these gaps, we propose a novel brain-inspired adversarial\nvisual attention network (BI-AVAN) to characterize human visual attention\ndirectly from functional brain activity. Our BI-AVAN model imitates the biased\ncompetition process between attention-related/neglected objects to identify and\nlocate the visual objects in a movie frame the human brain focuses on in an\nunsupervised manner. We use independent eye-tracking data as ground truth for\nvalidation and experimental results show that our model achieves robust and\npromising results when inferring meaningful human visual attention and mapping\nthe relationship between brain activities and visual stimuli. Our BI-AVAN model\ncontributes to the emerging field of leveraging the brain's functional\narchitecture to inspire and guide the model design in artificial intelligence\n(AI), e.g., deep neural networks.",
    "descriptor": "",
    "authors": [
      "Heng Huang",
      "Lin Zhao",
      "Xintao Hu",
      "Haixing Dai",
      "Lu Zhang",
      "Dajiang Zhu",
      "Tianming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15790"
  },
  {
    "id": "arXiv:2210.15791",
    "title": "RISO: Combining Rigid Grippers with Soft Switchable Adhesives",
    "abstract": "Robot arms that assist humans should be able to pick up, move, and release\neveryday objects. Today's assistive robot arms use rigid grippers to pinch\nitems between fingers; while these rigid grippers are well suited for large and\nheavy objects, they often struggle to grasp small, numerous, or delicate items\n(such as foods). Soft grippers cover the opposite end of the spectrum; these\ngrippers use adhesives or change shape to wrap around small and irregular\nitems, but cannot exert the large forces needed to manipulate heavy objects. In\nthis paper we introduce RIgid-SOft (RISO) grippers that combine switchable soft\nadhesives with standard rigid mechanisms to enable a diverse range of robotic\ngrasping. We develop RISO grippers by leveraging a novel class of soft\nmaterials that change adhesion force in real-time through pneumatically\ncontrolled shape and rigidity tuning. By mounting these soft adhesives on the\nbottom of rigid fingers, we create a gripper that can interact with objects\nusing either purely rigid grasps (pinching the object) or purely soft grasps\n(adhering to the object). This increased capability requires additional\ndecision making, and we therefore formulate a shared control approach that\npartially automates the motion of the robot arm. In practice, this controller\naligns the RISO gripper while inferring which object the human wants to grasp\nand how the human wants to grasp that item. Our user study demonstrates that\nRISO grippers can pick up, move, and release household items from existing\ndatasets, and that the system performs grasps more successfully and efficiently\nwhen sharing control between the human and robot. See videos here:\nhttps://youtu.be/5uLUkBYcnwg",
    "descriptor": "",
    "authors": [
      "Shaunak A. Mehta",
      "Yeunhee Kim",
      "Joshua Hoegerman",
      "Michael D. Bartlett",
      "Dylan P. Losey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15791"
  },
  {
    "id": "arXiv:2210.15796",
    "title": "Layout Aware Inpainting for Automated Furniture Removal in Indoor Scenes",
    "abstract": "We address the problem of detecting and erasing furniture from a wide angle\nphotograph of a room. Inpainting large regions of an indoor scene often results\nin geometric inconsistencies of background elements within the inpaint mask. To\naddress this problem, we utilize perceptual information (e.g. instance\nsegmentation, and room layout) to produce a geometrically consistent empty\nversion of a room. We share important details to make this system viable, such\nas per-plane inpainting, automatic rectification, and texture refinement. We\nprovide detailed ablation along with qualitative examples, justifying our\ndesign choices. We show an application of our system by removing real furniture\nfrom a room and redecorating it with virtual furniture.",
    "descriptor": "\nComments: 6 pages, 10 figures\n",
    "authors": [
      "Prakhar Kulshreshtha",
      "Konstantinos-Nektarios Lianos",
      "Brian Pugh",
      "Salma Jiddi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15796"
  },
  {
    "id": "arXiv:2210.15804",
    "title": "Handwashing Action Detection System for an Autonomous Social Robot",
    "abstract": "Young children are at an increased risk of contracting contagious diseases\nsuch as COVID-19 due to improper hand hygiene. An autonomous social agent that\nobserves children while handwashing and encourages good hand washing practices\ncould provide an opportunity for handwashing behavior to become a habit. In\nthis article, we present a human action recognition system, which is part of\nthe vision system of a social robot platform, to assist children in developing\na correct handwashing technique. A modified convolution neural network (CNN)\narchitecture with Channel Spatial Attention Bilinear Pooling (CSAB) frame, with\na VGG-16 architecture as the backbone is trained and validated on an augmented\ndataset. The modified architecture generalizes well with an accuracy of 90% for\nthe WHO-prescribed handwashing steps even in an unseen environment. Our\nfindings indicate that the approach can recognize even subtle hand movements in\nthe video and can be used for gesture detection and classification in social\nrobotics.",
    "descriptor": "",
    "authors": [
      "Sreejith Sasidharan",
      "Pranav Prabha",
      "Devasena Pasupuleti",
      "Anand M Das",
      "Chaitanya Kapoor",
      "Gayathri Manikutty",
      "Praveen Pankajakshan",
      "Bhavani Rao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15804"
  },
  {
    "id": "arXiv:2210.15805",
    "title": "Towards Reliable Zero Shot Classification in Self-Supervised Models with  Conformal Prediction",
    "abstract": "Self-supervised models trained with a contrastive loss such as CLIP have\nshown to be very powerful in zero-shot classification settings. However, to be\nused as a zero-shot classifier these models require the user to provide new\ncaptions over a fixed set of labels at test time. In many settings, it is hard\nor impossible to know if a new query caption is compatible with the source\ncaptions used to train the model. We address these limitations by framing the\nzero-shot classification task as an outlier detection problem and develop a\nconformal prediction procedure to assess when a given test caption may be\nreliably used. On a real-world medical example, we show that our proposed\nconformal procedure improves the reliability of CLIP-style models in the\nzero-shot classification setting, and we provide an empirical analysis of the\nfactors that may affect its performance.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Bhawesh Kumar",
      "Anil Palepu",
      "Rudraksh Tuwani",
      "Andrew Beam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15805"
  },
  {
    "id": "arXiv:2210.15806",
    "title": "Decentralized Federated Learning via Non-Coherent Over-the-Air Consensus",
    "abstract": "This paper presents NCOTA-DGD, a Decentralized Gradient Descent (DGD)\nalgorithm that combines local gradient descent with Non-Coherent Over-The-Air\n(NCOTA) consensus at the receivers to solve distributed machine-learning\nproblems over wirelessly-connected systems. NCOTA-DGD leverages the waveform\nsuperposition properties of the wireless channels: it enables simultaneous\ntransmissions under half-duplex constraints, by mapping local signals to a\nmixture of preamble sequences, and consensus via non-coherent combining at the\nreceivers. NCOTA-DGD operates without channel state information and leverages\nthe average channel pathloss to mix signals, without explicit knowledge of the\nmixing weights (typically known in consensus-based optimization algorithms). It\nis shown both theoretically and numerically that, for smooth and\nstrongly-convex problems with fixed consensus and learning stepsizes, the\nupdates of NCOTA-DGD converge (in Euclidean distance) to the global optimum\nwith rate $\\mathcal O(K^{-1/4})$ for a target number of iterations $K$.\nNCOTA-DGD is evaluated numerically over a logistic regression problem, showing\nfaster convergence vis-\\`a-vis running time than implementations of the\nclassical DGD algorithm over digital and analog orthogonal channels.",
    "descriptor": "\nComments: Submitted to IEEE ICC 2023\n",
    "authors": [
      "Nicol\u00f2 Michelusi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15806"
  },
  {
    "id": "arXiv:2210.15809",
    "title": "Coverage-centric Coreset Selection for High Pruning Rates",
    "abstract": "One-shot coreset selection aims to select a subset of the training data,\ngiven a pruning rate, that can achieve high accuracy for models that are\nsubsequently trained only with that subset. State-of-the-art coreset selection\nmethods typically assign an importance score to each example and select the\nmost important examples to form a coreset. These methods perform well at low\npruning rates; but at high pruning rates, they have been found to suffer a\ncatastrophic accuracy drop, performing worse than even random coreset\nselection. In this paper, we explore the reasons for this accuracy drop both\ntheoretically and empirically. We extend previous theoretical results on the\nbound for model loss in terms of coverage provided by the coreset. Inspired by\ntheoretical results, we propose a novel coverage-based metric and, based on the\nmetric, find that coresets selected by importance-based coreset methods at high\npruning rates can be expected to perform poorly compared to random coresets\nbecause of worse data coverage. We then propose a new coreset selection method,\nCoverage-centric Coreset Selection (CCS), where we jointly consider overall\ndata coverage based on the proposed metric as well as importance of each\nexample. We evaluate CCS on four datasets and show that they achieve\nsignificantly better accuracy than state-of-the-art coreset selection methods\nas well as random sampling under high pruning rates, and comparable performance\nat low pruning rates. For example, CCS achieves 7.04% better accuracy than\nrandom sampling and at least 20.16% better than popular importance-based\nselection methods on CIFAR10 with a 90% pruning rate.",
    "descriptor": "",
    "authors": [
      "Haizhong Zheng",
      "Rui Liu",
      "Fan Lai",
      "Atul Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15809"
  },
  {
    "id": "arXiv:2210.15815",
    "title": "On Infinite-horizon System Level Synthesis Problems",
    "abstract": "System level synthesis is a promising approach that formulates structured\noptimal controller synthesis problems as convex problems. This work solves the\ndistributed linear-quadratic regulator problem under communication constraints\ndirectly in infinite-dimensional space, without the finite-impulse response\nrelaxation common in related work. Our method can also be used to construct\noptimal distributed Kalman filters with limited information exchange. We\ncombine the distributed Kalman filter with state-feedback control to perform\nlocalized LQG control with communication constraints. We provide agent-level\nimplementation details for the resulting output-feedback state-space\ncontroller.",
    "descriptor": "\nComments: To Appear in IEEE Conference on Decision and Control (CDC) 2022\n",
    "authors": [
      "Olle Kjellqvist",
      "Jing Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15815"
  },
  {
    "id": "arXiv:2210.15818",
    "title": "FUSSL: Fuzzy Uncertain Self Supervised Learning",
    "abstract": "Self supervised learning (SSL) has become a very successful technique to\nharness the power of unlabeled data, with no annotation effort. A number of\ndeveloped approaches are evolving with the goal of outperforming supervised\nalternatives, which have been relatively successful. One main issue in SSL is\nrobustness of the approaches under different settings. In this paper, for the\nfirst time, we recognize the fundamental limits of SSL coming from the use of a\nsingle-supervisory signal. To address this limitation, we leverage the power of\nuncertainty representation to devise a robust and general standard hierarchical\nlearning/training protocol for any SSL baseline, regardless of their\nassumptions and approaches. Essentially, using the information bottleneck\nprinciple, we decompose feature learning into a two-stage training procedure,\neach with a distinct supervision signal. This double supervision approach is\ncaptured in two key steps: 1) invariance enforcement to data augmentation, and\n2) fuzzy pseudo labeling (both hard and soft annotation). This simple, yet,\neffective protocol which enables cross-class/cluster feature learning, is\ninstantiated via an initial training of an ensemble of models through\ninvariance enforcement to data augmentation as first training phase, and then\nassigning fuzzy labels to the original samples for the second training phase.\nWe consider multiple alternative scenarios with double supervision and evaluate\nthe effectiveness of our approach on recent baselines, covering four different\nSSL paradigms, including geometrical, contrastive, non-contrastive, and\nhard/soft whitening (redundancy reduction) baselines. Extensive experiments\nunder multiple settings show that the proposed training protocol consistently\nimproves the performance of the former baselines, independent of their\nrespective underlying principles.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Salman Mohamadi",
      "Gianfranco Doretto",
      "Donald A. Adjeroh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15818"
  },
  {
    "id": "arXiv:2210.15823",
    "title": "Two novel families of multiscale staggered patch schemes efficiently  simulate large-scale, weakly damped, linear waves",
    "abstract": "Many multiscale wave systems exhibit macroscale emergent behaviour, for\nexample, the fluid dynamics of floods and tsunamis. Resolving a large range of\nspatial scales typically requires a prohibitively high computational cost. The\nsmall dissipation in wave systems poses a significant challenge to further\ndeveloping multiscale modelling methods in multiple dimensions. This article\ndevelops and evaluates two families of equation-free multiscale methods on\nnovel 2D staggered patch schemes, and demonstrates the power and utility of\nthese multiscale schemes for weakly damped linear waves. A detailed study of\nsensitivity to numerical roundoff errors establishes the robustness of\ndeveloped staggered patch schemes. Comprehensive eigenvalue analysis over a\nwide range of parameters establishes the stability, accuracy, and consistency\nof the multiscale schemes. Analysis of the computational complexity shows that\nthe measured compute times of the multiscale schemes may be 10^5 times smaller\nthan the compute time for the corresponding full-domain computation. This work\nprovides the essential foundation for efficient large-scale simulation of\nchallenging nonlinear multiscale waves.",
    "descriptor": "\nComments: 35 pages, 12 figures, and 6 tables\n",
    "authors": [
      "J. Divahar",
      "A. J. Roberts",
      "Trent W. Mattner",
      "J. E. Bunder",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.15823"
  },
  {
    "id": "arXiv:2210.15824",
    "title": "Improving the Modality Representation with Multi-View Contrastive  Learning for Multimodal Sentiment Analysis",
    "abstract": "Modality representation learning is an important problem for multimodal\nsentiment analysis (MSA), since the highly distinguishable representations can\ncontribute to improving the analysis effect. Previous works of MSA have usually\nfocused on multimodal fusion strategies, and the deep study of modal\nrepresentation learning was given less attention. Recently, contrastive\nlearning has been confirmed effective at endowing the learned representation\nwith stronger discriminate ability. Inspired by this, we explore the\nimprovement approaches of modality representation with contrastive learning in\nthis study. To this end, we devise a three-stages framework with multi-view\ncontrastive learning to refine representations for the specific objectives. At\nthe first stage, for the improvement of unimodal representations, we employ the\nsupervised contrastive learning to pull samples within the same class together\nwhile the other samples are pushed apart. At the second stage, a\nself-supervised contrastive learning is designed for the improvement of the\ndistilled unimodal representations after cross-modal interaction. At last, we\nleverage again the supervised contrastive learning to enhance the fused\nmultimodal representation. After all the contrast trainings, we next achieve\nthe classification task based on frozen representations. We conduct experiments\non three open datasets, and results show the advance of our model.",
    "descriptor": "",
    "authors": [
      "Peipei Liu",
      "Xin Zheng",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15824"
  },
  {
    "id": "arXiv:2210.15827",
    "title": "Federated Learning with Intermediate Representation Regularization",
    "abstract": "In contrast to centralized model training that involves data collection,\nfederated learning (FL) enables remote clients to collaboratively train a model\nwithout exposing their private data. However, model performance usually\ndegrades in FL due to the heterogeneous data generated by clients of diverse\ncharacteristics. One promising strategy to maintain good performance is by\nlimiting the local training from drifting far away from the global model.\nPrevious studies accomplish this by regularizing the distance between the\nrepresentations learned by the local and global models. However, they only\nconsider representations from the early layers of a model or the layer\npreceding the output layer. In this study, we introduce FedIntR, which provides\na more fine-grained regularization by integrating the representations of\nintermediate layers into the local training process. Specifically, FedIntR\ncomputes a regularization term that encourages the closeness between the\nintermediate layer representations of the local and global models.\nAdditionally, FedIntR automatically determines the contribution of each layer's\nrepresentation to the regularization term based on the similarity between local\nand global representations. We conduct extensive experiments on various\ndatasets to show that FedIntR can achieve equivalent or higher performance\ncompared to the state-of-the-art approaches.",
    "descriptor": "\nComments: Under Review IEEE BigComp 2023\n",
    "authors": [
      "Ye Lin Tun",
      "Chu Myaet Thwal",
      "Seong-Bae Park",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15827"
  },
  {
    "id": "arXiv:2210.15828",
    "title": "On the Role of Visual Context in Enriching Music Representations",
    "abstract": "Human perception and experience of music is highly context-dependent.\nContextual variability contributes to differences in how we interpret and\ninteract with music, challenging the design of robust models for information\nretrieval. Incorporating multimodal context from diverse sources provides a\npromising approach toward modeling this variability. Music presented in media\nsuch as movies and music videos provide rich multimodal context that modulates\nunderlying human experiences. However, such context modeling is underexplored,\nas it requires large amounts of multimodal data along with relevant\nannotations. Self-supervised learning can help address these challenges by\nautomatically extracting rich, high-level correspondences between different\nmodalities, hence alleviating the need for fine-grained annotations at scale.\nIn this study, we propose VCMR -- Video-Conditioned Music Representations, a\ncontrastive learning framework that learns music representations from audio and\nthe accompanying music videos. The contextual visual information enhances\nrepresentations of music audio, as evaluated on the downstream task of music\ntagging. Experimental results show that the proposed framework can contribute\nadditive robustness to audio representations and indicates to what extent\nmusical elements are affected or determined by visual context.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table\n",
    "authors": [
      "Kleanthis Avramidis",
      "Shanti Stewart",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15828"
  },
  {
    "id": "arXiv:2210.15831",
    "title": "Cost Control and Efficiency Optimization in Maintainability  Implementation of Wireless Sensor Networks based on Serverless Computing",
    "abstract": "Wireless sensor network (WSN) has been developed for decades and have\nperformed well in the performance, power consumption, and congestion control.\nHowever, the following problems have not been addressed, such as inaccurate\ncost estimation of device's lifecycle, highly-coupled engineering development,\nand low utilization of hardware and software resources during the life cycle of\nWSN. Therefore, we first propose the conceptual view of maintainability\nimplementation for WSN based on Serverless Computing. The maintainability\nimplementation refers to the ability to meet the WSN product to consume the\nminimum resources with a higher probability in configuration, trial production,\ndebugging, batch production, deployment, operation, and maintenance phases. And\nthen, we discuss that Serverless Computing can be realized at the software\nfunctional level of WSN to decouple the device operation and functional\ndevelopment, greatly improve the reuse of resources and exclude the hardware\ninterference. From the perspective of maintainability and cost control, the\nconcept of Serverless Computing can be used to build WSN platforms, which can\nsupport the functions of data collection and data management into functional\ndevelopment that may benefit from exploration through upfront expenditures,\nthereby significantly reducing design, manufacturing, and operational costs.\nFinally, based on existing technologies and smart city scenarios, the idea of a\nWSN platform for Serverless Computing is given with a case study.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Tiannan Gao",
      "Minxian Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.15831"
  },
  {
    "id": "arXiv:2210.15834",
    "title": "GM-TCNet: Gated Multi-scale Temporal Convolutional Network using Emotion  Causality for Speech Emotion Recognition",
    "abstract": "In human-computer interaction, Speech Emotion Recognition (SER) plays an\nessential role in understanding the user's intent and improving the interactive\nexperience. While similar sentimental speeches own diverse speaker\ncharacteristics but share common antecedents and consequences, an essential\nchallenge for SER is how to produce robust and discriminative representations\nthrough causality between speech emotions. In this paper, we propose a Gated\nMulti-scale Temporal Convolutional Network (GM-TCNet) to construct a novel\nemotional causality representation learning component with a multi-scale\nreceptive field. GM-TCNet deploys a novel emotional causality representation\nlearning component to capture the dynamics of emotion across the time domain,\nconstructed with dilated causal convolution layer and gating mechanism.\nBesides, it utilizes skip connection fusing high-level features from different\ngated convolution blocks to capture abundant and subtle emotion changes in\nhuman speech. GM-TCNet first uses a single type of feature, mel-frequency\ncepstral coefficients, as inputs and then passes them through the gated\ntemporal convolutional module to generate the high-level features. Finally, the\nfeatures are fed to the emotion classifier to accomplish the SER task. The\nexperimental results show that our model maintains the highest performance in\nmost cases compared to state-of-the-art techniques.",
    "descriptor": "\nComments: The source code is available at: this https URL\n",
    "authors": [
      "Jia-Xin Ye",
      "Xin-Cheng Wen",
      "Xuan-Ze Wang",
      "Yong Xu",
      "Yan Luo",
      "Chang-Li Wu",
      "Li-Yan Chen",
      "Kun-Hong Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15834"
  },
  {
    "id": "arXiv:2210.15835",
    "title": "DHR: Distributed Hybrid Rendering for Metaverse Experiences",
    "abstract": "Classically, rasterization techniques are performed for real-time rendering\nto meet the constraint of interactive frame rates. However, such techniques do\nnot produce realistic results as compared to ray tracing approaches. Hence,\nhybrid rendering has emerged to improve the graphics fidelity of rasterization\nwith ray tracing in real-time. We explore the approach of distributed rendering\nin incorporating real-time hybrid rendering into metaverse experiences for\nimmersive graphics. In standalone extended reality (XR) devices, such ray\ntracing-enabled graphics is only feasible through pure cloud-based remote\nrendering systems that rely on low-latency networks to transmit real-time\nray-traced data in response to interactive user input. Under high network\nlatency conditions, remote rendering might not be able to maintain interactive\nframe rates for the client, adversely affecting the user experience. We adopt\nhybrid rendering via a distributed rendering approach by integrating ray\ntracing on powerful remote hardware with raster-based rendering on user access\ndevices. With this hybrid approach, our technique can help standalone XR\ndevices achieve ray tracing-incorporated graphics and maintain interactive\nframe rates even under high-latency conditions.",
    "descriptor": "",
    "authors": [
      "Yu Wei Tan",
      "Alden Tan",
      "Nicholas Nge",
      "Anand Bhojan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15835"
  },
  {
    "id": "arXiv:2210.15836",
    "title": "Domain Generalization through the Lens of Angular Invariance",
    "abstract": "Domain generalization (DG) aims at generalizing a classifier trained on\nmultiple source domains to an unseen target domain with domain shift. A common\npervasive theme in existing DG literature is domain-invariant representation\nlearning with various invariance assumptions. However, prior works restrict\nthemselves to a radical assumption for realworld challenges: If a mapping\ninduced by a deep neural network (DNN) could align the source domains well,\nthen such a mapping aligns a target domain as well. In this paper, we simply\ntake DNNs as feature extractors to relax the requirement of distribution\nalignment. Specifically, we put forward a novel angular invariance and the\naccompanied norm shift assumption. Based on the proposed term of invariance, we\npropose a novel deep DG method called Angular Invariance Domain Generalization\nNetwork (AIDGN). The optimization objective of AIDGN is developed with a\nvon-Mises Fisher (vMF) mixture model. Extensive experiments on multiple DG\nbenchmark datasets validate the effectiveness of the proposed AIDGN method.",
    "descriptor": "\nComments: 15 pages, 3 figures, published as a conference paper in IJCAI2022 (modified a few mistakes)\n",
    "authors": [
      "Yujie Jin",
      "Xu Chu",
      "Yasha Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15836"
  },
  {
    "id": "arXiv:2210.15837",
    "title": "Risk-Aware Bid Optimization for Online Display Advertisement",
    "abstract": "This research focuses on the bid optimization problem in the real-time\nbidding setting for online display advertisements, where an advertiser, or the\nadvertiser's agent, has access to the features of the website visitor and the\ntype of ad slots, to decide the optimal bid prices given a predetermined total\nadvertisement budget. We propose a risk-aware data-driven bid optimization\nmodel that maximizes the expected profit for the advertiser by exploiting\nhistorical data to design upfront a bidding policy, mapping the type of\nadvertisement opportunity to a bid price, and accounting for the risk of\nviolating the budget constraint during a given period of time. After employing\na Lagrangian relaxation, we derive a parametrized closed-form expression for\nthe optimal bidding strategy. Using a real-world dataset, we demonstrate that\nour risk-averse method can effectively control the risk of overspending the\nbudget while achieving a competitive level of profit compared with the\nrisk-neutral model and a state-of-the-art data-driven risk-aware bidding\napproach.",
    "descriptor": "\nComments: Accepted for CIKM '22\n",
    "authors": [
      "Rui Fan",
      "Erick Delage"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15837"
  },
  {
    "id": "arXiv:2210.15839",
    "title": "Optimal Inverter-Based Resources Placement in Low-Inertia Power Systems",
    "abstract": "An increase in the integration of Inverter Based Resources (IBRs) to the\nelectric grid, will lead to a corresponding decrease in the amount of connected\nsynchronous generators, resulting in a decline in the available rotational\ninertia system-wide. This can lead to pronounced frequency deviations when\nthere are disturbances and faults in the grid. This decline in available\nrotational inertia can be compensated for by fast acting IBRs participating in\nfrequency response services, by rapidly injecting into or removing power from\nthe grid. Currently, there are still relative small number of sizable IBRs in\nthe grid. Therefore, the placement of the IBRs in the system, as well as the\ninverter configuration type and controller, will have a material impact on the\nfrequency response of the grid. In this work, we present an optimal placement\nalgorithm that maximizes the benefits of utilizing IBRs in providing frequency\nresponse services. That is, we minimize the overall system frequency deviation\nwhile using a minimal amount of electric power injection from the IBRs. The\nproposed algorithm uses the resistance distance to place the IBRs at nodes that\nare central to the rest of the nodes in the network thus minimizing the\ndistance of power flow. The proposed greedy algorithm achieves a near optimal\nperformance and relies on the supermodularity of the resistance distances. We\nvalidate the performance of the placement algorithm on three IEEE test systems\nof varying sizes, by comparing its performance to an exhaustive search\nalgorithm. We further evaluate the performance of the placed IBRs on an IEEE\ntest system, to determine their impact on frequency stability. The IBRs are\nconfigured in a grid-forming mode and equipped with a model predictive control\n(MPC)-based inverter power control.",
    "descriptor": "",
    "authors": [
      "Atinuke Ademola-Idowu",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15839"
  },
  {
    "id": "arXiv:2210.15842",
    "title": "Leveraging Label Correlations in a Multi-label Setting: A Case Study in  Emotion",
    "abstract": "Detecting emotions expressed in text has become critical to a range of\nfields. In this work, we investigate ways to exploit label correlations in\nmulti-label emotion recognition models to improve emotion detection. First, we\ndevelop two modeling approaches to the problem in order to capture word\nassociations of the emotion words themselves, by either including the emotions\nin the input, or by leveraging Masked Language Modeling (MLM). Second, we\nintegrate pairwise constraints of emotion representations as regularization\nterms alongside the classification loss of the models. We split these terms\ninto two categories, local and global. The former dynamically change based on\nthe gold labels, while the latter remain static during training. We demonstrate\nstate-of-the-art performance across Spanish, English, and Arabic in SemEval\n2018 Task 1 E-c using monolingual BERT-based models. On top of better\nperformance, we also demonstrate improved robustness. Code is available at\nhttps://github.com/gchochla/Demux-MEmo.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Georgios Chochlakis",
      "Gireesh Mahajan",
      "Sabyasachee Baruah",
      "Keith Burghardt",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15842"
  },
  {
    "id": "arXiv:2210.15843",
    "title": "Bi-Directional Iterative Prompt-Tuning for Event Argument Extraction",
    "abstract": "Recently, prompt-tuning has attracted growing interests in event argument\nextraction (EAE). However, the existing prompt-tuning methods have not achieved\nsatisfactory performance due to the lack of consideration of entity\ninformation. In this paper, we propose a bi-directional iterative prompt-tuning\nmethod for EAE, where the EAE task is treated as a cloze-style task to take\nfull advantage of entity information and pre-trained language models (PLMs).\nFurthermore, our method explores event argument interactions by introducing the\nargument roles of contextual entities into prompt construction. Since template\nand verbalizer are two crucial components in a cloze-style prompt, we propose\nto utilize the role label semantic knowledge to construct a semantic verbalizer\nand design three kinds of templates for the EAE task. Experiments on the ACE\n2005 English dataset with standard and low-resource settings show that the\nproposed method significantly outperforms the peer state-of-the-art methods.\nOur code is available at https://github.com/HustMinsLab/BIP.",
    "descriptor": "\nComments: To be accept by EMNLP 2022 as a full paper\n",
    "authors": [
      "Lu Dai",
      "Bang Wang",
      "Wei Xiang",
      "Yijun Mo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15843"
  },
  {
    "id": "arXiv:2210.15845",
    "title": "I Know What You Are Searching For: Code Snippet Recommendation from  Stack Overflow Posts",
    "abstract": "Stack Overflow has been heavily used by software developers to seek\nprogramming-related information. More and more developers use Community\nQuestion and Answer forums, such as Stack Overflow, to search for code examples\nof how to accomplish a certain coding task. This is often considered to be more\nefficient than working from source documentation, tutorials or full worked\nexamples. However, due to the complexity of these online Question and Answer\nforums and the very large volume of information they contain, developers can be\noverwhelmed by the sheer volume of available information. This makes it hard to\nfind and/or even be aware of the most relevant code examples to meet their\nneeds. To alleviate this issue, in this work we present a query-driven code\nrecommendation tool, named Que2Code, that identifies the best code snippets for\na user query from Stack Overflow posts. Our approach has two main stages: (i)\nsemantically-equivalent question retrieval and (ii) best code snippet\nrecommendation. To evaluate the performance of our proposed model, we conduct a\nlarge scale experiment to evaluate the effectiveness of the\nsemantically-equivalent question retrieval task and best code snippet\nrecommendation task separately on Python and Java datasets in Stack Overflow.\nWe also perform a human study to measure how real-world developers perceive the\nresults generated by our model. Both the automatic and human evaluation results\ndemonstrate the promising performance of our model, and we have released our\ncode and data to assist other researchers.",
    "descriptor": "",
    "authors": [
      "Zhipeng Gao",
      "Xin Xia",
      "David Lo",
      "John Grundy",
      "Xindong Zhang",
      "Zhenchang Xing"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15845"
  },
  {
    "id": "arXiv:2210.15846",
    "title": "Technical Q&A Site Answer Recommendation via Question Boosting",
    "abstract": "Software developers have heavily used online question and answer platforms to\nseek help to solve their technical problems. However, a major problem with\nthese technical Q&A sites is \"answer hungriness\" i.e., a large number of\nquestions remain unanswered or unresolved, and users have to wait for a long\ntime or painstakingly go through the provided answers with various levels of\nquality. To alleviate this time-consuming problem, we propose a novel DeepAns\nneural network-based approach to identify the most relevant answer among a set\nof answer candidates. Our approach follows a three-stage process: question\nboosting, label establishment, and answer recommendation. Given a post, we\nfirst generate a clarifying question as a way of question boosting. We\nautomatically establish the positive, neutral+, neutral- and negative training\nsamples via label establishment. When it comes to answer recommendation, we\nsort answer candidates by the matching scores calculated by our neural\nnetwork-based model. To evaluate the performance of our proposed model, we\nconducted a large scale evaluation on four datasets, collected from the real\nworld technical Q&A sites (i.e., Ask Ubuntu, Super User, Stack Overflow Python\nand Stack Overflow Java). Our experimental results show that our approach\nsignificantly outperforms several state-of-the-art baselines in automatic\nevaluation. We also conducted a user study with 50 solved/unanswered/unresolved\nquestions. The user study results demonstrate that our approach is effective in\nsolving the answer hungry problem by recommending the most relevant answers\nfrom historical archives.",
    "descriptor": "",
    "authors": [
      "Zhipeng Gao",
      "Xin Xia",
      "David Lo",
      "John Grundy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15846"
  },
  {
    "id": "arXiv:2210.15847",
    "title": "Distributed Optimal Control of Graph Symmetric Systems via Graph Filters",
    "abstract": "Designing distributed optimal controllers subject to communication\nconstraints is a difficult problem unless structural assumptions are imposed on\nthe underlying dynamics and information exchange structure, e.g., sparsity,\ndelay, or spatial invariance. In this paper, we borrow ideas from graph signal\nprocessing and define and analyze a class of Graph Symmetric Systems (GSSs),\nwhich are systems that are symmetric with respect to an underlying graph\ntopology. We show that for linear quadratic problems subject to dynamics\ndefined by a GSS, the optimal centralized controller is given by a novel class\nof graph filters with transfer function valued filter taps and can be\nimplemented via distributed message passing. We then propose several methods\nfor approximating the optimal centralized graph filter by a distributed\ncontroller only requiring communication with a small subset of neighboring\nsubsystems. We further provide stability and suboptimality guarantees for the\nresulting distributed controllers. Finally, we empirically demonstrate that our\napproach allows for a principled tradeoff between communication cost and\nperformance while guaranteeing stability. Our results can be viewed as a first\nstep towards bridging the fields of distributed optimal control and graph\nsignal processing.",
    "descriptor": "",
    "authors": [
      "Fengjun Yang",
      "Fernando Gama",
      "Somayeh Sojoudi",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15847"
  },
  {
    "id": "arXiv:2210.15849",
    "title": "Local-global speaker representation for target speaker extraction",
    "abstract": "Target speaker extraction is to extract the target speaker's voice from a\nmixture of signals according to the given enrollment utterance. The target\nspeaker's enrollment utterance is also called as anchor speech. The effective\nutilization of anchor speech is crucial for speaker extraction. In this study,\nwe propose a new system to exploit speaker information from anchor speech\nfully. Unlike models that use only local or global features of the anchor, the\nproposed method extracts speaker information on global and local levels and\nfeeds the features into a speech separation network. Our approach benefits from\nthe complementary advantages of both global and local features, and the\nperformance of speaker extraction is improved. We verified the feasibility of\nthis local-global representation (LGR) method using multiple speaker extraction\nmodels. Systematic experiments were conducted on the open-source dataset\nLibri-2talker, and the results showed that the proposed method significantly\noutperformed the baseline models.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Shulin He",
      "Wei Rao",
      "Kanghao Zhang",
      "Yukai Ju",
      "Yang Yang",
      "Xueliang Zhang",
      "Yannan Wang",
      "Shidong Shang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15849"
  },
  {
    "id": "arXiv:2210.15850",
    "title": "Federated Learning based Energy Demand Prediction with Clustered  Aggregation",
    "abstract": "To reduce negative environmental impacts, power stations and energy grids\nneed to optimize the resources required for power production. Thus, predicting\nthe energy consumption of clients is becoming an important part of every energy\nmanagement system. Energy usage information collected by the clients' smart\nhomes can be used to train a deep neural network to predict the future energy\ndemand. Collecting data from a large number of distributed clients for\ncentralized model training is expensive in terms of communication resources. To\ntake advantage of distributed data in edge systems, centralized training can be\nreplaced by federated learning where each client only needs to upload model\nupdates produced by training on its local data. These model updates are\naggregated into a single global model by the server. But since different\nclients can have different attributes, model updates can have diverse weights\nand as a result, it can take a long time for the aggregated global model to\nconverge. To speed up the convergence process, we can apply clustering to group\nclients based on their properties and aggregate model updates from the same\ncluster together to produce a cluster specific global model. In this paper, we\npropose a recurrent neural network based energy demand predictor, trained with\nfederated learning on clustered clients to take advantage of distributed data\nand speed up the convergence process.",
    "descriptor": "\nComments: Accepted by BigComp 2021\n",
    "authors": [
      "Ye Lin Tun",
      "Kyi Thar",
      "Chu Myaet Thwal",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15850"
  },
  {
    "id": "arXiv:2210.15851",
    "title": "Improving Zero-Shot Multilingual Translation with Universal  Representations and Cross-Mappings",
    "abstract": "The many-to-many multilingual neural machine translation can translate\nbetween language pairs unseen during training, i.e., zero-shot translation.\nImproving zero-shot translation requires the model to learn universal\nrepresentations and cross-mapping relationships to transfer the knowledge\nlearned on the supervised directions to the zero-shot directions. In this work,\nwe propose the state mover's distance based on the optimal theory to model the\ndifference of the representations output by the encoder. Then, we bridge the\ngap between the semantic-equivalent representations of different languages at\nthe token level by minimizing the proposed distance to learn universal\nrepresentations. Besides, we propose an agreement-based training scheme, which\ncan help the model make consistent predictions based on the semantic-equivalent\nsentences to learn universal cross-mapping relationships for all translation\ndirections. The experimental results on diverse multilingual datasets show that\nour method can improve consistently compared with the baseline system and other\ncontrast methods. The analysis proves that our method can better align the\nsemantic space and improve the prediction consistency.",
    "descriptor": "\nComments: EMNLP 2022 Long Findings\n",
    "authors": [
      "Shuhao Gu",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15851"
  },
  {
    "id": "arXiv:2210.15852",
    "title": "A Game Benchmark for Real-Time Human-Swarm Control",
    "abstract": "We present a game benchmark for testing human-swarm control algorithms and\ninterfaces in a real-time, high-cadence scenario. Our benchmark consists of a\nswarm vs. swarm game in a virtual ROS environment in which the goal of the game\nis to capture all agents from the opposing swarm; the game's high-cadence is a\nresult of the capture rules, which cause agent team sizes to fluctuate rapidly.\nThese rules require players to consider both the number of agents currently at\ntheir disposal and the behavior of their opponent's swarm when they plan\nactions. We demonstrate our game benchmark with a default human-swarm control\nsystem that enables a player to interact with their swarm through a high-level\ntouchscreen interface. The touchscreen interface transforms player gestures\ninto swarm control commands via a low-level decentralized ergodic control\nframework. We compare our default human-swarm control system to a\nflocking-based control system, and discuss traits that are crucial for swarm\ncontrol algorithms and interfaces operating in real-time, high-cadence\nscenarios like our game benchmark. Our game benchmark code is available on\nGithub; more information can be found at\nhttps://sites.google.com/view/swarm-game-benchmark.",
    "descriptor": "\nComments: 8 pages, IEEE Conference on Automation Science and Engineering (CASE), 2022\n",
    "authors": [
      "Joel Meyer",
      "Allison Pinosky",
      "Thomas Trzpit",
      "Ed Colgate",
      "Todd D. Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15852"
  },
  {
    "id": "arXiv:2210.15853",
    "title": "Speech Enhancement with Intelligent Neural Homomorphic Synthesis",
    "abstract": "Most neural network speech enhancement models ignore speech production\nmathematical models by directly mapping Fourier transform spectrums or\nwaveforms. In this work, we propose a neural source filter network for speech\nenhancement. Specifically, we use homomorphic signal processing and cepstral\nanalysis to obtain noisy speech's excitation and vocal tract. Unlike\ntraditional signal processing, we use an attentive recurrent network (ARN)\nmodel predicted ratio mask to replace the liftering separation function. Then\ntwo convolutional attentive recurrent network (CARN) networks are used to\npredict the excitation and vocal tract of clean speech, respectively. The\nsystem's output is synthesized from the estimated excitation and vocal.\nExperiments prove that our proposed method performs better, with SI-SNR\nimproving by 1.363dB compared to FullSubNet.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Shulin He",
      "Wei Rao",
      "Jinjiang Liu",
      "Jun Chen",
      "Yukai Ju",
      "Xueliang Zhang",
      "Yannan Wang",
      "Shidong Shang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15853"
  },
  {
    "id": "arXiv:2210.15854",
    "title": "Computational bifurcation analysis of hyperelastic thin shells",
    "abstract": "The inflation of hyperelastic thin shells is an important and highly\nnonlinear problem that arises in multiple engineering applications involving\nsevere kinematic and constitutive nonlinearities in addition to various\ninstabilities. We present an isogeometric approach to compute the inflation of\nhyperelastic thin shells, following the Kirchhoff-Love hypothesis and\nassociated large deformation. Both the geometry and the deformation field are\ndiscretized using Catmull-Clark subdivision bases which provide the\nC1-continuous finite element framework required for the Kirchhoff-Love shell\nformulation. To follow the complex nonlinear response of hyperelastic thin\nshells, the inflation is simulated incrementally, and each incremental step is\nsolved via the Newton-Raphson method enriched with arc-length control.\nEigenvalue analysis of the linear system after each incremental step allows for\ninducing bifurcation to a lower energy mode in case stability of the\nequilibrium is lost. The proposed method is first validated using benchmarks,\nand then applied to engineering applications, where we demonstrate the ability\nto simulate large deformation and associated complex instabilities.",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Zhaowei Liu",
      "Andrew McBride",
      "Abhishek Ghosh",
      "Luca Heltai",
      "Weicheng Huang",
      "Tiantang Yu",
      "Paul Steinmann",
      "Prashant Saxena"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15854"
  },
  {
    "id": "arXiv:2210.15855",
    "title": "Optimal Policy for Task Migration to UAV in Discrete-Time Systems with  Firm Deadlines",
    "abstract": "The recent drastic increase in mobile data traffic has pushed the mobile edge\ncomputing systems to the limit of their capacity. Fortunately, the task\nmigration service provided by unmanned aerial vehicle (UAV) has brought a\npromising solution to the mentioned problem. In designing UAV offloading\nschemes, key factors include the number of tasks waiting and their\ncorresponding deadlines. An appropriate system cost is used as objective\nfunction to be minimized comprising two parts. First, an offloading cost which\ncan be interpreted as the cost of using computational resources at the UAV.\nSecond, a penalty cost due to potential task deadline expirations. In order to\nminimize the expected average cost over a time horizon, we formulate a dynamic\nprogramming (DP) equation aiming at describing properties of a candidate\noptimal offloading policy. The ensuing DP equation is revealed to suffer from\nthe Curse of Dimensionality. In order to resolve this complication, we analyze\nthree important properties of the optimal policy. First, our findings uncover\nthe relation between the original infinite state space model and a reduced\nfinite one. Second, we prove that the optimal task offloading decision\nassociated with a state can be inferred from that of other related states.\nFinally, we provide numerical results to show the influence of different\nparameters on the system performance as well as verify the presented results.",
    "descriptor": "",
    "authors": [
      "Khai Doan",
      "Wesley Araujo",
      "Evangelos Kranakis",
      "Ioannis Lambadaris",
      "Yannis Viniotis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15855"
  },
  {
    "id": "arXiv:2210.15858",
    "title": "Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit  Representation",
    "abstract": "In this work, we present a dense tracking and mapping system named\nVox-Fusion, which seamlessly fuses neural implicit representations with\ntraditional volumetric fusion methods. Our approach is inspired by the recently\ndeveloped implicit mapping and positioning system and further extends the idea\nso that it can be freely applied to practical scenarios. Specifically, we\nleverage a voxel-based neural implicit surface representation to encode and\noptimize the scene inside each voxel. Furthermore, we adopt an octree-based\nstructure to divide the scene and support dynamic expansion, enabling our\nsystem to track and map arbitrary scenes without knowing the environment like\nin previous works. Moreover, we proposed a high-performance multi-process\nframework to speed up the method, thus supporting some applications that\nrequire real-time performance. The evaluation results show that our methods can\nachieve better accuracy and completeness than previous methods. We also show\nthat our Vox-Fusion can be used in augmented reality and virtual reality\napplications. Our source code is publicly available at\nhttps://github.com/zju3dv/Vox-Fusion.",
    "descriptor": "",
    "authors": [
      "Xingrui Yang",
      "Hai Li",
      "Hongjia Zhai",
      "Yuhang Ming",
      "Yuqian Liu",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15858"
  },
  {
    "id": "arXiv:2210.15859",
    "title": "You can't pick your neighbors, or can you? When and how to rely on  retrieval in the $k$NN-LM",
    "abstract": "Retrieval-enhanced language models (LMs), which condition their predictions\non text retrieved from large external datastores, have recently shown\nsignificant perplexity improvements compared to standard LMs. One such\napproach, the $k$NN-LM, interpolates any existing LM's predictions with the\noutput of a $k$-nearest neighbors model and requires no additional training. In\nthis paper, we explore the importance of lexical and semantic matching in the\ncontext of items retrieved by $k$NN-LM. We find two trends: (1) the presence of\nlarge overlapping $n$-grams between the datastore and evaluation set plays an\nimportant factor in strong performance, even when the datastore is derived from\nthe training data; and (2) the $k$NN-LM is most beneficial when retrieved items\nhave high semantic similarity with the query. Based on our analysis, we define\na new formulation of the $k$NN-LM that uses retrieval quality to assign the\ninterpolation coefficient. We empirically measure the effectiveness of our\napproach on two English language modeling datasets, Wikitext-103 and PG-19. Our\nre-formulation of the $k$NN-LM is beneficial in both cases, and leads to nearly\n4% improvement in perplexity on the Wikitext-103 test set.",
    "descriptor": "",
    "authors": [
      "Andrew Drozdov",
      "Shufan Wang",
      "Razieh Rahimi",
      "Andrew McCallum",
      "Hamed Zamani",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15859"
  },
  {
    "id": "arXiv:2210.15861",
    "title": "Domain Adaptation of Machine Translation with Crowdworkers",
    "abstract": "Although a machine translation model trained with a large in-domain parallel\ncorpus achieves remarkable results, it still works poorly when no in-domain\ndata are available. This situation restricts the applicability of machine\ntranslation when the target domain's data are limited. However, there is great\ndemand for high-quality domain-specific machine translation models for many\ndomains. We propose a framework that efficiently and effectively collects\nparallel sentences in a target domain from the web with the help of\ncrowdworkers. With the collected parallel data, we can quickly adapt a machine\ntranslation model to the target domain. Our experiments show that the proposed\nmethod can collect target-domain parallel data over a few days at a reasonable\ncost. We tested it with five domains, and the domain-adapted model improved the\nBLEU scores to +19.7 by an average of +7.8 points compared to a general-purpose\ntranslation model.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Industry Track\n",
    "authors": [
      "Makoto Morishita",
      "Jun Suzuki",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15861"
  },
  {
    "id": "arXiv:2210.15865",
    "title": "Completely Heterogeneous Federated Learning",
    "abstract": "Federated learning (FL) faces three major difficulties: cross-domain,\nheterogeneous models, and non-i.i.d. labels scenarios. Existing FL methods fail\nto handle the above three constraints at the same time, and the level of\nprivacy protection needs to be lowered (e.g., the model architecture and data\ncategory distribution can be shared). In this work, we propose the challenging\n\"completely heterogeneous\" scenario in FL, which refers to that each client\nwill not expose any private information including feature space, model\narchitecture, and label distribution. We then devise an FL framework based on\nparameter decoupling and data-free knowledge distillation to solve the problem.\nExperiments show that our proposed method achieves high performance in\ncompletely heterogeneous scenarios where other approaches fail.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chang Liu",
      "Yuwen Yang",
      "Xun Cai",
      "Yue Ding",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.15865"
  },
  {
    "id": "arXiv:2210.15868",
    "title": "Residual Adapters for Few-Shot Text-to-Speech Speaker Adaptation",
    "abstract": "Adapting a neural text-to-speech (TTS) model to a target speaker typically\ninvolves fine-tuning most if not all of the parameters of a pretrained\nmulti-speaker backbone model. However, serving hundreds of fine-tuned neural\nTTS models is expensive as each of them requires significant footprint and\nseparate computational resources (e.g., accelerators, memory). To scale speaker\nadapted neural TTS voices to hundreds of speakers while preserving the\nnaturalness and speaker similarity, this paper proposes a parameter-efficient\nfew-shot speaker adaptation, where the backbone model is augmented with\ntrainable lightweight modules called residual adapters. This architecture\nallows the backbone model to be shared across different target speakers.\nExperimental results show that the proposed approach can achieve competitive\nnaturalness and speaker similarity compared to the full fine-tuning approaches,\nwhile requiring only $\\sim$0.1% of the backbone model parameters for each\nspeaker.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Nobuyuki Morioka",
      "Heiga Zen",
      "Nanxin Chen",
      "Yu Zhang",
      "Yifan Ding"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15868"
  },
  {
    "id": "arXiv:2210.15870",
    "title": "\"It's Not Just Hate'': A Multi-Dimensional Perspective on Detecting  Harmful Speech Online",
    "abstract": "Well-annotated data is a prerequisite for good Natural Language Processing\nmodels. Too often, though, annotation decisions are governed by optimizing time\nor annotator agreement. We make a case for nuanced efforts in an\ninterdisciplinary setting for annotating offensive online speech. Detecting\noffensive content is rapidly becoming one of the most important real-world NLP\ntasks. However, most datasets use a single binary label, e.g., for hate or\nincivility, even though each concept is multi-faceted. This modeling choice\nseverely limits nuanced insights, but also performance. We show that a more\nfine-grained multi-label approach to predicting incivility and hateful or\nintolerant content addresses both conceptual and performance issues. We release\na novel dataset of over 40,000 tweets about immigration from the US and UK,\nannotated with six labels for different aspects of incivility and intolerance.\nOur dataset not only allows for a more nuanced understanding of harmful speech\nonline, models trained on it also outperform or match performance on benchmark\ndatasets.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Federico Bianchi",
      "Stefanie Anja Hills",
      "Patricia Rossini",
      "Dirk Hovy",
      "Rebekah Tromble",
      "Nava Tintarev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15870"
  },
  {
    "id": "arXiv:2210.15871",
    "title": "VLT: Vision-Language Transformer and Query Generation for Referring  Segmentation",
    "abstract": "We propose a Vision-Language Transformer (VLT) framework for referring\nsegmentation to facilitate deep interactions among multi-modal information and\nenhance the holistic understanding to vision-language features. There are\ndifferent ways to understand the dynamic emphasis of a language expression,\nespecially when interacting with the image. However, the learned queries in\nexisting transformer works are fixed after training, which cannot cope with the\nrandomness and huge diversity of the language expressions. To address this\nissue, we propose a Query Generation Module, which dynamically produces\nmultiple sets of input-specific queries to represent the diverse comprehensions\nof language expression. To find the best among these diverse comprehensions, so\nas to generate a better mask, we propose a Query Balance Module to selectively\nfuse the corresponding responses of the set of queries. Furthermore, to enhance\nthe model's ability in dealing with diverse language expressions, we consider\ninter-sample learning to explicitly endow the model with knowledge of\nunderstanding different language expressions to the same object. We introduce\nmasked contrastive learning to narrow down the features of different\nexpressions for the same target object while distinguishing the features of\ndifferent objects. The proposed approach is lightweight and achieves new\nstate-of-the-art referring segmentation results consistently on five datasets.",
    "descriptor": "\nComments: TPAMI\n",
    "authors": [
      "Henghui Ding",
      "Chang Liu",
      "Suchen Wang",
      "Xudong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15871"
  },
  {
    "id": "arXiv:2210.15872",
    "title": "Exploring Spatial-Temporal Features for Deepfake Detection and  Localization",
    "abstract": "With the continuous research on Deepfake forensics, recent studies have\nattempted to provide the fine-grained localization of forgeries, in addition to\nthe coarse classification at the video-level. However, the detection and\nlocalization performance of existing Deepfake forensic methods still have\nplenty of room for further improvement. In this work, we propose a\nSpatial-Temporal Deepfake Detection and Localization (ST-DDL) network that\nsimultaneously explores spatial and temporal features for detecting and\nlocalizing forged regions. Specifically, we design a new Anchor-Mesh Motion\n(AMM) algorithm to extract temporal (motion) features by modeling the precise\ngeometric movements of the facial micro-expression. Compared with traditional\nmotion extraction methods (e.g., optical flow) designed to simulate\nlarge-moving objects, our proposed AMM could better capture the\nsmall-displacement facial features. The temporal features and the spatial\nfeatures are then fused in a Fusion Attention (FA) module based on a\nTransformer architecture for the eventual Deepfake forensic tasks. The\nsuperiority of our ST-DDL network is verified by experimental comparisons with\nseveral state-of-the-art competitors, in terms of both video- and pixel-level\ndetection and localization performance. Furthermore, to impel the future\ndevelopment of Deepfake forensics, we build a public forgery dataset consisting\nof 6000 videos, with many new features such as using widely-used commercial\nsoftware (e.g., After Effects) for the production, providing online social\nnetworks transmitted versions, and splicing multi-source videos. The source\ncode and dataset are available at https://github.com/HighwayWu/ST-DDL.",
    "descriptor": "",
    "authors": [
      "Wu Haiwei",
      "Zhou Jiantao",
      "Zhang Shile",
      "Tian Jinyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15872"
  },
  {
    "id": "arXiv:2210.15875",
    "title": "Dynamic Event-Triggered Discrete-Time Linear Time-Varying System with  Privacy-Preservation",
    "abstract": "This paper focuses on discrete-time wireless sensor networks with\nprivacy-preservation. In practical applications, information exchange between\nsensors is subject to attacks. For the information leakage caused by the attack\nduring the information transmission process, privacy-preservation is introduced\nfor system states. To make communication resources more effectively utilized, a\ndynamic event-triggered set-membership estimator is designed. Moreover, the\nprivacy of the system is analyzed to ensure the security of the real data. As a\nresult, the set-membership estimator with differential privacy is analyzed\nusing recursive convex optimization. Then the steady-state performance of the\nsystem is studied. Finally, one example is presented to demonstrate the\nfeasibility of the proposed distributed filter containing privacy-preserving\nanalysis.",
    "descriptor": "",
    "authors": [
      "Xuefeng Yang",
      "Li Liu",
      "Wenju Zhou",
      "Jing Shi",
      "Yinggang Zhang",
      "Xin Hu",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15875"
  },
  {
    "id": "arXiv:2210.15878",
    "title": "Facial Action Unit Detection and Intensity Estimation from  Self-supervised Representation",
    "abstract": "As a fine-grained and local expression behavior measurement, facial action\nunit (FAU) analysis (e.g., detection and intensity estimation) has been\ndocumented for its time-consuming, labor-intensive, and error-prone annotation.\nThus a long-standing challenge of FAU analysis arises from the data scarcity of\nmanual annotations, limiting the generalization ability of trained models to a\nlarge extent. Amounts of previous works have made efforts to alleviate this\nissue via semi/weakly supervised methods and extra auxiliary information.\nHowever, these methods still require domain knowledge and have not yet avoided\nthe high dependency on data annotation. This paper introduces a robust facial\nrepresentation model MAE-Face for AU analysis. Using masked autoencoding as the\nself-supervised pre-training approach, MAE-Face first learns a high-capacity\nmodel from a feasible collection of face images without additional data\nannotations. Then after being fine-tuned on AU datasets, MAE-Face exhibits\nconvincing performance for both AU detection and AU intensity estimation,\nachieving a new state-of-the-art on nearly all the evaluation results. Further\ninvestigation shows that MAE-Face achieves decent performance even when\nfine-tuned on only 1\\% of the AU training set, strongly proving its robustness\nand generalization performance.",
    "descriptor": "",
    "authors": [
      "Bowen Ma",
      "Rudong An",
      "Wei Zhang",
      "Yu Ding",
      "Zeng Zhao",
      "Rongsheng Zhang",
      "Tangjie Lv",
      "Changjie Fan",
      "Zhipeng Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15878"
  },
  {
    "id": "arXiv:2210.15879",
    "title": "Complex Handwriting Trajectory Recovery: Evaluation Metrics and  Algorithm",
    "abstract": "Many important tasks such as forensic signature verification, calligraphy\nsynthesis, etc, rely on handwriting trajectory recovery of which, however, even\nan appropriate evaluation metric is still missing. Indeed, existing metrics\nonly focus on the writing orders but overlook the fidelity of glyphs. Taking\nboth facets into account, we come up with two new metrics, the adaptive\nintersection on union (AIoU) which eliminates the influence of various stroke\nwidths, and the length-independent dynamic time warping (LDTW) which solves the\ntrajectory-point alignment problem. After that, we then propose a novel\nhandwriting trajectory recovery model named Parsing-and-tracing ENcoder-decoder\nNetwork (PEN-Net), in particular for characters with both complex glyph and\nlong trajectory, which was believed very challenging. In the PEN-Net, a\ncarefully designed double-stream parsing encoder parses the glyph structure,\nand a global tracing decoder overcomes the memory difficulty of long trajectory\nprediction. Our experiments demonstrate that the two new metrics AIoU and LDTW\ntogether can truly assess the quality of handwriting trajectory recovery and\nthe proposed PEN-Net exhibits satisfactory performance in various complex-glyph\nlanguages including Chinese, Japanese and Indic.",
    "descriptor": "\nComments: Accepted by Asian Conference on Computer Vision 2022(ACCV2022)\n",
    "authors": [
      "Zhounan Chen",
      "Daihui Yang",
      "Jinglin Liang",
      "Xinwu Liu",
      "Yuyi Wang",
      "Zhenghua Peng",
      "Shuangping Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15879"
  },
  {
    "id": "arXiv:2210.15882",
    "title": "Can Current Explainability Help Provide References in Clinical Notes to  Support Humans Annotate Medical Codes?",
    "abstract": "The medical codes prediction problem from clinical notes has received\nsubstantial interest in the NLP community, and several recent studies have\nshown the state-of-the-art (SOTA) code prediction results of full-fledged deep\nlearning-based methods. However, most previous SOTA works based on deep\nlearning are still in early stages in terms of providing textual references and\nexplanations of the predicted codes, despite the fact that this level of\nexplainability of the prediction outcomes is critical to gaining trust from\nprofessional medical coders. This raises the important question of how well\ncurrent explainability methods apply to advanced neural network models such as\ntransformers to predict correct codes and present references in clinical notes\nthat support code prediction. First, we present an explainable Read, Attend,\nand Code (xRAC) framework and assess two approaches, attention score-based\nxRAC-ATTN and model-agnostic knowledge-distillation-based xRAC-KD, through\nsimplified but thorough human-grounded evaluations with SOTA transformer-based\nmodel, RAC. We find that the supporting evidence text highlighted by xRAC-ATTN\nis of higher quality than xRAC-KD whereas xRAC-KD has potential advantages in\nproduction deployment scenarios. More importantly, we show for the first time\nthat, given the current state of explainability methodologies, using the SOTA\nmedical codes prediction system still requires the expertise and competencies\nof professional coders, even though its prediction accuracy is superior to that\nof human coders. This, we believe, is a very meaningful step toward developing\nexplainable and accurate machine learning systems for fully autonomous medical\ncode prediction from clinical notes.",
    "descriptor": "\nComments: To appear in Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (Louhi 2022), Virtual, December 7, 2022\n",
    "authors": [
      "Byung-Hak Kim",
      "Zhongfen Deng",
      "Philip S. Yu",
      "Varun Ganapathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15882"
  },
  {
    "id": "arXiv:2210.15889",
    "title": "Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on  Neuro-Symbolic Computing",
    "abstract": "Neural-symbolic computing (NeSy), which pursues the integration of the\nsymbolic and statistical paradigms of cognition, has been an active research\narea of Artificial Intelligence (AI) for many years. As NeSy shows promise of\nreconciling the advantages of reasoning and interpretability of symbolic\nrepresentation and robust learning in neural networks, it may serve as a\ncatalyst for the next generation of AI. In the present paper, we provide a\nsystematic overview of the important and recent developments of research on\nNeSy AI. Firstly, we introduce study history and background concepts of this\narea. Afterward, we categorize recent approaches along several main\ncharacteristics that underline this research paradigm, including\nneural-symbolic interrelation, neural architecture, knowledge representation,\nand functionality. Then, we briefly discuss the successful application of\nmodern NeSy approaches in several domains. Finally, we identify the open\nproblems together with potential future research directions.",
    "descriptor": "\nComments: Ongoing project, under revision\n",
    "authors": [
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15889"
  },
  {
    "id": "arXiv:2210.15893",
    "title": "When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad  Responses into Good Labels",
    "abstract": "Deployed dialogue agents have the potential to integrate human feedback to\ncontinuously improve themselves. However, humans may not always provide\nexplicit signals when the chatbot makes mistakes during interactions. In this\nwork, we propose Juicer, a framework to make use of both binary and free-form\ntextual human feedback. It works by: (i) extending sparse binary feedback by\ntraining a satisfaction classifier to label the unlabeled data; and (ii)\ntraining a reply corrector to map the bad replies to good ones. We find that\naugmenting training with model-corrected replies improves the final dialogue\nmodel, and we can further improve performance by using both positive and\nnegative replies through the recently proposed Director model.",
    "descriptor": "",
    "authors": [
      "Weiyan Shi",
      "Emily Dinan",
      "Kurt Shuster",
      "Jason Weston",
      "Jing Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15893"
  },
  {
    "id": "arXiv:2210.15898",
    "title": "Toward Equation of Motion for Deep Neural Networks: Continuous-time  Gradient Descent and Discretization Error Analysis",
    "abstract": "We derive and solve an ``Equation of Motion'' (EoM) for deep neural networks\n(DNNs), a differential equation that precisely describes the discrete learning\ndynamics of DNNs. Differential equations are continuous but have played a\nprominent role even in the study of discrete optimization (gradient descent\n(GD) algorithms). However, there still exist gaps between differential\nequations and the actual learning dynamics of DNNs due to discretization error.\nIn this paper, we start from gradient flow (GF) and derive a counter term that\ncancels the discretization error between GF and GD. As a result, we obtain EoM,\na continuous differential equation that precisely describes the discrete\nlearning dynamics of GD. We also derive discretization error to show to what\nextent EoM is precise. In addition, we apply EoM to two specific cases: scale-\nand translation-invariant layers. EoM highlights differences between\ncontinuous-time and discrete-time GD, indicating the importance of the counter\nterm for a better description of the discrete learning dynamics of GD. Our\nexperimental results support our theoretical findings.",
    "descriptor": "\nComments: NeurIPS 2022; 4 minutes video (SlidesLive) this https URL&s=38054b07-9651-417b-bef2-f2712b37c50f\n",
    "authors": [
      "Taiki Miyagawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15898"
  },
  {
    "id": "arXiv:2210.15900",
    "title": "An adaptive low-rank splitting approach for the extended  Fisher--Kolmogorov equation",
    "abstract": "The extended Fisher--Kolmogorov (EFK) equation has been used to describe some\nphenomena in physical, material and biology systems. In this paper, we propose\na full-rank splitting scheme and a rank-adaptive splitting approach for this\nequation. We first use a finite difference method to approximate the space\nderivatives. Then, the resulting semi-discrete system is split into two stiff\nlinear parts and a nonstiff nonlinear part. This leads to our full-rank\nsplitting scheme. The convergence and the maximum principle of the proposed\nscheme are proved rigorously. Based on the frame of the full-rank splitting\nscheme, a rank-adaptive splitting approach for obtaining a low-rank solution of\nthe EFK equation. Numerical examples show that our methods are robust and\naccurate. They can also preserve energy dissipation and the discrete maximum\nprinciple.",
    "descriptor": "\nComments: 17pages, 4 figures, 4 tables\n",
    "authors": [
      "Yong-Liang Zhao",
      "Xian-Ming Gu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15900"
  },
  {
    "id": "arXiv:2210.15901",
    "title": "Mitigating Health Disparities in EHR via Deconfounder",
    "abstract": "Health disparities, or inequalities between different patient demographics,\nare becoming crucial in medical decision-making, especially in Electronic\nHealth Record (EHR) predictive modeling. To ensure the fairness of sensitive\nattributes, conventional studies mainly adopt calibration or re-weighting\nmethods to balance the performance on among different demographic groups.\nHowever, we argue that these methods have some limitations. First, these\nmethods usually mean a trade-off between the model's performance and fairness.\nSecond, many methods completely attribute unfairness to the data collection\nprocess, which lacks substantial evidence. In this paper, we provide an\nempirical study to discover the possibility of using deconfounder to address\nthe disparity issue in healthcare. Our study can be summarized in two parts.\nThe first part is a pilot study demonstrating the exacerbation of disparity\nwhen unobserved confounders exist. The second part proposed a novel framework,\nParity Medical Deconfounder (PriMeD), to deal with the disparity issue in\nhealthcare datasets. Inspired by the deconfounder theory, PriMeD adopts a\nConditional Variational Autoencoder (CVAE) to learn latent factors (substitute\nconfounders) for observational data, and extensive experiments are provided to\nshow its effectiveness.",
    "descriptor": "",
    "authors": [
      "Zheng Liu",
      "Xiaohan Li",
      "Philip Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.15901"
  },
  {
    "id": "arXiv:2210.15904",
    "title": "Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud  Analysis",
    "abstract": "Recently, great progress has been made in 3D deep learning with the emergence\nof deep neural networks specifically designed for 3D point clouds. These\nnetworks are often trained from scratch or from pre-trained models learned\npurely from point cloud data. Inspired by the success of deep learning in the\nimage domain, we devise a novel pre-training technique for better model\ninitialization by utilizing the multi-view rendering of the 3D data. Our\npre-training is self-supervised by a local pixel/point level correspondence\nloss computed from perspective projection and a global image/point cloud level\nloss based on knowledge distillation, thus effectively improving upon popular\npoint cloud networks, including PointNet, DGCNN and SR-UNet. These improved\nmodels outperform existing state-of-the-art methods on various datasets and\ndownstream tasks. We also analyze the benefits of synthetic and real data for\npre-training, and observe that pre-training on synthetic data is also useful\nfor high-level downstream tasks. Code and pre-trained models are available at\nhttps://github.com/VinAIResearch/selfsup_pcd.",
    "descriptor": "\nComments: ACCV 2022 paper. 14 pages of content, 4 pages of references, 6 pages of supplementary material\n",
    "authors": [
      "Bach Tran",
      "Binh-Son Hua",
      "Anh Tuan Tran",
      "Minh Hoai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15904"
  },
  {
    "id": "arXiv:2210.15906",
    "title": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal  Specification and Reward Learning from Human Preferences",
    "abstract": "Generating complex behaviors from goals specified by non-expert users is a\ncrucial aspect of intelligent agents. Interactive reward learning from\ntrajectory comparisons is one way to allow non-expert users to convey complex\nobjectives by expressing preferences over short clips of agent behaviors. Even\nthough this method can encode complex tacit knowledge present in the underlying\ntasks, it implicitly assumes that the human is unable to provide rich-form\nfeedback other than binary preference labels, leading to extremely high\nfeedback complexity and poor user experience. While providing a detailed\nsymbolic specification of the objectives might be tempting, it is not always\nfeasible even for an expert user. However, in most cases, humans are aware of\nhow the agent should change its behavior along meaningful axes to fulfill the\nunderlying purpose, even if they are not able to fully specify task objectives\nsymbolically. Using this as motivation, we introduce the notion of Relative\nBehavioral Attributes, which acts as a middle ground, between exact goal\nspecification and reward learning purely from preference labels, by enabling\nthe users to tweak the agent's behavior through nameable concepts (e.g.,\nincreasing the softness of the movement of a two-legged \"sneaky\" agent). We\npropose two different parametric methods that can potentially encode any kind\nof behavioral attributes from ordered behavior clips. We demonstrate the\neffectiveness of our methods on 4 tasks with 9 different behavioral attributes\nand show that once the attributes are learned, end users can effortlessly\nproduce desirable agent behaviors, by providing feedback just around 10 times.\nThe feedback complexity of our approach is over 10 times less than the\nlearning-from-human-preferences baseline and this demonstrates that our\napproach is readily applicable in real-world applications.",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Karthik Valmeekam",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15906"
  },
  {
    "id": "arXiv:2210.15907",
    "title": "Credit-Based Congestion Pricing: Equilibrium Properties and Optimal  Scheme Design",
    "abstract": "Credit-based congestion pricing (CBCP) has emerged as a mechanism to\nalleviate the social inequity concerns of road congestion pricing - a promising\nstrategy for traffic congestion mitigation - by providing low-income users with\ntravel credits to offset some of their toll payments. While CBCP offers immense\npotential for addressing inequity issues that hamper the practical viability of\ncongestion pricing, the deployment of CBCP in practice is nascent, and the\npotential efficacy and optimal design of CBCP schemes have yet to be\nformalized. In this work, we study the design of CBCP schemes to achieve\nparticular societal objectives and investigate their influence on traffic\npatterns when routing heterogeneous users with different values of time (VoTs)\nin a multi-lane highway with an express lane. We introduce a new non-atomic\ncongestion game model of a mixed-economy, wherein eligible users receive travel\ncredits while the remaining ineligible users pay out-of-pocket to use the\nexpress lane. In this setting, we investigate the effect of CBCP schemes on\ntraffic patterns by characterizing the properties (i.e., existence, comparative\nstatics) of the corresponding Nash equilibria and, in the setting when eligible\nusers have time-invariant VoTs, develop a convex program to compute these\nequilibria. We further present a bi-level optimization framework to design\noptimal CBCP schemes to achieve a central planner's societal objectives.\nFinally, we conduct numerical experiments based on a case study of the San\nMateo 101 Express Lanes Project, one of the first North American CBCP pilots.\nOur results demonstrate the potential of CBCP to enable low-income travelers to\navail of the travel time savings provided by congestion pricing on express\nlanes while having comparatively low impacts on the travel costs of other road\nusers.",
    "descriptor": "",
    "authors": [
      "Devansh Jalota",
      "Jessica Lazarus",
      "Alexandre Bayen",
      "Marco Pavone"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15907"
  },
  {
    "id": "arXiv:2210.15908",
    "title": "Long-HOT: A Modular Hierarchical Approach for Long-Horizon Object  Transport",
    "abstract": "We address key challenges in long-horizon embodied exploration and navigation\nby proposing a new object transport task and a novel modular framework for\ntemporally extended navigation. Our first contribution is the design of a novel\nLong-HOT environment focused on deep exploration and long-horizon planning\nwhere the agent is required to efficiently find and pick up target objects to\nbe carried and dropped at a goal location, with load constraints and optional\naccess to a container if it finds one. Further, we propose a modular\nhierarchical transport policy (HTP) that builds a topological graph of the\nscene to perform exploration with the help of weighted frontiers. Our\nhierarchical approach uses a combination of motion planning algorithms to reach\npoint goals within explored locations and object navigation policies for moving\ntowards semantic targets at unknown locations. Experiments on both our proposed\nHabitat transport task and on MultiOn benchmarks show that our method\nsignificantly outperforms baselines and prior works. Further, we validate the\neffectiveness of our modular approach for long-horizon transport by\ndemonstrating meaningful generalization to much harder transport scenes with\ntraining only on simpler versions of the task.",
    "descriptor": "",
    "authors": [
      "Sriram Narayanan",
      "Dinesh Jayaraman",
      "Manmohan Chandraker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15908"
  },
  {
    "id": "arXiv:2210.15909",
    "title": "Subsidiary Prototype Alignment for Universal Domain Adaptation",
    "abstract": "Universal Domain Adaptation (UniDA) deals with the problem of knowledge\ntransfer between two datasets with domain-shift as well as category-shift. The\ngoal is to categorize unlabeled target samples, either into one of the \"known\"\ncategories or into a single \"unknown\" category. A major problem in UniDA is\nnegative transfer, i.e. misalignment of \"known\" and \"unknown\" classes. To this\nend, we first uncover an intriguing tradeoff between negative-transfer-risk and\ndomain-invariance exhibited at different layers of a deep network. It turns out\nwe can strike a balance between these two metrics at a mid-level layer. Towards\ndesigning an effective framework based on this insight, we draw motivation from\nBag-of-visual-Words (BoW). Word-prototypes in a BoW-like representation of a\nmid-level layer would represent lower-level visual primitives that are likely\nto be unaffected by the category-shift in the high-level features. We develop\nmodifications that encourage learning of word-prototypes followed by\nword-histogram based classification. Following this, subsidiary prototype-space\nalignment (SPA) can be seen as a closed-set alignment problem, thereby avoiding\nnegative transfer. We realize this with a novel word-histogram-related pretext\ntask to enable closed-set SPA, operating in conjunction with goal task UniDA.\nWe demonstrate the efficacy of our approach on top of existing UniDA\ntechniques, yielding state-of-the-art performance across three standard UniDA\nand Open-Set DA object recognition benchmarks.",
    "descriptor": "\nComments: NeurIPS 2022. Project page: this https URL\n",
    "authors": [
      "Jogendra Nath Kundu",
      "Suvaansh Bhambri",
      "Akshay Kulkarni",
      "Hiran Sarkar",
      "Varun Jampani",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15909"
  },
  {
    "id": "arXiv:2210.15911",
    "title": "Joint Semantic Transfer Network for IoT Intrusion Detection",
    "abstract": "In this paper, we propose a Joint Semantic Transfer Network (JSTN) towards\neffective intrusion detection for large-scale scarcely labelled IoT domain. As\na multi-source heterogeneous domain adaptation (MS-HDA) method, the JSTN\nintegrates a knowledge rich network intrusion (NI) domain and another\nsmall-scale IoT intrusion (II) domain as source domains, and preserves\nintrinsic semantic properties to assist target II domain intrusion detection.\nThe JSTN jointly transfers the following three semantics to learn a\ndomain-invariant and discriminative feature representation. The scenario\nsemantic endows source NI and II domain with characteristics from each other to\nease the knowledge transfer process via a confused domain discriminator and\ncategorical distribution knowledge preservation. It also reduces the\nsource-target discrepancy to make the shared feature space domain-invariant.\nMeanwhile, the weighted implicit semantic transfer boosts discriminability via\na fine-grained knowledge preservation, which transfers the source categorical\ndistribution to the target domain. The source-target divergence guides the\nimportance weighting during knowledge preservation to reflect the degree of\nknowledge learning. Additionally, the hierarchical explicit semantic alignment\nperforms centroid-level and representative-level alignment with the help of a\ngeometric similarity-aware pseudo-label refiner, which exploits the value of\nunlabelled target II domain and explicitly aligns feature representations from\na global and local perspective in a concentrated manner. Comprehensive\nexperiments on various tasks verify the superiority of the JSTN against\nstate-of-the-art comparing methods, on average a 10.3% of accuracy boost is\nachieved. The statistical soundness of each constituting component and the\ncomputational efficiency are also verified.",
    "descriptor": "\nComments: Accepted by IEEE Internet of Things Journal\n",
    "authors": [
      "Jiashu Wu",
      "Yang Wang",
      "Binhui Xie",
      "Shuang Li",
      "Hao Dai",
      "Kejiang Ye",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15911"
  },
  {
    "id": "arXiv:2210.15912",
    "title": "Decontamination of the scientific literature",
    "abstract": "Research misconduct and frauds pollute the scientific literature. Honest\nerrors and malevolent data fabrication, image manipulation, journal hijacking,\nand plagiarism passed peer review unnoticed. Problematic papers deceive\nreaders, authors citing them, and AI-powered literature-based discovery.\nFlagship publishers accepted hundreds flawed papers despite claiming to enforce\npeer review. This application ambitions to decontaminate the scientific\nliterature using curative and preventive actions.",
    "descriptor": "\nComments: Application to the 2022 IUF Chair Programme\n",
    "authors": [
      "Guillaume Cabanac"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15912"
  },
  {
    "id": "arXiv:2210.15913",
    "title": "GeoGCN: Geometric Dual-domain Graph Convolution Network for Point Cloud  Denoising",
    "abstract": "We propose GeoGCN, a novel geometric dual-domain graph convolution network\nfor point cloud denoising (PCD). Beyond the traditional wisdom of PCD, to fully\nexploit the geometric information of point clouds, we define two kinds of\nsurface normals, one is called Real Normal (RN), and the other is Virtual\nNormal (VN). RN preserves the local details of noisy point clouds while VN\navoids the global shape shrinkage during denoising. GeoGCN is a new PCD\nparadigm that, 1) first regresses point positions by spatialbased GCN with the\nhelp of VNs, 2) then estimates initial RNs by performing Principal Component\nAnalysis on the regressed points, and 3) finally regresses fine RNs by\nnormalbased GCN. Unlike existing PCD methods, GeoGCN not only exploits two\nkinds of geometry expertise (i.e., RN and VN) but also benefits from training\ndata. Experiments validate that GeoGCN outperforms SOTAs in terms of both\nnoise-robustness and local-and-global feature preservation.",
    "descriptor": "",
    "authors": [
      "Zhaowei Chen",
      "Peng Li",
      "Zeyong Wei",
      "Honghua Chen",
      "Haoran Xie",
      "Mingqiang Wei",
      "Fu Lee Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15913"
  },
  {
    "id": "arXiv:2210.15917",
    "title": "Low-Complexity Channel Estimation for Massive MIMO Systems with  Decentralized Baseband Processing",
    "abstract": "The traditional centralized baseband processing architecture is faced with\nthe bottlenecks of high computation complexity and excessive fronthaul\ncommunication, especially when the number of antennas at the base station (BS)\nis large. To cope with these two challenges, the decentralized baseband\nprocessing (DPB) architecture has been proposed, where the BS antennas are\npartitioned into multiple clusters, and each is connected to a local baseband\nunit (BBU). In this paper, we are interested in the low-complexity distributed\nchannel estimation (CE) method under such DBP architecture, which is rarely\nstudied in the literature. The aim is to devise distributed CE algorithms that\ncan perform as well as the centralized scheme but with a small inter-BBU\ncommunication cost. Specifically, based on the low-complexity diagonal minimum\nmean square error channel estimator, we propose two distributed CE algorithms,\nnamely the aggregate-then-estimate algorithm and the estimate-then-aggregate\nalgorithm. In contrast to the existing distributed CE algorithm which requires\niterative information exchanges among the nodes, our algorithms only require\none roundtrip communication among BBUs. Extensive experiment results are\npresented to demonstrate the advantages of the proposed distributed CE\nalgorithms in terms of estimation accuracy, inter-BBU communication cost, and\ncomputation complexity.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Yanqing Xu",
      "Bo Wang",
      "Enbin Song",
      "Qingjiang Shi",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15917"
  },
  {
    "id": "arXiv:2210.15923",
    "title": "DELFI: Deep Mixture Models for Long-term Air Quality Forecasting in the  Delhi National Capital Region",
    "abstract": "The identification and control of human factors in climate change is a\nrapidly growing concern and robust, real-time air-quality monitoring and\nforecasting plays a critical role in allowing effective policy formulation and\nimplementation. This paper presents DELFI, a novel deep learning-based mixture\nmodel to make effective long-term predictions of Particulate Matter (PM) 2.5\nconcentrations. A key novelty in DELFI is its multi-scale approach to the\nforecasting problem. The observation that point predictions are more suitable\nin the short-term and probabilistic predictions in the long-term allows\naccurate predictions to be made as much as 24 hours in advance. DELFI\nincorporates meteorological data as well as pollutant-based features to ensure\na robust model that is divided into two parts: (i) a stack of three Long\nShort-Term Memory (LSTM) networks that perform differential modelling of the\nsame window of past data, and (ii) a fully-connected layer enabling attention\nto each of the components. Experimental evaluation based on deployment of 13\nstations in the Delhi National Capital Region (Delhi-NCR) in India establishes\nthat DELFI offers far superior predictions especially in the long-term as\ncompared to even non-parametric baselines. The Delhi-NCR recorded the 3rd\nhighest PM levels amongst 39 mega-cities across the world during 2011-2015 and\nDELFI's performance establishes it as a potential tool for effective long-term\nforecasting of PM levels to enable public health management and environment\nprotection.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Naishadh Parmar",
      "Raunak Shah",
      "Tushar Goswamy",
      "Vatsalya Tandon",
      "Ravi Sahu",
      "Ronak Sutaria",
      "Purushottam Kar",
      "Sachchida Nand Tripathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15923"
  },
  {
    "id": "arXiv:2210.15926",
    "title": "Comparison of Stereo Matching Algorithms for the Development of  Disparity Map",
    "abstract": "Stereo Matching is one of the classical problems in computer vision for the\nextraction of 3D information but still controversial for accuracy and\nprocessing costs. The use of matching techniques and cost functions is crucial\nin the development of the disparity map. This paper presents a comparative\nstudy of six different stereo matching algorithms including Block Matching\n(BM), Block Matching with Dynamic Programming (BMDP), Belief Propagation (BP),\nGradient Feature Matching (GF), Histogram of Oriented Gradient (HOG), and the\nproposed method. Also three cost functions namely Mean Squared Error (MSE), Sum\nof Absolute Differences (SAD), Normalized Cross-Correlation (NCC) were used and\ncompared. The stereo images used in this study were from the Middlebury Stereo\nDatasets provided with perfect and imperfect calibrations. Results show that\nthe selection of matching function is quite important and also depends on the\nimages properties. Results showed that the BP algorithm in most cases provided\nbetter results getting accuracies over 95%.",
    "descriptor": "",
    "authors": [
      "Hamid Fsian",
      "Vahid Mohammadi",
      "Pierre Gouton",
      "Saeid Minaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15926"
  },
  {
    "id": "arXiv:2210.15928",
    "title": "Coincidence analysis of Stackelberg and Nash equilibria in three-player  leader-follower security games",
    "abstract": "There has been significant recent interest in leader-follower security games,\nwhere the leader dominates the decision process with the Stackelberg\nequilibrium (SE) strategy. However, such a leader-follower scheme may become\ninvalid in practice due to subjective or objective factors, and then the Nash\nequilibrium (NE) strategy may be an alternative option. In this case, the\nleader may face a dilemma of choosing an SE strategy or an NE strategy. In this\npaper, we focus on a unified three-player leader-follower security game and\nstudy the coincidence between SE and NE. We first explore a necessary and\nsufficient condition for the case that each SE is an NE, which can be further\npresented concisely when the SE is unique. This condition not only provides\naccess to seek a satisfactory SE strategy but also makes a criterion to verify\nan obtained SE strategy. Then we provide another appropriate condition for the\ncase that at least one SE is an NE. Moreover, since the coincidence condition\nmay not always be satisfied, we describe the closeness between SE and NE, and\ngive an upper bound of their deviation. Finally, we show the applicability of\nthe obtained theoretical results in several practical security cases, including\nthe secure transmission problem and the cybersecurity defense.",
    "descriptor": "",
    "authors": [
      "Gehui Xu",
      "Guanpu Chen",
      "Zhaoyang Cheng",
      "Yiguang Hong",
      "Hongsheng Qi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.15928"
  },
  {
    "id": "arXiv:2210.15929",
    "title": "OhMG: Zero-shot Open-vocabulary Human Motion Generation",
    "abstract": "Generating motion in line with text has attracted increasing attention\nnowadays. However, open-vocabulary human motion generation still remains\ntouchless and undergoes the lack of diverse labeled data. The good news is\nthat, recent studies of large multi-model foundation models (e.g., CLIP) have\ndemonstrated superior performance on few/zero-shot image-text alignment,\nlargely reducing the need for manually labeled data. In this paper, we take\nadvantage of CLIP for open-vocabulary 3D human motion generation in a zero-shot\nmanner. Specifically, our model is composed of two stages, i.e., text2pose and\npose2motion. For text2pose, to address the difficulty of optimization with\ndirect supervision from CLIP, we propose to carve the versatile CLIP model into\na slimmer but more specific model for aligning 3D poses and texts, via a novel\npipeline distillation strategy. Optimizing with the distilled 3D pose-text\nmodel, we manage to concretize the text-pose knowledge of CLIP into a text2pose\ngenerator effectively and efficiently. As for pose2motion, drawing inspiration\nfrom the advanced language model, we pretrain a transformer-based motion model,\nwhich makes up for the lack of motion dynamics of CLIP. After that, by\nformulating the generated poses from the text2pose stage as prompts, the motion\ngenerator can generate motions referring to the poses in a controllable and\nflexible manner. Our method is validated against advanced baselines and obtains\nsharp improvements. The code will be released here.",
    "descriptor": "",
    "authors": [
      "Junfan Lin",
      "Jianlong Chang",
      "Lingbo Liu",
      "Guanbin Li",
      "Liang Lin",
      "Qi Tian",
      "Chang-wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15929"
  },
  {
    "id": "arXiv:2210.15930",
    "title": "Lyapunov-based Nonlinear Model Predictive Control for Attitude  Trajectory Tracking of Unmanned Aerial Vehicles",
    "abstract": "This paper presents a new Lyapunov-based nonlinear model predictive\ncontroller (LNMPC) for the attitude control problem of unmanned aerial vehicles\n(UAVs), which is essential for their functioning operation. The controller is\ndesigned based on a quadratic cost function integrating UAV dynamics and system\nconstraints. An additional contraction constraint is then introduced to ensure\nclosed-loop system stability. That constraint is fulfilled via a Lyapunov\nfunction derived from a sliding mode controller (SMC). The feasibility and\nstability of the LNMPC are finally proved. Simulation and comparison results\nshow that the proposed controller guarantees the system stability and\noutperforms other state-of-the-art nonlinear controllers such as the\nbackstepping controller (BSC) and SMC. In addition, the proposed controller can\nbe integrated into an existing UAV model in the Gazebo simulator to perform\nsoftware-in-the-loop tests. The results show that the LNMPC is better than the\nbuilt-in PID controller of the UAV, which confirms the validity and\napplicability of our proposed approach.",
    "descriptor": "",
    "authors": [
      "Duy Nam Bui",
      "Thi Thanh Van Nguyen",
      "Manh Duong Phung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15930"
  },
  {
    "id": "arXiv:2210.15933",
    "title": "PSFormer: Point Transformer for 3D Salient Object Detection",
    "abstract": "We propose PSFormer, an effective point transformer model for 3D salient\nobject detection. PSFormer is an encoder-decoder network that takes full\nadvantage of transformers to model the contextual information in both\nmulti-scale point- and scene-wise manners. In the encoder, we develop a Point\nContext Transformer (PCT) module to capture region contextual features at the\npoint level; PCT contains two different transformers to excavate the\nrelationship among points. In the decoder, we develop a Scene Context\nTransformer (SCT) module to learn context representations at the scene level;\nSCT contains both Upsampling-and-Transformer blocks and Multi-context\nAggregation units to integrate the global semantic and multi-level features\nfrom the encoder into the global scene context. Experiments show clear\nimprovements of PSFormer over its competitors and validate that PSFormer is\nmore robust to challenging cases such as small objects, multiple objects, and\nobjects with complex structures.",
    "descriptor": "",
    "authors": [
      "Baian Chen",
      "Lipeng Gu",
      "Xin Zhuang",
      "Yiyang Shen",
      "Weiming Wang",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15933"
  },
  {
    "id": "arXiv:2210.15936",
    "title": "A comprehensive study on self-supervised distillation for speaker  representation learning",
    "abstract": "In real application scenarios, it is often challenging to obtain a large\namount of labeled data for speaker representation learning due to speaker\nprivacy concerns. Self-supervised learning with no labels has become a more and\nmore promising way to solve it. Compared with contrastive learning,\nself-distilled approaches use only positive samples in the loss function and\nthus are more attractive. In this paper, we present a comprehensive study on\nself-distilled self-supervised speaker representation learning, especially on\ncritical data augmentation. Our proposed strategy of audio perturbation\naugmentation has pushed the performance of the speaker representation to a new\nlimit. The experimental results show that our model can achieve a new SoTA on\nVoxceleb1 speaker verification evaluation benchmark ( i.e., equal error rate\n(EER) 2.505%, 2.473%, and 4.791% for trial Vox1-O, Vox1-E and Vox1-H ,\nrespectively), discarding any speaker labels in the training phase.",
    "descriptor": "\nComments: Accepted by SLT2022\n",
    "authors": [
      "Zhengyang Chen",
      "Yao Qian",
      "Bing Han",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15936"
  },
  {
    "id": "arXiv:2210.15937",
    "title": "On the Use of Modality-Specific Large-Scale Pre-Trained Encoders for  Multimodal Sentiment Analysis",
    "abstract": "This paper investigates the effectiveness and implementation of\nmodality-specific large-scale pre-trained encoders for multimodal sentiment\nanalysis~(MSA). Although the effectiveness of pre-trained encoders in various\nfields has been reported, conventional MSA methods employ them for only\nlinguistic modality, and their application has not been investigated. This\npaper compares the features yielded by large-scale pre-trained encoders with\nconventional heuristic features. One each of the largest pre-trained encoders\npublicly available for each modality are used; CLIP-ViT, WavLM, and BERT for\nvisual, acoustic, and linguistic modalities, respectively. Experiments on two\ndatasets reveal that methods with domain-specific pre-trained encoders attain\nbetter performance than those with conventional features in both unimodal and\nmultimodal scenarios. We also find it better to use the outputs of the\nintermediate layers of the encoders than those of the output layer. The codes\nare available at https://github.com/ando-hub/MSA_Pretrain.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Atsushi Ando",
      "Ryo Masumura",
      "Akihiko Takashima",
      "Satoshi Suzuki",
      "Naoki Makishima",
      "Keita Suzuki",
      "Takafumi Moriya",
      "Takanori Ashihara",
      "Hiroshi Sato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15937"
  },
  {
    "id": "arXiv:2210.15938",
    "title": "Data-driven Output Regulation via Gaussian Processes and Luenberger  Internal Models",
    "abstract": "This paper deals with the problem of adaptive output regulation for\nmultivariable nonlinear systems by presenting a learning-based adaptive\ninternal model-based design strategy. The approach builds on the recently\nproposed adaptive internal model design techniques based on the theory of\nnonlinear Luenberger observers, and the adaptation side is approached as a\nprobabilistic regression problem. In particular, Gaussian process priors are\nemployed to cope with the learning problem. Unlike the previous approaches in\nthe field, here only coarse assumptions about the friend structure are\nrequired, making the proposed approach suitable for applications where the\nexosystem is highly uncertain. The paper presents performance bounds on the\nattained regulation error and numerical simulations showing how the proposed\nmethod outperforms previous approaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.12225\n",
    "authors": [
      "Lorenzo Gentilini",
      "Michelangelo Bin",
      "Lorenzo Marconi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15938"
  },
  {
    "id": "arXiv:2210.15939",
    "title": "INTERNEURON: A Middleware with Multi-Network Communication Reliability  for Infrastructure Vehicle Cooperative Autonomous Driving",
    "abstract": "Infrastructure-Vehicle Cooperative Autonomous Driving (IVCAD) is a new\nparadigm of autonomous driving, which relies on the cooperation between\nintelligent roads and autonomous vehicles. This paradigm has been shown to be\nsafer and more efficient compared to the on-vehicle-only autonomous driving\nparadigm. Our real-world deployment data indicates that the effectiveness of\nIVCAD is constrained by reliability and performance of commercial communication\nnetworks. This paper targets this exact problem, and proposes INTERNEURON, a\nmiddleware to achieve high communication reliability between intelligent roads\nand autonomous vehicles, in the context of IVCAD. Specifically, INTERNEURON\ndynamically matches IVCAD applications and the underlying communication\ntechnologies based on varying communication performance and quality needs.\nEvaluation results confirm that INTERNEURON reduces deadline violations by more\nthan 95\\%, significantly improving the reliability of IVCAD systems.",
    "descriptor": "",
    "authors": [
      "Tianze Wu",
      "Shaoshan Liu",
      "Bo Yu",
      "Sa Wang",
      "Yungang Bao",
      "Weisong Shi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.15939"
  },
  {
    "id": "arXiv:2210.15943",
    "title": "Grafting Vision Transformers",
    "abstract": "Vision Transformers (ViTs) have recently become the state-of-the-art across\nmany computer vision tasks. In contrast to convolutional networks (CNNs), ViTs\nenable global information sharing even within shallow layers of a network,\ni.e., among high-resolution features. However, this perk was later overlooked\nwith the success of pyramid architectures such as Swin Transformer, which show\nbetter performance-complexity trade-offs. In this paper, we present a simple\nand efficient add-on component (termed GrafT) that considers global\ndependencies and multi-scale information throughout the network, in both high-\nand low-resolution features alike. GrafT can be easily adopted in both\nhomogeneous and pyramid Transformers while showing consistent gains. It has the\nflexibility of branching-out at arbitrary depths, widening a network with\nmultiple scales. This grafting operation enables us to share most of the\nparameters and computations of the backbone, adding only minimal complexity,\nbut with a higher yield. In fact, the process of progressively compounding\nmulti-scale receptive fields in GrafT enables communications between local\nregions. We show the benefits of the proposed method on multiple benchmarks,\nincluding image classification (ImageNet-1K), semantic segmentation (ADE20K),\nobject detection and instance segmentation (COCO2017). Our code and models will\nbe made available.",
    "descriptor": "",
    "authors": [
      "Jongwoo Park",
      "Kumara Kahatapitiya",
      "Donghyun Kim",
      "Shivchander Sudalairaj",
      "Quanfu Fan",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15943"
  },
  {
    "id": "arXiv:2210.15944",
    "title": "RoChBert: Towards Robust BERT Fine-tuning for Chinese",
    "abstract": "Despite of the superb performance on a wide range of tasks, pre-trained\nlanguage models (e.g., BERT) have been proved vulnerable to adversarial texts.\nIn this paper, we present RoChBERT, a framework to build more Robust BERT-based\nmodels by utilizing a more comprehensive adversarial graph to fuse Chinese\nphonetic and glyph features into pre-trained representations during\nfine-tuning. Inspired by curriculum learning, we further propose to augment the\ntraining dataset with adversarial texts in combination with intermediate\nsamples. Extensive experiments demonstrate that RoChBERT outperforms previous\nmethods in significant ways: (i) robust -- RoChBERT greatly improves the model\nrobustness without sacrificing accuracy on benign texts. Specifically, the\ndefense lowers the success rates of unlimited and limited attacks by 59.43% and\n39.33% respectively, while remaining accuracy of 93.30%; (ii) flexible --\nRoChBERT can easily extend to various language models to solve different\ndownstream tasks with excellent performance; and (iii) efficient -- RoChBERT\ncan be directly applied to the fine-tuning stage without pre-training language\nmodel from scratch, and the proposed data augmentation method is also low-cost.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Zihan Zhang",
      "Jinfeng Li",
      "Ning Shi",
      "Bo Yuan",
      "Xiangyu Liu",
      "Rong Zhang",
      "Hui Xue",
      "Donghong Sun",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15944"
  },
  {
    "id": "arXiv:2210.15947",
    "title": "NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed  Neural Radiance Fields",
    "abstract": "Visually exploring in a real-world 4D spatiotemporal space freely in VR has\nbeen a long-term quest. The task is especially appealing when only a few or\neven single RGB cameras are used for capturing the dynamic scene. To this end,\nwe present an efficient framework capable of fast reconstruction, compact\nmodeling, and streamable rendering. First, we propose to decompose the 4D\nspatiotemporal space according to temporal characteristics. Points in the 4D\nspace are associated with probabilities of belonging to three categories:\nstatic, deforming, and new areas. Each area is represented and regularized by a\nseparate neural field. Second, we propose a hybrid representations based\nfeature streaming scheme for efficiently modeling the neural fields. Our\napproach, coined NeRFPlayer, is evaluated on dynamic scenes captured by single\nhand-held cameras and multi-camera arrays, achieving comparable or superior\nrendering performance in terms of quality and speed comparable to recent\nstate-of-the-art methods, achieving reconstruction in 10 seconds per frame and\nreal-time rendering.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Liangchen Song",
      "Anpei Chen",
      "Zhong Li",
      "Zhang Chen",
      "Lele Chen",
      "Junsong Yuan",
      "Yi Xu",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15947"
  },
  {
    "id": "arXiv:2210.15948",
    "title": "Matching entropy based disparity estimation from light field",
    "abstract": "A major challenge for matching-based depth estimation is to prevent\nmismatches in occlusion and smooth regions. An effective matching window\nsatisfying three characteristics: texture richness, disparity consistency and\nanti-occlusion should be able to prevent mismatches to some extent. According\nto these characteristics, we propose matching entropy in the spatial domain of\nlight field to measure the amount of correct information in a matching window,\nwhich provides the criterion for matching window selection. Based on matching\nentropy regularization, we establish an optimization model for depth estimation\nwith a matching cost fidelity term. To find the optimum, we propose a two-step\nadaptive matching algorithm. First, the region type is adaptively determined to\nidentify occluding, occluded, smooth and textured regions. Then, the matching\nentropy criterion is used to adaptively select the size and shape of matching\nwindows, as well as the visible viewpoints. The two-step process can reduce\nmismatches and redundant calculations by selecting effective matching windows.\nThe experimental results on synthetic and real data show that the proposed\nmethod can effectively improve the accuracy of depth estimation in occlusion\nand smooth regions and has strong robustness for different noise levels.\nTherefore, high-precision depth estimation from 4D light field data is\nachieved.",
    "descriptor": "",
    "authors": [
      "Ligen Shi",
      "Chang Liu",
      "Di He",
      "Xing Zhao",
      "Jun Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15948"
  },
  {
    "id": "arXiv:2210.15950",
    "title": "LBF:Learnable Bilateral Filter For Point Cloud Denoising",
    "abstract": "Bilateral filter (BF) is a fast, lightweight and effective tool for image\ndenoising and well extended to point cloud denoising. However, it often\ninvolves continual yet manual parameter adjustment; this inconvenience\ndiscounts the efficiency and user experience to obtain satisfied denoising\nresults. We propose LBF, an end-to-end learnable bilateral filtering network\nfor point cloud denoising; to our knowledge, this is the first time. Unlike the\nconventional BF and its variants that receive the same parameters for a whole\npoint cloud, LBF learns adaptive parameters for each point according its\ngeometric characteristic (e.g., corner, edge, plane), avoiding remnant noise,\nwrongly-removed geometric details, and distorted shapes. Besides the learnable\nparadigm of BF, we have two cores to facilitate LBF. First, different from the\nlocal BF, LBF possesses a global-scale feature perception ability by exploiting\nmulti-scale patches of each point. Second, LBF formulates a geometry-aware\nbi-directional projection loss, leading the denoising results to being faithful\nto their underlying surfaces. Users can apply our LBF without any laborious\nparameter tuning to achieve the optimal denoising results. Experiments show\nclear improvements of LBF over its competitors on both synthetic and\nreal-scanned datasets.",
    "descriptor": "",
    "authors": [
      "Huajian Si",
      "Zeyong Wei",
      "Zhe Zhu",
      "Honghua Chen",
      "Dong Liang",
      "Weiming Wang",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15950"
  },
  {
    "id": "arXiv:2210.15954",
    "title": "Stanceosaurus: Classifying Stance Towards Multilingual Misinformation",
    "abstract": "We present Stanceosaurus, a new corpus of 28,033 tweets in English, Hindi,\nand Arabic annotated with stance towards 251 misinformation claims. As far as\nwe are aware, it is the largest corpus annotated with stance towards\nmisinformation claims. The claims in Stanceosaurus originate from 15\nfact-checking sources that cover diverse geographical regions and cultures.\nUnlike existing stance datasets, we introduce a more fine-grained 5-class\nlabeling strategy with additional subcategories to distinguish implicit stance.\nPre-trained transformer-based stance classifiers that are fine-tuned on our\ncorpus show good generalization on unseen claims and regional claims from\ncountries outside the training data. Cross-lingual experiments demonstrate\nStanceosaurus' capability of training multi-lingual models, achieving 53.1 F1\non Hindi and 50.4 F1 on Arabic without any target-language fine-tuning.\nFinally, we show how a domain adaptation method can be used to improve\nperformance on Stanceosaurus using additional RumourEval-2019 data. We make\nStanceosaurus publicly available to the research community and hope it will\nencourage further work on misinformation identification across languages and\ncultures.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Jonathan Zheng",
      "Ashutosh Baheti",
      "Tarek Naous",
      "Wei Xu",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15954"
  },
  {
    "id": "arXiv:2210.15956",
    "title": "Generalized Laplacian Positional Encoding for Graph Representation  Learning",
    "abstract": "Graph neural networks (GNNs) are the primary tool for processing\ngraph-structured data. Unfortunately, the most commonly used GNNs, called\nMessage Passing Neural Networks (MPNNs) suffer from several fundamental\nlimitations. To overcome these limitations, recent works have adapted the idea\nof positional encodings to graph data. This paper draws inspiration from the\nrecent success of Laplacian-based positional encoding and defines a novel\nfamily of positional encoding schemes for graphs. We accomplish this by\ngeneralizing the optimization problem that defines the Laplace embedding to\nmore general dissimilarity functions rather than the 2-norm used in the\noriginal formulation. This family of positional encodings is then instantiated\nby considering p-norms. We discuss a method for calculating these positional\nencoding schemes, implement it in PyTorch and demonstrate how the resulting\npositional encoding captures different properties of the graph. Furthermore, we\ndemonstrate that this novel family of positional encodings can improve the\nexpressive power of MPNNs. Lastly, we present preliminary experimental results.",
    "descriptor": "\nComments: Accepted at NeurIPS Workshop on Symmetry and Geometry in Neural Representations: Extended Abstract Track 2022\n",
    "authors": [
      "Sohir Maskey",
      "Ali Parviz",
      "Maximilian Thiessen",
      "Hannes St\u00e4rk",
      "Ylli Sadikaj",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15956"
  },
  {
    "id": "arXiv:2210.15957",
    "title": "Brain Modeling for Control: A Review",
    "abstract": "Neurostimulation technologies have seen a recent surge in interest from the\nneuroscience and controls communities alike due to their proven potential to\ntreat conditions such as Parkinson's Disease, and depression. The provided\nstimulation can be of different types, such as electric, and optogenetic, and\nis generally applied to a specific region of the brain in order to drive the\nlocal and/or global dynamics to a desired state of (in)activity. However, an\nunderlying theoretical understanding of the efficacy of neurostimulation is\nstill lacking. From a control-theoretic perspective, it is important to\nunderstand how each stimulus modality interacts with the complex brain network\nin order to assess the controllability of the system and develop\nneurophysiologically relevant computational models that can be used to design\nthe stimulation profile in a closed-loop manner. In this paper, we review the\ncomputational modeling studies of (i) deep brain stimulation, (ii) transcranial\nmagnetic stimulation, (iii) direct current stimulation, (iv) transcranial\nelectrical stimulation, and (v) optogenetics as five of the most popular\nneurostimulation technologies in research and clinical settings. For each\ntechnology, we split the reviewed studies into (a)theory-driven biophysical\nmodels capturing the low-level physics of the interactions between the\nstimulation source and neuronal tissue, (b) data-driven stimulus-response\nmodels which capture the end-to-end effects of stimulation on various\nbiomarkers of interest and (c) data-driven dynamical system models that extract\nthe precise dynamics of the brain's response to neurostimulation from neural\ndata. While our focus is particularly on the latter category due to their\ngreater utility in control design, we review key works in the former two\ncategories as the basis and context in which dynamical system models have been\nand will be developed.",
    "descriptor": "\nComments: 35 pages, 3 figures, 6 tables\n",
    "authors": [
      "Gagan Acharya",
      "Sebastian F. Ruf",
      "Erfan Nozari"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.15957"
  },
  {
    "id": "arXiv:2210.15958",
    "title": "Modular Model Reduction of Interconnected Systems: A Robust Performance  Analysis Perspective",
    "abstract": "Many complex engineering systems consist of multiple subsystems that are\ndeveloped by different teams of engineers. To analyse, simulate and control\nsuch complex systems, accurate yet computationally efficient models are\nrequired. Modular model reduction, in which the subsystem models are reduced\nindividually, is a practical and an efficient method to obtain accurate\nreduced-order models of such complex systems. However, when subsystems are\nreduced individually, without taking their interconnections into account, the\neffect on stability and accuracy of the resulting reduced-order interconnected\nsystem is difficult to predict. In this work, a mathematical relation between\nthe accuracy of reduced-order linear-time invariant subsystem models and\n(stability and accuracy of) resulting reduced-order interconnected linear\ntime-invariant model is introduced. This result can subsequently be used in two\nways. Firstly, it can be used to translate accuracy characteristics of the\nreduced-order subsystem models directly to accuracy properties of the\ninterconnected reduced-order model. Secondly, it can also be used to translate\nspecifications on the interconnected system model accuracy to accuracy\nrequirements on subsystem models that can be used for fit-for-purpose reduction\nof the subsystem models. These applications of the proposed analysis framework\nfor modular model reduction are demonstrated on an illustrative structural\ndynamics example.",
    "descriptor": "",
    "authors": [
      "Lars A.L. Janssen",
      "Bart Besselink",
      "Rob H.B. Fey",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15958"
  },
  {
    "id": "arXiv:2210.15959",
    "title": "Equally spaced points are optimal for Brownian Bridge kernel  interpolation",
    "abstract": "In this paper we show how ideas from spline theory can be used to construct a\nlocal basis for the space of translates of a general iterated Brownian Bridge\nkernel $k_{\\beta,\\varepsilon}$ for $\\beta\\in\\mathbb{N}$, $\\varepsilon\\geq 0$.\nIn the simple case $\\beta=1$, we derive an explicit formula for the\ncorresponding Lagrange basis, which allows us to solve interpolation problems\nwithout inverting any linear system.\nWe use this basis to prove that interpolation with $k_{1,\\varepsilon}$ is\nuniformly stable, i.e., the Lebesgue constant is bounded independently of the\nnumber an location of the interpolation points, and that equally spaced points\nare the unique minimizers of the associated power function, and are thus error\noptimal. In this derivation, we investigate the role of the shape parameter\n$\\varepsilon>0$, and discuss its effect on these error and stability bounds.\nSome of the ideas discussed in this paper could be extended to more general\nGreen kernels.",
    "descriptor": "",
    "authors": [
      "Gabriele Santin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15959"
  },
  {
    "id": "arXiv:2210.15960",
    "title": "Determining Ratio of Prunable Channels in MobileNet by Sparsity for  Acoustic Scene Classification",
    "abstract": "MobileNet is widely used for Acoustic Scene Classification (ASC) in embedded\nsystems. Existing works reduce the complexity of ASC algorithms by pruning some\ncomponents, e.g. pruning channels in the convolutional layer. In practice, the\nmaximum proportion of channels being pruned, which is defined as Ratio of\nPrunable Channels ($R_\\textit{PC}$), is often decided empirically. This paper\nproposes a method that determines the $R_\\textit{PC}$ by simple linear\nregression models related to the Sparsity of Channels ($S_C$) in the\nconvolutional layers. In the experiment, $R_\\textit{PC}$ is examined by\nremoving inactive channels until reaching a knee point of performance decrease.\nSimple methods for calculating the $S_C$ of trained models and resulted\n$R_\\textit{PC}$ are proposed. The experiment results demonstrate that 1) the\ndecision of $R_\\textit{PC}$ is linearly dependent on $S_C$ and the\nhyper-parameters have a little impact on the relationship; 2) MobileNet shows a\nhigh sensitivity and stability on proposed method.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to ICASSP 2023\n",
    "authors": [
      "Yiqiang Cai",
      "Shengchen Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15960"
  },
  {
    "id": "arXiv:2210.15962",
    "title": "Parallel Self-Avoiding Walks for a Low-Autocorrelation Binary Sequences  Problem",
    "abstract": "A low-autocorrelation binary sequences problem with a high figure of merit\nfactor represents a formidable computational challenge. An efficient parallel\ncomputing algorithm is required to reach the new best-known solutions for this\nproblem. Therefore, we developed the $\\mathit{sokol}_{\\mathit{skew}}$ solver\nfor the skew-symmetric search space. The developed solver takes the advantage\nof parallel computing on graphics processing units. The solver organized the\nsearch process as a sequence of parallel and contiguous self-avoiding walks and\nachieved a speedup factor of 387 compared with $\\mathit{lssOrel}$, its\npredecessor. The $\\mathit{sokol}_{\\mathit{skew}}$ solver belongs to stochastic\nsolvers and can not guarantee the optimality of solutions. To mitigate this\nproblem, we established the predictive model of stopping conditions according\nto the small instances for which the optimal skew-symmetric solutions are\nknown. With its help and 99% probability, the $\\mathit{sokol}_{\\mathit{skew}}$\nsolver found all the known and seven new best-known skew-symmetric sequences\nfor odd instances from $L=121$ to $L=223$. For larger instances, the solver can\nnot reach 99% probability within our limitations, but it still found several\nnew best-known binary sequences. We also analyzed the trend of the best merit\nfactor values, and it shows that as sequence size increases, the value of the\nmerit factor also increases, and this trend is flatter for larger instances.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Borko Bo\u0161kovi\u0107",
      "Jana Herzog",
      "Janez Brest"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15962"
  },
  {
    "id": "arXiv:2210.15965",
    "title": "System Network Analytics: Evolution and Stable Rules of a State Series",
    "abstract": "System Evolution Analytics on a system that evolves is a challenge because it\nmakes a State Series SS = {S1, S2... SN} (i.e., a set of states ordered by\ntime) with several inter-connected entities changing over time. We present\nstability characteristics of interesting evolution rules occurring in multiple\nstates. We defined an evolution rule with its stability as the fraction of\nstates in which the rule is interesting. Extensively, we defined stable rule as\nthe evolution rule having stability that exceeds a given threshold minimum\nstability (minStab). We also defined persistence metric, a quantitative measure\nof persistent entity-connections. We explain this with an approach and\nalgorithm for System Network Analytics (SysNet-Analytics), which uses minStab\nto retrieve Network Evolution Rules (NERs) and Stable NERs (SNERs). The\nretrieved information is used to calculate a proposed System Network\nPersistence (SNP) metric. This work is automated as a SysNet-Analytics Tool to\ndemonstrate application on real world systems including: software system,\nnatural-language system, retail market system, and IMDb system. We quantified\nstability and persistence of entity-connections in a system state series. This\nresults in evolution information, which helps in system evolution analytics\nbased on knowledge discovery and data mining.",
    "descriptor": "\nComments: Accepted on IEEE DSAA and Video Presentation this https URL&list=PLtvWi5o3JBnF3yxcjGdT4KCDLxRBIpsyR\n",
    "authors": [
      "Animesh Chaturvedi",
      "Aruna Tiwari",
      "Nicolas Spyratos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.15965"
  },
  {
    "id": "arXiv:2210.15968",
    "title": "Magnetorheological Axisymmetric Actuator with Permanent Magnet",
    "abstract": "This study examines the concept of axisymmetric actuator based on the\nmagnetorheological membrane, electromagnet and permanent magnet. The\nconstruction of the actuator enables its application in wide range of practical\ndevices like pumping, loudspeaker or varying-stiffness button. This work will\nhighlight its working principle especially the influence of permanent magnet.\nFurthermore, the model of devices will be defined relaying on the Hammerstein\nmodel. To show the properties of the actuator and to perform the model\nidentification, the set of experiments was run taking into account static and\ndynamic working conditions.",
    "descriptor": "",
    "authors": [
      "Jakub Bernat",
      "Paulina Superczynska",
      "Piotr Gajewski",
      "Agnieszka Marcinkowska"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15968"
  },
  {
    "id": "arXiv:2210.15971",
    "title": "Diversity enables the jump towards cooperation for the Traveler's  Dilemma",
    "abstract": "Social dilemmas are situations in which collective welfare is at odds with\nindividual gain. One widely studied example, due to the conflict it poses\nbetween human behaviour and game theoretic reasoning, is the Traveler's\nDilemma. The dilemma relies on the players' incentive to undercut their\nopponent at the expense of losing a collective high payoff. Such individual\nincentive leads players to a systematic mutual undercutting until the lowest\npossible payoff is reached, which is the game's unique Nash equilibrium.\nHowever, if players were satisfied with a high payoff -- that is not\nnecessarily higher than their opponent's -- they would both be better off\nindividually and collectively. Here, we explain how it is possible to converge\nto this cooperative high payoff equilibrium. Our analysis focuses on\ndecomposing the dilemma into a local and a global game. We show that players\nneed to escape the local maximisation and jump to the global game, in order to\nreach the cooperative equilibrium. Using a dynamic approach, based on\nevolutionary game theory and learning theory models, we find that diversity,\nunderstood as the presence of suboptimal strategies, is the general mechanism\nthat enables the jump towards cooperation.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Maria Alejandra Ramirez",
      "Matteo Smerlak",
      "Arne Traulsen",
      "J\u00fcrgen Jost"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2210.15971"
  },
  {
    "id": "arXiv:2210.15972",
    "title": "Contextual Learning in Fourier Complex Field for VHR Remote Sensing  Images",
    "abstract": "Very high-resolution (VHR) remote sensing (RS) image classification is the\nfundamental task for RS image analysis and understanding. Recently,\ntransformer-based models demonstrated outstanding potential for learning\nhigh-order contextual relationships from natural images with general resolution\n(224x224 pixels) and achieved remarkable results on general image\nclassification tasks. However, the complexity of the naive transformer grows\nquadratically with the increase in image size, which prevents transformer-based\nmodels from VHR RS image (500x500 pixels) classification and other\ncomputationally expensive downstream tasks. To this end, we propose to\ndecompose the expensive self-attention (SA) into real and imaginary parts via\ndiscrete Fourier transform (DFT) and therefore propose an efficient complex\nself-attention (CSA) mechanism. Benefiting from the conjugated symmetric\nproperty of DFT, CSA is capable to model the high-order contextual information\nwith less than half computations of naive SA. To overcome the gradient\nexplosion in Fourier complex field, we replace the Softmax function with the\ncarefully designed Logmax function to normalize the attention map of CSA and\nstabilize the gradient propagation. By stacking various layers of CSA blocks,\nwe propose the Fourier Complex Transformer (FCT) model to learn global\ncontextual information from VHR aerial images following the hierarchical\nmanners. Universal experiments conducted on commonly used RS classification\ndata sets demonstrate the effectiveness and efficiency of FCT, especially on\nvery high-resolution RS images.",
    "descriptor": "",
    "authors": [
      "Yan Zhang",
      "Xiyuan Gao",
      "Qingyan Duan",
      "Jiaxu Leng",
      "Xiao Pu",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15972"
  },
  {
    "id": "arXiv:2210.15973",
    "title": "A Deep Dive into VirusTotal: Characterizing and Clustering a Massive  File Feed",
    "abstract": "Online scanners analyze user-submitted files with a large number of security\ntools and provide access to the analysis results. As the most popular online\nscanner, VirusTotal (VT) is often used for determining if samples are\nmalicious, labeling samples with their family, hunting for new threats, and\ncollecting malware samples. We analyze 328M VT reports for 235M samples\ncollected for one year through the VT file feed. We use the reports to\ncharacterize the VT file feed in depth and compare it with the telemetry of a\nlarge security vendor. We answer questions such as How diverse is the feed?\nDoes it allow building malware datasets for different filetypes? How fresh are\nthe samples it provides? What is the distribution of malware families it sees?\nDoes that distribution really represent malware on user devices?\nWe then explore how to perform threat hunting at scale by investigating\nscalable approaches that can produce high purity clusters on the 235M feed\nsamples. We investigate three clustering approaches: hierarchical agglomerative\nclustering (HAC), a more scalable HAC variant for TLSH digests (HAC-T), and a\nsimple feature value grouping (FVG). Our results show that HAC-T and FVG using\nselected features produce high precision clusters on ground truth datasets.\nHowever, only FVG scales to the daily influx of samples in the feed. Moreover,\nFVG takes 15 hours to cluster the whole dataset of 235M samples. Finally, we\nuse the produced clusters for threat hunting, namely for detecting 190K samples\nthought to be benign (i.e., with zero detections) that may really be malicious\nbecause they belong to 29K clusters where most samples are detected as\nmalicious.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Kevin van Liebergen",
      "Juan Caballero",
      "Platon Kotzias",
      "Chris Gates"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15973"
  },
  {
    "id": "arXiv:2210.15976",
    "title": "BEBERT: Efficient and robust binary ensemble BERT",
    "abstract": "Pre-trained BERT models have achieved impressive accuracy on natural language\nprocessing (NLP) tasks. However, their excessive amount of parameters hinders\nthem from efficient deployment on edge devices. Binarization of the BERT models\ncan significantly alleviate this issue but comes with a severe accuracy drop\ncompared with their full-precision counterparts. In this paper, we propose an\nefficient and robust binary ensemble BERT (BEBERT) to bridge the accuracy gap.\nTo the best of our knowledge, this is the first work employing ensemble\ntechniques on binary BERTs, yielding BEBERT, which achieves superior accuracy\nwhile retaining computational efficiency. Furthermore, we remove the knowledge\ndistillation procedures during ensemble to speed up the training process\nwithout compromising accuracy. Experimental results on the GLUE benchmark show\nthat the proposed BEBERT significantly outperforms the existing binary BERT\nmodels in accuracy and robustness with a 2x speedup on training time. Moreover,\nour BEBERT has only a negligible accuracy loss of 0.3% compared to the\nfull-precision baseline while saving 15x and 13x in FLOPs and model size,\nrespectively. In addition, BEBERT also outperforms other compressed BERTs in\naccuracy by up to 6.7%.",
    "descriptor": "\nComments: In submission to ICASSP 2023\n",
    "authors": [
      "Jiayi Tian",
      "Chao Fang",
      "Haonan Wang",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15976"
  },
  {
    "id": "arXiv:2210.15977",
    "title": "FedVMR: A New Federated Learning method for Video Moment Retrieval",
    "abstract": "Despite the great success achieved, existing video moment retrieval (VMR)\nmethods are developed under the assumption that data are centralizedly stored.\nHowever, in real-world applications, due to the inherent nature of data\ngeneration and privacy concerns, data are often distributed on different silos,\nbringing huge challenges to effective large-scale training. In this work, we\ntry to overcome above limitation by leveraging the recent success of federated\nlearning. As the first that is explored in VMR field, the new task is defined\nas video moment retrieval with distributed data. Then, a novel federated\nlearning method named FedVMR is proposed to facilitate large-scale and secure\ntraining of VMR models in decentralized environment. Experiments on benchmark\ndatasets demonstrate its effectiveness. This work is the very first attempt to\nenable safe and efficient VMR training in decentralized scene, which is hoped\nto pave the way for further study in the related research field.",
    "descriptor": "",
    "authors": [
      "Yan Wang",
      "Xin Luo",
      "Zhen-Duo Chen",
      "Peng-Fei Zhang",
      "Meng Liu",
      "Xin-Shun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15977"
  },
  {
    "id": "arXiv:2210.15985",
    "title": "Understanding Adverse Biological Effect Predictions Using Knowledge  Graphs",
    "abstract": "Extrapolation of adverse biological (toxic) effects of chemicals is an\nimportant contribution to expand available hazard data in (eco)toxicology\nwithout the use of animals in laboratory experiments. In this work, we\nextrapolate effects based on a knowledge graph (KG) consisting of the most\nrelevant effect data as domain-specific background knowledge. An effect\nprediction model, with and without background knowledge, was used to predict\nmean adverse biological effect concentration of chemicals as a prototypical\ntype of stressors. The background knowledge improves the model prediction\nperformance by up to 40\\% in terms of $R^2$ (\\ie coefficient of determination).\nWe use the KG and KG embeddings to provide quantitative and qualitative\ninsights into the predictions. These insights are expected to improve the\nconfidence in effect prediction. Larger scale implementation of such\nextrapolation models should be expected to support hazard and risk assessment,\nby simplifying and reducing testing needs.",
    "descriptor": "\nComments: Under review. 29 pages\n",
    "authors": [
      "Erik Bryhn Myklebust",
      "Ernesto Jimenez-Ruiz",
      "Jiaoyan Chen",
      "Raoul Wolf",
      "Knut Erik Tollefsen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.15985"
  },
  {
    "id": "arXiv:2210.15986",
    "title": "Differentially Private CutMix for Split Learning with Vision Transformer",
    "abstract": "Recently, vision transformer (ViT) has started to outpace the conventional\nCNN in computer vision tasks. Considering privacy-preserving distributed\nlearning with ViT, federated learning (FL) communicates models, which becomes\nill-suited due to ViT' s large model size and computing costs. Split learning\n(SL) detours this by communicating smashed data at a cut-layer, yet suffers\nfrom data privacy leakage and large communication costs caused by high\nsimilarity between ViT' s smashed data and input data. Motivated by this\nproblem, we propose DP-CutMixSL, a differentially private (DP) SL framework by\ndeveloping DP patch-level randomized CutMix (DP-CutMix), a novel\nprivacy-preserving inter-client interpolation scheme that replaces randomly\nselected patches in smashed data. By experiment, we show that DP-CutMixSL not\nonly boosts privacy guarantees and communication efficiency, but also achieves\nhigher accuracy than its Vanilla SL counterpart. Theoretically, we analyze that\nDP-CutMix amplifies R\\'enyi DP (RDP), which is upper-bounded by its Vanilla\nMixup counterpart.",
    "descriptor": "\nComments: to be presented at the 36nd Conference on Neural Information Processing Systems (NeurIPS 2022), First Workshop on Interpolation Regularizers and Beyond (INTERPOLATE), New Orleans, United States\n",
    "authors": [
      "Seungeun Oh",
      "Jihong Park",
      "Sihun Baek",
      "Hyelin Nam",
      "Praneeth Vepakomma",
      "Ramesh Raskar",
      "Mehdi Bennis",
      "Seong-Lyun Kim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15986"
  },
  {
    "id": "arXiv:2210.15988",
    "title": "Spectrograms Are Sequences of Patches",
    "abstract": "Self-supervised pre-training models have been used successfully in several\nmachine learning domains. However, only a tiny amount of work is related to\nmusic. In our work, we treat a spectrogram of music as a series of patches and\ndesign a self-supervised model that captures the features of these sequential\npatches: Patchifier, which makes good use of self-supervised learning methods\nfrom both NLP and CV domains. We do not use labeled data for the pre-training\nprocess, only a subset of the MTAT dataset containing 16k music clips. After\npre-training, we apply the model to several downstream tasks. Our model\nachieves a considerably acceptable result compared to other audio\nrepresentation models. Meanwhile, our work demonstrates that it makes sense to\nconsider audio as a series of patch segments.",
    "descriptor": "",
    "authors": [
      "Leyi Zhao",
      "Yi Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15988"
  },
  {
    "id": "arXiv:2210.15991",
    "title": "Fast multivariate polynomials in R: the mvp package",
    "abstract": "In this short article I introduce the mvp package, which provides some\nfunctionality for handling multivariate polynomials. The package uses the C++\nStandard Template Library's map class to store and retrieve elements; it\nconforms to disordR discipline for coefficients. The package is available on\nCRAN at https://CRAN.R-project.org/package=mvp.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Robin K. S. Hankin"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.15991"
  },
  {
    "id": "arXiv:2210.15996",
    "title": "Towards Few-Shot Open-Set Object Detection",
    "abstract": "Open-set object detection (OSOD) aims to detect the known categories and\nidentify unknown objects in a dynamic world, which has achieved significant\nattentions. However, previous approaches only consider this problem in\ndata-abundant conditions. We seek a solution for few-shot open-set object\ndetection (FSOSOD), which aims to quickly train a detector based on few samples\nwhile detecting all known classes and identifying unknown classes. The main\nchallenge for this task is that few training samples tend to overfit on the\nknown classes, and lead to poor open-set performance. We propose a new FSOSOD\nalgorithm to tackle this issue, named FOOD, which contains a novel class\ndropout cosine classifier (CDCC) and a novel unknown decoupling learner (UDL).\nTo prevent over-fitting, CDCC randomly inactivates parts of the normalized\nneurons for the logit prediction of all classes, and then decreases the\nco-adaptability between the class and its neighbors. Alongside, UDL decouples\ntraining the unknown class and enables the model to form a compact unknown\ndecision boundary. Thus, the unknown objects can be identified with a\nconfidence probability without any pseudo-unknown samples for training. We\ncompare our method with several state-of-the-art OSOD methods in few-shot\nscenes and observe that our method improves the recall of unknown classes by\n5%-9% across all shots in VOC-COCO dataset setting.",
    "descriptor": "",
    "authors": [
      "Binyi Su",
      "Hua Zhang",
      "Zhong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15996"
  },
  {
    "id": "arXiv:2210.15997",
    "title": "Universal Adversarial Directions",
    "abstract": "Despite their great success in image recognition tasks, deep neural networks\n(DNNs) have been observed to be susceptible to universal adversarial\nperturbations (UAPs) which perturb all input samples with a single perturbation\nvector. However, UAPs often struggle in transferring across DNN architectures\nand lead to challenging optimization problems. In this work, we study the\ntransferability of UAPs by analyzing equilibrium in the universal adversarial\nexample game between the classifier and UAP adversary players. We show that\nunder mild assumptions the universal adversarial example game lacks a pure Nash\nequilibrium, indicating UAPs' suboptimal transferability across DNN\nclassifiers. To address this issue, we propose Universal Adversarial Directions\n(UADs) which only fix a universal direction for adversarial perturbations and\nallow the perturbations' magnitude to be chosen freely across samples. We prove\nthat the UAD adversarial example game can possess a Nash equilibrium with a\npure UAD strategy, implying the potential transferability of UADs. We also\nconnect the UAD optimization problem to the well-known principal component\nanalysis (PCA) and develop an efficient PCA-based algorithm for optimizing\nUADs. We evaluate UADs over multiple benchmark image datasets. Our numerical\nresults show the superior transferability of UADs over standard gradient-based\nUAPs.",
    "descriptor": "",
    "authors": [
      "Ching Lam Choi",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15997"
  },
  {
    "id": "arXiv:2210.15999",
    "title": "Benchmarking performance of object detection under image distortions in  an uncontrolled environment",
    "abstract": "The robustness of object detection algorithms plays a prominent role in\nreal-world applications, especially in uncontrolled environments due to\ndistortions during image acquisition. It has been proven that the performance\nof object detection methods suffers from in-capture distortions. In this study,\nwe present a performance evaluation framework for the state-of-the-art object\ndetection methods using a dedicated dataset containing images with various\ndistortions at different levels of severity. Furthermore, we propose an\noriginal strategy of image distortion generation applied to the MS-COCO dataset\nthat combines some local and global distortions to reach much better\nperformances. We have shown that training using the proposed dataset improves\nthe robustness of object detection by 31.5\\%. Finally, we provide a custom\ndataset including natural images distorted from MS-COCO to perform a more\nreliable evaluation of the robustness against common distortions. The database\nand the generation source codes of the different distortions are made publicly\navailable",
    "descriptor": "",
    "authors": [
      "Ayman Beghdadi",
      "Malik Mallem",
      "Lotfi Beji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.15999"
  },
  {
    "id": "arXiv:2210.16000",
    "title": "Thermal Infrared Image Inpainting via Edge-Aware Guidance",
    "abstract": "Image inpainting has achieved fundamental advances with deep learning.\nHowever, almost all existing inpainting methods aim to process natural images,\nwhile few target Thermal Infrared (TIR) images, which have widespread\napplications. When applied to TIR images, conventional inpainting methods\nusually generate distorted or blurry content. In this paper, we propose a novel\ntask -- Thermal Infrared Image Inpainting, which aims to reconstruct missing\nregions of TIR images. Crucially, we propose a novel deep-learning-based model\nTIR-Fill. We adopt the edge generator to complete the canny edges of broken TIR\nimages. The completed edges are projected to the normalization weights and\nbiases to enhance edge awareness of the model. In addition, a refinement\nnetwork based on gated convolution is employed to improve TIR image\nconsistency. The experiments demonstrate that our method outperforms\nstate-of-the-art image inpainting approaches on FLIR thermal dataset.",
    "descriptor": "",
    "authors": [
      "Zeyu Wang",
      "Haibin Shen",
      "Changyou Men",
      "Quan Sun",
      "Kejie Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16000"
  },
  {
    "id": "arXiv:2210.16002",
    "title": "An Online Learning Approach for Vehicle Usage Prediction During COVID-19",
    "abstract": "Today, there is an ongoing transition to more sustainable transportation, and\nan essential part of this transition is the switch from combustion engine\nvehicles to battery electric vehicles (BEVs). BEVs have many advantages from a\nsustainability perspective, but issues such as limited driving range and long\nrecharge times slow down the transition from combustion engines. One way to\nmitigate these issues is by performing battery thermal preconditioning, which\nincreases the energy efficiency of the battery. However, to optimally perform\nbattery thermal preconditioning, the vehicle usage pattern needs to be known,\ni.e., how and when the vehicle will be used. This study attempts to predict the\ndeparture time and distance of the first drive each day using different online\nmachine learning models. The online machine learning models are trained and\nevaluated on historical driving data collected from a fleet of BEVs during the\nCOVID-19 pandemic. Additionally, the prediction models are extended to quantify\nthe uncertainty of their predictions, which can be used as guidance to whether\nthe prediction should be used or dismissed. We show that the best-performing\nprediction models yield an aggregated mean absolute error of 2.75 hours when\npredicting departure time and 13.37 km when predicting trip distance.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tobias Lindroth",
      "Axel Svensson",
      "Niklas \u00c5kerblom",
      "Mitra Pourabdollah",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16002"
  },
  {
    "id": "arXiv:2210.16003",
    "title": "Evaluating the Impact of Loss Function Variation in Deep Learning for  Classification",
    "abstract": "The loss function is arguably among the most important hyperparameters for a\nneural network. Many loss functions have been designed to date, making a\ncorrect choice nontrivial. However, elaborate justifications regarding the\nchoice of the loss function are not made in related work. This is, as we see\nit, an indication of a dogmatic mindset in the deep learning community which\nlacks empirical foundation. In this work, we consider deep neural networks in a\nsupervised classification setting and analyze the impact the choice of loss\nfunction has onto the training result. While certain loss functions perform\nsuboptimally, our work empirically shows that under-represented losses such as\nthe KL Divergence can outperform the State-of-the-Art choices significantly,\nhighlighting the need to include the loss function as a tuned hyperparameter\nrather than a fixed choice.",
    "descriptor": "",
    "authors": [
      "Simon Dr\u00e4ger",
      "Jannik Dunkelau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16003"
  },
  {
    "id": "arXiv:2210.16006",
    "title": "Development of a rule-based lemmatization algorithm through Finite State  Machine for Uzbek language",
    "abstract": "Lemmatization is one of the core concepts in natural language processing,\nthus creating a lemmatization tool is an important task. This paper discusses\nthe construction of a lemmatization algorithm for the Uzbek language. The main\npurpose of the work is to remove affixes of words in the Uzbek language by\nmeans of the finite state machine and to identify a lemma (a word that can be\nfound in the dictionary) of the word. The process of removing affixes uses a\ndatabase of affixes and part of speech knowledge. This lemmatization consists\nof the general rules and a part of speech data of the Uzbek language, affixes,\nclassification of affixes, removing affixes on the basis of the finite state\nmachine for each class, as well as a definition of this word lemma.",
    "descriptor": "\nComments: Preprint version of the paper to be published in The International Conference and Workshop on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP), June 6, 2022, Koper, Slovenia\n",
    "authors": [
      "Maksud Sharipov",
      "Ogabek Sobirov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16006"
  },
  {
    "id": "arXiv:2210.16007",
    "title": "Design of Protograph LDPC-Coded MIMO-VLC Systems with Generalized  Spatial Modulation",
    "abstract": "This paper investigates the bit-interleaved coded generalized spatial\nmodulation (BICGSM) with iterative decoding (BICGSM-ID) for multiple-input\nmultiple-output (MIMO) visible light communications (VLC). In the BICGSM-ID\nscheme, the information bits conveyed by the signal-domain (SiD) symbols and\nthe spatial-domain (SpD) light emitting diode (LED)-index patterns are coded by\na protograph low-density parity-check (P-LDPC) code. Specifically, we propose a\nsignal-domain symbol expanding and re-allocating (SSER) method for constructing\na type of novel generalized spatial modulation (GSM) constellations, referred\nto as SSERGSM constellations, so as to boost the performance of the BICGSM-ID\nMIMO-VLC systems. Moreover, by applying a modified PEXIT (MPEXIT) algorithm, we\nfurther design a family of rate-compatible P-LDPC codes, referred to as\nenhanced accumulate-repeat-accumulate (EARA) codes, which possess both\nexcellent decoding thresholds and linear-minimum-distance-growth property. Both\nanalysis and simulation results illustrate that the proposed SSERGSM\nconstellations and P-LDPC codes can remarkably improve the convergence and\ndecoding performance of MIMO-VLC systems. Therefore, the proposed P-LDPC-coded\nSSERGSM-mapped BICGSM-ID configuration is envisioned as a promising\ntransmission solution to satisfy the high-throughput requirement of MIMO-VLC\napplications.",
    "descriptor": "",
    "authors": [
      "Lin Dai",
      "Yi Fang",
      "Yong Liang Guan",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.16007"
  },
  {
    "id": "arXiv:2210.16010",
    "title": "A consistent mixed-dimensional coupling approach for 1D Cosserat beams  and 2D solid surfaces",
    "abstract": "The present article proposes a novel computational method for coupling 1D\nfibers with the 2D surface of a 3D solid. The fibers are modeled as 1D Cosserat\ncontinua (beams) with six local degrees of freedom, three positional and three\nrotational ones. A kinematically consistent 1D-2D coupling scheme for this\nproblem type is proposed considering the positional and rotational degrees of\nfreedom along the beams. The positional degrees of freedom are coupled by\nenforcing a constant normal distance between a point on the beam centerline and\na corresponding point on the solid surface. This strategy requires a consistent\ndescription of the solid surface normal vector field to guarantee fundamental\nmechanical properties such as conservation of angular momentum. Coupling of the\nrotational degrees of freedom of the beams and a suitable rotation tensor\nrepresentative for the local orientation within a Boltzmann continuum has been\nconsidered in a previous contribution. In the present work, this coupling\napproach will be extended by constructing rotation tensors that are\nrepresentative for local surface orientations. Several numerical examples\ndemonstrate the consistency, robustness and accuracy of the proposed method. To\nshowcase its applicability to multi-physics systems of practical relevance, the\nfluid-structure interaction example of a vascular stent is presented.",
    "descriptor": "",
    "authors": [
      "Ivo Steinbrecher",
      "Nora Hagmeyer",
      "Christoph Meier",
      "Alexander Popp"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.16010"
  },
  {
    "id": "arXiv:2210.16011",
    "title": "UzbekStemmer: Development of a Rule-Based Stemming Algorithm for Uzbek  Language",
    "abstract": "In this paper we present a rule-based stemming algorithm for the Uzbek\nlanguage. Uzbek is an agglutinative language, so many words are formed by\nadding suffixes, and the number of suffixes is also large. For this reason, it\nis difficult to find a stem of words. The methodology is proposed for doing the\nstemming of the Uzbek words with an affix stripping approach whereas not\nincluding any database of the normal word forms of the Uzbek language. Word\naffixes are classified into fifteen classes and designed as finite state\nmachines (FSMs) for each class according to morphological rules. We created\nfifteen FSMs and linked them together to create the Basic FSM. A lexicon of\naffixes in XML format was created and a stemming application for Uzbek words\nhas been developed based on the FSMs.",
    "descriptor": "\nComments: Preprint of the paper to be published at The International Conference and Workshop on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP), June 6, 2022, Koper, Slovenia\n",
    "authors": [
      "Maksud Sharipov",
      "Ollabergan Yuldashov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16011"
  },
  {
    "id": "arXiv:2210.16016",
    "title": "Data-driven discovery of Green's functions",
    "abstract": "Discovering hidden partial differential equations (PDEs) and operators from\ndata is an important topic at the frontier between machine learning and\nnumerical analysis. This doctoral thesis introduces theoretical results and\ndeep learning algorithms to learn Green's functions associated with linear\npartial differential equations and rigorously justify PDE learning techniques.\nA theoretically rigorous algorithm is derived to obtain a learning rate, which\ncharacterizes the amount of training data needed to approximately learn Green's\nfunctions associated with elliptic PDEs. The construction connects the fields\nof PDE learning and numerical linear algebra by extending the randomized\nsingular value decomposition to non-standard Gaussian vectors and\nHilbert--Schmidt operators, and exploiting the low-rank hierarchical structure\nof Green's functions using hierarchical matrices. Rational neural networks\n(NNs) are introduced and consist of neural networks with trainable rational\nactivation functions. The highly compositional structure of these networks,\ncombined with rational approximation theory, implies that rational functions\nhave higher approximation power than standard activation functions. In\naddition, rational NNs may have poles and take arbitrarily large values, which\nis ideal for approximating functions with singularities such as Green's\nfunctions. Finally, theoretical results on Green's functions and rational NNs\nare combined to design a human-understandable deep learning method for\ndiscovering Green's functions from data. This approach complements\nstate-of-the-art PDE learning techniques, as a wide range of physics can be\ncaptured from the learned Green's functions such as dominant modes, symmetries,\nand singularity locations.",
    "descriptor": "\nComments: Doctoral thesis, Mathematical Institute, University of Oxford. 160 pages\n",
    "authors": [
      "Nicolas Boull\u00e9"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16016"
  },
  {
    "id": "arXiv:2210.16017",
    "title": "Upwind-SAV approach for constructing bound-preserving and energy-stable  schemes of the Cahn-Hilliard equation with degenerate mobility",
    "abstract": "This paper establishes an unconditionally bound-preserving and energy-stable\nscheme for the Cahn-Hilliard equation with degenerate mobility. More\nspecifically, by applying a finite volume method (FVM) with up-wind numerical\nfluxes to the degenerate Cahn-Hilliard equation rewritten by the scalar\nauxiliary variable (SAV) approach, we obtain an unconditionally\nbound-preserving, energy-stable and fully-discrete scheme, which, for the first\ntime, addresses the boundedness of the classical SAV approach under\nH^{-1}-gradient flow. Furthermore, the dimensional-splitting technique is\nintroduced in high-dimensional spaces, which greatly reduces the computational\ncomplexity while preserving original structural properties. Several numerical\nexperiments are presented to verify the bound-preserving and energy-stable\nproperties of the proposed scheme. Moreover, by applying the scheme to the\nmoving interface problem, we have numerically demonstrated that surface\ndiffusion can be modeled by the Cahn-Hilliard equation with degenerate mobility\nand Flory-Huggins potential at low temperature, which was only shown\ntheoretically by formal matched asymptotics.",
    "descriptor": "",
    "authors": [
      "Qiong-Ao Huang",
      "Wei Jiang",
      "Jerry Zhijian Yang",
      "Cheng Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.16017"
  },
  {
    "id": "arXiv:2210.16018",
    "title": "Code4ML: a Large-scale Dataset of annotated Machine Learning Code",
    "abstract": "Program code as a data source is gaining popularity in the data science\ncommunity. Possible applications for models trained on such assets range from\nclassification for data dimensionality reduction to automatic code generation.\nHowever, without annotation number of methods that could be applied is somewhat\nlimited. To address the lack of annotated datasets, we present the Code4ML\ncorpus. It contains code snippets, task summaries, competitions and dataset\ndescriptions publicly available from Kaggle - the leading platform for hosting\ndata science competitions. The corpus consists of ~2.5 million snippets of ML\ncode collected from ~100 thousand Jupyter notebooks. A representative fraction\nof the snippets is annotated by human assessors through a user-friendly\ninterface specially designed for that purpose. Code4ML dataset can potentially\nhelp address a number of software engineering or data science challenges\nthrough a data-driven approach. For example, it can be helpful for semantic\ncode classification, code auto-completion, and code generation for an ML task\nspecified in natural language.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Anastasia Drozdova",
      "Polina Guseva",
      "Ekaterina Trofimova",
      "Anna Scherbakova",
      "Andrey Ustyuzhanin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16018"
  },
  {
    "id": "arXiv:2210.16023",
    "title": "LegoNet: A Fast and Exact Unlearning Architecture",
    "abstract": "Machine unlearning aims to erase the impact of specific training samples upon\ndeleted requests from a trained model. Re-training the model on the retained\ndata after deletion is an effective but not efficient way due to the huge\nnumber of model parameters and re-training samples. To speed up, a natural way\nis to reduce such parameters and samples. However, such a strategy typically\nleads to a loss in model performance, which poses the challenge that increasing\nthe unlearning efficiency while maintaining acceptable performance. In this\npaper, we present a novel network, namely \\textit{LegoNet}, which adopts the\nframework of ``fixed encoder + multiple adapters''. We fix the encoder~(\\ie the\nbackbone for representation learning) of LegoNet to reduce the parameters that\nneed to be re-trained during unlearning. Since the encoder occupies a major\npart of the model parameters, the unlearning efficiency is significantly\nimproved. However, fixing the encoder empirically leads to a significant\nperformance drop. To compensate for the performance loss, we adopt the ensemble\nof multiple adapters, which are independent sub-models adopted to infer the\nprediction by the encoding~(\\ie the output of the encoder). Furthermore, we\ndesign an activation mechanism for the adapters to further trade off unlearning\nefficiency against model performance. This mechanism guarantees that each\nsample can only impact very few adapters, so during unlearning, parameters and\nsamples that need to be re-trained are both reduced. The empirical experiments\nverify that LegoNet accomplishes fast and exact unlearning while maintaining\nacceptable performance, synthetically outperforming unlearning baselines.",
    "descriptor": "",
    "authors": [
      "Sihao Yu",
      "Fei Sun",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16023"
  },
  {
    "id": "arXiv:2210.16024",
    "title": "Addressing Bias in Face Detectors using Decentralised Data collection  with incentives",
    "abstract": "Recent developments in machine learning have shown that successful models do\nnot rely only on huge amounts of data but the right kind of data. We show in\nthis paper how this data-centric approach can be facilitated in a decentralized\nmanner to enable efficient data collection for algorithms. Face detectors are a\nclass of models that suffer heavily from bias issues as they have to work on a\nlarge variety of different data. We also propose a face detection and\nanonymization approach using a hybrid MultiTask Cascaded CNN with FaceNet\nEmbeddings to benchmark multiple datasets to describe and evaluate the bias in\nthe models towards different ethnicities, gender, and age groups along with\nways to enrich fairness in a decentralized system of data labeling, correction,\nand verification by users to create a robust pipeline for model retraining.",
    "descriptor": "\nComments: 8 pages. Accepted at NeurIPS 2022 Workshop on Decentralization & Trustworthy Machine Learning in Web3\n",
    "authors": [
      "M. R. Ahan",
      "Robin Lehmann",
      "Richard Blythman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16024"
  },
  {
    "id": "arXiv:2210.16025",
    "title": "Ultra-fast, programmable, and electronics-free soft robots enabled by  snapping metacaps",
    "abstract": "Soft robots have a myriad of potentials because of their intrinsically\ncompliant bodies, enabling safe interactions with humans and adaptability to\nunpredictable environments. However, most of them have limited actuation\nspeeds, require complex control systems, and lack sensing capabilities. To\naddress these challenges, here we geometrically design a class of metacaps\nwhose rich nonlinear mechanical behaviors can be harnessed to create soft\nrobots with unprecedented functionalities. Specifically, we demonstrate a\nsensor-less metacap gripper that can grasp objects in 3.75 ms upon physical\ncontact and a pneumatically actuated gripper with tunable actuation behaviors\nthat have little dependence on the rate of input. Both grippers can be readily\nintegrated into a robotic platform for practical applications. Furthermore, we\ndemonstrate that the metacap enables propelling of a swimming robot, exhibiting\namplified swimming speed as well as untethered, electronics-free swimming with\ntunable speeds. Our metacaps provide new strategies to design the\nnext-generation soft robots that require high transient output energy and are\ncapable of autonomous and electronics-free maneuvering.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Lishuai Jin",
      "Yueying Yang",
      "Bryan O. Torres Maldonado",
      "Sebastian David Lee",
      "Nadia Figueroa",
      "Robert J. Full",
      "Shu Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Soft Condensed Matter (cond-mat.soft)"
    ],
    "url": "https://arxiv.org/abs/2210.16025"
  },
  {
    "id": "arXiv:2210.16027",
    "title": "HaptiX: Extending Cobot's Motion Intention Visualization by Haptic  Feedback",
    "abstract": "Nowadays, robots are found in a growing number of areas where they\ncollaborate closely with humans. Enabled by lightweight materials and safety\nsensors, these cobots are gaining increasing popularity in domestic care,\nsupporting people with physical impairments in their everyday lives. However,\nwhen cobots perform actions autonomously, it remains challenging for human\ncollaborators to understand and predict their behavior, which is crucial for\nachieving trust and user acceptance. One significant aspect of predicting cobot\nbehavior is understanding their motion intention and comprehending how they\n\"think\" about their actions. Moreover, other information sources often occupy\nhuman visual and audio modalities, rendering them frequently unsuitable for\ntransmitting such information. We work on a solution that communicates cobot\nintention via haptic feedback to tackle this challenge. In our concept, we map\nplanned motions of the cobot to different haptic patterns to extend the visual\nintention feedback.",
    "descriptor": "",
    "authors": [
      "Max Pascher",
      "Til Franzen",
      "Kirill Kronhardt",
      "Jens Gerken"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16027"
  },
  {
    "id": "arXiv:2210.16029",
    "title": "Assessing Phrase Break of ESL speech with Pre-trained Language Models",
    "abstract": "This work introduces an approach to assessing phrase break in ESL learners'\nspeech with pre-trained language models (PLMs). Different with traditional\nmethods, this proposal converts speech to token sequences, and then leverages\nthe power of PLMs. There are two sub-tasks: overall assessment of phrase break\nfor a speech clip; fine-grained assessment of every possible phrase break\nposition. Speech input is first force-aligned with texts, then pre-processed to\na token sequence, including words and associated phrase break information. The\ntoken sequence is then fed into the pre-training and fine-tuning pipeline. In\npre-training, a replaced break token detection module is trained with token\ndata where each token has a certain percentage chance to be randomly replaced.\nIn fine-tuning, overall and fine-grained scoring are optimized with text\nclassification and sequence labeling pipeline, respectively. With the\nintroduction of PLMs, the dependence on labeled training data has been greatly\nreduced, and performance has improved.",
    "descriptor": "\nComments: Under Review, ICASSP 2023\n",
    "authors": [
      "Zhiyi Wang",
      "Shaoguang Mao",
      "Wenshan Wu",
      "Yan Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16029"
  },
  {
    "id": "arXiv:2210.16031",
    "title": "UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal  Guidance",
    "abstract": "Diffusion generative models have recently greatly improved the power of\ntext-conditioned image generation. Existing image generation models mainly\ninclude text conditional diffusion model and cross-modal guided diffusion\nmodel, which are good at small scene image generation and complex scene image\ngeneration respectively. In this work, we propose a simple yet effective\napproach, namely UPainting, to unify simple and complex scene image generation,\nas shown in Figure~\\ref{fig:leading_samples}. Based on architecture\nimprovements and diverse guidance schedules, UPainting effectively integrates\ncross-modal guidance from a pretrained image-text matching model into a text\nconditional diffusion model that utilizes a pretrained Transformer language\nmodel as the text encoder. Our key findings is that combining the power of\nlarge-scale Transformer language model in understanding language and image-text\nmatching model in capturing cross-modal semantics and style, is effective to\nimprove sample fidelity and image-text alignment of image generation. In this\nway, UPainting has a more general image generation capability, which can\ngenerate images of both simple and complex scenes more effectively. %On the\nCOCO dataset, UPainting achieves much better performance than Stable Diffusion,\none of the state-of-the-art text-to-image diffusion models. To comprehensively\ncompare text-to-image models, we further create a more general benchmark,\nUniBench, with well-written Chinese and English prompts in both simple and\ncomplex scenes. We compare UPainting with recent models and find that UPainting\ngreatly outperforms other models in terms of caption similarity and image\nfidelity in both simple and complex scenes.",
    "descriptor": "\nComments: First Version, 16 pages\n",
    "authors": [
      "Wei Li",
      "Xue Xu",
      "Xinyan Xiao",
      "Jiachen Liu",
      "Hu Yang",
      "Guohao Li",
      "Zhanpeng Wang",
      "Zhifan Feng",
      "Qiaoqiao She",
      "Yajuan Lyu",
      "Hua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16031"
  },
  {
    "id": "arXiv:2210.16033",
    "title": "Improving Multi-class Classifier Using Likelihood Ratio Estimation with  Regularization",
    "abstract": "The universal-set naive Bayes classifier (UNB)~\\cite{Komiya:13}, defined\nusing likelihood ratios (LRs), was proposed to address imbalanced\nclassification problems. However, the LR estimator used in the UNB\noverestimates LRs for low-frequency data, degrading the classification\nperformance. Our previous study~\\cite{Kikuchi:19} proposed an effective LR\nestimator even for low-frequency data. This estimator uses regularization to\nsuppress the overestimation, but we did not consider imbalanced data. In this\npaper, we integrated the estimator with the UNB. Our experiments with\nimbalanced data showed that our proposed classifier effectively adjusts the\nclassification scores according to the class balance using regularization\nparameters and improves the classification performance.",
    "descriptor": "\nComments: The 9th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2022)\n",
    "authors": [
      "Masato Kikuchi",
      "Tadachika Ozono"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16033"
  },
  {
    "id": "arXiv:2210.16034",
    "title": "A Survey on Causal Representation Learning and Future Work for Medical  Image Analysis",
    "abstract": "Statistical machine learning algorithms have achieved state-of-the-art\nresults on benchmark datasets, outperforming humans in many tasks. However, the\nout-of-distribution data and confounder, which have an unpredictable causal\nrelationship, significantly degrade the performance of the existing models.\nCausal Representation Learning (CRL) has recently been a promising direction to\naddress the causal relationship problem in vision understanding. This survey\npresents recent advances in CRL in vision. Firstly, we introduce the basic\nconcept of causal inference. Secondly, we analyze the CRL theoretical work,\nespecially in invariant risk minimization, and the practical work in feature\nunderstanding and transfer learning. Finally, we propose a future research\ndirection in medical image analysis and CRL general theory.",
    "descriptor": "",
    "authors": [
      "Changjie Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16034"
  },
  {
    "id": "arXiv:2210.16038",
    "title": "Deep Learning-Based Anomaly Detection in Synthetic Aperture Radar  Imaging",
    "abstract": "In this paper, we proposed to investigate unsupervised anomaly detection in\nSynthetic Aperture Radar (SAR) images. Our approach considers anomalies as\nabnormal patterns that deviate from their surroundings but without any prior\nknowledge of their characteristics. In the literature, most model-based\nalgorithms face three main issues. First, the speckle noise corrupts the image\nand potentially leads to numerous false detections. Second, statistical\napproaches may exhibit deficiencies in modeling spatial correlation in SAR\nimages. Finally, neural networks based on supervised learning approaches are\nnot recommended due to the lack of annotated SAR data, notably for the class of\nabnormal patterns. Our proposed method aims to address these issues through a\nself-supervised algorithm. The speckle is first removed through the deep\nlearning SAR2SAR algorithm. Then, an adversarial autoencoder is trained to\nreconstruct an anomaly-free SAR image. Finally, a change detection processing\nstep is applied between the input and the output to detect anomalies.\nExperiments are performed to show the advantages of our method compared to the\nconventional Reed-Xiaoli algorithm, highlighting the importance of an efficient\ndespeckling pre-processing step.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Max Muzeau",
      "Chengfang Ren",
      "S\u00e9bastien Angelliaume",
      "Mihai Datcu",
      "Jean-Philippe Ovarlez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16038"
  },
  {
    "id": "arXiv:2210.16040",
    "title": "Review on Classification Techniques used in Biophysiological Stress  Monitoring",
    "abstract": "Cardiovascular activities are directly related to the response of a body in a\nstressed condition. Stress, based on its intensity, can be divided into two\ntypes i.e. Acute stress (short-term stress) and Chronic stress (long-term\nstress). Repeated acute stress and continuous chronic stress may play a vital\nrole in inflammation in the circulatory system and thus leads to a heart attack\nor to a stroke. In this study, we have reviewed commonly used machine learning\nclassification techniques applied to different stress-indicating parameters\nused in stress monitoring devices. These parameters include Photoplethysmograph\n(PPG), Electrocardiographs (ECG), Electromyograph (EMG), Galvanic Skin Response\n(GSR), Heart Rate Variation (HRV), skin temperature, respiratory rate,\nElectroencephalograph (EEG) and salivary cortisol, used in stress monitoring\ndevices. This study also provides a discussion on choosing a classifier, which\ndepends upon a number of factors other than accuracy, like the number of\nsubjects involved in an experiment, type of signals processing and\ncomputational limitations.",
    "descriptor": "\nComments: 17 pages, 17 figures, 1 table\n",
    "authors": [
      "Talha Iqbal",
      "Adnan Elahi",
      "Atif Shahzad",
      "William Wijns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16040"
  },
  {
    "id": "arXiv:2210.16041",
    "title": "Centralization Problem for Opinion Convergence in Decentralized Networks",
    "abstract": "This paper aims to provide a new perspective on the interplay between\ndecentralization -- a prevalent character of multi-agent systems -- and\ncentralization, i.e., the task of imposing central control to meet system-level\ngoals. In particular, in the context of networked opinion dynamic model, the\npaper proposes and discusses a framework for centralization. More precisely, a\ndecentralized network consists of autonomous agents and their social structure\nthat is unknown and dynamic. Centralization is a process of appointing agents\nin the network to act as access units who provide information and exert\ninfluence over their local surroundings. We discuss centralization for the\nDeGroot model of opinion dynamics, aiming to enforce opinion convergence using\nthe minimum number of access units. We show that the key to the centralization\nprocess lies in selecting access units so that they form a dominating set. We\nthen propose algorithms under a new local algorithmic framework, namely\nprowling, to accomplish this task. To validate our algorithm, we perform\nsystematic experiments over both real-world and synthetic networks and verify\nthat our algorithm outperforms benchmarks.",
    "descriptor": "",
    "authors": [
      "Yiping Liu",
      "Jiamou Liu",
      "Bakhadyr Khoussaino",
      "Miao Qiao",
      "Bo Yan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.16041"
  },
  {
    "id": "arXiv:2210.16043",
    "title": "Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised  Speech Models",
    "abstract": "Given the strong results of self-supervised models on various tasks, there\nhave been surprisingly few studies exploring self-supervised representations\nfor acoustic word embeddings (AWE), fixed-dimensional vectors representing\nvariable-length spoken word segments. In this work, we study several\npre-trained models and pooling methods for constructing AWEs with\nself-supervised representations. Owing to the contextualized nature of\nself-supervised representations, we hypothesize that simple pooling methods,\nsuch as averaging, might already be useful for constructing AWEs. When\nevaluating on a standard word discrimination task, we find that HuBERT\nrepresentations with mean-pooling rival the state of the art on English AWEs.\nMore surprisingly, despite being trained only on English, HuBERT\nrepresentations evaluated on Xitsonga, Mandarin, and French consistently\noutperform the multilingual model XLSR-53 (as well as Wav2Vec 2.0 trained on\nEnglish).",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Ramon Sanabria",
      "Hao Tang",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16043"
  },
  {
    "id": "arXiv:2210.16045",
    "title": "Towards zero-shot Text-based voice editing using acoustic context  conditioning, utterance embeddings, and reference encoders",
    "abstract": "Text-based voice editing (TBVE) uses synthetic output from text-to-speech\n(TTS) systems to replace words in an original recording. Recent work has used\nneural models to produce edited speech that is similar to the original speech\nin terms of clarity, speaker identity, and prosody. However, one limitation of\nprior work is the usage of finetuning to optimise performance: this requires\nfurther model training on data from the target speaker, which is a costly\nprocess that may incorporate potentially sensitive data into server-side\nmodels. In contrast, this work focuses on the zero-shot approach which avoids\nfinetuning altogether, and instead uses pretrained speaker verification\nembeddings together with a jointly trained reference encoder to encode\nutterance-level information that helps capture aspects such as speaker identity\nand prosody. Subjective listening tests find that both utterance embeddings and\na reference encoder improve the continuity of speaker identity and prosody\nbetween the edited synthetic speech and unedited original recording in the\nzero-shot setting.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jason Fong",
      "Yun Wang",
      "Prabhav Agrawal",
      "Vimal Manohar",
      "Jilong Wu",
      "Thilo K\u00f6hler",
      "Qing He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16045"
  },
  {
    "id": "arXiv:2210.16046",
    "title": "Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide  Variety of Environments",
    "abstract": "Image recognition models that can work in challenging environments (e.g.,\nextremely dark, blurry, or high dynamic range conditions) must be useful.\nHowever, creating a training dataset for such environments is expensive and\nhard due to the difficulties of data collection and annotation. It is desirable\nif we could get a robust model without the need of hard-to-obtain dataset. One\nsimple approach is to apply data augmentation such as color jitter and blur to\nstandard RGB (sRGB) images in simple scenes. Unfortunately, this approach\nstruggles to yield realistic images in terms of pixel intensity and noise\ndistribution due to not considering the non-linearity of Image Signal Processor\n(ISP) and noise characteristics of an image sensor. Instead, we propose a\nnoise-accounted RAW image augmentation method. In essence, color jitter and\nblur augmentation are applied to a RAW image before applying non-linear ISP,\nyielding realistic intensity. Furthermore, we introduce a noise amount\nalignment method that calibrates the domain gap in noise property caused by the\naugmentation. We show that our proposed noise-accounted RAW augmentation method\ndoubles the image recognition accuracy in challenging environments only with\nsimple training data.",
    "descriptor": "",
    "authors": [
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Atsushi Irie",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.16046"
  },
  {
    "id": "arXiv:2210.16049",
    "title": "Measuring the Confidence of Traffic Forecasting Models: Techniques,  Experimental Comparison and Guidelines towards Their Actionability",
    "abstract": "The estimation of the amount of uncertainty featured by predictive machine\nlearning models has acquired a great momentum in recent years. Uncertainty\nestimation provides the user with augmented information about the model's\nconfidence in its predicted outcome. Despite the inherent utility of this\ninformation for the trustworthiness of the user, there is a thin consensus\naround the different types of uncertainty that one can gauge in machine\nlearning models and the suitability of different techniques that can be used to\nquantify the uncertainty of a specific model. This subject is mostly non\nexistent within the traffic modeling domain, even though the measurement of the\nconfidence associated to traffic forecasts can favor significantly their\nactionability in practical traffic management systems. This work aims to cover\nthis lack of research by reviewing different techniques and metrics of\nuncertainty available in the literature, and by critically discussing how\nconfidence levels computed for traffic forecasting models can be helpful for\nresearchers and practitioners working in this research area. To shed light with\nempirical evidence, this critical discussion is further informed by\nexperimental results produced by different uncertainty estimation techniques\nover real traffic data collected in Madrid (Spain), rendering a general\noverview of the benefits and caveats of every technique, how they can be\ncompared to each other, and how the measured uncertainty decreases depending on\nthe amount, quality and diversity of data used to produce the forecasts.",
    "descriptor": "\nComments: 46 pages, 12 figures, under review\n",
    "authors": [
      "Ibai La\u00f1a",
      "Ignacio",
      "Olabarrieta",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16049"
  },
  {
    "id": "arXiv:2210.16050",
    "title": "Link Climate: An Interoperable Knowledge Graph Platform for Climate Data",
    "abstract": "Climate science has become more ambitious in recent years as global awareness\nabout the environment has grown. To better understand climate, historical\nclimate (e.g. archived meteorological variables such as temperature, wind,\nwater, etc.) and climate-related data (e.g. geographical features and human\nactivities) are widely used by today's climate research to derive models for an\nexplainable climate change and its effects. However, such data sources are\noften dispersed across a multitude of disconnected data silos on the Web.\nMoreover, there is a lack of advanced climate data platforms to enable\nmulti-source heterogeneous climate data analysis, therefore, researchers must\nface a stern challenge in collecting and analyzing multi-source data. In this\npaper, we address this problem by proposing a climate knowledge graph for the\nintegration of multiple climate data and other data sources into one service,\nleveraging Web technologies (e.g. HTTP) for multi-source climate data analysis.\nThe proposed knowledge graph is primarily composed of data from the National\nOceanic and Atmospheric Administration's daily climate summaries,\nOpenStreetMap, and Wikidata, and it supports joint data queries on these widely\nused databases. This paper shows, with a use case in Ireland and the United\nKingdom, how climate researchers could benefit from this platform as it allows\nthem to easily integrate datasets from different domains and geographical\nlocations.",
    "descriptor": "\nComments: Published in Computers and Geosciences, 2022\n",
    "authors": [
      "Jiantao Wu",
      "Fabrizio Orlandi",
      "Declan O'Sullivan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.16050"
  },
  {
    "id": "arXiv:2210.16051",
    "title": "Fuzzy Logic Model for Predicting the Heat Index",
    "abstract": "A fuzzy inference system was developed for predicting the heat index from\ntemperature and relative humidity data. The effectiveness of fuzzy logic in\nusing imprecise mapping of input to output to encode interconnectedness of\nsystem variables was exploited to uncover a linguistic model of how the\ntemperature and humidity conditions impact the heat index in a growth room. The\ndeveloped model achieved an R2 of 0.974 and a RMSE of 0.084 when evaluated on a\ntest set, and the results were statistically significant (F1,5915 = 222900.858,\np < 0.001). By providing the advantage of linguistic summarization of data\ntrends as well as high prediction accuracy, the fuzzy logic model proved to be\nan effective machine learning method for heat control problems.",
    "descriptor": "\nComments: 15 pages, 5 figures, 6 tables\n",
    "authors": [
      "Nnamdi Uzoukwu",
      "Acep Purqon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16051"
  },
  {
    "id": "arXiv:2210.16056",
    "title": "MagicMix: Semantic Mixing with Diffusion Models",
    "abstract": "Have you ever imagined what a corgi-alike coffee machine or a tiger-alike\nrabbit would look like? In this work, we attempt to answer these questions by\nexploring a new task called semantic mixing, aiming at blending two different\nsemantics to create a new concept (e.g., corgi + coffee machine -- >\ncorgi-alike coffee machine). Unlike style transfer, where an image is stylized\naccording to the reference style without changing the image content, semantic\nblending mixes two different concepts in a semantic manner to synthesize a\nnovel concept while preserving the spatial layout and geometry. To this end, we\npresent MagicMix, a simple yet effective solution based on pre-trained\ntext-conditioned diffusion models. Motivated by the progressive generation\nproperty of diffusion models where layout/shape emerges at early denoising\nsteps while semantically meaningful details appear at later steps during the\ndenoising process, our method first obtains a coarse layout (either by\ncorrupting an image or denoising from a pure Gaussian noise given a text\nprompt), followed by injection of conditional prompt for semantic mixing. Our\nmethod does not require any spatial mask or re-training, yet is able to\nsynthesize novel objects with high fidelity. To improve the mixing quality, we\nfurther devise two simple strategies to provide better control and flexibility\nover the synthesized content. With our method, we present our results over\ndiverse downstream applications, including semantic style transfer, novel\nobject synthesis, breed mixing, and concept removal, demonstrating the\nflexibility of our method. More results can be found on the project page\nhttps://magicmix.github.io",
    "descriptor": "",
    "authors": [
      "Jun Hao Liew",
      "Hanshu Yan",
      "Daquan Zhou",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16056"
  },
  {
    "id": "arXiv:2210.16057",
    "title": "Semi-UFormer: Semi-supervised Uncertainty-aware Transformer for Image  Dehazing",
    "abstract": "Image dehazing is fundamental yet not well-solved in computer vision. Most\ncutting-edge models are trained in synthetic data, leading to the poor\nperformance on real-world hazy scenarios. Besides, they commonly give\ndeterministic dehazed images while neglecting to mine their uncertainty. To\nbridge the domain gap and enhance the dehazing performance, we propose a novel\nsemi-supervised uncertainty-aware transformer network, called Semi-UFormer.\nSemi-UFormer can well leverage both the real-world hazy images and their\nuncertainty guidance information. Specifically, Semi-UFormer builds itself on\nthe knowledge distillation framework. Such teacher-student networks effectively\nabsorb real-world haze information for quality dehazing. Furthermore, an\nuncertainty estimation block is introduced into the model to estimate the pixel\nuncertainty representations, which is then used as a guidance signal to help\nthe student network produce haze-free images more accurately. Extensive\nexperiments demonstrate that Semi-UFormer generalizes well from synthetic to\nreal-world images.",
    "descriptor": "",
    "authors": [
      "Ming Tong",
      "Yongzhen Wang",
      "Peng Cui",
      "Xuefeng Yan",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16057"
  },
  {
    "id": "arXiv:2210.16058",
    "title": "Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward  Long-Horizon Goal-Conditioned Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) often struggles to accomplish a sparse-reward\nlong-horizon task in a complex environment. Goal-conditioned reinforcement\nlearning (GCRL) has been employed to tackle this difficult problem via a\ncurriculum of easy-to-reach sub-goals. In GCRL, exploring novel sub-goals is\nessential for the agent to ultimately find the pathway to the desired goal. How\nto explore novel sub-goals efficiently is one of the most challenging issues in\nGCRL. Several goal exploration methods have been proposed to address this issue\nbut still struggle to find the desired goals efficiently. In this paper, we\npropose a novel learning objective by optimizing the entropy of both achieved\nand new goals to be explored for more efficient goal exploration in sub-goal\nselection based GCRL. To optimize this objective, we first explore and exploit\nthe frequently occurring goal-transition patterns mined in the environments\nsimilar to the current task to compose skills via skill learning. Then, the\npretrained skills are applied in goal exploration. Evaluation on a variety of\nspare-reward long-horizon benchmark tasks suggests that incorporating our\nmethod into several state-of-the-art GCRL baselines significantly boosts their\nexploration efficiency while improving or maintaining their performance. The\nsource code is available at: https://github.com/GEAPS/GEAPS.",
    "descriptor": "\nComments: Technical Report (submitted to a journal for publication): 10 pages, 17 figures\n",
    "authors": [
      "Lisheng Wu",
      "Ke Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16058"
  },
  {
    "id": "arXiv:2210.16059",
    "title": "An Artificial Intelligence driven Learning Analytics Method to Examine  the Collaborative Problem solving Process from a Complex Adaptive Systems  Perspective",
    "abstract": "Collaborative problem solving (CPS) enables student groups to complete\nlearning tasks, construct knowledge, and solve problems. Previous research has\nargued the importance to examine the complexity of CPS, including its\nmultimodality, dynamics, and synergy from the complex adaptive systems\nperspective. However, there is limited empirical research examining the\nadaptive and temporal characteristics of CPS which might lead to an\noversimplified representation of the real complexity of the CPS process. To\nfurther understand the nature of CPS in online interaction settings, this\nresearch collected multimodal process and performance data (i.e., verbal\naudios, computer screen recordings, concept map data) and proposed a\nthree-layered analytical framework that integrated AI algorithms with learning\nanalytics to analyze the regularity of groups collaboration patterns. The\nresults detected three types of collaborative patterns in groups, namely the\nbehaviour-oriented collaborative pattern (Type 1) associated with medium-level\nperformance, the communication - behaviour - synergistic collaborative pattern\n(Type 2) associated with high-level performance, and the communication-oriented\ncollaborative pattern (Type 3) associated with low-level performance. The\nresearch further highlighted the multimodal, dynamic, and synergistic\ncharacteristics of groups collaborative patterns to explain the emergence of an\nadaptive, self-organizing system during the CPS process.",
    "descriptor": "\nComments: 27 pages, 8 Figures, Accepted to appear in the International Journal of Computer-Supported Collaborative Learning\n",
    "authors": [
      "Fan Ouyang",
      "Weiqi Xu",
      "Mutlu Cukurova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.16059"
  },
  {
    "id": "arXiv:2210.16063",
    "title": "Defense Against Smart Invaders with Swarms of Sweeping Agents",
    "abstract": "The goal of this research is to devise guaranteed defense policies that allow\nto protect a given region from the entrance of smart mobile invaders by\ndetecting them using a team of defending agents equipped with identical line\nsensors. By designing cooperative defense strategies that ensure all invaders\nare detected, conditions on the defenders' speed are derived. Successful\naccomplishment of the defense task implies invaders with a known limit on their\nspeed cannot slip past the defenders and enter the guarded region undetected.\nThe desired outcome of the defense protocols is to defend the area and\nadditionally to expand it as much as possible. Expansion becomes possible if\nthe defenders' speed exceeds a critical speed that is necessary to only defend\nthe initial region. We present results on the total search time, critical\nspeeds and maximal expansion possible for two types of novel pincer-movement\ndefense processes, circular and spiral, for any even number of defenders. The\nproposed spiral process allows to detect invaders at nearly the lowest\ntheoretically optimal speed, and if this speed is exceeded, it also allows to\nexpand the protected region almost to the maximal area.",
    "descriptor": "\nComments: 18 pages, 21 figures\n",
    "authors": [
      "Roee M. Francos",
      "Alfred M. Bruckstein"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.16063"
  },
  {
    "id": "arXiv:2210.16064",
    "title": "DORE: Document Ordered Relation Extraction based on Generative Framework",
    "abstract": "In recent years, there is a surge of generation-based information extraction\nwork, which allows a more direct use of pre-trained language models and\nefficiently captures output dependencies. However, previous generative methods\nusing lexical representation do not naturally fit document-level relation\nextraction (DocRE) where there are multiple entities and relational facts. In\nthis paper, we investigate the root cause of the underwhelming performance of\nthe existing generative DocRE models and discover that the culprit is the\ninadequacy of the training paradigm, instead of the capacities of the models.\nWe propose to generate a symbolic and ordered sequence from the relation matrix\nwhich is deterministic and easier for model to learn. Moreover, we design a\nparallel row generation method to process overlong target sequences. Besides,\nwe introduce several negative sampling strategies to improve the performance\nwith balanced signals. Experimental results on four datasets show that our\nproposed method can improve the performance of the generative DocRE models. We\nhave released our code at https://github.com/ayyyq/DORE.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Qipeng Guo",
      "Yuqing Yang",
      "Hang Yan",
      "Xipeng Qiu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16064"
  },
  {
    "id": "arXiv:2210.16065",
    "title": "Polarization and reliability of news sources in Wikipedia",
    "abstract": "Wikipedia is the largest online encyclopedia: its open contribution policy\nallows everyone to edit and share their knowledge. A challenge of radical\nopenness is that it facilitates introducing biased contents or perspectives in\nWikipedia. Wikipedia relies on numerous external sources such as journal\narticles, books, news media, and more. News media sources, in particular, take\nup nearly third of all citations from Wikipedia. However, despite their\nimportance for providing up-to-date and factual contents, there is still a\nlimited understanding on which news media sources are cited from Wikipedia.\nRelying on a large-scale open dataset of nearly 30M citations from English\nWikipedia, we find a moderate yet systematic liberal polarization in the\nselection of news media sources. We also show that this effect is not mitigated\nby controlling for news media factual reliability. Our results contribute to\nWikipedia's knowledge integrity agenda in suggesting that a systematic effort\nwould help to better map potential biases in Wikipedia and find means to\nstrengthen its neutral point of view policy.",
    "descriptor": "\nComments: 15pages, 10 figures\n",
    "authors": [
      "Puyu Yang",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.16065"
  },
  {
    "id": "arXiv:2210.16068",
    "title": "Using Supervised Deep-Learning to Model Edge-FBG Shape Sensors",
    "abstract": "Continuum robots in robot-assisted minimally invasive surgeries provide\nadequate access to target anatomies that are not directly reachable through\nsmall incisions. Achieving precise and reliable motion control of such\nsnake-like manipulators necessitates an accurate navigation system that\nrequires no line-of-sight and is immune to electromagnetic noises. Fiber Bragg\nGrating (FBG) shape sensors, particularly edge-FBGs, are promising tools for\nthis task. However, in edge-FBG sensors, the intensity ratio between Bragg\nwavelengths carries the strain information that can be affected by undesired\nbending-related phenomena, making standard characterization techniques less\nsuitable for these sensors. We showed in our previous work that a deep learning\nmodel has the potential to extract the strain information from the full\nedge-FBG spectrum and accurately predict the sensor's shape. In this paper, we\nconduct a more thorough investigation to find a suitable architectural design\nwith lower prediction errors. We use the Hyperband algorithm to search for\noptimal hyperparameters in two steps. First, we limit the search space to layer\nsettings, where the best-performing configuration gets selected. Then, we\nmodify the search space for tuning the training and loss calculation\nhyperparameters. We also analyze various data transformations on the input and\noutput variables, as data rescaling can directly influence the model's\nperformance. Moreover, we performed discriminative training using Siamese\nnetwork architecture that employs two CNNs with identical parameters to learn\nsimilarity metrics between the spectra of similar target values. The\nbest-performing network architecture among all evaluated configurations can\npredict the sensor's shape with a median tip error of 3.11 mm.",
    "descriptor": "\nComments: 26 pages, 11 figures, preprint\n",
    "authors": [
      "Samaneh Manavi Roodsari",
      "Antal Huck-Horvath",
      "Sara Freund",
      "Azhar Zam",
      "Georg Rauter",
      "Wolfgang Schade",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16068"
  },
  {
    "id": "arXiv:2210.16070",
    "title": "Ethereum Proof-of-Stake under Scrutiny",
    "abstract": "Ethereum has undergone a recent change called \\textit{the Merge}, which made\nEthereum a Proof-of-Stake blockchain shifting closer to BFT consensus.\nEthereum, which wished to keep the best of the two protocols designs (BFT and\nNakomoto-style), now has an involved consensus protocol as its core. The result\nis a blockchain being possibly produced in a tree-like form while participants\ntry to finalize blocks. Several attacks jeopardizing liveness have been found\nin this new setting. The Ethereum community has responded by creating a patch.\nWe discovered a new attack on the patched protocol. To support our analysis, we\npropose a new formalization of the properties of liveness and availability of\nthe Ethereum blockchain, and we provide a pseudo-code. We believe this\nformalization to be helpful for other analyses as well. Our results yield that\nthe Ethereum Proof-of-Stake has probabilistic liveness, influenced by the\nparameter describing the time frame allowed for validators to change their mind\nabout the current main chain.",
    "descriptor": "",
    "authors": [
      "Ulysse Pavloff",
      "Yackolley Amoussou-Guenou",
      "Sara Tucci-Piergiovanni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.16070"
  },
  {
    "id": "arXiv:2210.16071",
    "title": "A Rosenbrock framework for tangential interpolation of port-Hamiltonian  descriptor systems",
    "abstract": "We present a new structure-preserving model order reduction (MOR) framework\nfor large-scale port-Hamiltonian descriptor systems (pH-DAEs). Our method\nexploits the structural properties of the Rosenbrock system matrix for this\nsystem class and utilizes condensed forms which often arise in applications and\nreveal the solution behaviour of a system. Provided that the original system\nhas such a form, our method produces reduced-order models (ROMs) of minimal\ndimension, which tangentially interpolate the original model's transfer\nfunction and are guaranteed to be again in pH-DAE form. This allows the ROM to\nbe safely coupled with other dynamical systems when modelling large system\nnetworks, which is useful, for instance, in electric circuit simulation.",
    "descriptor": "",
    "authors": [
      "Tim Moser",
      "Boris Lohmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.16071"
  },
  {
    "id": "arXiv:2210.16074",
    "title": "Improving Chest X-Ray Classification by RNN-based Patient Monitoring",
    "abstract": "Chest X-Ray imaging is one of the most common radiological tools for\ndetection of various pathologies related to the chest area and lung function.\nIn a clinical setting, automated assessment of chest radiographs has the\npotential of assisting physicians in their decision making process and optimize\nclinical workflows, for example by prioritizing emergency patients.\nMost work analyzing the potential of machine learning models to classify\nchest X-ray images focuses on vision methods processing and predicting\npathologies for one image at a time. However, many patients undergo such a\nprocedure multiple times during course of a treatment or during a single\nhospital stay. The patient history, that is previous images and especially the\ncorresponding diagnosis contain useful information that can aid a\nclassification system in its prediction.\nIn this study, we analyze how information about diagnosis can improve\nCNN-based image classification models by constructing a novel dataset from the\nwell studied CheXpert dataset of chest X-rays. We show that a model trained on\nadditional patient history information outperforms a model trained without the\ninformation by a significant margin.\nWe provide code to replicate the dataset creation and model training.",
    "descriptor": "\nComments: To be published in proceedings of IEEE International Conference on Machine Learning Applications IEEE ICMLA 2022\n",
    "authors": [
      "David Biesner",
      "Helen Schneider",
      "Benjamin Wulff",
      "Ulrike Attenberger",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16074"
  },
  {
    "id": "arXiv:2210.16075",
    "title": "Convergence of Hamiltonian Particle methods for Vlasov--Poisson  equations with a nonhomogeneous magnetic field",
    "abstract": "In this paper, we study the error analysis of Hamiltonian particle methods\nfor the magnetized Vlasov{Poisson equation. The convergence of particle method\nfor Vlasov equation and Hamiltonian method for particle equation is provided\nindependently. By combining them, we can conclude that the numerical solution\nconverges to the exact particle trajectories.",
    "descriptor": "",
    "authors": [
      "Anjiao Gu",
      "Yajuan Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.16075"
  },
  {
    "id": "arXiv:2210.16078",
    "title": "Adaptive Mask-based Pyramid Network for Realistic Bokeh Rendering",
    "abstract": "Bokeh effect highlights an object (or any part of the image) while blurring\nthe rest of the image, and creates a visually pleasant artistic effect. Due to\nthe sensor-based limitations on mobile devices, machine learning (ML) based\nbokeh rendering has gained attention as a reliable alternative. In this paper,\nwe focus on several improvements in ML-based bokeh rendering; i) on-device\nperformance with high-resolution images, ii) ability to guide bokeh generation\nwith user-editable masks and iii) ability to produce varying blur strength. To\nthis end, we propose Adaptive Mask-based Pyramid Network (AMPN), which is\nformed of a Mask-Guided Bokeh Generator (MGBG) block and a Laplacian Pyramid\nRefinement (LPR) block. MGBG consists of two lightweight networks stacked to\neach other to generate the bokeh effect, and LPR refines and upsamples the\noutput of MGBG to produce the high-resolution bokeh image. We achieve i) via\nour lightweight, mobile-friendly design choices, ii) via the stacked-network\ndesign of MGBG and the weakly-supervised mask prediction scheme and iii) via\nmanually or automatically editing the intensity values of the mask that guide\nthe bokeh generation. In addition to these features, our results show that AMPN\nproduces competitive or better results compared to existing methods on the EBB!\ndataset, while being faster and smaller than the alternatives.",
    "descriptor": "\nComments: ECCV 2022 Advances in Image Manipulation Workshop. See the workshop website for posters and recordings\n",
    "authors": [
      "Konstantinos Georgiadis",
      "Albert Sa\u00e0-Garriga",
      "Mehmet Kerim Yucel",
      "Anastasios Drosou",
      "Bruno Manganelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16078"
  },
  {
    "id": "arXiv:2210.16079",
    "title": "Debiasing Masks: A New Framework for Shortcut Mitigation in NLU",
    "abstract": "Debiasing language models from unwanted behaviors in Natural Language\nUnderstanding tasks is a topic with rapidly increasing interest in the NLP\ncommunity. Spurious statistical correlations in the data allow models to\nperform shortcuts and avoid uncovering more advanced and desirable linguistic\nfeatures. A multitude of effective debiasing approaches has been proposed, but\nflexibility remains a major issue. For the most part, models must be retrained\nto find a new set of weights with debiased behavior. We propose a new debiasing\nmethod in which we identify debiased pruning masks that can be applied to a\nfinetuned model. This enables the selective and conditional application of\ndebiasing behaviors. We assume that bias is caused by a certain subset of\nweights in the network; our method is, in essence, a mask search to identify\nand remove biased weights. Our masks show equivalent or superior performance to\nthe standard counterparts, while offering important benefits. Pruning masks can\nbe stored with high efficiency in memory, and it becomes possible to switch\namong several debiasing behaviors (or revert back to the original biased model)\nat inference time. Finally, it opens the doors to further research on how\nbiases are acquired by studying the generated masks. For example, we observed\nthat the early layers and attention heads were pruned more aggressively,\npossibly hinting towards the location in which biases may be encoded.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Johannes Mario Meissner",
      "Saku Sugawara",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16079"
  },
  {
    "id": "arXiv:2210.16080",
    "title": "RESUS: Warm-Up Cold Users via Meta-Learning Residual User Preferences in  CTR Prediction",
    "abstract": "Click-Through Rate (CTR) prediction on cold users is a challenging task in\nrecommender systems. Recent researches have resorted to meta-learning to tackle\nthe cold-user challenge, which either perform few-shot user representation\nlearning or adopt optimization-based meta-learning. However, existing methods\nsuffer from information loss or inefficient optimization process, and they fail\nto explicitly model global user preference knowledge which is crucial to\ncomplement the sparse and insufficient preference information of cold users. In\nthis paper, we propose a novel and efficient approach named RESUS, which\ndecouples the learning of global preference knowledge contributed by collective\nusers from the learning of residual preferences for individual users.\nSpecifically, we employ a shared predictor to infer basis user preferences,\nwhich acquires global preference knowledge from the interactions of different\nusers. Meanwhile, we develop two efficient algorithms based on the nearest\nneighbor and ridge regression predictors, which infer residual user preferences\nvia learning quickly from a few user-specific interactions. Extensive\nexperiments on three public datasets demonstrate that our RESUS approach is\nefficient and effective in improving CTR prediction accuracy on cold users,\ncompared with various state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by TOIS 2022. Code are available in this https URL\n",
    "authors": [
      "Yanyan Shen",
      "Lifan Zhao",
      "Weiyu Cheng",
      "Zibin Zhang",
      "Wenwen Zhou",
      "Kangyi Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16080"
  },
  {
    "id": "arXiv:2210.16081",
    "title": "Object Segmentation of Cluttered Airborne LiDAR Point Clouds",
    "abstract": "Airborne topographic LiDAR is an active remote sensing technology that emits\nnear-infrared light to map objects on the Earth's surface. Derived products of\nLiDAR are suitable to service a wide range of applications because of their\nrich three-dimensional spatial information and their capacity to obtain\nmultiple returns. However, processing point cloud data still requires a\nsignificant effort in manual editing. Certain human-made objects are difficult\nto detect because of their variety of shapes, irregularly-distributed point\nclouds, and low number of class samples. In this work, we propose an end-to-end\ndeep learning framework to automatize the detection and segmentation of objects\ndefined by an arbitrary number of LiDAR points surrounded by clutter. Our\nmethod is based on a light version of PointNet that achieves good performance\non both object recognition and segmentation tasks. The results are tested\nagainst manually delineated power transmission towers and show promising\naccuracy.",
    "descriptor": "\nComments: proceedings of the 24th International Conference of the Catalan Association for Artificial Intelligence (CCIA 2022)\n",
    "authors": [
      "Mariona Caros",
      "Ariadna Just",
      "Santi Segui",
      "Jordi Vitria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16081"
  },
  {
    "id": "arXiv:2210.16082",
    "title": "Optimal Transportation for Electrical Impedance Tomography",
    "abstract": "This work establishes a framework for solving inverse boundary problems with\nthe geodesic based quadratic Wasserstein distance ($W_{2}$). A general form of\nthe Fr\\'echet gradient is systematically derived by optimal transportation (OT)\ntheory. In addition, a fast algorithm based on the new formulation of OT on\n$\\mathbb{S}^{1}$ is developed to solve the corresponding optimal transport\nproblem. The computational complexity of the algorithm is reduced to $O(N)$\nfrom $O(N^{3})$ of the traditional method. Combining with the adjoint-state\nmethod, this framework provides a new computational approach for solving the\nchallenging electrical impedance tomography (EIT) problem. Numerical examples\nare presented to illustrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Gang Bao",
      "Yixuan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.16082"
  },
  {
    "id": "arXiv:2210.16083",
    "title": "ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy",
    "abstract": "This paper analyzes the effects of dynamically varying video contents and\ndetection latency on the real-time detection accuracy of a detector and\nproposes a new run-time accuracy variation model, ROMA, based on the findings\nfrom the analysis. ROMA is designed to select an optimal detector out of a set\nof detectors in real time without label information to maximize real-time\nobject detection accuracy. ROMA utilizing four YOLOv4 detectors on an NVIDIA\nJetson Nano shows real-time accuracy improvements by 4 to 37% for a scenario of\ndynamically varying video contents and detection latency consisting of MOT17Det\nand MOT20Det datasets, compared to individual YOLOv4 detectors and two\nstate-of-the-art runtime techniques.",
    "descriptor": "\nComments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "JunKyu Lee",
      "Blesson Varghese",
      "Hans Vandierendonck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16083"
  },
  {
    "id": "arXiv:2210.16086",
    "title": "KD-EKF: A Kalman Decomposition Based Extended Kalman Filter for  Multi-Robot Cooperative Localization",
    "abstract": "This paper investigates the consistency problem of EKF-based cooperative\nlocalization (CL) from the perspective of Kalman decomposition, which\ndecomposes the observable and unobservable states and allows treating them\nindividually. The factors causing the dimension reduction of the unobservable\nsubspace, termed error discrepancy items, are explicitly isolated and\nidentified in the state propagation and measurement Jacobians for the first\ntime. We prove that the error discrepancy items lead to the global orientation\nbeing erroneously observable, which in turn causes the state estimation to be\ninconsistent. A CL algorithm, called Kalman decomposition-based EKF (KD-EKF),\nis proposed to improve consistency. The key idea is to perform state estimation\nusing the Kalman observable canonical form in the transformed coordinates. By\nannihilating the error discrepancy items, proper observability properties are\nguaranteed. More importantly, the modified state propagation and measurement\nJacobians are exactly equivalent to linearizing the nonlinear CL system at\ncurrent best state estimates. Consequently, the inconsistency caused by the\nerroneous dimension reduction of the unobservable subspace is completely\neliminated. The KD-EKF CL algorithm has been extensively verified in both Monte\nCarlo simulations and real-world experiments and shown to achieve better\nperformance than state-of-the-art algorithms in terms of accuracy and\nconsistency.",
    "descriptor": "",
    "authors": [
      "Ning Hao",
      "Fenghua He",
      "Chungeng Tian",
      "Yu Yao",
      "Shaoshuai Mou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16086"
  },
  {
    "id": "arXiv:2210.16089",
    "title": "Let's Go to the Whiteboard (Again):Perceptions from Software Architects  on Whiteboard Architecture Meetings",
    "abstract": "The whiteboard plays a crucial role in the day-to-day lives of software\narchitects, as they frequently will organize meetings at the whiteboard to\ndiscuss a new architecture, some proposed changes to the architecture, a\nmismatch between the architecture and the code, and more. While much has been\nstudied about software architects, the architectures they produce, and how they\nproduce them, a detailed understanding of these whiteboards meetings is still\nlacking. In this paper, we contribute a mixed-methods study involving\nsemi-structured interviews and a subsequent survey to understand the\nperceptions of software architects on whiteboard architecture meetings. We\nfocus on five aspects: (1) why do they hold these meetings, what is the impact\nof the experience levels of the participants in these meetings, how do the\narchitects document the meetings, what kinds of changes are made after the\nmeetings have concluded and their results are moved to implementation, and what\nrole do digital whiteboards plays? In studying these aspects, we identify 12\nobservations related to both technical aspects and social aspects of the\nmeetings. These insights have implications for further research, offer concrete\nadvice to practitioners, provide guidance for future tool design, and suggest\nways of educating future software architects.",
    "descriptor": "",
    "authors": [
      "Eduardo Santana de Almeida",
      "Iftekhar Ahmed",
      "Andre van der Hoek"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16089"
  },
  {
    "id": "arXiv:2210.16093",
    "title": "A CNN-LSTM Combination Network for Cataract Detection using Eye Fundus  Images",
    "abstract": "According to multiple authoritative authorities, including the World Health\nOrganization, vision-related impairments and disorders are becoming a\nsignificant issue. According to a recent report, one of the leading causes of\nirreversible blindness in persons over the age of 50 is delayed cataract\ntreatment. A cataract is a cloudy spot in the eye's lens that causes visual\nloss. Cataracts often develop slowly and consequently result in difficulty in\ndriving, reading, and even recognizing faces. This necessitates the development\nof rapid and dependable diagnosis and treatment solutions for ocular illnesses.\nPreviously, such visual illness diagnosis were done manually, which was\ntime-consuming and prone to human mistake. However, as technology advances,\nautomated, computer-based methods that decrease both time and human labor while\nproducing trustworthy results are now accessible. In this study, we developed a\nCNN-LSTM-based model architecture with the goal of creating a low-cost\ndiagnostic system that can classify normal and cataractous cases of ocular\ndisease from fundus images. The proposed model was trained on the publicly\navailable ODIR dataset, which included fundus images of patients' left and\nright eyes. The suggested architecture outperformed previous systems with a\nstate-of-the-art 97.53% accuracy.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Dishant Padalia",
      "Abhishek Mazumdar",
      "Bharati Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16093"
  },
  {
    "id": "arXiv:2210.16101",
    "title": "Layer-wise Shared Attention Network on Dynamical System Perspective",
    "abstract": "Attention networks have successfully boosted accuracy in various vision\nproblems. Previous works lay emphasis on designing a new self-attention module\nand follow the traditional paradigm that individually plugs the modules into\neach layer of a network. However, such a paradigm inevitably increases the\nextra parameter cost with the growth of the number of layers. From the\ndynamical system perspective of the residual neural network, we find that the\nfeature maps from the layers of the same stage are homogenous, which inspires\nus to propose a novel-and-simple framework, called the dense and implicit\nattention (DIA) unit, that shares a single attention module throughout\ndifferent network layers. With our framework, the parameter cost is independent\nof the number of layers and we further improve the accuracy of existing popular\nself-attention modules with significant parameter reduction without any\nelaborated model crafting. Extensive experiments on benchmark datasets show\nthat the DIA is capable of emphasizing layer-wise feature interrelation and\nthus leads to significant improvement in various vision tasks, including image\nclassification, object detection, and medical application. Furthermore, the\neffectiveness of the DIA unit is demonstrated by novel experiments where we\ndestabilize the model training by (1) removing the skip connection of the\nresidual neural network, (2) removing the batch normalization of the model, and\n(3) removing all data augmentation during training. In these cases, we verify\nthat DIA has a strong regularization ability to stabilize the training, i.e.,\nthe dense and implicit connections formed by our method can effectively recover\nand enhance the information communication across layers and the value of the\ngradient thus alleviate the training instability.",
    "descriptor": "\nComments: Work in progress. arXiv admin note: text overlap with arXiv:1905.10671\n",
    "authors": [
      "Zhongzhan Huang",
      "Senwei Liang",
      "Mingfu Liang",
      "Weiling He",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16101"
  },
  {
    "id": "arXiv:2210.16103",
    "title": "Collaborative Multi-Teacher Knowledge Distillation for Learning Low  Bit-width Deep Neural Networks",
    "abstract": "Knowledge distillation which learns a lightweight student model by distilling\nknowledge from a cumbersome teacher model is an attractive approach for\nlearning compact deep neural networks (DNNs). Recent works further improve\nstudent network performance by leveraging multiple teacher networks. However,\nmost of the existing knowledge distillation-based multi-teacher methods use\nseparately pretrained teachers. This limits the collaborative learning between\nteachers and the mutual learning between teachers and student. Network\nquantization is another attractive approach for learning compact DNNs. However,\nmost existing network quantization methods are developed and evaluated without\nconsidering multi-teacher support to enhance the performance of quantized\nstudent model. In this paper, we propose a novel framework that leverages both\nmulti-teacher knowledge distillation and network quantization for learning low\nbit-width DNNs. The proposed method encourages both collaborative learning\nbetween quantized teachers and mutual learning between quantized teachers and\nquantized student. During learning process, at corresponding layers, knowledge\nfrom teachers will form an importance-aware shared knowledge which will be used\nas input for teachers at subsequent layers and also be used to guide student.\nOur experimental results on CIFAR100 and ImageNet datasets show that the\ncompact quantized student models trained with our method achieve competitive\nresults compared to other state-of-the-art methods, and in some cases, indeed\nsurpass the full precision models.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Cuong Pham",
      "Tuan Hoang",
      "Thanh-Toan Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16103"
  },
  {
    "id": "arXiv:2210.16105",
    "title": "Efficient and Light-Weight Federated Learning via Asynchronous  Distributed Dropout",
    "abstract": "Asynchronous learning protocols have regained attention lately, especially in\nthe Federated Learning (FL) setup, where slower clients can severely impede the\nlearning process. Herein, we propose \\texttt{AsyncDrop}, a novel asynchronous\nFL framework that utilizes dropout regularization to handle device\nheterogeneity in distributed settings. Overall, \\texttt{AsyncDrop} achieves\nbetter performance compared to state of the art asynchronous methodologies,\nwhile resulting in less communication and training time overheads. The key idea\nrevolves around creating ``submodels'' out of the global model, and\ndistributing their training to workers, based on device heterogeneity. We\nrigorously justify that such an approach can be theoretically characterized. We\nimplement our approach and compare it against other asynchronous baselines,\nboth by design and by adapting existing synchronous FL algorithms to\nasynchronous scenarios. Empirically, \\texttt{AsyncDrop} reduces the\ncommunication cost and training time, while matching or improving the final\ntest accuracy in diverse non-i.i.d. FL scenarios.",
    "descriptor": "",
    "authors": [
      "Chen Dun",
      "Mirian Hipolito",
      "Chris Jermaine",
      "Dimitrios Dimitriadis",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.16105"
  },
  {
    "id": "arXiv:2210.16106",
    "title": "Motion Planning using Reactive Circular Fields: A 2D Analysis of  Collision Avoidance and Goal Convergence",
    "abstract": "Recently, many reactive trajectory planning approaches were suggested in the\nliterature because of their inherent immediate adaption in the ever more\ndemanding cluttered and unpredictable environments of robotic systems. However,\ntypically those approaches are only locally reactive without considering global\npath planning and no guarantees for simultaneous collision avoidance and goal\nconvergence can be given. In this paper, we study a recently developed circular\nfield (CF)-based motion planner that combines local reactive control with\nglobal trajectory generation by adapting an artificial magnetic field such that\nmultiple trajectories around obstacles can be evaluated. In particular, we\nprovide a mathematically rigorous analysis of this planner in a planar\nenvironment to ensure safe motion of the controlled robot. Contrary to existing\nresults, the derived collision avoidance analysis covers the entire CF motion\nplanning algorithm including attractive forces for goal convergence and is not\nlimited to a specific choice of the rotation field, i.e., our guarantees are\nnot limited to a specific potentially suboptimal trajectory. Our Lyapunov-type\ncollision avoidance analysis is based on the definition of an (equivalent)\ntwo-dimensional auxiliary system, which enables us to provide tight, if and\nonly if conditions for the case of a collision with point obstacles.\nFurthermore, we show how this analysis naturally extends to multiple obstacles\nand we specify sufficient conditions for goal convergence. Finally, we provide\na challenging simulation scenario with multiple non-convex point cloud\nobstacles and demonstrate collision avoidance and goal convergence.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control (12. September 2022)\n",
    "authors": [
      "Marvin Becker",
      "Johannes K\u00f6hler",
      "Sami Haddadin",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.16106"
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are known for their fast and versatile\napplicability. With UAVs' growth in availability and applications, they are now\nof vital importance in serving as technological support in\nsearch-and-rescue(SAR) operations in marine environments. High-resolution\ncameras and GPUs can be equipped on the UAVs to provide effective and efficient\naid to emergency rescue operations. With modern computer vision algorithms, we\ncan detect objects for aiming such rescue missions. However, these modern\ncomputer vision algorithms are dependent on numerous amounts of training data\nfrom UAVs, which is time-consuming and labor-intensive for maritime\nenvironments. To this end, we present a new benchmark suite,\n\\textit{\\textbf{SeaDroneSim}}, that can be used to create photo-realistic\naerial image datasets with the ground truth for segmentation masks of any given\nobject. Utilizing only the synthetic data generated from\n\\textit{\\textbf{SeaDroneSim}}, we obtain 71 mAP on real aerial images for\ndetecting BlueROV as a feasibility study. This result from the new simulation\nsuit also serves as a baseline for the detection of BlueROV.",
    "descriptor": "",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16107"
  },
  {
    "id": "arXiv:2210.16114",
    "title": "Toward Reliable Neural Specifications",
    "abstract": "Having reliable specifications is an unavoidable challenge in achieving\nverifiable correctness, robustness, and interpretability of AI systems.\nExisting specifications for neural networks are in the paradigm of data as\nspecification. That is, the local neighborhood centering around a reference\ninput is considered to be correct (or robust). However, our empirical study\nshows that such a specification is extremely overfitted since usually no data\npoints from the testing set lie in the certified region of the reference input,\nmaking them impractical for real-world applications. We propose a new family of\nspecifications called neural representation as specification, which uses the\nintrinsic information of neural networks - neural activation patterns (NAP),\nrather than input data to specify the correctness and/or robustness of neural\nnetwork predictions. We present a simple statistical approach to mining\ndominant neural activation patterns. We analyze NAPs from a statistical point\nof view and find that a single NAP can cover a large number of training and\ntesting data points whereas ad hoc data-as-specification only covers the given\nreference data point. To show the effectiveness of discovered NAPs, we formally\nverify several important properties, such as various types of\nmisclassifications will never happen for a given NAP, and there is no-ambiguity\nbetween different NAPs. We show that by using NAP, we can verify the prediction\nof the entire input space, while still recalling 84% of the data. Thus, we\nargue that using NAPs is a more reliable and extensible specification for\nneural network verification.",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Chuqin Geng",
      "Nham Le",
      "Xiaojie Xu",
      "Zhaoyue Wang",
      "Arie Gurfinkel",
      "Xujie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16114"
  },
  {
    "id": "arXiv:2210.16117",
    "title": "Improving Transferability of Adversarial Examples on Face Recognition  with Beneficial Perturbation Feature Augmentation",
    "abstract": "Face recognition (FR) models can be easily fooled by adversarial examples,\nwhich are crafted by adding imperceptible perturbations on benign face images.\nTo improve the transferability of adversarial examples on FR models, we propose\na novel attack method called Beneficial Perturbation Feature Augmentation\nAttack (BPFA), which reduces the overfitting of the adversarial examples to\nsurrogate FR models by the adversarial strategy. Specifically, in the\nbackpropagation step, BPFA records the gradients on pre-selected features and\nuses the gradient on the input image to craft adversarial perturbation to be\nadded on the input image. In the next forward propagation step, BPFA leverages\nthe recorded gradients to add perturbations(i.e., beneficial perturbations)\nthat can be pitted against the adversarial perturbation added on the input\nimage on their corresponding features. The above two steps are repeated until\nthe last backpropagation step before the maximum number of iterations is\nreached. The optimization process of the adversarial perturbation added on the\ninput image and the optimization process of the beneficial perturbations added\non the features correspond to a minimax two-player game. Extensive experiments\ndemonstrate that BPFA outperforms the state-of-the-art gradient-based\nadversarial attacks on FR.",
    "descriptor": "",
    "authors": [
      "Fengfan Zhou",
      "Hefei Ling",
      "Yuxuan Shi",
      "Jiazhong Chen",
      "Zongyi Li",
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16117"
  },
  {
    "id": "arXiv:2210.16118",
    "title": "Imitation Learning-based Implicit Semantic-aware Communication Networks:  Multi-layer Representation and Collaborative Reasoning",
    "abstract": "Semantic communication has recently attracted significant interest from both\nindustry and academia due to its potential to transform the existing\ndata-focused communication architecture towards a more generally intelligent\nand goal-oriented semantic-aware networking system. Despite its promising\npotential, semantic communications and semantic-aware networking are still at\ntheir infancy. Most existing works focus on transporting and delivering the\nexplicit semantic information, e.g., labels or features of objects, that can be\ndirectly identified from the source signal. The original definition of\nsemantics as well as recent results in cognitive neuroscience suggest that it\nis the implicit semantic information, in particular the hidden relations\nconnecting different concepts and feature items that plays the fundamental role\nin recognizing, communicating, and delivering the real semantic meanings of\nmessages. Motivated by this observation, we propose a novel reasoning-based\nimplicit semantic-aware communication network architecture that allows multiple\ntiers of CDC and edge servers to collaborate and support efficient semantic\nencoding, decoding, and interpretation for end-users. We introduce a new\nmulti-layer representation of semantic information taking into consideration\nboth the hierarchical structure of implicit semantics as well as the\npersonalized inference preference of individual users. We model the semantic\nreasoning process as a reinforcement learning process and then propose an\nimitation-based semantic reasoning mechanism learning (iRML) solution for the\nedge servers to leaning a reasoning policy that imitates the inference behavior\nof the source user. A federated GCN-based collaborative reasoning solution is\nproposed to allow multiple edge servers to jointly construct a shared semantic\ninterpretation model based on decentralized knowledge datasets.",
    "descriptor": "\nComments: Accepted at IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Yong Xiao",
      "Zijian Sun",
      "Guangming Shi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.16118"
  },
  {
    "id": "arXiv:2210.16125",
    "title": "BRATsynthetic: Text De-identification using a Markov Chain Replacement  Strategy for Surrogate Personal Identifying Information",
    "abstract": "Objective: Implement and assess personal health identifying information (PHI)\nsubstitution strategies and quantify their privacy preserving benefits.\nMaterials and Methods: We implement and assess 3 different `Hiding in Plain\nSight` (HIPS) strategies for PHI replacement including a standard Consistent\nreplacement strategy, a Random replacement strategy and a novel Markov\nmodel-based strategy. We evaluate the privacy preserving benefits of these\nstrategies on a synthetic PHI distribution and real clinical corpora from 2\ndifferent institutions using a range of false negative error rates (FNER).\nResults: Using FNER ranging from 0.1% to 5% PHI leakage at the document level\ncould be reduced from 27.1% to 0.1% (0.1% FNER) and from 94.2% to 57.7% (5%\nFNER) utilizing the Markov chain strategy versus the Consistent strategy on a\ncorpus containing a diverse set of notes from the University of Alabama at\nBirmingham (UAB). The Markov chain substitution strategy also consistently\noutperformed the Consistent and Random substitution strategies in a MIMIC\ncorpus of discharge summaries and on a range of synthetic clinical PHI\ndistributions. Discussion: We demonstrate that a Markov chain surrogate\ngeneration strategy substantially reduces the chance of inadvertent PHI release\nacross a range of assumed PHI FNER and release our implementation\n`BRATsynthetic` on Github.\nConclusion: The Markov chain replacement strategy allows for the release of\nlarger de-identified corpora at the same risk level relative to corpora\nreleased using a consistent HIPS strategy.",
    "descriptor": "",
    "authors": [
      "John D. Osborne",
      "Tobias O'Leary",
      "Akhil Nadimpalli",
      "Salma M. Aly.",
      "Richard E. Kennedy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.16125"
  },
  {
    "id": "arXiv:2210.16133",
    "title": "Stop Measuring Calibration When Humans Disagree",
    "abstract": "Calibration is a popular framework to evaluate whether a classifier knows\nwhen it does not know - i.e., its predictive probabilities are a good\nindication of how likely a prediction is to be correct. Correctness is commonly\nestimated against the human majority class. Recently, calibration to human\nmajority has been measured on tasks where humans inherently disagree about\nwhich class applies. We show that measuring calibration to human majority given\ninherent disagreements is theoretically problematic, demonstrate this\nempirically on the ChaosNLI dataset, and derive several instance-level measures\nof calibration that capture key statistical properties of human judgements -\nclass frequency, ranking and entropy.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Joris Baan",
      "Wilker Aziz",
      "Barbara Plank",
      "Raquel Fernandez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16133"
  },
  {
    "id": "arXiv:2210.16140",
    "title": "Localized Randomized Smoothing for Collective Robustness Certification",
    "abstract": "Models for image segmentation, node classification and many other tasks map a\nsingle input to multiple labels. By perturbing this single shared input (e.g.\nthe image) an adversary can manipulate several predictions (e.g. misclassify\nseveral pixels). Collective robustness certification is the task of provably\nbounding the number of robust predictions under this threat model. The only\ndedicated method that goes beyond certifying each output independently is\nlimited to strictly local models, where each prediction is associated with a\nsmall receptive field. We propose a more general collective robustness\ncertificate for all types of models and further show that this approach is\nbeneficial for the larger class of softly local models, where each output is\ndependent on the entire input but assigns different levels of importance to\ndifferent input regions (e.g. based on their proximity in the image). The\ncertificate is based on our novel localized randomized smoothing approach,\nwhere the random perturbation strength for different input regions is\nproportional to their importance for the outputs. Localized smoothing\nPareto-dominates existing certificates on both image segmentation and node\nclassification tasks, simultaneously offering higher accuracy and stronger\nguarantees.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Jan Schuchardt",
      "Tom Wollschl\u00e4ger",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16140"
  },
  {
    "id": "arXiv:2210.16142",
    "title": "Federated Learning for Chronic Obstructive Pulmonary Disease  Classification with Partial Personalized Attention Mechanism",
    "abstract": "Chronic Obstructive Pulmonary Disease (COPD) is the fourth leading cause of\ndeath worldwide. Yet, COPD diagnosis heavily relies on spirometric examination\nas well as functional airway limitation, which may cause a considerable portion\nof COPD patients underdiagnosed especially at the early stage. Recent advance\nin deep learning (DL) has shown their promising potential in COPD\nidentification from CT images. However, with heterogeneous syndromes and\ndistinct phenotypes, DL models trained with CTs from one data center fail to\ngeneralize on images from another center. Due to privacy regularizations, a\ncollaboration of distributed CT images into one centralized center is not\nfeasible. Federated learning (FL) approaches enable us to train with\ndistributed private data. Yet, routine FL solutions suffer from performance\ndegradation in the case where COPD CTs are not independent and identically\ndistributed (Non-IID). To address this issue, we propose a novel personalized\nfederated learning (PFL) method based on vision transformer (ViT) for\ndistributed and heterogeneous COPD CTs. To be more specific, we partially\npersonalize some heads in multiheaded self-attention layers to learn the\npersonalized attention for local data and retain the other heads shared to\nextract the common attention. To the best of our knowledge, this is the first\nproposal of a PFL framework specifically for ViT to identify COPD. Our\nevaluation of a dataset set curated from six medical centers shows our method\noutperforms the PFL approaches for convolutional neural networks.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Yiqing Shen",
      "Baiyun Liu",
      "Ruize Yu",
      "Yudong Wang",
      "Shaokang Wang",
      "Jiangfen Wu",
      "Weidao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16142"
  },
  {
    "id": "arXiv:2210.16144",
    "title": "Towards Trustworthy Multi-Modal Motion Prediction: Evaluation and  Interpretability",
    "abstract": "Predicting the motion of other road agents enables autonomous vehicles to\nperform safe and efficient path planning. This task is very complex, as the\nbehaviour of road agents depends on many factors and the number of possible\nfuture trajectories can be considerable (multi-modal). Most approaches proposed\nto address multi-modal motion prediction are based on complex machine learning\nsystems that have limited interpretability. Moreover, the metrics used in\ncurrent benchmarks do not evaluate all aspects of the problem, such as the\ndiversity and admissibility of the output. In this work, we aim to advance\ntowards the design of trustworthy motion prediction systems, based on some of\nthe requirements for the design of Trustworthy Artificial Intelligence. We\nfocus on evaluation criteria, robustness, and interpretability of outputs.\nFirst, we comprehensively analyse the evaluation metrics, identify the main\ngaps of current benchmarks, and propose a new holistic evaluation framework. In\naddition, we formulate a method for the assessment of spatial and temporal\nrobustness by simulating noise in the perception system. We propose an intent\nprediction layer that can be attached to multi-modal motion prediction models\nto enhance the interpretability of the outputs and generate more balanced\nresults in the proposed evaluation framework. Finally, the interpretability of\nthe outputs is assessed by means of a survey that explores different elements\nin the visualization of the multi-modal trajectories and intentions.",
    "descriptor": "\nComments: 16 pages, 7 figures, 6 tables\n",
    "authors": [
      "Sandra Carrasco Limeros",
      "Sylwia Majchrowska",
      "Joakim Johnander",
      "Christoffer Petersson",
      "Miguel \u00c1ngel Sotelo",
      "David Fern\u00e1ndez Llorca"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16144"
  },
  {
    "id": "arXiv:2210.16147",
    "title": "Modeling structure-building in the brain with CCG parsing and large  language models",
    "abstract": "To model behavioral and neural correlates of language comprehension in\nnaturalistic environments, researchers have turned to broad-coverage tools from\nnatural-language processing and machine learning. Where syntactic structure is\nexplicitly modeled, prior work has relied predominantly on context-free\ngrammars (CFG), yet such formalisms are not sufficiently expressive for human\nlanguages. Combinatory Categorial Grammars (CCGs) are sufficiently expressive\ndirectly compositional models of grammar with flexible constituency that\naffords incremental interpretation. In this work we evaluate whether a more\nexpressive CCG provides a better model than a CFG for human neural signals\ncollected with fMRI while participants listen to an audiobook story. We further\ntest between variants of CCG that differ in how they handle optional adjuncts.\nThese evaluations are carried out against a baseline that includes estimates of\nnext-word predictability from a Transformer neural network language model. Such\na comparison reveals unique contributions of CCG structure-building\npredominantly in the left posterior temporal lobe: CCG-derived measures offer a\nsuperior fit to neural signals compared to those derived from a CFG. These\neffects are spatially distinct from bilateral superior temporal effects that\nare unique to predictability. Neural effects for structure-building are thus\nseparable from predictability during naturalistic listening, and those effects\nare best characterized by a grammar whose expressive power is motivated on\nindependent linguistic grounds.",
    "descriptor": "",
    "authors": [
      "Milo\u0161 Stanojevi\u0107",
      "Jonathan R. Brennan",
      "Donald Dunagan",
      "Mark Steedman",
      "John T. Hale"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16147"
  },
  {
    "id": "arXiv:2210.16153",
    "title": "The MacWilliams Identity for the Skew Rank Metric",
    "abstract": "The weight distribution of an error correcting code is a crucial statistic in\ndetermining it's performance. One key tool for relating the weight of a code to\nthat of it's dual is the MacWilliams Identity, first developed for the Hamming\nmetric. This identity has two forms: one is a functional transformation of the\nweight enumerators, while the other is a direct relation of the weight\ndistributions via (generalised) Krawtchouk polynomials. The functional\ntransformation form can in particular be used to derive important moment\nidentities for the weight distribution of codes. In this paper, we focus on\ncodes in the skew rank metric. In these codes, the codewords are skew-symmetric\nmatrices, and the distance between two matrices is the skew rank metric, which\nis half the rank of their difference. This paper develops a $q$-analog\nMacWilliams Identity in the form of a functional transformation for codes based\non skew-symmetric matrices under their associated skew rank metric. The method\nintroduces a skew-$q$ algebra and uses generalised Krawtchouk polynomials.\nBased on this new MacWilliams Identity, we then derive several moments of the\nskew rank distribution for these codes.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Izzy Friedlander",
      "Thanasis Bouganis",
      "Maximilien Gadouleau"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.16153"
  },
  {
    "id": "arXiv:2210.16156",
    "title": "Reliability of CKA as a Similarity Measure in Deep Learning",
    "abstract": "Comparing learned neural representations in neural networks is a challenging\nbut important problem, which has been approached in different ways. The\nCentered Kernel Alignment (CKA) similarity metric, particularly its linear\nvariant, has recently become a popular approach and has been widely used to\ncompare representations of a network's different layers, of architecturally\nsimilar networks trained differently, or of models with different architectures\ntrained on the same data. A wide variety of conclusions about similarity and\ndissimilarity of these various representations have been made using CKA. In\nthis work we present analysis that formally characterizes CKA sensitivity to a\nlarge class of simple transformations, which can naturally occur in the context\nof modern machine learning. This provides a concrete explanation of CKA\nsensitivity to outliers, which has been observed in past works, and to\ntransformations that preserve the linear separability of the data, an important\ngeneralization attribute. We empirically investigate several weaknesses of the\nCKA similarity metric, demonstrating situations in which it gives unexpected or\ncounter-intuitive results. Finally we study approaches for modifying\nrepresentations to maintain functional behaviour while changing the CKA value.\nOur results illustrate that, in many cases, the CKA value can be easily\nmanipulated without substantial changes to the functional behaviour of the\nmodels, and call for caution when leveraging activation alignment metrics.",
    "descriptor": "",
    "authors": [
      "MohammadReza Davari",
      "Stefan Horoi",
      "Amine Natik",
      "Guillaume Lajoie",
      "Guy Wolf",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16156"
  },
  {
    "id": "arXiv:2210.16160",
    "title": "Some Remarks on Counting Propositional Logic",
    "abstract": "Counting propositional logic was recently introduced in relation to\nrandomized computation and shown able to logically characterize the full\ncounting hierarchy. In this paper we aim to clarify the intuitive meaning and\nexpressive power of its univariate fragment. On the one hand, we provide an\neffective procedure to measure the probability of counting formulas. On the\nother, we make the connection between this logic and stochastic experiments\nexplicit, proving that the counting language can simulate any (and only) event\nassociated with dyadic distributions.",
    "descriptor": "\nComments: joint work with Ugo Dal Lago and Paolo Pistone\n",
    "authors": [
      "Melissa Antonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.16160"
  },
  {
    "id": "arXiv:2210.16162",
    "title": "Are Neural Topic Models Broken?",
    "abstract": "Recently, the relationship between automated and human evaluation of topic\nmodels has been called into question. Method developers have staked the\nefficacy of new topic model variants on automated measures, and their failure\nto approximate human preferences places these models on uncertain ground.\nMoreover, existing evaluation paradigms are often divorced from real-world use.\nMotivated by content analysis as a dominant real-world use case for topic\nmodeling, we analyze two related aspects of topic models that affect their\neffectiveness and trustworthiness in practice for that purpose: the stability\nof their estimates and the extent to which the model's discovered categories\nalign with human-determined categories in the data. We find that neural topic\nmodels fare worse in both respects compared to an established classical method.\nWe take a step toward addressing both issues in tandem by demonstrating that a\nstraightforward ensembling method can reliably outperform the members of the\nensemble.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Alexander Hoyle",
      "Pranav Goel",
      "Rupak Sarkar",
      "Philip Resnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.16162"
  },
  {
    "id": "arXiv:2210.16165",
    "title": "On Modular Gray Map",
    "abstract": "This paper introduces an isometry between the modular rings $\\Z_{2^s}$ and\n$\\Z_{2^{s-1}}$ with respect to the homogeneous weights. Certain product of\nthese maps gives Carlet's generalised Gray map and also Vega's Gray map. For\n$s=2$ this reduces to popular Gray map. Several interesting properties of these\nmaps are studied. Towards the end we list several interesting problems to work\non.",
    "descriptor": "\nComments: 12 pages, note, presented at the Special Session on Algebraic Coding Theory, Central Section Meeting \\#995, American Mathematical Society, Athens,OH, 26-27 March 2004\n",
    "authors": [
      "Manish K Gupta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.16165"
  },
  {
    "id": "arXiv:2210.16168",
    "title": "Feature Engineering vs BERT on Twitter Data",
    "abstract": "In this paper, we compare the performances of traditional machine learning\nmodels using feature engineering and word vectors and the state-of-the-art\nlanguage model BERT using word embeddings on three datasets. We also consider\nthe time and cost efficiency of feature engineering compared to BERT. From our\nresults we conclude that the use of the BERT model was only worth the time and\ncost trade-off for one of the three datasets we used for comparison, where the\nBERT model significantly outperformed any kind of traditional classifier that\nuses feature vectors, instead of embeddings. Using the BERT model for the other\ndatasets only achieved an increase of 0.03 and 0.05 of accuracy and F1 score\nrespectively, which could be argued makes its use not worth the time and cost\nof GPU.",
    "descriptor": "",
    "authors": [
      "Ryiaadh Gani",
      "Lisa Chalaguine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16168"
  },
  {
    "id": "arXiv:2210.16169",
    "title": "LOFT: Finding Lottery Tickets through Filter-wise Training",
    "abstract": "Recent work on the Lottery Ticket Hypothesis (LTH) shows that there exist\n``\\textit{winning tickets}'' in large neural networks. These tickets represent\n``sparse'' versions of the full model that can be trained independently to\nachieve comparable accuracy with respect to the full model. However, finding\nthe winning tickets requires one to \\emph{pretrain} the large model for at\nleast a number of epochs, which can be a burdensome task, especially when the\noriginal neural network gets larger.\nIn this paper, we explore how one can efficiently identify the emergence of\nsuch winning tickets, and use this observation to design efficient pretraining\nalgorithms. For clarity of exposition, our focus is on convolutional neural\nnetworks (CNNs). To identify good filters, we propose a novel filter distance\nmetric that well-represents the model convergence. As our theory dictates, our\nfilter analysis behaves consistently with recent findings of neural network\nlearning dynamics. Motivated by these observations, we present the\n\\emph{LOttery ticket through Filter-wise Training} algorithm, dubbed as\n\\textsc{LoFT}. \\textsc{LoFT} is a model-parallel pretraining algorithm that\npartitions convolutional layers by filters to train them independently in a\ndistributed setting, resulting in reduced memory and communication costs during\npretraining. Experiments show that \\textsc{LoFT} $i)$ preserves and finds good\nlottery tickets, while $ii)$ it achieves non-trivial computation and\ncommunication savings, and maintains comparable or even better accuracy than\nother pretraining methods.",
    "descriptor": "",
    "authors": [
      "Qihan Wang",
      "Chen Dun",
      "Fangshuo Liao",
      "Chris Jermaine",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.16169"
  },
  {
    "id": "arXiv:2210.16171",
    "title": "Vanishing Component Analysis with Contrastive Normalization",
    "abstract": "Vanishing component analysis (VCA) computes approximate generators of\nvanishing ideals of samples, which are further used for extracting nonlinear\nfeatures of the samples. Recent studies have shown that normalization of\napproximate generators plays an important role and different normalization\nleads to generators of different properties. In this paper, inspired by recent\nself-supervised frameworks, we propose a contrastive normalization method for\nVCA, where we impose the generators to vanish on the target samples and to be\nnormalized on the transformed samples. We theoretically show that a contrastive\nnormalization enhances the discriminative power of VCA, and provide the\nalgebraic interpretation of VCA under our normalization. Numerical experiments\ndemonstrate the effectiveness of our method. This is the first study to tailor\nthe normalization of approximate generators of vanishing ideals to obtain\ndiscriminative features.",
    "descriptor": "\nComments: 22pages, 1 figure\n",
    "authors": [
      "Ryosuke Masuya",
      "Yuichi Ike",
      "Hiroshi Kera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.16171"
  },
  {
    "id": "arXiv:2210.16172",
    "title": "Violation Probabilities of AoI and PAoI and Optimal Arrival Rate  Allocation for the IoT-based Multi-Source Status Update System",
    "abstract": "Lots of real-time applications over Internet of things (IoT)-based status\nupdate systems have imperative demands on information freshness, which is\nusually evaluated by age of information (AoI). Compared to the average AoI and\npeak AoI (PAoI), violation probabilities and distributions of AoI and PAoI\ncharacterize the timeliness in more details. This paper studies the timeliness\nof the IoT-based multi-source status update system. By modeling the system as a\nmulti-source M/G/1/1 bufferless preemptive queue, general formulas of violation\nprobabilities and probability density functions (p.d.f.s) of AoI and PAoI are\nderived with a time-domain approach. For the case with negativeexponentially\ndistributed service time, the violation probabilities and p.d.f.s are obtained\nin closed form. Moreover, the maximal violation probabilities of AoI and PAoI\nare proposed to characterize the overall timeliness. To improve the overall\ntimeliness under the resource constraint of IoT-device, the arrival rate\nallocation scheme is used to minimize the maximal violation probabilities. It\nis proved that the optimal arrival rates can be found by convex optimization\nalgorithms. In addition, it is obtained that the minimum of maximal violation\nprobability of AoI (or PAoI) is achieved only if all violation probabilities of\nAoI (or PAoI) are equal. Finally, numerical results verify the theoretical\nanalysis and show the effectiveness of the arrival rate allocation scheme.",
    "descriptor": "",
    "authors": [
      "Tianci Zhang",
      "Shutong Chen",
      "Zhengchuan Chen",
      "Zhong Tian",
      "Yunjian Jia",
      "Min Wang",
      "Dapeng Oliver Wu"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.16172"
  },
  {
    "id": "arXiv:2210.16173",
    "title": "Deep Learning Object Detection Approaches to Source Identification",
    "abstract": "Traditionally source identification is solved using threshold based energy\ndetection algorithms. These algorithms frequently sum up the activity in\nregions, and consider regions above a specific activity threshold to be\nsources. While these algorithms work for the majority of cases, they often fail\nto detect signals that occupy small frequency bands, fail to distinguish\nsources with overlapping frequency bands, and cannot detect any signals under a\nspecified signal to noise ratio. Through the conversion of raw signal data to\nspectrogram, source identification can be framed as an object detection\nproblem. By leveraging modern advancements in deep learning based object\ndetection, we propose a system that manages to alleviate the failure cases\nencountered when using traditional source identification algorithms. Our\ncontributions include framing source identification as an object detection\nproblem, the publication of a spectrogram object detection dataset, and\nevaluation of the RetinaNet and YOLOv5 object detection models trained on the\ndataset. Our final models achieve Mean Average Precisions of up to 0.906. With\nsuch a high Mean Average Precision, these models are sufficiently robust for\nuse in real world applications.",
    "descriptor": "",
    "authors": [
      "Luke Wood",
      "Kevin Anderson",
      "Peter Gerstoft"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16173"
  },
  {
    "id": "arXiv:2210.16174",
    "title": "Multimodal Transformer for Parallel Concatenated Variational  Autoencoders",
    "abstract": "In this paper, we propose a multimodal transformer using parallel\nconcatenated architecture. Instead of using patches, we use column stripes for\nimages in R, G, B channels as the transformer input. The column stripes keep\nthe spatial relations of original image. We incorporate the multimodal\ntransformer with variational autoencoder for synthetic cross-modal data\ngeneration. The multimodal transformer is designed using multiple compression\nmatrices, and it serves as encoders for Parallel Concatenated Variational\nAutoEncoders (PC-VAE). The PC-VAE consists of multiple encoders, one latent\nspace, and two decoders. The encoders are based on random Gaussian matrices and\ndon't need any training. We propose a new loss function based on the\ninteraction information from partial information decomposition. The interaction\ninformation evaluates the input cross-modal information and decoder output. The\nPC-VAE are trained via minimizing the loss function. Experiments are performed\nto validate the proposed multimodal transformer for PC-VAE.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Vision Transformers: Theory and Application, New Orleans, LA, December 2022\n",
    "authors": [
      "Stephen D. Liang",
      "Jerry M. Mendel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16174"
  },
  {
    "id": "arXiv:2210.16175",
    "title": "Game-Theoretical Perspectives on Active Equilibria: A Preferred Solution  Concept over Nash Equilibria",
    "abstract": "Multiagent learning settings are inherently more difficult than single-agent\nlearning because each agent interacts with other simultaneously learning agents\nin a shared environment. An effective approach in multiagent reinforcement\nlearning is to consider the learning process of agents and influence their\nfuture policies toward desirable behaviors from each agent's perspective.\nImportantly, if each agent maximizes its long-term rewards by accounting for\nthe impact of its behavior on the set of convergence policies, the resulting\nmultiagent system reaches an active equilibrium. While this new solution\nconcept is general such that standard solution concepts, such as a Nash\nequilibrium, are special cases of active equilibria, it is unclear when an\nactive equilibrium is a preferred equilibrium over other solution concepts. In\nthis paper, we analyze active equilibria from a game-theoretic perspective by\nclosely studying examples where Nash equilibria are known. By directly\ncomparing active equilibria to Nash equilibria in these examples, we find that\nactive equilibria find more effective solutions than Nash equilibria,\nconcluding that an active equilibrium is the desired solution for multiagent\nlearning settings.",
    "descriptor": "",
    "authors": [
      "Dong-Ki Kim",
      "Matthew Riemer",
      "Miao Liu",
      "Jakob N. Foerster",
      "Gerald Tesauro",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16175"
  },
  {
    "id": "arXiv:2210.16181",
    "title": "Aggregation in the Mirror Space (AIMS): Fast, Accurate Distributed  Machine Learning in Military Settings",
    "abstract": "Distributed machine learning (DML) can be an important capability for modern\nmilitary to take advantage of data and devices distributed at multiple vantage\npoints to adapt and learn. The existing distributed machine learning\nframeworks, however, cannot realize the full benefits of DML, because they are\nall based on the simple linear aggregation framework, but linear aggregation\ncannot handle the $\\textit{divergence challenges}$ arising in military\nsettings: the learning data at different devices can be heterogeneous\n($\\textit{i.e.}$, Non-IID data), leading to model divergence, but the ability\nfor devices to communicate is substantially limited ($\\textit{i.e.}$, weak\nconnectivity due to sparse and dynamic communications), reducing the ability\nfor devices to reconcile model divergence. In this paper, we introduce a novel\nDML framework called aggregation in the mirror space (AIMS) that allows a DML\nsystem to introduce a general mirror function to map a model into a mirror\nspace to conduct aggregation and gradient descent. Adapting the convexity of\nthe mirror function according to the divergence force, AIMS allows automatic\noptimization of DML. We conduct both rigorous analysis and extensive\nexperimental evaluations to demonstrate the benefits of AIMS. For example, we\nprove that AIMS achieves a loss of\n$O\\left((\\frac{m^{r+1}}{T})^{\\frac1r}\\right)$ after $T$ network-wide updates,\nwhere $m$ is the number of devices and $r$ the convexity of the mirror\nfunction, with existing linear aggregation frameworks being a special case with\n$r=2$. Our experimental evaluations using EMANE (Extendable Mobile Ad-hoc\nNetwork Emulator) for military communications settings show similar results:\nAIMS can improve DML convergence rate by up to 57\\% and scale well to more\ndevices with weak connectivity, all with little additional computation overhead\ncompared to traditional linear aggregation.",
    "descriptor": "\nComments: 9 pages. To be published in MILCOM 2022\n",
    "authors": [
      "Ryan Yang",
      "Haizhou Du",
      "Andre Wibisono",
      "Patrick Baker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.16181"
  },
  {
    "id": "arXiv:2210.16186",
    "title": "Modelling and measuring complexity of traditional and ancient  technologies using Petri nets",
    "abstract": "Technologies and their production systems are used by archaeologists and\nanthropologists to study complexity of sociotechnical systems. However, there\nare several issues that hamper agreement about what constitutes complexity and\nhow we can systematically compare the complexity of production systems. In this\nwork, we propose a novel approach to assess the behavioural and structural\ncomplexity of production systems using Petri nets. Petri nets are well known\nformal models commonly used in, for example, biological and business process\nmodelling, as well as software engineering. The use of Petri nets overcomes\nseveral obstacles of current approaches in archaeology and anthropology, such\nas the incompatibility of the intrinsic sequential logic of the available\nmethods with inherently non sequential processes, and the inability to\nexplicitly model activities and resources separately. We test the proposed\nPetri net modelling approach on two traditional production systems of adhesives\nmade by Ju hoan makers from Nyae, Namibia from Ammocharis coranica and Ozoroa\nschinzii plants. We run simulations in which we assess the complexity of these\ntwo adhesive production systems in detail and show how Petri net dynamics\nreveal the structural and behavioural complexity of different production\nscenarios. We show that concurrency may be prevalent in the production system\nof adhesive technologies and discuss how changes in location during the process\nmay serve to control the behavioural complexity of a production system. The\napproach presented in this paper paves the way for future systematic\nvisualization, analysis, and comparison of ancient production systems,\naccounting for the inherent complex, concurrent, and action and resource\noriented aspects of such processes.",
    "descriptor": "\nComments: 54 pages, 21 figures\n",
    "authors": [
      "Sebastian Fajardo",
      "Jetty Kleijn",
      "Frank W. Takes",
      "Geeske H.J. Langejans"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.16186"
  },
  {
    "id": "arXiv:2210.16187",
    "title": "GRAND-assisted Optimal Modulation",
    "abstract": "Optimal modulation (OM) schemes for Gaussian channels with peak and average\npower constraints are known to require nonuniform probability distributions\nover signal points, which presents practical challenges. An established way to\nmap uniform binary sources to non-uniform symbol distributions is to assign a\ndifferent number of bits to different constellation points. Doing so, however,\nmeans that erroneous demodulation at the receiver can lead to bit insertions or\ndeletions that result in significant binary error propagation. In this paper,\nwe introduce a light-weight variant of Guessing Random Additive Noise Decoding\n(GRAND) to resolve insertion and deletion errors at the receiver by using a\nsimple padding scheme. Performance evaluation demonstrates that our approach\nresults in an overall gain in demodulated bit-error-rate of over 2 dB Eb/N0\nwhen compared to 128-Quadrature Amplitude Modulation (QAM). The GRAND-aided OM\nscheme outperforms coding with a low-density parity check code of the same\naverage rate as that induced by our simple padding.",
    "descriptor": "\nComments: Presented at IEEE Globecom 2022\n",
    "authors": [
      "Basak Ozaydin",
      "Muriel M\u00e9dard",
      "Ken Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.16187"
  },
  {
    "id": "arXiv:2210.16192",
    "title": "Supervised Contrastive Learning for Respiratory Sound Classification",
    "abstract": "Automatic respiratory sound classification using machine learning is a\nchallenging task, due to large biological variability, imbalanced datasets, as\nwell as a diversity in recording techniques used to capture the respiration\nsignal. While datasets with annotated respiration cycles have been proposed,\nmethods based on supervised learning using annotations only may be limited in\ntheir generalization capability. In this study, we address this issue using\nsupervised contrastive learning, relying both on respiration cycle annotations\nand a spectrogram frequency and temporal masking method SpecAugment to generate\naugmented samples for representation learning with a contrastive loss. We\ndemonstrate that such an approach can outperform supervised learning using\nexperiments on a convolutional neural network trained from scratch, achieving\nthe new state of the art. Our work shows the potential of supervised\ncontrastive learning in imbalanced and noisy settings. Our code is released at\nhttps://github.com/ilyassmoummad/scl_icbhi2017",
    "descriptor": "",
    "authors": [
      "Ilyass Moummad",
      "Nicolas Farrugia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16192"
  },
  {
    "id": "arXiv:2210.16193",
    "title": "M3FGM:a node masking and multi-granularity message passing-based  federated graph model for spatial-temporal data prediction",
    "abstract": "Researchers are solving the challenges of spatial-temporal prediction by\ncombining Federated Learning (FL) and graph models with respect to the\nconstrain of privacy and security. However, there are still several issues left\nunattended: 1) Clients might not be able to access the server during inference\nphase; 2) The graph of clients designed manually in the server model may not\nreveal the proper relationship between clients. This paper proposes a new\nembeddings aggregation structured FL approach named node Masking and\nMulti-granularity Message passing-based Federated Graph Model (M3FGM) for the\nabove issues. The server model of M3FGM employs a MaskNode layer to simulate\nthe case of offline clients. We also redesign the decoder of the client model\nusing a dual-sub-decoders structure so that each client model can use its local\ndata to predict independently when offline. As for the second issue, A new GNN\nlayer named Multi-Granularity Message Passing (MGMP) allows each client node to\nperceive global and local information.We conducted extensive experiments in two\ndifferent scenarios on two real traffic datasets. Results show that the\nproposed model outperforms the baselines and variant models, achieves the best\nresults in both scenarios.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yuxing Tian",
      "Zheng Liu",
      "Yanwen Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16193"
  },
  {
    "id": "arXiv:2210.16194",
    "title": "Environment-aware Interactive Movement Primitives for Object Reaching in  Clutter",
    "abstract": "The majority of motion planning strategies developed over the literature for\nreaching an object in clutter are applied to two dimensional (2-d) space where\nthe state space of the environment is constrained in one direction. Fewer works\nhave been investigated to reach a target in 3-d cluttered space, and when so,\nthey have limited performance when applied to complex cases. In this work, we\npropose a constrained multi-objective optimization framework (OptI-ProMP) to\napproach the problem of reaching a target in a compact clutter with a case\nstudy on soft fruits grown in clusters, leveraging the local optimisation-based\nplanner CHOMP. OptI-ProMP features costs related to both static, dynamic and\npushable objects in the target neighborhood, and it relies on probabilistic\nprimitives for problem initialisation. We tested, in a simulated poly-tunnel,\nboth ProMP-based planners from literature and the OptI-ProMP, on low (3-dofs)\nand high (7-dofs) dexterity robot body, respectively. Results show collision\nand pushing costs minimisation with 7-dofs robot kinematics, in addition to\nsuccessful static obstacles avoidance and systematic drifting from the pushable\nobjects center of mass.",
    "descriptor": "\nComments: 6 pages. 2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)\n",
    "authors": [
      "Sariah Mghames",
      "Marc Hanheide"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16194"
  },
  {
    "id": "arXiv:2210.16196",
    "title": "Convergence analysis of a quasi-Monte Carlo-based deep learning  algorithm for solving partial differential equations",
    "abstract": "Deep learning methods have achieved great success in solving partial\ndifferential equations (PDEs), where the loss is often defined as an integral.\nThe accuracy and efficiency of these algorithms depend greatly on the\nquadrature method. We propose to apply quasi-Monte Carlo (QMC) methods to the\nDeep Ritz Method (DRM) for solving the Neumann problems for the Poisson\nequation and the static Schr\\\"{o}dinger equation. For error estimation, we\ndecompose the error of using the deep learning algorithm to solve PDEs into the\ngeneralization error, the approximation error and the training error. We\nestablish the upper bounds and prove that QMC-based DRM achieves an\nasymptotically smaller error bound than DRM. Numerical experiments show that\nthe proposed method converges faster in all cases and the variances of the\ngradient estimators of randomized QMC-based DRM are much smaller than those of\nDRM, which illustrates the superiority of QMC in deep learning over MC.",
    "descriptor": "\nComments: 27 pages, 4 figures, 2 tables\n",
    "authors": [
      "Fengjiang Fu",
      "Xiaoqun Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16196"
  },
  {
    "id": "arXiv:2210.16204",
    "title": "TripletTrack: 3D Object Tracking using Triplet Embeddings and LSTM",
    "abstract": "3D object tracking is a critical task in autonomous driving systems. It plays\nan essential role for the system's awareness about the surrounding environment.\nAt the same time there is an increasing interest in algorithms for autonomous\ncars that solely rely on inexpensive sensors, such as cameras. In this paper we\ninvestigate the use of triplet embeddings in combination with motion\nrepresentations for 3D object tracking. We start from an off-the-shelf 3D\nobject detector, and apply a tracking mechanism where objects are matched by an\naffinity score computed on local object feature embeddings and motion\ndescriptors. The feature embeddings are trained to include information about\nthe visual appearance and monocular 3D object characteristics, while motion\ndescriptors provide a strong representation of object trajectories. We will\nshow that our approach effectively re-identifies objects, and also behaves\nreliably and accurately in case of occlusions, missed detections and can detect\nre-appearance across different field of views. Experimental evaluation shows\nthat our approach outperforms state-of-the-art on nuScenes by a large margin.\nWe also obtain competitive results on KITTI.",
    "descriptor": "\nComments: Accepted to CVPR 2022 Workshop on Autonomous Driving\n",
    "authors": [
      "Nicola Marinello",
      "Marc Proesmans",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16204"
  },
  {
    "id": "arXiv:2210.16205",
    "title": "Local Model Reconstruction Attacks in Federated Learning and their Uses",
    "abstract": "In this paper, we initiate the study of local model reconstruction attacks\nfor federated learning, where a honest-but-curious adversary eavesdrops the\nmessages exchanged between a targeted client and the server, and then\nreconstructs the local/personalized model of the victim. The local model\nreconstruction attack allows the adversary to trigger other classical attacks\nin a more effective way, since the local model only depends on the client's\ndata and can leak more private information than the global model learned by the\nserver. Additionally, we propose a novel model-based attribute inference attack\nin federated learning leveraging the local model reconstruction attack. We\nprovide an analytical lower-bound for this attribute inference attack.\nEmpirical results using real world datasets confirm that our local\nreconstruction attack works well for both regression and classification tasks.\nMoreover, we benchmark our novel attribute inference attack against the\nstate-of-the-art attacks in federated learning. Our attack results in higher\nreconstruction accuracy especially when the clients' datasets are\nheterogeneous. Our work provides a new angle for designing powerful and\nexplainable attacks to effectively quantify the privacy risk in FL.",
    "descriptor": "",
    "authors": [
      "Ilias Driouich",
      "Chuan Xu",
      "Giovanni Neglia",
      "Frederic Giroire",
      "Eoin Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.16205"
  },
  {
    "id": "arXiv:2210.16209",
    "title": "SoK: Not Quite Water Under the Bridge: Review of Cross-Chain Bridge  Hacks",
    "abstract": "The blockchain ecosystem has evolved into a multi-chain world with various\nblockchains vying for use. Although each blockchain may have its own native\ncryptocurrency or digital assets, there are use cases to transfer these assets\nbetween blockchains. Systems that bring these digital assets across blockchains\nare called bridges, and have become important parts of the ecosystem. The\ndesigns of bridges vary and range from quite primitive to extremely complex.\nHowever, they typically consist of smart contracts holding and releasing\ndigital assets, as well as nodes that help facilitate user interactions between\nchains. In this paper, we first provide a high level breakdown of components in\na bridge and the different processes for some bridge designs. In doing this, we\nidentify risks associated with bridge components. Then we analyse past exploits\nin the blockchain ecosystem that specifically targeted bridges.",
    "descriptor": "\nComments: 37 pages, 15 figures\n",
    "authors": [
      "Sung-Shine Lee",
      "Alexandr Murashkin",
      "Martin Derka",
      "Jan Gorzny"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.16209"
  },
  {
    "id": "arXiv:2210.16220",
    "title": "Interactive Imitation Learning of Bimanual Movement Primitives",
    "abstract": "Performing bimanual tasks with dual robotic setups can drastically increase\nthe impact on industrial and daily life applications. However, performing a\nbimanual task brings many challenges, like synchronization and coordination of\nthe single-arm policies. This article proposes the Safe, Interactive Movement\nPrimitives Learning (SIMPLe) algorithm, to teach and correct single or dual arm\nimpedance policies directly from human kinesthetic demonstrations. Moreover, it\nproposes a novel graph encoding of the policy based on Gaussian Process\nRegression (GPR) where the single-arm motion is guaranteed to converge close to\nthe trajectory and then towards the demonstrated goal. A modulation of the\nrobot stiffness according to the epistemic uncertainty of the policy allows for\neasily reshaping the motion with human feedback and/or adapting to external\nperturbations. We tested the SIMPLe algorithm on a real dual arm set up where\nthe teacher gave separate single-arm demonstrations and then successfully\nsynchronized them only using kinesthetic feedback or where the original\nbimanual demonstration was locally reshaped to pick a box at a different\nheight.",
    "descriptor": "",
    "authors": [
      "Giovanni Franzese",
      "Leandro de Souza Rosa",
      "Tim Verburg",
      "Luka Peternel",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16220"
  },
  {
    "id": "arXiv:2210.16222",
    "title": "Improving Lipschitz-Constrained Neural Networks by Learning Activation  Functions",
    "abstract": "Lipschitz-constrained neural networks have several advantages compared to\nunconstrained ones and can be applied to various different problems.\nConsequently, they have recently attracted considerable attention in the deep\nlearning community. Unfortunately, it has been shown both theoretically and\nempirically that networks with ReLU activation functions perform poorly under\nsuch constraints. On the contrary, neural networks with learnable 1-Lipschitz\nlinear splines are known to be more expressive in theory. In this paper, we\nshow that such networks are solutions of a functional optimization problem with\nsecond-order total-variation regularization. Further, we propose an efficient\nmethod to train such 1-Lipschitz deep spline neural networks. Our numerical\nexperiments for a variety of tasks show that our trained networks match or\noutperform networks with activation functions specifically tailored towards\nLipschitz-constrained architectures.",
    "descriptor": "",
    "authors": [
      "Stanislas Ducotterd",
      "Alexis Goujon",
      "Pakshal Bohra",
      "Dimitris Perdios",
      "Sebastian Neumayer",
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16222"
  },
  {
    "id": "arXiv:2210.16226",
    "title": "Discovery Dynamics: Leveraging Repeated Exposure for User and Music  Characterization",
    "abstract": "Repetition in music consumption is a common phenomenon. It is notably more\nfrequent when compared to the consumption of other media, such as books and\nmovies. In this paper, we show that one particularly interesting repetitive\nbehavior arises when users are consuming new items. Users' interest tends to\nrise with the first repetitions and attains a peak after which interest will\ndecrease with subsequent exposures, resulting in an inverted-U shape. This\nbehavior, which has been extensively studied in psychology, is called the mere\nexposure effect. In this paper, we show how a number of factors, both content\nand user-based, well documented in the literature on the mere exposure effect,\nmodulate the magnitude of the effect. Due to the vast availability of data of\nusers discovering new songs everyday in music streaming platforms, these\nfindings enable new ways to characterize both the music, users and their\nrelationships. Ultimately, it opens up the possibility of developing new\nrecommender systems paradigms based on these characterizations.",
    "descriptor": "",
    "authors": [
      "Bruno Sguerra",
      "Viet-Anh Tran",
      "Romain Hennequin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.16226"
  },
  {
    "id": "arXiv:2210.16227",
    "title": "Recursive/Iterative unique Projection-Aggregation of RM codes",
    "abstract": "We describe recursive unique projection-aggregation (RUPA) decoding and\niterative unique projection-aggregation (IUPA) decoding of Reed-Muller (RM)\ncodes, which remove non-unique projections from the recursive\nprojection-aggregation (RPA) and iterative projection-aggregation (IPA)\nalgorithms respectively. We show that these algorithms have competitive\nerror-correcting performance while requiring up to 95% projections less than\nthe baseline RPA algorithm.",
    "descriptor": "",
    "authors": [
      "Marzieh Hashemipour-Nazari",
      "Renate Debets",
      "Kees Goossens",
      "Alexios Balatsoukas-Stimming"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.16227"
  },
  {
    "id": "arXiv:2210.16228",
    "title": "Probing for targeted syntactic knowledge through grammatical error  detection",
    "abstract": "Targeted studies testing knowledge of subject-verb agreement (SVA) indicate\nthat pre-trained language models encode syntactic information. We assert that\nif models robustly encode subject-verb agreement, they should be able to\nidentify when agreement is correct and when it is incorrect. To that end, we\npropose grammatical error detection as a diagnostic probe to evaluate\ntoken-level contextual representations for their knowledge of SVA. We evaluate\ncontextual representations at each layer from five pre-trained English language\nmodels: BERT, XLNet, GPT-2, RoBERTa, and ELECTRA. We leverage public annotated\ntraining data from both English second language learners and Wikipedia edits,\nand report results on manually crafted stimuli for subject-verb agreement. We\nfind that masked language models linearly encode information relevant to the\ndetection of SVA errors, while the autoregressive models perform on par with\nour baseline. However, we also observe a divergence in performance when probes\nare trained on different training sets, and when they are evaluated on\ndifferent syntactic constructions, suggesting the information pertaining to SVA\nerror detection is not robustly encoded.",
    "descriptor": "\nComments: CoNLL 2022\n",
    "authors": [
      "Christopher Davis",
      "Christopher Bryant",
      "Andrew Caines",
      "Marek Rei",
      "Paula Buttery"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16228"
  },
  {
    "id": "arXiv:2210.16231",
    "title": "Universal speaker recognition encoders for different speech segments  duration",
    "abstract": "Creating universal speaker encoders which are robust for different acoustic\nand speech duration conditions is a big challenge today. According to our\nobservations systems trained on short speech segments are optimal for short\nphrase speaker verification and systems trained on long segments are superior\nfor long segments verification. A system trained simultaneously on pooled short\nand long speech segments does not give optimal verification results and usually\ndegrades both for short and long segments. This paper addresses the problem of\ncreating universal speaker encoders for different speech segments duration. We\ndescribe our simple recipe for training universal speaker encoder for any type\nof selected neural network architecture. According to our evaluation results of\nwav2vec-TDNN based systems obtained for NIST SRE and VoxCeleb1 benchmarks the\nproposed universal encoder provides speaker verification improvements in case\nof different enrollment and test speech segment duration. The key feature of\nthe proposed encoder is that it has the same inference time as the selected\nneural network architecture.",
    "descriptor": "\nComments: Submitted to ICASSP'23\n",
    "authors": [
      "Sergey Novoselov",
      "Vladimir Volokhov",
      "Galina Lavrentyeva"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16231"
  },
  {
    "id": "arXiv:2210.16234",
    "title": "Revisiting the matrix polynomial greatest common divisor",
    "abstract": "In this paper we revisit the greatest common right divisor (GCRD) extraction\nfrom a set of polynomial matrices $P_i(\\lambda)\\in \\F[\\la]^{m_i\\times n}$,\n$i=1,\\ldots,k$ with coefficients in a generic field $\\F$, and with common\ncolumn dimension $n$. We give necessary and sufficient conditions for a matrix\n$G(s)\\in \\F[\\la]^{\\ell\\times n}$ to be a GCRD using the Smith normal form of\nthe $m \\times n$ compound matrix obtained by concatenating $P_i(\\lambda)$\nvertically, where $m=\\sum_{i=1}^k m_i$. We also describe the complete set of\ndegrees of freedom for the solution $G(s)$, and we link it to the Smith form\nand Hermite form of $P(\\la)$. We then give an algorithm for constructing a\nparticular minimum rank solution for this problem when $\\F\\subseteq\\C$, using\nstate-space techniques. This new method works directly on the coefficient\nmatrices of $P(\\la)$, using orthogonal transformations only. The method is\nbased on the staircase algorithm, applied to a particular pencil derived from a\ngeneralized state-space model of $P(\\la)$.",
    "descriptor": "",
    "authors": [
      "Vanni Noferini",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.16234"
  },
  {
    "id": "arXiv:2210.16236",
    "title": "Multi-task Video Enhancement for Dental Interventions",
    "abstract": "A microcamera firmly attached to a dental handpiece allows dentists to\ncontinuously monitor the progress of conservative dental procedures. Video\nenhancement in video-assisted dental interventions alleviates low-light, noise,\nblur, and camera handshakes that collectively degrade visual comfort. To this\nend, we introduce a novel deep network for multi-task video enhancement that\nenables macro-visualization of dental scenes. In particular, the proposed\nnetwork jointly leverages video restoration and temporal alignment in a\nmulti-scale manner for effective video enhancement. Our experiments on videos\nof natural teeth in phantom scenes demonstrate that the proposed network\nachieves state-of-the-art results in multiple tasks with near real-time\nprocessing. We release Vident-lab at https://doi.org/10.34808/1jby-ay90, the\nfirst dataset of dental videos with multi-task labels to facilitate further\nresearch in relevant video processing applications.",
    "descriptor": "\nComments: Accepted at MICCAI 2022: this https URL\n",
    "authors": [
      "Efklidis Katsaros",
      "Piotr K. Ostrowski",
      "Krzysztof W\u0142\u00f3darczak",
      "Emilia Lewandowska",
      "Jacek Ruminski",
      "Damian Siupka-Mr\u00f3z",
      "\u0141ukasz Lassmann",
      "Anna Jezierska",
      "Daniel W\u0119sierski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.16236"
  },
  {
    "id": "arXiv:2210.16237",
    "title": "A Survey on Fundamental Concepts and Practical Challenges of  Hyperspectral images",
    "abstract": "The Remote sensing provides a synoptic view of land by detecting the energy\nreflected from Earth's surface. The Hyperspectral images (HSI) use perfect\nsensors that extract more than a hundred of images, with more detailed\ninformation than using traditional Multispectral data. In this paper, we aim to\nstudy this aspect of communication in the case of passive reception. First, a\nbrief overview of acquisition process and treatment of Hyperspectral images is\nprovided. Then, we explain representation spaces and the various analysis\nmethods of these images. Furthermore, the factors influencing this analysis are\ninvestigated and some applications, in this area, are presented. Finally, we\nexplain the relationship between Hyperspectral images and Datamining and we\noutline the open issues related to this area. So we consider the case study:\nHSI AVIRIS 92AV3C. This study serves as map of route for integrating\nclassification methods in the higher dimensionality data.\nKeywords-component: Hyperspectral images, Passive Sensing,Classification,\nData mining.",
    "descriptor": "",
    "authors": [
      "Hasna Nhaila",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16237"
  },
  {
    "id": "arXiv:2210.16239",
    "title": "Hyperspectral images classification and Dimensionality Reduction using  Homogeneity feature and mutual information",
    "abstract": "The Hyperspectral image (HSI) contains several hundred bands of the same\nregion called the Ground Truth (GT). The bands are taken in juxtaposed\nfrequencies, but some of them are noisily measured or contain no information.\nFor the classification, the selection of bands, affects significantly the\nresults of classification, in fact, using a subset of relevant bands, these\nresults can be better than those obtained using all bands, from which the need\nto reduce the dimensionality of the HSI. In this paper, a categorization of\ndimensionality reduction methods, according to the generation process, is\npresented. Furthermore, we reproduce an algorithm based on mutual information\n(MI) to reduce dimensionality by features selection and we introduce an\nalgorithm using mutual information and homogeneity. The two schemas are a\nfilter strategy. Finally, to validate this, we consider the case study AVIRIS\nHSI 92AV3C.\nKeywords: Hyperspectrale images; classification; features selection; mutual\ninformation; homogeneity",
    "descriptor": "",
    "authors": [
      "Hasna Nhaila",
      "Maria Merzouqi",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16239"
  },
  {
    "id": "arXiv:2210.16242",
    "title": "Fairness Certificates for Differentially Private Classification",
    "abstract": "In this work, we theoretically study the impact of differential privacy on\nfairness in binary classification. We prove that, given a class of models,\npopular group fairness measures are pointwise Lipschitz-continuous with respect\nto the parameters of the model. This result is a consequence of a more general\nstatement on the probability that a decision function makes a negative\nprediction conditioned on an arbitrary event (such as membership to a sensitive\ngroup), which may be of independent interest. We use the aforementioned\nLipschitz property to prove a high probability bound showing that, given enough\nexamples, the fairness level of private models is close to the one of their\nnon-private counterparts.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Paul Mangold",
      "Micha\u00ebl Perrot",
      "Aur\u00e9lien Bellet",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16242"
  },
  {
    "id": "arXiv:2210.16244",
    "title": "Design of Convolutional Extreme Learning Machines for Vision-Based  Navigation Around Small Bodies",
    "abstract": "Deep learning architectures such as convolutional neural networks are the\nstandard in computer vision for image processing tasks. Their accuracy however\noften comes at the cost of long and computationally expensive training, the\nneed for large annotated datasets, and extensive hyper-parameter searches. On\nthe other hand, a different method known as convolutional extreme learning\nmachine has shown the potential to perform equally with a dramatic decrease in\ntraining time. Space imagery, especially about small bodies, could be well\nsuited for this method. In this work, convolutional extreme learning machine\narchitectures are designed and tested against their deep-learning counterparts.\nBecause of the relatively fast training time of the former, convolutional\nextreme learning machine architectures enable efficient exploration of the\narchitecture design space, which would have been impractical with the latter,\nintroducing a methodology for an efficient design of a neural network\narchitecture for computer vision tasks. Also, the coupling between the image\nprocessing method and labeling strategy is investigated and demonstrated to\nplay a major role when considering vision-based navigation around small bodies.",
    "descriptor": "\nComments: 27 pages, 12 figures, journal contribution submitted to JGCD\n",
    "authors": [
      "Mattia Pugliatti",
      "Francesco Topputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16244"
  },
  {
    "id": "arXiv:2210.16247",
    "title": "Nonparametric Probabilistic Regression with Coarse Learners",
    "abstract": "Probabilistic Regression refers to predicting a full probability density\nfunction for the target conditional on the features. We present a nonparametric\napproach to this problem which combines base classifiers (typically gradient\nboosted forests) trained on different coarsenings of the target value. By\ncombining such classifiers and averaging the resulting densities, we are able\nto compute precise conditional densities with minimal assumptions on the shape\nor form of the density. We combine this approach with a structured\ncross-entropy loss function which serves to regularize and smooth the resulting\ndensities. Prediction intervals computed from these densities are shown to have\nhigh fidelity in practice. Furthermore, examining the properties of these\ndensities on particular observations can provide valuable insight. We\ndemonstrate this approach on a variety of datasets and show competitive\nperformance, particularly on larger datasets.",
    "descriptor": "",
    "authors": [
      "Brian Lucena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16247"
  },
  {
    "id": "arXiv:2210.16251",
    "title": "Latent Space is Feature Space: Regularization Term for GANs Training on  Limited Dataset",
    "abstract": "Generative Adversarial Networks (GAN) is currently widely used as an\nunsupervised image generation method. Current state-of-the-art GANs can\ngenerate photorealistic images with high resolution. However, a large amount of\ndata is required, or the model would prone to generate images with similar\npatterns (mode collapse) and bad quality. I proposed an additional structure\nand loss function for GANs called LFM, trained to maximize the feature\ndiversity between the different dimensions of the latent space to avoid mode\ncollapse without affecting the image quality. Orthogonal latent vector pairs\nare created, and feature vector pairs extracted by discriminator are examined\nby dot product, with which discriminator and generator are in a novel\nadversarial relationship. In experiments, this system has been built upon DCGAN\nand proved to have improvement on Frechet Inception Distance (FID) training\nfrom scratch on CelebA Dataset. This system requires mild extra performance and\ncan work with data augmentation methods. The code is available on\ngithub.com/penway/LFM.",
    "descriptor": "",
    "authors": [
      "Pengwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16251"
  },
  {
    "id": "arXiv:2210.16253",
    "title": "DOORS: Dataset fOr bOuldeRs Segmentation. Statistical properties and  Blender setup",
    "abstract": "The capability to detect boulders on the surface of small bodies is\nbeneficial for vision-based applications such as hazard detection during\ncritical operations and navigation. This task is challenging due to the wide\nassortment of irregular shapes, the characteristics of the boulders population,\nand the rapid variability in the illumination conditions. Moreover, the lack of\npublicly available labeled datasets for these applications damps the research\nabout data-driven algorithms. In this work, the authors provide a statistical\ncharacterization and setup used for the generation of two datasets about\nboulders on small bodies that are made publicly available.",
    "descriptor": "\nComments: 16 pages, 19 figures, summary paper of a dataset\n",
    "authors": [
      "Mattia Pugliatti",
      "Francesco Topputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16253"
  },
  {
    "id": "arXiv:2210.16257",
    "title": "Solving Math Word Problem via Cooperative Reasoning induced Language  Models",
    "abstract": "Large-scale pre-trained language models (PLMs) bring new opportunities to\nchallenge problems, especially those that need high-level intelligence, such as\nthe math word problem (MWPs). However, directly applying existing PLMs to MWPs\ncan fail as the generation process lacks sufficient supervision and thus lacks\nfast adaptivity as humans. We notice that human reasoning has a dual reasoning\nframework that consists of an immediate reaction system (system 1) and a\ndelicate reasoning system (system 2), where the entire reasoning is determined\nby their interaction. This inspires us to develop a cooperative\nreasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),\nresulting in a human-like reasoning architecture with system 1 as the generator\nand system 2 as the verifier. In our approach, the generator is responsible for\ngenerating reasoning paths, and the verifiers are used to supervise the\nevaluation in order to obtain reliable feedback for the generator. We evaluate\nour CoRe framework on several mathematical reasoning datasets and achieve\ndecent improvement over state-of-the-art methods, up to 9.8% increase over best\nbaselines.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhu",
      "Junjie Wang",
      "Lin Zhang",
      "Yuxiang Zhang",
      "Ruyi Gan",
      "Jiaxing Zhang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16257"
  },
  {
    "id": "arXiv:2210.16258",
    "title": "On the Vulnerability of Data Points under Multiple Membership Inference  Attacks and Target Models",
    "abstract": "Membership Inference Attacks (MIAs) infer whether a data point is in the\ntraining data of a machine learning model. It is a threat while being in the\ntraining data is private information of a data point. MIA correctly infers some\ndata points as members or non-members of the training data. Intuitively, data\npoints that MIA accurately detects are vulnerable. Considering those data\npoints may exist in different target models susceptible to multiple MIAs, the\nvulnerability of data points under multiple MIAs and target models is worth\nexploring.\nThis paper defines new metrics that can reflect the actual situation of data\npoints' vulnerability and capture vulnerable data points under multiple MIAs\nand target models. From the analysis, MIA has an inference tendency to some\ndata points despite a low overall inference performance. Additionally, we\nimplement 54 MIAs, whose average attack accuracy ranges from 0.5 to 0.9, to\nsupport our analysis with our scalable and flexible platform, Membership\nInference Attacks Platform (VMIAP). Furthermore, previous methods are\nunsuitable for finding vulnerable data points under multiple MIAs and different\ntarget models. Finally, we observe that the vulnerability is not characteristic\nof the data point but related to the MIA and target model.",
    "descriptor": "",
    "authors": [
      "Mauro Conti",
      "Jiaxin Li",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16258"
  },
  {
    "id": "arXiv:2210.16261",
    "title": "An RSE Group Model: Operational and Organizational Approaches From  Princeton University's Central Research Software Engineering Group",
    "abstract": "The Princeton Research Software Engineering Group has grown rapidly since its\ninception in late 2016. The group, housed in the central Research Computing\nDepartment, comprised of professional Research Software Engineers (RSEs), works\ndirectly with researchers to create high quality research software to enable\nnew scientific advances. As the group has matured so has the need for\nformalizing operational details and procedures. The RSE group uses an RSE\npartnership model, where Research Software Engineers work long-term with a\ndesignated academic department, institute, center, consortium, or individual\nprincipal investigator (PI). This article describes the operation of the\ncentral Princeton RSE group including funding, partner & project selection, and\nbest practices for defining expectations for a successful partnership with\nresearchers.",
    "descriptor": "\nComments: Submitted to IEEE Computing in Science & Engineering (CiSE) Special Issue on the Future of Research Software Engineers in the US\n",
    "authors": [
      "Ian A. Cosden"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16261"
  },
  {
    "id": "arXiv:2210.16264",
    "title": "Efficient Speech Translation with Dynamic Latent Perceivers",
    "abstract": "Transformers have been the dominant architecture for Speech Translation in\nrecent years, achieving significant improvements in translation quality. Since\nspeech signals are longer than their textual counterparts, and due to the\nquadratic complexity of the Transformer, a down-sampling step is essential for\nits adoption in Speech Translation. Instead, in this research, we propose to\nease the complexity by using a Perceiver encoder to map the speech inputs to a\nfixed-length latent representation. Furthermore, we introduce a novel way of\ntraining Perceivers, with Dynamic Latent Access (DLA), unlocking larger latent\nspaces without any additional computational overhead. Speech-to-Text Perceivers\nwith DLA can match the performance of a Transformer baseline across three\nlanguage pairs in MuST-C. Finally, a DLA-trained model is easily adaptable to\nDLA at inference, and can be flexibly deployed with various computational\nbudgets, without significant drops in translation quality.",
    "descriptor": "",
    "authors": [
      "Ioannis Tsiamas",
      "Gerard I. G\u00e1llego",
      "Jos\u00e9 A. R. Fonollosa",
      "Marta R. Costa-juss\u00e1"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16264"
  },
  {
    "id": "arXiv:2210.16269",
    "title": "ATM: Black-box Test Case Minimization based on Test Code Similarity and  Evolutionary Search",
    "abstract": "Executing large test suites is time and resource consuming, sometimes\nimpossible, and such test suites typically contain many redundant test cases.\nHence, test case minimization is used to remove redundant test cases that are\nunlikely to detect new faults. However, most test case minimization techniques\nrely on code coverage (white-box), model-based features, or requirements\nspecifications, which are not always accessible by test engineers. Recently, a\nset of novel techniques was proposed, called FAST-R, relying solely on test\ncase code for test case minimization, which appeared to be much more efficient\nthan white-box techniques. However, it achieved a comparable low fault\ndetection capability for Java projects, making its application challenging in\npractice. This paper proposes ATM (AST-based Test case Minimizer), a\nsimilarity-based, search-based test case minimization technique, taking a\nspecific budget as input, that also relies exclusively on the source code of\ntest cases but attempts to achieve higher fault detection through finer-grained\nsimilarity analysis and a dedicated search algorithm. ATM transforms test case\ncode into Abstract Syntax Trees (AST) and relies on four tree-based similarity\nmeasures to apply evolutionary search, specifically genetic algorithms, to\nminimize test cases. We evaluated the effectiveness and efficiency of ATM on a\nlarge dataset of 16 Java projects with 661 faulty versions using three budgets\nranging from 25% to 75% of test suites. ATM achieved significantly higher fault\ndetection rates (0.82 on average), compared to FAST-R (0.61 on average) and\nrandom minimization (0.52 on average), when running only 50% of the test cases,\nwithin practically acceptable time (1.1-4.3 hours, on average), given that\nminimization is only occasionally applied when many new test cases are created\n(major releases). Results achieved for other budgets were consistent.",
    "descriptor": "",
    "authors": [
      "Rongqi Pan",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16269"
  },
  {
    "id": "arXiv:2210.16270",
    "title": "Space-Time Graph Neural Networks with Stochastic Graph Perturbations",
    "abstract": "Space-time graph neural networks (ST-GNNs) are recently developed\narchitectures that learn efficient graph representations of time-varying data.\nST-GNNs are particularly useful in multi-agent systems, due to their stability\nproperties and their ability to respect communication delays between the\nagents. In this paper we revisit the stability properties of ST-GNNs and prove\nthat they are stable to stochastic graph perturbations. Our analysis suggests\nthat ST-GNNs are suitable for transfer learning on time-varying graphs and\nenables the design of generalized convolutional architectures that jointly\nprocess time-varying graphs and time-varying signals. Numerical experiments on\ndecentralized control systems validate our theoretical results and showcase the\nbenefits of traditional and generalized ST-GNN architectures.",
    "descriptor": "",
    "authors": [
      "Samar Hadou",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.16270"
  },
  {
    "id": "arXiv:2210.16271",
    "title": "MiCRO: Multi-interest Candidate Retrieval Online",
    "abstract": "Providing personalized recommendations in an environment where items exhibit\nephemerality and temporal relevancy (e.g. in social media) presents a few\nunique challenges: (1) inductively understanding ephemeral appeal for items in\na setting where new items are created frequently, (2) adapting to trends within\nengagement patterns where items may undergo temporal shifts in relevance, (3)\naccurately modeling user preferences over this item space where users may\nexpress multiple interests. In this work we introduce MiCRO, a generative\nstatistical framework that models multi-interest user preferences and temporal\nmulti-interest item representations. Our framework is specifically formulated\nto adapt to both new items and temporal patterns of engagement. MiCRO\ndemonstrates strong empirical performance on candidate retrieval experiments\nperformed on two large scale user-item datasets: (1) an open-source temporal\ndataset of (User, User) follow interactions and (2) a temporal dataset of\n(User, Tweet) favorite interactions which we will open-source as an additional\ncontribution to the community.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Frank Portman",
      "Stephen Ragain",
      "Ahmed El-Kishky"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.16271"
  },
  {
    "id": "arXiv:2210.16273",
    "title": "SEMPAI: a Self-Enhancing Multi-Photon Artificial Intelligence for  prior-informed assessment of muscle function and pathology",
    "abstract": "Deep learning (DL) shows notable success in biomedical studies. However, most\nDL algorithms work as a black box, exclude biomedical experts, and need\nextensive data. We introduce the Self-Enhancing Multi-Photon Artificial\nIntelligence (SEMPAI), that integrates hypothesis-driven priors in a\ndata-driven DL approach for research on multiphoton microscopy (MPM) of muscle\nfibers. SEMPAI utilizes meta-learning to optimize prior integration, data\nrepresentation, and neural network architecture simultaneously. This allows\nhypothesis testing and provides interpretable feedback about the origin of\nbiological information in MPM images. SEMPAI performs joint learning of several\ntasks to enable prediction for small datasets. The method is applied on an\nextensive multi-study dataset resulting in the largest joint analysis of\npathologies and function for single muscle fibers. SEMPAI outperforms\nstate-of-the-art biomarkers in six of seven predictive tasks, including those\nwith scarce data. SEMPAI's DL models with integrated priors are superior to\nthose without priors and to prior-only machine learning approaches.",
    "descriptor": "",
    "authors": [
      "Alexander M\u00fchlberg",
      "Paul Ritter",
      "Simon Langer",
      "Chlo\u00eb Goossens",
      "Stefanie N\u00fcbler",
      "Dominik Schneidereit",
      "Oliver Taubmann",
      "Felix Denzinger",
      "Dominik N\u00f6renberg",
      "Michael Haug",
      "Wolfgang H. Goldmann",
      "Andreas K. Maier",
      "Oliver Friedrich",
      "Lucas Kreiss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.16273"
  },
  {
    "id": "arXiv:2210.16280",
    "title": "Clustering Graphs -- Applying a Label Propagation Algorithm to Detect  Communities in Graph Databases",
    "abstract": "In the last few decades, Database Management Systems (DBMSs) became powerful\ntools for storing large amount of data and executing complex queries over them.\nIn the recent years, the growing amount of unstructured or semi-structured data\nhas seen a shift from representing data in the relational model towards\nalternative data models. Graph Databases and Graph Database Management Systems\n(GDBMSs) have seen an increase in use due to their ability to manage\nhighly-interconnected, continuously evolving data.\nThis thesis is a documentation of the work done in implementing a system to\nidentify clusters in graph modeled data using a Label Propagation Community\nDetection Algorithm. The graph was built using datasets of academic\npublications in the field of Computer Science obtained from dblp.org . The\nsystem developed is a FullStack WebApp consisting of a web-based user\ninterface, an API and the data (nodes, edges, graph) stored in a Graph Database\nManagement System (GDBMS).\nDescribed in this document are: - the process of manipulation pre-import and\nimport of the data in a Graph Database Management System (GDBMS) such as\nArangoDB, creation of nodes, relations (edges) between the nodes and a graph\ncomposed of these nodes and edges; - the GraphQL API implemented in NodeJS to\nrequest data from the Graph Database Management System (GDBMS); - the frontend\ninterface made with TypeScript and React consisting of the search\nfunctionalities and ability to visualize results in Cytoscape Network Graphs; -\nthe Label Propagation Community Detection Algorithm execution on the graph, the\nfound clusters which are stored and visualized to the user whenever requested.\nThis thesis hopes to contribute with a practical hands-on approach on the\ngraph representation, integration and analysis of interconnected data.",
    "descriptor": "\nComments: Master's Degree in Computer Science & Engineering. GitHub repo: this https URL\n",
    "authors": [
      "Andi Ferhati"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.16280"
  },
  {
    "id": "arXiv:2210.16282",
    "title": "Big Data Meets Metaverse: A Survey",
    "abstract": "We are living in the era of big data. The Metaverse is an emerging technology\nin the future, and it has a combination of big data, AI (artificial\nintelligence), VR (Virtual Reality), AR (Augmented Reality), MR (mixed\nreality), and other technologies that will diminish the difference between\nonline and real-life interaction. It has the goal of becoming a platform where\nwe can work, go shopping, play around, and socialize. Each user who enters the\nMetaverse interacts with the virtual world in a data way. With the development\nand application of the Metaverse, the data will continue to grow, thus forming\na big data network, which will bring huge data processing pressure to the\ndigital world. Therefore, big data processing technology is one of the key\ntechnologies to implement the Metaverse. In this survey, we provide a\ncomprehensive review of how Metaverse is changing big data. Moreover, we\ndiscuss the key security and privacy of Metaverse big data in detail. Finally,\nwe summarize the open problems and opportunities of Metaverse, as well as the\nfuture of Metaverse with big data. We hope that this survey will provide\nresearchers with the research direction and prospects of applying big data in\nthe Metaverse.",
    "descriptor": "\nComments: Preprint. 8 figures, 2 tables\n",
    "authors": [
      "Jiayi Sun",
      "Wensheng Gan",
      "Zefeng Chen",
      "Junhui Li",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.16282"
  },
  {
    "id": "arXiv:2210.16283",
    "title": "Boulders Identification on Small Bodies Under Varying Illumination  Conditions",
    "abstract": "The capability to detect boulders on the surface of small bodies is\nbeneficial for vision-based applications such as navigation and hazard\ndetection during critical operations. This task is challenging due to the wide\nassortment of irregular shapes, the characteristics of the boulders population,\nand the rapid variability in the illumination conditions. The authors address\nthis challenge by designing a multi-step training approach to develop a\ndata-driven image processing pipeline to robustly detect and segment boulders\nscattered over the surface of a small body. Due to the limited availability of\nlabeled image-mask pairs, the developed methodology is supported by two\nartificial environments designed in Blender specifically for this work. These\nare used to generate a large amount of synthetic image-label sets, which are\nmade publicly available to the image processing community. The methodology\npresented addresses the challenges of varying illumination conditions,\nirregular shapes, fast training time, extensive exploration of the architecture\ndesign space, and domain gap between synthetic and real images from previously\nflown missions. The performance of the developed image processing pipeline is\ntested both on synthetic and real images, exhibiting good performances, and\nhigh generalization capabilities",
    "descriptor": "\nComments: 12 pages, 15 figures, 3rd Space Imaging Workshop, Atlanta, Georgia Tech\n",
    "authors": [
      "Mattia Pugliatti",
      "Francesco Topputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.16283"
  },
  {
    "id": "arXiv:2210.16285",
    "title": "Multi-feature Dataset for Windows PE Malware Classification",
    "abstract": "This paper describes a multi-feature dataset for training machine learning\nclassifiers for detecting malicious Windows Portable Executable (PE) files. The\ndataset includes four feature sets from 18,551 binary samples belonging to five\nmalware families including Spyware, Ransomware, Downloader, Backdoor and\nGeneric Malware. The feature sets include the list of DLLs and their functions,\nvalues of different fields of PE Header and Sections. First, we explain the\ndata collection and creation phase and then we explain how did we label the\nsamples in it using VirusTotal's services. Finally, we explore the dataset to\ndescribe how this dataset can benefit the researchers for static malware\nanalysis. The dataset is made public in the hope that it will help inspire\nmachine learning research for malware detection.",
    "descriptor": "\nComments: 9 Pages, 1 Figure, 5 Tables\n",
    "authors": [
      "Muhammad Irfan Yousuf",
      "Izza Anwer",
      "Tanzeela Shakir",
      "Minahil Siddiqui",
      "Maysoon Shahid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.16285"
  },
  {
    "id": "arXiv:2210.16286",
    "title": "A Functional-Space Mean-Field Theory of Partially-Trained Three-Layer  Neural Networks",
    "abstract": "To understand the training dynamics of neural networks (NNs), prior studies\nhave considered the infinite-width mean-field (MF) limit of two-layer NN,\nestablishing theoretical guarantees of its convergence under gradient flow\ntraining as well as its approximation and generalization capabilities. In this\nwork, we study the infinite-width limit of a type of three-layer NN model whose\nfirst layer is random and fixed. To define the limiting model rigorously, we\ngeneralize the MF theory of two-layer NNs by treating the neurons as belonging\nto functional spaces. Then, by writing the MF training dynamics as a kernel\ngradient flow with a time-varying kernel that remains positive-definite, we\nprove that its training loss in $L_2$ regression decays to zero at a linear\nrate. Furthermore, we define function spaces that include the solutions\nobtainable through the MF training dynamics and prove Rademacher complexity\nbounds for these spaces. Our theory accommodates different scaling choices of\nthe model, resulting in two regimes of the MF limit that demonstrate\ndistinctive behaviors while both exhibiting feature learning.",
    "descriptor": "",
    "authors": [
      "Zhengdao Chen",
      "Eric Vanden-Eijnden",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16286"
  },
  {
    "id": "arXiv:2210.16288",
    "title": "Nonlinear Stability of Complex Droop Control in Converter-Based Power  Systems",
    "abstract": "In this letter, we study the nonlinear stability of converter-based power\nsystems, where the converter dynamics are governed by a complex droop control.\nThis complex droop control augments the well-known power-frequency (p-f) droop\ncontrol, and it proves to be equivalent to the state-of-the-art dispatchable\nvirtual oscillator control (dVOC). In this regard, it is recognized as a\npromising grid-forming solution to address the high penetration of converters\nin future power systems. In previous work, the nonlinear stability of dVOC\n(i.e., complex droop control) has been proven by prespecifying a nominal\nsynchronous steady state. For a general case of non-nominal (i.e., drooped)\nsynchronous steady states, however, the stability issue requires further\ninvestigation. We address this issue in this letter. We provide parametric\nconditions under which a non-nominal synchronous steady state exists and the\nsystem is almost globally asymptotically stable with respect to this\nnon-nominal synchronous steady state.",
    "descriptor": "",
    "authors": [
      "Xiuqiang He",
      "Verena H\u00e4berle",
      "Irina Suboti\u0107",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.16288"
  },
  {
    "id": "arXiv:2210.16294",
    "title": "Learning Modular Simulations for Homogeneous Systems",
    "abstract": "Complex systems are often decomposed into modular subsystems for engineering\ntractability. Although various equation based white-box modeling techniques\nmake use of such structure, learning based methods have yet to incorporate\nthese ideas broadly. We present a modular simulation framework for modeling\nhomogeneous multibody dynamical systems, which combines ideas from graph neural\nnetworks and neural differential equations. We learn to model the individual\ndynamical subsystem as a neural ODE module. Full simulation of the composite\nsystem is orchestrated via spatio-temporal message passing between these\nmodules. An arbitrary number of modules can be combined to simulate systems of\na wide variety of coupling topologies. We evaluate our framework on a variety\nof systems and show that message passing allows coordination between multiple\nmodules over time for accurate predictions and in certain cases, enables\nzero-shot generalization to new system configurations. Furthermore, we show\nthat our models can be transferred to new system configurations with lower data\nrequirement and training effort, compared to those trained from scratch.",
    "descriptor": "\nComments: First two authors contributed equally. Accepted at NeurIPS 2022\n",
    "authors": [
      "Jayesh K. Gupta",
      "Sai Vemprala",
      "Ashish Kapoor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.16294"
  },
  {
    "id": "arXiv:2210.16298",
    "title": "Investigating Ensemble Methods for Model Robustness Improvement of Text  Classifiers",
    "abstract": "Large pre-trained language models have shown remarkable performance over the\npast few years. These models, however, sometimes learn superficial features\nfrom the dataset and cannot generalize to the distributions that are dissimilar\nto the training scenario. There have been several approaches proposed to reduce\nmodel's reliance on these bias features which can improve model robustness in\nthe out-of-distribution setting. However, existing methods usually use a fixed\nlow-capacity model to deal with various bias features, which ignore the\nlearnability of those features. In this paper, we analyze a set of existing\nbias features and demonstrate there is no single model that works best for all\nthe cases. We further show that by choosing an appropriate bias model, we can\nobtain a better robustness result than baselines with a more sophisticated\nmodel design.",
    "descriptor": "\nComments: EMNLP 2022 Findings\n",
    "authors": [
      "Jieyu Zhao",
      "Xuezhi Wang",
      "Yao Qin",
      "Jilin Chen",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16298"
  },
  {
    "id": "arXiv:2210.16299",
    "title": "Nonuniqueness and Convergence to Equivalent Solutions in Observer-based  Inverse Reinforcement Learning",
    "abstract": "A key challenge in solving the deterministic inverse reinforcement learning\nproblem online and in real time is the existence of non-unique solutions.\nNonuniqueness necessitates the study of the notion of equivalent solutions and\nconvergence to such solutions.\nWhile \\emph{offline} algorithms that result in convergence to equivalent\nsolutions have been developed in the literature, online, real-time techniques\nthat address nonuniqueness are not available. In this paper, a regularized\nhistory stack observer is developed to generate solutions that are\napproximately equivalent. Novel data-richness conditions are developed to\nfacilitate the analysis and simulation results are provided to demonstrate the\neffectiveness of the developed technique.",
    "descriptor": "\nComments: 16 pages, 7 figures, submitted to American Controls Conference 2023\n",
    "authors": [
      "Jared Town",
      "Zachary Morrison",
      "Rushikesh Kamalapurkar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16299"
  },
  {
    "id": "arXiv:2210.16302",
    "title": "AGReE: A system for generating Automated Grammar Reading Exercises",
    "abstract": "We describe the AGReE system, which takes user-submitted passages as input\nand automatically generates grammar practice exercises that can be completed\nwhile reading. Multiple-choice practice items are generated for a variety of\ndifferent grammar constructs: punctuation, articles, conjunctions, pronouns,\nprepositions, verbs, and nouns. We also conducted a large-scale human\nevaluation with around 4,500 multiple-choice practice items. We notice for 95%\nof items, a majority of raters out of five were able to identify the correct\nanswer and for 85% of cases, raters agree that there is only one correct answer\namong the choices. Finally, the error analysis shows that raters made the most\nmistakes for punctuation and conjunctions.",
    "descriptor": "",
    "authors": [
      "Sophia Chan",
      "Swapna Somasundaran",
      "Debanjan Ghosh",
      "Mengxuan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16302"
  },
  {
    "id": "arXiv:2210.15709",
    "title": "Improvement-Focused Causal Recourse (ICR)",
    "abstract": "Algorithmic recourse recommendations, such as Karimi et al.'s (2021) causal\nrecourse (CR), inform stakeholders of how to act to revert unfavourable\ndecisions. However, some actions lead to acceptance (i.e., revert the model's\ndecision) but do not lead to improvement (i.e., may not revert the underlying\nreal-world state). To recommend such actions is to recommend fooling the\npredictor. We introduce a novel method, Improvement-Focused Causal Recourse\n(ICR), which involves a conceptual shift: Firstly, we require ICR\nrecommendations to guide towards improvement. Secondly, we do not tailor the\nrecommendations to be accepted by a specific predictor. Instead, we leverage\ncausal knowledge to design decision systems that predict accurately pre- and\npost-recourse. As a result, improvement guarantees translate into acceptance\nguarantees. We demonstrate that given correct causal knowledge, ICR, in\ncontrast to existing approaches, guides towards both acceptance and\nimprovement.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Gunnar K\u00f6nig",
      "Timo Freiesleben",
      "Moritz Grosse-Wentrup"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15709"
  },
  {
    "id": "arXiv:2210.15712",
    "title": "A mathematical framework for dynamical social interactions with  dissimulation",
    "abstract": "Modeling social interactions is a challenging task that requires flexible\nframeworks. For instance, dissimulation and externalities are relevant features\ninfluencing such systems -- elements that are often neglected in popular\nmodels. This paper is devoted to investigating general mathematical frameworks\nfor understanding social situations where agents dissimulate, and may be\nsensitive to exogenous objective information. Our model comprises a population\nwhere the participants can be honest, persuasive, or conforming. Firstly, we\nconsider a non-cooperative setting, where we establish existence, uniqueness\nand some properties of the Nash equilibria of the game. Secondly, we analyze a\ncooperative setting, identifying optimal strategies within the Pareto front. In\nboth cases, we develop numerical algorithms allowing us to computationally\nassess the behavior of our models under various settings.",
    "descriptor": "",
    "authors": [
      "Yuri Saporito",
      "Max O. Souza",
      "Yuri Thamsten"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15712"
  },
  {
    "id": "arXiv:2210.15715",
    "title": "Simulating realistic speech overlaps improves multi-talker ASR",
    "abstract": "Multi-talker automatic speech recognition (ASR) has been studied to generate\ntranscriptions of natural conversation including overlapping speech of multiple\nspeakers. Due to the difficulty in acquiring real conversation data with\nhigh-quality human transcriptions, a na\\\"ive simulation of multi-talker speech\nby randomly mixing multiple utterances was conventionally used for model\ntraining. In this work, we propose an improved technique to simulate\nmulti-talker overlapping speech with realistic speech overlaps, where an\narbitrary pattern of speech overlaps is represented by a sequence of discrete\ntokens. With this representation, speech overlapping patterns can be learned\nfrom real conversations based on a statistical language model, such as N-gram,\nwhich can be then used to generate multi-talker speech for training. In our\nexperiments, multi-talker ASR models trained with the proposed method show\nconsistent improvement on the word error rates across multiple datasets.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Muqiao Yang",
      "Naoyuki Kanda",
      "Xiaofei Wang",
      "Jian Wu",
      "Sunit Sivasankaran",
      "Zhuo Chen",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15715"
  },
  {
    "id": "arXiv:2210.15720",
    "title": "Solving the Schrodinger equation with genetic algorithms: a practical  approach",
    "abstract": "The Schrodinger equation is one of the most important equations in physics\nand chemistry and can be solved in the simplest cases by computer numerical\nmethods. Since the beginning of the 70s of the last century the computer began\nto be used to solve this equation in elementary quantum systems, e.g. and in\nthe most complex case a hydrogen-like system. Obtaining the solution means\nfinding the wave function, which allows predicting the physical and chemical\nproperties of the quantum system. However, when a quantum system is more\ncomplex than a hydrogen-like system then we must be satisfied with an\napproximate solution of the equation. During the last decade the application of\nalgorithms and principles of quantum computation in disciplines other than\nphysics and chemistry, such as biology and artificial intelligence, has led to\nthe search for alternative techniques with which to obtain approximate\nsolutions of the Schrodinger equation. In this paper, we review and illustrate\nthe application of genetic algorithms, i.e. stochastic optimization procedures\ninspired by Darwinian evolution, in elementary quantum systems and in quantum\nmodels of artificial intelligence. In this last field, we illustrate with two\ntoy models how to solve the Schrodinger equation in an elementary model of a\nquantum neuron and in the synthesis of quantum circuits controlling the\nbehavior of a Braitenberg vehicle.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Rafael Lahoz-Beltra"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15720"
  },
  {
    "id": "arXiv:2210.15724",
    "title": "Strong formulations of the generalised Navier-Stokes momentum equation",
    "abstract": "In this paper, the strong formulation of the generalised Navier-Stokes\nmomentum equation is investigated. Specifically, the formulation of\nshear-stress divergence is investigated, due to its effect on the performance\nand accuracy of computational methods. It is found that the term may be\nexpressed in two different ways. While the first formulation is commonly used,\nthe alternative derivation is found to be potentially more convenient for\ndirect numerical manipulation. The alternative formulation relocates a part of\nstrain information under the variable-coefficient Laplacian operator, thus\nmaking future computational schemes potentially simpler with larger time-step\nsizes.",
    "descriptor": "",
    "authors": [
      "Josip Basic",
      "Martina Basic",
      "Branko Blagojevic"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.15724"
  },
  {
    "id": "arXiv:2210.15754",
    "title": "Proceedings of the ACII Affective Vocal Bursts Workshop and Competition  2022 (A-VB): Understanding a critically understudied modality of emotional  expression",
    "abstract": "This is the Proceedings of the ACII Affective Vocal Bursts Workshop and\nCompetition (A-VB). A-VB was a workshop-based challenge that introduces the\nproblem of understanding emotional expression in vocal bursts -- a wide range\nof non-verbal vocalizations that includes laughs, grunts, gasps, and much more.\nWith affective states informing both mental and physical wellbeing, the core\nfocus of the A-VB workshop was the broader discussion of current strategies in\naffective computing for modeling vocal emotional expression. Within this first\niteration of the A-VB challenge, the participants were presented with four\nemotion-focused sub-challenges that utilize the large-scale and `in-the-wild'\nHume-VB dataset. The dataset and the four sub-challenges draw attention to new\ninnovations in emotion science as it pertains to vocal expression, addressing\nlow- and high-dimensional theories of emotional expression, cultural variation,\nand `call types' (laugh, cry, sigh, etc.).",
    "descriptor": "",
    "authors": [
      "Alice Baird",
      "Panagiotis Tzirakis",
      "Jeffrey A. Brooks",
      "Christopher B. Gregory",
      "Bj\u00f6rn Schuller",
      "Anton Batliner",
      "Dacher Keltner",
      "Alan Cowen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15754"
  },
  {
    "id": "arXiv:2210.15756",
    "title": "Scaling up Superconducting Quantum Computers with Cryogenic RF-photonics",
    "abstract": "Today's hundred-qubit quantum computers require a dramatic scale up to\nmillions of qubits to become practical for solving real-world problems.\nAlthough a variety of qubit technologies have been demonstrated, scalability\nremains a major hurdle. Superconducting (SC) qubits are one of the most mature\nand promising technologies to overcome this challenge. However, these qubits\nreside in a millikelvin cryogenic dilution fridge, isolating them from thermal\nand electrical noise. They are controlled by a rack-full of external\nelectronics through extremely complex wiring and cables. Although thousands of\nqubits can be fabricated on a single chip and cooled down to millikelvin\ntemperatures, scaling up the control and readout electronics remains an elusive\ngoal. This is mainly due to the limited available cooling power in cryogenic\nsystems constraining the wiring capacity and cabling heat load management.\nIn this paper, we focus on scaling up the number of XY-control lines by using\ncryogenic RF-photonic links. This is one of the major roadblocks to build a\nthousand qubit superconducting QC. We will first review and study the\nchallenges of state-of-the-art proposed approaches, including cryogenic CMOS\nand deep-cryogenic photonic methods, to scale up the control interface for SC\nqubit systems. We will discuss their limitations due to the active power\ndissipation and passive heat leakage in detail. By analytically modeling the\nnoise sources and thermal budget limits, we will show that our solution can\nachieve a scale up to a thousand of qubits. Our proposed method can be\nseamlessly implemented using advanced silicon photonic processes, and the\nnumber of required optical fibers can be further reduced by using wavelength\ndivision multiplexing (WDM).",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Sanskriti Joshi",
      "Sajjad Moazeni"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15756"
  },
  {
    "id": "arXiv:2210.15763",
    "title": "Bootstrapped Block Lanczos for large-dimension eigenvalue problems",
    "abstract": "The Lanczos algorithm has proven itself to be a valuable matrix eigensolver\nfor problems with large dimensions, up to hundreds of millions or even tens of\nbillions. The computational cost of using any Lanczos algorithm is dominated by\nthe number of sparse matrix-vector multiplications until suitable convergence\nis reached. Block Lanczos replaces sparse matrix-vector multiplication with\nsparse matrix-matrix multiplication, which is more efficient, but for a\nrandomly chosen starting block (or pivot), more multiplications are required to\nreach convergence. We find that a bootstrapped pivot block, that is, an initial\nblock constructed from approximate eigenvectors computed in a truncated space,\nleads to a dramatically reduced number of multiplications, significantly\noutperforming both standard vector Lanczos and block Lanczos with a random\npivot. A key condition for speed-up is that the pivot block have a non-trivial\noverlap with the final converged vectors. We implement this approach in a\nconfiguration-interaction code for nuclear structure, and find a reduction in\ntime-to-solution by a factor of two or more, up to a factor of ten.",
    "descriptor": "\nComments: 14 pages, 5 figures, 2 tables\n",
    "authors": [
      "Ryan M. Zbikowski",
      "Calvin W. Johnson"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2210.15763"
  },
  {
    "id": "arXiv:2210.15781",
    "title": "AmberNet: A Compact End-to-End Model for Spoken Language Identification",
    "abstract": "We present AmberNet, a compact end-to-end neural network for Spoken Language\nIdentification. AmberNet consists of 1D depth-wise separable convolutions and\nSqueeze-and-Excitation layers with global context, followed by statistics\npooling and linear layers. AmberNet achieves performance similar to\nstate-of-the-art(SOTA) models on VoxLingua107 dataset, while being 10x smaller.\nAmberNet can be adapted to unseen languages and new acoustic conditions with\nsimple finetuning. It attains SOTA accuracy of 75.8% on FLEURS benchmark. We\nshow the model is easily scalable to achieve a better trade-off between\naccuracy and speed. We further inspect the model's sensitivity to input length\nand show that AmberNet performs well even on short utterances.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Fei Jia",
      "Nithin Rao Koluguri",
      "Jagadeesh Balam",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15781"
  },
  {
    "id": "arXiv:2210.15785",
    "title": "Supply Chain Characteristics as Predictors of Cyber Risk: A  Machine-Learning Assessment",
    "abstract": "This paper provides the first large-scale data-driven analysis to evaluate\nthe predictive power of different attributes for assessing risk of cyberattack\ndata breaches. Furthermore, motivated by rapid increase in third party enabled\ncyberattacks, the paper provides the first quantitative empirical evidence that\ndigital supply-chain attributes are significant predictors of enterprise cyber\nrisk. The paper leverages outside-in cyber risk scores that aim to capture the\nquality of the enterprise internal cybersecurity management, but augment these\nwith supply chain features that are inspired by observed third party\ncyberattack scenarios, as well as concepts from network science research. The\nmain quantitative result of the paper is to show that supply chain network\nfeatures add significant detection power to predicting enterprise cyber risk,\nrelative to merely using enterprise-only attributes. Particularly, compared to\na base model that relies only on internal enterprise features, the supply chain\nnetwork features improve the out-of-sample AUC by 2.3\\%. Given that each cyber\ndata breach is a low probability high impact risk event, these improvements in\nthe prediction power have significant value. Additionally, the model highlights\nseveral cybersecurity risk drivers related to third party cyberattack and\nbreach mechanisms and provides important insights as to what interventions\nmight be effective to mitigate these risks.",
    "descriptor": "",
    "authors": [
      "Kevin Hu",
      "Retsef Levi",
      "Raphael Yahalom",
      "El Ghali Zerhouni"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15785"
  },
  {
    "id": "arXiv:2210.15786",
    "title": "Poisson Reweighted Laplacian Uncertainty Sampling for Graph-based Active  Learning",
    "abstract": "We show that uncertainty sampling is sufficient to achieve exploration versus\nexploitation in graph-based active learning, as long as the measure of\nuncertainty properly aligns with the underlying model and the model properly\nreflects uncertainty in unexplored regions. In particular, we use a recently\ndeveloped algorithm, Poisson ReWeighted Laplace Learning (PWLL) for the\nclassifier and we introduce an acquisition function designed to measure\nuncertainty in this graph-based classifier that identifies unexplored regions\nof the data. We introduce a diagonal perturbation in PWLL which produces\nexponential localization of solutions, and controls the exploration versus\nexploitation tradeoff in active learning. We use the well-posed continuum limit\nof PWLL to rigorously analyze our method, and present experimental results on a\nnumber of graph-based image classification problems.",
    "descriptor": "\nComments: 27 pages plus 20 pages supplemental material. Submitted to SIAM Journal on Mathematics of Data Science\n",
    "authors": [
      "Kevin Miller",
      "Jeff Calder"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15786"
  },
  {
    "id": "arXiv:2210.15793",
    "title": "Conditioning and Sampling in Variational Diffusion Models for Speech  Super-resolution",
    "abstract": "Recently, diffusion models (DMs) have been increasingly used in audio\nprocessing tasks, including speech super-resolution (SR), which aims to restore\nhigh-frequency content given low-resolution speech utterances. This is commonly\nachieved by conditioning the network of noise predictor with low-resolution\naudio. In this paper, we propose a novel sampling algorithm that communicates\nthe information of the low-resolution audio via the reverse sampling process of\nDMs. The proposed method can be a drop-in replacement for the vanilla sampling\nprocess and can significantly improve the performance of the existing works.\nMoreover, by coupling the proposed sampling method with an unconditional DM,\ni.e., a DM with no auxiliary inputs to its noise predictor, we can generalize\nit to a wide range of SR setups. We also attain state-of-the-art results on the\nVCTK Multi-Speaker benchmark with this novel formulation.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chin-Yun Yu",
      "Sung-Lin Yeh",
      "Gy\u00f6rgy Fazekas",
      "Hao Tang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15793"
  },
  {
    "id": "arXiv:2210.15798",
    "title": "Model Predictive Control of Spreading Processes via Sparse Resource  Allocation",
    "abstract": "In this paper, we propose a model predictive control (MPC) method for\nreal-time intervention of spreading processes, such as epidemics and wildfire,\nover large-scale networks. The goal is to allocate budgeted resources each time\nstep to minimize the risk of an undetected outbreak, i.e. the product of the\nprobability of an outbreak and the impact of that outbreak. By using dynamic\nprogramming relaxation, the MPC controller is reformulated as a convex\noptimization problem, in particular an exponential cone programming. We also\nprovide sufficient conditions for the closed-loop risks to asymptotically\ndecrease and a method to estimate the upper bound of when the risk will\nmonotonically decrease. Numerical results are provided for a wildfire example.",
    "descriptor": "",
    "authors": [
      "Ruigang Wang",
      "Armaghan Zafar",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15798"
  },
  {
    "id": "arXiv:2210.15799",
    "title": "Adaptive Physics-Informed Neural Operator for Coarse-Grained  Non-Equilibrium Flows",
    "abstract": "This work proposes a new machine learning (ML)-based paradigm aiming to\nenhance the computational efficiency of non-equilibrium reacting flow\nsimulations while ensuring compliance with the underlying physics. The\nframework combines dimensionality reduction and neural operators through a\nhierarchical and adaptive deep learning strategy to learn the solution of\nmulti-scale coarse-grained governing equations for chemical kinetics. The\nproposed surrogate's architecture is structured as a tree, where the leaf nodes\ncorrespond to separate physics-informed deep operator networks (PI-DeepONets).\nThe hierarchical attribute has two advantages: i) It allows the simplification\nof the training phase via transfer learning, starting from the slowest temporal\nscales; ii) It accelerates the prediction step by enabling adaptivity as the\nsurrogate's evaluation is limited to the necessary leaf nodes based on the\nlocal degree of non-equilibrium of the gas. The model is applied to the study\nof chemical kinetics relevant for application to hypersonic flight, and it is\ntested here on a pure oxygen gas mixture. The proposed ML framework can\nadaptively predict the dynamics of almost thirty species with a relative error\nsmaller than 4% for a broad range of initial conditions. This work lays the\nfoundation for constructing an efficient ML-based surrogate coupled with\nreactive Navier-Stokes solvers for accurately characterizing non-equilibrium\nphenomena.",
    "descriptor": "",
    "authors": [
      "Ivan Zanardi",
      "Simone Venturi",
      "Marco Panesi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15799"
  },
  {
    "id": "arXiv:2210.15808",
    "title": "Hyper-Connected Transformer Network for Co-Learning Multi-Modality  PET-CT Features",
    "abstract": "[18F]-Fluorodeoxyglucose (FDG) positron emission tomography - computed\ntomography (PET-CT) has become the imaging modality of choice for diagnosing\nmany cancers. Co-learning complementary PET-CT imaging features is a\nfundamental requirement for automatic tumor segmentation and for developing\ncomputer aided cancer diagnosis systems. We propose a hyper-connected\ntransformer (HCT) network that integrates a transformer network (TN) with a\nhyper connected fusion for multi-modality PET-CT images. The TN was leveraged\nfor its ability to provide global dependencies in image feature learning, which\nwas achieved by using image patch embeddings with a self-attention mechanism to\ncapture image-wide contextual information. We extended the single-modality\ndefinition of TN with multiple TN based branches to separately extract image\nfeatures. We introduced a hyper connected fusion to fuse the contextual and\ncomplementary image features across multiple transformers in an iterative\nmanner. Our results with two non-small cell lung cancer and soft-tissue sarcoma\ndatasets show that HCT achieved better performance in segmentation accuracy\nwhen compared to state-of-the-art methods. We also show that HCT produces\nconsistent performance across various image fusion strategies and network\nbackbones.",
    "descriptor": "\nComments: 18 Pages\n",
    "authors": [
      "Lei Bi",
      "Xiaohang Fu",
      "Qiufang Liu",
      "Shaoli Song",
      "David Dagan Feng",
      "Michael Fulham",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15808"
  },
  {
    "id": "arXiv:2210.15812",
    "title": "Differentiable Analog Quantum Computing for Optimization and Control",
    "abstract": "We formulate the first differentiable analog quantum computing framework with\na specific parameterization design at the analog signal (pulse) level to better\nexploit near-term quantum devices via variational methods. We further propose a\nscalable approach to estimate the gradients of quantum dynamics using a forward\npass with Monte Carlo sampling, which leads to a quantum stochastic gradient\ndescent algorithm for scalable gradient-based training in our framework.\nApplying our framework to quantum optimization and control, we observe a\nsignificant advantage of differentiable analog quantum computing against SOTAs\nbased on parameterized digital quantum circuits by orders of magnitude.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Jiaqi Leng",
      "Yuxiang Peng",
      "Yi-Ling Qiao",
      "Ming Lin",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15812"
  },
  {
    "id": "arXiv:2210.15819",
    "title": "Instance-Optimal Differentially Private Estimation",
    "abstract": "In this work, we study local minimax convergence estimation rates subject to\n$\\epsilon$-differential privacy. Unlike worst-case rates, which may be\nconservative, algorithms that are locally minimax optimal must adapt to easy\ninstances of the problem. We construct locally minimax differentially private\nestimators for one-parameter exponential families and estimating the tail rate\nof a distribution. In these cases, we show that optimal algorithms for simple\nhypothesis testing, namely the recent optimal private testers of Canonne et al.\n(2019), directly inform the design of locally minimax estimation algorithms.",
    "descriptor": "",
    "authors": [
      "Audra McMillan",
      "Adam Smith",
      "Jon Ullman"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15819"
  },
  {
    "id": "arXiv:2210.15821",
    "title": "Secure Distributed Optimization Under Gradient Attacks",
    "abstract": "In this paper, we study secure distributed optimization against arbitrary\ngradient attack in multi-agent networks. In distributed optimization, there is\nno central server to coordinate local updates, and each agent can only\ncommunicate with its neighbors on a predefined network. We consider the\nscenario where out of $n$ networked agents, a fixed but unknown fraction $\\rho$\nof the agents are under arbitrary gradient attack in that their stochastic\ngradient oracles return arbitrary information to derail the optimization\nprocess, and the goal is to minimize the sum of local objective functions on\nunattacked agents. We propose a distributed stochastic gradient method that\ncombines local variance reduction and clipping (CLIP-VRG). We show that, in a\nconnected network, when unattacked local objective functions are convex and\nsmooth, share a common minimizer, and their sum is strongly convex, CLIP-VRG\nleads to almost sure convergence of the iterates to the exact sum cost\nminimizer at all agents. We quantify a tight upper bound of the fraction $\\rho$\nof attacked agents in terms of problem parameters such as the condition number\nof the associated sum cost that guarantee exact convergence of CLIP-VRG, and\ncharacterize its asymptotic convergence rate. Finally, we empirically\ndemonstrate the effectiveness of the proposed method under gradient attacks in\nboth synthetic dataset and image classification datasets.",
    "descriptor": "\nComments: 33 pages, 8 figures\n",
    "authors": [
      "Shuhua Yu",
      "Soummya Kar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.15821"
  },
  {
    "id": "arXiv:2210.15822",
    "title": "UX-NET: Filter-and-Process-based Improved U-Net for Real-time  Time-domain Audio Separation",
    "abstract": "This study presents UX-Net, a time-domain audio separation network (TasNet)\nbased on a modified U-Net architecture. The proposed UX-Net works in real-time\nand handles either single or multi-microphone input. Inspired by the\nfilter-and-process-based human auditory behavior, the proposed system\nintroduces novel mixer and separation modules, which result in cost and memory\nefficient modeling of speech sources. The mixer module combines encoded input\nin a latent feature space and outputs a desired number of output streams. Then,\nin the separation module, a modified U-Net (UX) block is applied. The UX block\nfirst filters the encoded input at various resolutions followed by aggregating\nthe filtered information and applying recurrent processing to estimate masks of\nseparated sources. The letter 'X' in UX-Net is a name placeholder for the type\nof recurrent layer employed in the UX block. Empirical findings on the\nWSJ0-2mix benchmark dataset show that one of the UX-Net configurations\noutperforms the state-of-the-art Conv-TasNet system by 0.85 dB SI-SNR while\nusing only 16% of the model parameters, 58% fewer computations, and maintaining\nlow latency.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Kashyap Patel",
      "Anton Kovalyov",
      "Issa Panahi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15822"
  },
  {
    "id": "arXiv:2210.15826",
    "title": "Multimodal Estimation of Change Points of Physiological Arousal in  Drivers",
    "abstract": "Detecting unsafe driving states, such as stress, drowsiness, and fatigue, is\nan important component of ensuring driving safety and an essential prerequisite\nfor automatic intervention systems in vehicles. These concerning conditions are\nprimarily connected to the driver's low or high arousal levels. In this study,\nwe describe a framework for processing multimodal physiological time-series\nfrom wearable sensors during driving and locating points of prominent change in\ndrivers' physiological arousal state. These points of change could potentially\nindicate events that require just-in-time intervention. We apply time-series\nsegmentation on heart rate and breathing rate measurements and quantify their\nrobustness in capturing change points in electrodermal activity, treated as a\nreference index for arousal, as well as on self-reported stress ratings, using\nthree public datasets. Our experiments demonstrate that physiological measures\nare veritable indicators of change points of arousal and perform robustly\nacross an extensive ablation study.",
    "descriptor": "\nComments: 5 pages, 3 tables, 4 figures\n",
    "authors": [
      "Kleanthis Avramidis",
      "Tiantian Feng",
      "Digbalay Bose",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15826"
  },
  {
    "id": "arXiv:2210.15876",
    "title": "Improving short-video speech recognition using random utterance  concatenation",
    "abstract": "One of the limitations in end-to-end automatic speech recognition framework\nis its performance would be compromised if train-test utterance lengths are\nmismatched. In this paper, we propose a random utterance concatenation (RUC)\nmethod to alleviate train-test utterance length mismatch issue for short-video\nspeech recognition task. Specifically, we are motivated by observations our\nhuman-transcribed training utterances tend to be much shorter for short-video\nspontaneous speech (~3 seconds on average), while our test utterance generated\nfrom voice activity detection front-end is much longer (~10 seconds on\naverage). Such a mismatch can lead to sub-optimal performance. Experimentally,\nby using the proposed RUC method, the best word error rate reduction (WERR) can\nbe achieved with around three fold training data size increase as well as two\nutterance concatenation for each. In practice, the proposed method consistently\noutperforms the strong baseline models, where 3.64% average WERR is achieved on\n14 languages.",
    "descriptor": "\nComments: 5 pages, 2 figures, 4 tables\n",
    "authors": [
      "Haihua Xu",
      "Van Tung Pham",
      "Yerbolat Khassanov",
      "Yist Lin",
      "Tao Han",
      "Tze Yuan Chong",
      "Yi He",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15876"
  },
  {
    "id": "arXiv:2210.15887",
    "title": "Nonparallel High-Quality Audio Super Resolution with Domain Adaptation  and Resampling CycleGANs",
    "abstract": "Neural audio super-resolution models are typically trained on low- and\nhigh-resolution audio signal pairs. Although these methods achieve highly\naccurate super-resolution if the acoustic characteristics of the input data are\nsimilar to those of the training data, challenges remain: the models suffer\nfrom quality degradation for out-of-domain data, and paired data are required\nfor training. To address these problems, we propose Dual-CycleGAN, a\nhigh-quality audio super-resolution method that can utilize unpaired data based\non two connected cycle consistent generative adversarial networks (CycleGAN).\nOur method decomposes the super-resolution method into domain adaptation and\nresampling processes to handle acoustic mismatch in the unpaired low- and\nhigh-resolution signals. The two processes are then jointly optimized within\nthe CycleGAN framework. Experimental results verify that the proposed method\nsignificantly outperforms conventional methods when paired data are not\navailable. Code and audio samples are available from\nhttps://chomeyama.github.io/DualCycleGAN-Demo/.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Reo Yoneyama",
      "Ryuichi Yamamoto",
      "Kentaro Tachibana"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15887"
  },
  {
    "id": "arXiv:2210.15897",
    "title": "Single-Image HDR Reconstruction by Multi-Exposure Generation",
    "abstract": "High dynamic range (HDR) imaging is an indispensable technique in modern\nphotography. Traditional methods focus on HDR reconstruction from multiple\nimages, solving the core problems of image alignment, fusion, and tone mapping,\nyet having a perfect solution due to ghosting and other visual artifacts in the\nreconstruction. Recent attempts at single-image HDR reconstruction show a\npromising alternative: by learning to map pixel values to their irradiance\nusing a neural network, one can bypass the align-and-merge pipeline completely\nyet still obtain a high-quality HDR image. In this work, we propose a weakly\nsupervised learning method that inverts the physical image formation process\nfor HDR reconstruction via learning to generate multiple exposures from a\nsingle image. Our neural network can invert the camera response to reconstruct\npixel irradiance before synthesizing multiple exposures and hallucinating\ndetails in under- and over-exposed regions from a single input image. To train\nthe network, we propose a representation loss, a reconstruction loss, and a\nperceptual loss applied on pairs of under- and over-exposure images and thus do\nnot require HDR images for training. Our experiments show that our proposed\nmodel can effectively reconstruct HDR images. Our qualitative and quantitative\nresults show that our method achieves state-of-the-art performance on the DrTMO\ndataset. Our code is available at\nhttps://github.com/VinAIResearch/single_image_hdr.",
    "descriptor": "\nComments: WACV 2023 paper. 8 pages of content, 2 pages of references, 8 pages of supplementary material\n",
    "authors": [
      "Phuoc-Hieu Le",
      "Quynh Le",
      "Rang Nguyen",
      "Binh-Son Hua"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15897"
  },
  {
    "id": "arXiv:2210.15902",
    "title": "Learning to Immunize Images for Tamper Localization and Self-Recovery",
    "abstract": "Digital images are vulnerable to nefarious tampering attacks such as content\naddition or removal that severely alter the original meaning. It is somehow\nlike a person without protection that is open to various kinds of viruses.\nImage immunization (Imuge) is a technology of protecting the images by\nintroducing trivial perturbation, so that the protected images are immune to\nthe viruses in that the tampered contents can be auto-recovered. This paper\npresents Imuge+, an enhanced scheme for image immunization. By observing the\ninvertible relationship between image immunization and the corresponding\nself-recovery, we employ an invertible neural network to jointly learn image\nimmunization and recovery respectively in the forward and backward pass. We\nalso introduce an efficient attack layer that involves both malicious tamper\nand benign image post-processing, where a novel distillation-based JPEG\nsimulator is proposed for improved JPEG robustness. Our method achieves\npromising results in real-world tests where experiments show accurate tamper\nlocalization as well as high-fidelity content recovery. Additionally, we show\nsuperior performance on tamper localization compared to state-of-the-art\nschemes based on passive forensics.",
    "descriptor": "\nComments: Under Review. Extended version of our ACMMM 2021 paper\n",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15902"
  },
  {
    "id": "arXiv:2210.15903",
    "title": "Speaker recognition with two-step multi-modal deep cleansing",
    "abstract": "Neural network-based speaker recognition has achieved significant improvement\nin recent years. A robust speaker representation learns meaningful knowledge\nfrom both hard and easy samples in the training set to achieve good\nperformance. However, noisy samples (i.e., with wrong labels) in the training\nset induce confusion and cause the network to learn the incorrect\nrepresentation. In this paper, we propose a two-step audio-visual deep\ncleansing framework to eliminate the effect of noisy labels in speaker\nrepresentation learning. This framework contains a coarse-grained cleansing\nstep to search for the peculiar samples, followed by a fine-grained cleansing\nstep to filter out the noisy labels. Our study starts from an efficient\naudio-visual speaker recognition system, which achieves a close to perfect\nequal-error-rate (EER) of 0.01\\%, 0.07\\% and 0.13\\% on the Vox-O, E and H test\nsets. With the proposed multi-modal cleansing mechanism, four different speaker\nrecognition networks achieve an average improvement of 5.9\\%. Code has been\nmade available at:\n\\textcolor{magenta}{\\url{https://github.com/TaoRuijie/AVCleanse}}.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Ruijie Tao",
      "Kong Aik Lee",
      "Zhan Shi",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15903"
  },
  {
    "id": "arXiv:2210.15925",
    "title": "Incorporating Interactive Facts for Stock Selection via Neural Recursive  ODEs",
    "abstract": "Stock selection attempts to rank a list of stocks for optimizing investment\ndecision making, aiming at minimizing investment risks while maximizing profit\nreturns. Recently, researchers have developed various (recurrent) neural\nnetwork-based methods to tackle this problem. Without exceptions, they\nprimarily leverage historical market volatility to enhance the selection\nperformance. However, these approaches greatly rely on discrete sampled market\nobservations, which either fail to consider the uncertainty of stock\nfluctuations or predict continuous stock dynamics in the future. Besides, some\nstudies have considered the explicit stock interdependence derived from\nmultiple domains (e.g., industry and shareholder). Nevertheless, the implicit\ncross-dependencies among different domains are under-explored. To address such\nlimitations, we present a novel stock selection solution -- StockODE, a latent\nvariable model with Gaussian prior. Specifically, we devise a Movement Trend\nCorrelation module to expose the time-varying relationships regarding stock\nmovements. We design Neural Recursive Ordinary Differential Equation Networks\n(NRODEs) to capture the temporal evolution of stock volatility in a continuous\ndynamic manner. Moreover, we build a hierarchical hypergraph to incorporate the\ndomain-aware dependencies among the stocks. Experiments conducted on two\nreal-world stock market datasets demonstrate that StockODE significantly\noutperforms several baselines, such as up to 18.57% average improvement\nregarding Sharpe Ratio.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Qiang Gao",
      "Xinzhu Zhou",
      "Kunpeng Zhang",
      "Li Huang",
      "Siyuan Liu",
      "Fan Zhou"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15925"
  },
  {
    "id": "arXiv:2210.15934",
    "title": "Multiresolution Signal Processing of Financial Market Objects",
    "abstract": "Financial markets are among the most complex entities in our environment, yet\nmainstream quantitative models operate at predetermined scale, rely on linear\ncorrelation measures, and struggle to recognize non-linear or causal\nstructures. In this paper, we combine neural networks known to capture\nnon-linear associations with a multiscale decomposition approach to facilitate\na better understanding of financial market data substructures. Quantization\nkeeps our decompositions calibrated to market at every scale. We illustrate our\napproach in the context of a wide spectrum of applications.",
    "descriptor": "\nComments: 6 pages, 9 figures. Copy at this https URL may be updated more frequently than arXiv copy\n",
    "authors": [
      "Ioana Boier"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15934"
  },
  {
    "id": "arXiv:2210.15941",
    "title": "The Importance of Speech Stimuli for Pathologic Speech Classification",
    "abstract": "Current findings show that pre-trained wav2vec 2.0 models can be successfully\nused as feature extractors to discriminate on speaker-based tasks. We\ndemonstrate that latent representations extracted at different layers of a\npre-trained wav2vec 2.0 system can be effectively used for binary\nclassification of various types of pathologic speech. We examine the\npathologies laryngectomy, oral squamous cell carcinoma, parkinson's disease and\ncleft lip and palate for this purpose. The results show that a distinction\nbetween pathological and healthy voices, especially with latent representations\nfrom the lower layers, performs well with the lowest accuracy from 77.2% for\nparkinson's disease to 100% for laryngectomy classification. However,\ncross-pathology and cross-healthy tests show that the trained classifiers seem\nto be biased. The recognition rates vary considerably if there is a mismatch\nbetween training and out-of-domain test data, e.g., in age, spoken content or\nacoustic conditions.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. arXiv admin note: text overlap with arXiv:2210.15336\n",
    "authors": [
      "Ilja Baumann",
      "Dominik Wagner",
      "Franziska Braun",
      "Sebastian P. Bayerl",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15941"
  },
  {
    "id": "arXiv:2210.15949",
    "title": "IB-U-Nets: Improving medical image segmentation tasks with 3D Inductive  Biased kernels",
    "abstract": "Despite the success of convolutional neural networks for 3D medical-image\nsegmentation, the architectures currently used are still not robust enough to\nthe protocols of different scanners, and the variety of image properties they\nproduce. Moreover, access to large-scale datasets with annotated regions of\ninterest is scarce, and obtaining good results is thus difficult. To overcome\nthese challenges, we introduce IB-U-Nets, a novel architecture with inductive\nbias, inspired by the visual processing in vertebrates. With the 3D U-Net as\nthe base, we add two 3D residual components to the second encoder blocks. They\nprovide an inductive bias, helping U-Nets to segment anatomical structures from\n3D images with increased robustness and accuracy. We compared IB-U-Nets with\nstate-of-the-art 3D U-Nets on multiple modalities and organs, such as the\nprostate and spleen, using the same training and testing pipeline, including\ndata processing, augmentation and cross-validation. Our results demonstrate the\nsuperior robustness and accuracy of IB-U-Nets, especially on small datasets, as\nis typically the case in medical-image analysis. IB-U-Nets source code and\nmodels are publicly available.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Shrajan Bhandary",
      "Zahra Babaiee",
      "Dejan Kostyszyn",
      "Tobias Fechter",
      "Constantinos Zamboglou",
      "Anca-Ligia Grosu",
      "Radu Grosu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15949"
  },
  {
    "id": "arXiv:2210.15961",
    "title": "DPVIm: Differentially Private Variational Inference Improved",
    "abstract": "Differentially private (DP) release of multidimensional statistics typically\nconsiders an aggregate sensitivity, e.g. the vector norm of a high-dimensional\nvector. However, different dimensions of that vector might have widely\ndifferent magnitudes and therefore DP perturbation disproportionately affects\nthe signal across dimensions. We observe this problem in the gradient release\nof the DP-SGD algorithm when using it for variational inference (VI), where it\nmanifests in poor convergence as well as high variance in outputs for certain\nvariational parameters, and make the following contributions: (i) We\nmathematically isolate the cause for the difference in magnitudes between\ngradient parts corresponding to different variational parameters. Using this as\nprior knowledge we establish a link between the gradients of the variational\nparameters, and propose an efficient while simple fix for the problem to obtain\na less noisy gradient estimator, which we call $\\textit{aligned}$ gradients.\nThis approach allows us to obtain the updates for the covariance parameter of a\nGaussian posterior approximation without a privacy cost. We compare this to\nalternative approaches for scaling the gradients using analytically derived\npreconditioning, e.g. natural gradients. (ii) We suggest using iterate\naveraging over the DP parameter traces recovered during the training, to reduce\nthe DP-induced noise in parameter estimates at no additional cost in privacy.\nFinally, (iii) to accurately capture the additional uncertainty DP introduces\nto the model parameters, we infer the DP-induced noise from the parameter\ntraces and include that in the learned posteriors to make them $\\textit{noise\naware}$. We demonstrate the efficacy of our proposed improvements through\nvarious experiments on real data.",
    "descriptor": "",
    "authors": [
      "Joonas J\u00e4lk\u00f6",
      "Lukas Prediger",
      "Antti Honkela",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15961"
  },
  {
    "id": "arXiv:2210.15964",
    "title": "Period VITS: Variational Inference with Explicit Pitch Modeling for  End-to-end Emotional Speech Synthesis",
    "abstract": "Several fully end-to-end text-to-speech (TTS) models have been proposed that\nhave shown better performance compared to cascade models (i.e., training\nacoustic and vocoder models separately). However, they often generate unstable\npitch contour with audible artifacts when the dataset contains emotional\nattributes, i.e., large diversity of pronunciation and prosody. To address this\nproblem, we propose Period VITS, a novel end-to-end TTS model that incorporates\nan explicit periodicity generator. In the proposed method, we introduce a frame\npitch predictor that predicts prosodic features, such as pitch and voicing\nflags, from the input text. From these features, the proposed periodicity\ngenerator produces a sample-level sinusoidal source that enables the waveform\ndecoder to accurately reproduce the pitch. Finally, the entire model is jointly\noptimized in an end-to-end manner with variational inference and adversarial\nobjectives. As a result, the decoder becomes capable of generating more stable,\nexpressive, and natural output waveforms. The experimental results showed that\nthe proposed model significantly outperforms baseline models in terms of\nnaturalness, with improved pitch stability in the generated samples.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yuma Shirahata",
      "Ryuichi Yamamoto",
      "Eunwoo Song",
      "Ryo Terashima",
      "Jae-Min Kim",
      "Kentaro Tachibana"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15964"
  },
  {
    "id": "arXiv:2210.15975",
    "title": "Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band  Generation and Inverse Short-Time Fourier Transform",
    "abstract": "We propose a lightweight end-to-end text-to-speech model using multi-band\ngeneration and inverse short-time Fourier transform. Our model is based on\nVITS, a high-quality end-to-end text-to-speech model, but adopts two changes\nfor more efficient inference: 1) the most computationally expensive component\nis partially replaced with a simple inverse short-time Fourier transform, and\n2) multi-band generation, with fixed or trainable synthesis filters, is used to\ngenerate waveforms. Unlike conventional lightweight models, which employ\noptimization or knowledge distillation separately to train two cascaded\ncomponents, our method enjoys the full benefits of end-to-end optimization.\nExperimental results show that our model synthesized speech as natural as that\nsynthesized by VITS, while achieving a real-time factor of 0.066 on an Intel\nCore i7 CPU, 4.1 times faster than VITS. Moreover, a smaller version of the\nmodel significantly outperformed a lightweight baseline model with respect to\nboth naturalness and inference speed. Code and audio samples are available from\nhttps://github.com/MasayaKawamura/MB-iSTFT-VITS.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Masaya Kawamura",
      "Yuma Shirahata",
      "Ryuichi Yamamoto",
      "Kentaro Tachibana"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15975"
  },
  {
    "id": "arXiv:2210.15978",
    "title": "End-to-end Ensemble-based Feature Selection for Paralinguistics Tasks",
    "abstract": "The events of recent years have highlighted the importance of telemedicine\nsolutions which could potentially allow remote treatment and diagnosis.\nRelatedly, Computational Paralinguistics, a unique subfield of Speech\nProcessing, aims to extract information about the speaker and form an important\npart of telemedicine applications. In this work, we focus on two paralinguistic\nproblems: mask detection and breathing state prediction. Solutions developed\nfor these tasks could be invaluable and have the potential to help monitor and\nlimit the spread of a virus like COVID-19. The current state-of-the-art methods\nproposed for these tasks are ensembles based on deep neural networks like\nResNets in conjunction with feature engineering. Although these ensembles can\nachieve high accuracy, they also have a large footprint and require substantial\ncomputational power reducing portability to devices with limited resources.\nThese drawbacks also mean that the previously proposed solutions are infeasible\nto be used in a telemedicine system due to their size and speed. On the other\nhand, employing lighter feature-engineered systems can be laborious and add\nfurther complexity making them difficult to create a deployable system quickly.\nThis work proposes an ensemble-based automatic feature selection method to\nenable the development of fast and memory-efficient systems. In particular, we\npropose an output-gradient-based method to discover essential features using\nlarge, well-performing ensembles before training a smaller one. In our\nexperiments, we observed considerable (25-32%) reductions in inference times\nusing neural network ensembles based on output-gradient-based features. Our\nmethod offers a simple way to increase the speed of the system and enable\nreal-time usage while maintaining competitive results with larger-footprint\nensemble using all spectral features.",
    "descriptor": "",
    "authors": [
      "Tam\u00e1s Gr\u00f3sz",
      "Mittul Singh",
      "Sudarsana Reddy Kadiri",
      "Hemant Kathania",
      "Mikko Kurimo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15978"
  },
  {
    "id": "arXiv:2210.15982",
    "title": "Dysfluencies Seldom Come Alone -- Detection as a Multi-Label Problem",
    "abstract": "Specially adapted speech recognition models are necessary to handle stuttered\nspeech. For these to be used in a targeted manner, stuttered speech must be\nreliably detected. Recent works have treated stuttering as a multi-class\nclassification problem or viewed detecting each dysfluency type as an isolated\ntask; that does not capture the nature of stuttering, where one dysfluency\nseldom comes alone, i.e., co-occurs with others. This work explores an approach\nbased on a modified wav2vec 2.0 system for end-to-end stuttering detection and\nclassification as a multi-label problem. The method is evaluated on\ncombinations of three datasets containing English and German stuttered speech,\nyielding state-of-the-art results for stuttering detection on the\nSEP-28k-Extended dataset. Experimental results provide evidence for the\ntransferability of features and the generalizability of the method across\ndatasets and languages.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Florian H\u00f6nig",
      "Tobias Bocklet",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15982"
  },
  {
    "id": "arXiv:2210.15987",
    "title": "NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit",
    "abstract": "This paper describes the design of NNSVS, an open-source software for neural\nnetwork-based singing voice synthesis research. NNSVS is inspired by Sinsy, an\nopen-source pioneer in singing voice synthesis research, and provides many\nadditional features such as multi-stream models, autoregressive fundamental\nfrequency models, and neural vocoders. Furthermore, NNSVS provides extensive\ndocumentation and numerous scripts to build complete singing voice synthesis\nsystems. Experimental results demonstrate that our best system significantly\noutperforms our reproduction of Sinsy and other baseline systems. The toolkit\nis available at https://github.com/nnsvs/nnsvs.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Ryuichi Yamamoto",
      "Reo Yoneyama",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15987"
  },
  {
    "id": "arXiv:2210.16022",
    "title": "SG-VAD: Stochastic Gates Based Speech Activity Detection",
    "abstract": "We propose a novel voice activity detection (VAD) model in a low-resource\nenvironment. Our key idea is to model VAD as a denoising task, and construct a\nnetwork that is designed to identify nuisance features for a speech\nclassification task. We train the model to simultaneously identify irrelevant\nfeatures while predicting the type of speech event. Our model contains only\n7.8K parameters, outperforms the previously proposed methods on the AVA-Speech\nevaluation set, and provides comparative results on the HAVIC dataset. We\npresent its architecture, experimental results, and ablation study on the\nmodel's components. We publish the code and the models here\nhttps://www.github.com/jsvir/vad.",
    "descriptor": "",
    "authors": [
      "Jonathan Svirsky",
      "Ofir Lindenbaum"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16022"
  },
  {
    "id": "arXiv:2210.16028",
    "title": "Laugh Betrays You? Learning Robust Speaker Representation From Speech  Containing Non-Verbal Fragments",
    "abstract": "The success of automatic speaker verification shows that discriminative\nspeaker representations can be extracted from neutral speech. However, as a\nkind of non-verbal voice, laughter should also carry speaker information\nintuitively. Thus, this paper focuses on exploring speaker verification about\nutterances containing non-verbal laughter segments. We collect a set of clips\nwith laughter components by conducting a laughter detection script on VoxCeleb\nand part of the CN-Celeb dataset. To further filter untrusted clips,\nprobability scores are calculated by our binary laughter detection classifier,\nwhich is pre-trained by pure laughter and neutral speech. After that, based on\nthe clips whose scores are over the threshold, we construct trials under two\ndifferent evaluation scenarios: Laughter-Laughter (LL) and Speech-Laughter\n(SL). Then a novel method called Laughter-Splicing based Network (LSN) is\nproposed, which can significantly boost performance in both scenarios and\nmaintain the performance on the neutral speech, such as the VoxCeleb1 test set.\nSpecifically, our system achieves relative 20% and 22% improvement on\nLaughter-Laughter and Speech-Laughter trials, respectively. The meta-data and\nsample clips have been released at https://github.com/nevermoreLin/Laugh_LSN.",
    "descriptor": "",
    "authors": [
      "Yuke Lin",
      "Xiaoyi Qin",
      "Huahua Cui",
      "Zhenyi Zhu",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16028"
  },
  {
    "id": "arXiv:2210.16032",
    "title": "Parameter-efficient transfer learning of pre-trained Transformer models  for speaker verification using adapters",
    "abstract": "Recently, the pre-trained Transformer models have received a rising interest\nin the field of speech processing thanks to their great success in various\ndownstream tasks. However, most fine-tuning approaches update all the\nparameters of the pre-trained model, which becomes prohibitive as the model\nsize grows and sometimes results in overfitting on small datasets. In this\npaper, we conduct a comprehensive analysis of applying parameter-efficient\ntransfer learning (PETL) methods to reduce the required learnable parameters\nfor adapting to speaker verification tasks. Specifically, during the\nfine-tuning process, the pre-trained models are frozen, and only lightweight\nmodules inserted in each Transformer block are trainable (a method known as\nadapters). Moreover, to boost the performance in a cross-language low-resource\nscenario, the Transformer model is further tuned on a large intermediate\ndataset before directly fine-tuning it on a small dataset. With updating fewer\nthan 4% of parameters, (our proposed) PETL-based methods achieve comparable\nperformances with full fine-tuning methods (Vox1-O: 0.55%, Vox1-E: 0.82%,\nVox1-H:1.73%).",
    "descriptor": "\nComments: submitted to ICASSP2023\n",
    "authors": [
      "Junyi Peng",
      "Themos Stafylakis",
      "Rongzhi Gu",
      "Old\u0159ich Plchot",
      "Ladislav Mo\u0161ner",
      "Luk\u00e1\u0161 Burget",
      "Jan \u010cernock\u00fd"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.16032"
  },
  {
    "id": "arXiv:2210.16053",
    "title": "Automated analysis of diabetic retinopathy using vessel segmentation  maps as inductive bias",
    "abstract": "Recent studies suggest that early stages of diabetic retinopathy (DR) can be\ndiagnosed by monitoring vascular changes in the deep vascular complex. In this\nwork, we investigate a novel method for automated DR grading based on optical\ncoherence tomography angiography (OCTA) images. Our work combines OCTA scans\nwith their vessel segmentations, which then serve as inputs to task specific\nnetworks for lesion segmentation, image quality assessment and DR grading. For\nthis, we generate synthetic OCTA images to train a segmentation network that\ncan be directly applied on real OCTA data. We test our approach on MICCAI\n2022's DR analysis challenge (DRAC). In our experiments, the proposed method\nperforms equally well as the baseline model.",
    "descriptor": "\nComments: Submission for MICCAI 2022 Diabetic Retinopathy Analysis Challenge (DRAC) Proceedings, DOI: 10.5281/zenodo.6362349\n",
    "authors": [
      "Linus Kreitner",
      "Ivan Ezhov",
      "Daniel Rueckert",
      "Johannes C. Paetzold",
      "Martin J. Menten"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16053"
  },
  {
    "id": "arXiv:2210.16060",
    "title": "Deep network series for large-scale high-dynamic range imaging",
    "abstract": "We propose a new approach for large-scale high-dynamic range computational\nimaging. Deep Neural Networks (DNNs) trained end-to-end can solve linear\ninverse imaging problems almost instantaneously. While unfolded architectures\nprovide necessary robustness to variations of the measurement setting,\nembedding large-scale measurement operators in DNN architectures is\nimpractical. Alternative Plug-and-Play (PnP) approaches, where the denoising\nDNNs are blind to the measurement setting, have proven effective to address\nscalability and high-dynamic range challenges, but rely on highly iterative\nalgorithms. We propose a residual DNN series approach, where the reconstructed\nimage is built as a sum of residual images progressively increasing the dynamic\nrange, and estimated iteratively by DNNs taking the back-projected data\nresidual of the previous iteration as input. We demonstrate on simulations for\nradio-astronomical imaging that a series of only few terms provides a\nhigh-dynamic range reconstruction of similar quality to state-of-the-art PnP\napproaches, at a fraction of the cost.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table\n",
    "authors": [
      "Amir Aghabiglou",
      "Matthieu Terris",
      "Adrian Jackson",
      "Yves Wiaux"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16060"
  },
  {
    "id": "arXiv:2210.16062",
    "title": "Neural Network based Formation of Cognitive Maps of Semantic Spaces and  the Emergence of Abstract Concepts",
    "abstract": "The hippocampal-entorhinal complex plays a major role in the organization of\nmemory and thought. The formation of and navigation in cognitive maps of\narbitrary mental spaces via place and grid cells can serve as a representation\nof memories and experiences and their relations to each other. The multi-scale\nsuccessor representation is proposed to be the mathematical principle\nunderlying place and grid cell computations. Here, we present a neural network,\nwhich learns a cognitive map of a semantic space based on 32 different animal\nspecies encoded as feature vectors. The neural network successfully learns the\nsimilarities between different animal species, and constructs a cognitive map\nof 'animal space' based on the principle of successor representations with an\naccuracy of around 30% which is near to the theoretical maximum regarding the\nfact that all animal species have more than one possible successor, i.e.\nnearest neighbor in feature space. Furthermore, a hierarchical structure, i.e.\ndifferent scales of cognitive maps, can be modeled based on multi-scale\nsuccessor representations. We find that, in fine-grained cognitive maps, the\nanimal vectors are evenly distributed in feature space. In contrast, in\ncoarse-grained maps, animal vectors are highly clustered according to their\nbiological class, i.e. amphibians, mammals and insects. This could be a\npossible mechanism explaining the emergence of new abstract semantic concepts.\nFinally, even completely new or incomplete input can be represented by\ninterpolation of the representations from the cognitive map with remarkable\nhigh accuracy of up to 95%. We conclude that the successor representation can\nserve as a weighted pointer to past memories and experiences, and may therefore\nbe a crucial building block for future machine learning to include prior\nknowledge, and to derive context knowledge from novel input.",
    "descriptor": "",
    "authors": [
      "Paul Stoewer",
      "Achim Schilling",
      "Andreas Maier",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16062"
  },
  {
    "id": "arXiv:2210.16097",
    "title": "cRedAnno+: Annotation Exploitation in Self-Explanatory Lung Nodule  Diagnosis",
    "abstract": "Recently, attempts have been made to reduce annotation requirements in\nfeature-based self-explanatory models for lung nodule diagnosis. As a\nrepresentative, cRedAnno achieves competitive performance with considerably\nreduced annotation needs by introducing self-supervised contrastive learning to\ndo unsupervised feature extraction. However, it exhibits unstable performance\nunder scarce annotation conditions. To improve the accuracy and robustness of\ncRedAnno, we propose an annotation exploitation mechanism by conducting\nsemi-supervised active learning in the learned semantically meaningful space to\njointly utilise the extracted features, annotations, and unlabelled data. The\nproposed approach achieves comparable or even higher malignancy prediction\naccuracy with 10x fewer annotations, meanwhile showing better robustness and\nnodule attribute prediction accuracy. Our complete code is open-source\navailable: https://github.com/diku-dk/credanno.",
    "descriptor": "\nComments: 5 pages, 5 figures, 2 tables. arXiv admin note: text overlap with arXiv:2206.13608\n",
    "authors": [
      "Jiahao Lu",
      "Chong Yin",
      "Kenny Erleben",
      "Michael Bachmann Nielsen",
      "Sune Darkner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16097"
  },
  {
    "id": "arXiv:2210.16098",
    "title": "Predicting Protein-Ligand Binding Affinity with Equivariant Line Graph  Network",
    "abstract": "Binding affinity prediction of three-dimensional (3D) protein ligand\ncomplexes is critical for drug repositioning and virtual drug screening.\nExisting approaches transform a 3D protein-ligand complex to a two-dimensional\n(2D) graph, and then use graph neural networks (GNNs) to predict its binding\naffinity. However, the node and edge features of the 2D graph are extracted\nbased on invariant local coordinate systems of the 3D complex. As a result, the\nmethod can not fully learn the global information of the complex, such as, the\nphysical symmetry and the topological information of bonds. To address these\nissues, we propose a novel Equivariant Line Graph Network (ELGN) for affinity\nprediction of 3D protein ligand complexes. The proposed ELGN firstly adds a\nsuper node to the 3D complex, and then builds a line graph based on the 3D\ncomplex. After that, ELGN uses a new E(3)-equivariant network layer to pass the\nmessages between nodes and edges based on the global coordinate system of the\n3D complex. Experimental results on two real datasets demonstrate the\neffectiveness of ELGN over several state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Yiqiang Yi",
      "Xu Wan",
      "Kangfei Zhao",
      "Le Ou-Yang",
      "Peilin Zhao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16098"
  },
  {
    "id": "arXiv:2210.16099",
    "title": "An Empirical Evaluation of Zeroth-Order Optimization Methods on  AI-driven Molecule Optimization",
    "abstract": "Molecule optimization is an important problem in chemical discovery and has\nbeen approached using many techniques, including generative modeling,\nreinforcement learning, genetic algorithms, and much more. Recent work has also\napplied zeroth-order (ZO) optimization, a subset of gradient-free optimization\nthat solves problems similarly to gradient-based methods, for optimizing latent\nvector representations from an autoencoder. In this paper, we study the\neffectiveness of various ZO optimization methods for optimizing molecular\nobjectives, which are characterized by variable smoothness, infrequent optima,\nand other challenges. We provide insights on the robustness of various ZO\noptimizers in this setting, show the advantages of ZO sign-based gradient\ndescent (ZO-signGD), discuss how ZO optimization can be used practically in\nrealistic discovery tasks, and demonstrate the potential effectiveness of ZO\noptimization methods on widely used benchmark tasks from the Guacamol suite.\nCode is available at: https://github.com/IBM/QMO-bench.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Elvin Lo",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16099"
  },
  {
    "id": "arXiv:2210.16110",
    "title": "Towards prediction of turbulent flows at high Reynolds numbers using  high performance computing data and deep learning",
    "abstract": "In this paper, deep learning (DL) methods are evaluated in the context of\nturbulent flows. Various generative adversarial networks (GANs) are discussed\nwith respect to their suitability for understanding and modeling turbulence.\nWasserstein GANs (WGANs) are then chosen to generate small-scale turbulence.\nHighly resolved direct numerical simulation (DNS) turbulent data is used for\ntraining the WGANs and the effect of network parameters, such as learning rate\nand loss function, is studied. Qualitatively good agreement between DNS input\ndata and generated turbulent structures is shown. A quantitative statistical\nassessment of the predicted turbulent fields is performed.",
    "descriptor": "",
    "authors": [
      "Mathis Bode",
      "Michael Gauding",
      "Jens Henrik G\u00f6bbert",
      "Baohao Liao",
      "Jenia Jitsev",
      "Heinz Pitsch"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16110"
  },
  {
    "id": "arXiv:2210.16127",
    "title": "Target-Speaker Voice Activity Detection via Sequence-to-Sequence  Prediction",
    "abstract": "Target-speaker voice activity detection is currently a promising approach for\nspeaker diarization in complex acoustic environments. This paper presents a\nnovel Sequence-to-Sequence Target-Speaker Voice Activity Detection\n(Seq2Seq-TSVAD) method that can efficiently address the joint modeling of\nlarge-scale speakers and predict high-resolution voice activities. Experimental\nresults show that larger speaker capacity and higher output resolution can\nsignificantly reduce the diarization error rate (DER), which achieves the new\nstate-of-the-art performance of 4.55% on the VoxConverse test set and 10.77% on\nTrack 1 of the DIHARD-III evaluation set under the widely-used evaluation\nmetrics.",
    "descriptor": "\nComments: submitted to ICASSP2023\n",
    "authors": [
      "Ming Cheng",
      "Weiqing Wang",
      "Yucong Zhang",
      "Xiaoyi Qin",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16127"
  },
  {
    "id": "arXiv:2210.16176",
    "title": "A Novel Sparse Bayesian Learning and Its Application to Fault Diagnosis  for Multistation Assembly Systems",
    "abstract": "This paper addresses the problem of fault diagnosis in multistation assembly\nsystems. Fault diagnosis is to identify process faults that cause the excessive\ndimensional variation of the product using dimensional measurements. For such\nproblems, the challenge is solving an underdetermined system caused by a common\nphenomenon in practice; namely, the number of measurements is less than that of\nthe process errors. To address this challenge, this paper attempts to solve the\nfollowing two problems: (1) how to utilize the temporal correlation in the time\nseries data of each process error and (2) how to apply prior knowledge\nregarding which process errors are more likely to be process faults. A novel\nsparse Bayesian learning method is proposed to achieve the above objectives.\nThe method consists of three hierarchical layers. The first layer has\nparameterized prior distribution that exploits the temporal correlation of each\nprocess error. Furthermore, the second and third layers achieve the prior\ndistribution representing the prior knowledge of process faults. Then, these\nprior distributions are updated with the likelihood function of the measurement\nsamples from the process, resulting in the accurate posterior distribution of\nprocess faults from an underdetermined system. Since posterior distributions of\nprocess faults are intractable, this paper derives approximate posterior\ndistributions via Variational Bayes inference. Numerical and simulation case\nstudies using an actual autobody assembly process are performed to demonstrate\nthe effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jihoon Chung",
      "Bo Shen",
      "Zhenyu",
      "Kong"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16176"
  },
  {
    "id": "arXiv:2210.16189",
    "title": "Preferential Subsampling for Stochastic Gradient Langevin Dynamics",
    "abstract": "Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to\ntraditional MCMC, by constructing an unbiased estimate of the gradient of the\nlog-posterior with a small, uniformly-weighted subsample of the data. While\nefficient to compute, the resulting gradient estimator may exhibit a high\nvariance and impact sampler performance. The problem of variance control has\nbeen traditionally addressed by constructing a better stochastic gradient\nestimator, often using control variates. We propose to use a discrete,\nnon-uniform probability distribution to preferentially subsample data points\nthat have a greater impact on the stochastic gradient. In addition, we present\na method of adaptively adjusting the subsample size at each iteration of the\nalgorithm, so that we increase the subsample size in areas of the sample space\nwhere the gradient is harder to estimate. We demonstrate that such an approach\ncan maintain the same level of accuracy while substantially reducing the\naverage subsample size that is used.",
    "descriptor": "\nComments: 20 pages (including supplement), 5 figures\n",
    "authors": [
      "Srshti Putcha",
      "Christopher Nemeth",
      "Paul Fearnhead"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.16189"
  },
  {
    "id": "arXiv:2210.16190",
    "title": "Transferable E(3) equivariant parameterization for Hamiltonian of  molecules and solids",
    "abstract": "Machine learning, especially deep learning, can build a direct mapping from\nstructure to properties with its huge parameter space, making it possible to\nperform high-throughput screening for the desired properties of materials.\nHowever, since the electronic Hamiltonian transforms non-trivially under\nrotation operations, it is challenging to accurately predict the electronic\nHamiltonian while strictly satisfying this constraint. There is currently a\nlack of transferable machine learning models that can bypass the\ncomputationally demanding density functional theory (DFT) to obtain the ab\ninitio Hamiltonian of molecules and materials by complete data-driven methods.\nIn this work, we point out the necessity of explicitly considering the parity\nsymmetry of the electronic Hamiltonian in addition to rotational equivariance.\nWe propose a parameterized Hamiltonian that strictly satisfies rotational\nequivariance and parity symmetry simultaneously, based on which we develop an\nE(3) equivariant neural network called HamNet to predict the ab initio\ntight-binding Hamiltonian of various molecules and solids. The tests show that\nthis model has similar transferability to that of machine learning potentials\nand can be applied to a class of materials with different configurations using\nthe same set of trained network weights. The proposed framework provides a\ngeneral transferable model for accelerating electronic structure calculations.",
    "descriptor": "\nComments: 28 pages, 6 figures\n",
    "authors": [
      "Yang Zhong",
      "Hongyu Yu",
      "Mao Su",
      "Xingao Gong",
      "Hongjun Xiang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16190"
  },
  {
    "id": "arXiv:2210.16195",
    "title": "CNOT circuits need little help to implement arbitrary Hadamard-free  Clifford transformations they generate",
    "abstract": "A Hadamard-free Clifford transformation is a circuit composed of quantum\nPhase (P), CZ, and CNOT gates. It is known that such a circuit can be written\nas a three-stage computation, -P-CZ-CNOT-, where each stage consists only of\ngates of the specified type.\nIn this paper, we focus on the minimization of circuit depth by entangling\ngates, corresponding to the important time-to-solution metric and the reduction\nof noise due to decoherence. We consider two popular connectivity maps: Linear\nNearest Neighbor (LNN) and all-to-all. First, we show that a Hadamard-free\nClifford operation can be implemented over LNN in depth $5n$, i.e., in the same\ndepth as the -CNOT- stage alone. This implies the ability to implement\narbitrary Clifford transformation over LNN in depth no more than $7n{+}2$,\nimproving the best previous upper bound of $9n$. Second, we report heuristic\nevidence that on average a random uniformly distributed Hadamard-free Clifford\ntransformation over $n{>}6$ qubits can be implemented with only a tiny additive\nconstant overhead over all-to-all connected architecture compared to the\nbest-known depth-optimized implementation of the -CNOT- stage alone. This\nsuggests the reduction of the depth of Clifford circuits from\n$2n\\,{+}\\,O(\\log^2(n))$ to $1.5n\\,{+}\\,O(\\log^2(n))$ over unrestricted\narchitectures.",
    "descriptor": "",
    "authors": [
      "Dmitri Maslov",
      "Willers Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.16195"
  },
  {
    "id": "arXiv:2210.16206",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Turbulent Premixed Combustion and Engine-like Flame  Kernel Direct Numerical Simulation Data",
    "abstract": "Models for finite-rate-chemistry in underresolved flows still pose one of the\nmain challenges for predictive simulations of complex configurations. The\nproblem gets even more challenging if turbulence is involved. This work\nadvances the recently developed PIESRGAN modeling approach to turbulent\npremixed combustion. For that, the physical information processed by the\nnetwork and considered in the loss function are adjusted, the training process\nis smoothed, and especially effects from density changes are considered. The\nresulting model provides good results for a priori and a posteriori tests on\ndirect numerical simulation data of a fully turbulent premixed flame kernel.\nThe limits of the modeling approach are discussed. Finally, the model is\nemployed to compute further realizations of the premixed flame kernel, which\nare analyzed with a scale-sensitive framework regarding their cycle-to-cycle\nvariations. The work shows that the data-driven PIESRGAN subfilter model can\nvery accurately reproduce direct numerical simulation data on much coarser\nmeshes, which is hardly possible with classical subfilter models, and enables\nstudying statistical processes more efficiently due to the smaller computing\ncost.",
    "descriptor": "",
    "authors": [
      "Mathis Bode",
      "Michael Gauding",
      "Dominik Goeb",
      "Tobias Falkenstein",
      "Heinz Pitsch"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16206"
  },
  {
    "id": "arXiv:2210.16215",
    "title": "Physics-Informed Convolutional Neural Networks for Corruption Removal on  Dynamical Systems",
    "abstract": "Measurements on dynamical systems, experimental or otherwise, are often\nsubjected to inaccuracies capable of introducing corruption; removal of which\nis a problem of fundamental importance in the physical sciences. In this work\nwe propose physics-informed convolutional neural networks for stationary\ncorruption removal, providing the means to extract physical solutions from\ndata, given access to partial ground-truth observations at collocation points.\nWe showcase the methodology for 2D incompressible Navier-Stokes equations in\nthe chaotic-turbulent flow regime, demonstrating robustness to modality and\nmagnitude of corruption.",
    "descriptor": "\nComments: Published in NeurIPS 2022: Machine Learning and the Physical Sciences Workshop. Code at this this http URL\n",
    "authors": [
      "Daniel Kelshaw",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16215"
  },
  {
    "id": "arXiv:2210.16219",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Finite-Rate-Chemistry Flows and Predicting Lean  Premixed Gas Turbine Combustors",
    "abstract": "The accurate prediction of small scales in underresolved flows is still one\nof the main challenges in predictive simulations of complex configurations.\nOver the last few years, data-driven modeling has become popular in many fields\nas large, often extensively labeled datasets are now available and training of\nlarge neural networks has become possible on graphics processing units (GPUs)\nthat speed up the learning process tremendously. In fact, the successful\napplication of deep neural networks in fluid dynamics, such as for\nunderresolved reactive flows, is still challenging. This work advances the\nrecently introduced PIESRGAN to reactive finite-rate-chemistry flows. However,\nsince combustion chemistry typically acts on the smallest scales, the original\napproach needs to be extended. Therefore, the modeling approach of PIESRGAN is\nmodified to accurately account for the challenges in the context of laminar\nfinite-rate-chemistry flows. The modified PIESRGAN-based model gives good\nagreement in a priori and a posteriori tests in a laminar lean premixed\ncombustion setup. Furthermore, a reduced PIESRGAN-based model is presented that\nsolves only the major species on a reconstructed field and employs PIERSGAN\nlookup for the remaining species, utilizing staggering in time. The advantages\nof the discriminator-supported training are shown, and the usability of the new\nmodel demonstrated in the context of a model gas turbine combustor.",
    "descriptor": "",
    "authors": [
      "Mathis Bode"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16219"
  },
  {
    "id": "arXiv:2210.16238",
    "title": "Contextual-Utterance Training for Automatic Speech Recognition",
    "abstract": "Recent studies of streaming automatic speech recognition (ASR) recurrent\nneural network transducer (RNN-T)-based systems have fed the encoder with past\ncontextual information in order to improve its word error rate (WER)\nperformance. In this paper, we first propose a contextual-utterance training\ntechnique which makes use of the previous and future contextual utterances in\norder to do an implicit adaptation to the speaker, topic and acoustic\nenvironment. Also, we propose a dual-mode contextual-utterance training\ntechnique for streaming automatic speech recognition (ASR) systems. This\nproposed approach allows to make a better use of the available acoustic context\nin streaming models by distilling \"in-place\" the knowledge of a teacher, which\nis able to see both past and future contextual utterances, to the student which\ncan only see the current and past contextual utterances. The experimental\nresults show that a conformer-transducer system trained with the proposed\ntechniques outperforms the same system trained with the classical RNN-T loss.\nSpecifically, the proposed technique is able to reduce both the WER and the\naverage last token emission latency by more than 6% and 40ms relative,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Alejandro Gomez-Alanis",
      "Lukas Drude",
      "Andreas Schwarz",
      "Rupak Vignesh Swaminathan",
      "Simon Wiesler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.16238"
  },
  {
    "id": "arXiv:2210.16248",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Turbulent Non-Premixed Combustion on Non-Uniform  Meshes and Demonstration of an Accelerated Simulation Workflow",
    "abstract": "This paper extends the methodology to use physics-informed enhanced\nsuper-resolution generative adversarial networks (PIESRGANs) for LES subfilter\nmodeling in turbulent flows with finite-rate chemistry and shows a successful\napplication to a non-premixed temporal jet case. This is an important topic\nconsidering the need for more efficient and carbon-neutral energy devices to\nfight the climate change. Multiple a priori and a posteriori results are\npresented and discussed. As part of this, the impact of the underlying mesh on\nthe prediction quality is emphasized, and a multi-mesh approach is developed.\nIt is demonstrated how LES based on PIESRGAN can be employed to predict cases\nat Reynolds numbers which were not used for training. Finally, the amount of\ndata needed for a successful prediction is elaborated.",
    "descriptor": "",
    "authors": [
      "Mathis Bode"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16248"
  },
  {
    "id": "arXiv:2210.16272",
    "title": "Learning with Multigraph Convolutional Filters",
    "abstract": "In this paper, we introduce a convolutional architecture to perform learning\nwhen information is supported on multigraphs. Exploiting algebraic signal\nprocessing (ASP), we propose a convolutional signal processing model on\nmultigraphs (MSP). Then, we introduce multigraph convolutional neural networks\n(MGNNs) as stacked and layered structures where information is processed\naccording to an MSP model. We also develop a procedure for tractable\ncomputation of filter coefficients in the MGNN and a low cost method to reduce\nthe dimensionality of the information transferred between layers. We conclude\nby comparing the performance of MGNNs against other learning architectures on\nan optimal resource allocation task for multi-channel communication systems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.11354\n",
    "authors": [
      "Landon Butler",
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16272"
  },
  {
    "id": "arXiv:2210.16281",
    "title": "Terrain-like Graphs and the Median Genocchi Numbers",
    "abstract": "A graph with vertex set $\\{1,\\ldots,n\\}$ is terrain-like if, for any edge\npair $\\{a,c\\},\\{b,d\\}$ with $a<b<c<d$, the edge $\\{a,d\\}$ also exists.\nTerrain-like graphs frequently appear in geometry in the context of visibility\ngraphs. We show that terrain-like graphs are counted by the median Genocchi\nnumbers. To this end, we prove a bijection between terrain-like graphs and\nDumont derangements of the second kind.",
    "descriptor": "",
    "authors": [
      "Vincent Froese",
      "Malte Renken"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.16281"
  },
  {
    "id": "arXiv:2004.03853",
    "title": "Shape-Constrained Regression using Sum of Squares Polynomials",
    "abstract": "Shape-Constrained Regression using Sum of Squares Polynomials",
    "descriptor": "",
    "authors": [
      "Mihaela Curmei",
      "Georgina Hall"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2004.03853"
  },
  {
    "id": "arXiv:2005.08632",
    "title": "Universalization of any adversarial attack using very few test examples",
    "abstract": "Comments: Appeared in ACM CODS-COMAD 2022 (Research Track)",
    "descriptor": "\nComments: Appeared in ACM CODS-COMAD 2022 (Research Track)\n",
    "authors": [
      "Sandesh Kamath",
      "Amit Deshpande",
      "K V Subrahmanyam",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.08632"
  },
  {
    "id": "arXiv:2006.07218",
    "title": "An Accurate, Scalable and Verifiable Protocol for Federated  Differentially Private Averaging",
    "abstract": "Comments: Accepted to Machine Learning Journal. This arXiv version contains an additional introduction to zero knowledge proofs (Appendix D.2)",
    "descriptor": "\nComments: Accepted to Machine Learning Journal. This arXiv version contains an additional introduction to zero knowledge proofs (Appendix D.2)\n",
    "authors": [
      "C\u00e9sar Sabater",
      "Aur\u00e9lien Bellet",
      "Jan Ramon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07218"
  },
  {
    "id": "arXiv:2008.03920",
    "title": "Do ideas have shape? Idea registration as the continuous limit of  artificial neural networks",
    "abstract": "Comments: 65 pages. To appear in Physica D (special issue on Machine Learning and Dynamical Systems)",
    "descriptor": "\nComments: 65 pages. To appear in Physica D (special issue on Machine Learning and Dynamical Systems)\n",
    "authors": [
      "Houman Owhadi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.03920"
  },
  {
    "id": "arXiv:2011.14848",
    "title": "Output-Feedback Symbolic Control",
    "abstract": "Output-Feedback Symbolic Control",
    "descriptor": "",
    "authors": [
      "Mahmoud Khaled",
      "Kuize Zhang",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.14848"
  },
  {
    "id": "arXiv:2012.15274",
    "title": "Provably Training Overparameterized Neural Network Classifiers with  Non-convex Constraints",
    "abstract": "Provably Training Overparameterized Neural Network Classifiers with  Non-convex Constraints",
    "descriptor": "",
    "authors": [
      "You-Lin Chen",
      "Zhaoran Wang",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.15274"
  },
  {
    "id": "arXiv:2101.03058",
    "title": "Answer Counting under Guarded TGDs",
    "abstract": "Answer Counting under Guarded TGDs",
    "descriptor": "",
    "authors": [
      "Cristina Feier",
      "Carsten Lutz",
      "Marcin Przyby\u0142ko"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2101.03058"
  },
  {
    "id": "arXiv:2101.04724",
    "title": "Towards fast machine-learning-assisted Bayesian posterior inference of  microseismic event location and source mechanism",
    "abstract": "Comments: 17+4 pages, 13+3 figures, 2 tables. Matches version published in GJI, including extra tests with realistic noise and network configuration. Code available at this https URL",
    "descriptor": "\nComments: 17+4 pages, 13+3 figures, 2 tables. Matches version published in GJI, including extra tests with realistic noise and network configuration. Code available at this https URL\n",
    "authors": [
      "Davide Piras",
      "Alessio Spurio Mancini",
      "Ana M. G. Ferreira",
      "Benjamin Joachimi",
      "Michael P. Hobson"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2101.04724"
  },
  {
    "id": "arXiv:2102.11327",
    "title": "Uncertainty Estimation Using Riemannian Model~Dynamics for Offline  Reinforcement Learning",
    "abstract": "Uncertainty Estimation Using Riemannian Model~Dynamics for Offline  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Guy Tennenholtz",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11327"
  },
  {
    "id": "arXiv:2102.11469",
    "title": "Analysis of Evolutionary Diversity Optimisation for Permutation Problems",
    "abstract": "Comments: 20 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 20 pages, 4 figures, 1 table\n",
    "authors": [
      "Anh Viet Do",
      "Mingyu Guo",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.11469"
  },
  {
    "id": "arXiv:2104.08376",
    "title": "Concadia: Towards Image-Based Text Generation with a Purpose",
    "abstract": "Comments: Proceedings of EMNLP 2022",
    "descriptor": "\nComments: Proceedings of EMNLP 2022\n",
    "authors": [
      "Elisa Kreiss",
      "Fei Fang",
      "Noah D. Goodman",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08376"
  },
  {
    "id": "arXiv:2104.08763",
    "title": "Making Attention Mechanisms More Robust and Interpretable with Virtual  Adversarial Training",
    "abstract": "Comments: 18 pages, 3 figures. Accepted for publication in Springer Applied Intelligence (APIN)",
    "descriptor": "\nComments: 18 pages, 3 figures. Accepted for publication in Springer Applied Intelligence (APIN)\n",
    "authors": [
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08763"
  },
  {
    "id": "arXiv:2106.07520",
    "title": "JUGE: An Infrastructure for Benchmarking Java Unit Test Generators",
    "abstract": "JUGE: An Infrastructure for Benchmarking Java Unit Test Generators",
    "descriptor": "",
    "authors": [
      "Xavier Devroey",
      "Alessio Gambi",
      "Juan Pablo Galeotti",
      "Ren\u00e9 Just",
      "Fitsum Kifetew",
      "Annibale Panichella",
      "Sebastiano Panichella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07520"
  },
  {
    "id": "arXiv:2106.14651",
    "title": "MAGE: Nearly Zero-Cost Virtual Memory for Secure Computation",
    "abstract": "Comments: 19 pages; Accepted to OSDI 2021",
    "descriptor": "\nComments: 19 pages; Accepted to OSDI 2021\n",
    "authors": [
      "Sam Kumar",
      "David E. Culler",
      "Raluca Ada Popa"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.14651"
  },
  {
    "id": "arXiv:2107.01405",
    "title": "A Cost-Driven Fuzzy Scheduling Strategy for Intelligent Workflow  Decision Making Systems in Uncertain Edge-Cloud Environments",
    "abstract": "A Cost-Driven Fuzzy Scheduling Strategy for Intelligent Workflow  Decision Making Systems in Uncertain Edge-Cloud Environments",
    "descriptor": "",
    "authors": [
      "Bing Lin",
      "Chaowei Lin",
      "Xing Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.01405"
  },
  {
    "id": "arXiv:2107.12908",
    "title": "Digital Collections of Examples in Mathematical Sciences",
    "abstract": "Comments: Presented at 8th European Congress of Mathematicians; this version to appear in proceedings",
    "descriptor": "\nComments: Presented at 8th European Congress of Mathematicians; this version to appear in proceedings\n",
    "authors": [
      "James Harold Davenport"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2107.12908"
  },
  {
    "id": "arXiv:2108.07047",
    "title": "Expected Values for Variable Network Games",
    "abstract": "Expected Values for Variable Network Games",
    "descriptor": "",
    "authors": [
      "Subhadip Chakrabarti",
      "Loyimee Gogoi",
      "Robert P Gilles",
      "Surajit Borkotokey",
      "Rajnish Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.07047"
  },
  {
    "id": "arXiv:2108.09372",
    "title": "InBiodiv-O: An Ontology for Indian Biodiversity Knowledge Management",
    "abstract": "Comments: This paper has been withdrawn by the author due to many grammatical errors, and inconsistent content",
    "descriptor": "\nComments: This paper has been withdrawn by the author due to many grammatical errors, and inconsistent content\n",
    "authors": [
      "Archana Patel",
      "Sarika Jain",
      "Narayan C. Debnath",
      "Vishal Lama"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.09372"
  },
  {
    "id": "arXiv:2109.06724",
    "title": "Immersion and invariance orbital stabilization of underactuated  mechanical systems with collocated pre-feedback",
    "abstract": "Immersion and invariance orbital stabilization of underactuated  mechanical systems with collocated pre-feedback",
    "descriptor": "",
    "authors": [
      "Jose Guadalupe Romero",
      "Bowen Yi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06724"
  },
  {
    "id": "arXiv:2109.08079",
    "title": "Context-NER : Contextual Phrase Generation at Scale",
    "abstract": "Comments: 12 pages, 2 Figures, 1 Algorithm, 8 Tables. Accepted in NeurIPS 2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop",
    "descriptor": "\nComments: 12 pages, 2 Figures, 1 Algorithm, 8 Tables. Accepted in NeurIPS 2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop\n",
    "authors": [
      "Himanshu Gupta",
      "Shreyas Verma",
      "Tarun Kumar",
      "Swaroop Mishra",
      "Tamanna Agrawal",
      "Amogh Badugu",
      "Himanshu Sharad Bhatt"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08079"
  },
  {
    "id": "arXiv:2109.10561",
    "title": "Few-Shot Sound Source Distance Estimation Using Relation Networks",
    "abstract": "Few-Shot Sound Source Distance Estimation Using Relation Networks",
    "descriptor": "",
    "authors": [
      "Amirreza Sobhdel",
      "Roozbeh Razavi-Far",
      "Saeed Shahrivari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.10561"
  },
  {
    "id": "arXiv:2110.01109",
    "title": "FairMask: Better Fairness via Model-based Rebalancing of Protected  Attributes",
    "abstract": "Comments: 14 pages, 6 figures, 7 tables, accepted by TSE",
    "descriptor": "\nComments: 14 pages, 6 figures, 7 tables, accepted by TSE\n",
    "authors": [
      "Kewen Peng",
      "Joymallya Chakraborty",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.01109"
  },
  {
    "id": "arXiv:2110.04004",
    "title": "Trident Pyramid Networks: The importance of processing at the feature  pyramid level for better object detection",
    "abstract": "Comments: Accepted at BMVC 2022",
    "descriptor": "\nComments: Accepted at BMVC 2022\n",
    "authors": [
      "C\u00e9dric Picron",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04004"
  },
  {
    "id": "arXiv:2110.08565",
    "title": "Dynamic Graph Echo State Networks",
    "abstract": "Comments: Accepted for oral presentation at ESANN 2021",
    "descriptor": "\nComments: Accepted for oral presentation at ESANN 2021\n",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.08565"
  },
  {
    "id": "arXiv:2110.11024",
    "title": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Jing Xu",
      "Stefanos Koffas",
      "Oguzhan Ersoy",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11024"
  },
  {
    "id": "arXiv:2111.00655",
    "title": "Collage: Seamless Integration of Deep Learning Backends with Automatic  Placement",
    "abstract": "Comments: Published in PACT 22",
    "descriptor": "\nComments: Published in PACT 22\n",
    "authors": [
      "Byungsoo Jeon",
      "Sunghyun Park",
      "Peiyuan Liao",
      "Sheng Xu",
      "Tianqi Chen",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00655"
  },
  {
    "id": "arXiv:2111.13229",
    "title": "Generalizing Clinical Trials with Convex Hulls",
    "abstract": "Generalizing Clinical Trials with Convex Hulls",
    "descriptor": "",
    "authors": [
      "Eric V. Strobl",
      "Thomas A. Lasko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.13229"
  },
  {
    "id": "arXiv:2112.02513",
    "title": "Intention Recognition for Multiple Agents",
    "abstract": "Comments: 17pages, 30figures, 1 table, 2 algorithms, journal",
    "descriptor": "\nComments: 17pages, 30figures, 1 table, 2 algorithms, journal\n",
    "authors": [
      "Zhang Zhang",
      "Yifeng Zeng",
      "Yinghui Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02513"
  },
  {
    "id": "arXiv:2112.04302",
    "title": "Rational-approximation-based model order reduction of Helmholtz  frequency response problems with adaptive finite element snapshots",
    "abstract": "Rational-approximation-based model order reduction of Helmholtz  frequency response problems with adaptive finite element snapshots",
    "descriptor": "",
    "authors": [
      "Francesca Bonizzoni",
      "Davide Pradovera",
      "Michele Ruggeri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.04302"
  },
  {
    "id": "arXiv:2112.07381",
    "title": "You Only Need One Model for Open-domain Question Answering",
    "abstract": "Comments: EMNLP 2022 (main)",
    "descriptor": "\nComments: EMNLP 2022 (main)\n",
    "authors": [
      "Haejun Lee",
      "Akhil Kedia",
      "Jongwon Lee",
      "Ashwin Paranjape",
      "Christopher D. Manning",
      "Kyoung-Gu Woo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07381"
  },
  {
    "id": "arXiv:2112.08558",
    "title": "CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement  Learning",
    "abstract": "Comments: EMNLP 2022 camera-ready",
    "descriptor": "\nComments: EMNLP 2022 camera-ready\n",
    "authors": [
      "Zeqiu Wu",
      "Yi Luan",
      "Hannah Rashkin",
      "David Reitter",
      "Hannaneh Hajishirzi",
      "Mari Ostendorf",
      "Gaurav Singh Tomar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08558"
  },
  {
    "id": "arXiv:2112.09162",
    "title": "Nonparametric Two-Sample Testing by Betting",
    "abstract": "Comments: 47 pages, 3 figures",
    "descriptor": "\nComments: 47 pages, 3 figures\n",
    "authors": [
      "Shubhanshu Shekhar",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.09162"
  },
  {
    "id": "arXiv:2112.09762",
    "title": "Reproducible and Portable Big Data Analytics in the Cloud",
    "abstract": "Reproducible and Portable Big Data Analytics in the Cloud",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Pei Guo",
      "Xingyan Li",
      "Jianwu Wang",
      "Aryya Gangopadhyay",
      "Carl E. Busart",
      "Jade Freeman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.09762"
  },
  {
    "id": "arXiv:2112.15386",
    "title": "Efficient Single Image Super-Resolution Using Dual Path Connections with  Multiple Scale Learning",
    "abstract": "Comments: 21 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 21 pages, 9 figures, 5 tables\n",
    "authors": [
      "Bin-Cheng Yang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.15386"
  },
  {
    "id": "arXiv:2201.01339",
    "title": "Fast Decoding of Interleaved Linearized Reed-Solomon Codes and Variants",
    "abstract": "Comments: submitted to IEEE Transactions on Information Theory, 57 pages, 10 figures",
    "descriptor": "\nComments: submitted to IEEE Transactions on Information Theory, 57 pages, 10 figures\n",
    "authors": [
      "Hannes Bartz",
      "Sven Puchinger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.01339"
  },
  {
    "id": "arXiv:2201.06028",
    "title": "Natural Language Deduction through Search over Statement Compositions",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Kaj Bostrom",
      "Zayne Sprague",
      "Swarat Chaudhuri",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06028"
  },
  {
    "id": "arXiv:2201.06206",
    "title": "SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph  Reasoning",
    "abstract": "Comments: EMNLP 2022. Code is available at $\\href{this https URL}{\\text{this https URL}}$",
    "descriptor": "\nComments: EMNLP 2022. Code is available at $\\href{this https URL}{\\text{this https URL}}$\n",
    "authors": [
      "Yushi Bai",
      "Xin Lv",
      "Juanzi Li",
      "Lei Hou",
      "Yincen Qu",
      "Zelin Dai",
      "Feiyu Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.06206"
  },
  {
    "id": "arXiv:2201.08071",
    "title": "Temporal Sentence Grounding in Videos: A Survey and Future Directions",
    "abstract": "Comments: 29 pages, 32 figures, 9 tables",
    "descriptor": "\nComments: 29 pages, 32 figures, 9 tables\n",
    "authors": [
      "Hao Zhang",
      "Aixin Sun",
      "Wei Jing",
      "Joey Tianyi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.08071"
  },
  {
    "id": "arXiv:2201.09254",
    "title": "How networks shape diversity for better or worse",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Andrea Musso",
      "Dirk Helbing"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.09254"
  },
  {
    "id": "arXiv:2201.11523",
    "title": "ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing  Images Semantic Segmentation",
    "abstract": "ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing  Images Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Peng Guo",
      "Zihao Sun",
      "Xiuwan Chen",
      "Han Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11523"
  },
  {
    "id": "arXiv:2201.13086",
    "title": "Securing Federated Sensitive Topic Classification against Poisoning  Attacks",
    "abstract": "Securing Federated Sensitive Topic Classification against Poisoning  Attacks",
    "descriptor": "",
    "authors": [
      "Tianyue Chu",
      "Alvaro Garcia-Recuero",
      "Costas Iordanou",
      "Georgios Smaragdakis",
      "Nikolaos Laoutaris"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.13086"
  },
  {
    "id": "arXiv:2202.03101",
    "title": "Nonparametric Uncertainty Quantification for Single Deterministic Neural  Network",
    "abstract": "Comments: NeurIPS 2022 paper",
    "descriptor": "\nComments: NeurIPS 2022 paper\n",
    "authors": [
      "Nikita Kotelevskii",
      "Aleksandr Artemenkov",
      "Kirill Fedyanin",
      "Fedor Noskov",
      "Alexander Fishkov",
      "Artem Shelmanov",
      "Artem Vazhentsev",
      "Aleksandr Petiushko",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03101"
  },
  {
    "id": "arXiv:2202.04246",
    "title": "On the Keevash-Knox-Mycroft Conjecture",
    "abstract": "Comments: v1 is the conference version; v2 is the journal version",
    "descriptor": "\nComments: v1 is the conference version; v2 is the journal version\n",
    "authors": [
      "Luyining Gan",
      "Jie Han"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04246"
  },
  {
    "id": "arXiv:2202.05983",
    "title": "Uncalibrated Models Can Improve Human-AI Collaboration",
    "abstract": "Comments: 21 pages, 12 figures, NeurIPS 2022",
    "descriptor": "\nComments: 21 pages, 12 figures, NeurIPS 2022\n",
    "authors": [
      "Kailas Vodrahalli",
      "Tobias Gerstenberg",
      "James Zou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05983"
  },
  {
    "id": "arXiv:2202.06191",
    "title": "Incentivizing Participation in Clinical Trials",
    "abstract": "Incentivizing Participation in Clinical Trials",
    "descriptor": "",
    "authors": [
      "Yingkai Li",
      "Aleksandrs Slivkins"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06191"
  },
  {
    "id": "arXiv:2202.06856",
    "title": "Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient  for Out-of-Distribution Generalization",
    "abstract": "Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient  for Out-of-Distribution Generalization",
    "descriptor": "",
    "authors": [
      "Elan Rosenfeld",
      "Pradeep Ravikumar",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06856"
  },
  {
    "id": "arXiv:2202.08011",
    "title": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks",
    "abstract": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks",
    "descriptor": "",
    "authors": [
      "Jingyan Zhou",
      "Jiawen Deng",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Minlie Huang",
      "Xin Jiang",
      "Qun Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08011"
  },
  {
    "id": "arXiv:2202.08176",
    "title": "Bias and unfairness in machine learning models: a systematic literature  review",
    "abstract": "Bias and unfairness in machine learning models: a systematic literature  review",
    "descriptor": "",
    "authors": [
      "Tiago Palma Pagano",
      "Rafael Bessa Loureiro",
      "Fernanda Vitoria Nascimento Lisboa",
      "Gustavo Oliveira Ramos Cruz",
      "Rodrigo Matos Peixoto",
      "Guilherme Aragao de Sousa Guimaraes",
      "Ewerton Lopes Silva de Oliveira",
      "Ingrid Winkler",
      "Erick Giovani Sperandio Nascimento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08176"
  },
  {
    "id": "arXiv:2202.09367",
    "title": "Snowflake Point Deconvolution for Point Cloud Completion and Generation  with Skip-Transformer",
    "abstract": "Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022. This work is a journal extension of our ICCV 2021 paper arXiv:2108.04444 . The first two authors contributed equally",
    "descriptor": "\nComments: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022. This work is a journal extension of our ICCV 2021 paper arXiv:2108.04444 . The first two authors contributed equally\n",
    "authors": [
      "Peng Xiang",
      "Xin Wen",
      "Yu-Shen Liu",
      "Yan-Pei Cao",
      "Pengfei Wan",
      "Wen Zheng",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09367"
  },
  {
    "id": "arXiv:2202.12186",
    "title": "Sequential asset ranking in nonstationary time series",
    "abstract": "Sequential asset ranking in nonstationary time series",
    "descriptor": "",
    "authors": [
      "Gabriel Borrageiro"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2202.12186"
  },
  {
    "id": "arXiv:2202.12560",
    "title": "Kron Reduction and Effective Resistance of Directed Graphs",
    "abstract": "Kron Reduction and Effective Resistance of Directed Graphs",
    "descriptor": "",
    "authors": [
      "Tomohiro Sugiyama",
      "Kazuhiro Sato"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.12560"
  },
  {
    "id": "arXiv:2203.02592",
    "title": "Sparsity-Inducing Categorical Prior Improves Robustness of the  Information Bottleneck",
    "abstract": "Sparsity-Inducing Categorical Prior Improves Robustness of the  Information Bottleneck",
    "descriptor": "",
    "authors": [
      "Anirban Samaddar",
      "Sandeep Madireddy",
      "Prasanna Balaprakash",
      "Tapabrata Maiti",
      "Gustavo de los Campos",
      "Ian Fischer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.02592"
  },
  {
    "id": "arXiv:2203.02630",
    "title": "Online Adversarial Stabilization of Unknown Networked Systems",
    "abstract": "Online Adversarial Stabilization of Unknown Networked Systems",
    "descriptor": "",
    "authors": [
      "Jing Yu",
      "Dimitar Ho",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.02630"
  },
  {
    "id": "arXiv:2203.04989",
    "title": "Generalised entropy accumulation",
    "abstract": "Comments: 42 pages; v2 expands introduction but does not change any results; in FOCS 2022",
    "descriptor": "\nComments: 42 pages; v2 expands introduction but does not change any results; in FOCS 2022\n",
    "authors": [
      "Tony Metger",
      "Omar Fawzi",
      "David Sutter",
      "Renato Renner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.04989"
  },
  {
    "id": "arXiv:2203.05640",
    "title": "High Definition, Inexpensive, Underwater Mapping",
    "abstract": "Comments: IEEE Internation Conference on Robotics and Automation, 2022",
    "descriptor": "\nComments: IEEE Internation Conference on Robotics and Automation, 2022\n",
    "authors": [
      "Bharat Joshi",
      "Marios Xanthidis",
      "Sharmin Rahman",
      "Ioannis Rekleitis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05640"
  },
  {
    "id": "arXiv:2203.07216",
    "title": "A Novel Perspective to Look At Attention: Bi-level Attention-based  Explainable Topic Modeling for News Classification",
    "abstract": "Comments: Findings of ACL2022",
    "descriptor": "\nComments: Findings of ACL2022\n",
    "authors": [
      "Dairui Liu",
      "Derek Greene",
      "Ruihai Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07216"
  },
  {
    "id": "arXiv:2203.09303",
    "title": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "abstract": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "descriptor": "",
    "authors": [
      "Angel Villar-Corrales",
      "Ani Karapetyan",
      "Andreas Boltres",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09303"
  },
  {
    "id": "arXiv:2203.10885",
    "title": "Zoom Out and Observe: News Environment Perception for Fake News  Detection",
    "abstract": "Comments: ACL 2022 Main Conference (Long Paper)",
    "descriptor": "\nComments: ACL 2022 Main Conference (Long Paper)\n",
    "authors": [
      "Qiang Sheng",
      "Juan Cao",
      "Xueyao Zhang",
      "Rundong Li",
      "Danding Wang",
      "Yongchun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.10885"
  },
  {
    "id": "arXiv:2203.11167",
    "title": "Flow-matching -- efficient coarse-graining of molecular dynamics without  forces",
    "abstract": "Flow-matching -- efficient coarse-graining of molecular dynamics without  forces",
    "descriptor": "",
    "authors": [
      "Jonas K\u00f6hler",
      "Yaoyi Chen",
      "Andreas Kr\u00e4mer",
      "Cecilia Clementi",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.11167"
  },
  {
    "id": "arXiv:2203.14084",
    "title": "3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point  Clouds",
    "abstract": "Comments: Project page: this https URL; Code and data: this https URL",
    "descriptor": "\nComments: Project page: this https URL; Code and data: this https URL\n",
    "authors": [
      "Junsheng Zhou",
      "Xin Wen",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Yue Gao",
      "Yi Fang",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14084"
  },
  {
    "id": "arXiv:2203.14171",
    "title": "A Speech Representation Anonymization Framework via Selective Noise  Perturbation",
    "abstract": "A Speech Representation Anonymization Framework via Selective Noise  Perturbation",
    "descriptor": "",
    "authors": [
      "Minh Tran",
      "Mohammad Soleymani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.14171"
  },
  {
    "id": "arXiv:2204.00497",
    "title": "Mining contrast sets in classification, regression, and survival data by  fusing separate and conquer models",
    "abstract": "Comments: 33 pages, 6 figures, 3 tables, 3 algorithms",
    "descriptor": "\nComments: 33 pages, 6 figures, 3 tables, 3 algorithms\n",
    "authors": [
      "Adam Gudy\u015b",
      "Marek Sikora",
      "\u0141ukasz Wr\u00f3bel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00497"
  },
  {
    "id": "arXiv:2204.02446",
    "title": "Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models",
    "abstract": "Comments: To be published in the Fourth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2022)",
    "descriptor": "\nComments: To be published in the Fourth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2022)\n",
    "authors": [
      "Birendra Jha",
      "Medha Atre",
      "Ashwini Rao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02446"
  },
  {
    "id": "arXiv:2204.04977",
    "title": "Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures",
    "abstract": "Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures",
    "descriptor": "",
    "authors": [
      "Giovanni Bonetta",
      "Matteo Ribero",
      "Rossella Cancelliere"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04977"
  },
  {
    "id": "arXiv:2204.07367",
    "title": "On the Role of Pre-trained Language Models in Word Ordering: A Case  Study with BART",
    "abstract": "Comments: COLING 2022",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Zebin Ou",
      "Meishan Zhang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07367"
  },
  {
    "id": "arXiv:2204.12965",
    "title": "Scalable particle-based alternatives to EM",
    "abstract": "Scalable particle-based alternatives to EM",
    "descriptor": "",
    "authors": [
      "Juan Kuntz",
      "Jen Ning Lim",
      "Adam M. Johansen"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.12965"
  },
  {
    "id": "arXiv:2205.00119",
    "title": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "abstract": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "descriptor": "",
    "authors": [
      "Zhen Zhang",
      "Shuai Zheng",
      "Yida Wang",
      "Justin Chiu",
      "George Karypis",
      "Trishul Chilimbi",
      "Mu Li",
      "Xin Jin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.00119"
  },
  {
    "id": "arXiv:2205.02638",
    "title": "ImPosing: Implicit Pose Encoding for Efficient Visual Localization",
    "abstract": "Comments: Accepted at WACV 2023",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Arthur Moreau",
      "Thomas Gilles",
      "Nathan Piasco",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Arnaud de La Fortelle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02638"
  },
  {
    "id": "arXiv:2205.08210",
    "title": "Towards Robotic Laboratory Automation Plug & Play: Survey and Concept  Proposal on Teaching-free Robot Integration with the LAPP Digital Twin",
    "abstract": "Towards Robotic Laboratory Automation Plug & Play: Survey and Concept  Proposal on Teaching-free Robot Integration with the LAPP Digital Twin",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Wolf",
      "Stefan Romeder-Finger",
      "K\u00e1roly Sz\u00e9ll",
      "P\u00e9ter Galambos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.08210"
  },
  {
    "id": "arXiv:2205.09209",
    "title": "\"I'm sorry to hear that\": Finding New Biases in Language Models with a  Holistic Descriptor Dataset",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Eric Michael Smith",
      "Melissa Hall",
      "Melanie Kambadur",
      "Eleonora Presani",
      "Adina Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09209"
  },
  {
    "id": "arXiv:2205.09273",
    "title": "Twist Decoding: Diverse Generators Guide Each Other",
    "abstract": "Comments: Proc. of EMNLP 2022",
    "descriptor": "\nComments: Proc. of EMNLP 2022\n",
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Ronan Le Bras",
      "Hao Peng",
      "Ximing Lu",
      "Dragomir Radev",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09273"
  },
  {
    "id": "arXiv:2205.09641",
    "title": "SNaC: Coherence Error Detection for Narrative Summarization",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09641"
  },
  {
    "id": "arXiv:2205.09745",
    "title": "Understanding Gradient Descent on Edge of Stability in Deep Learning",
    "abstract": "Comments: 63 pages. This paper has been accepted for conference proceedings in the 39th International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: 63 pages. This paper has been accepted for conference proceedings in the 39th International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Sanjeev Arora",
      "Zhiyuan Li",
      "Abhishek Panigrahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.09745"
  },
  {
    "id": "arXiv:2205.10019",
    "title": "Translating Hanja Historical Documents to Contemporary Korean and  English",
    "abstract": "Comments: 2022 EMNLP Findings",
    "descriptor": "\nComments: 2022 EMNLP Findings\n",
    "authors": [
      "Juhee Son",
      "Jiho Jin",
      "Haneul Yoo",
      "JinYeong Bak",
      "Kyunghyun Cho",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10019"
  },
  {
    "id": "arXiv:2205.10646",
    "title": "Context Matters for Image Descriptions for Accessibility: Challenges for  Referenceless Evaluation Metrics",
    "abstract": "Comments: Proceedings of EMNLP 2022",
    "descriptor": "\nComments: Proceedings of EMNLP 2022\n",
    "authors": [
      "Elisa Kreiss",
      "Cynthia Bennett",
      "Shayan Hooshmand",
      "Eric Zelikman",
      "Meredith Ringel Morris",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10646"
  },
  {
    "id": "arXiv:2205.10926",
    "title": "Data-driven, Internet-inspired, and Scalable EV Charging for Power  Distribution Grid",
    "abstract": "Data-driven, Internet-inspired, and Scalable EV Charging for Power  Distribution Grid",
    "descriptor": "",
    "authors": [
      "Emin Ucer",
      "Mithat Kisacikoglu",
      "Murat Yuksel",
      "Ali C. Gurbuz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.10926"
  },
  {
    "id": "arXiv:2205.12206",
    "title": "PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised  Poetry Generation",
    "abstract": "Comments: EMNLP Findings 2022",
    "descriptor": "\nComments: EMNLP Findings 2022\n",
    "authors": [
      "Aitor Ormazabal",
      "Mikel Artetxe",
      "Manex Agirrezabal",
      "Aitor Soroa",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12206"
  },
  {
    "id": "arXiv:2205.13401",
    "title": "Your Transformer May Not be as Powerful as You Expect",
    "abstract": "Comments: 22 pages; NeurIPS 2022, Camera Ready Version",
    "descriptor": "\nComments: 22 pages; NeurIPS 2022, Camera Ready Version\n",
    "authors": [
      "Shengjie Luo",
      "Shanda Li",
      "Shuxin Zheng",
      "Tie-Yan Liu",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13401"
  },
  {
    "id": "arXiv:2205.13599",
    "title": "VectorAdam for Rotation Equivariant Geometry Optimization",
    "abstract": "Comments: 10 pages, 9 figures",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Selena Ling",
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.13599"
  },
  {
    "id": "arXiv:2205.14953",
    "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
    "abstract": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
    "descriptor": "",
    "authors": [
      "Muning Wen",
      "Jakub Grudzien Kuba",
      "Runji Lin",
      "Weinan Zhang",
      "Ying Wen",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14953"
  },
  {
    "id": "arXiv:2206.00121",
    "title": "Near-Optimal Collaborative Learning in Bandits",
    "abstract": "Near-Optimal Collaborative Learning in Bandits",
    "descriptor": "",
    "authors": [
      "Cl\u00e9mence R\u00e9da",
      "Sattar Vakili",
      "Emilie Kaufmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00121"
  },
  {
    "id": "arXiv:2206.02904",
    "title": "The Creativity of Text-to-Image Generation",
    "abstract": "The Creativity of Text-to-Image Generation",
    "descriptor": "",
    "authors": [
      "Jonas Oppenlaender"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.02904"
  },
  {
    "id": "arXiv:2206.06126",
    "title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform",
    "abstract": "Comments: 15 pages, 13 figures, 8 tables",
    "descriptor": "\nComments: 15 pages, 13 figures, 8 tables\n",
    "authors": [
      "Gaetan Frusque",
      "Olga Fink"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06126"
  },
  {
    "id": "arXiv:2206.06369",
    "title": "Towards predicting dynamic stability of power grids with Graph Neural  Networks",
    "abstract": "Comments: 10 pages + references and appendix, 8 figures",
    "descriptor": "\nComments: 10 pages + references and appendix, 8 figures\n",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.06369"
  },
  {
    "id": "arXiv:2206.07023",
    "title": "SBERT studies Meaning Representations: Decomposing Sentence Embeddings  into Explainable Semantic Features",
    "abstract": "Comments: to appear in AACL 2022 (main)",
    "descriptor": "\nComments: to appear in AACL 2022 (main)\n",
    "authors": [
      "Juri Opitz",
      "Anette Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07023"
  },
  {
    "id": "arXiv:2206.08325",
    "title": "Characteristics of Harmful Text: Towards Rigorous Benchmarking of  Language Models",
    "abstract": "Comments: Accepted to NeurIPS 2022 Datasets and Benchmarks Track; 10 pages plus appendix",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Datasets and Benchmarks Track; 10 pages plus appendix\n",
    "authors": [
      "Maribeth Rauh",
      "John Mellor",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "Johannes Welbl",
      "Laura Weidinger",
      "Sumanth Dathathri",
      "Amelia Glaese",
      "Geoffrey Irving",
      "Iason Gabriel",
      "William Isaac",
      "Lisa Anne Hendricks"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.08325"
  },
  {
    "id": "arXiv:2206.11895",
    "title": "Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens  in 3D Space",
    "abstract": "Comments: NeurIPS 2022. Our code is at this https URL Our project page is at this https URL v3 for minor updates on visualizations",
    "descriptor": "\nComments: NeurIPS 2022. Our code is at this https URL Our project page is at this https URL v3 for minor updates on visualizations\n",
    "authors": [
      "Jinghuan Shang",
      "Srijan Das",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.11895"
  },
  {
    "id": "arXiv:2206.13424",
    "title": "Benchopt: Reproducible, efficient and collaborative optimization  benchmarks",
    "abstract": "Comments: Accepted in proceedings of NeurIPS 22; Benchopt library documentation is available at this https URL",
    "descriptor": "\nComments: Accepted in proceedings of NeurIPS 22; Benchopt library documentation is available at this https URL\n",
    "authors": [
      "Thomas Moreau",
      "Mathurin Massias",
      "Alexandre Gramfort",
      "Pierre Ablin",
      "Pierre-Antoine Bannier",
      "Benjamin Charlier",
      "Mathieu Dagr\u00e9ou",
      "Tom Dupr\u00e9 la Tour",
      "Ghislain Durif",
      "Cassio F. Dantas",
      "Quentin Klopfenstein",
      "Johan Larsson",
      "En Lai",
      "Tanguy Lefort",
      "Benoit Mal\u00e9zieux",
      "Badr Moufad",
      "Binh T. Nguyen",
      "Alain Rakotomamonjy",
      "Zaccharie Ramzi",
      "Joseph Salmon",
      "Samuel Vaiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13424"
  },
  {
    "id": "arXiv:2206.13872",
    "title": "Disentangling Visual Embeddings with Minimal Distributional Assumptions",
    "abstract": "Comments: 23 pages. The first two authors contributed equally",
    "descriptor": "\nComments: 23 pages. The first two authors contributed equally\n",
    "authors": [
      "Tobias Leemann",
      "Michael Kirchhof",
      "Yao Rong",
      "Enkelejda Kasneci",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13872"
  },
  {
    "id": "arXiv:2206.14547",
    "title": "A Novel Attack to the Permuted Kernel Problem",
    "abstract": "A Novel Attack to the Permuted Kernel Problem",
    "descriptor": "",
    "authors": [
      "Paolo Santini",
      "Marco Baldi",
      "Franco Chiaraluce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14547"
  },
  {
    "id": "arXiv:2206.14855",
    "title": "SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice",
    "abstract": "SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice",
    "descriptor": "",
    "authors": [
      "Mohit Singhal",
      "Chen Ling",
      "Pujan Paudel",
      "Poojitha Thota",
      "Nihal Kumarswamy",
      "Gianluca Stringhini",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.14855"
  },
  {
    "id": "arXiv:2206.14976",
    "title": "Semi-Supervised Generative Adversarial Network for Stress Detection  Using Partially Labeled Physiological Data",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Nibraas Khan",
      "Nilanjan Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14976"
  },
  {
    "id": "arXiv:2207.02506",
    "title": "You have been warned: Abusing 5G's Warning and Emergency Systems",
    "abstract": "You have been warned: Abusing 5G's Warning and Emergency Systems",
    "descriptor": "",
    "authors": [
      "Evangelos Bitsikas",
      "Christina P\u00f6pper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.02506"
  },
  {
    "id": "arXiv:2207.03572",
    "title": "The ACII 2022 Affective Vocal Bursts Workshop & Competition:  Understanding a critically understudied modality of emotional expression",
    "abstract": "The ACII 2022 Affective Vocal Bursts Workshop & Competition:  Understanding a critically understudied modality of emotional expression",
    "descriptor": "",
    "authors": [
      "Alice Baird",
      "Panagiotis Tzirakis",
      "Jeffrey A. Brooks",
      "Christopher B. Gregory",
      "Bj\u00f6rn Schuller",
      "Anton Batliner",
      "Dacher Keltner",
      "Alan Cowen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.03572"
  },
  {
    "id": "arXiv:2207.03614",
    "title": "Approximate Carath\u00e9odory bounds via Discrepancy Theory",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Victor Reis",
      "Thomas Rothvoss"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.03614"
  },
  {
    "id": "arXiv:2207.04296",
    "title": "TensorIR: An Abstraction for Automatic Tensorized Program Optimization",
    "abstract": "Comments: Accepted to ASPLOS 2023",
    "descriptor": "\nComments: Accepted to ASPLOS 2023\n",
    "authors": [
      "Siyuan Feng",
      "Bohan Hou",
      "Hongyi Jin",
      "Wuwei Lin",
      "Junru Shao",
      "Ruihang Lai",
      "Zihao Ye",
      "Lianmin Zheng",
      "Cody Hao Yu",
      "Yong Yu",
      "Tianqi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.04296"
  },
  {
    "id": "arXiv:2207.05704",
    "title": "M-FUSE: Multi-frame Fusion for Scene Flow Estimation",
    "abstract": "Comments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023. Copyright: IEEE",
    "descriptor": "\nComments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023. Copyright: IEEE\n",
    "authors": [
      "Lukas Mehl",
      "Azin Jahedi",
      "Jenny Schmalfuss",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05704"
  },
  {
    "id": "arXiv:2207.06419",
    "title": "Model-Free Data-Driven Inference in Computational Mechanics",
    "abstract": "Comments: Preprint submitted to Elsevier",
    "descriptor": "\nComments: Preprint submitted to Elsevier\n",
    "authors": [
      "Erik Prume",
      "Stefanie Reese",
      "Michael Ortiz"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2207.06419"
  },
  {
    "id": "arXiv:2207.06983",
    "title": "Multitrack Music Transformer",
    "abstract": "Multitrack Music Transformer",
    "descriptor": "",
    "authors": [
      "Hao-Wen Dong",
      "Ke Chen",
      "Shlomo Dubnov",
      "Julian McAuley",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.06983"
  },
  {
    "id": "arXiv:2208.00458",
    "title": "A heuristic technique for decomposing multisets of non-negative integers  according to the Minkowski sum",
    "abstract": "A heuristic technique for decomposing multisets of non-negative integers  according to the Minkowski sum",
    "descriptor": "",
    "authors": [
      "Luciano Margara"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.00458"
  },
  {
    "id": "arXiv:2208.02469",
    "title": "Classification of some cosets of Reed-Muller codes",
    "abstract": "Classification of some cosets of Reed-Muller codes",
    "descriptor": "",
    "authors": [
      "Val\u00e9rie Gillot",
      "Philippe Langevin"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.02469"
  },
  {
    "id": "arXiv:2208.02810",
    "title": "Analyzing Data-Centric Properties for Graph Contrastive Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Puja Trivedi",
      "Ekdeep Singh Lubana",
      "Mark Heimann",
      "Danai Koutra",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02810"
  },
  {
    "id": "arXiv:2208.05379",
    "title": "Multi-task Active Learning for Pre-trained Transformer-based Models",
    "abstract": "Comments: Accepted for publication in Transactions of the Association for Computational Linguistics (TACL), 2022. Pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted for publication in Transactions of the Association for Computational Linguistics (TACL), 2022. Pre-MIT Press publication version\n",
    "authors": [
      "Guy Rotman",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.05379"
  },
  {
    "id": "arXiv:2208.06917",
    "title": "MTCSNN: Multi-task Clinical Siamese Neural Network for Diabetic  Retinopathy Severity Prediction",
    "abstract": "Comments: This paper is not sufficiently exhaustive and lacks some analysis. Besides, certain methods of this paper are from the first author's other co-first authoring research paper. There exist disputes among authors, thus we decide to withdraw this paper currently",
    "descriptor": "\nComments: This paper is not sufficiently exhaustive and lacks some analysis. Besides, certain methods of this paper are from the first author's other co-first authoring research paper. There exist disputes among authors, thus we decide to withdraw this paper currently\n",
    "authors": [
      "Chao Feng",
      "Jui Po Hung",
      "Aishan Li",
      "Jieping Yang",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06917"
  },
  {
    "id": "arXiv:2208.08758",
    "title": "Understanding Interpersonal Conflict Types and their Impact on  Perception Classification",
    "abstract": "Understanding Interpersonal Conflict Types and their Impact on  Perception Classification",
    "descriptor": "",
    "authors": [
      "Charles Welch",
      "Joan Plepi",
      "B\u00e9la Neuendorf",
      "Lucie Flek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08758"
  },
  {
    "id": "arXiv:2208.09021",
    "title": "VAuLT: Augmenting the Vision-and-Language Transformer for Sentiment  Classification on Social Media",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Georgios Chochlakis",
      "Tejas Srinivasan",
      "Jesse Thomason",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09021"
  },
  {
    "id": "arXiv:2208.09058",
    "title": "Mapping Husserlian phenomenology onto active inference",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Mahault Albarracin",
      "Riddhi J. Pitliya",
      "Maxwell J. D. Ramstead",
      "Jeffrey Yoshimi"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09058"
  },
  {
    "id": "arXiv:2208.12061",
    "title": "Evaluating Conversational Recommender Systems: A Landscape of Research",
    "abstract": "Evaluating Conversational Recommender Systems: A Landscape of Research",
    "descriptor": "",
    "authors": [
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.12061"
  },
  {
    "id": "arXiv:2208.12975",
    "title": "Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy  Data",
    "abstract": "Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy  Data",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Mengwu Guo",
      "Christoph Brune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.12975"
  },
  {
    "id": "arXiv:2208.13301",
    "title": "ECP SOLLVE: Validation and Verification Testsuite Status Update and  Compiler Insight for OpenMP",
    "abstract": "ECP SOLLVE: Validation and Verification Testsuite Status Update and  Compiler Insight for OpenMP",
    "descriptor": "",
    "authors": [
      "Thomas Huber",
      "Swaroop Pophale",
      "Nolan Baker",
      "Michael Carr",
      "Nikhil Rao",
      "Jaydon Reap",
      "Kristina Holsapple",
      "Joshua Hoke Davis",
      "Tobias Burnus",
      "Seyong Lee",
      "David E. Bernholdt",
      "Sunita Chandrasekaran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.13301"
  },
  {
    "id": "arXiv:2208.14314",
    "title": "Cardinal Optimizer (COPT) User Guide",
    "abstract": "Cardinal Optimizer (COPT) User Guide",
    "descriptor": "",
    "authors": [
      "Dongdong Ge",
      "Qi Huangfu",
      "Zizhuo Wang",
      "Jian Wu",
      "Yinyu Ye"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2208.14314"
  },
  {
    "id": "arXiv:2209.02190",
    "title": "A Multitask Deep Learning Model for Parsing Bridge Elements and  Segmenting Defect in Bridge Inspection Images",
    "abstract": "Comments: Accepted for presentation at the 2023 TRB Annual Meeting and publication in the Transportation Research Record: Journal of the Transportation Research Board (TRR)",
    "descriptor": "\nComments: Accepted for presentation at the 2023 TRB Annual Meeting and publication in the Transportation Research Record: Journal of the Transportation Research Board (TRR)\n",
    "authors": [
      "Chenyu Zhang",
      "Muhammad Monjurul Karim",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.02190"
  },
  {
    "id": "arXiv:2209.02418",
    "title": "Mortaring for linear elasticity using mixed and stabilized finite  elements",
    "abstract": "Mortaring for linear elasticity using mixed and stabilized finite  elements",
    "descriptor": "",
    "authors": [
      "Tom Gustafsson",
      "Peter R\u00e5back",
      "Juha Videman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.02418"
  },
  {
    "id": "arXiv:2209.05800",
    "title": "Time-of-Day Neural Style Transfer for Architectural Photographs",
    "abstract": "Comments: Updated version with corrected equations. Paper published at the International Conference on Computational Photography (ICCP) 2022. 12 pages of content with 6 pages of supplementary materials",
    "descriptor": "\nComments: Updated version with corrected equations. Paper published at the International Conference on Computational Photography (ICCP) 2022. 12 pages of content with 6 pages of supplementary materials\n",
    "authors": [
      "Yingshu Chen",
      "Tuan-Anh Vu",
      "Ka-Chun Shum",
      "Binh-Son Hua",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.05800"
  },
  {
    "id": "arXiv:2209.06442",
    "title": "SUN: Exploring Intrinsic Uncertainties in Text-to-SQL Parsers",
    "abstract": "Comments: Accepted at COLING 2022",
    "descriptor": "\nComments: Accepted at COLING 2022\n",
    "authors": [
      "Bowen Qin",
      "Lihan Wang",
      "Binyuan Hui",
      "Bowen Li",
      "Xiangpeng Wei",
      "Binhua Li",
      "Fei Huang",
      "Luo Si",
      "Min Yang",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.06442"
  },
  {
    "id": "arXiv:2209.07448",
    "title": "Proving Hypersafety Compositionally",
    "abstract": "Comments: 44 pages. Extended version of the OOPSLA'22 paper with the same title. Includes full proofs and case studies in appendix. v2 fixes typos in a derivation",
    "descriptor": "\nComments: 44 pages. Extended version of the OOPSLA'22 paper with the same title. Includes full proofs and case studies in appendix. v2 fixes typos in a derivation\n",
    "authors": [
      "Emanuele D'Osualdo",
      "Azadeh Farzan",
      "Derek Dreyer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.07448"
  },
  {
    "id": "arXiv:2209.07527",
    "title": "Improved proteasomal cleavage prediction with positive-unlabeled  learning",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 8 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 8 pages\n",
    "authors": [
      "Emilio Dorigatti",
      "Bernd Bischl",
      "Benjamin Schubert"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07527"
  },
  {
    "id": "arXiv:2209.07916",
    "title": "On Developing Facial Stress Analysis and Expression Recognition Platform",
    "abstract": "On Developing Facial Stress Analysis and Expression Recognition Platform",
    "descriptor": "",
    "authors": [
      "Fabio Cacciatori",
      "Sergei Nikolaev",
      "Dmitrii Grigorev",
      "Anastasiia Archangelskaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07916"
  },
  {
    "id": "arXiv:2209.08124",
    "title": "Comprehensively identifying Long Covid articles with human-in-the-loop  machine learning",
    "abstract": "Comprehensively identifying Long Covid articles with human-in-the-loop  machine learning",
    "descriptor": "",
    "authors": [
      "Robert Leaman",
      "Rezarta Islamaj",
      "Alexis Allot",
      "Qingyu Chen",
      "W. John Wilbur",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08124"
  },
  {
    "id": "arXiv:2209.10222",
    "title": "Fairness Reprogramming",
    "abstract": "Fairness Reprogramming",
    "descriptor": "",
    "authors": [
      "Guanhua Zhang",
      "Yihua Zhang",
      "Yang Zhang",
      "Wenqi Fan",
      "Qing Li",
      "Sijia Liu",
      "Shiyu Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.10222"
  },
  {
    "id": "arXiv:2209.10517",
    "title": "Model-Checking Branching-Time Properties of Stateless Probabilistic  Pushdown Systems and Its Quantum Extension",
    "abstract": "Comments: Obvious typos corrected in new version; this work is a quantum extension of arXiv:1405.4806, [v13]; 30 pages; comments are welcome",
    "descriptor": "\nComments: Obvious typos corrected in new version; this work is a quantum extension of arXiv:1405.4806, [v13]; 30 pages; comments are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2209.10517"
  },
  {
    "id": "arXiv:2209.10643",
    "title": "UPIR: Toward the Design of Unified Parallel Intermediate Representation  for Parallel Programming Models",
    "abstract": "Comments: Typos corrected. Format updated",
    "descriptor": "\nComments: Typos corrected. Format updated\n",
    "authors": [
      "Anjia Wang",
      "Xinyao Yi",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.10643"
  },
  {
    "id": "arXiv:2209.12202",
    "title": "Multimodal Exponentially Modified Gaussian Oscillators",
    "abstract": "Comments: IEEE International Ultrasonic Symposium 2022",
    "descriptor": "\nComments: IEEE International Ultrasonic Symposium 2022\n",
    "authors": [
      "Christopher Hahne"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.12202"
  },
  {
    "id": "arXiv:2209.13177",
    "title": "A Survey of Fairness in Medical Image Analysis: Concepts, Algorithms,  Evaluations, and Challenges",
    "abstract": "Comments: 23 pages, 11 figures",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Zikang Xu",
      "Jun Li",
      "Qingsong Yao",
      "Han Li",
      "Xin Shi",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.13177"
  },
  {
    "id": "arXiv:2209.13685",
    "title": "Hybrid Stochastic Synapses Enabled by Scaled Ferroelectric Field-effect  Transistors",
    "abstract": "Hybrid Stochastic Synapses Enabled by Scaled Ferroelectric Field-effect  Transistors",
    "descriptor": "",
    "authors": [
      "A N M Nafiul Islam",
      "Arnob Saha",
      "Zhouhang Jiang",
      "Kai Ni",
      "Abhronil Sengupta"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.13685"
  },
  {
    "id": "arXiv:2209.14734",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "abstract": "Comments: 22 pages. Preprint, under review",
    "descriptor": "\nComments: 22 pages. Preprint, under review\n",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14734"
  },
  {
    "id": "arXiv:2210.00882",
    "title": "MSRL: Distributed Reinforcement Learning with Dataflow Fragments",
    "abstract": "MSRL: Distributed Reinforcement Learning with Dataflow Fragments",
    "descriptor": "",
    "authors": [
      "Huanzhou Zhu",
      "Bo Zhao",
      "Gang Chen",
      "Weifeng Chen",
      "Yijie Chen",
      "Liang Shi",
      "Yaodong Yang",
      "Peter Pietzuch",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.00882"
  },
  {
    "id": "arXiv:2210.02067",
    "title": "Computing maximal generalized palindromes",
    "abstract": "Computing maximal generalized palindromes",
    "descriptor": "",
    "authors": [
      "Mitsuru Funakoshi",
      "Takuya Mieno",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Hideo Bannai",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02067"
  },
  {
    "id": "arXiv:2210.02318",
    "title": "FQDet: Fast-converging Query-based Detector",
    "abstract": "Comments: Accepted at NeurIPS VTTA workshop 2022",
    "descriptor": "\nComments: Accepted at NeurIPS VTTA workshop 2022\n",
    "authors": [
      "C\u00e9dric Picron",
      "Punarjay Chakravarty",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02318"
  },
  {
    "id": "arXiv:2210.03444",
    "title": "Depersonalized Federated Learning: Tackling Statistical Heterogeneity by  Alternating Stochastic Gradient Descent",
    "abstract": "Depersonalized Federated Learning: Tackling Statistical Heterogeneity by  Alternating Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Yujie Zhou",
      "Zhidu Li",
      "Tong Tang",
      "Ruyan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03444"
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": "Comments: 7 Pages",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03739"
  },
  {
    "id": "arXiv:2210.04095",
    "title": "How do you go where? Improving next location prediction by learning  travel mode information using transformers",
    "abstract": "Comments: updated main figure, 10 pages, camera ready SIGSPATIAL '22",
    "descriptor": "\nComments: updated main figure, 10 pages, camera ready SIGSPATIAL '22\n",
    "authors": [
      "Ye Hong",
      "Henry Martin",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.04095"
  },
  {
    "id": "arXiv:2210.05423",
    "title": "Learning to Locate Visual Answer in Video Corpus Using Question",
    "abstract": "Comments: 4 pages, 2 figures and 3 tables",
    "descriptor": "\nComments: 4 pages, 2 figures and 3 tables\n",
    "authors": [
      "Bin Li",
      "Yixuan Weng",
      "Bin Sun",
      "Shutao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.05423"
  },
  {
    "id": "arXiv:2210.06587",
    "title": "BLADERUNNER: Rapid Countermeasure for Synthetic (AI-Generated) StyleGAN  Faces",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Adam Dorian Wong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06587"
  },
  {
    "id": "arXiv:2210.07048",
    "title": "A New Optimality Property of Strang's Splitting",
    "abstract": "Comments: 2 figures",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Fernando Casas",
      "Jes\u00fas Mar\u00eda Sanz-Serna",
      "Luke Shaw"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.07048"
  },
  {
    "id": "arXiv:2210.07715",
    "title": "Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning",
    "abstract": "Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning",
    "descriptor": "",
    "authors": [
      "Tiantian He",
      "Haicang Zhou",
      "Yew-Soon Ong",
      "Gao Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07715"
  },
  {
    "id": "arXiv:2210.07805",
    "title": "Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set  Active Learning",
    "abstract": "Comments: to be published in NeurIPS 2022",
    "descriptor": "\nComments: to be published in NeurIPS 2022\n",
    "authors": [
      "Dongmin Park",
      "Yooju Shin",
      "Jihwan Bang",
      "Youngjun Lee",
      "Hwanjun Song",
      "Jae-Gil Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07805"
  },
  {
    "id": "arXiv:2210.08262",
    "title": "Motion estimation and filtered prediction for dynamic point cloud  attribute compression",
    "abstract": "Comments: Accepted for PCS2022",
    "descriptor": "\nComments: Accepted for PCS2022\n",
    "authors": [
      "Haoran Hong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Ryosuke Watanabe",
      "Keisuke Nonaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08262"
  },
  {
    "id": "arXiv:2210.08342",
    "title": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "abstract": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "descriptor": "",
    "authors": [
      "Philipp Scholl",
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08342"
  },
  {
    "id": "arXiv:2210.08400",
    "title": "A Multilevel Reinforcement Learning Framework for PDE-based Control",
    "abstract": "Comments: In preparation for submission to a journal",
    "descriptor": "\nComments: In preparation for submission to a journal\n",
    "authors": [
      "Atish Dixit",
      "Ahmed Elsheikh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08400"
  },
  {
    "id": "arXiv:2210.09155",
    "title": "Quantum Event Learning and Gentle Random Measurements",
    "abstract": "Quantum Event Learning and Gentle Random Measurements",
    "descriptor": "",
    "authors": [
      "Adam Bene Watts",
      "John Bostanci"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.09155"
  },
  {
    "id": "arXiv:2210.09232",
    "title": "Confound-leakage: Confound Removal in Machine Learning Leads to Leakage",
    "abstract": "Comments: Revised Introduction, added CoI, results unchanged",
    "descriptor": "\nComments: Revised Introduction, added CoI, results unchanged\n",
    "authors": [
      "Sami Hamdan",
      "Bradley C. Love",
      "Georg G. von Polier",
      "Susanne Weis",
      "Holger Schwender",
      "Simon B. Eickhoff",
      "Kaustubh R. Patil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09232"
  },
  {
    "id": "arXiv:2210.09482",
    "title": "You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous  Vehicles Driving Frameworks",
    "abstract": "Comments: Accepted to the 32nd USENIX Security Symposium (2023)",
    "descriptor": "\nComments: Accepted to the 32nd USENIX Security Symposium (2023)\n",
    "authors": [
      "Yulong Cao",
      "S. Hrushikesh Bhupathiraju",
      "Pirouz Naghavi",
      "Takeshi Sugawara",
      "Z. Morley Mao",
      "Sara Rampazzi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09482"
  },
  {
    "id": "arXiv:2210.09917",
    "title": "Controllable Fake Document Infilling for Cyber Deception",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Yibo Hu",
      "Yu Lin",
      "Erick Skorupa Parolin",
      "Latifur Khan",
      "Kevin Hamlen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09917"
  },
  {
    "id": "arXiv:2210.10173",
    "title": "Faster Matrix Multiplication via Asymmetric Hashing",
    "abstract": "Comments: 67 pages",
    "descriptor": "\nComments: 67 pages\n",
    "authors": [
      "Ran Duan",
      "Hongxun Wu",
      "Renfei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10173"
  },
  {
    "id": "arXiv:2210.10415",
    "title": "Optimal computational costs of AFEM with optimal local $hp$-robust  multigrid solver",
    "abstract": "Optimal computational costs of AFEM with optimal local $hp$-robust  multigrid solver",
    "descriptor": "",
    "authors": [
      "Michael Innerberger",
      "Ani Mira\u00e7i",
      "Dirk Praetorius",
      "Julian Streitberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10415"
  },
  {
    "id": "arXiv:2210.11845",
    "title": "A Stability Analysis of Modified Patankar-Runge-Kutta methods for a  nonlinear Production-Destruction System",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Thomas Izgin",
      "Stefan Kopecz",
      "Andreas Meister"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11845"
  },
  {
    "id": "arXiv:2210.11888",
    "title": "STAR: SQL Guided Pre-Training for Context-dependent Text-to-SQL Parsing",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zefeng Cai",
      "Xiangyu Li",
      "Binyuan Hui",
      "Min Yang",
      "Bowen Li",
      "Binhua Li",
      "Zheng Cao",
      "Weijie Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11888"
  },
  {
    "id": "arXiv:2210.12116",
    "title": "Error analysis for a Crouzeix-Raviart approximation of the $p$-Dirichlet  problem",
    "abstract": "Comments: 26 pages, 2 tables, 1 figure",
    "descriptor": "\nComments: 26 pages, 2 tables, 1 figure\n",
    "authors": [
      "Alex Kaltenbach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.12116"
  },
  {
    "id": "arXiv:2210.12160",
    "title": "On the connection between Bregman divergence and value in regularized  Markov decision processes",
    "abstract": "On the connection between Bregman divergence and value in regularized  Markov decision processes",
    "descriptor": "",
    "authors": [
      "Brendan O'Donoghue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.12160"
  },
  {
    "id": "arXiv:2210.12756",
    "title": "VP-SLAM: A Monocular Real-time Visual SLAM with Points, Lines and  Vanishing Points",
    "abstract": "VP-SLAM: A Monocular Real-time Visual SLAM with Points, Lines and  Vanishing Points",
    "descriptor": "",
    "authors": [
      "Andreas Georgis",
      "Panagiotis Mermigkas",
      "Petros Maragos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12756"
  },
  {
    "id": "arXiv:2210.12791",
    "title": "O-type Stars Stellar Parameter Estimation Using Recurrent Neural  Networks",
    "abstract": "O-type Stars Stellar Parameter Estimation Using Recurrent Neural  Networks",
    "descriptor": "",
    "authors": [
      "Miguel Flores R.",
      "Luis J. Corral",
      "Celia R. Fierro-Santill\u00e1n",
      "Silvana G. Navarro"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12791"
  },
  {
    "id": "arXiv:2210.13287",
    "title": "Control and Design Optimization of an Electric Vehicle Transmission  Using Analytical Modeling Methods",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Olaf Borsboom",
      "Thijs de Mooy",
      "Mauro Salazar",
      "Theo Hofman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.13287"
  },
  {
    "id": "arXiv:2210.13304",
    "title": "ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and  Effective Text Generation",
    "abstract": "Comments: Accepted to EMNLP 2022 main conference (long paper)",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference (long paper)\n",
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Wayne Xin Zhao",
      "Jian-Yun Nie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.13304"
  },
  {
    "id": "arXiv:2210.13403",
    "title": "Task-Driven In-Hand Manipulation of Unknown Objects with Tactile Sensing",
    "abstract": "Task-Driven In-Hand Manipulation of Unknown Objects with Tactile Sensing",
    "descriptor": "",
    "authors": [
      "Chaoyi Pan",
      "Marion Lepert",
      "Shenli Yuan",
      "Rika Antonova",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.13403"
  },
  {
    "id": "arXiv:2210.13668",
    "title": "ConnectedUNets++: Mass Segmentation from Whole Mammographic Images",
    "abstract": "Comments: Results are to be updated",
    "descriptor": "\nComments: Results are to be updated\n",
    "authors": [
      "Prithul Sarker",
      "Sushmita Sarker",
      "George Bebis",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13668"
  },
  {
    "id": "arXiv:2210.13772",
    "title": "Deformation Theory of Boltzmann Distributions",
    "abstract": "Comments: Machine Learning for the Physical Sciences Workshop at NeurIPS '22",
    "descriptor": "\nComments: Machine Learning for the Physical Sciences Workshop at NeurIPS '22\n",
    "authors": [
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13772"
  },
  {
    "id": "arXiv:2210.14152",
    "title": "SleepMore: Sleep Prediction at Scale via Multi-Device WiFi Sensing",
    "abstract": "Comments: 29 pages, 24 figures, 14 tables",
    "descriptor": "\nComments: 29 pages, 24 figures, 14 tables\n",
    "authors": [
      "Camellia Zakaria",
      "Gizem Yilmaz",
      "Priyanka Mammen",
      "Michael Chee",
      "Prashant Shenoy",
      "Rajesh Balan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14152"
  },
  {
    "id": "arXiv:2210.14403",
    "title": "Stealthy Measurement-Aided Pole-Dynamics Attacks with Nominal Models",
    "abstract": "Stealthy Measurement-Aided Pole-Dynamics Attacks with Nominal Models",
    "descriptor": "",
    "authors": [
      "Dajun Du",
      "Changda Zhang",
      "Chen Peng",
      "Minrui Fei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.14403"
  },
  {
    "id": "arXiv:2210.14458",
    "title": "Joint Waveform and Passive Beamformer Design in Multi-IRS Aided Radar",
    "abstract": "Joint Waveform and Passive Beamformer Design in Multi-IRS Aided Radar",
    "descriptor": "",
    "authors": [
      "Zahra Esmaeilbeig",
      "Arian Eamaz",
      "Kumar Vijay Mishra",
      "Mojtaba Soltanalian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.14458"
  },
  {
    "id": "arXiv:2210.14666",
    "title": "Xiaoicesing 2: A High-Fidelity Singing Voice Synthesizer Based on  Generative Adversarial Network",
    "abstract": "Comments: submitted to icassp2023",
    "descriptor": "\nComments: submitted to icassp2023\n",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.14666"
  },
  {
    "id": "arXiv:2210.14804",
    "title": "Approximate Quantum Random Access Memory Architectures",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Koustubh Phalak",
      "Junde Li",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.14804"
  },
  {
    "id": "arXiv:2210.14823",
    "title": "Visual Answer Localization with Cross-modal Mutual Knowledge Transfer",
    "abstract": "Comments: 4 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 4 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yixuan Weng",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14823"
  },
  {
    "id": "arXiv:2210.14826",
    "title": "A case for disaggregation of ML data processing",
    "abstract": "A case for disaggregation of ML data processing",
    "descriptor": "",
    "authors": [
      "Andrew Audibert",
      "Yang Chen",
      "Dan Graur",
      "Ana Klimovic",
      "Jiri Simsa",
      "Chandramohan A. Thekkath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.14826"
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": "Broken Neural Scaling Laws",
    "descriptor": "",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14891"
  },
  {
    "id": "arXiv:2210.15030",
    "title": "A Hierarchical Approach to Conditional Random Fields for System Anomaly  Detection",
    "abstract": "Comments: 8 pages, Preprint, This paper was originally written in 2019",
    "descriptor": "\nComments: 8 pages, Preprint, This paper was originally written in 2019\n",
    "authors": [
      "Srishti Mishra",
      "Tvarita Jain",
      "Dinkar Sitaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.15030"
  },
  {
    "id": "arXiv:2210.15056",
    "title": "UnfoldML: Cost-Aware and Uncertainty-Based Dynamic 2D Prediction for  Multi-Stage Classification",
    "abstract": "Comments: To be published in NeurIPS'22",
    "descriptor": "\nComments: To be published in NeurIPS'22\n",
    "authors": [
      "Yanbo Xu",
      "Alind Khare",
      "Glenn Matlin",
      "Monish Ramadoss",
      "Rishikesan Kamaleswaran",
      "Chao Zhang",
      "Alexey Tumanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15056"
  },
  {
    "id": "arXiv:2210.15078",
    "title": "Age of Information in Downlink Systems: Broadcast or Distributed  Transmission?",
    "abstract": "Age of Information in Downlink Systems: Broadcast or Distributed  Transmission?",
    "descriptor": "",
    "authors": [
      "Zhifeng Tang",
      "Nan Yang",
      "Parastoo Sadeghi",
      "Xiangyun Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15078"
  },
  {
    "id": "arXiv:2210.15109",
    "title": "Vetaverse: Technologies, Applications, and Visions toward the  Intersection of Metaverse, Vehicles, and Transportation Systems",
    "abstract": "Comments: 24 pages, 17 figures",
    "descriptor": "\nComments: 24 pages, 17 figures\n",
    "authors": [
      "Pengyuan Zhou",
      "Jinjing Zhu",
      "Yiting Wang",
      "Yunfan Lu",
      "Zixiang Wei",
      "Haolin Shi",
      "Yuchen Ding",
      "Yu Gao",
      "Qinglong Huang",
      "Yan Shi",
      "Ahmad Alhilal",
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pan Hui",
      "Lin Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.15109"
  },
  {
    "id": "arXiv:2210.15121",
    "title": "Bootstrapping Human Optical Flow and Pose",
    "abstract": "Comments: Accepted at BMVC 2022. Supplementary qualitative results - this https URL Code at this https URL",
    "descriptor": "\nComments: Accepted at BMVC 2022. Supplementary qualitative results - this https URL Code at this https URL\n",
    "authors": [
      "Aritro Roy Arko",
      "James J. Little",
      "Kwang Moo Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15121"
  },
  {
    "id": "arXiv:2210.15134",
    "title": "Learning Variational Motion Prior for Video-based Motion Capture",
    "abstract": "Comments: 9 pages, 9 figures",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Xin Chen",
      "Zhuo Su",
      "Lingbo Yang",
      "Pei Cheng",
      "Lan Xu",
      "Bin Fu",
      "Gang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15134"
  },
  {
    "id": "arXiv:2210.15149",
    "title": "Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study",
    "abstract": "Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study",
    "descriptor": "",
    "authors": [
      "Zhongyi Zhang",
      "Guixia Li",
      "Ziqiang Wang",
      "Feng Xia",
      "Ning Zhao",
      "Huibin Nie",
      "Zezhong Ye",
      "Joshua Lin",
      "Yiyi Hui",
      "Xiangchun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15149"
  },
  {
    "id": "arXiv:2210.15160",
    "title": "Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection",
    "abstract": "Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection",
    "descriptor": "",
    "authors": [
      "Rudong An",
      "Wei Zhang",
      "Hao Zeng",
      "Wei Chen",
      "Zhigang Deng",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15160"
  },
  {
    "id": "arXiv:2210.15248",
    "title": "Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI",
    "abstract": "Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI",
    "descriptor": "",
    "authors": [
      "Chenglin Wang",
      "Yucheng Zhou",
      "Guodong Long",
      "Xiaodong Wang",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15248"
  },
  {
    "id": "arXiv:2210.15305",
    "title": "Deformable Temporal Convolutional Networks for Monaural Noisy  Reverberant Speech Separation",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15305"
  },
  {
    "id": "arXiv:2210.15306",
    "title": "Rigid-Body Sound Synthesis with Differentiable Modal Resonators",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Rodrigo Diaz",
      "Ben Hayes",
      "Charalampos Saitis",
      "Gy\u00f6rgy Fazekas",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15306"
  },
  {
    "id": "arXiv:2210.15401",
    "title": "Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "abstract": "Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "descriptor": "",
    "authors": [
      "Zijie Yue",
      "Miaojing Shi",
      "Shuai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15401"
  },
  {
    "id": "arXiv:2210.15409",
    "title": "Constrained Differential Dynamic Programming: A primal-dual augmented  Lagrangian approach",
    "abstract": "Constrained Differential Dynamic Programming: A primal-dual augmented  Lagrangian approach",
    "descriptor": "",
    "authors": [
      "Wilson Jallet",
      "Antoine Bambade",
      "Nicolas Mansard",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.15409"
  },
  {
    "id": "arXiv:2210.15436",
    "title": "The weight distribution of codes over finite chain rings",
    "abstract": "The weight distribution of codes over finite chain rings",
    "descriptor": "",
    "authors": [
      "Giulia Cavicchioni",
      "Alessio Meneghetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2210.15436"
  },
  {
    "id": "arXiv:2210.15460",
    "title": "Accurate Bundle Matching and Generation via Multitask Learning with  Partially Shared Parameters",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Hyunsik Jeon",
      "Jun-Gi Jang",
      "Taehun Kim",
      "U Kang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15460"
  },
  {
    "id": "arXiv:2210.15539",
    "title": "Deep Convolutional Neural Networks for Multi-Target Tracking: A Transfer  Learning Approach",
    "abstract": "Comments: 5 pages, 4 figures; submitted to Proc. ICASSP2023, June 04-09, 2023, Rhodes Island, Greece; Associated code is available at this https URL",
    "descriptor": "\nComments: 5 pages, 4 figures; submitted to Proc. ICASSP2023, June 04-09, 2023, Rhodes Island, Greece; Associated code is available at this https URL\n",
    "authors": [
      "Damian Owerko",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro",
      "Donald J. Bucci Jr",
      "Jennifer Bondarchuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15539"
  }
]
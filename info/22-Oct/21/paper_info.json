[
  {
    "id": "arXiv:2210.10780",
    "title": "An out-of-distribution discriminator based on Bayesian neural network  epistemic uncertainty",
    "abstract": "Neural networks have revolutionized the field of machine learning with\nincreased predictive capability. In addition to improving the predictions of\nneural networks, there is a simultaneous demand for reliable uncertainty\nquantification on estimates made by machine learning methods such as neural\nnetworks. Bayesian neural networks (BNNs) are an important type of neural\nnetwork with built-in capability for quantifying uncertainty. This paper\ndiscusses aleatoric and epistemic uncertainty in BNNs and how they can be\ncalculated. With an example dataset of images where the goal is to identify the\namplitude of an event in the image, it is shown that epistemic uncertainty\ntends to be lower in images which are well-represented in the training dataset\nand tends to be high in images which are not well-represented. An algorithm for\nout-of-distribution (OoD) detection with BNN epistemic uncertainty is\nintroduced along with various experiments demonstrating factors influencing the\nOoD detection capability in a BNN. The OoD detection capability with epistemic\nuncertainty is shown to be comparable to the OoD detection in the discriminator\nnetwork of a generative adversarial network (GAN) with comparable network\narchitecture.",
    "descriptor": "\nComments: 26 pages, 25 figures\n",
    "authors": [
      "Ethan Ancell",
      "Christopher Bennett",
      "Bert Debusschere",
      "Sapan Agarwal",
      "Park Hays",
      "T. Patrick Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10780"
  },
  {
    "id": "arXiv:2210.10782",
    "title": "Topology Optimization via Machine Learning and Deep Learning: A Review",
    "abstract": "Topology optimization (TO) is a method of deriving an optimal design that\nsatisfies a given load and boundary conditions within a design domain. This\nmethod enables effective design without initial design, but has been limited in\nuse due to high computational costs. At the same time, machine learning (ML)\nmethodology including deep learning has made great progress in the 21st\ncentury, and accordingly, many studies have been conducted to enable effective\nand rapid optimization by applying ML to TO. Therefore, this study reviews and\nanalyzes previous research on ML-based TO (MLTO). Two different perspectives of\nMLTO are used to review studies: (1) TO and (2) ML perspectives. The TO\nperspective addresses \"why\" to use ML for TO, while the ML perspective\naddresses \"how\" to apply ML to TO. In addition, the limitations of current MLTO\nresearch and future research directions are examined.",
    "descriptor": "",
    "authors": [
      "Seungyeon Shin",
      "Dongju Shin",
      "Namwoo Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10782"
  },
  {
    "id": "arXiv:2210.10783",
    "title": "Self-learning locally-optimal hypertuning using maximum entropy, and  comparison of machine learning approaches for estimating fatigue life in  composite materials",
    "abstract": "Applications of Structural Health Monitoring (SHM) combined with Machine\nLearning (ML) techniques enhance real-time performance tracking and increase\nstructural integrity awareness of civil, aerospace and automotive\ninfrastructures. This SHM-ML synergy has gained popularity in the last years\nthanks to the anticipation of maintenance provided by arising ML algorithms and\ntheir ability of handling large quantities of data and considering their\ninfluence in the problem.\nIn this paper we develop a novel ML nearest-neighbors-alike algorithm based\non the principle of maximum entropy to predict fatigue damage (Palmgren-Miner\nindex) in composite materials by processing the signals of Lamb Waves -- a\nnon-destructive SHM technique -- with other meaningful features such as layup\nparameters and stiffness matrices calculated from the Classical Laminate Theory\n(CLT). The full data analysis cycle is applied to a dataset of delamination\nexperiments in composites. The predictions achieve a good level of accuracy,\nsimilar to other ML algorithms, e.g. Neural Networks or Gradient-Boosted Trees,\nand computation times are of the same order of magnitude.\nThe key advantages of our proposal are: (1) The automatic determination of\nall the parameters involved in the prediction, so no hyperparameters have to be\nset beforehand, which saves time devoted to hypertuning the model and also\nrepresents an advantage for autonomous, self-supervised SHM. (2) No training is\nrequired, which, in an \\textit{online learning} context where streams of data\nare fed continuously to the model, avoids repeated training -- essential for\nreliable real-time, continuous monitoring.",
    "descriptor": "",
    "authors": [
      "Ismael Ben-Yelun",
      "Miguel Diaz-Lago",
      "Luis Saucedo-Mora",
      "Miguel Angel Sanz",
      "Ricardo Callado",
      "Francisco Javier Montans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10783"
  },
  {
    "id": "arXiv:2210.10807",
    "title": "Self-Supervised Representation Learning for CAD",
    "abstract": "The design of man-made objects is dominated by computer aided design (CAD)\ntools. Assisting design with data-driven machine learning methods is hampered\nby lack of labeled data in CAD's native format; the parametric boundary\nrepresentation (B-Rep). Several data sets of mechanical parts in B-Rep format\nhave recently been released for machine learning research. However, large scale\ndatabases are largely unlabeled, and labeled datasets are small. Additionally,\ntask specific label sets are rare, and costly to annotate. This work proposes\nto leverage unlabeled CAD geometry on supervised learning tasks. We learn a\nnovel, hybrid implicit/explicit surface representation for B-Rep geometry, and\nshow that this pre-training significantly improves few-shot learning\nperformance and also achieves state-of-the-art performance on several existing\nB-Rep benchmarks.",
    "descriptor": "",
    "authors": [
      "Benjamin T. Jones",
      "Michael Hu",
      "Vladimir G. Kim",
      "Adriana Schulz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.10807"
  },
  {
    "id": "arXiv:2210.10814",
    "title": "MPOGames: Efficient Multimodal Partially Observable Dynamic Games",
    "abstract": "Game theoretic methods have become popular for planning and prediction in\nsituations involving rich multi-agent interactions. However, these methods\noften assume the existence of a single local Nash equilibria and are hence\nunable to handle uncertainty in the intentions of different agents. While\nmaximum entropy (MaxEnt) dynamic games try to address this issue, practical\napproaches solve for MaxEnt Nash equilibria using linear-quadratic\napproximations which are restricted to unimodal responses and unsuitable for\nscenarios with multiple local Nash equilibria. By reformulating the problem as\na POMDP, we propose MPOGames, a method for efficiently solving MaxEnt dynamic\ngames that captures the interactions between local Nash equilibria. We show the\nimportance of uncertainty-aware game theoretic methods via a two-agent merge\ncase study. Finally, we prove the real-time capabilities of our approach with\nhardware experiments on a 1/10th scale car platform.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Oswin So",
      "Paul Drews",
      "Thomas Balch",
      "Velin Dimitrov",
      "Guy Rosman",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10814"
  },
  {
    "id": "arXiv:2210.10817",
    "title": "A Continuum of Generation Tasks for Investigating Length Bias and  Degenerate Repetition",
    "abstract": "Language models suffer from various degenerate behaviors. These differ\nbetween tasks: machine translation (MT) exhibits length bias, while tasks like\nstory generation exhibit excessive repetition. Recent work has attributed the\ndifference to task constrainedness, but evidence for this claim has always\ninvolved many confounding variables. To study this question directly, we\nintroduce a new experimental framework that allows us to smoothly vary task\nconstrainedness, from MT at one end to fully open-ended generation at the\nother, while keeping all other aspects fixed. We find that: (1) repetition\ndecreases smoothly with constrainedness, explaining the difference in\nrepetition across tasks; (2) length bias surprisingly also decreases with\nconstrainedness, suggesting some other cause for the difference in length bias;\n(3) across the board, these problems affect the mode, not the whole\ndistribution; (4) the differences cannot be attributed to a change in the\nentropy of the distribution, since another method of changing the entropy,\nlabel smoothing, does not produce the same effect.",
    "descriptor": "\nComments: Accepted for publication at BlackboxNLP 2022\n",
    "authors": [
      "Darcey Riley",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10817"
  },
  {
    "id": "arXiv:2210.10820",
    "title": "VTC: Improving Video-Text Retrieval with User Comments",
    "abstract": "Multi-modal retrieval is an important problem for many applications, such as\nrecommendation and search. Current benchmarks and even datasets are often\nmanually constructed and consist of mostly clean samples where all modalities\nare well-correlated with the content. Thus, current video-text retrieval\nliterature largely focuses on video titles or audio transcripts, while ignoring\nuser comments, since users often tend to discuss topics only vaguely related to\nthe video. Despite the ubiquity of user comments online, there is currently no\nmulti-modal representation learning datasets that includes comments. In this\npaper, we a) introduce a new dataset of videos, titles and comments; b) present\nan attention-based mechanism that allows the model to learn from sometimes\nirrelevant data such as comments; c) show that by using comments, our method is\nable to learn better, more contextualised, representations for image, video and\naudio representations. Project page: https://unitaryai.github.io/vtc-paper.",
    "descriptor": "\nComments: Accepted paper at the European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Laura Hanu",
      "James Thewlis",
      "Yuki M. Asano",
      "Christian Rupprecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10820"
  },
  {
    "id": "arXiv:2210.10821",
    "title": "RCareWorld: A Human-centric Simulation World for Caregiving Robots",
    "abstract": "We present RCareWorld, a human-centric simulation world for physical and\nsocial robotic caregiving designed with inputs from stakeholders, including\ncare recipients, caregivers, occupational therapists, and roboticists.\nRCareWorld has realistic human models of care recipients with mobility\nlimitations and caregivers, home environments with multiple levels of\naccessibility and assistive devices, and robots commonly used for caregiving.\nIt interfaces with various physics engines to model diverse material types\nnecessary for simulating caregiving scenarios, and provides the capability to\nplan, control, and learn both human and robot control policies by integrating\nwith state-of-the-art external planning and learning libraries, and VR devices.\nWe propose a set of realistic caregiving tasks in RCareWorld as a benchmark for\nphysical robotic caregiving and provide baseline control policies for them. We\nillustrate the high-fidelity simulation capabilities of RCareWorld by\ndemonstrating the execution of a policy learnt in simulation for one of these\ntasks on a real-world setup. Additionally, we perform a real-world social\nrobotic caregiving experiment using behaviors modeled in RCareWorld. Robotic\ncaregiving, though potentially impactful towards enhancing the quality of life\nof care recipients and caregivers, is a field with many barriers to entry due\nto its interdisciplinary facets. RCareWorld takes the first step towards\nbuilding a realistic simulation world for robotic caregiving that would enable\nresearchers worldwide to contribute to this impactful field. Demo videos and\nsupplementary materials can be found at:\nhttps://emprise.cs.cornell.edu/rcareworld/.",
    "descriptor": "",
    "authors": [
      "Ruolin Ye",
      "Wenqiang Xu",
      "Haoyuan Fu",
      "Rajat Kumar Jenamani",
      "Vy Nguyen",
      "Cewu Lu",
      "Katherine Dimitropoulou",
      "Tapomayukh Bhattacharjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10821"
  },
  {
    "id": "arXiv:2210.10824",
    "title": "Supervised Contrastive Learning with TPE-based Bayesian Optimization of  Tabular Data for Imbalanced Learning",
    "abstract": "Class imbalance has a detrimental effect on the predictive performance of\nmost supervised learning algorithms as the imbalanced distribution can lead to\na bias preferring the majority class. To solve this problem, we propose a\nSupervised Contrastive Learning (SCL) method with Bayesian optimization\ntechnique based on Tree-structured Parzen Estimator (TPE) for imbalanced\ntabular datasets. Compared with supervised learning, contrastive learning can\navoid \"label bias\" by extracting the information hidden in data. Based on\ncontrastive loss, SCL can exploit the label information to address insufficient\ndata augmentation of tabular data, and is thus used in the proposed SCL-TPE\nmethod to learn a discriminative representation of data. Additionally, as the\nhyper-parameter temperature has a decisive influence on the SCL performance and\nis difficult to tune, TPE-based Bayesian optimization is introduced to\nautomatically select the best temperature. Experiments are conducted on both\nbinary and multi-class imbalanced tabular datasets. As shown in the results\nobtained, TPE outperforms other hyper-parameter optimization (HPO) methods such\nas grid search, random search, and genetic algorithm. More importantly, the\nproposed SCL-TPE method achieves much-improved performance compared with the\nstate-of-the-art methods.",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Shuting Tao",
      "Peng Peng",
      "Hongwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10824"
  },
  {
    "id": "arXiv:2210.10828",
    "title": "Grounded Video Situation Recognition",
    "abstract": "Dense video understanding requires answering several questions such as who is\ndoing what to whom, with what, how, why, and where. Recently, Video Situation\nRecognition (VidSitu) is framed as a task for structured prediction of multiple\nevents, their relationships, and actions and various verb-role pairs attached\nto descriptive entities. This task poses several challenges in identifying,\ndisambiguating, and co-referencing entities across multiple verb-role pairs,\nbut also faces some challenges of evaluation. In this work, we propose the\naddition of spatio-temporal grounding as an essential component of the\nstructured prediction task in a weakly supervised setting, and present a novel\nthree stage Transformer model, VideoWhisperer, that is empowered to make joint\npredictions. In stage one, we learn contextualised embeddings for video\nfeatures in parallel with key objects that appear in the video clips to enable\nfine-grained spatio-temporal reasoning. The second stage sees verb-role queries\nattend and pool information from object embeddings, localising answers to\nquestions posed about the action. The final stage generates these answers as\ncaptions to describe each verb-role pair present in the video. Our model\noperates on a group of events (clips) simultaneously and predicts verbs,\nverb-role pairs, their nouns, and their grounding on-the-fly. When evaluated on\na grounding-augmented version of the VidSitu dataset, we observe a large\nimprovement in entity captioning accuracy, as well as the ability to localize\nverb-roles without grounding annotations at training time.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Project Page: this https URL\n",
    "authors": [
      "Zeeshan Khan",
      "C.V. Jawahar",
      "Makarand Tapaswi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10828"
  },
  {
    "id": "arXiv:2210.10834",
    "title": "A Clinical Dataset for the Evaluation of Motion Planners in Medical  Applications",
    "abstract": "The prospect of using autonomous robots to enhance the capabilities of\nphysicians and enable novel procedures has led to considerable efforts in\ndeveloping medical robots and incorporating autonomous capabilities. Motion\nplanning is a core component for any such system working in an environment that\ndemands near perfect levels of safety, reliability, and precision. Despite the\nextensive and promising work that has gone into developing motion planners for\nmedical robots, a standardized and clinically-meaningful way to compare\nexisting algorithms and evaluate novel planners and robots is not well\nestablished. We present the Medical Motion Planning Dataset (Med-MPD), a\npublicly-available dataset of real clinical scenarios in various organs for the\npurpose of evaluating motion planners for minimally-invasive medical robots.\nOur goal is that this dataset serve as a first step towards creating a larger\nrobust medical motion planning benchmark framework, advance research into\nmedical motion planners, and lift some of the burden of generating medical\nevaluation data.",
    "descriptor": "\nComments: 4 pages, 3 figures, to appear at the workshop \"Evaluating Motion Planning Performance: Metrics, Tools, Datasets, and Experimental Design\" at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Japan, October 23 - October 27, 2022\n",
    "authors": [
      "Inbar Fried",
      "Jason A. Akulian",
      "Ron Alterovitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10834"
  },
  {
    "id": "arXiv:2210.10836",
    "title": "Scene Text Recognition with Semantics",
    "abstract": "Scene Text Recognition (STR) models have achieved high performance in recent\nyears on benchmark datasets where text images are presented with minimal noise.\nTraditional STR recognition pipelines take a cropped image as sole input and\nattempt to identify the characters present. This infrastructure can fail in\ninstances where the input image is noisy or the text is partially obscured.\nThis paper proposes using semantic information from the greater scene to\ncontextualise predictions. We generate semantic vectors using object tags and\nfuse this information into a transformer-based architecture. The results\ndemonstrate that our multimodal approach yields higher performance than\ntraditional benchmark models, particularly on noisy instances.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Joshua Cesare Placidi",
      "Yishu Miao",
      "Zixu Wang",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10836"
  },
  {
    "id": "arXiv:2210.10838",
    "title": "A Pareto-optimal compositional energy-based model for sampling and  optimization of protein sequences",
    "abstract": "Deep generative models have emerged as a popular machine learning-based\napproach for inverse design problems in the life sciences. However, these\nproblems often require sampling new designs that satisfy multiple properties of\ninterest in addition to learning the data distribution. This multi-objective\noptimization becomes more challenging when properties are independent or\northogonal to each other. In this work, we propose a Pareto-compositional\nenergy-based model (pcEBM), a framework that uses multiple gradient descent for\nsampling new designs that adhere to various constraints in optimizing distinct\nproperties. We demonstrate its ability to learn non-convex Pareto fronts and\ngenerate sequences that simultaneously satisfy multiple desired properties\nacross a series of real-world antibody design tasks.",
    "descriptor": "",
    "authors": [
      "Nata\u0161a Tagasovska",
      "Nathan C. Frey",
      "Andreas Loukas",
      "Isidro H\u00f6tzel",
      "Julien Lafrance-Vanasse",
      "Ryan Lewis Kelly",
      "Yan Wu",
      "Arvind Rajpal",
      "Richard Bonneau",
      "Kyunghyun Cho",
      "Stephen Ra",
      "Vladimir Gligorijevi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.10838"
  },
  {
    "id": "arXiv:2210.10839",
    "title": "How Hate Speech Varies by Target Identity: A Computational Analysis",
    "abstract": "This paper investigates how hate speech varies in systematic ways according\nto the identities it targets. Across multiple hate speech datasets annotated\nfor targeted identities, we find that classifiers trained on hate speech\ntargeting specific identity groups struggle to generalize to other targeted\nidentities. This provides empirical evidence for differences in hate speech by\ntarget identity; we then investigate which patterns structure this variation.\nWe find that the targeted demographic category (e.g. gender/sexuality or\nrace/ethnicity) appears to have a greater effect on the language of hate speech\nthan does the relative social power of the targeted identity group. We also\nfind that words associated with hate speech targeting specific identities often\nrelate to stereotypes, histories of oppression, current social movements, and\nother social contexts specific to identities. These experiments suggest the\nimportance of considering targeted identity, as well as the social contexts\nassociated with these identities, in automated hate speech classification.",
    "descriptor": "\nComments: CoNLL 2022 camera-ready\n",
    "authors": [
      "Michael Miller Yoder",
      "Lynnette Hui Xian Ng",
      "David West Brown",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10839"
  },
  {
    "id": "arXiv:2210.10841",
    "title": "Prompting through Prototype: A Prototype-based Prompt Learning on  Pretrained Vision-Language Models",
    "abstract": "Prompt learning is a new learning paradigm which reformulates downstream\ntasks as similar pretraining tasks on pretrained models by leveraging textual\nprompts. Recent works have demonstrated that prompt learning is particularly\nuseful for few-shot learning, where there is limited training data. Depending\non the granularity of prompts, those methods can be roughly divided into\ntask-level prompting and instance-level prompting. Task-level prompting methods\nlearn one universal prompt for all input samples, which is efficient but\nineffective to capture subtle differences among different classes.\nInstance-level prompting methods learn a specific prompt for each input, though\neffective but inefficient. In this work, we develop a novel prototype-based\nprompt learning method to overcome the above limitations. In particular, we\nfocus on few-shot image recognition tasks on pretrained vision-language models\n(PVLMs) and develop a method of prompting through prototype (PTP), where we\ndefine $K$ image prototypes and $K$ prompt prototypes. In PTP, the image\nprototype represents a centroid of a certain image cluster in the latent space\nand a prompt prototype is defined as a soft prompt in the continuous space. The\nsimilarity between a query image and an image prototype determines how much\nthis prediction relies on the corresponding prompt prototype. Hence, in PTP,\nsimilar images will utilize similar prompting ways. Through extensive\nexperiments on seven real-world benchmarks, we show that PTP is an effective\nmethod to leverage the latent knowledge and adaptive to various PVLMs.\nMoreover, through detailed analysis, we discuss pros and cons for prompt\nlearning and parameter-efficient fine-tuning under the context of few-shot\nlearning.",
    "descriptor": "",
    "authors": [
      "Yue Zhang",
      "Hongliang Fei",
      "Dingcheng Li",
      "Tan Yu",
      "Ping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10841"
  },
  {
    "id": "arXiv:2210.10842",
    "title": "MMRNet: Improving Reliability for Multimodal Computer Vision for Bin  Picking via Multimodal Redundancy",
    "abstract": "Recently, there has been tremendous interest in industry 4.0 infrastructure\nto address labor shortages in global supply chains. Deploying artificial\nintelligence-enabled robotic bin picking systems in real world has become\nparticularly important for reducing labor demands and costs while increasing\nefficiency. To this end, artificial intelligence-enabled robotic bin picking\nsystems may be used to automate bin picking, but may also cause expensive\ndamage during an abnormal event such as a sensor failure. As such, reliability\nbecomes a critical factor for translating artificial intelligence research to\nreal world applications and products. In this paper, we propose a reliable\nvision system with MultiModal Redundancy (MMRNet) for tackling object detection\nand segmentation for robotic bin picking using data from different modalities.\nThis is the first system that introduces the concept of multimodal redundancy\nto combat sensor failure issues during deployment. In particular, we realize\nthe multimodal redundancy framework with a gate fusion module and dynamic\nensemble learning. Finally, we present a new label-free multimodal consistency\nscore that utilizes the output from all modalities to measure the overall\nsystem output reliability and uncertainty. Through experiments, we demonstrate\nthat in an event of missing modality, our system provides a much more reliable\nperformance compared to baseline models. We also demonstrate that our MC score\nis a more powerful reliability indicator for outputs during inference time\nwhere model generated confidence score are often over-confident.",
    "descriptor": "",
    "authors": [
      "Yuhao Chen",
      "Hayden Gunraj",
      "E. Zhixuan Zeng",
      "Maximilian Gilles",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10842"
  },
  {
    "id": "arXiv:2210.10848",
    "title": "Sparse arrays in R: the spray package",
    "abstract": "In this short article I introduce the spray package, which provides some\nfunctionality for handling sparse arrays. The package uses the C++ Standard\nTemplate Library's map class to store and retrieve elements. One natural\napplication for sparse arrays is multivariate polynomials and I give two\nexamples of the package in use, one drawn from the fields of random walks on\nlattices and one from the field of recreational combinatorics. The package is\navailable on CRAN at https://CRAN.R-project.org/package=spray.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Robin K. S. Hankin"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.10848"
  },
  {
    "id": "arXiv:2210.10849",
    "title": "Black Box Model Explanations and the Human Interpretability Expectations  -- An Analysis in the Context of Homicide Prediction",
    "abstract": "Strategies based on Explainable Artificial Intelligence - XAI have promoted\nbetter human interpretability of the results of black box machine learning\nmodels. The XAI measures being currently used (Ciu, Dalex, Eli5, Lofo, Shap,\nand Skater) provide various forms of explanations, including global rankings of\nrelevance of attributes. Current research points to the need for further\nstudies on how these explanations meet the Interpretability Expectations of\nhuman experts and how they can be used to make the model even more transparent\nwhile taking into account specific complexities of the model and dataset being\nanalyzed, as well as important human factors of sensitive real-world\ncontexts/problems. Intending to shed light on the explanations generated by XAI\nmeasures and their interpretabilities, this research addresses a real-world\nclassification problem related to homicide prediction, duly endorsed by the\nscientific community, replicated its proposed black box model and used 6\ndifferent XAI measures to generate explanations and 6 different human experts\nto generate what this research referred to as Interpretability Expectations -\nIE. The results were computed by means of comparative analysis and\nidentification of relationships among all the attribute ranks produced, and\n~49% concordance was found among attributes indicated by means of XAI measures\nand human experts, ~41% exclusively by XAI measures and ~10% exclusively by\nhuman experts. The results allow for answering: \"Do the different XAI measures\ngenerate similar explanations for the proposed problem?\", \"Are the\ninterpretability expectations generated among different human experts\nsimilar?\", \"Do the explanations generated by XAI measures meet the\ninterpretability expectations of human experts?\" and \"Can Interpretability\nExplanations and Expectations work together?\", all of which concerning the\ncontext of homicide prediction.",
    "descriptor": "\nComments: 24 pages, 6 Figures and 2 Tables\n",
    "authors": [
      "Jos\u00e9 Ribeiro",
      "N\u00edkolas Carneiro",
      "Ronnie Alves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10849"
  },
  {
    "id": "arXiv:2210.10851",
    "title": "Scalable Coherent Optical Crossbar Architecture using PCM for AI  Acceleration",
    "abstract": "Optical computing has been recently proposed as a new compute paradigm to\nmeet the demands of future AI/ML workloads in datacenters and supercomputers.\nHowever, proposed implementations so far suffer from lack of scalability, large\nfootprints and high power consumption, and incomplete system-level\narchitectures to become integrated within existing datacenter architecture for\nreal-world applications. In this work, we present a truly scalable optical AI\naccelerator based on a crossbar architecture. We have considered all major\nroadblocks and address them in this design. Weights will be stored on chip\nusing phase change material (PCM) that can be monolithically integrated in\nsilicon photonic processes. All electro-optical components and circuit blocks\nare modeled based on measured performance metrics in a 45nm monolithic silicon\nphotonic process, which can be co-packaged with advanced CPU/GPUs and HBM\nmemories. We also present a system-level modeling and analysis of our chip's\nperformance for the Resnet-50V1.5, considering all critical parameters,\nincluding memory size, array size, photonic losses, and energy consumption of\nperipheral electronics. Both on-chip SRAM and off-chip DRAM energy overheads\nhave been considered in this modeling. We additionally address how using a\ndual-core crossbar design can eliminate programming time overhead at practical\nSRAM block sizes and batch sizes. Our results show that a 128 x 128 proposed\narchitecture can achieve inference per second (IPS) similar to Nvidia A100 GPU\nat 15.4 times lower power and 7.24 times lower area.",
    "descriptor": "\nComments: 6 Pages, 8 figures\n",
    "authors": [
      "Daniel Sturm",
      "Sajjad Moazeni"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.10851"
  },
  {
    "id": "arXiv:2210.10854",
    "title": "Decoding Polar Codes via Noisy Quantum Gates: Quantum Circuits and  Insights",
    "abstract": "The use of quantum computation for wireless network applications is emerging\nas a promising paradigm to bridge the performance gap between in-practice and\noptimal wireless algorithms. While today's quantum technology offers limited\nnumber of qubits and low fidelity gates, application-based quantum solutions\nhelp us to understand and improve the performance of such technology even\nfurther. This paper introduces QGateD-Polar, a novel Quantum Gate-based\nMaximum-Likelihood Decoder design for Polar error correction codes, which are\nbecoming widespread in today's 5G and tomorrow's NextG wireless networks.\nQGateD-Polar uses quantum gates to dictate the time evolution of Polar code\ndecoding -- from the received wireless soft data to the final decoded solution\n-- by leveraging quantum phenomena such as superposition, entanglement, and\ninterference, making it amenable to quantum gate-based computers. Our early\nresults show that QGateD-Polar achieves the Maximum Likelihood performance in\nideal quantum simulations, demonstrating how performance varies with noise.",
    "descriptor": "",
    "authors": [
      "Srikar Kasi",
      "John Kaewell",
      "Shahab Hamidi-Rad",
      "Kyle Jamieson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10854"
  },
  {
    "id": "arXiv:2210.10855",
    "title": "Spectral Subspace Dictionary Learning",
    "abstract": "\\textit{Dictionary learning}, the problem of recovering a sparsely used\nmatrix $\\mathbf{D} \\in \\mathbb{R}^{M \\times K}$ and $N$ independent $K \\times\n1$ $s$-sparse vectors $\\mathbf{X} \\in \\mathbb{R}^{K \\times N}$ from samples of\nthe form $\\mathbf{Y} = \\mathbf{D}\\mathbf{X}$, is of increasing importance to\napplications in signal processing and data science. Early papers on provable\ndictionary learning identified that one can detect whether two samples\n$\\mathbf{y}_i, \\mathbf{y}_j$ share a common dictionary element by testing if\ntheir absolute inner product (correlation) exceeds a certain threshold:\n$|\\left\\langle \\mathbf{y}_i, \\mathbf{y}_j \\right\\rangle| > \\tau$. These\ncorrelation-based methods work well when sparsity is small, but suffer from\ndeclining performance when sparsity grows faster than $\\sqrt{M}$; as a result,\nsuch methods were abandoned in the search for dictionary learning algorithms\nwhen sparsity is nearly linear in $M$.\nIn this paper, we revisit correlation-based dictionary learning. Instead of\nseeking to recover individual dictionary atoms, we employ a spectral method to\nrecover the subspace spanned by the dictionary atoms in the support of each\nsample. This approach circumvents the primary challenge encountered by previous\ncorrelation methods, namely that when sharing information between two samples\nit is difficult to tell \\textit{which} dictionary element the two samples\nshare. We prove that under a suitable random model the resulting algorithm\nrecovers dictionaries in polynomial time for sparsity linear in $M$ up to log\nfactors. Our results improve on the best known methods by achieving a decaying\nerror bound in dimension $M$; the best previously known results for the\novercomplete ($K > M$) setting achieve polynomial time linear regime only for\nconstant error bounds. Numerical simulations confirm our results.",
    "descriptor": "",
    "authors": [
      "Alexei Novikov",
      "Stephen White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.10855"
  },
  {
    "id": "arXiv:2210.10857",
    "title": "Modeling Animal Vocalizations through Synthesizers",
    "abstract": "Modeling real-world sound is a fundamental problem in the creative use of\nmachine learning and many other fields, including human speech processing and\nbioacoustics. Transformer-based generative models and some prior work (e.g.,\nDDSP) are known to produce realistic sound, although they have limited control\nand are hard to interpret. As an alternative, we aim to use modular\nsynthesizers, i.e., compositional, parametric electronic musical instruments,\nfor modeling non-music sounds. However, inferring synthesizer parameters given\na target sound, i.e., the parameter inference task, is not trivial for general\nsounds, and past research has typically focused on musical sound. In this work,\nwe optimize a differentiable synthesizer from TorchSynth in order to model,\nemulate, and creatively generate animal vocalizations. We compare an array of\noptimization methods, from gradient-based search to genetic algorithms, for\ninferring its parameters, and then demonstrate how one can control and\ninterpret the parameters for modeling non-music sounds.",
    "descriptor": "",
    "authors": [
      "Masato Hagiwara",
      "Maddie Cusimano",
      "Jen-Yu Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10857"
  },
  {
    "id": "arXiv:2210.10860",
    "title": "Two-Turn Debate Doesn't Help Humans Answer Hard Reading Comprehension  Questions",
    "abstract": "The use of language-model-based question-answering systems to aid humans in\ncompleting difficult tasks is limited, in part, by the unreliability of the\ntext these systems generate. Using hard multiple-choice reading comprehension\nquestions as a testbed, we assess whether presenting humans with arguments for\ntwo competing answer options, where one is correct and the other is incorrect,\nallows human judges to perform more accurately, even when one of the arguments\nis unreliable and deceptive. If this is helpful, we may be able to increase our\njustified trust in language-model-based systems by asking them to produce these\narguments where needed. Previous research has shown that just a single turn of\narguments in this format is not helpful to humans. However, as debate settings\nare characterized by a back-and-forth dialogue, we follow up on previous\nresults to test whether adding a second round of counter-arguments is helpful\nto humans. We find that, regardless of whether they have access to arguments or\nnot, humans perform similarly on our task. These findings suggest that, in the\ncase of answering reading comprehension questions, debate is not a helpful\nformat.",
    "descriptor": "\nComments: 12 pages, 6 figures, 7 tables\n",
    "authors": [
      "Alicia Parrish",
      "Harsh Trivedi",
      "Nikita Nangia",
      "Vishakh Padmakumar",
      "Jason Phang",
      "Amanpreet Singh Saimbhi",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10860"
  },
  {
    "id": "arXiv:2210.10861",
    "title": "QA Domain Adaptation using Hidden Space Augmentation and Self-Supervised  Contrastive Adaptation",
    "abstract": "Question answering (QA) has recently shown impressive results for answering\nquestions from customized domains. Yet, a common challenge is to adapt QA\nmodels to an unseen target domain. In this paper, we propose a novel\nself-supervised framework called QADA for QA domain adaptation. QADA introduces\na novel data augmentation pipeline used to augment training QA samples.\nDifferent from existing methods, we enrich the samples via hidden space\naugmentation. For questions, we introduce multi-hop synonyms and sample\naugmented token embeddings with Dirichlet distributions. For contexts, we\ndevelop an augmentation method which learns to drop context spans via a custom\nattentive sampling strategy. Additionally, contrastive learning is integrated\nin the proposed self-supervised adaptation framework QADA. Unlike existing\napproaches, we generate pseudo labels and propose to train the model via a\nnovel attention-based contrastive adaptation method. The attention weights are\nused to build informative features for discrepancy estimation that helps the QA\nmodel separate answers and generalize across source and target domains. To the\nbest of our knowledge, our work is the first to leverage hidden space\naugmentation and attention-based contrastive adaptation for self-supervised\ndomain adaptation in QA. Our evaluation shows that QADA achieves considerable\nimprovements on multiple target datasets over state-of-the-art baselines in QA\ndomain adaptation.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Bernhard Kratzwald",
      "Stefan Feuerriegel",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10861"
  },
  {
    "id": "arXiv:2210.10864",
    "title": "Cluster and Aggregate: Face Recognition with Large Probe Set",
    "abstract": "Feature fusion plays a crucial role in unconstrained face recognition where\ninputs (probes) comprise of a set of $N$ low quality images whose individual\nqualities vary. Advances in attention and recurrent modules have led to feature\nfusion that can model the relationship among the images in the input set.\nHowever, attention mechanisms cannot scale to large $N$ due to their quadratic\ncomplexity and recurrent modules suffer from input order sensitivity. We\npropose a two-stage feature fusion paradigm, Cluster and Aggregate, that can\nboth scale to large $N$ and maintain the ability to perform sequential\ninference with order invariance. Specifically, Cluster stage is a linear\nassignment of $N$ inputs to $M$ global cluster centers, and Aggregation stage\nis a fusion over $M$ clustered features. The clustered features play an\nintegral role when the inputs are sequential as they can serve as a\nsummarization of past features. By leveraging the order-invariance of\nincremental averaging operation, we design an update rule that achieves\nbatch-order invariance, which guarantees that the contributions of early image\nin the sequence do not diminish as time steps increase. Experiments on IJB-B\nand IJB-S benchmark datasets show the superiority of the proposed two-stage\nparadigm in unconstrained face recognition. Code and pretrained models are\navailable in https://github.com/mk-minchul/caface",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Minchul Kim",
      "Feng Liu",
      "Anil Jain",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10864"
  },
  {
    "id": "arXiv:2210.10865",
    "title": "Robotic Table Wiping via Reinforcement Learning and Whole-body  Trajectory Optimization",
    "abstract": "We propose a framework to enable multipurpose assistive mobile robots to\nautonomously wipe tables to clean spills and crumbs. This problem is\nchallenging, as it requires planning wiping actions while reasoning over\nuncertain latent dynamics of crumbs and spills captured via high-dimensional\nvisual observations. Simultaneously, we must guarantee constraints satisfaction\nto enable safe deployment in unstructured cluttered environments. To tackle\nthis problem, we first propose a stochastic differential equation to model\ncrumbs and spill dynamics and absorption with a robot wiper. Using this model,\nwe train a vision-based policy for planning wiping actions in simulation using\nreinforcement learning (RL). To enable zero-shot sim-to-real deployment, we\ndovetail the RL policy with a whole-body trajectory optimization framework to\ncompute base and arm joint trajectories that execute the desired wiping motions\nwhile guaranteeing constraints satisfaction. We extensively validate our\napproach in simulation and on hardware. Video: https://youtu.be/inORKP4F3EI",
    "descriptor": "",
    "authors": [
      "Thomas Lew",
      "Sumeet Singh",
      "Mario Prats",
      "Jeffrey Bingham",
      "Jonathan Weisz",
      "Benjie Holson",
      "Xiaohan Zhang",
      "Vikas Sindhwani",
      "Yao Lu",
      "Fei Xia",
      "Peng Xu",
      "Tingnan Zhang",
      "Jie Tan",
      "Montserrat Gonzalez"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10865"
  },
  {
    "id": "arXiv:2210.10867",
    "title": "An Optimization-Based Supervised Learning Algorithm for PXRD Phase  Fraction Estimation",
    "abstract": "In powder diffraction data analysis, phase identification is the process of\ndetermining the crystalline phases in a sample using its characteristic Bragg\npeaks. For multiphasic spectra, we must also determine the relative weight\nfraction of each phase in the sample. Machine Learning algorithms (e.g.,\nArtificial Neural Networks) have been applied to perform such difficult tasks\nin powder diffraction analysis, but typically require a significant number of\ntraining samples for acceptable performance. We have developed an approach that\nperforms well even with a small number of training samples. We apply a\nfixed-point iteration algorithm on the labelled training samples to estimate\nmonophasic spectra. Then, given an unknown sample spectrum, we again use a\nfixed-point iteration algorithm to determine the weighted combination of\nmonophase spectra that best approximates the unknown sample spectrum. These\nweights are the desired phase fractions for the sample. We compare our approach\nwith several traditional Machine Learning algorithms.",
    "descriptor": "\nComments: Brief Communications\n",
    "authors": [
      "Patrick Hosein",
      "Jaimie Greasley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10867"
  },
  {
    "id": "arXiv:2210.10868",
    "title": "Control Design under Actuator Saturation and Multi-Rate Sampling",
    "abstract": "The problem of designing a stabilizing feedback controller in the presence of\nsaturating actuators and multi-rate (asynchronous) aperiodic state measurements\nis studied. Specifically, we consider a scenario in which measurements of the\nplant states are collected at the controller end in a sporadic and asynchronous\nfashion. A hybrid controller is used to perform a fusion of measurements\nsampled at different times. In between sampling events, the controller behaves\nas a copy of the plant and provides a feedback control signal based on the\nreconstruction of the plant state. The presence of saturation at the plant\ninput limits the value of the components of this signal to a bounded range.\nWhen a new measurement is available, the controller state undergoes an\ninstantaneous jump. The resulting system is augmented with a set of timers\ntriggering the arrival of new measurements and analyzed in a hybrid systems\nframework. Relying on Lyapunov tools for hybrid systems and techniques for\ncontrol design under saturation, we propose sufficient conditions in the form\nof matrix inequalities to ensure regional exponential stability of a closed-set\ncontaining the origin of the plant, i.e., exponential stability with a\nguaranteed region of attraction. Specifically, explicit estimates of the basin\nof attraction are provided in the form of ellipsoidal sets. Leveraging those\nconditions, a design procedure based on semidefinite programming is proposed to\ndesign a stabilizing controller with maximized size of the basin attraction.\nThe effectiveness of the proposed methodology is shown in an example.",
    "descriptor": "\nComments: Extended version of the paper accepted for publication in Automatica\n",
    "authors": [
      "Francesco Ferrante",
      "Ricardo G. Sanfelice",
      "Sophie Tarbouriech"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10868"
  },
  {
    "id": "arXiv:2210.10873",
    "title": "A new Discrete Analysis Of Fourth Order Elliptic Variational  Inequalities",
    "abstract": "This paper applies the gradient discretisation method (GDM) for fourth order\nelliptic variational inequalities. The GDM provides a new formulation of error\nestimates and a complete convergence analysis of several numerical methods. We\nshow that the convergence is unconditional. Classical assumptions on data are\nonly sufficient to establish the convergence results. These results are\napplicable for all schemes fall in the framework of GDM.",
    "descriptor": "",
    "authors": [
      "Yahya Alnashri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10873"
  },
  {
    "id": "arXiv:2210.10876",
    "title": "Exiting the Simulation: The Road to Robust and Resilient Autonomous  Vehicles at Scale",
    "abstract": "In the past two decades, autonomous driving has been catalyzed into reality\nby the growing capabilities of machine learning. This paradigm shift possesses\nsignificant potential to transform the future of mobility and reshape our\nsociety as a whole. With the recent advances in perception, planning, and\ncontrol capabilities, autonomous driving technologies are being rolled out for\npublic trials, yet we remain far from being able to rigorously ensure the\nresilient operations of these systems across the long-tailed nature of the\ndriving environment. Given the limitations of real-world testing, autonomous\nvehicle simulation stands as the critical component in exploring the edge of\nautonomous driving capabilities, developing the robust behaviors required for\nsuccessful real-world operation, and enabling the extraction of hidden risks\nfrom these complex systems prior to deployment. This paper presents the current\nstate-of-the-art simulation frameworks and methodologies used in the\ndevelopment of autonomous driving systems, with a focus on outlining how\nsimulation is used to build the resiliency required for real-world operation\nand the methods developed to bridge the gap between simulation and reality. A\nsynthesis of the key challenges surrounding autonomous driving simulation is\npresented, specifically highlighting the opportunities to further advance the\nability to continuously learn in simulation and effectively transfer the\nlearning into the real-world - enabling autonomous vehicles to exit the\nguardrails of simulation and deliver robust and resilient operations at scale.",
    "descriptor": "",
    "authors": [
      "Richard Chakra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10876"
  },
  {
    "id": "arXiv:2210.10879",
    "title": "G-Augment: Searching For The Meta-Structure Of Data Augmentation  Policies For ASR",
    "abstract": "Data augmentation is a ubiquitous technique used to provide robustness to\nautomatic speech recognition (ASR) training. However, even as so much of the\nASR training process has become automated and more \"end-to-end\", the data\naugmentation policy (what augmentation functions to use, and how to apply them)\nremains hand-crafted. We present Graph-Augment, a technique to define the\naugmentation space as directed acyclic graphs (DAGs) and search over this space\nto optimize the augmentation policy itself. We show that given the same\ncomputational budget, policies produced by G-Augment are able to perform better\nthan SpecAugment policies obtained by random search on fine-tuning tasks on\nCHiME-6 and AMI. G-Augment is also able to establish a new state-of-the-art ASR\nperformance on the CHiME-6 evaluation set (30.7% WER). We further demonstrate\nthat G-Augment policies show better transfer properties across warm-start to\ncold-start training and model size compared to random-searched SpecAugment\npolicies.",
    "descriptor": "\nComments: 6 pages, accepted at SLT 2022\n",
    "authors": [
      "Gary Wang",
      "Ekin D.Cubuk",
      "Andrew Rosenberg",
      "Shuyang Cheng",
      "Ron J. Weiss",
      "Bhuvana Ramabhadran",
      "Pedro J. Moreno",
      "Quoc V. Le",
      "Daniel S. Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10879"
  },
  {
    "id": "arXiv:2210.10880",
    "title": "Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in  Federated Learning",
    "abstract": "Gradient inversion attack enables recovery of training samples from model\nupdates in federated learning (FL) and constitutes a serious threat to data\nprivacy. To mitigate this vulnerability, prior work proposed both principled\ndefenses based on differential privacy, as well as heuristic defenses based on\ngradient compression as countermeasures. These defenses have so far been very\neffective, in particular those based on gradient compression that allow the\nmodel to maintain high accuracy while greatly reducing the attack's\neffectiveness. In this work, we argue that such findings do not accurately\nreflect the privacy risk in FL, and show that existing defenses can be broken\nby a simple adaptive attack that trains a model using auxiliary data to learn\nhow to invert gradients on both vision and language tasks.",
    "descriptor": "",
    "authors": [
      "Ruihan Wu",
      "Xiangyu Chen",
      "Chuan Guo",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10880"
  },
  {
    "id": "arXiv:2210.10886",
    "title": "Backdoor Attack and Defense in Federated Generative Adversarial  Network-based Medical Image Synthesis",
    "abstract": "Deep Learning-based image synthesis techniques have been applied in\nhealthcare research for generating medical images to support open research and\naugment medical datasets. Training generative adversarial neural networks\n(GANs) usually require large amounts of training data. Federated learning (FL)\nprovides a way of training a central model using distributed data while keeping\nraw data locally. However, given that the FL server cannot access the raw data,\nit is vulnerable to backdoor attacks, an adversarial by poisoning training\ndata. Most backdoor attack strategies focus on classification models and\ncentralized domains. It is still an open question if the existing backdoor\nattacks can affect GAN training and, if so, how to defend against the attack in\nthe FL setting. In this work, we investigate the overlooked issue of backdoor\nattacks in federated GANs (FedGANs). The success of this attack is subsequently\ndetermined to be the result of some local discriminators overfitting the\npoisoned data and corrupting the local GAN equilibrium, which then further\ncontaminates other clients when averaging the generator's parameters and yields\nhigh generator loss. Therefore, we proposed FedDetect, an efficient and\neffective way of defending against the backdoor attack in the FL setting, which\nallows the server to detect the client's adversarial behavior based on their\nlosses and block the malicious clients. Our extensive experiments on two\nmedical datasets with different modalities demonstrate the backdoor attack on\nFedGANs can result in synthetic images with low fidelity. After detecting and\nsuppressing the detected malicious clients using the proposed defense strategy,\nwe show that FedGANs can synthesize high-quality medical datasets (with labels)\nfor data augmentation to improve classification models' performance.",
    "descriptor": "\nComments: 25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762\n",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10886"
  },
  {
    "id": "arXiv:2210.10888",
    "title": "Deep Learning-Derived Optimal Aviation Strategies to Control Pandemics",
    "abstract": "The COVID-19 pandemic has affected countries across the world, demanding\ndrastic public health policies to mitigate the spread of infection, leading to\neconomic crisis as a collateral damage. In this work, we investigated the\nimpact of human mobility (described via international commercial flights) on\nCOVID-19 infection dynamics at the global scale. For this, we developed a graph\nneural network-based framework referred to as Dynamic Connectivity GraphSAGE\n(DCSAGE), which operates over spatiotemporal graphs and is well-suited for\ndynamically changing adjacency information. To obtain insights on the relative\nimpact of different geographical locations, due to their associated air\ntraffic, on the evolution of the pandemic, we conducted local sensitivity\nanalysis on our model through node perturbation experiments. From our analyses,\nwe identified Western Europe, North America, and Middle East as the leading\ngeographical locations fueling the pandemic, attributed to the enormity of air\ntraffic originating or transiting through these regions. We used these\nobservations to identify tangible air traffic reduction strategies that can\nhave a high impact on controlling the pandemic, with minimal interference to\nhuman mobility. Our work provides a robust deep learning-based tool to study\nglobal pandemics and is of key relevance to policy makers to take informed\ndecisions regarding air traffic restrictions during future outbreaks.",
    "descriptor": "\nComments: 32 pages, 6 figures (with additional 9 supplementary figures)\n",
    "authors": [
      "Syed Rizvi",
      "Akash Awasthi",
      "Maria J. Pel\u00e1ez",
      "Zhihui Wang",
      "Vittorio Cristini",
      "Hien Van Nguyen",
      "Prashant Dogra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2210.10888"
  },
  {
    "id": "arXiv:2210.10890",
    "title": "HT-Net: Hierarchical Transformer based Operator Learning Model for  Multiscale PDEs",
    "abstract": "Complex nonlinear interplays of multiple scales give rise to many interesting\nphysical phenomena and pose major difficulties for the computer simulation of\nmultiscale PDE models in areas such as reservoir simulation, high frequency\nscattering and turbulence modeling. In this paper, we introduce a hierarchical\ntransformer (HT) scheme to efficiently learn the solution operator for\nmultiscale PDEs. We construct a hierarchical architecture with scale adaptive\ninteraction range, such that the features can be computed in a nested manner\nand with a controllable linear cost. Self-attentions over a hierarchy of levels\ncan be used to encode and decode the multiscale solution space over all scale\nranges. In addition, we adopt an empirical $H^1$ loss function to counteract\nthe spectral bias of the neural network approximation for multiscale functions.\nIn the numerical experiments, we demonstrate the superior performance of the HT\nscheme compared with state-of-the-art (SOTA) methods for representative\nmultiscale problems.",
    "descriptor": "",
    "authors": [
      "Xinliang Liu",
      "Bo Xu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10890"
  },
  {
    "id": "arXiv:2210.10892",
    "title": "DEEP$^2$: Deep Learning Powered De-scattering with Excitation Patterning",
    "abstract": "Limited throughput is a key challenge in in-vivo deep-tissue imaging using\nnonlinear optical microscopy. Point scanning multiphoton microscopy, the\ncurrent gold standard, is slow especially compared to the wide-field imaging\nmodalities used for optically cleared or thin specimens. We recently introduced\n'De-scattering with Excitation Patterning or DEEP', as a widefield alternative\nto point-scanning geometries. Using patterned multiphoton excitation, DEEP\nencodes spatial information inside tissue before scattering. However, to\nde-scatter at typical depths, hundreds of such patterned excitations are\nneeded. In this work, we present DEEP$^2$, a deep learning based model, that\ncan de-scatter images from just tens of patterned excitations instead of\nhundreds. Consequently, we improve DEEP's throughput by almost an order of\nmagnitude. We demonstrate our method in multiple numerical and physical\nexperiments including in-vivo cortical vasculature imaging up to four\nscattering lengths deep, in alive mice.",
    "descriptor": "",
    "authors": [
      "Navodini Wijethilake",
      "Mithunjha Anandakumar",
      "Cheng Zheng",
      "Josiah R. Boivin",
      "Peter T. C. So",
      "Murat Yildirim",
      "Dushan N. Wadduwage"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10892"
  },
  {
    "id": "arXiv:2210.10897",
    "title": "Distribution Shift Detection for Deep Neural Networks",
    "abstract": "To deploy and operate deep neural models in production, the quality of their\npredictions, which might be contaminated benignly or manipulated maliciously by\ninput distributional deviations, must be monitored and assessed. Specifically,\nwe study the case of monitoring the healthy operation of a deep neural network\n(DNN) receiving a stream of data, with the aim of detecting input\ndistributional deviations over which the quality of the network's predictions\nis potentially damaged. Using selective prediction principles, we propose a\ndistribution deviation detection method for DNNs. The proposed method is\nderived from a tight coverage generalization bound computed over a sample of\ninstances drawn from the true underlying distribution. Based on this bound, our\ndetector continuously monitors the operation of the network over a test window\nand fires off an alarm whenever a deviation is detected. This novel detection\nmethod consistently and significantly outperforms the state of the art with\nrespect to the CIFAR-10 and ImageNet datasets, thus establishing a new\nperformance bar for this task, while being substantially more efficient in time\nand space complexities.",
    "descriptor": "",
    "authors": [
      "Guy Bar-Shalom",
      "Yonatan Geifman",
      "Ran El-Yaniv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10897"
  },
  {
    "id": "arXiv:2210.10899",
    "title": "Learning Preferences for Interactive Autonomy",
    "abstract": "When robots enter everyday human environments, they need to understand their\ntasks and how they should perform those tasks. To encode these, reward\nfunctions, which specify the objective of a robot, are employed. However,\ndesigning reward functions can be extremely challenging for complex tasks and\nenvironments. A promising approach is to learn reward functions from humans.\nRecently, several robot learning works embrace this approach and leverage human\ndemonstrations to learn the reward functions. Known as inverse reinforcement\nlearning, this approach relies on a fundamental assumption: humans can provide\nnear-optimal demonstrations to the robot. Unfortunately, this is rarely the\ncase: human demonstrations to the robot are often suboptimal due to various\nreasons, e.g., difficulty of teleoperation, robot having high degrees of\nfreedom, or humans' cognitive limitations.\nThis thesis is an attempt towards learning reward functions from human users\nby using other, more reliable data modalities. Specifically, we study how\nreward functions can be learned using comparative feedback, in which the human\nuser compares multiple robot trajectories instead of (or in addition to)\nproviding demonstrations. To this end, we first propose various forms of\ncomparative feedback, e.g., pairwise comparisons, best-of-many choices,\nrankings, scaled comparisons; and describe how a robot can use these various\nforms of human feedback to infer a reward function, which may be parametric or\nnon-parametric. Next, we propose active learning techniques to enable the robot\nto ask for comparison feedback that optimizes for the expected information that\nwill be gained from that user feedback. Finally, we demonstrate the\napplicability of our methods in a wide variety of domains, ranging from\nautonomous driving simulations to home robotics, from standard reinforcement\nlearning benchmarks to lower-body exoskeletons.",
    "descriptor": "\nComments: Ph.D. Thesis (Stanford University), 198 pages\n",
    "authors": [
      "Erdem B\u0131y\u0131k"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10899"
  },
  {
    "id": "arXiv:2210.10900",
    "title": "$r-$Adaptive Deep Learning Method for Solving Partial Differential  Equations",
    "abstract": "We introduce an $r-$adaptive algorithm to solve Partial Differential\nEquations using a Deep Neural Network. The proposed method restricts to tensor\nproduct meshes and optimizes the boundary node locations in one dimension, from\nwhich we build two- or three-dimensional meshes. The method allows the\ndefinition of fixed interfaces to design conforming meshes, and enables changes\nin the topology, i.e., some nodes can jump across fixed interfaces. The method\nsimultaneously optimizes the node locations and the PDE solution values over\nthe resulting mesh. To numerically illustrate the performance of our proposed\n$r-$adaptive method, we apply it in combination with a collocation method, a\nLeast Squares Method, and a Deep Ritz Method. We focus on the latter to solve\none- and two-dimensional problems whose solutions are smooth, singular, and/or\nexhibit strong gradients.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "\u00c1ngel J. Omella",
      "David Pardo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.10900"
  },
  {
    "id": "arXiv:2210.10903",
    "title": "Machine and Deep Learning Methods with Manual and Automatic Labelling  for News Classification in Bangla Language",
    "abstract": "Research in Natural Language Processing (NLP) has increasingly become\nimportant due to applications such as text classification, text mining,\nsentiment analysis, POS tagging, named entity recognition, textual entailment,\nand many others. This paper introduces several machine and deep learning\nmethods with manual and automatic labelling for news classification in the\nBangla language. We implemented several machine (ML) and deep learning (DL)\nalgorithms. The ML algorithms are Logistic Regression (LR), Stochastic Gradient\nDescent (SGD), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest\nNeighbour (KNN), used with Bag of Words (BoW), Term Frequency-Inverse Document\nFrequency (TF-IDF), and Doc2Vec embedding models. The DL algorithms are Long\nShort-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit\n(GRU), and Convolutional Neural Network (CNN), used with Word2vec, Glove, and\nFastText word embedding models. We develop automatic labelling methods using\nLatent Dirichlet Allocation (LDA) and investigate the performance of\nsingle-label and multi-label article classification methods. To investigate\nperformance, we developed from scratch Potrika, the largest and the most\nextensive dataset for news classification in the Bangla language, comprising\n185.51 million words and 12.57 million sentences contained in 664,880 news\narticles in eight distinct categories, curated from six popular online news\nportals in Bangladesh for the period 2014-2020. GRU and Fasttext with 91.83%\nachieve the highest accuracy for manually-labelled data. For the automatic\nlabelling case, KNN and Doc2Vec at 57.72% and 75% achieve the highest accuracy\nfor single-label and multi-label data, respectively. The methods developed in\nthis paper are expected to advance research in Bangla and other languages.",
    "descriptor": "\nComments: 29 pages, 30 figures\n",
    "authors": [
      "Istiak Ahmad",
      "Fahad AlQurashi",
      "Rashid Mehmood"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10903"
  },
  {
    "id": "arXiv:2210.10906",
    "title": "A baseline revisited: Pushing the limits of multi-segment models for  context-aware translation",
    "abstract": "This paper addresses the task of contextual translation using multi-segment\nmodels. Specifically we show that increasing model capacity further pushes the\nlimits of this approach and that deeper models are more suited to capture\ncontext dependencies. Furthermore, improvements observed with larger models can\nbe transferred to smaller models using knowledge distillation. Our experiments\nshow that this approach achieves competitive performance across several\nlanguages and benchmarks, without additional language-specific tuning and task\nspecific architectures.",
    "descriptor": "",
    "authors": [
      "Suvodeep Majumde",
      "Stanislas Lauly",
      "Maria Nadejde",
      "Marcello Federico",
      "Georgiana Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10906"
  },
  {
    "id": "arXiv:2210.10910",
    "title": "A Referable NFT Scheme",
    "abstract": "Existing NFTs confront restrictions of \\textit{one-time incentive} and\n\\textit{product isolation}. Creators cannot obtain benefits once having sold\ntheir NFT products due to the lack of relationships across different NFTs,\nwhich results in controversial possible profit sharing. This work proposes a\nreferable NFT scheme to extend the incentive sustainability of NFTs. We\nconstruct the referable NFT (rNFT) network to increase exposure and enhance the\nreferring relationship of inclusive items. We introduce the DAG topology to\ngenerate directed edges between each pair of NFTs with corresponding weights\nand labels for advanced usage. We accordingly implement and propose the scheme\nunder Ethereum Improvement Proposal (EIP) standards, indexed in EIP-1155.\nFurther, we provide the mathematical formation to analyze the utility for each\nrNFT participant. The discussion gives general guidance among multi-dimensional\nparameters. To our knowledge, this is the first study to build the referable\nNFT network, explicitly showing the virtual connections among NFTs.",
    "descriptor": "\nComments: Align with EIP-5521\n",
    "authors": [
      "Qin Wang",
      "Guangsheng Yu",
      "Shange Fu",
      "Shiping Chen",
      "Jiangshan Yu",
      "Sherry Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10910"
  },
  {
    "id": "arXiv:2210.10913",
    "title": "Palm up: Playing in the Latent Manifold for Unsupervised Pretraining",
    "abstract": "Large and diverse datasets have been the cornerstones of many impressive\nadvancements in artificial intelligence. Intelligent creatures, however, learn\nby interacting with the environment, which changes the input sensory signals\nand the state of the environment. In this work, we aim to bring the best of\nboth worlds and propose an algorithm that exhibits an exploratory behavior\nwhilst it utilizes large diverse datasets. Our key idea is to leverage deep\ngenerative models that are pretrained on static datasets and introduce a\ndynamic model in the latent space. The transition dynamics simply mixes an\naction and a random sampled latent. It then applies an exponential moving\naverage for temporal persistency, the resulting latent is decoded to image\nusing pretrained generator. We then employ an unsupervised reinforcement\nlearning algorithm to explore in this environment and perform unsupervised\nrepresentation learning on the collected data. We further leverage the temporal\ninformation of this data to pair data points as a natural supervision for\nrepresentation learning. Our experiments suggest that the learned\nrepresentations can be successfully transferred to downstream tasks in both\nvision and reinforcement learning domains.",
    "descriptor": "\nComments: Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Hao Liu",
      "Tom Zahavy",
      "Volodymyr Mnih",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10913"
  },
  {
    "id": "arXiv:2210.10914",
    "title": "Prophet Attention: Predicting Attention with Future Attention for  Improved Image Captioning",
    "abstract": "Recently, attention based models have been used extensively in many\nsequence-to-sequence learning systems. Especially for image captioning, the\nattention based models are expected to ground correct image regions with proper\ngenerated words. However, for each time step in the decoding process, the\nattention based models usually use the hidden state of the current input to\nattend to the image regions. Under this setting, these attention models have a\n\"deviated focus\" problem that they calculate the attention weights based on\nprevious words instead of the one to be generated, impairing the performance of\nboth grounding and captioning. In this paper, we propose the Prophet Attention,\nsimilar to the form of self-supervision. In the training stage, this module\nutilizes the future information to calculate the \"ideal\" attention weights\ntowards image regions. These calculated \"ideal\" weights are further used to\nregularize the \"deviated\" attention. In this manner, image regions are grounded\nwith the correct words. The proposed Prophet Attention can be easily\nincorporated into existing image captioning models to improve their performance\nof both grounding and captioning. The experiments on the Flickr30k Entities and\nthe MSCOCO datasets show that the proposed Prophet Attention consistently\noutperforms baselines in both automatic metrics and human evaluations. It is\nworth noticing that we set new state-of-the-arts on the two benchmark datasets\nand achieve the 1st place on the leaderboard of the online MSCOCO benchmark in\nterms of the default ranking score, i.e., CIDEr-c40.",
    "descriptor": "\nComments: Accepted by NeurIPS 2020\n",
    "authors": [
      "Fenglin Liu",
      "Xuewei Ma",
      "Xuancheng Ren",
      "Xian Wu",
      "Wei Fan",
      "Yuexian Zou",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10914"
  },
  {
    "id": "arXiv:2210.10917",
    "title": "Substring Density Estimation from Traces",
    "abstract": "In the trace reconstruction problem, one seeks to reconstruct a binary string\n$s$ from a collection of traces, each of which is obtained by passing $s$\nthrough a deletion channel. It is known that $\\exp(\\tilde O(n^{1/5}))$ traces\nsuffice to reconstruct any length-$n$ string with high probability. We consider\na variant of the trace reconstruction problem where the goal is to recover a\n\"density map\" that indicates the locations of each length-$k$ substring\nthroughout $s$. We show that $\\epsilon^{-2}\\cdot \\text{poly}(n)$ traces suffice\nto recover the density map with error at most $\\epsilon$. As a result, when\nrestricted to a set of source strings whose minimum \"density map distance\" is\nat least $1/\\text{poly}(n)$, the trace reconstruction problem can be solved\nwith polynomially many traces.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Kayvon Mazooji",
      "Ilan Shomorony"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.10917"
  },
  {
    "id": "arXiv:2210.10920",
    "title": "DOT-VAE: Disentangling One Factor at a Time",
    "abstract": "As we enter the era of machine learning characterized by an overabundance of\ndata, discovery, organization, and interpretation of the data in an\n\\textit{unsupervised} manner becomes a critical need. One promising approach to\nthis endeavour is the problem of \\textit{Disentanglement}, which aims at\nlearning the underlying generative latent factors, called the factors of\nvariation, of the data and encoding them in disjoint latent representations.\nRecent advances have made efforts to solve this problem for synthetic datasets\ngenerated by a fixed set of independent factors of variation. Here, we propose\nto extend this to real-world datasets with a countable number of factors of\nvariations. We propose a novel framework which augments the latent space of a\nVariational Autoencoders with a disentangled space and is trained using a\nWake-Sleep-inspired two-step algorithm for unsupervised disentanglement. Our\nnetwork learns to disentangle interpretable, independent factors from the data\n``one at a time\", and encode it in different dimensions of the disentangled\nlatent space, while making no prior assumptions about the number of factors or\ntheir joint distribution. We demonstrate its quantitative and qualitative\neffectiveness by evaluating the latent representations learned on two synthetic\nbenchmark datasets; DSprites and 3DShapes and on a real datasets CelebA.",
    "descriptor": "",
    "authors": [
      "Vaishnavi Patil",
      "Matthew Evanusa",
      "Joseph JaJa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.10920"
  },
  {
    "id": "arXiv:2210.10922",
    "title": "Gradient Backpropagation based Feature Attribution to Enable  Explainable-AI on the Edge",
    "abstract": "There has been a recent surge in the field of Explainable AI (XAI) which\ntackles the problem of providing insights into the behavior of black-box\nmachine learning models. Within this field, \\textit{feature attribution}\nencompasses methods which assign relevance scores to input features and\nvisualize them as a heatmap. Designing flexible accelerators for multiple such\nalgorithms is challenging since the hardware mapping of these algorithms has\nnot been studied yet. In this work, we first analyze the dataflow of gradient\nbackpropagation based feature attribution algorithms to determine the resource\noverhead required over inference. The gradient computation is optimized to\nminimize the memory overhead. Second, we develop a High-Level Synthesis (HLS)\nbased configurable FPGA design that is targeted for edge devices and supports\nthree feature attribution algorithms. Tile based computation is employed to\nmaximally use on-chip resources while adhering to the resource constraints.\nRepresentative CNNs are trained on CIFAR-10 dataset and implemented on multiple\nXilinx FPGAs using 16-bit fixed-point precision demonstrating flexibility of\nour library. Finally, through efficient reuse of allocated hardware resources,\nour design methodology demonstrates a pathway to repurpose inference\naccelerators to support feature attribution with minimal overhead, thereby\nenabling real-time XAI on the edge.",
    "descriptor": "\nComments: To appear in 30th IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC 2022\n",
    "authors": [
      "Ashwin Bhat",
      "Adou Sangbone Assoa",
      "Arijit Raychowdhury"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.10922"
  },
  {
    "id": "arXiv:2210.10927",
    "title": "A Novel Approach to Set-Membership Observer for Systems with Unknown  Exogenous Inputs",
    "abstract": "Motivated by the increasing need to monitor safety-critical systems subject\nto uncertainties, a novel set-membership approach is proposed to estimate the\nstate of a dynamical system with unknown-but-bounded exogenous inputs. The\nproposed method decomposes the system into the strongly observable and weakly\nunobservable subsystem in which an unknown input observer and an ellipsoidal\nset-membership observer are designed for each subsystem, respectively. The\nconditions for the boundedness of the proposed set estimate are discussed, and\nthe proposed set-membership observer is also tested numerically using\nillustrative examples.",
    "descriptor": "",
    "authors": [
      "Marvin Jesse",
      "Dawei Sun",
      "Inseok Hwang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10927"
  },
  {
    "id": "arXiv:2210.10929",
    "title": "Hierarchical classification at multiple operating points",
    "abstract": "Many classification problems consider classes that form a hierarchy.\nClassifiers that are aware of this hierarchy may be able to make confident\npredictions at a coarse level despite being uncertain at the fine-grained\nlevel. While it is generally possible to vary the granularity of predictions\nusing a threshold at inference time, most contemporary work considers only\nleaf-node prediction, and almost no prior work has compared methods at multiple\noperating points. We present an efficient algorithm to produce operating\ncharacteristic curves for any method that assigns a score to every class in the\nhierarchy. Applying this technique to evaluate existing methods reveals that\ntop-down classifiers are dominated by a naive flat softmax classifier across\nthe entire operating range. We further propose two novel loss functions and\nshow that a soft variant of the structured hinge loss is able to significantly\noutperform the flat baseline. Finally, we investigate the poor accuracy of\ntop-down classifiers and demonstrate that they perform relatively well on\nunseen classes. Code is available online at https://github.com/jvlmdr/hiercls.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Jack Valmadre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10929"
  },
  {
    "id": "arXiv:2210.10933",
    "title": "The Software Stack That Won the Formula Student Driverless Competition",
    "abstract": "This report describes our approach to design and evaluate a software stack\nfor a race car capable of achieving competitive driving performance in the\ndifferent disciplines of the Formula Student Driverless. By using a 360{\\deg}\nLiDAR and optionally three cameras, we reliably recognize the plastic cones\nthat mark the track boundaries at distances of around 35 m, enabling us to\ndrive at the physical limits of the car. Using a GraphSLAM algorithm, we are\nable to map these cones with a root-mean-square error of less than 15 cm while\ndriving at speeds of over 70 kph on a narrow track. The high-precision map is\nused in the trajectory planning to detect the lane boundaries using Delaunay\ntriangulation and a parametric cubic spline. We calculate an optimized\ntrajectory using a minimum curvature approach together with a GGS-diagram that\ntakes the aerodynamics at different velocities into account. To track the\ntarget path with accelerations of up to 1.6 g, the control system is split into\na PI controller for longitudinal control and model predictive controller for\nlateral control. Additionally, a low-level optimal control allocation is used.\nThe software is realized in ROS C++ and tested in a custom simulation, as well\nas on the actual race track.",
    "descriptor": "\nComments: Published and presented at OCAR-ICRA2022, the 2nd Workshop on Opportunities and Challenges with Autonomous Racing at the IEEE International Conference on Robotics and Automation (ICRA) 2022. Recording available at this https URL\n",
    "authors": [
      "Andres Alvarez",
      "Nico Denner",
      "Zhe Feng",
      "David Fischer",
      "Yang Gao",
      "Lukas Harsch",
      "Sebastian Herz",
      "Nick Le Large",
      "Bach Nguyen",
      "Carlos Rosero",
      "Simon Schaefer",
      "Alexander Terletskiy",
      "Luca Wahl",
      "Shaoxiang Wang",
      "Jonona Yakupova",
      "Haocen Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10933"
  },
  {
    "id": "arXiv:2210.10936",
    "title": "FedRecover: Recovering from Poisoning Attacks in Federated Learning  using Historical Information",
    "abstract": "Federated learning is vulnerable to poisoning attacks in which malicious\nclients poison the global model via sending malicious model updates to the\nserver. Existing defenses focus on preventing a small number of malicious\nclients from poisoning the global model via robust federated learning methods\nand detecting malicious clients when there are a large number of them. However,\nit is still an open challenge how to recover the global model from poisoning\nattacks after the malicious clients are detected. A naive solution is to remove\nthe detected malicious clients and train a new global model from scratch, which\nincurs large cost that may be intolerable for resource-constrained clients such\nas smartphones and IoT devices.\nIn this work, we propose FedRecover, which can recover an accurate global\nmodel from poisoning attacks with small cost for the clients. Our key idea is\nthat the server estimates the clients' model updates instead of asking the\nclients to compute and communicate them during the recovery process. In\nparticular, the server stores the global models and clients' model updates in\neach round, when training the poisoned global model. During the recovery\nprocess, the server estimates a client's model update in each round using its\nstored historical information. Moreover, we further optimize FedRecover to\nrecover a more accurate global model using warm-up, periodic correction,\nabnormality fixing, and final tuning strategies, in which the server asks the\nclients to compute and communicate their exact model updates. Theoretically, we\nshow that the global model recovered by FedRecover is close to or the same as\nthat recovered by train-from-scratch under some assumptions. Empirically, our\nevaluation on four datasets, three federated learning methods, as well as\nuntargeted and targeted poisoning attacks (e.g., backdoor attacks) shows that\nFedRecover is both accurate and efficient.",
    "descriptor": "\nComments: To appear in IEEE S&P 2023\n",
    "authors": [
      "Xiaoyu Cao",
      "Jinyuan Jia",
      "Zaixi Zhang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10936"
  },
  {
    "id": "arXiv:2210.10945",
    "title": "Competitive Online Truthful Time-Sensitive-Valued Data Auction",
    "abstract": "In this work, we investigate online mechanisms for trading time-sensitive\nvalued data. We adopt a continuous function $d(t)$ to represent the data value\nfluctuation over time $t$. Our objective is to design an \\emph{online}\nmechanism achieving \\emph{truthfulness} and \\emph{revenue-competitiveness}. We\nfirst prove several lower bounds on the revenue competitive ratios under\nvarious assumptions. We then propose several online truthful auction mechanisms\nfor various adversarial models, such as a randomized observe-then-select\nmechanism $\\mathcal{M}_1$ and prove that it is \\textit{truthful} and\n$\\Theta(\\log n)$-competitive under some assumptions. Then we present an\neffective truthful weighted-selection mechanism $\\mathcal{M'}_W$ by relaxing\nthe assumptions on the sizes of the discount-classes. We prove that it achieves\na competitive ratio $\\Theta(n\\log n)$ for any known non-decreasing discount\nfunction $d(t)$, and the number of buyers in each discount class $n_c \\ge 2$.\nWhen the optimum expected revenue $OPT_1$ can be estimated within a constant\nfactor, i.e. $c_0 \\cdot OPT_1 \\le Z \\le OPT_1 $ for some constant $c_0\n\\in(0,1)$, we propose a truthful online posted-price mechanism that achieves a\nconstant competitive ratio $\\frac{4}{c_0}$. Our extensive numerical evaluations\ndemonstrate that our mechanisms perform very well in most cases.",
    "descriptor": "",
    "authors": [
      "Shuangshuang Xue",
      "Xiang-Yang Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10945"
  },
  {
    "id": "arXiv:2210.10946",
    "title": "Causally-guided Regularization of Graph Attention Improves  Generalizability",
    "abstract": "However, the inferred attentions are vulnerable to spurious correlations and\nconnectivity in the training data, hampering the generalizability of the model.\nWe introduce CAR, a general-purpose regularization framework for graph\nattention networks. Embodying a causal inference approach, \\methodname aligns\nthe attention mechanism with the causal effects of active interventions on\ngraph connectivity in a scalable manner. CAR is compatible with a variety of\ngraph attention architectures, and we show that it systematically improves\ngeneralizability on various node classification tasks. Our ablation studies\nindicate that \\methodname hones in on the aspects of graph structure most\npertinent to the prediction (e.g., homophily), and does so more effectively\nthan alternative approaches. Finally, we also show that CAR enhances\ninterpretability of attention weights by accentuating node-neighbor relations\nthat point to causal hypotheses. For social media network-sized graphs, a\nCAR-guided graph rewiring approach could allow us to combine the scalability of\ngraph convolutional methods with the higher performance of graph attention.",
    "descriptor": "",
    "authors": [
      "Alexander P. Wu",
      "Thomas Markovich",
      "Bonnie Berger",
      "Nils Hammerla",
      "Rohit Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10946"
  },
  {
    "id": "arXiv:2210.10947",
    "title": "Does Decentralized Learning with Non-IID Unlabeled Data Benefit from  Self Supervision?",
    "abstract": "Decentralized learning has been advocated and widely deployed to make\nefficient use of distributed datasets, with an extensive focus on supervised\nlearning (SL) problems. Unfortunately, the majority of real-world data are\nunlabeled and can be highly heterogeneous across sources. In this work, we\ncarefully study decentralized learning with unlabeled data through the lens of\nself-supervised learning (SSL), specifically contrastive visual representation\nlearning. We study the effectiveness of a range of contrastive learning\nalgorithms under decentralized learning settings, on relatively large-scale\ndatasets including ImageNet-100, MS-COCO, and a new real-world robotic\nwarehouse dataset. Our experiments show that the decentralized SSL (Dec-SSL)\napproach is robust to the heterogeneity of decentralized datasets, and learns\nuseful representation for object classification, detection, and segmentation\ntasks. This robustness makes it possible to significantly reduce communication\nand reduce the participation ratio of data sources with only minimal drops in\nperformance. Interestingly, using the same amount of data, the representation\nlearned by Dec-SSL can not only perform on par with that learned by centralized\nSSL which requires communication and excessive data storage costs, but also\nsometimes outperform representations extracted from decentralized SL which\nrequires extra knowledge about the data labels. Finally, we provide theoretical\ninsights into understanding why data heterogeneity is less of a concern for\nDec-SSL objectives, and introduce feature alignment and clustering techniques\nto develop a new Dec-SSL algorithm that further improves the performance, in\nthe face of highly non-IID data. Our study presents positive evidence to\nembrace unlabeled data in decentralized learning, and we hope to provide new\ninsights into whether and why decentralized SSL is effective.",
    "descriptor": "",
    "authors": [
      "Lirui Wang",
      "Kaiqing Zhang",
      "Yunzhu Li",
      "Yonglong Tian",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10947"
  },
  {
    "id": "arXiv:2210.10951",
    "title": "Automatic Document Selection for Efficient Encoder Pretraining",
    "abstract": "Building pretrained language models is considered expensive and\ndata-intensive, but must we increase dataset size to achieve better\nperformance? We propose an alternative to larger training sets by automatically\nidentifying smaller yet domain-representative subsets. We extend Cynical Data\nSelection, a statistical sentence scoring method that conditions on a\nrepresentative target domain corpus. As an example, we treat the OntoNotes\ncorpus as a target domain and pretrain a RoBERTa-like encoder from a cynically\nselected subset of the Pile. On both perplexity and across several downstream\ntasks in the target domain, it consistently outperforms random selection with\n20x less data, 3x fewer training iterations, and 2x less estimated cloud\ncompute cost, validating the recipe of automatic document selection for LM\npretraining.",
    "descriptor": "",
    "authors": [
      "Yukun Feng",
      "Patrick Xia",
      "Benjamin Van Durme",
      "Jo\u00e3o Sedoc"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10951"
  },
  {
    "id": "arXiv:2210.10953",
    "title": "Discovering Many Diverse Solutions with Bayesian Optimization",
    "abstract": "Bayesian optimization (BO) is a popular approach for sample-efficient\noptimization of black-box objective functions. While BO has been successfully\napplied to a wide range of scientific applications, traditional approaches to\nsingle-objective BO only seek to find a single best solution. This can be a\nsignificant limitation in situations where solutions may later turn out to be\nintractable. For example, a designed molecule may turn out to violate\nconstraints that can only be reasonably evaluated after the optimization\nprocess has concluded. To address this issue, we propose Rank-Ordered Bayesian\nOptimization with Trust-regions (ROBOT) which aims to find a portfolio of\nhigh-performing solutions that are diverse according to a user-specified\ndiversity metric. We evaluate ROBOT on several real-world applications and show\nthat it can discover large sets of high-performing diverse solutions while\nrequiring few additional function evaluations compared to finding a single best\nsolution.",
    "descriptor": "",
    "authors": [
      "Natalie Maus",
      "Kaiwen Wu",
      "David Eriksson",
      "Jacob Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10953"
  },
  {
    "id": "arXiv:2210.10956",
    "title": "Non-Iterative Scribble-Supervised Learning with Pacing Pseudo-Masks for  Medical Image Segmentation",
    "abstract": "Scribble-supervised medical image segmentation tackles the limitation of\nsparse masks. Conventional approaches alternate between: labeling pseudo-masks\nand optimizing network parameters. However, such iterative two-stage paradigm\nis unwieldy and could be trapped in poor local optima since the networks\nundesirably regress to the erroneous pseudo-masks. To address these issues, we\npropose a non-iterative method where a stream of varying (pacing) pseudo-masks\nteach a network via consistency training, named PacingPseudo. Our motivation\nlies first in a non-iterative process. Interestingly, it can be achieved\ngracefully by a siamese architecture, wherein a stream of pseudo-masks\nnaturally assimilate a stream of predicted masks during training. Second, we\nmake the consistency training effective with two necessary designs: (i) entropy\nregularization to obtain high-confidence pseudo-masks for effective teaching;\nand (ii) distorted augmentations to create discrepancy between the pseudo-mask\nand predicted-mask streams for consistency regularization. Third, we devise a\nnew memory bank mechanism that provides an extra source of ensemble features to\ncomplement scarce labeled pixels. The efficacy of the proposed PacingPseudo is\nvalidated on three public medical image datasets, including the segmentation\ntasks of abdominal multi-organs, cardiac structures, and myocardium. Extensive\nexperiments demonstrate our PacingPseudo improves the baseline by large margins\nand consistently outcompetes several previous methods. In some cases, our\nPacingPseudo achieves comparable performance with its fully-supervised\ncounterparts, showing the feasibility of our method for the challenging\nscribble-supervised segmentation applications. The code and scribble\nannotations will be publicly available.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Zefan Yang",
      "Di Lin",
      "Dong Ni",
      "Yi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10956"
  },
  {
    "id": "arXiv:2210.10957",
    "title": "3D Human Mesh Construction Leveraging Wi-Fi",
    "abstract": "In this paper, we present, Wi-Mesh, a WiFi vision-based 3D human mesh\nconstruction system. Our system leverages the advances of WiFi to visualize the\nshape and deformations of the human body for 3D mesh construction. In\nparticular, it leverages multiple transmitting and receiving antennas on WiFi\ndevices to estimate the two-dimensional angle of arrival (2D AoA) of the WiFi\nsignal reflections to enable WiFi devices to see the physical environment as we\nhumans do. It then extracts only the images of the human body from the physical\nenvironment and leverages deep learning models to digitize the extracted human\nbody into a 3D mesh representation. Experimental evaluation under various\nindoor environments shows that Wi-Mesh achieves an average vertices location\nerror of 2.81cm and joint position error of 2.4cm, which is comparable to the\nsystems that utilize specialized and dedicated hardware. The proposed system\nhas the advantage of re-using the WiFi devices that already exist in the\nenvironment for potential mass adoption. It can also work in non-line of sight\n(NLoS), poor lighting conditions, and baggy clothes, where the camera-based\nsystems do not work well.",
    "descriptor": "\nComments: SenSys 2022\n",
    "authors": [
      "Yichao Wang",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10957"
  },
  {
    "id": "arXiv:2210.10958",
    "title": "Federated Unlearning for On-Device Recommendation",
    "abstract": "The increasing data privacy concerns in recommendation systems have made\nfederated recommendations (FedRecs) attract more and more attention. Existing\nFedRecs mainly focus on how to effectively and securely learn personal\ninterests and preferences from their on-device interaction data. Still, none of\nthem considers how to efficiently erase a user's contribution to the federated\ntraining process. We argue that such a dual setting is necessary. First, from\nthe privacy protection perspective, ``the right to be forgotten'' requires that\nusers have the right to withdraw their data contributions. Without the\nreversible ability, FedRecs risk breaking data protection regulations. On the\nother hand, enabling a FedRec to forget specific users can improve its\nrobustness and resistance to malicious clients' attacks. To support user\nunlearning in FedRecs, we propose an efficient unlearning method FRU (Federated\nRecommendation Unlearning), inspired by the log-based rollback mechanism of\ntransactions in database management systems. It removes a user's contribution\nby rolling back and calibrating the historical parameter updates and then uses\nthese updates to speed up federated recommender reconstruction. However,\nstoring all historical parameter updates on resource-constrained personal\ndevices is challenging and even infeasible. In light of this challenge, we\npropose a small-sized negative sampling method to reduce the number of item\nembedding updates and an importance-based update selection mechanism to store\nonly important model updates. To evaluate the effectiveness of FRU, we propose\nan attack method to disturb FedRecs via a group of compromised users and use\nFRU to recover recommenders by eliminating these users' influence. Finally, we\nconduct experiments on two real-world recommendation datasets with two widely\nused FedRecs to show the efficiency and effectiveness of our proposed\napproaches.",
    "descriptor": "",
    "authors": [
      "Wei Yuan",
      "Hongzhi Yin",
      "Fangzhao Wu",
      "Shijie Zhang",
      "Tieke He",
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10958"
  },
  {
    "id": "arXiv:2210.10959",
    "title": "Uni6Dv3: 5D Anchor Mechanism for 6D Pose Estimation",
    "abstract": "Unlike indirect methods that usually require time-consuming post-processing,\nrecent deep learning-based direct methods for 6D pose estimation try to predict\nthe 3D rotation and 3D translation from RGB-D data directly. However, direct\nmethods, regressing the absolute translation of the pose, suffer from diverse\nobject translation distribution between training and test data, which is\nusually caused by expensive data collection and annotation in practice. To this\nend, we propose a 5D anchor mechanism by defining the anchor with 3D\ncoordinates in the physical space and 2D coordinates in the image plane.\nInspired by anchor-based object detection methods, 5D anchor regresses the\noffset between the target and anchor, which eliminates the distribution gap and\ntransforms the regression target to a small range. But regressing offset leads\nto the mismatch between the absolute input and relative output. We build an\nanchor-based projection model by replacing the absolute input with the relative\none, which further improves the performance. By plugging 5D anchor into the\nlatest direct methods, Uni6Dv2 and ES6D obtain 38.7% and 3.5% improvement,\nrespectively. Specifically, Uni6Dv2+5D anchor, dubbed Uni6Dv3, achieves\nstate-of-the-art overall results on datasets including Occlusion LineMOD\n(79.3%), LineMOD (99.5%), and YCB-Video datasets (91.5%), and requires only 10%\nof training data to reach comparable performance as full data.",
    "descriptor": "",
    "authors": [
      "Jianqiu Chen",
      "Mingshan Sun",
      "Ye Zheng",
      "Tianpeng Bao",
      "Zhenyu He",
      "Donghai Li",
      "Guoqiang Jin",
      "Rui Zhao",
      "Liwei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10959"
  },
  {
    "id": "arXiv:2210.10960",
    "title": "Diffusion Models already have a Semantic Latent Space",
    "abstract": "Diffusion models achieve outstanding generative performance in various\ndomains. Despite their great success, they lack semantic latent space which is\nessential for controlling the generative process. To address the problem, we\npropose asymmetric reverse process (Asyrp) which discovers the semantic latent\nspace in frozen pretrained diffusion models. Our semantic latent space, named\nh-space, has nice properties for accommodating semantic image manipulation:\nhomogeneity, linearity, robustness, and consistency across timesteps. In\naddition, we introduce a principled design of the generative process for\nversatile editing and quality boost ing by quantifiable measures: editing\nstrength of an interval and quality deficiency at a timestep. Our method is\napplicable to various architectures (DDPM++, iD- DPM, and ADM) and datasets\n(CelebA-HQ, AFHQ-dog, LSUN-church, LSUN- bedroom, and METFACES). Project page:\nhttps://kwonminki.github.io/Asyrp/",
    "descriptor": "",
    "authors": [
      "Mingi Kwon",
      "Jaeseok Jeong",
      "Youngjung Uh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10960"
  },
  {
    "id": "arXiv:2210.10963",
    "title": "UAV-Assisted Multi-Cluster Over-the-Air Computation",
    "abstract": "In this paper, we study unmanned aerial vehicles (UAVs) assisted wireless\ndata aggregation (WDA) in multicluster networks, where multiple UAVs\nsimultaneously perform different WDA tasks via over-the-air computation\n(AirComp) without terrestrial base stations. This work focuses on maximizing\nthe minimum amount of WDA tasks performed among all clusters by optimizing the\nUAV's trajectory and transceiver design as well as cluster scheduling and\nassociation, while considering the WDA accuracy requirement. Such a joint\ndesign is critical for interference management in multi-cluster AirComp\nnetworks, via enhancing the signal quality between each UAV and its associated\ncluster for signal alignment and meanwhile reducing the inter-cluster\ninterference between each UAV and its nonassociated clusters. Although it is\ngenerally challenging to optimally solve the formulated non-convex\nmixed-integer nonlinear programming, an efficient iterative algorithm as a\ncompromise approach is developed by exploiting bisection and block coordinate\ndescent methods, yielding an optimal transceiver solution in each iteration.\nThe optimal binary variables and a suboptimal trajectory are obtained by using\nthe dual method and successive convex approximation, respectively. Simulations\nshow the considerable performance gains of the proposed design over benchmarks\nand the superiority of deploying multiple UAVs in increasing the number of\nperformed tasks while reducing access delays.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Min Fu",
      "Yong Zhou",
      "Yuanming Shi",
      "Chunxiao Jiang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.10963"
  },
  {
    "id": "arXiv:2210.10964",
    "title": "Uncertainty Disentanglement with Non-stationary Heteroscedastic Gaussian  Processes for Active Learning",
    "abstract": "Gaussian processes are Bayesian non-parametric models used in many areas. In\nthis work, we propose a Non-stationary Heteroscedastic Gaussian process model\nwhich can be learned with gradient-based techniques. We demonstrate the\ninterpretability of the proposed model by separating the overall uncertainty\ninto aleatoric (irreducible) and epistemic (model) uncertainty. We illustrate\nthe usability of derived epistemic uncertainty on active learning problems. We\ndemonstrate the efficacy of our model with various ablations on multiple\ndatasets.",
    "descriptor": "\nComments: Accepted at NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems, 2023\n",
    "authors": [
      "Zeel B Patel",
      "Nipun Batra",
      "Kevin Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10964"
  },
  {
    "id": "arXiv:2210.10965",
    "title": "IDM-Follower: A Model-Informed Deep Learning Method for Long-Sequence  Car-Following Trajectory Prediction",
    "abstract": "Model-based and learning-based methods are two major types of methodologies\nto model car following behaviors. Model-based methods describe the\ncar-following behaviors with explicit mathematical equations, while\nlearning-based methods focus on getting a mapping between inputs and outputs.\nBoth types of methods have advantages and weaknesses. Meanwhile, most\ncar-following models are generative and only consider the inputs of the speed,\nposition, and acceleration of the last time step. To address these issues, this\nstudy proposes a novel framework called IDM-Follower that can generate a\nsequence of following vehicle trajectory by a recurrent autoencoder informed by\na physical car-following model, the Intelligent Driving Model (IDM).We\nimplement a novel structure with two independent encoders and a self-attention\ndecoder that could sequentially predict the following trajectories. A loss\nfunction considering the discrepancies between predictions and labeled data\nintegrated with discrepancies from model-based predictions is implemented to\nupdate the neural network parameters. Numerical experiments with multiple\nsettings on simulation and NGSIM datasets show that the IDM-Follower can\nimprove the prediction performance compared to the model-based or\nlearning-based methods alone. Analysis on different noise levels also shows\ngood robustness of the model.",
    "descriptor": "",
    "authors": [
      "Yilin Wang",
      "Yiheng Feng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10965"
  },
  {
    "id": "arXiv:2210.10968",
    "title": "Identities and periodic oscillations of divide-and-conquer recurrences  splitting at half",
    "abstract": "We study divide-and-conquer recurrences of the form \\begin{equation*}\nf(n)\n= \\alpha f(\\lfloor \\tfrac n2\\rfloor)\n+ \\beta f(\\lceil \\tfrac n2\\rceil)\n+ g(n) \\qquad(n\\ge2), \\end{equation*} with $g(n)$ and $f(1)$ given, where\n$\\alpha,\\beta\\ge0$ with $\\alpha+\\beta>0$; such recurrences appear often in\nanalysis of computer algorithms, numeration systems, combinatorial sequences,\nand related areas. We show that the solution satisfies always the simple\n\\emph{identity} \\begin{equation*}\nf(n)\n= n^{\\log_2(\\alpha+\\beta)} P(\\log_2n) - Q(n) \\end{equation*} under an optimum\n(iff) condition on $g(n)$. This form is not only an identity but also an\nasymptotic expansion because $Q(n)$ is of a smaller order. Explicit forms for\nthe \\emph{continuity} of the periodic function $P$ are provided, together with\na few other smoothness properties. We show how our results can be easily\napplied to many dozens of concrete examples collected from the literature, and\nhow they can be extended in various directions. Our method of proof is\nsurprisingly simple and elementary, but leads to the strongest types of results\nfor all examples to which our theory applies.",
    "descriptor": "\nComments: 69 pages, 13 figures, 13 tables\n",
    "authors": [
      "Hsien-Kuei Hwang",
      "Svante Janson",
      "Tsung-Hsi Tsai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.10968"
  },
  {
    "id": "arXiv:2210.10969",
    "title": "SSiT: Saliency-guided Self-supervised Image Transformer for Diabetic  Retinopathy Grading",
    "abstract": "Self-supervised learning (SSL) has been widely applied to learn image\nrepresentations through exploiting unlabeled images. However, it has not been\nfully explored in the medical image analysis field. In this work, we propose\nSaliency-guided Self-Supervised image Transformer (SSiT) for diabetic\nretinopathy (DR) grading from fundus images. We novelly introduce saliency maps\ninto SSL, with a goal of guiding self-supervised pre-training with\ndomain-specific prior knowledge. Specifically, two saliency-guided learning\ntasks are employed in SSiT: (1) We conduct saliency-guided contrastive learning\nbased on the momentum contrast, wherein we utilize fundus images' saliency maps\nto remove trivial patches from the input sequences of the momentum-updated key\nencoder. And thus, the key encoder is constrained to provide target\nrepresentations focusing on salient regions, guiding the query encoder to\ncapture salient features. (2) We train the query encoder to predict the\nsaliency segmentation, encouraging preservation of fine-grained information in\nthe learned representations. Extensive experiments are conducted on four\npublicly-accessible fundus image datasets. The proposed SSiT significantly\noutperforms other representative state-of-the-art SSL methods on all datasets\nand under various evaluation settings, establishing the effectiveness of the\nlearned representations from SSiT. The source code is available at\nhttps://github.com/YijinHuang/SSiT.",
    "descriptor": "",
    "authors": [
      "Yijin Huang",
      "Junyan Lyu",
      "Pujin Cheng",
      "Roger Tam",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10969"
  },
  {
    "id": "arXiv:2210.10972",
    "title": "A Multimodal Sensor Fusion Framework Robust to Missing Modalities for  Person Recognition",
    "abstract": "Utilizing the sensor characteristics of the audio, visible camera, and\nthermal camera, the robustness of person recognition can be enhanced. Existing\nmultimodal person recognition frameworks are primarily formulated assuming that\nmultimodal data is always available. In this paper, we propose a novel trimodal\nsensor fusion framework using the audio, visible, and thermal camera, which\naddresses the missing modality problem. In the framework, a novel deep latent\nembedding framework, termed the AVTNet, is proposed to learn multiple latent\nembeddings. Also, a novel loss function, termed missing modality loss, accounts\nfor possible missing modalities based on the triplet loss calculation while\nlearning the individual latent embeddings. Additionally, a joint latent\nembedding utilizing the trimodal data is learnt using the multi-head attention\ntransformer, which assigns attention weights to the different modalities. The\ndifferent latent embeddings are subsequently used to train a deep neural\nnetwork. The proposed framework is validated on the Speaking Faces dataset. A\ncomparative analysis with baseline algorithms shows that the proposed framework\nsignificantly increases the person recognition accuracy while accounting for\nmissing modalities.",
    "descriptor": "\nComments: Accepted for ACM MM Asia, 2022\n",
    "authors": [
      "Vijay John",
      "Yasutomo Kawanishi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10972"
  },
  {
    "id": "arXiv:2210.10973",
    "title": "Scalable Bayesian Transformed Gaussian Processes",
    "abstract": "The Bayesian transformed Gaussian process (BTG) model, proposed by Kedem and\nOliviera, is a fully Bayesian counterpart to the warped Gaussian process (WGP)\nand marginalizes out a joint prior over input warping and kernel\nhyperparameters. This fully Bayesian treatment of hyperparameters often\nprovides more accurate regression estimates and superior uncertainty\npropagation, but is prohibitively expensive. The BTG posterior predictive\ndistribution, itself estimated through high-dimensional integration, must be\ninverted in order to perform model prediction. To make the Bayesian approach\npractical and comparable in speed to maximum-likelihood estimation (MLE), we\npropose principled and fast techniques for computing with BTG. Our framework\nuses doubly sparse quadrature rules, tight quantile bounds, and rank-one matrix\nalgebra to enable both fast model prediction and model selection. These\nscalable methods allow us to regress over higher-dimensional datasets and apply\nBTG with layered transformations that greatly improve its expressibility. We\ndemonstrate that BTG achieves superior empirical performance over MLE-based\nmodels.",
    "descriptor": "",
    "authors": [
      "Xinran Zhu",
      "Leo Huang",
      "Cameron Ibrahim",
      "Eric Hans Lee",
      "David Bindel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10973"
  },
  {
    "id": "arXiv:2210.10975",
    "title": "Improving Segmentation of Breast Ultrasound Images: Semi Automatic Two  Pointers Histogram Splitting Technique",
    "abstract": "Automatically segmenting lesion area in breast ultrasound (BUS) images is a\nchallenging one due to its noise, speckle and artifacts. Edge-map of BUS images\nalso does not help because in most cases the edge-map gives no information\nwhatsoever. Almost all segmentation technique takes the edge-map of the image\nas its first step, though there are a few algorithms that try to avoid\nedge-maps as well. Improving the edge-map of breast ultrasound images\ntheoretically improves the chances of automatic segmentation to be more\nprecise. In this paper, we propose a semi-automatic technique of histogram\nsplitting using two pointers. Here the user only has to select two initially\nguessed points denoting a circle on the region of interest (ROI). The method\nwill automatically study the internal histogram and split it using two\npointers. The output BUS image has improved edge-map and ultimately the\nsegmentation on it is better compared to regular segmentation using same\nalgorithm and same initialization. Also, we further processed the edge-map to\nhave less edge-pixels to area ratio, improving the homogeneity and the chances\nof easy segmentation in the future.",
    "descriptor": "",
    "authors": [
      "Rasheed Abid",
      "S. Kaisar Alam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10975"
  },
  {
    "id": "arXiv:2210.10978",
    "title": "A Comprehensive Survey on Edge Data Integrity Verification: Fundamentals  and Future Trends",
    "abstract": "Recent advances in edge computing have pushed cloud-based data caching\nservices to edge, however, such emerging edge storage comes with numerous\nchallenging and unique security issues. One of them is the problem of edge data\nintegrity verification (EDIV) which coordinates multiple participants (e.g.,\ndata owners and edge nodes) to inspect whether data cached on edge is\nauthentic. To date, various solutions have been proposed to address the EDIV\nproblem, while there is no systematic review. Thus, we offer a comprehensive\nsurvey for the first time, aiming to show current research status, open\nproblems, and potentially promising insights for readers to further investigate\nthis under-explored field. Specifically, we begin with stating the significance\nof the EDIV problem, the integrity verification difference between data cached\non cloud and edge, and three typical system models with corresponding\ninspection processes. Then, we synthesize a universal criteria framework that\nan effective verification approach should satisfy. Subsequently, we adopt a\nschematic development timeline to reveal the research advance on EDIV in a\nsequential manner, followed by a detailed review on the existing EDIV\nsolutions. Finally, we highlight intriguing research challenges and possible\ndirections for future research.",
    "descriptor": "",
    "authors": [
      "Yao Zhao",
      "Youyang Qu",
      "Yong Xiang",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10978"
  },
  {
    "id": "arXiv:2210.10981",
    "title": "MGTUNet: An new UNet for colon nuclei instance segmentation and  quantification",
    "abstract": "Colorectal cancer (CRC) is among the top three malignant tumor types in terms\nof morbidity and mortality. Histopathological images are the gold standard for\ndiagnosing colon cancer. Cellular nuclei instance segmentation and\nclassification, and nuclear component regression tasks can aid in the analysis\nof the tumor microenvironment in colon tissue. Traditional methods are still\nunable to handle both types of tasks end-to-end at the same time, and have poor\nprediction accuracy and high application costs. This paper proposes a new UNet\nmodel for handling nuclei based on the UNet framework, called MGTUNet, which\nuses Mish, Group normalization and transposed convolution layer to improve the\nsegmentation model, and a ranger optimizer to adjust the SmoothL1Loss values.\nSecondly, it uses different channels to segment and classify different types of\nnucleus, ultimately completing the nuclei instance segmentation and\nclassification task, and the nuclei component regression task simultaneously.\nFinally, we did extensive comparison experiments using eight segmentation\nmodels. By comparing the three evaluation metrics and the parameter sizes of\nthe models, MGTUNet obtained 0.6254 on PQ, 0.6359 on mPQ, and 0.8695 on R2.\nThus, the experiments demonstrated that MGTUNet is now a state-of-the-art\nmethod for quantifying histopathological images of colon cancer.",
    "descriptor": "\nComments: Accepted in BIBM2022(regular paper)\n",
    "authors": [
      "Liangrui Pan",
      "Lian Wang",
      "Mingting Liu",
      "Zhujun Xu",
      "Liwen Xu",
      "Shaoliang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.10981"
  },
  {
    "id": "arXiv:2210.10982",
    "title": "A generalized expansion method for computing Laplace-Beltrami  eigenfunctions on manifolds",
    "abstract": "Eigendecomposition of the Laplace-Beltrami operator is instrumental for a\nvariety of applications from physics to data science. We develop a numerical\nmethod of computation of the eigenvalues and eigenfunctions of the\nLaplace-Beltrami operator on a smooth bounded domain based on the relaxation to\nthe Schr\\\"odinger operator with finite potential on a Riemannian manifold and\nprojection in a special basis. We prove spectral exactness of the method and\nprovide examples of calculated results and applications, particularly, in\nquantum billiards on manifolds.",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Jackson C. Turner",
      "Elena Cherkaev",
      "Dong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10982"
  },
  {
    "id": "arXiv:2210.10983",
    "title": "PSA-Det3D: Pillar Set Abstraction for 3D object Detection",
    "abstract": "Small object detection for 3D point cloud is a challenging problem because of\ntwo limitations: (1) Perceiving small objects is much more diffcult than normal\nobjects due to the lack of valid points. (2) Small objects are easily blocked\nwhich breaks the shape of their meshes in 3D point cloud. In this paper, we\npropose a pillar set abstraction (PSA) and foreground point compensation (FPC)\nand design a point-based detection network, PSA-Det3D, to improve the detection\nperformance for small object. The PSA embeds a pillar query operation on the\nbasis of set abstraction (SA) to expand its receptive field of the network,\nwhich can aggregate point-wise features effectively. To locate more occluded\nobjects, we persent a proposal generation layer consisting of a foreground\npoint segmentation and a FPC module. Both the foreground points and the\nestimated centers are finally fused together to generate the detection result.\nThe experiments on the KITTI 3D detection benchmark show that our proposed\nPSA-Det3D outperforms other algorithms with high accuracy for small object\ndetection.",
    "descriptor": "",
    "authors": [
      "Zhicong Huang",
      "Jingwen Zhao",
      "Zhijie Zheng",
      "Dihu Chena",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10983"
  },
  {
    "id": "arXiv:2210.10984",
    "title": "RAIS: Robust and Accurate Interactive Segmentation via Continual  Learning",
    "abstract": "Interactive image segmentation aims at segmenting a target region through a\nway of human-computer interaction. Recent works based on deep learning have\nachieved excellent performance, while most of them focus on improving the\naccuracy of the training set and ignore potential improvement on the test set.\nIn the inference phase, they tend to have a good performance on similar domains\nto the training set, and lack adaptability to domain shift, so they require\nmore user efforts to obtain satisfactory results. In this work, we propose\nRAIS, a robust and accurate architecture for interactive segmentation with\ncontinuous learning, where the model can learn from both train and test data\nsets. For efficient learning on the test set, we propose a novel optimization\nstrategy to update global and local parameters with a basic segmentation module\nand adaptation module, respectively. Moreover, we perform extensive experiments\non several benchmarks that show our method can handle data distribution shifts\nand achieves SOTA performance compared with recent interactive segmentation\nmethods. Besides, our method also shows its robustness in the datasets of\nremote sensing and medical imaging where the data domains are completely\ndifferent between training and testing.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yuying Hao",
      "Yi Liu",
      "Juncai Peng",
      "Haoyi Xiong",
      "Guowei Chen",
      "Shiyu Tang",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10984"
  },
  {
    "id": "arXiv:2210.10985",
    "title": "Large-scale learning of generalised representations for speaker  recognition",
    "abstract": "The objective of this work is to develop a speaker recognition model to be\nused in diverse scenarios. We hypothesise that two components should be\nadequately configured to build such a model. First, adequate architecture would\nbe required. We explore several recent state-of-the-art models, including\nECAPA-TDNN and MFA-Conformer, as well as other baselines. Second, a massive\namount of data would be required. We investigate several new training data\nconfigurations combining a few existing datasets. The most extensive\nconfiguration includes over 87k speakers' 10.22k hours of speech. Four\nevaluation protocols are adopted to measure how the trained model performs in\ndiverse scenarios. Through experiments, we find that MFA-Conformer with the\nleast inductive bias generalises the best. We also show that training with\nproposed large data configurations gives better performance. A boost in\ngeneralisation is observed, where the average performance on four evaluation\nprotocols improves by more than 20%. In addition, we also demonstrate that\nthese models' performances can improve even further when increasing capacity.",
    "descriptor": "\nComments: 5pages, 5 tables, submitted to ICASSP\n",
    "authors": [
      "Jee-weon Jung",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "Jaesong Lee",
      "Hye-jin Shim",
      "Youngki Kwon",
      "Joon Son Chung",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10985"
  },
  {
    "id": "arXiv:2210.10990",
    "title": "Convergence Analysis of Discrete Conformal Transformation",
    "abstract": "Continuous conformal transformation minimizes the conformal energy. The\nconvergence of minimizing discrete conformal energy when the discrete mesh size\ntends to zero is an open problem. This paper addresses this problem via a\ncareful error analysis of the discrete conformal energy. Under a weak condition\non triangulation, the discrete function minimizing the discrete conformal\nenergy converges to the continuous conformal mapping as the mesh size tends to\nzero.",
    "descriptor": "",
    "authors": [
      "Zhenyue Zhang",
      "Zhong-Heng Tan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.10990"
  },
  {
    "id": "arXiv:2210.10992",
    "title": "NIFT: Neural Interaction Field and Template for Object Manipulation",
    "abstract": "We introduce NIFT, Neural Interaction Field and Template, a descriptive and\nrobust interaction representation of object manipulations to facilitate\nimitation learning. Given a few object manipulation demos, NIFT guides the\ngeneration of the interaction imitation for a new object instance by matching\nthe Neural Interaction Template (NIT) extracted from the demos to the Neural\nInteraction Field (NIF) defined for the new object. Specifically, the NIF is a\nneural field which encodes the relationship between each spatial point and a\ngiven object, where the relative position is defined by a spherical distance\nfunction rather than occupancies or signed distances, which are commonly\nadopted by conventional neural fields but less informative. For a given demo\ninteraction, the corresponding NIT is defined by a set of spatial points\nsampled in the NIF of the demo object with associated neural features. To\nbetter capture the interaction, the points are sampled on the interaction\nbisector surface, which consists of points that are equidistant to two\ninteracting objects and has been used extensively for interaction\nrepresentation. With both point selection and pointwise features defined for\nbetter interaction encoding, NIT effectively guides the feature matching in the\nNIFs of the new object instances to optimize the object poses to realize the\nmanipulation while imitating the demo interactions. Experiments show that our\nNIFT solution outperforms state-of-the-art imitation learning methods for\nobject manipulation and generalizes better to objects from new categories.",
    "descriptor": "",
    "authors": [
      "Zeyu Huang",
      "Juzhan Xu",
      "Sisi Dai",
      "Kai Xu",
      "Hao Zhang",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.10992"
  },
  {
    "id": "arXiv:2210.10993",
    "title": "A Magnetic Framelet-Based Convolutional Neural Network for Directed  Graphs",
    "abstract": "Spectral Graph Convolutional Networks (spectral GCNNs), a powerful tool for\nanalyzing and processing graph data, typically apply frequency filtering via\nFourier transform to obtain representations with selective information.\nAlthough research shows that spectral GCNNs can be enhanced by framelet-based\nfiltering, the massive majority of such research only considers undirected\ngraphs. In this paper, we introduce Framelet-MagNet, a magnetic framelet-based\nspectral GCNN for directed graphs (digraphs). The model applies the framelet\ntransform to digraph signals to form a more sophisticated representation for\nfiltering. Digraph framelets are constructed with the complex-valued magnetic\nLaplacian, simultaneously leading to signal processing in both real and complex\ndomains. We empirically validate the predictive power of Framelet-MagNet over a\nrange of state-of-the-art models in node classification, link prediction, and\ndenoising.",
    "descriptor": "",
    "authors": [
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10993"
  },
  {
    "id": "arXiv:2210.10994",
    "title": "MBTI Personality Prediction for Fictional Characters Using Movie Scripts",
    "abstract": "An NLP model that understands stories should be able to understand the\ncharacters in them. To support the development of neural models for this\npurpose, we construct a benchmark, Story2Personality. The task is to predict a\nmovie character's MBTI or Big 5 personality types based on the narratives of\nthe character. Experiments show that our task is challenging for the existing\ntext classification models, as none is able to largely outperform random\nguesses. We further proposed a multi-view model for personality prediction\nusing both verbal and non-verbal descriptions, which gives improvement compared\nto using only verbal descriptions. The uniqueness and challenges in our dataset\ncall for the development of narrative comprehension techniques from the\nperspective of understanding characters.",
    "descriptor": "\nComments: paper accepted to EMNLP 2022\n",
    "authors": [
      "Yisi Sang",
      "Xiangyang Mou",
      "Mo Yu",
      "Dakuo Wang",
      "Jing Li",
      "Jeffrey Stanton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10994"
  },
  {
    "id": "arXiv:2210.10995",
    "title": "Reference Governor for Input-Constrained MPC to Enforce State  Constraints at Lower Computational Cost",
    "abstract": "In this paper, a control scheme is developed based on an input constrained\nModel Predictive Controller (MPC) and the idea of modifying the reference\ncommand to enforce constraints, usual of Reference Governors (RG). The proposed\nscheme, referred to as the RGMPC, requires optimization for MPC with input\nconstraints for which fast algorithms exist, and can handle (possibly\nnonlinear) state and input constraints. Conditions are given that ensure\nrecursive feasibility of the RGMPC scheme and finite-time convergence of the\nmodified command to the the desired reference command. Simulation results for a\nspacecraft rendezvous maneuver with linear and nonlinear constraints\ndemonstrate that the RGMPC scheme has lower average computational time as\ncompared to state and input constrained MPC with similar performance.",
    "descriptor": "",
    "authors": [
      "Miguel Castroviejo Fernandez",
      "Jordan Leung",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10995"
  },
  {
    "id": "arXiv:2210.10996",
    "title": "Improving Chinese Spelling Check by Character Pronunciation Prediction:  The Effects of Adaptivity and Granularity",
    "abstract": "Chinese spelling check (CSC) is a fundamental NLP task that detects and\ncorrects spelling errors in Chinese texts. As most of these spelling errors are\ncaused by phonetic similarity, effectively modeling the pronunciation of\nChinese characters is a key factor for CSC. In this paper, we consider\nintroducing an auxiliary task of Chinese pronunciation prediction (CPP) to\nimprove CSC, and, for the first time, systematically discuss the adaptivity and\ngranularity of this auxiliary task. We propose SCOPE which builds on top of a\nshared encoder two parallel decoders, one for the primary CSC task and the\nother for a fine-grained auxiliary CPP task, with a novel adaptive weighting\nscheme to balance the two tasks. In addition, we design a delicate iterative\ncorrection strategy for further improvements during inference. Empirical\nevaluation shows that SCOPE achieves new state-of-the-art on three CSC\nbenchmarks, demonstrating the effectiveness and superiority of the auxiliary\nCPP task. Comprehensive ablation studies further verify the positive effects of\nadaptivity and granularity of the task. Code and data used in this paper are\npublicly available at https://github.com/jiahaozhenbang/SCOPE.",
    "descriptor": "\nComments: To appear at the main conference of EMNLP 2022\n",
    "authors": [
      "Jiahao Li",
      "Quan Wang",
      "Zhendong Mao",
      "Junbo Guo",
      "Yanyan Yang",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10996"
  },
  {
    "id": "arXiv:2210.10997",
    "title": "Demystifying Hidden Sensitive Operations in Android apps",
    "abstract": "Security of Android devices is now paramount, given their wide adoption among\nconsumers. As researchers develop tools for statically or dynamically detecting\nsuspicious apps, malware writers regularly update their attack mechanisms to\nhide malicious behavior implementation. This poses two problems to current\nresearch techniques: static analysis approaches, given their\nover-approximations, can report an overwhelming number of false alarms, while\ndynamic approaches will miss those behaviors that are hidden through evasion\ntechniques. We propose in this work a static approach specifically targeted at\nhighlighting hidden sensitive operations, mainly sensitive data flows. The\nprototype version of HiSenDroid has been evaluated on a large-scale dataset of\nthousands of malware and goodware samples on which it successfully revealed\nanti-analysis code snippets aiming at evading detection by dynamic analysis. We\nfurther experimentally show that, with FlowDroid, some of the hidden sensitive\nbehaviors would eventually lead to private data leaks. Those leaks would have\nbeen hard to spot either manually among the large number of false positives\nreported by the state of the art static analyzers, or by dynamic tools.\nOverall, by putting the light on hidden sensitive operations, HiSenDroid helps\nsecurity analysts in validating potential sensitive data operations, which\nwould be previously unnoticed.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Sun",
      "Xiao Chen",
      "Li Li",
      "Haipeng Cai",
      "John Grundy",
      "Jordan Samhi",
      "Tegawend\u00e9 F. Bissyand\u00e9",
      "Jacques Klein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.10997"
  },
  {
    "id": "arXiv:2210.10999",
    "title": "Task Phasing: Automated Curriculum Learning from Demonstrations",
    "abstract": "Applying reinforcement learning (RL) to sparse reward domains is notoriously\nchallenging due to insufficient guiding signals. Common techniques for\naddressing such domains include (1) learning from demonstrations and (2)\ncurriculum learning. While these two approaches have been studied in detail,\nthey have rarely been considered together. This paper aims to do so by\nintroducing a principled task phasing approach that uses demonstrations to\nautomatically generate a curriculum sequence. Using inverse RL from\n(suboptimal) demonstrations we define a simple initial task. Our task phasing\napproach then provides a framework to gradually increase the complexity of the\ntask all the way to the target task, while retuning the RL agent in each\nphasing iteration. Two approaches for phasing are considered: (1) gradually\nincreasing the proportion of time steps an RL agent is in control, and (2)\nphasing out a guiding informative reward function. We present conditions that\nguarantee the convergence of these approaches to an optimal policy.\nExperimental results on 3 sparse reward domains demonstrate that our task\nphasing approaches outperform state-of-the-art approaches with respect to their\nasymptotic performance.",
    "descriptor": "\nComments: 7 pages main paper, 7 figures, 4 pages appendix. Submitted to AAAI 2023 Conference\n",
    "authors": [
      "Vaibhav Bajaj",
      "Guni Sharon",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10999"
  },
  {
    "id": "arXiv:2210.11000",
    "title": "Visual-Semantic Contrastive Alignment for Few-Shot Image Classification",
    "abstract": "Few-Shot learning aims to train and optimize a model that can adapt to unseen\nvisual classes with only a few labeled examples. The existing few-shot learning\n(FSL) methods, heavily rely only on visual data, thus fail to capture the\nsemantic attributes to learn a more generalized version of the visual concept\nfrom very few examples. However, it is a known fact that human visual learning\nbenefits immensely from inputs from multiple modalities such as vision,\nlanguage, and audio. Inspired by the human learning nature of encapsulating the\nexisting knowledge of a visual category which is in the form of language, we\nintroduce a contrastive alignment mechanism for visual and semantic feature\nvectors to learn much more generalized visual concepts for few-shot learning.\nOur method simply adds an auxiliary contrastive learning objective which\ncaptures the contextual knowledge of a visual category from a strong textual\nencoder in addition to the existing training mechanism. Hence, the approach is\nmore generalized and can be plugged into any existing FSL method. The\npre-trained semantic feature extractor (learned from a large-scale text\ncorpora) we use in our approach provides a strong contextual prior knowledge to\nassist FSL. The experimental results done in popular FSL datasets show that our\napproach is generic in nature and provides a strong boost to the existing FSL\nbaselines.",
    "descriptor": "\nComments: ECCV 2022 Workshop on Computer Vision in the Wild\n",
    "authors": [
      "Mohamed Afham",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11000"
  },
  {
    "id": "arXiv:2210.11005",
    "title": "Pre-trained Sentence Embeddings for Implicit Discourse Relation  Classification",
    "abstract": "Implicit discourse relations bind smaller linguistic units into coherent\ntexts. Automatic sense prediction for implicit relations is hard, because it\nrequires understanding the semantics of the linked arguments. Furthermore,\nannotated datasets contain relatively few labeled examples, due to the scale of\nthe phenomenon: on average each discourse relation encompasses several dozen\nwords. In this paper, we explore the utility of pre-trained sentence embeddings\nas base representations in a neural network for implicit discourse relation\nsense classification. We present a series of experiments using both supervised\nend-to-end trained models and pre-trained sentence encoding techniques -\nSkipThought, Sent2vec and Infersent. The pre-trained embeddings are competitive\nwith the end-to-end model, and the approaches are complementary, with combined\nmodels yielding significant performance improvements on two of the three\nevaluations.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Murali Raghu Babu Balusu",
      "Yangfeng Ji",
      "Jacob Eisenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11005"
  },
  {
    "id": "arXiv:2210.11006",
    "title": "SimpleClick: Interactive Image Segmentation with Simple Vision  Transformers",
    "abstract": "Click-based interactive image segmentation aims at extracting objects with\nlimited user clicking. Hierarchical backbone is the de-facto architecture for\ncurrent methods. Recently, the plain, non-hierarchical Vision Transformer (ViT)\nhas emerged as a competitive backbone for dense prediction tasks. This design\nallows the original ViT to be a foundation model that can be finetuned for the\ndownstream task without redesigning a hierarchical backbone for pretraining.\nAlthough this design is simple and has been proven effective, it has not yet\nbeen explored for interactive segmentation. To fill this gap, we propose the\nfirst plain-backbone method, termed as SimpleClick due to its simplicity in\narchitecture, for interactive segmentation. With the plain backbone pretrained\nas masked autoencoder (MAE), SimpleClick achieves state-of-the-art performance\nwithout bells and whistles. Remarkably, our method achieves 4.15 NoC@90 on SBD,\nimproving 21.8% over previous best result. Extensive evaluation of medical\nimages highlights the generalizability of our method. We also provide a\ndetailed computation analysis for our method, highlighting its availability as\na practical annotation tool.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Qin Liu",
      "Zhenlin Xu",
      "Gedas Bertasius",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11006"
  },
  {
    "id": "arXiv:2210.11012",
    "title": "Law Article-Enhanced Legal Case Matching: a Model-Agnostic Causal  Learning Approach",
    "abstract": "Legal case matching, which automatically constructs a model to estimate the\nsimilarities between the source and target cases, has played an essential role\nin intelligent legal systems. Semantic text matching models have been applied\nto the task where the source and target legal cases are considered as long-form\ntext documents. These general-purpose matching models make the predictions\nsolely based on the texts in the legal cases, overlooking the essential role of\nthe law articles in legal case matching. In the real world, the matching\nresults (e.g., relevance labels) are dramatically affected by the law articles\nbecause the contents and the judgments of a legal case are radically formed on\nthe basis of law. From the causal sense, a matching decision is affected by the\nmediation effect from the cited law articles by the legal cases, and the direct\neffect of the key circumstances (e.g., detailed fact descriptions) in the legal\ncases. In light of the observation, this paper proposes a model-agnostic causal\nlearning framework called Law-Match, under which the legal case matching models\nare learned by respecting the corresponding law articles. Given a pair of legal\ncases and the related law articles, Law-Match considers the embeddings of the\nlaw articles as instrumental variables (IVs), and the embeddings of legal cases\nas treatments. Using IV regression, the treatments can be decomposed into\nlaw-related and law-unrelated parts, respectively reflecting the mediation and\ndirect effects. These two parts are then combined with different weights to\ncollectively support the final matching prediction. We show that the framework\nis model-agnostic, and a number of legal case matching models can be applied as\nthe underlying models. Comprehensive experiments show that Law-Match can\noutperform state-of-the-art baselines on three public datasets.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Zhongxiang Sun",
      "Jun Xu",
      "Xiao Zhang",
      "Zhenhua Dong",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11012"
  },
  {
    "id": "arXiv:2210.11016",
    "title": "Towards Sustainable Self-supervised Learning",
    "abstract": "Although increasingly training-expensive, most self-supervised learning (SSL)\nmodels have repeatedly been trained from scratch but not fully utilized, since\nonly a few SOTAs are employed for downstream tasks. In this work, we explore a\nsustainable SSL framework with two major challenges: i) learning a stronger new\nSSL model based on the existing pretrained SSL model, also called as \"base\"\nmodel, in a cost-friendly manner, ii) allowing the training of the new model to\nbe compatible with various base models. We propose a Target-Enhanced\nConditional (TEC) scheme which introduces two components to the existing\nmask-reconstruction based SSL. Firstly, we propose patch-relation enhanced\ntargets which enhances the target given by base model and encourages the new\nmodel to learn semantic-relation knowledge from the base model by using\nincomplete inputs. This hardening and target-enhancing help the new model\nsurpass the base model, since they enforce additional patch relation modeling\nto handle incomplete input. Secondly, we introduce a conditional adapter that\nadaptively adjusts new model prediction to align with the target of different\nbase models. Extensive experimental results show that our TEC scheme can\naccelerate the learning speed, and also improve SOTA SSL base models, e.g., MAE\nand iBOT, taking an explorative step towards sustainable SSL.",
    "descriptor": "\nComments: Extension of NeurIPS 2022 workshop\n",
    "authors": [
      "Shanghua Gao",
      "Pan Zhou",
      "Ming-Ming Cheng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11016"
  },
  {
    "id": "arXiv:2210.11017",
    "title": "Multi-Granularity Optimization for Non-Autoregressive Translation",
    "abstract": "Despite low latency, non-autoregressive machine translation (NAT) suffers\nsevere performance deterioration due to the naive independence assumption. This\nassumption is further strengthened by cross-entropy loss, which encourages a\nstrict match between the hypothesis and the reference token by token. To\nalleviate this issue, we propose multi-granularity optimization for NAT, which\ncollects model behaviors on translation segments of various granularities and\nintegrates feedback for backpropagation. Experiments on four WMT benchmarks\nshow that the proposed method significantly outperforms the baseline models\ntrained with cross-entropy loss, and achieves the best performance on WMT'16\nEn-Ro and highly competitive results on WMT'14 En-De for fully\nnon-autoregressive translation.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Yafu Li",
      "Leyang Cui",
      "Yongjing Yin",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11017"
  },
  {
    "id": "arXiv:2210.11018",
    "title": "Infrared and visible image fusion via dual-domain adversarial learning",
    "abstract": "The GAN-based infrared and visible image fusion methods have gained\never-increasing attention due to its effectiveness and superiority. However,\nthe existing methods adopt the global pixel distribution of source images as\nthe basis for discrimination, which fails to focus on the key modality\ninformation. Moreover, the dual-discriminator based methods suffer from the\nconfrontation between the discriminators. To this end, we propose a dual-domain\nadversarial based infrared and visible image fusion method (D2AFGAN). In this\nmethod, two unique discrimination strategies are designed to improve the fusion\nperformance. Specifically, we introduce the spatial attention modules (SAM)\ninto the generator to obtain the spatial attention maps, and then the attention\nmaps are utilized to force the discrimination of infrared images to focus on\nthe target regions. In addition, we extend the discrimination range of visible\ninformation to the wavelet subspace, which can force the generator to restore\nthe high-frequency details of visible images. Ablation experiments demonstrate\nthe effectiveness of our method in eliminating the confrontation between\ndiscriminators. And the comparison experiments on public datasets demonstrate\nthe effectiveness and superiority of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiaowen Liu",
      "Renhua Wang",
      "Hongtao Huo",
      "Jing Li",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.11018"
  },
  {
    "id": "arXiv:2210.11020",
    "title": "Maximum Common Subgraph Guided Graph Retrieval: Late and Early  Interaction Networks",
    "abstract": "The graph retrieval problem is to search in a large corpus of graphs for ones\nthat are most similar to a query graph. A common consideration for scoring\nsimilarity is the maximum common subgraph (MCS) between the query and corpus\ngraphs, usually counting the number of common edges (i.e., MCES). In some\napplications, it is also desirable that the common subgraph be connected, i.e.,\nthe maximum common connected subgraph (MCCS). Finding exact MCES and MCCS is\nintractable, but may be unnecessary if ranking corpus graphs by relevance is\nthe goal. We design fast and trainable neural functions that approximate MCES\nand MCCS well. Late interaction methods compute dense representations for the\nquery and corpus graph separately, and compare these representations using\nsimple similarity functions at the last stage, leading to highly scalable\nsystems. Early interaction methods combine information from both graphs right\nfrom the input stages, are usually considerably more accurate, but slower. We\npropose both late and early interaction neural MCES and MCCS formulations. They\nare both based on a continuous relaxation of a node alignment matrix between\nquery and corpus nodes. For MCCS, we propose a novel differentiable network for\nestimating the size of the largest connected common subgraph. Extensive\nexperiments with seven data sets show that our proposals are superior among\nlate interaction models in terms of both accuracy and speed. Our early\ninteraction models provide accuracy competitive with the state of the art, at\nsubstantially greater speeds.",
    "descriptor": "",
    "authors": [
      "Indradyumna Roy",
      "Soumen Chakrabarti",
      "Abir De"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11020"
  },
  {
    "id": "arXiv:2210.11021",
    "title": "Independence Testing-Based Approach to Causal Discovery under  Measurement Error and Linear Non-Gaussian Models",
    "abstract": "Causal discovery aims to recover causal structures generating the\nobservational data. Despite its success in certain problems, in many real-world\nscenarios the observed variables are not the target variables of interest, but\nthe imperfect measures of the target variables. Causal discovery under\nmeasurement error aims to recover the causal graph among unobserved target\nvariables from observations made with measurement error. We consider a specific\nformulation of the problem, where the unobserved target variables follow a\nlinear non-Gaussian acyclic model, and the measurement process follows the\nrandom measurement error model. Existing methods on this formulation rely on\nnon-scalable over-complete independent component analysis (OICA). In this work,\nwe propose the Transformed Independent Noise (TIN) condition, which checks for\nindependence between a specific linear transformation of some measured\nvariables and certain other measured variables. By leveraging the\nnon-Gaussianity and higher-order statistics of data, TIN is informative about\nthe graph structure among the unobserved target variables. By utilizing TIN,\nthe ordered group decomposition of the causal model is identifiable. In other\nwords, we could achieve what once required OICA to achieve by only conducting\nindependence tests. Experimental results on both synthetic and real-world data\ndemonstrate the effectiveness and reliability of our method.",
    "descriptor": "\nComments: accepted to NeurIPS 2022\n",
    "authors": [
      "Haoyue Dai",
      "Peter Spirtes",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11021"
  },
  {
    "id": "arXiv:2210.11022",
    "title": "SPARCS: Structuring Physically Assistive Robotics for Caregiving with  Stakeholders-in-the-loop",
    "abstract": "Existing work in physical robot caregiving is limited in its ability to\nprovide long-term assistance. This is majorly due to (i) lack of well-defined\nproblems, (ii) diversity of tasks, and (iii) limited access to stakeholders\nfrom the caregiving community. We propose Structuring Physically Assistive\nRobotics for Caregiving with Stakeholders-in-the-loop (SPARCS) to address these\nchallenges. SPARCS is a framework for physical robot caregiving comprising (i)\nBuilding Blocks, models that define physical robot caregiving scenarios, (ii)\nStructured Workflows, hierarchical workflows that enable us to answer the Whats\nand Hows of physical robot caregiving, and (iii) SPARCS-Box, a web-based\nplatform to facilitate dialogue between all stakeholders. We collect clinical\ndata for six care recipients with varying disabilities and demonstrate the use\nof SPARCS in designing well-defined caregiving scenarios and identifying their\ncare requirements. All the data and workflows are available on SPARCS-Box. We\ndemonstrate the utility of SPARCS in building a robot-assisted feeding system\nfor one of the care recipients. We also perform experiments to show the\nadaptability of this system to different caregiving scenarios. Finally, we\nidentify open challenges in physical robot caregiving by consulting care\nrecipients and caregivers. Supplementary material can be found at\nhttps://emprise.cs.cornell.edu/sparcs/.",
    "descriptor": "\nComments: 8 pages, 9 figures, IEEE International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Rishabh Madan",
      "Rajat Kumar Jenamani",
      "Vy Thuy Nguyen",
      "Ahmed Moustafa",
      "Xuefeng Hu",
      "Katherine Dimitropoulou",
      "Tapomayukh Bhattacharjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11022"
  },
  {
    "id": "arXiv:2210.11024",
    "title": "A survey on Self Supervised learning approaches for improving Multimodal  representation learning",
    "abstract": "Recently self supervised learning has seen explosive growth and use in\nvariety of machine learning tasks because of its ability to avoid the cost of\nannotating large-scale datasets.\nThis paper gives an overview for best self supervised learning approaches for\nmultimodal learning. The presented approaches have been aggregated by extensive\nstudy of the literature and tackle the application of self supervised learning\nin different ways. The approaches discussed are cross modal generation, cross\nmodal pretraining, cyclic translation, and generating unimodal labels in self\nsupervised fashion.",
    "descriptor": "",
    "authors": [
      "Naman Goyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11024"
  },
  {
    "id": "arXiv:2210.11025",
    "title": "Double precision is not necessary for LSQR for solving discrete linear  ill-posed problems",
    "abstract": "The growing availability and usage of low precision foating point formats has\nattracts many interests of developing lower or mixed precision algorithms for\nscientific computing problems. In this paper we investigate the possibility of\nexploiting lower precision computing in LSQR for solving discrete linear\nill-posed problems. We analyze the choice of proper computing precisions in the\ntwo main parts of LSQR, including the construction of Lanczos vectors and\nupdating procedure of iterative solutions. We show that, under some mild\nconditions, the Lanczos vectors can be computed using single precision without\nloss of any accuracy of final regularized solutions as long as the noise level\nis not extremely small. We also show that the most time consuming part for\nupdating iterative solutions can be performed using single precision without\nsacrificing any accuracy. The results indicate that the most time consuming\nparts of the algorithm can be implemented using single precision, and thus the\nperformance of LSQR for solving discrete linear ill-posed problems can be\nsignificantly enhanced. Numerical experiments are made for testing the single\nprecision variants of LSQR and confirming our results.",
    "descriptor": "",
    "authors": [
      "Haibo Li",
      "Guangming Tan",
      "Tong Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11025"
  },
  {
    "id": "arXiv:2210.11029",
    "title": "DeepRING: Learning Roto-translation Invariant Representation for LiDAR  based Place Recognition",
    "abstract": "LiDAR based place recognition is popular for loop closure detection and\nre-localization. In recent years, deep learning brings improvements to place\nrecognition by learnable feature extraction. However, these methods degenerate\nwhen the robot re-visits previous places with large perspective difference. To\naddress the challenge, we propose DeepRING to learn the roto-translation\ninvariant representation from LiDAR scan, so that robot visits the same place\nwith different perspective can have similar representations. There are two keys\nin DeepRING: the feature is extracted from sinogram, and the feature is\naggregated by magnitude spectrum. The two steps keeps the final representation\nwith both discrimination and roto-translation invariance. Moreover, we state\nthe place recognition as a one-shot learning problem with each place being a\nclass, leveraging relation learning to build representation similarity.\nSubstantial experiments are carried out on public datasets, validating the\neffectiveness of each proposed component, and showing that DeepRING outperforms\nthe comparative methods, especially in dataset level generalization.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Sha Lu",
      "Xuecheng Xu",
      "Li Tang",
      "Rong Xiong",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11029"
  },
  {
    "id": "arXiv:2210.11033",
    "title": "Neural Estimation of Submodular Functions with Applications to  Differentiable Subset Selection",
    "abstract": "Submodular functions and variants, through their ability to characterize\ndiversity and coverage, have emerged as a key tool for data selection and\nsummarization. Many recent approaches to learn submodular functions suffer from\nlimited expressiveness. In this work, we propose FLEXSUBNET, a family of\nflexible neural models for both monotone and non-monotone submodular functions.\nTo fit a latent submodular function from (set, value) observations, FLEXSUBNET\napplies a concave function on modular functions in a recursive manner. We do\nnot draw the concave function from a restricted family, but rather learn from\ndata using a highly expressive neural network that implements a differentiable\nquadrature procedure. Such an expressive neural model for concave functions may\nbe of independent interest. Next, we extend this setup to provide a novel\ncharacterization of monotone \\alpha-submodular functions, a recently introduced\nnotion of approximate submodular functions. We then use this characterization\nto design a novel neural model for such functions. Finally, we consider\nlearning submodular set functions under distant supervision in the form of\n(perimeter-set, high-value-subset) pairs. This yields a novel subset selection\nmethod based on an order-invariant, yet greedy sampler built around the above\nneural set functions. Our experiments on synthetic and real data show that\nFLEXSUBNET outperforms several baselines.",
    "descriptor": "",
    "authors": [
      "Abir De",
      "Soumen Chakrabarti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11033"
  },
  {
    "id": "arXiv:2210.11034",
    "title": "Enhancing Out-of-Distribution Detection in Natural Language  Understanding via Implicit Layer Ensemble",
    "abstract": "Out-of-distribution (OOD) detection aims to discern outliers from the\nintended data distribution, which is crucial to maintaining high reliability\nand a good user experience. Most recent studies in OOD detection utilize the\ninformation from a single representation that resides in the penultimate layer\nto determine whether the input is anomalous or not. Although such a method is\nstraightforward, the potential of diverse information in the intermediate\nlayers is overlooked. In this paper, we propose a novel framework based on\ncontrastive learning that encourages intermediate features to learn\nlayer-specialized representations and assembles them implicitly into a single\nrepresentation to absorb rich information in the pre-trained language model.\nExtensive experiments in various intent classification and OOD datasets\ndemonstrate that our approach is significantly more effective than other works.",
    "descriptor": "\nComments: EMNLP Findings 2022\n",
    "authors": [
      "Hyunsoo Cho",
      "Choonghyun Park",
      "Jaewook Kang",
      "Kang Min Yoo",
      "Taeuk Kim",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11034"
  },
  {
    "id": "arXiv:2210.11035",
    "title": "PointTAD: Multi-Label Temporal Action Detection with Learnable Query  Points",
    "abstract": "Traditional temporal action detection (TAD) usually handles untrimmed videos\nwith small number of action instances from a single label (e.g., ActivityNet,\nTHUMOS). However, this setting might be unrealistic as different classes of\nactions often co-occur in practice. In this paper, we focus on the task of\nmulti-label temporal action detection that aims to localize all action\ninstances from a multi-label untrimmed video. Multi-label TAD is more\nchallenging as it requires for fine-grained class discrimination within a\nsingle video and precise localization of the co-occurring instances. To\nmitigate this issue, we extend the sparse query-based detection paradigm from\nthe traditional TAD and propose the multi-label TAD framework of PointTAD.\nSpecifically, our PointTAD introduces a small set of learnable query points to\nrepresent the important frames of each action instance. This point-based\nrepresentation provides a flexible mechanism to localize the discriminative\nframes at boundaries and as well the important frames inside the action.\nMoreover, we perform the action decoding process with the Multi-level\nInteractive Module to capture both point-level and instance-level action\nsemantics. Finally, our PointTAD employs an end-to-end trainable framework\nsimply based on RGB input for easy deployment. We evaluate our proposed method\non two popular benchmarks and introduce the new metric of detection-mAP for\nmulti-label TAD. Our model outperforms all previous methods by a large margin\nunder the detection-mAP metric, and also achieves promising results under the\nsegmentation-mAP metric. Code is available at\nhttps://github.com/MCG-NJU/PointTAD.",
    "descriptor": "\nComments: NeurIPS 2022 camera ready version\n",
    "authors": [
      "Jing Tan",
      "Xiaotong Zhao",
      "Xintian Shi",
      "Bing Kang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11035"
  },
  {
    "id": "arXiv:2210.11039",
    "title": "Entire Space Counterfactual Learning: Tuning, Analytical Properties and  Industrial Applications",
    "abstract": "As a basic research problem for building effective recommender systems,\npost-click conversion rate (CVR) estimation has long been plagued by sample\nselection bias and data sparsity issues. To address the data sparsity issue,\nprevalent methods based on entire space multi-task model leverage the\nsequential pattern of user actions, i.e. exposure $\\rightarrow$ click\n$\\rightarrow$ conversion to construct auxiliary learning tasks. However, they\nstill fall short of guaranteeing the unbiasedness of CVR estimates. This paper\ntheoretically demonstrates two defects of these entire space multi-task models:\n(1) inherent estimation bias (IEB) for CVR estimation, where the CVR estimate\nis inherently higher than the ground truth; (2) potential independence priority\n(PIP) for CTCVR estimation, where the causality from click to conversion might\nbe overlooked. This paper further proposes a principled method named entire\nspace counterfactual multi-task model (ESCM$^2$), which employs a\ncounterfactual risk minimizer to handle both IEB and PIP issues at once. To\ndemonstrate the effectiveness of the proposed method, this paper explores its\nparameter tuning in practice, derives its analytic properties, and showcases\nits effectiveness in industrial CVR estimation, where ESCM$^2$ can effectively\nalleviate the intrinsic IEB and PIP issues and outperform baseline models.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.05125\n",
    "authors": [
      "Hao Wang",
      "Zhichao Chen",
      "Jiajun Fan",
      "Yuxin Huang",
      "Weiming Liu",
      "Xinggao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11039"
  },
  {
    "id": "arXiv:2210.11047",
    "title": "Thwarting Piracy: Anti-debugging Using GPU-assisted Self-healing Codes",
    "abstract": "Software piracy is one of the concerns in the IT sector. Pirates leverage the\ndebugger tools to reverse engineer the logic that verifies the license keys or\nbypass the entire verification process. Anti-debugging techniques are used to\ndefeat piracy using self-healing codes. However, anti-debugging methods can be\ndefeated when the licensing protections are limited to CPU-based implementation\nby writing custom codes to deactivate the anti-debugging methods. In the paper,\nwe demonstrate how GPU implementation can prevent pirates from deactivating the\nanti-debugging methods by using the limitations of debugging on GPU. Generally,\nGPUs do not support debugging directly on the hardware, and therefore all the\ndebugging is limited to CPU-based emulation. Also, a process running on CPU\ngenerally does not have any visibility on codes running on GPU, which comes as\nan added benefit for our work. We provide an implementation on GPU to show the\nfeasibility of our method. As GPUs are getting widespread with the raise in\npopularity of gaming software, our technique provides a method to protect\nagainst piracy. Our method thwarts any attempts to bypass the license\nverification step thus offering a better anti-piracy mechanism.",
    "descriptor": "",
    "authors": [
      "Adhokshaj Mishra",
      "Manjesh Kumar Hanawal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11047"
  },
  {
    "id": "arXiv:2210.11049",
    "title": "How Does a Deep Learning Model Architecture Impact Its Privacy?",
    "abstract": "As a booming research area in the past decade, deep learning technologies\nhave been driven by big data collected and processed on an unprecedented scale.\nHowever, the sensitive information in the collected training data raises\nprivacy concerns. Recent research indicated that deep learning models are\nvulnerable to various privacy attacks, including membership inference attacks,\nattribute inference attacks, and gradient inversion attacks. It is noteworthy\nthat the performance of the attacks varies from model to model. In this paper,\nwe conduct empirical analyses to answer a fundamental question: Does model\narchitecture affect model privacy? We investigate several representative model\narchitectures from CNNs to Transformers, and show that Transformers are\ngenerally more vulnerable to privacy attacks than CNNs. We further demonstrate\nthat the micro design of activation layers, stem layers, and bias parameters,\nare the major reasons why CNNs are more resilient to privacy attacks than\nTransformers. We also find that the presence of attention modules is another\nreason why Transformers are more vulnerable to privacy attacks. We hope our\ndiscovery can shed some new light on how to defend against the investigated\nprivacy attacks and help the community build privacy-friendly model\narchitectures.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Guangsheng Zhang",
      "Bo Liu",
      "Huan Tian",
      "Tianqing Zhu",
      "Ming Ding",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11049"
  },
  {
    "id": "arXiv:2210.11050",
    "title": "Vertical Federated Linear Contextual Bandits",
    "abstract": "In this paper, we investigate a novel problem of building contextual bandits\nin the vertical federated setting, i.e., contextual information is vertically\ndistributed over different departments. This problem remains largely unexplored\nin the research community. To this end, we carefully design a customized\nencryption scheme named orthogonal matrix-based mask mechanism(O3M) for\nencrypting local contextual information while avoiding expensive conventional\ncryptographic techniques. We further apply the mechanism to two commonly-used\nbandit algorithms, LinUCB and LinTS, and instantiate two practical protocols\nfor online recommendation under the vertical federated setting. The proposed\nprotocols can perfectly recover the service quality of centralized bandit\nalgorithms while achieving a satisfactory runtime efficiency, which is\ntheoretically proved and analyzed in this paper. By conducting extensive\nexperiments on both synthetic and real-world datasets, we show the superiority\nof the proposed method in terms of privacy protection and recommendation\nperformance.",
    "descriptor": "",
    "authors": [
      "Zeyu Cao",
      "Zhipeng Liang",
      "Shu Zhang",
      "Hangyu Li",
      "Ouyang Wen",
      "Yu Rong",
      "Peilin Zhao",
      "Bingzhe Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11050"
  },
  {
    "id": "arXiv:2210.11054",
    "title": "Incorporating Bias-aware Margins into Contrastive Loss for Collaborative  Filtering",
    "abstract": "Collaborative filtering (CF) models easily suffer from popularity bias, which\nmakes recommendation deviate from users' actual preferences. However, most\ncurrent debiasing strategies are prone to playing a trade-off game between head\nand tail performance, thus inevitably degrading the overall recommendation\naccuracy. To reduce the negative impact of popularity bias on CF models, we\nincorporate Bias-aware margins into Contrastive loss and propose a simple yet\neffective BC Loss, where the margin tailors quantitatively to the bias degree\nof each user-item interaction. We investigate the geometric interpretation of\nBC loss, then further visualize and theoretically prove that it simultaneously\nlearns better head and tail representations by encouraging the compactness of\nsimilar users/items and enlarging the dispersion of dissimilar users/items.\nOver eight benchmark datasets, we use BC loss to optimize two high-performing\nCF models. On various evaluation settings (i.e., imbalanced/balanced, temporal\nsplit, fully-observed unbiased, tail/head test evaluations), BC loss\noutperforms the state-of-the-art debiasing and non-debiasing methods with\nremarkable improvements. Considering the theoretical guarantee and empirical\nsuccess of BC loss, we advocate using it not just as a debiasing strategy, but\nalso as a standard loss in recommender models.",
    "descriptor": "",
    "authors": [
      "An Zhang",
      "Wenchang Ma",
      "Xiang Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11054"
  },
  {
    "id": "arXiv:2210.11055",
    "title": "Shepherding Heterogeneous Flock with Model-Based Discrimination",
    "abstract": "The problem of guiding a flock of agents to a destination by the repulsion\nforces exerted by a smaller number of external agents is called the shepherding\nproblem. This problem has attracted attention due to its potential\napplications, including diverting birds away for preventing airplane accidents,\nrecovering spilled oil in the ocean, and guiding a swarm of robots for mapping.\nAlthough there have been various studies on the shepherding problem, most of\nthem place the uniformity assumption on the dynamics of agents to be guided.\nHowever, we can find various practical situations where this assumption does\nnot necessarily hold. In this paper, we propose a shepherding method for a\nflock of agents consisting of normal agents to be guided and other variant\nagents. In this method, the shepherd discriminates normal and variant agents\nbased on their behaviors' deviation from the one predicted by the potentially\ninaccurate model of the normal agents. As for the discrimination process, we\npropose two methods using static and dynamic thresholds. Our simulation results\nshow that the proposed methods outperform a conventional method for various\ntypes of variant agents.",
    "descriptor": "\nComments: 19 pages, 6 figures, accepted for publication\n",
    "authors": [
      "Anna Fujioka",
      "Masaki Ogura",
      "Naoki Wakamiya"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.11055"
  },
  {
    "id": "arXiv:2210.11058",
    "title": "Representation Learning with Diffusion Models",
    "abstract": "Diffusion models (DMs) have achieved state-of-the-art results for image\nsynthesis tasks as well as density estimation. Applied in the latent space of a\npowerful pretrained autoencoder (LDM), their immense computational requirements\ncan be significantly reduced without sacrificing sampling quality. However, DMs\nand LDMs lack a semantically meaningful representation space as the diffusion\nprocess gradually destroys information in the latent variables. We introduce a\nframework for learning such representations with diffusion models (LRDM). To\nthat end, a LDM is conditioned on the representation extracted from the clean\nimage by a separate encoder. In particular, the DM and the representation\nencoder are trained jointly in order to learn rich representations specific to\nthe generative denoising process. By introducing a tractable representation\nprior, we can efficiently sample from the representation distribution for\nunconditional image synthesis without training of any additional model. We\ndemonstrate that i) competitive image generation results can be achieved with\nimage-parameterized LDMs, ii) LRDMs are capable of learning semantically\nmeaningful representations, allowing for faithful image reconstructions and\nsemantic interpolations. Our implementation is available at\nhttps://github.com/jeremiastraub/diffusion.",
    "descriptor": "",
    "authors": [
      "Jeremias Traub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11058"
  },
  {
    "id": "arXiv:2210.11060",
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "abstract": "This paper introduces Doc2Bot, a novel dataset for building machines that\nhelp users seek information via conversations. This is of particular interest\nfor companies and organizations that own a large number of manuals or\ninstruction books. Despite its potential, the nature of our task poses several\nchallenges: (1) documents contain various structures that hinder the ability of\nmachines to comprehend, and (2) user information needs are often\nunderspecified. Compared to prior datasets that either focus on a single\nstructural type or overlook the role of questioning to uncover user needs, the\nDoc2Bot dataset is developed to target such challenges systematically. Our\ndataset contains over 100,000 turns based on Chinese documents from five\ndomains, larger than any prior document-grounded dialog dataset for information\nseeking. We propose three tasks in Doc2Bot: (1) dialog state tracking to track\nuser intentions, (2) dialog policy learning to plan system actions and\ncontents, and (3) response generation which generates responses based on the\noutputs of the dialog policy. Baseline methods based on the latest deep\nlearning models are presented, indicating that our proposed tasks are\nchallenging and worthy of further research.",
    "descriptor": "\nComments: 17 pages, 14 figures. Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam-Tu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11060"
  },
  {
    "id": "arXiv:2210.11061",
    "title": "Analyzing the Robustness of Decentralized Horizontal and Vertical  Federated Learning Architectures in a Non-IID Scenario",
    "abstract": "Federated learning (FL) allows participants to collaboratively train machine\nand deep learning models while protecting data privacy. However, the FL\nparadigm still presents drawbacks affecting its trustworthiness since malicious\nparticipants could launch adversarial attacks against the training process.\nRelated work has studied the robustness of horizontal FL scenarios under\ndifferent attacks. However, there is a lack of work evaluating the robustness\nof decentralized vertical FL and comparing it with horizontal FL architectures\naffected by adversarial attacks. Thus, this work proposes three decentralized\nFL architectures, one for horizontal and two for vertical scenarios, namely\nHoriChain, VertiChain, and VertiComb. These architectures present different\nneural networks and training protocols suitable for horizontal and vertical\nscenarios. Then, a decentralized, privacy-preserving, and federated use case\nwith non-IID data to classify handwritten digits is deployed to evaluate the\nperformance of the three architectures. Finally, a set of experiments computes\nand compares the robustness of the proposed architectures when they are\naffected by different data poisoning based on image watermarks and gradient\npoisoning adversarial attacks. The experiments show that even though particular\nconfigurations of both attacks can destroy the classification performance of\nthe architectures, HoriChain is the most robust one.",
    "descriptor": "",
    "authors": [
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Alberto Huertas Celdr\u00e1n",
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Daniel Demeter",
      "G\u00e9r\u00f4me Bovet",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11061"
  },
  {
    "id": "arXiv:2210.11064",
    "title": "Competitive Equilibrium for Dynamic Multi-Agent Systems: Social Shaping  and Price Trajectories",
    "abstract": "In this paper, we consider dynamic multi-agent systems (MAS) for\ndecentralized resource allocation. The MAS operates at a competitive\nequilibrium to ensure supply and demand are balanced. First, we investigate the\nMAS over a finite horizon. The utility functions of agents are parameterized to\nincorporate individual preferences. We shape individual preferences through a\nset of utility functions to guarantee the resource price at a competitive\nequilibrium remains socially acceptable, i.e., the price is upper-bounded by an\naffordability threshold. We show this problem is solvable at the conceptual\nlevel. Next, we consider quadratic MAS and formulate the associated social\nshaping problem as a multi-agent linear quadratic regulator (LQR) problem which\nenables us to propose explicit utility sets using quadratic programming and\ndynamic programming. Then, a numerical algorithm is presented for calculating a\ntight range of the preference function parameters which guarantees a socially\naccepted price. We investigate the properties of a competitive equilibrium over\nan infinite horizon. Considering general utility functions, we show that under\nfeasibility assumptions, any competitive equilibrium maximizes the social\nwelfare. Then, we prove that for sufficiently small initial conditions, the\nsocial welfare maximization solution constitutes a competitive equilibrium with\nzero price. We also prove for general feasible initial conditions, there exists\na time instant after which the optimal price, corresponding to a competitive\nequilibrium, becomes zero. Finally, we specifically focus on quadratic MAS and\npropose explicit results.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.04621\n",
    "authors": [
      "Zeinab Salehi",
      "Yijun Chen",
      "Elizabeth L. Ratnam",
      "Ian R. Petersen",
      "Guodong Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11064"
  },
  {
    "id": "arXiv:2210.11065",
    "title": "MovieCLIP: Visual Scene Recognition in Movies",
    "abstract": "Longform media such as movies have complex narrative structures, with events\nspanning a rich variety of ambient visual scenes. Domain specific challenges\nassociated with visual scenes in movies include transitions, person coverage,\nand a wide array of real-life and fictional scenarios. Existing visual scene\ndatasets in movies have limited taxonomies and don't consider the visual scene\ntransition within movie clips. In this work, we address the problem of visual\nscene recognition in movies by first automatically curating a new and extensive\nmovie-centric taxonomy of 179 scene labels derived from movie scripts and\nauxiliary web-based video datasets. Instead of manual annotations which can be\nexpensive, we use CLIP to weakly label 1.12 million shots from 32K movie clips\nbased on our proposed taxonomy. We provide baseline visual models trained on\nthe weakly labeled dataset called MovieCLIP and evaluate them on an independent\ndataset verified by human raters. We show that leveraging features from models\npretrained on MovieCLIP benefits downstream tasks such as multi-label scene and\ngenre classification of web videos and movie trailers.",
    "descriptor": "\nComments: Accepted to 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2023). Project website with supplemental material: this https URL\n",
    "authors": [
      "Digbalay Bose",
      "Rajat Hebbar",
      "Krishna Somandepalli",
      "Haoyang Zhang",
      "Yin Cui",
      "Kree Cole-McLaughlin",
      "Huisheng Wang",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.11065"
  },
  {
    "id": "arXiv:2210.11068",
    "title": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly  Detection Performance",
    "abstract": "Accurately extracting driving events is the way to maximize computational\nefficiency and anomaly detection performance in the tire frictional nose-based\nanomaly detection task. This study proposes a concise and highly useful method\nfor improving the precision of the event extraction that is hindered by extra\nnoise such as wind noise, which is difficult to characterize clearly due to its\nrandomness. The core of the proposed method is based on the identification of\nthe road friction sound corresponding to the frequency of interest and removing\nthe opposite characteristics with several frequency filters. Our method enables\nprecision maximization of driving event extraction while improving anomaly\ndetection performance by an average of 8.506%. Therefore, we conclude our\nmethod is a practical solution suitable for road surface anomaly detection\npurposes in outdoor edge computing environments.",
    "descriptor": "\nComments: 5 pages, 4 figures, 4 tables\n",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Won Seok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11068"
  },
  {
    "id": "arXiv:2210.11069",
    "title": "Hardware Implementation of Iterative Projection Aggregation Decoding for  Reed-Muller Codes",
    "abstract": "The recently proposed recursive projection-aggregation (RPA) decoding\nalgorithm for Reed-Muller codes has received significant attention as it\nprovides near-ML decoding performance at reasonable complexity for short codes.\nHowever, its complicated structure makes it unsuitable for hardware\nimplementation. Iterative projection-aggregation (IPA) decoding is a modified\nversion of RPA decoding that simplifies the hardware implementation. In this\nwork, we present a flexible hardware architecture for the IPA decoder that can\nbe configured from fully-sequential to fully-parallel, thus making it suitable\nfor a wide range of applications with different constraints and resource\nbudgets. Our simulation and implementation results show that the IPA decoder\nhas 41% lower area consumption, 44% lower latency, and four times higher\nthroughput for a code with block length of 128 and information length of 29\ncompared to a state-of-the-art polar successive cancellation list (SCL) decoder\nwith comparable decoding performance.",
    "descriptor": "",
    "authors": [
      "Marzieh Hashemipour-Nazari",
      "Kees Goossens",
      "Alexios Balatsoukas-Stimming"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11069"
  },
  {
    "id": "arXiv:2210.11075",
    "title": "Freeze then Train: Towards Provable Representation Learning under  Spurious Correlations and Feature Noise",
    "abstract": "The existence of spurious correlations such as image backgrounds in the\ntraining environment can make empirical risk minimization (ERM) perform badly\nin the test environment. To address this problem, Kirichenko et al. (2022)\nempirically found that the core features that are causally related to the\noutcome can still be learned well even with the presence of spurious\ncorrelations. This opens a promising strategy to first train a feature learner\nrather than a classifier, and then perform linear probing (last layer\nretraining) in the test environment. However, a theoretical understanding of\nwhen and why this approach works is lacking. In this paper, we find that core\nfeatures are only learned well when they are less noisy than spurious features,\nwhich is not necessarily true in practice. We provide both theories and\nexperiments to support this finding and to illustrate the importance of feature\nnoise. Moreover, we propose an algorithm called Freeze then Train (FTT), that\nfirst freezes certain salient features and then trains the rest of the features\nusing ERM. We theoretically show that FTT preserves features that are more\nbeneficial to test time probing. Across two commonly used real-world\nbenchmarks, FTT outperforms ERM, JTT and CVaR-DRO, with especially substantial\nimprovement in accuracy (by 4.8%) when the feature noise is large.",
    "descriptor": "",
    "authors": [
      "Haotian Ye",
      "James Zou",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11075"
  },
  {
    "id": "arXiv:2210.11076",
    "title": "A Gauss Laguerre approach for the resolvent of fractional powers",
    "abstract": "This paper introduces a very fast method for the computation of the resolvent\nof fractional powers of operators. The analysis is kept in the continuous\nsetting of (potentially unbounded) self adjoint positive operators in Hilbert\nspaces. The method is based on the Gauss-Laguerre rule, exploiting a particular\nintegral representation of the resolvent. We provide sharp error estimates that\ncan be used to a priori select the number of nodes to achieve a prescribed\ntolerance.",
    "descriptor": "",
    "authors": [
      "Eleonora Denich",
      "Laura Grazia Dolce",
      "Paolo Novati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11076"
  },
  {
    "id": "arXiv:2210.11078",
    "title": "Large-batch Optimization for Dense Visual Predictions",
    "abstract": "Training a large-scale deep neural network in a large-scale dataset is\nchallenging and time-consuming. The recent breakthrough of large-batch\noptimization is a promising way to tackle this challenge. However, although the\ncurrent advanced algorithms such as LARS and LAMB succeed in classification\nmodels, the complicated pipelines of dense visual predictions such as object\ndetection and segmentation still suffer from the heavy performance drop in the\nlarge-batch training regime. To address this challenge, we propose a simple yet\neffective algorithm, named Adaptive Gradient Variance Modulator (AGVM), which\ncan train dense visual predictors with very large batch size, enabling several\nbenefits more appealing than prior arts. Firstly, AGVM can align the gradient\nvariances between different modules in the dense visual predictors, such as\nbackbone, feature pyramid network (FPN), detection, and segmentation heads. We\nshow that training with a large batch size can fail with the gradient variances\nmisaligned among them, which is a phenomenon primarily overlooked in previous\nwork. Secondly, AGVM is a plug-and-play module that generalizes well to many\ndifferent architectures (e.g., CNNs and Transformers) and different tasks\n(e.g., object detection, instance segmentation, semantic segmentation, and\npanoptic segmentation). It is also compatible with different optimizers (e.g.,\nSGD and AdamW). Thirdly, a theoretical analysis of AGVM is provided. Extensive\nexperiments on the COCO and ADE20K datasets demonstrate the superiority of\nAGVM. For example, it can train Faster R-CNN+ResNet50 in 4 minutes without\nlosing performance. AGVM enables training an object detector with one billion\nparameters in just 3.5 hours, reducing the training time by 20.9x, whilst\nachieving 62.2 mAP on COCO. The deliverables are released at\nhttps://github.com/Sense-X/AGVM.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Zeyue Xue",
      "Jianming Liang",
      "Guanglu Song",
      "Zhuofan Zong",
      "Liang Chen",
      "Yu Liu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11078"
  },
  {
    "id": "arXiv:2210.11079",
    "title": "Sequential Quantum Channel Discrimination",
    "abstract": "We consider the sequential quantum channel discrimination problem using\nadaptive and non-adaptive strategies. In this setting the number of uses of the\nunderlying quantum channel is not fixed but a random variable that is either\nbounded in expectation or with high probability. We show that both types of\nerror probabilities decrease to zero exponentially fast and, when using\nadaptive strategies, the rates are characterized by the measured relative\nentropy between two quantum channels, yielding a strictly larger region than\nthat achievable by non-adaptive strategies. Allowing for quantum memory, we see\nthat the optimal rates are given by the regularized channel relative entropy.\nFinally, we discuss achievable rates when allowing for repeated measurements\nvia quantum instruments and conjecture that the achievable rate region is not\nlarger than that achievable with POVMs by connecting the result to the strong\nconverse for the quantum channel Stein's Lemma.",
    "descriptor": "",
    "authors": [
      "Yonglong Li",
      "Christoph Hirche",
      "Marco Tomamichel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11079"
  },
  {
    "id": "arXiv:2210.11082",
    "title": "Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via  Contrastive Learning",
    "abstract": "This paper finds that contrastive learning can produce superior sentence\nembeddings for pre-trained models but is also vulnerable to backdoor attacks.\nWe present the first backdoor attack framework, BadCSE, for state-of-the-art\nsentence embeddings under supervised and unsupervised learning settings. The\nattack manipulates the construction of positive and negative pairs so that the\nbackdoored samples have a similar embedding with the target sample (targeted\nattack) or the negative embedding of its clean version (non-targeted attack).\nBy injecting the backdoor in sentence embeddings, BadCSE is resistant against\ndownstream fine-tuning. We evaluate BadCSE on both STS tasks and other\ndownstream tasks. The supervised non-targeted attack obtains a performance\ndegradation of 194.86%, and the targeted attack maps the backdoored samples to\nthe target embedding with a 97.70% success rate while maintaining the model\nutility.",
    "descriptor": "",
    "authors": [
      "Xiaoyi Chen",
      "Baisong Xin",
      "Shengfang Zhai",
      "Shiqing Ma",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11082"
  },
  {
    "id": "arXiv:2210.11084",
    "title": "Confiabilidad en la capa de transporte para la red de sensores  ant\u00e1rtica",
    "abstract": "The SHETLAND-NET research project aims to develop an Internet of Things (IoT)\ntelemetry service in Antarctica by interconnecting Wireless Sensor Networks\n(WSN) through Near Vertical Incidence Skywave radio links (NVIS) that build a\nLong Fat Network (LFN). This architecture presents some typical properties of\nthe so-called challenging networks, which require an evaluation of the\nviability of the proposed solution and an analysis of which transport protocol\ncan provide greater reliability for this use case. For this purpose, a\nlayer-based heterogeneous trustworthiness model is defined and presented.\nThrough extensive simulations, the model is validated, different transport\nprotocols are compared, and the reliability of the system is evaluated.",
    "descriptor": "\nComments: in Spanish language\n",
    "authors": [
      "Adri\u00e0 Mallorqu\u00ed",
      "Agust\u00edn Zaballos",
      "Alan Briones",
      "Guiomar Corral"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.11084"
  },
  {
    "id": "arXiv:2210.11087",
    "title": "Weighted Maximum Likelihood for Controller Tuning",
    "abstract": "Recently, Model Predictive Contouring Control (MPCC) has arisen as the\nstate-of-the-art approach for model-based agile flight. MPCC benefits from\ngreat flexibility in trading-off between progress maximization and path\nfollowing at runtime without relying on globally optimized trajectories.\nHowever, finding the optimal set of tuning parameters for MPCC is challenging\nbecause (i) the full quadrotor dynamics are non-linear, (ii) the cost function\nis highly non-convex, and (iii) of the high dimensionality of the\nhyperparameter space. This paper leverages a probabilistic Policy Search method\n- Weighted Maximum Likelihood (WML)- to automatically learn the optimal\nobjective for MPCC. WML is sample-efficient due to its closed-form solution for\nupdating the learning parameters. Additionally, the data efficiency provided by\nthe use of a model-based approach allows us to directly train in a\nhigh-fidelity simulator, which in turn makes our approach able to transfer\nzero-shot to the real world. We validate our approach in the real world, where\nwe show that our method outperforms both the previous manually tuned controller\nand the state-of-the-art auto-tuning baseline reaching speeds of 75 km/h.",
    "descriptor": "",
    "authors": [
      "Angel Romero",
      "Shreedhar Govil",
      "Gonca Yilmaz",
      "Yunlong Song",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11087"
  },
  {
    "id": "arXiv:2210.11092",
    "title": "Robustcaps: a transformation-robust capsule network for image  classification",
    "abstract": "Geometric transformations of the training data as well as the test data\npresent challenges to the use of deep neural networks to vision-based learning\ntasks. In order to address this issue, we present a deep neural network model\nthat exhibits the desirable property of transformation-robustness. Our model,\ntermed RobustCaps, uses group-equivariant convolutions in an improved capsule\nnetwork model. RobustCaps uses a global context-normalised procedure in its\nrouting algorithm to learn transformation-invariant part-whole relationships\nwithin image data. This learning of such relationships allows our model to\noutperform both capsule and convolutional neural network baselines on\ntransformation-robust classification tasks. Specifically, RobustCaps achieves\nstate-of-the-art accuracies on CIFAR-10, FashionMNIST, and CIFAR-100 when the\nimages in these datasets are subjected to train and test-time rotations and\ntranslations.",
    "descriptor": "",
    "authors": [
      "Sai Raam Venkataraman",
      "S. Balasubramanian",
      "R. Raghunatha Sarma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11092"
  },
  {
    "id": "arXiv:2210.11094",
    "title": "Toward Multiple Specialty Learners for Explaining GNNs via Online  Knowledge Distillation",
    "abstract": "Graph Neural Networks (GNNs) have become increasingly ubiquitous in numerous\napplications and systems, necessitating explanations of their predictions,\nespecially when making critical decisions. However, explaining GNNs is\nchallenging due to the complexity of graph data and model execution. Despite\nadditional computational costs, post-hoc explanation approaches have been\nwidely adopted due to the generality of their architectures. Intrinsically\ninterpretable models provide instant explanations but are usually\nmodel-specific, which can only explain particular GNNs. Therefore, we propose a\nnovel GNN explanation framework named SCALE, which is general and fast for\nexplaining predictions. SCALE trains multiple specialty learners to explain\nGNNs since constructing one powerful explainer to examine attributions of\ninteractions in input graphs is complicated. In training, a black-box GNN model\nguides learners based on an online knowledge distillation paradigm. In the\nexplanation phase, explanations of predictions are provided by multiple\nexplainers corresponding to trained learners. Specifically, edge masking and\nrandom walk with restart procedures are executed to provide structural\nexplanations for graph-level and node-level predictions, respectively. A\nfeature attribution module provides overall summaries and instance-level\nfeature contributions. We compare SCALE with state-of-the-art baselines via\nquantitative and qualitative experiments to prove its explanation correctness\nand execution performance. We also conduct a series of ablation studies to\nunderstand the strengths and weaknesses of the proposed framework.",
    "descriptor": "\nComments: 13 pages, 11 figures, A preliminary paper under review of IEEE ICDE 2023\n",
    "authors": [
      "Tien-Cuong Bui",
      "Van-Duc Le",
      "Wen-syan Li",
      "Sang Kyun Cha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11094"
  },
  {
    "id": "arXiv:2210.11095",
    "title": "Iterative collaborative routing among equivariant capsules for  transformation-robust capsule networks",
    "abstract": "Transformation-robustness is an important feature for machine learning models\nthat perform image classification. Many methods aim to bestow this property to\nmodels by the use of data augmentation strategies, while more formal guarantees\nare obtained via the use of equivariant models. We recognise that\ncompositional, or part-whole structure is also an important aspect of images\nthat has to be considered for building transformation-robust models. Thus, we\npropose a capsule network model that is, at once, equivariant and\ncompositionality-aware. Equivariance of our capsule network model comes from\nthe use of equivariant convolutions in a carefully-chosen novel architecture.\nThe awareness of compositionality comes from the use of our proposed novel,\niterative, graph-based routing algorithm, termed Iterative collaborative\nrouting (ICR). ICR, the core of our contribution, weights the predictions made\nfor capsules based on an iteratively averaged score of the degree-centralities\nof its nearest neighbours. Experiments on transformed image classification on\nFashionMNIST, CIFAR-10, and CIFAR-100 show that our model that uses ICR\noutperforms convolutional and capsule baselines to achieve state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Sai Raam Venkataraman",
      "S. Balasubramanian",
      "R. Raghunatha Sarma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11095"
  },
  {
    "id": "arXiv:2210.11096",
    "title": "Robust One-Shot Singing Voice Conversion",
    "abstract": "Many existing works on singing voice conversion (SVC) require clean\nrecordings of target singer's voice for training. However, it is often\ndifficult to collect them in advance and singing voices are often distorted\nwith reverb and accompaniment music. In this work, we propose robust one-shot\nSVC (ROSVC) that performs any-to-any SVC robustly even on such distorted\nsinging voices using less than 10s of a reference voice. To this end, we\npropose two-stage training method called Robustify. In the first stage, a novel\none-shot SVC model based on a generative adversarial network is trained on\nclean data to ensure high-quality conversion. In the second stage, enhancement\nmodules are introduced to the encoders of the model to improve the robustness\nagainst distortions in the feature space. Experimental results show that the\nproposed method outperforms one-shot SVC baselines for both seen and unseen\nsingers and greatly improves the robustness against the distortions.",
    "descriptor": "",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11096"
  },
  {
    "id": "arXiv:2210.11102",
    "title": "Piecewise linear interpolation of noise in finite element approximations  of parabolic SPDEs",
    "abstract": "Simulation of stochastic partial differential equations (SPDE) on a general\ndomain requires a discretization of the noise. In this paper, the noise is\ndiscretized by a piecewise linear interpolation. The error caused by this is\nanalyzed in the context of a fully discrete finite element approximation of a\nsemilinear stochastic reaction-advection-diffusion equation on a convex\npolygon. The noise is Gaussian, white in time and correlated in space. It is\nmodeled as a standard cylindrical Wiener process on the reproducing kernel\nHilbert space associated to the covariance kernel. The noise is assumed to\nextend to a larger polygon than the SPDE domain to allow for sampling by the\ncirculant embedding method. The interpolation error is analyzed under mild\nassumptions on the kernel. The main tools used are Hilbert--Schmidt bounds of\nmultiplication operators onto negative order Sobolev spaces and an error bound\nfor the finite element interpolant in fractional Sobolev norms. Examples with\ncovariance kernels encountered in applications are illustrated in numerical\nsimulations using the FEniCS finite element software. Conclusions from the\nanalysis include that interpolation of noise with Mat\\'ern kernels does not\ncause an additional error, that there exist kernels where the interpolation\nerror dominates and that generation of noise on a coarser mesh than that of the\nSPDE discretization does not always result in a loss of accuracy.",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Gabriel Lord",
      "Andreas Petersson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.11102"
  },
  {
    "id": "arXiv:2210.11105",
    "title": "Execution Time Program Verification With Tight Bounds",
    "abstract": "This paper presents a proof system for reasoning about execution time bounds\nfor a core imperative programming language. Proof systems are defined for three\ndifferent scenarios: approximations of the worst-case execution time, exact\ntime reasoning, and less pessimistic execution time estimation using amortized\nanalysis. We define a Hoare logic for the three cases and prove its soundness\nwith respect to an annotated cost-aware operational semantics. Finally, we\ndefine a verification conditions (VC) generator that generates the goals needed\nto prove program correctness, cost, and termination. Those goals are then sent\nto the Easycrypt toolset for validation. The practicality of the proof system\nis demonstrated with an implementation in OCaml of the different modules needed\nto apply it to example programs. Our case studies are motivated by real-time\nand cryptographic software.",
    "descriptor": "",
    "authors": [
      "Ana Carolina Silva",
      "Manuel Barbosa",
      "Mario Florido"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11105"
  },
  {
    "id": "arXiv:2210.11106",
    "title": "Robust Multi-Read Reconstruction from Contaminated Clusters Using Deep  Neural Network for DNA Storage",
    "abstract": "DNA has immense potential as an emerging data storage medium. The principle\nof DNA storage is the conversion and flow of digital information between binary\ncode stream, quaternary base, and actual DNA fragments. This process will\ninevitably introduce errors, posing challenges to accurate data recovery.\nSequence reconstruction consists of inferring the DNA reference from a cluster\nof erroneous copies. A common assumption in existing methods is that all the\nstrands within a cluster are noisy copies originating from the same reference,\nthereby contributing equally to the reconstruction. However, this is not always\nvalid considering the existence of contaminated sequences caused, for example,\nby DNA fragmentation and rearrangement during the DNA storage process.This\npaper proposed a robust multi-read reconstruction model using DNN, which is\nresilient to contaminated clusters with outlier sequences, as well as to noisy\nreads with IDS errors. The effectiveness and robustness of the method are\nvalidated on three next-generation sequencing datasets, where a series of\ncomparative experiments are performed by simulating varying contamination\nlevels that occurring during the process of DNA storage.",
    "descriptor": "",
    "authors": [
      "Yun Qin",
      "Fei Zhu",
      "Bo Xi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11106"
  },
  {
    "id": "arXiv:2210.11109",
    "title": "Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text  Generation",
    "abstract": "Image-to-text tasks, such as open-ended image captioning and controllable\nimage description, have received extensive attention for decades. Here, we\nfurther advance this line of work by presenting Visual Spatial Description\n(VSD), a new perspective for image-to-text toward spatial semantics. Given an\nimage and two objects inside it, VSD aims to produce one description focusing\non the spatial perspective between the two objects. Accordingly, we manually\nannotate a dataset to facilitate the investigation of the newly-introduced task\nand build several benchmark encoder-decoder models by using VL-BART and VL-T5\nas backbones. In addition, we investigate pipeline and joint end-to-end\narchitectures for incorporating visual spatial relationship classification\n(VSRC) information into our model. Finally, we conduct experiments on our\nbenchmark dataset to evaluate all our models. Results show that our models are\nimpressive, providing accurate and human-like spatial-oriented text\ndescriptions. Meanwhile, VSRC has great potential for VSD, and the joint\nend-to-end architecture is the better choice for their integration. We make the\ndataset and codes public for research purposes.",
    "descriptor": "",
    "authors": [
      "Yu Zhao",
      "Jianguo Wei",
      "Zhichao Lin",
      "Yueheng Sun",
      "Meishan Zhang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11109"
  },
  {
    "id": "arXiv:2210.11111",
    "title": "The Pump Scheduling Problem: A Real-World Scenario for Reinforcement  Learning",
    "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success in\nscenarios such as games and has emerged as a potential solution for control\ntasks. That is due to its ability to leverage scalability and handle complex\ndynamics. However, few works have targeted environments grounded in real-world\nsettings. Indeed, real-world scenarios can be challenging, especially when\nfaced with the high dimensionality of the state space and unknown reward\nfunction. We release a testbed consisting of an environment simulator and\ndemonstrations of human operation concerning pump scheduling of a real-world\nwater distribution facility to facilitate research. The pump scheduling problem\ncan be viewed as a decision process to decide when to operate pumps to supply\nwater while limiting electricity consumption and meeting system constraints. To\nprovide a starting point, we release a well-documented codebase, present an\noverview of some challenges that can be addressed and provide a baseline\nrepresentation of the problem. The code and dataset are available at\nhttps://gitlab.com/hdonancio/pumpscheduling.",
    "descriptor": "",
    "authors": [
      "Henrique Don\u00e2ncio",
      "Laurent Vercouter",
      "Harald Roclawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11111"
  },
  {
    "id": "arXiv:2210.11113",
    "title": "PAC-Bayesian Learning of Optimization Algorithms",
    "abstract": "We apply the PAC-Bayes theory to the setting of learning-to-optimize. To the\nbest of our knowledge, we present the first framework to learn optimization\nalgorithms with provable generalization guarantees (PAC-bounds) and explicit\ntrade-off between a high probability of convergence and a high convergence\nspeed. Even in the limit case, where convergence is guaranteed, our learned\noptimization algorithms provably outperform related algorithms based on a\n(deterministic) worst-case analysis. Our results rely on PAC-Bayes bounds for\ngeneral, unbounded loss-functions based on exponential families. By\ngeneralizing existing ideas, we reformulate the learning procedure into a\none-dimensional minimization problem and study the possibility to find a global\nminimum, which enables the algorithmic realization of the learning procedure.\nAs a proof-of-concept, we learn hyperparameters of standard optimization\nalgorithms to empirically underline our theory.",
    "descriptor": "\nComments: 10 pages main text, 5 pages appendix, 2 pages references, 4 figures\n",
    "authors": [
      "Michael Sucker",
      "Peter Ochs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11113"
  },
  {
    "id": "arXiv:2210.11114",
    "title": "Pruning by Active Attention Manipulation",
    "abstract": "Filter pruning of a CNN is typically achieved by applying discrete masks on\nthe CNN's filter weights or activation maps, post-training. Here, we present a\nnew filter-importance-scoring concept named pruning by active attention\nmanipulation (PAAM), that sparsifies the CNN's set of filters through a\nparticular attention mechanism, during-training. PAAM learns analog filter\nscores from the filter weights by optimizing a cost function regularized by an\nadditive term in the scores. As the filters are not independent, we use\nattention to dynamically learn their correlations. Moreover, by training the\npruning scores of all layers simultaneously, PAAM can account for layer\ninter-dependencies, which is essential to finding a performant sparse\nsub-network. PAAM can also train and generate a pruned network from scratch in\na straightforward, one-stage training process without requiring a pre-trained\nnetwork. Finally, PAAM does not need layer-specific hyperparameters and\npre-defined layer budgets, since it can implicitly determine the appropriate\nnumber of filters in each layer. Our experimental results on different network\narchitectures suggest that PAAM outperforms state-of-the-art structured-pruning\nmethods (SOTA). On CIFAR-10 dataset, without requiring a pre-trained baseline\nnetwork, we obtain 1.02% and 1.19% accuracy gain and 52.3% and 54% parameters\nreduction, on ResNet56 and ResNet110, respectively. Similarly, on the ImageNet\ndataset, PAAM achieves 1.06% accuracy gain while pruning 51.1% of the\nparameters on ResNet50. For Cifar-10, this is better than the SOTA with a\nmargin of 9.5% and 6.6%, respectively, and on ImageNet with a margin of 11%.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.07412\n",
    "authors": [
      "Zahra Babaiee",
      "Lucas Liebenwein",
      "Ramin Hasani",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.11114"
  },
  {
    "id": "arXiv:2210.11119",
    "title": "Minimum Age of Information in Internet of Things with Opportunistic  Channel Access",
    "abstract": "This paper investigates an Internet of Things (IoT) system in which multiple\ndevices are observing some object's physical parameters and then offloading\ntheir observations back to the BS in time with opportunistic channel access.\nSpecifically, each device accesses the common channel through contention with a\ncertain probability firstly and then the winner evaluates the instant channel\ncondition and decides to accept the right of channel access or not. We analyze\nthis system through the perspective of Age of Information (AoI), which\ndescribes the freshness of observed information. The target is to minimize\naverage AoI by optimizing the probability of device participation in contention\nand the transmission rate threshold. The problem is hard to solve since the AoI\nexpression in fractional form is complex. We first decompose the original\nproblem into two single-variable optimization sub-problems through Dinkelbach\nmethod and Block Coordinate Descent (BCD) method. And then we transform them to\nMonotonic optimization problems by proving the monotonicity of the objective\nfunctions, whose global optimal solution is able to be found through Polyblock\nalgorithm. Numerical results verify the validity of our proposed method.",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Rongfei Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11119"
  },
  {
    "id": "arXiv:2210.11124",
    "title": "Forest: Structural Code Editing with Multiple Cursors",
    "abstract": "Software developers frequently refactor code. Often, a single logical\nrefactoring change involves changing multiple related components in a source\nbase such as renaming each occurrence of a variable or function. While many\ncode editors can perform such common and generic refactorings, they do not\nsupport more complex refactorings or those that are specific to a given code\nbase. For those, as a flexible - albeit less interactive - alternative,\ndevelopers can write refactoring scripts that can implement arbitrarily complex\nlogic by manipulating the program's tree representation. In this work, we\npresent Forest, a structural code editor that aims to bridge the gap between\nthe interactiveness of code editors and the expressiveness of refactoring\nscripts. While structural editors have occupied a niche as general code\neditors, the key insight of this work is that they enable a novel structural\nmulti-cursor design that allows Forest to reach a similar expressiveness as\nrefactoring scripts; Forest allows to perform a single action simultaneously in\nmultiple program locations and thus support complex refactorings. To support\ninteractivity, Forest provides features typical for text code editors such as\nwriting and displaying the program through its textual representation. Our\nevaluation demonstrates that Forest allows performing edits similar to those\nfrom refactoring scripts, while still being interactive. We attempted to\nperform edits from 48 real-world refactoring scripts using Forest and found\nthat 11 were possible, while another 17 would be possible with added features.\nWe believe that a multi-cursor setting plays to the strengths of structural\nediting, since it benefits from reliable and expressive commands. Our results\nsuggest that multi-cursor structural editors could be practical for performing\nsmall-scale specialized refactorings.",
    "descriptor": "\nComments: To be published in \"Onward! '22: 2022 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software Proceedings\"\n",
    "authors": [
      "Philippe Voinov",
      "Manuel Rigger",
      "Zhendong Su"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11124"
  },
  {
    "id": "arXiv:2210.11126",
    "title": "Co-Training an Observer and an Evading Target",
    "abstract": "Reinforcement learning (RL) is already widely applied to applications such as\nrobotics, but it is only sparsely used in sensor management. In this paper, we\napply the popular Proximal Policy Optimization (PPO) approach to a multi-agent\nUAV tracking scenario. While recorded data of real scenarios can accurately\nreflect the real world, the required amount of data is not always available.\nSimulation data, however, is typically cheap to generate, but the utilized\ntarget behavior is often naive and only vaguely represents the real world. In\nthis paper, we utilize multi-agent RL to jointly generate protagonistic and\nantagonistic policies and overcome the data generation problem, as the policies\nare generated on-the-fly and adapt continuously. This way, we are able to\nclearly outperform baseline methods and robustly generate competitive policies.\nIn addition, we investigate explainable artificial intelligence (XAI) by\ninterpreting feature saliency and generating an easy-to-read decision tree as a\nsimplified policy.",
    "descriptor": "\nComments: Accepted for IEEE 24th International Conference on Information Fusion (FUSION 2021)\n",
    "authors": [
      "Andr\u00e9 Brandenburger",
      "Folker Hoffmann",
      "Alexander Charlish"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11126"
  },
  {
    "id": "arXiv:2210.11129",
    "title": "Super-Resolution and Image Re-projection for Iris Recognition",
    "abstract": "Several recent works have addressed the ability of deep learning to disclose\nrich, hierarchical and discriminative models for the most diverse purposes.\nSpecifically in the super-resolution field, Convolutional Neural Networks\n(CNNs) using different deep learning approaches attempt to recover realistic\ntexture and fine grained details from low resolution images. In this work we\nexplore the viability of these approaches for iris Super-Resolution (SR) in an\niris recognition environment. For this, we test different architectures with\nand without a so called image re-projection to reduce artifacts applying it to\ndifferent iris databases to verify the viability of the different CNNs for iris\nsuper-resolution. Results show that CNNs and image re-projection can improve\nthe results specially for the accuracy of recognition systems using a complete\ndifferent training database performing the transfer learning successfully.",
    "descriptor": "\nComments: Published at IEEE International Conference on Identity, Security and Behavior Analysis, ISBA 2019\n",
    "authors": [
      "Eduardo Ribeiro",
      "Andreas Uhl",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11129"
  },
  {
    "id": "arXiv:2210.11135",
    "title": "On-line signature verification using Tablet PC",
    "abstract": "On-line signature verification for Tablet PC devices is studied. The on-line\nsignature verification algorithm presented by the authors at the First\nInternational Signature Verification Competition (SVC 2004) is adapted to work\nin Tablet PC environments. An example prototype of securing access and securing\ndocument application using this Tablet PC system is also reported. Two\ndifferent commercial Tablet PCs are evaluated, including information of\ninterest for signature verification systems such as sampling and pressure\nstatistics. Authentication performance experiments are reported considering\nboth random and skilled forgeries by using a new database with over 3000\nsignatures.",
    "descriptor": "\nComments: Published at 4th International Symposium on Image and Signal Processing and Analysis, ISPA 2005\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Julian Fierrez-Aguilar",
      "Francisco del-Valle",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11135"
  },
  {
    "id": "arXiv:2210.11137",
    "title": "Trust Region Policy Optimization with Optimal Transport Discrepancies:  Duality and Algorithm for Continuous Actions",
    "abstract": "Policy Optimization (PO) algorithms have been proven particularly suited to\nhandle the high-dimensionality of real-world continuous control tasks. In this\ncontext, Trust Region Policy Optimization methods represent a popular approach\nto stabilize the policy updates. These usually rely on the Kullback-Leibler\n(KL) divergence to limit the change in the policy. The Wasserstein distance\nrepresents a natural alternative, in place of the KL divergence, to define\ntrust regions or to regularize the objective function. However,\nstate-of-the-art works either resort to its approximations or do not provide an\nalgorithm for continuous state-action spaces, reducing the applicability of the\nmethod. In this paper, we explore optimal transport discrepancies (which\ninclude the Wasserstein distance) to define trust regions, and we propose a\nnovel algorithm - Optimal Transport Trust Region Policy Optimization (OT-TRPO)\n- for continuous state-action spaces. We circumvent the infinite-dimensional\noptimization problem for PO by providing a one-dimensional dual reformulation\nfor which strong duality holds. We then analytically derive the optimal policy\nupdate given the solution of the dual problem. This way, we bypass the\ncomputation of optimal transport costs and of optimal transport maps, which we\nimplicitly characterize by solving the dual formulation. Finally, we provide an\nexperimental evaluation of our approach across various control tasks. Our\nresults show that optimal transport discrepancies can offer an advantage over\nstate-of-the-art approaches.",
    "descriptor": "\nComments: Accepted for presentation at, and publication in the proceedings of, the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Antonio Terpin",
      "Nicolas Lanzetti",
      "Batuhan Yardim",
      "Florian D\u00f6rfler",
      "Giorgia Ramponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11137"
  },
  {
    "id": "arXiv:2210.11139",
    "title": "Sensor interoperability and fusion in signature verification: A case  study using tablet PC",
    "abstract": "Several works related to information fusion for signature verification have\nbeen presented. However, few works have focused on sensor fusion and sensor\ninteroperability. In this paper, these two topics are evaluated for signature\nverification using two different commercial Tablet PCs. An enrolment strategy\nusing signatures from the two Tablet PCs is also proposed. Authentication\nperformance experiments are reported by using a database with over 3000\nsignatures.",
    "descriptor": "\nComments: Published at Intl. Workshop on Biometric Recognition Systems, IWBRS 2005\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Julian Fierrez-Aguilar",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11139"
  },
  {
    "id": "arXiv:2210.11141",
    "title": "General Image Descriptors for Open World Image Retrieval using ViT CLIP",
    "abstract": "The Google Universal Image Embedding (GUIE) Challenge is one of the first\ncompetitions in multi-domain image representations in the wild, covering a wide\ndistribution of objects: landmarks, artwork, food, etc. This is a fundamental\ncomputer vision problem with notable applications in image retrieval, search\nengines and e-commerce. In this work, we explain our 4th place solution to the\nGUIE Challenge, and our \"bag of tricks\" to fine-tune zero-shot Vision\nTransformers (ViT) pre-trained using CLIP.",
    "descriptor": "\nComments: ECCV 2022 Instance-Level Recognition Workshop\n",
    "authors": [
      "Marcos V. Conde",
      "Ivan Aerlic",
      "Simon J\u00e9gou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11141"
  },
  {
    "id": "arXiv:2210.11146",
    "title": "Reproducibility of the Methods in Medical Imaging with Deep Learning",
    "abstract": "Concerns about the reproducibility of deep learning research are more\nprominent than ever, with no clear solution in sight. The relevance of machine\nlearning research can only be improved if we also employ empirical rigor that\nincorporates reproducibility guidelines, especially so in the medical imaging\nfield. The Medical Imaging with Deep Learning (MIDL) conference has made\nadvancements in this direction by advocating open access, and recently also\nrecommending authors to make their code public - both aspects being adopted by\nthe majority of the conference submissions. This helps the reproducibility of\nthe methods, however, there is currently little or no support for further\nevaluation of these supplementary material, making them vulnerable to poor\nquality, which affects the impact of the entire submission. We have evaluated\nall accepted full paper submissions to MIDL between 2018 and 2022 using\nestablished, but slightly adjusted guidelines on reproducibility and the\nquality of the public repositories. The evaluations show that publishing\nrepositories and using public datasets are becoming more popular, which helps\ntraceability, but the quality of the repositories has not improved over the\nyears, leaving room for improvement in every aspect of designing repositories.\nMerely 22% of all submissions contain a repository that were deemed repeatable\nusing our evaluations. From the commonly encountered issues during the\nevaluations, we propose a set of guidelines for machine learning-related\nresearch for medical imaging applications, adjusted specifically for future\nsubmissions to MIDL.",
    "descriptor": "",
    "authors": [
      "Attila Simko",
      "Anders Garpebring",
      "Joakim Jonsson",
      "Tufve Nyholm",
      "Tommy L\u00f6fstedt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.11146"
  },
  {
    "id": "arXiv:2210.11151",
    "title": "Transformer-based Entity Typing in Knowledge Graphs",
    "abstract": "We investigate the knowledge graph entity typing task which aims at inferring\nplausible entity types. In this paper, we propose a novel Transformer-based\nEntity Typing (TET) approach, effectively encoding the content of neighbors of\nan entity. More precisely, TET is composed of three different mechanisms: a\nlocal transformer allowing to infer missing types of an entity by independently\nencoding the information provided by each of its neighbors; a global\ntransformer aggregating the information of all neighbors of an entity into a\nsingle long sequence to reason about more complex entity types; and a context\ntransformer integrating neighbors content based on their contribution to the\ntype inference through information exchange between neighbor pairs.\nFurthermore, TET uses information about class membership of types to\nsemantically strengthen the representation of an entity. Experiments on two\nreal-world datasets demonstrate the superior performance of TET compared to the\nstate-of-the-art.",
    "descriptor": "\nComments: Paper accepted at EMNLP 2022\n",
    "authors": [
      "Zhiwei Hu",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11151"
  },
  {
    "id": "arXiv:2210.11158",
    "title": "VideoPipe 2022 Challenge: Real-World Video Understanding for Urban Pipe  Inspection",
    "abstract": "Video understanding is an important problem in computer vision. Currently,\nthe well-studied task in this research is human action recognition, where the\nclips are manually trimmed from the long videos, and a single class of human\naction is assumed for each clip. However, we may face more complicated\nscenarios in the industrial applications. For example, in the real-world urban\npipe system, anomaly defects are fine-grained, multi-labeled, domain-relevant.\nTo recognize them correctly, we need to understand the detailed video content.\nFor this reason, we propose to advance research areas of video understanding,\nwith a shift from traditional action recognition to industrial anomaly\nanalysis. In particular, we introduce two high-quality video benchmarks, namely\nQV-Pipe and CCTV-Pipe, for anomaly inspection in the real-world urban pipe\nsystems. Based on these new datasets, we will host two competitions including\n(1) Video Defect Classification on QV-Pipe and (2) Temporal Defect Localization\non CCTV-Pipe. In this report, we describe the details of these benchmarks, the\nproblem definitions of competition tracks, the evaluation metric, and the\nresult summary. We expect that, this competition would bring new opportunities\nand challenges for video understanding in smart city and beyond. The details of\nour VideoPipe challenge can be found in https://videopipe.github.io.",
    "descriptor": "\nComments: VideoPipe Challenge @ ICPR2022. Homepage: this https URL\n",
    "authors": [
      "Yi Liu",
      "Xuan Zhang",
      "Ying Li",
      "Guixin Liang",
      "Yabing Jiang",
      "Lixia Qiu",
      "Haiping Tang",
      "Fei Xie",
      "Wei Yao",
      "Yi Dai",
      "Yu Qiao",
      "Yali Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11158"
  },
  {
    "id": "arXiv:2210.11161",
    "title": "From Modelling to Understanding Children's Behaviour in the Context of  Robotics and Social Artificial Intelligence",
    "abstract": "Understanding and modelling children's cognitive processes and their\nbehaviour in the context of their interaction with robots and social artificial\nintelligence systems is a fundamental prerequisite for meaningful and effective\nrobot interventions. However, children's development involve complex faculties\nsuch as exploration, creativity and curiosity which are challenging to model.\nAlso, often children express themselves in a playful way which is different\nfrom a typical adult behaviour. Different children also have different needs,\nand it remains a challenge in the current state of the art that those of\nneurodiverse children are under-addressed. With this workshop, we aim to\npromote a common ground among different disciplines such as developmental\nsciences, artificial intelligence and social robotics and discuss cutting-edge\nresearch in the area of user modelling and adaptive systems for children.",
    "descriptor": "\nComments: Accepted proposal for a workshop to be held in conjunction with the 14th International Conference on Social Robotics (ICSR'22)\n",
    "authors": [
      "Serge Thill",
      "Vicky Charisi",
      "Tony Belpaeme",
      "Ana Paiva"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11161"
  },
  {
    "id": "arXiv:2210.11164",
    "title": "Graph Neural Networks with Trainable Adjacency Matrices for Fault  Diagnosis on Multivariate Sensor Data",
    "abstract": "Timely detected anomalies in the chemical technological processes, as well as\nthe earliest detection of the cause of the fault, significantly reduce the\nproduction cost in the industrial factories. Data on the state of the\ntechnological process and the operation of production equipment are received by\na large number of different sensors. To better predict the behavior of the\nprocess and equipment, it is necessary not only to consider the behavior of the\nsignals in each sensor separately, but also to take into account their\ncorrelation and hidden relationships with each other. Graph-based data\nrepresentation helps with this. The graph nodes can be represented as data from\nthe different sensors, and the edges can display the influence of these data on\neach other. In this work, the possibility of applying graph neural networks to\nthe problem of fault diagnosis in a chemical process is studied. It was\nproposed to construct a graph during the training of graph neural network. This\nallows to train models on data where the dependencies between the sensors are\nnot known in advance. In this work, several methods for obtaining adjacency\nmatrices were considered, as well as their quality was studied. It has also\nbeen proposed to use multiple adjacency matrices in one model. We showed\nstate-of-the-art performance on the fault diagnosis task with the Tennessee\nEastman Process dataset. The proposed graph neural networks outperformed the\nresults of recurrent neural networks.",
    "descriptor": "",
    "authors": [
      "Alexander Kovalenko",
      "Vitaliy Pozdnyakov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11164"
  },
  {
    "id": "arXiv:2210.11165",
    "title": "Pre-training Language Models with Deterministic Factual Knowledge",
    "abstract": "Previous works show that Pre-trained Language Models (PLMs) can capture\nfactual knowledge. However, some analyses reveal that PLMs fail to perform it\nrobustly, e.g., being sensitive to the changes of prompts when extracting\nfactual knowledge. To mitigate this issue, we propose to let PLMs learn the\ndeterministic relationship between the remaining context and the masked\ncontent. The deterministic relationship ensures that the masked factual content\ncan be deterministically inferable based on the existing clues in the context.\nThat would provide more stable patterns for PLMs to capture factual knowledge\nthan randomly masking. Two pre-training tasks are further introduced to\nmotivate PLMs to rely on the deterministic relationship when filling masks.\nSpecifically, we use an external Knowledge Base (KB) to identify deterministic\nrelationships and continuously pre-train PLMs with the proposed methods. The\nfactual knowledge probing experiments indicate that the continuously\npre-trained PLMs achieve better robustness in factual knowledge capturing.\nFurther experiments on question-answering datasets show that trying to learn a\ndeterministic relationship with the proposed methods can also help other\nknowledge-intensive tasks.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Shaobo Li",
      "Xiaoguang Li",
      "Lifeng Shang",
      "Chengjie Sun",
      "Bingquan Liu",
      "Zhenzhou Ji",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11165"
  },
  {
    "id": "arXiv:2210.11166",
    "title": "Dude, where's my NFT? Distributed Infrastructures for Digital Art",
    "abstract": "We explore issues relating to the storage of digital art, based on an\nempirical investigation into the storage of audiovisual data referenced by\nnon-fungible tokens (NFTs). We identify current trends in NFT data storage and\nhighlight problems with implemented solutions. We particularly focus our\ninvestigation on the use of the Interplanetary Filesystem (IPFS), which emerges\nas a popular and versatile distributed storage solution for NFTs. Based on the\nanalysis of discovered data storage techniques, we propose a set of best\npractices to ensure long-term storage survivability of NFT data. While helpful\nfor forming the NFT art market into a legitimate long-term environment for\ndigital art, our recommendations are also directly applicable for improving the\navailability and integrity of non-NFT digital art.",
    "descriptor": "\nComments: To be presented at the DICG Workshop 2022\n",
    "authors": [
      "Leonhard Balduf",
      "Martin Florian",
      "Bj\u00f6rn Scheuermann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.11166"
  },
  {
    "id": "arXiv:2210.11168",
    "title": "User Value in Modern Payment Platforms: A Graph Approach",
    "abstract": "Payment platforms have significantly evolved in recent years to keep pace\nwith the proliferation of online and cashless payments. These platforms are\nincreasingly aligned with online social networks, allowing users to interact\nwith each other and transfer small amounts of money in a Peer-to-Peer fashion.\nThis poses new challenges for analysing payment data, as traditional methods\nare only user-centric or business-centric and neglect the network users build\nduring the interaction. This paper proposes a first methodology for measuring\nuser value in modern payment platforms. We combine quantitative user-centric\nmetrics with an analysis of the graph created by users' activities and its\ntopological features inspired by the evolution of opinions in social networks.\nWe showcase our approach using a dataset from a large operational payment\nplatform and show how it can support business decisions and marketing campaign\ndesign, e.g., by targeting specific users.",
    "descriptor": "\nComments: 8 pages, 11 figures. Accepted for presentation at the 22nd IEEE International Conference on Data Mining (IEEE ICDM 2022)\n",
    "authors": [
      "Laura Arditti",
      "Martino Trevisan",
      "Luca Vassio",
      "Alberto De Lazzari",
      "Alberto Danese"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11168"
  },
  {
    "id": "arXiv:2210.11169",
    "title": "Content-based Graph Privacy Advisor",
    "abstract": "People may be unaware of the privacy risks of uploading an image online. In\nthis paper, we present an image privacy classifier that uses scene information\nand object cardinality as cues for the prediction of image privacy. Our Graph\nPrivacy Advisor (GPA) model simplifies a state-of-the-art graph model and\nimproves its performance by refining the relevance of the content-based\ninformation extracted from the image. We determine the most informative visual\nfeatures to be used for the privacy classification task and reduce the\ncomplexity of the model by replacing high-dimensional image-based feature\nvectors with lower-dimensional, more effective features. We also address the\nbiased prior information by modelling object co-occurrences instead of the\nfrequency of object occurrences in each class.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to BigMM conference\n",
    "authors": [
      "Dimitrios Stoidis",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11169"
  },
  {
    "id": "arXiv:2210.11170",
    "title": "Coordinates Are NOT Lonely -- Codebook Prior Helps Implicit Neural 3D  Representations",
    "abstract": "Implicit neural 3D representation has achieved impressive results in surface\nor scene reconstruction and novel view synthesis, which typically uses the\ncoordinate-based multi-layer perceptrons (MLPs) to learn a continuous scene\nrepresentation. However, existing approaches, such as Neural Radiance Field\n(NeRF) and its variants, usually require dense input views (i.e. 50-150) to\nobtain decent results. To relive the over-dependence on massive calibrated\nimages and enrich the coordinate-based feature representation, we explore\ninjecting the prior information into the coordinate-based network and introduce\na novel coordinate-based model, CoCo-INR, for implicit neural 3D\nrepresentation. The cores of our method are two attention modules: codebook\nattention and coordinate attention. The former extracts the useful prototypes\ncontaining rich geometry and appearance information from the prior codebook,\nand the latter propagates such prior information into each coordinate and\nenriches its feature representation for a scene or object surface. With the\nhelp of the prior information, our method can render 3D views with more\nphoto-realistic appearance and geometries than the current methods using fewer\ncalibrated images available. Experiments on various scene reconstruction\ndatasets, including DTU and BlendedMVS, and the full 3D head reconstruction\ndataset, H3DS, demonstrate the robustness under fewer input views and fine\ndetail-preserving capability of our proposed method.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Fukun Yin",
      "Wen Liu",
      "Zilong Huang",
      "Pei Cheng",
      "Tao Chen",
      "Gang YU"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11170"
  },
  {
    "id": "arXiv:2210.11171",
    "title": "On the Automation, Optimization, and In-Orbit Validation of Intelligent  Satellite Constellation Operations",
    "abstract": "Recent breakthroughs in technology have led to a thriving \"new space\" culture\nin low-Earth orbit (LEO) in which performance and cost considerations dominate\nover resilience and reliability as mission goals. These advances create a\nmanifold of opportunities for new research and business models but come with a\nnumber of striking new challenges. In particular, the size and weight\nlimitations of low-Earth orbit small satellites make their successful operation\nrest on a fine balance between solar power infeed and the power demands of the\nmission payload and supporting platform technologies, buffered by on-board\nbattery storage. At the same time, these satellites are being rolled out as\npart of ever-larger constellations and mega-constellations. Altogether, this\ninduces a number of challenging computational problems related to the recurring\nneed to make decisions about which task each satellite is to effectuate next.\nAgainst this background, GomSpace and Saarland University have joined forces to\ndevelop highly sophisticated software-based automated solutions rooted in\noptimal algorithmic and self-improving learning techniques, all this validated\nin modern nanosatellite networked missions operating in orbit.",
    "descriptor": "\nComments: This is an author-generated technical report of a paper published in the Small Satellite Conference 2021\n",
    "authors": [
      "Gregory Stock",
      "Juan A. Fraire",
      "Holger Hermanns",
      "Eduardo Cruz",
      "Alastair Isaacs",
      "Zhana Imbrosh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11171"
  },
  {
    "id": "arXiv:2210.11173",
    "title": "Mathematical Justification of Hard Negative Mining via Isometric  Approximation Theorem",
    "abstract": "In deep metric learning, the Triplet Loss has emerged as a popular method to\nlearn many computer vision and natural language processing tasks such as facial\nrecognition, object detection, and visual-semantic embeddings. One issue that\nplagues the Triplet Loss is network collapse, an undesirable phenomenon where\nthe network projects the embeddings of all data onto a single point.\nResearchers predominately solve this problem by using triplet mining\nstrategies. While hard negative mining is the most effective of these\nstrategies, existing formulations lack strong theoretical justification for\ntheir empirical success. In this paper, we utilize the mathematical theory of\nisometric approximation to show an equivalence between the Triplet Loss sampled\nby hard negative mining and an optimization problem that minimizes a\nHausdorff-like distance between the neural network and its ideal counterpart\nfunction. This provides the theoretical justifications for hard negative\nmining's empirical efficacy. In addition, our novel application of the\nisometric approximation theorem provides the groundwork for future forms of\nhard negative mining that avoid network collapse. Our theory can also be\nextended to analyze other Euclidean space-based metric learning methods like\nLadder Loss or Contrastive Learning.",
    "descriptor": "\nComments: 9 pages, 6 figures, submitted to AAAI 2023\n",
    "authors": [
      "Albert Xu",
      "Jhih-Yi Hsieh",
      "Bhaskar Vundurthy",
      "Eliana Cohen",
      "Howie Choset",
      "Lu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11173"
  },
  {
    "id": "arXiv:2210.11174",
    "title": "Overlapping Community Detection using Dynamic Dilated Aggregation in  Deep Residual GCN",
    "abstract": "Overlapping community detection is a key problem in graph mining. Some\nresearch has considered applying graph convolutional networks (GCN) to tackle\nthe problem. However, it is still challenging to incorporate deep graph\nconvolutional networks in the case of general irregular graphs. In this study,\nwe design a deep dynamic residual graph convolutional network (DynaResGCN)\nbased on our novel dynamic dilated aggregation mechanisms and a unified\nend-to-end encoder-decoder-based framework to detect overlapping communities in\nnetworks. The deep DynaResGCN model is used as the encoder, whereas we\nincorporate the Bernoulli-Poisson (BP) model as the decoder. Consequently, we\napply our overlapping community detection framework in a research topics\ndataset without having ground truth, a set of networks from Facebook having a\nreliable (hand-labeled) ground truth, and in a set of very large co-authorship\nnetworks having empirical (not hand-labeled) ground truth. Our experimentation\non these datasets shows significantly superior performance over many\nstate-of-the-art methods for the detection of overlapping communities in\nnetworks.",
    "descriptor": "",
    "authors": [
      "Md Nurul Muttakin",
      "Md Iqbal Hossain",
      "Md Saidur Rahman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11174"
  },
  {
    "id": "arXiv:2210.11175",
    "title": "Structure-Preserving Discretization of Fractional Vector Calculus using  Discrete Exterior Calculus",
    "abstract": "Fractional vector calculus is the building block of the fractional partial\ndifferential equations that model non-local or long-range phenomena, e.g.,\nanomalous diffusion, fractional electromagnetism, and fractional\nadvection-dispersion. In this work, we reformulate a type of fractional vector\ncalculus that uses Caputo fractional partial derivatives and discretize this\nreformulation using discrete exterior calculus on a cubical complex in the\nstructure-preserving way, meaning that the continuous-level properties\n$\\operatorname{curl}^\\alpha \\operatorname{grad}^\\alpha = \\mathbf{0}$ and\n$\\operatorname{div}^\\alpha \\operatorname{curl}^\\alpha = 0$ hold exactly on the\ndiscrete level. We discuss important properties of our fractional discrete\nexterior derivatives and verify their second-order convergence in the root mean\nsquare error numerically. Our proposed discretization has the potential to\nprovide accurate and stable numerical solutions to fractional partial\ndifferential equations and exactly preserve fundamental physics laws on the\ndiscrete level regardless of the mesh size.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Alon Jacobson",
      "Xiaozhe Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11175"
  },
  {
    "id": "arXiv:2210.11177",
    "title": "Towards Better Guided Attention and Human Knowledge Insertion in Deep  Convolutional Neural Networks",
    "abstract": "Attention Branch Networks (ABNs) have been shown to simultaneously provide\nvisual explanation and improve the performance of deep convolutional neural\nnetworks (CNNs). In this work, we introduce Multi-Scale Attention Branch\nNetworks (MSABN), which enhance the resolution of the generated attention maps,\nand improve the performance. We evaluate MSABN on benchmark image recognition\nand fine-grained recognition datasets where we observe MSABN outperforms ABN\nand baseline models. We also introduce a new data augmentation strategy\nutilizing the attention maps to incorporate human knowledge in the form of\nbounding box annotations of the objects of interest. We show that even with a\nlimited number of edited samples, a significant performance gain can be\nachieved with this strategy.",
    "descriptor": "",
    "authors": [
      "Ankit Gupta",
      "Ida-Maria Sintorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11177"
  },
  {
    "id": "arXiv:2210.11179",
    "title": "Multi-hypothesis 3D human pose estimation metrics favor miscalibrated  distributions",
    "abstract": "Due to depth ambiguities and occlusions, lifting 2D poses to 3D is a highly\nill-posed problem. Well-calibrated distributions of possible poses can make\nthese ambiguities explicit and preserve the resulting uncertainty for\ndownstream tasks. This study shows that previous attempts, which account for\nthese ambiguities via multiple hypotheses generation, produce miscalibrated\ndistributions. We identify that miscalibration can be attributed to the use of\nsample-based metrics such as minMPJPE. In a series of simulations, we show that\nminimizing minMPJPE, as commonly done, should converge to the correct mean\nprediction. However, it fails to correctly capture the uncertainty, thus\nresulting in a miscalibrated distribution. To mitigate this problem, we propose\nan accurate and well-calibrated model called Conditional Graph Normalizing Flow\n(cGNFs). Our model is structured such that a single cGNF can estimate both\nconditional and marginal densities within the same model - effectively solving\na zero-shot density estimation problem. We evaluate cGNF on the Human~3.6M\ndataset and show that cGNF provides a well-calibrated distribution estimate\nwhile being close to state-of-the-art in terms of overall minMPJPE.\nFurthermore, cGNF outperforms previous methods on occluded joints while it\nremains well-calibrated.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Pawe\u0142 A. Pierzchlewicz",
      "R. James Cotton",
      "Mohammad Bashiri",
      "Fabian H. Sinz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11179"
  },
  {
    "id": "arXiv:2210.11182",
    "title": "Facial Expression Video Generation Based-On Spatio-temporal  Convolutional GAN: FEV-GAN",
    "abstract": "Facial expression generation has always been an intriguing task for\nscientists and researchers all over the globe. In this context, we present our\nnovel approach for generating videos of the six basic facial expressions.\nStarting from a single neutral facial image and a label indicating the desired\nfacial expression, we aim to synthesize a video of the given identity\nperforming the specified facial expression. Our approach, referred to as\nFEV-GAN (Facial Expression Video GAN), is based on Spatio-temporal\nConvolutional GANs, that are known to model both content and motion in the same\nnetwork. Previous methods based on such a network have shown a good ability to\ngenerate coherent videos with smooth temporal evolution. However, they still\nsuffer from low image quality and low identity preservation capability. In this\nwork, we address this problem by using a generator composed of two image\nencoders. The first one is pre-trained for facial identity feature extraction\nand the second for spatial feature extraction. We have qualitatively and\nquantitatively evaluated our model on two international facial expression\nbenchmark databases: MUG and Oulu-CASIA NIR&VIS. The experimental results\nanalysis demonstrates the effectiveness of our approach in generating videos of\nthe six basic facial expressions while preserving the input identity. The\nanalysis also proves that the use of both identity and spatial features\nenhances the decoder ability to better preserve the identity and generate\nhigh-quality videos. The code and the pre-trained model will soon be made\npublicly available.",
    "descriptor": "\nComments: 13 pages, 8 figures, accepted in ISWA journal\n",
    "authors": [
      "Hamza Bouzid",
      "Lahoucine Ballihi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11182"
  },
  {
    "id": "arXiv:2210.11185",
    "title": "Using Integer Programming Techniques in Real-Time Scheduling Analysis",
    "abstract": "Real-time scheduling theory assists developers of embedded systems in\nverifying that the timing constraints required by critical software tasks can\nbe feasibly met on a given hardware platform. Fundamental problems in the\ntheory are often formulated as search problems for fixed points of functions\nand are solved by fixed-point iterations. These fixed-point methods are used\nwidely because they are simple to understand, simple to implement, and seem to\nwork well in practice. These fundamental problems can also be formulated as\ninteger programs and solved with algorithms that are based on theories of\nlinear programming and cutting planes amongst others. However, such algorithms\nare harder to understand and implement than fixed-point iterations. In this\nresearch, we show that ideas like linear programming duality and cutting planes\ncan be used to develop algorithms that are as easy to implement as existing\nfixed-point iteration schemes but have better convergence properties. We\nevaluate the algorithms on synthetically generated problem instances to\ndemonstrate that the new algorithms are faster than the existing algorithms.",
    "descriptor": "",
    "authors": [
      "Abhishek Singh"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11185"
  },
  {
    "id": "arXiv:2210.11190",
    "title": "Integration of Neuromorphic AI in Event-Driven Distributed Digitized  Systems: Concepts and Research Directions",
    "abstract": "Increasing complexity and data-generation rates in cyber-physical systems and\nthe industrial Internet of things are calling for a corresponding increase in\nAI capabilities at the resource-constrained edges of the Internet. Meanwhile,\nthe resource requirements of digital computing and deep learning are growing\nexponentially, in an unsustainable manner. One possible way to bridge this gap\nis the adoption of resource-efficient brain-inspired \"neuromorphic\" processing\nand sensing devices, which use event-driven, asynchronous, dynamic\nneurosynaptic elements with colocated memory for distributed processing and\nmachine learning. However, since neuromorphic systems are fundamentally\ndifferent from conventional von Neumann computers and clock-driven sensor\nsystems, several challenges are posed to large-scale adoption and integration\nof neuromorphic devices into the existing distributed digital-computational\ninfrastructure. Here, we describe the current landscape of neuromorphic\ncomputing, focusing on characteristics that pose integration challenges. Based\non this analysis, we propose a microservice-based framework for neuromorphic\nsystems integration, consisting of a neuromorphic-system proxy, which provides\nvirtualization and communication capabilities required in distributed systems\nof systems, in combination with a declarative programming approach offering\nengineering-process abstraction. We also present concepts that could serve as a\nbasis for the realization of this framework, and identify directions for\nfurther research required to enable large-scale system integration of\nneuromorphic devices.",
    "descriptor": "",
    "authors": [
      "Mattias Nilsson",
      "Olov Schel\u00e9n",
      "Anders Lindgren",
      "Ulf Bodin",
      "Cristina Paniagua",
      "Jerker Delsing",
      "Fredrik Sandin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.11190"
  },
  {
    "id": "arXiv:2210.11194",
    "title": "Towards Mitigating the Problem of Insufficient and Ambiguous Supervision  in Online Crowdsourcing Annotation",
    "abstract": "In real-world crowdsourcing annotation systems, due to differences in user\nknowledge and cultural backgrounds, as well as the high cost of acquiring\nannotation information, the supervision information we obtain might be\ninsufficient and ambiguous. To mitigate the negative impacts, in this paper, we\ninvestigate a more general and broadly applicable learning problem, i.e.\n\\emph{semi-supervised partial label learning}, and propose a novel method based\non pseudo-labeling and contrastive learning. Following the key inventing\nprinciple, our method facilitate the partial label disambiguation process with\nunlabeled data and at the same time assign reliable pseudo-labels to weakly\nsupervised examples. Specifically, our method learns from the ambiguous\nlabeling information via partial cross-entropy loss. Meanwhile, high-accuracy\npseudo-labels are generated for both partial and unlabeled examples through\nconfidence-based thresholding and contrastive learning is performed in a hybrid\nunsupervised and supervised manner for more discriminative representations,\nwhile its supervision increases curriculumly. The two main components\nsystematically work as a whole and reciprocate each other. In experiments, our\nmethod consistently outperforms all comparing methods by a significant margin\nand set up the first state-of-the-art performance for semi-supervised partial\nlabel learning on image benchmarks.",
    "descriptor": "",
    "authors": [
      "Qian-Wei Wang",
      "Bowen Zhao",
      "Mingyan Zhu",
      "Tianxiang Li",
      "Zimo Liu",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11194"
  },
  {
    "id": "arXiv:2210.11195",
    "title": "Rob\u00f3tica M\u00f3vel e Intelig\u00eancia Artificial para Investiga\u00e7\u00e3o,  Competi\u00e7\u00e3o e Automatiza\u00e7\u00e3o de Sistemas Industriais",
    "abstract": "The implementation of robots to enhance some processes has become popular in\nrecent years due to the accelerated way of production in some factories. Within\nthis context was where robotics has emerged, firstly with stationary robots and\nmore recently mobile robots, namely aerial and terrestrial robots. They can be\nused for delimited processes within a function, mainly the stationary robots,\nbut also for research in wider areas and even competition. This work summarizes\nthe construction of a model of terrestrial mobile robot that makes the use of\nartificial intelligence for the purpose of research and competitions, all of\nthat with the basic sensing that can be used in industry.",
    "descriptor": "\nComments: in Spanish language. Artigo aceito na FEBITEC 2022\n",
    "authors": [
      "Hiago Jacobs Sodre Pereira",
      "Pablo Ezequiel Moraes",
      "Andr\u00e9 Da Silva Kelbouscas",
      "Ricardo Grando"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11195"
  },
  {
    "id": "arXiv:2210.11199",
    "title": "Drones e Inteligencia Artificial para Investigaci\u00f3n y Competici\u00f3n",
    "abstract": "This work focuses on drones or UAVs (Unmanned Aerial Vehicles) for use in\nindustry in general. These vehicles have a large number of uses and potential\nin the industry, as a tool for civil engineering, medicine, mining, among\nothers. However, this vehicle is limited for use indoors due to the need for\nGPS and it does not work indoors. In this way, this work presents a UAV that\nworks without GPS, thus being able to be used in closed spaces for example and\nhave good precision. The work is based on an approach that uses computer vision\nand GPS.",
    "descriptor": "\nComments: in Spanish language. Articulo aceptado en la FEBITEC 2022\n",
    "authors": [
      "Victoria Saravia",
      "William Moraes",
      "Andr\u00e9 Kelbouscas",
      "Ricardo Grando"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11199"
  },
  {
    "id": "arXiv:2210.11201",
    "title": "Robust Imitation via Mirror Descent Inverse Reinforcement Learning",
    "abstract": "Recently, adversarial imitation learning has shown a scalable reward\nacquisition method for inverse reinforcement learning (IRL) problems. However,\nestimated reward signals often become uncertain and fail to train a reliable\nstatistical model since the existing methods tend to solve hard optimization\nproblems directly. Inspired by a first-order optimization method called mirror\ndescent, this paper proposes to predict a sequence of reward functions, which\nare iterative solutions for a constrained convex problem. IRL solutions derived\nby mirror descent are tolerant to the uncertainty incurred by target density\nestimation since the amount of reward learning is regulated with respect to\nlocal geometric constraints. We prove that the proposed mirror descent update\nrule ensures robust minimization of a Bregman divergence in terms of a rigorous\nregret bound of $\\mathcal{O}(1/T)$ for step sizes $\\{\\eta_t\\}_{t=1}^{T}$. Our\nIRL method was applied on top of an adversarial framework, and it outperformed\nexisting adversarial methods in an extensive suite of benchmarks.",
    "descriptor": "",
    "authors": [
      "Dong-Sig Han",
      "Hyunseo Kim",
      "Hyundo Lee",
      "Je-Hwan Ryu",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11201"
  },
  {
    "id": "arXiv:2210.11203",
    "title": "Multiparty Democracy in Decentralized Autonomous Organization (DAO):  Evidence from MakerDAO",
    "abstract": "Decentralized Autonomous Organization (DAO) provides a decentralized\ngovernance solution through blockchain, where decision-making process relies on\non-chain voting and follows majority rule. This paper focuses on the most\ninfluential DAO, namely MakerDAO, and we find voters fall into different\n'voting parties' after applying clustering algorithm to voting history. The\nsignificant voting power controlled by voting parties is a signal of governance\ncentralization in DAO, and voting parties have complicated influence on Maker\nprotocol, which is governed by MakerDAO. This paper presents empirical evidence\nof multiparty democracy in DAO and further contributes to the contemporary\ndebate on whether decentralized governance is possible.",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun",
      "Xi Chen",
      "Charalampos Stasinakis",
      "Georgios Sermpinis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "General Finance (q-fin.GN)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2210.11203"
  },
  {
    "id": "arXiv:2210.11204",
    "title": "PalGAN: Image Colorization with Palette Generative Adversarial Networks",
    "abstract": "Multimodal ambiguity and color bleeding remain challenging in colorization.\nTo tackle these problems, we propose a new GAN-based colorization approach\nPalGAN, integrated with palette estimation and chromatic attention. To\ncircumvent the multimodality issue, we present a new colorization formulation\nthat estimates a probabilistic palette from the input gray image first, then\nconducts color assignment conditioned on the palette through a generative\nmodel. Further, we handle color bleeding with chromatic attention. It studies\ncolor affinities by considering both semantic and intensity correlation. In\nextensive experiments, PalGAN outperforms state-of-the-arts in quantitative\nevaluation and visual comparison, delivering notable diverse, contrastive, and\nedge-preserving appearances. With the palette design, our method enables color\ntransfer between images even with irrelevant contexts.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Yi Wang",
      "Menghan Xia",
      "Lu Qi",
      "Jing Shao",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11204"
  },
  {
    "id": "arXiv:2210.11206",
    "title": "Data analysis and the metric evolution of hypergraphs",
    "abstract": "In this paper we aim to use different metrics in the Euclidean space and\nSobolev type metrics in function spaces in order to produce reliable parameters\nfor the differentiation of point distributions and dynamical systems. The main\ntool is the analysis of the geometrical evolution of the hypergraphs generated\nby the growth of the radial parameters for a choice of an appropriate metric in\nthe space containing the data points. Once this geometric dynamics is obtained\nwe use Lebesque and Sobolev type norms in order to compare the basic geometric\nsignals obtained.",
    "descriptor": "\nComments: 11 pages, 5 figures, 6 tables\n",
    "authors": [
      "Dalma Bilbao",
      "Hugo Aimar",
      "Diego M. Mateos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Databases (cs.DB)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11206"
  },
  {
    "id": "arXiv:2210.11212",
    "title": "Robust prescribed-time coordination control of cooperative-antagonistic  networks with disturbances",
    "abstract": "This article targets at addressing the robust prescribed-time coordination\ncontrol (PTCC) problems for single-integrator cooperative-antagonistic networks\n(CANs) with external disturbances under arbitrary fixed signed digraphs without\nany structural constraints. Toward this end, the PTCC problems for nominal\nsingle-integrator CANs without disturbances are first investigated and a fully\ndistributed control protocol with a time-varying gain, which grows to infinity\nas the time approaches the settling time, is proposed utilizing the relative\nstates of neighboring agents. Then, based on the proposed control protocol for\nthe nominal single-integrator CANs, a new second-order prescribed-time sliding\nmode control protocol is constructed to achieve accurate PTCC for\nsingle-integrator CANs in the presence of external disturbances. Using Lyapunov\nbased analysis, sufficient conditions to guarantee the prescribed-time\nstability, bipartite consensus, interval bipartite consensus, and bipartite\ncontainment of single-integrator CANs without or with disturbances are,\nrespectively, derived. In the end, numerical simulations are given to confirm\nthe derived results.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Zhen-Hua Zhu",
      "Huaiyu Wu",
      "Zhi-Hong Guan",
      "Zhi-Wei Liu",
      "Yang Chen",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11212"
  },
  {
    "id": "arXiv:2210.11213",
    "title": "Automated Control and Simulation of Dynamic Robot Teams in the Domain of  CFK Production",
    "abstract": "This paper is concerned with the automation and simulation of pick and place\nprocesses in the domain of CFK aircraft production. We introduce a workflow\nwhich starts from a CAD construction, extracts relevant data out of it, assigns\ngrippers to the CFK pieces and schedules the single steps using a PDDL solver.\nFinally, the result is visualized in Blender where also prior mistakes can be\nidentified.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Roland Gl\u00fcck",
      "Marian K\u00f6rber"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11213"
  },
  {
    "id": "arXiv:2210.11217",
    "title": "Modelling and Explaining Legal Case-based Reasoners through Classifiers",
    "abstract": "This paper brings together two lines of research: factor-based models of\ncase-based reasoning (CBR) and the logical specification of classifiers.\nLogical approaches to classifiers capture the connection between features and\noutcomes in classifier systems. Factor-based reasoning is a popular approach to\nreasoning by precedent in AI & Law. Horty (2011) has developed the factor-based\nmodels of precedent into a theory of precedential constraint. In this paper we\ncombine the modal logic approach (binary-input classifier, BLC) to classifiers\nand their explanations given by Liu & Lorini (2021) with Horty's account of\nfactor-based CBR, since both a classifier and CBR map sets of features to\ndecisions or classifications. We reformulate case bases of Horty in the\nlanguage of BCL, and give several representation results. Furthermore, we show\nhow notions of CBR, e.g. reason, preference between reasons, can be analyzed by\nnotions of classifier system.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Xinghan Liu",
      "Emiliano Lorini",
      "Antonino Rotolo",
      "Giovanni Sartor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11217"
  },
  {
    "id": "arXiv:2210.11218",
    "title": "Explainable Multi-Agent Recommendation System for Energy-Efficient  Decision Support in Smart Homes",
    "abstract": "Understandable and persuasive recommendations support the electricity\nconsumers' behavioral change to tackle the energy efficiency problem.\nGenerating load shifting recommendations for household appliances as\nexplainable increases the transparency and trustworthiness of the system. This\npaper proposes an explainable multi-agent recommendation system for load\nshifting for household appliances. First, we provide agents with enhanced\npredictive capacity by including weather data, applying state-of-the-art\nmodels, and tuning the hyperparameters. Second, we suggest an Explainability\nAgent providing transparent recommendations. We also provide an overview of the\npredictive and explainability performance. Third, we discuss the impact and\nscaling potential of the suggested approach.",
    "descriptor": "",
    "authors": [
      "Alona Zharova",
      "Annika Boer",
      "Julia Knoblauch",
      "Kai Ingo Schewina",
      "Jana Vihs"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.11218"
  },
  {
    "id": "arXiv:2210.11219",
    "title": "YOWO-Plus: An Incremental Improvement",
    "abstract": "In this technical report, we would like to introduce our updates to YOWO, a\nreal-time method for spatio-temporal action detection. We make a bunch of\nlittle design changes to make it better. For network structure, we use the same\nones of official implemented YOWO, including 3D-ResNext-101 and YOLOv2, but we\nuse a better pretrained weight of our reimplemented YOLOv2, which is better\nthan the official YOLOv2. We also optimize the label assignment used in YOWO.\nTo accurately detection action instances, we deploy GIoU loss for box\nregression. After our incremental improvement, YOWO achieves 84.9\\% frame mAP\nand 50.5\\% video mAP on the UCF101-24, significantly higher than the official\nYOWO. On the AVA, our optimized YOWO achieves 20.6\\% frame mAP with 16 frames,\nalso exceeding the official YOWO. With 32 frames, our YOWO achieves 21.6 frame\nmAP with 25 FPS on an RTX 3090 GPU. We name the optimized YOWO as YOWO-Plus.\nMoreover, we replace the 3D-ResNext-101 with the efficient 3D-ShuffleNet-v2 to\ndesign a lightweight action detector, YOWO-Nano. YOWO-Nano achieves 81.0 \\%\nframe mAP and 49.7\\% video frame mAP with over 90 FPS on the UCF101-24. It also\nachieves 18.4 \\% frame mAP with about 90 FPS on the AVA. As far as we know,\nYOWO-Nano is the fastest state-of-the-art action detector. Our code is\navailable on https://github.com/yjh0410/PyTorch_YOWO.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Jianhua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11219"
  },
  {
    "id": "arXiv:2210.11220",
    "title": "Wait-info Policy: Balancing Source and Target at Information Level for  Simultaneous Machine Translation",
    "abstract": "Simultaneous machine translation (SiMT) outputs the translation while\nreceiving the source inputs, and hence needs to balance the received source\ninformation and translated target information to make a reasonable decision\nbetween waiting for inputs or outputting translation. Previous methods always\nbalance source and target information at the token level, either directly\nwaiting for a fixed number of tokens or adjusting the waiting based on the\ncurrent token. In this paper, we propose a Wait-info Policy to balance source\nand target at the information level. We first quantify the amount of\ninformation contained in each token, named info. Then during simultaneous\ntranslation, the decision of waiting or outputting is made based on the\ncomparison results between the total info of previous target outputs and\nreceived source inputs. Experiments show that our method outperforms strong\nbaselines under and achieves better balance via the proposed info.",
    "descriptor": "\nComments: Accept to EMNLP 2022. 15 pages, 10 Figures, 6 Tables\n",
    "authors": [
      "Shaolei Zhang",
      "Shoutao Guo",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11220"
  },
  {
    "id": "arXiv:2210.11222",
    "title": "Private Algorithms with Private Predictions",
    "abstract": "When applying differential privacy to sensitive data, a common way of getting\nimproved performance is to use external information such as other sensitive\ndata, public data, or human priors. We propose to use the algorithms with\npredictions framework -- previously applied largely to improve time complexity\nor competitive ratios -- as a powerful way of designing and analyzing\nprivacy-preserving methods that can take advantage of such external information\nto improve utility. For four important tasks -- quantile release, its extension\nto multiple quantiles, covariance estimation, and data release -- we construct\nprediction-dependent differentially private methods whose utility scales with\nnatural measures of prediction quality. The analyses enjoy several advantages,\nincluding minimal assumptions about the data, natural ways of adding robustness\nto noisy predictions, and novel \"meta\" algorithms that can learn predictions\nfrom other (potentially sensitive) data. Overall, our results demonstrate how\nto enable differentially private algorithms to make use of and learn noisy\npredictions, which holds great promise for improving utility while preserving\nprivacy across a variety of tasks.",
    "descriptor": "",
    "authors": [
      "Kareem Amin",
      "Travis Dick",
      "Mikhail Khodak",
      "Sergei Vassilvitskii"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11222"
  },
  {
    "id": "arXiv:2210.11223",
    "title": "A Dialogue Robot System to Improve Credibility in Sightseeing Spot  Recommendations",
    "abstract": "Various studies have been conducted on human-supporting robot systems. These\nsystems have been put to practical use over the years and are now seen in our\ndaily lives. In particular, robots communicating smoothly with people are\nexpected to play an active role in customer service and guidance. In this case,\nit is essential to determine whether the customer is satisfied with the dialog\nrobot or not. However, it is not easy to satisfy all of the customer's requests\ndue to the diversity of the customer's speech. In this study, we developed a\ndialog mechanism that prevents dialog breakdowns and keeps the customer\nsatisfied by providing multiple scenarios for the robot to take control of the\ndialog. We tested it in a travel destination recommendation task at a travel\nagency.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Naoki Yoshimaru",
      "Tomohiro Masuda",
      "Hyejin Hong",
      "Yusei Tanaka",
      "Motoharu Okuma",
      "Nagihiro Matsumoto",
      "Kazuma Kusu",
      "Takamasa Iio",
      "Kenji Hatano"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11223"
  },
  {
    "id": "arXiv:2210.11226",
    "title": "Comparing Machine Learning Techniques for Alfalfa Biomass Yield  Prediction",
    "abstract": "The alfalfa crop is globally important as livestock feed, so highly efficient\nplanting and harvesting could benefit many industries, especially as the global\nclimate changes and traditional methods become less accurate. Recent work using\nmachine learning (ML) to predict yields for alfalfa and other crops has shown\npromise. Previous efforts used remote sensing, weather, planting, and soil data\nto train machine learning models for yield prediction. However, while remote\nsensing works well, the models require large amounts of data and cannot make\npredictions until the harvesting season begins. Using weather and planting data\nfrom alfalfa variety trials in Kentucky and Georgia, our previous work compared\nfeature selection techniques to find the best technique and best feature set.\nIn this work, we trained a variety of machine learning models, using cross\nvalidation for hyperparameter optimization, to predict biomass yields, and we\nshowed better accuracy than similar work that employed more complex techniques.\nOur best individual model was a random forest with a mean absolute error of\n0.081 tons/acre and R{$^2$} of 0.941. Next, we expanded this dataset to include\nWisconsin and Mississippi, and we repeated our experiments, obtaining a higher\nbest R{$^2$} of 0.982 with a regression tree. We then isolated our testing\ndatasets by state to explore this problem's eligibility for domain adaptation\n(DA), as we trained on multiple source states and tested on one target state.\nThis Trivial DA (TDA) approach leaves plenty of room for improvement through\nexploring more complex DA techniques in forthcoming work.",
    "descriptor": "",
    "authors": [
      "Jonathan Vance",
      "Khaled Rasheed",
      "Ali Missaoui",
      "Frederick Maier",
      "Christian Adkins",
      "Chris Whitmire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11226"
  },
  {
    "id": "arXiv:2210.11228",
    "title": "Intramorphic Testing: A New Approach to the Test Oracle Problem",
    "abstract": "A test oracle determines whether a system behaves correctly for a given\ninput. Automatic testing techniques rely on an automated test oracle to test\nthe system without user interaction. Important families of automated test\noracles include Differential Testing and Metamorphic Testing, which are both\nblack-box approaches; that is, they provide a test oracle that is oblivious to\nthe system's internals. In this work, we propose Intramorphic Testing as a\nwhite-box methodology to tackle the test oracle problem. To realize an\nIntramorphic Testing approach, a modified version of the system is created, for\nwhich, given a single input, a test oracle can be provided that relates the\noutput of the original and modified systems. As a concrete example, by\nreplacing a greater-equals operator in the implementation of a sorting\nalgorithm with smaller-equals, it would be expected that the output of the\nmodified implementation is the reverse output of the original implementation.\nIn this paper, we introduce the methodology and illustrate it via a set of use\ncases.",
    "descriptor": "",
    "authors": [
      "Manuel Rigger",
      "Zhendong Su"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.11228"
  },
  {
    "id": "arXiv:2210.11231",
    "title": "Knowledge Graph Enhanced Relation Extraction Datasets",
    "abstract": "Knowledge-enhanced methods that take advantage of auxiliary knowledge graphs\nrecently emerged in relation extraction, and they surpass traditional\ntext-based relation extraction methods. However, there are no unified public\nbenchmarks that currently involve evidence sentences and knowledge graphs for\nknowledge-enhanced relation extraction. To combat these issues, we propose\nKGRED, a knowledge graph enhanced relation extraction dataset with features as\nfollows: (1) the benchmarks are based on widely-used distantly supervised\nrelation extraction datasets; (2) we refine these existing datasets to improve\nthe data quality, and we also construct auxiliary knowledge graphs for these\nexisting datasets through entity linking to support knowledge-enhanced relation\nextraction tasks; (3) with the new benchmarks we curated, we build baselines in\ntwo popular relation extraction settings including sentence-level and bag-level\nrelation extraction, and we also make comparisons among the latest\nknowledge-enhanced relation extraction methods. KGRED provides high-quality\nrelation extraction datasets with auxiliary knowledge graphs for evaluating the\nperformance of knowledge-enhanced relation extraction methods. Meanwhile, our\nexperiments on KGRED reveal the influence of knowledge graph information on\nrelation extraction tasks.",
    "descriptor": "\nComments: 25 pages, 11 figures, will be submitted to Neurocomputing soon\n",
    "authors": [
      "Yucong Lin",
      "Hongming Xiao",
      "Jiani Liu",
      "Zichao Lin",
      "Keming Lu",
      "Feifei Wang",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11231"
  },
  {
    "id": "arXiv:2210.11233",
    "title": "Context-driven Visual Object Recognition based on Knowledge Graphs",
    "abstract": "Current deep learning methods for object recognition are purely data-driven\nand require a large number of training samples to achieve good results. Due to\ntheir sole dependence on image data, these methods tend to fail when confronted\nwith new environments where even small deviations occur. Human perception,\nhowever, has proven to be significantly more robust to such distribution\nshifts. It is assumed that their ability to deal with unknown scenarios is\nbased on extensive incorporation of contextual knowledge. Context can be based\neither on object co-occurrences in a scene or on memory of experience. In\naccordance with the human visual cortex which uses context to form different\nobject representations for a seen image, we propose an approach that enhances\ndeep learning methods by using external contextual knowledge encoded in a\nknowledge graph. Therefore, we extract different contextual views from a\ngeneric knowledge graph, transform the views into vector space and infuse it\ninto a DNN. We conduct a series of experiments to investigate the impact of\ndifferent contextual views on the learned object representations for the same\nimage dataset. The experimental results provide evidence that the contextual\nviews influence the image representations in the DNN differently and therefore\nlead to different predictions for the same images. We also show that context\nhelps to strengthen the robustness of object recognition models for\nout-of-distribution images, usually occurring in transfer learning tasks or\nreal-world scenarios.",
    "descriptor": "\nComments: ISWC 2022\n",
    "authors": [
      "Sebastian Monka",
      "Lavdim Halilaj",
      "Achim Rettinger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.11233"
  },
  {
    "id": "arXiv:2210.11234",
    "title": "Development of a hardware-In-the-Loop (HIL) testbed for cyber-physical  security in smart buildings",
    "abstract": "As smart buildings move towards open communication technologies, providing\naccess to the Building Automation System (BAS) through the intranet, or even\nremotely through the Internet, has become a common practice. However, BAS was\nhistorically developed as a closed environment and designed with limited\ncyber-security considerations. Thus, smart buildings are vulnerable to\ncyber-attacks with the increased accessibility. This study introduces the\ndevelopment and capability of a Hardware-in-the-Loop (HIL) testbed for testing\nand evaluating the cyber-physical security of typical BASs in smart buildings.\nThe testbed consists of three subsystems: (1) a real-time HIL emulator\nsimulating the behavior of a virtual building as well as the Heating,\nVentilation, and Air Conditioning (HVAC) equipment via a dynamic simulation in\nModelica; (2) a set of real HVAC controllers monitoring the virtual building\noperation and providing local control signals to control HVAC equipment in the\nHIL emulator; and (3) a BAS server along with a web-based service for users to\nfully access the schedule, setpoints, trends, alarms, and other control\nfunctions of the HVAC controllers remotely through the BACnet network. The\nserver generates rule-based setpoints to local HVAC controllers. Based on these\nthree subsystems, the HIL testbed supports attack/fault-free and\nattack/fault-injection experiments at various levels of the building system.\nThe resulting test data can be used to inform the building community and\nsupport the cyber-physical security technology transfer to the building\nindustry.",
    "descriptor": "\nComments: to be published in 2023 ASHRAE Winter Conference\n",
    "authors": [
      "Guowen Li",
      "Zhiyao Yang",
      "Yangyang Fu. Lingyu Ren",
      "Zheng O'Neill",
      "Chirag Parikh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11234"
  },
  {
    "id": "arXiv:2210.11235",
    "title": "Interpretable Machine Learning for Detection and Classification of  Ransomware Families Based on API Calls",
    "abstract": "Ransomware has appeared as one of the major global threats in recent days The\nalarming increasing rate of ransomware attacks and new ransomware variants\nintrigue the researchers to constantly examine the distinguishing traits of\nransomware and refine their detection strategies Application Programming\nInterface API is a way for one program to collaborate with another API calls\nare the medium by which they communicate Ransomware uses this strategy to\ninteract with the OS and makes a significantly higher number of calls in\ndifferent sequences to ask for taking action This research work utilizes the\nfrequencies of different API calls to detect and classify ransomware families\nFirst a WebCrawler is developed to automate collecting the Windows Portable\nExecutable PE files of 15 different ransomware families By extracting different\nfrequencies of 68 API calls we develop our dataset in the first phase of the\ntwo phase feature engineering process After selecting the most significant\nfeatures in the second phase of the feature engineering process we deploy six\nSupervised Machine Learning models Naive Bayes Logistic Regression Random\nForest Stochastic Gradient Descent K Nearest Neighbor and Support Vector\nMachine Then the performances of all the classifiers are compared to select the\nbest model The results reveal that Logistic Regression can efficiently classify\nransomware into their corresponding families securing 9915 accuracy Finally\ninstead of relying on the Black box characteristic of the Machine Learning\nmodels we present the interpretability of our best performing model using SHAP\nvalues to ascertain the transparency and trustworthiness of the models\nprediction",
    "descriptor": "",
    "authors": [
      "Rawshan Ara Mowri",
      "Madhuri Siddula",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11235"
  },
  {
    "id": "arXiv:2210.11237",
    "title": "Emerging Threats in Deep Learning-Based Autonomous Driving: A  Comprehensive Survey",
    "abstract": "Since the 2004 DARPA Grand Challenge, the autonomous driving technology has\nwitnessed nearly two decades of rapid development. Particularly, in recent\nyears, with the application of new sensors and deep learning technologies\nextending to the autonomous field, the development of autonomous driving\ntechnology has continued to make breakthroughs. Thus, many carmakers and\nhigh-tech giants dedicated to research and system development of autonomous\ndriving. However, as the foundation of autonomous driving, the deep learning\ntechnology faces many new security risks. The academic community has proposed\ndeep learning countermeasures against the adversarial examples and AI backdoor,\nand has introduced them into the autonomous driving field for verification.\nDeep learning security matters to autonomous driving system security, and then\nmatters to personal safety, which is an issue that deserves attention and\nresearch.This paper provides an summary of the concepts, developments and\nrecent research in deep learning security technologies in autonomous driving.\nFirstly, we briefly introduce the deep learning framework and pipeline in the\nautonomous driving system, which mainly include the deep learning technologies\nand algorithms commonly used in this field. Moreover, we focus on the potential\nsecurity threats of the deep learning based autonomous driving system in each\nfunctional layer in turn. We reviews the development of deep learning attack\ntechnologies to autonomous driving, investigates the State-of-the-Art\nalgorithms, and reveals the potential risks. At last, we provides an outlook on\ndeep learning security in the autonomous driving field and proposes\nrecommendations for building a safe and trustworthy autonomous driving system.",
    "descriptor": "\nComments: 28 pages,10 figures\n",
    "authors": [
      "Hui Cao",
      "Wenlong Zou",
      "Yinkun Wang",
      "Ting Song",
      "Mengjun Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11237"
  },
  {
    "id": "arXiv:2210.11239",
    "title": "The State-of-the-Art in AI-Based Malware Detection Techniques: A Review",
    "abstract": "Artificial Intelligence techniques have evolved rapidly in recent years,\nrevolutionising the approaches used to fight against cybercriminals. But as the\ncyber security field has progressed, so has malware development, making it an\neconomic imperative to strengthen businesses' defensive capability against\nmalware attacks. This review aims to outline the state-of-the-art AI techniques\nused in malware detection and prevention, providing an in-depth analysis of the\nlatest studies in this field. The algorithms investigated consist of Shallow\nLearning, Deep Learning and Bio-Inspired Computing, applied to a variety of\nplatforms, such as PC, cloud, Android and IoT. This survey also touches on the\nrapid adoption of AI by cybercriminals as a means to create ever more advanced\nmalware and exploit the AI algorithms designed to defend against them.",
    "descriptor": "\nComments: 18 pages, 2 figures, 6 tables\n",
    "authors": [
      "Adam Wolsey"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11239"
  },
  {
    "id": "arXiv:2210.11240",
    "title": "Strong Normalization for the Calculus of Constructions",
    "abstract": "The calculus of constructions (CC) is a core theory for dependently typed\nprogramming and higher-order constructive logic. Originally introduced in\nCoquand's 1985 thesis, CC has inspired 25 years of research in programming\nlanguages and type theory. Today, extensions of CC form the basis of languages\nlike Coq and Agda. This survey reviews three proofs of CC's strong\nnormalization property (the fact that there are no infinite reduction sequences\nfrom well-typed expressions). It highlights the similarities in the structure\nof the proofs while showing how their differences are motivated by the varying\ngoals of their authors.",
    "descriptor": "\nComments: This survey was originally written to fulfill the written preliminary exam requirement of the University of Pennsylvania's computer science PhD program\n",
    "authors": [
      "Chris Casinghino"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.11240"
  },
  {
    "id": "arXiv:2210.11242",
    "title": "Attacking Motion Estimation with Adversarial Snow",
    "abstract": "Current adversarial attacks for motion estimation (optical flow) optimize\nsmall per-pixel perturbations, which are unlikely to appear in the real world.\nIn contrast, we exploit a real-world weather phenomenon for a novel attack with\nadversarially optimized snow. At the core of our attack is a differentiable\nrenderer that consistently integrates photorealistic snowflakes with realistic\nmotion into the 3D scene. Through optimization we obtain adversarial snow that\nsignificantly impacts the optical flow while being indistinguishable from\nordinary snow. Surprisingly, the impact of our novel attack is largest on\nmethods that previously showed a high robustness to small L_p perturbations.",
    "descriptor": "",
    "authors": [
      "Jenny Schmalfuss",
      "Lukas Mehl",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11242"
  },
  {
    "id": "arXiv:2210.11248",
    "title": "OCR-VQGAN: Taming Text-within-Image Generation",
    "abstract": "Synthetic image generation has recently experienced significant improvements\nin domains such as natural image or art generation. However, the problem of\nfigure and diagram generation remains unexplored. A challenging aspect of\ngenerating figures and diagrams is effectively rendering readable texts within\nthe images. To alleviate this problem, we present OCR-VQGAN, an image encoder,\nand decoder that leverages OCR pre-trained features to optimize a text\nperceptual loss, encouraging the architecture to preserve high-fidelity text\nand diagram structure. To explore our approach, we introduce the Paper2Fig100k\ndataset, with over 100k images of figures and texts from research papers. The\nfigures show architecture diagrams and methodologies of articles available at\narXiv.org from fields like artificial intelligence and computer vision. Figures\nusually include text and discrete objects, e.g., boxes in a diagram, with lines\nand arrows that connect them. We demonstrate the effectiveness of OCR-VQGAN by\nconducting several experiments on the task of figure reconstruction.\nAdditionally, we explore the qualitative and quantitative impact of weighting\ndifferent perceptual metrics in the overall loss function. We release code,\nmodels, and dataset at https://github.com/joanrod/ocr-vqgan.",
    "descriptor": "\nComments: Paper accepted at WACV 2023\n",
    "authors": [
      "Juan A. Rodriguez",
      "David Vazquez",
      "Issam Laradji",
      "Marco Pedersoli",
      "Pau Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11248"
  },
  {
    "id": "arXiv:2210.11253",
    "title": "Image Semantic Relation Generation",
    "abstract": "Scene graphs provide structured semantic understanding beyond images. For\ndownstream tasks, such as image retrieval, visual question answering, visual\nrelationship detection, and even autonomous vehicle technology, scene graphs\ncan not only distil complex image information but also correct the bias of\nvisual models using semantic-level relations, which has broad application\nprospects. However, the heavy labour cost of constructing graph annotations may\nhinder the application of PSG in practical scenarios. Inspired by the\nobservation that people usually identify the subject and object first and then\ndetermine the relationship between them, we proposed to decouple the scene\ngraphs generation task into two sub-tasks: 1) an image segmentation task to\npick up the qualified objects. 2) a restricted auto-regressive text generation\ntask to generate the relation between given objects. Therefore, in this work,\nwe introduce image semantic relation generation (ISRG), a simple but effective\nimage-to-text model, which achieved 31 points on the OpenPSG dataset and\noutperforms strong baselines respectively by 16 points (ResNet-50) and 5 points\n(CLIP).",
    "descriptor": "",
    "authors": [
      "Mingzhe Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11253"
  },
  {
    "id": "arXiv:2210.11255",
    "title": "Evidence > Intuition: Transferability Estimation for Encoder Selection",
    "abstract": "With the increase in availability of large pre-trained language models (LMs)\nin Natural Language Processing (NLP), it becomes critical to assess their fit\nfor a specific target task a priori - as fine-tuning the entire space of\navailable LMs is computationally prohibitive and unsustainable. However,\nencoder transferability estimation has received little to no attention in NLP.\nIn this paper, we propose to generate quantitative evidence to predict which\nLM, out of a pool of models, will perform best on a target task without having\nto fine-tune all candidates. We provide a comprehensive study on LM ranking for\n10 NLP tasks spanning the two fundamental problem types of classification and\nstructured prediction. We adopt the state-of-the-art Logarithm of Maximum\nEvidence (LogME) measure from Computer Vision (CV) and find that it positively\ncorrelates with final LM performance in 94% of the setups. In the first study\nof its kind, we further compare transferability measures with the de facto\nstandard of human practitioner ranking, finding that evidence from quantitative\nmetrics is more robust than pure intuition and can help identify unexpected LM\ncandidates.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (main conference)\n",
    "authors": [
      "Elisa Bassignana",
      "Max M\u00fcller-Eberstein",
      "Mike Zhang",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11255"
  },
  {
    "id": "arXiv:2210.11257",
    "title": "A note on diffusion limits for stochastic gradient descent",
    "abstract": "In the machine learning literature stochastic gradient descent has recently\nbeen widely discussed for its purported implicit regularization properties.\nMuch of the theory, that attempts to clarify the role of noise in stochastic\ngradient algorithms, has widely approximated stochastic gradient descent by a\nstochastic differential equation with Gaussian noise. We provide a novel\nrigorous theoretical justification for this practice that showcases how the\nGaussianity of the noise arises naturally.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Alberto Lanconelli",
      "Christopher S. A. Lauria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.11257"
  },
  {
    "id": "arXiv:2210.11259",
    "title": "Safe Policy Improvement in Constrained Markov Decision Processes",
    "abstract": "The automatic synthesis of a policy through reinforcement learning (RL) from\na given set of formal requirements depends on the construction of a reward\nsignal and consists of the iterative application of many policy-improvement\nsteps. The synthesis algorithm has to balance target, safety, and comfort\nrequirements in a single objective and to guarantee that the policy improvement\ndoes not increase the number of safety-requirements violations, especially for\nsafety-critical applications. In this work, we present a solution to the\nsynthesis problem by solving its two main challenges: reward-shaping from a set\nof formal requirements and safe policy update. For the former, we propose an\nautomatic reward-shaping procedure, defining a scalar reward signal compliant\nwith the task specification. For the latter, we introduce an algorithm ensuring\nthat the policy is improved in a safe fashion with high-confidence guarantees.\nWe also discuss the adoption of a model-based RL algorithm to efficiently use\nthe collected data and train a model-free agent on the predicted trajectories,\nwhere the safety violation does not have the same impact as in the real world.\nFinally, we demonstrate in standard control benchmarks that the resulting\nlearning procedure is effective and robust even under heavy perturbations of\nthe hyperparameters.",
    "descriptor": "\nComments: Accepted for presentation at the International Symposium on Leveraging Applications of Formal Methods (ISoLA, 2022)\n",
    "authors": [
      "Luigi Berducci",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11259"
  },
  {
    "id": "arXiv:2210.11260",
    "title": "An Efficient Merge Search Matheuristic for Maximising the Net Present  Value of Project Schedules",
    "abstract": "Resource constrained project scheduling is an important combinatorial\noptimisation problem with many practical applications. With complex\nrequirements such as precedence constraints, limited resources, and\nfinance-based objectives, finding optimal solutions for large problem instances\nis very challenging even with well-customised meta-heuristics and\nmatheuristics. To address this challenge, we propose a new math-heuristic\nalgorithm based on Merge Search and parallel computing to solve the resource\nconstrained project scheduling with the aim of maximising the net present\nvalue. This paper presents a novel matheuristic framework designed for resource\nconstrained project scheduling, Merge search, which is a variable partitioning\nand merging mechanism to formulate restricted mixed integer programs with the\naim of improving an existing pool of solutions. The solution pool is obtained\nvia a customised parallel ant colony optimisation algorithm, which is also\ncapable of generating high quality solutions on its own. The experimental\nresults show that the proposed method outperforms the current state-of-the-art\nalgorithms on known benchmark problem instances. Further analyses also\ndemonstrate that the proposed algorithm is substantially more efficient\ncompared to its counterparts in respect to its convergence properties when\nconsidering multiple cores.",
    "descriptor": "",
    "authors": [
      "Dhananjay R. Thiruvady",
      "Su Nguyen",
      "Christian Blum",
      "Andreas T. Ernst"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11260"
  },
  {
    "id": "arXiv:2210.11262",
    "title": "RMBench: Benchmarking Deep Reinforcement Learning for Robotic  Manipulator Control",
    "abstract": "Reinforcement learning is applied to solve actual complex tasks from\nhigh-dimensional, sensory inputs. The last decade has developed a long list of\nreinforcement learning algorithms. Recent progress benefits from deep learning\nfor raw sensory signal representation. One question naturally arises: how well\ndo they perform concerning different robotic manipulation tasks? Benchmarks use\nobjective performance metrics to offer a scientific way to compare algorithms.\nIn this paper, we present RMBench, the first benchmark for robotic\nmanipulations, which have high-dimensional continuous action and state spaces.\nWe implement and evaluate reinforcement learning algorithms that directly use\nobserved pixels as inputs. We report their average performance and learning\ncurves to show their performance and stability of training. Our study concludes\nthat none of the studied algorithms can handle all tasks well, soft\nActor-Critic outperforms most algorithms in average reward and stability, and\nan algorithm combined with data augmentation may facilitate learning policies.\nOur code is publicly available at\nhttps://anonymous.4open.science/r/RMBench-2022-3424, including all benchmark\ntasks and studied algorithms.",
    "descriptor": "\nComments: 8 pages, 2 figures, 2 tables\n",
    "authors": [
      "Yanfei Xiang",
      "Xin Wang",
      "Shu Hu",
      "Bin Zhu",
      "Xiaomeng Huang",
      "Xi Wu",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11262"
  },
  {
    "id": "arXiv:2210.11264",
    "title": "Detecting Backdoors in Deep Text Classifiers",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks, such as backdoor\nattacks in which a malicious adversary compromises a model during training such\nthat specific behaviour can be triggered at test time by attaching a specific\nword or phrase to an input. This paper considers the problem of diagnosing\nwhether a model has been compromised and if so, identifying the backdoor\ntrigger. We present the first robust defence mechanism that generalizes to\nseveral backdoor attacks against text classification models, without prior\nknowledge of the attack type, nor does our method require access to any\n(potentially compromised) training resources. Our experiments show that our\ntechnique is highly accurate at defending against state-of-the-art backdoor\nattacks, including data poisoning and weight poisoning, across a range of text\nclassification tasks and model architectures. Our code will be made publicly\navailable upon acceptance.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "You Guo",
      "Jun Wang",
      "Trevor Cohn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11264"
  },
  {
    "id": "arXiv:2210.11265",
    "title": "Disentangling Reasoning Capabilities from Language Models with  Compositional Reasoning Transformers",
    "abstract": "This paper presents ReasonFormer, a unified reasoning framework for mirroring\nthe modular and compositional reasoning process of humans in complex decision\nmaking. Inspired by dual-process theory in cognitive science, the\nrepresentation module (automatic thinking) and reasoning modules (controlled\nthinking) are disentangled to capture different levels of cognition. Upon the\ntop of the representation module, the pre-trained reasoning modules are modular\nand expertise in specific and fundamental reasoning skills (e.g., logic, simple\nQA, etc). To mimic the controlled compositional thinking process, different\nreasoning modules are dynamically activated and composed in both parallel and\ncascaded manners to control what reasoning skills are activated and how deep\nthe reasoning process will be reached to solve the current problems. The\nunified reasoning framework solves multiple tasks with a single model,and is\ntrained and inferred in an end-to-end manner. Evaluated on 11 datasets\nrequiring different reasoning skills and complexity, ReasonFormer demonstrates\nsubstantial performance boosts, revealing the compositional reasoning ability.\nFew-shot experiments exhibit better generalization ability by learning to\ncompose pre-trained skills for new tasks with limited data,and decoupling the\nrepresentation module and the reasoning modules. Further analysis shows the\nmodularity of reasoning modules as different tasks activate distinct reasoning\nskills at different reasoning depths.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Wanjun Zhong",
      "Tingting Ma",
      "Jiahai Wang",
      "Jian Yin",
      "Tiejun Zhao",
      "Chin-Yew Lin",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11265"
  },
  {
    "id": "arXiv:2210.11266",
    "title": "Knowledge Management Skills for 21st Century Library Professionals in  India A Study",
    "abstract": "In any kind of educational institute and organization, libraries are playing\na crucial role. For the development of library services, skillful library\nprofessionals are indispensable. Without knowledge management skills, no one\ncan provide essential services to the users. Library is a growing organism by\nS.R. Ranganathan 1931, based on his law, as library professionals have to adopt\nfuturistic skills for better user services. The study investigates knowledge\nmanagement skills and the chief strengths of library and information science\nprofessionals in India. For this study, data collected from the Institute of\nNational Importance and Central Universities around India. The principal aim of\nthis study is to understand the current scenario and data literacy skills of\nlibrary professionals.",
    "descriptor": "",
    "authors": [
      "A. Subaveerapandiyan",
      "Dharmavarapu Sindhu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11266"
  },
  {
    "id": "arXiv:2210.11267",
    "title": "A Study of Teacher Educators Skill and ICT Integration in Online  Teaching during the Pandemic Situation in India",
    "abstract": "Information and communication technology prompted the sharing of information\nover the world. For its impact on education the government and the authorities\nlike the University Grants Commission in India have energized the higher\neducation institutions in India to implement online education during the\npandemic situation. This paper attempts to know the teaching faculties ICT\nskills and related online class skills in higher educational institutions in\nIndia. In India like developing countries quick as the lightning change in\ntraditional to fully online classes are like a rumble of thunder because\nfaculties are adopting this situation but students are challenging to adopt.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "R Nandhakumar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.11267"
  },
  {
    "id": "arXiv:2210.11268",
    "title": "Digital Publishing Habits, Perceptions of Open Access Publishing and  Other Access Publishing: Across Continents Survey Study",
    "abstract": "In this transformative world, changes are happening in all the fields,\nincluding scholarly communications are trending in the academic area of\npublication and access to the resources, especially emerging the wave of open\naccess, open science and open research. The study aims to investigate the\ndigital publishing behaviour of manuscript authors. This study applied a\nquantitative approach and survey questionnaire method. The researcher collected\nthe data from 251 authors, editors, and peer-reviewers from 45 countries\nworldwide. The research mainly focuses on the importance, need, and author\npreference for open access journals. Everyone cannot use and access\nsubscription-based journals; the critical reason is the cost of purchasing a\ntremendous amount. As an independent researcher, developing countries and other\nimpoverished countries, researchers can give the utmost importance to open\naccess journals. The author also wishes to publish a journal in open access\nonly. The findings reveal that most authors like to publish digital and print\nin both formats, with chargeless publications. Open access publishing has a\nvital role with researchers, scholars, and students because accessing the\narticles is costless. The researcher publishing the manuscript is more\nimportant than the quality of the content also important in scholarly\npublication. Nowadays, open-access peer-reviewed journals are also equal to the\npaid journals.",
    "descriptor": "",
    "authors": [
      "A. Subaveerapandiyan",
      "K. Yohapriya",
      "Ghouse Modin Nabeesab Mamdapur"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11268"
  },
  {
    "id": "arXiv:2210.11269",
    "title": "Accurate Extrinsic Prediction of Physical Systems Using Transformers",
    "abstract": "Accurate high-altitude wind forecasting is important for air traffic control.\nAnd the large volume of data available for this task makes deep neural\nnetwork-based models a possibility. However, special methods are required\nbecause the data is measured only sparsely: along the main aircraft\ntrajectories and arranged sparsely in space, namely along the main air\ncorridors. Several deep learning approaches have been proposed, and in this\nwork, we show that Transformers can fit this data efficiently and are able to\nextrapolate coherently from a context set.\nWe show this by an extensive comparison of Transformers to numerous existing\ndeep learning-based baselines in the literature. Besides high-altitude wind\nforecasting, we compare competing models on other dynamical physical systems,\nnamely those modelled by partial differential equations, in particular the\nPoisson equation and Darcy Flow equation. For these experiments, in the case\nwhere the data is arranged non-regularly in space, Transformers outperform all\nthe other evaluated methods. We also compared them in a more standard setup\nwhere the data is arranged on a grid and show that the Transformers are\ncompetitive with state-of-the-art methods, even though it does not require\nregular spacing. The code and datasets of the different experiments will be\nmade publicly available at publication time.",
    "descriptor": "\nComments: 13 pages, 10 figures, submitted at SIAM Data Mining 23 (SDM23)\n",
    "authors": [
      "Arnaud Pannatier",
      "Kyle Matoba",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.11269"
  },
  {
    "id": "arXiv:2210.11270",
    "title": "Factorisation in the semiring of finite dynamical systems",
    "abstract": "Finite dynamical systems (FDSs) are commonly used to model systems with a\nfinite number of states that evolve deterministically and at discrete time\nsteps. Considered up to isomorphism, those correspond to functional graphs. As\nsuch, FDSs have a sum and product operation, which correspond to the direct sum\nand direct product of their respective graphs; the collection of FDSs endowed\nwith these operations then forms a semiring. The algebraic structure of the\nproduct of FDSs is particularly interesting. For instance, an FDS can be\nfactorised if and only if it is composed of two sub-systems running in\nparallel. In this work, we further the understanding of the factorisation,\ndivision, and root finding problems for FDSs. Firstly, an FDS $A$ is\ncancellative if one can divide by it unambiguously, i.e. $AX = AY$ implies $X =\nY$. We prove that an FDS $A$ is cancellative if and only if it has a fixpoint.\nSecondly, we prove that if an FDS $A$ has a $k$-th root (i.e. $B$ such that\n$B^k = A$), then it is unique. Thirdly, unlike integers, the monoid of FDS\nproduct does not have unique factorisation into irreducibles. We instead\nexhibit a large class of monoids of FDSs with unique factorisation. To obtain\nour main results, we introduce the unrolling of an FDS, which can be viewed as\na space-time expansion of the system. This allows us to work with (possibly\ninfinite) trees, where the product is easier to handle than its counterpart for\nFDSs.",
    "descriptor": "",
    "authors": [
      "\u00c9mile Naquin",
      "Maximilien Gadouleau"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Dynamical Systems (math.DS)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2210.11270"
  },
  {
    "id": "arXiv:2210.11271",
    "title": "In-Vehicle Interface Adaptation to Environment-Induced Cognitive  Workload",
    "abstract": "Many car accidents are caused by human distractions, including cognitive\ndistractions. In-vehicle human-machine interfaces (HMIs) have evolved\nthroughout the years, providing more and more functions. Interaction with the\nHMIs can, however, also lead to further distractions and, as a consequence,\naccidents. To tackle this problem, we propose using adaptive HMIs that change\naccording to the mental workload of the driver. In this work, we present the\ncurrent status as well as preliminary results of a user study using\nnaturalistic secondary tasks while driving (i.e., the primary task) that\nattempt to understand the effects of one such interface.",
    "descriptor": "",
    "authors": [
      "Elena Meiser",
      "Alexandra Alles",
      "Samuel Selter",
      "Marco Molz",
      "Amr Gomaa",
      "Guillermo Reyes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11271"
  },
  {
    "id": "arXiv:2210.11272",
    "title": "Low-Latency Hybrid NOMA-TDMA: QoS-Driven Design Framework",
    "abstract": "Enabling ultra-reliable and low-latency communication services while\nproviding massive connectivity is one of the major goals to be accomplished in\nfuture wireless communication networks. In this paper, we investigate the\nperformance of a hybrid multi-access scheme in the finite blocklength (FBL)\nregime that combines the advantages of both non-orthogonal multiple access\n(NOMA) and time-division multiple access (TDMA) schemes. Two latency-sensitive\napplication scenarios are studied, distinguished by whether the queuing\nbehaviour has an influence on the transmission performance or not. In\nparticular, for the latency-critical case with one-shot transmission, we aim at\na certain physical-layer quality-of-service (QoS) performance, namely the\noptimization of the reliability. And for the case in which queuing behaviour\nplays a role, we focus on the link-layer QoS performance and provide a design\nthat maximizes the effective capacity. For both designs, we leverage the\ncharacterizations in the FBL regime to provide the optimal framework by jointly\nallocating the blocklength and transmit power of each user. In particular, for\nthe reliability-oriented design, the original problem is decomposed and the\njoint convexity of sub-problems is shown via a variable substitution method.\nFor the effective-capacity-oriented design, we exploit the method of Lagrange\nmultipliers to formulate a solvable dual problem with strong duality to the\noriginal problem. Via simulations, we validate our analytical results of\nconvexity/concavity and show the advantage of our proposed approaches compared\nto other existing schemes.",
    "descriptor": "\nComments: 32pages, 9 figures. Accepted by IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Yao Zhu",
      "Xiaopeng Yuan",
      "Yulin Hu",
      "Tong Wang",
      "M. Cenk Gursoy",
      "Anke Schmeink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11272"
  },
  {
    "id": "arXiv:2210.11275",
    "title": "Hypothesis Testing using Causal and Causal Variational Generative Models",
    "abstract": "Hypothesis testing and the usage of expert knowledge, or causal priors, has\nnot been well explored in the context of generative models. We propose a novel\nset of generative architectures, Causal Gen and Causal Variational Gen, that\ncan utilize nonparametric structural causal knowledge combined with a deep\nlearning functional approximation. We show how, using a deliberate (non-random)\nsplit of training and testing data, these models can generalize better to\nsimilar, but out-of-distribution data points, than non-causal generative models\nand prediction models such as Variational autoencoders and Fully Connected\nNeural Networks. We explore using this generalization error as a proxy for\ncausal model hypothesis testing. We further show how dropout can be used to\nlearn functional relationships of structural models that are difficult to learn\nwith traditional methods. We validate our methods on a synthetic pendulum\ndataset, as well as a trauma surgery ground level fall dataset.",
    "descriptor": "\nComments: Submitted To: NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research\n",
    "authors": [
      "Jeffrey Jiang",
      "Omead Pooladzandi",
      "Sunay Bhat",
      "Gregory Pottie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11275"
  },
  {
    "id": "arXiv:2210.11277",
    "title": "TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting  Decomposition",
    "abstract": "Creation of 3D content by stylization is a promising yet challenging problem\nin computer vision and graphics research. In this work, we focus on stylizing\nphotorealistic appearance renderings of a given surface mesh of arbitrary\ntopology. Motivated by the recent surge of cross-modal supervision of the\nContrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which\ntransfers the appearance style of a given 3D shape according to a text prompt\nin a photorealistic manner. Technically, we propose to disentangle the\nappearance style as the spatially varying bidirectional reflectance\ndistribution function, the local geometric variation, and the lighting\ncondition, which are jointly optimized, via supervision of the CLIP loss, by a\nspherical Gaussians based differentiable renderer. As such, TANGO enables\nphotorealistic 3D style transfer by automatically predicting reflectance\neffects even for bare, low-quality meshes, without training on a task-specific\ndataset. Extensive experiments show that TANGO outperforms existing methods of\ntext-driven 3D style transfer in terms of photorealistic quality, consistency\nof 3D geometry, and robustness when stylizing low-quality meshes. Our codes and\nresults are available at our project webpage https://cyw-3d.github.io/tango/.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yongwei Chen",
      "Rui Chen",
      "Jiabao Lei",
      "Yabin Zhang",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11277"
  },
  {
    "id": "arXiv:2210.11279",
    "title": "DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for  Multiple Intent Detection",
    "abstract": "While interacting with chatbots, users may elicit multiple intents in a\nsingle dialogue utterance. Instead of training a dedicated multi-intent\ndetection model, we propose DialogUSR, a dialogue utterance splitting and\nreformulation task that first splits multi-intent user query into several\nsingle-intent sub-queries and then recovers all the coreferred and omitted\ninformation in the sub-queries. DialogUSR can serve as a plug-in and\ndomain-agnostic module that empowers the multi-intent detection for the\ndeployed chatbots with minimal efforts. We collect a high-quality naturally\noccurring dataset that covers 23 domains with a multi-step crowd-souring\nprocedure. To benchmark the proposed dataset, we propose multiple action-based\ngenerative models that involve end-to-end and two-stage training, and conduct\nin-depth analyses on the pros and cons of the proposed baselines.",
    "descriptor": "\nComments: Accepted by EMNLP2022(findings); The first three authors contribute equally\n",
    "authors": [
      "Haoran Meng",
      "Zheng Xin",
      "Tianyu Liu",
      "Zizhen Wang",
      "He Feng",
      "Binghuai Lin",
      "Xuemin Zhao",
      "Yunbo Cao",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11279"
  },
  {
    "id": "arXiv:2210.11287",
    "title": "MoCoDA: Model-based Counterfactual Data Augmentation",
    "abstract": "The number of states in a dynamic process is exponential in the number of\nobjects, making reinforcement learning (RL) difficult in complex, multi-object\ndomains. For agents to scale to the real world, they will need to react to and\nreason about unseen combinations of objects. We argue that the ability to\nrecognize and use local factorization in transition dynamics is a key element\nin unlocking the power of multi-object reasoning. To this end, we show that (1)\nknown local structure in the environment transitions is sufficient for an\nexponential reduction in the sample complexity of training a dynamics model,\nand (2) a locally factored dynamics model provably generalizes\nout-of-distribution to unseen states and actions. Knowing the local structure\nalso allows us to predict which unseen states and actions this dynamics model\nwill generalize to. We propose to leverage these observations in a novel\nModel-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies\na learned locally factored dynamics model to an augmented distribution of\nstates and actions to generate counterfactual transitions for RL. MoCoDA works\nwith a broader set of local structures than prior work and allows for direct\ncontrol over the augmented training distribution. We show that MoCoDA enables\nRL agents to learn policies that generalize to unseen states and actions. We\nuse MoCoDA to train an offline RL agent to solve an out-of-distribution\nrobotics manipulation task on which standard offline RL algorithms fail.",
    "descriptor": "\nComments: In Proceedings of NeurIPS 2022. 10 pages (+3 references, +10 appendix). Code available at this https URL\n",
    "authors": [
      "Silviu Pitis",
      "Elliot Creager",
      "Ajay Mandlekar",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11287"
  },
  {
    "id": "arXiv:2210.11289",
    "title": "Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty",
    "abstract": "We introduce a modified version of the excess risk, which can be used to\nobtain tighter, fast-rate PAC-Bayesian generalisation bounds. This modified\nexcess risk leverages information about the relative hardness of data examples\nto reduce the variance of its empirical counterpart, tightening the bound. We\ncombine this with a new bound for $[-1, 1]$-valued (and potentially\nnon-independent) signed losses, which is more favourable when they empirically\nhave low variance around $0$. The primary new technical tool is a novel result\nfor sequences of interdependent random vectors which may be of independent\ninterest. We empirically evaluate these new bounds on a number of real-world\ndatasets.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11289"
  },
  {
    "id": "arXiv:2210.11291",
    "title": "Cyclical Self-Supervision for Semi-Supervised Ejection Fraction  Prediction from Echocardiogram Videos",
    "abstract": "Left-ventricular ejection fraction (LVEF) is an important indicator of heart\nfailure. Existing methods for LVEF estimation from video require large amounts\nof annotated data to achieve high performance, e.g. using 10,030 labeled\nechocardiogram videos to achieve mean absolute error (MAE) of 4.10. Labeling\nthese videos is time-consuming however and limits potential downstream\napplications to other heart diseases. This paper presents the first\nsemi-supervised approach for LVEF prediction. Unlike general video prediction\ntasks, LVEF prediction is specifically related to changes in the left ventricle\n(LV) in echocardiogram videos. By incorporating knowledge learned from\npredicting LV segmentations into LVEF regression, we can provide additional\ncontext to the model for better predictions. To this end, we propose a novel\nCyclical Self-Supervision (CSS) method for learning video-based LV\nsegmentation, which is motivated by the observation that the heartbeat is a\ncyclical process with temporal repetition. Prediction masks from our\nsegmentation model can then be used as additional input for LVEF regression to\nprovide spatial context for the LV region. We also introduce teacher-student\ndistillation to distill the information from LV segmentation masks into an\nend-to-end LVEF regression model that only requires video inputs. Results show\nour method outperforms alternative semi-supervised methods and can achieve MAE\nof 4.17, which is competitive with state-of-the-art supervised performance,\nusing half the number of labels. Validation on an external dataset also shows\nimproved generalization ability from using our method.",
    "descriptor": "",
    "authors": [
      "Weihang Dai",
      "Xiaomeng Li",
      "Xinpeng Ding",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11291"
  },
  {
    "id": "arXiv:2210.11292",
    "title": "Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts",
    "abstract": "Prompt tuning is a parameter-efficient tuning (PETuning) method for utilizing\npre-trained models (PTMs) that simply prepends a soft prompt to the input and\nonly optimizes the prompt to adapt PTMs to downstream tasks. Although it is\nparameter- and deployment-efficient, its performance still lags behind other\nstate-of-the-art PETuning methods. Besides, the training cost of prompt tuning\nis not significantly reduced due to the back-propagation through the entire\nmodel. Through empirical analyses, we shed some light on the lagging\nperformance of prompt tuning and recognize a trade-off between the propagation\ndistance from label signals to the inserted prompt and the influence of the\nprompt on model outputs. Further, we present Late Prompt Tuning (LPT) that\ninserts a late prompt into an intermediate layer of the PTM instead of the\ninput layer or all layers. The late prompt is obtained by a neural prompt\ngenerator conditioned on the hidden states before the prompt insertion layer\nand therefore is instance-dependent. Through extensive experimental results\nacross various tasks and PTMs, we show that LPT can achieve competitive\nperformance to full model tuning and other PETuning methods under both\nfull-data and few-shot scenarios while possessing faster training speed and\nlower memory cost.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022. Camera-ready version\n",
    "authors": [
      "Xiangyang Liu",
      "Tianxiang Sun",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11292"
  },
  {
    "id": "arXiv:2210.11295",
    "title": "Block subsampled randomized Hadamard transform for low-rank  approximation on distributed architectures",
    "abstract": "This article introduces a novel structured random matrix composed blockwise\nfrom subsampled randomized Hadamard transforms (SRHTs). The block SRHT is\nexpected to outperform well-known dimension reduction maps, including SRHT and\nGaussian matrices, on distributed architectures with not too many cores\ncompared to the dimension. We prove that a block SRHT with enough rows is an\noblivious subspace embedding, i.e., an approximate isometry for an arbitrary\nlow-dimensional subspace with high probability. Our estimate of the required\nnumber of rows is similar to that of the standard SRHT. This suggests that the\ntwo transforms should provide the same accuracy of approximation in the\nalgorithms. The block SRHT can be readily incorporated into randomized methods,\nfor instance to compute a low-rank approximation of a large-scale matrix. For\ncompleteness, we revisit some common randomized approaches for this problem\nsuch as Randomized Singular Value Decomposition and Nystr\\\"{o}m approximation,\nwith a discussion of their accuracy and implementation on distributed\narchitectures.",
    "descriptor": "",
    "authors": [
      "Oleg Balabanov",
      "Matthias Beaupere",
      "Laura Grigori",
      "Victor Lederer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11295"
  },
  {
    "id": "arXiv:2210.11296",
    "title": "Mean field teams and games with correlated types",
    "abstract": "Mean field games have traditionally been defined~[1,2] as a model of large\nscale interaction of players where each player has a private type that is\nindependent across the players. In this paper, we introduce a new model of mean\nfield teams and games with \\emph{correlated types} where there are a large\npopulation of homogeneous players sequentially making strategic decisions and\neach player is affected by other players through an aggregate population state.\nEach player has a private type that only she observes and types of any $N$\nplayers are correlated through a kernel $Q$. All players commonly observe a\ncorrelated mean-field population state which represents the empirical\ndistribution of any $N$ players' correlated joint types. We define the\nMean-Field Team optimal Strategies (MFTO) as strategies of the players that\nmaximize total expected joint reward of the players. We also define Mean-Field\nEquilibrium (MFE) in such games as solution of coupled Bellman dynamic\nprogramming backward equation and Fokker Planck forward equation of the\ncorrelated mean field state, where a player's strategy in an MFE depends on\nboth, her private type and current correlated mean field population state. We\npresent sufficient conditions for the existence of such an equilibria. We also\npresent a backward recursive methodology equivalent of master's equation to\ncompute all MFTO and MFEs of the team and game respectively. Each step in this\nmethodology consists of solving an optimization problem for the team problem\nand a fixed-point equation for the game. We provide sufficient conditions that\nguarantee existence of this fixed-point equation for the game for each time\n$t$.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Deepanshu Vasal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11296"
  },
  {
    "id": "arXiv:2210.11297",
    "title": "A multiscale method for inhomogeneous elastic problems with high  contrast coefficients",
    "abstract": "In this paper, we develop the constrained energy minimizing generalized\nmultiscale finite element method (CEM-GMsFEM) with mixed boundary conditions\n(Dirichlet and Neumann) for the elasticity equations in high contrast media. By\na special treatment of mixed boundary conditions separately, and combining the\nconstruction of the relaxed and constraint version of the CEM-GMsFEM, we\ndiscover that the method offers some advantages such as the independence of the\ntarget region's contrast from precision, while the sizes of oversampling\ndomains have a significant impact on numerical accuracy. Moreover, to our best\nknowledge, this is the first proof of the convergence of the CEM-GMsFEM with\nmixed boundary conditions for the elasticity equations given. Some numerical\nexperiments are provided to demonstrate the method's performance.",
    "descriptor": "\nComments: CEM-GMsFEM; mixed boundary conditions; high contrast media\n",
    "authors": [
      "Zhongqian Wang",
      "Changqing Ye",
      "Eric T. Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.11297"
  },
  {
    "id": "arXiv:2210.11298",
    "title": "Tele-Knowledge Pre-training for Fault Analysis",
    "abstract": "In this work, we share our experience on tele-knowledge pre-training for\nfault analysis. Fault analysis is a vital task for tele-application, which\nshould be timely and properly handled. Fault analysis is also a complex task,\nthat has many sub-tasks. Solving each task requires diverse tele-knowledge.\nMachine log data and product documents contain part of the tele-knowledge. We\ncreate a Tele-KG to organize other tele-knowledge from experts uniformly. With\nthese valuable tele-knowledge data, in this work, we propose a tele-domain\npre-training model KTeleBERT and its knowledge-enhanced version KTeleBERT,\nwhich includes effective prompt hints, adaptive numerical data encoding, and\ntwo knowledge injection paradigms. We train our model in two stages:\npre-training TeleBERT on 20 million telecommunication corpora and re-training\nTeleBERT on 1 million causal and machine corpora to get the KTeleBERT. Then, we\napply our models for three tasks of fault analysis, including root-cause\nanalysis, event association prediction, and fault chain tracing. The results\nshow that with KTeleBERT, the performance of task models has been boosted,\ndemonstrating the effectiveness of pre-trained KTeleBERT as a model containing\ndiverse tele-knowledge.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Zhuo Chen",
      "Wen Zhang",
      "Yufeng Huang",
      "Mingyang Chen",
      "Yuxia Geng",
      "Hongtao Yu",
      "Zhen Bi",
      "Yichi Zhang",
      "Zhen Yao",
      "Wenting Song",
      "Xinliang Wu",
      "Yi Yang",
      "Song Jiang",
      "Zhaoyang Lian",
      "Yingying Li",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11298"
  },
  {
    "id": "arXiv:2210.11299",
    "title": "Real-World Chaos-Based Cryptography Using Synchronised Chua Chaotic  Circuits",
    "abstract": "This work presents the hardware demonstrator of a secure encryption system\nbased on synchronised Chua chaotic circuits. In particular, the presented\nencryption system comprises two Chua circuits that are synchronised using a\ndedicated bidirectional synchronisation line. One of them forms part of the\ntransmitter, while the other of the receiver. Both circuits are tuned to\noperate in a chaotic mode. The output (chaotic) signal of the first circuit\n(transmitter) is digitised and then combined with the message to be encrypted,\nthrough an XOR gate. The second Chua circuit (receiver) is used for the\ndecryption; the output chaotic signal of this circuit is similarly digitised\nand combined with the encrypted message to retrieve the original message. Our\nhardware demonstrator proves that this method can be used in order to provide\nextremely lightweight real-world, chaos-based cryptographic solutions.",
    "descriptor": "\nComments: This work was accepted for and presented as a hardware demo at the 2022 IEEE International Symposium on Hardware Oriented Security and Trust (HOST 2022), held from 27 to 30 June 2022, in Washington, DC, USA\n",
    "authors": [
      "Emiliia Nazarenko",
      "Nikolaos Athanasios Anagnostopoulos",
      "Stavros G. Stavrinides",
      "Nico Mexis",
      "Florian Frank",
      "Tolga Arul",
      "Stefan Katzenbeisser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11299"
  },
  {
    "id": "arXiv:2210.11300",
    "title": "Uncovering Fingerprinting Networks. An Analysis of In-Browser Tracking  using a Behavior-based Approach",
    "abstract": "Throughout recent years, the importance of internet-privacy has continuously\nrisen. [...] Browser fingerprinting is a technique that does not require\ncookies or persistent identifiers. It derives a sufficiently unique identifier\nfrom the various browser or device properties. Academic work has covered\noffensive and defensive fingerprinting methods for almost a decade, observing a\nrise in popularity. This thesis explores the current state of browser\nfingerprinting on the internet. For that, we implement FPNET - a scalable &\nreliable tool based on FPMON, to identify fingerprinting scripts on large sets\nof websites by observing their behavior. By scanning the Alexa Top 10,000\nwebsites, we spot several hundred networks of equally behaving scripts. For\neach network, we determine the actor behind it. We track down companies like\nGoogle, Yandex, Maxmind, Sift, or FingerprintJS, to name a few. In three\ncomplementary studies, we further investigate the uncovered networks with\nregards to I) randomization of filenames or domains, II) behavior changes, III)\nsecurity. Two consecutive scans reveal that only less than 12.5% of the pages\ndo not change script files. With our behavior-based approach, we successfully\nre-identify almost 9,000 scripts whose filename or domain changed, and over 86%\nof the scripts without URL changes. The security analysis shows an adoption of\nTLS/SSL to over 98% and specific web security headers set for over 30% of the\nscripts. Finally, we voice concerns about the unavoidability of modern\nfingerprinting and its implications for internet users' privacy since we\nbelieve that many users are unaware of being fingerprinted or have insufficient\npossibilities to protect against it.",
    "descriptor": "\nComments: Master's thesis\n",
    "authors": [
      "Sebastian Neef"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.11300"
  },
  {
    "id": "arXiv:2210.11309",
    "title": "The University of Edinburgh's Submission to the WMT22 Code-Mixing Shared  Task (MixMT)",
    "abstract": "The University of Edinburgh participated in the WMT22 shared task on\ncode-mixed translation. This consists of two subtasks: i) generating code-mixed\nHindi/English (Hinglish) text generation from parallel Hindi and English\nsentences and ii) machine translation from Hinglish to English. As both\nsubtasks are considered low-resource, we focused our efforts on careful data\ngeneration and curation, especially the use of backtranslation from monolingual\nresources. For subtask 1 we explored the effects of constrained decoding on\nEnglish and transliterated subwords in order to produce Hinglish. For subtask\n2, we investigated different pretraining techniques, namely comparing simple\ninitialisation from existing machine translation models and aligned\naugmentation. For both subtasks, we found that our baseline systems worked\nbest. Our systems for both subtasks were one of the overall top-performing\nsubmissions.",
    "descriptor": "",
    "authors": [
      "Faheem Kirefu",
      "Vivek Iyer",
      "Pinzhen Chen",
      "Laurie Burchell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11309"
  },
  {
    "id": "arXiv:2210.11318",
    "title": "A Survey of Computer Vision Technologies In Urban and  Controlled-environment Agriculture",
    "abstract": "In the evolution of agriculture to its next stage, Agriculture 5.0,\nartificial intelligence will play a central role. Controlled-environment\nagriculture, or CEA, is a special form of urban and suburban agricultural\npractice that offers numerous economic, environmental, and social benefits,\nincluding shorter transportation routes to population centers, reduced\nenvironmental impact, and increased productivity. Due to its ability to control\nenvironmental factors, CEA couples well with computer vision (CV) in the\nadoption of real-time monitoring of the plant conditions and autonomous\ncultivation and harvesting. The objective of this paper is to familiarize CV\nresearchers with agricultural applications and agricultural practitioners with\nthe solutions offered by CV. We identify five major CV applications in CEA,\nanalyze their requirements and motivation, and survey the state of the art as\nreflected in 68 technical papers using deep learning methods. In addition, we\ndiscuss five key subareas of computer vision and how they related to these CEA\nproblems, as well as nine vision-based CEA datasets. We hope the survey will\nhelp researchers quickly gain a bird-eye view of the striving research area and\nwill spark inspiration for new research and development.",
    "descriptor": "\nComments: 18 pages, 2 tables, submitted to ACM Computing Surveys\n",
    "authors": [
      "Jiayun Luo",
      "Boyang Li",
      "Cyril Leung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11318"
  },
  {
    "id": "arXiv:2210.11319",
    "title": "Image-Text Retrieval with Binary and Continuous Label Supervision",
    "abstract": "Most image-text retrieval work adopts binary labels indicating whether a pair\nof image and text matches or not. Such a binary indicator covers only a limited\nsubset of image-text semantic relations, which is insufficient to represent\nrelevance degrees between images and texts described by continuous labels such\nas image captions. The visual-semantic embedding space obtained by learning\nbinary labels is incoherent and cannot fully characterize the relevance\ndegrees. In addition to the use of binary labels, this paper further\nincorporates continuous pseudo labels (generally approximated by text\nsimilarity between captions) to indicate the relevance degrees. To learn a\ncoherent embedding space, we propose an image-text retrieval framework with\nBinary and Continuous Label Supervision (BCLS), where binary labels are used to\nguide the retrieval model to learn limited binary correlations, and continuous\nlabels are complementary to the learning of image-text semantic relations. For\nthe learning of binary labels, we improve the common Triplet ranking loss with\nSoft Negative mining (Triplet-SN) to improve convergence. For the learning of\ncontinuous labels, we design Kendall ranking loss inspired by Kendall rank\ncorrelation coefficient (Kendall), which improves the correlation between the\nsimilarity scores predicted by the retrieval model and the continuous labels.\nTo mitigate the noise introduced by the continuous pseudo labels, we further\ndesign Sliding Window sampling and Hard Sample mining strategy (SW-HS) to\nalleviate the impact of noise and reduce the complexity of our framework to the\nsame order of magnitude as the triplet ranking loss. Extensive experiments on\ntwo image-text retrieval benchmarks demonstrate that our method can improve the\nperformance of state-of-the-art image-text retrieval models.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Zheng Li",
      "Caili Guo",
      "Zerun Feng",
      "Jenq-Neng Hwang",
      "Ying Jin",
      "Yufeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.11319"
  },
  {
    "id": "arXiv:2210.11321",
    "title": "A Study of Scalarisation Techniques for Multi-Objective QUBO Solving",
    "abstract": "In recent years, there has been significant research interest in solving\nQuadratic Unconstrained Binary Optimisation (QUBO) problems. Physics-inspired\noptimisation algorithms have been proposed for deriving optimal or sub-optimal\nsolutions to QUBOs. These methods are particularly attractive within the\ncontext of using specialised hardware, such as quantum computers, application\nspecific CMOS and other high performance computing resources for solving\noptimisation problems. These solvers are then applied to QUBO formulations of\ncombinatorial optimisation problems. Quantum and quantum-inspired optimisation\nalgorithms have shown promising performance when applied to academic benchmarks\nas well as real-world problems. However, QUBO solvers are single objective\nsolvers. To make them more efficient at solving problems with multiple\nobjectives, a decision on how to convert such multi-objective problems to\nsingle-objective problems need to be made. In this study, we compare methods of\nderiving scalarisation weights when combining two objectives of the cardinality\nconstrained mean-variance portfolio optimisation problem into one. We show\nsignificant performance improvement (measured in terms of hypervolume) when\nusing a method that iteratively fills the largest space in the Pareto front\ncompared to a n\\\"aive approach using uniformly generated weights.",
    "descriptor": "",
    "authors": [
      "Mayowa Ayodele",
      "Richard Allmendinger",
      "Manuel L\u00f3pez-Ib\u00e1\u00f1ez",
      "Matthieu Parizy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.11321"
  },
  {
    "id": "arXiv:2210.11322",
    "title": "The Effectiveness of Social Media Engagement Strategy on Disaster  Fundraising",
    "abstract": "Social media has been a powerful tool and an integral part of communication,\nespecially during natural disasters. Social media platforms help nonprofits in\neffective disaster management by disseminating crucial information to various\ncommunities at the earliest. Besides spreading information to every corner of\nthe world, various platforms incorporate many features that give access to host\nonline fundraising events, process online donations, etc. The current\nliterature lacks the theoretical structure investigating the correlation\nbetween social media engagement and crisis management. Large nonprofit\norganisations like the Australian Red Cross have upscaled their operations to\nhelp nearly 6,000 bushfire survivors through various grants and helped 21,563\npeople with psychological support and other assistance through their recovery\nprogram (Australian Red Cross, 2021). This paper considers the case of\nbushfires in Australia 2019-2020 to inspect the role of social media in\nescalating fundraising via analysing the donation data of the Australian Red\nCross from October 2019 - March 2020 and analysing the level of public\ninteraction with their Facebook page and its content in the same period.",
    "descriptor": "",
    "authors": [
      "Vivek Velivela",
      "Chahat Raj",
      "Muhammad Salman Tiwana",
      "Raj Prasanna",
      "Mahendra Samarawickrama",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11322"
  },
  {
    "id": "arXiv:2210.11327",
    "title": "Improving Data Quality with Training Dynamics of Gradient Boosting  Decision Trees",
    "abstract": "Real world datasets contain incorrectly labeled instances that hamper the\nperformance of the model and, in particular, the ability to generalize out of\ndistribution. Also, each example might have different contribution towards\nlearning. This motivates studies to better understanding of the role of data\ninstances with respect to their contribution in good metrics in models. In this\npaper we propose a method based on metrics computed from training dynamics of\nGradient Boosting Decision Trees (GBDTs) to assess the behavior of each\ntraining example. We focus on datasets containing mostly tabular or structured\ndata, for which the use of Decision Trees ensembles are still the\nstate-of-the-art in terms of performance. We show results on detecting noisy\nlabels in order to either remove them, improving models' metrics in synthetic\nand real datasets, as well as a productive dataset. Our methods achieved the\nbest results overall when compared with confident learning and heuristics.",
    "descriptor": "",
    "authors": [
      "Moacir Antonelli Ponti",
      "Lucas de Angelis Oliveira",
      "Juan Mart\u00edn Rom\u00e1n",
      "Luis Argerich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11327"
  },
  {
    "id": "arXiv:2210.11328",
    "title": "Play It Back: Iterative Attention for Audio Recognition",
    "abstract": "A key function of auditory cognition is the association of characteristic\nsounds with their corresponding semantics over time. Humans attempting to\ndiscriminate between fine-grained audio categories, often replay the same\ndiscriminative sounds to increase their prediction confidence. We propose an\nend-to-end attention-based architecture that through selective repetition\nattends over the most discriminative sounds across the audio sequence. Our\nmodel initially uses the full audio sequence and iteratively refines the\ntemporal segments replayed based on slot attention. At each playback, the\nselected segments are replayed using a smaller hop length which represents\nhigher resolution features within these segments. We show that our method can\nconsistently achieve state-of-the-art performance across three\naudio-classification benchmarks: AudioSet, VGG-Sound, and EPIC-KITCHENS-100.",
    "descriptor": "",
    "authors": [
      "Alexandros Stergiou",
      "Dima Damen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11328"
  },
  {
    "id": "arXiv:2210.11334",
    "title": "Proof of Unlearning: Definitions and Instantiation",
    "abstract": "The \"Right to be Forgotten\" rule in machine learning (ML) practice enables\nsome individual data to be deleted from a trained model, as pursued by recently\ndeveloped machine unlearning techniques. To truly comply with the rule, a\nnatural and necessary step is to verify if the individual data are indeed\ndeleted after unlearning. Yet, previous parameter-space verification metrics\nmay be easily evaded by a distrustful model trainer. Thus, Thudi et al.\nrecently present a call to action on algorithm-level verification in USENIX\nSecurity'22.\nWe respond to the call, by reconsidering the unlearning problem in the\nscenario of machine learning as a service (MLaaS), and proposing a new\ndefinition framework for Proof of Unlearning (PoUL) on algorithm level.\nSpecifically, our PoUL definitions (i) enforce correctness properties on both\nthe pre and post phases of unlearning, so as to prevent the state-of-the-art\nforging attacks; (ii) highlight proper practicality requirements of both the\nprover and verifier sides with minimal invasiveness to the off-the-shelf\nservice pipeline and computational workloads. Under the definition framework,\nwe subsequently present a trusted hardware-empowered instantiation using SGX\nenclave, by logically incorporating an authentication layer for tracing the\ndata lineage with a proving layer for supporting the audit of learning. We\ncustomize authenticated data structures to support large out-of-enclave storage\nwith simple operation logic, and meanwhile, enable proving complex unlearning\nlogic with affordable memory footprints in the enclave. We finally validate the\nfeasibility of the proposed instantiation with a proof-of-concept\nimplementation and multi-dimensional performance evaluation.",
    "descriptor": "",
    "authors": [
      "Jiasi Weng",
      "Shenglong Yao",
      "Yuefeng Du",
      "Junjie Huang",
      "Jian Weng",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11334"
  },
  {
    "id": "arXiv:2210.11339",
    "title": "VIOLA: Imitation Learning for Vision-Based Manipulation with Object  Proposal Priors",
    "abstract": "We introduce VIOLA, an object-centric imitation learning approach to learning\nclosed-loop visuomotor policies for robot manipulation. Our approach constructs\nobject-centric representations based on general object proposals from a\npre-trained vision model. VIOLA uses a transformer-based policy to reason over\nthese representations and attend to the task-relevant visual factors for action\nprediction. Such object-based structural priors improve deep imitation learning\nalgorithm's robustness against object variations and environmental\nperturbations. We quantitatively evaluate VIOLA in simulation and on real\nrobots. VIOLA outperforms the state-of-the-art imitation learning methods by\n$45.8\\%$ in success rate. It has also been deployed successfully on a physical\nrobot to solve challenging long-horizon tasks, such as dining table arrangement\nand coffee making. More videos and model details can be found in supplementary\nmaterial and the project website: https://ut-austin-rpl.github.io/VIOLA .",
    "descriptor": "\nComments: To be published at the 6th Conference on Robot Learning\n",
    "authors": [
      "Yifeng Zhu",
      "Abhishek Joshi",
      "Peter Stone",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11339"
  },
  {
    "id": "arXiv:2210.11340",
    "title": "Towards cryptographically-authenticated in-memory data structures",
    "abstract": "Modern processors include high-performance cryptographic functionalities such\nas Intel's AES-NI and ARM's Pointer Authentication that allow programs to\nefficiently authenticate data held by the program. Pointer Authentication is\nalready used to protect return addresses in recent Apple devices, but as yet\nthese structures have seen little use for the protection of general program\ndata.\nIn this paper, we show how cryptographically-authenticated data structures\ncan be used to protect against attacks based on memory corruption, and show how\nthey can be efficiently realized using widely available hardware-assisted\ncryptographic mechanisms. We present realizations of secure stacks and queues\nwith minimal overall performance overhead (3.4%-6.4% slowdown of the OpenCV\ncore performance tests), and provide proofs of correctness.",
    "descriptor": "\nComments: Presented at the 2022 IEEE Secure Development Conference. Copyright 2022 IEEE\n",
    "authors": [
      "Setareh Ghorshi",
      "Lachlan J. Gunn",
      "Hans Liljestrand",
      "N. Asokan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.11340"
  },
  {
    "id": "arXiv:2210.11341",
    "title": "SS-VAERR: Self-Supervised Apparent Emotional Reaction Recognition from  Video",
    "abstract": "This work focuses on the apparent emotional reaction recognition (AERR) from\nthe video-only input, conducted in a self-supervised fashion. The network is\nfirst pre-trained on different self-supervised pretext tasks and later\nfine-tuned on the downstream target task. Self-supervised learning facilitates\nthe use of pre-trained architectures and larger datasets that might be deemed\nunfit for the target task and yet might be useful to learn informative\nrepresentations and hence provide useful initializations for further\nfine-tuning on smaller more suitable data. Our presented contribution is\ntwo-fold: (1) an analysis of different state-of-the-art (SOTA) pretext tasks\nfor the video-only apparent emotional reaction recognition architecture, and\n(2) an analysis of various combinations of the regression and classification\nlosses that are likely to improve the performance further. Together these two\ncontributions result in the current state-of-the-art performance for the\nvideo-only spontaneous apparent emotional reaction recognition with continuous\nannotations.",
    "descriptor": "",
    "authors": [
      "Marija Jegorova",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11341"
  },
  {
    "id": "arXiv:2210.11344",
    "title": "Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual  Funds",
    "abstract": "The profitability of various investment styles in investment funds depends on\nmacroeconomic conditions. Market ecology, which views financial markets as\necosystems of diverse, interacting and evolving trading strategies, has shown\nthat endogenous interactions between strategies determine market behaviour and\nstyles' performance. We present Evology: a heterogeneous, empirically\ncalibrated multi-agent market ecology agent-based model to quantify endogenous\ninteractions between US equity mutual funds, particularly Value and Growth\ninvestment styles. We outline the model design, validation and calibration\napproach and its potential for optimising investment strategies using machine\nlearning algorithms.",
    "descriptor": "",
    "authors": [
      "Aymeric Vie",
      "Maarten Scholl",
      "Alissa M. Kleinnijenhuis",
      "Doyne J. Farmer"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.11344"
  },
  {
    "id": "arXiv:2210.11348",
    "title": "Hypernetworks in Meta-Reinforcement Learning",
    "abstract": "Training a reinforcement learning (RL) agent on a real-world robotics task\nremains generally impractical due to sample inefficiency. Multi-task RL and\nmeta-RL aim to improve sample efficiency by generalizing over a distribution of\nrelated tasks. However, doing so is difficult in practice: In multi-task RL,\nstate of the art methods often fail to outperform a degenerate solution that\nsimply learns each task separately. Hypernetworks are a promising path forward\nsince they replicate the separate policies of the degenerate solution while\nalso allowing for generalization across tasks, and are applicable to meta-RL.\nHowever, evidence from supervised learning suggests hypernetwork performance is\nhighly sensitive to the initialization. In this paper, we 1) show that\nhypernetwork initialization is also a critical factor in meta-RL, and that\nnaive initializations yield poor performance; 2) propose a novel hypernetwork\ninitialization scheme that matches or exceeds the performance of a\nstate-of-the-art approach proposed for supervised settings, as well as being\nsimpler and more general; and 3) use this method to show that hypernetworks can\nimprove performance in meta-RL by evaluating on multiple simulated robotics\nbenchmarks.",
    "descriptor": "\nComments: Published at CoRL 2022\n",
    "authors": [
      "Jacob Beck",
      "Matthew Thomas Jackson",
      "Risto Vuorio",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11348"
  },
  {
    "id": "arXiv:2210.11350",
    "title": "A Survey on Over-the-Air Computation",
    "abstract": "Communication and computation are often viewed as separate tasks. This\napproach is very effective from the perspective of engineering as isolated\noptimizations can be performed. On the other hand, there are many cases where\nthe main interest is a function of the local information at the devices instead\nof the local information itself. For such scenarios, information theoretical\nresults show that harnessing the interference in a multiple-access channel for\ncomputation, i.e., over-the-air computation (OAC), can provide a significantly\nhigher achievable computation rate than the one with the separation of\ncommunication and computation tasks. Besides, the gap between OAC and\nseparation in terms of computation rate increases with more participating\nnodes. Given this motivation, in this study, we provide a comprehensive survey\non practical OAC methods. After outlining fundamentals related to OAC, we\ndiscuss the available OAC schemes with their pros and cons. We then provide an\noverview of the enabling mechanisms and relevant metrics to achieve reliable\ncomputation in the wireless channel. Finally, we summarize the potential\napplications of OAC and point out some future directions.",
    "descriptor": "\nComments: 26 pages, 6 Figures; Comments are welcome! (IEEE Communications Surveys & Tutorials)\n",
    "authors": [
      "Alphan Sahin",
      "Rui Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11350"
  },
  {
    "id": "arXiv:2210.11359",
    "title": "Data-Efficient Strategies for Expanding Hate Speech Detection into  Under-Resourced Languages",
    "abstract": "Hate speech is a global phenomenon, but most hate speech datasets so far\nfocus on English-language content. This hinders the development of more\neffective hate speech detection models in hundreds of languages spoken by\nbillions across the world. More data is needed, but annotating hateful content\nis expensive, time-consuming and potentially harmful to annotators. To mitigate\nthese issues, we explore data-efficient strategies for expanding hate speech\ndetection into under-resourced languages. In a series of experiments with mono-\nand multilingual models across five non-English languages, we find that 1) a\nsmall amount of target-language fine-tuning data is needed to achieve strong\nperformance, 2) the benefits of using more such data decrease exponentially,\nand 3) initial fine-tuning on readily-available English data can partially\nsubstitute target-language data and improve model generalisability. Based on\nthese findings, we formulate actionable recommendations for hate speech\ndetection in low-resource language settings.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (Main Conference)\n",
    "authors": [
      "Paul R\u00f6ttger",
      "Debora Nozza",
      "Federico Bianchi",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11359"
  },
  {
    "id": "arXiv:2210.11362",
    "title": "Practical Alternating Least Squares for Tensor Ring Decomposition",
    "abstract": "Tensor ring (TR) decomposition has been widely applied as an effective\napproach in a variety of applications to discover the hidden low-rank patterns\nin multidimensional data. A well-known method for TR decomposition is the\nalternating least squares (ALS). However, it often suffers from the notorious\nintermediate data explosion issue, especially for large-scale tensors. In this\npaper, we provide two strategies to tackle this issue and design three\nALS-based algorithms. Specifically, the first strategy is used to simplify the\ncalculation of the coefficient matrices of the normal equations for the ALS\nsubproblems, which takes full advantage of the structure of the coefficient\nmatrices of the subproblems and hence makes the corresponding algorithm perform\nmuch better than the regular ALS method in terms of computing time. The second\nstrategy is to stabilize the ALS subproblems by QR factorizations on TR-cores,\nand hence the corresponding algorithms are more numerically stable compared\nwith our first algorithm. Extensive numerical experiments on synthetic and real\ndata are given to illustrate and confirm the above results. In addition, we\nalso present the complexity analyses of the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Yajie Yu",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.11362"
  },
  {
    "id": "arXiv:2210.11366",
    "title": "Deep conditional transformation models for survival analysis",
    "abstract": "An every increasing number of clinical trials features a time-to-event\noutcome and records non-tabular patient data, such as magnetic resonance\nimaging or text data in the form of electronic health records. Recently,\nseveral neural-network based solutions have been proposed, some of which are\nbinary classifiers. Parametric, distribution-free approaches which make full\nuse of survival time and censoring status have not received much attention. We\npresent deep conditional transformation models (DCTMs) for survival outcomes as\na unifying approach to parametric and semiparametric survival analysis. DCTMs\nallow the specification of non-linear and non-proportional hazards for both\ntabular and non-tabular data and extend to all types of censoring and\ntruncation. On real and semi-synthetic data, we show that DCTMs compete with\nstate-of-the-art DL approaches to survival analysis.",
    "descriptor": "",
    "authors": [
      "Gabriele Campanella",
      "Lucas Kook",
      "Ida H\u00e4ggstr\u00f6m",
      "Torsten Hothorn",
      "Thomas J. Fuchs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11366"
  },
  {
    "id": "arXiv:2210.11369",
    "title": "On Feature Learning in the Presence of Spurious Correlations",
    "abstract": "Deep classifiers are known to rely on spurious features $\\unicode{x2013}$\npatterns which are correlated with the target on the training data but not\ninherently relevant to the learning problem, such as the image backgrounds when\nclassifying the foregrounds. In this paper we evaluate the amount of\ninformation about the core (non-spurious) features that can be decoded from the\nrepresentations learned by standard empirical risk minimization (ERM) and\nspecialized group robustness training. Following recent work on Deep Feature\nReweighting (DFR), we evaluate the feature representations by re-training the\nlast layer of the model on a held-out set where the spurious correlation is\nbroken. On multiple vision and NLP problems, we show that the features learned\nby simple ERM are highly competitive with the features learned by specialized\ngroup robustness methods targeted at reducing the effect of spurious\ncorrelations. Moreover, we show that the quality of learned feature\nrepresentations is greatly affected by the design decisions beyond the training\nmethod, such as the model architecture and pre-training strategy. On the other\nhand, we find that strong regularization is not necessary for learning high\nquality feature representations. Finally, using insights from our analysis, we\nsignificantly improve upon the best results reported in the literature on the\npopular Waterbirds, CelebA hair color prediction and WILDS-FMOW problems,\nachieving 97%, 92% and 50% worst-group accuracies, respectively.",
    "descriptor": "\nComments: NeurIPS 2022. Code available at this https URL\n",
    "authors": [
      "Pavel Izmailov",
      "Polina Kirichenko",
      "Nate Gruver",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11369"
  },
  {
    "id": "arXiv:2210.11370",
    "title": "Optimizing Surveillance Satellites for the Synthetic Theater Operations  Research Model",
    "abstract": "The Synthetic Theater Operations Research Model (STORM) simulates\ntheater-level conflict and requires inputs about utilization of surveillance\nsatellites to search large geographical areas. We develop a mixed-integer\nlinear optimization model that prescribes plans for how satellites and their\nsensors should be directed to best search an area of operations. It also\nspecifies the resolution levels employed by the sensors to ensure a suitable\nfidelity of the resulting images. We solve large-scale instances of the model\ninvolving up to 22 million variables and 11 million constraints in scenarios\nderived from STORM. On average, the model yields 55% improvement in search\ncoverage relative to an existing heuristic algorithm in STORM.",
    "descriptor": "",
    "authors": [
      "Steven M. Warner",
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11370"
  },
  {
    "id": "arXiv:2210.11374",
    "title": "Meeting Decision Tracker: Making Meeting Minutes with De-Contextualized  Utterances",
    "abstract": "Meetings are a universal process to make decisions in business and project\ncollaboration. The capability to automatically itemize the decisions in daily\nmeetings allows for extensive tracking of past discussions. To that end, we\ndeveloped Meeting Decision Tracker, a prototype system to construct decision\nitems comprising decision utterance detector (DUD) and decision utterance\nrewriter (DUR). We show that DUR makes a sizable contribution to improving the\nuser experience by dealing with utterance collapse in natural conversation. An\nintroduction video of our system is also available at\nhttps://youtu.be/TG1pJJo0Iqo.",
    "descriptor": "\nComments: 7 pages, AACL-IJCNLP 2022\n",
    "authors": [
      "Shumpei Inoue",
      "Hy Nguyen",
      "Pham Viet Hoang",
      "Tsungwei Liu",
      "Minh-Tien Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11374"
  },
  {
    "id": "arXiv:2210.11384",
    "title": "Transformer-based Global 3D Hand Pose Estimation in Two Hands  Manipulating Objects Scenarios",
    "abstract": "This report describes our 1st place solution to ECCV 2022 challenge on Human\nBody, Hands, and Activities (HBHA) from Egocentric and Multi-view Cameras (hand\npose estimation). In this challenge, we aim to estimate global 3D hand poses\nfrom the input image where two hands and an object are interacting on the\negocentric viewpoint. Our proposed method performs end-to-end multi-hand pose\nestimation via transformer architecture. In particular, our method robustly\nestimates hand poses in a scenario where two hands interact. Additionally, we\npropose an algorithm that considers hand scales to robustly estimate the\nabsolute depth. The proposed algorithm works well even when the hand sizes are\nvarious for each person. Our method attains 14.4 mm (left) and 15.9 mm (right)\nerrors for each hand in the test set.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Hoseong Cho",
      "Donguk Kim",
      "Chanwoo Kim",
      "Seongyeong Lee",
      "Seungryul Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11384"
  },
  {
    "id": "arXiv:2210.11387",
    "title": "Transformer-based Action recognition in hand-object interacting  scenarios",
    "abstract": "This report describes the 2nd place solution to the ECCV 2022 Human Body,\nHands, and Activities (HBHA) from Egocentric and Multi-view Cameras Challenge:\nAction Recognition. This challenge aims to recognize hand-object interaction in\nan egocentric view. We propose a framework that estimates keypoints of two\nhands and an object with a Transformer-based keypoint estimator and recognizes\nactions based on the estimated keypoints. We achieved a top-1 accuracy of\n87.19% on the testset.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Hoseong Cho",
      "Seungryul Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11387"
  },
  {
    "id": "arXiv:2210.11389",
    "title": "TTTFlow: Unsupervised Test-Time Training with Normalizing Flow",
    "abstract": "A major problem of deep neural networks for image classification is their\nvulnerability to domain changes at test-time. Recent methods have proposed to\naddress this problem with test-time training (TTT), where a two-branch model is\ntrained to learn a main classification task and also a self-supervised task\nused to perform test-time adaptation. However, these techniques require\ndefining a proxy task specific to the target application. To tackle this\nlimitation, we propose TTTFlow: a Y-shaped architecture using an unsupervised\nhead based on Normalizing Flows to learn the normal distribution of latent\nfeatures and detect domain shifts in test examples. At inference, keeping the\nunsupervised head fixed, we adapt the model to domain-shifted examples by\nmaximizing the log likelihood of the Normalizing Flow. Our results show that\nour method can significantly improve the accuracy with respect to previous\nworks.",
    "descriptor": "",
    "authors": [
      "David Osowiechi",
      "Gustavo A. Vargas Hakim",
      "Mehrdad Noori",
      "Milad Cheraghalikhani",
      "Ismail Ben Ayed",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11389"
  },
  {
    "id": "arXiv:2210.11392",
    "title": "Deep reinforcement learning oriented for real world dynamic scenarios",
    "abstract": "Autonomous navigation in dynamic environments is a complex but essential task\nfor autonomous robots. Recent deep reinforcement learning approaches show\npromising results to solve the problem, but it is not solved yet, as they\ntypically assume no robot kinodynamic restrictions, holonomic movement or\nperfect environment knowledge. Moreover, most algorithms fail in the real world\ndue to the inability to generate real-world training data for the huge\nvariability of possible scenarios. In this work, we present a novel planner,\nDQN-DOVS, that uses deep reinforcement learning on a descriptive robocentric\nvelocity space model to navigate in highly dynamic environments. It is trained\nusing a smart curriculum learning approach on a simulator that faithfully\nreproduces the real world, reducing the gap between the reality and simulation.\nWe test the resulting algorithm in scenarios with different number of obstacles\nand compare it with many state-of-the-art approaches, obtaining a better\nperformance. Finally, we try the algorithm in a ground robot, using the same\nsetup as in the simulation experiments.",
    "descriptor": "\nComments: Perception and Navigation for Autonomous Robotics in Unstructured and Dynamic Environments (PNARUDE) workshop in IROS 2022\n",
    "authors": [
      "Diego Martinez",
      "Luis Riazuelo",
      "Luis Montano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11392"
  },
  {
    "id": "arXiv:2210.11394",
    "title": "Solving Reasoning Tasks with a Slot Transformer",
    "abstract": "The ability to carve the world into useful abstractions in order to reason\nabout time and space is a crucial component of intelligence. In order to\nsuccessfully perceive and act effectively using senses we must parse and\ncompress large amounts of information for further downstream reasoning to take\nplace, allowing increasingly complex concepts to emerge. If there is any hope\nto scale representation learning methods to work with real world scenes and\ntemporal dynamics then there must be a way to learn accurate, concise, and\ncomposable abstractions across time. We present the Slot Transformer, an\narchitecture that leverages slot attention, transformers and iterative\nvariational inference on video scene data to infer such representations. We\nevaluate the Slot Transformer on CLEVRER, Kinetics-600 and CATER datesets and\ndemonstrate that the approach allows us to develop robust modeling and\nreasoning around complex behaviours as well as scores on these datasets that\ncompare favourably to existing baselines. Finally we evaluate the effectiveness\nof key components of the architecture, the model's representational capacity\nand its ability to predict from incomplete input.",
    "descriptor": "",
    "authors": [
      "Ryan Faulkner",
      "Daniel Zoran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11394"
  },
  {
    "id": "arXiv:2210.11399",
    "title": "Transcending Scaling Laws with 0.1% Extra Compute",
    "abstract": "Scaling language models improves performance but comes with significant\ncomputational costs. This paper proposes UL2R, a method that substantially\nimproves existing language models and their scaling curves with a relatively\ntiny amount of extra compute. The key idea is to continue training a\nstate-of-the-art large language model (e.g., PaLM) on a few more steps with\nUL2's mixture-of-denoiser objective. We show that, with almost negligible extra\ncomputational costs and no new sources of data, we are able to substantially\nimprove the scaling properties of large language models on downstream metrics.\nIn this paper, we continue training PaLM with UL2R, introducing a new set of\nmodels at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B\nscale, we show an approximately 2x computational savings rate where U-PaLM\nachieves the same performance as the final PaLM 540B model at around half its\ncomputational budget (i.e., saving $\\sim$4.4 million TPUv4 hours). We further\nshow that this improved scaling curve leads to 'emergent abilities' on\nchallenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM\non some tasks or demonstrates better quality at much smaller scale (62B as\nopposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many\nfew-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question\nanswering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual\ntasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide\nqualitative examples showing the new capabilities of U-PaLM for single and\nmulti-span infilling.",
    "descriptor": "",
    "authors": [
      "Yi Tay",
      "Jason Wei",
      "Hyung Won Chung",
      "Vinh Q. Tran",
      "David R. So",
      "Siamak Shakeri",
      "Xavier Garcia",
      "Huaixiu Steven Zheng",
      "Jinfeng Rao",
      "Aakanksha Chowdhery",
      "Denny Zhou",
      "Donald Metzler",
      "Slav Petrov",
      "Neil Houlsby",
      "Quoc V. Le",
      "Mostafa Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11399"
  },
  {
    "id": "arXiv:2210.11402",
    "title": "Learning Rationalizable Equilibria in Multiplayer Games",
    "abstract": "A natural goal in multiagent learning besides finding equilibria is to learn\nrationalizable behavior, where players learn to avoid iteratively dominated\nactions. However, even in the basic setting of multiplayer general-sum games,\nexisting algorithms require a number of samples exponential in the number of\nplayers to learn rationalizable equilibria under bandit feedback. This paper\ndevelops the first line of efficient algorithms for learning rationalizable\nCoarse Correlated Equilibria (CCE) and Correlated Equilibria (CE) whose sample\ncomplexities are polynomial in all problem parameters including the number of\nplayers. To achieve this result, we also develop a new efficient algorithm for\nthe simpler task of finding one rationalizable action profile (not necessarily\nan equilibrium), whose sample complexity substantially improves over the best\nexisting results of Wu et al. (2021). Our algorithms incorporate several novel\ntechniques to guarantee rationalizability and no (swap-)regret simultaneously,\nincluding a correlated exploration scheme and adaptive learning rates, which\nmay be of independent interest. We complement our results with a sample\ncomplexity lower bound showing the sharpness of our guarantees.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Yuanhao Wang",
      "Dingwen Kong",
      "Yu Bai",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11402"
  },
  {
    "id": "arXiv:2210.11404",
    "title": "Self-Supervised Learning with Masked Image Modeling for Teeth Numbering,  Detection of Dental Restorations, and Instance Segmentation in Dental  Panoramic Radiographs",
    "abstract": "The computer-assisted radiologic informative report is currently emerging in\ndental practice to facilitate dental care and reduce time consumption in manual\npanoramic radiographic interpretation. However, the amount of dental\nradiographs for training is very limited, particularly from the point of view\nof deep learning. This study aims to utilize recent self-supervised learning\nmethods like SimMIM and UM-MAE to increase the model efficiency and\nunderstanding of the limited number of dental radiographs. We use the Swin\nTransformer for teeth numbering, detection of dental restorations, and instance\nsegmentation tasks. To the best of our knowledge, this is the first study that\napplied self-supervised learning methods to Swin Transformer on dental\npanoramic radiographs. Our results show that the SimMIM method obtained the\nhighest performance of 90.4% and 88.9% on detecting teeth and dental\nrestorations and instance segmentation, respectively, increasing the average\nprecision by 13.4 and 12.8 over the random initialization baseline. Moreover,\nwe augment and correct the existing dataset of panoramic radiographs. The code\nand the dataset are available at https://github.com/AmaniHAlmalki/DentalMIM.",
    "descriptor": "",
    "authors": [
      "Amani Almalki",
      "Longin Jan Latecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11404"
  },
  {
    "id": "arXiv:2210.11407",
    "title": "Similarity of Neural Architectures Based on Input Gradient  Transferability",
    "abstract": "In this paper, we aim to design a quantitative similarity function between\ntwo neural architectures. Specifically, we define a model similarity using\ninput gradient transferability. We generate adversarial samples of two networks\nand measure the average accuracy of the networks on adversarial samples of each\nother. If two networks are highly correlated, then the attack transferability\nwill be high, resulting in high similarity. Using the similarity score, we\ninvestigate two topics: (1) Which network component contributes to the model\ndiversity? (2) How does model diversity affect practical scenarios? We answer\nthe first question by providing feature importance analysis and clustering\nanalysis. The second question is validated by two different scenarios: model\nensemble and knowledge distillation. Our findings show that model diversity\ntakes a key role when interacting with different neural architectures. For\nexample, we found that more diversity leads to better ensemble performance. We\nalso observe that the relationship between teacher and student networks and\ndistillation performance depends on the choice of the base architecture of the\nteacher and student networks. We expect our analysis tool helps a high-level\nunderstanding of differences between various neural architectures as well as\npractical guidance when using multiple architectures.",
    "descriptor": "\nComments: 21pages, 10 figures, 1.5MB\n",
    "authors": [
      "Jaehui Hwang",
      "Dongyoon Han",
      "Byeongho Heo",
      "Song Park",
      "Sanghyuk Chun",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11407"
  },
  {
    "id": "arXiv:2210.11411",
    "title": "Holbert: Reading, Writing, Proving and Learning in the Browser",
    "abstract": "This paper presents Holbert: a work-in-progress pedagogical proof assistant\nand online textbook platform, aimed at the educational use-case, specifically\nfor the teaching of programming language theory. Holbert allows proof exercises\nand rule definitions to be embedded directly in an online textbook, where\nproofs and rules can be manipulated using a graphical interface. We give an\noverview of the logical foundations of Holbert, examples of its use, and give\nan update as to its current implementation status.",
    "descriptor": "\nComments: Short paper for Human Aspects of Types and Reasoning Assistants (HATRA), 2022. 8 pages, plus 2 pages references\n",
    "authors": [
      "Liam O'Connor",
      "Rayhana Amjad"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.11411"
  },
  {
    "id": "arXiv:2210.11416",
    "title": "Scaling Instruction-Finetuned Language Models",
    "abstract": "Finetuning language models on a collection of datasets phrased as\ninstructions has been shown to improve model performance and generalization to\nunseen tasks. In this paper we explore instruction finetuning with a particular\nfocus on (1) scaling the number of tasks, (2) scaling the model size, and (3)\nfinetuning on chain-of-thought data. We find that instruction finetuning with\nthe above aspects dramatically improves performance on a variety of model\nclasses (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and\nevaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For\ninstance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM\n540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves\nstate-of-the-art performance on several benchmarks, such as 75.2% on five-shot\nMMLU. We also publicly release Flan-T5 checkpoints, which achieve strong\nfew-shot performance even compared to much larger models, such as PaLM 62B.\nOverall, instruction finetuning is a general method for improving the\nperformance and usability of pretrained language models.",
    "descriptor": "\nComments: Public checkpoints: this https URL\n",
    "authors": [
      "Hyung Won Chung",
      "Le Hou",
      "Shayne Longpre",
      "Barret Zoph",
      "Yi Tay",
      "William Fedus",
      "Eric Li",
      "Xuezhi Wang",
      "Mostafa Dehghani",
      "Siddhartha Brahma",
      "Albert Webson",
      "Shixiang Shane Gu",
      "Zhuyun Dai",
      "Mirac Suzgun",
      "Xinyun Chen",
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Gaurav Mishra",
      "Adams Yu",
      "Vincent Zhao",
      "Yanping Huang",
      "Andrew Dai",
      "Hongkun Yu",
      "Slav Petrov",
      "Ed H. Chi",
      "Jeff Dean",
      "Jacob Devlin",
      "Adam Roberts",
      "Denny Zhou",
      "Quoc V. Le",
      "Jason Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11416"
  },
  {
    "id": "arXiv:2210.11419",
    "title": "GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama  Registration Network",
    "abstract": "Reconstructing 3D layouts from multiple $360^{\\circ}$ panoramas has received\nincreasing attention recently as estimating a complete layout of a large-scale\nand complex room from a single panorama is very difficult. The state-of-the-art\nmethod, called PSMNet, introduces the first learning-based framework that\njointly estimates the room layout and registration given a pair of panoramas.\nHowever, PSMNet relies on an approximate (i.e., \"noisy\") registration as input.\nObtaining this input requires a solution for wide baseline registration which\nis a challenging problem. In this work, we present a complete multi-view\npanoramic layout estimation framework that jointly learns panorama registration\nand layout estimation given a pair of panoramas without relying on a pose\nprior. The major improvement over PSMNet comes from a novel Geometry-aware\nPanorama Registration Network or GPR-Net that effectively tackles the wide\nbaseline registration problem by exploiting the layout geometry and computing\nfine-grained correspondences on the layout boundaries, instead of the global\npixel-space. Our architecture consists of two parts. First, given two\npanoramas, we adopt a vision transformer to learn a set of 1D horizon features\nsampled on the panorama. These 1D horizon features encode the depths of\nindividual layout boundary samples and the correspondence and covisibility maps\nbetween layout boundaries. We then exploit a non-linear registration module to\nconvert these 1D horizon features into a set of corresponding 2D boundary\npoints on the layout. Finally, we estimate the final relative camera pose via\nRANSAC and obtain the complete layout simply by taking the union of registered\nlayouts. Experimental results indicate that our method achieves\nstate-of-the-art performance in both panorama registration and layout\nestimation on a large-scale indoor panorama dataset ZInD.",
    "descriptor": "",
    "authors": [
      "Jheng-Wei Su",
      "Chi-Han Peng",
      "Peter Wonka",
      "Hung-Kuo Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11419"
  },
  {
    "id": "arXiv:2210.11421",
    "title": "Application of artificial neural network to determine the thickness  profile of thin film",
    "abstract": "In this paper, we introduce a novel artificial neural network (ANN) based\nscheme to estimate the thickness of thin films deposited on a given substrate.\nHere we consider the visible interference pattern between a plane wave and a\ndiverging wave reflected from the thin film surface that records the thickness\ninformation of the thin film. We assume a uniform thickness profile of the\nfilm. However, the thickness increases as the deposition takes place. We\nextract the intensity data along a line through the center of the interference\npattern. We train our network by using a number of such line information of\nknown thickness profiles. The performance of the trained network is then tested\nby estimating the thickness of unknown surfaces. The numerical simulation\nresults show that the proposed technique can be very much useful for automated\nmeasurement of thickness, quickly and in real time, during deposition",
    "descriptor": "\nComments: 8 pages, 4 figures, XII Biennial National Conference of Physics Academy of North East (PANE2021) 15-17 December, 2021\n",
    "authors": [
      "Archana Bora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11421"
  },
  {
    "id": "arXiv:2210.11427",
    "title": "DiffEdit: Diffusion-based semantic image editing with mask guidance",
    "abstract": "Image generation has recently seen tremendous advances, with diffusion models\nallowing to synthesize convincing images for a large variety of text prompts.\nIn this article, we propose DiffEdit, a method to take advantage of\ntext-conditioned diffusion models for the task of semantic image editing, where\nthe goal is to edit an image based on a text query. Semantic image editing is\nan extension of image generation, with the additional constraint that the\ngenerated image should be as similar as possible to a given input image.\nCurrent editing methods based on diffusion models usually require to provide a\nmask, making the task much easier by treating it as a conditional inpainting\ntask. In contrast, our main contribution is able to automatically generate a\nmask highlighting regions of the input image that need to be edited, by\ncontrasting predictions of a diffusion model conditioned on different text\nprompts. Moreover, we rely on latent inference to preserve content in those\nregions of interest and show excellent synergies with mask-based diffusion.\nDiffEdit achieves state-of-the-art editing performance on ImageNet. In\naddition, we evaluate semantic image editing in more challenging settings,\nusing images from the COCO dataset as well as text-based generated images.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Guillaume Couairon",
      "Jakob Verbeek",
      "Holger Schwenk",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11427"
  },
  {
    "id": "arXiv:2210.11429",
    "title": "Text Enhancement for Paragraph Processing in End-to-End Code-switching  TTS",
    "abstract": "Current end-to-end code-switching Text-to-Speech (TTS) can already generate\nhigh quality two languages speech in the same utterance with single speaker\nbilingual corpora. When the speakers of the bilingual corpora are different,\nthe naturalness and consistency of the code-switching TTS will be poor. The\ncross-lingual embedding layers structure we proposed makes similar syllables in\ndifferent languages relevant, thus improving the naturalness and consistency of\ngenerated speech. In the end-to-end code-switching TTS, there exists problem of\nprosody instability when synthesizing paragraph text. The text enhancement\nmethod we proposed makes the input contain prosodic information and\nsentence-level context information, thus improving the prosody stability of\nparagraph text. Experimental results demonstrate the effectiveness of the\nproposed methods in the naturalness, consistency, and prosody stability. In\naddition to Mandarin and English, we also apply these methods to Shanghaiese\nand Cantonese corpora, proving that the methods we proposed can be extended to\nother languages to build end-to-end code-switching TTS system.",
    "descriptor": "\nComments: accepted in ISCSLP 2021\n",
    "authors": [
      "Chunyu Qiang",
      "Jianhua Tao",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Jiangyan Yi",
      "Tao Wang",
      "Shiming Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.11429"
  },
  {
    "id": "arXiv:2210.11431",
    "title": "Counterfactual Recipe Generation: Exploring Compositional Generalization  in a Realistic Scenario",
    "abstract": "People can acquire knowledge in an unsupervised manner by reading, and\ncompose the knowledge to make novel combinations. In this paper, we investigate\nwhether pretrained language models can perform compositional generalization in\na realistic setting: recipe generation. We design the counterfactual recipe\ngeneration task, which asks models to modify a base recipe according to the\nchange of an ingredient. This task requires compositional generalization at two\nlevels: the surface level of incorporating the new ingredient into the base\nrecipe, and the deeper level of adjusting actions related to the changing\ningredient. We collect a large-scale recipe dataset in Chinese for models to\nlearn culinary knowledge, and a subset of action-level fine-grained annotations\nfor evaluation. We finetune pretrained language models on the recipe corpus,\nand use unsupervised counterfactual generation methods to generate modified\nrecipes. Results show that existing models have difficulties in modifying the\ningredients while preserving the original text style, and often miss actions\nthat need to be adjusted. Although pretrained language models can generate\nfluent recipe texts, they fail to truly learn and use the culinary knowledge in\na compositional way. Code and data are available at\nhttps://github.com/xxxiaol/counterfactual-recipe-generation.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 main conference. Project website: this https URL\n",
    "authors": [
      "Xiao Liu",
      "Yansong Feng",
      "Jizhi Tang",
      "Chengang Hu",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11431"
  },
  {
    "id": "arXiv:2210.11435",
    "title": "Learning and Retrieval from Prior Data for Skill-based Imitation  Learning",
    "abstract": "Imitation learning offers a promising path for robots to learn\ngeneral-purpose behaviors, but traditionally has exhibited limited scalability\ndue to high data supervision requirements and brittle generalization. Inspired\nby recent advances in multi-task imitation learning, we investigate the use of\nprior data from previous tasks to facilitate learning novel tasks in a robust,\ndata-efficient manner. To make effective use of the prior data, the robot must\ninternalize knowledge from past experiences and contextualize this knowledge in\nnovel tasks. To that end, we develop a skill-based imitation learning framework\nthat extracts temporally extended sensorimotor skills from prior data and\nsubsequently learns a policy for the target task that invokes these learned\nskills. We identify several key design choices that significantly improve\nperformance on novel tasks, namely representation learning objectives to enable\nmore predictable skill representations and a retrieval-based data augmentation\nmechanism to increase the scope of supervision for policy training. On a\ncollection of simulated and real-world manipulation domains, we demonstrate\nthat our method significantly outperforms existing imitation learning and\noffline reinforcement learning approaches. Videos and code are available at\nhttps://ut-austin-rpl.github.io/sailor",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Soroush Nasiriany",
      "Tian Gao",
      "Ajay Mandlekar",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11435"
  },
  {
    "id": "arXiv:2210.11441",
    "title": "Cell tracking for live-cell microscopy using an activity-prioritized  assignment strategy",
    "abstract": "Cell tracking is an essential tool in live-cell imaging to determine\nsingle-cell features, such as division patterns or elongation rates. Unlike in\ncommon multiple object tracking, in microbial live-cell experiments cells are\ngrowing, moving, and dividing over time, to form cell colonies that are densely\npacked in mono-layer structures. With increasing cell numbers, following the\nprecise cell-cell associations correctly over many generations becomes more and\nmore challenging, due to the massively increasing number of possible\nassociations.\nTo tackle this challenge, we propose a fast parameter-free cell tracking\napproach, which consists of activity-prioritized nearest neighbor assignment of\ngrowing cells and a combinatorial solver that assigns splitting mother cells to\ntheir daughters. As input for the tracking, Omnipose is utilized for instance\nsegmentation. Unlike conventional nearest-neighbor-based tracking approaches,\nthe assignment steps of our proposed method are based on a Gaussian\nactivity-based metric, predicting the cell-specific migration probability,\nthereby limiting the number of erroneous assignments. In addition to being a\nbuilding block for cell tracking, the proposed activity map is a standalone\ntracking-free metric for indicating cell activity. Finally, we perform a\nquantitative analysis of the tracking accuracy for different frame rates, to\ninform life scientists about a suitable (in terms of tracking performance)\nchoice of the frame rate for their cultivation experiments, when cell tracks\nare the desired key outcome.",
    "descriptor": "\nComments: Accepted for publication at the 5th IEEE International Conference on Image Processing Applications and Systems 2022 (IPAS)\n",
    "authors": [
      "Karina Ruzaeva",
      "Jan-Christopher Cohrs",
      "Keitaro Kasahara",
      "Dietrich Kohlheyer",
      "Katharina N\u00f6h",
      "Benjamin Berkels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11441"
  },
  {
    "id": "arXiv:2210.11442",
    "title": "Augmentative Topology Agents For Open-Ended Learning",
    "abstract": "In this work, we tackle the problem of open-ended learning by introducing a\nmethod that simultaneously evolves agents and increasingly challenging\nenvironments. Unlike previous open-ended approaches that optimize agents using\na fixed neural network topology, we hypothesize that generalization can be\nimproved by allowing agents' controllers to become more complex as they\nencounter more difficult environments. Our method, Augmentative Topology EPOET\n(ATEP), extends the Enhanced Paired Open-Ended Trailblazer (EPOET) algorithm by\nallowing agents to evolve their own neural network structures over time, adding\ncomplexity and capacity as necessary. Empirical results demonstrate that ATEP\nresults in general agents capable of solving more environments than a\nfixed-topology baseline. We also investigate mechanisms for transferring agents\nbetween environments and find that a species-based approach further improves\nthe performance and generalization of agents.",
    "descriptor": "\nComments: Accepted to Life-long Learning of High-level Cognitive and Reasoning Skills Workshop at IROS 2022\n",
    "authors": [
      "Muhammad Umair Nasir",
      "Michael Beukman",
      "Steven James",
      "Christopher Wesley Cleghorn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.11442"
  },
  {
    "id": "arXiv:2210.11449",
    "title": "The Natural Robotics Contest: Crowdsourced Biomimetic Design",
    "abstract": "Biomimetic and Bioinspired design is not only a potent resource for\nroboticists looking to develop robust engineering systems or understand the\nnatural world. It is also a uniquely accessible entry point into science and\ntechnology. Every person on Earth constantly interacts with nature, and most\npeople have an intuitive sense of animal and plant behavior, even without\nrealizing it. The Natural Robotics Contest is novel piece of science\ncommunication that takes advantage of this intuition, and creates an\nopportunity for anyone with an interest in nature or robotics to submit their\nidea and have it turned into a real engineering system. In this paper we will\ndiscuss the competition's submissions, which show how the public thinks of\nnature as well as the problems people see as most pressing for engineers to\nsolve. We will then show our design process from the winning submitted concept\nsketch through to functioning robot, to offer a case study in biomimetic robot\ndesign. The winning design is a robotic fish which uses gill structures to\nfilter out microplastics. This was fabricated into an open source robot with a\nnovel 3D printed gill design. By presenting the competition and the winning\nentry we hope to foster further interest in nature-inspired design, and\nincrease the interplay between nature and engineering in the minds of readers.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Robert Siddall",
      "Raphael Zufferey",
      "Sophie Armanini",
      "Ketao Zhang",
      "Sina Sareh",
      "Elisavetha Sergeev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11449"
  },
  {
    "id": "arXiv:2210.11452",
    "title": "Global Convergence of SGD On Two Layer Neural Nets",
    "abstract": "In this note we demonstrate provable convergence of SGD to the global minima\nof appropriately regularized $\\ell_2-$empirical risk of depth $2$ nets -- for\narbitrary data and with any number of gates, if they are using adequately\nsmooth and bounded activations like sigmoid and tanh. We build on the results\nin [1] and leverage a constant amount of Frobenius norm regularization on the\nweights, along with sampling of the initial weights from an appropriate\ndistribution. We also give a continuous time SGD convergence result that also\napplies to smooth unbounded activations like SoftPlus. Our key idea is to show\nthe existence loss functions on constant sized neural nets which are \"Villani\nFunctions\".",
    "descriptor": "\nComments: 21 pages, 4 figures. Extended abstract accepted at DeepMath 2022\n",
    "authors": [
      "Pulkit Gopalani",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11452"
  },
  {
    "id": "arXiv:2210.11456",
    "title": "MixMask: Revisiting Masked Siamese Self-supervised Learning in  Asymmetric Distance",
    "abstract": "Recent advances in self-supervised learning integrate Masked Modeling and\nSiamese Networks into a single framework to fully reap the advantages of both\nthe two techniques. However, previous erasing-based masking scheme in masked\nimage modeling is not originally designed for siamese networks. Existing\napproaches simply inherit the default loss design from previous siamese\nnetworks, and ignore the information loss and distance change after employing\nmasking operation in the frameworks. In this paper, we propose a filling-based\nmasking strategy called MixMask to prevent information loss due to the randomly\nerased areas of an image in vanilla masking method. We further introduce a\ndynamic loss function design with soft distance to adapt the integrated\narchitecture and avoid mismatches between transformed input and objective in\nMasked Siamese ConvNets (MSCN). The dynamic loss distance is calculated\naccording to the proposed mix-masking scheme. Extensive experiments are\nconducted on various datasets of CIFAR-100, Tiny-ImageNet and ImageNet-1K. The\nresults demonstrate that the proposed framework can achieve better accuracy on\nlinear probing, semi-supervised and {supervised finetuning}, which outperforms\nthe state-of-the-art MSCN by a significant margin. We also show the superiority\non downstream tasks of object detection and segmentation. Our source code is\navailable at https://github.com/LightnessOfBeing/MixMask.",
    "descriptor": "\nComments: Technical report. Code is available at this https URL\n",
    "authors": [
      "Kirill Vishniakov",
      "Eric Xing",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11456"
  },
  {
    "id": "arXiv:2210.11460",
    "title": "Closed-loop Control of Catalytic Janus Microrobots",
    "abstract": "We report a closed-loop control system for paramagnetic catalytically\nself-propelled Janus microrobots. We achieve this control by employing\nelectromagnetic coils that direct the magnetic field in a desired orientation\nto steer the microrobots. The microrobots move due to the catalytic\ndecomposition of hydrogen peroxide, during which they align themselves to the\nmagnetic torques applied to them. Because the angle between their direction of\nmotion and their magnetic orientation is a priori unknown, an algorithm is used\nto determine this angular offset and adjust the magnetic field appropriately.\nThe microrobots are located using real-time particle tracking that integrates\nwith a video camera. A target location or desired trajectory can be drawn by\nthe user for the microrobots to follow.",
    "descriptor": "\nComments: micro-robots, magnetic-control, closed-loop, computer-vision\n",
    "authors": [
      "Max Sokolich",
      "David Rivas",
      "Zameer Hussain Shah",
      "Sambeeta Das"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11460"
  },
  {
    "id": "arXiv:2210.11463",
    "title": "Breaking Bad: A Dataset for Geometric Fracture and Reassembly",
    "abstract": "We introduce Breaking Bad, a large-scale dataset of fractured objects. Our\ndataset consists of over one million fractured objects simulated from ten\nthousand base models. The fracture simulation is powered by a recent physically\nbased algorithm that efficiently generates a variety of fracture modes of an\nobject. Existing shape assembly datasets decompose objects according to\nsemantically meaningful parts, effectively modeling the construction process.\nIn contrast, Breaking Bad models the destruction process of how a geometric\nobject naturally breaks into fragments. Our dataset serves as a benchmark that\nenables the study of fractured object reassembly and presents new challenges\nfor geometric shape understanding. We analyze our dataset with several geometry\nmeasurements and benchmark three state-of-the-art shape assembly deep learning\nmethods under various settings. Extensive experimental results demonstrate the\ndifficulty of our dataset, calling on future research in model designs\nspecifically for the geometric shape assembly task. We host our dataset at\nhttps://breaking-bad-dataset.github.io/.",
    "descriptor": "\nComments: NeurIPS 2022 Track on Datasets and Benchmarks. The first three authors contributed equally to this work. Project page: this https URL Code: this https URL Dataset: this https URL\n",
    "authors": [
      "Silvia Sell\u00e1n",
      "Yun-Chun Chen",
      "Ziyi Wu",
      "Animesh Garg",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11463"
  },
  {
    "id": "arXiv:2210.11464",
    "title": "Self-Supervised Learning via Maximum Entropy Coding",
    "abstract": "A mainstream type of current self-supervised learning methods pursues a\ngeneral-purpose representation that can be well transferred to downstream\ntasks, typically by optimizing on a given pretext task such as instance\ndiscrimination. In this work, we argue that existing pretext tasks inevitably\nintroduce biases into the learned representation, which in turn leads to biased\ntransfer performance on various downstream tasks. To cope with this issue, we\npropose Maximum Entropy Coding (MEC), a more principled objective that\nexplicitly optimizes on the structure of the representation, so that the\nlearned representation is less biased and thus generalizes better to unseen\ndownstream tasks. Inspired by the principle of maximum entropy in information\ntheory, we hypothesize that a generalizable representation should be the one\nthat admits the maximum entropy among all plausible representations. To make\nthe objective end-to-end trainable, we propose to leverage the minimal coding\nlength in lossy data coding as a computationally tractable surrogate for the\nentropy, and further derive a scalable reformulation of the objective that\nallows fast computation. Extensive experiments demonstrate that MEC learns a\nmore generalizable representation than previous methods based on specific\npretext tasks. It achieves state-of-the-art performance consistently on various\ndownstream tasks, including not only ImageNet linear probe, but also\nsemi-supervised classification, object detection, instance segmentation, and\nobject tracking. Interestingly, we show that existing batch-wise and\nfeature-wise self-supervised objectives could be seen equivalent to low-order\napproximations of MEC. Code and pre-trained models are available at\nhttps://github.com/xinliu20/MEC.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Xin Liu",
      "Zhongdao Wang",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11464"
  },
  {
    "id": "arXiv:2210.11466",
    "title": "Surgical Fine-Tuning Improves Adaptation to Distribution Shifts",
    "abstract": "A common approach to transfer learning under distribution shift is to\nfine-tune the last few layers of a pre-trained model, preserving learned\nfeatures while also adapting to the new task. This paper shows that in such\nsettings, selectively fine-tuning a subset of layers (which we term surgical\nfine-tuning) matches or outperforms commonly used fine-tuning approaches.\nMoreover, the type of distribution shift influences which subset is more\neffective to tune: for example, for image corruptions, fine-tuning only the\nfirst few layers works best. We validate our findings systematically across\nseven real-world data tasks spanning three types of distribution shifts.\nTheoretically, we prove that for two-layer neural networks in an idealized\nsetting, first-layer tuning can outperform fine-tuning all layers. Intuitively,\nfine-tuning more parameters on a small target dataset can cause information\nlearned during pre-training to be forgotten, and the relevant information\ndepends on the type of shift.",
    "descriptor": "",
    "authors": [
      "Yoonho Lee",
      "Annie S. Chen",
      "Fahim Tajwar",
      "Ananya Kumar",
      "Huaxiu Yao",
      "Percy Liang",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11466"
  },
  {
    "id": "arXiv:2210.11467",
    "title": "Multi-View Guided Multi-View Stereo",
    "abstract": "This paper introduces a novel deep framework for dense 3D reconstruction from\nmultiple image frames, leveraging a sparse set of depth measurements gathered\njointly with image acquisition. Given a deep multi-view stereo network, our\nframework uses sparse depth hints to guide the neural network by modulating the\nplane-sweep cost volume built during the forward step, enabling us to infer\nconstantly much more accurate depth maps. Moreover, since multiple viewpoints\ncan provide additional depth measurements, we propose a multi-view guidance\nstrategy that increases the density of the sparse points used to guide the\nnetwork, thus leading to even more accurate results. We evaluate our Multi-View\nGuided framework within a variety of state-of-the-art deep multi-view stereo\nnetworks, demonstrating its effectiveness at improving the results achieved by\neach of them on BlendedMVG and DTU datasets.",
    "descriptor": "\nComments: IROS 2022. First two authors contributed equally. Project page: this https URL\n",
    "authors": [
      "Matteo Poggi",
      "Andrea Conti",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11467"
  },
  {
    "id": "arXiv:2210.11468",
    "title": "ObSynth: An Interactive Synthesis System for Generating Object Models  from Natural Language Specifications",
    "abstract": "We introduce ObSynth, an interactive system leveraging the domain knowledge\nembedded in large language models (LLMs) to help users design object models\nfrom high level natural language prompts. This is an example of specification\nreification, the process of taking a high-level, potentially vague\nspecification and reifying it into a more concrete form. We evaluate ObSynth\nvia a user study, leading to three key findings: first, object models designed\nusing ObSynth are more detailed, showing that it often synthesizes fields users\nmight have otherwise omitted. Second, a majority of objects, methods, and\nfields generated by ObSynth are kept by the user in the final object model,\nhighlighting the quality of generated components. Third, ObSynth altered the\nworkflow of participants: they focus on checking that synthesized components\nwere correct rather than generating them from scratch, though ObSynth did not\nreduce the time participants took to generate object models.",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Alex Gu",
      "Tamara Mitrovska",
      "Daniela Velez",
      "Jacob Andreas",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11468"
  },
  {
    "id": "arXiv:2210.11469",
    "title": "G2NetPL: Generic Game-Theoretic Network for Partial-Label Image  Classification",
    "abstract": "Multi-label image classification aims to predict all possible labels in an\nimage. It is usually formulated as a partial-label learning problem, since it\ncould be expensive in practice to annotate all the labels in every training\nimage. Existing works on partial-label learning focus on the case where each\ntraining image is labeled with only a subset of its positive/negative labels.\nTo effectively address partial-label classification, this paper proposes an\nend-to-end Generic Game-theoretic Network (G2NetPL) for partial-label learning,\nwhich can be applied to most partial-label settings, including a very\nchallenging, but annotation-efficient case where only a subset of the training\nimages are labeled, each with only one positive label, while the rest of the\ntraining images remain unlabeled. In G2NetPL, each unobserved label is\nassociated with a soft pseudo label, which, together with the network,\nformulates a two-player non-zero-sum non-cooperative game. The objective of the\nnetwork is to minimize the loss function with given pseudo labels, while the\npseudo labels will seek convergence to 1 (positive) or 0 (negative) with a\npenalty of deviating from the predicted labels determined by the network. In\naddition, we introduce a confidence-aware scheduler into the loss of the\nnetwork to adaptively perform easy-to-hard learning for different labels.\nExtensive experiments demonstrate that our proposed G2NetPL outperforms many\nstate-of-the-art multi-label classification methods under various partial-label\nsettings on three different datasets.",
    "descriptor": "\nComments: Accepted by BMVC2022\n",
    "authors": [
      "Rabab Abdelfattah",
      "Xin Zhang",
      "Mostafa M. Fouda",
      "Xiaofeng Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11469"
  },
  {
    "id": "arXiv:2210.11470",
    "title": "i-MAE: Are Latent Representations in Masked Autoencoders Linearly  Separable?",
    "abstract": "Masked image modeling (MIM) has been recognized as a strong and popular\nself-supervised pre-training approach in the vision domain. However, the\ninterpretability of the mechanism and properties of the learned representations\nby such a scheme are so far not well-explored. In this work, through\ncomprehensive experiments and empirical studies on Masked Autoencoders (MAE),\nwe address two critical questions to explore the behaviors of the learned\nrepresentations: (i) Are the latent representations in Masked Autoencoders\nlinearly separable if the input is a mixture of two images instead of one? This\ncan be concrete evidence used to explain why MAE-learned representations have\nsuperior performance on downstream tasks, as proven by many literature\nimpressively. (ii) What is the degree of semantics encoded in the latent\nfeature space by Masked Autoencoders? To explore these two problems, we propose\na simple yet effective Interpretable MAE (i-MAE) framework with a two-way image\nreconstruction and a latent feature reconstruction with distillation loss to\nhelp us understand the behaviors inside MAE's structure. Extensive experiments\nare conducted on CIFAR-10/100, Tiny-ImageNet and ImageNet-1K datasets to verify\nthe observations we discovered. Furthermore, in addition to qualitatively\nanalyzing the characteristics of the latent representations, we examine the\nexistence of linear separability and the degree of semantics in the latent\nspace by proposing two novel metrics. The surprising and consistent results\nacross the qualitative and quantitative experiments demonstrate that i-MAE is a\nsuperior framework design for interpretability research of MAE frameworks, as\nwell as achieving better representational ability. Code is available at\nhttps://github.com/vision-learning-acceleration-lab/i-mae.",
    "descriptor": "\nComments: Technical report. Project page: this https URL\n",
    "authors": [
      "Kevin Zhang",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11470"
  },
  {
    "id": "arXiv:2210.11471",
    "title": "Choose Your Lenses: Flaws in Gender Bias Evaluation",
    "abstract": "Considerable efforts to measure and mitigate gender bias in recent years have\nled to the introduction of an abundance of tasks, datasets, and metrics used in\nthis vein. In this position paper, we assess the current paradigm of gender\nbias evaluation and identify several flaws in it. First, we highlight the\nimportance of extrinsic bias metrics that measure how a model's performance on\nsome task is affected by gender, as opposed to intrinsic evaluations of model\nrepresentations, which are less strongly connected to specific harms to people\ninteracting with systems. We find that only a few extrinsic metrics are\nmeasured in most studies, although more can be measured. Second, we find that\ndatasets and metrics are often coupled, and discuss how their coupling hinders\nthe ability to obtain reliable conclusions, and how one may decouple them. We\nthen investigate how the choice of the dataset and its composition, as well as\nthe choice of the metric, affect bias measurement, finding significant\nvariations across each of them. Finally, we propose several guidelines for more\nreliable gender bias evaluation.",
    "descriptor": "\nComments: Accepted to the 4th Workshop on Gender Bias in Natural Language Processing\n",
    "authors": [
      "Hadas Orgad",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11471"
  },
  {
    "id": "arXiv:2210.11472",
    "title": "VIBUS: Data-efficient 3D Scene Parsing with VIewpoint Bottleneck and  Uncertainty-Spectrum Modeling",
    "abstract": "Recently, 3D scenes parsing with deep learning approaches has been a heating\ntopic. However, current methods with fully-supervised models require manually\nannotated point-wise supervision which is extremely user-unfriendly and\ntime-consuming to obtain. As such, training 3D scene parsing models with sparse\nsupervision is an intriguing alternative. We term this task as data-efficient\n3D scene parsing and propose an effective two-stage framework named VIBUS to\nresolve it by exploiting the enormous unlabeled points. In the first stage, we\nperform self-supervised representation learning on unlabeled points with the\nproposed Viewpoint Bottleneck loss function. The loss function is derived from\nan information bottleneck objective imposed on scenes under different\nviewpoints, making the process of representation learning free of degradation\nand sampling. In the second stage, pseudo labels are harvested from the sparse\nlabels based on uncertainty-spectrum modeling. By combining data-driven\nuncertainty measures and 3D mesh spectrum measures (derived from normal\ndirections and geodesic distances), a robust local affinity metric is obtained.\nFinite gamma/beta mixture models are used to decompose category-wise\ndistributions of these measures, leading to automatic selection of thresholds.\nWe evaluate VIBUS on the public benchmark ScanNet and achieve state-of-the-art\nresults on both validation set and online test server. Ablation studies show\nthat both Viewpoint Bottleneck and uncertainty-spectrum modeling bring\nsignificant improvements. Codes and models are publicly available at\nhttps://github.com/AIR-DISCOVER/VIBUS.",
    "descriptor": "\nComments: Accepted to ISPRS Journal of Photogrammetry and Remote Sensing, Code: this https URL\n",
    "authors": [
      "Beiwen Tian",
      "Liyi Luo",
      "Hao Zhao",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11472"
  },
  {
    "id": "arXiv:2210.10779",
    "title": "Routine Usage of AI-based Chest X-ray Reading Support in a Multi-site  Medical Supply Center",
    "abstract": "Research question: How can we establish an AI support for reading of chest\nX-rays in clinical routine and which benefits emerge for the clinicians and\nradiologists. Can it perform 24/7 support for practicing clinicians? 2.\nFindings: We installed an AI solution for Chest X-ray in a given structure (MVZ\nUhlenbrock & Partner, Germany). We could demonstrate the practicability,\nperformance, and benefits in 10 connected clinical sites. 3. Meaning: A\ncommercially available AI solution for the evaluation of Chest X-ray images is\nable to help radiologists and clinical colleagues 24/7 in a complex\nenvironment. The system performs in a robust manner, supporting radiologists\nand clinical colleagues in their important decisions, in practises and\nhospitals regardless of the user and X-ray system type producing the\nimage-data.",
    "descriptor": "",
    "authors": [
      "Karsten Ridder",
      "Alexander Preuhs",
      "Axel Mertins",
      "Clemens Joerger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10779"
  },
  {
    "id": "arXiv:2210.10781",
    "title": "Generalization Properties of Decision Trees on Real-valued and  Categorical Features",
    "abstract": "We revisit binary decision trees from the perspective of partitions of the\ndata. We introduce the notion of partitioning function, and we relate it to the\ngrowth function and to the VC dimension. We consider three types of features:\nreal-valued, categorical ordinal and categorical nominal, with different split\nrules for each. For each feature type, we upper bound the partitioning function\nof the class of decision stumps before extending the bounds to the class of\ngeneral decision tree (of any fixed structure) using a recursive approach.\nUsing these new results, we are able to find the exact VC dimension of decision\nstumps on examples of $\\ell$ real-valued features, which is given by the\nlargest integer $d$ such that $2\\ell \\ge \\binom{d}{\\lfloor\\frac{d}{2}\\rfloor}$.\nFurthermore, we show that the VC dimension of a binary tree structure with\n$L_T$ leaves on examples of $\\ell$ real-valued features is in $O(L_T\n\\log(L_T\\ell))$. Finally, we elaborate a pruning algorithm based on these\nresults that performs better than the cost-complexity and reduced-error pruning\nalgorithms on a number of data sets, with the advantage that no\ncross-validation is required.",
    "descriptor": "\nComments: 79 pages. arXiv admin note: text overlap with arXiv:2010.07374\n",
    "authors": [
      "Jean-Samuel Leboeuf",
      "Fr\u00e9d\u00e9ric LeBlanc",
      "Mario Marchand"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10781"
  },
  {
    "id": "arXiv:2210.10784",
    "title": "Graph Regularized Probabilistic Matrix Factorization for Drug-Drug  Interactions Prediction",
    "abstract": "Co-administration of two or more drugs simultaneously can result in adverse\ndrug reactions. Identifying drug-drug interactions (DDIs) is necessary,\nespecially for drug development and for repurposing old drugs. DDI prediction\ncan be viewed as a matrix completion task, for which matrix factorization (MF)\nappears as a suitable solution. This paper presents a novel Graph Regularized\nProbabilistic Matrix Factorization (GRPMF) method, which incorporates expert\nknowledge through a novel graph-based regularization strategy within an MF\nframework. An efficient and sounded optimization algorithm is proposed to solve\nthe resulting non-convex problem in an alternating fashion. The performance of\nthe proposed method is evaluated through the DrugBank dataset, and comparisons\nare provided against state-of-the-art techniques. The results demonstrate the\nsuperior performance of GRPMF when compared to its counterparts.",
    "descriptor": "",
    "authors": [
      "Stuti Jain",
      "Emilie Chouzenoux",
      "Kriti Kumar",
      "Angshul Majumdar"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10784"
  },
  {
    "id": "arXiv:2210.10837",
    "title": "On Learning Fairness and Accuracy on Multiple Subgroups",
    "abstract": "We propose an analysis in fair learning that preserves the utility of the\ndata while reducing prediction disparities under the criteria of group\nsufficiency. We focus on the scenario where the data contains multiple or even\nmany subgroups, each with limited number of samples. As a result, we present a\nprincipled method for learning a fair predictor for all subgroups via\nformulating it as a bilevel objective. Specifically, the subgroup specific\npredictors are learned in the lower-level through a small amount of data and\nthe fair predictor. In the upper-level, the fair predictor is updated to be\nclose to all subgroup specific predictors. We further prove that such a bilevel\nobjective can effectively control the group sufficiency and generalization\nerror. We evaluate the proposed framework on real-world datasets. Empirical\nevidence suggests the consistently improved fair predictions, as well as the\ncomparable accuracy to the baselines.",
    "descriptor": "\nComments: NeurIPS-2022 Camera-ready\n",
    "authors": [
      "Changjian Shui",
      "Gezheng Xu",
      "Qi Chen",
      "Jiaqi Li",
      "Charles Ling",
      "Tal Arbel",
      "Boyu Wang",
      "Christian Gagn\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10837"
  },
  {
    "id": "arXiv:2210.10887",
    "title": "Data-Driven Distributionally Robust Electric Vehicle Balancing for  Mobility-on-Demand Systems under Demand and Supply Uncertainties",
    "abstract": "As electric vehicle (EV) technologies become mature, EV has been rapidly\nadopted in modern transportation systems, and is expected to provide future\nautonomous mobility-on-demand (AMoD) service with economic and societal\nbenefits. However, EVs require frequent recharges due to their limited and\nunpredictable cruising ranges, and they have to be managed efficiently given\nthe dynamic charging process. It is urgent and challenging to investigate a\ncomputationally efficient algorithm that provide EV AMoD system performance\nguarantees under model uncertainties, instead of using heuristic demand or\ncharging models. To accomplish this goal, this work designs a data-driven\ndistributionally robust optimization approach for vehicle supply-demand ratio\nand charging station utilization balancing, while minimizing the worst-case\nexpected cost considering both passenger mobility demand uncertainties and EV\nsupply uncertainties. We then derive an equivalent computationally tractable\nform for solving the distributionally robust problem in a computationally\nefficient way under ellipsoid uncertainty sets constructed from data. Based on\nE-taxi system data of Shenzhen city, we show that the average total balancing\ncost is reduced by 14.49%, the average unfairness of supply-demand ratio and\nutilization is reduced by 15.78% and 34.51% respectively with the\ndistributionally robust vehicle balancing method, compared with solutions which\ndo not consider model uncertainties.",
    "descriptor": "\nComments: This paper has been published in IROS2020\n",
    "authors": [
      "Sihong He",
      "Lynn Pepin",
      "Guang Wang",
      "Desheng Zhang",
      "Fei Miao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.10887"
  },
  {
    "id": "arXiv:2210.10950",
    "title": "ESPNN: Deep Neural Network on the IAEA stopping power database. Atomic  targets",
    "abstract": "The International Atomic Energy Agency (IAEA) stopping power database is a\nhighly valued public resource compiling most of the experimental measurements\npublished over nearly a century. The database -- accessible to the global\nscientific community -- is continuously updated and has been extensively\nemployed in theoretical and experimental research for more than thirty years.\nThis work aims to employ machine learning algorithms on the 2021 IAEA database\nto predict accurate electronic stopping power cross sections for any ion and\ntarget combination in a wide range of incident energies. Unsupervised machine\nlearning methods are applied to clean the database in an automated manner.\nThese techniques purge the data by removing suspicious outliers and old\nisolated values. A large portion of the remaining data is used to train a deep\nneural network, while the rest is set aside, constituting the test set. The\npresent work considers collisional systems only with atomic targets. The first\nversion of the electronic stopping power neural network code (espnn), openly\navailable to users, is shown to yield predicted values in excellent agreement\nwith the experimental results of the test set.",
    "descriptor": "",
    "authors": [
      "F. Bivort Haiek",
      "A.M.P. Mendez",
      "C.C. Montanari",
      "D.M. Mitnik"
    ],
    "subjectives": [
      "Atomic and Molecular Clusters (physics.atm-clus)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10950"
  },
  {
    "id": "arXiv:2210.10952",
    "title": "Autoencoded sparse Bayesian in-IRT factorization, calibration, and  amortized inference for the Work Disability Functional Assessment Battery",
    "abstract": "The Work Disability Functional Assessment Battery (WD-FAB) is a\nmultidimensional item response theory (IRT) instrument designed for assessing\nwork-related mental and physical function based on responses to an item bank.\nIn prior iterations it was developed using traditional means -- linear\nfactorization, followed by statistical testing for item selection, and finally,\ncalibration of disjoint unidimensional IRT models. As a result, the WD-FAB,\nlike many other IRT instruments, is a posthoc model. In this manuscript, we\nderive an interpretable probabilistic autoencoder architecture that embeds as\nthe decoder a Bayesian hierarchical model for self-consistently performing the\nfollowing simultaneous tasks: scale factorization, item selection, parameter\nidentification, and response scoring. This method obviates the linear\nfactorization and null hypothesis statistical tests that are usually required\nfor developing multidimensional IRT models, so that partitioning is consistent\nwith the ultimate nonlinear factor model. We use the method on WD-FAB item\nresponses and compare the resulting item discriminations to those obtained\nusing the traditional method.",
    "descriptor": "",
    "authors": [
      "Joshua C. Chang",
      "Carson C. Chow",
      "Julia Porcino"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.10952"
  },
  {
    "id": "arXiv:2210.10962",
    "title": "Optimization on Manifolds via Graph Gaussian Processes",
    "abstract": "This paper integrates manifold learning techniques within a \\emph{Gaussian\nprocess upper confidence bound} algorithm to optimize an objective function on\na manifold. Our approach is motivated by applications where a full\nrepresentation of the manifold is not available and querying the objective is\nexpensive. We rely on a point cloud of manifold samples to define a graph\nGaussian process surrogate model for the objective. Query points are\nsequentially chosen using the posterior distribution of the surrogate model\ngiven all previous queries. We establish regret bounds in terms of the number\nof queries and the size of the point cloud. Several numerical examples\ncomplement the theory and illustrate the performance of our method.",
    "descriptor": "",
    "authors": [
      "Hwanwoo Kim",
      "Daniel Sanz-Alonso",
      "Ruiyi Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10962"
  },
  {
    "id": "arXiv:2210.10971",
    "title": "Optimal Settings for Cryptocurrency Trading Pairs",
    "abstract": "The goal of cryptocurrencies is decentralization. In principle, all\ncurrencies have equal status. Unlike traditional stock markets, there is no\ndefault currency of denomination (fiat), thus the trading pairs can be set\nfreely. However, it is impractical to set up a trading market between every two\ncurrencies. In order to control management costs and ensure sufficient\nliquidity, we must give priority to covering those large-volume trading pairs\nand ensure that all coins are reachable. We note that this is an optimization\nproblem. Its particularity lies in: 1) the trading volume between most (>99.5%)\npossible trading pairs cannot be directly observed. 2) It satisfies the\nconnectivity constraint, that is, all currencies are guaranteed to be tradable.\nTo solve this problem, we use a two-stage process: 1) Fill in missing values\nbased on a regularized, truncated eigenvalue decomposition, where the\nregularization term is used to control what extent missing values should be\nlimited to zero. 2) Search for the optimal trading pairs, based on a branch and\nbound process, with heuristic search and pruning strategies.\nThe experimental results show that: 1) If the number of denominated coins is\nnot limited, we will get a more decentralized trading pair settings, which\nadvocates the establishment of trading pairs directly between large currency\npairs. 2) There is a certain room for optimization in all exchanges. The\nsetting of inappropriate trading pairs is mainly caused by subjectively setting\nsmall coins to quote, or failing to track emerging big coins in time. 3) Too\nfew trading pairs will lead to low coverage; too many trading pairs will need\nto be adjusted with markets frequently. Exchanges should consider striking an\nappropriate balance between them.",
    "descriptor": "",
    "authors": [
      "Di Zhang",
      "Qiang Niu",
      "Youzhou Zhou"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10971"
  },
  {
    "id": "arXiv:2210.10998",
    "title": "Semi-supervised object detection based on single-stage detector for  thighbone fracture localization",
    "abstract": "The thighbone is the largest bone supporting the lower body. If the thighbone\nfracture is not treated in time, it will lead to lifelong inability to walk.\nCorrect diagnosis of thighbone disease is very important in orthopedic\nmedicine. Deep learning is promoting the development of fracture detection\ntechnology. However, the existing computer aided diagnosis (CAD) methods baesd\non deep learning rely on a large number of manually labeled data, and labeling\nthese data costs a lot of time and energy. Therefore, we develop a object\ndetection method with limited labeled image quantity and apply it to the\nthighbone fracture localization. In this work, we build a semi-supervised\nobject detection(SSOD) framework based on single-stage detector, which\nincluding three modules: adaptive difficult sample oriented (ADSO) module,\nFusion Box and deformable expand encoder (Dex encoder). ADSO module takes the\nclassification score as the label reliability evaluation criterion by\nweighting, Fusion Box is designed to merge similar pseudo boxes into a reliable\nbox for box regression and Dex encoder is proposed to enhance the adaptability\nof image augmentation. The experiment is conducted on the thighbone fracture\ndataset, which includes 3484 training thigh fracture images and 358 testing\nthigh fracture images. The experimental results show that the proposed method\nachieves the state-of-the-art AP in thighbone fracture detection at different\nlabeled data rates, i.e. 1%, 5% and 10%. Besides, we use full data to achieve\nknowledge distillation, our method achieves 86.2% AP50 and 52.6% AP75.",
    "descriptor": "\nComments: Preprint submitted to Applied Soft Computing\n",
    "authors": [
      "Jinman Wei",
      "Jinkun Yao",
      "Guoshan Zhanga",
      "Bin Guan",
      "Yueming Zhang",
      "Shaoquan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10998"
  },
  {
    "id": "arXiv:2210.11003",
    "title": "Synthetic Blip Effects: Generalizing Synthetic Controls for the Dynamic  Treatment Regime",
    "abstract": "We propose a generalization of the synthetic control and synthetic\ninterventions methodology to the dynamic treatment regime. We consider the\nestimation of unit-specific treatment effects from panel data collected via a\ndynamic treatment regime and in the presence of unobserved confounding. That\nis, each unit receives multiple treatments sequentially, based on an adaptive\npolicy, which depends on a latent endogenously time-varying confounding state\nof the treated unit. Under a low-rank latent factor model assumption and a\ntechnical overlap assumption we propose an identification strategy for any\nunit-specific mean outcome under any sequence of interventions. The latent\nfactor model we propose admits linear time-varying and time-invariant dynamical\nsystems as special cases. Our approach can be seen as an identification\nstrategy for structural nested mean models under a low-rank latent factor\nassumption on the blip effects. Our method, which we term \"synthetic blip\neffects\", is a backwards induction process, where the blip effect of a\ntreatment at each period and for a target unit is recursively expressed as\nlinear combinations of blip effects of a carefully chosen group of other units\nthat received the designated treatment. Our work avoids the combinatorial\nexplosion in the number of units that would be required by a vanilla\napplication of prior synthetic control and synthetic intervention methods in\nsuch dynamic treatment regime settings.",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.11003"
  },
  {
    "id": "arXiv:2210.11019",
    "title": "Single Image Super-Resolution Using Lightweight Networks Based on Swin  Transformer",
    "abstract": "Image super-resolution reconstruction is an important task in the field of\nimage processing technology, which can restore low resolution image to high\nquality image with high resolution. In recent years, deep learning has been\napplied in the field of image super-resolution reconstruction. With the\ncontinuous development of deep neural network, the quality of the reconstructed\nimages has been greatly improved, but the model complexity has also been\nincreased. In this paper, we propose two lightweight models named as MSwinSR\nand UGSwinSR based on Swin Transformer. The most important structure in MSwinSR\nis called Multi-size Swin Transformer Block (MSTB), which mainly contains four\nparallel multi-head self-attention (MSA) blocks. UGSwinSR combines U-Net and\nGAN with Swin Transformer. Both of them can reduce the model complexity, but\nMSwinSR can reach a higher objective quality, while UGSwinSR can reach a higher\nperceptual quality. The experimental results demonstrate that MSwinSR increases\nPSNR by $\\mathbf{0.07dB}$ compared with the state-of-the-art model SwinIR,\nwhile the number of parameters can reduced by $\\mathbf{30.68\\%}$, and the\ncalculation cost can reduced by $\\mathbf{9.936\\%}$. UGSwinSR can effectively\nreduce the amount of calculation of the network, which can reduced by\n$\\mathbf{90.92\\%}$ compared with SwinIR.",
    "descriptor": "",
    "authors": [
      "Bolong Zhang",
      "Juan Chen",
      "Quan Wen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11019"
  },
  {
    "id": "arXiv:2210.11044",
    "title": "Equilibria analysis of a networked bivirus epidemic model using  Poincar\u00e9--Hopf and Manifold Theory",
    "abstract": "This paper considers a deterministic Susceptible-Infected-Susceptible (SIS)\nnetworked bivirus epidemic model (termed the bivirus model for short), in which\ntwo competing viruses spread through a set of populations (nodes) connected by\ntwo graphs, which may be different if the two viruses have different\ntransmission pathways. The networked dynamics can give rise to complex\nequilibria patterns, and most current results identify conditions on the model\nparameters for convergence to the healthy equilibrium (where both viruses are\nextinct) or a boundary equilibrium (where one virus is endemic and the other is\nextinct). However, there are only limited results on coexistence equilibria\n(where both viruses are endemic). This paper establishes a set of ``counting''\nresults which provide lower bounds on the number of coexistence equilibria, and\nperhaps more importantly, establish properties on the local\nstability/instability properties of these equilibria. In order to do this, we\nemploy the Poincar\\'e-Hopf Theorem but with significant modifications to\novercome several challenges arising from the bivirus system model, such as the\nfact that the system dynamics do not evolve on a manifold in the typical sense\nrequired to apply Poincar\\'e-Hopf Theory. Subsequently, Morse inequalities are\nused to tighten the counting results, under the reasonable assumption that the\nbivirus system is a Morse-Smale dynamical system. Numerical examples are\nprovided which demonstrate the presence of multiple attractor equilibria, and\nmultiple coexistence equilibria.",
    "descriptor": "\nComments: Submitted to SIAM Journal of Applied Dynamical Systems 2022-Oct-20\n",
    "authors": [
      "Brian D.O. Anderson",
      "Mengbin Ye"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2210.11044"
  },
  {
    "id": "arXiv:2210.11045",
    "title": "Robust Image Registration with Absent Correspondences in Pre-operative  and Follow-up Brain MRI Scans of Diffuse Glioma Patients",
    "abstract": "Registration of pre-operative and follow-up brain MRI scans is challenging\ndue to the large variation of tissue appearance and missing correspondences in\ntumour recurrence regions caused by tumour mass effect. Although recent deep\nlearning-based deformable registration methods have achieved remarkable success\nin various medical applications, most of them are not capable of registering\nimages with pathologies. In this paper, we propose a 3-step registration\npipeline for pre-operative and follow-up brain MRI scans that consists of 1) a\nmulti-level affine registration, 2) a conditional deep Laplacian pyramid image\nregistration network (cLapIRN) with forward-backward consistency constraint,\nand 3) a non-linear instance optimization method. We apply the method to the\nBrain Tumor Sequence Registration (BraTS-Reg) Challenge. Our method achieves\naccurate and robust registration of brain MRI scans with pathologies, which\nachieves a median absolute error of 1.64 mm and 88% of successful registration\nrate in the validation set of BraTS-Reg challenge.",
    "descriptor": "\nComments: BraTS-Reg workshop\n",
    "authors": [
      "Tony C. W. Mok",
      "Albert C. S. Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11045"
  },
  {
    "id": "arXiv:2210.11053",
    "title": "The Network Structure of Unequal Diffusion",
    "abstract": "Social networks affect the diffusion of information, and thus have the\npotential to reduce or amplify inequality in access to opportunity. We show\nempirically that social networks often exhibit a much larger potential for\nunequal diffusion across groups along paths of length 2 and 3 than expected by\nour random graph models. We argue that homophily alone cannot not fully explain\nthe extent of unequal diffusion and attribute this mismatch to unequal\ndistribution of cross-group links among the nodes. Based on this insight, we\ndevelop a variant of the stochastic block model that incorporates the\nheterogeneity in cross-group linking. The model provides an unbiased and\nconsistent estimate of assortativity or homophily on paths of length 2 and\nprovide a more accurate estimate along paths of length 3 than existing models.\nWe characterize the null distribution of its log-likelihood ratio test and\nargue that the goodness of fit test is valid only when the network is dense.\nBased on our empirical observations and modeling results, we conclude that the\nimpact of any departure from equal distribution of links to source nodes in the\ndiffusion process is not limited to its first order effects as some nodes will\nhave fewer direct links to the sources. More importantly, this unequal\ndistribution will also lead to second order effects as the whole group will\nhave fewer diffusion paths to the sources.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Eaman Jahani",
      "Dean Eckles",
      "Alex 'Sandy' Pentland"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11053"
  },
  {
    "id": "arXiv:2210.11059",
    "title": "DisC-VC: Disentangled and F0-Controllable Neural Voice Conversion",
    "abstract": "Voice conversion is a task to convert a non-linguistic feature of a given\nutterance. Since naturalness of speech strongly depends on its pitch pattern,\nin some applications, it would be desirable to keep the original rise/fall\npitch pattern while changing the speaker identity. Some of the existing methods\naddress this problem by either using a source-filter model or developing a\nneural network that takes an F0 pattern as input to the model. Although the\nlatter approach can achieve relatively high sound quality compared to the\nformer one, there is no consideration for discrepancy between the target and\ngenerated F0 patterns in its training process. In this paper, we propose a new\nvariational-autoencoder-based voice conversion model accompanied by an\nauxiliary network, which ensures that the conversion result correctly reflects\nthe specified F0/timbre information. We show the effectiveness of the proposed\nmethod by objective and subjective evaluations.",
    "descriptor": "",
    "authors": [
      "Chihiro Watanabe",
      "Hirokazu Kameoka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.11059"
  },
  {
    "id": "arXiv:2210.11089",
    "title": "Speech Dereverberation with a Reverberation Time Shortening Target",
    "abstract": "This work proposes a new learning target based on reverberation time\nshortening (RTS) for speech dereverberation. The learning target for\ndereverberation is usually set as the direct-path speech or optionally with\nsome early reflections. This type of target suddenly truncates the\nreverberation, and thus it may not be suitable for network training. The\nproposed RTS target suppresses reverberation and meanwhile maintains the\nexponential decaying property of reverberation, which will ease the network\ntraining, and thus reduce signal distortion caused by the prediction error.\nMoreover, this work experimentally study to adapt our previously proposed\nFullSubNet speech denoising network to speech dereverberation. Experiments show\nthat RTS is a more suitable learning target than direct-path speech and early\nreflections, in terms of better suppressing reverberation and signal\ndistortion. FullSubNet is able to achieve outstanding dereverberation\nperformance.",
    "descriptor": "\nComments: submitted to ICASSP 2023. arXiv admin note: substantial text overlap with arXiv:2204.08765\n",
    "authors": [
      "Rui Zhou",
      "Wenye Zhu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11089"
  },
  {
    "id": "arXiv:2210.11091",
    "title": "Standardized Medical Image Classification across Medical Disciplines",
    "abstract": "AUCMEDI is a Python-based framework for medical image classification. In this\npaper, we evaluate the capabilities of AUCMEDI, by applying it to multiple\ndatasets. Datasets were specifically chosen to cover a variety of medical\ndisciplines and imaging modalities. We designed a simple pipeline using Jupyter\nnotebooks and applied it to all datasets. Results show that AUCMEDI was able to\ntrain a model with accurate classification capabilities for each dataset:\nAveraged AUC per dataset range between 0.82 and 1.0, averaged F1 scores range\nbetween 0.61 and 1.0. With its high adaptability and strong performance,\nAUCMEDI proves to be a powerful instrument to build widely applicable neural\nnetworks. The notebooks serve as application examples for AUCMEDI.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Simone Mayer",
      "Dominik M\u00fcller",
      "Frank Kramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11091"
  },
  {
    "id": "arXiv:2210.11122",
    "title": "Developments in Performance and Portability for MadGraph5_aMC@NLO",
    "abstract": "Event generators simulate particle interactions using Monte Carlo techniques,\nproviding the primary connection between experiment and theory in experimental\nhigh energy physics. These software packages, which are the first step in the\nsimulation worflow of collider experiments, represent approximately 5 to 20% of\nthe annual WLCG usage for the ATLAS and CMS experiments. With computing\narchitectures becoming more heterogeneous, it is important to ensure that these\nkey software frameworks can be run on future systems, large and small. In this\ncontribution, recent progress on porting and speeding up the Madgraph5_aMC@NLO\nevent generator on hybrid architectures, i.e. CPU with GPU accelerators, is\ndiscussed. The main focus of this work has been in the calculation of\nscattering amplitudes and \"matrix elements\", which is the computational\nbottleneck of an event generation application. For physics processes limited to\nQCD leading order, the code generation toolkit has been expanded to produce\nmatrix element calculations using C++ vector instructions on CPUs and using\nCUDA for NVidia GPUs, as well as using Alpaka, Kokkos and SYCL for multiple CPU\nand GPU architectures. Performance is reported in terms of matrix element\ncalculations per time on NVidia, Intel, and AMD devices. The status and outlook\nfor the integration of this work into a production release usable by the LHC\nexperiments, with the same functionalities and very similar user interfaces as\nthe current Fortran version, is also described.",
    "descriptor": "\nComments: 6 pages, 2 figures, 2 tables; submitted to ICHEP2022 proceedings in PoS\n",
    "authors": [
      "Andrea Valassi",
      "Taylor Childers",
      "Laurence Field",
      "Stefan Hageb\u00f6ck",
      "Walter Hopkins",
      "Olivier Mattelaer",
      "Nathan Nichols",
      "Stefan Roiser",
      "David Smith"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Software Engineering (cs.SE)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11122"
  },
  {
    "id": "arXiv:2210.11123",
    "title": "Model-matching Principle Applied to the Design of an Array-based  All-neural Binaural Rendering System for Audio Telepresence",
    "abstract": "Telepresence aims to create an immersive but virtual experience of the\nfar-end audio and visual scene for users at the near-end. In this contribution,\nwe propose an array-based binaural rendering system that converts the array\nmicrophone signals into the head-related transfer function (HRTF)-filtered\noutput signals for headphone-rendering. The proposed approach is formulated on\nthe basis of a model-matching principle (MMP) and is capable of delivering more\nnatural immersiveness than the conventional localization-beamforming-HRTF\nfiltering (LBH) approach. The MMP-based rendering system can be realized via\nmultichannel inverse filtering (MIF) and multichannel deep filtering (MDF). In\nthis study, we adopted the MDF approach and used the LBH as well as MIF as the\nbaselines. The all-neural system jointly captures the spatial information\n(spatial rendering), preserves ambient sound (enhancement), and reduces noise\n(enhancement), prior to generating binaural outputs. Objective and subjective\ntests are employed to compare the proposed telepresence system with two\nbaselines.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Yicheng Hsu",
      "Chenghumg Ma",
      "Mingsian R. Bai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11123"
  },
  {
    "id": "arXiv:2210.11132",
    "title": "A general model-and-run solver for multistage robust discrete linear  optimization",
    "abstract": "The necessity to deal with uncertain data is a major challenge in decision\nmaking. Robust optimization emerged as one of the predominant paradigms to\nproduce solutions that hedge against uncertainty. In order to obtain an even\nmore realistic description of the underlying problem where the decision maker\ncan react to newly disclosed information, multistage models can be used.\nHowever, due to their computational difficulty, multistage problems beyond two\nstages have received less attention and are often only addressed using\napproximation rather than optimization schemes. Even less attention is paid to\nthe consideration of decision-dependent uncertainty in a multistage setting. We\nexplore multistage robust optimization via quantified linear programs, which\nare linear programs with ordered variables that are either existentially or\nuniversally quantified. Building upon a (mostly) discrete setting where the\nuncertain parameters -- the universally quantified variables -- are only\nrestricted by their bounds, we present an augmented version that allows stating\nthe discrete uncertainty set via a linear constraint system that also can be\naffected by decision variables. We present a general search-based solution\napproach and introduce our solver Yasol that is able to deal with multistage\nrobust linear discrete optimization problems, with final mixed-integer recourse\nactions and a discrete uncertainty set, which even can be decision-dependent.\nIn doing so, we provide a convenient model-and-run approach, that can serve as\nbaseline for computational experiments in the field of multistage robust\noptimization, providing optimal solutions for problems with an arbitrary number\nof decision stages.",
    "descriptor": "",
    "authors": [
      "Michael Hartisch",
      "Ulf Lorenz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11132"
  },
  {
    "id": "arXiv:2210.11133",
    "title": "A lower confidence sequence for the changing mean of non-negative right  heavy-tailed observations with bounded mean",
    "abstract": "A confidence sequence (CS) is an anytime-valid sequential inference primitive\nwhich produces an adapted sequence of sets for a predictable parameter sequence\nwith a time-uniform coverage guarantee. This work constructs a non-parametric\nnon-asymptotic lower CS for the running average conditional expectation whose\nslack converges to zero given non-negative right heavy-tailed observations with\nbounded mean. Specifically, when the variance is finite the approach dominates\nthe empirical Bernstein supermartingale of Howard et. al.; with infinite\nvariance, can adapt to a known or unknown $(1 + \\delta)$-th moment bound; and\ncan be efficiently approximated using a sublinear number of sufficient\nstatistics. In certain cases this lower CS can be converted into a\nclosed-interval CS whose width converges to zero, e.g., any bounded\nrealization, or post contextual-bandit inference with bounded rewards and\nunbounded importance weights. A reference implementation and example\nsimulations demonstrate the technique.",
    "descriptor": "\nComments: Reference implementation at this https URL\n",
    "authors": [
      "Paul Mineiro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11133"
  },
  {
    "id": "arXiv:2210.11152",
    "title": "Machine Learning for $K$-adaptability in Two-stage Robust Optimization",
    "abstract": "Two-stage robust optimization problems constitute one of the hardest\noptimization problem classes. One of the solution approaches to this class of\nproblems is $K$-adaptability. This approach simultaneously seeks the best\npartitioning of the uncertainty set of scenarios into $K$ subsets, and\noptimizes decisions corresponding to each of these subsets. In general case, it\nis solved using the $K$-adaptability branch-and-bound algorithm, which requires\nexploration of exponentially-growing solution trees. To accelerate finding\nhigh-quality solutions in such trees, we propose a machine learning-based node\nselection strategy. In particular, we construct a feature engineering scheme\nbased on general two-stage robust optimization insights that allows us to train\nour machine learning tool on a database of resolved B\\&B trees, and to apply it\nas-is to problems of different sizes and/or types. We experimentally show that\nusing our learned node selection strategy outperforms a vanilla, random node\nselection strategy when tested on problems of the same type as the training\nproblems, also in case the $K$-value or the problem size differs from the\ntraining ones.",
    "descriptor": "",
    "authors": [
      "Esther Julien",
      "Krzysztof Postek",
      "\u015e. \u0130lker Birbil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11152"
  },
  {
    "id": "arXiv:2210.11153",
    "title": "Reversed Image Signal Processing and RAW Reconstruction. AIM 2022  Challenge Report",
    "abstract": "Cameras capture sensor RAW images and transform them into pleasant RGB\nimages, suitable for the human eyes, using their integrated Image Signal\nProcessor (ISP). Numerous low-level vision tasks operate in the RAW domain\n(e.g. image denoising, white balance) due to its linear relationship with the\nscene irradiance, wide-range of information at 12bits, and sensor designs.\nDespite this, RAW image datasets are scarce and more expensive to collect than\nthe already large and public RGB datasets.\nThis paper introduces the AIM 2022 Challenge on Reversed Image Signal\nProcessing and RAW Reconstruction. We aim to recover raw sensor images from the\ncorresponding RGBs without metadata and, by doing this, \"reverse\" the ISP\ntransformation. The proposed methods and benchmark establish the\nstate-of-the-art for this low-level vision inverse problem, and generating\nrealistic raw sensor readings can potentially benefit other tasks such as\ndenoising and super-resolution.",
    "descriptor": "\nComments: ECCV 2022 Advances in Image Manipulation (AIM) workshop\n",
    "authors": [
      "Marcos V. Conde",
      "Radu Timofte",
      "Yibin Huang",
      "Jingyang Peng",
      "Chang Chen",
      "Cheng Li",
      "Eduardo P\u00e9rez-Pellitero",
      "Fenglong Song",
      "Furui Bai",
      "Shuai Liu",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Yu Zhu",
      "Chenghua Li",
      "Yingying Jiang",
      "Yong A",
      "Peisong Wang",
      "Cong Leng",
      "Jian Cheng",
      "Xiaoyu Liu",
      "Zhicun Yin",
      "Zhilu Zhang",
      "Junyi Li",
      "Ming Liu",
      "Wangmeng Zuo",
      "Jun Jiang",
      "Jinha Kim",
      "Yue Zhang",
      "Beiji Zou",
      "Zhikai Zong",
      "Xiaoxiao Liu",
      "Juan Mar\u00edn Vega",
      "Michael Sloth",
      "Peter Schneider-Kamp",
      "Richard R\u00f6ttger",
      "Furkan K\u0131nl\u0131",
      "Bar\u0131\u015f \u00d6zcan",
      "Furkan K\u0131ra\u00e7",
      "Li Leyi",
      "SM Nadim Uddin",
      "Dipon Kumar Ghosh",
      "Yong Ju Jung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11153"
  },
  {
    "id": "arXiv:2210.11184",
    "title": "On completely regular codes with minimum eigenvalue in geometric graphs",
    "abstract": "We prove that any completely regular code with minimum eigenvalue in any\ngeometric graph G corresponds to a completely regular code in the clique graph\nof G. Studying the interrelation of these codes, a complete characterization of\nthe completely regular codes in the Johnson graphs J(n,w) with covering radius\nw-1 and strength 1 is obtained. In particular this result finishes a\ncharacterization of the completely regular codes in the Johnson graphs J(n,3).\nWe also classify the completely regular codes of strength 1 in the Johnson\ngraphs J(n,4) with only one case for the eigenvalues left open.",
    "descriptor": "",
    "authors": [
      "I.Yu.Mogilnykh",
      "K. V. Vorob'ev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.11184"
  },
  {
    "id": "arXiv:2210.11197",
    "title": "Noisy Tree Data Structures and Quantum Applications",
    "abstract": "The paper presents a technique for constructing noisy data structures called\na walking tree. We apply it for a Red-Black tree (an implementation of a\nSelf-Balanced Binary Search Tree) and a segment tree. We obtain the same\ncomplexity of the main operations for these data structures as in the case\nwithout noise (asymptotically). We use these data structures in quantum\nalgorithms for two problems: the Exam Problem and the Largest File Problem.\nFinally, we suggest new quantum solution for strings sorting problem and show\nthe lower bound. The upper bound and lower bound for the problem are the same\nup to log factor. At the same time, it is more effective than classical\ncounterparts.",
    "descriptor": "",
    "authors": [
      "Kamil Khadiev",
      "Nikita Savelyev",
      "Mansur Ziatdinov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.11197"
  },
  {
    "id": "arXiv:2210.11200",
    "title": "Removing grid structure in angle-resolved photoemission spectra via deep  learning method",
    "abstract": "Spectroscopic data may often contain unwanted extrinsic signals. For example,\nin ARPES experiment, a wire mesh is typically placed in front of the CCD to\nblock stray photo-electrons, but could cause a grid-like structure in the\nspectra during quick measurement mode. In the past, this structure was often\nremoved using the mathematical Fourier filtering method by erasing the periodic\nstructure. However, this method may lead to information loss and vacancies in\nthe spectra because the grid structure is not strictly linearly superimposed.\nHere, we propose a deep learning method to effectively overcome this problem.\nOur method takes advantage of the self-correlation information within the\nspectra themselves and can greatly optimize the quality of the spectra while\nremoving the grid structure and noise simultaneously. It has the potential to\nbe extended to all spectroscopic measurements to eliminate other extrinsic\nsignals and enhance the spectral quality based on the self-correlation of the\nspectra solely.",
    "descriptor": "",
    "authors": [
      "Junde Liu",
      "Dongchen Huang",
      "Yi-feng Yang",
      "Tian Qian"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.11200"
  },
  {
    "id": "arXiv:2210.11238",
    "title": "Analysis of Smooth Pursuit Assessment in Virtual Reality and Concussion  Detection using BiLSTM",
    "abstract": "The sport-related concussion (SRC) battery relies heavily upon subjective\nsymptom reporting in order to determine the diagnosis of a concussion.\nUnfortunately, athletes with SRC may return-to-play (RTP) too soon if they are\nuntruthful of their symptoms. It is critical to provide accurate assessments\nthat can overcome underreporting to prevent further injury. To lower the risk\nof injury, a more robust and precise method for detecting concussion is needed\nto produce reliable and objective results. In this paper, we propose a novel\napproach to detect SRC using long short-term memory (LSTM) recurrent neural\nnetwork (RNN) architectures from oculomotor data. In particular, we propose a\nnew error metric that incorporates mean squared error in different proportions.\nThe experimental results on the smooth pursuit test of the VR-VOMS dataset\nsuggest that the proposed approach can predict concussion symptoms with higher\naccuracy compared to symptom provocation on the vestibular ocular motor\nscreening (VOMS).",
    "descriptor": "\nComments: International Symposium on Visual Computing\n",
    "authors": [
      "Prithul Sarker",
      "Khondker Fariha Hossain",
      "Isayas Berhe Adhanom",
      "Philip K Pavilionis",
      "Nicholas G. Murray",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.11238"
  },
  {
    "id": "arXiv:2210.11245",
    "title": "Neural ODEs as Feedback Policies for Nonlinear Optimal Control",
    "abstract": "Neural ordinary differential equations (Neural ODEs) model continuous time\ndynamics as differential equations parametrized with neural networks. Thanks to\ntheir modeling flexibility, they have been adopted for multiple tasks where the\ncontinuous time nature of the process is specially relevant, as in system\nidentification and time series analysis. When applied in a control setting, it\nis possible to adapt their use to approximate optimal nonlinear feedback\npolicies. This formulation follows the same approach as policy gradients in\nreinforcement learning, covering the case where the environment consists of\nknown deterministic dynamics given by a system of differential equations. The\nwhite box nature of the model specification allows the direct calculation of\npolicy gradients through sensitivity analysis, avoiding the inexact and\ninefficient gradient estimation through sampling. In this work we propose the\nuse of a neural control policy posed as a Neural ODE to solve general nonlinear\noptimal control problems while satisfying both state and control constraints,\nwhich are crucial for real world scenarios. Since the state feedback policy\npartially modifies the model dynamics, the whole space phase of the system is\nreshaped upon the optimization. This approach is a sensible approximation to\nthe historically intractable closed loop solution of nonlinear control problems\nthat efficiently exploits the availability of a dynamical system model.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Ilya Orson Sandoval",
      "Panagiotis Petsagkourakis",
      "Ehecatl Antonio del Rio-Chanona"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11245"
  },
  {
    "id": "arXiv:2210.11250",
    "title": "Structure-based drug design with geometric deep learning",
    "abstract": "Structure-based drug design uses three-dimensional geometric information of\nmacromolecules, such as proteins or nucleic acids, to identify suitable\nligands. Geometric deep learning, an emerging concept of neural-network-based\nmachine learning, has been applied to macromolecular structures. This review\nprovides an overview of the recent applications of geometric deep learning in\nbioorganic and medicinal chemistry, highlighting its potential for\nstructure-based drug discovery and design. Emphasis is placed on molecular\nproperty prediction, ligand binding site and pose prediction, and\nstructure-based de novo molecular design. The current challenges and\nopportunities are highlighted, and a forecast of the future of geometric deep\nlearning for drug discovery is presented.",
    "descriptor": "",
    "authors": [
      "Clemens Isert",
      "Kenneth Atz",
      "Gisbert Schneider"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11250"
  },
  {
    "id": "arXiv:2210.11302",
    "title": "Fleet-Level Environmental Assessments for Feasibility of Aviation  Emission Reduction Goals",
    "abstract": "The International Air Transport Association (IATA) is one of several\norganizations that have presented goals for future CO2 emissions from\ncommercial aviation with the intent of alleviating the associated environmental\nimpacts. These goals include attaining carbon-neutral growth in the year 2020\nand total aviation CO2 emissions in 2050 equal to 50% of 2005 aviation CO2\nemissions. This paper presents the use of a simulation-based approach to\npredict future CO2 emissions from commercial aviation based upon a set of\nscenarios developed as part of the Aircraft Technology Modeling and Assessment\nproject within ASCENT, the FAA Center of Excellence for Alternative Jet Fuels\nand the Environment. Results indicate that, in future scenarios with increasing\ndemand for air travel, it is difficult to reduce CO2 emissions in 2050 to\nlevels equal to or below 2005 levels, although neutral CO2 growth after 2020\nmay be possible.",
    "descriptor": "\nComments: Presented at the Council of Engineering Systems Universities (CESUN) conference in 2018\n",
    "authors": [
      "Kolawole Ogunsina",
      "Hsun Chao",
      "Nithin Jojo Kolencherry",
      "Samarth Jain",
      "Kushal Moolchandani",
      "Daniel DeLaurentis",
      "William Crossley"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11302"
  },
  {
    "id": "arXiv:2210.11317",
    "title": "Dynamic selection of p-norm in linear adaptive filtering via online  kernel-based reinforcement learning",
    "abstract": "This study addresses the problem of selecting dynamically, at each time\ninstance, the ``optimal'' p-norm to combat outliers in linear adaptive\nfiltering without any knowledge on the potentially time-varying probability\ndistribution function of the outliers. To this end, an online and data-driven\nframework is designed via kernel-based reinforcement learning (KBRL). Novel\nBellman mappings on reproducing kernel Hilbert spaces (RKHSs) are introduced\nthat need no knowledge on transition probabilities of Markov decision\nprocesses, and are nonexpansive with respect to the underlying Hilbertian norm.\nAn approximate policy-iteration framework is finally offered via the\nintroduction of a finite-dimensional affine superset of the fixed-point set of\nthe proposed Bellman mappings. The well-known ``curse of dimensionality'' in\nRKHSs is addressed by building a basis of vectors via an approximate linear\ndependency criterion. Numerical tests on synthetic data demonstrate that the\nproposed framework selects always the ``optimal'' p-norm for the outlier\nscenario at hand, outperforming at the same time several non-RL and KBRL\nschemes.",
    "descriptor": "",
    "authors": [
      "Minh Vu",
      "Yuki Akiyama",
      "Konstantinos Slavakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11317"
  },
  {
    "id": "arXiv:2210.11355",
    "title": "Network Synthetic Interventions: A Framework for Panel Data with Network  Interference",
    "abstract": "We propose a generalization of the synthetic controls and synthetic\ninterventions methodology to incorporate network interference. We consider the\nestimation of unit-specific treatment effects from panel data where there are\nspillover effects across units and in the presence of unobserved confounding.\nKey to our approach is a novel latent factor model that takes into account\nnetwork interference and generalizes the factor models typically used in panel\ndata settings. We propose an estimator, \"network synthetic interventions\", and\nshow that it consistently estimates the mean outcomes for a unit under an\narbitrary sequence of treatments for itself and its neighborhood, given certain\nobservation patterns hold in the data. We corroborate our theoretical findings\nwith simulations.",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Sarah Cen",
      "Devavrat Shah",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.11355"
  },
  {
    "id": "arXiv:2210.11377",
    "title": "Krylov-Bellman boosting: Super-linear policy evaluation in general state  spaces",
    "abstract": "We present and analyze the Krylov-Bellman Boosting (KBB) algorithm for policy\nevaluation in general state spaces. It alternates between fitting the Bellman\nresidual using non-parametric regression (as in boosting), and estimating the\nvalue function via the least-squares temporal difference (LSTD) procedure\napplied with a feature set that grows adaptively over time. By exploiting the\nconnection to Krylov methods, we equip this method with two attractive\nguarantees. First, we provide a general convergence bound that allows for\nseparate estimation errors in residual fitting and LSTD computation. Consistent\nwith our numerical experiments, this bound shows that convergence rates depend\non the restricted spectral structure, and are typically super-linear. Second,\nby combining this meta-result with sample-size dependent guarantees for\nresidual fitting and LSTD computation, we obtain concrete statistical\nguarantees that depend on the sample size along with the complexity of the\nfunction class used to fit the residuals. We illustrate the behavior of the KBB\nalgorithm for various types of policy evaluation problems, and typically find\nlarge reductions in sample complexity relative to the standard approach of\nfitted value iterationn.",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Eric Xia",
      "Martin J. Wainwright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11377"
  },
  {
    "id": "arXiv:2210.11385",
    "title": "On Representations of Mean-Field Variational Inference",
    "abstract": "The mean field variational inference (MFVI) formulation restricts the general\nBayesian inference problem to the subspace of product measures. We present a\nframework to analyze MFVI algorithms, which is inspired by a similar\ndevelopment for general variational Bayesian formulations. Our approach enables\nthe MFVI problem to be represented in three different manners: a gradient flow\non Wasserstein space, a system of Fokker-Planck-like equations and a diffusion\nprocess. Rigorous guarantees are established to show that a time-discretized\nimplementation of the coordinate ascent variational inference algorithm in the\nproduct Wasserstein space of measures yields a gradient flow in the limit. A\nsimilar result is obtained for their associated densities, with the limit being\ngiven by a quasi-linear partial differential equation. A popular class of\npractical algorithms falls in this framework, which provides tools to establish\nconvergence. We hope this framework could be used to guarantee convergence of\nalgorithms in a variety of approaches, old and new, to solve variational\ninference problems.",
    "descriptor": "",
    "authors": [
      "Soumyadip Ghosh",
      "Yingdong Lu",
      "Tomasz Nowicki",
      "Edith Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11385"
  },
  {
    "id": "arXiv:2210.11388",
    "title": "Physics-informed deep diffusion MRI reconstruction: break the bottleneck  of training data in artificial intelligence",
    "abstract": "In this work, we propose a Physics-Informed Deep Diffusion magnetic resonance\nimaging (DWI) reconstruction method (PIDD). PIDD contains two main components:\nThe multi-shot DWI data synthesis and a deep learning reconstruction network.\nFor data synthesis, we first mathematically analyze the motion during the\nmulti-shot data acquisition and approach it by a simplified physical motion\nmodel. The motion model inspires a polynomial model for motion-induced phase\nsynthesis. Then, lots of synthetic phases are combined with a few real data to\ngenerate a large amount of training data. For reconstruction network, we\nexploit the smoothness property of each shot image phase as learnable\nconvolution kernels in the k-space and complementary sparsity in the image\ndomain. Results on both synthetic and in vivo brain data show that, the\nproposed PIDD trained on synthetic data enables sub-second ultra-fast,\nhigh-quality, and robust reconstruction with different b-values and\nundersampling patterns.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Chen Qian",
      "Zi Wang",
      "Xinlin Zhang",
      "Qingrui Cai",
      "Taishan Kang",
      "Boyu Jiang",
      "Ran Tao",
      "Zhigang Wu",
      "Di Guo",
      "Xiaobo Qu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11388"
  },
  {
    "id": "arXiv:2210.11406",
    "title": "ProSky: NEAT Meets NOMA-mmWave in the Sky of 6G",
    "abstract": "Rendering to their abilities to provide ubiquitous connectivity, flexibly and\ncost effectively, unmanned aerial vehicles (UAVs) have been getting more and\nmore research attention. To take the UAVs' performance to the next level,\nhowever, they need to be merged with some other technologies like\nnon-orthogonal multiple access (NOMA) and millimeter wave (mmWave), which both\npromise high spectral efficiency (SE). As managing UAVs efficiently may not be\npossible using model-based techniques, another key innovative technology that\nUAVs will inevitably need to leverage is artificial intelligence (AI).\nDesigning an AI-based technique that adaptively allocates radio resources and\nplaces UAVs in 3D space to meet certain communication objectives, however, is a\ntough row to hoe. In this paper, we propose a neuroevolution of augmenting\ntopologies NEAT framework, referred to as ProSky, to manage NOMA-mmWave-UAV\nnetworks. ProSky exhibits a remarkable performance improvement over a\nmodel-based method. Moreover, ProSky learns 5.3 times faster than and\noutperforms, in both SE and energy efficiency EE while being reasonably fair, a\ndeep reinforcement learning DRL based scheme. The ProSky source code is\naccessible to use here: https://github.com/Fouzibenfaid/ProSky",
    "descriptor": "\nComments: IEEE GC WS 2022\n",
    "authors": [
      "Ahmed Benfaid",
      "Nadia Adem",
      "Abdurrahman Elmaghbub"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11406"
  },
  {
    "id": "arXiv:2210.11408",
    "title": "Hierarchical Deep Learning with Generative Adversarial Network for  Automatic Cardiac Diagnosis from ECG Signals",
    "abstract": "Cardiac disease is the leading cause of death in the US. Accurate heart\ndisease detection is of critical importance for timely medical treatment to\nsave patients' lives. Routine use of electrocardiogram (ECG) is the most common\nmethod for physicians to assess the electrical activities of the heart and\ndetect possible abnormal cardiac conditions. Fully utilizing the ECG data for\nreliable heart disease detection depends on developing effective analytical\nmodels. In this paper, we propose a two-level hierarchical deep learning\nframework with Generative Adversarial Network (GAN) for automatic diagnosis of\nECG signals. The first-level model is composed of a Memory-Augmented Deep\nauto-Encoder with GAN (MadeGAN), which aims to differentiate abnormal signals\nfrom normal ECGs for anomaly detection. The second-level learning aims at\nrobust multi-class classification for different arrhythmias identification,\nwhich is achieved by integrating the transfer learning technique to transfer\nknowledge from the first-level learning with the multi-branching architecture\nto handle the data-lacking and imbalanced data issue. We evaluate the\nperformance of the proposed framework using real-world medical data from the\nMIT-BIH arrhythmia database. Experimental results show that our proposed model\noutperforms existing methods that are commonly used in current practice.",
    "descriptor": "",
    "authors": [
      "Zekai Wang",
      "Stavros Stavrakis",
      "Bing Yao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11408"
  },
  {
    "id": "arXiv:2210.11409",
    "title": "Development of information system suited for statistical analysis of  global brands distributions",
    "abstract": "This qualification work studies methods of statistical analysis of global\nbrands distributions and development process of information system which is\nrepresented by computer program. Algorithm of estimation of correspondance to\ndistribution laws was shown. Correspondance of datasets (3) to Pareto Law and\nZipf's Law were defined.\nKey words: analysis, method, distribution, data, function, statistics,\nsolution, program.",
    "descriptor": "\nComments: 40 pages, in Ukranian language, 24 figures. Specialty 122 Computer science. Vasyl' Stus Donetsk National University, Vinnytsia, 2022\n",
    "authors": [
      "Vladyslav Solohub"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2210.11409"
  },
  {
    "id": "arXiv:2210.11413",
    "title": "Finding the smallest or largest element of a tensor from its low-rank  factors",
    "abstract": "We consider the problem of finding the smallest or largest entry of a tensor\nof order $N$ that is specified via its rank decomposition. Stated in a\ndifferent way, we are given $N$ sets of $R$-dimensional vectors and we wish to\nselect one vector from each set such that the sum of the Hadamard product of\nthe selected vectors is minimized or maximized. This is a fundamental tensor\nproblem with numerous applications in embedding similarity search, recommender\nsystems, graph mining, multivariate probability, and statistics. We show that\nthis discrete optimization problem is NP-hard for any tensor rank higher than\none, but also provide an equivalent continuous problem reformulation which is\namenable to disciplined non-convex optimization. We propose a suite of\ngradient-based approximation algorithms whose performance in preliminary\nexperiments appears to be promising.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Nicholas D. Sidiropoulos",
      "Paris Karakasis",
      "Aritra Konar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11413"
  },
  {
    "id": "arXiv:2210.11415",
    "title": "Multi-Head Cross-Attentional PPG and Motion Signal Fusion for Heart Rate  Estimation",
    "abstract": "Nowadays, Hearth Rate (HR) monitoring is a key feature of almost all\nwrist-worn devices exploiting photoplethysmography (PPG) sensors. However, arm\nmovements affect the performance of PPG-based HR tracking. This issue is\nusually addressed by fusing the PPG signal with data produced by inertial\nmeasurement units. Thus, deep learning algorithms have been proposed, but they\nare considered too complex to deploy on wearable devices and lack the\nexplainability of results. In this work, we present a new deep learning model,\nPULSE, which exploits temporal convolutions and multi-head cross-attention to\nimprove sensor fusion's effectiveness and achieve a step towards\nexplainability. We evaluate the performance of PULSE on three publicly\navailable datasets, reducing the mean absolute error by 7.56% on the most\nextensive available dataset, PPG-DaLiA. Finally, we demonstrate the\nexplainability of PULSE and the benefits of applying attention modules to PPG\nand motion data.",
    "descriptor": "\nComments: To be submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Panagiotis Kasnesis",
      "Lazaros Toumanidis",
      "Alessio Burrello",
      "Christos Chatzigeorgiou",
      "Charalampos Z. Patrikakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11415"
  },
  {
    "id": "arXiv:2210.11420",
    "title": "Granger Causality for Compressively Sensed Sparse Signals",
    "abstract": "Compressed sensing is a scheme that allows for sparse signals to be acquired,\ntransmitted and stored using far fewer measurements than done by conventional\nmeans employing Nyquist sampling theorem. Since many naturally occurring\nsignals are sparse (in some domain), compressed sensing has rapidly seen\npopularity in a number of applied physics and engineering applications,\nparticularly in designing signal and image acquisition strategies, e.g.,\nmagnetic resonance imaging, quantum state tomography, scanning tunneling\nmicroscopy, analog to digital conversion technologies. Contemporaneously,\ncausal inference has become an important tool for the analysis and\nunderstanding of processes and their interactions in many disciplines of\nscience, especially those dealing with complex systems. Direct causal analysis\nfor compressively sensed data is required to avoid the task of reconstructing\nthe compressed data. Also, for some sparse signals, such as for sparse temporal\ndata, it may be difficult to discover causal relations directly using available\ndata-driven/ model-free causality estimation techniques. In this work, we\nprovide a mathematical proof that structured compressed sensing matrices,\nspecifically Circulant and Toeplitz, preserve causal relationships in the\ncompressed signal domain, as measured by Granger Causality. We then verify this\ntheorem on a number of bivariate and multivariate coupled sparse signal\nsimulations which are compressed using these matrices. We also demonstrate a\nreal world application of network causal connectivity estimation from sparse\nneural spike train recordings from rat prefrontal cortex.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Aditi Kathpalia",
      "Nithin Nagaraj"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.11420"
  },
  {
    "id": "arXiv:2210.11423",
    "title": "Multi-Mode High Altitude Platform Stations (HAPS) for Next Generation  Wireless Networks",
    "abstract": "The high altitude platform station (HAPS) concept has recently received\nnotable attention from both industry and academia to support future wireless\nnetworks. A HAPS can be equipped with 5th generation (5G) and beyond\ntechnologies such as massive multiple-input multiple-output (MIMO) and\nreconfigurable intelligent surface (RIS). Hence, it is expected that HAPS will\nsupport numerous applications in both rural and urban areas. However, this\ncomes at the expense of high energy consumption and thus shorter loitering\ntime. To tackle this issue, we envision the use of a multi-mode HAPS that can\nadaptively switch between different modes so as to reduce energy consumption\nand extend the HAPS loitering time. These modes comprise a HAPS super macro\nbase station (HAPS-SMBS) mode for enhanced computing, caching, and\ncommunication services, a HAPS relay station (HAPS-RS) mode for active\ncommunication, and a HAPS-RIS mode for passive communication. This multimode\nHAPS ensures that operations rely mostly on the passive communication payload,\nwhile switching to an energy-greedy active mode only when necessary. In this\narticle, we begin with a brief review of HAPS features compared to other\nnon-terrestrial systems, followed by an exposition of the different HAPS modes\nproposed. Subsequently, we illustrate the envisioned multi-mode HAPS, and\ndiscuss its benefits and challenges. Finally, we validate the multi-mode\nefficiency through a case study.",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to IEEE magazine\n",
    "authors": [
      "Safwan Alfattani",
      "Wael Jaafar",
      "Halim Yanikomeroglu",
      "Abbas Yonga\u00e7oglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.11423"
  },
  {
    "id": "arXiv:2210.11443",
    "title": "Snapshot of Algebraic Vision",
    "abstract": "In this survey article, we present interactions between algebraic geometry\nand computer vision, which have recently come under the header of Algebraic\nVision. The subject has given new insights in multiple view geometry and its\napplication to 3D scene reconstruction, and carried a host of novel problems\nand ideas back into algebraic geometry.",
    "descriptor": "",
    "authors": [
      "Joe Kileel",
      "Kathl\u00e9n Kohn"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.11443"
  },
  {
    "id": "arXiv:2210.11444",
    "title": "How can a Radar Mask its Cognition?",
    "abstract": "A cognitive radar is a constrained utility maximizer that adapts its sensing\nmode in response to a changing environment. If an adversary can estimate the\nutility function of a cognitive radar, it can determine the radar's sensing\nstrategy and mitigate the radar performance via electronic countermeasures\n(ECM). This paper discusses how a cognitive radar can {\\em hide} its strategy\nfrom an adversary that detects cognition. The radar does so by transmitting\npurposefully designed sub-optimal responses to spoof the adversary's\nNeyman-Pearson detector. We provide theoretical guarantees by ensuring the\nType-I error probability of the adversary's detector exceeds a pre-defined\nlevel for a specified tolerance on the radar's performance loss. We illustrate\nour cognition masking scheme via numerical examples involving waveform\nadaptation and beam allocation. We show that small purposeful deviations from\nthe optimal strategy of the radar confuse the adversary by significant amounts,\nthereby masking the radar's cognition. Our approach uses novel ideas from\nrevealed preference in microeconomics and adversarial inverse reinforcement\nlearning. Our proposed algorithms provide a principled approach for\nsystem-level electronic counter-countermeasures (ECCM) to mask the radar's\ncognition, i.e., hide the radar's strategy from an adversary. We also provide\nperformance bounds for our cognition masking scheme when the adversary has\nmisspecified measurements of the radar's response.",
    "descriptor": "",
    "authors": [
      "Kunal Pattanayak",
      "Vikram Krishnamurthy",
      "Christopher Berry"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11444"
  },
  {
    "id": "arXiv:2210.11462",
    "title": "Local lower bounds on characteristics of quantum and classical systems",
    "abstract": "We consider methods of obtaining local lower bounds on characteristics of\nquantum (correspondingly, classical) systems, i.e. lower bounds valid in the\ntrace norm $\\epsilon$-neighborhood of a given state (correspondingly,\nprobability distribution). The main attention is paid to infinite-dimensional\nsystems.",
    "descriptor": "\nComments: 33 pages, preliminary version, any comments and references are welcome\n",
    "authors": [
      "M.E.Shirokov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.11462"
  },
  {
    "id": "arXiv:1808.06324",
    "title": "PAC-learning is Undecidable",
    "abstract": "Comments: Error in paper",
    "descriptor": "\nComments: Error in paper\n",
    "authors": [
      "Sairaam Venkatraman",
      "S Balasubramanian",
      "R Raghunatha Sarma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1808.06324"
  },
  {
    "id": "arXiv:1905.10124",
    "title": "Sliced Gromov-Wasserstein",
    "abstract": "Sliced Gromov-Wasserstein",
    "descriptor": "",
    "authors": [
      "Titouan Vayer",
      "R\u00e9mi Flamary",
      "Romain Tavenard",
      "Laetitia Chapel",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.10124"
  },
  {
    "id": "arXiv:1909.10811",
    "title": "Image Recognition using Region Creep",
    "abstract": "Image Recognition using Region Creep",
    "descriptor": "",
    "authors": [
      "Kieran Greer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1909.10811"
  },
  {
    "id": "arXiv:1912.09500",
    "title": "Front-Running Protection for Distributed Exchanges using  Tamper-Resistant Round Trip Time Measurements",
    "abstract": "Front-Running Protection for Distributed Exchanges using  Tamper-Resistant Round Trip Time Measurements",
    "descriptor": "",
    "authors": [
      "Hannah Atmer",
      "Kilian Rausch",
      "Daniel McNally"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1912.09500"
  },
  {
    "id": "arXiv:2002.05068",
    "title": "The Complexity of Binary Matrix Completion Under Diameter Constraints",
    "abstract": "The Complexity of Binary Matrix Completion Under Diameter Constraints",
    "descriptor": "",
    "authors": [
      "Tomohiro Koana",
      "Vincent Froese",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2002.05068"
  },
  {
    "id": "arXiv:2006.02745",
    "title": "Asymptotic Analysis of Conditioned Stochastic Gradient Descent",
    "abstract": "Asymptotic Analysis of Conditioned Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Leluc",
      "Fran\u00e7ois Portier"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.02745"
  },
  {
    "id": "arXiv:2009.04984",
    "title": "Dialogue-adaptive Language Model Pre-training From Quality Estimation",
    "abstract": "Comments: Accepted by Neurocomputing",
    "descriptor": "\nComments: Accepted by Neurocomputing\n",
    "authors": [
      "Junlong Li",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.04984"
  },
  {
    "id": "arXiv:2010.11869",
    "title": "Rewriting Meaningful Sentences via Conditional BERT Sampling and an  application on fooling text classifiers",
    "abstract": "Comments: Please see an updated version of this paper at arXiv:2104.08453",
    "descriptor": "\nComments: Please see an updated version of this paper at arXiv:2104.08453\n",
    "authors": [
      "Lei Xu",
      "Ivan Ramirez",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11869"
  },
  {
    "id": "arXiv:2011.10725",
    "title": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "abstract": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "descriptor": "",
    "authors": [
      "Xiucai Ding",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.10725"
  },
  {
    "id": "arXiv:2101.02780",
    "title": "SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things  and Cyber-Physical Systems based on Machine Learning",
    "abstract": "Comments: This article has been accepted in IEEE Transactions on Emerging Topics in Computing. 17 pages, 12 figures, IEEE copyright",
    "descriptor": "\nComments: This article has been accepted in IEEE Transactions on Emerging Topics in Computing. 17 pages, 12 figures, IEEE copyright\n",
    "authors": [
      "Tanujay Saha",
      "Najwa Aaraj",
      "Neel Ajjarapu",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.02780"
  },
  {
    "id": "arXiv:2101.08611",
    "title": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "abstract": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "descriptor": "",
    "authors": [
      "Rupak Majumdar",
      "Ramanathan S. Thinniyam",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2101.08611"
  },
  {
    "id": "arXiv:2102.08581",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08581"
  },
  {
    "id": "arXiv:2102.10458",
    "title": "Efficient Learning of Non-Interacting Fermion Distributions",
    "abstract": "Comments: 18 pages, 1 figure. This version corrects a serious error in the previous version. Our new algorithm uses measurements in additional bases, rather than only standard basis measurements",
    "descriptor": "\nComments: 18 pages, 1 figure. This version corrects a serious error in the previous version. Our new algorithm uses measurements in additional bases, rather than only standard basis measurements\n",
    "authors": [
      "Scott Aaronson",
      "Sabee Grewal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10458"
  },
  {
    "id": "arXiv:2103.03793",
    "title": "Learning Collision-free and Torque-limited Robot Trajectories based on  Alternative Safe Behaviors",
    "abstract": "Comments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022); 8 pages; 6 figures",
    "descriptor": "\nComments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022); 8 pages; 6 figures\n",
    "authors": [
      "Jonas C. Kiemel",
      "Torsten Kr\u00f6ger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.03793"
  },
  {
    "id": "arXiv:2104.08453",
    "title": "R&R: Metric-guided Adversarial Sentence Generation",
    "abstract": "Comments: Accepted to Finding of AACL-IJCNLP2022",
    "descriptor": "\nComments: Accepted to Finding of AACL-IJCNLP2022\n",
    "authors": [
      "Lei Xu",
      "Alfredo Cuesta-Infante",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08453"
  },
  {
    "id": "arXiv:2105.04080",
    "title": "Exponentially convergent multiscale methods for high frequency  heterogeneous Helmholtz equations",
    "abstract": "Exponentially convergent multiscale methods for high frequency  heterogeneous Helmholtz equations",
    "descriptor": "",
    "authors": [
      "Yifan Chen",
      "Thomas Y. Hou",
      "Yixuan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04080"
  },
  {
    "id": "arXiv:2105.11107",
    "title": "FineAction: A Fine-Grained Video Dataset for Temporal Action  Localization",
    "abstract": "Comments: Accepted by IEEE T-IP. HomePage: this https URL",
    "descriptor": "\nComments: Accepted by IEEE T-IP. HomePage: this https URL\n",
    "authors": [
      "Yi Liu",
      "Limin Wang",
      "Yali Wang",
      "Xiao Ma",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11107"
  },
  {
    "id": "arXiv:2106.02226",
    "title": "The saturation spectrum for antichains of subsets",
    "abstract": "Comments: This is a merger of arXiv:2106.02226v2 with arXiv:2106.02230",
    "descriptor": "\nComments: This is a merger of arXiv:2106.02226v2 with arXiv:2106.02230\n",
    "authors": [
      "Jerrold R. Griggs",
      "Thomas Kalinowski",
      "Uwe Leck",
      "Ian T. Roberts",
      "Michael Schmitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02226"
  },
  {
    "id": "arXiv:2106.02230",
    "title": "Maximal antichains of subsets II: Constructions",
    "abstract": "Comments: This paper has been merged with arXiv:2106.02226",
    "descriptor": "\nComments: This paper has been merged with arXiv:2106.02226\n",
    "authors": [
      "Jerrold R. Griggs",
      "Thomas Kalinowski",
      "Uwe Leck",
      "Ian T. Roberts",
      "Michael Schmitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02230"
  },
  {
    "id": "arXiv:2106.03917",
    "title": "Mixture Outlier Exposure: Towards Out-of-Distribution Detection in  Fine-grained Environments",
    "abstract": "Comments: Accepted by WACV'23",
    "descriptor": "\nComments: Accepted by WACV'23\n",
    "authors": [
      "Jingyang Zhang",
      "Nathan Inkawhich",
      "Randolph Linderman",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03917"
  },
  {
    "id": "arXiv:2106.05152",
    "title": "Rethinking Transfer Learning for Medical Image Classification",
    "abstract": "Rethinking Transfer Learning for Medical Image Classification",
    "descriptor": "",
    "authors": [
      "Le Peng",
      "Hengyue Liang",
      "Gaoxiang Luo",
      "Taihui Li",
      "Ju Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05152"
  },
  {
    "id": "arXiv:2106.06090",
    "title": "Graph Neural Networks for Natural Language Processing: A Survey",
    "abstract": "Comments: 127 pages, accepted by Foundations and Trends in Machine Learning",
    "descriptor": "\nComments: 127 pages, accepted by Foundations and Trends in Machine Learning\n",
    "authors": [
      "Lingfei Wu",
      "Yu Chen",
      "Kai Shen",
      "Xiaojie Guo",
      "Hanning Gao",
      "Shucheng Li",
      "Jian Pei",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06090"
  },
  {
    "id": "arXiv:2106.06965",
    "title": "Contrastive Attention for Automatic Chest X-ray Report Generation",
    "abstract": "Comments: Appear in Findings of ACL 2021 (The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021))",
    "descriptor": "\nComments: Appear in Findings of ACL 2021 (The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021))\n",
    "authors": [
      "Xuewei Ma",
      "Fenglin Liu",
      "Changchang Yin",
      "Xian Wu",
      "Shen Ge",
      "Yuexian Zou",
      "Ping Zhang",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06965"
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": "Comments: Appeared in ICML 2022 (errata added on 19 Oct., 2022)",
    "descriptor": "\nComments: Appeared in ICML 2022 (errata added on 19 Oct., 2022)\n",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10771"
  },
  {
    "id": "arXiv:2106.11483",
    "title": "A Comprehensive Exploration of Pre-training Language Models",
    "abstract": "Comments: working in progress",
    "descriptor": "\nComments: working in progress\n",
    "authors": [
      "Tong Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11483"
  },
  {
    "id": "arXiv:2108.07503",
    "title": "On balanced sequences and their critical exponent",
    "abstract": "On balanced sequences and their critical exponent",
    "descriptor": "",
    "authors": [
      "Francesco Dolce",
      "Lubomira Dvorakova",
      "Edita Pelantova"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.07503"
  },
  {
    "id": "arXiv:2109.00212",
    "title": "Diverse Sample Generation: Pushing the Limit of Generative Data-free  Quantization",
    "abstract": "Diverse Sample Generation: Pushing the Limit of Generative Data-free  Quantization",
    "descriptor": "",
    "authors": [
      "Haotong Qin",
      "Yifu Ding",
      "Xiangguo Zhang",
      "Jiakai Wang",
      "Xianglong Liu",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00212"
  },
  {
    "id": "arXiv:2109.06141",
    "title": "On Tilted Losses in Machine Learning: Theory and Applications",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2007.01162",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.01162\n",
    "authors": [
      "Tian Li",
      "Ahmad Beirami",
      "Maziar Sanjabi",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06141"
  },
  {
    "id": "arXiv:2109.10892",
    "title": "The Design of Stretch: A Compact, Lightweight Mobile Manipulator for  Indoor Human Environments",
    "abstract": "Comments: 6 pages + refs, 9 figures. Published in peer-reviewed conference (ICRA 2022) with DOI 10.1109/ICRA46639.2022.9811922. Please cite like: [1] Charles C. Kemp, Aaron Edsinger, Henry M. Clever and Blaine Matulevich, \"The Design of Stretch: A Compact, Lightweight Mobile Manipulator for Indoor Human Environments\", IEEE International Conference on Robotics and Automation (ICRA), 2022",
    "descriptor": "\nComments: 6 pages + refs, 9 figures. Published in peer-reviewed conference (ICRA 2022) with DOI 10.1109/ICRA46639.2022.9811922. Please cite like: [1] Charles C. Kemp, Aaron Edsinger, Henry M. Clever and Blaine Matulevich, \"The Design of Stretch: A Compact, Lightweight Mobile Manipulator for Indoor Human Environments\", IEEE International Conference on Robotics and Automation (ICRA), 2022\n",
    "authors": [
      "Charles C. Kemp",
      "Aaron Edsinger",
      "Henry M. Clever",
      "Blaine Matulevich"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.10892"
  },
  {
    "id": "arXiv:2109.13211",
    "title": "Composite Resource Scheduling for Networked Control Systems",
    "abstract": "Composite Resource Scheduling for Networked Control Systems",
    "descriptor": "",
    "authors": [
      "Peng Wu",
      "Chenchen Fu",
      "Tianyu Wang",
      "Minming Li",
      "Yingchao Zhao",
      "Chun Jason Xue",
      "Song Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.13211"
  },
  {
    "id": "arXiv:2110.00637",
    "title": "ML4C: Seeing Causality Through Latent Vicinity",
    "abstract": "Comments: causal discovery, supervised causal learning, vicinity, identifiability, learnability",
    "descriptor": "\nComments: causal discovery, supervised causal learning, vicinity, identifiability, learnability\n",
    "authors": [
      "Haoyue Dai",
      "Rui Ding",
      "Yuanyuan Jiang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00637"
  },
  {
    "id": "arXiv:2110.03032",
    "title": "Learning Multi-Objective Curricula for Robotic Policy Learning",
    "abstract": "Comments: CoRL 2022; Reinforcement Learning; Meta-Reinforcement Learning; Hyper-network",
    "descriptor": "\nComments: CoRL 2022; Reinforcement Learning; Meta-Reinforcement Learning; Hyper-network\n",
    "authors": [
      "Jikun Kang",
      "Miao Liu",
      "Abhinav Gupta",
      "Chris Pal",
      "Xue Liu",
      "Jie Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03032"
  },
  {
    "id": "arXiv:2110.03485",
    "title": "Cartoon Explanations of Image Classifiers",
    "abstract": "Comments: ECCV 2022 (oral)",
    "descriptor": "\nComments: ECCV 2022 (oral)\n",
    "authors": [
      "Stefan Kolek",
      "Duc Anh Nguyen",
      "Ron Levie",
      "Joan Bruna",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03485"
  },
  {
    "id": "arXiv:2110.15416",
    "title": "On computing root polynomials and minimal bases of matrix pencils",
    "abstract": "On computing root polynomials and minimal bases of matrix pencils",
    "descriptor": "",
    "authors": [
      "Vanni Noferini",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15416"
  },
  {
    "id": "arXiv:2111.06027",
    "title": "Theoretical Exploration of Flexible Transmitter Model",
    "abstract": "Comments: 45 pages, to be published in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: 45 pages, to be published in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Jin-Hui Wu",
      "Shao-Qun Zhang",
      "Yuan Jiang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.06027"
  },
  {
    "id": "arXiv:2111.07267",
    "title": "Understanding Jargon: Combining Extraction and Generation for Definition  Modeling",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Jie Huang",
      "Hanyin Shao",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.07267"
  },
  {
    "id": "arXiv:2111.11309",
    "title": "No-Regret Dynamics in the Fenchel Game: A Unified Framework for  Algorithmic Convex Optimization",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.12923",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.12923\n",
    "authors": [
      "Jun-Kun Wang",
      "Jacob Abernethy",
      "Kfir Y. Levy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.11309"
  },
  {
    "id": "arXiv:2112.03162",
    "title": "Embedding Arithmetic of Multimodal Queries for Image Retrieval",
    "abstract": "Comments: accepted at O-DRUM (CVPR workshop 2022)",
    "descriptor": "\nComments: accepted at O-DRUM (CVPR workshop 2022)\n",
    "authors": [
      "Guillaume Couairon",
      "Matthieu Cord",
      "Matthijs Douze",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03162"
  },
  {
    "id": "arXiv:2112.06736",
    "title": "Roof-Transformer: Divided and Joined Understanding with Knowledge  Enhancement",
    "abstract": "Roof-Transformer: Divided and Joined Understanding with Knowledge  Enhancement",
    "descriptor": "",
    "authors": [
      "Wei-Lin Liao",
      "Cheng-En Su",
      "Wei-Yun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06736"
  },
  {
    "id": "arXiv:2112.06786",
    "title": "On using the complex step method for the approximation of Fr\u00e9chet  derivatives of matrix functions in automorphism groups",
    "abstract": "On using the complex step method for the approximation of Fr\u00e9chet  derivatives of matrix functions in automorphism groups",
    "descriptor": "",
    "authors": [
      "Tom Werner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.06786"
  },
  {
    "id": "arXiv:2112.07356",
    "title": "Technical Language Supervision for Intelligent Fault Diagnosis in  Process Industry",
    "abstract": "Technical Language Supervision for Intelligent Fault Diagnosis in  Process Industry",
    "descriptor": "",
    "authors": [
      "Karl L\u00f6wenmark",
      "Cees Taal",
      "Stephan Schnabel",
      "Marcus Liwicki",
      "Fredrik Sandin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07356"
  },
  {
    "id": "arXiv:2112.14337",
    "title": "Closer Look at the Transferability of Adversarial Examples: How They  Fool Different Models Differently",
    "abstract": "Comments: 25 pages, 13 figures, Accepted at the IEEE Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: 25 pages, 13 figures, Accepted at the IEEE Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Futa Waseda",
      "Sosuke Nishikawa",
      "Trung-Nghia Le",
      "Huy H. Nguyen",
      "Isao Echizen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14337"
  },
  {
    "id": "arXiv:2112.15577",
    "title": "How Infinitely Wide Neural Networks Can Benefit from Multi-task Learning  -- an Exact Macroscopic Characterization",
    "abstract": "Comments: 13 pages + appendix",
    "descriptor": "\nComments: 13 pages + appendix\n",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.15577"
  },
  {
    "id": "arXiv:2201.05928",
    "title": "Computing Truncated Joint Approximate Eigenbases for Model Order  Reduction",
    "abstract": "Computing Truncated Joint Approximate Eigenbases for Model Order  Reduction",
    "descriptor": "",
    "authors": [
      "Terry A. Loring",
      "Fredy Vides"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.05928"
  },
  {
    "id": "arXiv:2201.08455",
    "title": "LOSTIN: Logic Optimization via Spatio-Temporal Information with Hybrid  Graph Models",
    "abstract": "LOSTIN: Logic Optimization via Spatio-Temporal Information with Hybrid  Graph Models",
    "descriptor": "",
    "authors": [
      "Nan Wu",
      "Jiwon Lee",
      "Yuan Xie",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.08455"
  },
  {
    "id": "arXiv:2201.09186",
    "title": "pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing",
    "abstract": "pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing",
    "descriptor": "",
    "authors": [
      "Jiasi Weng",
      "Jian Weng",
      "Gui Tang",
      "Anjia Yang",
      "Ming Li",
      "Jia-Nan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09186"
  },
  {
    "id": "arXiv:2201.11443",
    "title": "Yes-Yes-Yes: Proactive Data Collection for ACL Rolling Review and Beyond",
    "abstract": "Comments: Accepted at Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2022\n",
    "authors": [
      "Nils Dycke",
      "Ilia Kuznetsov",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11443"
  },
  {
    "id": "arXiv:2201.11596",
    "title": "FairEGM: Fair Link Prediction and Recommendation via Emulated Graph  Modification",
    "abstract": "Comments: 14 pages, 3 figures, 6 tables",
    "descriptor": "\nComments: 14 pages, 3 figures, 6 tables\n",
    "authors": [
      "Sean Current",
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11596"
  },
  {
    "id": "arXiv:2202.05897",
    "title": "On maximal autocorrelations of Rudin-Shapiro sequences",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Daniel Tarnu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05897"
  },
  {
    "id": "arXiv:2202.05903",
    "title": "Can We Talk? An Exploratory Study of Gender and Network Ties in a Local  Government Setting",
    "abstract": "Can We Talk? An Exploratory Study of Gender and Network Ties in a Local  Government Setting",
    "descriptor": "",
    "authors": [
      "Leisha DeHart-Davis",
      "Nicole Humphrey",
      "Travis A. Whetsell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.05903"
  },
  {
    "id": "arXiv:2202.06483",
    "title": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "abstract": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "descriptor": "",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Yao Tian",
      "Zejun Ma",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06483"
  },
  {
    "id": "arXiv:2202.06729",
    "title": "Random walk informed community detection reveals heterogeneities in the  lymph node conduits network",
    "abstract": "Random walk informed community detection reveals heterogeneities in the  lymph node conduits network",
    "descriptor": "",
    "authors": [
      "Sol\u00e8ne Song",
      "Malek Senoussi",
      "Paul Escande",
      "Paul Villoutreix"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.06729"
  },
  {
    "id": "arXiv:2202.07880",
    "title": "$\\rm{C {\\small IS}}^2$: A Simplified Commonsense Inference Evaluation  for Story Prose",
    "abstract": "Comments: Published at the Workshop on Commonsense Representation and Reasoning (CSRR) @ ACL 2022",
    "descriptor": "\nComments: Published at the Workshop on Commonsense Representation and Reasoning (CSRR) @ ACL 2022\n",
    "authors": [
      "Bryan Li",
      "Lara J. Martin",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07880"
  },
  {
    "id": "arXiv:2202.10213",
    "title": "A harmonic framework for stepsize selection in gradient methods",
    "abstract": "A harmonic framework for stepsize selection in gradient methods",
    "descriptor": "",
    "authors": [
      "Giulia Ferrandi",
      "Michiel E. Hochstenbach",
      "Natasa Krejic"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.10213"
  },
  {
    "id": "arXiv:2202.10679",
    "title": "Physics-Informed Graph Learning",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Ciyuan Peng",
      "Feng Xia",
      "Vidya Saikrishna",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10679"
  },
  {
    "id": "arXiv:2202.12837",
    "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning  Work?",
    "abstract": "Comments: 17 pages; 12 figures. Published as a conference paper at EMNLP 2022 (long). Code available at this https URL",
    "descriptor": "\nComments: 17 pages; 12 figures. Published as a conference paper at EMNLP 2022 (long). Code available at this https URL\n",
    "authors": [
      "Sewon Min",
      "Xinxi Lyu",
      "Ari Holtzman",
      "Mikel Artetxe",
      "Mike Lewis",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12837"
  },
  {
    "id": "arXiv:2203.00418",
    "title": "Recovery of Missing Sensor Data by Reconstructing Time-varying Graph  Signals",
    "abstract": "Comments: Five pages, two figures, 2022 30th European Signal Processing Conference (EUSIPCO). Published version available at: this https URL",
    "descriptor": "\nComments: Five pages, two figures, 2022 30th European Signal Processing Conference (EUSIPCO). Published version available at: this https URL\n",
    "authors": [
      "Anindya Mondal",
      "Mayukhmali Das",
      "Aditi Chatterjee",
      "Palaniandavar Venkateswaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.00418"
  },
  {
    "id": "arXiv:2203.00725",
    "title": "A Conformer Based Acoustic Model for Robust Automatic Speech Recognition",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yufeng Yang",
      "Peidong Wang",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.00725"
  },
  {
    "id": "arXiv:2203.01116",
    "title": "Superiorized Adaptive Projected Subgradient Method with Application to  MIMO Detection",
    "abstract": "Comments: Submitted to IEEE Transactions on Signal Processing for possible publication",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal Processing for possible publication\n",
    "authors": [
      "Jochen Fink",
      "Renato L. G. Cavalcante",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.01116"
  },
  {
    "id": "arXiv:2203.01968",
    "title": "Learning Time-optimized Path Tracking with or without Sensory Feedback",
    "abstract": "Comments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022); 8 pages, 11 figures; A video presentation is available at this https URL",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022); 8 pages, 11 figures; A video presentation is available at this https URL\n",
    "authors": [
      "Jonas C. Kiemel",
      "Torsten Kr\u00f6ger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01968"
  },
  {
    "id": "arXiv:2203.02053",
    "title": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive  Representation Learning",
    "abstract": "Comments: Published at NeurIPS 2022. Code and data are available at this https URL",
    "descriptor": "\nComments: Published at NeurIPS 2022. Code and data are available at this https URL\n",
    "authors": [
      "Weixin Liang",
      "Yuhui Zhang",
      "Yongchan Kwon",
      "Serena Yeung",
      "James Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.02053"
  },
  {
    "id": "arXiv:2203.07682",
    "title": "Enriched CNN-Transformer Feature Aggregation Networks for  Super-Resolution",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Jinsu Yoo",
      "Taehoon Kim",
      "Sihaeng Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07682"
  },
  {
    "id": "arXiv:2203.10537",
    "title": "Iwin: Human-Object Interaction Detection via Transformer with Irregular  Windows",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Danyang Tu",
      "Xiongkuo Min",
      "Huiyu Duan",
      "Guodong Guo",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10537"
  },
  {
    "id": "arXiv:2203.14832",
    "title": "A new Nested Cross Approximation",
    "abstract": "Comments: 26 pages, 10 figures, 3 Tables",
    "descriptor": "\nComments: 26 pages, 10 figures, 3 Tables\n",
    "authors": [
      "Vaishnavi Gujjula",
      "Sivaram Ambikasaran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.14832"
  },
  {
    "id": "arXiv:2204.00279",
    "title": "Studying the Impact of Data Disclosure Mechanism in Recommender Systems  via Simulation",
    "abstract": "Comments: Accepted by TOIS 2022",
    "descriptor": "\nComments: Accepted by TOIS 2022\n",
    "authors": [
      "Ziqian Chen",
      "Fei Sun",
      "Yifan Tang",
      "Haokun Chen",
      "Jinyang Gao",
      "Bolin Ding"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.00279"
  },
  {
    "id": "arXiv:2204.01403",
    "title": "How stable are Transferability Metrics evaluations?",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Andrea Agostinelli",
      "Michal P\u00e1ndy",
      "Jasper Uijlings",
      "Thomas Mensink",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01403"
  },
  {
    "id": "arXiv:2204.01936",
    "title": "Hall-type theorems for fast dynamic matching and applications",
    "abstract": "Comments: This version is a major improvement of the previous one. The case of full dynamic matching is now covered. The title has been changed to reflect this. Abstract abridged to conform to arxiv requirements",
    "descriptor": "\nComments: This version is a major improvement of the previous one. The case of full dynamic matching is now covered. The title has been changed to reflect this. Abstract abridged to conform to arxiv requirements\n",
    "authors": [
      "Bruno Bauwens",
      "Marius Zimand"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.01936"
  },
  {
    "id": "arXiv:2204.06601",
    "title": "A Study of Causal Confusion in Preference-Based Reward Learning",
    "abstract": "A Study of Causal Confusion in Preference-Based Reward Learning",
    "descriptor": "",
    "authors": [
      "Jeremy Tien",
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "Anca D. Dragan",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.06601"
  },
  {
    "id": "arXiv:2204.07155",
    "title": "Tight Bounds for Quantum State Certification with Incoherent  Measurements",
    "abstract": "Comments: 55 pages, comments welcome; v2: bug fix for Claims 6.11 and 7.13",
    "descriptor": "\nComments: 55 pages, comments welcome; v2: bug fix for Claims 6.11 and 7.13\n",
    "authors": [
      "Sitan Chen",
      "Brice Huang",
      "Jerry Li",
      "Allen Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07155"
  },
  {
    "id": "arXiv:2204.07615",
    "title": "TabNAS: Rejection Sampling for Neural Architecture Search on Tabular  Datasets",
    "abstract": "Comments: NeurIPS 2022; 30 pages, 15 figures, 7 tables",
    "descriptor": "\nComments: NeurIPS 2022; 30 pages, 15 figures, 7 tables\n",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07615"
  },
  {
    "id": "arXiv:2204.08152",
    "title": "Back to the Future: Bidirectional Information Decoupling Network for  Multi-turn Dialogue Modeling",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08152"
  },
  {
    "id": "arXiv:2204.09345",
    "title": "Online Caching with no Regret: Optimistic Learning via Recommendations",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2202.10590",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.10590\n",
    "authors": [
      "Naram Mhaisen",
      "George Iosifidis",
      "Douglas Leith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09345"
  },
  {
    "id": "arXiv:2204.10109",
    "title": "Deep Model-Based Super-Resolution with Non-uniform Blur",
    "abstract": "Deep Model-Based Super-Resolution with Non-uniform Blur",
    "descriptor": "",
    "authors": [
      "Charles Laroche",
      "Andr\u00e9s Almansa",
      "Matias Tassano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.10109"
  },
  {
    "id": "arXiv:2204.10691",
    "title": "The mixed search game against an agile and visible fugitive is monotone",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Guillaume Mescoff",
      "Christophe Paul",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.10691"
  },
  {
    "id": "arXiv:2204.11137",
    "title": "Evaluating regular path queries under the all-shortest paths semantics",
    "abstract": "Evaluating regular path queries under the all-shortest paths semantics",
    "descriptor": "",
    "authors": [
      "Domagoj Vrgo\u010d"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.11137"
  },
  {
    "id": "arXiv:2204.13004",
    "title": "Defending Person Detection Against Adversarial Patch Attack by using  Universal Defensive Frame",
    "abstract": "Comments: Accepted at IEEE Transactions on Image Processing (TIP), 2022",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Image Processing (TIP), 2022\n",
    "authors": [
      "Youngjoon Yu",
      "Hong Joo Lee",
      "Hakmin Lee",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13004"
  },
  {
    "id": "arXiv:2204.13631",
    "title": "Reliable Visual Question Answering: Abstain Rather Than Answer  Incorrectly",
    "abstract": "Comments: ECCV 2022. Code and models are available here: this https URL",
    "descriptor": "\nComments: ECCV 2022. Code and models are available here: this https URL\n",
    "authors": [
      "Spencer Whitehead",
      "Suzanne Petryk",
      "Vedaad Shakib",
      "Joseph Gonzalez",
      "Trevor Darrell",
      "Anna Rohrbach",
      "Marcus Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13631"
  },
  {
    "id": "arXiv:2204.13778",
    "title": "Inferring Implicit Relations in Complex Questions with Language Models",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Uri Katz",
      "Mor Geva",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.13778"
  },
  {
    "id": "arXiv:2204.14030",
    "title": "Neural Implicit Representations for Physical Parameter Inference from a  Single Video",
    "abstract": "Comments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Florian Hofherr",
      "Lukas Koestler",
      "Florian Bernard",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.14030"
  },
  {
    "id": "arXiv:2204.14047",
    "title": "A Deep Learning based No-reference Quality Assessment Model for UGC  Videos",
    "abstract": "Comments: Accepted by ACM MM 2022",
    "descriptor": "\nComments: Accepted by ACM MM 2022\n",
    "authors": [
      "Wei Sun",
      "Xiongkuo Min",
      "Wei Lu",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.14047"
  },
  {
    "id": "arXiv:2205.02361",
    "title": "Creating a Forensic Database of Shoeprints from Online Shoe Tread Photos",
    "abstract": "Comments: published in WACV 2023; 8 pages including 11 figures and 3 tables; contains reference and appendix",
    "descriptor": "\nComments: published in WACV 2023; 8 pages including 11 figures and 3 tables; contains reference and appendix\n",
    "authors": [
      "Samia Shafique",
      "Bailey Kong",
      "Shu Kong",
      "Charless C. Fowlkes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02361"
  },
  {
    "id": "arXiv:2205.04287",
    "title": "A Regular and Complete Notion of Delay for Streaming String Transducers",
    "abstract": "A Regular and Complete Notion of Delay for Streaming String Transducers",
    "descriptor": "",
    "authors": [
      "Emmanuel Filiot",
      "Isma\u00ebl Jecker",
      "Christof L\u00f6ding",
      "Sarah Winter"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.04287"
  },
  {
    "id": "arXiv:2205.06187",
    "title": "Efficient Deep Visual and Inertial Odometry with Adaptive Visual  Modality Selection",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Mingyu Yang",
      "Yu Chen",
      "Hun-Seok Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06187"
  },
  {
    "id": "arXiv:2205.06207",
    "title": "CiteSum: Citation Text-guided Scientific Extreme Summarization and  Domain Adaptation with Limited Supervision",
    "abstract": "Comments: EMNLP 2022. TLDR: By pretraining on (automatically extracted) citation sentences in scientific papers, we achieve SOTA on SciTLDR, XSum, and Gigaword in zero-shot and (or) few-shot settings",
    "descriptor": "\nComments: EMNLP 2022. TLDR: By pretraining on (automatically extracted) citation sentences in scientific papers, we achieve SOTA on SciTLDR, XSum, and Gigaword in zero-shot and (or) few-shot settings\n",
    "authors": [
      "Yuning Mao",
      "Ming Zhong",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.06207"
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "descriptor": "",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09389"
  },
  {
    "id": "arXiv:2205.10455",
    "title": "Pre-training Transformer Models with Sentence-Level Objectives for  Answer Sentence Selection",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Luca Di Liello",
      "Siddhant Garg",
      "Luca Soldaini",
      "Alessandro Moschitti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10455"
  },
  {
    "id": "arXiv:2205.10479",
    "title": "DEER: Descriptive Knowledge Graph for Explaining Entity Relationships",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Jie Huang",
      "Kerui Zhu",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10479"
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representations",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Jing Chen",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10852"
  },
  {
    "id": "arXiv:2205.11102",
    "title": "The k-Server with Preferences Problem",
    "abstract": "Comments: A conference version of this paper was accepted at the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA 2022)",
    "descriptor": "\nComments: A conference version of this paper was accepted at the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA 2022)\n",
    "authors": [
      "Jannik Castenow",
      "Bj\u00f6rn Feldkord",
      "Till Knollmann",
      "Manuel Malatyali",
      "Friedhelm Meyer auf der Heide"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.11102"
  },
  {
    "id": "arXiv:2205.11432",
    "title": "Logical Reasoning with Span-Level Predictions for Interpretable and  Robust NLI Models",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Joe Stacey",
      "Pasquale Minervini",
      "Haim Dubossarsky",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11432"
  },
  {
    "id": "arXiv:2205.11691",
    "title": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
    "abstract": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
    "descriptor": "",
    "authors": [
      "Chenqing Hua",
      "Guillaume Rabusseau",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11691"
  },
  {
    "id": "arXiv:2205.11935",
    "title": "CryptoTL: Private, Efficient and Secure Transfer Learning",
    "abstract": "CryptoTL: Private, Efficient and Secure Transfer Learning",
    "descriptor": "",
    "authors": [
      "Roman Walch",
      "Samuel Sousa",
      "Lukas Helminger",
      "Stefanie Lindstaedt",
      "Christian Rechberger",
      "Andreas Tr\u00fcgler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11935"
  },
  {
    "id": "arXiv:2205.12302",
    "title": "Garden-Path Traversal in GPT-2",
    "abstract": "Comments: 9 pages, 6 figures, Accepted to EMNLP BlackBox NLP 2022",
    "descriptor": "\nComments: 9 pages, 6 figures, Accepted to EMNLP BlackBox NLP 2022\n",
    "authors": [
      "William Jurayj",
      "William Rudman",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12302"
  },
  {
    "id": "arXiv:2205.12628",
    "title": "Are Large Pre-Trained Language Models Leaking Your Personal Information?",
    "abstract": "Comments: Accepted to Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Jie Huang",
      "Hanyin Shao",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12628"
  },
  {
    "id": "arXiv:2205.12695",
    "title": "Surprises in adversarially-trained linear regression",
    "abstract": "Surprises in adversarially-trained linear regression",
    "descriptor": "",
    "authors": [
      "Ant\u00f4nio H. Ribeiro",
      "Dave Zachariah",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.12695"
  },
  {
    "id": "arXiv:2205.13418",
    "title": "Avoiding Barren Plateaus with Classical Deep Neural Networks",
    "abstract": "Avoiding Barren Plateaus with Classical Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13418"
  },
  {
    "id": "arXiv:2205.13462",
    "title": "FedDebias: Reducing the Local Learning Bias Improves Federated Learning  on Heterogeneous Data",
    "abstract": "FedDebias: Reducing the Local Learning Bias Improves Federated Learning  on Heterogeneous Data",
    "descriptor": "",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13462"
  },
  {
    "id": "arXiv:2205.13647",
    "title": "Learning to Reason with Neural Networks: Generalization, Unseen Data and  Boolean Measures",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Emmanuel Abbe",
      "Samy Bengio",
      "Elisabetta Cornacchia",
      "Jon Kleinberg",
      "Aryo Lotfi",
      "Maithra Raghu",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13647"
  },
  {
    "id": "arXiv:2205.13925",
    "title": "DELTA: Diverse Client Sampling for Fasting Federated Learning",
    "abstract": "DELTA: Diverse Client Sampling for Fasting Federated Learning",
    "descriptor": "",
    "authors": [
      "Lin Wang",
      "YongXin Guo",
      "Tao Lin",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13925"
  },
  {
    "id": "arXiv:2205.15864",
    "title": "Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern  Recognition on Neuromorphic Hardware",
    "abstract": "Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern  Recognition on Neuromorphic Hardware",
    "descriptor": "",
    "authors": [
      "Simon F Muller-Cleve",
      "Vittorio Fra",
      "Lyes Khacef",
      "Alejandro Pequeno-Zurro",
      "Daniel Klepatsch",
      "Evelina Forno",
      "Diego G Ivanovich",
      "Shavika Rastogi",
      "Gianvito Urgese",
      "Friedemann Zenke",
      "Chiara Bartolozzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15864"
  },
  {
    "id": "arXiv:2206.00278",
    "title": "On the Perils of Cascading Robust Classifiers",
    "abstract": "On the Perils of Cascading Robust Classifiers",
    "descriptor": "",
    "authors": [
      "Ravi Mangal",
      "Zifan Wang",
      "Chi Zhang",
      "Klas Leino",
      "Corina Pasareanu",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00278"
  },
  {
    "id": "arXiv:2206.01295",
    "title": "Rashomon Capacity: A Metric for Predictive Multiplicity in  Classification",
    "abstract": "Comments: NeurIPS 2022 camera-ready version (34 pages, 23 figures, 2 tables)",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready version (34 pages, 23 figures, 2 tables)\n",
    "authors": [
      "Hsiang Hsu",
      "Flavio du Pin Calmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01295"
  },
  {
    "id": "arXiv:2206.01666",
    "title": "Algorithm for Constrained Markov Decision Process with Linear  Convergence",
    "abstract": "Comments: 27 pages, 2 figures, 3 tables. Improved presentation of the material, added a table with results, stated contributions more clearly, changed article template",
    "descriptor": "\nComments: 27 pages, 2 figures, 3 tables. Improved presentation of the material, added a table with results, stated contributions more clearly, changed article template\n",
    "authors": [
      "Egor Gladin",
      "Maksim Lavrik-Karmazin",
      "Karina Zainullina",
      "Varvara Rudenko",
      "Alexander Gasnikov",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01666"
  },
  {
    "id": "arXiv:2206.01962",
    "title": "Formal Specifications from Natural Language",
    "abstract": "Formal Specifications from Natural Language",
    "descriptor": "",
    "authors": [
      "Christopher Hahn",
      "Frederik Schmitt",
      "Julia J. Tillman",
      "Niklas Metzger",
      "Julian Siber",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.01962"
  },
  {
    "id": "arXiv:2206.04158",
    "title": "Texture Extraction Methods Based Ensembling Framework for Improved  Classification",
    "abstract": "Texture Extraction Methods Based Ensembling Framework for Improved  Classification",
    "descriptor": "",
    "authors": [
      "Vijay Pandey",
      "Trapti Kalra",
      "Mayank Gubba",
      "Mohammed Faisal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04158"
  },
  {
    "id": "arXiv:2206.04403",
    "title": "VITA: Video Instance Segmentation via Object Token Association",
    "abstract": "VITA: Video Instance Segmentation via Object Token Association",
    "descriptor": "",
    "authors": [
      "Miran Heo",
      "Sukjun Hwang",
      "Seoung Wug Oh",
      "Joon-Young Lee",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04403"
  },
  {
    "id": "arXiv:2206.04607",
    "title": "On Margins and Generalisation for Voting Classifiers",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Felix Biggs",
      "Valentina Zantedeschi",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04607"
  },
  {
    "id": "arXiv:2206.05091",
    "title": "Muffliato: Peer-to-Peer Privacy Amplification for Decentralized  Optimization and Averaging",
    "abstract": "Muffliato: Peer-to-Peer Privacy Amplification for Decentralized  Optimization and Averaging",
    "descriptor": "",
    "authors": [
      "Edwige Cyffers",
      "Mathieu Even",
      "Aur\u00e9lien Bellet",
      "Laurent Massouli\u00e9"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05091"
  },
  {
    "id": "arXiv:2206.05630",
    "title": "Mathematical Theory of Bayesian Statistics for Unknown Information  Source",
    "abstract": "Mathematical Theory of Bayesian Statistics for Unknown Information  Source",
    "descriptor": "",
    "authors": [
      "Sumio Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05630"
  },
  {
    "id": "arXiv:2206.05778",
    "title": "Learning-Based Data Storage [Vision] (Technical Report)",
    "abstract": "Comments: 11 pages, 13 figures",
    "descriptor": "\nComments: 11 pages, 13 figures\n",
    "authors": [
      "Xiang Lian",
      "Xiaofei Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05778"
  },
  {
    "id": "arXiv:2206.06043",
    "title": "Combining BMC and Fuzzing Techniques for Finding Software  Vulnerabilities in Concurrent Programs",
    "abstract": "Combining BMC and Fuzzing Techniques for Finding Software  Vulnerabilities in Concurrent Programs",
    "descriptor": "",
    "authors": [
      "Fatimah K. Aljaafari",
      "Rafael Menezes",
      "Edoardo Manino",
      "Fedor Shmarov",
      "Mustafa A. Mustafa",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06043"
  },
  {
    "id": "arXiv:2206.06131",
    "title": "Seeing the forest and the tree: Building representations of both  individual and collective dynamics with transformers",
    "abstract": "Comments: accepted by NeurIPS 2022",
    "descriptor": "\nComments: accepted by NeurIPS 2022\n",
    "authors": [
      "Ran Liu",
      "Mehdi Azabou",
      "Max Dabagia",
      "Jingyun Xiao",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06131"
  },
  {
    "id": "arXiv:2206.07181",
    "title": "To Aggregate or Not? Learning with Separate Noisy Labels",
    "abstract": "Comments: Paper under Review",
    "descriptor": "\nComments: Paper under Review\n",
    "authors": [
      "Jiaheng Wei",
      "Zhaowei Zhu",
      "Tianyi Luo",
      "Ehsan Amid",
      "Abhishek Kumar",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07181"
  },
  {
    "id": "arXiv:2206.07817",
    "title": "Low-Cost Superconducting Fan-Out with Repurposed Josephson Junctions",
    "abstract": "Comments: 11 pages, 20 figures, submitted to IEEE TAS",
    "descriptor": "\nComments: 11 pages, 20 figures, submitted to IEEE TAS\n",
    "authors": [
      "Jennifer Volk",
      "George Tzimpragos",
      "Alex Wynn",
      "Evan Golden",
      "Timothy Sherwood"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.07817"
  },
  {
    "id": "arXiv:2206.07823",
    "title": "An Investigation of Kripke-style Modal Type Theories",
    "abstract": "An Investigation of Kripke-style Modal Type Theories",
    "descriptor": "",
    "authors": [
      "Jason Z. S. Hu",
      "Brigitte Pientka"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.07823"
  },
  {
    "id": "arXiv:2206.09391",
    "title": "Towards Adversarial Attack on Vision-Language Pre-training Models",
    "abstract": "Comments: Accepted by ACM MM2022. Code is available in GitHub",
    "descriptor": "\nComments: Accepted by ACM MM2022. Code is available in GitHub\n",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.09391"
  },
  {
    "id": "arXiv:2206.09546",
    "title": "Policy Optimization with Linear Temporal Logic Constraints",
    "abstract": "Policy Optimization with Linear Temporal Logic Constraints",
    "descriptor": "",
    "authors": [
      "Cameron Voloshin",
      "Hoang M. Le",
      "Swarat Chaudhuri",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09546"
  },
  {
    "id": "arXiv:2206.09960",
    "title": "A Fast Algorithm for Ranking Users by their Influence in Online Social  Platforms",
    "abstract": "Comments: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)",
    "descriptor": "\nComments: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\n",
    "authors": [
      "Nouamane Arhachoui",
      "Esteban Bautista",
      "Maximilien Danisch",
      "Anastasios Giovanidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09960"
  },
  {
    "id": "arXiv:2206.11081",
    "title": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "abstract": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "descriptor": "",
    "authors": [
      "Hongjoon Ahn",
      "Yongyi Yang",
      "Quan Gan",
      "Taesup Moon",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11081"
  },
  {
    "id": "arXiv:2206.11898",
    "title": "Score-based Generative Models for Calorimeter Shower Simulation",
    "abstract": "Score-based Generative Models for Calorimeter Shower Simulation",
    "descriptor": "",
    "authors": [
      "Vinicius Mikuni",
      "Benjamin Nachman"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2206.11898"
  },
  {
    "id": "arXiv:2206.12788",
    "title": "Representative Teacher Keys for Knowledge Distillation Model Compression  Based on Attention Mechanism for Image Classification",
    "abstract": "Comments: eight pages, six figures, three tables",
    "descriptor": "\nComments: eight pages, six figures, three tables\n",
    "authors": [
      "Jun-Teng Yang",
      "Sheng-Che Kao",
      "Scott C.-H. Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12788"
  },
  {
    "id": "arXiv:2206.12800",
    "title": "Energy Circuit-based Integrated Energy Management System: Theory,  Implementation, and Application",
    "abstract": "Energy Circuit-based Integrated Energy Management System: Theory,  Implementation, and Application",
    "descriptor": "",
    "authors": [
      "Binbin Chen",
      "Qinglai Guo",
      "Guanxiong Yin",
      "Bin Wang",
      "Zhaoguang Pan",
      "Yuwei Chen",
      "Wenchuan Wu",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12800"
  },
  {
    "id": "arXiv:2206.13455",
    "title": "IBISCape: A Simulated Benchmark for multi-modal SLAM Systems Evaluation  in Large-scale Dynamic Environments",
    "abstract": "Comments: Accepted for publication in the Journal of Intelligent & Robotic Systems",
    "descriptor": "\nComments: Accepted for publication in the Journal of Intelligent & Robotic Systems\n",
    "authors": [
      "Abanob Soliman",
      "Fabien Bonardi",
      "D\u00e9sir\u00e9 Sidib\u00e9",
      "Samia Bouchafa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13455"
  },
  {
    "id": "arXiv:2206.13580",
    "title": "Ranking with multiple types of pairwise comparisons",
    "abstract": "Comments: 10 pages, 1 table, and 6 figures",
    "descriptor": "\nComments: 10 pages, 1 table, and 6 figures\n",
    "authors": [
      "M. E. J. Newman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13580"
  },
  {
    "id": "arXiv:2206.14579",
    "title": "Competence-based Multimodal Curriculum Learning for Medical Report  Generation",
    "abstract": "Comments: Accepted by ACL 2021 (Oral)",
    "descriptor": "\nComments: Accepted by ACL 2021 (Oral)\n",
    "authors": [
      "Xuewei Ma",
      "Fenglin Liu",
      "Shen Ge",
      "Xian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14579"
  },
  {
    "id": "arXiv:2207.01151",
    "title": "Modeling Randomly Walking Volatility with Chained Gamma Distributions",
    "abstract": "Modeling Randomly Walking Volatility with Chained Gamma Distributions",
    "descriptor": "",
    "authors": [
      "Di Zhang",
      "Qiang Niu",
      "Youzhou Zhou"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01151"
  },
  {
    "id": "arXiv:2207.05182",
    "title": "Fine-grained Activities of People Worldwide",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Jeffrey Byrne",
      "Greg Castanon",
      "Zhongheng Li",
      "Gil Ettinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05182"
  },
  {
    "id": "arXiv:2207.05695",
    "title": "A machine-learning-based tool for last closed-flux surface  reconstruction on tokamaks",
    "abstract": "A machine-learning-based tool for last closed-flux surface  reconstruction on tokamaks",
    "descriptor": "",
    "authors": [
      "Chenguang Wan",
      "Zhi Yu",
      "Alessandro Pau",
      "Xiaojuan Liu",
      "Jiangang Li"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05695"
  },
  {
    "id": "arXiv:2207.06827",
    "title": "Point-to-Box Network for Accurate Object Detection via Single Point  Supervision",
    "abstract": "Comments: Accepted by ECCV2022, github: this https URL",
    "descriptor": "\nComments: Accepted by ECCV2022, github: this https URL\n",
    "authors": [
      "Pengfei Chen",
      "Xuehui Yu",
      "Xumeng Han",
      "Najmul Hassan",
      "Kai Wang",
      "Jiachen Li",
      "Jian Zhao",
      "Humphrey Shi",
      "Zhenjun Han",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06827"
  },
  {
    "id": "arXiv:2207.07888",
    "title": "SizeShiftReg: a Regularization Method for Improving Size-Generalization  in Graph Neural Networks",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Davide Buffelli",
      "Pietro Li\u00f2",
      "Fabio Vandin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07888"
  },
  {
    "id": "arXiv:2207.08051",
    "title": "SatMAE: Pre-training Transformers for Temporal and Multi-Spectral  Satellite Imagery",
    "abstract": "Comments: Accepted at NeurIPS 2022. The first two listed names contributed equally to this project",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. The first two listed names contributed equally to this project\n",
    "authors": [
      "Yezhen Cong",
      "Samar Khanna",
      "Chenlin Meng",
      "Patrick Liu",
      "Erik Rozi",
      "Yutong He",
      "Marshall Burke",
      "David B. Lobell",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.08051"
  },
  {
    "id": "arXiv:2207.08993",
    "title": "Machine Learning in Orbit Estimation: a Survey",
    "abstract": "Comments: submitted to Acta Astronautica",
    "descriptor": "\nComments: submitted to Acta Astronautica\n",
    "authors": [
      "Francisco Caldas",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08993"
  },
  {
    "id": "arXiv:2207.09442",
    "title": "Theseus: A Library for Differentiable Nonlinear Optimization",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS), 2022",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Luis Pineda",
      "Taosha Fan",
      "Maurizio Monge",
      "Shobha Venkataraman",
      "Paloma Sodhi",
      "Ricky T. Q. Chen",
      "Joseph Ortiz",
      "Daniel DeTone",
      "Austin Wang",
      "Stuart Anderson",
      "Jing Dong",
      "Brandon Amos",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.09442"
  },
  {
    "id": "arXiv:2207.09508",
    "title": "HSE-NN Team at the 4th ABAW Competition: Multi-task Emotion Recognition  and Learning from Synthetic Images",
    "abstract": "Comments: accepted at ECCV Workshop ABAW4; 14 pages, 3 figures, 8 tables",
    "descriptor": "\nComments: accepted at ECCV Workshop ABAW4; 14 pages, 3 figures, 8 tables\n",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09508"
  },
  {
    "id": "arXiv:2207.11311",
    "title": "Understanding Non-linearity in Graph Neural Networks from the  Bayesian-Inference Perspective",
    "abstract": "Understanding Non-linearity in Graph Neural Networks from the  Bayesian-Inference Perspective",
    "descriptor": "",
    "authors": [
      "Rongzhe Wei",
      "Haoteng Yin",
      "Junteng Jia",
      "Austin R. Benson",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.11311"
  },
  {
    "id": "arXiv:2207.11592",
    "title": "Thermal half-lives of azobenzene derivatives: virtual screening based on  intersystem crossing using a machine learning potential",
    "abstract": "Thermal half-lives of azobenzene derivatives: virtual screening based on  intersystem crossing using a machine learning potential",
    "descriptor": "",
    "authors": [
      "Simon Axelrod",
      "Eugene Shakhnovich",
      "Rafael Gomez-Bombarelli"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11592"
  },
  {
    "id": "arXiv:2207.14358",
    "title": "Topological structure of complex predictions",
    "abstract": "Topological structure of complex predictions",
    "descriptor": "",
    "authors": [
      "Meng Liu",
      "Tamal K. Dey",
      "David F. Gleich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2207.14358"
  },
  {
    "id": "arXiv:2208.02713",
    "title": "NP Decision Procedure for Monomial and Linear Integer Constraints",
    "abstract": "NP Decision Procedure for Monomial and Linear Integer Constraints",
    "descriptor": "",
    "authors": [
      "Rodrigo Raya",
      "Jad Hamza",
      "Viktor Kun\u010dak"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.02713"
  },
  {
    "id": "arXiv:2208.03438",
    "title": "DeepGen: Diverse Search Ad Generation and Real-Time Customization",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Konstantin Golobokov",
      "Junyi Chai",
      "Victor Ye Dong",
      "Mandy Gu",
      "Bingyu Chi",
      "Jie Cao",
      "Yulan Yan",
      "Yi Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.03438"
  },
  {
    "id": "arXiv:2208.05706",
    "title": "A Cooperative Positioning Flamework for Robot and Smart Phone Based on  Visible Light Communication",
    "abstract": "Comments: high accuracy, cooperative positioning system",
    "descriptor": "\nComments: high accuracy, cooperative positioning system\n",
    "authors": [
      "Junye Chen",
      "Fangdi Li",
      "Futong An",
      "Chen Yang",
      "Hongzhan Song",
      "Shangsheng Wen",
      "Weipeng Guan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.05706"
  },
  {
    "id": "arXiv:2208.05863",
    "title": "GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions",
    "abstract": "GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions",
    "descriptor": "",
    "authors": [
      "Lihang Liu",
      "Donglong He",
      "Xiaomin Fang",
      "Shanzhuo Zhang",
      "Fan Wang",
      "Jingzhou He",
      "Hua Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.05863"
  },
  {
    "id": "arXiv:2208.07846",
    "title": "TexPrax: A Messaging Application for Ethical, Real-time Data Collection  and Annotation",
    "abstract": "Comments: Accepted at AACL 2022 (System Demonstrations). Code and data: this https URL",
    "descriptor": "\nComments: Accepted at AACL 2022 (System Demonstrations). Code and data: this https URL\n",
    "authors": [
      "Lorenz Stangier",
      "Ji-Ung Lee",
      "Yuxi Wang",
      "Marvin M\u00fcller",
      "Nicholas Frick",
      "Joachim Metternich",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.07846"
  },
  {
    "id": "arXiv:2208.09316",
    "title": "UKP-SQuARE v2: Explainability and Adversarial Attacks for Trustworthy QA",
    "abstract": "Comments: Accepted at AACL 2022 as Demo Paper",
    "descriptor": "\nComments: Accepted at AACL 2022 as Demo Paper\n",
    "authors": [
      "Rachneet Sachdeva",
      "Haritz Puerto",
      "Tim Baumg\u00e4rtner",
      "Sewin Tariverdian",
      "Hao Zhang",
      "Kexin Wang",
      "Hossain Shaikh Saadi",
      "Leonardo F. R. Ribeiro",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09316"
  },
  {
    "id": "arXiv:2208.09378",
    "title": "Federated Learning with Noisy Labels",
    "abstract": "Federated Learning with Noisy Labels",
    "descriptor": "",
    "authors": [
      "Vasileios Tsouvalas",
      "Aaqib Saeed",
      "Tanir Ozcelebi",
      "Nirvana Meratnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09378"
  },
  {
    "id": "arXiv:2208.12210",
    "title": "Learning Relational Causal Models with Cycles through Relational  Acyclification",
    "abstract": "Learning Relational Causal Models with Cycles through Relational  Acyclification",
    "descriptor": "",
    "authors": [
      "Ragib Ahsan",
      "David Arbour",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.12210"
  },
  {
    "id": "arXiv:2209.03138",
    "title": "Treating Motion as Option to Reduce Motion Dependency in Unsupervised  Video Object Segmentation",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Chaewon Park",
      "Donghyeong Kim",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03138"
  },
  {
    "id": "arXiv:2209.03891",
    "title": "IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal  Triplets via Pre-trained Autoregressive Language Model",
    "abstract": "Comments: Camera-ready for CASE@EMNLP",
    "descriptor": "\nComments: Camera-ready for CASE@EMNLP\n",
    "authors": [
      "Martin Fajcik",
      "Muskaan Singh",
      "Juan Zuluaga-Gomez",
      "Esa\u00fa Villatoro-Tello",
      "Sergio Burdisso",
      "Petr Motlicek",
      "Pavel Smrz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03891"
  },
  {
    "id": "arXiv:2209.05188",
    "title": "A Note on the Efficient Evaluation of PAC-Bayes Bounds",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Felix Biggs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.05188"
  },
  {
    "id": "arXiv:2209.07526",
    "title": "OmniVL:One Foundation Model for Image-Language and Video-Language Tasks",
    "abstract": "Comments: To appear at NeurIPs 2022, Camera Ready with Typos fixed",
    "descriptor": "\nComments: To appear at NeurIPs 2022, Camera Ready with Typos fixed\n",
    "authors": [
      "Junke Wang",
      "Dongdong Chen",
      "Zuxuan Wu",
      "Chong Luo",
      "Luowei Zhou",
      "Yucheng Zhao",
      "Yujia Xie",
      "Ce Liu",
      "Yu-Gang Jiang",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07526"
  },
  {
    "id": "arXiv:2209.07692",
    "title": "Answering Numerical Reasoning Questions in Table-Text Hybrid Contents  with Graph-based Encoder and Tree-based Decoder",
    "abstract": "Comments: Accepted by COLING 2022",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Fangyu Lei",
      "Shizhu He",
      "Xiang Li",
      "Jun Zhao",
      "Kang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07692"
  },
  {
    "id": "arXiv:2209.07699",
    "title": "Graph Contrastive Learning with Cross-view Reconstruction",
    "abstract": "Graph Contrastive Learning with Cross-view Reconstruction",
    "descriptor": "",
    "authors": [
      "Qianlong Wen",
      "Zhongyu Ouyang",
      "Chunhui Zhang",
      "Yiyue Qian",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07699"
  },
  {
    "id": "arXiv:2209.07805",
    "title": "A Comprehensive Benchmark for COVID-19 Predictive Modeling Using  Electronic Health Records in Intensive Care: Choosing the Best Model for  COVID-19 Prognosis",
    "abstract": "A Comprehensive Benchmark for COVID-19 Predictive Modeling Using  Electronic Health Records in Intensive Care: Choosing the Best Model for  COVID-19 Prognosis",
    "descriptor": "",
    "authors": [
      "Junyi Gao",
      "Yinghao Zhu",
      "Wenqing Wang",
      "Yasha Wang",
      "Wen Tang",
      "Liantao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07805"
  },
  {
    "id": "arXiv:2209.08885",
    "title": "Causal Effect Estimation with Global Probabilistic Forecasting: A Case  Study of the Impact of Covid-19 Lockdowns on Energy Demand",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ankitha Nandipura Prasanna",
      "Priscila Grecov",
      "Angela Dieyu Weng",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2209.08885"
  },
  {
    "id": "arXiv:2209.09038",
    "title": "A fast front-tracking approach and its analysis for a temporal  multiscale flow problem with a fractional-order boundary growth",
    "abstract": "A fast front-tracking approach and its analysis for a temporal  multiscale flow problem with a fractional-order boundary growth",
    "descriptor": "",
    "authors": [
      "Zhaoyang Wang",
      "Ping Lin",
      "Lei Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2209.09038"
  },
  {
    "id": "arXiv:2209.11178",
    "title": "Poisson Flow Generative Models",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yilun Xu",
      "Ziming Liu",
      "Max Tegmark",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11178"
  },
  {
    "id": "arXiv:2209.15148",
    "title": "Embedded System Performance Analysis for Implementing a Portable  Drowsiness Detection System for Drivers",
    "abstract": "Comments: 16 pages, 11 figures, 3 tables",
    "descriptor": "\nComments: 16 pages, 11 figures, 3 tables\n",
    "authors": [
      "Minjeong Kim",
      "Jimin Koo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.15148"
  },
  {
    "id": "arXiv:2209.15214",
    "title": "Construction and Applications of Billion-Scale Pre-trained Multimodal  Business Knowledge Graph",
    "abstract": "Comments: Work in Progress",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Shumin Deng",
      "Chengming Wang",
      "Zhoubo Li",
      "Ningyu Zhang",
      "Zelin Dai",
      "Hehong Chen",
      "Feiyu Xiong",
      "Ming Yan",
      "Qiang Chen",
      "Mosha Chen",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Bryan Hooi",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.15214"
  },
  {
    "id": "arXiv:2209.15362",
    "title": "Towards End-to-end Handwritten Document Recognition",
    "abstract": "Comments: Ph.D Thesis",
    "descriptor": "\nComments: Ph.D Thesis\n",
    "authors": [
      "Denis Coquenet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15362"
  },
  {
    "id": "arXiv:2209.15392",
    "title": "Improving the Efficiency of Payments Systems Using Quantum Computing",
    "abstract": "Improving the Efficiency of Payments Systems Using Quantum Computing",
    "descriptor": "",
    "authors": [
      "Christopher McMahon",
      "Donald McGillivray",
      "Ajit Desai",
      "Francisco Rivadeneyra",
      "Jean-Paul Lam",
      "Thomas Lo",
      "Danica Marsden",
      "Vladimir Skavysh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Emerging Technologies (cs.ET)",
      "Quantum Algebra (math.QA)"
    ],
    "url": "https://arxiv.org/abs/2209.15392"
  },
  {
    "id": "arXiv:2209.15571",
    "title": "Building Normalizing Flows with Stochastic Interpolants",
    "abstract": "Building Normalizing Flows with Stochastic Interpolants",
    "descriptor": "",
    "authors": [
      "Michael S. Albergo",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.15571"
  },
  {
    "id": "arXiv:2210.01162",
    "title": "Learning Minimally-Violating Continuous Control for Infeasible Linear  Temporal Logic Specifications",
    "abstract": "Learning Minimally-Violating Continuous Control for Infeasible Linear  Temporal Logic Specifications",
    "descriptor": "",
    "authors": [
      "Mingyu Cai",
      "Makai Mann",
      "Zachary Serlin",
      "Kevin Leahy",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01162"
  },
  {
    "id": "arXiv:2210.01438",
    "title": "Complementary consistency semi-supervised learning for 3D left atrial  image segmentation",
    "abstract": "Complementary consistency semi-supervised learning for 3D left atrial  image segmentation",
    "descriptor": "",
    "authors": [
      "Hejun Huang",
      "Zuguo Chen",
      "Chaoyang Chen",
      "Ming Lu",
      "Ying Zou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01438"
  },
  {
    "id": "arXiv:2210.01582",
    "title": "FRIDA: Fisheye Re-Identification Dataset with Annotations",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Mertcan Cokbas",
      "John Bolognino",
      "Janusz Konrad",
      "Prakash Ishwar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01582"
  },
  {
    "id": "arXiv:2210.01689",
    "title": "Vision-based Warning System for Maintenance Personnel on Short-Term  Roadwork Site",
    "abstract": "Vision-based Warning System for Maintenance Personnel on Short-Term  Roadwork Site",
    "descriptor": "",
    "authors": [
      "Xiao Ni",
      "Walpola Layantha Perera",
      "Carsten K\u00fchnel",
      "Christian Vollrath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01689"
  },
  {
    "id": "arXiv:2210.02595",
    "title": "Exploration of A Self-Supervised Speech Model: A Study on Emotional  Corpora",
    "abstract": "Comments: Accepted for SLT 2022",
    "descriptor": "\nComments: Accepted for SLT 2022\n",
    "authors": [
      "Yuanchao Li",
      "Yumnah Mohamied",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.02595"
  },
  {
    "id": "arXiv:2210.02928",
    "title": "MuRAG: Multimodal Retrieval-Augmented Generator for Open Question  Answering over Images and Text",
    "abstract": "Comments: Accepted to EMNLP 2022 main conference",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Wenhu Chen",
      "Hexiang Hu",
      "Xi Chen",
      "Pat Verga",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02928"
  },
  {
    "id": "arXiv:2210.03016",
    "title": "\"A Special Operation\": A Quantitative Approach to Dissecting and  Comparing Different Media Ecosystems' Coverage of the Russo-Ukrainian War",
    "abstract": "Comments: Accepted to ICWSM 2023",
    "descriptor": "\nComments: Accepted to ICWSM 2023\n",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03016"
  },
  {
    "id": "arXiv:2210.03283",
    "title": "Design Amortization for Bayesian Optimal Experimental Design",
    "abstract": "Design Amortization for Bayesian Optimal Experimental Design",
    "descriptor": "",
    "authors": [
      "Noble Kennamer",
      "Steven Walton",
      "Alexander Ihler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.03283"
  },
  {
    "id": "arXiv:2210.03435",
    "title": "IDPL: Intra-subdomain adaptation adversarial learning segmentation  method based on Dynamic Pseudo Labels",
    "abstract": "Comments: Accepted at The 29th International Conference on Neural Information Processing (ICONIP 2022)",
    "descriptor": "\nComments: Accepted at The 29th International Conference on Neural Information Processing (ICONIP 2022)\n",
    "authors": [
      "Xuewei Li",
      "Weilun Zhang",
      "Jie Gao",
      "Xuzhou Fu",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03435"
  },
  {
    "id": "arXiv:2210.04108",
    "title": "Visual Looming from Motion Field and Surface Normals",
    "abstract": "Comments: Includes supplemental material",
    "descriptor": "\nComments: Includes supplemental material\n",
    "authors": [
      "Juan Yepes",
      "Daniel Raviv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04108"
  },
  {
    "id": "arXiv:2210.05148",
    "title": "DiffRoll: Diffusion-based Generative Music Transcription with  Unsupervised Pretraining Capability",
    "abstract": "DiffRoll: Diffusion-based Generative Music Transcription with  Unsupervised Pretraining Capability",
    "descriptor": "",
    "authors": [
      "Kin Wai Cheuk",
      "Ryosuke Sawata",
      "Toshimitsu Uesaka",
      "Naoki Murata",
      "Naoya Takahashi",
      "Shusuke Takahashi",
      "Dorien Herremans",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.05148"
  },
  {
    "id": "arXiv:2210.05261",
    "title": "Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair  Modeling",
    "abstract": "Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair  Modeling",
    "descriptor": "",
    "authors": [
      "Yuanhang Yang",
      "shiyi qi",
      "Cuiyun Gao",
      "Zenglin Xu",
      "Yulan He",
      "Qifan Wang",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.05261"
  },
  {
    "id": "arXiv:2210.06719",
    "title": "Partial Information as Full: Reward Imputation with Sketching in Bandits",
    "abstract": "Comments: Contextual batch bandits",
    "descriptor": "\nComments: Contextual batch bandits\n",
    "authors": [
      "Xiao Zhang",
      "Ninglu Shao",
      "Zihua Si",
      "Jun Xu",
      "Wenhan Wang",
      "Hanjing Su",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06719"
  },
  {
    "id": "arXiv:2210.06820",
    "title": "Personalized Federated Hypernetworks for Privacy Preservation in  Multi-Task Reinforcement Learning",
    "abstract": "Personalized Federated Hypernetworks for Privacy Preservation in  Multi-Task Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Doseok Jang",
      "Larry Yan",
      "Lucas Spangher",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.06820"
  },
  {
    "id": "arXiv:2210.06965",
    "title": "CUF: Continuous Upsampling Filters",
    "abstract": "CUF: Continuous Upsampling Filters",
    "descriptor": "",
    "authors": [
      "Cristina Vasconcelos",
      "Cengiz Oztireli",
      "Mark Matthews",
      "Milad Hashemi",
      "Kevin Swersky",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06965"
  },
  {
    "id": "arXiv:2210.07002",
    "title": "Anonymizing Speech with Generative Adversarial Networks to Preserve  Speaker Privacy",
    "abstract": "Comments: IEEE Spoken Language Technology Workshop 2022",
    "descriptor": "\nComments: IEEE Spoken Language Technology Workshop 2022\n",
    "authors": [
      "Sarina Meyer",
      "Pascal Tilli",
      "Pavel Denisov",
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07002"
  },
  {
    "id": "arXiv:2210.07278",
    "title": "Meta-Uncertainty in Bayesian Model Comparison",
    "abstract": "Meta-Uncertainty in Bayesian Model Comparison",
    "descriptor": "",
    "authors": [
      "Marvin Schmitt",
      "Stefan T. Radev",
      "Paul-Christian B\u00fcrkner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07278"
  },
  {
    "id": "arXiv:2210.07920",
    "title": "MOVE: Unsupervised Movable Object Segmentation and Detection",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Adam Bielski",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07920"
  },
  {
    "id": "arXiv:2210.07978",
    "title": "Improving generalizability of distilled self-supervised speech  processing models under distorted settings",
    "abstract": "Comments: Accepted by IEEE SLT2022",
    "descriptor": "\nComments: Accepted by IEEE SLT2022\n",
    "authors": [
      "Kuan-Po Huang",
      "Yu-Kuan Fu",
      "Tsu-Yuan Hsu",
      "Fabian Ritter Gutierrez",
      "Fan-Lin Wang",
      "Liang-Hsuan Tseng",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07978"
  },
  {
    "id": "arXiv:2210.07983",
    "title": "Trailers12k: Improving Transfer Learning with a Dual Image and Video  Transformer for Multi-label Movie Trailer Genre Classification",
    "abstract": "Trailers12k: Improving Transfer Learning with a Dual Image and Video  Transformer for Multi-label Movie Trailer Genre Classification",
    "descriptor": "",
    "authors": [
      "Ricardo Montalvo-Lezama",
      "Berenice Montalvo-Lezama",
      "Gibran Fuentes-Pineda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07983"
  },
  {
    "id": "arXiv:2210.08209",
    "title": "Large Language Models for Multi-label Propaganda Detection",
    "abstract": "Large Language Models for Multi-label Propaganda Detection",
    "descriptor": "",
    "authors": [
      "Tanmay Chavan",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08209"
  },
  {
    "id": "arXiv:2210.08332",
    "title": "Code Recommendation for Open Source Software Developers",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Yiqiao Jin",
      "Yunsheng Bai",
      "Yanqiao Zhu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08332"
  },
  {
    "id": "arXiv:2210.08465",
    "title": "Character-Centric Story Visualization via Visual Planning and Token  Alignment",
    "abstract": "Comments: accepted by EMNLP2022",
    "descriptor": "\nComments: accepted by EMNLP2022\n",
    "authors": [
      "Hong Chen",
      "Rujun Han",
      "Te-Lin Wu",
      "Hideki Nakayama",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08465"
  },
  {
    "id": "arXiv:2210.08523",
    "title": "Some Languages are More Equal than Others: Probing Deeper into the  Linguistic Disparity in the NLP World",
    "abstract": "Some Languages are More Equal than Others: Probing Deeper into the  Linguistic Disparity in the NLP World",
    "descriptor": "",
    "authors": [
      "Surangika Ranathunga",
      "Nisansa de Silva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08523"
  },
  {
    "id": "arXiv:2210.08994",
    "title": "Knowledge Representation for Conceptual, Motivational, and Affective  Processes in Natural Language Communication",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Seng-Beng Ho",
      "Zhaoxia Wang",
      "Boon-Kiat Quek",
      "Erik Cambria"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08994"
  },
  {
    "id": "arXiv:2210.09292",
    "title": "Efficient Diffusion Models for Vision: A Survey",
    "abstract": "Comments: 14 Pages, 5 Figures (in progress)",
    "descriptor": "\nComments: 14 Pages, 5 Figures (in progress)\n",
    "authors": [
      "Anwaar Ulhaq",
      "Naveed Akhtar",
      "Ganna Pogrebna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09292"
  },
  {
    "id": "arXiv:2210.09420",
    "title": "Differentiable Physics Simulation of Dynamics-Augmented Neural Objects",
    "abstract": "Differentiable Physics Simulation of Dynamics-Augmented Neural Objects",
    "descriptor": "",
    "authors": [
      "Simon Le Cleac'h",
      "Hong-Xing Yu",
      "Michelle Guo",
      "Taylor A. Howell",
      "Ruohan Gao",
      "Jiajun Wu",
      "Zachary Manchester",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09420"
  },
  {
    "id": "arXiv:2210.09477",
    "title": "UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation  Model on a Single Image",
    "abstract": "UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation  Model on a Single Image",
    "descriptor": "",
    "authors": [
      "Dani Valevski",
      "Matan Kalman",
      "Yossi Matias",
      "Yaniv Leviathan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09477"
  },
  {
    "id": "arXiv:2210.09520",
    "title": "Using Language to Extend to Unseen Domains",
    "abstract": "Using Language to Extend to Unseen Domains",
    "descriptor": "",
    "authors": [
      "Lisa Dunlap",
      "Clara Mohri",
      "Devin Guillory",
      "Han Zhang",
      "Trevor Darrell",
      "Joseph E. Gonzalez",
      "Aditi Raghunathan",
      "Anja Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09520"
  },
  {
    "id": "arXiv:2210.09535",
    "title": "Graph Anomaly Detection with Unsupervised GNNs",
    "abstract": "Comments: ICDM 2022 Short Paper Extension",
    "descriptor": "\nComments: ICDM 2022 Short Paper Extension\n",
    "authors": [
      "Lingxiao Zhao",
      "Saurabh Sawlani",
      "Arvind Srinivasan",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09535"
  },
  {
    "id": "arXiv:2210.09706",
    "title": "Privacy Explanations -- A Means to End-User Trust",
    "abstract": "Privacy Explanations -- A Means to End-User Trust",
    "descriptor": "",
    "authors": [
      "Wasja Brunotte",
      "Alexander Specht",
      "Larissa Chazette",
      "Kurt Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09706"
  },
  {
    "id": "arXiv:2210.09837",
    "title": "Deep Scattering Spectrum germaneness to Fault Detection and Diagnosis  for Component-level Prognostics and Health Management (PHM)",
    "abstract": "Comments: need changes",
    "descriptor": "\nComments: need changes\n",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09837"
  },
  {
    "id": "arXiv:2210.09964",
    "title": "Efficient Evaluation of Arbitrary Relational Calculus Queries",
    "abstract": "Comments: processed with pdflatex (instead of latex as the previous version)",
    "descriptor": "\nComments: processed with pdflatex (instead of latex as the previous version)\n",
    "authors": [
      "Martin Raszyk",
      "David Basin",
      "Sr\u0111an Krsti\u0107",
      "Dmitriy Traytel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09964"
  },
  {
    "id": "arXiv:2210.10084",
    "title": "On History-Deterministic One-Counter Nets",
    "abstract": "On History-Deterministic One-Counter Nets",
    "descriptor": "",
    "authors": [
      "Aditya Prakash",
      "K. S. Thejaswini"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.10084"
  },
  {
    "id": "arXiv:2210.10105",
    "title": "ELASTIC: Numerical Reasoning with Adaptive Symbolic Compiler",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Jiaxin Zhang",
      "Yashar Moshfeghi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10105"
  },
  {
    "id": "arXiv:2210.10110",
    "title": "Trixi the Librarian",
    "abstract": "Trixi the Librarian",
    "descriptor": "",
    "authors": [
      "Fabian Wieczorek",
      "Shang-Ching Liu",
      "Bj\u00f6rn Sygo",
      "Mykhailo Koshil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10110"
  },
  {
    "id": "arXiv:2210.10133",
    "title": "STAMP: Lightweight TEE-Assisted MPC for Efficient Privacy-Preserving  Machine Learning",
    "abstract": "Comments: USENIX'23 submitted",
    "descriptor": "\nComments: USENIX'23 submitted\n",
    "authors": [
      "Pengzhi Huang",
      "Thang Hoang",
      "Yueying Li",
      "Elaine Shi",
      "G. Edward Suh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.10133"
  },
  {
    "id": "arXiv:2210.10401",
    "title": "Asynchronous RIS-assisted Localization: A Comprehensive Analysis of  Fundamental Limits",
    "abstract": "Asynchronous RIS-assisted Localization: A Comprehensive Analysis of  Fundamental Limits",
    "descriptor": "",
    "authors": [
      "Ziyi Gong",
      "Liang Wu",
      "Zaichen Zhang",
      "Jian Dang",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10401"
  },
  {
    "id": "arXiv:2210.10411",
    "title": "Shape calculus for fitted and unfitted discretizations: domain  transformations vs. boundary-face dilations",
    "abstract": "Shape calculus for fitted and unfitted discretizations: domain  transformations vs. boundary-face dilations",
    "descriptor": "",
    "authors": [
      "Martin Berggren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.10411"
  },
  {
    "id": "arXiv:2210.10414",
    "title": "High-Resolution Depth Estimation for 360-degree Panoramas through  Perspective and Panoramic Depth Images Registration",
    "abstract": "Comments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023, to appear",
    "descriptor": "\nComments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023, to appear\n",
    "authors": [
      "Chi-Han Peng",
      "Jiayao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10414"
  },
  {
    "id": "arXiv:2210.10436",
    "title": "LightEA: A Scalable, Robust, and Interpretable Entity Alignment  Framework via Three-view Label Propagation",
    "abstract": "Comments: 15 pages; Accepted by EMNLP2022 (Main Conf)",
    "descriptor": "\nComments: 15 pages; Accepted by EMNLP2022 (Main Conf)\n",
    "authors": [
      "Xin Mao",
      "Wenting Wang",
      "Yuanbin Wu",
      "Man Lan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10436"
  },
  {
    "id": "arXiv:2210.10488",
    "title": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "abstract": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "descriptor": "",
    "authors": [
      "Adaku Uchendu",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10488"
  },
  {
    "id": "arXiv:2210.10629",
    "title": "Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender  Systems",
    "abstract": "Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender  Systems",
    "descriptor": "",
    "authors": [
      "Guanghu Yuan",
      "Fajie Yuan",
      "Yudong Li",
      "Beibei Kong",
      "Shujie Li",
      "Lei Chen",
      "Min Yang",
      "Chenyun YU",
      "Bo Hu",
      "Zang Li",
      "Yu Xu",
      "Xiaohu Qie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.10629"
  },
  {
    "id": "arXiv:2210.10662",
    "title": "Towards Practical Explainability with Cluster Descriptors",
    "abstract": "Towards Practical Explainability with Cluster Descriptors",
    "descriptor": "",
    "authors": [
      "Xiaoyuan Liu",
      "Ilya Tyagin",
      "Hayato Ushijima-Mwesigwa",
      "Indradeep Ghosh",
      "Ilya Safro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10662"
  },
  {
    "id": "arXiv:2210.10692",
    "title": "Separating Grains from the Chaff: Using Data Filtering to Improve  Multilingual Translation for Low-Resourced African Languages",
    "abstract": "Comments: Accepted at the Seventh Conference on Machine Translation (WMT22)",
    "descriptor": "\nComments: Accepted at the Seventh Conference on Machine Translation (WMT22)\n",
    "authors": [
      "Idris Abdulmumin",
      "Michael Beukman",
      "Jesujoba O. Alabi",
      "Chris Emezue",
      "Everlyn Asiko",
      "Tosin Adewumi",
      "Shamsuddeen Hassan Muhammad",
      "Mofetoluwa Adeyemi",
      "Oreen Yousuf",
      "Sahib Singh",
      "Tajuddeen Rabiu Gwadabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10692"
  },
  {
    "id": "arXiv:2210.10729",
    "title": "Ruminations on Matrix Convexity and the Strong Subadditivity of Quantum  Entropy",
    "abstract": "Comments: 12 pages, no figures, fixing a typo of version 1, where \"self adjoint\" was omitted in the description of Q in Prop. 1.1",
    "descriptor": "\nComments: 12 pages, no figures, fixing a typo of version 1, where \"self adjoint\" was omitted in the description of Q in Prop. 1.1\n",
    "authors": [
      "Michael Aizenman",
      "Giorgio Cipolloni"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10729"
  }
]
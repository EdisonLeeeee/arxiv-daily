[
  {
    "id": "arXiv:2210.08003",
    "title": "Hierarchical Decentralized Deep Reinforcement Learning Architecture for  a Simulated Four-Legged Agent",
    "abstract": "Legged locomotion is widespread in nature and has inspired the design of\ncurrent robots. The controller of these legged robots is often realized as one\ncentralized instance. However, in nature, control of movement happens in a\nhierarchical and decentralized fashion. Introducing these biological design\nprinciples into robotic control systems has motivated this work. We tackle the\nquestion whether decentralized and hierarchical control is beneficial for\nlegged robots and present a novel decentral, hierarchical architecture to\ncontrol a simulated legged agent. Three different tasks varying in complexity\nare designed to benchmark five architectures (centralized, decentralized,\nhierarchical and two different combinations of hierarchical decentralized\narchitectures). The results demonstrate that decentralizing the different\nlevels of the hierarchical architectures facilitates learning of the agent,\nensures more energy efficient movements as well as robustness towards new\nunseen environments. Furthermore, this comparison sheds light on the importance\nof modularity in hierarchical architectures to solve complex goal-directed\ntasks. We provide an open-source code implementation of our architecture\n(https://github.com/wzaielamri/hddrl).",
    "descriptor": "\nComments: Conference paper (LOD 2022), 15 pages, 8 figures, 4 tables\n",
    "authors": [
      "W. Zai El Amri",
      "L. Hermes",
      "M. Schilling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08003"
  },
  {
    "id": "arXiv:2210.08005",
    "title": "A MIP-Based Approach for Multi-Robot Geometric Task-and-Motion Planning",
    "abstract": "We address multi-robot geometric task-and-motion planning (MR-GTAMP) problems\nin synchronous, monotone setups. The goal of the MR-GTAMP problem is to move\nobjects with multiple robots to goal regions in the presence of other movable\nobjects. To perform the tasks successfully and effectively, the robots have to\nadopt intelligent collaboration strategies, i.e., decide which robot should\nmove which objects to which positions, and perform collaborative actions, such\nas handovers. To endow robots with these collaboration capabilities, we propose\nto first collect occlusion and reachability information for each robot as well\nas information about whether two robots can perform a handover action by\ncalling motion-planning algorithms. We then propose a method that uses the\ncollected information to build a graph structure which captures the precedence\nof the manipulations of different objects and supports the implementation of a\nmixed-integer program to guide the search for highly effective collaborative\ntask-and-motion plans. The search process for collaborative task-and-motion\nplans is based on a Monte-Carlo Tree Search (MCTS) exploration strategy to\nachieve exploration-exploitation balance. We evaluate our framework in two\nchallenging GTAMP domains and show that it can generate high-quality\ntask-and-motion plans with respect to the planning time, the resulting plan\nlength and the number of objects moved compared to two state-of-the-art\nbaselines.",
    "descriptor": "\nComments: 9 pages, 4 figures, accepted in The 18th IEEE International Conference on Automation Science and Engineering (CASE), 2022\n",
    "authors": [
      "Hejia Zhang",
      "Shao-Hung Chan",
      "Jie Zhong",
      "Jiaoyang Li",
      "Sven Koenig",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08005"
  },
  {
    "id": "arXiv:2210.08006",
    "title": "Failure Analysis of Big Cloud Service Providers Prior to and During  Covid-19 Period",
    "abstract": "Cloud services are important for societal function such as healthcare,\ncommerce, entertainment and education. Cloud can provide a variety of features\nsuch as increased collaboration and inexpensive computing. Failures are\nunavoidable in cloud services due to the large size and complexity, resulting\nin decreased reliability and efficiency. For example, due to bugs, many\nhigh-severity failures have been occurring in cloud infrastructure of popular\nproviders, causing outages of several hours and the unrecoverable loss of user\ndata. There are prior studies about cloud failure analyses are limited and use\nsources such as news articles. However, a detailed cloud failure focused study\nis required that provides analyses for cloud failure data gathered directly\nfrom the vendors. Furthermore, the Covid-19 cloud failures should be studied as\ncloud services played a major role throughout the Covid-19 period, as\nindividuals relied on cloud services for activities such as working from home.\nA program can be made for this task. As a result, we will be able to better\nunderstand and mitigate cloud failures to reduce the effect of cloud failures.",
    "descriptor": "\nComments: Undergraduate project report, advisors Alexandru Iosup and Sacheendra Talluri\n",
    "authors": [
      "Muhammad Ahsan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08006"
  },
  {
    "id": "arXiv:2210.08007",
    "title": "Knowledge acquisition via interactive Distributed Cognitive skill  Modules",
    "abstract": "The human's cognitive capacity for problem solving is always limited to\nhis/her educational background, skills, experiences, etc. Hence, it is often\ninsufficient to bring solution to extraordinary problems especially when there\nis a time restriction. Nowadays this sort of personal cognitive limitations are\novercome at some extend by the computational utilities (e.g. program packages,\ninternet, etc.) where each one provides a specific background skill to the\nindividual to solve a particular problem. Nevertheless these models are all\nbased on already available conventional tools or knowledge and unable to solve\nspontaneous unique problems, except human's procedural cognitive skills. But\nunfortunately such low-level skills can not be modelled and stored in a\nconventional way like classical models and knowledge. This work aims to\nintroduce an early stage of a modular approach to procedural skill acquisition\nand storage via distributed cognitive skill modules which provide unique\nopportunity to extend the limits of its exploitation.",
    "descriptor": "",
    "authors": [
      "Ahmet Orun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08007"
  },
  {
    "id": "arXiv:2210.08008",
    "title": "Inductive Logical Query Answering in Knowledge Graphs",
    "abstract": "Formulating and answering logical queries is a standard communication\ninterface for knowledge graphs (KGs). Alleviating the notorious incompleteness\nof real-world KGs, neural methods achieved impressive results in link\nprediction and complex query answering tasks by learning representations of\nentities, relations, and queries. Still, most existing query answering methods\nrely on transductive entity embeddings and cannot generalize to KGs containing\nnew entities without retraining the entity embeddings. In this work, we study\nthe inductive query answering task where inference is performed on a graph\ncontaining new entities with queries over both seen and unseen entities. To\nthis end, we devise two mechanisms leveraging inductive node and relational\nstructure representations powered by graph neural networks (GNNs).\nExperimentally, we show that inductive models are able to perform logical\nreasoning at inference time over unseen nodes generalizing to graphs up to 500%\nlarger than training ones. Exploring the efficiency--effectiveness trade-off,\nwe find the inductive relational structure representation method generally\nachieves higher performance, while the inductive node representation method is\nable to answer complex queries in the inference-only regime without any\ntraining on queries and scales to graphs of millions of nodes. Code is\navailable at https://github.com/DeepGraphLearning/InductiveQE.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Mikhail Galkin",
      "Zhaocheng Zhu",
      "Hongyu Ren",
      "Jian Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08008"
  },
  {
    "id": "arXiv:2210.08009",
    "title": "Trajectory Prediction for Vehicle Conflict Identification at  Intersections Using Sequence-to-Sequence Recurrent Neural Networks",
    "abstract": "Surrogate safety measures in the form of conflict indicators are\nindispensable components of the proactive traffic safety toolbox. Conflict\nindicators can be classified into past-trajectory-based conflicts and\npredicted-trajectory-based conflicts. While the calculation of the former class\nof conflicts is deterministic and unambiguous, the latter category is computed\nusing predicted vehicle trajectories and is thus more stochastic. Consequently,\nthe accuracy of prediction-based conflicts is contingent on the accuracy of the\nutilized trajectory prediction algorithm. Trajectory prediction can be a\nchallenging task, particularly at intersections where vehicle maneuvers are\ndiverse. Furthermore, due to limitations relating to the road user trajectory\nextraction pipelines, accurate geometric representation of vehicles during\nconflict analysis is a challenging task. Misrepresented geometries distort the\nreal distances between vehicles under observation. In this research, a\nprediction-based conflict identification methodology was proposed. A\nsequence-to-sequence Recurrent Neural Network was developed to sequentially\npredict future vehicle trajectories for up to 3 seconds ahead. Furthermore, the\nproposed network was trained using the CitySim Dataset to forecast both future\nvehicle positions and headings to facilitate the prediction of future bounding\nboxes, thus maintaining accurate vehicle geometric representations. It was\nexperimentally determined that the proposed method outperformed frequently used\ntrajectory prediction models for conflict analysis at intersections. A\ncomparison between Time-to-Collision (TTC) conflict identification using\nvehicle bounding boxes versus the commonly used vehicle center points for\ngeometric representation was conducted. Compared to the bounding box method,\nthe center point approach often failed to identify TTC conflicts or\nunderestimated their severity.",
    "descriptor": "",
    "authors": [
      "Amr Abdelraouf",
      "Mohamed Abdel-Aty",
      "Zijin Wang",
      "Ou Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08009"
  },
  {
    "id": "arXiv:2210.08011",
    "title": "Autoencoder based Anomaly Detection and Explained Fault Localization in  Industrial Cooling Systems",
    "abstract": "Anomaly detection in large industrial cooling systems is very challenging due\nto the high data dimensionality, inconsistent sensor recordings, and lack of\nlabels. The state of the art for automated anomaly detection in these systems\ntypically relies on expert knowledge and thresholds. However, data is viewed\nisolated and complex, multivariate relationships are neglected. In this work,\nwe present an autoencoder based end-to-end workflow for anomaly detection\nsuitable for multivariate time series data in large industrial cooling systems,\nincluding explained fault localization and root cause analysis based on expert\nknowledge. We identify system failures using a threshold on the total\nreconstruction error (autoencoder reconstruction error including all sensor\nsignals). For fault localization, we compute the individual reconstruction\nerror (autoencoder reconstruction error for each sensor signal) allowing us to\nidentify the signals that contribute most to the total reconstruction error.\nExpert knowledge is provided via look-up table enabling root-cause analysis and\nassignment to the affected subsystem. We demonstrated our findings in a cooling\nsystem unit including 34 sensors over a 8-months time period using 4-fold cross\nvalidation approaches and automatically created labels based on thresholds\nprovided by domain experts. Using 4-fold cross validation, we reached a\nF1-score of 0.56, whereas the autoencoder results showed a higher consistency\nscore (CS of 0.92) compared to the automatically created labels (CS of 0.62) --\nindicating that the anomaly is recognized in a very stable manner. The main\nanomaly was found by the autoencoder and automatically created labels and was\nalso recorded in the log files. Further, the explained fault localization\nhighlighted the most affected component for the main anomaly in a very\nconsistent manner.",
    "descriptor": "\nComments: accepted at phme 2022\n",
    "authors": [
      "Stephanie Holly",
      "Robin Heel",
      "Denis Katic",
      "Leopold Schoeffl",
      "Andreas Stiftinger",
      "Peter Holzner",
      "Thomas Kaufmann",
      "Bernhard Haslhofer",
      "Daniel Schall",
      "Clemens Heitzinger",
      "Jana Kemnitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08011"
  },
  {
    "id": "arXiv:2210.08012",
    "title": "A geospatial bounded confidence model including mega-influencers with an  application to Covid-19 vaccine hesitancy",
    "abstract": "We introduce a geospatial bounded confidence model with mega-influencers,\ninspired by Hegselmann and Krause. The inclusion of geography gives rise to\nlarge-scale geospatial patterns evolving out of random initial data; that is,\nspatial clusters of like-minded agents emerge regardless of initialization.\nMega-influencers and stochasticity amplify this effect, and soften local\nconsensus. As an application, we consider national views on Covid-19 vaccines.\nFor a certain set of parameters, our model yields results comparable to real\nsurvey results on vaccine hesitancy from late 2020.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.00630\n",
    "authors": [
      "Anna Haensch",
      "Natasa Dragovic",
      "Christoph B\u00f6rgers",
      "Bruce Boghosian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08012"
  },
  {
    "id": "arXiv:2210.08013",
    "title": "On the Relationship Between Variational Inference and Auto-Associative  Memory",
    "abstract": "In this article, we propose a variational inference formulation of\nauto-associative memories, allowing us to combine perceptual inference and\nmemory retrieval into the same mathematical framework. In this formulation, the\nprior probability distribution onto latent representations is made memory\ndependent, thus pulling the inference process towards previously stored\nrepresentations. We then study how different neural network approaches to\nvariational inference can be applied in this framework. We compare methods\nrelying on amortized inference such as Variational Auto Encoders and methods\nrelying on iterative inference such as Predictive Coding and suggest combining\nboth approaches to design new auto-associative memory models. We evaluate the\nobtained algorithms on the CIFAR10 and CLEVR image datasets and compare them\nwith other associative memory models such as Hopfield Networks, End-to-End\nMemory Networks and Neural Turing Machines.",
    "descriptor": "",
    "authors": [
      "Louis Annabi",
      "Alexandre Pitti",
      "Mathias Quoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08013"
  },
  {
    "id": "arXiv:2210.08015",
    "title": "AR Training App for Energy Optimal Programming of Cobots",
    "abstract": "Worldwide most factories aim for low-cost and fast production ignoring\nresources and energy consumption. But, high revenues have been accompanied by\nenvironmental degradation. The United Nations reacted to the ecological problem\nand proposed the Sustainable Development Goals, and one of them is Sustainable\nProduction (Goal 12). In addition, the participation of lightweight robots,\nsuch as collaborative robots, in modern industrial production is increasing.\nThe energy consumption of a single collaborative robot is not significant,\nhowever, the consumption of more and more cobots worldwide is representative.\nConsequently, our research focuses on strategies to reduce the energy\nconsumption of lightweight robots aiming for sustainable production. Firstly,\nthe energy consumption of the lightweight robot UR10e is assessed by a set of\nexperiments. We analyzed the results of the experiments to describe the\nrelationship between the energy consumption and the evaluation parameters, thus\npaving the way to optimization strategies. Next, we propose four strategies to\nreduce energy consumption: 1) optimal standby position, 2) optimal robot\ninstruction, 3) optimal motion time, and 4) reduction of dissipative energy.\nThe results show that cobots potentially reduce from 3\\% up to 37\\% of their\nenergy consumption, depending on the optimization technique. To disseminate the\nresults of our research, we developed an AR game in which the users learn how\nto energy-efficiently program cobots.",
    "descriptor": "",
    "authors": [
      "Juan Heredia",
      "Christian Schlette",
      "Mikkel Baun Kj\u00e6rgaard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08015"
  },
  {
    "id": "arXiv:2210.08031",
    "title": "Neural Attentive Circuits",
    "abstract": "Recent work has seen the development of general purpose neural architectures\nthat can be trained to perform tasks across diverse data modalities. General\npurpose models typically make few assumptions about the underlying\ndata-structure and are known to perform well in the large-data regime. At the\nsame time, there has been growing interest in modular neural architectures that\nrepresent the data using sparsely interacting modules. These models can be more\nrobust out-of-distribution, computationally efficient, and capable of\nsample-efficient adaptation to new data. However, they tend to make\ndomain-specific assumptions about the data, and present challenges in how\nmodule behavior (i.e., parameterization) and connectivity (i.e., their layout)\ncan be jointly learned. In this work, we introduce a general purpose, yet\nmodular neural architecture called Neural Attentive Circuits (NACs) that\njointly learns the parameterization and a sparse connectivity of neural modules\nwithout using domain knowledge. NACs are best understood as the combination of\ntwo systems that are jointly trained end-to-end: one that determines the module\nconfiguration and the other that executes it on an input. We demonstrate\nqualitatively that NACs learn diverse and meaningful module configurations on\nthe NLVR2 dataset without additional supervision. Quantitatively, we show that\nby incorporating modularity in this way, NACs improve upon a strong non-modular\nbaseline in terms of low-shot adaptation on CIFAR and CUBs dataset by about\n10%, and OOD robustness on Tiny ImageNet-R by about 2.5%. Further, we find that\nNACs can achieve an 8x speedup at inference time while losing less than 3%\nperformance. Finally, we find NACs to yield competitive results on diverse data\nmodalities spanning point-cloud classification, symbolic processing and\ntext-classification from ASCII bytes, thereby confirming its general purpose\nnature.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Nasim Rahaman",
      "Martin Weiss",
      "Francesco Locatello",
      "Chris Pal",
      "Yoshua Bengio",
      "Bernhard Sch\u00f6lkopf",
      "Erran Li",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08031"
  },
  {
    "id": "arXiv:2210.08034",
    "title": "Empirical Network Structure of Malicious Programs",
    "abstract": "A modern binary executable is a composition of various networks. Control flow\ngraphs are commonly used to represent an executable program in labeled datasets\nused for classification tasks. Control flow and term representations are widely\nadopted, but provide only a partial view of program semantics. This study is an\nempirical analysis of the networks composing malicious binaries in order to\nprovide a complete representation of the structural properties of a program.\nThis is accomplished by the measurement of structural properties of program\nnetworks in a malicious binary executable dataset. We demonstrate the presence\nof Scale-Free properties of network structure for program data dependency and\ncontrol flow graphs, and show that data dependency graphs also have Small-World\nstructural properties. We show that program data dependency graphs have a\ndegree correlation that is structurally disassortative, and that control flow\ngraphs have a neutral degree assortativity, indicating the use of random graphs\nto model the structural properties of program control flow graphs would show\nincreased accuracy. By providing an increase in feature resolution within\nlabeled datasets of executable programs we provide a quantitative basis to\ninterpret the results of classifiers trained on CFG graph features. An increase\nin feature resolution allows for the structural properties of program classes\nto be analyzed for patterns as well as their component parts. By capturing a\ncomplete picture of program graphs we can enable theoretical solutions for the\nmapping a program's operational semantics to its structure.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "John Musgrave",
      "Alina Campan",
      "Temesguen Messay-Kebede",
      "David Kapp",
      "Anca Ralescu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08034"
  },
  {
    "id": "arXiv:2210.08036",
    "title": "Meta Transferring for Deblurring",
    "abstract": "Most previous deblurring methods were built with a generic model trained on\nblurred images and their sharp counterparts. However, these approaches might\nhave sub-optimal deblurring results due to the domain gap between the training\nand test sets. This paper proposes a reblur-deblur meta-transferring scheme to\nrealize test-time adaptation without using ground truth for dynamic scene\ndeblurring. Since the ground truth is usually unavailable at inference time in\na real-world scenario, we leverage the blurred input video to find and use\nrelatively sharp patches as the pseudo ground truth. Furthermore, we propose a\nreblurring model to extract the homogenous blur from the blurred input and\ntransfer it to the pseudo-sharps to obtain the corresponding pseudo-blurred\npatches for meta-learning and test-time adaptation with only a few gradient\nupdates. Extensive experimental results show that our reblur-deblur\nmeta-learning scheme can improve state-of-the-art deblurring models on the DVD,\nREDS, and RealBlur benchmark datasets.",
    "descriptor": "\nComments: Accepted at BMVC 2022\n",
    "authors": [
      "Po-Sheng Liu",
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Chung-Chi Tsai",
      "Chia-Wen Lin",
      "Yen-Yu Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08036"
  },
  {
    "id": "arXiv:2210.08041",
    "title": "Region2Vec: Community Detection on Spatial Networks Using Graph  Embedding with Node Attributes and Spatial Interactions",
    "abstract": "Community Detection algorithms are used to detect densely connected\ncomponents in complex networks and reveal underlying relationships among\ncomponents. As a special type of networks, spatial networks are usually\ngenerated by the connections among geographic regions. Identifying the spatial\nnetwork communities can help reveal the spatial interaction patterns,\nunderstand the hidden regional structures and support regional development\ndecision-making. Given the recent development of Graph Convolutional Networks\n(GCN) and its powerful performance in identifying multi-scale spatial\ninteractions, we proposed an unsupervised GCN-based community detection method\n\"region2vec\" on spatial networks. Our method first generates node embeddings\nfor regions that share common attributes and have intense spatial interactions,\nand then applies clustering algorithms to detect communities based on their\nembedding similarity and spatial adjacency. Experimental results show that\nwhile existing methods trade off either attribute similarities or spatial\ninteractions for one another, \"region2vec\" maintains a great balance between\nboth and performs the best when one wants to maximize both attribute\nsimilarities and spatial interactions within communities.",
    "descriptor": "\nComments: 4 pages, 1 page\n",
    "authors": [
      "Yunlei Liang",
      "Jiawei Zhu",
      "Wen Ye",
      "Song Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08041"
  },
  {
    "id": "arXiv:2210.08042",
    "title": "Measuring Network Resilience via Geospatial Knowledge Graph: a Case  Study of the US Multi-Commodity Flow Network",
    "abstract": "Quantifying the resilience in the food system is important for food security\nissues. In this work, we present a geospatial knowledge graph (GeoKG)-based\nmethod for measuring the resilience of a multi-commodity flow network.\nSpecifically, we develop a CFS-GeoKG ontology to describe geospatial semantics\nof a multi-commodity flow network comprehensively, and design resilience\nmetrics that measure the node-level and network-level dependence of\nsingle-sourcing, distant, or non-adjacent suppliers/customers in food supply\nchains. We conduct a case study of the US state-level agricultural\nmulti-commodity flow network with hierarchical commodity types. The results\nindicate that, by leveraging GeoKG, our method supports measuring both\nnode-level and network-level resilience across space and over time and also\nhelps discover concentration patterns of agricultural resources in the spatial\nnetwork at different geographic scales.",
    "descriptor": "\nComments: 9 pages, 5 figures, GeoKG'22\n",
    "authors": [
      "Jinmeng Rao",
      "Song Gao",
      "Michelle Miller",
      "Alfonso Morales"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08042"
  },
  {
    "id": "arXiv:2210.08046",
    "title": "Differentiable Hybrid Traffic Simulation",
    "abstract": "We introduce a novel differentiable hybrid traffic simulator, which simulates\ntraffic using a hybrid model of both macroscopic and microscopic models and can\nbe directly integrated into a neural network for traffic control and flow\noptimization. This is the first differentiable traffic simulator for\nmacroscopic and hybrid models that can compute gradients for traffic states\nacross time steps and inhomogeneous lanes. To compute the gradient flow between\ntwo types of traffic models in a hybrid framework, we present a novel\nintermediate conversion component that bridges the lanes in a differentiable\nmanner as well. We also show that we can use analytical gradients to accelerate\nthe overall process and enhance scalability. Thanks to these gradients, our\nsimulator can provide more efficient and scalable solutions for complex\nlearning and control problems posed in traffic engineering than other existing\nalgorithms. Refer to https://sites.google.com/umd.edu/diff-hybrid-traffic-sim\nfor our project.",
    "descriptor": "\nComments: 13 pages, Siggraph Asia 2022 Journal Paper\n",
    "authors": [
      "Sanghyun Son",
      "Yi-Ling Qiao",
      "Jason Sewall",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.08046"
  },
  {
    "id": "arXiv:2210.08047",
    "title": "Injecting Domain Knowledge from Empirical Interatomic Potentials to  Neural Networks for Predicting Material Properties",
    "abstract": "For decades, atomistic modeling has played a crucial role in predicting the\nbehavior of materials in numerous fields ranging from nanotechnology to drug\ndiscovery. The most accurate methods in this domain are rooted in\nfirst-principles quantum mechanical calculations such as density functional\ntheory (DFT). Because these methods have remained computationally prohibitive,\npractitioners have traditionally focused on defining physically motivated\nclosed-form expressions known as empirical interatomic potentials (EIPs) that\napproximately model the interactions between atoms in materials. In recent\nyears, neural network (NN)-based potentials trained on quantum mechanical\n(DFT-labeled) data have emerged as a more accurate alternative to conventional\nEIPs. However, the generalizability of these models relies heavily on the\namount of labeled training data, which is often still insufficient to generate\nmodels suitable for general-purpose applications. In this paper, we propose two\ngeneric strategies that take advantage of unlabeled training instances to\ninject domain knowledge from conventional EIPs to NNs in order to increase\ntheir generalizability. The first strategy, based on weakly supervised\nlearning, trains an auxiliary classifier on EIPs and selects the\nbest-performing EIP to generate energies to supplement the ground-truth DFT\nenergies in training the NN. The second strategy, based on transfer learning,\nfirst pretrains the NN on a large set of easily obtainable EIP energies, and\nthen fine-tunes it on ground-truth DFT energies. Experimental results on three\nbenchmark datasets demonstrate that the first strategy improves baseline NN\nperformance by 5% to 51% while the second improves baseline performance by up\nto 55%. Combining them further boosts performance.",
    "descriptor": "\nComments: To appear as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Zeren Shui",
      "Daniel S. Karls",
      "Mingjian Wen",
      "Ilia A. Nikiforov",
      "Ellad B. Tadmor",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08047"
  },
  {
    "id": "arXiv:2210.08050",
    "title": "Multi-trainer Interactive Reinforcement Learning System",
    "abstract": "Interactive reinforcement learning can effectively facilitate the agent\ntraining via human feedback. However, such methods often require the human\nteacher to know what is the correct action that the agent should take. In other\nwords, if the human teacher is not always reliable, then it will not be\nconsistently able to guide the agent through its training. In this paper, we\npropose a more effective interactive reinforcement learning system by\nintroducing multiple trainers, namely Multi-Trainer Interactive Reinforcement\nLearning (MTIRL), which could aggregate the binary feedback from multiple\nnon-perfect trainers into a more reliable reward for an agent training in a\nreward-sparse environment. In particular, our trainer feedback aggregation\nexperiments show that our aggregation method has the best accuracy when\ncompared with the majority voting, the weighted voting, and the Bayesian\nmethod. Finally, we conduct a grid-world experiment to show that the policy\ntrained by the MTIRL with the review model is closer to the optimal policy than\nthat without a review model.",
    "descriptor": "",
    "authors": [
      "Zhaori Guo",
      "Timothy J. Norman",
      "Enrico H. Gerding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08050"
  },
  {
    "id": "arXiv:2210.08054",
    "title": "Semi-supervised Body Parsing and Pose Estimation for Enhancing Infant  General Movement Assessment",
    "abstract": "General movement assessment (GMA) of infant movement videos (IMVs) is an\neffective method for early detection of cerebral palsy (CP) in infants. We\ndemonstrate in this paper that end-to-end trainable neural networks for image\nsequence recognition can be applied to achieve good results in GMA, and more\nimportantly, augmenting raw video with infant body parsing and pose estimation\ninformation can significantly improve performance. To solve the problem of\nefficiently utilizing partially labeled IMVs for body parsing, we propose a\nsemi-supervised model, termed SiamParseNet (SPN), which consists of two\nbranches, one for intra-frame body parts segmentation and another for\ninter-frame label propagation. During training, the two branches are jointly\ntrained by alternating between using input pairs of only labeled frames and\ninput of both labeled and unlabeled frames. We also investigate training data\naugmentation by proposing a factorized video generative adversarial network\n(FVGAN) to synthesize novel labeled frames for training. When testing, we\nemploy a multi-source inference mechanism, where the final result for a test\nframe is either obtained via the segmentation branch or via propagation from a\nnearby key frame. We conduct extensive experiments for body parsing using SPN\non two infant movement video datasets, where SPN coupled with FVGAN achieves\nstate-of-the-art performance. We further demonstrate that SPN can be easily\nadapted to the infant pose estimation task with superior performance. Last but\nnot least, we explore the clinical application of our method for GMA. We\ncollected a new clinical IMV dataset with GMA annotations, and our experiments\nshow that SPN models for body parsing and pose estimation trained on the first\ntwo datasets generalize well to the new clinical dataset and their results can\nsignificantly boost the CRNN-based GMA prediction performance.",
    "descriptor": "\nComments: Elsevier Medical Image Analysis 2022\n",
    "authors": [
      "Haomiao Ni",
      "Yuan Xue",
      "Liya Ma",
      "Qian Zhang",
      "Xiaoye Li",
      "Xiaolei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08054"
  },
  {
    "id": "arXiv:2210.08057",
    "title": "Pishgu: Universal Path Prediction Architecture through Graph Isomorphism  and Attentive Convolution",
    "abstract": "Path prediction is an essential task for several real-world real-time\napplications, from autonomous driving and video surveillance to environmental\nmonitoring. Most existing approaches are computation-intensive and only target\na narrow domain (e.g., a specific point of view for a particular subject).\nHowever, many real-time applications demand a universal path predictor that can\nwork across different subjects (vehicles, pedestrians), perspectives\n(bird's-eye, high-angle), and scenes (sidewalk, highway). This article proposes\nPishgu, a universal graph isomorphism approach for attentive path prediction\nthat accounts for environmental challenges. Pishgu captures the\ninter-dependencies within the subjects in each frame by taking advantage of\nGraph Isomorphism Networks. In addition, an attention module is adopted to\nrepresent the intrinsic relations of the subjects of interest with their\nsurroundings. We evaluate the adaptability of our approach to multiple publicly\navailable vehicle (bird's-eye view) and pedestrian (bird's-eye and high-angle\nview) path prediction datasets. Pishgu's universal solution outperforms\nexisting domain-focused methods by producing state-of-the-art results for\nvehicle bird's-eye view by 42% and 61% and pedestrian high-angle views by 23%\nand 22% in terms of ADE and FDE, respectively. Moreover, we analyze the\ndomain-specific details for various datasets to understand their effect on path\nprediction and model interpretation. Although our model is a single solution\nfor path prediction problems and defines a new standard in multiple domains, it\nstill has a comparable complexity to state-of-the-art models, which makes it\nsuitable for real-world application. We also report the latency and throughput\nfor all three domains on multiple embedded processors.",
    "descriptor": "",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Armin Danesh Pazho",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08057"
  },
  {
    "id": "arXiv:2210.08059",
    "title": "Word Clouds in the Wild",
    "abstract": "Word clouds are frequently used to analyze and communicate text data in many\ndomains. In order to help guide research on improving the legibility of word\nclouds, we have conducted a survey of their usage in Digital Humanities\nacademia and journalism. Using a modified grounded theory approach, we sought\nto identify the most common purposes for which word clouds were employed and\nthe most common visual encodings they contained. Our findings indicate that\nfont size, color, and word placement dominate as the primary data-encoding\nchannels, as we hypothesized. Perhaps more surprisingly, we found that asking\nviewers to perform analytical tasks with word clouds was relatively common,\nespecially in DH sources. This suggests that research into the interactions of\nthese visual encoding channels (particularly in regards to legibility) is\nwarranted.",
    "descriptor": "",
    "authors": [
      "Rebecca M. M. Hicke",
      "Maanya Goenka",
      "Eric Alexander"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08059"
  },
  {
    "id": "arXiv:2210.08060",
    "title": "Learning Skills from Demonstrations: A Trend from Motion Primitives to  Experience Abstraction",
    "abstract": "The uses of robots are changing from static environments in factories to\nencompass novel concepts such as Human-Robot Collaboration in unstructured\nsettings. Pre-programming all the functionalities for robots becomes\nimpractical, and hence, robots need to learn how to react to new events\nautonomously, just like humans. However, humans, unlike machines, are naturally\nskilled in responding to unexpected circumstances based on either experiences\nor observations. Hence, embedding such anthropoid behaviours into robots\nentails the development of neuro-cognitive models that emulate motor skills\nunder a robot learning paradigm. Effective encoding of these skills is bound to\nthe proper choice of tools and techniques. This paper studies different motion\nand behaviour learning methods ranging from Movement Primitives (MP) to\nExperience Abstraction (EA), applied to different robotic tasks. These methods\nare scrutinized and then experimentally benchmarked by reconstructing a\nstandard pick-n-place task. Apart from providing a standard guideline for the\nselection of strategies and algorithms, this paper aims to draw a perspectives\non their possible extensions and improvements",
    "descriptor": "\nComments: Under Review at IEEE TCDS for future Publication\n",
    "authors": [
      "Mehrdad Tavassoli",
      "Sunny Katyara",
      "Maria Pozzi",
      "Nikhil Deshpande",
      "Darwin G. Caldwell",
      "Domenico Prattichizzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08060"
  },
  {
    "id": "arXiv:2210.08061",
    "title": "Motion Inspired Unsupervised Perception and Prediction in Autonomous  Driving",
    "abstract": "Learning-based perception and prediction modules in modern autonomous driving\nsystems typically rely on expensive human annotation and are designed to\nperceive only a handful of predefined object categories. This closed-set\nparadigm is insufficient for the safety-critical autonomous driving task, where\nthe autonomous vehicle needs to process arbitrarily many types of traffic\nparticipants and their motion behaviors in a highly dynamic world. To address\nthis difficulty, this paper pioneers a novel and challenging direction, i.e.,\ntraining perception and prediction models to understand open-set moving\nobjects, with no human supervision. Our proposed framework uses self-learned\nflow to trigger an automated meta labeling pipeline to achieve automatic\nsupervision. 3D detection experiments on the Waymo Open Dataset show that our\nmethod significantly outperforms classical unsupervised approaches and is even\ncompetitive to the counterpart with supervised scene flow. We further show that\nour approach generates highly promising results in open-set 3D detection and\ntrajectory prediction, confirming its potential in closing the safety gap of\nfully supervised systems.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Mahyar Najibi",
      "Jingwei Ji",
      "Yin Zhou",
      "Charles R. Qi",
      "Xinchen Yan",
      "Scott Ettinger",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08061"
  },
  {
    "id": "arXiv:2210.08063",
    "title": "On the simultanenous identification of two space dependent coefficients  in a quasilinear wave equation",
    "abstract": "This paper considers the Westervelt equation, one of the most widely used\nmodels in nonlinear acoustics, and seeks to recover two spatially-dependent\nparameters of physical importance from time-trace boundary measurements.\nSpecifically, these are the nonlinearity parameter $\\kappa(x)$ often referred\nto as $B/A$ in the acoustics literature and the wave speed $c_0(x)$. The\ndetermination of the spatial change in these quantities can be used as a means\nof imaging. We consider identifiability from one or two boundary measurements\nas relevant in these applications. More precisely, we provide results on local\nuniqueness of $\\kappa(x)$ from a single observation and on simultaneous\nidentifiability of $\\kappa(x)$ and $c_0(x)$ from two measurements. For a\nreformulation of the problem in terms of the squared slowness $\\ssl=1/c_0^2$\nand the combined coefficient $\\nlc=\\frac{\\kappa}{c_0^2}$ we devise a frozen\nNewton method and prove its convergence. The effectiveness (and limitations) of\nthis iterative scheme are demonstrated by numerical examples.",
    "descriptor": "",
    "authors": [
      "Barbara Kaltenbacher",
      "William Rundell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.08063"
  },
  {
    "id": "arXiv:2210.08064",
    "title": "LESS: Label-Efficient Semantic Segmentation for LiDAR Point Clouds",
    "abstract": "Semantic segmentation of LiDAR point clouds is an important task in\nautonomous driving. However, training deep models via conventional supervised\nmethods requires large datasets which are costly to label. It is critical to\nhave label-efficient segmentation approaches to scale up the model to new\noperational domains or to improve performance on rare cases. While most prior\nworks focus on indoor scenes, we are one of the first to propose a\nlabel-efficient semantic segmentation pipeline for outdoor scenes with LiDAR\npoint clouds. Our method co-designs an efficient labeling process with\nsemi/weakly supervised learning and is applicable to nearly any 3D semantic\nsegmentation backbones. Specifically, we leverage geometry patterns in outdoor\nscenes to have a heuristic pre-segmentation to reduce the manual labeling and\njointly design the learning targets with the labeling process. In the learning\nstep, we leverage prototype learning to get more descriptive point embeddings\nand use multi-scan distillation to exploit richer semantics from temporally\naggregated point clouds to boost the performance of single-scan models.\nEvaluated on the SemanticKITTI and the nuScenes datasets, we show that our\nproposed method outperforms existing label-efficient methods. With extremely\nlimited human annotations (e.g., 0.1% point labels), our proposed method is\neven highly competitive compared to the fully supervised counterpart with 100%\nlabels.",
    "descriptor": "",
    "authors": [
      "Minghua Liu",
      "Yin Zhou",
      "Charles R. Qi",
      "Boqing Gong",
      "Hao Su",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08064"
  },
  {
    "id": "arXiv:2210.08065",
    "title": "Just Round: Quantized Observation Spaces Enable Memory Efficient  Learning of Dynamic Locomotion",
    "abstract": "Deep reinforcement learning (DRL) is one of the most powerful tools for\nsynthesizing complex robotic behaviors. But training DRL models is incredibly\ncompute and memory intensive, requiring large training datasets and replay\nbuffers to achieve performant results. This poses a challenge for the next\ngeneration of field robots that will need to learn on the edge to adapt to\ntheir environment. In this paper, we begin to address this issue through\nobservation space quantization. We evaluate our approach using four simulated\nrobot locomotion tasks and two state-of-the-art DRL algorithms, the on-policy\nProximal Policy Optimization (PPO) and off-policy Soft Actor-Critic (SAC) and\nfind that observation space quantization reduces overall memory costs by as\nmuch as 4.2x without impacting learning performance.",
    "descriptor": "",
    "authors": [
      "Lev Grossman",
      "Brian Plancher"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08065"
  },
  {
    "id": "arXiv:2210.08066",
    "title": "Optimizing Vision Transformers for Medical Image Segmentation and  Few-Shot Domain Adaptation",
    "abstract": "The adaptation of transformers to computer vision is not straightforward\nbecause the modelling of image contextual information results in quadratic\ncomputational complexity with relation to the input features. Most of existing\nmethods require extensive pre-training on massive datasets such as ImageNet and\ntherefore their application to fields such as healthcare is less effective.\nCNNs are the dominant architecture in computer vision tasks because\nconvolutional filters can effectively model local dependencies and reduce\ndrastically the parameters required. However, convolutional filters cannot\nhandle more complex interactions, which are beyond a small neighbour of pixels.\nFurthermore, their weights are fixed after training and thus they do not take\ninto consideration changes in the visual input. Inspired by recent work on\nhybrid visual transformers with convolutions and hierarchical transformers, we\npropose Convolutional Swin-Unet (CS-Unet) transformer blocks and optimise their\nsettings with relation to patch embedding, projection, the feed-forward\nnetwork, up sampling and skip connections. CS-Unet can be trained from scratch\nand inherits the superiority of convolutions in each feature process phase. It\nhelps to encode precise spatial information and produce hierarchical\nrepresentations that contribute to object concepts at various scales.\nExperiments show that CS-Unet without pre-training surpasses other\nstate-of-the-art counterparts by large margins on two medical CT and MRI\ndatasets with fewer parameters. In addition, two domain-adaptation experiments\non optic disc and polyp image segmentation further prove that our method is\nhighly generalizable and effectively bridges the domain gap between images from\ndifferent sources.",
    "descriptor": "",
    "authors": [
      "Qianying Liu",
      "Chaitanya Kaul",
      "Christos Anagnostopoulos",
      "Roderick Murray-Smith",
      "Fani Deligianni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08066"
  },
  {
    "id": "arXiv:2210.08068",
    "title": "Whole-body tumor segmentation of 18F -FDG PET/CT using a cascaded and  ensembled convolutional neural networks",
    "abstract": "Background: A crucial initial processing step for quantitative PET/CT\nanalysis is the segmentation of tumor lesions enabling accurate feature\nex-traction, tumor characterization, oncologic staging, and image-based therapy\nresponse assessment. Manual lesion segmentation is however associated with\nenormous effort and cost and is thus infeasible in clinical routine. Goal: The\ngoal of this study was to report the performance of a deep neural network\ndesigned to automatically segment regions suspected of cancer in whole-body\n18F-FDG PET/CT images in the context of the AutoPET challenge. Method: A\ncascaded approach was developed where a stacked ensemble of 3D UNET CNN\nprocessed the PET/CT images at a fixed 6mm resolution. A refiner network\ncomposed of residual layers enhanced the 6mm segmentation mask to the original\nresolution. Results: 930 cases were used to train the model. 50% were\nhistologically proven cancer patients and 50% were healthy controls. We\nobtained a dice=0.68 on 84 stratified test cases. Manual and automatic\nMetabolic Tumor Volume (MTV) were highly correlated (R2 = 0.969,Slope = 0.947).\nInference time was 89.7 seconds on average. Conclusion: The proposed algorithm\naccurately segmented regions suspicious for cancer in whole-body 18F -FDG\nPET/CT images.",
    "descriptor": "",
    "authors": [
      "Ludovic Sibille",
      "Xinrui Zhan",
      "Lei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08068"
  },
  {
    "id": "arXiv:2210.08069",
    "title": "Zonotope Domains for Lagrangian Neural Network Verification",
    "abstract": "Neural network verification aims to provide provable bounds for the output of\na neural network for a given input range. Notable prior works in this domain\nhave either generated bounds using abstract domains, which preserve some\ndependency between intermediate neurons in the network; or framed verification\nas an optimization problem and solved a relaxation using Lagrangian methods. A\nkey drawback of the latter technique is that each neuron is treated\nindependently, thereby ignoring important neuron interactions. We provide an\napproach that merges these two threads and uses zonotopes within a Lagrangian\ndecomposition. Crucially, we can decompose the problem of verifying a deep\nneural network into the verification of many 2-layer neural networks. While\neach of these problems is provably hard, we provide efficient relaxation\nmethods that are amenable to efficient dual ascent procedures. Our technique\nyields bounds that improve upon both linear programming and Lagrangian-based\nverification techniques in both time and bound tightness.",
    "descriptor": "\nComments: Accepted into NeurIPS 2022. Code: this https URL\n",
    "authors": [
      "Matt Jordan",
      "Jonathan Hayase",
      "Alexandros G. Dimakis",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08069"
  },
  {
    "id": "arXiv:2210.08073",
    "title": "Eliciting Compatible Demonstrations for Multi-Human Imitation Learning",
    "abstract": "Imitation learning from human-provided demonstrations is a strong approach\nfor learning policies for robot manipulation. While the ideal dataset for\nimitation learning is homogenous and low-variance -- reflecting a single,\noptimal method for performing a task -- natural human behavior has a great deal\nof heterogeneity, with several optimal ways to demonstrate a task. This\nmultimodality is inconsequential to human users, with task variations\nmanifesting as subconscious choices; for example, reaching down, then across to\ngrasp an object, versus reaching across, then down. Yet, this mismatch presents\na problem for interactive imitation learning, where sequences of users improve\non a policy by iteratively collecting new, possibly conflicting demonstrations.\nTo combat this problem of demonstrator incompatibility, this work designs an\napproach for 1) measuring the compatibility of a new demonstration given a base\npolicy, and 2) actively eliciting more compatible demonstrations from new\nusers. Across two simulation tasks requiring long-horizon, dexterous\nmanipulation and a real-world \"food plating\" task with a Franka Emika Panda\narm, we show that we can both identify incompatible demonstrations via post-hoc\nfiltering, and apply our compatibility measure to actively elicit compatible\ndemonstrations from new users, leading to improved task success rates across\nsimulated and real environments.",
    "descriptor": "\nComments: To appear at the 6th Annual Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Kanishk Gandhi",
      "Siddharth Karamcheti",
      "Madeline Liao",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08073"
  },
  {
    "id": "arXiv:2210.08079",
    "title": "On Triangular Inequality of the Discounted Least Information Theory of  Entropy (DLITE)",
    "abstract": "The Discounted Least Information Theory of Entropy (DLITE) is a new\ninformation measure that quantifies the amount of entropic difference between\ntwo probability distributions. It manifests multiple critical properties both\nas an information-theoretic quantity and as metric distance. In the report, we\nprovide a proof of the triangular inequality of DLITE's cube root\n($\\sqrt[3]{DL}$), an important property of a metric, along with alternative\nproofs for two additional properties.",
    "descriptor": "\nComments: 3 pages, a technical report\n",
    "authors": [
      "Kashti S. Umare",
      "Weimao Ke"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08079"
  },
  {
    "id": "arXiv:2210.08080",
    "title": "Deep Learning based Super-Resolution for Medical Volume Visualization  with Direct Volume Rendering",
    "abstract": "Modern-day display systems demand high-quality rendering. However, rendering\nat higher resolution requires a large number of data samples and is\ncomputationally expensive. Recent advances in deep learning-based image and\nvideo super-resolution techniques motivate us to investigate such networks for\nhigh-fidelity upscaling of frames rendered at a lower resolution to a higher\nresolution. While our work focuses on super-resolution of medical volume\nvisualization performed with direct volume rendering, it is also applicable for\nvolume visualization with other rendering techniques. We propose a\nlearning-based technique where our proposed system uses color information along\nwith other supplementary features gathered from our volume renderer to learn\nefficient upscaling of a low-resolution rendering to a higher-resolution space.\nFurthermore, to improve temporal stability, we also implement the temporal\nreprojection technique for accumulating history samples in volumetric\nrendering.",
    "descriptor": "",
    "authors": [
      "Sudarshan Devkota",
      "Sumanta Pattanaik"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08080"
  },
  {
    "id": "arXiv:2210.08083",
    "title": "Reference Based Color Transfer for Medical Volume Rendering",
    "abstract": "The benefits of medical imaging are enormous. Medical images provide\nconsiderable amounts of anatomical information and this facilitates medical\npractitioners in performing effective disease diagnosis and deciding upon the\nbest course of medical treatment. A transition from traditional monochromatic\nmedical images like CT scans, X-Rays or MRI images to a colored 3D\nrepresentation of the anatomical structure further enhances the capabilities of\nmedical professionals in extracting valuable medical information. The proposed\nframework in our research starts with performing color transfer by finding deep\nsemantic correspondence between two medical images: a colored reference image,\nand a monochromatic CT scan or an MRI image. We extend this idea of\nreference-based colorization technique to perform colored volume rendering from\na stack of grayscale medical images. Furthermore, we also propose to use an\neffective reference image recommendation system to aid in the selection of good\nreference images. With our approach, we successfully perform colored medical\nvolume visualization and essentially eliminate the painstaking process of user\ninteraction with a transfer function to obtain color and opacity parameters for\nvolume rendering.",
    "descriptor": "",
    "authors": [
      "Sudarshan Devkota",
      "Summanta Pattanaik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08083"
  },
  {
    "id": "arXiv:2210.08084",
    "title": "Model Predictive Control for Flexible Joint Robots",
    "abstract": "Modern Lightweight robots are constructed to be collaborative, which often\nresults in a low structural stiffness compared to conventional rigid robots.\nTherefore, the controller must be able to handle the dynamic oscillatory effect\nmainly due to the intrinsic joint elasticity. Singular perturbation theory\nmakes it possible to decompose the flexible joint dynamics into fast and slow\nsubsystems. This model separation provides additional features to incorporate\nfuture knowledge of the jointlevel dynamical behavior within the controller\ndesign using the Model Predictive Control (MPC) technique. In this study,\ndifferent architectures are considered that combine the method of Singular\nPerturbation and MPC. For Singular Perturbation, the parameters that influence\nthe validity of using this technique to control a flexible-joint robot are\ninvestigated. Furthermore, limits on the input constraints for the future\ntrajectory are considered with MPC. The position control performance and\nrobustness against external forces of each architecture are validated\nexperimentally for a flexible joint robot.",
    "descriptor": "",
    "authors": [
      "Maged Iskandar",
      "Christiaan van Ommeren",
      "Xuwei Wu",
      "Alin Albu-Schaffer",
      "Alexander Dietrich"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08084"
  },
  {
    "id": "arXiv:2210.08085",
    "title": "Adaptive patch foraging in deep reinforcement learning agents",
    "abstract": "Patch foraging is one of the most heavily studied behavioral optimization\nchallenges in biology. However, despite its importance to biological\nintelligence, this behavioral optimization problem is understudied in\nartificial intelligence research. Patch foraging is especially amenable to\nstudy given that it has a known optimal solution, which may be difficult to\ndiscover given current techniques in deep reinforcement learning. Here, we\ninvestigate deep reinforcement learning agents in an ecological patch foraging\ntask. For the first time, we show that machine learning agents can learn to\npatch forage adaptively in patterns similar to biological foragers, and\napproach optimal patch foraging behavior when accounting for temporal\ndiscounting. Finally, we show emergent internal dynamics in these agents that\nresemble single-cell recordings from foraging non-human primates, which\ncomplements experimental and theoretical work on the neural mechanisms of\nbiological foraging. This work suggests that agents interacting in complex\nenvironments with ecologically valid pressures arrive at common solutions,\nsuggesting the emergence of foundational computations behind adaptive,\nintelligent behavior in both biological and artificial agents.",
    "descriptor": "",
    "authors": [
      "Nathan J. Wispinski",
      "Andrew Butcher",
      "Kory W. Mathewson",
      "Craig S. Chapman",
      "Matthew M. Botvinick",
      "Patrick M. Pilarski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.08085"
  },
  {
    "id": "arXiv:2210.08086",
    "title": "Knowledge Distillation approach towards Melanoma Detection",
    "abstract": "Melanoma is regarded as the most threatening among all skin cancers. There is\na pressing need to build systems which can aid in the early detection of\nmelanoma and enable timely treatment to patients. Recent methods are geared\ntowards machine learning based systems where the task is posed as image\nrecognition, tag dermoscopic images of skin lesions as melanoma or\nnon-melanoma. Even though these methods show promising results in terms of\naccuracy, they are computationally quite expensive to train, that questions the\nability of these models to be deployable in a clinical setting or memory\nconstraint devices. To address this issue, we focus on building simple and\nperformant models having few layers, less than ten compared to hundreds. As\nwell as with fewer learnable parameters, 0.26 million (M) compared to 42.5M\nusing knowledge distillation with the goal to detect melanoma from dermoscopic\nimages. First, we train a teacher model using a ResNet-50 to detect melanoma.\nUsing the teacher model, we train the student model known as Distilled Student\nNetwork (DSNet) which has around 0.26M parameters using knowledge distillation\nachieving an accuracy of 91.7%. We compare against ImageNet pre-trained models\nsuch MobileNet, VGG-16, Inception-V3, EfficientNet-B0, ResNet-50 and\nResNet-101. We find that our approach works well in terms of inference runtime\ncompared to other pre-trained models, 2.57 seconds compared to 14.55 seconds.\nWe find that DSNet (0.26M parameters), which is 15 times smaller, consistently\nperforms better than EfficientNet-B0 (4M parameters) in both melanoma and\nnon-melanoma detection across Precision, Recall and F1 scores",
    "descriptor": "",
    "authors": [
      "Md. Shakib Khan",
      "Kazi Nabiul Alam",
      "Abdur Rab Dhruba",
      "Hasib Zunair",
      "Nabeel Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08086"
  },
  {
    "id": "arXiv:2210.08090",
    "title": "Where to Begin? On the Impact of Pre-Training and Initialization in  Federated Learning",
    "abstract": "An oft-cited challenge of federated learning is the presence of\nheterogeneity. \\emph{Data heterogeneity} refers to the fact that data from\ndifferent clients may follow very different distributions. \\emph{System\nheterogeneity} refers to the fact that client devices have different system\ncapabilities. A considerable number of federated optimization methods address\nthis challenge. In the literature, empirical evaluations usually start\nfederated training from random initialization. However, in many practical\napplications of federated learning, the server has access to proxy data for the\ntraining task that can be used to pre-train a model before starting federated\ntraining. We empirically study the impact of starting from a pre-trained model\nin federated learning using four standard federated learning benchmark\ndatasets. Unsurprisingly, starting from a pre-trained model reduces the\ntraining time required to reach a target error rate and enables the training of\nmore accurate models (up to 40\\%) than is possible when starting from random\ninitialization. Surprisingly, we also find that starting federated learning\nfrom a pre-trained initialization reduces the effect of both data and system\nheterogeneity. We recommend that future work proposing and evaluating federated\noptimization methods evaluate the performance when starting from random and\npre-trained initializations. We also believe this study raises several\nquestions for further work on understanding the role of heterogeneity in\nfederated optimization.",
    "descriptor": "\nComments: v2. arXiv admin note: substantial text overlap with arXiv:2206.15387\n",
    "authors": [
      "John Nguyen",
      "Jianyu Wang",
      "Kshitiz Malik",
      "Maziar Sanjabi",
      "Michael Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08090"
  },
  {
    "id": "arXiv:2210.08092",
    "title": "Probably Approximately Correct Nonlinear Model Predictive Control  (PAC-NMPC)",
    "abstract": "Approaches for stochastic nonlinear model predictive control (SNMPC)\ntypically make restrictive assumptions about the system dynamics and rely on\napproximations to characterize the evolution of the underlying uncertainty\ndistributions. For this reason, they are often unable to capture more complex\ndistributions (e.g., non-Gaussian or multi-modal) and cannot provide accurate\nguarantees of performance. In this paper, we present a sampling-based SNMPC\napproach that leverages recently derived sample complexity bounds to certify\nthe performance of a feedback policy without making assumptions about the\nsystem dynamics or underlying uncertainty distributions. By parallelizing our\napproach, we are able to demonstrate real-time receding-horizon SNMPC with\nstatistical safety guarantees in simulation on a 24-inch wingspan fixed-wing\nUAV and on hardware using a 1/10th scale rally car.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Adam Polevoy",
      "Marin Kobilarov",
      "Joseph Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08092"
  },
  {
    "id": "arXiv:2210.08095",
    "title": "Bayesian Spline Learning for Equation Discovery of Nonlinear Dynamics  with Quantified Uncertainty",
    "abstract": "Nonlinear dynamics are ubiquitous in science and engineering applications,\nbut the physics of most complex systems is far from being fully understood.\nDiscovering interpretable governing equations from measurement data can help us\nunderstand and predict the behavior of complex dynamic systems. Although\nextensive work has recently been done in this field, robustly distilling\nexplicit model forms from very sparse data with considerable noise remains\nintractable. Moreover, quantifying and propagating the uncertainty of the\nidentified system from noisy data is challenging, and relevant literature is\nstill limited. To bridge this gap, we develop a novel Bayesian spline learning\nframework to identify parsimonious governing equations of nonlinear\n(spatio)temporal dynamics from sparse, noisy data with quantified uncertainty.\nThe proposed method utilizes spline basis to handle the data scarcity and\nmeasurement noise, upon which a group of derivatives can be accurately computed\nto form a library of candidate model terms. The equation residuals are used to\ninform the spline learning in a Bayesian manner, where approximate Bayesian\nuncertainty calibration techniques are employed to approximate posterior\ndistributions of the trainable parameters. To promote the sparsity, an\niterative sequential-threshold Bayesian learning approach is developed, using\nthe alternative direction optimization strategy to systematically approximate\nL0 sparsity constraints. The proposed algorithm is evaluated on multiple\nnonlinear dynamical systems governed by canonical ordinary and partial\ndifferential equations, and the merit/superiority of the proposed method is\ndemonstrated by comparison with state-of-the-art methods.",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "Luning Sun",
      "Daniel Zhengyu Huang",
      "Hao Sun",
      "Jian-Xun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08095"
  },
  {
    "id": "arXiv:2210.08097",
    "title": "TestAug: A Framework for Augmenting Capability-based NLP Tests",
    "abstract": "The recently proposed capability-based NLP testing allows model developers to\ntest the functional capabilities of NLP models, revealing functional failures\nthat cannot be detected by the traditional heldout mechanism. However, existing\nwork on capability-based testing requires extensive manual efforts and domain\nexpertise in creating the test cases. In this paper, we investigate a low-cost\napproach for the test case generation by leveraging the GPT-3 engine. We\nfurther propose to use a classifier to remove the invalid outputs from GPT-3\nand expand the outputs into templates to generate more test cases. Our\nexperiments show that TestAug has three advantages over the existing work on\nbehavioral testing: (1) TestAug can find more bugs than existing work; (2) The\ntest cases in TestAug are more diverse; and (3) TestAug largely saves the\nmanual efforts in creating the test suites. The code and data for TestAug can\nbe found at our project website (https://guanqun-yang.github.io/testaug/) and\nGitHub (https://github.com/guanqun-yang/testaug).",
    "descriptor": "\nComments: Accepted by COLING 2022; Presentation Video: this https URL; Website: this https URL; GitHub: this https URL\n",
    "authors": [
      "Guanqun Yang",
      "Mirazul Haque",
      "Qiaochu Song",
      "Wei Yang",
      "Xueqing Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08097"
  },
  {
    "id": "arXiv:2210.08101",
    "title": "Parameter Sharing in Budget-Aware Adapters for Multi-Domain Learning",
    "abstract": "Deep learning has achieved state-of-the-art performance on several computer\nvision tasks and domains. Nevertheless, it still demands a high computational\ncost and a significant amount of parameters that need to be learned for each\nnew domain. Such requirements hinder the use in resource-limited environments\nand demand both software and hardware optimization. Multi-domain learning\naddresses this problem by adapting to new domains while retaining the knowledge\nof the original domain. One limitation of most multi-domain learning approaches\nis that they usually are not designed for taking into account the resources\navailable to the user. Recently, some works that can reduce computational\ncomplexity and amount of parameters to fit the user needs have been proposed,\nbut they need the entire original model to handle all the domains together.\nThis work proposes a method capable of adapting to a user-defined budget while\nencouraging parameter sharing among domains. Hence, filters that are not used\nby any domain can be pruned from the network at test time. The proposed\napproach innovates by better adapting to resource-limited devices while being\nable to handle multiple domains at test time with fewer parameters and lower\ncomputational complexity than the baseline model.",
    "descriptor": "",
    "authors": [
      "Samuel Felipe dos Santos",
      "Rodrigo Berriel",
      "Thiago Oliveira-Santos",
      "Nicu Sebe",
      "Jurandy Almeida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08101"
  },
  {
    "id": "arXiv:2210.08102",
    "title": "Central pattern generators evolved for real-time adaptation",
    "abstract": "For a robot to be both autonomous and collaborative requires the ability to\nadapt its movement to a variety of external stimuli, whether these come from\nhumans or other robots. Typically, legged robots have oscillation periods\nexplicitly defined as a control parameter, limiting the adaptability of walking\ngaits. Here we demonstrate a virtual quadruped robot employing a bio-inspired\ncentral pattern generator (CPG) that can spontaneously synchronize its movement\nto a range of rhythmic stimuli. Multi-objective evolutionary algorithms were\nused to optimize the variation of movement speed and direction as a function of\nthe brain stem drive and the center of mass control respectively. This was\nfollowed by optimization of an additional layer of neurons that filters\nfluctuating inputs. As a result, a range of CPGs were able to adjust their gait\npattern and/or frequency to match the input period. We show how this can be\nused to facilitate coordinated movement despite differences in morphology, as\nwell as to learn new movement patterns.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Alex Szorkovszky",
      "Frank Veenstra",
      "Kyrre Glette"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.08102"
  },
  {
    "id": "arXiv:2210.08103",
    "title": "High-resolution synthetic residential energy use profiles for the United  States",
    "abstract": "Efficient energy consumption is crucial for achieving sustainable energy\ngoals in the era of climate change and grid modernization. Thus, it is vital to\nunderstand how energy is consumed at finer resolutions such as household in\norder to plan demand-response events or analyze the impacts of weather,\nelectricity prices, electric vehicles, solar, and occupancy schedules on energy\nconsumption. However, availability and access to detailed energy-use data,\nwhich would enable detailed studies, has been rare. In this paper, we release a\nunique, large-scale, synthetic, residential energy-use dataset for the\nresidential sector across the contiguous United States covering millions of\nhouseholds. The data comprise of hourly energy use profiles for synthetic\nhouseholds, disaggregated into Thermostatically Controlled Loads (TCL) and\nappliance use. The underlying framework is constructed using a bottom-up\napproach. Diverse open-source surveys and first principles models are used for\nend-use modeling. Extensive validation of the synthetic dataset has been\nconducted through comparisons with reported energy-use data. We present a\ndetailed, open, high-resolution, residential energy-use dataset for the United\nStates.",
    "descriptor": "\nComments: The paper has been conditionally accepted for publication in Nature Scientific Data\n",
    "authors": [
      "Swapna Thorve",
      "Young Yun Baek",
      "Samarth Swarup",
      "Henning Mortveit",
      "Achla Marathe",
      "Anil Vullikanti",
      "Madhav Marathe"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08103"
  },
  {
    "id": "arXiv:2210.08106",
    "title": "A Primal-Dual Algorithm for Hybrid Federated Learning",
    "abstract": "Very few methods for hybrid federated learning, where clients only hold\nsubsets of both features and samples, exist. Yet, this scenario is very\nimportant in practical settings. We provide a fast, robust algorithm for hybrid\nfederated learning that hinges on Fenchel Duality. We prove the convergence of\nthe algorithm to the same solution as if the model was trained centrally in a\nvariety of practical regimes. Furthermore, we provide experimental results that\ndemonstrate the performance improvements of the algorithm over a commonly used\nmethod in federated learning, FedAvg. We also provide privacy considerations\nand necessary steps to protect client data.",
    "descriptor": "",
    "authors": [
      "Tom Overman",
      "Garrett Blum",
      "Diego Klabjan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08106"
  },
  {
    "id": "arXiv:2210.08107",
    "title": "Approximation Algorithms for Robot Tours in Random Fields with  Guaranteed Estimation Accuracy",
    "abstract": "We study the sample placement and shortest tour problem for robots tasked\nwith mapping environmental phenomena modeled as stationary random fields. The\nobjective is to minimize the resources used (samples or tour length) while\nguaranteeing estimation accuracy. We give approximation algorithms for both\nproblems in convex environments. These improve previously known results, both\nin terms of theoretical guarantees and in simulations. In addition, we disprove\nan existing claim in the literature on a lower bound for a solution to the\nsample placement problem.",
    "descriptor": "",
    "authors": [
      "Shamak Dutta",
      "Nils Wilde",
      "Pratap Tokekar",
      "Stephen L. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08107"
  },
  {
    "id": "arXiv:2210.08111",
    "title": "Angular Center of Mass for Humanoid Robots",
    "abstract": "The center of mass (CoM) has been widely used in planning and control for\nhumanoid locomotion, because it carries key information about the position of a\nrobot. In contrast, an ''angular center of mass'' (ACoM), which provides an\n''average'' orientation of a robot, is less well-known in the community,\nalthough the concept has been in the literature for about a decade. In this\npaper, we introduce the ACoM from a CoM perspective. We optimize for an ACoM on\nthe humanoid robot Nadia, and demonstrate its application in walking with\nnatural upper body motion on hardware.",
    "descriptor": "",
    "authors": [
      "Yu-Ming Chen",
      "Gabriel Nelson",
      "Robert Griffin",
      "Michael Posa",
      "Jerry Pratt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08111"
  },
  {
    "id": "arXiv:2210.08113",
    "title": "Instance Segmentation with Cross-Modal Consistency",
    "abstract": "Segmenting object instances is a key task in machine perception, with\nsafety-critical applications in robotics and autonomous driving. We introduce a\nnovel approach to instance segmentation that jointly leverages measurements\nfrom multiple sensor modalities, such as cameras and LiDAR. Our method learns\nto predict embeddings for each pixel or point that give rise to a dense\nsegmentation of the scene. Specifically, our technique applies contrastive\nlearning to points in the scene both across sensor modalities and the temporal\ndomain. We demonstrate that this formulation encourages the models to learn\nembeddings that are invariant to viewpoint variations and consistent across\nsensor modalities. We further demonstrate that the embeddings are stable over\ntime as objects move around the scene. This not only provides stable instance\nmasks, but can also provide valuable signals to downstream tasks, such as\nobject tracking. We evaluate our method on the Cityscapes and KITTI-360\ndatasets. We further conduct a number of ablation studies, demonstrating\nbenefits when applying additional inputs for the contrastive loss.",
    "descriptor": "\nComments: 8 pages, 9 figures, 5 tables. Presented at IROS 2022\n",
    "authors": [
      "Alex Zihao Zhu",
      "Vincent Casser",
      "Reza Mahjourian",
      "Henrik Kretzschmar",
      "S\u00f6ren Pirk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08113"
  },
  {
    "id": "arXiv:2210.08115",
    "title": "Censored Deep Reinforcement Patrolling with Information Criterion for  Monitoring Large Water Resources using Autonomous Surface Vehicles",
    "abstract": "Monitoring and patrolling large water resources is a major challenge for\nconservation. The problem of acquiring data of an underlying environment that\nusually changes within time involves a proper formulation of the information.\nThe use of Autonomous Surface Vehicles equipped with water quality sensor\nmodules can serve as an early-warning system agents for contamination\npeak-detection, algae blooms monitoring, or oil-spill scenarios. In addition to\ninformation gathering, the vehicle must plan routes that are free of obstacles\non non-convex maps. This work proposes a framework to obtain a collision-free\npolicy that addresses the patrolling task for static and dynamic scenarios.\nUsing information gain as a measure of the uncertainty reduction over data, it\nis proposed a Deep Q-Learning algorithm improved by a Q-Censoring mechanism for\nmodel-based obstacle avoidance. The obtained results demonstrate the usefulness\nof the proposed algorithm for water resource monitoring for static and dynamic\nscenarios. Simulations showed the use of noise-networks are a good choice for\nenhanced exploration, with 3 times less redundancy in the paths. Previous\ncoverage strategies are also outperformed both in the accuracy of the obtained\ncontamination model by a 13% on average and by a 37% in the detection of\ndangerous contamination peaks. Finally, these results indicate the\nappropriateness of the proposed framework for monitoring scenarios with\nautonomous vehicles.",
    "descriptor": "\nComments: This article is currently under revision for the Applied Soft Computing Journal (Elsevier)\n",
    "authors": [
      "Samuel Yanes Luis",
      "Daniel Guti\u00e9rrez Reina",
      "Sergio Toral Mar\u00edn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08115"
  },
  {
    "id": "arXiv:2210.08116",
    "title": "A Low-cost Humanoid Prototype Intended to assist people with disability  using Raspberry Pi",
    "abstract": "This paper will try to delineate the making of a Humanoid prototype intended\nto assist people with disability (PWD). The assistance that this prototype will\noffer is rather rudimentary. However, our key focus is to make the prototype\ncost-friendly while pertaining to its humanoid-like functionalities.\nConsidering growing needs of Robots, facilities for further installment of\nfeatures have been made available in this project. The prototype will be of\nhumanoid shape harnessing the power of Artificial Neural Network (ANN) to\nconverse with the users. The prototype uses a raspberry pi and as the\ncomputational capability of a raspberry pi is minimal, we cut corners to\nsqueeze the last drop of performance and make it as efficient as possible.",
    "descriptor": "\nComments: The number of total pages is 8, number of figures is 3, and number of tables is 2\n",
    "authors": [
      "Md. Nayem Hasan Muntasir",
      "Tariqul Islam Siam",
      "Md. Kamruzzaman Sarker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08116"
  },
  {
    "id": "arXiv:2210.08117",
    "title": "An Improved Multi-State Constraint Kalman Filter for Visual-Inertial  Odometry",
    "abstract": "Fast pose estimation (PE) is of vital importance for successful mission\nperformance of agile autonomous robots. Global Positioning Systems such as GPS\nand GNSS have been typically used in fusion with Inertial Navigation Systems\n(INS) for PE. However, the low update rate and lack of proper signals make\ntheir utility impractical for indoor and urban applications. On the other hand,\nVisual-Inertial Odometry (VIO) is gaining popularity as a practical alternative\nfor GNSS/INS systems in GPS-denied environments. Among the many VIO-based\nmethods, the Multi-State Constraint Kalman Filter (MSCKF) has received a\ngreater attention due to its robustness, speed and accuracy. To this end, the\nhigh computational cost associated with image processing for real-time\nimplementation of MSCKF on resource-constrained vehicles is still a challenging\nongoing research. In this paper, an enhanced version of the MSCKF is proposed.\nTo this aim, different feature marginalization and state pruning strategies are\nsuggested that result in a much faster algorithm. The proposed algorithm is\ntested both on an open-source dataset and in real-world experiments for\nvalidation. It is demonstrated that the proposed Fast-MSCKF (FMSCKF) is about\nsix times faster and at least 20% more accurate in final position estimation\nthan the standard MSCKF algorithm.",
    "descriptor": "",
    "authors": [
      "M.R. Abdollahi",
      "Seid H. Pourtakdoust",
      "M.H. Yoosefian Nooshabadi",
      "H.N. Pishkenari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08117"
  },
  {
    "id": "arXiv:2210.08118",
    "title": "TraInterSim: Adaptive and Planning-Aware Hybrid-Driven Traffic  Intersection Simulation",
    "abstract": "Traffic intersections are important scenes that can be seen almost everywhere\nin the traffic system. Currently, most simulation methods perform well at\nhighways and urban traffic networks. In intersection scenarios, the challenge\nlies in the lack of clearly defined lanes, where agents with various motion\nplannings converge in the central area from different directions. Traditional\nmodel-based methods are difficult to drive agents to move realistically at\nintersections without enough predefined lanes, while data-driven methods often\nrequire a large amount of high-quality input data. Simultaneously, tedious\nparameter tuning is inevitable involved to obtain the desired simulation\nresults. In this paper, we present a novel adaptive and planning-aware\nhybrid-driven method (TraInterSim) to simulate traffic intersection scenarios.\nOur hybrid-driven method combines an optimization-based data-driven scheme with\na velocity continuity model. It guides the agent's movements using real-world\ndata and can generate those behaviors not present in the input data. Our\noptimization method fully considers velocity continuity, desired speed,\ndirection guidance, and planning-aware collision avoidance. Agents can perceive\nothers' motion planning and relative distance to avoid possible collisions. To\npreserve the individual flexibility of different agents, the parameters in our\nmethod are automatically adjusted during the simulation. TraInterSim can\ngenerate realistic behaviors of heterogeneous agents in different traffic\nintersection scenarios in interactive rates. Through extensive experiments as\nwell as user studies, we validate the effectiveness and rationality of the\nproposed simulation method.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Pei Lv",
      "Xinming Pei",
      "Xinyu Ren",
      "Yuzhen Zhang",
      "Chaochao Li",
      "Mingliang Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.08118"
  },
  {
    "id": "arXiv:2210.08119",
    "title": "A Survey on Knowledge Graph-based Methods for Automated Driving",
    "abstract": "Automated driving is one of the most active research areas in computer\nscience. Deep learning methods have made remarkable breakthroughs in machine\nlearning in general and in automated driving (AD)in particular. However, there\nare still unsolved problems to guarantee reliability and safety of automated\nsystems, especially to effectively incorporate all available information and\nknowledge in the driving task. Knowledge graphs (KG) have recently gained\nsignificant attention from both industry and academia for applications that\nbenefit by exploiting structured, dynamic, and relational data. The complexity\nof graph-structured data with complex relationships and inter-dependencies\nbetween objects has posed significant challenges to existing machine learning\nalgorithms. However, recent progress in knowledge graph embeddings and graph\nneural networks allows to applying machine learning to graph-structured data.\nTherefore, we motivate and discuss the potential benefit of KGs applied to the\nmain tasks of AD including 1) ontologies 2) perception, 3) scene understanding,\n4) motion planning, and 5) validation. Then, we survey, analyze and categorize\nontologies and KG-based approaches for AD. We discuss current research\nchallenges and propose promising future research directions for KG-based\nsolutions for AD.",
    "descriptor": "\nComments: Preprint to appear in KGSWC Knowledge Graph and Semantic Web Conference 2022\n",
    "authors": [
      "Juergen Luettin",
      "Sebastian Monka",
      "Cory Henson",
      "Lavdim Halilaj"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08119"
  },
  {
    "id": "arXiv:2210.08120",
    "title": "Towards a Fully Autonomous UAV Controller for Moving Platform Detection  and Landing",
    "abstract": "While Unmanned Aerial Vehicles (UAVs) are increasingly deployed in several\nmissions, their inability of reliable and consistent autonomous landing poses a\nmajor setback for deploying such systems truly autonomously. In this paper we\npresent an autonomous UAV landing system for landing on a moving platform. In\ncontrast to existing attempts, the proposed system relies only on the camera\nsensor, and has been designed as lightweight as possible. The proposed system\ncan be deployed on a low power platform as part of the drone payload, whilst\nbeing indifferent to any external communication or any other sensors. The\nsystem relies on a Neural Network (NN) based controller, for which a target and\nenvironment agnostic simulator was created, used in training and testing of the\nproposed system, via Reinforcement Learning (RL) and Proximal Policy\noptimization (PPO) to optimally control and steer the drone towards landing on\nthe target. Through real-world testing, the system was evaluated with an\naverage deviation of 15cm from the center of the target, for 40 landing\nattempts.",
    "descriptor": "\nComments: 2022 35th International Conference on VLSI Design and 2022 21st International Conference on Embedded Systems (VLSID)\n",
    "authors": [
      "Michalis Piponidis",
      "Panayiotis Aristodemou",
      "Theocharis Theocharides"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08120"
  },
  {
    "id": "arXiv:2210.08121",
    "title": "Inferring Versatile Behavior from Demonstrations by Matching Geometric  Descriptors",
    "abstract": "Humans intuitively solve tasks in versatile ways, varying their behavior in\nterms of trajectory-based planning and for individual steps. Thus, they can\neasily generalize and adapt to new and changing environments. Current Imitation\nLearning algorithms often only consider unimodal expert demonstrations and act\nin a state-action-based setting, making it difficult for them to imitate human\nbehavior in case of versatile demonstrations. Instead, we combine a mixture of\nmovement primitives with a distribution matching objective to learn versatile\nbehaviors that match the expert's behavior and versatility. To facilitate\ngeneralization to novel task configurations, we do not directly match the\nagent's and expert's trajectory distributions but rather work with concise\ngeometric descriptors which generalize well to unseen task configurations. We\nempirically validate our method on various robot tasks using versatile human\ndemonstrations and compare to imitation learning algorithms in a state-action\nsetting as well as a trajectory-based setting. We find that the geometric\ndescriptors greatly help in generalizing to new task configurations and that\ncombining them with our distribution-matching objective is crucial for\nrepresenting and reproducing versatile behavior.",
    "descriptor": "\nComments: Accepted as a poster at the 6th Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Niklas Freymuth",
      "Nicolas Schreiber",
      "Philipp Becker",
      "Aleksander Taranovic",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08121"
  },
  {
    "id": "arXiv:2210.08122",
    "title": "Old can be Gold: Better Gradient Flow can Make Vanilla-GCNs Great Again",
    "abstract": "Despite the enormous success of Graph Convolutional Networks (GCNs) in\nmodeling graph-structured data, most of the current GCNs are shallow due to the\nnotoriously challenging problems of over-smoothening and information squashing\nalong with conventional difficulty caused by vanishing gradients and\nover-fitting. Previous works have been primarily focused on the study of\nover-smoothening and over-squashing phenomena in training deep GCNs.\nSurprisingly, in comparison with CNNs/RNNs, very limited attention has been\ngiven to understanding how healthy gradient flow can benefit the trainability\nof deep GCNs. In this paper, firstly, we provide a new perspective of gradient\nflow to understand the substandard performance of deep GCNs and hypothesize\nthat by facilitating healthy gradient flow, we can significantly improve their\ntrainability, as well as achieve state-of-the-art (SOTA) level performance from\nvanilla-GCNs. Next, we argue that blindly adopting the Glorot initialization\nfor GCNs is not optimal, and derive a topology-aware isometric initialization\nscheme for vanilla-GCNs based on the principles of isometry. Additionally,\ncontrary to ad-hoc addition of skip-connections, we propose to use\ngradient-guided dynamic rewiring of vanilla-GCNs} with skip connections. Our\ndynamic rewiring method uses the gradient flow within each layer during\ntraining to introduce on-demand skip-connections adaptively. We provide\nextensive empirical evidence across multiple datasets that our methods improve\ngradient flow in deep vanilla-GCNs and significantly boost their performance to\ncomfortably compete and outperform many fancy state-of-the-art methods. Codes\nare available at: https://github.com/VITA-Group/GradientGCN.",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Ajay Jaiswal",
      "Peihao Wang",
      "Tianlong Chen",
      "Justin F. Rousseau",
      "Ying Ding",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08122"
  },
  {
    "id": "arXiv:2210.08123",
    "title": "Keypoint Cascade Voting for Point Cloud Based 6DoF Pose Estimation",
    "abstract": "We propose a novel keypoint voting 6DoF object pose estimation method, which\ntakes pure unordered point cloud geometry as input without RGB information. The\nproposed cascaded keypoint voting method, called RCVPose3D, is based upon a\nnovel architecture which separates the task of semantic segmentation from that\nof keypoint regression, thereby increasing the effectiveness of both and\nimproving the ultimate performance. The method also introduces a pairwise\nconstraint in between different keypoints to the loss function when regressing\nthe quantity for keypoint estimation, which is shown to be effective, as well\nas a novel Voter Confident Score which enhances both the learning and inference\nstages. Our proposed RCVPose3D achieves state-of-the-art performance on the\nOcclusion LINEMOD (74.5%) and YCB-Video (96.9%) datasets, outperforming\nexisting pure RGB and RGB-D based methods, as well as being competitive with\nRGB plus point cloud methods.",
    "descriptor": "",
    "authors": [
      "Yangzheng Wu",
      "Alireza Javaheri",
      "Mohsen Zand",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08123"
  },
  {
    "id": "arXiv:2210.08126",
    "title": "Geometric Reinforcement Learning: The Case of Cartesian Space  Orientation",
    "abstract": "Reinforcement learning (RL) enables an agent to learn by trial and error\nwhile interacting with a dynamic environment. Traditionally, RL is used to\nlearn and predict Euclidean robotic manipulation skills like positions,\nvelocities, and forces. However, in robotics, it is common to have\nnon-Euclidean data like orientation or stiffness, and neglecting their\ngeometric nature can adversely affect learning performance and accuracy. In\nthis paper, we propose a novel framework for RL by using Riemannian geometry,\nand show how it can be applied to learn manipulation skills with a specific\ngeometric structure (e.g., robot's orientation in the task space). The proposed\nframework is suitable for any policy representation and is independent of the\nalgorithm choice. Specifically, we propose to apply policy parameterization and\nlearning on the tangent space, then map the learned actions back to the\nappropriate manifold (e.g., the S3 manifold for orientation). Therefore, we\nintroduce a geometrically grounded pre- and post-processing step into the\ntypical RL pipeline, which opens the door to all algorithms designed for\nEuclidean space to learn from non-Euclidean data without changes. Experimental\nresults, obtained both in simulation and on a real robot, support our\nhypothesis that learning on the tangent space is more accurate and converges to\na better solution than approximating non-Euclidean data.",
    "descriptor": "\nComments: 9 pages, 9 figures, journal\n",
    "authors": [
      "Naseem Alhousani",
      "Matteo Saveriano",
      "Ibrahim Sevinc",
      "Talha Abdulkuddus",
      "Hatice Kose",
      "Fares J. Abu-Dakka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08126"
  },
  {
    "id": "arXiv:2210.08127",
    "title": "Reflections on trusting distributed trust",
    "abstract": "Many systems today distribute trust across multiple parties such that the\nsystem provides certain security properties if a subset of the parties are\nhonest. In the past few years, we have seen an explosion of academic and\nindustrial cryptographic systems built on distributed trust, including secure\nmulti-party computation applications (e.g., private analytics, secure learning,\nand private key recovery) and blockchains. These systems have great potential\nfor improving security and privacy, but face a significant hurdle on the path\nto deployment. We initiate study of the following problem: a single\norganization is, by definition, a single party, and so how can a single\norganization build a distributed-trust system where corruptions are\nindependent? We instead consider an alternative formulation of the problem:\nrather than ensuring that a distributed-trust system is set up correctly by\ndesign, what if instead, users can audit a distributed-trust deployment? We\npropose a framework that enables a developer to efficiently and cheaply set up\nany distributed-trust system in a publicly auditable way. To do this, we\nidentify two application-independent building blocks that we can use to\nbootstrap arbitrary distributed-trust applications: secure hardware and an\nappend-only log. We show how to leverage existing implementations of these\nbuilding blocks to deploy distributed-trust systems, and we give\nrecommendations for infrastructure changes that would make it easier to deploy\ndistributed-trust systems in the future.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Emma Dauterman",
      "Vivian Fang",
      "Natacha Crooks",
      "Raluca Ada Popa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08127"
  },
  {
    "id": "arXiv:2210.08128",
    "title": "Computing Distributed Knowledge as the Greatest Lower Bound of Knowledge",
    "abstract": "Let $L$ be a distributive lattice and $\\mathcal{E}(L)$ be the set of join\nendomorphisms of $L$. We consider the problem of finding $f\n\\sqcap_{{\\scriptsize \\mathcal{E}(L)}} g$ given $L$ and $f,g\\in \\mathcal{E}(L)$\nas inputs. (1) We show that it can be solved in time $O(n)$ where $n=| L |$.\nThe previous upper bound was $O(n^2)$. (2) We characterize the standard notion\nof distributed knowledge of a group as the greatest lower bound of the\njoin-endomorphisms representing the knowledge of each member of the group. (3)\nWe show that deciding whether an agent has the distributed knowledge of two\nother agents can be computed in time $O(n^2)$ where $n$ is the size of the\nunderlying set of states. (4) For the special case of $S5$ knowledge, we show\nthat it can be decided in time $O(n\\alpha_{n})$ where $\\alpha_{n}$ is the\ninverse of the Ackermann function.",
    "descriptor": "",
    "authors": [
      "Santiago Quintero",
      "Carlos Pinz\u00f3n",
      "Sergio Ram\u00edrez",
      "Frank Valencia"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.08128"
  },
  {
    "id": "arXiv:2210.08129",
    "title": "TweetNERD -- End to End Entity Linking Benchmark for Tweets",
    "abstract": "Named Entity Recognition and Disambiguation (NERD) systems are foundational\nfor information retrieval, question answering, event detection, and other\nnatural language processing (NLP) applications. We introduce TweetNERD, a\ndataset of 340K+ Tweets across 2010-2021, for benchmarking NERD systems on\nTweets. This is the largest and most temporally diverse open sourced dataset\nbenchmark for NERD on Tweets and can be used to facilitate research in this\narea. We describe evaluation setup with TweetNERD for three NERD tasks: Named\nEntity Recognition (NER), Entity Linking with True Spans (EL), and End to End\nEntity Linking (End2End); and provide performance of existing publicly\navailable methods on specific TweetNERD splits. TweetNERD is available at:\nhttps://doi.org/10.5281/zenodo.6617192 under Creative Commons Attribution 4.0\nInternational (CC BY 4.0) license. Check out more details at\nhttps://github.com/twitter-research/TweetNERD.",
    "descriptor": "\nComments: 19 pages, 2 figures. Accepted to Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track 2022. Data available at: this https URL under Creative Commons Attribution 4.0 International (CC BY 4.0) license. Check out more details at this https URL\n",
    "authors": [
      "Shubhanshu Mishra",
      "Aman Saini",
      "Raheleh Makki",
      "Sneha Mehta",
      "Aria Haghighi",
      "Ali Mollahosseini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08129"
  },
  {
    "id": "arXiv:2210.08132",
    "title": "VHetNets for AI and AI for VHetNets: An Anomaly Detection Case Study for  Ubiquitous IoT",
    "abstract": "Vertical heterogenous networks (VHetNets) and artificial intelligence (AI)\nplay critical roles in 6G and beyond networks. This article presents an\nAI-native VHetNets architecture to enable the synergy of VHetNets and AI,\nthereby supporting varieties of AI services while facilitating automatic and\nintelligent network management. Anomaly detection in Internet of Things (IoT)\nis a major AI service required by many fields, including intrusion detection,\nstate monitoring, device-activity analysis, security supervision and so on.\nConventional anomaly detection technologies mainly consider the anomaly\ndetection as a standalone service that is independent of any other network\nmanagement functionalities, which cannot be used directly in ubiquitous IoT due\nto the resource constrained end nodes and decentralized data distribution. In\nthis article, we develop an AI-native VHetNets-enabled framework to provide the\nanomaly detection service for ubiquitous IoT, whose implementation is assisted\nby intelligent network management functionalities. We first discuss the\npossibilities of VHetNets used for distributed AI model training to provide\nanomaly detection service for ubiquitous IoT, i.e., VHetNets for AI. After\nthat, we study the application of AI approaches in helping provide automatic\nand intelligent network management functionalities for VHetNets, i.e., AI for\nVHetNets, whose aim is to facilitate the efficient implementation of anomaly\ndetection service. Finally, a case study is presented to demonstrate the\nefficiency and effectiveness of the proposed AI-native VHetNets-enabled anomaly\ndetection framework.",
    "descriptor": "",
    "authors": [
      "Weili Wang",
      "Omid Abbasi",
      "Halim Yanikomeroglu",
      "Chengchao Liang",
      "Lun Tang",
      "Qianbin Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08132"
  },
  {
    "id": "arXiv:2210.08136",
    "title": "No Video Left Behind: A Utility-Preserving Obfuscation Approach for  YouTube Recommendations",
    "abstract": "Online content platforms optimize engagement by providing personalized\nrecommendations to their users. These recommendation systems track and profile\nusers to predict relevant content a user is likely interested in. While the\npersonalized recommendations provide utility to users, the tracking and\nprofiling that enables them poses a privacy issue because the platform might\ninfer potentially sensitive user interests. There is increasing interest in\nbuilding privacy-enhancing obfuscation approaches that do not rely on\ncooperation from online content platforms. However, existing obfuscation\napproaches primarily focus on enhancing privacy but at the same time they\ndegrade the utility because obfuscation introduces unrelated recommendations.\nWe design and implement De-Harpo, an obfuscation approach for YouTube's\nrecommendation system that not only obfuscates a user's video watch history to\nprotect privacy but then also denoises the video recommendations by YouTube to\npreserve their utility. In contrast to prior obfuscation approaches, De-Harpo\nadds a denoiser that makes use of a \"secret\" input (i.e., a user's actual watch\nhistory) as well as information that is also available to the adversarial\nrecommendation system (i.e., obfuscated watch history and corresponding \"noisy\"\nrecommendations). Our large-scale evaluation of De-Harpo shows that it\noutperforms the state-of-the-art by a factor of 2x in terms of preserving\nutility for the same level of privacy, while maintaining stealthiness and\nrobustness to de-obfuscation.",
    "descriptor": "",
    "authors": [
      "Jiang Zhang",
      "Hadi Askari",
      "Konstantinos Psounis",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08136"
  },
  {
    "id": "arXiv:2210.08137",
    "title": "User-specific, Adaptable Safety Controllers Facilitate User Adoption in  Human-Robot Collaboration",
    "abstract": "As assistive and collaborative robots become more ubiquitous in the\nreal-world, we need to develop interfaces and controllers that are safe for\nusers to build trust and encourage adoption. In this Blue Sky paper, we discuss\nthe need for co-evolving task and user-specific safety controllers that can\naccommodate people's safety preferences. We argue that while most adaptive\ncontrollers focus on behavioral adaptation, safety adaptation is also a major\nconsideration for building trust in collaborative systems. Furthermore, we\nhighlight the need for adaptation over time, to account for user's changes in\npreferences as experience and trust builds. We provide a general formulation\nfor what these interfaces should look like and what features are necessary for\nmaking them feasible and successful. In this formulation, users provide\ndemonstrations and labelled safety ratings from which a safety value function\nis learned. These value functions can be updated by updating the safety labels\non demonstrations to learn an updated function. We discuss how this can be\nimplemented at a high-level, as well as some promising approaches and\ntechniques for enabling this.",
    "descriptor": "\nComments: Presented at the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022 (arXiv:2209.14292)\n",
    "authors": [
      "Ahalya Prabhakar",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08137"
  },
  {
    "id": "arXiv:2210.08139",
    "title": "Partial Identification of Treatment Effects with Implicit Generative  Models",
    "abstract": "We consider the problem of partial identification, the estimation of bounds\non the treatment effects from observational data. Although studied using\ndiscrete treatment variables or in specific causal graphs (e.g., instrumental\nvariables), partial identification has been recently explored using tools from\ndeep generative modeling. We propose a new method for partial identification of\naverage treatment effects(ATEs) in general causal graphs using implicit\ngenerative models comprising continuous and discrete random variables. Since\nATE with continuous treatment is generally non-regular, we leverage the partial\nderivatives of response functions to define a regular approximation of ATE, a\nquantity we call uniform average treatment derivative (UATD). We prove that our\nalgorithm converges to tight bounds on ATE in linear structural causal models\n(SCMs). For nonlinear SCMs, we empirically show that using UATD leads to\ntighter and more stable bounds than methods that directly optimize the ATE.",
    "descriptor": "",
    "authors": [
      "Vahid Balazadeh",
      "Vasilis Syrgkanis",
      "Rahul G. Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08139"
  },
  {
    "id": "arXiv:2210.08141",
    "title": "Pseudo AI Bias",
    "abstract": "Pseudo Artificial Intelligence bias (PAIB) is broadly disseminated in the\nliterature, which can result in unnecessary AI fear in society, exacerbate the\nenduring inequities and disparities in access to and sharing the benefits of AI\napplications, and waste social capital invested in AI research. This study\nsystematically reviews publications in the literature to present three types of\nPAIBs identified due to: a) misunderstandings, b) pseudo mechanical bias, and\nc) over-expectations. We discussed the consequences of and solutions to PAIBs,\nincluding certifying users for AI applications to mitigate AI fears, providing\ncustomized user guidance for AI applications, and developing systematic\napproaches to monitor bias. We concluded that PAIB due to misunderstandings,\npseudo mechanical bias, and over-expectations of algorithmic predictions is\nsocially harmful.",
    "descriptor": "",
    "authors": [
      "Xiaoming Zhai",
      "Joseph Krajcik"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08141"
  },
  {
    "id": "arXiv:2210.08145",
    "title": "Self-Repetition in Abstractive Neural Summarizers",
    "abstract": "We provide a quantitative and qualitative analysis of self-repetition in the\noutput of neural summarizers. We measure self-repetition as the number of\nn-grams of length four or longer that appear in multiple outputs of the same\nsystem. We analyze the behavior of three popular architectures (BART, T5, and\nPegasus), fine-tuned on five datasets. In a regression analysis, we find that\nthe three architectures have different propensities for repeating content\nacross output summaries for inputs, with BART being particularly prone to\nself-repetition. Fine-tuning on more abstractive data, and on data featuring\nformulaic language, is associated with a higher rate of self-repetition. In\nqualitative analysis we find systems produce artefacts such as ads and\ndisclaimers unrelated to the content being summarized, as well as formulaic\nphrases common in the fine-tuning domain. Our approach to corpus-level analysis\nof self-repetition may help practitioners clean up training data for\nsummarizers and ultimately support methods for minimizing the amount of\nself-repetition.",
    "descriptor": "",
    "authors": [
      "Nikita Salkar",
      "Thomas Trikalinos",
      "Byron C. Wallace",
      "Ani Nenkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08145"
  },
  {
    "id": "arXiv:2210.08151",
    "title": "ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model",
    "abstract": "The need for interpretable models has fostered the development of\nself-explainable classifiers. Prior approaches are either based on multi-stage\noptimization schemes, impacting the predictive performance of the model, or\nproduce explanations that are not transparent, trustworthy or do not capture\nthe diversity of the data. To address these shortcomings, we propose ProtoVAE,\na variational autoencoder-based framework that learns class-specific prototypes\nin an end-to-end manner and enforces trustworthiness and diversity by\nregularizing the representation space and introducing an orthonormality\nconstraint. Finally, the model is designed to be transparent by directly\nincorporating the prototypes into the decision process. Extensive comparisons\nwith previous self-explainable approaches demonstrate the superiority of\nProtoVAE, highlighting its ability to generate trustworthy and diverse\nexplanations, while not degrading predictive performance.",
    "descriptor": "",
    "authors": [
      "Srishti Gautam",
      "Ahcene Boubekki",
      "Stine Hansen",
      "Suaiba Amina Salahuddin",
      "Robert Jenssen",
      "Marina MC H\u00f6hne",
      "Michael Kampffmeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08151"
  },
  {
    "id": "arXiv:2210.08153",
    "title": "CUP: Critic-Guided Policy Reuse",
    "abstract": "The ability to reuse previous policies is an important aspect of human\nintelligence. To achieve efficient policy reuse, a Deep Reinforcement Learning\n(DRL) agent needs to decide when to reuse and which source policies to reuse.\nPrevious methods solve this problem by introducing extra components to the\nunderlying algorithm, such as hierarchical high-level policies over source\npolicies, or estimations of source policies' value functions on the target\ntask. However, training these components induces either optimization\nnon-stationarity or heavy sampling cost, significantly impairing the\neffectiveness of transfer. To tackle this problem, we propose a novel policy\nreuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training\nany extra components and efficiently reuses source policies. CUP utilizes the\ncritic, a common component in actor-critic methods, to evaluate and choose\nsource policies. At each state, CUP chooses the source policy that has the\nlargest one-step improvement over the current target policy, and forms a\nguidance policy. The guidance policy is theoretically guaranteed to be a\nmonotonic improvement over the current target policy. Then the target policy is\nregularized to imitate the guidance policy to perform efficient policy search.\nEmpirical results demonstrate that CUP achieves efficient transfer and\nsignificantly outperforms baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Jin Zhang",
      "Siyuan Li",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08153"
  },
  {
    "id": "arXiv:2210.08158",
    "title": "Hidden Complexities in the Computational Modeling of Proportionality for  Robotic Norm Violation Response",
    "abstract": "Language-capable robots hold unique persuasive power over humans, and thus\ncan help regulate people's behavior and preserve a better moral ecosystem, by\nrejecting unethical commands and calling out norm violations. However,\nmiscalibrated norm violation responses (when the harshness of a response does\nnot match the actual norm violation severity) may not only decrease the\neffectiveness of human-robot communication, but may also damage the rapport\nbetween humans and robots. Therefore, when robots respond to norm violations,\nit is crucial that they consider both the moral value of their response (by\nconsidering how much positive moral influence their response could exert) and\nthe social value (by considering how much face threat might be imposed by their\nutterance). In this paper, we present a simple (naive) mathematical model of\nproportionality which could explain how moral and social considerations should\nbe balanced in multi-agent norm violation response generation. But even more\nimportantly, we use this model to start a discussion about the hidden\ncomplexity of modeling proportionality, and use this discussion to identify key\nresearch directions that must be explored in order to develop socially and\nmorally competent language-capable robots.",
    "descriptor": "\nComments: 5 pages, the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022\n",
    "authors": [
      "Ruchen Wen",
      "Tom Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08158"
  },
  {
    "id": "arXiv:2210.08159",
    "title": "Dynamics-aware Adversarial Attack of Adaptive Neural Networks",
    "abstract": "In this paper, we investigate the dynamics-aware adversarial attack problem\nof adaptive neural networks. Most existing adversarial attack algorithms are\ndesigned under a basic assumption -- the network architecture is fixed\nthroughout the attack process. However, this assumption does not hold for many\nrecently proposed adaptive neural networks, which adaptively deactivate\nunnecessary execution units based on inputs to improve computational\nefficiency. It results in a serious issue of lagged gradient, making the\nlearned attack at the current step ineffective due to the architecture change\nafterward. To address this issue, we propose a Leaded Gradient Method (LGM) and\nshow the significant effects of the lagged gradient. More specifically, we\nreformulate the gradients to be aware of the potential dynamic changes of\nnetwork architectures, so that the learned attack better \"leads\" the next step\nthan the dynamics-unaware methods when network architecture changes\ndynamically. Extensive experiments on representative types of adaptive neural\nnetworks for both 2D images and 3D point clouds show that our LGM achieves\nimpressive adversarial attack performance compared with the dynamic-unaware\nattack methods.",
    "descriptor": "",
    "authors": [
      "An Tao",
      "Yueqi Duan",
      "Yingqi Wang",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08159"
  },
  {
    "id": "arXiv:2210.08160",
    "title": "Learning Dual Memory Dictionaries for Blind Face Restoration",
    "abstract": "To improve the performance of blind face restoration, recent works mainly\ntreat the two aspects, i.e., generic and specific restoration, separately. In\nparticular, generic restoration attempts to restore the results through general\nfacial structure prior, while on the one hand, cannot generalize to real-world\ndegraded observations due to the limited capability of direct CNNs' mappings in\nlearning blind restoration, and on the other hand, fails to exploit the\nidentity-specific details. On the contrary, specific restoration aims to\nincorporate the identity features from the reference of the same identity, in\nwhich the requirement of proper reference severely limits the application\nscenarios. Generally, it is a challenging and intractable task to improve the\nphoto-realistic performance of blind restoration and adaptively handle the\ngeneric and specific restoration scenarios with a single unified model. Instead\nof implicitly learning the mapping from a low-quality image to its high-quality\ncounterpart, this paper suggests a DMDNet by explicitly memorizing the generic\nand specific features through dual dictionaries. First, the generic dictionary\nlearns the general facial priors from high-quality images of any identity,\nwhile the specific dictionary stores the identity-belonging features for each\nperson individually. Second, to handle the degraded input with or without\nspecific reference, dictionary transform module is suggested to read the\nrelevant details from the dual dictionaries which are subsequently fused into\nthe input features. Finally, multi-scale dictionaries are leveraged to benefit\nthe coarse-to-fine restoration. Moreover, a new high-quality dataset, termed\nCelebRef-HQ, is constructed to promote the exploration of specific face\nrestoration in the high-resolution space.",
    "descriptor": "\nComments: IEEE TPAMI 2022. Code and dataset: this https URL\n",
    "authors": [
      "Xiaoming Li",
      "Shiguang Zhang",
      "Shangchen Zhou",
      "Lei Zhang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08160"
  },
  {
    "id": "arXiv:2210.08161",
    "title": "Geometric Representation Learning for Document Image Rectification",
    "abstract": "In document image rectification, there exist rich geometric constraints\nbetween the distorted image and the ground truth one. However, such geometric\nconstraints are largely ignored in existing advanced solutions, which limits\nthe rectification performance. To this end, we present DocGeoNet for document\nimage rectification by introducing explicit geometric representation.\nTechnically, two typical attributes of the document image are involved in the\nproposed geometric representation learning, i.e., 3D shape and textlines. Our\nmotivation arises from the insight that 3D shape provides global unwarping cues\nfor rectifying a distorted document image while overlooking the local\nstructure. On the other hand, textlines complementarily provide explicit\ngeometric constraints for local patterns. The learned geometric representation\neffectively bridges the distorted image and the ground truth one. Extensive\nexperiments show the effectiveness of our framework and demonstrate the\nsuperiority of our DocGeoNet over state-of-the-art methods on both the DocUNet\nBenchmark dataset and our proposed DIR300 test set. The code is available at\nhttps://github.com/fh2019ustc/DocGeoNet.",
    "descriptor": "\nComments: This paper has been accepted by ECCV 2022\n",
    "authors": [
      "Hao Feng",
      "Wengang Zhou",
      "Jiajun Deng",
      "Yuechen Wang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08161"
  },
  {
    "id": "arXiv:2210.08162",
    "title": "AMD-DBSCAN: An Adaptive Multi-density DBSCAN for datasets of extremely  variable density",
    "abstract": "DBSCAN has been widely used in density-based clustering algorithms. However,\nwith the increasing demand for Multi-density clustering, previous traditional\nDSBCAN can not have good clustering results on Multi-density datasets. In order\nto address this problem, an adaptive Multi-density DBSCAN algorithm\n(AMD-DBSCAN) is proposed in this paper. An improved parameter adaptation method\nis proposed in AMD-DBSCAN to search for multiple parameter pairs (i.e., Eps and\nMinPts), which are the key parameters to determine the clustering results and\nperformance, therefore allowing the model to be applied to Multi-density\ndatasets. Moreover, only one hyperparameter is required for AMD-DBSCAN to avoid\nthe complicated repetitive initialization operations. Furthermore, the variance\nof the number of neighbors (VNN) is proposed to measure the difference in\ndensity between each cluster. The experimental results show that our AMD-DBSCAN\nreduces execution time by an average of 75% due to lower algorithm complexity\ncompared with the traditional adaptive algorithm. In addition, AMD-DBSCAN\nimproves accuracy by 24.7% on average over the state-of-the-art design on\nMulti-density datasets of extremely variable density, while having no\nperformance loss in Single-density scenarios.",
    "descriptor": "",
    "authors": [
      "Ziqing Wang",
      "Zhirong Ye",
      "Yuyang Du",
      "Yi Mao",
      "Yanying Liu",
      "Ziling Wu",
      "Jun Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08162"
  },
  {
    "id": "arXiv:2210.08164",
    "title": "Linear Video Transformer with Feature Fixation",
    "abstract": "Vision Transformers have achieved impressive performance in video\nclassification, while suffering from the quadratic complexity caused by the\nSoftmax attention mechanism. Some studies alleviate the computational costs by\nreducing the number of tokens in attention calculation, but the complexity is\nstill quadratic. Another promising way is to replace Softmax attention with\nlinear attention, which owns linear complexity but presents a clear performance\ndrop. We find that such a drop in linear attention results from the lack of\nattention concentration on critical features. Therefore, we propose a feature\nfixation module to reweight the feature importance of the query and key before\ncomputing linear attention. Specifically, we regard the query, key, and value\nas various latent representations of the input token, and learn the feature\nfixation ratio by aggregating Query-Key-Value information. This is beneficial\nfor measuring the feature importance comprehensively. Furthermore, we enhance\nthe feature fixation by neighborhood association, which leverages additional\nguidance from spatial and temporal neighbouring tokens. The proposed method\nsignificantly improves the linear attention baseline and achieves\nstate-of-the-art performance among linear video Transformers on three popular\nvideo classification benchmarks. With fewer parameters and higher efficiency,\nour performance is even comparable to some Softmax-based quadratic\nTransformers.",
    "descriptor": "",
    "authors": [
      "Kaiyue Lu",
      "Zexiang Liu",
      "Jianyuan Wang",
      "Weixuan Sun",
      "Zhen Qin",
      "Dong Li",
      "Xuyang Shen",
      "Hui Deng",
      "Xiaodong Han",
      "Yuchao Dai",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08164"
  },
  {
    "id": "arXiv:2210.08168",
    "title": "MKIS-Net: A Light-Weight Multi-Kernel Network for Medical Image  Segmentation",
    "abstract": "Image segmentation is an important task in medical imaging. It constitutes\nthe backbone of a wide variety of clinical diagnostic methods, treatments, and\ncomputer-aided surgeries. In this paper, we propose a multi-kernel image\nsegmentation net (MKIS-Net), which uses multiple kernels to create an efficient\nreceptive field and enhance segmentation performance. As a result of its\nmulti-kernel design, MKIS-Net is a light-weight architecture with a small\nnumber of trainable parameters. Moreover, these multi-kernel receptive fields\nalso contribute to better segmentation results. We demonstrate the efficacy of\nMKIS-Net on several tasks including segmentation of retinal vessels, skin\nlesion segmentation, and chest X-ray segmentation. The performance of the\nproposed network is quite competitive, and often superior, in comparison to\nstate-of-the-art methods. Moreover, in some cases MKIS-Net has more than an\norder of magnitude fewer trainable parameters than existing medical image\nsegmentation alternatives and is at least four times smaller than other\nlight-weight architectures.",
    "descriptor": "",
    "authors": [
      "Tariq M. Khan",
      "Muhammad Arsalan",
      "Antonio Robles-Kelly",
      "Erik Meijering"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08168"
  },
  {
    "id": "arXiv:2210.08169",
    "title": "Self-supervised Graph Learning for Long-tailed Cognitive Diagnosis",
    "abstract": "Cognitive diagnosis is a fundamental yet critical research task in the field\nof intelligent education, which aims to discover the proficiency level of\ndifferent students on specific knowledge concepts. Despite the effectiveness of\nexisting efforts, previous methods always considered the mastery level on the\nwhole students, so they still suffer from the Long Tail Effect. A large number\nof students who have sparse data are performed poorly in the model. To relieve\nthe situation, we proposed a Self-supervised Cognitive Diagnosis (SCD)\nframework which leverages the self-supervised manner to assist the graph-based\ncognitive diagnosis, then the performance on those students with sparse data\ncan be improved. Specifically, we came up with a graph confusion method that\ndrops edges under some special rules to generate different sparse views of the\ngraph. By maximizing the consistency of the representation on the same node\nunder different views, the model could be more focused on long-tailed students.\nAdditionally, we proposed an importance-based view generation rule to improve\nthe influence of long-tailed students. Extensive experiments on real-world\ndatasets show the effectiveness of our approach, especially on the students\nwith sparse data.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Zhen Zeng",
      "Xun Yang",
      "Xingyi Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08169"
  },
  {
    "id": "arXiv:2210.08170",
    "title": "Attention Regularized Laplace Graph for Domain Adaptation",
    "abstract": "In leveraging manifold learning in domain adaptation (DA), graph\nembedding-based DA methods have shown their effectiveness in preserving data\nmanifold through the Laplace graph. However, current graph embedding DA methods\nsuffer from two issues: 1). they are only concerned with preservation of the\nunderlying data structures in the embedding and ignore sub-domain adaptation,\nwhich requires taking into account intra-class similarity and inter-class\ndissimilarity, thereby leading to negative transfer; 2). manifold learning is\nproposed across different feature/label spaces separately, thereby hindering\nunified comprehensive manifold learning. In this paper, starting from our\nprevious DGA-DA, we propose a novel DA method, namely Attention Regularized\nLaplace Graph-based Domain Adaptation (ARG-DA), to remedy the aforementioned\nissues. Specifically, by weighting the importance across different sub-domain\nadaptation tasks, we propose the Attention Regularized Laplace Graph for\nclass-aware DA, thereby generating the attention regularized DA. Furthermore,\nusing a specifically designed FEEL strategy, our approach dynamically unifies\nalignment of the manifold structures across different feature/label spaces,\nthus leading to comprehensive manifold learning. Comprehensive experiments are\ncarried out to verify the effectiveness of the proposed DA method, which\nconsistently outperforms the state-of-the-art DA methods on 7 standard DA\nbenchmarks, i.e., 37 cross-domain image classification tasks including object,\nface, and digit images. An in-depth analysis of the proposed DA method is also\ndiscussed, including sensitivity, convergence, and robustness.",
    "descriptor": "\nComments: 18 pages, 19 figures, This work is accepted by IEEE Transactions on Image Processing and will be available online soon. arXiv admin note: text overlap with arXiv:2101.04563\n",
    "authors": [
      "Lingkun Luo",
      "Liming Chen",
      "Shiqiang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08170"
  },
  {
    "id": "arXiv:2210.08173",
    "title": "Beyond the Worst Case: Semi-Random Complexity Analysis of Winner  Determination",
    "abstract": "The computational complexity of winner determination is a classical and\nimportant problem in computational social choice. Previous work based on\nworst-case analysis has established NP-hardness of winner determination for\nsome classic voting rules, such as Kemeny, Dodgson, and Young.\nIn this paper, we revisit the classical problem of winner determination\nthrough the lens of semi-random analysis, which is a worst average-case\nanalysis where the preferences are generated from a distribution chosen by the\nadversary. Under a natural class of semi-random models that are inspired by\nrecommender systems, we prove that winner determination remains hard for\nDodgson, Young, and some multi-winner rules such as the Chamberlin-Courant rule\nand the Monroe rule. Under another natural class of semi-random models that are\nextensions of the Impartial Culture, we show that winner determination is hard\nfor Kemeny, but is easy for Dodgson. This illustrates an interesting separation\nbetween Kemeny and Dodgson.",
    "descriptor": "\nComments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)\n",
    "authors": [
      "Lirong Xia",
      "Weiqiang Zheng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.08173"
  },
  {
    "id": "arXiv:2210.08174",
    "title": "Generating Synthetic Speech from SpokenVocab for Speech Translation",
    "abstract": "Training end-to-end speech translation (ST) systems requires sufficiently\nlarge-scale data, which is unavailable for most language pairs and domains. One\npractical solution to the data scarcity issue is to convert machine translation\ndata (MT) to ST data via text-to-speech (TTS) systems. Yet, using TTS systems\ncan be tedious and slow, as the conversion needs to be done for each MT\ndataset. In this work, we propose a simple, scalable and effective data\naugmentation technique, i.e., SpokenVocab, to convert MT data to ST data\non-the-fly. The idea is to retrieve and stitch audio snippets from a\nSpokenVocab bank according to words in an MT sequence. Our experiments on\nmultiple language pairs from Must-C show that this method outperforms strong\nbaselines by an average of 1.83 BLEU scores, and it performs equally well as\nTTS-generated speech. We also showcase how SpokenVocab can be applied in\ncode-switching ST for which often no TTS systems exit. Our code is available at\nhttps://github.com/mingzi151/SpokenVocab",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Jinming Zhao",
      "Gholamreza Haffar",
      "Ehsan Shareghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08174"
  },
  {
    "id": "arXiv:2210.08175",
    "title": "DataTV: Streaming Data Videos for Storytelling",
    "abstract": "Data videos -- motion graphics that incorporate visualizations -- have been\nrecognized as an effective way to communicate ideas, but creating such video\nrequires both time and expertise, precluding them from being created and\nstreamed live. We introduce DataTV, a system for combining multiple media\nsources in real time. We validate our work through an expert review involving\nresearchers using the DataTV prototype to create a one-minute data video for\ntheir current project. Results show that the new method facilitates rapid\ncreation and enables users to focus on the narrative rather than mechanics of\nvideo production.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Zhenpeng Zhao",
      "Niklas Elmqvist"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08175"
  },
  {
    "id": "arXiv:2210.08176",
    "title": "Invertible Monotone Operators for Normalizing Flows",
    "abstract": "Normalizing flows model probability distributions by learning invertible\ntransformations that transfer a simple distribution into complex distributions.\nSince the architecture of ResNet-based normalizing flows is more flexible than\nthat of coupling-based models, ResNet-based normalizing flows have been widely\nstudied in recent years. Despite their architectural flexibility, it is\nwell-known that the current ResNet-based models suffer from constrained\nLipschitz constants. In this paper, we propose the monotone formulation to\novercome the issue of the Lipschitz constants using monotone operators and\nprovide an in-depth theoretical analysis. Furthermore, we construct an\nactivation function called Concatenated Pila (CPila) to improve gradient flow.\nThe resulting model, Monotone Flows, exhibits an excellent performance on\nmultiple density estimation benchmarks (MNIST, CIFAR-10, ImageNet32,\nImageNet64). Code is available at https://github.com/mlvlab/MonotoneFlows.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Byeongkeun Ahn",
      "Chiyoon Kim",
      "Youngjoon Hong",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08176"
  },
  {
    "id": "arXiv:2210.08178",
    "title": "Is Face Recognition Safe from Realizable Attacks?",
    "abstract": "Face recognition is a popular form of biometric authentication and due to its\nwidespread use, attacks have become more common as well. Recent studies show\nthat Face Recognition Systems are vulnerable to attacks and can lead to\nerroneous identification of faces. Interestingly, most of these attacks are\nwhite-box, or they are manipulating facial images in ways that are not\nphysically realizable. In this paper, we propose an attack scheme where the\nattacker can generate realistic synthesized face images with subtle\nperturbations and physically realize that onto his face to attack black-box\nface recognition systems. Comprehensive experiments and analyses show that\nsubtle perturbations realized on attackers face can create successful attacks\non state-of-the-art face recognition systems in black-box settings. Our study\nexposes the underlying vulnerability posed by the Face Recognition Systems\nagainst realizable black-box attacks.",
    "descriptor": "\nComments: 2020 IEEE International Joint Conference on Biometrics (IJCB)\n",
    "authors": [
      "Sanjay Saha",
      "Terence Sim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08178"
  },
  {
    "id": "arXiv:2210.08180",
    "title": "How advertising strategies affects the diffusion of information in  markets",
    "abstract": "Consumer behavior under social influence is a well-known phenomenon and\ncomputer scientists and economists are prevalently trying to analyze the\ndynamics behind decision making during the consumption process through\nagent-based modeling (ABM). Some articles tried to explain market inequality\nbecause of the social influencing, but the impact of advertising is\nunderestimated and not included as a parameter in the ABM simulations. In the\nfirst part of the work we give a background about related works, afterwards, we\nexplain our model with newly introduced advertisement and penalty parameters.\nTo best our knowledge our work will be the first paper that will consider the\neffects of social influencing, advertisement, and the novelty of the product at\nthe same time. The type of interactions is defined as advertisement and social\ninfluencing. We are interested in showing the effects of advertisement and\nsocial interactions in different time intervals. The influencing takes time by\nits nature, however, advertisement is a stronger approach to introduce new\nproducts to consumers. These effects are not linearly positive for the fashion\nproducts, since the fashion changes over time and consumed items get\nold-fashioned and ordinary for users. Our Sigmoid penalty function adds\nnon-linearity to the model to show the time and popularity effects against the\nadvertisement and social interactions.",
    "descriptor": "",
    "authors": [
      "Eren Arkangil"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08180"
  },
  {
    "id": "arXiv:2210.08181",
    "title": "Panchromatic and Multispectral Image Fusion via Alternating Reverse  Filtering Network",
    "abstract": "Panchromatic (PAN) and multi-spectral (MS) image fusion, named\nPan-sharpening, refers to super-resolve the low-resolution (LR) multi-spectral\n(MS) images in the spatial domain to generate the expected high-resolution (HR)\nMS images, conditioning on the corresponding high-resolution PAN images. In\nthis paper, we present a simple yet effective \\textit{alternating reverse\nfiltering network} for pan-sharpening. Inspired by the classical reverse\nfiltering that reverses images to the status before filtering, we formulate\npan-sharpening as an alternately iterative reverse filtering process, which\nfuses LR MS and HR MS in an interpretable manner. Different from existing\nmodel-driven methods that require well-designed priors and degradation\nassumptions, the reverse filtering process avoids the dependency on pre-defined\nexact priors. To guarantee the stability and convergence of the iterative\nprocess via contraction mapping on a metric space, we develop the learnable\nmulti-scale Gaussian kernel module, instead of using specific filters. We\ndemonstrate the theoretical feasibility of such formulations. Extensive\nexperiments on diverse scenes to thoroughly verify the performance of our\nmethod, significantly outperforming the state of the arts.",
    "descriptor": "",
    "authors": [
      "Keyu Yan",
      "Man Zhou",
      "Jie Huang",
      "Feng Zhao",
      "Chengjun Xie",
      "Chongyi Li",
      "Danfeng Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08181"
  },
  {
    "id": "arXiv:2210.08182",
    "title": "Learning Invariant Representation and Risk Minimized for Unsupervised  Accent Domain Adaptation",
    "abstract": "Unsupervised representation learning for speech audios attained impressive\nperformances for speech recognition tasks, particularly when annotated speech\nis limited. However, the unsupervised paradigm needs to be carefully designed\nand little is known about what properties these representations acquire. There\nis no guarantee that the model learns meaningful representations for valuable\ninformation for recognition. Moreover, the adaptation ability of the learned\nrepresentations to other domains still needs to be estimated. In this work, we\nexplore learning domain-invariant representations via a direct mapping of\nspeech representations to their corresponding high-level linguistic\ninformations. Results prove that the learned latents not only capture the\narticulatory feature of each phoneme but also enhance the adaptation ability,\noutperforming the baseline largely on accented benchmarks.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Chendong Zhao",
      "Jianzong Wang",
      "Xiaoyang Qu",
      "Haoqian Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08182"
  },
  {
    "id": "arXiv:2210.08184",
    "title": "Label distribution learning via label correlation grid",
    "abstract": "Label distribution learning can characterize the polysemy of an instance\nthrough label distributions. However, some noise and uncertainty may be\nintroduced into the label space when processing label distribution data due to\nartificial or environmental factors. To alleviate this problem, we propose a\n\\textbf{L}abel \\textbf{C}orrelation \\textbf{G}rid (LCG) to model the\nuncertainty of label relationships. Specifically, we compute a covariance\nmatrix for the label space in the training set to represent the relationships\nbetween labels, then model the information distribution (Gaussian distribution\nfunction) for each element in the covariance matrix to obtain an LCG. Finally,\nour network learns the LCG to accurately estimate the label distribution for\neach instance. In addition, we propose a label distribution projection\nalgorithm as a regularization term in the model training process. Extensive\nexperiments verify the effectiveness of our method on several real benchmarks.",
    "descriptor": "",
    "authors": [
      "Qimeng Guo",
      "Zhuoran Zheng",
      "Xiuyi Jia",
      "Liancheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08184"
  },
  {
    "id": "arXiv:2210.08185",
    "title": "GFlowCausal: Generative Flow Networks for Causal Discovery",
    "abstract": "Causal discovery aims to uncover causal structure among a set of variables.\nScore-based approaches mainly focus on searching for the best Directed Acyclic\nGraph (DAG) based on a predefined score function. However, most of them are not\napplicable on a large scale due to the limited searchability. Inspired by the\nactive learning in generative flow networks, we propose a novel approach to\nlearning a DAG from observational data called GFlowCausal. It converts the\ngraph search problem to a generation problem, in which direct edges are added\ngradually. GFlowCausal aims to learn the best policy to generate high-reward\nDAGs by sequential actions with probabilities proportional to predefined\nrewards. We propose a plug-and-play module based on transitive closure to\nensure efficient sampling. Theoretical analysis shows that this module could\nguarantee acyclicity properties effectively and the consistency between final\nstates and fully-connected graphs. We conduct extensive experiments on both\nsynthetic and real datasets, and results show the proposed approach to be\nsuperior and also performs well in a large-scale setting.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Wenqian Li",
      "Yinchuan Li",
      "Shengyu Zhu",
      "Yunfeng Shao",
      "Jianye Hao",
      "Yan Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08185"
  },
  {
    "id": "arXiv:2210.08186",
    "title": "Machine Learning Approach for Predicting Students Academic Performance  and Study Strategies based on their Motivation",
    "abstract": "This research aims to develop machine learning models for students academic\nperformance and study strategies prediction which could be generalized to all\ncourses in higher education. Key learning attributes (intrinsic, extrinsic,\nautonomy, relatedness, competence, and self-esteem) essential for students\nlearning process were used in building the models. Determining the broad effect\nof these attributes on students' academic performance and study strategy is the\ncenter of our interest. To investigate this, we used Scikit-learn in python to\nbuild five machine learning models (Decision Tree, K-Nearest Neighbour, Random\nForest, Linear/Logistic Regression, and Support Vector Machine) for both\nregression and classification tasks to perform our analysis. The models were\ntrained, evaluated, and tested for accuracy using 924 university dentistry\nstudents' data collected by Chilean authors through quantitative research\ndesign. A comparative analysis of the models revealed that the tree-based\nmodels such as the random forest (with prediction accuracy of 94.9%) and\ndecision tree show the best results compared to the linear, support vector, and\nk-nearest neighbours. The models built in this research can be used in\npredicting student performance and study strategy so that appropriate\ninterventions could be implemented to improve student learning progress. Thus,\nincorporating strategies that could improve diverse student learning attributes\nin the design of online educational systems may increase the likelihood of\nstudents continuing with their learning tasks as required. Moreover, the\nresults show that the attributes could be modelled together and used to\nadapt/personalize the learning process.",
    "descriptor": "",
    "authors": [
      "Fidelia A. Orji",
      "Julita Vassileva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08186"
  },
  {
    "id": "arXiv:2210.08187",
    "title": "Optimal Controller Tuning Technique for a First-Order Process with Time  Delay",
    "abstract": "We present a controller tuning strategy for first-order plus time delay\n(FOPTD) processes where the time delay in the model is approximated using the\nPad\\'e function. Using Routh-Hurwitz stability analysis, we derive the gain\nthat will give rise to desirable PID controller settings. The resulting PID\ncontroller, now correctly tuned, produces satisfactory closed-loop behavior and\nstabilizes the first-order plant. Our proposed technique eliminates the\ndeadtime component in the model and results in a minimum-phase system with all\nof its poles and zeros in the left-half s-plane. To demonstrate the\neffectiveness of our approach, we present control simulation results from an\nin-depth performance comparison between our technique and other established\nmodel-based strategies used for the control of time-delayed systems. These\nresults prove that, for the FOPTD model, Pad\\'e approximation eliminates the\nundesirable effects of the time delay and promises a faster tracking\nperformance superior to conventional controllers.",
    "descriptor": "\nComments: 11 pages, 7 figures, and 7 tables\n",
    "authors": [
      "Clinton Enwerem",
      "Ihechiluru Okoro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08187"
  },
  {
    "id": "arXiv:2210.08188",
    "title": "How Does Pseudo-Labeling Affect the Generalization Error of the  Semi-Supervised Gibbs Algorithm?",
    "abstract": "This paper provides an exact characterization of the expected generalization\nerror (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via\nthe Gibbs algorithm. This characterization is expressed in terms of the\nsymmetrized KL information between the output hypothesis, the pseudo-labeled\ndataset, and the labeled dataset. It can be applied to obtain distribution-free\nupper and lower bounds on the gen-error. Our findings offer new insights that\nthe generalization performance of SSL with pseudo-labeling is affected not only\nby the information between the output hypothesis and input training data but\nalso by the information {\\em shared} between the {\\em labeled} and {\\em\npseudo-labeled} data samples. To deepen our understanding, we further explore\ntwo examples -- mean estimation and logistic regression. In particular, we\nanalyze how the ratio of the number of unlabeled to labeled data $\\lambda$\naffects the gen-error under both scenarios. As $\\lambda$ increases, the\ngen-error for mean estimation decreases and then saturates at a value larger\nthan when all the samples are labeled, and the gap can be quantified {\\em\nexactly} with our analysis, and is dependent on the \\emph{cross-covariance}\nbetween the labeled and pseudo-labeled data sample. In logistic regression, the\ngen-error and the variance component of the excess risk also decrease as\n$\\lambda$ increases.",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Haiyun He",
      "Gholamali Aminian",
      "Yuheng Bu",
      "Miguel Rodrigues",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08188"
  },
  {
    "id": "arXiv:2210.08189",
    "title": "Parameter-free Dynamic Graph Embedding for Link Prediction",
    "abstract": "Dynamic interaction graphs have been widely adopted to model the evolution of\nuser-item interactions over time. There are two crucial factors when modelling\nuser preferences for link prediction in dynamic interaction graphs: 1)\ncollaborative relationship among users and 2) user personalized interaction\npatterns. Existing methods often implicitly consider these two factors\ntogether, which may lead to noisy user modelling when the two factors diverge.\nIn addition, they usually require time-consuming parameter learning with\nback-propagation, which is prohibitive for real-time user preference modelling.\nTo this end, this paper proposes FreeGEM, a parameter-free dynamic graph\nembedding method for link prediction. Firstly, to take advantage of the\ncollaborative relationships, we propose an incremental graph embedding engine\nto obtain user/item embeddings, which is an Online-Monitor-Offline architecture\nconsisting of an Online module to approximately embed users/items over time, a\nMonitor module to estimate the approximation error in real time and an Offline\nmodule to calibrate the user/item embeddings when the online approximation\nerrors exceed a threshold. Meanwhile, we integrate attribute information into\nthe model, which enables FreeGEM to better model users belonging to some under\nrepresented groups. Secondly, we design a personalized dynamic interaction\npattern modeller, which combines dynamic time decay with attention mechanism to\nmodel user short-term interests. Experimental results on two link prediction\ntasks show that FreeGEM can outperform the state-of-the-art methods in accuracy\nwhile achieving over 36X improvement in efficiency. All code and datasets can\nbe found in https://github.com/FudanCISL/FreeGEM.",
    "descriptor": "\nComments: 19 pages, 9 figures, 13 tables, Thirty-Sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Jiahao Liu",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Ning Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08189"
  },
  {
    "id": "arXiv:2210.08195",
    "title": "HP-GMN: Graph Memory Networks for Heterophilous Graphs",
    "abstract": "Graph neural networks (GNNs) have achieved great success in various graph\nproblems. However, most GNNs are Message Passing Neural Networks (MPNNs) based\non the homophily assumption, where nodes with the same label are connected in\ngraphs. Real-world problems bring us heterophily problems, where nodes with\ndifferent labels are connected in graphs. MPNNs fail to address the heterophily\nproblem because they mix information from different distributions and are not\ngood at capturing global patterns. Therefore, we investigate a novel Graph\nMemory Networks model on Heterophilous Graphs (HP-GMN) to the heterophily\nproblem in this paper. In HP-GMN, local information and global patterns are\nlearned by local statistics and the memory to facilitate the prediction. We\nfurther propose regularization terms to help the memory learn global\ninformation. We conduct extensive experiments to show that our method achieves\nstate-of-the-art performance on both homophilous and heterophilous graphs.",
    "descriptor": "",
    "authors": [
      "Junjie Xu",
      "Enyan Dai",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08195"
  },
  {
    "id": "arXiv:2210.08196",
    "title": "Deep Regression Unlearning",
    "abstract": "With the introduction of data protection and privacy regulations, it has\nbecome crucial to remove the lineage of data on demand in a machine learning\nsystem. In past few years, there has been notable development in machine\nunlearning to remove the information of certain training data points\nefficiently and effectively from the model. In this work, we explore unlearning\nin a regression problem, particularly in deep learning models. Unlearning in\nclassification and simple linear regression has been investigated considerably.\nHowever, unlearning in deep regression models largely remain an untouched\nproblem till now. In this work, we introduce deep regression unlearning methods\nthat are well generalized and robust to privacy attacks. We propose the\nBlindspot unlearning method which uses a novel weight optimization process. A\nrandomly initialized model, partially exposed to the retain samples and a copy\nof original model are used together to selectively imprint knowledge about the\ndata that we wish to keep and scrub the information of the data we wish to\nforget. We also propose a Gaussian distribution based fine tuning method for\nregression unlearning. The existing evaluation metrics for unlearning in a\nclassification task are not directly applicable for regression unlearning.\nTherefore, we adapt these metrics for regression task. We devise a membership\ninference attack to check the privacy leaks in the unlearned regression model.\nWe conduct the experiments on regression tasks for computer vision, natural\nlanguage processing and forecasting applications. Our deep regression\nunlearning methods show excellent performance across all of these datasets and\nmetrics.",
    "descriptor": "",
    "authors": [
      "Ayush K Tarun",
      "Vikram S Chundawat",
      "Murari Mandal",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08196"
  },
  {
    "id": "arXiv:2210.08197",
    "title": "DyFEn: Agent-Based Fee Setting in Payment Channel Networks",
    "abstract": "In recent years, with the development of easy to use learning environments,\nimplementing and reproducible benchmarking of reinforcement learning algorithms\nhas been largely accelerated by utilizing these frameworks. In this article, we\nintroduce the Dynamic Fee learning Environment (DyFEn), an open-source\nreal-world financial network model. It can provide a testbed for evaluating\ndifferent reinforcement learning techniques. To illustrate the promise of\nDyFEn, we present a challenging problem which is a simultaneous multi-channel\ndynamic fee setting for off-chain payment channels. This problem is well-known\nin the Bitcoin Lightning Network and has no effective solutions. Specifically,\nwe report the empirical results of several commonly used deep reinforcement\nlearning methods on this dynamic fee setting task as a baseline for further\nexperiments. To the best of our knowledge, this work proposes the first virtual\nlearning environment based on a simulation of blockchain and distributed ledger\ntechnologies, unlike many others which are based on physics simulations or game\nplatforms.",
    "descriptor": "",
    "authors": [
      "Kiana Asgari",
      "Aida Afshar Mohammadian",
      "Mojtaba Tefagh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2210.08197"
  },
  {
    "id": "arXiv:2210.08198",
    "title": "Distributionally Robust Multiclass Classification and Applications in  Deep Image Classifiers",
    "abstract": "We develop a Distributionally Robust Optimization (DRO) formulation for\nMulticlass Logistic Regression (MLR), which could tolerate data contaminated by\noutliers. The DRO framework uses a probabilistic ambiguity set defined as a\nball of distributions that are close to the empirical distribution of the\ntraining set in the sense of the Wasserstein metric. We relax the DRO\nformulation into a regularized learning problem whose regularizer is a norm of\nthe coefficient matrix. We establish out-of-sample performance guarantees for\nthe solutions to our model, offering insights on the role of the regularizer in\ncontrolling the prediction error. We apply the proposed method in rendering\ndeep Vision Transformer (ViT)-based image classifiers robust to random and\nadversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we\ndemonstrate reductions in test error rate by up to 83.5% and loss by up to\n91.3% compared with baseline methods, by adopting a novel random training\nmethod.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.12772\n",
    "authors": [
      "Ruidi Chen",
      "Boran Hao",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08198"
  },
  {
    "id": "arXiv:2210.08202",
    "title": "IBL-NeRF: Image-Based Lighting Formulation of Neural Radiance Fields",
    "abstract": "We propose IBL-NeRF, which decomposes the neural radiance fields (NeRF) of\nlarge-scale indoor scenes into intrinsic components. Previous approaches for\nthe inverse rendering of NeRF transform the implicit volume to fit the\nrendering pipeline of explicit geometry, and approximate the views of\nsegmented, isolated objects with environment lighting. In contrast, our inverse\nrendering extends the original NeRF formulation to capture the spatial\nvariation of lighting within the scene volume, in addition to surface\nproperties. Specifically, the scenes of diverse materials are decomposed into\nintrinsic components for image-based rendering, namely, albedo, roughness,\nsurface normal, irradiance, and prefiltered radiance. All of the components are\ninferred as neural images from MLP, which can model large-scale general scenes.\nBy adopting the image-based formulation of NeRF, our approach inherits superior\nvisual quality and multi-view consistency for synthesized images. We\ndemonstrate the performance on scenes with complex object layouts and light\nconfigurations, which could not be processed in any of the previous works.",
    "descriptor": "",
    "authors": [
      "Changwoon Choi",
      "Juhyeon Kim",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08202"
  },
  {
    "id": "arXiv:2210.08203",
    "title": "Unit Selection: Learning Benefit Function from Finite Population Data",
    "abstract": "The unit selection problem is to identify a group of individuals who are most\nlikely to exhibit a desired mode of behavior, for example, selecting\nindividuals who would respond one way if incentivized and a different way if\nnot. The unit selection problem consists of evaluation and search subproblems.\nLi and Pearl defined the \"benefit function\" to evaluate the average payoff of\nselecting a certain individual with given characteristics. The search\nsubproblem is then to design an algorithm to identify the characteristics that\nmaximize the above benefit function. The hardness of the search subproblem\narises due to the large number of characteristics available for each individual\nand the sparsity of the data available in each cell of characteristics. In this\npaper, we present a machine learning framework that uses the bounds of the\nbenefit function that are estimable from the finite population data to learn\nthe bounds of the benefit function for each cell of characteristics. Therefore,\nwe could easily obtain the characteristics that maximize the benefit function.",
    "descriptor": "",
    "authors": [
      "Ang Li",
      "Song Jiang",
      "Yizhou Sun",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08203"
  },
  {
    "id": "arXiv:2210.08205",
    "title": "Active Learning from the Web",
    "abstract": "Labeling data is one of the most costly processes in machine learning\npipelines. Active learning is a standard approach to alleviating this problem.\nPool-based active learning first builds a pool of unlabelled data and\niteratively selects data to be labeled so that the total number of required\nlabels is minimized, keeping the model performance high. Many effective\ncriteria for choosing data from the pool have been proposed in the literature.\nHowever, how to build the pool is less explored. Specifically, most of the\nmethods assume that a task-specific pool is given for free. In this paper, we\nadvocate that such a task-specific pool is not always available and propose the\nuse of a myriad of unlabelled data on the Web for the pool for which active\nlearning is applied. As the pool is extremely large, it is likely that relevant\ndata exist in the pool for many tasks, and we do not need to explicitly design\nand build the pool for each task. The challenge is that we cannot compute the\nacquisition scores of all data exhaustively due to the size of the pool. We\npropose an efficient method, Seafaring, to retrieve informative data in terms\nof active learning from the Web using a user-side information retrieval\nalgorithm. In the experiments, we use the online Flickr environment as the pool\nfor active learning. This pool contains more than ten billion images and is\nseveral orders of magnitude larger than the existing pools in the literature\nfor active learning. We confirm that our method performs better than existing\napproaches of using a small unlabelled pool.",
    "descriptor": "",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08205"
  },
  {
    "id": "arXiv:2210.08207",
    "title": "Temporal Word Meaning Disambiguation using TimeLMs",
    "abstract": "Meaning of words constantly changes given the events in modern civilization.\nLarge Language Models use word embeddings, which are often static and thus\ncannot cope with this semantic change. Thus,it is important to resolve\nambiguity in word meanings. This paper is an effort in this direction, where we\nexplore methods for word sense disambiguation for the EvoNLP shared task. We\nconduct rigorous ablations for two solutions to this problem. We see that an\napproach using time-aware language models helps this task. Furthermore, we\nexplore possible future directions to this problem.",
    "descriptor": "",
    "authors": [
      "Mihir Godbole",
      "Parth Dandavate",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08207"
  },
  {
    "id": "arXiv:2210.08209",
    "title": "Large Language Models for Multi-label Propaganda Detection",
    "abstract": "The spread of propaganda through the internet has increased drastically over\nthe past years. Lately, propaganda detection has started gaining importance\nbecause of the negative impact it has on society. In this work, we describe our\napproach for the WANLP 2022 shared task which handles the task of propaganda\ndetection in a multi-label setting. The task demands the model to label the\ngiven text as having one or more types of propaganda techniques. There are a\ntotal of 22 propaganda techniques to be detected. We show that an ensemble of\nfive models performs the best on the task, scoring a micro-F1 score of 59.73%.\nWe also conduct comprehensive ablations and propose various future directions\nfor this work.",
    "descriptor": "",
    "authors": [
      "Tanmay Chavan",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08209"
  },
  {
    "id": "arXiv:2210.08210",
    "title": "Providing Error Detection for Deep Learning Image Classifiers Using  Self-Explainability",
    "abstract": "This paper proposes a self-explainable Deep Learning (SE-DL) system for an\nimage classification problem that performs self-error detection. The self-error\ndetection is key to improving the DL system's safe operation, especially in\nsafety-critical applications such as automotive systems. A SE-DL system outputs\nboth the class prediction and an explanation for that prediction, which\nprovides insight into how the system makes its predictions for humans.\nAdditionally, we leverage the explanation of the proposed SE-DL system to\ndetect potential class prediction errors of the system. The proposed SE-DL\nsystem uses a set of concepts to generate the explanation. The concepts are\nhuman-understandable lower-level image features in each input image relevant to\nthe higher-level class of that image. We present a concept selection\nmethodology for scoring all concepts and selecting a subset of them based on\ntheir contribution to the error detection performance of the proposed SE-DL\nsystem. Finally, we present different error detection schemes using the\nproposed SE-DL system to compare them against an error detection scheme without\nany SE-DL system.",
    "descriptor": "",
    "authors": [
      "Mohammad Mahdi Karimi",
      "Azin Heidarshenas",
      "William W. Edmonson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08210"
  },
  {
    "id": "arXiv:2210.08212",
    "title": "D.MCA: Outlier Detection with Explicit Micro-Cluster Assignments",
    "abstract": "How can we detect outliers, both scattered and clustered, and also explicitly\nassign them to respective micro-clusters, without knowing apriori how many\nmicro-clusters exist? How can we perform both tasks in-house, i.e., without any\npost-hoc processing, so that both detection and assignment can benefit\nsimultaneously from each other? Presenting outliers in separate micro-clusters\nis informative to analysts in many real-world applications. However, a na\\\"ive\nsolution based on post-hoc clustering of the outliers detected by any existing\nmethod suffers from two main drawbacks: (a) appropriate hyperparameter values\nare commonly unknown for clustering, and most algorithms struggle with clusters\nof varying shapes and densities; (b) detection and assignment cannot benefit\nfrom one another. In this paper, we propose D.MCA to $\\underline{D}$etect\noutliers with explicit $\\underline{M}$icro-$\\underline{C}$luster\n$\\underline{A}$ssignment. Our method performs both detection and assignment\niteratively, and in-house, by using a novel strategy that prunes entire\nmicro-clusters out of the training set to improve the performance of the\ndetection. It also benefits from a novel strategy that avoids clustered\noutliers to mask each other, which is a well-known problem in the literature.\nAlso, D.MCA is designed to be robust to a critical hyperparameter by employing\na hyperensemble \"warm up\" phase. Experiments performed on 16 real-world and\nsynthetic datasets demonstrate that D.MCA outperforms 8 state-of-the-art\ncompetitors, especially on the explicit outlier micro-cluster assignment task.",
    "descriptor": "\nComments: Proceedings of the 22nd IEEE International Conference on Data Mining (ICDM 2022)\n",
    "authors": [
      "Shuli Jiang",
      "Robson Leonardo Ferreira Cordeiro",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08212"
  },
  {
    "id": "arXiv:2210.08216",
    "title": "UDoc-GAN: Unpaired Document Illumination Correction with Background  Light Prior",
    "abstract": "Document images captured by mobile devices are usually degraded by\nuncontrollable illumination, which hampers the clarity of document content.\nRecently, a series of research efforts have been devoted to correcting the\nuneven document illumination. However, existing methods rarely consider the use\nof ambient light information, and usually rely on paired samples including\ndegraded and the corrected ground-truth images which are not always accessible.\nTo this end, we propose UDoc-GAN, the first framework to address the problem of\ndocument illumination correction under the unpaired setting. Specifically, we\nfirst predict the ambient light features of the document. Then, according to\nthe characteristics of different level of ambient lights, we re-formulate the\ncycle consistency constraint to learn the underlying relationship between\nnormal and abnormal illumination domains. To prove the effectiveness of our\napproach, we conduct extensive experiments on DocProj dataset under the\nunpaired setting. Compared with the state-of-the-art approaches, our method\ndemonstrates promising performance in terms of character error rate (CER) and\nedit distance (ED), together with better qualitative results for textual detail\npreservation. The source code is now publicly available at\nhttps://github.com/harrytea/UDoc-GAN.",
    "descriptor": "",
    "authors": [
      "Yonghui Wang",
      "Wengang Zhou",
      "Zhenbo Lu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08216"
  },
  {
    "id": "arXiv:2210.08217",
    "title": "PI-QT-Opt: Predictive Information Improves Multi-Task Robotic  Reinforcement Learning at Scale",
    "abstract": "The predictive information, the mutual information between the past and\nfuture, has been shown to be a useful representation learning auxiliary loss\nfor training reinforcement learning agents, as the ability to model what will\nhappen next is critical to success on many control tasks. While existing\nstudies are largely restricted to training specialist agents on single-task\nsettings in simulation, in this work, we study modeling the predictive\ninformation for robotic agents and its importance for general-purpose agents\nthat are trained to master a large repertoire of diverse skills from large\namounts of data. Specifically, we introduce Predictive Information QT-Opt\n(PI-QT-Opt), a QT-Opt agent augmented with an auxiliary loss that learns\nrepresentations of the predictive information to solve up to 297 vision-based\nrobot manipulation tasks in simulation and the real world with a single set of\nparameters. We demonstrate that modeling the predictive information\nsignificantly improves success rates on the training tasks and leads to better\nzero-shot transfer to unseen novel tasks. Finally, we evaluate PI-QT-Opt on\nreal robots, achieving substantial and consistent improvement over QT-Opt in\nmultiple experimental settings of varying environments, skills, and multi-task\nconfigurations.",
    "descriptor": "\nComments: CoRL 2022. 21 pages, 9 figures. The supplementary video is available at this https URL\n",
    "authors": [
      "Kuang-Huei Lee",
      "Ted Xiao",
      "Adrian Li",
      "Paul Wohlhart",
      "Ian Fischer",
      "Yao Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08217"
  },
  {
    "id": "arXiv:2210.08218",
    "title": "Massive MIMO Evolution Towards 3GPP Release 18",
    "abstract": "Since the introduction of fifth-generation new radio (5G-NR) in Third\nGeneration Partnership Project (3GPP) Release 15, swift progress has been made\nto evolve 5G with 3GPP Release 18 emerging. A critical aspect is the design of\nmassive multiple-input multiple-output (MIMO) technology. In this line, this\npaper makes several important contributions: We provide a comprehensive\noverview of the evolution of standardized massive MIMO features from 3GPP\nRelease 15 to 17 for both time/frequency-division duplex operation across bands\nFR-1 and FR-2. We analyze the progress on channel state information (CSI)\nframeworks, beam management frameworks and present enhancements for uplink CSI.\nWe shed light on emerging 3GPP Release 18 problems requiring imminent\nattention. These include advanced codebook design and sounding reference signal\ndesign for coherent joint transmission (CJT) with multiple\ntransmission/reception points (multi- TRPs). We discuss advancements in uplink\ndemodulation reference signal design, enhancements for mobility to provide\naccurate CSI estimates, and unified transmission configuration indicator\nframework tailored for FR-2 bands. For each concept, we provide system level\nsimulation results to highlight their performance benefits. Via field trials in\nan outdoor environment at Shanghai Jiaotong University, we demonstrate the\ngains of multi-TRP CJT relative to single TRP at 3.7 GHz.",
    "descriptor": "\nComments: 23 pages, 37 Figures, one fig in the annex\n",
    "authors": [
      "Huangping Jin",
      "Kunpeng Liu",
      "Gilwon Lee",
      "Emad J. Farag",
      "Min Zhang",
      "Dalin Zhu",
      "Leiming Zhang",
      "Eko Onggosanusi",
      "Mansoor Shafi",
      "Harsh Tataria"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08218"
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": "A powerful framework for studying graphs is to consider them as geometric\ngraphs: nodes are randomly sampled from an underlying metric space, and any\npair of nodes is connected if their distance is less than a specified\nneighborhood radius. Currently, the literature mostly focuses on uniform\nsampling and constant neighborhood radius. However, real-world graphs are\nlikely to be better represented by a model in which the sampling density and\nthe neighborhood radius can both vary over the latent space. For instance, in a\nsocial network communities can be modeled as densely sampled areas, and hubs as\nnodes with larger neighborhood radius. In this work, we first perform a\nrigorous mathematical analysis of this (more general) class of models,\nincluding derivations of the resulting graph shift operators. The key insight\nis that graph shift operators should be corrected in order to avoid potential\ndistortions introduced by the non-uniform sampling. Then, we develop methods to\nestimate the unknown sampling density in a self-supervised fashion. Finally, we\npresent exemplary applications in which the learnt density is used to 1)\ncorrect the graph shift operator and improve performance on a variety of tasks,\n2) improve pooling, and 3) extract knowledge from networks. Our experimental\nfindings support our theory and provide strong evidence for our model.",
    "descriptor": "",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08219"
  },
  {
    "id": "arXiv:2210.08223",
    "title": "A Theory of Formal Choreographic Languages",
    "abstract": "We introduce a meta-model based on formal languages, dubbed formal\nchoreographic languages, to study message-passing systems. Our framework allows\nus to generalise standard constructions from the literature and to compare\nthem. In particular, we consider notions such as global view, local view, and\nprojections from the former to the latter. The correctness of local views\nprojected from global views is characterised in terms of a closure property. We\nconsider a number of communication properties -- such as (dead)lock-freedom --\nand give conditions on formal choreographic languages to guarantee them.\nFinally, we show how formal choreographic languages can capture existing\nformalisms; specifically we consider communicating finite-state machines,\nchoreography automata, and multiparty session types. Notably, formal\nchoreographic languages, differently from most approaches in the literature,\ncan naturally model systems exhibiting non-regular behaviour.",
    "descriptor": "",
    "authors": [
      "Franco Barbanera",
      "Ivan Lanese",
      "Emilio Tuosto"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08223"
  },
  {
    "id": "arXiv:2210.08226",
    "title": "Self-Distillation for Unsupervised 3D Domain Adaptation",
    "abstract": "Point cloud classification is a popular task in 3D vision. However, previous\nworks, usually assume that point clouds at test time are obtained with the same\nprocedure or sensor as those at training time. Unsupervised Domain Adaptation\n(UDA) instead, breaks this assumption and tries to solve the task on an\nunlabeled target domain, leveraging only on a supervised source domain. For\npoint cloud classification, recent UDA methods try to align features across\ndomains via auxiliary tasks such as point cloud reconstruction, which however\ndo not optimize the discriminative power in the target domain in feature space.\nIn contrast, in this work, we focus on obtaining a discriminative feature space\nfor the target domain enforcing consistency between a point cloud and its\naugmented version. We then propose a novel iterative self-training methodology\nthat exploits Graph Neural Networks in the UDA context to refine pseudo-labels.\nWe perform extensive experiments and set the new state-of-the-art in standard\nUDA benchmarks for point cloud classification. Finally, we show how our\napproach can be extended to more complex tasks such as part segmentation.",
    "descriptor": "\nComments: WACV 2023, Project Page: this https URL\n",
    "authors": [
      "Adriano Cardace",
      "Riccardo Spezialetti",
      "Pierluigi Zama Ramirez",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08226"
  },
  {
    "id": "arXiv:2210.08229",
    "title": "A Codec Information Assisted Framework for Efficient Compressed Video  Super-Resolution",
    "abstract": "Online processing of compressed videos to increase their resolutions attracts\nincreasing and broad attention. Video Super-Resolution (VSR) using recurrent\nneural network architecture is a promising solution due to its efficient\nmodeling of long-range temporal dependencies. However, state-of-the-art\nrecurrent VSR models still require significant computation to obtain a good\nperformance, mainly because of the complicated motion estimation for\nframe/feature alignment and the redundant processing of consecutive video\nframes. In this paper, considering the characteristics of compressed videos, we\npropose a Codec Information Assisted Framework (CIAF) to boost and accelerate\nrecurrent VSR models for compressed videos. Firstly, the framework reuses the\ncoded video information of Motion Vectors to model the temporal relationships\nbetween adjacent frames. Experiments demonstrate that the models with Motion\nVector based alignment can significantly boost the performance with negligible\nadditional computation, even comparable to those using more complex optical\nflow based alignment. Secondly, by further making use of the coded video\ninformation of Residuals, the framework can be informed to skip the computation\non redundant pixels. Experiments demonstrate that the proposed framework can\nsave up to 70% of the computation without performance drop on the REDS4 test\nvideos encoded by H.264 when CRF is 23.",
    "descriptor": "",
    "authors": [
      "Hengsheng Zhang",
      "Xueyi Zou",
      "Jiaming Guo",
      "Youliang Yan",
      "Rong Xie",
      "Li Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08229"
  },
  {
    "id": "arXiv:2210.08232",
    "title": "A tutorial on implementing De Morgan cubical type theory",
    "abstract": "This tutorial explains (one way) how to implement De Morgan cubical type\ntheory to people who know how to implement a dependent type theory. It contains\nan introduction to basic concepts of cubes, type checking algorithms under a\ncofibration, the idea of \"transportation rules\" and cubical operations. This\ntutorial is a by-product of an experimental implementation of cubical type\ntheory, called Guest0x0.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Tesla Zhang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.08232"
  },
  {
    "id": "arXiv:2210.08233",
    "title": "Hand Gestures Recognition in Videos Taken with Lensless Camera",
    "abstract": "A lensless camera is an imaging system that uses a mask in place of a lens,\nmaking it thinner, lighter, and less expensive than a lensed camera. However,\nadditional complex computation and time are required for image reconstruction.\nThis work proposes a deep learning model named Raw3dNet that recognizes hand\ngestures directly on raw videos captured by a lensless camera without the need\nfor image restoration. In addition to conserving computational resources, the\nreconstruction-free method provides privacy protection. Raw3dNet is a novel\nend-to-end deep neural network model for the recognition of hand gestures in\nlensless imaging systems. It is created specifically for raw video captured by\na lensless camera and has the ability to properly extract and combine temporal\nand spatial features. The network is composed of two stages: 1. spatial feature\nextractor (SFE), which enhances the spatial features of each frame prior to\ntemporal convolution; 2. 3D-ResNet, which implements spatial and temporal\nconvolution of video streams. The proposed model achieves 98.59% accuracy on\nthe Cambridge Hand Gesture dataset in the lensless optical experiment, which is\ncomparable to the lensed-camera result. Additionally, the feasibility of\nphysical object recognition is assessed. Furtherly, we show that the\nrecognition can be achieved with respectable accuracy using only a tiny portion\nof the original raw data, indicating the potential for reducing data traffic in\ncloud computing scenarios.",
    "descriptor": "",
    "authors": [
      "Yinger Zhang",
      "Zhouyi Wu",
      "Peiying Lin",
      "Yang Pan",
      "Yuting Wu",
      "Liufang Zhang",
      "Jiangtao Huangfu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08233"
  },
  {
    "id": "arXiv:2210.08238",
    "title": "Near-Optimal Regret Bounds for Multi-batch Reinforcement Learning",
    "abstract": "In this paper,\nwe study the episodic reinforcement learning (RL) problem modeled by\nfinite-horizon Markov Decision Processes (MDPs) with constraint on the number\nof batches. The multi-batch reinforcement learning framework, where the agent\nis required to provide a time schedule to update policy before everything,\nwhich is particularly suitable for the scenarios where the agent suffers\nextensively from changing the policy adaptively. Given a finite-horizon MDP\nwith $S$ states, $A$ actions and planning horizon $H$, we design a\ncomputational efficient algorithm to achieve near-optimal regret of\n$\\tilde{O}(\\sqrt{SAH^3K\\ln(1/\\delta)})$\\footnote{$\\tilde{O}(\\cdot)$ hides\nlogarithmic terms of $(S,A,H,K)$} in $K$ episodes using\n$O\\left(H+\\log_2\\log_2(K) \\right)$ batches with confidence parameter $\\delta$.\nTo our best of knowledge, it is the first $\\tilde{O}(\\sqrt{SAH^3K})$ regret\nbound with $O(H+\\log_2\\log_2(K))$ batch complexity. Meanwhile, we show that to\nachieve $\\tilde{O}(\\mathrm{poly}(S,A,H)\\sqrt{K})$ regret, the number of batches\nis at least $\\Omega\\left(H/\\log_A(K)+ \\log_2\\log_2(K) \\right)$, which matches\nour upper bound up to logarithmic terms.\nOur technical contribution are two-fold: 1) a near-optimal design scheme to\nexplore over the unlearned states; 2) an computational efficient algorithm to\nexplore certain directions with an approximated transition model.",
    "descriptor": "",
    "authors": [
      "Zihan Zhang",
      "Yuhang Jiang",
      "Yuan Zhou",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08238"
  },
  {
    "id": "arXiv:2210.08241",
    "title": "On sketch-and-project methods for solving tensor equations",
    "abstract": "We first propose the regular sketch-and-project method for solving tensor\nequations with respect to the popular t-product. Then, three adaptive sampling\nstrategies and three corresponding adaptive sketch-and-project methods are\nderived. We prove that all the proposed methods have linear convergence in\nexpectation. Furthermore, we investigate the Fourier domain versions and some\nspecial cases of the new methods, where the latter corresponds to some famous\nmatrix equation methods. Finally, numerical experiments are presented to\ndemonstrate and test the feasibility and effectiveness of the proposed methods\nfor solving tensor equations",
    "descriptor": "",
    "authors": [
      "Ling Tang",
      "Yanjun Zhang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08241"
  },
  {
    "id": "arXiv:2210.08242",
    "title": "A Novel Few-Shot Relation Extraction Pipeline Based on Adaptive  Prototype Fusion",
    "abstract": "Few-shot relation extraction (FSRE) aims at recognizing unseen relations by\nlearning with merely a handful of annotated instances. To more effectively\ngeneralize to new relations, this paper proposes a novel pipeline for the FSRE\ntask based on adaptive prototype fusion. Specifically, for each relation class,\nthe pipeline fully explores the relation information by concatenating two types\nof embedding, and then elaborately combine the relation representation with the\nadaptive prototype fusion mechanism. The whole framework can be effectively and\nefficiently optimized in an end-to-end fashion. Experiments on the benchmark\ndataset FewRel 1.0 show a significant improvement of our method against\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yuzhe Zhang",
      "Min Cen",
      "Tongzhou Wu",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08242"
  },
  {
    "id": "arXiv:2210.08243",
    "title": "Substructure-Atom Cross Attention for Molecular Representation Learning",
    "abstract": "Designing a neural network architecture for molecular representation is\ncrucial for AI-driven drug discovery and molecule design. In this work, we\npropose a new framework for molecular representation learning. Our contribution\nis threefold: (a) demonstrating the usefulness of incorporating substructures\nto node-wise features from molecules, (b) designing two branch networks\nconsisting of a transformer and a graph neural network so that the networks\nfused with asymmetric attention, and (c) not requiring heuristic features and\ncomputationally-expensive information from molecules. Using 1.8 million\nmolecules collected from ChEMBL and PubChem database, we pretrain our network\nto learn a general representation of molecules with minimal supervision. The\nexperimental results show that our pretrained network achieves competitive\nperformance on 11 downstream tasks for molecular property prediction.",
    "descriptor": "\nComments: 18 pages, 10 figures, 11 tables\n",
    "authors": [
      "Jiye Kim",
      "Seungbeom Lee",
      "Dongwoo Kim",
      "Sungsoo Ahn",
      "Jaesik Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08243"
  },
  {
    "id": "arXiv:2210.08244",
    "title": "Extreme-Long-short Term Memory for Time-series Prediction",
    "abstract": "The emergence of Long Short-Term Memory (LSTM) solves the problems of\nvanishing gradient and exploding gradient in traditional Recurrent Neural\nNetworks (RNN). LSTM, as a new type of RNN, has been widely used in various\nfields, such as text prediction, Wind Speed Forecast, depression prediction by\nEEG signals, etc. The results show that improving the efficiency of LSTM can\nhelp to improve the efficiency in other application areas.\nIn this paper, we proposed an advanced LSTM algorithm, the Extreme Long\nShort-Term Memory (E-LSTM), which adds the inverse matrix part of Extreme\nLearning Machine (ELM) as a new \"gate\" into the structure of LSTM. This \"gate\"\npreprocess a portion of the data and involves the processed data in the cell\nupdate of the LSTM to obtain more accurate data with fewer training rounds,\nthus reducing the overall training time.\nIn this research, the E-LSTM model is used for the text prediction task.\nExperimental results showed that the E-LSTM sometimes takes longer to perform a\nsingle training round, but when tested on a small data set, the new E-LSTM\nrequires only 2 epochs to obtain the results of the 7th epoch traditional LSTM.\nTherefore, the E-LSTM retains the high accuracy of the traditional LSTM, whilst\nalso improving the training speed and the overall efficiency of the LSTM.",
    "descriptor": "",
    "authors": [
      "Sida Xing",
      "Feihu Han",
      "Suiyang Khoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08244"
  },
  {
    "id": "arXiv:2210.08246",
    "title": "A User Interface for Sense-making of the Reasoning Process while  Interacting with Robots",
    "abstract": "As knowledge graph has the potential to bridge the gap between commonsense\nknowledge and reasoning over actionable capabilities of mobile robotic\nplatforms, incorporating knowledge graph into robotic system attracted\nincreasing attention in recent years. Previously, graph visualization has been\nused wildly by developers to make sense of knowledge representations. However,\ndue to lacking the link between abstract knowledge of the real-world\nenvironment and the robot's actions, transitional visualization tools are\nincompatible for expert-user to understand, test, supervise and modify the\ngraph-based reasoning system with the embodiment of the robots. Therefore, we\ndeveloped an interface which enables robotic experts to send commands to the\nrobot in natural language, then interface visualizes the procedures of the\nrobot mapping the command to the functions for querying in the commonsense\nknowledge database, links the result to the real world instances in a 3D map\nand demonstrate the execution of the robot from the first-person perspective of\nthe robot. After 3 weeks of usage of the system by robotic experts in their\ndaily development, some feedback was collected, which provides insight for\ndesigning such systems.",
    "descriptor": "\nComments: 7 figures\n",
    "authors": [
      "Chao Wang",
      "Joerg Deigmoeller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08246"
  },
  {
    "id": "arXiv:2210.08247",
    "title": "A sparse spectral method for fractional differential equations in  one-spacial dimension",
    "abstract": "We develop a sparse spectral method for a class of fractional differential\nequations, posed on $\\mathbb{R}$, in one dimension. These equations can include\nsqrt-Laplacian, Hilbert, derivative and identity terms. The numerical method\nutilizes a basis consisting of weighted Chebyshev polynomials of the second\nkind in conjunction with their Hilbert transforms. The former functions are\nsupported on $[-1,1]$ whereas the latter have global support. The global\napproximation space can contain different affine transformations of the basis,\nmapping $[-1,1]$ to other intervals. Remarkably, not only are the induced\nlinear systems sparse, but the operator decouples across the different affine\ntransformations. Hence, the solve reduces to solving $K$ independent sparse\nlinear systems of size $\\mathcal{O}(n)\\times \\mathcal{O}(n)$, with\n$\\mathcal{O}(n)$ nonzero entries, where $K$ is the number of different\nintervals and $n$ is the highest polynomial degree contained in the sum space.\nThis results in an $\\mathcal{O}(n)$ complexity solve. Applications to\nfractional heat and wave equations are considered.",
    "descriptor": "",
    "authors": [
      "Ioannis P. A. Papadopoulos",
      "Sheehan Olver"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08247"
  },
  {
    "id": "arXiv:2210.08248",
    "title": "A Closer Look at the Calibration of Differentially Private Learners",
    "abstract": "We systematically study the calibration of classifiers trained with\ndifferentially private stochastic gradient descent (DP-SGD) and observe\nmiscalibration across a wide range of vision and language tasks. Our analysis\nidentifies per-example gradient clipping in DP-SGD as a major cause of\nmiscalibration, and we show that existing approaches for improving calibration\nwith differential privacy only provide marginal improvements in calibration\nerror while occasionally causing large degradations in accuracy. As a solution,\nwe show that differentially private variants of post-processing calibration\nmethods such as temperature scaling and Platt scaling are surprisingly\neffective and have negligible utility cost to the overall model. Across 7\ntasks, temperature scaling and Platt scaling with DP-SGD result in an average\n3.1-fold reduction in the in-domain expected calibration error and only incur\nat most a minor percent drop in accuracy.",
    "descriptor": "",
    "authors": [
      "Hanlin Zhang",
      "Xuechen Li",
      "Prithviraj Sen",
      "Salim Roukos",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08248"
  },
  {
    "id": "arXiv:2210.08249",
    "title": "UniRPG: Unified Discrete Reasoning over Table and Text as Program  Generation",
    "abstract": "Question answering requiring discrete reasoning, e.g., arithmetic computing,\ncomparison, and counting, over knowledge is a challenging task. In this paper,\nwe propose UniRPG, a semantic-parsing-based approach advanced in\ninterpretability and scalability, to perform unified discrete reasoning over\nheterogeneous knowledge resources, i.e., table and text, as program generation.\nConcretely, UniRPG consists of a neural programmer and a symbolic program\nexecutor, where a program is the composition of a set of pre-defined general\natomic and higher-order operations and arguments extracted from table and text.\nFirst, the programmer parses a question into a program by generating operations\nand copying arguments, and then the executor derives answers from table and\ntext based on the program. To alleviate the costly program annotation issue, we\ndesign a distant supervision approach for programmer learning, where pseudo\nprograms are automatically constructed without annotated derivations. Extensive\nexperiments on the TAT-QA dataset show that UniRPG achieves tremendous\nimprovements and enhances interpretability and scalability compared with\nstate-of-the-art methods, even without derivation annotation. Moreover, it\nachieves promising performance on the textual dataset DROP without derivations.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Yongwei Zhou",
      "Junwei Bao",
      "Chaoqun Duan",
      "Youzheng Wu",
      "Xiaodong He",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08249"
  },
  {
    "id": "arXiv:2210.08251",
    "title": "Improving Your Graph Neural Networks: A High-Frequency Booster",
    "abstract": "Graph neural networks (GNNs) hold the promise of learning efficient\nrepresentations of graph-structured data, and one of its most important\napplications is semi-supervised node classification. However, in this\napplication, GNN frameworks tend to fail due to the following issues:\nover-smoothing and heterophily. The most popular GNNs are known to be focused\non the message-passing framework, and recent research shows that these GNNs are\noften bounded by low-pass filters from a signal processing perspective. We thus\nincorporate high-frequency information into GNNs to alleviate this genetic\nproblem. In this paper, we argue that the complement of the original graph\nincorporates a high-pass filter and propose Complement Laplacian Regularization\n(CLAR) for an efficient enhancement of high-frequency components. The\nexperimental results demonstrate that CLAR helps GNNs tackle over-smoothing,\nimproving the expressiveness of heterophilic graphs, which adds up to 3.6%\nimprovement over popular baselines and ensures topological robustness.",
    "descriptor": "",
    "authors": [
      "Jiaqi Sun",
      "Lin Zhang",
      "Shenglin Zhao",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08251"
  },
  {
    "id": "arXiv:2210.08252",
    "title": "DI-NIDS: Domain Invariant Network Intrusion Detection System",
    "abstract": "The performance of machine learning based network intrusion detection systems\n(NIDSs) severely degrades when deployed on a network with significantly\ndifferent feature distributions from the ones of the training dataset. In\nvarious applications, such as computer vision, domain adaptation techniques\nhave been successful in mitigating the gap between the distributions of the\ntraining and test data. In the case of network intrusion detection however, the\nstate-of-the-art domain adaptation approaches have had limited success.\nAccording to recent studies, as well as our own results, the performance of an\nNIDS considerably deteriorates when the `unseen' test dataset does not follow\nthe training dataset distribution. In some cases, swapping the train and test\ndatasets makes this even more severe. In order to enhance the generalisibility\nof machine learning based network intrusion detection systems, we propose to\nextract domain invariant features using adversarial domain adaptation from\nmultiple network domains, and then apply an unsupervised technique for\nrecognising abnormalities, i.e., intrusions. More specifically, we train a\ndomain adversarial neural network on labelled source domains, extract the\ndomain invariant features, and train a One-Class SVM (OSVM) model to detect\nanomalies. At test time, we feedforward the unlabeled test data to the feature\nextractor network to project it into a domain invariant space, and then apply\nOSVM on the extracted features to achieve our final goal of detecting\nintrusions. Our extensive experiments on the NIDS benchmark datasets of\nNFv2-CIC-2018 and NFv2-UNSW-NB15 show that our proposed setup demonstrates\nsuperior cross-domain performance in comparison to the previous approaches.",
    "descriptor": "",
    "authors": [
      "Siamak Layeghy",
      "Mahsa Baktashmotlagh",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.08252"
  },
  {
    "id": "arXiv:2210.08256",
    "title": "On Trustworthy Decision-Making Process of Human Drivers from the View of  Perceptual Uncertainty Reduction",
    "abstract": "Humans are experts in making decisions for challenging driving tasks with\nuncertainties. Many efforts have been made to model the decision-making process\nof human drivers at the behavior level. However, limited studies explain how\nhuman drivers actively make reliable sequential decisions to complete\ninteractive driving tasks in an uncertain environment. This paper argues that\nhuman drivers intently search for actions to reduce the uncertainty of their\nperception of the environment, i.e., perceptual uncertainty, to a low level\nthat allows them to make a trustworthy decision easily. This paper provides a\nproof of concept framework to empirically reveal that human drivers' perceptual\nuncertainty decreases when executing interactive tasks with uncertainties. We\nfirst introduce an explainable-artificial intelligence approach (i.e., SHapley\nAdditive exPlanation, SHAP) to determine the salient features on which human\ndrivers make decisions. Then, we use entropy-based measures to quantify the\ndrivers' perceptual changes in these ranked salient features across the\ndecision-making process, reflecting the changes in uncertainties. The\nvalidation and verification of our proposed method are conducted in the highway\non-ramp merging scenario with congested traffic using the INTERACTION dataset.\nExperimental results support that human drivers intentionally seek information\nto reduce their perceptual uncertainties in the number and rank of salient\nfeatures of their perception of environments to make a trustworthy decision.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Huanjie Wang",
      "Haibin Liu",
      "Wenshuo Wang",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08256"
  },
  {
    "id": "arXiv:2210.08258",
    "title": "Handling missing values in healthcare data: A systematic review of deep  learning-based imputation techniques",
    "abstract": "Objective: The proper handling of missing values is critical to delivering\nreliable estimates and decisions, especially in high-stakes fields such as\nclinical research. The increasing diversity and complexity of data have led\nmany researchers to develop deep learning (DL)-based imputation techniques. We\nconducted a systematic review to evaluate the use of these techniques, with a\nparticular focus on data types, aiming to assist healthcare researchers from\nvarious disciplines in dealing with missing values.\nMethods: We searched five databases (MEDLINE, Web of Science, Embase, CINAHL,\nand Scopus) for articles published prior to August 2021 that applied DL-based\nmodels to imputation. We assessed selected publications from four perspectives:\nhealth data types, model backbone (i.e., main architecture), imputation\nstrategies, and comparison with non-DL-based methods. Based on data types, we\ncreated an evidence map to illustrate the adoption of DL models.\nResults: We included 64 articles, of which tabular static (26.6%, 17/64) and\ntemporal data (37.5%, 24/64) were the most frequently investigated. We found\nthat model backbone(s) differed among data types as well as the imputation\nstrategy. The \"integrated\" strategy, that is, the imputation task being solved\nconcurrently with downstream tasks, was popular for tabular temporal (50%,\n12/24) and multi-modal data (71.4%, 5/7), but limited for other data types.\nMoreover, DL-based imputation methods yielded better imputation accuracy in\nmost studies, compared with non-DL-based methods.\nConclusion: DL-based imputation models can be customized based on data type,\naddressing the corresponding missing patterns, and its associated \"integrated\"\nstrategy can enhance the efficacy of imputation, especially in scenarios where\ndata is complex. Future research may focus on the portability and fairness of\nDL-based models for healthcare data imputation.",
    "descriptor": "",
    "authors": [
      "Mingxuan Liu",
      "Siqi Li",
      "Han Yuan",
      "Marcus Eng Hock Ong",
      "Yilin Ning",
      "Feng Xie",
      "Seyed Ehsan Saffari",
      "Victor Volovici",
      "Bibhas Chakraborty",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08258"
  },
  {
    "id": "arXiv:2210.08262",
    "title": "Motion estimation and filtered prediction for dynamic point cloud  attribute compression",
    "abstract": "In point cloud compression, exploiting temporal redundancy for inter\npredictive coding is challenging because of the irregular geometry. This paper\nproposes an efficient block-based inter-coding scheme for color attribute\ncompression. The scheme includes integer-precision motion estimation and an\nadaptive graph based in-loop filtering scheme for improved attribute\nprediction. The proposed block-based motion estimation scheme consists of an\ninitial motion search that exploits geometric and color attributes, followed by\na motion refinement that only minimizes color prediction error. To further\nimprove color prediction, we propose a vertex-domain low-pass graph filtering\nscheme that can adaptively remove noise from predictors computed from motion\nestimation with different accuracy. Our experiments demonstrate significant\ncoding gain over state-of-the-art coding methods.",
    "descriptor": "\nComments: Accepted for PCS2022\n",
    "authors": [
      "Haoran Hong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Ryosuke Watanabe",
      "Keisuke Nonaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08262"
  },
  {
    "id": "arXiv:2210.08263",
    "title": "Reinforcement Learning for ConnectX",
    "abstract": "ConnectX is a two-player game that generalizes the popular game Connect 4.\nThe objective is to get X coins across a row, column, or diagonal of an M x N\nboard. The first player to do so wins the game. The parameters (M, N, X) are\nallowed to change in each game, making ConnectX a novel and challenging\nproblem. In this paper, we present our work on the implementation and\nmodification of various reinforcement learning algorithms to play ConnectX.",
    "descriptor": "",
    "authors": [
      "Sheel Shah",
      "Shubham Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08263"
  },
  {
    "id": "arXiv:2210.08265",
    "title": "Bearing-based Relative Localization for Robotic Swarm with Partially  Mutual Observations",
    "abstract": "Mutual localization provides a consensus of reference frame as an essential\nbasis for cooperation in multirobot systems. Previous works have developed\ncertifiable and robust solvers for relative transformation estimation between\neach pair of robots. However, recovering relative poses for robotic swarm with\npartially mutual observations is still an unexploited problem. In this paper,\nwe present a complete algorithm for it with optimality, scalability and\nrobustness. Firstly, we fuse all odometry and bearing measurements in a unified\nminimization problem among the Stiefel manifold. Furthermore, we relax the\noriginal non-convex problem into a semi-definite programming (SDP) problem with\na strict tightness guarantee. Then, to hold the exactness in noised cases, we\nadd a convex (linear) rank cost and apply a convex iteration algorithm. We\ncompare our approach with local optimization methods on extensive simulations\nwith different robot amounts under various noise levels to show our global\noptimality and scalability advantage. Finally, we conduct real-world\nexperiments to show the practicality and robustness.",
    "descriptor": "",
    "authors": [
      "Yingjian Wang",
      "Xiangyong Wen",
      "Yanjun Cao",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08265"
  },
  {
    "id": "arXiv:2210.08266",
    "title": "MenuAI: Restaurant Food Recommendation System via a Transformer-based  Deep Learning Model",
    "abstract": "Food recommendation system has proven as an effective technology to provide\nguidance on dietary choices, and this is especially important for patients\nsuffering from chronic diseases. Unlike other multimedia recommendations, such\nas books and movies, food recommendation task is highly relied on the context\nat the moment, since users' food preference can be highly dynamic over time.\nFor example, individuals tend to eat more calories earlier in the day and eat a\nlittle less at dinner. However, there are still limited research works trying\nto incorporate both current context and nutritional knowledge for food\nrecommendation. Thus, a novel restaurant food recommendation system is proposed\nin this paper to recommend food dishes to users according to their special\nnutritional needs. Our proposed system utilises Optical Character Recognition\n(OCR) technology and a transformer-based deep learning model, Learning to Rank\n(LTR) model, to conduct food recommendation. Given a single RGB image of the\nmenu, the system is then able to rank the food dishes in terms of the input\nsearch key (e.g., calorie, protein level). Due to the property of the\ntransformer, our system can also rank unseen food dishes. Comprehensive\nexperiments are conducted to validate our methods on a self-constructed menu\ndataset, known as MenuRank dataset. The promising results, with accuracy\nranging from 77.2% to 99.5%, have demonstrated the great potential of LTR model\nin addressing food recommendation problems.",
    "descriptor": "",
    "authors": [
      "Xinwei Ju",
      "Frank Po Wen Lo",
      "Jianing Qiu",
      "Peilun Shi",
      "Jiachuan Peng",
      "Benny Lo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08266"
  },
  {
    "id": "arXiv:2210.08268",
    "title": "Product Ranking for Revenue Maximization with Multiple Purchases",
    "abstract": "Product ranking is the core problem for revenue-maximizing online retailers.\nTo design proper product ranking algorithms, various consumer choice models are\nproposed to characterize the consumers' behaviors when they are provided with a\nlist of products. However, existing works assume that each consumer purchases\nat most one product or will keep viewing the product list after purchasing a\nproduct, which does not agree with the common practice in real scenarios. In\nthis paper, we assume that each consumer can purchase multiple products at\nwill. To model consumers' willingness to view and purchase, we set a random\nattention span and purchase budget, which determines the maximal amount of\nproducts that he/she views and purchases, respectively. Under this setting, we\nfirst design an optimal ranking policy when the online retailer can precisely\nmodel consumers' behaviors. Based on the policy, we further develop the\nMultiple-Purchase-with-Budget UCB (MPB-UCB) algorithms with $\\~O(\\sqrt{T})$\nregret that estimate consumers' behaviors and maximize revenue simultaneously\nin online settings. Experiments on both synthetic and semi-synthetic datasets\nprove the effectiveness of the proposed algorithms.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Renzhe Xu",
      "Xingxuan Zhang",
      "Bo Li",
      "Yafeng Zhang",
      "Xiaolong Chen",
      "Peng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08268"
  },
  {
    "id": "arXiv:2210.08269",
    "title": "Correct-by-Design Control of Parametric Stochastic Systems",
    "abstract": "This paper addresses the problem of computing controllers that are correct by\ndesign for safety-critical systems and can provably satisfy (complex)\nfunctional requirements. We develop new methods for models of systems subject\nto both stochastic and parametric uncertainties. We provide for the first time\nnovel simulation relations for enabling correct-by-design control refinement,\nthat are founded on coupling uncertainties of stochastic systems via\nsub-probability measures. Such new relations are essential for constructing\nabstract models that are related to not only one model but to a set of\nparameterized models. We provide theoretical results for establishing this new\nclass of relations and the associated closeness guarantees for both linear and\nnonlinear parametric systems with additive Gaussian uncertainty. The results\nare demonstrated on a linear model and the nonlinear model of the Van der Pol\nOscillator.",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted to CDC 2022\n",
    "authors": [
      "Oliver Sch\u00f6n",
      "Birgit van Huijgevoort",
      "Sofie Haesaert",
      "Sadegh Soudjani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08269"
  },
  {
    "id": "arXiv:2210.08270",
    "title": "Assessing the Solid Protocol in Relation to Security & Privacy  Obligations",
    "abstract": "The Solid specification aims to empower data subjects by giving them direct\naccess control over their data across multiple applications. As governments are\nmanifesting their interest in this framework for citizen empowerment and\ne-government services, security and privacy represent pivotal issues to be\naddressed. By analyzing the relevant legislation, notably GDPR, and\ninternational standards, namely ISO/IEC 27001:2011 and 15408, we formulate the\nprimary security and privacy requirements for such a framework. Furthermore, we\nsurvey the current Solid protocol specifications regarding how they cover the\nhighlighted requirements, and draw attention to potential gaps between the\nspecifications and requirements. We also point out the contribution of recent\nacademic work presenting novel approaches to increase the security and privacy\ndegree provided by the Solid project. This paper has a twofold contribution to\nimprove user awareness of how Solid can help protect their data and to present\npossible future research lines on Solid security and privacy enhancements.",
    "descriptor": "\nComments: under submission\n",
    "authors": [
      "Christian Esposito",
      "Olaf Hartig",
      "Ross Horne",
      "Chang Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08270"
  },
  {
    "id": "arXiv:2210.08273",
    "title": "Classification of Web Phishing Kits for early detection by platform  providers",
    "abstract": "Phishing kits are tools that dark side experts provide to the community of\ncriminal phishers to facilitate the construction of malicious Web sites. As\nthese kits evolve in sophistication, providers of Web-based services need to\nkeep pace with continuous complexity. We present an original classification of\na corpus of over 2000 recent phishing kits according to their adopted evasion\nand obfuscation functions. We carry out an initial deterministic analysis of\nthe source code of the kits to extract the most discriminant features and\ninformation about their principal authors. We then integrate this initial\nclassification through supervised machine learning models. Thanks to the\nground-truth achieved in the first step, we can demonstrate whether and which\nmachine learning models are able to suitably classify even the kits adopting\nnovel evasion and obfuscation techniques that were unseen during the training\nphase. We compare different algorithms and evaluate their robustness in the\nrealistic case in which only a small number of phishing kits are available for\ntraining. This paper represents an initial but important step to support Web\nservice providers and analysts in improving early detection mechanisms and\nintelligence operations for the phishing kits that might be installed on their\nplatforms.",
    "descriptor": "",
    "authors": [
      "Andrea Venturi",
      "Michele Colajanni",
      "Marco Ramilli",
      "Giorgio Valenziano Santangelo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08273"
  },
  {
    "id": "arXiv:2210.08274",
    "title": "CLARE: A Semi-supervised Community Detection Algorithm",
    "abstract": "Community detection refers to the task of discovering closely related\nsubgraphs to understand the networks. However, traditional community detection\nalgorithms fail to pinpoint a particular kind of community. This limits its\napplicability in real-world networks, e.g., distinguishing fraud groups from\nnormal ones in transaction networks. Recently, semi-supervised community\ndetection emerges as a solution. It aims to seek other similar communities in\nthe network with few labeled communities as training data. Existing works can\nbe regarded as seed-based: locate seed nodes and then develop communities\naround seeds. However, these methods are quite sensitive to the quality of\nselected seeds since communities generated around a mis-detected seed may be\nirrelevant. Besides, they have individual issues, e.g., inflexibility and high\ncomputational overhead. To address these issues, we propose CLARE, which\nconsists of two key components, Community Locator and Community Rewriter. Our\nidea is that we can locate potential communities and then refine them.\nTherefore, the community locator is proposed for quickly locating potential\ncommunities by seeking subgraphs that are similar to training ones in the\nnetwork. To further adjust these located communities, we devise the community\nrewriter. Enhanced by deep reinforcement learning, it suggests intelligent\ndecisions, such as adding or dropping nodes, to refine community structures\nflexibly. Extensive experiments verify both the effectiveness and efficiency of\nour work compared with prior state-of-the-art approaches on multiple real-world\ndatasets.",
    "descriptor": "\nComments: Accepted by KDD'2022\n",
    "authors": [
      "Xixi Wu",
      "Yun Xiong",
      "Yao Zhang",
      "Yizhu Jiao",
      "Caihua Shan",
      "Yiheng Sun",
      "Yangyong Zhu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08274"
  },
  {
    "id": "arXiv:2210.08277",
    "title": "Deep Differentiable Logic Gate Networks",
    "abstract": "Recently, research has increasingly focused on developing efficient neural\nnetwork architectures. In this work, we explore logic gate networks for machine\nlearning tasks by learning combinations of logic gates. These networks comprise\nlogic gates such as \"AND\" and \"XOR\", which allow for very fast execution. The\ndifficulty in learning logic gate networks is that they are conventionally\nnon-differentiable and therefore do not allow training with gradient descent.\nThus, to allow for effective training, we propose differentiable logic gate\nnetworks, an architecture that combines real-valued logics and a continuously\nparameterized relaxation of the network. The resulting discretized logic gate\nnetworks achieve fast inference speeds, e.g., beyond a million images of MNIST\nper second on a single CPU core.",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08277"
  },
  {
    "id": "arXiv:2210.08280",
    "title": "Robot Navigation Anticipative Strategies in Deep Reinforcement Motion  Planning",
    "abstract": "The navigation of robots in dynamic urban environments, requires elaborated\nanticipative strategies for the robot to avoid collisions with dynamic objects,\nlike bicycles or pedestrians, and to be human aware. We have developed and\nanalyzed three anticipative strategies in motion planning taking into account\nthe future motion of the mobile objects that can move up to 18 km/h. First, we\nhave used our hybrid policy resulting from a Deep Deterministic Policy Gradient\n(DDPG) training and the Social Force Model (SFM), and we have tested it in\nsimulation in four complex map scenarios with many pedestrians. Second, we have\nused these anticipative strategies in real-life experiments using the hybrid\nmotion planning method and the ROS Navigation Stack with Dynamic Windows\nApproach (NS-DWA). The results in simulations and real-life experiments show\nvery good results in open environments and also in mixed scenarios with narrow\nspaces.",
    "descriptor": "\nComments: This is a preprint. This paper has been accepted to the fifth Iberian Robotics Conference (Robot 2022)\n",
    "authors": [
      "\u00d3scar Gil",
      "Alberto Sanfeliu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08280"
  },
  {
    "id": "arXiv:2210.08281",
    "title": "Man-in-the-OBD: A modular, protocol agnostic firewall for automotive  dongles to enhance privacy and security",
    "abstract": "Third-party dongles for cars, e.g. from insurance companies, can extract\nsensitive data and even send commands to the car via the standardized OBD-II\ninterface. Due to the lack of message authentication mechanisms, this leads to\nmajor security vulnerabilities for example regarding the connection with\nmalicious devices. Therefore, we apply a modular, protocol-independent firewall\napproach by placing a man-in-the-middle between the third-party dongle and the\ncar's OBD-II interface. With this privileged network position, we demonstrate\nhow the data flow accessible through the OBD-II interface can be modified or\nrestricted. We can modify the messages contents or delay the arrival of\nmessages by using our fine-granular configurable rewriting rules, specifically\ndesigned to work protocol agnostic. We have implemented our modular approach\nfor a configurable firewall at the OBD-II interface and successfully tested it\nagainst third-party dongles available on the market. Thus, our approach enables\na security layer to enhance automotive privacy and security of dongle users,\nwhich is of high relevance due to missing message authentications on the level\nof the electronic control units.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Felix Klement",
      "Henrich C. P\u00f6hls",
      "Stefan Katzenbeisser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.08281"
  },
  {
    "id": "arXiv:2210.08282",
    "title": "LAD: A Hybrid Deep Learning System for Benign Paroxysmal Positional  Vertigo Disorders Diagnostic",
    "abstract": "Herein, we introduce \"Look and Diagnose\" (LAD), a hybrid deep learning-based\nsystem that aims to support doctors in the medical field in diagnosing\neffectively the Benign Paroxysmal Positional Vertigo (BPPV) disorder. Given the\nbody postures of the patient in the Dix-Hallpike and lateral head turns test,\nthe visual information of both eyes is captured and fed into LAD for analyzing\nand classifying into one of six possible disorders the patient might be\nsuffering from. The proposed system consists of two streams: (1) an RNN-based\nstream that takes raw RGB images of both eyes to extract visual features and\noptical flow of each eye followed by ternary classification to determine\nleft/right posterior canal (PC) or other; and (2) pupil detector stream that\ndetects the pupil when it is classified as Non-PC and classifies the direction\nand strength of the beating to categorize the Non-PC types into the remaining\nfour classes: Geotropic BPPV (left and right) and Apogeotropic BPPV (left and\nright). Experimental results show that with the patient's body postures, the\nsystem can accurately classify given BPPV disorder into the six types of\ndisorders with an accuracy of 91% on the validation set. The proposed method\ncan successfully classify disorders with an accuracy of 93% for the Posterior\nCanal disorder and 95% for the Geotropic and Apogeotropic disorder, paving a\npotential direction for research with the medical data.",
    "descriptor": "\nComments: Accepted to IEEE Access 2022, 13 pages, 14 figures\n",
    "authors": [
      "Trung Xuan Pham",
      "Jin Woong Choi",
      "Rusty John Lloyd Mina",
      "Thanh Nguyen",
      "Sultan Rizky Madjid",
      "Chang Dong Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08282"
  },
  {
    "id": "arXiv:2210.08284",
    "title": "AraLegal-BERT: A pretrained language model for Arabic Legal text",
    "abstract": "The effectiveness of the BERT model on multiple linguistic tasks has been\nwell documented. On the other hand, its potentials for narrow and specific\ndomains such as Legal, have not been fully explored. In this paper, we examine\nhow BERT can be used in the Arabic legal domain and try customizing this\nlanguage model for several downstream tasks using several different\ndomain-relevant training and testing datasets to train BERT from scratch. We\nintroduce the AraLegal-BERT, a bidirectional encoder Transformer-based model\nthat have been thoroughly tested and carefully optimized with the goal to\namplify the impact of NLP-driven solution concerning jurisprudence, legal\ndocuments, and legal practice. We fine-tuned AraLegal-BERT and evaluated it\nagainst three BERT variations for Arabic language in three natural languages\nunderstanding (NLU) tasks. The results show that the base version of\nAraLegal-BERT achieve better accuracy than the general and original BERT over\nthe Legal text.",
    "descriptor": "",
    "authors": [
      "Muhammad AL-Qurishi",
      "Sarah AlQaseemi",
      "Riad Soussi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08284"
  },
  {
    "id": "arXiv:2210.08285",
    "title": "FedCross: Towards Accurate Federated Learning via Multi-Model Cross  Aggregation",
    "abstract": "Due to the remarkable performance in preserving data privacy for\ndecentralized data scenarios, Federated Learning (FL) has been considered as a\npromising distributed machine learning paradigm to deal with data silos\nproblems. Typically, conventional FL approaches adopts a one-to-multi training\nscheme, where the cloud server keeps only one single global model for all the\ninvolved clients for the purpose of model aggregation. However, this scheme\nsuffers from inferior classification performance, since only one global model\ncannot always accommodate all the incompatible convergence directions of local\nmodels, resulting in a low convergence rate and classification accuracy. To\naddress this issue, this paper presents an efficient FL framework named\nFedCross, which adopts a novel multi-to-multi FL training scheme based on our\nproposed similarity-based multi-model cross aggregation method. Unlike\ntraditional FL methods, in each round of FL training, FedCross uses a small set\nof distinct intermediate models to conduct weighted fusion under the guidance\nof model similarities. In this way, the intermediate models used by FedCross\ncan sufficiently respect the convergence characteristics of clients, thus\nleading to much fewer conflicts in tuning the convergence directions of\nclients. Finally, in the deployment stage, FedCross forms a global model for\nall the clients by performing the federated averaging on the trained immediate\nmodels.",
    "descriptor": "",
    "authors": [
      "Ming Hu",
      "Peiheng Zhou",
      "Zhihao Yue",
      "Zhiwei Ling",
      "Yihao Huang",
      "Yang Liu",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08285"
  },
  {
    "id": "arXiv:2210.08287",
    "title": "Linear Scalarization for Byzantine-robust learning on non-IID data",
    "abstract": "In this work we study the problem of Byzantine-robust learning when data\namong clients is heterogeneous. We focus on poisoning attacks targeting the\nconvergence of SGD. Although this problem has received great attention; the\nmain Byzantine defenses rely on the IID assumption causing them to fail when\ndata distribution is non-IID even with no attack. We propose the use of Linear\nScalarization (LS) as an enhancing method to enable current defenses to\ncircumvent Byzantine attacks in the non-IID setting. The LS method is based on\nthe incorporation of a trade-off vector that penalizes the suspected malicious\nclients. Empirical analysis corroborates that the proposed LS variants are\nviable in the IID setting. For mild to strong non-IID data splits, LS is either\ncomparable or outperforming current approaches under state-of-the-art Byzantine\nattack scenarios.",
    "descriptor": "",
    "authors": [
      "Latifa Errami",
      "El Houcine Bergou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08287"
  },
  {
    "id": "arXiv:2210.08288",
    "title": "Transformer-based dimensionality reduction",
    "abstract": "Recently, Transformer is much popular and plays an important role in the\nfields of Machine Learning (ML), Natural Language Processing (NLP), and\nComputer Vision (CV), etc. In this paper, based on the Vision Transformer (ViT)\nmodel, a new dimensionality reduction (DR) model is proposed, named\nTransformer-DR. From data visualization, image reconstruction and face\nrecognition, the representation ability of Transformer-DR after dimensionality\nreduction is studied, and it is compared with some representative DR methods to\nunderstand the difference between Transformer-DR and existing DR methods. The\nexperimental results show that Transformer-DR is an effective dimensionality\nreduction method.",
    "descriptor": "",
    "authors": [
      "Ruisheng Ran",
      "Tianyu Gao",
      "Bin Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08288"
  },
  {
    "id": "arXiv:2210.08290",
    "title": "Prediction Calibration for Generalized Few-shot Semantic Segmentation",
    "abstract": "Generalized Few-shot Semantic Segmentation (GFSS) aims to segment each image\npixel into either base classes with abundant training examples or novel classes\nwith only a handful of (e.g., 1-5) training images per class. Compared to the\nwidely studied Few-shot Semantic Segmentation FSS, which is limited to\nsegmenting novel classes only, GFSS is much under-studied despite being more\npractical. Existing approach to GFSS is based on classifier parameter fusion\nwhereby a newly trained novel class classifier and a pre-trained base class\nclassifier are combined to form a new classifier. As the training data is\ndominated by base classes, this approach is inevitably biased towards the base\nclasses. In this work, we propose a novel Prediction Calibration Network PCN to\naddress this problem. Instead of fusing the classifier parameters, we fuse the\nscores produced separately by the base and novel classifiers. To ensure that\nthe fused scores are not biased to either the base or novel classes, a new\nTransformer-based calibration module is introduced. It is known that the\nlower-level features are useful of detecting edge information in an input image\nthan higher-level features. Thus, we build a cross-attention module that guides\nthe classifier's final prediction using the fused multi-level features.\nHowever, transformers are computationally demanding. Crucially, to make the\nproposed cross-attention module training tractable at the pixel level, this\nmodule is designed based on feature-score cross-covariance and episodically\ntrained to be generalizable at inference time. Extensive experiments on\nPASCAL-$5^{i}$ and COCO-$20^{i}$ show that our PCN outperforms the\nstate-the-the-art alternatives by large margins.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Zhihe Lu",
      "Sen He",
      "Da Li",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08290"
  },
  {
    "id": "arXiv:2210.08291",
    "title": "Bidirectional Semi-supervised Dual-branch CNN for Robust 3D  Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel  Supervisions",
    "abstract": "Semi-supervised learning via teacher-student network can train a model\neffectively on a few labeled samples. It enables a student model to distill\nknowledge from the teacher's predictions of extra unlabeled data. However, such\nknowledge flow is typically unidirectional, having the performance vulnerable\nto the quality of teacher model. In this paper, we seek to robust 3D\nreconstruction of stereo endoscopic images by proposing a novel fashion of\nbidirectional learning between two learners, each of which can play both roles\nof teacher and student concurrently. Specifically, we introduce two\nself-supervisions, i.e., Adaptive Cross Supervision (ACS) and Adaptive Parallel\nSupervision (APS), to learn a dual-branch convolutional neural network. The two\nbranches predict two different disparity probability distributions for the same\nposition, and output their expectations as disparity values. The learned\nknowledge flows across branches along two directions: a cross direction\n(disparity guides distribution in ACS) and a parallel direction (disparity\nguides disparity in APS). Moreover, each branch also learns confidences to\ndynamically refine its provided supervisions. In ACS, the predicted disparity\nis softened into a unimodal distribution, and the lower the confidence, the\nsmoother the distribution. In APS, the incorrect predictions are suppressed by\nlowering the weights of those with low confidence. With the adaptive\nbidirectional learning, the two branches enjoy well-tuned supervisions from\neach other, and eventually converge on a consistent and more accurate disparity\nestimation. The experimental results on three public datasets demonstrate our\nsuperior performance over other state-of-the-arts with a decrease of averaged\ndisparity error by at least 9.76%.",
    "descriptor": "\nComments: 10 pages, submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Hongkuan Shi",
      "Zhiwei Wang",
      "Ying Zhou",
      "Dun Li",
      "Xin Yang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08291"
  },
  {
    "id": "arXiv:2210.08293",
    "title": "Approximate Graph Colouring and Crystals",
    "abstract": "We show that approximate graph colouring is not solved by any level of the\naffine integer programming (AIP) hierarchy. To establish the result, we\ntranslate the problem of exhibiting a graph fooling a level of the AIP\nhierarchy into the problem of constructing a highly symmetric crystal tensor.\nIn order to prove the existence of crystals in arbitrary dimension, we provide\na combinatorial characterisation for realisable systems of tensors; i.e., sets\nof low-dimensional tensors that can be realised as the projections of a single\nhigh-dimensional tensor.",
    "descriptor": "\nComments: Full version of a SODA 2023 paper\n",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.08293"
  },
  {
    "id": "arXiv:2210.08295",
    "title": "A Secure Federated Data-Driven Evolutionary Multi-objective Optimization  Algorithm",
    "abstract": "Data-driven evolutionary algorithms usually aim to exploit the information\nbehind a limited amount of data to perform optimization, which have proved to\nbe successful in solving many complex real-world optimization problems.\nHowever, most data-driven evolutionary algorithms are centralized, causing\nprivacy and security concerns. Existing federated Bayesian algorithms and\ndata-driven evolutionary algorithms mainly protect the raw data on each client.\nTo address this issue, this paper proposes a secure federated data-driven\nevolutionary multi-objective optimization algorithm to protect both the raw\ndata and the newly infilled solutions obtained by optimizing the acquisition\nfunction conducted on the server. We select the query points on a randomly\nselected client at each round of surrogate update by calculating the\nacquisition function values of the unobserved points on this client, thereby\nreducing the risk of leaking the information about the solution to be sampled.\nIn addition, since the predicted objective values of each client may contain\nsensitive information, we mask the objective values with Diffie-Hellmann-based\nnoise, and then send only the masked objective values of other clients to the\nselected client via the server. Since the calculation of the acquisition\nfunction also requires both the predicted objective value and the uncertainty\nof the prediction, the predicted mean objective and uncertainty are normalized\nto reduce the influence of noise. Experimental results on a set of widely used\nmulti-objective optimization benchmarks show that the proposed algorithm can\nprotect privacy and enhance security with only negligible sacrifice in the\nperformance of federated data-driven evolutionary optimization.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Qiqi Liu",
      "Yuping Yan",
      "Peter Ligeti",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.08295"
  },
  {
    "id": "arXiv:2210.08298",
    "title": "A Myhill-Nerode Theorem for Higher-Dimensional Automata",
    "abstract": "We establish a Myhill-Nerode type theorem for higher-dimensional automata\n(HDAs), stating that a language is regular precisely if it has finite prefix\nquotient. HDAs extend standard automata with additional structure, making it\npossible to distinguish between interleavings and concurrency. We also\nintroduce deterministic HDAs and show that not all HDAs are determinizable,\nthat is, there exist regular languages that cannot be recognised by a\ndeterministic HDA. Using our theorem, we develop an internal characterisation\nof deterministic languages and also show that there exist infinitely ambiguous\nlanguages.",
    "descriptor": "",
    "authors": [
      "Uli Fahrenberg",
      "Krzysztof Ziemia\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.08298"
  },
  {
    "id": "arXiv:2210.08300",
    "title": "On depth-3 circuits and covering number: an explicit counter-example",
    "abstract": "We give a simple construction of $n\\times n$ Boolean matrices with\n$\\Omega(n^{4/3})$ zero entries that are free of $2 \\times 2$ all-zero\nsubmatrices and have covering number $O(\\log^4(n))$. This construction provides\nan explicit counterexample to a conjecture of Pudl\\'{a}k, R\\\"{o}dl and\nSavick\\'{y} and Research Problems 1.33, 4.9, 11.17 of Jukna [Boolean function\ncomplexity]. These conjectures were previously refuted by Katz using a\nprobabilistic construction.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Lianna Hambardzumyan",
      "Hamed Hatami",
      "Ndiam\u00e9 Ndiaye"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.08300"
  },
  {
    "id": "arXiv:2210.08302",
    "title": "Projective Integration Methods in the Runge-Kutta Framework and the  Extension to Adaptivity in Time",
    "abstract": "Projective Integration methods are explicit time integration schemes for\nstiff ODEs with large spectral gaps. In this paper, we show that all existing\nProjective Integration methods can be written as Runge-Kutta methods with an\nextended Butcher tableau including many stages. We prove consistency and order\nconditions of the Projective Integration methods using the Runge-Kutta\nframework. Spatially adaptive Projective Integration methods are included via\npartitioned Runge-Kutta methods. New time adaptive Projective Integration\nschemes are derived via embedded Runge-Kutta methods and step size variation\nwhile their stability, convergence, and error estimators are investigated\nnumerically.",
    "descriptor": "",
    "authors": [
      "Julian Koellermeier",
      "Giovanni Samaey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08302"
  },
  {
    "id": "arXiv:2210.08303",
    "title": "Improving Radiology Summarization with Radiograph and Anatomy Prompts",
    "abstract": "The impression is crucial for the referring physicians to grasp key\ninformation since it is concluded from the findings and reasoning of\nradiologists. To alleviate the workload of radiologists and reduce repetitive\nhuman labor in impression writing, many researchers have focused on automatic\nimpression generation. However, recent works on this task mainly summarize the\ncorresponding findings and pay less attention to the radiology images. In\nclinical, radiographs can provide more detailed valuable observations to\nenhance radiologists' impression writing, especially for complicated cases.\nBesides, each sentence in findings usually focuses on single anatomy, so they\nonly need to be matched to corresponding anatomical regions instead of the\nwhole image, which is beneficial for textual and visual features alignment.\nTherefore, we propose a novel anatomy-enhanced multimodal model to promote\nimpression generation. In detail, we first construct a set of rules to extract\nanatomies and put these prompts into each sentence to highlight anatomy\ncharacteristics. Then, two separate encoders are applied to extract features\nfrom the radiograph and findings. Afterward, we utilize a contrastive learning\nmodule to align these two representations at the overall level and use a\nco-attention to fuse them at the sentence level with the help of\nanatomy-enhanced sentence representation. Finally, the decoder takes the fused\ninformation as the input to generate impressions. The experimental results on\ntwo benchmark datasets confirm the effectiveness of the proposed method, which\nachieves state-of-the-art results.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jinpeng Hu",
      "Zhihong Chen",
      "Yang Liu",
      "Xiang Wan",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08303"
  },
  {
    "id": "arXiv:2210.08305",
    "title": "PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning  of Point Clouds",
    "abstract": "Digital neuron reconstruction from 3D microscopy images is an essential\ntechnique for investigating brain connectomics and neuron morphology. Existing\nreconstruction frameworks use convolution-based segmentation networks to\npartition the neuron from noisy backgrounds before applying the tracing\nalgorithm. The tracing results are sensitive to the raw image quality and\nsegmentation accuracy. In this paper, we propose a novel framework for 3D\nneuron reconstruction. Our key idea is to use the geometric representation\npower of the point cloud to better explore the intrinsic structural information\nof neurons. Our proposed framework adopts one graph convolutional network to\npredict the neural skeleton points and another one to produce the connectivity\nof these points. We finally generate the target SWC file through the\ninterpretation of the predicted point coordinates, radius, and connections.\nEvaluated on the Janelia-Fly dataset from the BigNeuron project, we show that\nour framework achieves competitive neuron reconstruction performance. Our\ngeometry and topology learning of point clouds could further benefit 3D medical\nimage analysis, such as cardiac surface reconstruction.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Runkai Zhao",
      "Heng Wang",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08305"
  },
  {
    "id": "arXiv:2210.08307",
    "title": "MoRSE: Deep Learning-based Arm Gesture Recognition for Search and Rescue  Operations",
    "abstract": "Efficient and quick remote communication in search and rescue operations can\nbe life-saving for the first responders. However, while operating on the field\nmeans of communication based on text, image and audio are not suitable for\nseveral disaster scenarios. In this paper, we present a smartwatch-based\napplication, which utilizes a Deep Learning (DL) model, to recognize a set of\npredefined arm gestures, maps them into Morse code via vibrations enabling\nremote communication amongst first responders. The model performance was\nevaluated by training it using 4,200 gestures performed by 7 subjects\n(cross-validation) wearing a smartwatch on their dominant arm. Our DL model\nrelies on convolutional pooling and surpasses the performance of existing DL\napproaches and common machine learning classifiers, obtaining gesture\nrecognition accuracy above 95%. We conclude by discussing the results and\nproviding future directions.",
    "descriptor": "\nComments: Accepted for presentation in the IEEE 8th World Forum on Internet of Things\n",
    "authors": [
      "Panagiotis Kasnesis",
      "Christos Chatzigeorgiou",
      "Dimitrios G. Kogias",
      "Charalampos Z. Patrikakis",
      "Harris V. Georgiou",
      "Aspasia Tzeletopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08307"
  },
  {
    "id": "arXiv:2210.08308",
    "title": "Coupling chemotaxis and growth poromechanics for the modelling of  feather primordia patterning",
    "abstract": "We propose a new mathematical model for the interaction of skin cell\npopulations with fibroblast growth factor and bone morphogenetic protein,\noccurring within deformable porous media. The equations for feather primordia\npattering are based on the work by K.J. Painter et al. [J. Theoret. Biol., 437\n(2018) 225--238]. We perform a linear stability analysis to identify relevant\nparameters in the coupling mechanisms, focusing in the regime of infinitesimal\nstrains. We also extend the model to the case of nonlinear poroelasticity and\ninclude solid growth by means of Lee decompositions of the deformation\ngradient. We present a few illustrative computational examples in 2D and 3D,\nand briefly discuss the design of tailored efficient solvers.",
    "descriptor": "\nComments: 25 pages, 9 figures\n",
    "authors": [
      "Nicol\u00e1s A. Barnafi",
      "Luis Miguel De Oliveira Vilaca",
      "Michel C. Milinkovitch",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08308"
  },
  {
    "id": "arXiv:2210.08316",
    "title": "Call Graph Evolution Analytics over a Version Series of an Evolving  Software System",
    "abstract": "Call Graph evolution analytics can aid a software engineer when maintaining\nor evolving a software system. This paper proposes Call Graph Evolution\nAnalytics to extract information from an evolving call graph ECG = CG_1,\nCG_2,... CG_N for their version series VS = V_1, V_2, ... V_N of an evolving\nsoftware system. This is done using Call Graph Evolution Rules (CGERs) and Call\nGraph Evolution Subgraphs (CGESs). Similar to association rule mining, the\nCGERs are used to capture co-occurrences of dependencies in the system. Like\nsubgraph patterns in a call graph, the CGESs are used to capture evolution of\ndependency patterns in evolving call graphs. Call graph analytics on the\nevolution in these patterns can identify potentially affected dependencies (or\nprocedure calls) that need attention. The experiments are done on the evolving\ncall graphs of 10 large evolving systems to support dependency evolution\nmanagement. We also consider results from a detailed study for evolving call\ngraphs of Maven-Core's version series.",
    "descriptor": "",
    "authors": [
      "Animesh Chaturvedi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.08316"
  },
  {
    "id": "arXiv:2210.08318",
    "title": "CoRe: An Automated Pipeline for The Prediction of Liver Resection  Complexity from Preoperative CT Scans",
    "abstract": "Surgical resections are the most prevalent curative treatment for primary\nliver cancer. Tumors located in critical positions are known to complexify\nliver resections (LR). While experienced surgeons in specialized medical\ncenters may have the necessary expertise to accurately anticipate LR\ncomplexity, and prepare accordingly, an objective method able to reproduce this\nbehavior would have the potential to improve the standard routine of care, and\navoid intra- and postoperative complications. In this article, we propose CoRe,\nan automated medical image processing pipeline for the prediction of\npostoperative LR complexity from preoperative CT scans, using imaging\nbiomarkers. The CoRe pipeline first segments the liver, lesions, and vessels\nwith two deep learning networks. The liver vasculature is then pruned based on\na topological criterion to define the hepatic central zone (HCZ), a convex\nvolume circumscribing the major liver vessels, from which a new imaging\nbiomarker, BHCZ is derived. Additional biomarkers are extracted and leveraged\nto train and evaluate a LR complexity prediction model. An ablation study shows\nthe HCZ-based biomarker as the central feature in predicting LR complexity. The\nbest predictive model reaches an accuracy, F1, and AUC of 77.3, 75.4, and 84.1%\nrespectively.",
    "descriptor": "\nComments: Accepted by the MIABID workshop at MICCAI 2022\n",
    "authors": [
      "Omar Ali",
      "Alexandre Bone",
      "Caterina Accardo",
      "Omar Belkouchi",
      "Marc-Michel Rohe",
      "Eric Vibert",
      "Irene Vignon-Clementel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08318"
  },
  {
    "id": "arXiv:2210.08319",
    "title": "A Scalable Reinforcement Learning Approach for Attack Allocation in  Swarm to Swarm Engagement Problems",
    "abstract": "In this work we propose a reinforcement learning (RL) framework that controls\nthe density of a large-scale swarm for engaging with adversarial swarm attacks.\nAlthough there is a significant amount of existing work in applying artificial\nintelligence methods to swarm control, analysis of interactions between two\nadversarial swarms is a rather understudied area. Most of the existing work in\nthis subject develop strategies by making hard assumptions regarding the\nstrategy and dynamics of the adversarial swarm. Our main contribution is the\nformulation of the swarm to swarm engagement problem as a Markov Decision\nProcess and development of RL algorithms that can compute engagement strategies\nwithout the knowledge of strategy/dynamics of the adversarial swarm. Simulation\nresults show that the developed framework can handle a wide array of\nlarge-scale engagement scenarios in an efficient manner.",
    "descriptor": "\nComments: submitted to ICRA 2023\n",
    "authors": [
      "Umut Demir",
      "Nazim Kemal Ure"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08319"
  },
  {
    "id": "arXiv:2210.08321",
    "title": "Construction Repetition Reduces Information Rate in Dialogue",
    "abstract": "Speakers repeat constructions frequently in dialogue. Due to their peculiar\ninformation-theoretic properties, repetitions can be thought of as a strategy\nfor cost-effective communication. In this study, we focus on the repetition of\nlexicalised constructions -- i.e., recurring multi-word units -- in English\nopen-domain spoken dialogues. We hypothesise that speakers use construction\nrepetition to mitigate information rate, leading to an overall decrease in\nutterance information content over the course of a dialogue. We conduct a\nquantitative analysis, measuring the information content of constructions and\nthat of their containing utterances, estimating information content with an\nadaptive neural language model. We observe that construction usage lowers the\ninformation content of utterances. This facilitating effect (i) increases\nthroughout dialogues, (ii) is boosted by repetition, (iii) grows as a function\nof repetition frequency and density, and (iv) is stronger for repetitions of\nreferential constructions.",
    "descriptor": "\nComments: In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (AACL-IJCNLP 2022)\n",
    "authors": [
      "Mario Giulianelli",
      "Arabella Sinclair",
      "Raquel Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08321"
  },
  {
    "id": "arXiv:2210.08323",
    "title": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) methods can generally be categorized into\ntwo types: RL-based and Imitation-based. RL-based methods could in principle\nenjoy out-of-distribution generalization but suffer from erroneous off-policy\nevaluation. Imitation-based methods avoid off-policy evaluation but are too\nconservative to surpass the dataset. In this study, we propose an alternative\napproach, inheriting the training stability of imitation-style methods while\nstill allowing logical out-of-distribution generalization. We decompose the\nconventional reward-maximizing policy in offline RL into a guide-policy and an\nexecute-policy. During training, the guide-poicy and execute-policy are learned\nusing only data from the dataset, in a supervised and decoupled manner. During\nevaluation, the guide-policy guides the execute-policy by telling where it\nshould go so that the reward can be maximized, serving as the \\textit{Prophet}.\nBy doing so, our algorithm allows \\textit{state-compositionality} from the\ndataset, rather than \\textit{action-compositionality} conducted in prior\nimitation-style methods. We dumb this new approach Policy-guided Offline RL\n(\\texttt{POR}). \\texttt{POR} demonstrates the state-of-the-art performance on\nD4RL, a standard benchmark for offline RL. We also highlight the benefits of\n\\texttt{POR} in terms of improving with supplementary suboptimal data and\neasily adapting to new tasks by only changing the guide-poicy.",
    "descriptor": "\nComments: NeurIPS 2022, code at this https URL\n",
    "authors": [
      "Haoran Xu",
      "Li Jiang",
      "Jianxiong Li",
      "Xianyuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08323"
  },
  {
    "id": "arXiv:2210.08331",
    "title": "Combination Of Convolution Neural Networks And Deep Neural Networks For  Fake News Detection",
    "abstract": "Nowadays, People prefer to follow the latest news on social media, as it is\ncheap, easily accessible, and quickly disseminated. However, it can spread fake\nor unreliable, low-quality news that intentionally contains false information.\nThe spread of fake news can have a negative effect on people and society. Given\nthe seriousness of such a problem, researchers did their best to identify\npatterns and characteristics that fake news may exhibit to design a system that\ncan detect fake news before publishing. In this paper, we have described the\nFake News Challenge stage #1 (FNC-1) dataset and given an overview of the\ncompetitive attempts to build a fake news detection system using the FNC-1\ndataset. The proposed model was evaluated with the FNC-1 dataset. A competitive\ndataset is considered an open problem and a challenge worldwide. This system's\nprocedure implies processing the text in the headline and body text columns\nwith different natural language processing techniques. After that, the\nextracted features are reduced using the elbow truncated method, finding the\nsimilarity between each pair using the soft cosine similarity method. The new\nfeature is entered into CNN and DNN deep learning approaches. The proposed\nsystem detects all the categories with high accuracy except the disagree\ncategory. As a result, the system achieves up to 84.6 % accuracy, classifying\nit as the second ranking based on other competitive studies regarding this\ndataset.",
    "descriptor": "",
    "authors": [
      "Zainab A. Jawad",
      "Ahmed J. Obaid"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08331"
  },
  {
    "id": "arXiv:2210.08332",
    "title": "Code Recommendation for Open Source Software Developers",
    "abstract": "Open Source Software (OSS) is forming the spines of technology\ninfrastructures, attracting millions of talents to contribute. Notably, it is\nchallenging and critical to consider both the developers' interests and the\nsemantic features of the project code to recommend appropriate development\ntasks to OSS developers. In this paper, we formulate the novel problem of code\nrecommendation, whose purpose is to predict the future contribution behaviors\nof developers given their interaction history, the semantic features of source\ncode, and the hierarchical file structures of projects. Considering the complex\ninteractions among multiple parties within the system, we propose CODER, a\nnovel graph-based code recommendation framework for open source software\ndevelopers. CODER jointly models microscopic user-code interactions and\nmacroscopic user-project interactions via a heterogeneous graph and further\nbridges the two levels of information through aggregation on file-structure\ngraphs that reflect the project hierarchy. Moreover, due to the lack of\nreliable benchmarks, we construct three large-scale datasets to facilitate\nfuture research in this direction. Extensive experiments show that our CODER\nframework achieves superior performance under various experimental settings,\nincluding intra-project, cross-project, and cold-start recommendation. We will\nrelease all the datasets, code, and utilities for data retrieval upon the\nacceptance of this work.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Yiqiao Jin",
      "Yunsheng Bai",
      "Yanqiao Zhu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08332"
  },
  {
    "id": "arXiv:2210.08335",
    "title": "NOMA Made Practical: Removing the Receive SIC Processing through  Interference Exploitation",
    "abstract": "Non-orthogonal multiple access (NOMA) is a powerful transmission technique\nthat enhances the spectral efficiency of communication links, and is being\ninvestigated for 5G standards and beyond. A major drawback of NOMA is the need\nto apply successive interference cancellation (SIC) at the receiver on a\nsymbol-by-symbol basis, which limits its practicality. To circumvent this, in\nthis paper a novel constructive multiple access (CoMA) scheme is proposed and\ninvestigated. CoMA aligns the superimposed signals to the different users\nconstructively to the signal of interest. Since the superimposed signal aligns\nwith the data signal, there is no need to remove it at the receiver using SIC.\nAccordingly, SIC component can be removed at the receiver side. In this regard\nand in order to provide a comprehensive investigation and comparison, different\noptimization problems for user paring NOMA multiple-input-single-output (MISO)\nsystems are considered. Firstly, an optimal precoder to minimize the total\ntransmission power for CoMA subject to a quality-of-service constraint is\nobtained, and compared to conventional NOMA. Then, a precoder that minimizes\nthe CoMA symbol error rate (SER) subject to power constraint is investigated.\nFurther, the computational complexity of CoMA is considered and compared with\nconventional NOMA scheme in terms of total number of complex operations. The\nresults in this paper prove the superiority of the proposed CoMA scheme over\nthe conventional NOMA technique, and demonstrate that CoMA is an attractive\nsolution for user paring NOMA MISO systems with low number of BS antennas,\nwhile circumventing the receive SIC complexity.",
    "descriptor": "",
    "authors": [
      "Abdelhamid Salem",
      "Xiao Tong",
      "Ang Li",
      "Christos Masouros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08335"
  },
  {
    "id": "arXiv:2210.08336",
    "title": "DProtoNet: Decoupling the inference module and the explanation module  enables neural networks to have better accuracy and interpretability",
    "abstract": "The interpretation of decisions made by neural networks is the focus of\nrecent research. In the previous method, by modifying the architecture of the\nneural network, the network simulates the human reasoning process, that is, by\nfinding the decision elements to make decisions, so that the network has the\ninterpretability of the reasoning process. The specific interpretable\narchitecture will limit the fitting space of the network, resulting in a\ndecrease in the classification performance of the network, unstable\nconvergence, and general interpretability. We propose DProtoNet (Decoupling\nPrototypical network), it stores the decision basis of the neural network by\nusing feature masks, and it uses Multiple Dynamic Masks (MDM) to explain the\ndecision basis for feature mask retention. It decouples the neural network\ninference module from the interpretation module, and removes the specific\narchitectural limitations of the interpretable network, so that the\ndecision-making architecture of the network retains the original network\narchitecture as much as possible, making the neural network more expressive,\nand greatly improving the interpretability. Classification performance and\ninterpretability of explanatory networks. We propose to replace the prototype\nlearning of a single image with the prototype learning of multiple images,\nwhich makes the prototype robust, improves the convergence speed of network\ntraining, and makes the accuracy of the network more stable during the learning\nprocess. We test on multiple datasets, DProtoNet can improve the accuracy of\nrecent advanced interpretable network models by 5% to 10%, and its\nclassification performance is comparable to that of backbone networks without\ninterpretability. It also achieves the state of the art in interpretability\nperformance.",
    "descriptor": "",
    "authors": [
      "Yitao Peng",
      "Yihang Liu",
      "Longzhen Yang",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08336"
  },
  {
    "id": "arXiv:2210.08338",
    "title": "Fair Effect Attribution in Parallel Online Experiments",
    "abstract": "A/B tests serve the purpose of reliably identifying the effect of changes\nintroduced in online services. It is common for online platforms to run a large\nnumber of simultaneous experiments by splitting incoming user traffic randomly\nin treatment and control groups. Despite a perfect randomization between\ndifferent groups, simultaneous experiments can interact with each other and\ncreate a negative impact on average population outcomes such as engagement\nmetrics. These are measured globally and monitored to protect overall user\nexperience. Therefore, it is crucial to measure these interaction effects and\nattribute their overall impact in a fair way to the respective experimenters.\nWe suggest an approach to measure and disentangle the effect of simultaneous\nexperiments by providing a cost sharing approach based on Shapley values. We\nalso provide a counterfactual perspective, that predicts shared impact based on\nconditional average treatment effects making use of causal inference\ntechniques. We illustrate our approach in real world and synthetic data\nexperiments.",
    "descriptor": "\nComments: Published as this https URL\n",
    "authors": [
      "Alexander Buchholz",
      "Vito Bellini",
      "Giuseppe Di Benedetto",
      "Yannik Stein",
      "Matteo Ruffini",
      "Fabian Moerchen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.08338"
  },
  {
    "id": "arXiv:2210.08339",
    "title": "Reachable Polyhedral Marching (RPM): An Exact Analysis Tool for  Deep-Learned Control Systems",
    "abstract": "We present a tool for computing exact forward and backward reachable sets of\ndeep neural networks with rectified linear unit (ReLU) activation. We then\ndevelop algorithms using this tool to compute invariant sets and regions of\nattraction (ROAs) for control systems with neural networks in the feedback\nloop. Our algorithm is unique in that it builds the reachable sets by\nincrementally enumerating polyhedral regions in the input space, rather than\niterating layer-by-layer through the network as in other methods. When\nperforming safety verification, if an unsafe region is found, our algorithm can\nreturn this result without completing the full reachability computation, thus\ngiving an anytime property that accelerates safety verification. Furthermore,\nwe introduce a method to accelerate the computation of ROAs in the case that\ndeep learned components are homeomorphisms, which we find is surprisingly\ncommon in practice. We demonstrate our tool in several test cases. We compute a\nROA for a learned van der Pol oscillator model. We find a control invariant set\nfor a learned torque-controlled pendulum model. We also verify specific safety\nproperties for multiple deep networks related to the ACAS Xu aircraft collision\nadvisory system. Finally, we apply our algorithm to find ROAs for an\nimage-based aircraft runway taxi problem. Algorithm source code:\nhttps://github.com/StanfordMSL/Neural-Network-Reach .",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Joseph A. Vincent",
      "Mac Schwager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08339"
  },
  {
    "id": "arXiv:2210.08340",
    "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI  Revolution",
    "abstract": "Neuroscience has long been an important driver of progress in artificial\nintelligence (AI). We propose that to accelerate progress in AI, we must invest\nin fundamental research in NeuroAI.",
    "descriptor": "\nComments: White paper, 8 pages + 3 pages of references, 0 figures\n",
    "authors": [
      "Anthony Zador",
      "Blake Richards",
      "Bence \u00d6lveczky",
      "Sean Escola",
      "Yoshua Bengio",
      "Kwabena Boahen",
      "Matthew Botvinick",
      "Dmitri Chklovskii",
      "Anne Churchland",
      "Claudia Clopath",
      "James DiCarlo",
      "Surya Ganguli",
      "Jeff Hawkins",
      "Konrad Koerding",
      "Alexei Koulakov",
      "Yann LeCun",
      "Timothy Lillicrap",
      "Adam Marblestone",
      "Bruno Olshausen",
      "Alexandre Pouget",
      "Cristina Savin",
      "Terrence Sejnowski",
      "Eero Simoncelli",
      "Sara Solla",
      "David Sussillo",
      "Andreas S. Tolias",
      "Doris Tsao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.08340"
  },
  {
    "id": "arXiv:2210.08342",
    "title": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "abstract": "Physical law learning is the ambiguous attempt at automating the derivation\nof governing equations with the use of machine learning techniques. The current\nliterature focuses however solely on the development of methods to achieve this\ngoal, and a theoretical foundation is at present missing. This paper shall thus\nserve as a first step to build a comprehensive theoretical framework for\nlearning physical laws, aiming to provide reliability to according algorithms.\nOne key problem consists in the fact that the governing equations might not be\nuniquely determined by the given data. We will study this problem in the common\nsituation of having a physical law be described by an ordinary or partial\ndifferential equation. For various different classes of differential equations,\nwe provide both necessary and sufficient conditions for a function from a given\nfunction class to uniquely determine the differential equation which is\ngoverning the phenomenon. We then use our results to devise numerical\nalgorithms to determine whether a function solves a differential equation\nuniquely. Finally, we provide extensive numerical experiments showing that our\nalgorithms in combination with common approaches for learning physical laws\nindeed allow to guarantee that a unique governing differential equation is\nlearnt, without assuming any knowledge about the function, thereby ensuring\nreliability.",
    "descriptor": "",
    "authors": [
      "Philipp Scholl",
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08342"
  },
  {
    "id": "arXiv:2210.08343",
    "title": "Modular machine learning-based elastoplasticity: generalization in the  context of limited data",
    "abstract": "The development of accurate constitutive models for materials that undergo\npath-dependent processes continues to be a complex challenge in computational\nsolid mechanics. Challenges arise both in considering the appropriate model\nassumptions and from the viewpoint of data availability, verification, and\nvalidation. Recently, data-driven modeling approaches have been proposed that\naim to establish stress-evolution laws that avoid user-chosen functional forms\nby relying on machine learning representations and algorithms. However, these\napproaches not only require a significant amount of data but also need data\nthat probes the full stress space with a variety of complex loading paths.\nFurthermore, they rarely enforce all necessary thermodynamic principles as hard\nconstraints. Hence, they are in particular not suitable for low-data or\nlimited-data regimes, where the first arises from the cost of obtaining the\ndata and the latter from the experimental limitations of obtaining labeled\ndata, which is commonly the case in engineering applications. In this work, we\ndiscuss a hybrid framework that can work on a variable amount of data by\nrelying on the modularity of the elastoplasticity formulation where each\ncomponent of the model can be chosen to be either a classical phenomenological\nor a data-driven model depending on the amount of available information and the\ncomplexity of the response. The method is tested on synthetic uniaxial data\ncoming from simulations as well as cyclic experimental data for structural\nmaterials. The discovered material models are found to not only interpolate\nwell but also allow for accurate extrapolation in a thermodynamically\nconsistent manner far outside the domain of the training data. Training aspects\nand details of the implementation of these models into Finite Element\nsimulations are discussed and analyzed.",
    "descriptor": "\nComments: 36 pages, 25 figures\n",
    "authors": [
      "Jan N. Fuhg",
      "Craig M. Hamel",
      "Kyle Johnson",
      "Reese Jones",
      "Nikolaos Bouklas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.08343"
  },
  {
    "id": "arXiv:2210.08344",
    "title": "How Mask Matters: Towards Theoretical Understandings of Masked  Autoencoders",
    "abstract": "Masked Autoencoders (MAE) based on a reconstruction task have risen to be a\npromising paradigm for self-supervised learning (SSL) and achieve\nstate-of-the-art performance across different benchmark datasets. However,\ndespite its impressive empirical success, there is still limited theoretical\nunderstanding of it. In this paper, we propose a theoretical understanding of\nhow masking matters for MAE to learn meaningful features. We establish a close\nconnection between MAE and contrastive learning, which shows that MAE implicit\naligns the mask-induced positive pairs. Built upon this connection, we develop\nthe first downstream guarantees for MAE methods, and analyze the effect of mask\nratio. Besides, as a result of the implicit alignment, we also point out the\ndimensional collapse issue of MAE, and propose a Uniformity-enhanced MAE\n(U-MAE) loss that can effectively address this issue and bring significant\nimprovements on real-world datasets, including CIFAR-10, ImageNet-100, and\nImageNet-1K. Code is available at (https://github.com/zhangq327/U-MAE).",
    "descriptor": "",
    "authors": [
      "Qi Zhang",
      "Yifei Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08344"
  },
  {
    "id": "arXiv:2210.08345",
    "title": "Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative  Representations",
    "abstract": "The pretasks are mainly built on mutual information estimation, which\nrequires data augmentation to construct positive samples with similar semantics\nto learn invariant signals and negative samples with dissimilar semantics in\norder to empower representation discriminability. However, an appropriate data\naugmentation configuration depends heavily on lots of empirical trials such as\nchoosing the compositions of data augmentation techniques and the corresponding\nhyperparameter settings. We propose an augmentation-free graph contrastive\nlearning method, invariant-discriminative graph contrastive learning (iGCL),\nthat does not intrinsically require negative samples. iGCL designs the\ninvariant-discriminative loss (ID loss) to learn invariant and discriminative\nrepresentations. On the one hand, ID loss learns invariant signals by directly\nminimizing the mean square error between the target samples and positive\nsamples in the representation space. On the other hand, ID loss ensures that\nthe representations are discriminative by an orthonormal constraint forcing the\ndifferent dimensions of representations to be independent of each other. This\nprevents representations from collapsing to a point or subspace. Our\ntheoretical analysis explains the effectiveness of ID loss from the\nperspectives of the redundancy reduction criterion, canonical correlation\nanalysis, and information bottleneck principle. The experimental results\ndemonstrate that iGCL outperforms all baselines on 5 node classification\nbenchmark datasets. iGCL also shows superior performance for different label\nratios and is capable of resisting graph attacks, which indicates that iGCL has\nexcellent generalization and robustness.",
    "descriptor": "\nComments: 11 pages 8 figs\n",
    "authors": [
      "Haifeng Li",
      "Jun Cao",
      "Jiawei Zhu",
      "Qinyao Luo",
      "Silu He",
      "Xuyin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08345"
  },
  {
    "id": "arXiv:2210.08347",
    "title": "Mini-Batch Learning Strategies for modeling long term temporal  dependencies: A study in environmental applications",
    "abstract": "In many environmental applications, recurrent neural networks (RNNs) are\noften used to model physical variables with long temporal dependencies.\nHowever, due to mini-batch training, temporal relationships between training\nsegments within the batch (intra-batch) as well as between batches\n(inter-batch) are not considered, which can lead to limited performance.\nStateful RNNs aim to address this issue by passing hidden states between\nbatches. Since Stateful RNNs ignore intra-batch temporal dependency, there\nexists a trade-off between training stability and capturing temporal\ndependency. In this paper, we provide a quantitative comparison of different\nStateful RNN modeling strategies, and propose two strategies to enforce both\nintra- and inter-batch temporal dependency. First, we extend Stateful RNNs by\ndefining a batch as a temporally ordered set of training segments, which\nenables intra-batch sharing of temporal information. While this approach\nsignificantly improves the performance, it leads to much larger training times\ndue to highly sequential training. To address this issue, we further propose a\nnew strategy which augments a training segment with an initial value of the\ntarget variable from the timestep right before the starting of the training\nsegment. In other words, we provide an initial value of the target variable as\nadditional input so that the network can focus on learning changes relative to\nthat initial value. By using this strategy, samples can be passed in any order\n(mini-batch training) which significantly reduces the training time while\nmaintaining the performance. In demonstrating our approach in hydrological\nmodeling, we observe that the most significant gains in predictive accuracy\noccur when these methods are applied to state variables whose values change\nmore slowly, such as soil water and snowpack, rather than continuously moving\nflux variables such as streamflow.",
    "descriptor": "\nComments: submitted to SIAM International Conference on Data Mining (SDM23)\n",
    "authors": [
      "Shaoming Xu",
      "Ankush Khandelwal",
      "Xiang Li",
      "Xiaowei Jia",
      "Licheng Liu",
      "Jared Willard",
      "Rahul Ghosh",
      "Kelly Cutler",
      "Michael Steinbach",
      "Christopher Duffy",
      "John Nieber",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08347"
  },
  {
    "id": "arXiv:2210.08349",
    "title": "When to Update Your Model: Constrained Model-based Reinforcement  Learning",
    "abstract": "Designing and analyzing model-based RL (MBRL) algorithms with guaranteed\nmonotonic improvement has been challenging, mainly due to the interdependence\nbetween policy optimization and model learning. Existing discrepancy bounds\ngenerally ignore the impacts of model shifts, and their corresponding\nalgorithms are prone to degrade performance by drastic model updating. In this\nwork, we first propose a novel and general theoretical scheme for a\nnon-decreasing performance guarantee of MBRL. Our follow-up derived bounds\nreveal the relationship between model shifts and performance improvement. These\ndiscoveries encourage us to formulate a constrained lower-bound optimization\nproblem to permit the monotonicity of MBRL. A further example demonstrates that\nlearning models from a dynamically-varying number of explorations benefit the\neventual returns. Motivated by these analyses, we design a simple but effective\nalgorithm CMLO (Constrained Model-shift Lower-bound Optimization), by\nintroducing an event-triggered mechanism that flexibly determines when to\nupdate the model. Experiments show that CMLO surpasses other state-of-the-art\nmethods and produces a boost when various policy optimization methods are\nemployed.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Tianying Ji",
      "Yu Luo",
      "Fuchun Sun",
      "Mingxuan Jing",
      "Fengxiang He",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08349"
  },
  {
    "id": "arXiv:2210.08350",
    "title": "Self-Improving SLAM in Dynamic Environments: Learning When to Mask",
    "abstract": "Visual SLAM -- Simultaneous Localization and Mapping -- in dynamic\nenvironments typically relies on identifying and masking image features on\nmoving objects to prevent them from negatively affecting performance. Current\napproaches are suboptimal: they either fail to mask objects when needed or, on\nthe contrary, mask objects needlessly. Thus, we propose a novel SLAM that\nlearns when masking objects improves its performance in dynamic scenarios.\nGiven a method to segment objects and a SLAM, we give the latter the ability of\nTemporal Masking, i.e., to infer when certain classes of objects should be\nmasked to maximize any given SLAM metric. We do not make any priors on motion:\nour method learns to mask moving objects by itself. To prevent high annotations\ncosts, we created an automatic annotation method for self-supervised training.\nWe constructed a new dataset, named ConsInv, which includes challenging\nreal-world dynamic sequences respectively indoors and outdoors. Our method\nreaches the state of the art on the TUM RGB-D dataset and outperforms it on\nKITTI and ConsInv datasets.",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Adrian Bojko",
      "Romain Dupont",
      "Mohamed Tamaazousti",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08350"
  },
  {
    "id": "arXiv:2210.08353",
    "title": "MGNNI: Multiscale Graph Neural Networks with Implicit Layers",
    "abstract": "Recently, implicit graph neural networks (GNNs) have been proposed to capture\nlong-range dependencies in underlying graphs. In this paper, we introduce and\njustify two weaknesses of implicit GNNs: the constrained expressiveness due to\ntheir limited effective range for capturing long-range dependencies, and their\nlack of ability to capture multiscale information on graphs at multiple\nresolutions. To show the limited effective range of previous implicit GNNs, We\nfirst provide a theoretical analysis and point out the intrinsic relationship\nbetween the effective range and the convergence of iterative equations used in\nthese models. To mitigate the mentioned weaknesses, we propose a multiscale\ngraph neural network with implicit layers (MGNNI) which is able to model\nmultiscale structures on graphs and has an expanded effective range for\ncapturing long-range dependencies. We conduct comprehensive experiments for\nboth node classification and graph classification to show that MGNNI\noutperforms representative baselines and has a better ability for multiscale\nmodeling and capturing of long-range dependencies.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Juncheng Liu",
      "Bryan Hooi",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08353"
  },
  {
    "id": "arXiv:2210.08355",
    "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse  Parsing",
    "abstract": "To promote and further develop RST-style discourse parsing models, we need a\nstrong baseline that can be regarded as a reference for reporting reliable\nexperimental results. This paper explores a strong baseline by integrating\nexisting simple parsing strategies, top-down and bottom-up, with various\ntransformer-based pre-trained language models. The experimental results\nobtained from two benchmark datasets demonstrate that the parsing performance\nstrongly relies on the pretrained language models rather than the parsing\nstrategies. In particular, the bottom-up parser achieves large performance\ngains compared to the current best parser when employing DeBERTa. We further\nreveal that language models with a span-masking scheme especially boost the\nparsing performance through our analysis within intra- and multi-sentential\nparsing, and nuclearity prediction.",
    "descriptor": "\nComments: Accepted in Findings of EMNLP 2022\n",
    "authors": [
      "Naoki Kobayashi",
      "Tsutomu Hirao",
      "Hidetaka Kamigaito",
      "Manabu Okumura",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08355"
  },
  {
    "id": "arXiv:2210.08356",
    "title": "HUDD: A tool to debug DNNs for safety analysis",
    "abstract": "We present HUDD, a tool that supports safety analysis practices for systems\nenabled by Deep Neural Networks (DNNs) by automatically identifying the root\ncauses for DNN errors and retraining the DNN. HUDD stands for Heatmap-based\nUnsupervised Debugging of DNNs, it automatically clusters error-inducing images\nwhose results are due to common subsets of DNN neurons. The intent is for the\ngenerated clusters to group error-inducing images having common\ncharacteristics, that is, having a common root cause. HUDD identifies root\ncauses by applying a clustering algorithm to matrices (i.e., heatmaps)\ncapturing the relevance of every DNN neuron on the DNN outcome. Also, HUDD\nretrains DNNs with images that are automatically selected based on their\nrelatedness to the identified image clusters. Our empirical evaluation with\nDNNs from the automotive domain have shown that HUDD automatically identifies\nall the distinct root causes of DNN errors, thus supporting safety analysis.\nAlso, our retraining approach has shown to be more effective at improving DNN\naccuracy than existing approaches. A demo video of HUDD is available at\nhttps://youtu.be/drjVakP7jdU.",
    "descriptor": "\nComments: 5 pages, 3 figures, 1 table. arXiv admin note: text overlap with arXiv:2002.00863\n",
    "authors": [
      "Hazem Fahmy",
      "Fabrizio Pastore",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08356"
  },
  {
    "id": "arXiv:2210.08359",
    "title": "The Influence of Multiple Classes on Learning Online Classifiers from  Imbalanced and Concept Drifting Data Streams",
    "abstract": "This work is aimed at the experimental studying the influence of local data\ncharacteristics and drifts on the difficulties of learning various online\nclassifiers from multi-class imbalanced data streams. Firstly we present a\ncategorization of these data factors and drifts in the context of imbalanced\nstreams, then we introduce the generators of synthetic streams that model these\nfactors and drifts. The results of many experiments with synthetically\ngenerated data streams have shown a much greater role of the overlapping\nbetween many minority classes (the type of borderline examples) than for\nstreams with one minority class. The presence of rare examples in the stream is\nthe most difficult single factor. The local drift of splitting minority classes\nis the third influential factor. Unlike binary streams, the specialized UOB and\nOOB classifiers perform well enough for even high imbalance ratios. The most\nchallenging for all classifiers are complex scenarios integrating the drifts of\nthe identified factors simultaneously, which worsen the evaluation measures in\nthe case of a several minority classes stronger than for binary ones. This is\nan extended version of the short paper presented at LIDTA'2022 workshop at\nECMLPKDD2022.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Agnieszka Lipska",
      "Jerzy Stefanowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08359"
  },
  {
    "id": "arXiv:2210.08360",
    "title": "MIXER: Multiattribute, Multiway Fusion of Uncertain Pairwise Affinities",
    "abstract": "We present a multiway fusion algorithm capable of directly processing\nuncertain pairwise affinities. In contrast to existing works that require\ninitial pairwise associations, our MIXER algorithm improves accuracy by\nleveraging the additional information provided by pairwise affinities. Our main\ncontribution is a multiway fusion formulation that is particularly suited to\nprocessing non-binary affinities and a novel continuous relaxation whose\nsolutions are guaranteed to be binary, thus avoiding the typical, but\npotentially problematic, solution binarization steps that may cause\ninfeasibility. A crucial insight of our formulation is that it allows for three\nmodes of association, ranging from non-match, undecided, and match. Exploiting\nthis insight allows fusion to be delayed for some data pairs until more\ninformation is available, which is an effective feature for fusion of data with\nmultiple attributes/information sources. We evaluate MIXER on typical synthetic\ndata and benchmark datasets and show increased accuracy against the state of\nthe art in multiway matching, especially in noisy regimes with low observation\nredundancy. Additionally, we collect RGB data of cars in a parking lot to\ndemonstrate MIXER's ability to fuse data having multiple attributes (color,\nvisual appearance, and bounding box). On this challenging dataset, MIXER\nachieves 74% F1 accuracy and is 49x faster than the next best algorithm, which\nhas 42% accuracy.",
    "descriptor": "\nComments: 8 pages + proofs\n",
    "authors": [
      "Parker C. Lusk",
      "Kaveh Fathian",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08360"
  },
  {
    "id": "arXiv:2210.08361",
    "title": "A Nearly Optimal Size Coreset Algorithm with Nearly Linear Time",
    "abstract": "A coreset is a point set containing information about geometric properties of\na larger point set. A series of previous works show that in many machine\nlearning problems, especially in clustering problems, coreset could be very\nuseful to build efficient algorithms. Two main measures of an coreset\nconstruction algorithm's performance are the running time of the algorithm and\nthe size of the coreset output by the algorithm. In this paper we study the\nconstruction of coresets for the $(k,z)$-clustering problem, which is a\ngeneralization of $k$-means and $k$-median problem. By properly designing a\nsketching-based distance estimation data structure, we propose faster\nalgorithms that construct coresets with matching size of the state-of-the-art\nresults.",
    "descriptor": "",
    "authors": [
      "Yichuan Deng",
      "Zhao Song",
      "Yitan Wang",
      "Yuanyuan Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.08361"
  },
  {
    "id": "arXiv:2210.08362",
    "title": "PAR: Political Actor Representation Learning with Social Context and  Expert Knowledge",
    "abstract": "Modeling the ideological perspectives of political actors is an essential\ntask in computational political science with applications in many downstream\ntasks. Existing approaches are generally limited to textual data and voting\nrecords, while they neglect the rich social context and valuable expert\nknowledge for holistic ideological analysis. In this paper, we propose\n\\textbf{PAR}, a \\textbf{P}olitical \\textbf{A}ctor \\textbf{R}epresentation\nlearning framework that jointly leverages social context and expert knowledge.\nSpecifically, we retrieve and extract factual statements about legislators to\nleverage social context information. We then construct a heterogeneous\ninformation network to incorporate social context and use relational graph\nneural networks to learn legislator representations. Finally, we train PAR with\nthree objectives to align representation learning with expert knowledge, model\nideological stance consistency, and simulate the echo chamber phenomenon.\nExtensive experiments demonstrate that PAR is better at augmenting political\ntext understanding and successfully advances the state-of-the-art in political\nperspective detection and roll call vote prediction. Further analysis proves\nthat PAR learns representations that reflect the political reality and provide\nnew insights into political behavior.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Zilong Chen",
      "Ningnan Wang",
      "Peisheng Yu",
      "Qinghua Zheng",
      "Xiaojun Chang",
      "Minnan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08362"
  },
  {
    "id": "arXiv:2210.08363",
    "title": "Data-Efficient Augmentation for Training Neural Networks",
    "abstract": "Data augmentation is essential to achieve state-of-the-art performance in\nmany deep learning applications. However, the most effective augmentation\ntechniques become computationally prohibitive for even medium-sized datasets.\nTo address this, we propose a rigorous technique to select subsets of data\npoints that when augmented, closely capture the training dynamics of full data\naugmentation. We first show that data augmentation, modeled as additive\nperturbations, improves learning and generalization by relatively enlarging and\nperturbing the smaller singular values of the network Jacobian, while\npreserving its prominent directions. This prevents overfitting and enhances\nlearning the harder to learn information. Then, we propose a framework to\niteratively extract small subsets of training data that when augmented, closely\ncapture the alignment of the fully augmented Jacobian with labels/residuals. We\nprove that stochastic gradient descent applied to the augmented subsets found\nby our approach has similar training dynamics to that of fully augmented data.\nOur experiments demonstrate that our method achieves 6.3x speedup on CIFAR10\nand 2.2x speedup on SVHN, and outperforms the baselines by up to 10% across\nvarious subset sizes. Similarly, on TinyImageNet and ImageNet, our method beats\nthe baselines by up to 8%, while achieving up to 3.3x speedup across various\nsubset sizes. Finally, training on and augmenting 50% subsets using our method\non a version of CIFAR10 corrupted with label noise even outperforms using the\nfull dataset.",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08363"
  },
  {
    "id": "arXiv:2210.08367",
    "title": "Active Learning with Neural Networks: Insights from Nonparametric  Statistics",
    "abstract": "Deep neural networks have great representation power, but typically require\nlarge numbers of training examples. This motivates deep active learning methods\nthat can significantly reduce the amount of labeled training data. Empirical\nsuccesses of deep active learning have been recently reported in the\nliterature, however, rigorous label complexity guarantees of deep active\nlearning have remained elusive. This constitutes a significant gap between\ntheory and practice. This paper tackles this gap by providing the first\nnear-optimal label complexity guarantees for deep active learning. The key\ninsight is to study deep active learning from the nonparametric classification\nperspective. Under standard low noise conditions, we show that active learning\nwith neural networks can provably achieve the minimax label complexity, up to\ndisagreement coefficient and other logarithmic terms. When equipped with an\nabstention option, we further develop an efficient deep active learning\nalgorithm that achieves $\\mathsf{polylog}(\\frac{1}{\\epsilon})$ label\ncomplexity, without any low noise assumptions. We also provide extensions of\nour results beyond the commonly studied Sobolev/H\\\"older spaces and develop\nlabel complexity guarantees for learning in Radon $\\mathsf{BV}^2$ spaces, which\nhave recently been proposed as natural function spaces associated with neural\nnetworks.",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Yinglun Zhu",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08367"
  },
  {
    "id": "arXiv:2210.08371",
    "title": "Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth  Channel and Vulnerability",
    "abstract": "Sketching is one of the most fundamental tools in large-scale machine\nlearning. It enables runtime and memory saving via randomly compressing the\noriginal large problem onto lower dimensions. In this paper, we propose a novel\nsketching scheme for the first order method in large-scale distributed learning\nsetting, such that the communication costs between distributed agents are saved\nwhile the convergence of the algorithms is still guaranteed. Given gradient\ninformation in a high dimension $d$, the agent passes the compressed\ninformation processed by a sketching matrix $R\\in \\R^{s\\times d}$ with $s\\ll\nd$, and the receiver de-compressed via the de-sketching matrix $R^\\top$ to\n``recover'' the information in original dimension. Using such a framework, we\ndevelop algorithms for federated learning with lower communication costs.\nHowever, such random sketching does not protect the privacy of local data\ndirectly. We show that the gradient leakage problem still exists after applying\nthe sketching technique by showing a specific gradient attack method. As a\nremedy, we prove rigorously that the algorithm will be differentially private\nby adding additional random noises in gradient information, which results in a\nboth communication-efficient and differentially private first order approach\nfor federated learning tasks. Our sketching scheme can be further generalized\nto other learning settings and might be of independent interest itself.",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Yitan Wang",
      "Zheng Yu",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08371"
  },
  {
    "id": "arXiv:2210.08372",
    "title": "An Efficient and Decentralized Blockchain-based Commercial Alternative  (Full Version)",
    "abstract": "While online interactions and exchanges have grown exponentially over the\npast decade, most commercial infrastructures still operate through centralized\nprotocols, and their success essentially depends on trust between different\neconomic actors. Digital advances such as blockchain technology has led to a\nmassive wave of \\textit{Decentralized Ledger Technology} (\\textit{DLT})\ninitiatives, protocols and solutions. This advance makes it possible to\nimplement trustless systems in the real world, which, combined with appropriate\neconomic and participatory incentives, would foster the proper functioning and\ndrive the adoption of a decentralized platform among different actors. This\npaper describes an alternative to current commercial structures and networks by\nintroducing \\textit{Lyzis Labs}, which is is an incentive-driven and democratic\nprotocol designed to support a decentralized online marketplace, based on\nblockchain technology. The proposal, \\textit{Lyzis Marketplace}, allows to\nconnect two or more people in a decentralized and secure way without having to\nrely on a \\textit{Trusted Third Party} (\\textit{TTP}) in order to perform\nphysical asset exchanges while mainly providing transparent and fully protected\ndata storage. This approach can potentially lead to the creation of a\npermissionless, efficient, secure and transparent business environment where\neach user can gain purchasing and decision-making power by supporting the\ncollective welfare while following their personal interests during their\nvarious interactions on the network.",
    "descriptor": "\nComments: 62 pages, 9 figures, 19 tables\n",
    "authors": [
      "Marwan Zeggari",
      "Renaud Lambiotte",
      "Aydin Abadi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.08372"
  },
  {
    "id": "arXiv:2210.08374",
    "title": "How security professionals are being attacked: A study of malicious CVE  proof of concept exploits in GitHub",
    "abstract": "Proof-of-concept (PoC) of exploits for known vulnerabilities are widely\nshared in the security community. They help security analysts to learn from\neach other and they facilitate security assessments and red teaming tasks. In\nthe recent years, PoCs have been widely distributed, e.g., via dedicated\nwebsites and platforms, and also via public code repositories like GitHub.\nHowever, public code repositories do not provide any guarantees that any given\nPoC comes from a trustworthy source, or even that it simply does exactly what\nit is supposed to do.\nIn this work we investigate PoCs shared on GitHub for known vulnerabilities\ndiscovered in 2017-2021. We discovered that not all PoCs are trustworthy. Some\nproof-of-concepts are fake (i.e., they do not actually offer PoC\nfunctionality), or even malicious: e.g., they attempt to exfiltrate data from\nthe system they are being run on, or they try to install malware on this\nsystem.\nTo address this issue, we have proposed an approach to detect if a PoC is\nmalicious. Our approach relies on detecting the symptoms we have observed in\nthe collected dataset, for example, calls to malicious IP addresses, encoded\nmalicious code, or included Trojanized binaries. With this approach, we have\ndiscovered 4893 malicious repository out of 47313 repositories that have been\ndownloaded and checked (i.e., 10.3% of the studied repositories have symptoms\nof malicious intent). This figure shows a worrying prevalence of dangerous\nmalicious PoCs among the exploit code distributed on GitHub.",
    "descriptor": "",
    "authors": [
      "Soufian El Yadmani",
      "Robin The",
      "Olga Gadyatskaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08374"
  },
  {
    "id": "arXiv:2210.08375",
    "title": "Improving the Intra-class Long-tail in 3D Detection via Rare Example  Mining",
    "abstract": "Continued improvements in deep learning architectures have steadily advanced\nthe overall performance of 3D object detectors to levels on par with humans for\ncertain tasks and datasets, where the overall performance is mostly driven by\ncommon examples. However, even the best performing models suffer from the most\nnaive mistakes when it comes to rare examples that do not appear frequently in\nthe training data, such as vehicles with irregular geometries. Most studies in\nthe long-tail literature focus on class-imbalanced classification problems with\nknown imbalanced label counts per class, but they are not directly applicable\nto the intra-class long-tail examples in problems with large intra-class\nvariations such as 3D object detection, where instances with the same class\nlabel can have drastically varied properties such as shapes and sizes. Other\nworks propose to mitigate this problem using active learning based on the\ncriteria of uncertainty, difficulty, or diversity. In this study, we identify a\nnew conceptual dimension - rareness - to mine new data for improving the\nlong-tail performance of models. We show that rareness, as opposed to\ndifficulty, is the key to data-centric improvements for 3D detectors, since\nrareness is the result of a lack in data support while difficulty is related to\nthe fundamental ambiguity in the problem. We propose a general and effective\nmethod to identify the rareness of objects based on density estimation in the\nfeature space using flow models, and propose a principled cost-aware\nformulation for mining rare object tracks, which improves overall model\nperformance, but more importantly - significantly improves the performance for\nrare objects (by 30.97\\%",
    "descriptor": "\nComments: Accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Chiyu Max Jiang",
      "Mahyar Najibi",
      "Charles R. Qi",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08375"
  },
  {
    "id": "arXiv:2210.08376",
    "title": "Variant Parallelism: Lightweight Deep Convolutional Models for  Distributed Inference on IoT Devices",
    "abstract": "Two major techniques are commonly used to meet real-time inference\nlimitations when distributing models across resource-constrained IoT devices:\n(1) model parallelism (MP) and (2) class parallelism (CP). In MP, transmitting\nbulky intermediate data (orders of magnitude larger than input) between devices\nimposes huge communication overhead. Although CP solves this problem, it has\nlimitations on the number of sub-models. In addition, both solutions are fault\nintolerant, an issue when deployed on edge devices. We propose variant\nparallelism (VP), an ensemble-based deep learning distribution method where\ndifferent variants of a main model are generated and can be deployed on\nseparate machines. We design a family of lighter models around the original\nmodel, and train them simultaneously to improve accuracy over single models.\nOur experimental results on six common mid-sized object recognition datasets\ndemonstrate that our models can have 5.8-7.1x fewer parameters, 4.3-31x fewer\nmultiply-accumulations (MACs), and 2.5-13.2x less response time on atomic\ninputs compared to MobileNetV2 while achieving comparable or higher accuracy.\nOur technique easily generates several variants of the base architecture. Each\nvariant returns only 2k outputs 1 <= k <= (#classes/2), representing Top-k\nclasses, instead of tons of floating point values required in MP. Since each\nvariant provides a full-class prediction, our approach maintains higher\navailability compared with MP and CP in presence of failure.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Navidreza Asadi",
      "Maziar Goudarzi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08376"
  },
  {
    "id": "arXiv:2210.08384",
    "title": "Revisiting the Roles of \"Text\" in Text Games",
    "abstract": "Text games present opportunities for natural language understanding (NLU)\nmethods to tackle reinforcement learning (RL) challenges. However, recent work\nhas questioned the necessity of NLU by showing random text hashes could perform\ndecently. In this paper, we pursue a fine-grained investigation into the roles\nof text in the face of different RL challenges, and reconcile that semantic and\nnon-semantic language representations could be complementary rather than\ncontrasting. Concretely, we propose a simple scheme to extract relevant\ncontextual information into an approximate state hash as extra input for an\nRNN-based text agent. Such a lightweight plug-in achieves competitive\nperformance with state-of-the-art text agents using advanced NLU techniques\nsuch as knowledge graph and passage retrieval, suggesting non-NLU methods might\nsuffice to tackle the challenge of partial observability. However, if we remove\nRNN encoders and use approximate or even ground-truth state hash alone, the\nmodel performs miserably, which confirms the importance of semantic function\napproximation to tackle the challenge of combinatorially large observation and\naction spaces. Our findings and analysis provide new insights for designing\nbetter text game task setups and agents.",
    "descriptor": "",
    "authors": [
      "Yi Gu",
      "Shunyu Yao",
      "Chuang Gan",
      "Joshua B. Tenenbaum",
      "Mo Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08384"
  },
  {
    "id": "arXiv:2210.08388",
    "title": "RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy  Medical Imaging",
    "abstract": "AI-powered Medical Imaging has recently achieved enormous attention due to\nits ability to provide fast-paced healthcare diagnoses. However, it usually\nsuffers from a lack of high-quality datasets due to high annotation cost,\ninter-observer variability, human annotator error, and errors in\ncomputer-generated labels. Deep learning models trained on noisy labelled\ndatasets are sensitive to the noise type and lead to less generalization on the\nunseen samples. To address this challenge, we propose a Robust Stochastic\nKnowledge Distillation (RoS-KD) framework which mimics the notion of learning a\ntopic from multiple sources to ensure deterrence in learning noisy information.\nMore specifically, RoS-KD learns a smooth, well-informed, and robust student\nmanifold by distilling knowledge from multiple teachers trained on overlapping\nsubsets of training data. Our extensive experiments on popular medical imaging\nclassification tasks (cardiopulmonary disease and lesion classification) using\nreal-world datasets, show the performance benefit of RoS-KD, its ability to\ndistill knowledge from many popular large networks (ResNet-50, DenseNet-121,\nMobileNet-V2) in a comparatively small network, and its robustness to\nadversarial attacks (PGD, FSGM). More specifically, RoS-KD achieves >2% and >4%\nimprovement on F1-score for lesion classification and cardiopulmonary disease\nclassification tasks, respectively, when the underlying student is ResNet-18\nagainst recent competitive knowledge distillation baseline. Additionally, on\ncardiopulmonary disease classification task, RoS-KD outperforms most of the\nSOTA baselines by ~1% gain in AUC score.",
    "descriptor": "\nComments: Accepted in ICDM 2022\n",
    "authors": [
      "Ajay Jaiswal",
      "Kumar Ashutosh",
      "Justin F Rousseau",
      "Yifan Peng",
      "Zhangyang Wang",
      "Ying Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08388"
  },
  {
    "id": "arXiv:2210.08389",
    "title": "Semantic Video Moments Retrieval at Scale: A New Task and a Baseline",
    "abstract": "Motivated by the increasing need of saving search effort by obtaining\nrelevant video clips instead of whole videos, we propose a new task, named\nSemantic Video Moments Retrieval at scale (SVMR), which aims at finding\nrelevant videos coupled with re-localizing the video clips in them. Instead of\na simple combination of video retrieval and video re-localization, our task is\nmore challenging because of several essential aspects. In the 1st stage, our\nSVMR should take into account the fact that: 1) a positive candidate long video\ncan contain plenty of irrelevant clips which are also semantically meaningful.\n2) a long video can be positive to two totally different query clips if it\ncontains clips relevant to two queries. The 2nd re-localization stage also\nexhibits different assumptions from existing video re-localization tasks, which\nhold an assumption that the reference video must contain semantically similar\nsegments corresponding to the query clip. Instead, in our scenario, the\nretrieved long video can be a false positive one due to the inaccuracy of the\nfirst stage. To address these challenges, we propose our two-stage baseline\nsolution of candidate videos retrieval followed by a novel attention-based\nquery-reference semantically alignment framework to re-localize target clips\nfrom candidate videos. Furthermore, we build two more appropriate benchmark\ndatasets from the off-the-shelf ActivityNet-1.3 and HACS for a thorough\nevaluation of SVMR models. Extensive experiments are carried out to show that\nour solution outperforms several reference solutions.",
    "descriptor": "",
    "authors": [
      "Na Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08389"
  },
  {
    "id": "arXiv:2210.08390",
    "title": "SOCIALMAPF: Optimal and Efficient Multi-Agent Path Finding with  Strategic Agents for Social Navigation",
    "abstract": "We propose an extension to the MAPF formulation, called SocialMAPF, to\naccount for private incentives of agents in constrained environments such as\ndoorways, narrow hallways, and corridor intersections. SocialMAPF is able to,\nfor instance, accurately reason about the urgent incentive of an agent rushing\nto the hospital over another agent's less urgent incentive of going to a\ngrocery store; MAPF ignores such agent-specific incentives. Our proposed\nformulation addresses the open problem of optimal and efficient path planning\nfor agents with private incentives. To solve SocialMAPF, we propose a new class\nof algorithms that use mechanism design during conflict resolution to\nsimultaneously optimize agents' private local utilities and the global system\nobjective. We perform an extensive array of experiments that show that optimal\nsearch-based MAPF techniques lead to collisions and increased time-to-goal in\nSocialMAPF compared to our proposed method using mechanism design. Furthermore,\nwe empirically demonstrate that mechanism design results in models that\nmaximizes agent utility and minimizes the overall time-to-goal of the entire\nsystem. We further showcase the capabilities of mechanism design-based planning\nby successfully deploying it in environments with static obstacles. To\nconclude, we briefly list several research directions using the SocialMAPF\nformulation, such as exploring motion planning in the continuous domain for\nagents with private incentives.",
    "descriptor": "\nComments: Full paper submission to R-AL. Shorter Blue Sky paper version available at AIHRI/2022/1016\n",
    "authors": [
      "Rohan Chandra",
      "Rahul Maligi",
      "Arya Anantula",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08390"
  },
  {
    "id": "arXiv:2210.08391",
    "title": "Video in 10 Bits: Few-Bit VideoQA for Efficiency and Privacy",
    "abstract": "In Video Question Answering (VideoQA), answering general questions about a\nvideo requires its visual information. Yet, video often contains redundant\ninformation irrelevant to the VideoQA task. For example, if the task is only to\nanswer questions similar to \"Is someone laughing in the video?\", then all other\ninformation can be discarded. This paper investigates how many bits are really\nneeded from the video in order to do VideoQA by introducing a novel Few-Bit\nVideoQA problem, where the goal is to accomplish VideoQA with few bits of video\ninformation (e.g., 10 bits). We propose a simple yet effective task-specific\nfeature compression approach to solve this problem. Specifically, we insert a\nlightweight Feature Compression Module (FeatComp) into a VideoQA model which\nlearns to extract task-specific tiny features as little as 10 bits, which are\noptimal for answering certain types of questions. We demonstrate more than\n100,000-fold storage efficiency over MPEG4-encoded videos and 1,000-fold over\nregular floating point features, with just 2.0-6.6% absolute loss in accuracy,\nwhich is a surprising and novel finding. Finally, we analyze what the learned\ntiny features capture and demonstrate that they have eliminated most of the\nnon-task-specific information, and introduce a Bit Activation Map to visualize\nwhat information is being stored. This decreases the privacy risk of data by\nproviding k-anonymity and robustness to feature-inversion techniques, which can\ninfluence the machine learning community, allowing us to store data with\nprivacy guarantees while still performing the task effectively.",
    "descriptor": "\nComments: ECCV Workshop 2023\n",
    "authors": [
      "Shiyuan Huang",
      "Robinson Piramuthu",
      "Shih-Fu Chang",
      "Gunnar A. Sigurdsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08391"
  },
  {
    "id": "arXiv:2210.08392",
    "title": "The Effects of Partitioning Strategies on Energy Consumption in  Distributed CNN Inference at The Edge",
    "abstract": "Nowadays, many AI applications utilizing resource-constrained edge devices\n(e.g., small mobile robots, tiny IoT devices, etc.) require Convolutional\nNeural Network (CNN) inference on a distributed system at the edge due to\nlimited resources of a single edge device to accommodate and execute a large\nCNN. There are four main partitioning strategies that can be utilized to\npartition a large CNN model and perform distributed CNN inference on multiple\ndevices at the edge. However, to the best of our knowledge, no research has\nbeen conducted to investigate how these four partitioning strategies affect the\nenergy consumption per edge device. Such an investigation is important because\nit will reveal the potential of these partitioning strategies to be used\neffectively for reduction of the per-device energy consumption when a large CNN\nmodel is deployed for distributed inference at the edge. Therefore, in this\npaper, we investigate and compare the per-device energy consumption of CNN\nmodel inference at the edge on a distributed system when the four partitioning\nstrategies are utilized. The goal of our investigation and comparison is to\nfind out which partitioning strategies (and under what conditions) have the\nhighest potential to decrease the energy consumption per edge device when CNN\ninference is performed at the edge on a distributed system.",
    "descriptor": "",
    "authors": [
      "Erqian Tang",
      "Xiaotian Guo",
      "Todor Stefanov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08392"
  },
  {
    "id": "arXiv:2210.08394",
    "title": "mRI: Multi-modal 3D Human Pose Estimation Dataset using mmWave, RGB-D,  and Inertial Sensors",
    "abstract": "The ability to estimate 3D human body pose and movement, also known as human\npose estimation (HPE), enables many applications for home-based health\nmonitoring, such as remote rehabilitation training. Several possible solutions\nhave emerged using sensors ranging from RGB cameras, depth sensors,\nmillimeter-Wave (mmWave) radars, and wearable inertial sensors. Despite\nprevious efforts on datasets and benchmarks for HPE, few dataset exploits\nmultiple modalities and focuses on home-based health monitoring. To bridge the\ngap, we present mRI, a multi-modal 3D human pose estimation dataset with\nmmWave, RGB-D, and Inertial Sensors. Our dataset consists of over 160k\nsynchronized frames from 20 subjects performing rehabilitation exercises and\nsupports the benchmarks of HPE and action detection. We perform extensive\nexperiments using our dataset and delineate the strength of each modality. We\nhope that the release of mRI can catalyze the research in pose estimation,\nmulti-modal learning, and action understanding, and more importantly facilitate\nthe applications of home-based health monitoring.",
    "descriptor": "\nComments: Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022). Project page: this https URL\n",
    "authors": [
      "Sizhe An",
      "Yin Li",
      "Umit Ogras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08394"
  },
  {
    "id": "arXiv:2210.08397",
    "title": "Taxonomy of A Decision Support System for Adaptive Experimental Design  in Field Robotics",
    "abstract": "Experimental design in field robotics is an adaptive human-in-the-loop\ndecision-making process in which an experimenter learns about system\nperformance and limitations through interactions with a robot in the form of\nconstructed experiments. This can be challenging because of system complexity,\nthe need to operate in unstructured environments, and the competing objectives\nof maximizing information gain while simultaneously minimizing experimental\ncosts. Based on the successes in other domains, we propose the use of a\nDecision Support System (DSS) to amplify the human's decision-making abilities,\novercome their inherent shortcomings, and enable principled decision-making in\nfield experiments. In this work, we propose common terminology and a six-stage\ntaxonomy of DSSs specifically for adaptive experimental design of more\ninformative tests and reduced experimental costs. We construct and present our\ntaxonomy using examples and trends from DSS literature, including works\ninvolving artificial intelligence and Intelligent DSSs. Finally, we identify\ncritical technical gaps and opportunities for future research to direct the\nscientific community in the pursuit of next-generation DSSs for experimental\ndesign.",
    "descriptor": "\nComments: 10 pages, 3 figures, presented at the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022\n",
    "authors": [
      "Jason M. Gregory",
      "Sarah Al-Hussaini",
      "Ali-akbar Agha-mohammadi",
      "Satyandra K. Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08397"
  },
  {
    "id": "arXiv:2210.08398",
    "title": "SPIDR: SDF-based Neural Point Fields for Illumination and Deformation",
    "abstract": "Implicit neural representations such as neural radiance fields (NeRFs) have\nrecently emerged as a promising approach for 3D reconstruction and novel view\nsynthesis. However, NeRF-based methods encode shape, reflectance, and\nillumination implicitly in their neural representations, and this makes it\nchallenging for users to manipulate these properties in the rendered images\nexplicitly. Existing approaches only enable limited editing of the scene and\ndeformation of the geometry. Furthermore, no existing work enables accurate\nscene illumination after object deformation. In this work, we introduce SPIDR,\na new hybrid neural SDF representation. SPIDR combines point cloud and neural\nimplicit representations to enable the reconstruction of higher quality meshes\nand surfaces for object deformation and lighting estimation. To more accurately\ncapture environment illumination for scene relighting, we propose a novel\nneural implicit model to learn environment light. To enable accurate\nillumination updates after deformation, we use the shadow mapping technique to\nefficiently approximate the light visibility updates caused by geometry\nediting. We demonstrate the effectiveness of SPIDR in enabling high quality\ngeometry editing and deformation with accurate updates to the illumination of\nthe scene. In comparison to prior work, we demonstrate significantly better\nrendering quality after deformation and lighting estimation.",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Ruofan Liang",
      "Jiahao Zhang",
      "Haoda Li",
      "Chen Yang",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.08398"
  },
  {
    "id": "arXiv:2210.08399",
    "title": "Tensor-Train Compression of Discrete Element Method Simulation Data",
    "abstract": "We propose a framework for discrete scientific data compression based on the\ntensor-train (TT) decomposition. Our approach is tailored to handle\nunstructured output data from discrete element method (DEM) simulations,\ndemonstrating its effectiveness in compressing both raw (e.g. particle position\nand velocity) and derived (e.g. stress and strain) datasets. We show that\ngeometry-driven \"tensorization\" coupled with the TT decomposition (known as\nquantized TT) yields a hierarchical compression scheme, achieving high\ncompression ratios for key variables in these DEM datasets.",
    "descriptor": "",
    "authors": [
      "Saibal De",
      "Eduardo Corona",
      "Paramsothy Jayakumar",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08399"
  },
  {
    "id": "arXiv:2210.08400",
    "title": "A multilevel reinforcement learning framework for PDE based control",
    "abstract": "Reinforcement learning (RL) is a promising method to solve control problems.\nHowever, model-free RL algorithms are sample inefficient and require thousands\nif not millions of samples to learn optimal control policies. A major source of\ncomputational cost in RL corresponds to the transition function, which is\ndictated by the model dynamics. This is especially problematic when model\ndynamics is represented with coupled PDEs. In such cases, the transition\nfunction often involves solving a large-scale discretization of the said PDEs.\nWe propose a multilevel RL framework in order to ease this cost by exploiting\nsublevel models that correspond to coarser scale discretization (i.e.\nmultilevel models). This is done by formulating an approximate multilevel Monte\nCarlo estimate of the objective function of the policy and / or value network\ninstead of Monte Carlo estimates, as done in the classical framework. As a\ndemonstration of this framework, we present a multilevel version of the\nproximal policy optimization (PPO) algorithm. Here, the level refers to the\ngrid fidelity of the chosen simulation-based environment. We provide two\nexamples of simulation-based environments that employ stochastic PDEs that are\nsolved using finite-volume discretization. For the case studies presented, we\nobserved substantial computational savings using multilevel PPO compared to its\nclassical counterpart.",
    "descriptor": "\nComments: In preparation for submission to a journal\n",
    "authors": [
      "Atish Dixit",
      "Ahmed Elsheikh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08400"
  },
  {
    "id": "arXiv:2210.08402",
    "title": "LAION-5B: An open large-scale dataset for training next generation  image-text models",
    "abstract": "Groundbreaking language-vision architectures like CLIP and DALL-E proved the\nutility of training on large amounts of noisy image-text data, without relying\non expensive accurate labels used in standard vision unimodal supervised\nlearning. The resulting models showed capabilities of strong text-guided image\ngeneration and transfer to downstream tasks, while performing remarkably at\nzero-shot classification with noteworthy out-of-distribution robustness. Since\nthen, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and\nImagen made further improvements. Studying the training and capabilities of\nsuch models requires datasets containing billions of image-text pairs. Until\nnow, no datasets of this size have been made openly available for the broader\nresearch community. To address this problem and democratize research on\nlarge-scale multi-modal models, we present LAION-5B - a dataset consisting of\n5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English\nlanguage. We show successful replication and fine-tuning of foundational models\nlike CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further\nexperiments enabled with an openly available dataset of this scale.\nAdditionally we provide several nearest neighbor indices, an improved\nweb-interface for dataset exploration and subset generation, and detection\nscores for watermark, NSFW, and toxic content detection. Announcement page\nhttps://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022), Track on Datasets and Benchmarks. OpenReview: this https URL\n",
    "authors": [
      "Christoph Schuhmann",
      "Romain Beaumont",
      "Richard Vencu",
      "Cade Gordon",
      "Ross Wightman",
      "Mehdi Cherti",
      "Theo Coombes",
      "Aarush Katta",
      "Clayton Mullis",
      "Mitchell Wortsman",
      "Patrick Schramowski",
      "Srivatsa Kundurthy",
      "Katherine Crowson",
      "Ludwig Schmidt",
      "Robert Kaczmarczyk",
      "Jenia Jitsev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08402"
  },
  {
    "id": "arXiv:2210.08403",
    "title": "Semantic Segmentation with Active Semi-Supervised Representation  Learning",
    "abstract": "Obtaining human per-pixel labels for semantic segmentation is incredibly\nlaborious, often making labeled dataset construction prohibitively expensive.\nHere, we endeavor to overcome this problem with a novel algorithm that combines\nsemi-supervised and active learning, resulting in the ability to train an\neffective semantic segmentation algorithm with significantly lesser labeled\ndata. To do this, we extend the prior state-of-the-art S4AL algorithm by\nreplacing its mean teacher approach for semi-supervised learning with a\nself-training approach that improves learning with noisy labels. We further\nboost the neural network's ability to query useful data by adding a contrastive\nlearning head, which leads to better understanding of the objects in the scene,\nand hence, better queries for active learning. We evaluate our method on CamVid\nand CityScapes datasets, the de-facto standards for active learning for\nsemantic segmentation. We achieve more than 95% of the network's performance on\nCamVid and CityScapes datasets, utilizing only 12.1% and 15.1% of the labeled\ndata, respectively. We also benchmark our method across existing stand-alone\nsemi-supervised learning methods on the CityScapes dataset and achieve superior\nperformance without any bells or whistles.",
    "descriptor": "\nComments: To appear in the British Machine Vision Conference (BMVC-2022)\n",
    "authors": [
      "Aneesh Rangnekar",
      "Christopher Kanan",
      "Matthew Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08403"
  },
  {
    "id": "arXiv:2210.08404",
    "title": "Using Answer Set Programming for HPC Dependency Solving",
    "abstract": "Modern scientific software stacks have become extremely complex, using many\nprogramming models and libraries to exploit a growing variety of GPUs and\naccelerators. Package managers can mitigate this complexity using dependency\nsolvers, but they are reaching their limits. Finding compatible dependency\nversions is NP-complete, and modeling the semantics of package compatibility\nmodulo build-time options, GPU runtimes, flags, and other parameters is\nextremely difficult. Within this enormous configuration space, defining a\n\"good\" configuration is daunting.\nWe tackle this problem using Answer Set Programming (ASP), a declarative\nmodel for combinatorial search problems. We show, using the Spack package\nmanager, that ASP programs can concisely express the compatibility rules of HPC\nsoftware stacks and provide strong quality-of-solution guarantees. Using ASP,\nwe can mix new builds with preinstalled binaries, and solver performance is\nacceptable even when considering tens of thousands of packages.",
    "descriptor": "",
    "authors": [
      "Todd Gamblin",
      "Massimiliano Culpo",
      "Gregory Becker",
      "Sergei Shudler"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.08404"
  },
  {
    "id": "arXiv:2210.08405",
    "title": "Non-Transferability in Communication Channels and Tarski's Truth Theorem",
    "abstract": "This article is about the transferability issues in communication channels. I\nproved that there are situations in communication channels that are not\ntransferable. Also, I showed that a communication channel that wants to\ntransmit its error situation is in a non-transferable situation. I justify the\nsimilarities that exist between the non-transferability in communication\nchannels and Tarski's Truth Undefinability Theorem. This new perspective gives\nus more expressive power on the other aspects of this famous theorem.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Farhad Naderian"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08405"
  },
  {
    "id": "arXiv:2210.08408",
    "title": "Learning-based Motion Planning in Dynamic Environments Using GNNs and  Temporal Encoding",
    "abstract": "Learning-based methods have shown promising performance for accelerating\nmotion planning, but mostly in the setting of static environments. For the more\nchallenging problem of planning in dynamic environments, such as multi-arm\nassembly tasks and human-robot interaction, motion planners need to consider\nthe trajectories of the dynamic obstacles and reason about temporal-spatial\ninteractions in very large state spaces. We propose a GNN-based approach that\nuses temporal encoding and imitation learning with data aggregation for\nlearning both the embeddings and the edge prioritization policies. Experiments\nshow that the proposed methods can significantly accelerate online planning\nover state-of-the-art complete dynamic planning algorithms. The learned models\ncan often reduce costly collision checking operations by more than 1000x, and\nthus accelerating planning by up to 95%, while achieving high success rates on\nhard instances as well.",
    "descriptor": "",
    "authors": [
      "Ruipeng Zhang",
      "Chenning Yu",
      "Jingkai Chen",
      "Chuchu Fan",
      "Sicun Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08408"
  },
  {
    "id": "arXiv:2210.08410",
    "title": "End-to-End Learning to Index and Search in Large Output Spaces",
    "abstract": "Extreme multi-label classification (XMC) is a popular framework for solving\nmany real-world problems that require accurate prediction from a very large\nnumber of potential output choices. A popular approach for dealing with the\nlarge label space is to arrange the labels into a shallow tree-based index and\nthen learn an ML model to efficiently search this index via beam search.\nExisting methods initialize the tree index by clustering the label space into a\nfew mutually exclusive clusters based on pre-defined features and keep it fixed\nthroughout the training procedure. This approach results in a sub-optimal\nindexing structure over the label space and limits the search performance to\nthe quality of choices made during the initialization of the index. In this\npaper, we propose a novel method ELIAS which relaxes the tree-based index to a\nspecialized weighted graph-based index which is learned end-to-end with the\nfinal task objective. More specifically, ELIAS models the discrete\ncluster-to-label assignments in the existing tree-based index as soft learnable\nparameters that are learned jointly with the rest of the ML model. ELIAS\nachieves state-of-the-art performance on several large-scale extreme\nclassification benchmarks with millions of labels. In particular, ELIAS can be\nup to 2.5% better at precision@1 and up to 4% better at recall@100 than\nexisting XMC methods. A PyTorch implementation of ELIAS along with other\nresources is available at https://github.com/nilesh2797/ELIAS.",
    "descriptor": "\nComments: 21 pages, 9 figures, NeurIPS 2022 camera-ready publication\n",
    "authors": [
      "Nilesh Gupta",
      "Patrick H. Chen",
      "Hsiang-Fu Yu",
      "Cho-Jui Hsieh",
      "Inderjit S Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08410"
  },
  {
    "id": "arXiv:2210.08412",
    "title": "Towards an Interpretable Hierarchical Agent Framework using Semantic  Goals",
    "abstract": "Learning to solve long horizon temporally extended tasks with reinforcement\nlearning has been a challenge for several years now. We believe that it is\nimportant to leverage both the hierarchical structure of complex tasks and to\nuse expert supervision whenever possible to solve such tasks. This work\nintroduces an interpretable hierarchical agent framework by combining planning\nand semantic goal directed reinforcement learning. We assume access to certain\nspatial and haptic predicates and construct a simple and powerful semantic goal\nspace. These semantic goal representations are more interpretable, making\nexpert supervision and intervention easier. They also eliminate the need to\nwrite complex, dense reward functions thereby reducing human engineering\neffort. We evaluate our framework on a robotic block manipulation task and show\nthat it performs better than other methods, including both sparse and dense\nreward functions. We also suggest some next steps and discuss how this\nframework makes interaction and collaboration with humans easier.",
    "descriptor": "",
    "authors": [
      "Bharat Prakash",
      "Nicholas Waytowich",
      "Tim Oates",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08412"
  },
  {
    "id": "arXiv:2210.08414",
    "title": "Using Virtual Reality to Simulate Human-Robot Emergency Evacuation  Scenarios",
    "abstract": "This paper describes our recent effort to use virtual reality to simulate\nthreatening emergency evacuation scenarios in which a robot guides a person to\nan exit. Our prior work has demonstrated that people will follow a robot's\nguidance, even when the robot is faulty, during an emergency evacuation. Yet,\nbecause physical in-person emergency evacuation experiments are difficult and\ncostly to conduct and because we would like to evaluate many different factors,\nwe are motivated to develop a system that immerses people in the simulation\nenvironment to encourage genuine subject reactions. We are working to complete\nexperiments verifying the validity of our approach.",
    "descriptor": "\nComments: Accepted at AAAI Fall Symposium AI-HRI Workshop\n",
    "authors": [
      "Alan R. Wagner",
      "Colin Holbrook",
      "Daniel Holman",
      "Brett Sheeran",
      "Vidullan Surendran",
      "Jared Armagost",
      "Savanna Spazak",
      "Yinxuan Yin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08414"
  },
  {
    "id": "arXiv:2210.08415",
    "title": "Stability of Accuracy for the Training of DNNs Via the Uniform Doubling  Condition",
    "abstract": "We study the stability of accuracy for the training of deep neural networks.\nHere the training of a DNN is preformed via the minimization of a cross-entropy\nloss function and the performance metric is the accuracy (the proportion of\nobjects classified correctly). While training amounts to the decrease of loss,\nthe accuracy does not necessarily increase during the training. A recent result\nby Berlyand, Jabin and Safsten introduces a doubling condition on the training\ndata which ensures the stability of accuracy during training for DNNs with the\nabsolute value activation function. For training data in $\\R^n$, this doubling\ncondition is formulated using slabs in $\\R^n$ and it depends on the choice of\nthe slabs. The goal of this paper is twofold. First to make the doubling\ncondition uniform, that is independent on the choice of slabs leading to\nsufficient conditions for stability in terms of training data only. Second to\nextend the original stability results for the absolute value activation\nfunction to a broader class of piecewise linear activation function with\nfinitely many critical points such as the popular Leaky ReLU.",
    "descriptor": "",
    "authors": [
      "Yitzchak Shmalo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08415"
  },
  {
    "id": "arXiv:2210.08418",
    "title": "VerifyML: Obliviously Checking Model Fairness Resilient to Malicious  Model Holder",
    "abstract": "In this paper, we present VerifyML, the first secure inference framework to\ncheck the fairness degree of a given Machine learning (ML) model. VerifyML is\ngeneric and is immune to any obstruction by the malicious model holder during\nthe verification process. We rely on secure two-party computation (2PC)\ntechnology to implement VerifyML, and carefully customize a series of\noptimization methods to boost its performance for both linear and nonlinear\nlayer execution. Specifically, (1) VerifyML allows the vast majority of the\noverhead to be performed offline, thus meeting the low latency requirements for\nonline inference. (2) To speed up offline preparation, we first design novel\nhomomorphic parallel computing techniques to accelerate the authenticated\nBeaver's triple (including matrix-vector and convolution triples) generation\nprocedure. It achieves up to $1.7\\times$ computation speedup and gains at least\n$10.7\\times$ less communication overhead compared to state-of-the-art work. (3)\nWe also present a new cryptographic protocol to evaluate the activation\nfunctions of non-linear layers, which is $4\\times$--$42\\times$ faster and has\n$>48\\times$ lesser communication than existing 2PC protocol against malicious\nparties. In fact, VerifyML even beats the state-of-the-art semi-honest ML\nsecure inference system! We provide formal theoretical analysis for VerifyML\nsecurity and demonstrate its performance superiority on mainstream ML models\nincluding ResNet-18 and LeNet.",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Xingshuo Han",
      "Gelei Deng",
      "Tianwei Zhang",
      "Shengmin Xu",
      "Jianting Ning",
      "Anjia Yang",
      "Hongwei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08418"
  },
  {
    "id": "arXiv:2210.08421",
    "title": "New Secure Sparse Inner Product with Applications to Machine Learning",
    "abstract": "Sparse inner product (SIP) has the attractive property of overhead being\ndominated by the intersection of inputs between parties, independent of the\nactual input size. It has intriguing prospects, especially for boosting machine\nlearning on large-scale data, which is tangled with sparse data. In this paper,\nwe investigate privacy-preserving SIP problems that have rarely been explored\nbefore. Specifically, we propose two concrete constructs, one requiring offline\nlinear communication which can be amortized across queries, while the other has\nsublinear overhead but relies on the more computationally expensive tool. Our\napproach exploits state-of-the-art cryptography tools including garbled Bloom\nfilters (GBF) and Private Information Retrieval (PIR) as the cornerstone, but\ncarefully fuses them to obtain non-trivial overhead reductions. We provide\nformal security analysis of the proposed constructs and implement them into\nrepresentative machine learning algorithms including k-nearest neighbors, naive\nBayes classification and logistic regression. Compared to the existing efforts,\nour method achieves $2$-$50\\times$ speedup in runtime and up to $10\\times$\nreduction in communication.",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Shengmin Xu",
      "Jianting Ning",
      "Tianwei Zhang",
      "Xinyi Huang",
      "Hongwei Li",
      "Rongxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08421"
  },
  {
    "id": "arXiv:2210.08423",
    "title": "TransVisDrone: Spatio-Temporal Transformer for Vision-based  Drone-to-Drone Detection in Aerial Videos",
    "abstract": "Drone-to-drone detection using visual feed has crucial applications like\navoiding collision with other drones/airborne objects, tackling a drone attack\nor coordinating flight with other drones. However, the existing methods are\ncomputationally costly, follow a non-end-to-end optimization and have complex\nmulti-stage pipeline, which make them less suitable to deploy on edge devices\nfor real-time drone flight. In this work, we propose a simple-yet-effective\nframework TransVisDrone, which provides end-to-end solution with higher\ncomputational efficiency. We utilize CSPDarkNet-53 network to learn\nobject-related spatial features and VideoSwin model to learn the\nspatio-temporal dependencies of drone motion which improves drone detection in\nchallenging scenarios. Our method obtains state-of-the-art performance on three\nchallenging real-world datasets (Average Precision@0.5IOU): NPS 0.95, FLDrones\n0.75 and AOT 0.80. Apart from its superior performance, it achieves higher\nthroughput than the prior work. We also demonstrate its deployment capability\non edge-computing devices and usefulness in applications like drone-collision\n(encounter) detection. Code:\n\\url{https://github.com/tusharsangam/TransVisDrone}.",
    "descriptor": "",
    "authors": [
      "Tushar Sangam",
      "Ishan Rajendrakumar Dave",
      "Waqas Sultani",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08423"
  },
  {
    "id": "arXiv:2210.08424",
    "title": "A cusp-capturing PINN for elliptic interface problems",
    "abstract": "In this paper, we propose a cusp-capturing physics-informed neural network\n(PINN) to solve variable-coefficient elliptic interface problems whose solution\nis continuous but has discontinuous first derivatives on the interface. To find\nsuch a solution using neural network representation, we introduce a\ncusp-enforced level set function as an additional feature input to the network\nto retain the inherent solution properties, capturing the solution cusps (where\nthe derivatives are discontinuous) sharply. In addition, the proposed neural\nnetwork has the advantage of being mesh-free, so it can easily handle problems\nin irregular domains. We train the network using the physics-informed framework\nin which the loss function comprises the residual of the differential equation\ntogether with a certain interface and boundary conditions. We conduct a series\nof numerical experiments to demonstrate the effectiveness of the cusp-capturing\ntechnique and the accuracy of the present network model. Numerical results show\nthat even a one-hidden-layer (shallow) network with a moderate number of\nneurons ($40-60$) and sufficient training data points, the present network\nmodel can achieve high prediction accuracy (relative $L^2$ errors in the order\nof $10^{-5}-10^{-6}$), which outperforms several existing neural network models\nand traditional grid-based methods in the literature.",
    "descriptor": "",
    "authors": [
      "Yu-Hau Tseng",
      "Te-Sheng Lin",
      "Wei-Fan Hu",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08424"
  },
  {
    "id": "arXiv:2210.08425",
    "title": "A generalized scalar auxiliary variable method for the time-dependent  Ginzburg-Landau equations",
    "abstract": "This paper develops a generalized scalar auxiliary variable (SAV) method for\nthe time-dependent Ginzburg-Landau equations. The backward Euler is used for\ndiscretizing the temporal derivative of the time-dependent Ginzburg-Landau\nequations. In this method, the system is decoupled and linearized to avoid\nsolving the non-linear equation at each step. The theoretical analysis proves\nthat the generalized SAV method can preserve the maximum bound principle and\nenergy stability, which is confirmed by the numerical results. It shows that\nthe numerical algorithm is stable.",
    "descriptor": "",
    "authors": [
      "Zhiyong Si"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08425"
  },
  {
    "id": "arXiv:2210.08427",
    "title": "Shape Estimation of Continuum Robots via Modal Parameterization and Dual  Extended Kalman Filter",
    "abstract": "The equilibrium shape of a continuum robot is resulted from both its internal\nactuation and the external physical interaction with a surrounding environment.\nA fast and accurate shape estimation method (i) can be used as a feedback to\ncompensate for more accurate motion; and (ii) can reveal rich information about\nphysical interactions (e.g. instrument-anatomy contacts / forces during a\nsurgery). From a prior work that demonstrated an offline calibration of\ncontinuum robots, we adopt its shape modal representation and error propagation\nmodels that include identification Jacobians. In this work, we present an\niterative observer approach to enable online shape estimation. We develop a\ndual Extended Kalman Filter (EKF) to estimate both the robot state and the\nshape modal parameters. The dual EKF provides robust estimation on (i) the\nconfiguration space variables that are controllable and driven by internal\nactuation; and (ii) the modal coefficients representing homotopies of shape\nfamilies that are governed by the physical interactions with the environment.\nWe report results from simulation studies in this work, and plan to investigate\nmethods in the future to use the proposed approach for predicting physical\ninteractions.",
    "descriptor": "\nComments: 8 pages, submitted to 2023 American Control Conference (ACC), under review\n",
    "authors": [
      "Guoqing Zhang",
      "Long Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08427"
  },
  {
    "id": "arXiv:2210.08430",
    "title": "Explainable Causal Analysis of Mental Health on Social Media Data",
    "abstract": "With recent developments in Social Computing, Natural Language Processing and\nClinical Psychology, the social NLP research community addresses the challenge\nof automation in mental illness on social media. A recent extension to the\nproblem of multi-class classification of mental health issues is to identify\nthe cause behind the user's intention. However, multi-class causal\ncategorization for mental health issues on social media has a major challenge\nof wrong prediction due to the overlapping problem of causal explanations.\nThere are two possible mitigation techniques to solve this problem: (i)\nInconsistency among causal explanations/ inappropriate human-annotated\ninferences in the dataset, (ii) in-depth analysis of arguments and stances in\nself-reported text using discourse analysis. In this research work, we\nhypothesise that if there exists the inconsistency among F1 scores of different\nclasses, there must be inconsistency among corresponding causal explanations as\nwell. In this task, we fine tune the classifiers and find explanations for\nmulti-class causal categorization of mental illness on social media with LIME\nand Integrated Gradient (IG) methods. We test our methods with CAMS dataset and\nvalidate with annotated interpretations. A key contribution of this research\nwork is to find the reason behind inconsistency in accuracy of multi-class\ncausal categorization. The effectiveness of our methods is evident with the\nresults obtained having category-wise average scores of $81.29 \\%$ and $0.906$\nusing cosine similarity and word mover's distance, respectively.",
    "descriptor": "",
    "authors": [
      "Chandni Saxena",
      "Muskan Garg",
      "Gunjan Saxena"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08430"
  },
  {
    "id": "arXiv:2210.08431",
    "title": "Modeling Context With Linear Attention for Scalable Document-Level  Translation",
    "abstract": "Document-level machine translation leverages inter-sentence dependencies to\nproduce more coherent and consistent translations. However, these models,\npredominantly based on transformers, are difficult to scale to long documents\nas their attention layers have quadratic complexity in the sequence length.\nRecent efforts on efficient attention improve scalability, but their effect on\ndocument translation remains unexplored. In this work, we investigate the\nefficacy of a recent linear attention model by Peng et al. (2021) on document\ntranslation and augment it with a sentential gate to promote a recency\ninductive bias. We evaluate the model on IWSLT 2015 and OpenSubtitles 2018\nagainst the transformer, demonstrating substantially increased decoding speed\non long sequences with similar or better BLEU scores. We show that sentential\ngating further improves translation quality on IWSLT.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Zhaofeng Wu",
      "Hao Peng",
      "Nikolaos Pappas",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08431"
  },
  {
    "id": "arXiv:2210.08432",
    "title": "QStack: Re-architecting User-space Network Stack to Optimize CPU  Efficiency and Service Quality",
    "abstract": "TCP/IP network stack is irreplaceable for Web services in datacenter\nfront-end servers, and the demand for which is growing rapidly for emerging\nhigh concurrency network service applications (including Internet, Internet of\nThings, mobile Internet, etc.) especially. The existing network stack schemes\noften face the dilemma between the data center server resource utilization\n(i.e., high CPU efficiency) and application service quality (i.e., low tail\nlatency). We break this dilemma via a flexible architectural design QStack,\nwhich simultaneously achieves CPU efficiency and low tail latency in user-space\nnetwork stack for front-end datacenter server. QStack proposes elastic\nframework and application definable full-datapath priority, such that the\nnetwork stack collaboration among CPU cores horizontally and coordination\nacross network layers in fine grained vertically on demand. We prototype QStack\non commodity servers. Testbed experiments demonstrate the effectiveness of\nQStack over state-of-the-art user-space network stack designs.",
    "descriptor": "",
    "authors": [
      "WL Zhang",
      "YF Shen",
      "H Song",
      "Zh Zhang",
      "K Liu",
      "Q Huang",
      "MY Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.08432"
  },
  {
    "id": "arXiv:2210.08435",
    "title": "On the User Behavior Leakage from Recommender Exposure",
    "abstract": "Modern recommender systems are trained to predict users potential future\ninteractions from users historical behavior data. During the interaction\nprocess, despite the data coming from the user side recommender systems also\ngenerate exposure data to provide users with personalized recommendation\nslates. Compared with the sparse user behavior data, the system exposure data\nis much larger in volume since only very few exposed items would be clicked by\nthe user. Besides, the users historical behavior data is privacy sensitive and\nis commonly protected with careful access authorization. However, the large\nvolume of recommender exposure data usually receives less attention and could\nbe accessed within a relatively larger scope of various information seekers. In\nthis paper, we investigate the problem of user behavior leakage in recommender\nsystems. We show that the privacy sensitive user past behavior data can be\ninferred through the modeling of system exposure. Besides, one can infer which\nitems the user have clicked just from the observation of current system\nexposure for this user. Given the fact that system exposure data could be\nwidely accessed from a relatively larger scope, we believe that the user past\nbehavior privacy has a high risk of leakage in recommender systems. More\nprecisely, we conduct an attack model whose input is the current recommended\nitem slate (i.e., system exposure) for the user while the output is the user's\nhistorical behavior. Experimental results on two real-world datasets indicate a\ngreat danger of user behavior leakage. To address the risk, we propose a\ntwo-stage privacy-protection mechanism which firstly selects a subset of items\nfrom the exposure slate and then replaces the selected items with uniform or\npopularity-based exposure. Experimental evaluation reveals a trade-off effect\nbetween the recommendation accuracy and the privacy disclosure risk.",
    "descriptor": "",
    "authors": [
      "Xin Xin",
      "Jiyuan Yang",
      "Hanbing Wang",
      "Jun Ma",
      "Pengjie Ren",
      "Hengliang Luo",
      "Xinlei Shi",
      "Zhumin Chen",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08435"
  },
  {
    "id": "arXiv:2210.08442",
    "title": "Navigating Memory Construction by Global Pseudo-Task Simulation for  Continual Learning",
    "abstract": "Continual learning faces a crucial challenge of catastrophic forgetting. To\naddress this challenge, experience replay (ER) that maintains a tiny subset of\nsamples from previous tasks has been commonly used. Existing ER works usually\nfocus on refining the learning objective for each task with a static memory\nconstruction policy. In this paper, we formulate the dynamic memory\nconstruction in ER as a combinatorial optimization problem, which aims at\ndirectly minimizing the global loss across all experienced tasks. We first\napply three tactics to solve the problem in the offline setting as a starting\npoint. To provide an approximate solution to this problem in the online\ncontinual learning setting, we further propose the Global Pseudo-task\nSimulation (GPS), which mimics future catastrophic forgetting of the current\ntask by permutation. Our empirical results and analyses suggest that the GPS\nconsistently improves accuracy across four commonly used vision benchmarks. We\nhave also shown that our GPS can serve as the unified framework for integrating\nvarious memory construction policies in existing ER works.",
    "descriptor": "\nComments: Accepted by the NeurIPS 2022\n",
    "authors": [
      "Yejia Liu",
      "Wang Zhu",
      "Shaolei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08442"
  },
  {
    "id": "arXiv:2210.08443",
    "title": "CLEAR: Generative Counterfactual Explanations on Graphs",
    "abstract": "Counterfactual explanations promote explainability in machine learning models\nby answering the question \"how should an input instance be perturbed to obtain\na desired predicted label?\". The comparison of this instance before and after\nperturbation can enhance human interpretation. Most existing studies on\ncounterfactual explanations are limited in tabular data or image data. In this\nwork, we study the problem of counterfactual explanation generation on graphs.\nA few studies have explored counterfactual explanations on graphs, but many\nchallenges of this problem are still not well-addressed: 1) optimizing in the\ndiscrete and disorganized space of graphs; 2) generalizing on unseen graphs;\nand 3) maintaining the causality in the generated counterfactuals without prior\nknowledge of the causal model. To tackle these challenges, we propose a novel\nframework CLEAR which aims to generate counterfactual explanations on graphs\nfor graph-level prediction models. Specifically, CLEAR leverages a graph\nvariational autoencoder based mechanism to facilitate its optimization and\ngeneralization, and promotes causality by leveraging an auxiliary variable to\nbetter identify the underlying causal model. Extensive experiments on both\nsynthetic and real-world graphs validate the superiority of CLEAR over the\nstate-of-the-art methods in different aspects.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Jing Ma",
      "Ruocheng Guo",
      "Saumitra Mishra",
      "Aidong Zhang",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08443"
  },
  {
    "id": "arXiv:2210.08444",
    "title": "Model Criticism for Long-Form Text Generation",
    "abstract": "Language models have demonstrated the ability to generate highly fluent text;\nhowever, it remains unclear whether their output retains coherent high-level\nstructure (e.g., story progression). Here, we propose to apply a statistical\ntool, model criticism in latent space, to evaluate the high-level structure of\nthe generated text. Model criticism compares the distributions between real and\ngenerated data in a latent space obtained according to an assumptive generative\nprocess. Different generative processes identify specific failure modes of the\nunderlying model. We perform experiments on three representative aspects of\nhigh-level discourse -- coherence, coreference, and topicality -- and find that\ntransformer-based language models are able to capture topical structures but\nhave a harder time maintaining structural coherence or modeling coreference.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Yuntian Deng",
      "Volodymyr Kuleshov",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08444"
  },
  {
    "id": "arXiv:2210.08445",
    "title": "Connection-Based Scheduling for Real-Time Intersection Control",
    "abstract": "We introduce a heuristic scheduling algorithm for real-time adaptive traffic\nsignal control to reduce traffic congestion. This algorithm adopts a lane-based\nmodel that estimates the arrival time of all vehicles approaching an\nintersection through different lanes, and then computes a schedule (i.e., a\nsignal timing plan) that minimizes the cumulative delay incurred by all\napproaching vehicles. State space, pruning checks and an admissible heuristic\nfor A* search are described and shown to be capable of generating an\nintersection schedule in real-time (i.e., every second). Due to the\neffectiveness of the heuristics, the proposed approach outperforms a less\nexpressive Dynamic Programming approach and previous A*-based approaches in\nrun-time performance, both in simulated test environments and actual field\ntests.",
    "descriptor": "",
    "authors": [
      "Hsu-Chieh Hu",
      "Joseph Zhou",
      "Gregory J. Barlow",
      "Stephen F. Smith"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08445"
  },
  {
    "id": "arXiv:2210.08450",
    "title": "FAQS: Communication-efficient Federate DNN Architecture and Quantization  Co-Search for personalized Hardware-aware Preferences",
    "abstract": "Due to user privacy and regulatory restrictions, federate learning (FL) is\nproposed as a distributed learning framework for training deep neural networks\n(DNN) on decentralized data clients. Recent advancements in FL have applied\nNeural Architecture Search (NAS) to replace the predefined one-size-fit-all DNN\nmodel, which is not optimal for all tasks of various data distributions, with\nsearchable DNN architectures. However, previous methods suffer from expensive\ncommunication cost rasied by frequent large model parameters transmission\nbetween the server and clients. Such difficulty is further amplified when\ncombining NAS algorithms, which commonly require prohibitive computation and\nenormous model storage. Towards this end, we propose FAQS, an efficient\npersonalized FL-NAS-Quantization framework to reduce the communication cost\nwith three features: weight-sharing super kernels, bit-sharing quantization and\nmasked transmission. FAQS has an affordable search time and demands very\nlimited size of transmitted messages at each round. By setting different\npersonlized pareto function loss on local clients, FAQS can yield heterogeneous\nhardware-aware models for various user preferences. Experimental results show\nthat FAQS achieves average reduction of 1.58x in communication bandwith per\nround compared with normal FL framework and 4.51x compared with FL+NAS\nframwork.",
    "descriptor": "",
    "authors": [
      "Hongjiang Chen",
      "Yang Wang",
      "Leibo Liu",
      "Shaojun Wei",
      "Shouyi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08450"
  },
  {
    "id": "arXiv:2210.08451",
    "title": "Bridging the Domain Gap for Multi-Agent Perception",
    "abstract": "Existing multi-agent perception algorithms usually select to share deep\nneural features extracted from raw sensing data between agents, achieving a\ntrade-off between accuracy and communication bandwidth limit. However, these\nmethods assume all agents have identical neural networks, which might not be\npractical in the real world. The transmitted features can have a large domain\ngap when the models differ, leading to a dramatic performance drop in\nmulti-agent perception. In this paper, we propose the first lightweight\nframework to bridge such domain gaps for multi-agent perception, which can be a\nplug-in module for most existing systems while maintaining confidentiality. Our\nframework consists of a learnable feature resizer to align features in multiple\ndimensions and a sparse cross-domain transformer for domain adaption. Extensive\nexperiments on the public multi-agent perception dataset V2XSet have\ndemonstrated that our method can effectively bridge the gap for features from\ndifferent domains and outperform other baseline methods significantly by at\nleast 8% for point-cloud-based 3D object detection.",
    "descriptor": "",
    "authors": [
      "Runsheng Xu",
      "Jinlong Li",
      "Xiaoyu Dong",
      "Hongkai Yu",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08451"
  },
  {
    "id": "arXiv:2210.08452",
    "title": "Efficient Cross-Modal Video Retrieval with Meta-Optimized Frames",
    "abstract": "Cross-modal video retrieval aims to retrieve the semantically relevant videos\ngiven a text as a query, and is one of the fundamental tasks in Multimedia.\nMost of top-performing methods primarily leverage Visual Transformer (ViT) to\nextract video features [1, 2, 3], suffering from high computational complexity\nof ViT especially for encoding long videos. A common and simple solution is to\nuniformly sample a small number (say, 4 or 8) of frames from the video (instead\nof using the whole video) as input to ViT. The number of frames has a strong\ninfluence on the performance of ViT, e.g., using 8 frames performs better than\nusing 4 frames yet needs more computational resources, resulting in a\ntrade-off. To get free from this trade-off, this paper introduces an automatic\nvideo compression method based on a bilevel optimization program (BOP)\nconsisting of both model-level (i.e., base-level) and frame-level (i.e.,\nmeta-level) optimizations. The model-level learns a cross-modal video retrieval\nmodel whose input is the \"compressed frames\" learned by frame-level\noptimization. In turn, the frame-level optimization is through gradient descent\nusing the meta loss of video retrieval model computed on the whole video. We\ncall this BOP method as well as the \"compressed frames\" as Meta-Optimized\nFrames (MOF). By incorporating MOF, the video retrieval model is able to\nutilize the information of whole videos (for training) while taking only a\nsmall number of input frames in actual implementation. The convergence of MOF\nis guaranteed by meta gradient descent algorithms. For evaluation, we conduct\nextensive experiments of cross-modal video retrieval on three large-scale\nbenchmarks: MSR-VTT, MSVD, and DiDeMo. Our results show that MOF is a generic\nand efficient method to boost multiple baseline methods, and can achieve a new\nstate-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Ning Han",
      "Xun Yang",
      "Ee-Peng Lim",
      "Hao Chen",
      "Qianru Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08452"
  },
  {
    "id": "arXiv:2210.08453",
    "title": "Learning Probabilities of Causation from Finite Population Data",
    "abstract": "This paper deals with the problem of learning the probabilities of causation\nof subpopulations given finite population data. The tight bounds of three basic\nprobabilities of causation, the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN),\nwere derived by Tian and Pearl. However, obtaining the bounds for each\nsubpopulation requires experimental and observational distributions of each\nsubpopulation, which is usually impractical to estimate given finite population\ndata. We propose a machine learning model that helps to learn the bounds of the\nprobabilities of causation for subpopulations given finite population data. We\nfurther show by a simulated study that the machine learning model is able to\nlearn the bounds of PNS for 32768 subpopulations with only knowing roughly 500\nof them from the finite population data.",
    "descriptor": "",
    "authors": [
      "Ang Li",
      "Song Jiang",
      "Yizhou Sun",
      "Judea Pearl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.08453"
  },
  {
    "id": "arXiv:2210.08455",
    "title": "Self-Reconfigurable Soft-Rigid Mobile Agent with Variable Stiffness and  Adaptive Morphology",
    "abstract": "In this paper, we propose a novel design of a hybrid mobile robot with\ncontrollable stiffness and deformable shape. Compared to conventional mobile\nagents, our system can switch between rigid and compliant phases by solidifying\nor melting Field's metal in its structure and, thus, alter its shape through\nthe motion of its active components. In the soft state, the robot's main body\ncan bend into circular arcs, which enables it to conform to surrounding curved\nobjects. This variable geometry of the robot creates new motion modes which\ncannot be described by standard (i.e., fixed geometry) models. To this end, we\ndevelop a unified mathematical model that captures the differential kinematics\nof both rigid and soft states. An optimised control strategy is further\nproposed to select the most appropriate phase states and motion modes needed to\nreach a target pose-shape configuration. The performance of our new method is\nvalidated with numerical simulations and experiments conducted on a prototype\nsystem. The simulation source code is available at\nhttps://github.com/Louashka/2sr-agent-simulation.git}{GitHub repository.",
    "descriptor": "",
    "authors": [
      "Luiza Labazanova",
      "Shuang Peng",
      "Liuming Qiu",
      "Hoi-Yin Lee",
      "Thrishantha Nanayakkara",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08455"
  },
  {
    "id": "arXiv:2210.08457",
    "title": "Scratching Visual Transformer's Back with Uniform Attention",
    "abstract": "The favorable performance of Vision Transformers (ViTs) is often attributed\nto the multi-head self-attention (MSA). The MSA enables global interactions at\neach layer of a ViT model, which is a contrasting feature against Convolutional\nNeural Networks (CNNs) that gradually increase the range of interaction across\nmultiple layers. We study the role of the density of the attention. Our\npreliminary analyses suggest that the spatial interactions of attention maps\nare close to dense interactions rather than sparse ones. This is a curious\nphenomenon, as dense attention maps are harder for the model to learn due to\nsteeper softmax gradients around them. We interpret this as a strong preference\nfor ViT models to include dense interaction. We thus manually insert the\nuniform attention to each layer of ViT models to supply the much needed dense\ninteractions. We call this method Context Broadcasting, CB. We observe that the\ninclusion of CB reduces the degree of density in the original attention maps\nand increases both the capacity and generalizability of the ViT models. CB\nincurs negligible costs: 1 line in your model code, no additional parameters,\nand minimal extra operations.",
    "descriptor": "",
    "authors": [
      "Nam Hyeon-Woo",
      "Kim Yu-Ji",
      "Byeongho Heo",
      "Doonyoon Han",
      "Seong Joon Oh",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08457"
  },
  {
    "id": "arXiv:2210.08458",
    "title": "Learning Self-Regularized Adversarial Views for Self-Supervised Vision  Transformers",
    "abstract": "Automatic data augmentation (AutoAugment) strategies are indispensable in\nsupervised data-efficient training protocols of vision transformers, and have\nled to state-of-the-art results in supervised learning. Despite the success,\nits development and application on self-supervised vision transformers have\nbeen hindered by several barriers, including the high search cost, the lack of\nsupervision, and the unsuitable search space. In this work, we propose\nAutoView, a self-regularized adversarial AutoAugment method, to learn views for\nself-supervised vision transformers, by addressing the above barriers. First,\nwe reduce the search cost of AutoView to nearly zero by learning views and\nnetwork parameters simultaneously in a single forward-backward step, minimizing\nand maximizing the mutual information among different augmented views,\nrespectively. Then, to avoid information collapse caused by the lack of label\nsupervision, we propose a self-regularized loss term to guarantee the\ninformation propagation. Additionally, we present a curated augmentation policy\nsearch space for self-supervised learning, by modifying the generally used\nsearch space designed for supervised learning. On ImageNet, our AutoView\nachieves remarkable improvement over RandAug baseline (+10.2% k-NN accuracy),\nand consistently outperforms sota manually tuned view policy by a clear margin\n(up to +1.3% k-NN accuracy). Extensive experiments show that AutoView\npretraining also benefits downstream tasks (+1.2% mAcc on ADE20K Semantic\nSegmentation and +2.8% mAP on revisited Oxford Image Retrieval benchmark) and\nimproves model robustness (+2.3% Top-1 Acc on ImageNet-A and +1.0% AUPR on\nImageNet-O). Code and models will be available at\nhttps://github.com/Trent-tangtao/AutoView.",
    "descriptor": "",
    "authors": [
      "Tao Tang",
      "Changlin Li",
      "Guangrun Wang",
      "Kaicheng Yu",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08458"
  },
  {
    "id": "arXiv:2210.08459",
    "title": "StoryER: Automatic Story Evaluation via Ranking, Rating and Reasoning",
    "abstract": "Existing automatic story evaluation methods place a premium on story lexical\nlevel coherence, deviating from human preference. We go beyond this limitation\nby considering a novel \\textbf{Story} \\textbf{E}valuation method that mimics\nhuman preference when judging a story, namely \\textbf{StoryER}, which consists\nof three sub-tasks: \\textbf{R}anking, \\textbf{R}ating and \\textbf{R}easoning.\nGiven either a machine-generated or a human-written story, StoryER requires the\nmachine to output 1) a preference score that corresponds to human preference,\n2) specific ratings and their corresponding confidences and 3) comments for\nvarious aspects (e.g., opening, character-shaping). To support these tasks, we\nintroduce a well-annotated dataset comprising (i) 100k ranked story pairs; and\n(ii) a set of 46k ratings and comments on various aspects of the story. We\nfinetune Longformer-Encoder-Decoder (LED) on the collected dataset, with the\nencoder responsible for preference score and aspect prediction and the decoder\nfor comment generation. Our comprehensive experiments result in a competitive\nbenchmark for each task, showing the high correlation to human preference. In\naddition, we have witnessed the joint learning of the preference scores, the\naspect ratings, and the comments brings gain in each single task. Our dataset\nand benchmarks are publicly available to advance the research of story\nevaluation tasks.\\footnote{Dataset and pre-trained model demo are available at\nanonymous website \\url{this http URL} and\n\\url{https://github.com/sairin1202/StoryER}}",
    "descriptor": "\nComments: accepted by EMNLP 2022\n",
    "authors": [
      "Hong Chen",
      "Duc Minh Vo",
      "Hiroya Takamura",
      "Yusuke Miyao",
      "Hideki Nakayama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08459"
  },
  {
    "id": "arXiv:2210.08461",
    "title": "Positive-Unlabeled Learning using Random Forests via Recursive Greedy  Risk Minimization",
    "abstract": "The need to learn from positive and unlabeled data, or PU learning, arises in\nmany applications and has attracted increasing interest. While random forests\nare known to perform well on many tasks with positive and negative data, recent\nPU algorithms are generally based on deep neural networks, and the potential of\ntree-based PU learning is under-explored. In this paper, we propose new random\nforest algorithms for PU-learning. Key to our approach is a new interpretation\nof decision tree algorithms for positive and negative data as \\emph{recursive\ngreedy risk minimization algorithms}. We extend this perspective to the PU\nsetting to develop new decision tree learning algorithms that directly\nminimizes PU-data based estimators for the expected risk. This allows us to\ndevelop an efficient PU random forest algorithm, PU extra trees. Our approach\nfeatures three desirable properties: it is robust to the choice of the loss\nfunction in the sense that various loss functions lead to the same decision\ntrees; it requires little hyperparameter tuning as compared to neural network\nbased PU learning; it supports a feature importance that directly measures a\nfeature's contribution to risk minimization. Our algorithms demonstrate strong\nperformance on several datasets. Our code is available at\n\\url{https://github.com/puetpaper/PUExtraTrees}.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Jonathan Wilton",
      "Abigail M. Y. Koay",
      "Ryan K. L. Ko",
      "Miao Xu",
      "Nan Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08461"
  },
  {
    "id": "arXiv:2210.08463",
    "title": "Two classes of narrow-sense BCH codes and their duals",
    "abstract": "BCH codes and their dual codes are two special subclasses of cyclic codes and\nare the best linear codes in many cases. A lot of progress on the study of BCH\ncyclic codes has been made, but little is known about the minimum distances of\nthe duals of BCH codes. Recently, a new concept called dually-BCH code was\nintroduced to investigate the duals of BCH codes and the lower bounds on their\nminimum distances in \\cite{GDL21}. For a prime power $q$ and an integer $m \\ge\n4$, let $n=\\frac{q^m-1}{q+1}$ \\ ($m$ even), or $n=\\frac{q^m-1}{q-1}$ \\ ($q>2$).\nIn this paper, some sufficient and necessary conditions in terms of the\ndesigned distance will be given to ensure that the narrow-sense BCH codes of\nlength $n$ are dually-BCH codes, which extended the results in \\cite{GDL21}.\nLower bounds on the minimum distances of their dual codes are developed for\n$n=\\frac{q^m-1}{q+1}$ \\ ($m$ even). As byproducts, we present the largest coset\nleader $\\delta_1$ modulo $n$ being of two types, which proves a conjecture in\n\\cite{WLP19} and partially solves an open problem in \\cite{Li2017}. We also\ninvestigate the parameters of the narrow-sense BCH codes of length $n$ with\ndesign distance $\\delta_1$. The BCH codes presented in this paper have good\nparameters in general.",
    "descriptor": "",
    "authors": [
      "Xiaoqiang Wang",
      "Jiaojiao Wang",
      "Chengju Li",
      "Yansheng Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08463"
  },
  {
    "id": "arXiv:2210.08464",
    "title": "Federated Learning with Privacy-Preserving Ensemble Attention  Distillation",
    "abstract": "Federated Learning (FL) is a machine learning paradigm where many local nodes\ncollaboratively train a central model while keeping the training data\ndecentralized. This is particularly relevant for clinical applications since\npatient data are usually not allowed to be transferred out of medical\nfacilities, leading to the need for FL. Existing FL methods typically share\nmodel parameters or employ co-distillation to address the issue of unbalanced\ndata distribution. However, they also require numerous rounds of synchronized\ncommunication and, more importantly, suffer from a privacy leakage risk. We\npropose a privacy-preserving FL framework leveraging unlabeled public data for\none-way offline knowledge distillation in this work. The central model is\nlearned from local knowledge via ensemble attention distillation. Our technique\nuses decentralized and heterogeneous local data like existing FL approaches,\nbut more importantly, it significantly reduces the risk of privacy leakage. We\ndemonstrate that our method achieves very competitive performance with more\nrobust privacy preservation based on extensive experiments on image\nclassification, segmentation, and reconstruction tasks.",
    "descriptor": "",
    "authors": [
      "Xuan Gong",
      "Liangchen Song",
      "Rishi Vedula",
      "Abhishek Sharma",
      "Meng Zheng",
      "Benjamin Planche",
      "Arun Innanje",
      "Terrence Chen",
      "Junsong Yuan",
      "David Doermann",
      "Ziyan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08464"
  },
  {
    "id": "arXiv:2210.08465",
    "title": "Character-Centric Story Visualization via Visual Planning and Token  Alignment",
    "abstract": "Story visualization advances the traditional text-to-image generation by\nenabling multiple image generation based on a complete story. This task\nrequires machines to 1) understand long text inputs and 2) produce a globally\nconsistent image sequence that illustrates the contents of the story. A key\nchallenge of consistent story visualization is to preserve characters that are\nessential in stories. To tackle the challenge, we propose to adapt a recent\nwork that augments Vector-Quantized Variational Autoencoders (VQ-VAE) with a\ntext-tovisual-token (transformer) architecture. Specifically, we modify the\ntext-to-visual-token module with a two-stage framework: 1) character token\nplanning model that predicts the visual tokens for characters only; 2) visual\ntoken completion model that generates the remaining visual token sequence,\nwhich is sent to VQ-VAE for finalizing image generations. To encourage\ncharacters to appear in the images, we further train the two-stage framework\nwith a character-token alignment objective. Extensive experiments and\nevaluations demonstrate that the proposed method excels at preserving\ncharacters and can produce higher quality image sequences compared with the\nstrong baselines. Codes can be found in https://github.com/sairin1202/VP-CSV",
    "descriptor": "\nComments: accepted by EMNLP2022\n",
    "authors": [
      "Hong Chen",
      "Rujun Han",
      "Te-Lin Wu",
      "Hideki Nakayama",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08465"
  },
  {
    "id": "arXiv:2210.08470",
    "title": "Class Distribution Monitoring for Concept Drift Detection",
    "abstract": "We introduce Class Distribution Monitoring (CDM), an effective concept-drift\ndetection scheme that monitors the class-conditional distributions of a\ndatastream. In particular, our solution leverages multiple instances of an\nonline and nonparametric change-detection algorithm based on QuantTree. CDM\nreports a concept drift after detecting a distribution change in any class,\nthus identifying which classes are affected by the concept drift. This can be\nprecious information for diagnostics and adaptation. Our experiments on\nsynthetic and real-world datastreams show that when the concept drift affects a\nfew classes, CDM outperforms algorithms monitoring the overall data\ndistribution, while achieving similar detection delays when the drift affects\nall the classes. Moreover, CDM outperforms comparable approaches that monitor\nthe classification error, particularly when the change is not very apparent.\nFinally, we demonstrate that CDM inherits the properties of the underlying\nchange detector, yielding an effective control over the expected time before a\nfalse alarm, or Average Run Length (ARL$_0$).",
    "descriptor": "\nComments: 2022 International Joint Conference on Neural Networks (IJCNN)\n",
    "authors": [
      "Diego Stucchi",
      "Luca Frittoli",
      "Giacomo Boracchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08470"
  },
  {
    "id": "arXiv:2210.08471",
    "title": "Improving Semantic Matching through Dependency-Enhanced Pre-trained  Model with Adaptive Fusion",
    "abstract": "Transformer-based pre-trained models like BERT have achieved great progress\non Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also\nshown general benefits in multiple NLP tasks. However, how to efficiently\nintegrate dependency prior structure into pre-trained models to better model\ncomplex semantic matching relations is still unsettled. In this paper, we\npropose the \\textbf{D}ependency-Enhanced \\textbf{A}daptive \\textbf{F}usion\n\\textbf{A}ttention (\\textbf{DAFA}), which explicitly introduces dependency\nstructure into pre-trained models and adaptively fuses it with semantic\ninformation. Specifically, \\textbf{\\emph{(i)}} DAFA first proposes a\nstructure-sensitive paradigm to construct a dependency matrix for calibrating\nattention weights. It adopts an adaptive fusion module to integrate the\nobtained dependency information and the original semantic signals. Moreover,\nDAFA reconstructs the attention calculation flow and provides better\ninterpretability. By applying it on BERT, our method achieves state-of-the-art\nor competitive performance on 10 public datasets, demonstrating the benefits of\nadaptively fusing dependency structure in semantic matching task.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Jian Song",
      "Di Liang",
      "Rumei Li",
      "Yuntao Li",
      "Sirui Wang",
      "Minlong Peng",
      "Wei Wu",
      "Yongxin Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08471"
  },
  {
    "id": "arXiv:2210.08472",
    "title": "Object-Attentional Untargeted Adversarial Attack",
    "abstract": "Deep neural networks are facing severe threats from adversarial attacks. Most\nexisting black-box attacks fool target model by generating either global\nperturbations or local patches. However, both global perturbations and local\npatches easily cause annoying visual artifacts in adversarial example. Compared\nwith some smooth regions of an image, the object region generally has more\nedges and a more complex texture. Thus small perturbations on it will be more\nimperceptible. On the other hand, the object region is undoubtfully the\ndecisive part of an image to classification tasks. Motivated by these two\nfacts, we propose an object-attentional adversarial attack method for\nuntargeted attack. Specifically, we first generate an object region by\nintersecting the object detection region from YOLOv4 with the salient object\ndetection (SOD) region from HVPNet. Furthermore, we design an activation\nstrategy to avoid the reaction caused by the incomplete SOD. Then, we perform\nan adversarial attack only on the detected object region by leveraging Simple\nBlack-box Adversarial Attack (SimBA). To verify the proposed method, we create\na unique dataset by extracting all the images containing the object defined by\nCOCO from ImageNet-1K, named COCO-Reduced-ImageNet in this paper. Experimental\nresults on ImageNet-1K and COCO-Reduced-ImageNet show that under various system\nsettings, our method yields the adversarial example with better perceptual\nquality meanwhile saving the query budget up to 24.16\\% compared to the\nstate-of-the-art approaches including SimBA.",
    "descriptor": "",
    "authors": [
      "Chao Zhou",
      "Yuan-Gen Wang",
      "Guopu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08472"
  },
  {
    "id": "arXiv:2210.08473",
    "title": "1st Place Solution in Google Universal Images Embedding",
    "abstract": "This paper presents the 1st place solution for the Google Universal Images\nEmbedding Competition on Kaggle. The highlighted part of our solution is based\non 1) A novel way to conduct training and fine-tuning; 2) The idea of a better\nensemble in the pool of models that make embedding; 3) The potential trade-off\nbetween fine-tuning on high-resolution and overlapping patches; 4) The\npotential factors to work for the dynamic margin. Our solution reaches 0.728 in\nthe private leader board, which achieve 1st place in Google Universal Images\nEmbedding Competition.",
    "descriptor": "\nComments: 4 pages, Kaggle Competition, ECCV workshop\n",
    "authors": [
      "Shihao Shao",
      "Qinghua Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08473"
  },
  {
    "id": "arXiv:2210.08474",
    "title": "Sentence Representation Learning with Generative Objective rather than  Contrastive Objective",
    "abstract": "Though offering amazing contextualized token-level representations, current\npre-trained language models take less attention on accurately acquiring\nsentence-level representation during their self-supervised pre-training.\nHowever, contrastive objectives which dominate the current sentence\nrepresentation learning bring little linguistic interpretability and no\nperformance guarantee on downstream semantic tasks. We instead propose a novel\ngenerative self-supervised learning objective based on phrase reconstruction.\nTo overcome the drawbacks of previous generative methods, we carefully model\nintra-sentence structure by breaking down one sentence into pieces of important\nphrases. Empirical studies show that our generative learning achieves powerful\nenough performance improvement and outperforms the current state-of-the-art\ncontrastive methods not only on the STS benchmarks, but also on downstream\nsemantic retrieval and reranking tasks. Our code is available at\nhttps://github.com/chengzhipanpan/PaSeR.",
    "descriptor": "\nComments: Accepted by the Main Conference of EMNLP 2022, long paper. arXiv admin note: substantial text overlap with arXiv:2204.09358\n",
    "authors": [
      "Bohong Wu",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08474"
  },
  {
    "id": "arXiv:2210.08475",
    "title": "RedApt: An Adaptor for wav2vec 2 Encoding \\\\ Faster and Smaller Speech  Translation without Quality Compromise",
    "abstract": "Pre-trained speech Transformers in speech translation (ST) have facilitated\nstate-of-the-art (SotA) results; yet, using such encoders is computationally\nexpensive. To improve this, we present a novel Reducer Adaptor block, RedApt,\nthat could be seamlessly integrated within any Transformer-based speech\nencoding architecture. Integrating the pretrained wav2vec 2 speech encoder with\nRedAptbrings 41% speedup, 33% memory reduction with 24% fewer FLOPs at\ninference. To our positive surprise, our ST model with RedApt outperforms the\nSotA architecture by an average of 0.68 BLEU score on 8 language pairs from\nMust-C.",
    "descriptor": "\nComments: EMNLP 2022 Finding\n",
    "authors": [
      "Jinming Zhao",
      "Hao Yang",
      "Gholamreza Haffari",
      "Ehsan Shareghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08475"
  },
  {
    "id": "arXiv:2210.08477",
    "title": "Large-scale Text-to-Image Generation Models for Visual Artists' Creative  Works",
    "abstract": "Large-scale Text-to-image Generation Models (LTGMs) (e.g., DALL-E),\nself-supervised deep learning models trained on a huge dataset, have\ndemonstrated the capacity for generating high-quality open-domain images from\nmulti-modal input. Although they can even produce anthropomorphized versions of\nobjects and animals, combine irrelevant concepts in reasonable ways, and give\nvariation to any user-provided images, we witnessed such rapid technological\nadvancement left many visual artists disoriented in leveraging LTGMs more\nactively in their creative works. Our goal in this work is to understand how\nvisual artists would adopt LTGMs to support their creative works. To this end,\nwe conducted an interview study as well as a systematic literature review of 72\nsystem/application papers for a thorough examination. A total of 28 visual\nartists covering 35 distinct visual art domains acknowledged LTGMs' versatile\nroles with high usability to support creative works in automating the creation\nprocess (i.e., automation), expanding their ideas (i.e., exploration), and\nfacilitating or arbitrating in communication (i.e., mediation). We conclude by\nproviding four design guidelines that future researchers can refer to in making\nintelligent user interfaces using LTGMs.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Hyung-Kwon Ko",
      "Gwanmo Park",
      "Hyeon Jeon",
      "Jaemin Jo",
      "Juho Kim",
      "Jinwook Seo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08477"
  },
  {
    "id": "arXiv:2210.08478",
    "title": "Increasing Visual Awareness in Multimodal Neural Machine Translation  from an Information Theoretic Perspective",
    "abstract": "Multimodal machine translation (MMT) aims to improve translation quality by\nequipping the source sentence with its corresponding image. Despite the\npromising performance, MMT models still suffer the problem of input\ndegradation: models focus more on textual information while visual information\nis generally overlooked. In this paper, we endeavor to improve MMT performance\nby increasing visual awareness from an information theoretic perspective. In\ndetail, we decompose the informative visual signals into two parts:\nsource-specific information and target-specific information. We use mutual\ninformation to quantify them and propose two methods for objective optimization\nto better leverage visual signals. Experiments on two datasets demonstrate that\nour approach can effectively enhance the visual awareness of MMT model and\nachieve superior results against strong baselines.",
    "descriptor": "\nComments: 10 pages, 4 figures; EMNLP main conference\n",
    "authors": [
      "Baijun Ji",
      "Tong Zhang",
      "Yicheng Zou",
      "Bojie Hu",
      "Si Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08478"
  },
  {
    "id": "arXiv:2210.08480",
    "title": "Analytical Volume Analysis for the Finite-time Controllable Region of  the Linear Discrete-time Systems",
    "abstract": "In this paper, the works on the analytical volume analysis for the\ncontrollable regions of the linear discrete-time (LDT) systems in papers\n\\cite{zhaomw202001} and \\cite {zhaomw202004} are discussed further and a new\ntheorem on the analytical computing for the finite-time controllability\nzonotope (controllable region) of LDT systems are proven. And then, three\nanalytical factors describing the control capability of the systems are\ndeconstructed successfully from the analytical volume expression of the\ncontrollable region. Finally, the theorem is generalized to three cases: the\nnarrow controllable region, the matrix $A$ with $n$ negative eigenvalues, the\nlinear continuous-time systems.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Mingwang Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08480"
  },
  {
    "id": "arXiv:2210.08481",
    "title": "TLDW: Extreme Multimodal Summarisation of News Videos",
    "abstract": "Multimodal summarisation with multimodal output is drawing increasing\nattention due to the rapid growth of multimedia data. While several methods\nhave been proposed to summarise visual-text contents, their multimodal outputs\nare not succinct enough at an extreme level to address the information overload\nissue. To the end of extreme multimodal summarisation, we introduce a new task,\neXtreme Multimodal Summarisation with Multimodal Output (XMSMO) for the\nscenario of TL;DW - Too Long; Didn't Watch, akin to TL;DR. XMSMO aims to\nsummarise a video-document pair into a summary with an extremely short length,\nwhich consists of one cover frame as the visual summary and one sentence as the\ntextual summary. We propose a novel unsupervised Hierarchical Optimal Transport\nNetwork (HOT-Net) consisting of three components: hierarchical multimodal\nencoders, hierarchical multimodal fusion decoders, and optimal transport\nsolvers. Our method is trained, without using reference summaries, by\noptimising the visual and textual coverage from the perspectives of the\ndistance between the semantic distributions under optimal transport plans. To\nfacilitate the study on this task, we collect a large-scale dataset XMSMO-News\nby harvesting 4,891 video-document pairs. The experimental results show that\nour method achieves promising performance in terms of ROUGE and IoU metrics.",
    "descriptor": "",
    "authors": [
      "Peggy Tang",
      "Kun Hu",
      "Lei Zhang",
      "Jiebo Luo",
      "Zhiyong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08481"
  },
  {
    "id": "arXiv:2210.08483",
    "title": "Direct Computing on Control Capability for Linear Continuous-time  Systems Based on Hurwitz Matrix",
    "abstract": "In this paper, based on the controllable canonical form and the Hurwitz\nmatrix of the Hurwitz stability criterion, an analytical volume computing\nmethod for the smooth controllability zonotope for the linear\ncontinuous-time(LCT) systems, without of help of the eigenvalue computing of\nthe systems, is presented. And then, the computing method is generlized to the\nvolume computing of the controllability ellipsoid of the LCT systems. Because\nthe controllability zonotope and ellipsoid are directly related to control\ncapability and their volumes are the main index describing the control\ncapability, the new volume computing methods proposed in this paper can help\ngreatly the computing, analysis and optimization of the control capability of\nLCT systems.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Mingwang Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08483"
  },
  {
    "id": "arXiv:2210.08485",
    "title": "HQNAS: Auto CNN deployment framework for joint quantization and  architecture search",
    "abstract": "Deep learning applications are being transferred from the cloud to edge with\nthe rapid development of embedded computing systems. In order to achieve higher\nenergy efficiency with the limited resource budget, neural networks(NNs) must\nbe carefully designed in two steps, the architecture design and the\nquantization policy choice. Neural Architecture Search(NAS) and Quantization\nhave been proposed separately when deploying NNs onto embedded devices.\nHowever, taking the two steps individually is time-consuming and leads to a\nsub-optimal final deployment. To this end, we propose a novel neural network\ndesign framework called Hardware-aware Quantized Neural Architecture\nSearch(HQNAS) framework which combines the NAS and Quantization together in a\nvery efficient manner using weight-sharing and bit-sharing. It takes only 4 GPU\nhours to discover an outstanding NN policy on CIFAR10. It also takes only %10\nGPU time to generate a comparable model on Imagenet compared to the traditional\nNAS method with 1.8x decrease of latency and a negligible accuracy loss of only\n0.7%. Besides, our method can be adapted in a lifelong situation where the\nneural network needs to evolve occasionally due to changes of local data,\nenvironment and user preference.",
    "descriptor": "",
    "authors": [
      "Hongjiang Chen",
      "Yang Wang",
      "Leibo Liu",
      "Shaojun Wei",
      "Shouyi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08485"
  },
  {
    "id": "arXiv:2210.08486",
    "title": "Streaming PAC-Bayes Gaussian process regression with a performance  guarantee for online decision making",
    "abstract": "As a powerful Bayesian non-parameterized algorithm, the Gaussian process (GP)\nhas performed a significant role in Bayesian optimization and signal\nprocessing. GPs have also advanced online decision-making systems because their\nposterior distribution has a closed-form solution. However, its training and\ninference process requires all historic data to be stored and the GP model to\nbe trained from scratch. For those reasons, several online GP algorithms, such\nas O-SGPR and O-SVGP, have been specifically designed for streaming settings.\nIn this paper, we present a new theoretical framework for online GPs based on\nthe online probably approximately correct (PAC) Bayes theory. The framework\noffers both a guarantee of generalized performance and good accuracy. Instead\nof minimizing the marginal likelihood, our algorithm optimizes both the\nempirical risk function and a regularization item, which is in proportion to\nthe divergence between the prior distribution and posterior distribution of\nparameters. In addition to its theoretical appeal, the algorithm performs well\nempirically on several regression datasets. Compared to other online GP\nalgorithms, ours yields a generalization guarantee and very competitive\naccuracy.",
    "descriptor": "",
    "authors": [
      "Tianyu Liu",
      "Jie Lu",
      "Zheng Yan",
      "Guangquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08486"
  },
  {
    "id": "arXiv:2210.08487",
    "title": "Survey of Deep Learning for Autonomous Surface Vehicles in the Marine  Environment",
    "abstract": "Within the next several years, there will be a high level of autonomous\ntechnology that will be available for widespread use, which will reduce labor\ncosts, increase safety, save energy, enable difficult unmanned tasks in harsh\nenvironments, and eliminate human error. Compared to software development for\nother autonomous vehicles, maritime software development, especially on aging\nbut still functional fleets, is described as being in a very early and emerging\nphase. This introduces very large challenges and opportunities for researchers\nand engineers to develop maritime autonomous systems. Recent progress in sensor\nand communication technology has introduced the use of autonomous surface\nvehicles (ASVs) in applications such as coastline surveillance, oceanographic\nobservation, multi-vehicle cooperation, and search and rescue missions.\nAdvanced artificial intelligence technology, especially deep learning (DL)\nmethods that conduct nonlinear mapping with self-learning representations, has\nbrought the concept of full autonomy one step closer to reality. This paper\nsurveys the existing work regarding the implementation of DL methods in\nASV-related fields. First, the scope of this work is described after reviewing\nsurveys on ASV developments and technologies, which draws attention to the\nresearch gap between DL and maritime operations. Then, DL-based navigation,\nguidance, control (NGC) systems and cooperative operations, are presented.\nFinally, this survey is completed by highlighting the current challenges and\nfuture research directions.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Qiao",
      "Jiaxin Yin",
      "Wei Wang",
      "F\u00e1bio Duarte",
      "Jie Yang",
      "Carlo Ratti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08487"
  },
  {
    "id": "arXiv:2210.08490",
    "title": "STAR: Zero-Shot Chinese Character Recognition with Stroke- and  Radical-Level Decompositions",
    "abstract": "Zero-shot Chinese character recognition has attracted rising attention in\nrecent years. Existing methods for this problem are mainly based on either\ncertain low-level stroke-based decomposition or medium-level radical-based\ndecomposition. Considering that the stroke- and radical-level decompositions\ncan provide different levels of information, we propose an effective zero-shot\nChinese character recognition method by combining them. The proposed method\nconsists of a training stage and an inference stage. In the training stage, we\nadopt two similar encoder-decoder models to yield the estimates of stroke and\nradical encodings, which together with the true encodings are then used to\nformalize the associated stroke and radical losses for training. A similarity\nloss is introduced to regularize stroke and radical encoders to yield features\nof the same characters with high correlation. In the inference stage, two key\nmodules, i.e., the stroke screening module (SSM) and feature matching module\n(FMM) are introduced to tackle the deterministic and confusing cases\nrespectively. In particular, we introduce an effective stroke rectification\nscheme in FMM to enlarge the candidate set of characters for final inference.\nNumerous experiments over three benchmark datasets covering the handwritten,\nprinted artistic and street view scenarios are conducted to demonstrate the\neffectiveness of the proposed method. Numerical results show that the proposed\nmethod outperforms the state-of-the-art methods in both character and radical\nzero-shot settings, and maintains competitive performance in the traditional\nseen character setting.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Jinshan Zeng",
      "Ruiying Xu",
      "Yu Wu",
      "Hongwei Li",
      "Jiaxing Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08490"
  },
  {
    "id": "arXiv:2210.08492",
    "title": "On the necessity of separating MAC protocols into data and control  planes",
    "abstract": "The network protocol architecture not only can be designed from the\ntraditional view of layers, but also can be designed from the view of planes,\ni.e., the data, control and management planes. Media access control (MAC) is a\nfunction of the data link layer, and thus the MAC protocols involve of both the\ndata and control planes. However, although the international wireless local\narea network (WLAN) standard, IEEE 802.11 or Wi-Fi, has developed over 20\nyears, the control plane of the MAC protocols is not explicitly described yet.\nThus, does it need to separate the MAC protocols into data and control planes?\nIf not, are there some problems in existing hybrid architecture? To answer\nabove questions, we analyse the possible problems of the current MAC protocols\nin IEEE 802.11, particularly in std 802.11-2020. These problems can be seen as\nnew starts for the next study of the WLAN for the next generation (WNG).",
    "descriptor": "\nComments: 6 pages, 6 figures, unsubmitted\n",
    "authors": [
      "Zhongjiang Yan",
      "Bo Li",
      "Mao Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.08492"
  },
  {
    "id": "arXiv:2210.08493",
    "title": "Indoor Smartphone SLAM with Learned Echoic Location Features",
    "abstract": "Indoor self-localization is a highly demanded system function for\nsmartphones. The current solutions based on inertial, radio frequency, and\ngeomagnetic sensing may have degraded performance when their limiting factors\ntake effect. In this paper, we present a new indoor simultaneous localization\nand mapping (SLAM) system that utilizes the smartphone's built-in audio\nhardware and inertial measurement unit (IMU). Our system uses a smartphone's\nloudspeaker to emit near-inaudible chirps and then the microphone to record the\nacoustic echoes from the indoor environment. Our profiling measurements show\nthat the echoes carry location information with sub-meter granularity. To\nenable SLAM, we apply contrastive learning to construct an echoic location\nfeature (ELF) extractor, such that the loop closures on the smartphone's\ntrajectory can be accurately detected from the associated ELF trace. The\ndetection results effectively regulate the IMU-based trajectory reconstruction.\nExtensive experiments show that our ELF-based SLAM achieves median localization\nerrors of $0.1\\,\\text{m}$, $0.53\\,\\text{m}$, and $0.4\\,\\text{m}$ on the\nreconstructed trajectories in a living room, an office, and a shopping mall,\nand outperforms the Wi-Fi and geomagnetic SLAM systems.",
    "descriptor": "",
    "authors": [
      "Wenjie Luo",
      "Qun Song",
      "Zhenyu Yan",
      "Rui Tan",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08493"
  },
  {
    "id": "arXiv:2210.08494",
    "title": "Brand New K-FACs: Speeding up K-FAC with Online Decomposition Updates",
    "abstract": "K-FAC (arXiv:1503.05671, arXiv:1602.01407) is a tractable implementation of\nNatural Gradient (NG) for Deep Learning (DL), whose bottleneck is computing the\ninverses of the so-called ``Kronecker-Factors'' (K-factors). RS-KFAC\n(arXiv:2206.15397) is a K-FAC improvement which provides a cheap way of\nestimating the K-factors inverses. In this paper, we exploit the\nexponential-average construction paradigm of the K-factors, and use online\nnumerical linear algebra techniques to propose an even cheaper (but less\naccurate) way of estimating the K-factors inverses for Fully Connected layers.\nNumerical results show RS-KFAC's inversion error can be reduced with minimal\nCPU overhead by adding our proposed update to it. Based on the proposed\nprocedure, a correction to it, and RS-KFAC, we propose three practical\nalgorithms for optimizing generic Deep Neural Nets. Numerical results show that\ntwo of these outperform RS-KFAC for any target test accuracy on CIFAR10\nclassification with a slightly modified version of VGG16_bn. Our proposed\nalgorithms achieve 91$\\%$ test accuracy faster than SENG (the state of art\nimplementation of empirical NG for DL; arXiv:2006.05924) but underperform it\nfor higher test-accuracy.",
    "descriptor": "\nComments: Version 1\n",
    "authors": [
      "Constantin Octavian Puiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08494"
  },
  {
    "id": "arXiv:2210.08495",
    "title": "Pareto Set Learning for Expensive Multi-Objective Optimization",
    "abstract": "Expensive multi-objective optimization problems can be found in many\nreal-world applications, where their objective function evaluations involve\nexpensive computations or physical experiments. It is desirable to obtain an\napproximate Pareto front with a limited evaluation budget. Multi-objective\nBayesian optimization (MOBO) has been widely used for finding a finite set of\nPareto optimal solutions. However, it is well-known that the whole Pareto set\nis on a continuous manifold and can contain infinite solutions. The structural\nproperties of the Pareto set are not well exploited in existing MOBO methods,\nand the finite-set approximation may not contain the most preferred solution(s)\nfor decision-makers. This paper develops a novel learning-based method to\napproximate the whole Pareto set for MOBO, which generalizes the\ndecomposition-based multi-objective optimization algorithm (MOEA/D) from finite\npopulations to models. We design a simple and powerful acquisition search\nmethod based on the learned Pareto set, which naturally supports batch\nevaluation. In addition, with our proposed model, decision-makers can readily\nexplore any trade-off area in the approximate Pareto set for flexible\ndecision-making. This work represents the first attempt to model the Pareto set\nfor expensive multi-objective optimization. Experimental results on different\nsynthetic and real-world problems demonstrate the effectiveness of our proposed\nmethod.",
    "descriptor": "\nComments: To appear in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Xi Lin",
      "Zhiyuan Yang",
      "Xiaoyuan Zhang",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08495"
  },
  {
    "id": "arXiv:2210.08496",
    "title": "Hierarchical Pricing Game for Balancing the Charging of Ride-Hailing  Electric Fleets",
    "abstract": "Due to the ever-increasing popularity of ride-hailing services and the\nindisputable shift towards alternative fuel vehicles, the intersection of the\nride-hailing market and smart electric mobility provides an opportunity to\ntrade different services to achieve societal optimum. In this work, we present\na hierarchical, game-based, control mechanism for balancing the simultaneous\ncharging of multiple ride-hailing fleets. The mechanism takes into account\nsometimes conflicting interests of the ride-hailing drivers, the ride-hailing\ncompany management, and the external agents such as power-providing companies\nor city governments that will play a significant role in charging management in\nthe future. The upper-level control considers charging price incentives and\nmodels the interactions between the external agents and ride-hailing companies\nas a Reverse Stackelberg game with a single leader and multiple followers. The\nlower-level control motivates the revenue-maximizing drivers to follow the\ncompany operator's requests through surge pricing and models the interactions\nas a single leader, multiple followers Stackelberg game. We provide a pricing\nmechanism that ensures the existence of a unique Nash equilibrium of the\nupper-level game that minimizes the external agent's objective at the same\ntime. We provide theoretical and experimental robustness analysis of the\nupper-level control with respect to parameters whose values depend on sensitive\ninformation that might not be entirely accessible to the external agent. For\nthe lower-level algorithm, we combine the Nash equilibrium of the upper-level\ngame with a quadratic mixed integer optimization problem to find the optimal\nsurge prices. Finally, we illustrate the performance of the control mechanism\nin a case study based on real taxi data from the city of Shenzhen in China.",
    "descriptor": "",
    "authors": [
      "Marko Maljkovic",
      "Gustav Nilsson",
      "Nikolas Geroliminis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08496"
  },
  {
    "id": "arXiv:2210.08497",
    "title": "Urban form and COVID-19 cases and deaths in Greater London: an urban  morphometric approach",
    "abstract": "The COVID-19 pandemic generated a considerable debate in relation to urban\ndensity. This is an old debate, originated in mid 19th century's England with\nthe emergence of public health and urban planning disciplines. While popularly\nlinked, evidence suggests that such relationship cannot be generally assumed.\nFurthermore, urban density has been investigated in a spatially coarse manner\n(predominantly at city level) and never contextualised with other descriptors\nof urban form. In this work, we explore COVID-19 and urban form in Greater\nLondon, relating a comprehensive set of morphometric descriptors (including\nbuilt-up density) to COVID-19 deaths and cases, while controlling for\nsocioeconomic, ethnicity, age, and co-morbidity. We describe urban form at\nindividual building level and then aggregate information for official\nneighbourhoods, allowing for a detailed intra-urban representation. Results\nshow that: i) control variables significantly explain more variance of both\nCOVID-19 cases and deaths than the morphometric descriptors; ii) of what the\nlatter can explain, built-up density is indeed the most associated, though\ninversely. The typical London neighbourhood with high levels of COVID-19\ninfections and deaths resembles a suburb, featuring a low-density urban fabric\ndotted by larger free-standing buildings and framed by a poorly inter-connected\nstreet network.",
    "descriptor": "\nComments: 19 pages 2 figures, 2 tables (supplementary materials: 10 pages, 7 figures, 3 tables)\n",
    "authors": [
      "Alessandro Venerandi",
      "Luca Maria Aiello",
      "Sergio Porta"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08497"
  },
  {
    "id": "arXiv:2210.08500",
    "title": "This Patient Looks Like That Patient: Prototypical Networks for  Interpretable Diagnosis Prediction from Clinical Text",
    "abstract": "The use of deep neural models for diagnosis prediction from clinical text has\nshown promising results. However, in clinical practice such models must not\nonly be accurate, but provide doctors with interpretable and helpful results.\nWe introduce ProtoPatient, a novel method based on prototypical networks and\nlabel-wise attention with both of these abilities. ProtoPatient makes\npredictions based on parts of the text that are similar to prototypical\npatients - providing justifications that doctors understand. We evaluate the\nmodel on two publicly available clinical datasets and show that it outperforms\nexisting baselines. Quantitative and qualitative evaluations with medical\ndoctors further demonstrate that the model provides valuable explanations for\nclinical decision support.",
    "descriptor": "\nComments: AACL-IJCNLP 2022 Main Conference (Long Paper)\n",
    "authors": [
      "Betty van Aken",
      "Jens-Michalis Papaioannou",
      "Marcel G. Naik",
      "Georgios Eleftheriadis",
      "Wolfgang Nejdl",
      "Felix A. Gers",
      "Alexander L\u00f6ser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08500"
  },
  {
    "id": "arXiv:2210.08501",
    "title": "A Uniquely Solvable, Positivity-Preserving and Unconditionally Energy  Stable Numerical Scheme for the Functionalized Cahn-Hilliard Equation with  Logarithmic Potential",
    "abstract": "We propose and analyze a first-order finite difference scheme for the\nfunctionalized Cahn-Hilliard (FCH) equation with a logarithmic Flory-Huggins\npotential. The semi-implicit numerical scheme is designed based on a suitable\nconvex-concave decomposition of the FCH free energy. We prove unique\nsolvability of the numerical algorithm and verify its unconditional energy\nstability without any restriction on the time step size. Thanks to the singular\nnature of the logarithmic part in the Flory-Huggins potential near the pure\nstates $\\pm 1$, we establish the so-called positivity-preserving property for\nthe phase function at a theoretic level. As a consequence, the numerical\nsolutions will never reach the singular values $\\pm 1$ in the point-wise sense\nand the fully discrete scheme is well defined at each time step. Next, we\npresent a detailed optimal rate convergence analysis and derive error estimates\nin $l^{\\infty}(0,T;L_h^2)\\cap l^2(0,T;H^3_h)$ under a mild CFL condition $C_1\nh\\leq\\Delta t\\leq C_2 h$. To achieve the goal, a higher order asymptotic\nexpansion (up to the second order temporal and spatial accuracy) based on the\nFourier projection is utilized to control the discrete maximum norm of\nsolutions to the numerical scheme. We show that if the exact solution to the\ncontinuous problem is strictly separated from the pure states $\\pm 1$, then the\nnumerical solutions can be kept away from $\\pm 1$ by a positive distance that\nis uniform with respect to the size of the time step and the grid. Finally, a\nfew numerical experiments are presented to demonstrate the accuracy and\nrobustness of the proposed numerical scheme.",
    "descriptor": "\nComments: 37 pages, 11 figures\n",
    "authors": [
      "Wenbin Chen",
      "Jianyu Jing",
      "Hao Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.08501"
  },
  {
    "id": "arXiv:2210.08502",
    "title": "FIT: A Metric for Model Sensitivity",
    "abstract": "Model compression is vital to the deployment of deep learning on edge\ndevices. Low precision representations, achieved via quantization of weights\nand activations, can reduce inference time and memory requirements. However,\nquantifying and predicting the response of a model to the changes associated\nwith this procedure remains challenging. This response is non-linear and\nheterogeneous throughout the network. Understanding which groups of parameters\nand activations are more sensitive to quantization than others is a critical\nstage in maximizing efficiency. For this purpose, we propose FIT. Motivated by\nan information geometric perspective, FIT combines the Fisher information with\na model of quantization. We find that FIT can estimate the final performance of\na network without retraining. FIT effectively fuses contributions from both\nparameter and activation quantization into a single metric. Additionally, FIT\nis fast to compute when compared to existing methods, demonstrating favourable\nconvergence properties. These properties are validated experimentally across\nhundreds of quantization configurations, with a focus on layer-wise\nmixed-precision quantization.",
    "descriptor": "",
    "authors": [
      "Ben Zandonati",
      "Adrian Alan Pol",
      "Maurizio Pierini",
      "Olya Sirkin",
      "Tal Kopetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08502"
  },
  {
    "id": "arXiv:2210.08503",
    "title": "Entropy Regularized Reinforcement Learning with Cascading Networks",
    "abstract": "Deep Reinforcement Learning (Deep RL) has had incredible achievements on high\ndimensional problems, yet its learning process remains unstable even on the\nsimplest tasks. Deep RL uses neural networks as function approximators. These\nneural models are largely inspired by developments in the (un)supervised\nmachine learning community. Compared to these learning frameworks, one of the\nmajor difficulties of RL is the absence of i.i.d. data. One way to cope with\nthis difficulty is to control the rate of change of the policy at every\niteration. In this work, we challenge the common practices of the\n(un)supervised learning community of using a fixed neural architecture, by\nhaving a neural model that grows in size at each policy update. This allows a\nclosed form entropy regularized policy update, which leads to a better control\nof the rate of change of the policy at each iteration and help cope with the\nnon i.i.d. nature of RL. Initial experiments on classical RL benchmarks show\npromising results with remarkable convergence on some RL tasks when compared to\nother deep RL baselines, while exhibiting limitations on others.",
    "descriptor": "",
    "authors": [
      "Riccardo Della Vecchia",
      "Alena Shilova",
      "Philippe Preux",
      "Riad Akrour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08503"
  },
  {
    "id": "arXiv:2210.08506",
    "title": "ResAttUNet: Detecting Marine Debris using an Attention activated  Residual UNet",
    "abstract": "Currently, a significant amount of research has been done in field of Remote\nSensing with the use of deep learning techniques. The introduction of Marine\nDebris Archive (MARIDA), an open-source dataset with benchmark results, for\nmarine debris detection opened new pathways to use deep learning techniques for\nthe task of debris detection and segmentation. This paper introduces a novel\nattention based segmentation technique that outperforms the existing\nstate-of-the-art results introduced with MARIDA. The paper presents a novel\nspatial aware encoder and decoder architecture to maintain the contextual\ninformation and structure of sparse ground truth patches present in the images.\nThe attained results are expected to pave the path for further research\ninvolving deep learning using remote sensing images. The code is available at\nhttps://github.com/sheikhazhanmohammed/SADMA.git",
    "descriptor": "",
    "authors": [
      "Azhan Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08506"
  },
  {
    "id": "arXiv:2210.08507",
    "title": "New hybrid quadrature schemes for weakly singular kernels applied to  isogeometric boundary elements for 3D Stokes flow",
    "abstract": "This work proposes four novel hybrid quadrature schemes for the efficient and\naccurate evaluation of weakly singular boundary integrals (1/r kernel) on\narbitrary smooth surfaces. Such integrals appear in boundary element analysis\nfor several partial differential equations including the Stokes equation for\nviscous flow and the Helmholtz equation for acoustics. The proposed quadrature\nschemes apply a Duffy transform-based quadrature rule to surface elements\ncontaining the singularity and classical Gaussian quadrature to the remaining\nelements. Two of the four schemes additionally consider a special treatment for\nelements near to the singularity, where refined Gaussian quadrature and a new\nmoment-fitting quadrature rule are used.\nThe hybrid quadrature schemes are systematically studied on flat B-spline\npatches and on NURBS spheres considering two different sphere discretizations:\nAn exact single-patch sphere with degenerate control points at the poles and an\napproximate discretization that consist of six patches with regular elements.\nThe efficiency of the quadrature schemes is further demonstrated in boundary\nelement analysis for Stokes flow, where steady problems with rotating and\ntranslating curved objects are investigated in convergence studies for both,\nmesh and quadrature refinement. Much higher convergence rates are observed for\nthe proposed new schemes in comparison to classical schemes.",
    "descriptor": "",
    "authors": [
      "Maximilian Harmel",
      "Roger Andrew Sauer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08507"
  },
  {
    "id": "arXiv:2210.08508",
    "title": "RevaMp3D: Architecting the Processor Core and Cache Hierarchy for  Systems with Monolithically-Integrated Logic and Memory",
    "abstract": "Recent nano-technological advances enable the Monolithic 3D (M3D) integration\nof multiple memory and logic layers in a single chip with fine-grained\nconnections. M3D technology leads to significantly higher main memory bandwidth\nand shorter latency than existing 3D-stacked systems. We show for a variety of\nworkloads on a state-of-the-art M3D system that the performance and energy\nbottlenecks shift from the main memory to the core and cache hierarchy. Hence,\nthere is a need to revisit current core and cache designs that have been\nconventionally tailored to tackle the memory bottleneck.\nOur goal is to redesign the core and cache hierarchy, given the fundamentally\nnew trade-offs of M3D, to benefit a wide range of workloads. To this end, we\ntake two steps. First, we perform a design space exploration of the cache and\ncore's key components. We highlight that in M3D systems, (i) removing the\nshared last-level cache leads to similar or larger performance benefits than\nincreasing its size or reducing its latency; (ii) improving L1 latency has a\nlarge impact on improving performance; (iii) wider pipelines are increasingly\nbeneficial; (iv) the performance impact of branch speculation and pipeline\nfrontend increases; (v) the current synchronization schemes limit parallel\nspeedup. Second, we propose an optimized M3D system, RevaMp3D, where (i) using\nthe tight connectivity between logic layers, we efficiently increase pipeline\nwidth, reduce L1 latency, and enable fine-grained synchronization; (ii) using\nthe high-bandwidth and energy-efficient main memory, we alleviate the amplified\nenergy and speculation bottlenecks by memoizing the repetitive fetched,\ndecoded, and reordered instructions and turning off the relevant parts of the\ncore pipeline when possible. RevaMp3D provides, on average, 81% speedup, 35%\nenergy reduction, and 12.3% smaller area compared to the baseline M3D system.",
    "descriptor": "",
    "authors": [
      "Nika Mansouri Ghiasi",
      "Mohammad Sadrosadati",
      "Geraldo F. Oliveira",
      "Konstantinos Kanellopoulos",
      "Rachata Ausavarungnirun",
      "Juan G\u00f3mez Luna",
      "Aditya Manglik",
      "Jo\u00e3o Ferreira",
      "Jeremie S. Kim",
      "Christina Giannoula",
      "Nandita Vijaykumar",
      "Jisung Park",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08508"
  },
  {
    "id": "arXiv:2210.08511",
    "title": "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations",
    "abstract": "Dialogue contradiction is a critical issue in open-domain dialogue systems.\nThe contextualization nature of conversations makes dialogue contradiction\ndetection rather challenging. In this work, we propose a benchmark for\nContradiction Detection in Chinese Conversations, namely CDConv. It contains\n12K multi-turn conversations annotated with three typical contradiction\ncategories: Intra-sentence Contradiction, Role Confusion, and History\nContradiction. To efficiently construct the CDConv conversations, we devise a\nseries of methods for automatic conversation generation, which simulate common\nuser behaviors that trigger chatbots to make contradictions. We conduct careful\nmanual quality screening of the constructed conversations and show that\nstate-of-the-art Chinese chatbots can be easily goaded into making\ncontradictions. Experiments on CDConv show that properly modeling contextual\ninformation is critical for dialogue contradiction detection, but there are\nstill unresolved challenges that require future research.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Chujie Zheng",
      "Jinfeng Zhou",
      "Yinhe Zheng",
      "Libiao Peng",
      "Zhen Guo",
      "Wenquan Wu",
      "Zhengyu Niu",
      "Hua Wu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08511"
  },
  {
    "id": "arXiv:2210.08518",
    "title": "OST: Efficient One-stream Network for 3D Single Object Tracking in Point  Clouds",
    "abstract": "Although recent Siamese network-based trackers have achieved impressive\nperceptual accuracy for single object tracking in LiDAR point clouds, they\nadvance with some heavy correlation operations on relation modeling and\noverlook the inherent merit of arbitrariness compared to multiple object\ntracking. In this work, we propose a radically novel one-stream network with\nthe strength of the Transformer encoding, which avoids the correlation\noperations occurring in previous Siamese network, thus considerably reducing\nthe computational effort. In particular, the proposed method mainly consists of\na Template-aware Transformer Module (TTM) and a Multi-scale Feature Aggregation\n(MFA) module capable of fusing spatial and semantic information. The TTM\nstitches the specified template and the search region together and leverages an\nattention mechanism to establish the information flow, breaking the previous\npattern of independent \\textit{extraction-and-correlation}. As a result, this\nmodule makes it possible to directly generate template-aware features that are\nsuitable for the arbitrary and continuously changing nature of the target,\nenabling the model to deal with unseen categories. In addition, the MFA is\nproposed to make spatial and semantic information complementary to each other,\nwhich is characterized by reverse directional feature propagation that\naggregates information from shallow to deep layers. Extensive experiments on\nKITTI and nuScenes demonstrate that our method has achieved considerable\nperformance not only for class-specific tracking but also for class-agnostic\ntracking with less computation and higher efficiency.",
    "descriptor": "",
    "authors": [
      "Xiantong Zhao",
      "Yinan Han",
      "Shengjing Tian",
      "Jian Liu",
      "Xiuping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08518"
  },
  {
    "id": "arXiv:2210.08519",
    "title": "PCR: Pessimistic Consistency Regularization for Semi-Supervised  Segmentation",
    "abstract": "Currently, state-of-the-art semi-supervised learning (SSL) segmentation\nmethods employ pseudo labels to train their models, which is an optimistic\ntraining manner that supposes the predicted pseudo labels are correct. However,\ntheir models will be optimized incorrectly when the above assumption does not\nhold. In this paper, we propose a Pessimistic Consistency Regularization (PCR)\nwhich considers a pessimistic case that pseudo labels are not always correct.\nPCR makes it possible for our model to learn the ground truth (GT) in pessimism\nby adaptively providing a candidate label set containing K proposals for each\nunlabeled pixel. Specifically, we propose a pessimistic consistency loss which\ntrains our model to learn the possible GT from multiple candidate labels. In\naddition, we develop a candidate label proposal method to adaptively decide\nwhich pseudo labels are provided for each pixel. Our method is easy to\nimplement and could be applied to existing baselines without changing their\nframeworks. Theoretical analysis and experiments on various benchmarks\ndemonstrate the superiority of our approach to state-of-the-art alternatives.",
    "descriptor": "",
    "authors": [
      "Pengchong Qiao",
      "Zhidan Wei",
      "Yu Wang",
      "Chang Liu",
      "Zhennan Wang",
      "Guoli Song",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08519"
  },
  {
    "id": "arXiv:2210.08520",
    "title": "A Policy-based Approach to the SpecAugment Method for Low Resource E2E  ASR",
    "abstract": "SpecAugment is a very effective data augmentation method for both HMM and\nE2E-based automatic speech recognition (ASR) systems. Especially, it also works\nin low-resource scenarios. However, SpecAugment masks the spectrum of time or\nthe frequency domain in a fixed augmentation policy, which may bring relatively\nless data diversity to the low-resource ASR. In this paper, we propose a\npolicy-based SpecAugment (Policy-SpecAugment) method to alleviate the above\nproblem. The idea is to use the augmentation-select policy and the\naugmentation-parameter changing policy to solve the fixed way. These policies\nare learned based on the loss of validation set, which is applied to the\ncorresponding augmentation policies. It aims to encourage the model to learn\nmore diverse data, which the model relatively requires. In experiments, we\nevaluate the effectiveness of our approach in low-resource scenarios, i.e., the\n100 hours librispeech task. According to the results and analysis, we can see\nthat the above issue can be obviously alleviated using our proposal. In\naddition, the experimental results show that, compared with the\nstate-of-the-art SpecAugment, the proposed Policy-SpecAugment has a relative\nWER reduction of more than 10% on the Test/Dev-clean set, more than 5% on the\nTest/Dev-other set, and an absolute WER reduction of more than 1% on all test\nsets.",
    "descriptor": "\nComments: Accepted to APSIPA ASC 2022\n",
    "authors": [
      "Rui Li",
      "Guodong Ma",
      "Dexin Zhao",
      "Ranran Zeng",
      "Xiaoyu Li",
      "Hao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08520"
  },
  {
    "id": "arXiv:2210.08521",
    "title": "Demystifying CNNs for Images by Matched Filters",
    "abstract": "The success of convolution neural networks (CNN) has been revolutionising the\nway we approach and use intelligent machines in the Big Data era. Despite\nsuccess, CNNs have been consistently put under scrutiny owing to their\n\\textit{black-box} nature, an \\textit{ad hoc} manner of their construction,\ntogether with the lack of theoretical support and physical meanings of their\noperation. This has been prohibitive to both the quantitative and qualitative\nunderstanding of CNNs, and their application in more sensitive areas such as AI\nfor health. We set out to address these issues, and in this way demystify the\noperation of CNNs, by employing the perspective of matched filtering. We first\nilluminate that the convolution operation, the very core of CNNs, represents a\nmatched filter which aims to identify the presence of features in input data.\nThis then serves as a vehicle to interpret the convolution-activation-pooling\nchain in CNNs under the theoretical umbrella of matched filtering, a common\noperation in signal processing. We further provide extensive examples and\nexperiments to illustrate this connection, whereby the learning in CNNs is\nshown to also perform matched filtering, which further sheds light onto\nphysical meaning of learnt parameters and layers. It is our hope that this\nmaterial will provide new insights into the understanding, constructing and\nanalysing of CNNs, as well as paving the way for developing new methods and\narchitectures of CNNs.",
    "descriptor": "",
    "authors": [
      "Shengxi Li",
      "Xinyi Zhao",
      "Ljubisa Stankovic",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08521"
  },
  {
    "id": "arXiv:2210.08523",
    "title": "Some Languages are More Equal than Others: Probing Deeper into the  Linguistic Disparity in the NLP World",
    "abstract": "Linguistic disparity in the NLP world is a problem that has been widely\nacknowledged recently. However, different facets of this problem, or the\nreasons behind this disparity are seldom discussed within the NLP community.\nThis paper provides a comprehensive analysis of the disparity that exists\nwithin the languages of the world. We show that simply categorising languages\nconsidering data availability may not be always correct. Using an existing\nlanguage categorisation based on speaker population and vitality, we analyse\nthe distribution of language data resources, amount of NLP/CL research,\ninclusion in multilingual web-based platforms and the inclusion in pre-trained\nmultilingual models. We show that many languages do not get covered in these\nresources or platforms, and even within the languages belonging to the same\nlanguage group, there is wide disparity. We analyse the impact of family,\ngeographical location, GDP and the speaker population of languages and provide\npossible reasons for this disparity, along with some suggestions to overcome\nthe same.",
    "descriptor": "",
    "authors": [
      "Surangika Ranathunga",
      "Nisansa de Silva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08523"
  },
  {
    "id": "arXiv:2210.08528",
    "title": "Comparing Synthetic Tabular Data Generation Between a Probabilistic  Model and a Deep Learning Model for Education Use Cases",
    "abstract": "The ability to generate synthetic data has a variety of use cases across\ndifferent domains. In education research, there is a growing need to have\naccess to synthetic data to test certain concepts and ideas. In recent years,\nseveral deep learning architectures were used to aid in the generation of\nsynthetic data but with varying results. In the education context, the\nsophistication of implementing different models requiring large datasets is\nbecoming very important. This study aims to compare the application of\nsynthetic tabular data generation between a probabilistic model specifically a\nBayesian Network, and a deep learning model, specifically a Generative\nAdversarial Network using a classification task. The results of this study\nindicate that synthetic tabular data generation is better suited for the\neducation context using probabilistic models (overall accuracy of 75%) than\ndeep learning architecture (overall accuracy of 38%) because of probabilistic\ninterdependence. Lastly, we recommend that other data types, should be explored\nand evaluated for their application in generating synthetic data for education\nuse cases.",
    "descriptor": "\nComments: 11 paged, 5 figures, Proceedings for the SACAIR 2023 Conference\n",
    "authors": [
      "Herkulaas MvE Combrink",
      "Vukosi Marivate",
      "Benjamin Rosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08528"
  },
  {
    "id": "arXiv:2210.08529",
    "title": "Towards Effective Image Manipulation Detection with Proposal Contrastive  Learning",
    "abstract": "Deep models have been widely and successfully used in image manipulation\ndetection, which aims to classify tampered images and localize tampered\nregions. Most existing methods mainly focus on extracting \\textit{global\nfeatures} from tampered images, while neglecting the \\textit{relationships of\nlocal features} between tampered and authentic regions within a single tampered\nimage. To exploit such spatial relationships, we propose Proposal Contrastive\nLearning (PCL) for effective image manipulation detection. Our PCL consists of\na two-stream architecture by extracting two types of global features from RGB\nand noise views respectively. To further improve the discriminative power, we\nexploit the relationships of local features through a proxy proposal\ncontrastive learning task by attracting/repelling proposal-based\npositive/negative sample pairs. Moreover, we show that our PCL can be easily\nadapted to unlabeled data in practice, which can reduce manual labeling costs\nand promote more generalizable features. Extensive experiments among several\nstandard datasets demonstrate that our PCL can be a general module to obtain\nconsistent improvement.",
    "descriptor": "",
    "authors": [
      "Yuyuan Zeng",
      "Bowen Zhao",
      "Shanzhao Qiu",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08529"
  },
  {
    "id": "arXiv:2210.08530",
    "title": "Logical Relations for Partial Features and Automatic Differentiation  Correctness",
    "abstract": "We present a simple technique for semantic, open logical relations arguments\nabout languages with recursive types, which, as we show, follows from a\nprincipled foundation in categorical semantics. We demonstrate how it can be\nused to give a very straightforward proof of correctness of practical forward-\nand reverse-mode dual numbers style automatic differentiation (AD) on ML-family\nlanguages. The key idea is to combine it with a suitable open logical relations\ntechnique for reasoning about differentiable partial functions (a suitable\nlifting of the partiality monad to logical relations), which we introduce.",
    "descriptor": "\nComments: conference paper, 25 pages. arXiv admin note: substantial text overlap with arXiv:2210.07724\n",
    "authors": [
      "Fernando Lucatelli Nunes",
      "Matthijs V\u00e1k\u00e1r"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08530"
  },
  {
    "id": "arXiv:2210.08532",
    "title": "AskYourDB: An end-to-end system for querying and visualizing relational  databases using natural language",
    "abstract": "Querying databases for the right information is a time consuming and\nerror-prone task and often requires experienced professionals for the job.\nFurthermore, the user needs to have some prior knowledge about the database.\nThere have been various efforts to develop an intelligence which can help\nbusiness users to query databases directly. However, there has been some\nsuccesses, but very little in terms of testing and deploying those for real\nworld users. In this paper, we propose a semantic parsing approach to address\nthe challenge of converting complex natural language into SQL and institute a\nproduct out of it. For this purpose, we modified state-of-the-art models, by\nvarious pre and post processing steps which make the significant part when a\nmodel is deployed in production. To make the product serviceable to businesses\nwe added an automatic visualization framework over the queried results.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Manu Joseph",
      "Harsh Raj",
      "Anubhav Yadav",
      "Aaryamann Sharma"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08532"
  },
  {
    "id": "arXiv:2210.08535",
    "title": "Realistic, Animatable Human Reconstructions for Virtual Fit-On",
    "abstract": "We present an end-to-end virtual try-on pipeline, that can fit different\nclothes on a personalized 3-D human model, reconstructed using a single RGB\nimage. Our main idea is to construct an animatable 3-D human model and try-on\ndifferent clothes in a 3-D virtual environment. The existing frame by frame\nvolumetric reconstruction of 3-D human models are highly resource-demanding and\ndo not allow clothes switching. Moreover, existing virtual fit-on systems also\nlack realism due to predominantly being 2-D or not using user's features in the\nreconstruction. These shortcomings are due to either the human body or clothing\nmodel being 2-D or not having the user's facial features in the dressed model.\nWe solve these problems by manipulating a parametric representation of the 3-D\nhuman body model and stitching a head model reconstructed from the actual\nimage. Fitting the 3-D clothing models on the parameterized human model is also\nadjustable to the body shape of the input image. Our reconstruction results, in\ncomparison with recent existing work, are more visually-pleasing.",
    "descriptor": "",
    "authors": [
      "Gayal Kuruppu",
      "Bumuthu Dilshan",
      "Shehan Samarasinghe",
      "Nipuna Madhushan",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08535"
  },
  {
    "id": "arXiv:2210.08536",
    "title": "Knowledge Prompting in Pre-trained Language Model for Natural Language  Understanding",
    "abstract": "Knowledge-enhanced Pre-trained Language Model (PLM) has recently received\nsignificant attention, which aims to incorporate factual knowledge into PLMs.\nHowever, most existing methods modify the internal structures of fixed types of\nPLMs by stacking complicated modules, and introduce redundant and irrelevant\nfactual knowledge from knowledge bases (KBs). In this paper, to address these\nproblems, we introduce a seminal knowledge prompting paradigm and further\npropose a knowledge-prompting-based PLM framework KP-PLM. This framework can be\nflexibly combined with existing mainstream PLMs. Specifically, we first\nconstruct a knowledge sub-graph from KBs for each context. Then we design\nmultiple continuous prompts rules and transform the knowledge sub-graph into\nnatural language prompts. To further leverage the factual knowledge from these\nprompts, we propose two novel knowledge-aware self-supervised tasks including\nprompt relevance inspection and masked prompt modeling. Extensive experiments\non multiple natural language understanding (NLU) tasks show the superiority of\nKP-PLM over other state-of-the-art methods in both full-resource and\nlow-resource settings.",
    "descriptor": "\nComments: 14 pages, 5 figures. This paper has been accepted for the main conference of EMNLP2022 (long paper)\n",
    "authors": [
      "Jianing Wang",
      "Wenkang Huang",
      "Qiuhui Shi",
      "Hongbin Wang",
      "Minghui Qiu",
      "Xiang Li",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08536"
  },
  {
    "id": "arXiv:2210.08537",
    "title": "Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and  Visual Affordance",
    "abstract": "Currently, task-oriented grasp detection approaches are mostly based on\npixel-level affordance detection and semantic segmentation. These pixel-level\napproaches heavily rely on the accuracy of a 2D affordance mask, and the\ngenerated grasp candidates are restricted to a small workspace. To mitigate\nthese limitations, we first construct a novel affordance-based grasp dataset\nand propose a 6-DoF task-oriented grasp detection framework, which takes the\nobserved object point cloud as input and predicts diverse 6-DoF grasp poses for\ndifferent tasks. Specifically, our implicit estimation network and visual\naffordance network in this framework could directly predict coarse grasp\ncandidates, and corresponding 3D affordance heatmap for each potential task,\nrespectively. Furthermore, the grasping scores from coarse grasps are combined\nwith heatmap values to generate more accurate and finer candidates. Our\nproposed framework shows significant improvements compared to baselines for\nexisting and novel objects on our simulation dataset. Although our framework is\ntrained based on the simulated objects and environment, the final generated\ngrasp candidates can be accurately and stably executed in real robot\nexperiments when the object is randomly placed on a support surface.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Wenkai Chen",
      "Hongzhuo Liang",
      "Zhaopeng Chen",
      "Fuchun Sun",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08537"
  },
  {
    "id": "arXiv:2210.08538",
    "title": "Advantages of OKID-ERA Identification in Control Systems. An Application  to the Tennessee Eastman Plant",
    "abstract": "Data-driven OKID-ERA identification of the open-loop Tennessee Eastman plant\nis performed to obtain a linear model for control design purposes. Analysis\nsuch as numerical conditioning, output response errors, and zero-pole mappings\nhighlight some definite advantages of the OKID-ERA approach when compared with\nmodels derived from typical linearization techniques. The plant under study is\na recognized benchmark in the field of plant-wide control systems.",
    "descriptor": "",
    "authors": [
      "Sergio F. Yapur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08538"
  },
  {
    "id": "arXiv:2210.08540",
    "title": "TransAlign: Fully Automatic and Effective Entity Alignment for Knowledge  Graphs",
    "abstract": "The task of entity alignment between knowledge graphs (KGs) aims to identify\nevery pair of entities from two different KGs that represent the same entity.\nMany machine learning-based methods have been proposed for this task. However,\nto our best knowledge, existing methods all require manually crafted seed\nalignments, which are expensive to obtain. In this paper, we propose the first\nfully automatic alignment method named TransAlign, which does not require any\nmanually crafted seed alignments. Specifically, for predicate embeddings,\nTransAlign constructs a predicate-proximity-graph to automatically capture the\nsimilarity between predicates across two KGs by learning the attention of\nentity types. For entity embeddings, TransAlign first computes the entity\nembeddings of each KG independently using TransE, and then shifts the two KGs'\nentity embeddings into the same vector space by computing the similarity\nbetween entities based on their attributes. Thus, both predicate alignment and\nentity alignment can be done without manually crafted seed alignments.\nTransAlign is not only fully automatic, but also highly effective. Experiments\nusing real-world KGs show that TransAlign improves the accuracy of entity\nalignment significantly compared to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Rui Zhang",
      "Xiaoyan Zhao",
      "Bayu Distiawan Trisedya",
      "Min Yang",
      "Hong Cheng",
      "Jianzhong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08540"
  },
  {
    "id": "arXiv:2210.08548",
    "title": "Investigating the Robustness of Natural Language Generation from Logical  Forms via Counterfactual Samples",
    "abstract": "The aim of Logic2Text is to generate controllable and faithful texts\nconditioned on tables and logical forms, which not only requires a deep\nunderstanding of the tables and logical forms, but also warrants symbolic\nreasoning over the tables. State-of-the-art methods based on pre-trained models\nhave achieved remarkable performance on the standard test dataset. However, we\nquestion whether these methods really learn how to perform logical reasoning,\nrather than just relying on the spurious correlations between the headers of\nthe tables and operators of the logical form. To verify this hypothesis, we\nmanually construct a set of counterfactual samples, which modify the original\nlogical forms to generate counterfactual logical forms with rarely co-occurred\ntable headers and logical operators. SOTA methods give much worse results on\nthese counterfactual samples compared with the results on the original test\ndataset, which verifies our hypothesis. To deal with this problem, we firstly\nanalyze this bias from a causal perspective, based on which we propose two\napproaches to reduce the model's reliance on the shortcut. The first one\nincorporates the hierarchical structure of the logical forms into the model.\nThe second one exploits automatically generated counterfactual data for\ntraining. Automatic and manual experimental results on the original test\ndataset and the counterfactual dataset show that our method is effective to\nalleviate the spurious correlation. Our work points out the weakness of\nprevious methods and takes a further step toward developing Logic2Text models\nwith real logical reasoning ability.",
    "descriptor": "\nComments: Accepted to appear at the main conference of EMNLP 2022\n",
    "authors": [
      "Chengyuan Liu",
      "Leilei Gan",
      "Kun Kuang",
      "Fei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08548"
  },
  {
    "id": "arXiv:2210.08550",
    "title": "Assessing the Optimality of LinDist3Flow for Optimal Tap Selection of  Step Voltage Regulators in Unbalanced Distribution Networks",
    "abstract": "The adoption of distributed energy resources such as photovoltaics (PVs) has\nincreased dramatically during the previous decade. The increased penetration of\nPVs into distribution networks (DNs) can cause voltage fluctuations that have\nto be mitigated. One of the key utility assets employed to this end are\nstep-voltage regulators (SVRs). It is desirable to include tap selection of\nSVRs in optimal power flow (OPF) routines, a task that turns out to be\nchallenging because the resultant OPF problem is nonconvex with added\ncomplexities stemming from accurate SVR modeling. While several convex\nrelaxations based on semi-definite programming (SDP) have been presented in the\nliterature for optimal tap selection, SDP-based schemes do not scale well and\nare challenging to implement in large-scale planning or operational frameworks.\nThis paper deals with the optimal tap selection (OPTS) problem for\nwye-connected SVRs using linear approximations of power flow equations.\nSpecifically, the $\\textit{LinDist3Flow}$ model is adopted and the effective\nSVR ratio is assumed to be continuous--enabling the formulation of a problem\ncalled $\\textit{LinDist3Flow-OPTS}$, which amounts to a linear program. The\nscalability and optimality gap of $\\textit{LinDist3Flow-OPTS}$ are evaluated\nwith respect to existing SDP-based and nonlinear programming techniques for\noptimal tap selection in three standard feeders, namely, the IEEE 13-bus,\n123-bus, and 8500-node DNs. For all DNs considered,\n$\\textit{LinDist3Flow-OPTS}$ achieves an optimality gap of approximately $1\\%$\nor less while significantly lowering the computational burden.",
    "descriptor": "\nComments: Accepted at the 61st IEEE Conference on Decision and Control - Dec. 6-9, 2022, in Canc\\'un, Mexico\n",
    "authors": [
      "Krishna Sandeep Ayyagari",
      "Sherin Ann Abraham",
      "Yiyun Yao",
      "Shibani Ghosh",
      "Francisco Flores-Espino",
      "Adarsh Nagarajan",
      "Nikolaos Gatsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08550"
  },
  {
    "id": "arXiv:2210.08554",
    "title": "COFAR: Commonsense and Factual Reasoning in Image Search",
    "abstract": "One characteristic that makes humans superior to modern artificially\nintelligent models is the ability to interpret images beyond what is visually\napparent. Consider the following two natural language search queries - (i) \"a\nqueue of customers patiently waiting to buy ice cream\" and (ii) \"a queue of\ntourists going to see a famous Mughal architecture in India.\" Interpreting\nthese queries requires one to reason with (i) Commonsense such as interpreting\npeople as customers or tourists, actions as waiting to buy or going to see; and\n(ii) Fact or world knowledge associated with named visual entities, for\nexample, whether the store in the image sells ice cream or whether the landmark\nin the image is a Mughal architecture located in India. Such reasoning goes\nbeyond just visual recognition. To enable both commonsense and factual\nreasoning in the image search, we present a unified framework, namely Knowledge\nRetrieval-Augmented Multimodal Transformer (KRAMT), that treats the named\nvisual entities in an image as a gateway to encyclopedic knowledge and\nleverages them along with natural language query to ground relevant knowledge.\nFurther, KRAMT seamlessly integrates visual content and grounded knowledge to\nlearn alignment between images and search queries. This unified framework is\nthen used to perform image search requiring commonsense and factual reasoning.\nThe retrieval performance of KRAMT is evaluated and compared with related\napproaches on a new dataset we introduce - namely COFAR. We make our code and\ndataset available at https://vl2g.github.io/projects/cofar",
    "descriptor": "\nComments: Accepted in AACL-IJCNLP 2022\n",
    "authors": [
      "Prajwal Gatti",
      "Abhirama Subramanyam Penamakuri",
      "Revant Teotia",
      "Anand Mishra",
      "Shubhashis Sengupta",
      "Roshni Ramnani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08554"
  },
  {
    "id": "arXiv:2210.08559",
    "title": "Coordinated Topic Modeling",
    "abstract": "We propose a new problem called coordinated topic modeling that imitates\nhuman behavior while describing a text corpus. It considers a set of\nwell-defined topics like the axes of a semantic space with a reference\nrepresentation. It then uses the axes to model a corpus for easily\nunderstandable representation. This new task helps represent a corpus more\ninterpretably by reusing existing knowledge and benefits the corpora comparison\ntask. We design ECTM, an embedding-based coordinated topic model that\neffectively uses the reference representation to capture the target\ncorpus-specific aspects while maintaining each topic's global semantics. In\nECTM, we introduce the topic- and document-level supervision with a\nself-training mechanism to solve the problem. Finally, extensive experiments on\nmultiple domains show the superiority of our model over other baselines.",
    "descriptor": "",
    "authors": [
      "Pritom Saha Akash",
      "Jie Huang",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08559"
  },
  {
    "id": "arXiv:2210.08562",
    "title": "A New Spatio-Temporal Loss Function for 3D Motion Reconstruction and  Extended Temporal Metrics for Motion Evaluation",
    "abstract": "We propose a new loss function that we call Laplacian loss, based on\nspatio-temporal Laplacian representation of the motion as a graph. This loss\nfunction is intended to be used in training models for motion reconstruction\nthrough 3D human pose estimation from videos. It compares the differential\ncoordinates of the joints obtained from the graph representation of the ground\ntruth against the one of the estimation. We design a fully convolutional\ntemporal network for motion reconstruction to achieve better temporal\nconsistency of estimation. We use this generic model to study the impact of our\nproposed loss function on the benchmarks provided by Human3.6M. We also make\nuse of various motion descriptors such as velocity, acceleration to make a\nthorough evaluation of the temporal consistency while comparing the results to\nsome of the state-of-the-art solutions.",
    "descriptor": "",
    "authors": [
      "Mansour Tchenegnon",
      "Sylvie Gibet",
      "Thibaut Le Naour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08562"
  },
  {
    "id": "arXiv:2210.08568",
    "title": "High-order finite-difference entropy stable schemes for two-fluid  relativistic plasma flow equations",
    "abstract": "In this article, we propose high-order finite-difference entropy stable\nschemes for the two-fluid relativistic plasma flow equations. This is achieved\nby exploiting the structure of the equations, which consists of three\nindependent flux components. The first two components describe the ion and\nelectron flows, which are modeled using the relativistic hydrodynamics\nequation. The third component is Maxwell's equations, which are linear systems.\nThe coupling of the ion and electron flows, and electromagnetic fields is via\nsource terms only. Furthermore, we also show that the source terms do not\naffect the entropy evolution.\nTo design semi-discrete entropy stable schemes, we extend the RHD entropy\nstable schemes in Bhoriya et al. to three dimensions. This is then coupled with\nentropy stable discretization of the Maxwell's equations. Finally, we use\nSSP-RK schemes to discretize in time. We also propose ARK-IMEX schemes to treat\nthe stiff source terms; the resulting nonlinear set of algebraic equations is\nlocal (at each discretization point). These equations are solved using the\nNewton's Method, which results in an efficient method. The proposed schemes are\nthen tested using various test problems to demonstrate their stability,\naccuracy and efficiency.",
    "descriptor": "",
    "authors": [
      "Deepak Bhoriya",
      "Harish Kumar",
      "Praveen Chandrashekar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08568"
  },
  {
    "id": "arXiv:2210.08569",
    "title": "Biased or Limited: Modeling Sub-Rational Human Investors in Financial  Markets",
    "abstract": "Multi-agent market simulation is an effective tool to investigate the impact\nof various trading strategies in financial markets. One way of designing a\ntrading agent in simulated markets is through reinforcement learning where the\nagent is trained to optimize its cumulative rewards (e.g., maximizing profits,\nminimizing risk, improving equitability). While the agent learns a rational\npolicy that optimizes the reward function, in reality, human investors are\nsub-rational with their decisions often differing from the optimal. In this\nwork, we model human sub-rationality as resulting from two possible causes:\npsychological bias and computational limitation. We first examine the\nrelationship between investor profits and their degree of sub-rationality, and\ncreate hand-crafted market scenarios to intuitively explain the sub-rational\nhuman behaviors. Through experiments, we show that our models successfully\ncapture human sub-rationality as observed in the behavioral finance literature.\nWe also examine the impact of sub-rational human investors on market\nobservables such as traded volumes, spread and volatility. We believe our work\nwill benefit research in behavioral finance and provide a better understanding\nof human trading behavior.",
    "descriptor": "\nComments: Accepted to ICAIF'22 Workshop on Machine Learning for Investor Modelling\n",
    "authors": [
      "Penghang Liu",
      "Kshama Dwarakanath",
      "Svitlana S Vyetrenko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2210.08569"
  },
  {
    "id": "arXiv:2210.08572",
    "title": "Automatic Differentiation of Programs with Discrete Randomness",
    "abstract": "Automatic differentiation (AD), a technique for constructing new programs\nwhich compute the derivative of an original program, has become ubiquitous\nthroughout scientific computing and deep learning due to the improved\nperformance afforded by gradient-based optimization. However, AD systems have\nbeen restricted to the subset of programs that have a continuous dependence on\nparameters. Programs that have discrete stochastic behaviors governed by\ndistribution parameters, such as flipping a coin with probability of being\nheads, pose a challenge to these systems because the connection between the\nresult (heads vs tails) and the parameters ($p$) is fundamentally discrete. In\nthis paper we develop a new reparameterization-based methodology that allows\nfor generating programs whose expectation is the derivative of the expectation\nof the original program. We showcase how this method gives an unbiased and\nlow-variance estimator which is as automated as traditional AD mechanisms. We\ndemonstrate unbiased forward-mode AD of discrete-time Markov chains,\nagent-based models such as Conway's Game of Life, and unbiased reverse-mode AD\nof a particle filter. Our code is available at\nhttps://github.com/gaurav-arya/StochasticAD.jl.",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready. 10 pages in the main text, 27 pages total, 5 figures\n",
    "authors": [
      "Gaurav Arya",
      "Moritz Schauer",
      "Frank Sch\u00e4fer",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.08572"
  },
  {
    "id": "arXiv:2210.08573",
    "title": "DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using  Image-to-Image Diffusion Models",
    "abstract": "Recent generative models show impressive results in photo-realistic image\ngeneration. However, artifacts often inevitably appear in the generated\nresults, leading to downgraded user experience and reduced performance in\ndownstream tasks. This work aims to develop a plugin post-processing module for\ndiverse generative models, which can faithfully restore images from diverse\ngenerative artifacts. This is challenging because: (1) Unlike traditional\ndegradation patterns, generative artifacts are non-linear and the\ntransformation function is highly complex. (2) There are no readily available\nartifact-image pairs. (3) Different from model-specific anti-artifact methods,\na model-agnostic framework views the generator as a black-box machine and has\nno access to the architecture details. In this work, we first design a group of\nmechanisms to simulate generative artifacts of popular generators (i.e., GANs,\nautoregressive models, and diffusion models), given real images. Second, we\nimplement the model-agnostic anti-artifact framework as an image-to-image\ndiffusion model, due to its advantage in generation quality and capacity.\nFinally, we design a conditioning scheme for the diffusion model to enable both\nblind and non-blind image restoration. A guidance parameter is also introduced\nto allow for a trade-off between restoration accuracy and image quality.\nExtensive experiments show that our method significantly outperforms previous\napproaches on the proposed datasets and real-world artifact images.",
    "descriptor": "",
    "authors": [
      "Yueqin Yin",
      "Lianghua Huang",
      "Yu Liu",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08573"
  },
  {
    "id": "arXiv:2210.08577",
    "title": "Stochastic Occupancy Grid Map Prediction in Dynamic Scenes",
    "abstract": "This paper presents two variations of a novel stochastic prediction algorithm\nthat enables mobile robots to accurately and robustly predict the future state\nof complex dynamic scenes, such as environments full of people. The proposed\nalgorithm uses a variational autoencoder-based neural network to predict a\nrange of possible future states of the environment. The algorithm takes full\nadvantage of the motion of the robot itself, the motion of dynamic objects, and\nthe geometry of static objects in the scene to improve prediction accuracy.\nThree different datasets collected by different robot models are used to\ndemonstrate that the proposed algorithm is able to achieve smaller absolute\nerror, higher structure similarity, and higher tracking accuracy than\nstate-of-the-art prediction algorithms for video prediction tasks.\nImplementations of both proposed stochastic prediction algorithms are available\nopen source at https://github.com/TempleRAIL/SOGMP.",
    "descriptor": "",
    "authors": [
      "Zhanteng Xie",
      "Philip Dames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08577"
  },
  {
    "id": "arXiv:2210.08578",
    "title": "Data-Model-Hardware Tri-Design for Energy-Efficient Video Intelligence",
    "abstract": "In this paper, we propose a data-model-hardware tri-design framework for\nhigh-throughput, low-cost, and high-accuracy multi-object tracking (MOT) on\nHigh-Definition (HD) video stream. First, to enable ultra-light video\nintelligence, we propose temporal frame-filtering and spatial saliency-focusing\napproaches to reduce the complexity of massive video data. Second, we exploit\nstructure-aware weight sparsity to design a hardware-friendly model compression\nmethod. Third, assisted with data and model complexity reduction, we propose a\nsparsity-aware, scalable, and low-power accelerator design, aiming to deliver\nreal-time performance with high energy efficiency. Different from existing\nworks, we make a solid step towards the synergized software/hardware\nco-optimization for realistic MOT model implementation. Compared to the\nstate-of-the-art MOT baseline, our tri-design approach can achieve 12.5x\nlatency reduction, 20.9x effective frame rate improvement, 5.83x lower power,\nand 9.78x better energy efficiency, without much accuracy drop.",
    "descriptor": "\nComments: Accepted to ASP-DAC'23\n",
    "authors": [
      "Yimeng Zhang",
      "Akshay Karkal Kamath",
      "Qiucheng Wu",
      "Zhiwen Fan",
      "Wuyang Chen",
      "Zhangyang Wang",
      "Shiyu Chang",
      "Sijia Liu",
      "Cong Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08578"
  },
  {
    "id": "arXiv:2210.08579",
    "title": "Nowhere to Hide: A Lightweight Unsupervised Detector against Adversarial  Examples",
    "abstract": "Although deep neural networks (DNNs) have shown impressive performance on\nmany perceptual tasks, they are vulnerable to adversarial examples that are\ngenerated by adding slight but maliciously crafted perturbations to benign\nimages. Adversarial detection is an important technique for identifying\nadversarial examples before they are entered into target DNNs. Previous studies\nto detect adversarial examples either targeted specific attacks or required\nexpensive computation. How design a lightweight unsupervised detector is still\na challenging problem. In this paper, we propose an AutoEncoder-based\nAdversarial Examples (AEAE) detector, that can guard DNN models by detecting\nadversarial examples with low computation in an unsupervised manner. The AEAE\nincludes only a shallow autoencoder but plays two roles. First, a well-trained\nautoencoder has learned the manifold of benign examples. This autoencoder can\nproduce a large reconstruction error for adversarial images with large\nperturbations, so we can detect significantly perturbed adversarial examples\nbased on the reconstruction error. Second, the autoencoder can filter out the\nsmall noise and change the DNN's prediction on adversarial examples with small\nperturbations. It helps to detect slightly perturbed adversarial examples based\non the prediction distance. To cover these two cases, we utilize the\nreconstruction error and prediction distance from benign images to construct a\ntwo-tuple feature set and train an adversarial detector using the isolation\nforest algorithm. We show empirically that the AEAE is unsupervised and\ninexpensive against the most state-of-the-art attacks. Through the detection in\nthese two cases, there is nowhere to hide adversarial examples.",
    "descriptor": "",
    "authors": [
      "Hui Liu",
      "Bo Zhao",
      "Kehuan Zhang",
      "Peng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08579"
  },
  {
    "id": "arXiv:2210.08580",
    "title": "Fast Direct Solvers for Integral Equations at Low-Frequency Based on  Operator Filtering",
    "abstract": "This paper focuses on fast direct solvers for integral equations in the\nlow-to-moderate-frequency regime obtained by leveraging preconditioned first\nkind or second kind operators regularized with Laplacian filters. The spectral\nerrors arising from boundary element discretizations are properly handled by\nfiltering that, in addition, allows for the use of low-rank representations for\nthe compact perturbations of all operators involved. Numerical results show the\neffectiveness of the approaches and their effectiveness in the direct solution\nof integral equations.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Henry",
      "Davide Consoli",
      "Alexandre D\u00e9ly",
      "Lyes Rahmouni",
      "Adrien Merlini",
      "Francesco P. Andriulli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08580"
  },
  {
    "id": "arXiv:2210.08585",
    "title": "A new trigonometric kernel function for SVM",
    "abstract": "In recent years, several machine learning algorithms have been proposed.\nAmong of them, kernel approaches have been considered as a powerful tool for\nclassification. Using an appropriate kernel function can significantly improve\nthe accuracy of the classification. The main goal of this paper is to introduce\na new trigonometric kernel function containing one parameter for the machine\nlearning algorithms. Using simple mathematical tools, several useful properties\nof the proposed kernel function are presented. We also conduct an empirical\nevaluation on the kernel-SVM and kernel-SVR methods and demonstrate its strong\nperformance compared to other kernel functions.",
    "descriptor": "",
    "authors": [
      "Sajad Fathi Hafshejani",
      "Zahra Moberfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.08585"
  },
  {
    "id": "arXiv:2210.08590",
    "title": "Zero-Shot Learners for Natural Language Understanding via a Unified  Multiple Choice Perspective",
    "abstract": "We propose a new paradigm for zero-shot learners that is format agnostic,\ni.e., it is compatible with any format and applicable to a list of language\ntasks, such as text classification, commonsense reasoning, coreference\nresolution, and sentiment analysis. Zero-shot learning aims to train a model on\na given task such that it can address new learning tasks without any additional\ntraining. Our approach converts zero-shot learning into multiple-choice tasks,\navoiding problems in commonly used large-scale generative models such as FLAN.\nIt not only adds generalization ability to models but also significantly\nreduces the number of parameters. Our method shares the merits of efficient\ntraining and deployment. Our approach shows state-of-the-art performance on\nseveral benchmarks and produces satisfactory results on tasks such as natural\nlanguage inference and text classification. Our model achieves this success\nwith only 235M parameters, which is substantially smaller than state-of-the-art\nmodels with billions of parameters. The code and pre-trained models are\navailable at https://github.com/IDEA-CCNL/Fengshenbang-LM .",
    "descriptor": "",
    "authors": [
      "Ping Yang",
      "Junjie Wang",
      "Ruyi Gan",
      "Xinyu Zhu",
      "Lin Zhang",
      "Ziwei Wu",
      "Xinyu Gao",
      "Jiaxing Zhang",
      "Tetsuya Sakai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08590"
  },
  {
    "id": "arXiv:2210.08596",
    "title": "Logical Zonotope: A Set Representation for Binary Vectors",
    "abstract": "In this paper, we propose a new set representation for binary vectors called\nlogical zonotopes. A logical zonotope is constructed by XOR-ing a binary vector\nwith a combination of binary vectors called generators. A logical zonotope can\nefficiently represent up to 2^n binary vectors using only n generators. Instead\nof the explicit enumeration of the zonotopes' members, logical operations over\nsets of binary vectors are applied directly to a zonotopes' generators. Thus,\nlogical zonotopes can be used to greatly reduce the computational complexity of\na variety of operations over sets of binary vectors, including logical\noperations (e.g. XOR, NAND, AND, OR) and semi-tensor products. Additionally, we\nshow that, similar to the role classical zonotopes play for formally verifying\ndynamical systems defined over real vector spaces, logical zonotopes can be\nused to efficiently analyze the forward reachability of dynamical systems\ndefined over binary vector spaces (e.g. logical circuits or Boolean networks).\nTo showcase the utility of logical zonotopes, we illustrate three use cases:\n(1) discovering the key of a linear-feedback shift register with a linear time\ncomplexity, (2) verifying the safety of a logical vehicle intersection crossing\nprotocol, and (3) performing reachability analysis for a high-dimensional\nBoolean function.",
    "descriptor": "",
    "authors": [
      "Amr Alanwar",
      "Frank J. Jiang",
      "Samy Amin",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08596"
  },
  {
    "id": "arXiv:2210.08597",
    "title": "Acute Triangulation of Constant Curvature Polygonal Complexes",
    "abstract": "We prove that every 2-dimensional polygonal complex, where each polygon is\ngiven a constant curvature metric and belongs to one of finitely many isometry\nclasses can be triangulated using only acute simplices. There is no requirement\non the complex to be finite or even locally finite.",
    "descriptor": "",
    "authors": [
      "Florestan Brunck"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2210.08597"
  },
  {
    "id": "arXiv:2210.08600",
    "title": "Heterogeneous Full-body Control of a Mobile Manipulator with Behavior  Trees",
    "abstract": "Integrating the heterogeneous controllers of a complex mechanical system,\nsuch as a mobile manipulator, within the same structure and in a modular way is\nstill challenging. In this work we extend our framework based on Behavior Trees\nfor the control of a redundant mechanical system to the problem of commanding\nmore complex systems that involve multiple low-level controllers. This allows\nthe integrated systems to achieve non-trivial goals that require coordination\namong the sub-systems.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2209.08619\n",
    "authors": [
      "Marco Iannotta",
      "David C\u00e1ceres Dom\u00ednguez",
      "Johannes A. Stork",
      "Erik Schaffernicht",
      "Todor Stoyanov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08600"
  },
  {
    "id": "arXiv:2210.08601",
    "title": "Towards Dynamic Fault Tolerance for Hardware-Implemented Artificial  Neural Networks: A Deep Learning Approach",
    "abstract": "The functionality of electronic circuits can be seriously impaired by the\noccurrence of dynamic hardware faults. Particularly, for digital ultra\nlow-power systems, a reduced safety margin can increase the probability of\ndynamic failures. This work investigates a deep learning approach to mitigate\ndynamic fault impact for artificial neural networks. As a theoretic use case,\nimage compression by means of a deep autoencoder is considered. The evaluation\nshows a linear dependency of the test loss to the fault injection rate during\ntesting. If the number of training epochs is sufficiently large, our approach\nshows more than 2% reduction of the test loss compared to a baseline network\nwithout the need of additional hardware. At the absence of faults during\ntesting, our approach also decreases the test loss compared to reference\nnetworks.",
    "descriptor": "\nComments: Presented at On- and Near-sensor Vision Processing, from Photons to Applications (ONSVP) Workshop during IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Daniel Gregorek",
      "Nils H\u00fclsmeier",
      "Steffen Paul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08601"
  },
  {
    "id": "arXiv:2210.08604",
    "title": "NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations  On-the-Fly",
    "abstract": "Norm discovery is important for understanding and reasoning about the\nacceptable behaviors and potential violations in human communication and\ninteractions. We introduce NormSage, a framework for addressing the novel task\nof conversation-grounded multi-lingual, multi-cultural norm discovery, based on\nlanguage model prompting and self-verification. NormSAGE leverages the\nexpressiveness and implicit knowledge of the pretrained GPT-3 language model\nbackbone, to elicit knowledge about norms through directed questions\nrepresenting the norm discovery task and conversation context. It further\naddresses the risk of language model hallucination with a self-verification\nmechanism ensuring that the norms discovered are correct and are substantially\ngrounded to their source conversations. Evaluation results show that our\napproach discovers significantly more relevant and insightful norms for\nconversations on-the-fly compared to baselines (>10+% in Likert scale rating).\nThe norms discovered from Chinese conversation are also comparable to the norms\ndiscovered from English conversation in terms of insightfulness and correctness\n(<3% difference). In addition, the culture-specific norms are promising\nquality, allowing for 80% accuracy in culture pair human identification.\nFinally, our grounding process in norm discovery self-verification can be\nextended for instantiating the adherence and violation of any norm for a given\nconversation on-the-fly, with explainability and transparency. NormSAGE\nachieves an AUC of 95.4% in grounding, with natural language explanation\nmatching human-written quality.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yi R. Fung",
      "Tuhin Chakraborty",
      "Hao Guo",
      "Owen Rambow",
      "Smaranda Muresan",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08604"
  },
  {
    "id": "arXiv:2210.08607",
    "title": "The Impact of Task Underspecification in Evaluating Deep Reinforcement  Learning",
    "abstract": "Evaluations of Deep Reinforcement Learning (DRL) methods are an integral part\nof scientific progress of the field. Beyond designing DRL methods for general\nintelligence, designing task-specific methods is becoming increasingly\nprominent for real-world applications. In these settings, the standard\nevaluation practice involves using a few instances of Markov Decision Processes\n(MDPs) to represent the task. However, many tasks induce a large family of MDPs\nowing to variations in the underlying environment, particularly in real-world\ncontexts. For example, in traffic signal control, variations may stem from\nintersection geometries and traffic flow levels. The select MDP instances may\nthus inadvertently cause overfitting, lacking the statistical power to draw\nconclusions about the method's true performance across the family. In this\narticle, we augment DRL evaluations to consider parameterized families of MDPs.\nWe show that in comparison to evaluating DRL methods on select MDP instances,\nevaluating the MDP family often yields a substantially different relative\nranking of methods, casting doubt on what methods should be considered\nstate-of-the-art. We validate this phenomenon in standard control benchmarks\nand the real-world application of traffic signal control. At the same time, we\nshow that accurately evaluating on an MDP family is nontrivial. Overall, this\nwork identifies new challenges for empirical rigor in reinforcement learning,\nespecially as the outcomes of DRL trickle into downstream decision-making.",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2022\n",
    "authors": [
      "Vindula Jayawardana",
      "Catherine Tang",
      "Sirui Li",
      "Dajiang Suo",
      "Cathy Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08607"
  },
  {
    "id": "arXiv:2210.08608",
    "title": "Posterior Regularized Bayesian Neural Network Incorporating Soft and  Hard Knowledge Constraints",
    "abstract": "Neural Networks (NNs) have been widely {used in supervised learning} due to\ntheir ability to model complex nonlinear patterns, often presented in\nhigh-dimensional data such as images and text. However, traditional NNs often\nlack the ability for uncertainty quantification. Bayesian NNs (BNNS) could help\nmeasure the uncertainty by considering the distributions of the NN model\nparameters. Besides, domain knowledge is commonly available and could improve\nthe performance of BNNs if it can be appropriately incorporated. In this work,\nwe propose a novel Posterior-Regularized Bayesian Neural Network (PR-BNN) model\nby incorporating different types of knowledge constraints, such as the soft and\nhard constraints, as a posterior regularization term. Furthermore, we propose\nto combine the augmented Lagrangian method and the existing BNN solvers for\nefficient inference. The experiments in simulation and two case studies about\naviation landing prediction and solar energy output prediction have shown the\nknowledge constraints and the performance improvement of the proposed model\nover traditional BNNs without the constraints.",
    "descriptor": "\nComments: Accepted in Knowledge-Based System\n",
    "authors": [
      "Jiayu Huang",
      "Yutian Pang",
      "Yongming Liu",
      "Hao Yan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08608"
  },
  {
    "id": "arXiv:2210.08610",
    "title": "Robust, General, and Low Complexity Acoustic Scene Classification  Systems and An Effective Visualization for Presenting a Sound Scene Context",
    "abstract": "In this paper, we present a comprehensive analysis of Acoustic Scene\nClassification (ASC), the task of identifying the scene of an audio recording\nfrom its acoustic signature. In particular, we firstly propose an\ninception-based and low footprint ASC model, referred to as the ASC baseline.\nThe proposed ASC baseline is then compared with benchmark and high-complexity\nnetwork architectures of MobileNetV1, MobileNetV2, VGG16, VGG19, ResNet50V2,\nResNet152V2, DenseNet121, DenseNet201, and Xception. Next, we improve the ASC\nbaseline by proposing a novel deep neural network architecture which leverages\nresidual-inception architectures and multiple kernels. Given the novel\nresidual-inception (NRI) model, we further evaluate the trade off between the\nmodel complexity and the model accuracy performance. Finally, we evaluate\nwhether sound events occurring in a sound scene recording can help to improve\nASC accuracy, then indicate how a sound scene context is well presented by\ncombining both sound scene and sound event information. We conduct extensive\nexperiments on various ASC datasets, including Crowded Scenes, IEEE AASP\nChallenge on Detection and Classification of Acoustic Scenes and Events (DCASE)\n2018 Task 1A and 1B, 2019 Task 1A and 1B, 2020 Task 1A, 2021 Task 1A, 2022 Task\n1. The experimental results on several different ASC challenges highlight two\nmain achievements; the first is to propose robust, general, and low complexity\nASC systems which are suitable for real-life applications on a wide range of\nedge devices and mobiles; the second is to propose an effective visualization\nmethod for comprehensively presenting a sound scene context.",
    "descriptor": "",
    "authors": [
      "Lam Pham",
      "Dusan Salovic",
      "Anahid Jalali",
      "Alexander Schindler",
      "Khoa Tran",
      "Canh Vu",
      "Phu X. Nguyen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08610"
  },
  {
    "id": "arXiv:2210.08616",
    "title": "LoS MIMO-Arrays vs. LoS MIMO-Surfaces",
    "abstract": "The wireless research community has expressed major interest in the\nsub-terahertz band for enabling mobile communications in future wireless\nnetworks. The sub-terahertz band offers a large amount of available bandwidth\nand, therefore, the promise to realize wireless communications at optical\nspeeds. At such high frequency bands, the transceivers need to have larger\napertures and need to be deployed more densely than at lower frequency bands.\nThese factors proportionally increase the far-field limit and the spherical\ncurvature of the electromagnetic waves cannot be ignored anymore. This offers\nthe opportunity to realize spatial multiplexing even in line-of-sight channels.\nIn this paper, we overview and compare existing design options to realize\nhigh-rank transmissions in line-of-sight channels.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Marco Di Renzo",
      "Davide Dardari",
      "Nicolo' Decarli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08616"
  },
  {
    "id": "arXiv:2210.08619",
    "title": "Modeling the Mutual Coupling of Reconfigurable Metaurfaces",
    "abstract": "In [1], the authors have recently introduced a circuits-based approach for\nmodeling the mutual coupling of reconfigurable surfaces, which comprise\nsub-wavelength spaced passive scattering elements coupled with electronic\ncircuits for enabling the reconfiguration of the surface. The approach is based\non a finite-length discrete dipole representation of a reconfigurable surface,\nand on the assumption that the current distribution on each thin wire dipole is\na sinusoidal function. Under these assumptions, the voltages at the ports of a\nmulti-antenna receiver can be formulated in terms of the voltage generators at\na multi-antenna transmitter through a transfer function matrix that explicitly\ndepends on the mutual coupling and the tuning circuits through the mutual\nimpedances between every pair of thin wire dipoles. In [1], the mutual\nimpedances are formulated in an integral form. In this paper, we show that the\nmutual impedances can be formulated in a closed-form expression in terms of\nexponential integral functions.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Marco Di Renzo",
      "Vincenzo Galdi",
      "Giuseppe Castaldi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08619"
  },
  {
    "id": "arXiv:2210.08627",
    "title": "Torque-Limited Manipulation Planning through Contact by Interleaving  Graph Search and Trajectory Optimization",
    "abstract": "Robots often have to perform manipulation tasks in close proximity to people.\nAs such, it is desirable to use a robot arm that has limited joint torques so\nas to not injure the nearby person. Unfortunately, these limited torques then\nlimit the payload capability of the arm. By using contact with the environment,\nrobots can expand their reachable workspace that, otherwise, would be\ninaccessible due to exceeding actuator torque limits. We adapt our recently\ndeveloped INSAT algorithm \\cite{insat} to tackle the problem of torque-limited\nwhole arm manipulation planning through contact. INSAT requires no prior over\ncontact mode sequence and no initial template or seed for trajectory\noptimization. INSAT achieves this by interleaving graph search to explore the\nmanipulator joint configuration space with incremental trajectory optimizations\nseeded by neighborhood solutions to find a dynamically feasible trajectory\nthrough contact. We demonstrate our results on a variety of manipulators and\nscenarios in simulation. We also experimentally show our planner exploiting\nrobot-environment contact for the pick and place of a payload using a Kinova\nGen3 robot. In comparison to the same trajectory running in free space, we\nexperimentally show that the utilization of bracing contacts reduces the\noverall torque required to execute the trajectory.",
    "descriptor": "",
    "authors": [
      "Ramkumar Natarajan",
      "Garrison L.H. Johnston",
      "Nabil Simaan",
      "Maxim Likhachev",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08627"
  },
  {
    "id": "arXiv:2210.08632",
    "title": "Perceptual-Score: A Psychophysical Measure for Assessing the Biological  Plausibility of Visual Recognition Models",
    "abstract": "For the last decade, convolutional neural networks (CNNs) have vastly\nsuperseded their predecessors in nearly all vision tasks in artificial\nintelligence, including object recognition. However, in spite of abundant\nadvancements, they continue to pale in comparison to biological vision. This\nchasm has prompted the development of biologically-inspired models that have\nattempted to mimic the human visual system, primarily at a neural-level, which\nare evaluated using standard dataset benchmarks. However, more work is needed\nto understand how these models actually perceive the visual world. This article\nproposes a state-of-the-art procedure that generates a new metric,\nPerceptual-Score, which is grounded in visual psychophysics, and is capable of\nreliably estimating perceptual responses across numerous models -- representing\na large range in complexity and biological inspiration. We perform the\nprocedure on twelve models that vary in degree of biological inspiration and\ncomplexity, and compare the results against the aggregated results of 2,390\nAmazon Mechanical Turk workers who together provided ~2.7 million perceptual\nresponses. Each model's Perceptual-Score is compared against the\nstate-of-the-art neural activity-based metric, Brain-Score. Our study indicates\nthat models with high correlation to human perceptual behavior also have high\ncorrelation with the corresponding neural activity.",
    "descriptor": "",
    "authors": [
      "Brandon RichardWebster",
      "Anthony DiFalco",
      "Elisabetta Caldesi",
      "Walter J. Scheirer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08632"
  },
  {
    "id": "arXiv:2210.08634",
    "title": "SUPERB @ SLT 2022: Challenge on Generalization and Efficiency of  Self-Supervised Speech Representation Learning",
    "abstract": "We present the SUPERB challenge at SLT 2022, which aims at learning\nself-supervised speech representation for better performance, generalization,\nand efficiency. The challenge builds upon the SUPERB benchmark and implements\nmetrics to measure the computation requirements of self-supervised learning\n(SSL) representation and to evaluate its generalizability and performance\nacross the diverse SUPERB tasks. The SUPERB benchmark provides comprehensive\ncoverage of popular speech processing tasks, from speech and speaker\nrecognition to audio generation and semantic understanding. As SSL has gained\ninterest in the speech community and showed promising outcomes, we envision the\nchallenge to uplevel the impact of SSL techniques by motivating more practical\ndesigns of techniques beyond task performance. We summarize the results of 14\nsubmitted models in this paper. We also discuss the main findings from those\nsubmissions and the future directions of SSL research.",
    "descriptor": "\nComments: Accepted by 2022 SLT Workshop\n",
    "authors": [
      "Tzu-hsun Feng",
      "Annie Dong",
      "Ching-Feng Yeh",
      "Shu-wen Yang",
      "Tzu-Quan Lin",
      "Jiatong Shi",
      "Kai-Wei Chang",
      "Zili Huang",
      "Haibin Wu",
      "Xuankai Chang",
      "Shinji Watanabe",
      "Abdelrahman Mohamed",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08634"
  },
  {
    "id": "arXiv:2210.08635",
    "title": "Tracing Semantic Variation in Slang",
    "abstract": "The meaning of a slang term can vary in different communities. However, slang\nsemantic variation is not well understood and under-explored in the natural\nlanguage processing of slang. One existing view argues that slang semantic\nvariation is driven by culture-dependent communicative needs. An alternative\nview focuses on slang's social functions suggesting that the desire to foster\nsemantic distinction may have led to the historical emergence of\ncommunity-specific slang senses. We explore these theories using computational\nmodels and test them against historical slang dictionary entries, with a focus\non characterizing regularity in the geographical variation of slang usages\nattested in the US and the UK over the past two centuries. We show that our\nmodels are able to predict the regional identity of emerging slang word\nmeanings from historical slang records. We offer empirical evidence that both\ncommunicative need and semantic distinction play a role in the variation of\nslang meaning yet their relative importance fluctuates over the course of\nhistory. Our work offers an opportunity for incorporating historical cultural\nelements into the natural language processing of slang.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Zhewei Sun",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08635"
  },
  {
    "id": "arXiv:2210.08640",
    "title": "Evaluating Guiding Spaces for Motion Planning",
    "abstract": "Randomized sampling based algorithms are widely used in robot motion planning\ndue to the problem's intractability, and are experimentally effective on a wide\nrange of problem instances. Most variants do not sample uniformly at random,\nand instead bias their sampling using various heuristics for determining which\nsamples will provide more information, or are more likely to participate in the\nfinal solution. In this work, we define the \\emph{motion planning guiding\nspace}, which encapsulates many seemingly distinct prior works under the same\nframework. In addition, we suggest an information theoretic method to evaluate\nguided planning which places the focus on the quality of the resulting biased\nsampling. Finally, we analyze several motion planning algorithms in order to\ndemonstrate the applicability of our definition and its evaluation.",
    "descriptor": "\nComments: Accepted at IROS 2022, Workshop for Evaluating Motion Planning Performance\n",
    "authors": [
      "Amnon Attali",
      "Stav Ashur",
      "Isaac Burton Love",
      "Courtney McBeth",
      "James Motes",
      "Diane Uwacu",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08640"
  },
  {
    "id": "arXiv:2210.08642",
    "title": "Data-Efficient Pipeline for Offline Reinforcement Learning with Limited  Data",
    "abstract": "Offline reinforcement learning (RL) can be used to improve future performance\nby leveraging historical data. There exist many different algorithms for\noffline RL, and it is well recognized that these algorithms, and their\nhyperparameter settings, can lead to decision policies with substantially\ndiffering performance. This prompts the need for pipelines that allow\npractitioners to systematically perform algorithm-hyperparameter selection for\ntheir setting. Critically, in most real-world settings, this pipeline must only\ninvolve the use of historical data. Inspired by statistical model selection\nmethods for supervised learning, we introduce a task- and method-agnostic\npipeline for automatically training, comparing, selecting, and deploying the\nbest policy when the provided dataset is limited in size. In particular, our\nwork highlights the importance of performing multiple data splits to produce\nmore reliable algorithm-hyperparameter selection. While this is a common\napproach in supervised learning, to our knowledge, this has not been discussed\nin detail in the offline RL setting. We show it can have substantial impacts\nwhen the dataset is small. Compared to alternate approaches, our proposed\npipeline outputs higher-performing deployed policies from a broad range of\noffline policy learning algorithms and across various simulation domains in\nhealthcare, education, and robotics. This work contributes toward the\ndevelopment of a general-purpose meta-algorithm for automatic\nalgorithm-hyperparameter selection for offline RL.",
    "descriptor": "\nComments: 32 pages. To be published at NeurIPS 2022. Presented at RLDM 2022\n",
    "authors": [
      "Allen Nie",
      "Yannis Flet-Berliac",
      "Deon R. Jordan",
      "William Steenbergen",
      "Emma Brunskill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08642"
  },
  {
    "id": "arXiv:2210.08643",
    "title": "A General Framework for Auditing Differentially Private Machine Learning",
    "abstract": "We present a framework to statistically audit the privacy guarantee conferred\nby a differentially private machine learner in practice. While previous works\nhave taken steps toward evaluating privacy loss through poisoning attacks or\nmembership inference, they have been tailored to specific models or have\ndemonstrated low statistical power. Our work develops a general methodology to\nempirically evaluate the privacy of differentially private machine learning\nimplementations, combining improved privacy search and verification methods\nwith a toolkit of influence-based poisoning attacks. We demonstrate\nsignificantly improved auditing power over previous approaches on a variety of\nmodels including logistic regression, Naive Bayes, and random forest. Our\nmethod can be used to detect privacy violations due to implementation errors or\nmisuse. When violations are not present, it can aid in understanding the amount\nof information that can be leaked from a given dataset, algorithm, and privacy\nspecification.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Fred Lu",
      "Joseph Munoz",
      "Maya Fuchs",
      "Tyler LeBlond",
      "Elliott Zaresky-Williams",
      "Edward Raff",
      "Francis Ferraro",
      "Brian Testa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08643"
  },
  {
    "id": "arXiv:2210.08644",
    "title": "Computing a Stable Distance on Merge Trees",
    "abstract": "Distances on merge trees facilitate visual comparison of collections of\nscalar fields. Two desirable properties for these distances to exhibit are 1)\nthe ability to discern between scalar fields which other, less complex\ntopological summaries cannot and 2) to still be robust to perturbations in the\ndataset. The combination of these two properties, known respectively as\nstability and discriminativity, has led to theoretical distances which are\neither thought to be or shown to be computationally complex and thus their\nimplementations have been scarce. In order to design similarity measures on\nmerge trees which are computationally feasible for more complex merge trees,\nmany researchers have elected to loosen the restrictions on at least one of\nthese two properties. The question still remains, however, if there are\npractical situations where trading these desirable properties is necessary.\nHere we construct a distance between merge trees which is designed to retain\nboth discriminativity and stability. While our approach can be expensive for\nlarge merge trees, we illustrate its use in a setting where the number of nodes\nis small. This setting can be made more practical since we also provide a proof\nthat persistence simplification increases the outputted distance by at most\nhalf of the simplified value. We demonstrate our distance measure on\napplications in shape comparison and on detection of periodicity in the von\nK\\'arm\\'an vortex street.",
    "descriptor": "\nComments: Accepted to IEEE VIS 2022 (IEEE Transactions on Visualization and Computer Graphics, 2022)\n",
    "authors": [
      "Brian Bollen",
      "Pasindu Tennakoon",
      "Joshua A. Levine"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.08644"
  },
  {
    "id": "arXiv:2210.08645",
    "title": "3D-GMIC: an efficient deep neural network to find small objects in large  3D images",
    "abstract": "3D imaging enables a more accurate diagnosis by providing spatial information\nabout organ anatomy. However, using 3D images to train AI models is\ncomputationally challenging because they consist of tens or hundreds of times\nmore pixels than their 2D counterparts. To train with high-resolution 3D\nimages, convolutional neural networks typically resort to downsampling them or\nprojecting them to two dimensions. In this work, we propose an effective\nalternative, a novel neural network architecture that enables computationally\nefficient classification of 3D medical images in their full resolution.\nCompared to off-the-shelf convolutional neural networks, 3D-GMIC uses\n77.98%-90.05% less GPU memory and 91.23%-96.02% less computation. While our\nnetwork is trained only with image-level labels, without segmentation labels,\nit explains its classification predictions by providing pixel-level saliency\nmaps. On a dataset collected at NYU Langone Health, including 85,526 patients\nwith full-field 2D mammography (FFDM), synthetic 2D mammography, and 3D\nmammography (DBT), our model, the 3D Globally-Aware Multiple Instance\nClassifier (3D-GMIC), achieves a breast-wise AUC of 0.831 (95% CI: 0.769-0.887)\nin classifying breasts with malignant findings using DBT images. As DBT and 2D\nmammography capture different information, averaging predictions on 2D and 3D\nmammography together leads to a diverse ensemble with an improved breast-wise\nAUC of 0.841 (95% CI: 0.768-0.895). Our model generalizes well to an external\ndataset from Duke University Hospital, achieving an image-wise AUC of 0.848\n(95% CI: 0.798-0.896) in classifying DBT images with malignant findings.",
    "descriptor": "",
    "authors": [
      "Jungkyu Park",
      "Jakub Ch\u0142\u0119dowski",
      "Stanis\u0142aw Jastrz\u0119bski",
      "Jan Witowski",
      "Yanqi Xu",
      "Linda Du",
      "Sushma Gaddam",
      "Eric Kim",
      "Alana Lewin",
      "Ujas Parikh",
      "Anastasia Plaunova",
      "Sardius Chen",
      "Alexandra Millet",
      "James Park",
      "Kristine Pysarenko",
      "Shalin Patel",
      "Julia Goldberg",
      "Melanie Wegener",
      "Linda Moy",
      "Laura Heacock",
      "Beatriu Reig",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08645"
  },
  {
    "id": "arXiv:2210.08646",
    "title": "EventGraph: Event Extraction as Semantic Graph Parsing",
    "abstract": "Event extraction involves the detection and extraction of both the event\ntriggers and corresponding event arguments. Existing systems often decompose\nevent extraction into multiple subtasks, without considering their possible\ninteractions. In this paper, we propose EventGraph, a joint framework for event\nextraction, which encodes events as graphs. We represent event triggers and\narguments as nodes in a semantic graph. Event extraction therefore becomes a\ngraph parsing problem, which provides the following advantages: 1) performing\nevent detection and argument extraction jointly; 2) detecting and extracting\nmultiple events from a piece of text; and 3) capturing the complicated\ninteraction between event arguments and triggers. Experimental results on\nACE2005 show that our model is competitive to state-of-the-art systems and has\nsubstantially improved the results on argument extraction. Additionally, we\ncreate two new datasets from ACE2005 where we keep the entire text spans for\nevent arguments, instead of just the head word(s). Our code and models are\nreleased as open-source.",
    "descriptor": "\nComments: Accepted by CASE@EMNLP 2022\n",
    "authors": [
      "Huiling You",
      "David Samuel",
      "Samia Touileb",
      "Lilja \u00d8vrelid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08646"
  },
  {
    "id": "arXiv:2210.08647",
    "title": "D2SLAM: Semantic visual SLAM based on the influence of Depth for Dynamic  environments",
    "abstract": "Taking into account the dynamics of the scene is the most effective solution\nto obtain an accurate perception of unknown environments within the framework\nof a real autonomous robotic application. Many works have attempted to address\nthe non-rigid scene assumption by taking advantage of deep learning\nadvancements. Most new methods combine geometric and semantic approaches to\ndetermine dynamic elements that lack generalization and scene awareness. We\npropose a novel approach that overcomes the limitations of these methods by\nusing scene depth information that refines the accuracy of estimates from\ngeometric and semantic modules. In addition, the depth information is used to\ndetermine an area of influence of dynamic objects through our Objects\nInteraction module that estimates the state of both non-matched keypoints and\nout of segmented region keypoints. The obtained results demonstrate the\nefficacy of the proposed method in providing accurate localization and mapping\nin dynamic environments.",
    "descriptor": "",
    "authors": [
      "Ayman Beghdadi",
      "Malik Mallem",
      "Lotfi Beji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08647"
  },
  {
    "id": "arXiv:2210.08648",
    "title": "AttTrack: Online Deep Attention Transfer for Multi-object Tracking",
    "abstract": "Multi-object tracking (MOT) is a vital component of intelligent video\nanalytics applications such as surveillance and autonomous driving. The time\nand storage complexity required to execute deep learning models for visual\nobject tracking hinder their adoption on embedded devices with limited\ncomputing power. In this paper, we aim to accelerate MOT by transferring the\nknowledge from high-level features of a complex network (teacher) to a\nlightweight network (student) at both training and inference times. The\nproposed AttTrack framework has three key components: 1) cross-model feature\nlearning to align intermediate representations from the teacher and student\nmodels, 2) interleaving the execution of the two models at inference time, and\n3) incorporating the updated predictions from the teacher model as prior\nknowledge to assist the student model. Experiments on pedestrian tracking tasks\nare conducted on the MOT17 and MOT15 datasets using two different object\ndetection backbones YOLOv5 and DLA34 show that AttTrack can significantly\nimprove student model tracking performance while sacrificing only minor\ndegradation of tracking speed.",
    "descriptor": "\nComments: WACV 2023 Camera-ready version\n",
    "authors": [
      "Keivan Nalaie",
      "Rong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08648"
  },
  {
    "id": "arXiv:2210.08649",
    "title": "Loss Minimization through the Lens of Outcome Indistinguishability",
    "abstract": "We present a new perspective on loss minimization and the recent notion of\nOmniprediction through the lens of Outcome Indistingusihability. For a\ncollection of losses and hypothesis class, omniprediction requires that a\npredictor provide a loss-minimization guarantee simultaneously for every loss\nin the collection compared to the best (loss-specific) hypothesis in the class.\nWe present a generic template to learn predictors satisfying a guarantee we\ncall Loss Outcome Indistinguishability. For a set of statistical tests--based\non a collection of losses and hypothesis class--a predictor is Loss OI if it is\nindistinguishable (according to the tests) from Nature's true probabilities\nover outcomes. By design, Loss OI implies omniprediction in a direct and\nintuitive manner. We simplify Loss OI further, decomposing it into a\ncalibration condition plus multiaccuracy for a class of functions derived from\nthe loss and hypothesis classes. By careful analysis of this class, we give\nefficient constructions of omnipredictors for interesting classes of loss\nfunctions, including non-convex losses.\nThis decomposition highlights the utility of a new multi-group fairness\nnotion that we call calibrated multiaccuracy, which lies in between\nmultiaccuracy and multicalibration. We show that calibrated multiaccuracy\nimplies Loss OI for the important set of convex losses arising from Generalized\nLinear Models, without requiring full multicalibration. For such losses, we\nshow an equivalence between our computational notion of Loss OI and a geometric\nnotion of indistinguishability, formulated as Pythagorean theorems in the\nassociated Bregman divergence. We give an efficient algorithm for calibrated\nmultiaccuracy with computational complexity comparable to that of\nmultiaccuracy. In all, calibrated multiaccuracy offers an interesting tradeoff\npoint between efficiency and generality in the omniprediction landscape.",
    "descriptor": "",
    "authors": [
      "Parikshit Gopalan",
      "Lunjia Hu",
      "Michael P. Kim",
      "Omer Reingold",
      "Udi Wieder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08649"
  },
  {
    "id": "arXiv:2210.08650",
    "title": "Accelerating Transfer Learning with Near-Data Computation on Cloud  Object Stores",
    "abstract": "Storage disaggregation is fundamental to today's cloud due to cost and\nscalability benefits. Unfortunately, this design must cope with an inherent\nnetwork bottleneck between the storage and the compute tiers. The widely\ndeployed mitigation strategy is to provide computational resources next to\nstorage to push down a part of an application and thus reduce the amount of\ndata transferred to the compute tier. Overall, users of disaggregated storage\nneed to consider two main constraints: the network may remain a bottleneck, and\nthe storage-side computational resources are limited. This paper identifies\ntransfer learning (TL) as a natural fit for the disaggregated cloud. TL,\nfamously described as the next driver of ML commercial success, is widely\npopular and has broad-range applications. We show how to leverage the unique\nstructure of TL's fine-tuning phase (i.e., a combination of feature extraction\nand training) to flexibly address the aforementioned constraints and improve\nboth user and operator-centric metrics. The key to improving user-perceived\nperformance is to mitigate the network bottleneck by carefully splitting the TL\ndeep neural network (DNN) such that feature extraction is, partially or\nentirely, executed next to storage. Crucially, such splitting enables\ndecoupling the batch size of feature extraction from the training batch size,\nfacilitating efficient storage-side batch size adaptation to increase\nconcurrency in the storage tier while avoiding out-of-memory errors. Guided by\nthese insights, we present HAPI, a processing system for TL that spans the\ncompute and storage tiers while remaining transparent to the user. Our\nevaluation with several DNNs, such as ResNet, VGG, and Transformer, shows up to\n11x improvement in application runtime and up to 8.3x reduction in the data\ntransferred from the storage to the compute tier compared to running the\ncomputation in the compute tier.",
    "descriptor": "\nComments: 14 pages, 14 figures, 5 tables\n",
    "authors": [
      "Arsany Guirguis",
      "Diana Petrescu",
      "Florin Dinu",
      "Do Le Quoc",
      "Javier Picorel",
      "Rachid Guerraoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.08650"
  },
  {
    "id": "arXiv:2210.08652",
    "title": "Adaptive Contrastive Learning with Dynamic Correlation for Multi-Phase  Organ Segmentation",
    "abstract": "Recent studies have demonstrated the superior performance of introducing\n``scan-wise\" contrast labels into contrastive learning for multi-organ\nsegmentation on multi-phase computed tomography (CT). However, such scan-wise\nlabels are limited: (1) a coarse classification, which could not capture the\nfine-grained ``organ-wise\" contrast variations across all organs; (2) the label\n(i.e., contrast phase) is typically manually provided, which is error-prone and\nmay introduce manual biases of defining phases. In this paper, we propose a\nnovel data-driven contrastive loss function that adapts the similar/dissimilar\ncontrast relationship between samples in each minibatch at organ-level.\nSpecifically, as variable levels of contrast exist between organs, we\nhypothesis that the contrast differences in the organ-level can bring\nadditional context for defining representations in the latent space. An\norgan-wise contrast correlation matrix is computed with mean organ intensities\nunder one-hot attention maps. The goal of adapting the organ-driven correlation\nmatrix is to model variable levels of feature separability at different phases.\nWe evaluate our proposed approach on multi-organ segmentation with both\nnon-contrast CT (NCCT) datasets and the MICCAI 2015 BTCV Challenge\ncontrast-enhance CT (CECT) datasets. Compared to the state-of-the-art\napproaches, our proposed contrastive loss yields a substantial and significant\nimprovement of 1.41% (from 0.923 to 0.936, p-value$<$0.01) and 2.02% (from\n0.891 to 0.910, p-value$<$0.01) on mean Dice scores across all organs with\nrespect to NCCT and CECT cohorts. We further assess the trained model\nperformance with the MICCAI 2021 FLARE Challenge CECT datasets and achieve a\nsubstantial improvement of mean Dice score from 0.927 to 0.934\n(p-value$<$0.01). The code is available at: https://github.com/MASILab/DCC_CL",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ho Hin Lee",
      "Yucheng Tang",
      "Han Liu",
      "Yubo Fan",
      "Leon Y. Cai",
      "Qi Yang",
      "Xin Yu",
      "Shunxing Bao",
      "Yuankai Huo",
      "Bennett A. Landman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08652"
  },
  {
    "id": "arXiv:2210.08654",
    "title": "Learning to Sample and Aggregate: Few-shot Reasoning over Temporal  Knowledge Graphs",
    "abstract": "In this paper, we investigate a realistic but underexplored problem, called\nfew-shot temporal knowledge graph reasoning, that aims to predict future facts\nfor newly emerging entities based on extremely limited observations in evolving\ngraphs. It offers practical value in applications that need to derive instant\nnew knowledge about new entities in temporal knowledge graphs (TKGs) with\nminimal supervision. The challenges mainly come from the few-shot and time\nshift properties of new entities. First, the limited observations associated\nwith them are insufficient for training a model from scratch. Second, the\npotentially dynamic distributions from the initially observable facts to the\nfuture facts ask for explicitly modeling the evolving characteristics of new\nentities. We correspondingly propose a novel Meta Temporal Knowledge Graph\nReasoning (MetaTKGR) framework. Unlike prior work that relies on rigid\nneighborhood aggregation schemes to enhance low-data entity representation,\nMetaTKGR dynamically adjusts the strategies of sampling and aggregating\nneighbors from recent facts for new entities, through temporally supervised\nsignals on future facts as instant feedback. Besides, such a meta temporal\nreasoning procedure goes beyond existing meta-learning paradigms on static\nknowledge graphs that fail to handle temporal adaptation with large entity\nvariance. We further provide a theoretical analysis and propose a temporal\nadaptation regularizer to stabilize the meta temporal reasoning over time.\nEmpirically, extensive experiments on three real-world TKGs demonstrate the\nsuperiority of MetaTKGR over state-of-the-art baselines by a large margin.",
    "descriptor": "\nComments: This paper is accepted by Neurips 2022\n",
    "authors": [
      "Ruijie Wang",
      "Zheng Li",
      "Dachun Sun",
      "Shengzhong Liu",
      "Jinning Li",
      "Bing Yin",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08654"
  },
  {
    "id": "arXiv:2210.08655",
    "title": "Evaluation of the Synthetic Electronic Health Records",
    "abstract": "Generative models have been found effective for data synthesis due to their\nability to capture complex underlying data distributions. The quality of\ngenerated data from these models is commonly evaluated by visual inspection for\nimage datasets or downstream analytical tasks for tabular datasets. These\nevaluation methods neither measure the implicit data distribution nor consider\nthe data privacy issues, and it remains an open question of how to compare and\nrank different generative models. Medical data can be sensitive, so it is of\ngreat importance to draw privacy concerns of patients while maintaining the\ndata utility of the synthetic dataset. Beyond the utility evaluation, this work\noutlines two metrics called Similarity and Uniqueness for sample-wise\nassessment of synthetic datasets. We demonstrate the proposed notions with\nseveral state-of-the-art generative models to synthesise Cystic Fibrosis (CF)\npatients' electronic health records (EHRs), observing that the proposed metrics\nare suitable for synthetic data evaluation and generative model comparison.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2201.05400\n",
    "authors": [
      "Emily Muller",
      "Xu Zheng",
      "Jer Hayes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08655"
  },
  {
    "id": "arXiv:2210.08659",
    "title": "Anticipatory Fleet Repositioning for Shared-use Autonomous Mobility  Services: An Optimization and Learning-Based Approach",
    "abstract": "With the development of mobility-on-demand services, increasing sources of\nrich transportation data, and the advent of autonomous vehicles (AVs), there\nare significant opportunities for shared-use AV mobility services (SAMSs) to\nprovide accessible and demand-responsive personal mobility. This paper focuses\non the problem of anticipatory repositioning of idle vehicles in a SAMS fleet\nto enable better assignment decisions in serving future demand. The rebalancing\nproblem is formulated as a Markov Decision Process and a reinforcement learning\napproach using an advantage actor critic (A2C) method is proposed to learn a\nrebalancing policy that anticipates future demand and cooperates with an\noptimization-based assignment strategy. The proposed formulation and solution\napproach allow for centralized repositioning decisions for the entire vehicle\nfleet but ensure that the problem size does not change with the size of the\nvehicle fleet. Using an agent-based simulation tool and New York City taxi data\nto simulate demand for rides in a SAMS system, two versions of the A2C AV\nrepositioning approach are tested: A2C-AVR(A) observing past demand for rides\nand learning to anticipate future demand, and A2C-AVR(B) that receives demand\nforecasts. Numerical experiments demonstrate that the A2C-AVR approaches\nsignificantly reduce mean passenger wait times relative to an alternative\noptimization-based rebalancing approach, at the expense of slightly increased\npercentage of empty fleet miles travelled. The experiments show comparable\nperformance between the A2C-AVR(A) and (B), indicating that the approach can\nanticipate future demand based on past demand observations. Testing with\nvarious demand and time-of-day scenarios, and an alternative assignment\nstrategy, experiments demonstrate the models transferability to cases unseen at\nthe training stage.",
    "descriptor": "",
    "authors": [
      "Monika Filipovska",
      "Michael Hyland",
      "Haimanti Bala"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08659"
  },
  {
    "id": "arXiv:2210.08664",
    "title": "Design and Modeling of a Smart Torque-Adjustable Rotary Electroadhesive  Clutch for Application in Human-Robot Interaction",
    "abstract": "The increasing need for sharing workspace and interactive physical tasks\nbetween robots and humans has raised concerns regarding safety of such\noperations. In this regard, controllable clutches have shown great potential\nfor addressing important safety concerns at the hardware level by separating\nthe high-impedance actuator from the end effector by providing the power\ntransfer from electromagnetic source to the human. However, the existing\nclutches suffer from high power consumption and large-weight, which make them\nundesirable from the design point of view. In this paper, for the first time,\nthe design and development of a novel, lightweight, and low-power\ntorque-adjustable rotary clutch using electroadhesive materials is presented.\nThe performance of three different pairs of clutch plates is investigated in\nthe context of the smoothness and quality of output torque. The performance\ndegradation issue due to the polarization of the insulator is addressed through\nthe utilization of an alternating current waveform activation signal. Moreover,\nthe effect of the activation frequency on the output torque and power\nconsumption of the clutch is investigated. Finally, a time-dependent model for\nthe output torque of the clutch is presented, and the performance of the clutch\nwas evaluated through experiments, including physical human-robot interaction.\nThe proposed clutch offers a torque to power consumption ratio that is six\ntimes better than commercial magnetic particle clutches. The proposed clutch\npresents great potential for developing safe, lightweight, and low-power\nphysical human-robot interaction systems, such as exoskeletons and robotic\nwalkers.",
    "descriptor": "\nComments: submitted to IEEE T-MECH, 11 pages, 14 figures,\n",
    "authors": [
      "Navid Feizi",
      "S. Farokh Atashzar",
      "Mehrdad R. Kermani",
      "Rajni V. Patel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08664"
  },
  {
    "id": "arXiv:2210.08667",
    "title": "From Function to Failure",
    "abstract": "Failure Mode Reasoning (FMR) is a method for formal analysis of\nsystem-related faults. The method was originally developed for identifying\nfailure modes of safety-critical systems based on an analysis of their\nprograms. In this paper, we generalize the method and present a mathematical\nframework for its use in model-based system and safety analyses. We explain the\nconcepts, formalize the method, formulate models for example systems, and\ndiscuss the practical application of the method.",
    "descriptor": "",
    "authors": [
      "Hamid Jahanian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08667"
  },
  {
    "id": "arXiv:2210.08668",
    "title": "Temporal-Spatial dependencies ENhanced deep learning model (TSEN) for  household leverage series forecasting",
    "abstract": "Analyzing both temporal and spatial patterns for an accurate forecasting\nmodel for financial time series forecasting is a challenge due to the complex\nnature of temporal-spatial dynamics: time series from different locations often\nhave distinct patterns; and for the same time series, patterns may vary as time\ngoes by. Inspired by the successful applications of deep learning, we propose a\nnew model to resolve the issues of forecasting household leverage in China. Our\nsolution consists of multiple RNN-based layers and an attention layer: each\nRNN-based layer automatically learns the temporal pattern of a specific series\nwith multivariate exogenous series, and then the attention layer learns the\nspatial correlative weight and obtains the global representations\nsimultaneously. The results show that the new approach can capture the\ntemporal-spatial dynamics of household leverage well and get more accurate and\nsolid predictive results. More, the simulation also studies show that\nclustering and choosing correlative series are necessary to obtain accurate\nforecasting results.",
    "descriptor": "",
    "authors": [
      "Hu Yang",
      "Yi Huang",
      "Haijun Wang",
      "Yu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08668"
  },
  {
    "id": "arXiv:2210.08672",
    "title": "Decision-Making Among Bounded Rational Agents",
    "abstract": "When robots share the same workspace with other intelligent agents (e.g.,\nother robots or humans), they must be able to reason about the behaviors of\ntheir neighboring agents while accomplishing the designated tasks. In practice,\nfrequently, agents do not exhibit absolutely rational behavior due to their\nlimited computational resources. Thus, predicting the optimal agent behaviors\nis undesirable (because it demands prohibitive computational resources) and\nundesirable (because the prediction may be wrong). Motivated by this\nobservation, we remove the assumption of perfectly rational agents and propose\nincorporating the concept of bounded rationality from an information-theoretic\nview into the game-theoretic framework. This allows the robots to reason other\nagents' sub-optimal behaviors and act accordingly under their computational\nconstraints. Specifically, bounded rationality directly models the agent's\ninformation processing ability, which is represented as the KL-divergence\nbetween nominal and optimized stochastic policies, and the solution to the\nbounded-optimal policy can be obtained by an efficient importance sampling\napproach. Using both simulated and real-world experiments in multi-robot\nnavigation tasks, we demonstrate that the resulting framework allows the robots\nto reason about different levels of rational behaviors of other agents and\ncompute a reasonable strategy under its computational constraint.",
    "descriptor": "\nComments: accepted by DARS2022\n",
    "authors": [
      "Junhong Xu",
      "Durgakant Pushp",
      "Kai Yin",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.08672"
  },
  {
    "id": "arXiv:2210.08674",
    "title": "Scaling up Trustless DNN Inference with Zero-Knowledge Proofs",
    "abstract": "As ML models have increased in capabilities and accuracy, so has the\ncomplexity of their deployments. Increasingly, ML model consumers are turning\nto service providers to serve the ML models in the ML-as-a-service (MLaaS)\nparadigm. As MLaaS proliferates, a critical requirement emerges: how can model\nconsumers verify that the correct predictions were served, in the face of\nmalicious, lazy, or buggy service providers?\nIn this work, we present the first practical ImageNet-scale method to verify\nML model inference non-interactively, i.e., after the inference has been done.\nTo do so, we leverage recent developments in ZK-SNARKs (zero-knowledge succinct\nnon-interactive argument of knowledge), a form of zero-knowledge proofs.\nZK-SNARKs allows us to verify ML model execution non-interactively and with\nonly standard cryptographic hardness assumptions. In particular, we provide the\nfirst ZK-SNARK proof of valid inference for a full resolution ImageNet model,\nachieving 79\\% top-5 accuracy. We further use these ZK-SNARKs to design\nprotocols to verify ML model execution in a variety of scenarios, including for\nverifying MLaaS predictions, verifying MLaaS model accuracy, and using ML\nmodels for trustless retrieval. Together, our results show that ZK-SNARKs have\nthe promise to make verified ML model inference practical.",
    "descriptor": "",
    "authors": [
      "Daniel Kang",
      "Tatsunori Hashimoto",
      "Ion Stoica",
      "Yi Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08674"
  },
  {
    "id": "arXiv:2210.08675",
    "title": "SGRAM: Improving Scene Graph Parsing via Abstract Meaning Representation",
    "abstract": "Scene graph is structured semantic representation that can be modeled as a\nform of graph from images and texts. Image-based scene graph generation\nresearch has been actively conducted until recently, whereas text-based scene\ngraph generation research has not. In this paper, we focus on the problem of\nscene graph parsing from textual description of a visual scene. The core idea\nis to use abstract meaning representation (AMR) instead of the dependency\nparsing mainly used in previous studies. AMR is a graph-based semantic\nformalism of natural language which abstracts concepts of words in a sentence\ncontrary to the dependency parsing which considers dependency relationships on\nall words in a sentence. To this end, we design a simple yet effective\ntwo-stage scene graph parsing framework utilizing abstract meaning\nrepresentation, SGRAM (Scene GRaph parsing via Abstract Meaning\nrepresentation): 1) transforming a textual description of an image into an AMR\ngraph (Text-to-AMR) and 2) encoding the AMR graph into a Transformer-based\nlanguage model to generate a scene graph (AMR-to-SG). Experimental results show\nthe scene graphs generated by our framework outperforms the dependency\nparsing-based model by 11.61\\% and the previous state-of-the-art model using a\npre-trained Transformer language model by 3.78\\%. Furthermore, we apply SGRAM\nto image retrieval task which is one of downstream tasks for scene graph, and\nconfirm the effectiveness of scene graphs generated by our framework.",
    "descriptor": "\nComments: 7 pages, 3 figures, 3 tables\n",
    "authors": [
      "Woo Suk Choi",
      "Yu-Jung Heo",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08675"
  },
  {
    "id": "arXiv:2210.08676",
    "title": "Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate  Networks",
    "abstract": "We propose using a coordinate network decoder for the task of\nsuper-resolution in MRI. The continuous signal representation of coordinate\nnetworks enables this approach to be scale-agnostic, i.e. one can train over a\ncontinuous range of scales and subsequently query at arbitrary resolutions. Due\nto the difficulty of performing super-resolution on inherently noisy data, we\nanalyze network behavior under multiple denoising strategies. Lastly we compare\nthis method to a standard convolutional decoder using both quantitative metrics\nand a radiologist study implemented in Voxel, our newly developed tool for\nweb-based evaluation of medical images.",
    "descriptor": "",
    "authors": [
      "Dave Van Veen",
      "Rogier van der Sluijs",
      "Batu Ozturkler",
      "Arjun Desai",
      "Christian Bluethgen",
      "Robert D. Boutin",
      "Marc H. Willis",
      "Gordon Wetzstein",
      "David Lindell",
      "Shreyas Vasanawala",
      "John Pauly",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08676"
  },
  {
    "id": "arXiv:2210.08677",
    "title": "Regularized Data Programming with Bayesian Priors",
    "abstract": "The cost of manual data labeling can be a significant obstacle in supervised\nlearning. Data programming (DP) offers a weakly supervised solution for\ntraining dataset creation, wherein the outputs of user-defined programmatic\nlabeling functions (LFs) are reconciled through unsupervised learning. However,\nDP can fail to outperform an unweighted majority vote in some scenarios,\nincluding low-data contexts. This work introduces a Bayesian extension of\nclassical DP that mitigates failures of unsupervised learning by augmenting the\nDP objective with regularization terms. Regularized learning is achieved\nthrough maximum a posteriori estimation in the Bayesian model. Results suggest\nthat regularized DP improves performance relative to maximum likelihood and\nmajority voting, confers greater interpretability, and bolsters performance in\nlow-data regimes.",
    "descriptor": "",
    "authors": [
      "Jacqueline R. M. A. Maasch",
      "Hao Zhang",
      "Qian Yang",
      "Fei Wang",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08677"
  },
  {
    "id": "arXiv:2210.08679",
    "title": "Causal Inference for De-biasing Motion Estimation from Robotic  Observational Data",
    "abstract": "Robot data collected in complex real-world scenarios are often biased due to\nsafety concerns, human preferences, and mission or platform constraints.\nConsequently, robot learning from such observational data poses great\nchallenges for accurate parameter estimation. We propose a principled causal\ninference framework for robots to learn the parameters of a stochastic motion\nmodel using observational data. Specifically, we leverage the de-biasing\nfunctionality of the potential-outcome causal inference framework, the Inverse\nPropensity Weighting (IPW), and the Doubly Robust (DR) methods, to obtain a\nbetter parameter estimation of the robot's stochastic motion model. The IPW is\na re-weighting approach to ensure unbiased estimation, and the DR approach\nfurther combines any two estimators to strengthen the unbiased result even if\none of these estimators is biased. We then develop an approximate policy\niteration algorithm using the bias-eliminated estimated state transition\nfunction. We validate our framework using both simulation and real-world\nexperiments, and the results have revealed that the proposed causal\ninference-based navigation and control framework can correctly and efficiently\nlearn the parameters from biased observational data.",
    "descriptor": "\nComments: submitted to ICRA 2023\n",
    "authors": [
      "Junhong Xu",
      "Kai Yin",
      "Jason M. Gregory",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08679"
  },
  {
    "id": "arXiv:2210.08682",
    "title": "AMF-Placer 2.0: Open Source Timing-driven Analytical Mixed-size Placer  for Large-scale Heterogeneous FPGA",
    "abstract": "On modern field-programmable gate arrays (FPGAs), certain critical path\nportions of the designs might be prearranged into many multi-cell macros during\nsynthesis. These movable macros with constraints of shape and resources lead to\nchallenging mixed-size placement for FPGA designs which cannot be addressed by\nprevious analytical placers. Moreover, general timing-driven placement\nalgorithms are facing challenges when handling real-world application design\nand ultrascale FPGA architectures. In this work, we propose AMF-Placer 2.0, an\nopen-source comprehensive timing-driven analytical mixed-size FPGA placer. It\nsupports mixed-size placement of heterogeneous resources (e.g.,\nLUT/FF/LUTRAM/MUX/CARRY/DSP/BRAM) on FPGA, with an interface to Xilinx Vivado.\nStanding upon the shoulders of AMF-Placer 1.0, AMFPlacer 2.0 is equipped with a\nseries of new techniques for timing optimization, including a simple but\neffective timing model, placement-blockage-aware anchor insertion, WNS-aware\ntiming-driven quadratic placement, and sector-guided detailed placement. Based\non a set of the latest large open-source benchmarks from various domains for\nXilinx Ultrascale FPGAs, experimental results indicate that critical path\ndelays realized by AMF-Placer 2.0 are averagely 2.2% and 0.59% higher than\nthose achieved by commercial tool Xilinx Vivavo 2020.2 and 2021.2 respectively.\nMeanwhile, the average runtime of placement procedure of AMF-Placer 2.0 is 14%\nand 8.5% higher than Xilinx Vivavo 2020.2 and 2021.2 respectively. Although\nlimited by the absence of the exact timing model of the device, the information\nof design hierarchy and accurate routing feedback, AMF-Placer 2.0 is the first\nopen-source FPGA placer which can handle the timingdriven mixed-size placement\nof practical complex designs with various FPGA resources and achieves the\ncomparable quality to the latest commercial tools.",
    "descriptor": "",
    "authors": [
      "Tingyuan Liang",
      "Gengjie Chen",
      "Jieru Zhao",
      "Sharad Sinha",
      "Wei Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08682"
  },
  {
    "id": "arXiv:2210.08685",
    "title": "GeoThermalCloud: Machine Learning for Geothermal Resource Exploration",
    "abstract": "This paper presents a novel ML-based methodology for geothermal exploration\ntowards PFA applications. Our methodology is provided through our open-source\nML framework, GeoThermalCloud\n\\url{https://github.com/SmartTensors/GeoThermalCloud.jl}. The GeoThermalCloud\nuses a series of unsupervised, supervised, and physics-informed ML methods\navailable in SmartTensors AI platform \\url{https://github.com/SmartTensors}.\nHere, the presented analyses are performed using our unsupervised ML algorithm\ncalled NMF$k$, which is available in the SmartTensors AI platform. Our ML\nalgorithm facilitates the discovery of new phenomena, hidden patterns, and\nmechanisms that helps us to make informed decisions. Moreover, the\nGeoThermalCloud enhances the collected PFA data and discovers signatures\nrepresentative of geothermal resources. Through GeoThermalCloud, we could\nidentify hidden patterns in the geothermal field data needed to discover blind\nsystems efficiently. Crucial geothermal signatures often overlooked in\ntraditional PFA are extracted using the GeoThermalCloud and analyzed by the\nsubject matter experts to provide ML-enhanced PFA, which is informative for\nefficient exploration. We applied our ML methodology to various open-source\ngeothermal datasets within the U.S. (some of these are collected by past PFA\nwork). The results provide valuable insights into resource types within those\nregions. This ML-enhanced workflow makes the GeoThermalCloud attractive for the\ngeothermal community to improve existing datasets and extract valuable\ninformation often unnoticed during geothermal exploration.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Maruti K. Mudunuru",
      "Velimir V. Vesselinov",
      "Bulbul Ahmmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.08685"
  },
  {
    "id": "arXiv:2210.08692",
    "title": "A Generative User Simulator with GPT-based Architecture and Goal State  Tracking for Reinforced Multi-Domain Dialog Systems",
    "abstract": "Building user simulators (USs) for reinforcement learning (RL) of\ntask-oriented dialog systems (DSs) has gained more and more attention, which,\nhowever, still faces several fundamental challenges. First, it is unclear\nwhether we can leverage pretrained language models to design, for example,\nGPT-2 based USs, to catch up and interact with the recently advanced GPT-2\nbased DSs. Second, an important ingredient in a US is that the user goal can be\neffectively incorporated and tracked; but how to flexibly integrate goal state\ntracking and develop an end-to-end trainable US for multi-domains has remained\nto be a challenge. In this work, we propose a generative user simulator (GUS)\nwith GPT-2 based architecture and goal state tracking towards addressing the\nabove two challenges. Extensive experiments are conducted on MultiWOZ2.1.\nDifferent DSs are trained via RL with GUS, the classic agenda-based user\nsimulator (ABUS) and other ablation simulators respectively, and are compared\nfor cross-model evaluation, corpus-based evaluation and human evaluation. The\nGUS achieves superior results in all three evaluation tasks.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 SereTOD Workshop\n",
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08692"
  },
  {
    "id": "arXiv:2210.08697",
    "title": "ConReader: Exploring Implicit Relations in Contracts for Contract Clause  Extraction",
    "abstract": "We study automatic Contract Clause Extraction (CCE) by modeling implicit\nrelations in legal contracts. Existing CCE methods mostly treat contracts as\nplain text, creating a substantial barrier to understanding contracts of high\ncomplexity. In this work, we first comprehensively analyze the complexity\nissues of contracts and distill out three implicit relations commonly found in\ncontracts, namely, 1) Long-range Context Relation that captures the\ncorrelations of distant clauses; 2) Term-Definition Relation that captures the\nrelation between important terms with their corresponding definitions; and 3)\nSimilar Clause Relation that captures the similarities between clauses of the\nsame type. Then we propose a novel framework ConReader to exploit the above\nthree relations for better contract understanding and improving CCE.\nExperimental results show that ConReader makes the prediction more\ninterpretable and achieves new state-of-the-art on two CCE tasks in both\nconventional and zero-shot settings.",
    "descriptor": "\nComments: To appear at EMNLP 2022 main conference\n",
    "authors": [
      "Weiwen Xu",
      "Yang Deng",
      "Wenqiang Lei",
      "Wenlong Zhao",
      "Tat-Seng Chua",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08697"
  },
  {
    "id": "arXiv:2210.08701",
    "title": "ODG-Q: Robust Quantization via Online Domain Generalization",
    "abstract": "Quantizing neural networks to low-bitwidth is important for model deployment\non resource-limited edge hardware. Although a quantized network has a smaller\nmodel size and memory footprint, it is fragile to adversarial attacks. However,\nfew methods study the robustness and training efficiency of quantized networks.\nTo this end, we propose a new method by recasting robust quantization as an\nonline domain generalization problem, termed ODG-Q, which generates diverse\nadversarial data at a low cost during training. ODG-Q consistently outperforms\nexisting works against various adversarial attacks. For example, on CIFAR-10\ndataset, ODG-Q achieves 49.2% average improvements under five common white-box\nattacks and 21.7% average improvements under five common black-box attacks,\nwith a training cost similar to that of natural training (viz. without\nadversaries). To our best knowledge, this work is the first work that trains\nboth quantized and binary neural networks on ImageNet that consistently improve\nrobustness under different attacks. We also provide a theoretical insight of\nODG-Q that accounts for the bound of model risk on attacked data.",
    "descriptor": "",
    "authors": [
      "Chaofan Tao",
      "Ngai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08701"
  },
  {
    "id": "arXiv:2210.08703",
    "title": "Spoken Dialogue System Based on Attribute Vector for Travel Agent Robot",
    "abstract": "In this study, we develop a dialogue system for a dialogue robot competition.\nIn the system, the characteristics of sightseeing spots are expressed as\n\"attribute vectors\" in advance, and the user is questioned on the different\nattributes of the two candidate spots. Consequently, the system can make\nrecommendations based on user intentions. A dialogue experiment is conducted\nduring a preliminary round of competition. The overall satisfaction score\nobtained is 40.1 out of 63 points, which is a reasonable result. Analysis of\nthe relationship between the system behavior and satisfaction scores reveals\nthat satisfaction increases when the system correctly understands the user\nintention and responds appropriately. However, a negative correlation is\nobserved between the number of user utterances and the satisfaction score. This\nimplies that inappropriate responses reduce the usefulness of the system as a\nconsultation partner.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Motoyuki Suzuki",
      "Shintaro Sodeya",
      "Taichi Nakamura"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08703"
  },
  {
    "id": "arXiv:2210.08708",
    "title": "Teacher Forcing Recovers Reward Functions for Text Generation",
    "abstract": "Reinforcement learning (RL) has been widely used in text generation to\nalleviate the exposure bias issue or to utilize non-parallel datasets. The\nreward function plays an important role in making RL training successful.\nHowever, previous reward functions are typically task-specific and sparse,\nrestricting the use of RL. In our work, we propose a task-agnostic approach\nthat derives a step-wise reward function directly from a model trained with\nteacher forcing. We additionally propose a simple modification to stabilize the\nRL training on non-parallel datasets with our induced reward function.\nEmpirical results show that our method outperforms self-training and reward\nregression methods on several text generation tasks, confirming the\neffectiveness of our reward function.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yongchang Hao",
      "Yuxin Liu",
      "Lili Mou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08708"
  },
  {
    "id": "arXiv:2210.08709",
    "title": "A Unified Positive-Unlabeled Learning Framework for Document-Level  Relation Extraction with Different Levels of Labeling",
    "abstract": "Document-level relation extraction (RE) aims to identify relations between\nentities across multiple sentences. Most previous methods focused on\ndocument-level RE under full supervision. However, in real-world scenario, it\nis expensive and difficult to completely label all relations in a document\nbecause the number of entity pairs in document-level RE grows quadratically\nwith the number of entities. To solve the common incomplete labeling problem,\nwe propose a unified positive-unlabeled learning framework - shift and squared\nranking loss positive-unlabeled (SSR-PU) learning. We use positive-unlabeled\n(PU) learning on document-level RE for the first time. Considering that labeled\ndata of a dataset may lead to prior shift of unlabeled data, we introduce a PU\nlearning under prior shift of training data. Also, using none-class score as an\nadaptive threshold, we propose squared ranking loss and prove its Bayesian\nconsistency with multi-label ranking metrics. Extensive experiments demonstrate\nthat our method achieves an improvement of about 14 F1 points relative to the\nprevious baseline with incomplete labeling. In addition, it outperforms\nprevious state-of-the-art results under both fully supervised and extremely\nunlabeled settings as well.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ye Wang",
      "Xinxin Liu",
      "Wenxin Hu",
      "Tao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08709"
  },
  {
    "id": "arXiv:2210.08710",
    "title": "Joint Plasticity Learning for Camera Incremental Person  Re-Identification",
    "abstract": "Recently, incremental learning for person re-identification receives\nincreasing attention, which is considered a more practical setting in\nreal-world applications. However, the existing works make the strong assumption\nthat the cameras are fixed and the new-emerging data is class-disjoint from\nprevious classes. In this paper, we focus on a new and more practical task,\nnamely Camera Incremental person ReID (CIP-ReID). CIP-ReID requires ReID models\nto continuously learn informative representations without forgetting the\npreviously learned ones only through the data from newly installed cameras.\nThis is challenging as the new data only have local supervision in new cameras\nwith no access to the old data due to privacy issues, and they may also contain\npersons seen by previous cameras. To address this problem, we propose a\nnon-exemplar-based framework, named JPL-ReID. JPL-ReID first adopts a\none-vs-all detector to discover persons who have been presented in previous\ncameras. To maintain learned representations, JPL-ReID utilizes a similarity\ndistillation strategy with no previous training data available. Simultaneously,\nJPL-ReID is capable of learning new knowledge to improve the generalization\nability using a Joint Plasticity Learning objective. The comprehensive\nexperimental results on two datasets demonstrate that our proposed method\nsignificantly outperforms the comparative methods and can achieve\nstate-of-the-art results with remarkable advantages.",
    "descriptor": "",
    "authors": [
      "Zexian Yang",
      "Dayan wu",
      "Bo Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08710"
  },
  {
    "id": "arXiv:2210.08711",
    "title": "Continuous Pseudo-Labeling from the Start",
    "abstract": "Self-training (ST), or pseudo-labeling has sparked significant interest in\nthe automatic speech recognition (ASR) community recently because of its\nsuccess in harnessing unlabeled data. Unlike prior semi-supervised learning\napproaches that relied on iteratively regenerating pseudo-labels (PLs) from a\ntrained model and using them to train a new model, recent state-of-the-art\nmethods perform `continuous training' where PLs are generated using a very\nrecent version of the model being trained. Nevertheless, these approaches still\nrely on bootstrapping the ST using an initial supervised learning phase where\nthe model is trained on labeled data alone. We believe this has the potential\nfor over-fitting to the labeled dataset in low resource settings and that ST\nfrom the start of training should reduce over-fitting. In this paper we show\nhow we can do this by dynamically controlling the evolution of PLs during the\ntraining process in ASR. To the best of our knowledge, this is the first study\nthat shows the feasibility of generating PLs from the very start of the\ntraining. We are able to achieve this using two techniques that avoid\ninstabilities which lead to degenerate models that do not generalize. Firstly,\nwe control the evolution of PLs through a curriculum that uses the online\nchanges in PLs to control the membership of the cache of PLs and improve\ngeneralization. Secondly, we find that by sampling transcriptions from the\npredictive distribution, rather than only using the best transcription, we can\nstabilize training further. With these techniques, our ST models match prior\nworks without an external language model.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Dan Berrebbi",
      "Ronan Collobert",
      "Samy Bengio",
      "Navdeep Jaitly",
      "Tatiana Likhomanenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08711"
  },
  {
    "id": "arXiv:2210.08713",
    "title": "Supervised Prototypical Contrastive Learning for Emotion Recognition in  Conversation",
    "abstract": "Capturing emotions within a conversation plays an essential role in modern\ndialogue systems. However, the weak correlation between emotions and semantics\nbrings many challenges to emotion recognition in conversation (ERC). Even\nsemantically similar utterances, the emotion may vary drastically depending on\ncontexts or speakers. In this paper, we propose a Supervised Prototypical\nContrastive Learning (SPCL) loss for the ERC task. Leveraging the Prototypical\nNetwork, the SPCL targets at solving the imbalanced classification problem\nthrough contrastive learning and does not require a large batch size.\nMeanwhile, we design a difficulty measure function based on the distance\nbetween classes and introduce curriculum learning to alleviate the impact of\nextreme samples. We achieve state-of-the-art results on three widely used\nbenchmarks. Further, we conduct analytical experiments to demonstrate the\neffectiveness of our proposed SPCL and curriculum learning strategy. We release\nthe code at https://github.com/caskcsg/SPCL.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Xiaohui Song",
      "Longtao Huang",
      "Hui Xue",
      "Songlin Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08713"
  },
  {
    "id": "arXiv:2210.08714",
    "title": "Selective Query-guided Debiasing Network for Video Corpus Moment  Retrieval",
    "abstract": "Video moment retrieval (VMR) aims to localize target moments in untrimmed\nvideos pertinent to a given textual query. Existing retrieval systems tend to\nrely on retrieval bias as a shortcut and thus, fail to sufficiently learn\nmulti-modal interactions between query and video. This retrieval bias stems\nfrom learning frequent co-occurrence patterns between query and moments, which\nspuriously correlate objects (e.g., a pencil) referred in the query with\nmoments (e.g., scene of writing with a pencil) where the objects frequently\nappear in the video, such that they converge into biased moment predictions.\nAlthough recent debiasing methods have focused on removing this retrieval bias,\nwe argue that these biased predictions sometimes should be preserved because\nthere are many queries where biased predictions are rather helpful. To\nconjugate this retrieval bias, we propose a Selective Query-guided Debiasing\nnetwork (SQuiDNet), which incorporates the following two main properties: (1)\nBiased Moment Retrieval that intentionally uncovers the biased moments inherent\nin objects of the query and (2) Selective Query-guided Debiasing that performs\nselective debiasing guided by the meaning of the query. Our experimental\nresults on three moment retrieval benchmarks (i.e., TVR, ActivityNet, DiDeMo)\nshow the effectiveness of SQuiDNet and qualitative analysis shows improved\ninterpretability.",
    "descriptor": "\nComments: 16 pages, 6 figures, Accepted in ECCV 2022\n",
    "authors": [
      "Sunjae Yoon",
      "Ji Woo Hong",
      "Eunseop Yoon",
      "Dahyun Kim",
      "Junyeong Kim",
      "Hee Suk Yoon",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08714"
  },
  {
    "id": "arXiv:2210.08715",
    "title": "ReAFFPN: Rotation-equivariant Attention Feature Fusion Pyramid Networks  for Aerial Object Detection",
    "abstract": "This paper proposes a Rotation-equivariant Attention Feature Fusion Pyramid\nNetworks for Aerial Object Detection named ReAFFPN. ReAFFPN aims at improving\nthe effect of rotation-equivariant features fusion between adjacent layers\nwhich suffers from the semantic and scale discontinuity. Due to the\nparticularity of rotational equivariant convolution, general methods are unable\nto achieve their original effect while ensuring rotation equivariance of the\nnetwork. To solve this problem, we design a new Rotation-equivariant Channel\nAttention which has the ability to both generate channel attention and keep\nrotation equivariance. Then we embed a new channel attention function into\nIterative Attentional Feature Fusion (iAFF) module to realize\nRotation-equivariant Attention Feature Fusion. Experimental results demonstrate\nthat ReAFFPN achieves a better rotation-equivariant feature fusion ability and\nsignificantly improve the accuracy of the Rotation-equivariant Convolutional\nNetworks.",
    "descriptor": "\nComments: IGARSS, 4 pages, 3 figures\n",
    "authors": [
      "Chongyu Sun",
      "Yang Xu",
      "Zebin Wu",
      "Zhihui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08715"
  },
  {
    "id": "arXiv:2210.08716",
    "title": "On construction of quantum codes with dual-containing quasi-cyclic codes",
    "abstract": "One of the main objectives of quantum error-correction theory is to construct\nquantum codes with optimal parameters and properties. In this paper, we propose\na class of 2-generator quasi-cyclic codes and study their applications in the\nconstruction of quantum codes over small fields. Firstly, some sufficient\nconditions for these 2-generator quasi-cyclic codes to be dual-containing\nconcerning Hermitian inner product are determined. Then, we utilize these\nHermitian dual-containing quasi-cyclic codes to produce quantum codes via the\nfamous Hermitian construction. Moreover, we present a lower bound on the\nminimum distance of these quasi-cyclic codes, which is helpful to construct\nquantum codes with larger lengths and dimensions. As the computational results,\nmany new quantum codes that exceed the quantum Gilbert-Varshamov bound are\nconstructed over $F_q$, where $q$ is $2,3,4,5$. In particular, 16 binary\nquantum codes raise the lower bound on the minimum distance in Grassl's table\n\\cite{Grassl:codetables}. In nonbinary cases, many quantum codes are new or\nhave better parameters than those in the literature.",
    "descriptor": "\nComments: There was a minor problem with Theorem 7 in the previous version, which we have fixed in this version\n",
    "authors": [
      "Chaofeng Guan",
      "Ruihu Li",
      "Liangdong Lu",
      "Yang Liu",
      "Hao Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08716"
  },
  {
    "id": "arXiv:2210.08717",
    "title": "PROVIDENCE: a Flexible Round-by-Round Risk-Limiting Audit",
    "abstract": "A Risk-Limiting Audit (RLA) is a statistical election tabulation audit with a\nrigorous error guarantee. We present ballot polling RLA PROVIDENCE, an audit\nwith the efficiency of MINERVA and flexibility of BRAVO. We prove that\nPROVIDENCE is risk-limiting in the presence of an adversary who can choose\nsubsequent round sizes given knowledge of previous samples. We describe a\nmeasure of audit workload as a function of the number of rounds, precincts\ntouched, and ballots drawn.We quantify the problem of obtaining a misleading\naudit sample when rounds are too small, demonstrating the importance of the\nresulting constraint on audit planning. We present simulation results\ndemonstrating the superiority of PROVIDENCE using these measures and describing\nan approach to planning audit round schedules.\nWe describe the use of PROVIDENCE by the Rhode Island Board of Elections in a\ntabulation audit of the 2021 election. Our implementation of PROVIDENCE and\naudit planning tools in the open source R2B2 library should be useful to the\nstates of Georgia and Pennsylvania, which are planning pre-certification ballot\npolling RLAs for the 2022 general election.",
    "descriptor": "",
    "authors": [
      "Oliver Broadrick",
      "Poorvi L. Vora",
      "Filip Zag\u00f3rski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08717"
  },
  {
    "id": "arXiv:2210.08723",
    "title": "Private Data Valuation and Fair Payment in Data Marketplaces",
    "abstract": "Data valuation is an essential task in a data marketplace. It aims at fairly\ncompensating data owners for their contribution. There is increasing\nrecognition in the machine learning community that the Shapley value -- a\nfoundational profit-sharing scheme in cooperative game theory -- has major\npotential to value data, because it uniquely satisfies basic properties for\nfair credit allocation and has been shown to be able to identify data sources\nthat are useful or harmful to model performance. However, calculating the\nShapley value requires accessing original data sources. It still remains an\nopen question how to design a real-world data marketplace that takes advantage\nof the Shapley value-based data pricing while protecting privacy and allowing\nfair payments. In this paper, we propose the {\\em first} prototype of a data\nmarketplace that values data sources based on the Shapley value in a\nprivacy-preserving manner and at the same time ensures fair payments. Our\napproach is enabled by a suite of innovations on both algorithm and system\ndesign. We firstly propose a Shapley value calculation algorithm that can be\nefficiently implemented via multiparty computation (MPC) circuits. The key idea\nis to learn a performance predictor that can directly predict model performance\ncorresponding to an input dataset without performing actual training. We\nfurther optimize the MPC circuit design based on the structure of the\nperformance predictor. We further incorporate fair payment into the MPC circuit\nto guarantee that the data that the buyer pays for is exactly the same as the\none that has been valuated. Our experimental results show that the proposed new\ndata valuation algorithm is as effective as the original expensive one.\nFurthermore, the customized MPC protocol is efficient and scalable.",
    "descriptor": "",
    "authors": [
      "Zhihua Tian",
      "Jian Liu",
      "Jingyu Li",
      "Xinle Cao",
      "Ruoxi Jia",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08723"
  },
  {
    "id": "arXiv:2210.08726",
    "title": "Attributed Text Generation via Post-hoc Research and Revision",
    "abstract": "Language models (LMs) now excel at many tasks such as few-shot learning,\nquestion answering, reasoning, and dialog. However, they sometimes generate\nunsupported or misleading content. A user cannot easily determine whether their\noutputs are trustworthy or not, because most LMs do not have any built-in\nmechanism for attribution to external evidence. To enable attribution while\nstill preserving all the powerful advantages of recent generation models, we\npropose RARR (Retrofit Attribution using Research and Revision), a system that\n1) automatically finds attribution for the output of any text generation model\nand 2) post-edits the output to fix unsupported content while preserving the\noriginal output as much as possible. When applied to the output of several\nstate-of-the-art LMs on a diverse set of generation tasks, we find that RARR\nsignificantly improves attribution while otherwise preserving the original\ninput to a much greater degree than previously explored edit models.\nFurthermore, the implementation of RARR requires only a handful of training\nexamples, a large language model, and standard web search.",
    "descriptor": "",
    "authors": [
      "Luyu Gao",
      "Zhuyun Dai",
      "Panupong Pasupat",
      "Anthony Chen",
      "Arun Tejasvi Chaganty",
      "Yicheng Fan",
      "Vincent Y. Zhao",
      "Ni Lao",
      "Hongrae Lee",
      "Da-Cheng Juan",
      "Kelvin Guu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08726"
  },
  {
    "id": "arXiv:2210.08727",
    "title": "Can Quadruped Navigation Robots be Used as Guide Dogs?",
    "abstract": "Bionic robots are generally considered to have strong flexibility,\nadaptability, and stability. Their bionic forms are more likely to interact\nemotionally with people, which means obvious advantages as socially assistive\nrobots. However, it has not been widely concerned and verified in the blind and\nlow-vision community. In this paper, we explored the guiding performance and\nexperience of bionic quadruped robots compared to wheeled robots. We invited\nthe visually impaired participants to complete a) the indoor straight & turn\ntask and obstacle avoidance task in a laboratory environment; b) the outdoor\nreal and complex environment. With the transition from indoor to outdoor, we\nfound that the workload of the bionic quadruped robots changed to\ninsignificant. Moreover, obvious temporal demand indoors changed to significant\nmental demand outdoors. Also, there was no significant advantage of quadruped\nrobots in usability, trust, or satisfaction, which was amplified outdoors. We\nconcluded that walking noise and the gait of quadruped robots would limit the\nguiding effect to a certain extent, and the empathetic effect of its zoomorphic\nform for visually impaired people could not be fully reflected. This paper\nprovides evidence for the empirical research of bionic quadruped robots in the\nfield of guiding VI people, pointing out their shortcomings in guiding\nperformance and experience, and has good instructive value for the design of\nbionic guided robots in the future.",
    "descriptor": "",
    "authors": [
      "Qihe Chen",
      "Luyao Wang",
      "Yan Zhang",
      "ZiangL Li",
      "Tingmin Yan",
      "Fan Wang",
      "Guyue Zhou",
      "Jiangtao Gong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08727"
  },
  {
    "id": "arXiv:2210.08728",
    "title": "Fault Injection based Failure Analysis of CentOS, Anolis OS and  OpenEuler",
    "abstract": "The reliability of operating system (OS) has always been a major concern in\nthe academia and industry. This paper studies how to perform OS failure\nanalysis by fault injection based on the fault mode library. Firstly, we use\nthe fault mode generation method based on Linux abstract hierarchy structure\nanalysis to systematically define the Linux-like fault modes, construct a Linux\nfault mode library and develop a fault injection tool based on the fault mode\nlibrary (FIFML). Then, fault injection experiments are carried out on three\ncommercial Linux distributions, CentOS, Anolis OS and openEuler, to identify\ntheir reliability problems and give improvement suggestions. We also use the\nvirtual file systems of these three OSs as experimental objects, to perform\nfault injection at levels of Light and Normal, measure the performance of 13\ncommon file operations before and after fault injection.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Hao Xu",
      "Yuxi Hu",
      "Bolong Tan",
      "Xiaohai Shi",
      "Zhangjun Lu",
      "Wei Zhang",
      "Jianhui Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.08728"
  },
  {
    "id": "arXiv:2210.08729",
    "title": "VoxelCache: Accelerating Online Mapping in Robotics and 3D  Reconstruction Tasks",
    "abstract": "Real-time 3D mapping is a critical component in many important applications\ntoday including robotics, AR/VR, and 3D visualization. 3D mapping involves\ncontinuously fusing depth maps obtained from depth sensors in phones, robots,\nand autonomous vehicles into a single 3D representative model of the scene.\nMany important applications, e.g., global path planning and trajectory\ngeneration in micro aerial vehicles, require the construction of large maps at\nhigh resolutions. In this work, we identify mapping, i.e., construction and\nupdates of 3D maps to be a critical bottleneck in these applications. The\nmemory required and access times of these maps limit the size of the\nenvironment and the resolution with which the environment can be feasibly\nmapped, especially in resource constrained environments such as autonomous\nrobot platforms and portable devices. To address this challenge, we propose\nVoxelCache: a hardware-software technique to accelerate map data access times\nin 3D mapping applications. We observe that mapping applications typically\naccess voxels in the map that are spatially co-located to each other. We\nleverage this temporal locality in voxel accesses to cache indices to blocks of\nvoxels to enable quick lookup and avoid expensive access times. We evaluate\nVoxelCache on popularly used mapping and reconstruction applications on both\nGPUs and CPUs. We demonstrate an average speedup of 1.47X (up to 1.66X) and\n1.79X (up to 1.91X) on CPUs and GPUs respectively.",
    "descriptor": "",
    "authors": [
      "Sankeerth Durvasula",
      "Raymond Kiguru",
      "Samarth Mathur",
      "Jenny Xu",
      "Jimmy Lin",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08729"
  },
  {
    "id": "arXiv:2210.08730",
    "title": "Robust Bayesian state and parameter estimation framework for stochastic  dynamical systems with combined time-varying and time-invariant parameters",
    "abstract": "We consider state and parameter estimation for a dynamical system having both\ntime-varying and time-invariant parameters. It has been shown that the\nrobustness of the Markov Chain Monte Carlo (MCMC) algorithm for estimating\ntime-invariant parameters alongside nonlinear filters for state estimation\nprovided more reliable estimates than the estimates obtained solely using\nnonlinear filters for combined state and parameter estimation. In a similar\nfashion, we adopt the extended Kalman filter (EKF) for state estimation and the\nestimation of the time-varying system parameters, but reserve the task of\nestimating time-invariant parameters to the MCMC algorithm. In a standard\nmethod, we augment the state vector to include the original states of the\nsystem and the subset of the parameters that are time-varying. Each\ntime-varying parameter is perturbed by a white noise process, and we treat the\nstrength of this artificial noise as an additional time-invariant parameter to\nbe estimated by MCMC, circumventing the need for manual tuning. Conventionally,\nboth time-varying and time-invariant parameters are appended in the state\nvector, and thus for the purpose of estimation, both are free to vary in time.\nHowever, allowing time-invariant system parameters to vary in time introduces\nartificial dynamics into the system, which we avoid by treating these\ntime-invariant parameters as static and estimating them using MCMC.\nFurthermore, by estimating the time-invariant parameters by MCMC, the augmented\nstate is smaller and the nonlinearity in the ensuing state space model will\ntend to be weaker than in the conventional approach. We illustrate the\nabove-described approach for a simple dynamical system in which some model\nparameters are time-varying, while the remaining parameters are time-invariant.",
    "descriptor": "",
    "authors": [
      "Philippe Bisaillon",
      "Brandon Robinson",
      "Mohammad Khalil",
      "Chris L. Pettit",
      "Dominique Poirel",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.08730"
  },
  {
    "id": "arXiv:2210.08731",
    "title": "A High Fidelity Simulation Framework for Potential Safety Benefits  Estimation of Cooperative Pedestrian Perception",
    "abstract": "This paper proposes a high-fidelity simulation framework that can estimate\nthe potential safety benefits of vehicle-to-infrastructure (V2I) pedestrian\nsafety strategies. This simulator can support cooperative perception algorithms\nin the loop by simulating the environmental conditions, traffic conditions, and\npedestrian characteristics at the same time. Besides, the benefit estimation\nmodel applied in our framework can systematically quantify both the risk\nconflict (non-crash condition) and the severity of the pedestrian's injuries\n(crash condition). An experiment was conducted in this paper that built a\ndigital twin of a crowded urban intersection in China. The result shows that\nour framework is efficient for safety benefit estimation of V2I pedestrian\nsafety strategies.",
    "descriptor": "",
    "authors": [
      "Yan Zhang",
      "Longrui Chen",
      "Wenjie Jiang",
      "Jiangtao Gong",
      "Jiahao Shen",
      "Mengdi Chu",
      "Chuxuan Li",
      "Yifeng Pan",
      "Yifeng Shi",
      "Nairui Luo",
      "Xu Gao",
      "Jirui Yuan",
      "Guyue Zhou",
      "Yaqin Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08731"
  },
  {
    "id": "arXiv:2210.08732",
    "title": "Forecasting Human Trajectory from Scene History",
    "abstract": "Predicting the future trajectory of a person remains a challenging problem,\ndue to randomness and subjectivity of human movement. However, the moving\npatterns of human in a constrained scenario typically conform to a limited\nnumber of regularities to a certain extent, because of the scenario\nrestrictions and person-person or person-object interactivity. Thus, an\nindividual person in this scenario should follow one of the regularities as\nwell. In other words, a person's subsequent trajectory has likely been traveled\nby others. Based on this hypothesis, we propose to forecast a person's future\ntrajectory by learning from the implicit scene regularities. We call the\nregularities, inherently derived from the past dynamics of the people and the\nenvironment in the scene, scene history. We categorize scene history\ninformation into two types: historical group trajectory and\nindividual-surroundings interaction. To exploit these two types of information\nfor trajectory prediction, we propose a novel framework Scene History\nExcavating Network (SHENet), where the scene history is leveraged in a simple\nyet effective approach. In particular, we design two components: the group\ntrajectory bank module to extract representative group trajectories as the\ncandidate for future path, and the cross-modal interaction module to model the\ninteraction between individual past trajectory and its surroundings for\ntrajectory refinement. In addition, to mitigate the uncertainty in ground-truth\ntrajectory, caused by the aforementioned randomness and subjectivity of human\nmovement, we propose to include smoothness into the training process and\nevaluation metrics. We conduct extensive evaluations to validate the efficacy\nof our proposed framework on ETH, UCY, as well as a new, challenging benchmark\ndataset PAV, demonstrating superior performance compared to state-of-the-art\nmethods.",
    "descriptor": "\nComments: Accept in the Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Mancheng Meng",
      "Ziyan Wu",
      "Terrence Chen",
      "Xiran Cai",
      "Xiang Sean Zhou",
      "Fan Yang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08732"
  },
  {
    "id": "arXiv:2210.08735",
    "title": "Runner-Up Solution to Google Universal Image Embedding Competition 2022",
    "abstract": "Image representations are a critical building block of computer vision\napplications. This paper presents the 2nd place solution to the Google\nUniversal Image Embedding Competition, which is part of the ECCV2022\ninstance-level recognition workshops. We use the instance-level fine-grained\nimage classification method to complete this competition. We focus on data\nbuilding and processing, model structure, and training strategies. Finally, the\nsolution scored 0.713 on the public leaderboard and 0.709 on the private\nleaderboard.",
    "descriptor": "\nComments: Instance-Level Recognition Workshop at ECCV 2022, Google Universal Image Embedding, 2nd place solution\n",
    "authors": [
      "Xiaolong Huang",
      "QianKun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08735"
  },
  {
    "id": "arXiv:2210.08737",
    "title": "Temporal and Contextual Transformer for Multi-Camera Editing of TV Shows",
    "abstract": "The ability to choose an appropriate camera view among multiple cameras plays\na vital role in TV shows delivery. But it is hard to figure out the statistical\npattern and apply intelligent processing due to the lack of high-quality\ntraining data. To solve this issue, we first collect a novel benchmark on this\nsetting with four diverse scenarios including concerts, sports games, gala\nshows, and contests, where each scenario contains 6 synchronized tracks\nrecorded by different cameras. It contains 88-hour raw videos that contribute\nto the 14-hour edited videos. Based on this benchmark, we further propose a new\napproach temporal and contextual transformer that utilizes clues from\nhistorical shots and other views to make shot transition decisions and predict\nwhich view to be used. Extensive experiments show that our method outperforms\nexisting methods on the proposed multi-camera editing benchmark.",
    "descriptor": "\nComments: Extended Abstract of ECCV 2022 Workshop on AI for Creative Video Editing and Understanding\n",
    "authors": [
      "Anyi Rao",
      "Xuekun Jiang",
      "Sichen Wang",
      "Yuwei Guo",
      "Zihao Liu",
      "Bo Dai",
      "Long Pang",
      "Xiaoyu Wu",
      "Dahua Lin",
      "Libiao Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08737"
  },
  {
    "id": "arXiv:2210.08738",
    "title": "PCGen: Point Cloud Generator for LiDAR Simulation",
    "abstract": "Data is a fundamental building block for LiDAR perception systems.\nUnfortunately, real-world data collection and annotation is extremely costly &\nlaborious. Recently, real data based LiDAR simulators have shown tremendous\npotential to complement real data, due to their scalability and high-fidelity\ncompared to graphics engine based methods. Before simulation can be deployed in\nthe real-world, two shortcomings need to be addressed. First, existing methods\nusually generate data which are more noisy and complete than the real point\nclouds, due to 3D reconstruction error and pure geometry-based raycasting\nmethod. Second, prior works on simulation for object detection focus solely on\nrigid objects, like cars, but VRUs, like pedestrians, are important road\nparticipants. To tackle the first challenge, we propose FPA raycasting and\nsurrogate model raydrop. FPA enables the simulation of both point cloud\ncoordinates and sensor features, while taking into account reconstruction\nnoise. The ray-wise surrogate raydrop model mimics the physical properties of\nLiDAR's laser receiver to determine whether a simulated point would be recorded\nby a real LiDAR. With minimal training data, the surrogate model can generalize\nto different geographies and scenes, closing the domain gap between raycasted\nand real point clouds. To tackle the simulation of deformable VRU simulation,\nwe employ SMPL dataset to provide a pedestrian simulation baseline and compare\nthe domain gap between CAD and reconstructed objects. Applying our pipeline to\nperform novel sensor synthesis, results show that object detection models\ntrained by simulation data can achieve similar result as the real data trained\nmodel.",
    "descriptor": "",
    "authors": [
      "Chenqi Li",
      "Yuan Ren",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08738"
  },
  {
    "id": "arXiv:2210.08742",
    "title": "Tencent AI Lab - Shanghai Jiao Tong University Low-Resource Translation  System for the WMT22 Translation Task",
    "abstract": "This paper describes Tencent AI Lab - Shanghai Jiao Tong University\n(TAL-SJTU) Low-Resource Translation systems for the WMT22 shared task. We\nparticipate in the general translation task on\nEnglish$\\Leftrightarrow$Livonian. Our system is based on M2M100 with novel\ntechniques that adapt it to the target language pair. (1) Cross-model word\nembedding alignment: inspired by cross-lingual word embedding alignment, we\nsuccessfully transfer a pre-trained word embedding to M2M100, enabling it to\nsupport Livonian. (2) Gradual adaptation strategy: we exploit Estonian and\nLatvian as auxiliary languages for many-to-many translation training and then\nadapt to English-Livonian. (3) Data augmentation: to enlarge the parallel data\nfor English-Livonian, we construct pseudo-parallel data with Estonian and\nLatvian as pivot languages. (4) Fine-tuning: to make the most of all available\ndata, we fine-tune the model with the validation set and online\nback-translation, further boosting the performance. In model evaluation: (1) We\nfind that previous work underestimated the translation performance of Livonian\ndue to inconsistent Unicode normalization, which may cause a discrepancy of up\nto 14.9 BLEU score. (2) In addition to the standard validation set, we also\nemploy round-trip BLEU to evaluate the models, which we find more appropriate\nfor this task. Finally, our unconstrained system achieves BLEU scores of 17.0\nand 30.4 for English to/from Livonian.",
    "descriptor": "\nComments: WMT 2022\n",
    "authors": [
      "Zhiwei He",
      "Xing Wang",
      "Zhaopeng Tu",
      "Shuming Shi",
      "Rui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08742"
  },
  {
    "id": "arXiv:2210.08745",
    "title": "Row-wise LiDAR Lane Detection Network with Lane Correlation Refinement",
    "abstract": "Lane detection is one of the most important functions for autonomous driving.\nIn recent years, deep learning-based lane detection networks with RGB camera\nimages have shown promising performance. However, camera-based methods are\ninherently vulnerable to adverse lighting conditions such as poor or dazzling\nlighting. Unlike camera, LiDAR sensor is robust to the lighting conditions. In\nthis work, we propose a novel two-stage LiDAR lane detection network with\nrow-wise detection approach. The first-stage network produces lane proposals\nthrough a global feature correlator backbone and a row-wise detection head.\nMeanwhile, the second-stage network refines the feature map of the first-stage\nnetwork via attention-based mechanism between the local features around the\nlane proposals, and outputs a set of new lane proposals. Experimental results\non the K-Lane dataset show that the proposed network advances the\nstate-of-the-art in terms of F1-score with 30% less GFLOPs. In addition, the\nsecond-stage network is found to be especially robust to lane occlusions, thus,\ndemonstrating the robustness of the proposed network for driving in crowded\nenvironments.",
    "descriptor": "\nComments: Accepted at 2022 IEEE Conference on Intelligent Transportation Systems (ITSC)\n",
    "authors": [
      "Dong-Hee Paek",
      "Kevin Tirta Wijaya",
      "Seung-Hyun Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08745"
  },
  {
    "id": "arXiv:2210.08748",
    "title": "Dual-Curriculum Teacher for Domain-Inconsistent Object Detection in  Autonomous Driving",
    "abstract": "Object detection for autonomous vehicles has received increasing attention in\nrecent years, where labeled data are often expensive while unlabeled data can\nbe collected readily, calling for research on semi-supervised learning for this\narea. Existing semi-supervised object detection (SSOD) methods usually assume\nthat the labeled and unlabeled data come from the same data distribution. In\nautonomous driving, however, data are usually collected from different\nscenarios, such as different weather conditions or different times in a day.\nMotivated by this, we study a novel but challenging domain inconsistent SSOD\nproblem. It involves two kinds of distribution shifts among different domains,\nincluding (1) data distribution discrepancy, and (2) class distribution shifts,\nmaking existing SSOD methods suffer from inaccurate pseudo-labels and hurting\nmodel performance. To address this problem, we propose a novel method, namely\nDual-Curriculum Teacher (DucTeacher). Specifically, DucTeacher consists of two\ncurriculums, i.e., (1) domain evolving curriculum seeks to learn from the data\nprogressively to handle data distribution discrepancy by estimating the\nsimilarity between domains, and (2) distribution matching curriculum seeks to\nestimate the class distribution for each unlabeled domain to handle class\ndistribution shifts. In this way, DucTeacher can calibrate biased pseudo-labels\nand handle the domain-inconsistent SSOD problem effectively. DucTeacher shows\nits advantages on SODA10M, the largest public semi-supervised autonomous\ndriving dataset, and COCO, a widely used SSOD benchmark. Experiments show that\nDucTeacher achieves new state-of-the-art performance on SODA10M with 2.2 mAP\nimprovement and on COCO with 0.8 mAP improvement.",
    "descriptor": "\nComments: Accepted at BMVC 2022\n",
    "authors": [
      "Longhui Yu",
      "Yifan Zhang",
      "Lanqing Hong",
      "Fei Chen",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08748"
  },
  {
    "id": "arXiv:2210.08749",
    "title": "A Transformer-based Generative Model for De Novo Molecular Design",
    "abstract": "Deep learning draws a lot of attention as a new way of generating unseen\nstructures for drug discovery. We propose a Transformer-based deep model for de\nnovo target-specific molecular design. The proposed method is capable of\ngenerating both drug-like compounds and target-specific compounds. The latter\nare generated by enforcing different keys and values of the multi-head\nattention for each target. We allow the generation of SMILES strings to be\nconditional on the specified target. The sampled compounds largely occupy the\nreal target-specific data's chemical space and also cover a significant\nfraction of novel compounds.",
    "descriptor": "",
    "authors": [
      "Wenlu Wang",
      "Ye Wang",
      "Honggang Zhao",
      "Simone Sciabola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.08749"
  },
  {
    "id": "arXiv:2210.08750",
    "title": "Keep Me Updated! Memory Management in Long-term Conversations",
    "abstract": "Remembering important information from the past and continuing to talk about\nit in the present are crucial in long-term conversations. However, previous\nliterature does not deal with cases where the memorized information is\noutdated, which may cause confusion in later conversations. To address this\nissue, we present a novel task and a corresponding dataset of memory management\nin long-term conversations, in which bots keep track of and bring up the latest\ninformation about users while conversing through multiple sessions. In order to\nsupport more precise and interpretable memory, we represent memory as\nunstructured text descriptions of key information and propose a new mechanism\nof memory management that selectively eliminates invalidated or redundant\ninformation. Experimental results show that our approach outperforms the\nbaselines that leave the stored memory unchanged in terms of engagingness and\nhumanness, with larger performance gap especially in the later sessions.",
    "descriptor": "\nComments: Accepted to EMNLP2022 Findings\n",
    "authors": [
      "Sanghwan Bae",
      "Donghyun Kwak",
      "Soyoung Kang",
      "Min Young Lee",
      "Sungdong Kim",
      "Yuin Jeong",
      "Hyeri Kim",
      "Sang-Woo Lee",
      "Woomyoung Park",
      "Nako Sung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08750"
  },
  {
    "id": "arXiv:2210.08751",
    "title": "Use of a smartphone camera to determine the focal length of a thin lens  by finding the transverse magnification of the virtual image of an object",
    "abstract": "In this work we have determined the focal length of a concave lens by\nphotographing the virtual image of an object by a smartphone camera. We have\nsimilarly determined the focal length of a convex lens by forming a virtual\nimage of an object keeping it within the focal distance from the lens. When a\nphotograph is taken by a smartphone, the transverse width of the image on the\nsensor of the camera in pixels can be read off by software available freely\nfrom the internet. By taking a photograph of the virtual image from two\npositions of the camera separated by a distance along the line of sight of the\ncamera, we have determined the transverse width of the virtual image. From this\nwe find the focal lengths of the lenses knowing the transverse width and the\ndistance of the object from the lenses.",
    "descriptor": "\nComments: 11 pages,2 figures\n",
    "authors": [
      "Sanjoy Kumar Pal",
      "Soumen Sarkar",
      "Surajit Chakrabarti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08751"
  },
  {
    "id": "arXiv:2210.08753",
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "abstract": "Personalized chatbots focus on endowing the chatbots with a consistent\npersonality to behave like real users and further act as personal assistants.\nPrevious studies have explored generating implicit user profiles from the\nuser's dialogue history for building personalized chatbots. However, these\nstudies only use the response generation loss to train the entire model, thus\nit is prone to suffer from the problem of data sparsity. Besides, they\noveremphasize the final generated response's quality while ignoring the\ncorrelations and fusions between the user's dialogue history, leading to rough\ndata representations and performance degradation. To tackle these problems, we\npropose a self-supervised learning framework MCP for capturing better\nrepresentations from users' dialogue history for personalized chatbots.\nSpecifically, we apply contrastive sampling methods to leverage the supervised\nsignals hidden in user dialog history, and generate the pre-training samples\nfor enhancing the model. We design three pre-training tasks based on three\ntypes of contrastive pairs from user dialogue history, namely response pairs,\nsequence augmentation pairs, and user pairs. We pre-train the utterance encoder\nand the history encoder towards the contrastive objectives and use these\npre-trained encoders for generating user profiles while personalized response\ngeneration. Experimental results on two real-world datasets show a significant\nimprovement in our proposed model MCP compared with the existing methods.",
    "descriptor": "",
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08753"
  },
  {
    "id": "arXiv:2210.08758",
    "title": "Systematic Evaluation of Predictive Fairness",
    "abstract": "Mitigating bias in training on biased datasets is an important open problem.\nSeveral techniques have been proposed, however the typical evaluation regime is\nvery limited, considering very narrow data conditions. For instance, the effect\nof target class imbalance and stereotyping is under-studied. To address this\ngap, we examine the performance of various debiasing methods across multiple\ntasks, spanning binary classification (Twitter sentiment), multi-class\nclassification (profession prediction), and regression (valence prediction).\nThrough extensive experimentation, we find that data conditions have a strong\ninfluence on relative model performance, and that general conclusions cannot be\ndrawn about method efficacy when evaluating only on standard datasets, as is\ncurrent practice in fairness research.",
    "descriptor": "\nComments: AACL 2022\n",
    "authors": [
      "Xudong Han",
      "Aili Shen",
      "Trevor Cohn",
      "Timothy Baldwin",
      "Lea Frermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08758"
  },
  {
    "id": "arXiv:2210.08759",
    "title": "Towards Relation Extraction From Speech",
    "abstract": "Relation extraction typically aims to extract semantic relationships between\nentities from the unstructured text. One of the most essential data sources for\nrelation extraction is the spoken language, such as interviews and dialogues.\nHowever, the error propagation introduced in automatic speech recognition (ASR)\nhas been ignored in relation extraction, and the end-to-end speech-based\nrelation extraction method has been rarely explored. In this paper, we propose\na new listening information extraction task, i.e., speech relation extraction.\nWe construct the training dataset for speech relation extraction via\ntext-to-speech systems, and we construct the testing dataset via crowd-sourcing\nwith native English speakers. We explore speech relation extraction via two\napproaches: the pipeline approach conducting text-based extraction with a\npretrained ASR module, and the end2end approach via a new proposed\nencoder-decoder model, or what we called SpeechRE. We conduct comprehensive\nexperiments to distinguish the challenges in speech relation extraction, which\nmay shed light on future explorations. We share the code and data on\nhttps://github.com/wutong8023/SpeechRE.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Tongtong Wu",
      "Guitao Wang",
      "Jinming Zhao",
      "Zhaoran Liu",
      "Guilin Qi",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08759"
  },
  {
    "id": "arXiv:2210.08763",
    "title": "ReasonChainQA: Text-based Complex Question Answering with Explainable  Evidence Chains",
    "abstract": "The ability of reasoning over evidence has received increasing attention in\nquestion answering (QA). Recently, natural language database (NLDB) conducts\ncomplex QA in knowledge base with textual evidences rather than structured\nrepresentations, this task attracts a lot of attention because of the\nflexibility and richness of textual evidence. However, existing text-based\ncomplex question answering datasets fail to provide explicit reasoning process,\nwhile it's important for retrieval effectiveness and reasoning\ninterpretability. Therefore, we present a benchmark \\textbf{ReasonChainQA} with\nexplanatory and explicit evidence chains. ReasonChainQA consists of two\nsubtasks: answer generation and evidence chains extraction, it also contains\nhigher diversity for multi-hop questions with varying depths, 12 reasoning\ntypes and 78 relations. To obtain high-quality textual evidences for answering\ncomplex question. Additional experiment on supervised and unsupervised\nretrieval fully indicates the significance of ReasonChainQA. Dataset and codes\nwill be made publicly available upon accepted.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Minjun Zhu",
      "Yixuan Weng",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08763"
  },
  {
    "id": "arXiv:2210.08765",
    "title": "Temporal Link Prediction: A Unified Framework, Taxonomy, and Review",
    "abstract": "Dynamic graphs serve as a generic abstraction and description of the\nevolutionary behaviors of various complex systems (e.g., social networks and\ncommunication networks). Temporal link prediction (TLP) is a classic inference\ntask on dynamic graphs, which aims to predict possible future linkage using\nhistorical dynamic topology. The predicted future topology can be used to\nsupport some advanced applications on real-world systems (e.g., resource\npre-allocation) for better system performance. This survey provides a\ncomprehensive review of existing representative TLP methods. Concretely, we\nfirst give the formal statements regarding data models, task settings, and\nlearning paradigms that are commonly used in related research. A hierarchical\nfine-grained taxonomy is further introduced to categorize existing methods in\nterms of their data models, learning paradigms, and techniques. From a generic\nperspective, we propose a unified encoder-decoder framework to formulate all\nthe methods reviewed, where different approaches only differ in terms of some\ncomponents of the unified framework. Moreover, we envision serving the\ncommunity with an open-source project OpenTLP that refactors or implements some\nrepresentative TLP methods using the proposed unified framework and summarizes\nother public sources. To conclude this survey, we also discuss some advanced\ntopics in recent research and highlight possible future directions.",
    "descriptor": "",
    "authors": [
      "Meng Qin",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08765"
  },
  {
    "id": "arXiv:2210.08768",
    "title": "N-pad : Neighboring Pixel-based Industrial Anomaly Detection",
    "abstract": "Identifying defects in the images of industrial products has been an\nimportant task to enhance quality control and reduce maintenance costs. In\nrecent studies, industrial anomaly detection models were developed using\npre-trained networks to learn nominal representations. To employ the relative\npositional information of each pixel, we present \\textit{\\textbf{N-pad}}, a\nnovel method for anomaly detection and segmentation in a one-class learning\nsetting that includes the neighborhood of the target pixel for model training\nand evaluation. Within the model architecture, pixel-wise nominal distributions\nare estimated by using the features of neighboring pixels with the target pixel\nto allow possible marginal misalignment. Moreover, the centroids from clusters\nof nominal features are identified as a representative nominal set.\nAccordingly, anomaly scores are inferred based on the Mahalanobis distances and\nEuclidean distances between the target pixel and the estimated distributions or\nthe centroid set, respectively. Thus, we have achieved state-of-the-art\nperformance in MVTec-AD with AUROC of 99.37 for anomaly detection and 98.75 for\nanomaly segmentation, reducing the error by 34\\% compared to the next best\nperforming model. Experiments in various settings further validate our model.",
    "descriptor": "",
    "authors": [
      "JunKyu Jang",
      "Eugene Hwang",
      "Sung-Hyuk Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08768"
  },
  {
    "id": "arXiv:2210.08770",
    "title": "Massive MIMO Channel Prediction Via Meta-Learning and Deep Denoising: Is  a Small Dataset Enough?",
    "abstract": "Accurate channel knowledge is critical in massive multiple-input\nmultiple-output (MIMO), which motivates the use of channel prediction. Machine\nlearning techniques for channel prediction hold much promise, but current\nschemes are limited in their ability to adapt to changes in the environment\nbecause they require large training overheads. To accurately predict wireless\nchannels for new environments with reduced training overhead, we propose a fast\nadaptive channel prediction technique based on a meta-learning algorithm for\nmassive MIMO communications. We exploit the model-agnostic meta-learning (MAML)\nalgorithm to achieve quick adaptation with a small amount of labeled data.\nAlso, to improve the prediction accuracy, we adopt the denoising process for\nthe training data by using deep image prior (DIP). Numerical results show that\nthe proposed MAML-based channel predictor can improve the prediction accuracy\nwith only a few fine-tuning samples. The DIP-based denoising process gives an\nadditional gain in channel prediction, especially in low signal-to-noise ratio\nregimes.",
    "descriptor": "\nComments: 11 pages, 11 figures, submitted to IEEE Transactions on Wireless Communications (TWC)\n",
    "authors": [
      "Hwanjin Kim",
      "Junil Choi",
      "David J. Love"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08770"
  },
  {
    "id": "arXiv:2210.08772",
    "title": "Signal Processing for Implicit Neural Representations",
    "abstract": "Implicit Neural Representations (INRs) encoding continuous multi-media data\nvia multi-layer perceptrons has shown undebatable promise in various computer\nvision tasks. Despite many successful applications, editing and processing an\nINR remains intractable as signals are represented by latent parameters of a\nneural network. Existing works manipulate such continuous representations via\nprocessing on their discretized instance, which breaks down the compactness and\ncontinuous nature of INR. In this work, we present a pilot study on the\nquestion: how to directly modify an INR without explicit decoding? We answer\nthis question by proposing an implicit neural signal processing network, dubbed\nINSP-Net, via differential operators on INR. Our key insight is that spatial\ngradients of neural networks can be computed analytically and are invariant to\ntranslation, while mathematically we show that any continuous convolution\nfilter can be uniformly approximated by a linear combination of high-order\ndifferential operators. With these two knobs, INSP-Net instantiates the signal\nprocessing operator as a weighted composition of computational graphs\ncorresponding to the high-order derivatives of INRs, where the weighting\nparameters can be data-driven learned. Based on our proposed INSP-Net, we\nfurther build the first Convolutional Neural Network (CNN) that implicitly runs\non INRs, named INSP-ConvNet. Our experiments validate the expressiveness of\nINSP-Net and INSP-ConvNet in fitting low-level image and geometry processing\nkernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as\nwell as for high-level tasks on implicit fields such as image classification.",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Dejia Xu",
      "Peihao Wang",
      "Yifan Jiang",
      "Zhiwen Fan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08772"
  },
  {
    "id": "arXiv:2210.08773",
    "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models  with Zero Training",
    "abstract": "Visual question answering (VQA) is a hallmark of vision and language\nreasoning and a challenging task under the zero-shot setting. We propose\nPlug-and-Play VQA (PNP-VQA), a modular framework for zero-shot VQA. In contrast\nto most existing works, which require substantial adaptation of pretrained\nlanguage models (PLMs) for the vision modality, PNP-VQA requires no additional\ntraining of the PLMs. Instead, we propose to use natural language and network\ninterpretation as an intermediate representation that glues pretrained models\ntogether. We first generate question-guided informative image captions, and\npass the captions to a PLM as context for question answering. Surpassing\nend-to-end trained baselines, PNP-VQA achieves state-of-the-art results on\nzero-shot VQAv2 and GQA. With 11B parameters, it outperforms the 80B-parameter\nFlamingo model by 8.5% on VQAv2. With 738M PLM parameters, PNP-VQA achieves an\nimprovement of 9.1% on GQA over FewVLM with 740M PLM parameters. Code is\nreleased at https://github.com/salesforce/LAVIS/tree/main/projects/pnp-vqa",
    "descriptor": "\nComments: EMNLP 2022 (Findings)\n",
    "authors": [
      "Anthony Meng Huat Tiong",
      "Junnan Li",
      "Boyang Li",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08773"
  },
  {
    "id": "arXiv:2210.08779",
    "title": "Towards Summary Candidates Fusion",
    "abstract": "Sequence-to-sequence deep neural models fine-tuned for abstractive\nsummarization can achieve great performance on datasets with enough human\nannotations. Yet, it has been shown that they have not reached their full\npotential, with a wide gap between the top beam search output and the oracle\nbeam. Recently, re-ranking methods have been proposed, to learn to select a\nbetter summary candidate. However, such methods are limited by the summary\nquality aspects captured by the first-stage candidates. To bypass this\nlimitation, we propose a new paradigm in second-stage abstractive summarization\ncalled SummaFusion that fuses several summary candidates to produce a novel\nabstractive second-stage summary. Our method works well on several\nsummarization datasets, improving both the ROUGE scores and qualitative\nproperties of fused summaries. It is especially good when the candidates to\nfuse are worse, such as in the few-shot setup where we set a new\nstate-of-the-art. We will make our code and checkpoints available at\nhttps://github.com/ntunlp/SummaFusion/.",
    "descriptor": "\nComments: 4 Figures, 9 Tables, EMNLP 2022\n",
    "authors": [
      "Mathieu Ravaut",
      "Shafiq Joty",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08779"
  },
  {
    "id": "arXiv:2210.08780",
    "title": "Sample-efficient Model Predictive Control Design of Soft Robotics by  Bayesian Optimization",
    "abstract": "This paper presents a sample-efficient data-driven method to design model\npredictive control (MPC) for cable-actuated soft robotics using Bayesian\noptimization. Instead of modeling the complex dynamics of the soft robots, the\nproposed approach uses Bayesian optimization to search the best-guessed\nlow-dimensional prediction model and its associated controller to minimize the\nobjective function of closed-loop responses. The prediction model is updated by\nBayesian optimization from the closed-loop input-output data in each iteration.\nA linear MPC is then designed based on the updated prediction model, and\nevaluated based on the closed-loop responses. Different from directly searching\ncontroller parameters, the closed-loop system stability, and inputs/outputs\nconstraints can be easily handled in the MPC design. After a few iterations, a\nconvergent solution of a (sub-)optimal controller can be obtained, which\nminimizes the user-defined closed-loop performance index. The proposed method\nis simulated and validated by a high-fidelity simulation of a cable-actuated\nsoft robot. The simulation results demonstrate that the proposed approach can\nachieve desired tracking controller for the soft robot without a prior-known\nmodel.",
    "descriptor": "\nComments: submitted to ACC 2023\n",
    "authors": [
      "Anuj Pal",
      "Tianyi He",
      "Wenpeng Wei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08780"
  },
  {
    "id": "arXiv:2210.08781",
    "title": "Stochastic Differentially Private and Fair Learning",
    "abstract": "Machine learning models are increasingly used in high-stakes decision-making\nsystems. In such applications, a major concern is that these models sometimes\ndiscriminate against certain demographic groups such as individuals with\ncertain race, gender, or age. Another major concern in these applications is\nthe violation of the privacy of users. While fair learning algorithms have been\ndeveloped to mitigate discrimination issues, these algorithms can still leak\nsensitive information, such as individuals' health or financial records.\nUtilizing the notion of differential privacy (DP), prior works aimed at\ndeveloping learning algorithms that are both private and fair. However,\nexisting algorithms for DP fair learning are either not guaranteed to converge\nor require full batch of data in each iteration of the algorithm to converge.\nIn this paper, we provide the first stochastic differentially private algorithm\nfor fair learning that is guaranteed to converge. Here, the term \"stochastic\"\nrefers to the fact that our proposed algorithm converges even when minibatches\nof data are used at each iteration (i.e. stochastic optimization). Our\nframework is flexible enough to permit different fairness notions, including\ndemographic parity and equalized odds. In addition, our algorithm can be\napplied to non-binary classification tasks with multiple (non-binary) sensitive\nattributes. As a byproduct of our convergence analysis, we provide the first\nutility guarantee for a DP algorithm for solving nonconvex-strongly concave\nmin-max problems. Our numerical experiments show that the proposed algorithm\nconsistently offers significant performance gains over the state-of-the-art\nbaselines, and can be applied to larger scale problems with non-binary\ntarget/sensitive attributes.",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Devansh Gupta",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08781"
  },
  {
    "id": "arXiv:2210.08782",
    "title": "On powers of circular arc graphs",
    "abstract": "A class of graphs $\\mathcal{C}$ is closed under powers if for every graph\n$G\\in\\mathcal{C}$ and every $k\\in\\mathbb{N}$, $G^k\\in\\mathcal{C}$. Also\n$\\mathcal{C}$ is strongly closed under powers if for every $k\\in\\mathbb{N}$, if\n$G^k\\in\\mathcal{C}$, then $G^{k+1}\\in\\mathcal{C}$. It is known that circular\narc graphs and proper circular arc graphs are closed under powers. But it is\nopen whether these classes of graphs are also strongly closed under powers. In\nthis paper we have settled these problems.",
    "descriptor": "",
    "authors": [
      "Ashok Kumar Das",
      "Indrajit Paul"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.08782"
  },
  {
    "id": "arXiv:2210.08784",
    "title": "Cross-layer Attention Network for Fine-grained Visual Categorization",
    "abstract": "Learning discriminative representations for subtle localized details plays a\nsignificant role in Fine-grained Visual Categorization (FGVC). Compared to\nprevious attention-based works, our work does not explicitly define or localize\nthe part regions of interest; instead, we leverage the complementary properties\nof different stages of the network, and build a mutual refinement mechanism\nbetween the mid-level feature maps and the top-level feature map by our\nproposed Cross-layer Attention Network (CLAN). Specifically, CLAN is composed\nof 1) the Cross-layer Context Attention (CLCA) module, which enhances the\nglobal context information in the intermediate feature maps with the help of\nthe top-level feature map, thereby improving the expressive power of the middle\nlayers, and 2) the Cross-layer Spatial Attention (CLSA) module, which takes\nadvantage of the local attention in the mid-level feature maps to boost the\nfeature extraction of local regions at the top-level feature maps. Experimental\nresults show our approach achieves state-of-the-art on three publicly available\nfine-grained recognition datasets (CUB-200-2011, Stanford Cars and\nFGVC-Aircraft). Ablation studies and visualizations are provided to understand\nour approach. Experimental results show our approach achieves state-of-the-art\non three publicly available fine-grained recognition datasets (CUB-200-2011,\nStanford Cars and FGVC-Aircraft).",
    "descriptor": "",
    "authors": [
      "Ranran Huang",
      "Yu Wang",
      "Huazhong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08784"
  },
  {
    "id": "arXiv:2210.08786",
    "title": "How \"troll\" are you? Measuring and detecting troll behavior in online  social networks",
    "abstract": "The detection of state-sponsored trolls acting in misinformation operations\nis an unsolved and critical challenge for the research community, with\nrepercussions that go beyond the online realm. In this paper, we propose a\nnovel approach for the detection of troll accounts, which consists of two\nsteps. The first step aims at classifying trajectories of accounts' online\nactivities as belonging to either a troll account or to an organic user\naccount. In the second step, we exploit the classified trajectories to compute\na metric, namely \"troll score\", which allows us to quantify the extent to which\nan account behaves like a troll. Experimental results show that our approach\nidentifies accounts' trajectories with an AUC close to 99% and, accordingly,\nclassify trolls and organic users with an AUC of 97%. Finally, we evaluate\nwhether the proposed solution can be generalized to different contexts (e.g.,\ndiscussions about Covid-19) and generic misbehaving users, showing promising\nresults that will be further expanded in our future endeavors.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Fatima Ezzeddine",
      "Luca Luceri",
      "Omran Ayoub",
      "Ihab Sbeity",
      "Gianluca Nogara",
      "Emilio Ferrara",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08786"
  },
  {
    "id": "arXiv:2210.08788",
    "title": "EISeg: An Efficient Interactive Segmentation Annotation Tool based on  PaddlePaddle",
    "abstract": "In recent years, the rapid development of deep learning has brought great\nadvancements to image and video segmentation methods based on neural networks.\nHowever, to unleash the full potential of such models, large numbers of\nhigh-quality annotated images are necessary for model training. Currently, many\nwidely used open-source image segmentation software relies heavily on manual\nannotation which is tedious and time-consuming. In this work, we introduce\nEISeg, an efficient interactive segmentation annotation tool that can\ndrastically improve image segmentation annotation efficiency, generating highly\naccurate segmentation masks with only a few clicks. We also provide various\ndomain-specific models for remote sensing, medical imaging, industrial quality\ninspections, human segmentation, and temporal aware models for video\nsegmentation. The source code for our algorithm and user interface are\navailable at PaddleSeg: https://github.com/PaddlePaddle/PaddleSeg.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yuying Hao",
      "Yi Liu",
      "Yizhou Chen",
      "Lin Han",
      "Juncai Peng",
      "Shiyu Tang",
      "Guowei Chen",
      "Zewu Wu",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08788"
  },
  {
    "id": "arXiv:2210.08792",
    "title": "Unifying Graph Contrastive Learning with Flexible Contextual Scopes",
    "abstract": "Graph contrastive learning (GCL) has recently emerged as an effective\nlearning paradigm to alleviate the reliance on labelling information for graph\nrepresentation learning. The core of GCL is to maximise the mutual information\nbetween the representation of a node and its contextual representation (i.e.,\nthe corresponding instance with similar semantic information) summarised from\nthe contextual scope (e.g., the whole graph or 1-hop neighbourhood). This\nscheme distils valuable self-supervision signals for GCL training. However,\nexisting GCL methods still suffer from limitations, such as the incapacity or\ninconvenience in choosing a suitable contextual scope for different datasets\nand building biased contrastiveness. To address aforementioned problems, we\npresent a simple self-supervised learning method termed Unifying Graph\nContrastive Learning with Flexible Contextual Scopes (UGCL for short). Our\nalgorithm builds flexible contextual representations with tunable contextual\nscopes by controlling the power of an adjacency matrix. Additionally, our\nmethod ensures contrastiveness is built within connected components to reduce\nthe bias of contextual representations. Based on representations from both\nlocal and contextual scopes, UGCL optimises a very simple contrastive loss\nfunction for graph representation learning. Essentially, the architecture of\nUGCL can be considered as a general framework to unify existing GCL methods. We\nhave conducted intensive experiments and achieved new state-of-the-art\nperformance in six out of eight benchmark datasets compared with\nself-supervised graph representation learning baselines. Our code has been\nopen-sourced.",
    "descriptor": "\nComments: Accepted in ICDM2022\n",
    "authors": [
      "Yizhen Zheng",
      "Yu Zheng",
      "Xiaofei Zhou",
      "Chen Gong",
      "Vincent CS Lee",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08792"
  },
  {
    "id": "arXiv:2210.08793",
    "title": "Rethinking Trajectory Prediction via \"Team Game\"",
    "abstract": "To accurately predict trajectories in multi-agent settings, e.g. team games,\nit is important to effectively model the interactions among agents. Whereas a\nnumber of methods have been developed for this purpose, existing methods\nimplicitly model these interactions as part of the deep net architecture.\nHowever, in the real world, interactions often exist at multiple levels, e.g.\nindividuals may form groups, where interactions among groups and those among\nthe individuals in the same group often follow significantly different\npatterns. In this paper, we present a novel formulation for multi-agent\ntrajectory prediction, which explicitly introduces the concept of interactive\ngroup consensus via an interactive hierarchical latent space. This formulation\nallows group-level and individual-level interactions to be captured jointly,\nthus substantially improving the capability of modeling complex dynamics. On\ntwo multi-agent settings, i.e. team sports and pedestrians, the proposed\nframework consistently achieves superior performance compared to existing\nmethods.",
    "descriptor": "\nComments: Accepted to ECCV2022 WIMF Workshop\n",
    "authors": [
      "Zikai Wei",
      "Xinge Zhu",
      "Bo Dai",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.08793"
  },
  {
    "id": "arXiv:2210.08794",
    "title": "Break The Spell Of Total Correlation In betaTCVAE",
    "abstract": "This paper proposes a way to break the spell of total correlation in\nbetaTCVAE based on the motivation of the total correlation decomposition. An\niterative decomposition path of total correlation is proposed, and an\nexplanation for representation learning ability of VAE from the perspective of\nmodel capacity allocation. Newly developed objective function combines latent\nvariable dimensions into joint distribution while relieving independent\ndistribution constraint of the marginal distribution in combination, leading to\nlatent variables with a more manipulable prior distribution. The novel model\nenables VAE to adjust the parameter capacity to divide dependent and\nindependent data features flexibly. Experimental results on various datasets\nshow an interesting relevance between model capacity and the latent variable\ngrouping size, called the \"V\"-shaped best ELBO trajectory. Additional\nexperiments demonstrate that the proposed method obtains better disentanglement\nperformance with reasonable parameter capacity allocation. Finally, we design\nexperiments to show the limitations of estimating total correlation with mutual\ninformation, identifying its source of estimation deviation.",
    "descriptor": "",
    "authors": [
      "Zihao Chen",
      "Qiang Li",
      "Bing Guo",
      "Yan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08794"
  },
  {
    "id": "arXiv:2210.08798",
    "title": "Cluster Explanation via Polyhedral Descriptions",
    "abstract": "Clustering is an unsupervised learning problem that aims to partition\nunlabelled data points into groups with similar features. Traditional\nclustering algorithms provide limited insight into the groups they find as\ntheir main focus is accuracy and not the interpretability of the group\nassignments. This has spurred a recent line of work on explainable machine\nlearning for clustering. In this paper we focus on the cluster description\nproblem where, given a dataset and its partition into clusters, the task is to\nexplain the clusters. We introduce a new approach to explain clusters by\nconstructing polyhedra around each cluster while minimizing either the\ncomplexity of the resulting polyhedra or the number of features used in the\ndescription. We formulate the cluster description problem as an integer program\nand present a column generation approach to search over an exponential number\nof candidate half-spaces that can be used to build the polyhedra. To deal with\nlarge datasets, we introduce a novel grouping scheme that first forms smaller\ngroups of data points and then builds the polyhedra around the grouped data, a\nstrategy which out-performs simply sub-sampling data. Compared to state of the\nart cluster description algorithms, our approach is able to achieve competitive\ninterpretability with improved description accuracy.",
    "descriptor": "",
    "authors": [
      "Connor Lawless",
      "Oktay Gunluk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08798"
  },
  {
    "id": "arXiv:2210.08801",
    "title": "Sequential Topic Selection Model with Latent Variable for Topic-Grounded  Dialogue",
    "abstract": "Recently, topic-grounded dialogue system has attracted significant attention\ndue to its effectiveness in predicting the next topic to yield better responses\nvia the historical context and given topic sequence. However, almost all\nexisting topic prediction solutions focus on only the current conversation and\ncorresponding topic sequence to predict the next conversation topic, without\nexploiting other topic-guided conversations which may contain relevant\ntopic-transitions to current conversation. To address the problem, in this\npaper we propose a novel approach, named Sequential Global Topic Attention\n(SGTA) to exploit topic transition over all conversations in a subtle way for\nbetter modeling post-to-response topic-transition and guiding the response\ngeneration to the current conversation. Specifically, we introduce a latent\nspace modeled as a Multivariate Skew-Normal distribution with hybrid kernel\nfunctions to flexibly integrate the global-level information with\nsequence-level information, and predict the topic based on the distribution\nsampling results. We also leverage a topic-aware prior-posterior approach for\nsecondary selection of predicted topics, which is utilized to optimize the\nresponse generation task. Extensive experiments demonstrate that our model\noutperforms competitive baselines on prediction and generation tasks.",
    "descriptor": "\nComments: 11 pages, accepted by EMNLP2022 Findings\n",
    "authors": [
      "Xiaofei Wen",
      "Wei Wei",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08801"
  },
  {
    "id": "arXiv:2210.08803",
    "title": "Merlin HugeCTR: GPU-accelerated Recommender System Training and  Inference",
    "abstract": "In this talk, we introduce Merlin HugeCTR. Merlin HugeCTR is an open source,\nGPU-accelerated integration framework for click-through rate estimation. It\noptimizes both training and inference, whilst enabling model training at scale\nwith model-parallel embeddings and data-parallel neural networks. In\nparticular, Merlin HugeCTR combines a high-performance GPU embedding cache with\nan hierarchical storage architecture, to realize low-latency retrieval of\nembeddings for online model inference tasks. In the MLPerf v1.0 DLRM model\ntraining benchmark, Merlin HugeCTR achieves a speedup of up to 24.6x on a\nsingle DGX A100 (8x A100) over PyTorch on 4x4-socket CPU nodes (4x4x28 cores).\nMerlin HugeCTR can also take advantage of multi-node environments to accelerate\ntraining even further. Since late 2021, Merlin HugeCTR additionally features a\nhierarchical parameter server (HPS) and supports deployment via the NVIDIA\nTriton server framework, to leverage the computational capabilities of GPUs for\nhigh-speed recommendation model inference. Using this HPS, Merlin HugeCTR users\ncan achieve a 5~62x speedup (batch size dependent) for popular recommendation\nmodels over CPU baseline implementations, and dramatically reduce their\nend-to-end inference latency.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Joey Wang",
      "Yingcan Wei",
      "Minseok Lee",
      "Matthias Langer",
      "Fan Yu",
      "Jie Liu",
      "Alex Liu",
      "Daniel Abel",
      "Gems Guo",
      "Jianbing Dong",
      "Jerry Shi",
      "Kunlun Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08803"
  },
  {
    "id": "arXiv:2210.08804",
    "title": "A GPU-specialized Inference Parameter Server for Large-Scale Deep  Recommendation Models",
    "abstract": "Recommendation systems are of crucial importance for a variety of modern apps\nand web services, such as news feeds, social networks, e-commerce, search, etc.\nTo achieve peak prediction accuracy, modern recommendation models combine deep\nlearning with terabyte-scale embedding tables to obtain a fine-grained\nrepresentation of the underlying data. Traditional inference serving\narchitectures require deploying the whole model to standalone servers, which is\ninfeasible at such massive scale.\nIn this paper, we provide insights into the intriguing and challenging\ninference domain of online recommendation systems. We propose the HugeCTR\nHierarchical Parameter Server (HPS), an industry-leading distributed\nrecommendation inference framework, that combines a high-performance GPU\nembedding cache with an hierarchical storage architecture, to realize\nlow-latency retrieval of embeddings for online model inference tasks. Among\nother things, HPS features (1) a redundant hierarchical storage system, (2) a\nnovel high-bandwidth cache to accelerate parallel embedding lookup on NVIDIA\nGPUs, (3) online training support and (4) light-weight APIs for easy\nintegration into existing large-scale recommendation workflows. To demonstrate\nits capabilities, we conduct extensive studies using both synthetically\nengineered and public datasets. We show that our HPS can dramatically reduce\nend-to-end inference latency, achieving 5~62x speedup (depending on the batch\nsize) over CPU baseline implementations for popular recommendation models.\nThrough multi-GPU concurrent deployment, the HPS can also greatly increase the\ninference QPS.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yingcan Wei",
      "Matthias Langer",
      "Fan Yu",
      "Minseok Lee",
      "Kingsley Liu",
      "Jerry Shi",
      "Joey Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08804"
  },
  {
    "id": "arXiv:2210.08806",
    "title": "HCL-TAT: A Hybrid Contrastive Learning Method for Few-shot Event  Detection with Task-Adaptive Threshold",
    "abstract": "Conventional event detection models under supervised learning settings suffer\nfrom the inability of transfer to newly-emerged event types owing to lack of\nsufficient annotations. A commonly-adapted solution is to follow a\nidentify-then-classify manner, which first identifies the triggers and then\nconverts the classification task via a few-shot learning paradigm. However,\nthese methods still fall far short of expectations due to: (i) insufficient\nlearning of discriminative representations in low-resource scenarios, and (ii)\ntrigger misidentification caused by the overlap of the learned representations\nof triggers and non-triggers. To address the problems, in this paper, we\npropose a novel Hybrid Contrastive Learning method with a Task-Adaptive\nThreshold (abbreviated as HCLTAT), which enables discriminative representation\nlearning with a two-view contrastive loss (support-support and\nprototype-query), and devises a easily-adapted threshold to alleviate\nmisidentification of triggers. Extensive experiments on the benchmark dataset\nFewEvent demonstrate the superiority of our method to achieve better results\ncompared to the state-of-the-arts. All the code and data of this paper will be\navailable for online public access.",
    "descriptor": "\nComments: This paper has been accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Ruihan Zhang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08806"
  },
  {
    "id": "arXiv:2210.08808",
    "title": "Towards Robust k-Nearest-Neighbor Machine Translation",
    "abstract": "k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research\ndirection of NMT in recent years. Its main idea is to retrieve useful key-value\npairs from an additional datastore to modify translations without updating the\nNMT model. However, the underlying retrieved noisy pairs will dramatically\ndeteriorate the model performance. In this paper, we conduct a preliminary\nstudy and find that this problem results from not fully exploiting the\nprediction of the NMT model. To alleviate the impact of noise, we propose a\nconfidence-enhanced kNN-MT model with robust training. Concretely, we introduce\nthe NMT confidence to refine the modeling of two important components of\nkNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two\ntypes of perturbations into the retrieved pairs for robust training.\nExperimental results on four benchmark datasets demonstrate that our model not\nonly achieves significant improvements over current kNN-MT models, but also\nexhibits better robustness. Our code is available at\nhttps://github.com/DeepLearnXMU/Robust-knn-mt.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Hui Jiang",
      "Ziyao Lu",
      "Fandong Meng",
      "Chulun Zhou",
      "Jie Zhou",
      "Degen Huang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08808"
  },
  {
    "id": "arXiv:2210.08809",
    "title": "Effective and Efficient Query-aware Snippet Extraction for Web Search",
    "abstract": "Query-aware webpage snippet extraction is widely used in search engines to\nhelp users better understand the content of the returned webpages before\nclicking. Although important, it is very rarely studied. In this paper, we\npropose an effective query-aware webpage snippet extraction method named\nDeepQSE, aiming to select a few sentences which can best summarize the webpage\ncontent in the context of input query. DeepQSE first learns query-aware\nsentence representations for each sentence to capture the fine-grained\nrelevance between query and sentence, and then learns document-aware\nquery-sentence relevance representations for snippet extraction. Since the\nquery and each sentence are jointly modeled in DeepQSE, its online inference\nmay be slow. Thus, we further propose an efficient version of DeepQSE, named\nEfficient-DeepQSE, which can significantly improve the inference speed of\nDeepQSE without affecting its performance. The core idea of Efficient-DeepQSE\nis to decompose the query-aware snippet extraction task into two stages, i.e.,\na coarse-grained candidate sentence selection stage where sentence\nrepresentations can be cached, and a fine-grained relevance modeling stage.\nExperiments on two real-world datasets validate the effectiveness and\nefficiency of our methods.",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Jingwei Yi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Xiaolong Huang",
      "Binxing Jiao",
      "Guangzhong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08809"
  },
  {
    "id": "arXiv:2210.08811",
    "title": "CS-MLGCN : Multiplex Graph Convolutional Networks for Community Search  in Multiplex Networks",
    "abstract": "Community Search (CS) is one of the fundamental tasks in network science and\nhas attracted much attention due to its ability to discover personalized\ncommunities with a wide range of applications. Given any query nodes, CS seeks\nto find a densely connected subgraph containing query nodes. Most existing\napproaches usually study networks with a single type of proximity between\nnodes, which defines a single view of a network. However, in many applications\nsuch as biological, social, and transportation networks, interactions between\nobjects span multiple aspects, yielding networks with multiple views, called\nmultiplex networks. Existing CS approaches in multiplex networks adopt\npre-defined subgraph patterns to model the communities, which cannot find\ncommunities that do not have such pre-defined patterns in real-world networks.\nIn this paper, we propose a query-driven graph convolutional network in\nmultiplex networks, CS-MLGCN, that can capture flexible community structures by\nlearning from the ground-truth communities in a data-driven fashion. CS-MLGCN\nfirst combines the local query-dependent structure and global graph embedding\nin each type of proximity and then uses an attention mechanism to incorporate\ninformation on different types of relations. Experiments on real-world graphs\nwith ground-truth communities validate the quality of the solutions we obtain\nand the efficiency of our model.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Ali Behrouz",
      "Farnoosh Hashemi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08811"
  },
  {
    "id": "arXiv:2210.08812",
    "title": "ITSRN++: Stronger and Better Implicit Transformer Network for Continuous  Screen Content Image Super-Resolution",
    "abstract": "Nowadays, online screen sharing and remote cooperation are becoming\nubiquitous. However, the screen content may be downsampled and compressed\nduring transmission, while it may be displayed on large screens or the users\nwould zoom in for detail observation at the receiver side. Therefore,\ndeveloping a strong and effective screen content image (SCI) super-resolution\n(SR) method is demanded. We observe that the weight-sharing upsampler (such as\ndeconvolution or pixel shuffle) could be harmful to sharp and thin edges in\nSCIs, and the fixed scale upsampler makes it inflexible to fit screens with\nvarious sizes. To solve this problem, we propose an implicit transformer\nnetwork for continuous SCI SR (termed as ITSRN++). Specifically, we propose a\nmodulation based transformer as the upsampler, which modulates the pixel\nfeatures in discrete space via a periodic nonlinear function to generate\nfeatures for continuous pixels. To enhance the extracted features, we further\npropose an enhanced transformer as the feature extraction backbone, where\nconvolution and attention branches are utilized parallelly. Besides, we\nconstruct a large scale SCI2K dataset to facilitate the research on SCI SR.\nExperimental results on nine datasets demonstrate that the proposed method\nachieves state-of-the-art performance for SCI SR (outperforming SwinIR by 0.74\ndB for x3 SR) and also works well for natural image SR. Our codes and dataset\nwill be released upon the acceptance of this work.",
    "descriptor": "\nComments: 14pages,10 figures\n",
    "authors": [
      "Sheng Shen",
      "Huanjing Yue",
      "Jingyu Yang",
      "Kun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08812"
  },
  {
    "id": "arXiv:2210.08813",
    "title": "Test-Time Training for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have made tremendous progress in the graph\nclassification task. However, a performance gap between the training set and\nthe test set has often been noticed. To bridge such gap, in this work we\nintroduce the first test-time training framework for GNNs to enhance the model\ngeneralization capacity for the graph classification task. In particular, we\ndesign a novel test-time training strategy with self-supervised learning to\nadjust the GNN model for each test graph sample. Experiments on the benchmark\ndatasets have demonstrated the effectiveness of the proposed framework,\nespecially when there are distribution shifts between training set and test\nset. We have also conducted exploratory studies and theoretical analysis to\ngain deeper understandings on the rationality of the design of the proposed\ngraph test time training framework (GT3).",
    "descriptor": "",
    "authors": [
      "Yiqi Wang",
      "Chaozhuo Li",
      "Wei Jin",
      "Rui Li",
      "Jianan Zhao",
      "Jiliang Tang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08813"
  },
  {
    "id": "arXiv:2210.08817",
    "title": "PACIFIC: Towards Proactive Conversational Question Answering over  Tabular and Textual Data in Finance",
    "abstract": "To facilitate conversational question answering (CQA) over hybrid contexts in\nfinance, we present a new dataset, named PACIFIC. Compared with existing CQA\ndatasets, PACIFIC exhibits three key features: (i) proactivity, (ii) numerical\nreasoning, and (iii) hybrid context of tables and text. A new task is defined\naccordingly to study Proactive Conversational Question Answering (PCQA), which\ncombines clarification question generation and CQA. In addition, we propose a\nnovel method, namely UniPCQA, to adapt a hybrid format of input and output\ncontent in PCQA into the Seq2Seq problem, including the reformulation of the\nnumerical reasoning process as code generation. UniPCQA performs multi-task\nlearning over all sub-tasks in PCQA and incorporates a simple ensemble strategy\nto alleviate the error propagation issue in the multi-task learning by\ncross-validating top-$k$ sampled Seq2Seq outputs. We benchmark the PACIFIC\ndataset with extensive baselines and provide comprehensive evaluations on each\nsub-task of PCQA.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (main conference)\n",
    "authors": [
      "Yang Deng",
      "Wenqiang Lei",
      "Wenxuan Zhang",
      "Wai Lam",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08817"
  },
  {
    "id": "arXiv:2210.08818",
    "title": "The Digital Foundation Platform -- A Multi-layered SOA Architecture for  Intelligent Connected Vehicle Operating System",
    "abstract": "Legacy AD/ADAS development from OEMs centers around developing functions on\nECUs using services provided by AUTOSAR Classic Platform (CP) to meet\nautomotive-grade and mass-production requirements. The AUTOSAR CP couples\nhardware and software components statically and encounters challenges to\nprovide sufficient capacities for the processing of high-level intelligent\ndriving functions, whereas the new platform, AUTOSAR Adaptive Platform (AP) is\ndesigned to support dynamically communication and provide richer services and\nfunction abstractions for those resource-intensive (memory, CPU) applications.\nYet for both platforms, application development and the supporting system\nsoftware are still closely coupled together, and this makes application\ndevelopment and the enhancement less scalable and flexible, resulting in longer\ndevelopment cycles and slower time-to-market. This paper presents a\nmulti-layered, service-oriented intelligent driving operating system foundation\n(we named it as Digital Foundation Platform) that provides abstractions for\neasier adoption of heterogeneous computing hardware. It features a multi-layer\nSOA software architecture with each layer providing adaptive service API at\nnorth-bound for application developers. The proposed Digital Foundation\nPlatform (DFP) has significant advantages of decoupling hardware, operating\nsystem core, middle-ware, functional software and application software\ndevelopment. It provides SOA at multiple layers and enables application\ndevelopers from OEMs, to customize and develop new applications or enhance\nexisting applications with new features, either in autonomous domain or\nintelligent cockpit domain, with great agility, and less code through\nre-usability, and thus reduce the time-to-market.",
    "descriptor": "\nComments: WCX SAE World Congress Experience 2022\n",
    "authors": [
      "David Yu",
      "Andy Xiao"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.08818"
  },
  {
    "id": "arXiv:2210.08819",
    "title": "Correlation between Alignment-Uniformity and Performance of Dense  Contrastive Representations",
    "abstract": "Recently, dense contrastive learning has shown superior performance on dense\nprediction tasks compared to instance-level contrastive learning. Despite its\nsupremacy, the properties of dense contrastive representations have not yet\nbeen carefully studied. Therefore, we analyze the theoretical ideas of dense\ncontrastive learning using a standard CNN and straightforward feature matching\nscheme rather than propose a new complex method. Inspired by the analysis of\nthe properties of instance-level contrastive representations through the lens\nof alignment and uniformity on the hypersphere, we employ and extend the same\nlens for the dense contrastive representations to analyze their underexplored\nproperties. We discover the core principle in constructing a positive pair of\ndense features and empirically proved its validity. Also, we introduces a new\nscalar metric that summarizes the correlation between alignment-and-uniformity\nand downstream performance. Using this metric, we study various facets of\ndensely learned contrastive representations such as how the correlation changes\nover single- and multi-object datasets or linear evaluation and dense\nprediction tasks. The source code is publicly available at:\nhttps://github.com/SuperSupermoon/DenseCL-analysis",
    "descriptor": "\nComments: BMVC22 accepted\n",
    "authors": [
      "Jong Hak Moon",
      "Wonjae Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08819"
  },
  {
    "id": "arXiv:2210.08821",
    "title": "MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph  Completion",
    "abstract": "Multimodal knowledge graph completion (MKGC) aims to predict missing entities\nin MKGs. Previous works usually share relation representation across\nmodalities. This results in mutual interference between modalities during\ntraining, since for a pair of entities, the relation from one modality probably\ncontradicts that from another modality. Furthermore, making a unified\nprediction based on the shared relation representation treats the input in\ndifferent modalities equally, while their importance to the MKGC task should be\ndifferent. In this paper, we propose MoSE, a Modality Split representation\nlearning and Ensemble inference framework for MKGC. Specifically, in the\ntraining phase, we learn modality-split relation embeddings for each modality\ninstead of a single modality-shared one, which alleviates the modality\ninterference. Based on these embeddings, in the inference phase, we first make\nmodality-split predictions and then exploit various ensemble methods to combine\nthe predictions with different weights, which models the modality importance\ndynamically. Experimental results on three KG datasets show that MoSE\noutperforms state-of-the-art MKGC methods. Codes are available at\nhttps://github.com/OreOZhao/MoSE4MKGC.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yu Zhao",
      "Xiangrui Cai",
      "Yike Wu",
      "Haiwei Zhang",
      "Ying Zhang",
      "Guoqing Zhao",
      "Ning Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08821"
  },
  {
    "id": "arXiv:2210.08823",
    "title": "Scaling & Shifting Your Features: A New Baseline for Efficient Model  Tuning",
    "abstract": "Existing fine-tuning methods either tune all parameters of the pre-trained\nmodel (full fine-tuning), which is not efficient, or only tune the last linear\nlayer (linear probing), which suffers a significant accuracy drop compared to\nthe full fine-tuning. In this paper, we propose a new parameter-efficient\nfine-tuning method termed as SSF, representing that researchers only need to\nScale and Shift the deep Features extracted by a pre-trained model to catch up\nwith the performance of full fine-tuning. In this way, SSF also surprisingly\noutperforms other parameter-efficient fine-tuning approaches even with a\nsmaller number of tunable parameters. Furthermore, different from some existing\nparameter-efficient fine-tuning methods (e.g., Adapter or VPT) that introduce\nthe extra parameters and computational cost in the training and inference\nstages, SSF only adds learnable parameters during the training stage, and these\nadditional parameters can be merged into the original pre-trained model weights\nvia re-parameterization in the inference phase. With the proposed SSF, our\nmodel obtains 2.46% (90.72% vs. 88.54%) and 11.48% (73.10% vs. 65.57%)\nperformance improvement on FGVC and VTAB-1k in terms of Top-1 accuracy compared\nto the full fine-tuning but only fine-tuning about 0.3M parameters. We also\nconduct amounts of experiments in various model families (CNNs, Transformers,\nand MLPs) and datasets. Results on 26 image classification datasets in total\nand 3 robustness & out-of-distribution datasets show the effectiveness of SSF.\nCode is available at https://github.com/dongzelian/SSF.",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Dongze Lian",
      "Daquan Zhou",
      "Jiashi Feng",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08823"
  },
  {
    "id": "arXiv:2210.08826",
    "title": "Bootstrapping the Relationship Between Images and Their Clean and Noisy  Labels",
    "abstract": "Many state-of-the-art noisy-label learning methods rely on learning\nmechanisms that estimate the samples' clean labels during training and discard\ntheir original noisy labels. However, this approach prevents the learning of\nthe relationship between images, noisy labels and clean labels, which has been\nshown to be useful when dealing with instance-dependent label noise problems.\nFurthermore, methods that do aim to learn this relationship require cleanly\nannotated subsets of data, as well as distillation or multi-faceted models for\ntraining. In this paper, we propose a new training algorithm that relies on a\nsimple model to learn the relationship between clean and noisy labels without\nthe need for a cleanly labelled subset of data. Our algorithm follows a 3-stage\nprocess, namely: 1) self-supervised pre-training followed by an early-stopping\ntraining of the classifier to confidently predict clean labels for a subset of\nthe training set; 2) use the clean set from stage (1) to bootstrap the\nrelationship between images, noisy labels and clean labels, which we exploit\nfor effective relabelling of the remaining training set using semi-supervised\nlearning; and 3) supervised training of the classifier with all relabelled\nsamples from stage (2). By learning this relationship, we achieve\nstate-of-the-art performance in asymmetric and instance-dependent label noise\nproblems.",
    "descriptor": "",
    "authors": [
      "Brandon Smart",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08826"
  },
  {
    "id": "arXiv:2210.08828",
    "title": "Search-Based Path Planning Algorithm for Autonomous  Parking:Multi-Heuristic Hybrid A*",
    "abstract": "This paper proposed a novel method for autonomous parking. Autonomous parking\nhas received a lot of attention because of its convenience, but due to the\ncomplex environment and the non-holonomic constraints of vehicle, it is\ndifficult to get a collision-free and feasible path in a short time. To solve\nthis problem, this paper introduced a novel algorithm called Multi-Heuristic\nHybrid A* (MHHA*) which incorporates the characteristic of Multi-Heuristic A*\nand Hybrid A*. So it could provide the guarantee for completeness, the\navoidance of local minimum and sub-optimality, and generate a feasible path in\na short time. And this paper also proposed a new collision check method based\non coordinate transformation which could improve the computational efficiency.\nThe performance of the proposed method was compared with Hybrid A* in\nsimulation experiments and its superiority has been proved.",
    "descriptor": "",
    "authors": [
      "Jihao Huang",
      "Zhitao Liu",
      "Xuemin Chi",
      "Feng Hong",
      "Hongye Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08828"
  },
  {
    "id": "arXiv:2210.08829",
    "title": "Intelligent Traffic Steering in Beyond 5G Open RAN based on LSTM Traffic  Prediction",
    "abstract": "Open radio access network (ORAN) Alliance offers a disaggregated RAN\nfunctionality built using open interface specifications between blocks. To\nefficiently support various competing services, \\textit{namely} enhanced mobile\nbroadband (eMBB) and ultra-reliable and low-latency (uRLLC), the ORAN Alliance\nhas introduced a standard approach toward more virtualized, open and\nintelligent networks. To realize benefits of ORAN in optimizing resource\nutilization, this paper studies an intelligent traffic steering (TS) scheme\nwithin the proposed disaggregated ORAN architecture. For this purpose, we\npropose a joint intelligent traffic prediction, flow-split distribution,\ndynamic user association and radio resource management (JIFDR) framework in the\npresence of unknown dynamic traffic demands. To adapt to dynamic environments\non different time scales, we decompose the formulated optimization problem into\ntwo long-term and short-term subproblems, where the optimality of the later is\nstrongly dependent on the optimal dynamic traffic demand. We then apply a\nlong-short-term memory (LSTM) model to effectively solve the long-term\nsubproblem, aiming to predict dynamic traffic demands, RAN slicing, and\nflow-split decisions. The resulting non-convex short-term subproblem is\nconverted to a more computationally tractable form by exploiting successive\nconvex approximations. Finally, simulation results are provided to demonstrate\nthe effectiveness of the proposed algorithms compared to several well-known\nbenchmark schemes.",
    "descriptor": "",
    "authors": [
      "Fatemeh Kavehmadavani",
      "Van-Dinh Nguyen",
      "Thang X. Vu",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08829"
  },
  {
    "id": "arXiv:2210.08830",
    "title": "Disentangling Confidence Score Distribution for Out-of-Domain Intent  Detection with Energy-Based Learning",
    "abstract": "Detecting Out-of-Domain (OOD) or unknown intents from user queries is\nessential in a task-oriented dialog system. Traditional softmax-based\nconfidence scores are susceptible to the overconfidence issue. In this paper,\nwe propose a simple but strong energy-based score function to detect OOD where\nthe energy scores of OOD samples are higher than IND samples. Further, given a\nsmall set of labeled OOD samples, we introduce an energy-based margin objective\nfor supervised OOD detection to explicitly distinguish OOD samples from INDs.\nComprehensive experiments and analysis prove our method helps disentangle\nconfidence score distributions of IND and OOD data.\\footnote{Our code is\navailable at \\url{https://github.com/pris-nlp/EMNLP2022-energy_for_OOD/}.}",
    "descriptor": "\nComments: accepted by the EMNLP2022 SereTOD workshop\n",
    "authors": [
      "Yanan Wu",
      "Zhiyuan Zeng",
      "Keqing He",
      "Yutao Mou",
      "Pei Wang",
      "Yuanmeng Yan",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08830"
  },
  {
    "id": "arXiv:2210.08832",
    "title": "Second-Order Coding Rate of Quasi-Static Rayleigh-Product MIMO Channels",
    "abstract": "With the development of innovative applications that require high reliability\nand low latency, ultra-reliable and low latency communications become critical\nfor wireless networks. In this paper, the second-order coding rate of the\ncoherent quasi-static Rayleigh-product MIMO channel is investigated. We\nconsider the coding rate within O(1/\\sqrt(Mn)) of the capacity, where M and n\ndenote the number of transmit antennas and the blocklength, respectively, and\nderive the closed-form upper and lower bounds for the optimal average error\nprobability. This analysis is achieved by setting up a central limit theorem\n(CLT) for the mutual information density (MID) with the assumption that the\nblock-length, the number of the scatterers, and the number of the antennas go\nto infinity with the same pace. To obtain more physical insights, the high and\nlow SNR approximations for the upper and lower bounds are also given. One\ninteresting observation is that rank-deficiency degrades the performance of\nMIMO systems with FBL and the fundamental limits of the Rayleigh-product\nchannel approaches those of the single Rayleigh case when the number of\nscatterers approaches infinity. Finally, the fitness of the CLT and the gap\nbetween the derived bounds and the performance of practical LDPC coding are\nillustrated by simulations.",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Shenghui Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.08832"
  },
  {
    "id": "arXiv:2210.08834",
    "title": "How to Leverage DNN-based speech enhancement for multi-channel speaker  verification?",
    "abstract": "Speaker verification (SV) suffers from unsatisfactory performance in\nfar-field scenarios due to environmental noise andthe adverse impact of room\nreverberation. This work presents a benchmark of multichannel speech\nenhancement for far-fieldspeaker verification. One approach is a deep neural\nnetwork-based, and the other is a combination of deep neural network andsignal\nprocessing. We integrated a DNN architecture with signal processing techniques\nto carry out various experiments. Ourapproach is compared to the existing\nstate-of-the-art approaches. We examine the importance of enrollment in\npre-processing,which has been largely overlooked in previous studies.\nExperimental evaluation shows that pre-processing can improve the SVperformance\nas long as the enrollment files are processed similarly to the test data and\nthat test and enrollment occur within similarSNR ranges. Considerable\nimprovement is obtained on the generated and all the noise conditions of the\nVOiCES dataset.",
    "descriptor": "",
    "authors": [
      "Sandipana Dowerah",
      "Romain Serizel",
      "Denis Jouvet",
      "Mohammad Mohammadamini",
      "Driss Matrouf"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08834"
  },
  {
    "id": "arXiv:2210.08836",
    "title": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "abstract": "Although online handwriting verification has made great progress recently,\nthe verification performances are still far behind the real usage owing to the\nsmall scale of the datasets as well as the limited biometric mediums.\nTherefore, this paper proposes a new handwriting verification benchmark dataset\nnamed Multimodal Signature and Digit String (MSDS), which consists of two\nsubsets: MSDS-ChS (Chinese Signatures) and MSDS-TDS (Token Digit Strings),\ncontributed by 402 users, with 20 genuine samples and 20 skilled forgeries per\nuser per subset. MSDS-ChS consists of handwritten Chinese signatures, which, to\nthe best of our knowledge, is the largest publicly available Chinese signature\ndataset for handwriting verification, at least eight times larger than existing\nonline datasets. Meanwhile, MSDS-TDS consists of handwritten Token Digit\nStrings, i.e, the actual phone numbers of users, which have not been explored\nyet. Extensive experiments with different baselines are respectively conducted\nfor MSDS-ChS and MSDS-TDS. Surprisingly, verification performances of\nstate-of-the-art methods on MSDS-TDS are generally better than those on\nMSDS-ChS, which indicates that the handwritten Token Digit String could be a\nmore effective biometric than handwritten Chinese signature. This is a\npromising discovery that could inspire us to explore new biometric traits. The\nMSDS dataset is available at https://github.com/HCIILAB/MSDS.",
    "descriptor": "",
    "authors": [
      "Peirong Zhang",
      "Jiajia Jiang",
      "Yuliang Liu",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08836"
  },
  {
    "id": "arXiv:2210.08839",
    "title": "Using Mixed Precision in Low-Synchronization Reorthogonalized Block  Classical Gram-Schmidt",
    "abstract": "Using lower precision in algorithms can be beneficial in terms of reducing\nboth computation and communication costs. Motivated by this, we aim to further\nthe state-of-the-art in developing and analyzing mixed precision variants of\niterative methods. In this work, we focus on the block variant of\nlow-synchronization classical Gram-Schmidt with reorthogonalization, which we\ncall BCGSI+LS. We demonstrate that the loss of orthogonality produced by this\northogonalization scheme can exceed $O(u)\\kappa(\\mathcal{X})$, where $u$ is the\nunit roundoff and $\\kappa(\\mathcal{X})$ is the condition number of the matrix\nto be orthogonalized, and thus we can not in general expect this to result in a\nbackward stable block GMRES implementation. We then develop a mixed precision\nvariant of this algorithm, called BCGSI+LS-MP, which uses higher precision in\ncertain parts of the computation. We demonstrate experimentally that for a\nnumber of challenging test problems, our mixed precision variant successfully\nmaintains a loss of orthogonality below $O(u)\\kappa(\\mathcal{X})$. This\nindicates that we can achieve a backward stable block GMRES algorithm that\nrequires only one synchronization per iteration.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Eda Oktay",
      "Erin Carson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08839"
  },
  {
    "id": "arXiv:2210.08844",
    "title": "Sequential Elimination Voting Games",
    "abstract": "Voting by sequential elimination is a low-communication voting protocol:\nvoters play in sequence and eliminate one or more of the remaining candidates,\nuntil only one remains. While the fairness and efficiency of such protocols\nhave been explored, the impact of strategic behaviour has not been addressed.\nWe model voting by sequential elimination as a game. Given a fixed elimination\nsequence, we show that the outcome is the same in all subgame-perfect Nash\nequilibria of the corresponding game, and is polynomial-time computable. We\nmeasure the loss of social welfare due to strategic behaviour, with respect to\nthe outcome under sincere behaviour, and with respect to the outcome maximizing\nsocial welfare. We give tight bounds for worst-case ratios, and show using\nexperiments that the average impact of manipulation can be much lower than in\nthe worst case.",
    "descriptor": "",
    "authors": [
      "Ulysse Pavloff",
      "Tristan Cazenave",
      "J\u00e9r\u00f4me Lang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.08844"
  },
  {
    "id": "arXiv:2210.08846",
    "title": "Sample Identifying Complexity of Encrypted Control Systems Under Least  Squares Identification",
    "abstract": "A sample identifying complexity has been introduced in the previous study to\ncapture an adversary's estimation error of system identification. The\ncomplexity plays a crucial role in defining the security of encrypted control\nsystems and designing a controller and security parameter for the systems. This\nstudy proposes a novel sample identifying complexity of encrypted control\nsystems under an adversary who identifies system parameters using a least\nsquares method. The proposed complexity is characterized by a controllability\nGramian and ratio of identification input variance to the noise variance. We\nexamine the tightness of the proposed complexity and its changes associated\nwith the Gramian and variance ratio through numerical simulations. The\nsimulation results demonstrate that the proposed complexity captures a behavior\nof estimation error with a sufficient level. Moreover, it confirmed that the\neffect of controllability Gramian in the proposed complexity becomes larger as\nthe variance ratio increases.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Kaoru Teranishi",
      "Kiminao Kogiso"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08846"
  },
  {
    "id": "arXiv:2210.08847",
    "title": "tegdet: An extensible Python Library for Anomaly Detection using  Time-Evolving Graphs",
    "abstract": "This paper presents a new Python library for anomaly detection in\nunsupervised learning approaches. The input for the library is a univariate\ntime series representing observations of a given phenomenon. Then, it can\nidentify anomalous epochs, i.e., time intervals where the observations are\nabove a given percentile of a baseline distribution, defined by a dissimilarity\nmetric. Using time-evolving graphs for the anomaly detection, the library\nleverages valuable information given by the inter-dependencies among data.\nCurrently, the library implements 28 different dissimilarity metrics, and it\nhas been designed to be easily extended with new ones. Through an API, the\nlibrary exposes a complete functionality to carry out the anomaly detection.\nSummarizing, to the best of our knowledge, this library is the only one\npublicly available, that based on dynamic graphs, can be extended with other\nstate-of-the-art anomaly detection techniques. Our experimentation shows\npromising results regarding the execution times of the algorithms and the\naccuracy of the implemented techniques. Additionally, the paper provides\nguidelines for setting the parameters of the detectors to improve their\nperformance and prediction accuracy.",
    "descriptor": "\nComments: 30 pages, 15 figures. A short version of this manuscript has been submitted to SoftwareX journal\n",
    "authors": [
      "Simona Bernardi",
      "Jos\u00e9 Merseguer",
      "Ra\u00fal Javierre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08847"
  },
  {
    "id": "arXiv:2210.08849",
    "title": "Towards Provably Secure Encrypted Control Using Homomorphic Encryption",
    "abstract": "Encrypted control is a promising method for the secure outsourcing of\ncontroller computation to a public cloud. However, a feasible method for\nsecurity proofs of control has not yet been developed in the field of encrypted\ncontrol systems. Additionally, cryptography does not consider certain types of\nattacks on encrypted control systems; therefore, the security of such a system\ncannot be guaranteed using a secure cryptosystem. This study proposes a novel\nsecurity definition for encrypted control under attack for control systems\nusing cryptography. It applies the concept of provable security, which is the\nsecurity of cryptosystems based on mathematical proofs, to encrypted control\nsystems. Furthermore, this study analyzes the relation between the proposed\nsecurity and the conventional security of cryptosystems. The results of the\nanalysis demonstrated that the security of an encrypted control system can be\nenhanced by employing secure homomorphic encryption.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Kaoru Teranishi",
      "Kiminao Kogiso"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08849"
  },
  {
    "id": "arXiv:2210.08854",
    "title": "Inexpensive polynomial-degree- and number-of-hanging-nodes-robust  equilibrated flux a posteriori estimates for isogeometric analysis",
    "abstract": "We consider isogeometric discretizations of the Poisson model problem,\nfocusing on high polynomial degrees and strong hierarchical refinements. We\nderive a posteriori error estimates by equilibrated fluxes, i.e., vector-valued\nmapped piecewise polynomials lying in the $\\boldsymbol{H}({\\rm div})$ space\nwhich appropriately approximate the desired divergence constraint. Our\nestimates are constant-free in the leading term, locally efficient, and robust\nwith respect to the polynomial degree. They are also robust with respect to the\nnumber of hanging nodes arising in adaptive mesh refinement employing\nhierarchical B-splines. Two partitions of unity are designed, one with larger\nsupports corresponding to the mapped splines, and one with small supports\ncorresponding to mapped piecewise affine polynomials. The equilibration is only\nperformed on the small supports, avoiding the higher computational price of\nequilibration on the large supports or even a global system solve. Thus, the\nderived estimates are also as inexpensive as possible. An abstract framework\nfor such a setting is developed, whose application to a specific situation only\nrequests a verification of a few clearly identified assumptions. Numerical\nexperiments illustrate the theoretical developments.",
    "descriptor": "",
    "authors": [
      "Gregor Gantner",
      "Martin Vohral\u00edk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08854"
  },
  {
    "id": "arXiv:2210.08855",
    "title": "PeerDA: Data Augmentation via Modeling Peer Relation for Span  Identification Tasks",
    "abstract": "Span Identification (SpanID) is a family of NLP tasks that aims to detect and\nclassify text spans. Different from previous works that merely leverage\nSubordinate (\\textsc{Sub}) relation about \\textit{if a span is an instance of a\ncertain category} to train SpanID models, we explore Peer (\\textsc{Pr})\nrelation, which indicates that \\textit{the two spans are two different\ninstances from the same category sharing similar features}, and propose a novel\n\\textbf{Peer} \\textbf{D}ata \\textbf{A}ugmentation (PeerDA) approach to treat\nspan-span pairs with the \\textsc{Pr} relation as a kind of augmented training\ndata. PeerDA has two unique advantages: (1) There are a large number of\nspan-span pairs with the \\textsc{Pr} relation for augmenting the training data.\n(2) The augmented data can prevent over-fitting to the superficial\nspan-category mapping by pushing SpanID models to leverage more on spans'\nsemantics. Experimental results on ten datasets over four diverse SpanID tasks\nacross seven domains demonstrate the effectiveness of PeerDA. Notably, seven of\nthem achieve state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Weiwen Xu",
      "Xin Li",
      "Yang Deng",
      "Lidong Bing",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08855"
  },
  {
    "id": "arXiv:2210.08856",
    "title": "TIVE: A Toolbox for Identifying Video Instance Segmentation Errors",
    "abstract": "Since first proposed, Video Instance Segmentation(VIS) task has attracted\nvast researchers' focus on architecture modeling to boost performance. Though\ngreat advances achieved in online and offline paradigms, there are still\ninsufficient means to identify model errors and distinguish discrepancies\nbetween methods, as well approaches that correctly reflect models' performance\nin recognizing object instances of various temporal lengths remain barely\navailable. More importantly, as the fundamental model abilities demanded by the\ntask, spatial segmentation and temporal association are still understudied in\nboth evaluation and interaction mechanisms. In this paper, we introduce TIVE, a\nToolbox for Identifying Video instance segmentation Errors. By directly\noperating output prediction files, TIVE defines isolated error types and\nweights each type's damage to mAP, for the purpose of distinguishing model\ncharacters. By decomposing localization quality in spatial-temporal dimensions,\nmodel's potential drawbacks on spatial segmentation and temporal association\ncan be revealed. TIVE can also report mAP over instance temporal length for\nreal applications. We conduct extensive experiments by the toolbox to further\nillustrate how spatial segmentation and temporal association affect each other.\nWe expect the analysis of TIVE can give the researchers more insights, guiding\nthe community to promote more meaningful explorations for video instance\nsegmentation. The proposed toolbox is available at\nhttps://github.com/wenhe-jia/TIVE.",
    "descriptor": "\nComments: 11pages, 6 figures\n",
    "authors": [
      "Wenhe Jia",
      "Lu Yang",
      "Zilong Jia",
      "Wenyi Zhao",
      "Yilin Zhou",
      "Qing Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08856"
  },
  {
    "id": "arXiv:2210.08857",
    "title": "On the convergence of policy gradient methods to Nash equilibria in  general stochastic games",
    "abstract": "Learning in stochastic games is a notoriously difficult problem because, in\naddition to each other's strategic decisions, the players must also contend\nwith the fact that the game itself evolves over time, possibly in a very\ncomplicated manner. Because of this, the convergence properties of popular\nlearning algorithms - like policy gradient and its variants - are poorly\nunderstood, except in specific classes of games (such as potential or\ntwo-player, zero-sum games). In view of this, we examine the long-run behavior\nof policy gradient methods with respect to Nash equilibrium policies that are\nsecond-order stationary (SOS) in a sense similar to the type of sufficiency\nconditions used in optimization. Our first result is that SOS policies are\nlocally attracting with high probability, and we show that policy gradient\ntrajectories with gradient estimates provided by the REINFORCE algorithm\nachieve an $\\mathcal{O}(1/\\sqrt{n})$ distance-squared convergence rate if the\nmethod's step-size is chosen appropriately. Subsequently, specializing to the\nclass of deterministic Nash policies, we show that this rate can be improved\ndramatically and, in fact, policy gradient methods converge within a finite\nnumber of iterations in that case.",
    "descriptor": "\nComments: 43 pages, 2 tables; to appear in the proceedings of NeurIPS 2022\n",
    "authors": [
      "Angeliki Giannou",
      "Kyriakos Lotidis",
      "Panayotis Mertikopoulos",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08857"
  },
  {
    "id": "arXiv:2210.08859",
    "title": "Social Biases in Automatic Evaluation Metrics for NLG",
    "abstract": "Many studies have revealed that word embeddings, language models, and models\nfor specific downstream tasks in NLP are prone to social biases, especially\ngender bias. Recently these techniques have been gradually applied to automatic\nevaluation metrics for text generation. In the paper, we propose an evaluation\nmethod based on Word Embeddings Association Test (WEAT) and Sentence Embeddings\nAssociation Test (SEAT) to quantify social biases in evaluation metrics and\ndiscover that social biases are also widely present in some model-based\nautomatic evaluation metrics. Moreover, we construct gender-swapped\nmeta-evaluation datasets to explore the potential impact of gender bias in\nimage caption and text summarization tasks. Results show that given\ngender-neutral references in the evaluation, model-based evaluation metrics may\nshow a preference for the male hypothesis, and the performance of them, i.e.\nthe correlation between evaluation metrics and human judgments, usually has\nmore significant variation after gender swapping.",
    "descriptor": "",
    "authors": [
      "Mingqi Gao",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08859"
  },
  {
    "id": "arXiv:2210.08860",
    "title": "Automatic Analysis of Human Body Representations in Western Art",
    "abstract": "The way the human body is depicted in classical and modern paintings is\nrelevant for art historical analyses. Each artist has certain themes and\nconcerns, resulting in different poses being used more heavily than others. In\nthis paper, we propose a computer vision pipeline to analyse human pose and\nrepresentations in paintings, which can be used for specific artists or\nperiods. Specifically, we combine two pose estimation approaches (OpenPose and\nDensePose, respectively) and introduce methods to deal with occlusion and\nperspective issues. For normalisation, we map the detected poses and contours\nto Leonardo da Vinci's Vitruvian Man, the classical depiction of body\nproportions. We propose a visualisation approach for illustrating the\narticulation of joints in a set of paintings. Combined with a hierarchical\nclustering of poses, our approach reveals common and uncommon poses used by\nartists. Our approach improves over purely skeleton based analyses of human\nbody in paintings.",
    "descriptor": "",
    "authors": [
      "Shu Zhao",
      "Alm\u0131la Akda\u011f Salah",
      "Albert Ali Salah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08860"
  },
  {
    "id": "arXiv:2210.08861",
    "title": "A Unitary Transform Based Generalized Approximate Message Passing",
    "abstract": "We consider the problem of recovering an unknown signal ${\\mathbf x}\\in\n{\\mathbb R}^n$ from general nonlinear measurements obtained through a\ngeneralized linear model (GLM), i.e., ${\\mathbf y}= f\\left({\\mathbf A}{\\mathbf\nx}+{\\mathbf w}\\right)$, where $f(\\cdot)$ is a componentwise nonlinear function.\nBased on the unitary transform approximate message passing (UAMP) and\nexpectation propagation, a unitary transform based generalized approximate\nmessage passing (GUAMP) algorithm is proposed for general measurement matrices\n$\\bf{A}$, in particular highly correlated matrices. Experimental results on\nquantized compressed sensing demonstrate that the proposed GUAMP significantly\noutperforms state-of-the-art GAMP and GVAMP under correlated matrices $\\bf{A}$.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Jiang Zhu",
      "Xiangming Meng",
      "Xupeng Lei",
      "Qinghua Guo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08861"
  },
  {
    "id": "arXiv:2210.08863",
    "title": "You Only Live Once: Single-Life Reinforcement Learning",
    "abstract": "Reinforcement learning algorithms are typically designed to learn a\nperformant policy that can repeatedly and autonomously complete a task, usually\nstarting from scratch. However, in many real-world situations, the goal might\nnot be to learn a policy that can do the task repeatedly, but simply to perform\na new task successfully once in a single trial. For example, imagine a disaster\nrelief robot tasked with retrieving an item from a fallen building, where it\ncannot get direct supervision from humans. It must retrieve this object within\none test-time trial, and must do so while tackling unknown obstacles, though it\nmay leverage knowledge it has of the building before the disaster. We formalize\nthis problem setting, which we call single-life reinforcement learning (SLRL),\nwhere an agent must complete a task within a single episode without\ninterventions, utilizing its prior experience while contending with some form\nof novelty. SLRL provides a natural setting to study the challenge of\nautonomously adapting to unfamiliar situations, and we find that algorithms\ndesigned for standard episodic reinforcement learning often struggle to recover\nfrom out-of-distribution states in this setting. Motivated by this observation,\nwe propose an algorithm, $Q$-weighted adversarial learning (QWALE), which\nemploys a distribution matching strategy that leverages the agent's prior\nexperience as guidance in novel situations. Our experiments on several\nsingle-life continuous control problems indicate that methods based on our\ndistribution matching formulation are 20-60% more successful because they can\nmore quickly recover from novel states.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Annie S. Chen",
      "Archit Sharma",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08863"
  },
  {
    "id": "arXiv:2210.08864",
    "title": "Reducing Collision Checking for Sampling-Based Motion Planning Using  Graph Neural Networks",
    "abstract": "Sampling-based motion planning is a popular approach in robotics for finding\npaths in continuous configuration spaces. Checking collision with obstacles is\nthe major computational bottleneck in this process. We propose new\nlearning-based methods for reducing collision checking to accelerate motion\nplanning by training graph neural networks (GNNs) that perform path exploration\nand path smoothing. Given random geometric graphs (RGGs) generated from batch\nsampling, the path exploration component iteratively predicts collision-free\nedges to prioritize their exploration. The path smoothing component then\noptimizes paths obtained from the exploration stage. The methods benefit from\nthe ability of GNNs of capturing geometric patterns from RGGs through batch\nsampling and generalize better to unseen environments. Experimental results\nshow that the learned components can significantly reduce collision checking\nand improve overall planning efficiency in challenging high-dimensional motion\nplanning tasks.",
    "descriptor": "",
    "authors": [
      "Chenning Yu",
      "Sicun Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08864"
  },
  {
    "id": "arXiv:2210.08869",
    "title": "Performance Analysis of Cell-Free Massive MIMO Systems with Asynchronous  Reception",
    "abstract": "Cell-free (CF) massive multiple-input multiple-output (MIMO) is considered as\na promising technology for achieving the ultimate performance limit. However,\ndue to its distributed architecture and low-cost access points (APs), the\nsignals received at user equipments (UEs) are most likely asynchronous. In this\npaper, we investigate the performance of CF massive MIMO systems with\nasynchronous reception, including both effects of delay and oscillator phases.\nTaking into account the imperfect channel state information caused by phase\nasynchronization and pilot contamination, we obtain novel and closed-form\ndownlink spectral efficiency (SE) expressions with coherent and non-coherent\ndata transmission schemes, respectively. Simulation results show that\nasynchronous reception destroys the orthogonality of pilots and coherent\ntransmission of data, and thus results in poor system performance. In addition,\ngetting a highly accurate delay phase is substantial for CF massive MIMO\nsystems to achieve coherent transmission gain. Moreover, the oscillator phase\nof UEs has a larger effect on SE than that of the APs, because the latter can\nbe significantly reduced by increasing the number of antennas.",
    "descriptor": "\nComments: Accepted in IEEE GLOBECOM Workshops 2022\n",
    "authors": [
      "Jiakang Zheng",
      "Zhuoyi Zhao",
      "Jiayi Zhang",
      "Julian Cheng",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.08869"
  },
  {
    "id": "arXiv:2210.08870",
    "title": "Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors",
    "abstract": "Recent studies reveal that deep neural network (DNN) based object detectors\nare vulnerable to adversarial attacks in the form of adding the perturbation to\nthe images, leading to the wrong output of object detectors. Most current\nexisting works focus on generating perturbed images, also called adversarial\nexamples, to fool object detectors. Though the generated adversarial examples\nthemselves can remain a certain naturalness, most of them can still be easily\nobserved by human eyes, which limits their further application in the real\nworld. To alleviate this problem, we propose a differential evolution based\ndual adversarial camouflage (DE_DAC) method, composed of two stages to fool\nhuman eyes and object detectors simultaneously. Specifically, we try to obtain\nthe camouflage texture, which can be rendered over the surface of the object.\nIn the first stage, we optimize the global texture to minimize the discrepancy\nbetween the rendered object and the scene images, making human eyes difficult\nto distinguish. In the second stage, we design three loss functions to optimize\nthe local texture, making object detectors ineffective. In addition, we\nintroduce the differential evolution algorithm to search for the near-optimal\nareas of the object to attack, improving the adversarial performance under\ncertain attack area limitations. Besides, we also study the performance of\nadaptive DE_DAC, which can be adapted to the environment. Experiments show that\nour proposed method could obtain a good trade-off between the fooling human\neyes and object detectors under multiple specific scenes and objects.",
    "descriptor": "",
    "authors": [
      "Jialiang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08870"
  },
  {
    "id": "arXiv:2210.08871",
    "title": "Industry-Scale Orchestrated Federated Learning for Drug Discovery",
    "abstract": "To apply federated learning to drug discovery we developed a novel platform\nin the context of European Innovative Medicines Initiative (IMI) project\nMELLODDY (grant n{\\deg}831472), which was comprised of 10 pharmaceutical\ncompanies, academic research labs, large industrial companies and startups. To\nthe best of our knowledge, The MELLODDY platform was the first industry-scale\nplatform to enable the creation of a global federated model for drug discovery\nwithout sharing the confidential data sets of the individual partners. The\nfederated model was trained on the platform by aggregating the gradients of all\ncontributing partners in a cryptographic, secure way following each training\niteration. The platform was deployed on an Amazon Web Services (AWS)\nmulti-account architecture running Kubernetes clusters in private subnets.\nOrganisationally, the roles of the different partners were codified as\ndifferent rights and permissions on the platform and administrated in a\ndecentralized way. The MELLODDY platform generated new scientific discoveries\nwhich are described in a companion paper.",
    "descriptor": "",
    "authors": [
      "Martijn Oldenhof",
      "Gergely \u00c1cs",
      "Bal\u00e1zs Pej\u00f3",
      "Ansgar Schuffenhauer",
      "Nicholas Holway",
      "No\u00e9 Sturm",
      "Arne Dieckmann",
      "Oliver Fortmeier",
      "Eric Boniface",
      "Cl\u00e9ment Mayer",
      "Arnaud Gohier",
      "Peter Schmidtke",
      "Ritsuya Niwayama",
      "Dieter Kopecky",
      "Lewis Mervin",
      "Prakash Chandra Rathi",
      "Lukas Friedrich",
      "Andr\u00e1s Formanek",
      "Peter Antal",
      "Jordon Rahaman",
      "Adam Zalewski",
      "Ezron Oluoch",
      "Manuel St\u00f6\u00dfel",
      "Michal Van\u010do",
      "David Endico",
      "Fabien Gelus",
      "Tha\u00efs de Boisfoss\u00e9",
      "Adrien Darbier",
      "Ashley Nicollet",
      "Matthieu Blotti\u00e8re",
      "Maria Telenczuk",
      "Van Tien Nguyen",
      "Thibaud Martinez",
      "Camille Boillet",
      "Kelvin Moutet",
      "Alexandre Picosson",
      "Aur\u00e9lien Gasser",
      "Inal Djafar",
      "\u00c1d\u00e1m Arany",
      "Jaak Simm",
      "Yves Moreau",
      "Ola Engkvist",
      "Hugo Ceulemans",
      "Camille Marini",
      "Mathieu Galtier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08871"
  },
  {
    "id": "arXiv:2210.08872",
    "title": "PTDE: Personalized Training with Distillated Execution for Multi-Agent  Reinforcement Learning",
    "abstract": "Centralized Training with Decentralized Execution (CTDE) has been a very\npopular paradigm for multi-agent reinforcement learning. One of its main\nfeatures is making full use of the global information to learn a better joint\n$Q$-function or centralized critic. In this paper, we in turn explore how to\nleverage the global information to directly learn a better individual\n$Q$-function or individual actor. We find that applying the same global\ninformation to all agents indiscriminately is not enough for good performance,\nand thus propose to specify the global information for each agent to obtain\nagent-specific global information for better performance. Furthermore, we\ndistill such agent-specific global information into the agent's local\ninformation, which is used during decentralized execution without too much\nperformance degradation. We call this new paradigm Personalized Training with\nDistillated Execution (PTDE). PTDE can be easily combined with many\nstate-of-the-art algorithms to further improve their performance, which is\nverified in both SMAC and Google Research Football scenarios.",
    "descriptor": "",
    "authors": [
      "Yiqun Chen",
      "Hangyu Mao",
      "Tianle Zhang",
      "Shiguang Wu",
      "Bin Zhang",
      "Jianye Hao",
      "Dong Li",
      "Bin Wang",
      "Hongxing Chang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.08872"
  },
  {
    "id": "arXiv:2210.08873",
    "title": "Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog  Systems",
    "abstract": "Recent advances in neural approaches greatly improve task-oriented dialogue\n(TOD) systems which assist users to accomplish their goals. However, such\nsystems rely on costly manually labeled dialogs which are not available in\npractical scenarios. In this paper, we present our models for Track 2 of the\nSereTOD 2022 challenge, which is the first challenge of building\nsemi-supervised and reinforced TOD systems on a large-scale real-world Chinese\nTOD dataset MobileCS. We build a knowledge-grounded dialog model to formulate\ndialog history and local KB as input and predict the system response. And we\nperform semi-supervised pre-training both on the labeled and unlabeled data.\nOur system achieves the first place both in the automatic evaluation and human\ninteraction, especially with higher BLEU (+7.64) and Success (+13.6\\%) than the\nsecond place.",
    "descriptor": "\nComments: Accepted at the SereTOD 2022 Workshop, EMNLP 2022\n",
    "authors": [
      "Weihao Zeng",
      "Keqing He",
      "Zechen Wang",
      "Dayuan Fu",
      "Guanting Dong",
      "Ruotong Geng",
      "Pei Wang",
      "Jingang Wang",
      "Chaobo Sun",
      "Wei Wu",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08873"
  },
  {
    "id": "arXiv:2210.08874",
    "title": "Probabilities of Causation: Role of Observational Data",
    "abstract": "Probabilities of causation play a crucial role in modern decision-making.\nPearl defined three binary probabilities of causation, the probability of\nnecessity and sufficiency (PNS), the probability of sufficiency (PS), and the\nprobability of necessity (PN). These probabilities were then bounded by Tian\nand Pearl using a combination of experimental and observational data. However,\nobservational data are not always available in practice; in such a case, Tian\nand Pearl's Theorem provided valid but less effective bounds using pure\nexperimental data. In this paper, we discuss the conditions that observational\ndata are worth considering to improve the quality of the bounds. More\nspecifically, we defined the expected improvement of the bounds by assuming the\nobservational distributions are uniformly distributed on their feasible\ninterval. We further applied the proposed theorems to the unit selection\nproblem defined by Li and Pearl.",
    "descriptor": "",
    "authors": [
      "Ang Li",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08874"
  },
  {
    "id": "arXiv:2210.08875",
    "title": "Bridging the Gap between Local Semantic Concepts and Bag of Visual Words  for Natural Scene Image Retrieval",
    "abstract": "This paper addresses the problem of semantic-based image retrieval of natural\nscenes. A typical content-based image retrieval system deals with the query\nimage and images in the dataset as a collection of low-level features and\nretrieves a ranked list of images based on the similarities between features of\nthe query image and features of images in the image dataset. However, top\nranked images in the retrieved list, which have high similarities to the query\nimage, may be different from the query image in terms of the semantic\ninterpretation of the user which is known as the semantic gap. In order to\nreduce the semantic gap, this paper investigates how natural scene retrieval\ncan be performed using the bag of visual word model and the distribution of\nlocal semantic concepts. The paper studies the efficiency of using different\napproaches for representing the semantic information, depicted in natural scene\nimages, for image retrieval. An extensive experimental work has been conducted\nto study the efficiency of using semantic information as well as the bag of\nvisual words model for natural and urban scene image retrieval.",
    "descriptor": "",
    "authors": [
      "Yousef Alqasrawi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08875"
  },
  {
    "id": "arXiv:2210.08877",
    "title": "Data-Driven Short-Term Daily Operational Sea Ice Regional Forecasting",
    "abstract": "Global warming made the Arctic available for marine operations and created\ndemand for reliable operational sea ice forecasts to make them safe. While\nocean-ice numerical models are highly computationally intensive, relatively\nlightweight ML-based methods may be more efficient in this task. Many works\nhave exploited different deep learning models alongside classical approaches\nfor predicting sea ice concentration in the Arctic. However, only a few focus\non daily operational forecasts and consider the real-time availability of data\nthey need for operation. In this work, we aim to close this gap and investigate\nthe performance of the U-Net model trained in two regimes for predicting sea\nice for up to the next 10 days. We show that this deep learning model can\noutperform simple baselines by a significant margin and improve its quality by\nusing additional weather data and training on multiple regions, ensuring its\ngeneralization abilities. As a practical outcome, we build a fast and flexible\ntool that produces operational sea ice forecasts in the Barents Sea, the\nLabrador Sea, and the Laptev Sea regions.",
    "descriptor": "",
    "authors": [
      "Timofey Grigoryev",
      "Polina Verezemskaya",
      "Mikhail Krinitskiy",
      "Nikita Anikin",
      "Alexander Gavrikov",
      "Ilya Trofimov",
      "Nikita Balabin",
      "Aleksei Shpilman",
      "Andrei Eremchenko",
      "Sergey Gulev",
      "Evgeny Burnaev",
      "Vladimir Vanovskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08877"
  },
  {
    "id": "arXiv:2210.08879",
    "title": "Robust Planning for Human-Robot Joint Tasks with Explicit Reasoning on  Human Mental State",
    "abstract": "We consider the human-aware task planning problem where a human-robot team is\ngiven a shared task with a known objective to achieve. Recent approaches tackle\nit by modeling it as a team of independent, rational agents, where the robot\nplans for both agents' (shared) tasks. However, the robot knows that humans\ncannot be administered like artificial agents, so it emulates and predicts the\nhuman's decisions, actions, and reactions. Based on earlier approaches, we\ndescribe a novel approach to solve such problems, which models and uses\nexecution-time observability conventions. Abstractly, this modeling is based on\nsituation assessment, which helps our approach capture the evolution of\nindividual agents' beliefs and anticipate belief divergences that arise in\npractice. It decides if and when belief alignment is needed and achieves it\nwith communication. These changes improve the solver's performance: (a)\ncommunication is effectively used, and (b) robust for more realistic and\nchallenging problems.",
    "descriptor": "\nComments: 10 pages, 2 figures, 1 table, AI-HRI AAAI 2022 Fall Symposium Series\n",
    "authors": [
      "Anthony Favier",
      "Shashank Shekhar",
      "Rachid Alami"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08879"
  },
  {
    "id": "arXiv:2210.08882",
    "title": "A ''New Ara'' for Vector Computing: An Open Source Highly Efficient  RISC-V V 1.0 Vector Processor Design",
    "abstract": "Vector architectures are gaining traction for highly efficient processing of\ndata-parallel workloads, driven by all major ISAs (RISC-V, Arm, Intel), and\nboosted by landmark chips, like the Arm SVE-based Fujitsu A64FX, powering the\nTOP500 leader Fugaku. The RISC-V V extension has recently reached 1.0-Frozen\nstatus. Here, we present its first open-source implementation, discuss the new\nspecification's impact on the micro-architecture of a lane-based design, and\nprovide insights on performance-oriented design of coupled scalar-vector\nprocessors. Our system achieves comparable/better PPA than state-of-the-art\nvector engines that implement older RVV versions: 15% better area, 6% improved\nthroughput, and FPU utilization >98.5% on crucial kernels.",
    "descriptor": "",
    "authors": [
      "Matteo Perotti",
      "Matheus Cavalcante",
      "Nils Wistoff",
      "Renzo Andri",
      "Lukas Cavigelli",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08882"
  },
  {
    "id": "arXiv:2210.08883",
    "title": "Social Media App Usage in Relation with PHQ-9 Depression Scores during  the COVID-19 Pandemic",
    "abstract": "With about 300 million affected people, major depressive disorder (MDD) is\none of the most common diseases worldwide. During the COVID-19 pandemic, the\nnumber of cases increased even further, by 28%. Many factors may be correlated\nwith MDD, including the excessive use of social media apps. In this paper, we\ninvestigated the relationship between the use of social media and communication\napps and depressive symptoms during the COVID-19 pandemic. The pandemic and\nsocial distancing like lockdowns probably changed smartphone usage times and\nusage patterns. While previous studies have shown an association between\ndepression and social media usage, we report about the situation during these\nspecial circumstances.We employed a log-linear regression to examine the\nassociation of social media and communication app usage and depression. To\nquantify the usage, we applied the total usage time in hours of social media\napps (e.g., WhatsApp, Facebook) as well as communication apps (Phone and\nMessaging) within one week. To measure depressive symptoms, we used the PHQ-9\nscore. We discovered a significant association between the usage time and the\nPHQ-9 score (beta=0.0084, p-value=0.010). We conclude that social media usage\nis a robust marker for depression severity and future research should focus on\na better understanding of the underlying causality and potential\ncounter-measures.",
    "descriptor": "\nComments: Accepted for the UbiComp/ISWC 2022 conference\n",
    "authors": [
      "Lena Mulansky",
      "R\u00fcdiger Pryss",
      "Caroline Cohrdes",
      "Harald Baumeister",
      "Felix Beierle"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08883"
  },
  {
    "id": "arXiv:2210.08884",
    "title": "HyperDomainNet: Universal Domain Adaptation for Generative Adversarial  Networks",
    "abstract": "Domain adaptation framework of GANs has achieved great progress in recent\nyears as a main successful approach of training contemporary GANs in the case\nof very limited training data. In this work, we significantly improve this\nframework by proposing an extremely compact parameter space for fine-tuning the\ngenerator. We introduce a novel domain-modulation technique that allows to\noptimize only 6 thousand-dimensional vector instead of 30 million weights of\nStyleGAN2 to adapt to a target domain. We apply this parameterization to the\nstate-of-art domain adaptation methods and show that it has almost the same\nexpressiveness as the full parameter space. Additionally, we propose a new\nregularization loss that considerably enhances the diversity of the fine-tuned\ngenerator. Inspired by the reduction in the size of the optimizing parameter\nspace we consider the problem of multi-domain adaptation of GANs, i.e. setting\nwhen the same model can adapt to several domains depending on the input query.\nWe propose the HyperDomainNet that is a hypernetwork that predicts our\nparameterization given the target domain. We empirically confirm that it can\nsuccessfully learn a number of domains at once and may even generalize to\nunseen domains. Source code can be found at\nhttps://github.com/MACderRu/HyperDomainNet",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Aibek Alanov",
      "Vadim Titov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08884"
  },
  {
    "id": "arXiv:2210.08885",
    "title": "Space, Time, and Interaction: A Taxonomy of Corner Cases in Trajectory  Datasets for Automated Driving",
    "abstract": "Trajectory data analysis is an essential component for highly automated\ndriving. Complex models developed with these data predict other road users'\nmovement and behavior patterns. Based on these predictions - and additional\ncontextual information such as the course of the road, (traffic) rules, and\ninteraction with other road users - the highly automated vehicle (HAV) must be\nable to reliably and safely perform the task assigned to it, e.g., moving from\npoint A to B. Ideally, the HAV moves safely through its environment, just as we\nwould expect a human driver to do. However, if unusual trajectories occur,\nso-called trajectory corner cases, a human driver can usually cope well, but an\nHAV can quickly get into trouble. In the definition of trajectory corner cases,\nwhich we provide in this work, we will consider the relevance of unusual\ntrajectories with respect to the task at hand. Based on this, we will also\npresent a taxonomy of different trajectory corner cases. The categorization of\ncorner cases into the taxonomy will be shown with examples and is done by cause\nand required data sources. To illustrate the complexity between the machine\nlearning (ML) model and the corner case cause, we present a general processing\nchain underlying the taxonomy.",
    "descriptor": "",
    "authors": [
      "Kevin R\u00f6sch",
      "Florian Heidecker",
      "Julian Truetsch",
      "Kamil Kowol",
      "Clemens Schicktanz",
      "Maarten Bieshaar",
      "Bernhard Sick",
      "Christoph Stiller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08885"
  },
  {
    "id": "arXiv:2210.08897",
    "title": "Macaw: The Machine Learning Magnetometer Calibration Workflow",
    "abstract": "In Earth Systems Science, many complex data pipelines combine different data\nsources and apply data filtering and analysis steps. Typically, such data\nanalysis processes are historically grown and implemented with many\nsequentially executed scripts. Scientific workflow management systems (SWMS)\nallow scientists to use their existing scripts and provide support for\nparallelization, reusability, monitoring, or failure handling. However, many\nscientists still rely on their sequentially called scripts and do not profit\nfrom the out-of-the-box advantages a SWMS can provide.\nIn this work, we transform the data analysis processes of a Machine\nLearning-based approach to calibrate the platform magnetometers of\nnon-dedicated satellites utilizing neural networks into a workflow called Macaw\n(MAgnetometer CAlibration Workflow). We provide details on the workflow and the\nsteps needed to port these scripts to a scientific workflow. Our experimental\nevaluation compares the original sequential script executions on the original\nHPC cluster with our workflow implementation on a commodity cluster. Our\nresults show that through porting, our implementation decreased the allocated\nCPU hours by 50.2% and the memory hours by 59.5%, leading to significantly less\nresource wastage. Further, through parallelizing single tasks, we reduced the\nruntime by 17.5%.",
    "descriptor": "\nComments: Paper accepted in 2022 IEEE International Conference on Data Mining Workshops (ICDMW)\n",
    "authors": [
      "Jonathan Bader",
      "Kevin Styp-Rekowski",
      "Leon Doehler",
      "Soeren Becker",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08897"
  },
  {
    "id": "arXiv:2210.08901",
    "title": "Contrastive Language-Image Pre-Training with Knowledge Graphs",
    "abstract": "Recent years have witnessed the fast development of large-scale pre-training\nframeworks that can extract multi-modal representations in a unified form and\nachieve promising performances when transferred to downstream tasks.\nNevertheless, existing approaches mainly focus on pre-training with simple\nimage-text pairs, while neglecting the semantic connections between concepts\nfrom different modalities. In this paper, we propose a knowledge-based\npre-training framework, dubbed Knowledge-CLIP, which injects semantic\ninformation into the widely used CLIP model. Through introducing\nknowledge-based objectives in the pre-training process and utilizing different\ntypes of knowledge graphs as training data, our model can semantically align\nthe representations in vision and language with higher quality, and enhance the\nreasoning ability across scenarios and modalities. Extensive experiments on\nvarious vision-language downstream tasks demonstrate the effectiveness of\nKnowledge-CLIP compared with the original CLIP and competitive baselines.",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Xuran Pan",
      "Tianzhu Ye",
      "Dongchen Han",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08901"
  },
  {
    "id": "arXiv:2210.08902",
    "title": "Beyond Model Interpretability: On the Faithfulness and Adversarial  Robustness of Contrastive Textual Explanations",
    "abstract": "Contrastive explanation methods go beyond transparency and address the\ncontrastive aspect of explanations. Such explanations are emerging as an\nattractive option to provide actionable change to scenarios adversely impacted\nby classifiers' decisions. However, their extension to textual data is\nunder-explored and there is little investigation on their vulnerabilities and\nlimitations.\nThis work motivates textual counterfactuals by laying the ground for a novel\nevaluation scheme inspired by the faithfulness of explanations. Accordingly, we\nextend the computation of three metrics, proximity,connectedness and stability,\nto textual data and we benchmark two successful contrastive methods, POLYJUICE\nand MiCE, on our suggested metrics. Experiments on sentiment analysis data show\nthat the connectedness of counterfactuals to their original counterparts is not\nobvious in both models. More interestingly, the generated contrastive texts are\nmore attainable with POLYJUICE which highlights the significance of latent\nrepresentations in counterfactual search. Finally, we perform the first\nsemantic adversarial attack on textual recourse methods. The results\ndemonstrate the robustness of POLYJUICE and the role that latent input\nrepresentations play in robustness and reliability.",
    "descriptor": "",
    "authors": [
      "Julia El Zini",
      "Mariette Awad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.08902"
  },
  {
    "id": "arXiv:2210.08904",
    "title": "The Role of User Reviews in App Updates: A Preliminary Investigation on  App Release Notes",
    "abstract": "Release planning for mobile apps has recently become an area of active\nresearch. Prior research in this area concentrated on the analysis of release\nnotes and on tracking user reviews to support app evolution with issue\ntrackers. However, little is known about the impact of user reviews on the\nevolution of mobile apps. Our work explores the role of user reviews in app\nupdates based on release notes. For this purpose, we collected user reviews and\nrelease notes of Spotify, the 'number one' app in the 'Music' category in Apple\nApp Store, as the research data. Then, we manually removed non-informative\nparts of each release note, and manually determined the relevance of the app\nreviews with respect to the release notes. We did this by using Word2Vec\ncalculation techniques based on the top 80 app release notes with the highest\nsimilarities. Our empirical results show that more than 60% of the matched\nreviews are actually irrelevant to the corresponding release notes. When\nzooming in at these relevant user reviews, we found that around half of them\nwere posted before the new release and referred to requests, suggestions, and\ncomplaints. Whereas, the other half of the relevant user reviews were posted\nafter updating the apps and concentrated more on bug reports and praise.",
    "descriptor": "\nComments: 6 pages, 2 figures. Chong Wang and Tianyang Liu contribute equally\n",
    "authors": [
      "Chong Wang",
      "Tianyang Liu",
      "Peng Liang",
      "Maya Daneva",
      "Marten van Sinderen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.08904"
  },
  {
    "id": "arXiv:2210.08906",
    "title": "A.I. Robustness: a Human-Centered Perspective on Technological  Challenges and Opportunities",
    "abstract": "Despite the impressive performance of Artificial Intelligence (AI) systems,\ntheir robustness remains elusive and constitutes a key issue that impedes\nlarge-scale adoption. Robustness has been studied in many domains of AI, yet\nwith different interpretations across domains and contexts. In this work, we\nsystematically survey the recent progress to provide a reconciled terminology\nof concepts around AI robustness. We introduce three taxonomies to organize and\ndescribe the literature both from a fundamental and applied point of view: 1)\nrobustness by methods and approaches in different phases of the machine\nlearning pipeline; 2) robustness for specific model architectures, tasks, and\nsystems; and in addition, 3) robustness assessment methodologies and insights,\nparticularly the trade-offs with other trustworthiness properties. Finally, we\nidentify and discuss research gaps and opportunities and give an outlook on the\nfield. We highlight the central role of humans in evaluating and enhancing AI\nrobustness, considering the necessary knowledge humans can provide, and discuss\nthe need for better understanding practices and developing supportive tools in\nthe future.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Andrea Tocchetti",
      "Lorenzo Corti",
      "Agathe Balayn",
      "Mireia Yurrita",
      "Philip Lippmann",
      "Marco Brambilla",
      "Jie Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08906"
  },
  {
    "id": "arXiv:2210.08908",
    "title": "Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval",
    "abstract": "Image-sentence retrieval has attracted extensive research attention in\nmultimedia and computer vision due to its promising application. The key issue\nlies in jointly learning the visual and textual representation to accurately\nestimate their similarity. To this end, the mainstream schema adopts an\nobject-word based attention to calculate their relevance scores and refine\ntheir interactive representations with the attention features, which, however,\nneglects the context of the object representation on the inter-object\nrelationship that matches the predicates in sentences. In this paper, we\npropose a Cross-modal Semantic Enhanced Interaction method, termed CMSEI for\nimage-sentence retrieval, which correlates the intra- and inter-modal semantics\nbetween objects and words. In particular, we first design the intra-modal\nspatial and semantic graphs based reasoning to enhance the semantic\nrepresentations of objects guided by the explicit relationships of the objects'\nspatial positions and their scene graph. Then the visual and textual semantic\nrepresentations are refined jointly via the inter-modal interactive attention\nand the cross-modal alignment. To correlate the context of objects with the\ntextual context, we further refine the visual semantic representation via the\ncross-level object-sentence and word-image based interactive attention.\nExperimental results on seven standard evaluation metrics show that the\nproposed CMSEI outperforms the state-of-the-art and the alternative approaches\non MS-COCO and Flickr30K benchmarks.",
    "descriptor": "\nComments: accepted to WACV 2023\n",
    "authors": [
      "Xuri Ge",
      "Fuhai Chen",
      "Songpei Xu",
      "Fuxiang Tao",
      "Joemon M. Jose"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08908"
  },
  {
    "id": "arXiv:2210.08909",
    "title": "Watch the Neighbors: A Unified K-Nearest Neighbor Contrastive Learning  Framework for OOD Intent Discovery",
    "abstract": "Discovering out-of-domain (OOD) intent is important for developing new skills\nin task-oriented dialogue systems. The key challenges lie in how to transfer\nprior in-domain (IND) knowledge to OOD clustering, as well as jointly learn OOD\nrepresentations and cluster assignments. Previous methods suffer from in-domain\noverfitting problem, and there is a natural gap between representation learning\nand clustering objectives. In this paper, we propose a unified K-nearest\nneighbor contrastive learning framework to discover OOD intents. Specifically,\nfor IND pre-training stage, we propose a KCL objective to learn inter-class\ndiscriminative features, while maintaining intra-class diversity, which\nalleviates the in-domain overfitting problem. For OOD clustering stage, we\npropose a KCC method to form compact clusters by mining true hard negative\nsamples, which bridges the gap between clustering and representation learning.\nExtensive experiments on three benchmark datasets show that our method achieves\nsubstantial improvements over the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted at EMNLP2022 main conference\n",
    "authors": [
      "Yutao Mou",
      "Keqing He",
      "Pei Wang",
      "Yanan Wu",
      "Jingang Wang",
      "Wei Wu",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08909"
  },
  {
    "id": "arXiv:2210.08914",
    "title": "A Category of Surface-Embedded Graphs",
    "abstract": "We introduce a categorical formalism for rewriting surface-embedded graphs.\nSuch graphs can represent string diagrams in a non-symmetric setting where we\nguarantee that the wires do not intersect each other. The main technical\nnovelty is a new formulation of double pushout rewriting on graphs which\nexplicitly records the boundary of the rewrite. Using this boundary structure\nwe can augment these graphs with a rotation system, allowing the surface\ntopology to be incorporated.",
    "descriptor": "\nComments: 22 pages. Presented at Applied Category Theory 2022\n",
    "authors": [
      "Malin Altenm\u00fcller",
      "Ross Duncan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08914"
  },
  {
    "id": "arXiv:2210.08916",
    "title": "A sharp, structure preserving two-velocity model for two-phase flow",
    "abstract": "The numerical modelling of convection dominated high density ratio two-phase\nflow poses several challenges, amongst which is resolving the relatively thin\nshear layer at the interface. To this end we propose a sharp discretisation of\nthe two-velocity model of the two-phase Navier-Stokes equations. This results\nin the ability to model the shear layer, rather than resolving it, by allowing\nfor a velocity discontinuity in the direction(s) tangential to the interface.\nIn a previous paper (Remmerswaal and Veldman (2022), arXiv:2209.14934) we\nhave discussed the transport of mass and momentum, where the two fluids were\nnot yet coupled. In this paper an implicit coupling of the two fluids is\nproposed, which imposes continuity of the velocity field in the interface\nnormal direction. The coupling is included in the pressure Poisson problem, and\nis discretised using a multidimensional generalisation of the ghost fluid\nmethod. Furthermore, a discretisation of the diffusive forces is proposed,\nwhich leads to recovering the continuous one-velocity solution as the interface\nshear layer is resolved.\nThe proposed two-velocity formulation is validated and compared to our\none-velocity formulation, where we consider a multitude of two-phase flow\nproblems. It is demonstrated that the proposed two-velocity model is able to\nconsistently, and sharply, approximate solutions to the inviscid Euler\nequations, where velocity discontinuities appear analytically as well.\nFurthermore, the proposed two-velocity model is shown to accurately model the\ninterface shear layer in viscous problems, and it is successfully applied to\nthe simulation of breaking waves where the model was used to sharply capture\nfree surface instabilities.",
    "descriptor": "",
    "authors": [
      "Ronald A. Remmerswaal",
      "Arthur E.P. Veldman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08916"
  },
  {
    "id": "arXiv:2210.08917",
    "title": "Mars: Semantic-aware Contrastive Learning for End-to-End Task-Oriented  Dialog",
    "abstract": "Traditional end-to-end task-oriented dialog systems first convert dialog\ncontext into dialog state and action state, before generating the system\nresponse. In this paper, we first empirically investigate the relationship\nbetween dialog/action state and generated system response. The empirical\nexploration shows that the system response performance is significantly\naffected by the quality of dialog state and action state. Based on these\nfindings, we argue that enhancing the relationship modeling between dialog\ncontext and dialog/action state is beneficial to improving the quality of the\ndialog state and action state, which further improves the generated response\nquality. Therefore, we propose Mars, an end-to-end task-oriented dialog system\nwith semantic-aware contrastive learning strategies to model the relationship\nbetween dialog context and dialog/action state. Empirical results show our\nproposed Mars achieves state-of-the-art performance on the MultiWOZ 2.0,\nCamRest676, and CrossWOZ.",
    "descriptor": "",
    "authors": [
      "Haipeng Sun",
      "Junwei Bao",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08917"
  },
  {
    "id": "arXiv:2210.08918",
    "title": "A Treatise On FST Lattice Based MMI Training",
    "abstract": "Maximum mutual information (MMI) has become one of the two de facto methods\nfor sequence-level training of speech recognition acoustic models. This paper\naims to isolate, identify and bring forward the implicit modelling decisions\ninduced by the design implementation of standard finite state transducer (FST)\nlattice based MMI training framework. The paper particularly investigates the\nnecessity to maintain a preselected numerator alignment and raises the\nimportance of determinizing FST denominator lattices on the fly. The efficacy\nof employing on the fly FST lattice determinization is mathematically shown to\nguarantee discrimination at the hypothesis level and is empirically shown\nthrough training deep CNN models on a 18K hours Mandarin dataset and on a 2.8K\nhours English dataset. On assistant and dictation tasks, the approach achieves\nbetween 2.3-4.6% relative WER reduction (WERR) over the standard FST lattice\nbased approach.",
    "descriptor": "\nComments: Presented at Sane Worksop 2022 : this https URL\n",
    "authors": [
      "Adnan Haider",
      "Tim Ng",
      "Zhen Huang",
      "Xingyu Na",
      "Antti Veikko Rosti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08918"
  },
  {
    "id": "arXiv:2210.08922",
    "title": "Joint Multilingual Knowledge Graph Completion and Alignment",
    "abstract": "Knowledge graph (KG) alignment and completion are usually treated as two\nindependent tasks. While recent work has leveraged entity and relation\nalignments from multiple KGs, such as alignments between multilingual KGs with\ncommon entities and relations, a deeper understanding of the ways in which\nmultilingual KG completion (MKGC) can aid the creation of multilingual KG\nalignments (MKGA) is still limited. Motivated by the observation that\nstructural inconsistencies -- the main challenge for MKGA models -- can be\nmitigated through KG completion methods, we propose a novel model for jointly\ncompleting and aligning knowledge graphs. The proposed model combines two\ncomponents that jointly accomplish KG completion and alignment. These two\ncomponents employ relation-aware graph neural networks that we propose to\nencode multi-hop neighborhood structures into entity and relation\nrepresentations. Moreover, we also propose (i) a structural inconsistency\nreduction mechanism to incorporate information from the completion into the\nalignment component, and (ii) an alignment seed enlargement and triple\ntransferring mechanism to enlarge alignment seeds and transfer triples during\nKGs alignment. Extensive experiments on a public multilingual benchmark show\nthat our proposed model outperforms existing competitive baselines, obtaining\nnew state-of-the-art results on both MKGC and MKGA tasks.",
    "descriptor": "",
    "authors": [
      "Vinh Tong",
      "Dat Quoc Nguyen",
      "Trung Thanh Huynh",
      "Thanh Tam Nguyen",
      "Nguyen Quoc Viet Hung",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08922"
  },
  {
    "id": "arXiv:2210.08923",
    "title": "RPoA: Redefined Proof of Activity",
    "abstract": "We propose RPoA, a new consensus protocol that builds on top of some of the\nbest features of the previous protocols, such as PoW, PoS, and PoA, and values\nactive service provided by users on the network. While PoA tried to address\nsome of the issues pertinent to PoS and PoW, it still fell short of solving the\nissues regarding high energy consumption, high resources needed, high mining\nlatency, and the requirement for private blockchains. Our approach tries to\naddress all the mentioned issues and falls in the service-based protocols\ncategory that gives mining credit to users as they serve on the network.",
    "descriptor": "\nComments: 11 pages with 1 figure\n",
    "authors": [
      "Sina Kamali",
      "Shayan Shabihi",
      "Taha Fakharian",
      "Alireza Arbabi",
      "Pouriya Tajmehrabi",
      "Mohammad Saadati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08923"
  },
  {
    "id": "arXiv:2210.08927",
    "title": "Event-based Stereo Depth Estimation from Ego-motion using Ray Density  Fusion",
    "abstract": "Event cameras are bio-inspired sensors that mimic the human retina by\nresponding to brightness changes in the scene. They generate asynchronous\nspike-based outputs at microsecond resolution, providing advantages over\ntraditional cameras like high dynamic range, low motion blur and power\nefficiency. Most event-based stereo methods attempt to exploit the high\ntemporal resolution of the camera and the simultaneity of events across cameras\nto establish matches and estimate depth. By contrast, this work investigates\nhow to estimate depth from stereo event cameras without explicit data\nassociation by fusing back-projected ray densities, and demonstrates its\neffectiveness on head-mounted camera data, which is recorded in an egocentric\nfashion. Code and video are available at https://github.com/tub-rip/dvs_mcemvs",
    "descriptor": "\nComments: 6 pages, 3 figures, project page: this https URL\n",
    "authors": [
      "Suman Ghosh",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08927"
  },
  {
    "id": "arXiv:2210.08928",
    "title": "Robust Variable-Speed Variable-Pitch Power Regulation of Tethered-Wing  Systems Based on Gain-Scheduled H-infinity Synthesis",
    "abstract": "This paper deals with the power regulation of tethered-wing systems while\nconsidering the robust performance and the mitigation of dynamic mechanical\nloads and power fluctuations. The strategy is to maximize the energy capture\nduring low-speed wind by controlling the reeling-speed and limiting it during\nhigh-speed wind by adjusting both the tether's force and the speed. The\nH-infinity method is employed to synthesize the output-feedback controllers\nwhile making compromises between the control objectives. The synthesis\nprocedure is based on a linear parameter varying (LPV) system that expresses\nthe flexible longitudinal dynamics of the reeling-mechanism, the tether, and\nthe kite. We carry out various simulations to demonstrate the controllers'\nperformance, including the implementation of the control strategy in a\n3-dimensional tethered-wing system simulator with a realistic turbulent wind\nfield",
    "descriptor": "\nComments: 20 pages, 23 figures\n",
    "authors": [
      "Mani Kakavand",
      "Amin Nikoobin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08928"
  },
  {
    "id": "arXiv:2210.08929",
    "title": "DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers",
    "abstract": "Certified defense using randomized smoothing is a popular technique to\nprovide robustness guarantees for deep neural networks against l2 adversarial\nattacks. Existing works use this technique to provably secure a pretrained\nnon-robust model by training a custom denoiser network on entire training data.\nHowever, access to the training set may be restricted to a handful of data\nsamples due to constraints such as high transmission cost and the proprietary\nnature of the data. Thus, we formulate a novel problem of \"how to certify the\nrobustness of pretrained models using only a few training samples\". We observe\nthat training the custom denoiser directly using the existing techniques on\nlimited samples yields poor certification. To overcome this, our proposed\napproach (DE-CROP) generates class-boundary and interpolated samples\ncorresponding to each training sample, ensuring high diversity in the feature\nspace of the pretrained classifier. We train the denoiser by maximizing the\nsimilarity between the denoised output of the generated sample and the original\ntraining sample in the classifier's logit space. We also perform distribution\nlevel matching using domain discriminator and maximum mean discrepancy that\nyields further benefit. In white box setup, we obtain significant improvements\nover the baseline on multiple benchmark datasets and also report similar\nperformance under the challenging black box setup.",
    "descriptor": "\nComments: WACV 2023. Project page: this https URL\n",
    "authors": [
      "Gaurav Kumar Nayak",
      "Ruchit Rawal",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08929"
  },
  {
    "id": "arXiv:2210.08933",
    "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
    "abstract": "Recently, diffusion models have emerged as a new paradigm for generative\nmodels. Despite the success in domains using continuous signals such as vision\nand audio, adapting diffusion models to natural language is difficult due to\nthe discrete nature of text. We tackle this challenge by proposing DiffuSeq: a\ndiffusion model designed for sequence-to-sequence (Seq2Seq) text generation\ntasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we find\nDiffuSeq achieving comparable or even better performance than six established\nbaselines, including a state-of-the-art model that is based on pre-trained\nlanguage models. Apart from quality, an intriguing property of DiffuSeq is its\nhigh diversity during generation, which is desired in many Seq2Seq tasks. We\nfurther include a theoretical analysis revealing the connection between\nDiffuSeq and autoregressive/non-autoregressive models. Bringing together\ntheoretical analysis and empirical evidence, we demonstrate the great potential\nof diffusion models in complex conditional language generation tasks.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Shansan Gong",
      "Mukai Li",
      "Jiangtao Feng",
      "Zhiyong Wu",
      "LingPeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08933"
  },
  {
    "id": "arXiv:2210.08934",
    "title": "RIO: Order-Preserving and CPU-Efficient Remote Storage Access",
    "abstract": "Modern NVMe SSDs and RDMA networks provide dramatically higher bandwidth and\nconcurrency. Existing networked storage systems (e.g., NVMe over Fabrics) fail\nto fully exploit these new devices due to inefficient storage ordering\nguarantees. Severe synchronous execution for storage order in these systems\nstalls the CPU and I/O devices and lowers the CPU and I/O performance\nefficiency of the storage system.\nWe present Rio, a new approach to the storage order of remote storage access.\nThe key insight in Rio is that the layered design of the software stack, along\nwith the concurrent and asynchronous network and storage devices, makes the\nstorage stack conceptually similar to the CPU pipeline. Inspired by the CPU\npipeline that executes out-of-order and commits in-order, Rio introduces the\nI/O pipeline that allows internal out-of-order and asynchronous execution for\nordered write requests while offering intact external storage order to\napplications. Together with merging consecutive ordered requests, these design\ndecisions make for write throughput and CPU efficiency close to that of\norderless requests.\nWe implement Rio in Linux NVMe over RDMA stack, and further build a file\nsystem named RioFS atop Rio. Evaluations show that Rio outperforms Linux NVMe\nover RDMA and a state-of-the-art storage stack named Horae by two orders of\nmagnitude and 4.9 times on average in terms of throughput of ordered write\nrequests, respectively. RioFS increases the throughput of RocksDB by 1.9 times\nand 1.5 times on average, against Ext4 and HoraeFS, respectively.",
    "descriptor": "",
    "authors": [
      "Xiaojian Liao",
      "Zhe Yang",
      "Jiwu Shu"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2210.08934"
  },
  {
    "id": "arXiv:2210.08936",
    "title": "S$^3$-NeRF: Neural Reflectance Field from Shading and Shadow under a  Single Viewpoint",
    "abstract": "In this paper, we address the \"dual problem\" of multi-view scene\nreconstruction in which we utilize single-view images captured under different\npoint lights to learn a neural scene representation. Different from existing\nsingle-view methods which can only recover a 2.5D scene representation (i.e., a\nnormal / depth map for the visible surface), our method learns a neural\nreflectance field to represent the 3D geometry and BRDFs of a scene. Instead of\nrelying on multi-view photo-consistency, our method exploits two\ninformation-rich monocular cues, namely shading and shadow, to infer scene\ngeometry. Experiments on multiple challenging datasets show that our method is\ncapable of recovering 3D geometry, including both visible and invisible parts,\nof a scene from single-view images. Thanks to the neural reflectance field\nrepresentation, our method is robust to depth discontinuities. It supports\napplications like novel-view synthesis and relighting. Our code and model can\nbe found at https://ywq.github.io/s3nerf.",
    "descriptor": "\nComments: NeurIPS 2022, Project page: this https URL\n",
    "authors": [
      "Wenqi Yang",
      "Guanying Chen",
      "Chaofeng Chen",
      "Zhenfang Chen",
      "Kwan-Yee K. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08936"
  },
  {
    "id": "arXiv:2210.08940",
    "title": "Configured Grant for Ultra-Reliable and Low-Latency Communications:  Standardization and Beyond",
    "abstract": "Uplink configured Grant allocation has been introduced in 3rd Generation\nPartnership Project New Radio Release 15. This is beneficial in supporting\nUltra-Reliable and Low Latency Communication for industrial communication, a\nkey Fifth Generation mobile communication usage scenario. This scheduling\nmechanism enables a user with periodic traffic to transmits its data readily\nand bypasses the control signaling entailed to scheduling requests and\nscheduling grants and provides low latency access. To facilitate ultra-reliable\ncommunication, the scheduling mechanism can allow users to transmit consecutive\nredundant transmissions in a pre-defined period. However, if the traffic is\nsemi-deterministic, the current standardized configured grant allocation is not\nequipped to emulate the traffic as the configured grant's period is\npre-configured and fixed. This article describes the recent advancements in the\nstandardization process in Release 15 and 16 for configured grant allocation\nand the prospective solutions to accommodate semi-deterministic traffic\nbehavior for configured grant allocations.",
    "descriptor": "\nComments: Accepted in IEEE Communications Standard Magazine 2021, 5 figures\n",
    "authors": [
      "Majid Gerami",
      "Bikramjit Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.08940"
  },
  {
    "id": "arXiv:2210.08942",
    "title": "Meta-Learning via Classifier(-free) Guidance",
    "abstract": "State-of-the-art meta-learning techniques do not optimize for zero-shot\nadaptation to unseen tasks, a setting in which humans excel. On the contrary,\nmeta-learning algorithms learn hyperparameters and weight initializations that\nexplicitly optimize for few-shot learning performance. In this work, we take\ninspiration from recent advances in generative modeling and\nlanguage-conditioned image synthesis to propose meta-learning techniques that\nuse natural language guidance to achieve higher zero-shot performance compared\nto the state-of-the-art. We do so by recasting the meta-learning problem as a\nmulti-modal generative modeling problem: given a task, we consider its adapted\nneural network weights and its natural language description as equivalent\nmulti-modal task representations. We first train an unconditional generative\nhypernetwork model to produce neural network weights; then we train a second\n\"guidance\" model that, given a natural language task description, traverses the\nhypernetwork latent space to find high-performance task-adapted weights in a\nzero-shot manner. We explore two alternative approaches for latent space\nguidance: \"HyperCLIP\"-based classifier guidance and a conditional Hypernetwork\nLatent Diffusion Model (\"HyperLDM\"), which we show to benefit from the\nclassifier-free guidance technique common in image generation. Finally, we\ndemonstrate that our approaches outperform existing meta-learning methods with\nzero-shot learning experiments on our Meta-VQA dataset, which we specifically\nconstructed to reflect the multi-modal meta-learning setting.",
    "descriptor": "",
    "authors": [
      "Elvis Nava",
      "Seijin Kobayashi",
      "Yifei Yin",
      "Robert K. Katzschmann",
      "Benjamin F. Grewe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08942"
  },
  {
    "id": "arXiv:2210.08951",
    "title": "Approximating Continuous Convolutions for Deep Network Compression",
    "abstract": "We present ApproxConv, a novel method for compressing the layers of a\nconvolutional neural network. Reframing conventional discrete convolution as\ncontinuous convolution of parametrised functions over space, we use functional\napproximations to capture the essential structures of CNN filters with fewer\nparameters than conventional operations. Our method is able to reduce the size\nof trained CNN layers requiring only a small amount of fine-tuning. We show\nthat our method is able to compress existing deep network models by half whilst\nlosing only 1.86% accuracy. Further, we demonstrate that our method is\ncompatible with other compression methods like quantisation allowing for\nfurther reductions in model size.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Theo W. Costain",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08951"
  },
  {
    "id": "arXiv:2210.08952",
    "title": "Predicting Dense and Context-aware Cost Maps for Semantic Robot  Navigation",
    "abstract": "We investigate the task of object goal navigation in unknown environments\nwhere the target is specified by a semantic label (e.g. find a couch). Such a\nnavigation task is especially challenging as it requires understanding of\nsemantic context in diverse settings. Most of the prior work tackles this\nproblem under the assumption of a discrete action policy whereas we present an\napproach with continuous control which brings it closer to real world\napplications. We propose a deep neural network architecture and loss function\nto predict dense cost maps that implicitly contain semantic context and guide\nthe robot towards the semantic goal. We also present a novel way of fusing\nmid-level visual representations in our architecture to provide additional\nsemantic cues for cost map prediction. The estimated cost maps are then used by\na sampling-based model predictive controller (MPC) for generating continuous\nrobot actions. The preliminary experiments suggest that the cost maps generated\nby our network are suitable for the MPC and can guide the agent to the semantic\ngoal more efficiently than a baseline approach. The results also indicate the\nimportance of mid-level representations for navigation by improving the success\nrate by 7 percentage points.",
    "descriptor": "\nComments: Accepted at IROS PNARUDE(Perception and Navigation for Autonomous Robotics in Unstructured and Dynamic Environments) Workshop 2022\n",
    "authors": [
      "Yash Goel",
      "Narunas Vaskevicius",
      "Luigi Palmieri",
      "Nived Chebrolu",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08952"
  },
  {
    "id": "arXiv:2210.08954",
    "title": "Conversion of Legal Agreements into Smart Legal Contracts using NLP",
    "abstract": "A Smart Legal Contract (SLC) is a specialized digital agreement that consists\nof natural language and computable components. The Accord Project is an\nopen-source SLC framework containing three main modules: Cicero, Concerto, and\nErgo. Currently, we need lawyers, programmers, and clients to work together\nwith a great deal of effort to create a useable SLC using the Accord Project.\nThis paper proposes a pipeline to automate the SLC creation process with\nseveral NLP models to convert law contracts to the Accord Project's SLC format.\nWe then further describe an interface enabling users to build their SLC with\nthe proposed pipeline.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Eason Chen",
      "Niall Roche",
      "Yuen-Hsien Tseng",
      "Walter Hernandez",
      "Jiangbo Shangguan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08954"
  },
  {
    "id": "arXiv:2210.08956",
    "title": "A Novel Membership Inference Attack against Dynamic Neural Networks by  Utilizing Policy Networks Information",
    "abstract": "Unlike traditional static deep neural networks (DNNs), dynamic neural\nnetworks (NNs) adjust their structures or parameters to different inputs to\nguarantee accuracy and computational efficiency. Meanwhile, it has been an\nemerging research area in deep learning recently. Although traditional static\nDNNs are vulnerable to the membership inference attack (MIA) , which aims to\ninfer whether a particular point was used to train the model, little is known\nabout how such an attack performs on the dynamic NNs. In this paper, we propose\na novel MI attack against dynamic NNs, leveraging the unique policy networks\nmechanism of dynamic NNs to increase the effectiveness of membership inference.\nWe conducted extensive experiments using two dynamic NNs, i.e., GaterNet,\nBlockDrop, on four mainstream image classification tasks, i.e., CIFAR-10,\nCIFAR-100, STL-10, and GTSRB. The evaluation results demonstrate that the\ncontrol-flow information can significantly promote the MIA. Based on\nbackbone-finetuning and information-fusion, our method achieves better results\nthan baseline attack and traditional attack using intermediate information.",
    "descriptor": "",
    "authors": [
      "Pan Li",
      "Peizhuo Lv",
      "Shenchen Zhu",
      "Ruigang Liang",
      "Kai Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08956"
  },
  {
    "id": "arXiv:2210.08957",
    "title": "Weakly Supervised Face Naming with Symmetry-Enhanced Contrastive Loss",
    "abstract": "We revisit the weakly supervised cross-modal face-name alignment task; that\nis, given an image and a caption, we label the faces in the image with the\nnames occurring in the caption. Whereas past approaches have learned the latent\nalignment between names and faces by uncertainty reasoning over a set of images\nand their respective captions, in this paper, we rely on appropriate loss\nfunctions to learn the alignments in a neural network setting and propose SECLA\nand SECLA-B. SECLA is a Symmetry-Enhanced Contrastive Learning-based Alignment\nmodel that can effectively maximize the similarity scores between corresponding\nfaces and names in a weakly supervised fashion. A variation of the model,\nSECLA-B, learns to align names and faces as humans do, that is, learning from\neasy to hard cases to further increase the performance of SECLA. More\nspecifically, SECLA-B applies a two-stage learning framework: (1) Training the\nmodel on an easy subset with a few names and faces in each image-caption pair.\n(2) Leveraging the known pairs of names and faces from the easy cases using a\nbootstrapping strategy with additional loss to prevent forgetting and learning\nnew alignments at the same time. We achieve state-of-the-art results for both\nthe augmented Labeled Faces in the Wild dataset and the Celebrity Together\ndataset. In addition, we believe that our methods can be adapted to other\nmultimodal news understanding tasks.",
    "descriptor": "\nComments: Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Tingyu Qu",
      "Tinne Tuytelaars",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08957"
  },
  {
    "id": "arXiv:2210.08958",
    "title": "Chat Control or Child Protection?",
    "abstract": "Ian Levy and Crispin Robinson's position paper \"Thoughts on child safety on\ncommodity platforms\" is to be welcomed for extending the scope of the debate\nabout the extent to which child safety concerns justify legal limits to online\nprivacy. Their paper's context is the laws proposed in both the UK and the EU\nto give the authorities the power to undermine end-to-end cryptography in\nonline communications services, with a justification of preventing and\ndetecting of child abuse and terrorist recruitment. Both jurisdictions plan to\nmake it easier to get service firms to take down a range of illegal material\nfrom their servers; but they also propose to mandate client-side scanning - not\njust for known illegal images, but for text messages indicative of sexual\ngrooming or terrorist recruitment. In this initial response, I raise technical\nissues about the capabilities of the technologies the authorities propose to\nmandate, and a deeper strategic issue: that we should view the child safety\ndebate from the perspective of children at risk of violence, rather than from\nthat of the security and intelligence agencies and the firms that sell\nsurveillance software. The debate on terrorism similarly needs to be grounded\nin the context in which young people are radicalised. Both political violence\nand violence against children tend to be politicised and as a result are often\npoorly policed. Effective policing, particularly of crimes embedded in wicked\nsocial problems, must be locally led and involve multiple stakeholders; the\nidea of using 'artificial intelligence' to replace police officers, social\nworkers and teachers is just the sort of magical thinking that leads to bad\npolicy. The debate must also be conducted within the boundary conditions set by\nhuman rights and privacy law, and to be pragmatic must also consider reasonable\npolice priorities.",
    "descriptor": "",
    "authors": [
      "Ross Anderson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08958"
  },
  {
    "id": "arXiv:2210.08959",
    "title": "Flipped Classroom: Effective Teaching for Time Series Forecasting",
    "abstract": "Sequence-to-sequence models based on LSTM and GRU are a most popular choice\nfor forecasting time series data reaching state-of-the-art performance.\nTraining such models can be delicate though. The two most common training\nstrategies within this context are teacher forcing (TF) and free running (FR).\nTF can be used to help the model to converge faster but may provoke an exposure\nbias issue due to a discrepancy between training and inference phase. FR helps\nto avoid this but does not necessarily lead to better results, since it tends\nto make the training slow and unstable instead. Scheduled sampling was the\nfirst approach tackling these issues by picking the best from both worlds and\ncombining it into a curriculum learning (CL) strategy. Although scheduled\nsampling seems to be a convincing alternative to FR and TF, we found that, even\nif parametrized carefully, scheduled sampling may lead to premature termination\nof the training when applied for time series forecasting. To mitigate the\nproblems of the above approaches we formalize CL strategies along the training\nas well as the training iteration scale. We propose several new curricula, and\nsystematically evaluate their performance in two experimental sets. For our\nexperiments, we utilize six datasets generated from prominent chaotic systems.\nWe found that the newly proposed increasing training scale curricula with a\nprobabilistic iteration scale curriculum consistently outperforms previous\ntraining strategies yielding an NRMSE improvement of up to 81% over FR or TF\ntraining. For some datasets we additionally observe a reduced number of\ntraining iterations. We observed that all models trained with the new curricula\nyield higher prediction stability allowing for longer prediction horizons.",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (10/2022)\n",
    "authors": [
      "Philipp Teutsch",
      "Patrick M\u00e4der"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08959"
  },
  {
    "id": "arXiv:2210.08960",
    "title": "Deceptive AI Systems That Give Explanations Are Just as Convincing as  Honest AI Systems in Human-Machine Decision Making",
    "abstract": "The ability to discern between true and false information is essential to\nmaking sound decisions. However, with the recent increase in AI-based\ndisinformation campaigns, it has become critical to understand the influence of\ndeceptive systems on human information processing. In experiment (N=128), we\ninvestigated how susceptible people are to deceptive AI systems by examining\nhow their ability to discern true news from fake news varies when AI systems\nare perceived as either human fact-checkers or AI fact-checking systems, and\nwhen explanations provided by those fact-checkers are either deceptive or\nhonest. We find that deceitful explanations significantly reduce accuracy,\nindicating that people are just as likely to believe deceptive AI explanations\nas honest AI explanations. Although before getting assistance from an\nAI-system, people have significantly higher weighted discernment accuracy on\nfalse headlines than true headlines, we found that with assistance from an AI\nsystem, discernment accuracy increased significantly when given honest\nexplanations on both true headlines and false headlines, and decreased\nsignificantly when given deceitful explanations on true headlines and false\nheadlines. Further, we did not observe any significant differences in\ndiscernment between explanations perceived as coming from a human fact checker\ncompared to an AI-fact checker. Similarly, we found no significant differences\nin trust. These findings exemplify the dangers of deceptive AI systems and the\nneed for finding novel ways to limit their influence human information\nprocessing.",
    "descriptor": "",
    "authors": [
      "Valdemar Danry",
      "Pat Pataranutaporn",
      "Ziv Epstein",
      "Matthew Groh",
      "Pattie Maes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08960"
  },
  {
    "id": "arXiv:2210.08961",
    "title": "Determinants Influencing Intention to Use Social Commerce for Shopping  in developing countries: A Case Study of Oman",
    "abstract": "Social media has had a significant impact on our individual lives, including\nour behavior regarding the purchasing of daily products. This study\ninvestigates the factors influencing Omani nationals' intentions to obtain\nproducts via social commerce. The researcher surveyed 202 participants and\nutilized the Technology Acceptance Model to develop the theoretical framework.\nThe data collection was analyzed statistically using an appropriate testing\nmechanism. Statistical methods, including Cronbach's alpha and multiple linear\nregression, were utilized for reliability and hypotheses testing. After\nanalyzing the collected data and testing the hypotheses, the findings indicated\nthat perceived usefulness, enjoyment, and ease of use of social commerce affect\npositively on Omani nationals' intentions to utilize social commerce for\nshopping. The independent variables had a statistically significant impact on\nthe intention to use social commerce shopping for products; these explain 69.9%\nof the variation on customers intention to utilize social commerce for\nshopping.",
    "descriptor": "\nComments: 17 Pages\n",
    "authors": [
      "Shamma Al Harizi",
      "Maryam Al Areimi",
      "Abdul. Khalique Shaikh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08961"
  },
  {
    "id": "arXiv:2210.08962",
    "title": "Artificial Intelligence and Innovation to Reduce the Impact of Extreme  Weather Events on Sustainable Production",
    "abstract": "Frequent occurrences of extreme weather events substantially impact the lives\nof the less privileged in our societies, particularly in agriculture-inclined\neconomies. The unpredictability of extreme fires, floods, drought, cyclones,\nand others endangers sustainable production and life on land (SDG goal 15),\nwhich translates into food insecurity and poorer populations. Fortunately,\nmodern technologies such as Artificial Intelligent (AI), the Internet of Things\n(IoT), blockchain, 3D printing, and virtual and augmented reality (VR and AR)\nare promising to reduce the risk and impact of extreme weather in our\nsocieties. However, research directions on how these technologies could help\nreduce the impact of extreme weather are unclear. This makes it challenging to\nemploring digital technologies within the spheres of extreme weather. In this\npaper, we employed the Delphi Best Worst method and Machine learning approaches\nto identify and assess the push factors of technology. The BWM evaluation\nrevealed that predictive nature was AI's most important criterion and role,\nwhile the mass-market potential was the less important criterion. Based on this\noutcome, we tested the predictive ability of machine elarning on a publilcly\navailable dataset to affrm the predictive rols of AI. We presented the\nmanagerial and methodological implications of the study, which are crucial for\nresearch and practice. The methodology utilized in this study could aid\ndecision-makers in devising strategies and interventions to safeguard\nsustainable production. This will also facilitate allocating scarce resources\nand investment in improving AI techniques to reduce the adverse impacts of\nextreme events. Correspondingly, we put forward the limitations of this, which\nnecessitate future research.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Derrick Effah",
      "Chunguang Bai",
      "Matthew Quayson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08962"
  },
  {
    "id": "arXiv:2210.08963",
    "title": "A Framework for Operations Research Model Use in Resilience to  Fundamental Surprise Events: Observations from University Operations during  COVID-19",
    "abstract": "Operations research (OR) approaches have been increasingly applied to model\nthe resilience of a system to surprise events. In order to model a surprise\nevent, one must have an understanding of its characteristics, which then become\nparameters, decisions, and/or constraints in the resulting model. This means\nthat these models cannot (directly) handle fundamental surprise events, which\nare events that could not be defined before they happen. However, OR models may\nbe adapted, improvised, or created during a fundamental surprise event, such as\nthe COVID-19 pandemic, to help respond to it. We provide a framework for how OR\nmodels were applied by a university in response to the pandemic, thus helping\nto understand the role of OR models during fundamental surprise events. Our\nframework includes the following adaptations: adapting data, adding\nconstraints, model switching, pulling from the modeling toolkit, and creating a\nnew model. Each of these adaptations is formally presented, with supporting\nevidence gathered through interviews with modelers and users involved in the\nuniversity response to the pandemic. We discuss the implications of this\nframework for both OR and resilience.",
    "descriptor": "",
    "authors": [
      "Thomas C. Sharkey",
      "Steven Foster",
      "Sudeep Hegde",
      "Mary E. Kurz",
      "Emily L. Tucker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08963"
  },
  {
    "id": "arXiv:2210.08965",
    "title": "Calling for a feminist revolt to decolonise data and algorithms in the  age of Datification",
    "abstract": "Feminist and women groups, indigenous communities and scholars in the global\nsouth/north refusing to adhere to hegemonic datafication programs have started\nto organise and fight back from the inside. The first essential step is to show\nand problematise technological progress exhibiting the poverty, violence,\nexclusion, and cultural erase promoted by this \"progress\". The second step is\nto promote technology, algorithmic and artificial literacy. Education is\ncritical to learn how to revert and revoke the datified digital twin already\ncolonising all Earth's societies silently and with impunity. It is not the\ncolonisation of body-territories; it goes beyond and occupies humanity's mind's\nessence, i.e., imagination and imaginary. Against the colonisation of the\nimaginary, militant groups are imagining and designing alternative algorithms,\ndatasets collection strategies and appropriation methods. The paper discusses\ntheir actions and alternative thinking.",
    "descriptor": "",
    "authors": [
      "Genoveva Vargas-Solar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.08965"
  },
  {
    "id": "arXiv:2210.08966",
    "title": "Design and implementation of a scalable authentic-research education  program for Artificial Intelligence and Science",
    "abstract": "We report a program designed to bring authentic research experience to\nmachine learning and science students at scale. Our design addresses common\nbarriers to such efforts and should allow students and faculty from other\nuniversities to implement similar programs with ease. With support from a\nfaculty member, students form a group. The group contains several teams working\non independent projects in a consulting type of arrangement with research labs\nin natural sciences. Each team comprises students with complementary skills (in\nAI, science, and leadership). Labs provide the data, and the teams work on the\ndiscovery, design, and development of an AI solution. A student leadership team\nmanages the student group. This team interviews applicants, forms other teams,\nsets up standards for operations, fosters collaborations, and ensures the\ncontinuity of multi-semester projects. To date, this group has run for three\nconsecutive semesters and has engaged more than forty students, ranging from\nfirst-year college students to master's candidates. This effort has resulted in\nover a dozen successful collaborations with academic and industry partners.",
    "descriptor": "",
    "authors": [
      "Sergey V Samsonau",
      "Aziza Kurbonova",
      "Lu Jiang",
      "Hazem Lashen",
      "Jiamu Bai",
      "Theresa Merchant"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08966"
  },
  {
    "id": "arXiv:2210.08970",
    "title": "Digital Twins for Industry 4.0 in the 6G Era",
    "abstract": "Having the Fifth Generation (5G) mobile communication system recently rolled\nout in many countries, the wireless community is now setting its eyes on the\nnext era of Sixth Generation (6G). Inheriting from 5G its focus on industrial\nuse cases, 6G is envisaged to become the infrastructural backbone of future\nintelligent industry. Especially, a combination of 6G and the emerging\ntechnologies of Digital Twins (DT) will give impetus to the next evolution of\nIndustry 4.0 (I4.0) systems. Here we provide a vision for the future 6G\nindustrial DT ecosystem, which shall bridge the gaps between humans, machines,\nand the data infrastructure, and therewith enable numerous novel application\nscenarios. Subsequently, we explore the technical challenges that are brought\nby such ambitions, and identify the key enabling technologies that may help\ntackle down these issues.",
    "descriptor": "\nComments: Submitted to Nature Electronics\n",
    "authors": [
      "Bin Han",
      "Mohammad Asif Habibi",
      "Bjoern Richerzhagen",
      "Kim Schindhelm",
      "Florian Zeiger",
      "Fabrizio Lamberti",
      "Filippo Gabriele Prattic\u00f2",
      "Karthik Upadhya",
      "Charalampos Korovesis",
      "Ioannis-Prodromos Belikaidis",
      "Panagiotis Demestichas",
      "Siyu Yuan",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08970"
  },
  {
    "id": "arXiv:2210.08971",
    "title": "APGKT: Exploiting Associative Path on Skills Graph for Knowledge Tracing",
    "abstract": "Knowledge tracing (KT) is a fundamental task in educational data mining that\nmainly focuses on students' dynamic cognitive states of skills. The\nquestion-answering process of students can be regarded as a thinking process\nthat considers the following two problems. One problem is which skills are\nneeded to answer the question, and the other is how to use these skills in\norder. If a student wants to answer a question correctly, the student should\nnot only master the set of skills involved in the question but also think and\nobtain the associative path on the skills graph. The nodes in the associative\npath refer to the skills needed and the path shows the order of using them. The\nassociative path is referred to as the skill mode. Thus, obtaining the skill\nmodes is the key to answering questions successfully. However, most existing KT\nmodels only focus on a set of skills, without considering the skill modes. We\npropose a KT model, called APGKT, that exploits skill modes. Specifically, we\nextract the subgraph topology of the skills involved in the question and\ncombine the difficulty level of the skills to obtain the skill modes via\nencoding; then, through multi-layer recurrent neural networks, we obtain a\nstudent's higher-order cognitive states of skills, which is used to predict the\nstudent's future answering performance. Experiments on five benchmark datasets\nvalidate the effectiveness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Haotian Zhang",
      "Chenyang Bu",
      "Fei Liu",
      "Shuochen Liu",
      "Yuhong Zhang",
      "Xuegang Hu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08971"
  },
  {
    "id": "arXiv:2210.08972",
    "title": "A new nonparametric interpoint distance-based measure for assessment of  clustering",
    "abstract": "A new interpoint distance-based measure is proposed to identify the optimal\nnumber of clusters present in a data set. Designed in nonparametric approach,\nit is independent of the distribution of given data. Interpoint distances\nbetween the data members make our cluster validity index applicable to\nunivariate and multivariate data measured on arbitrary scales, or having\nobservations in any dimensional space where the number of study variables can\nbe even larger than the sample size. Our proposed criterion is compatible with\nany clustering algorithm, and can be used to determine the unknown number of\nclusters or to assess the quality of the resulting clusters for a data set.\nDemonstration through synthetic and real-life data establishes its superiority\nover the well-known clustering accuracy measures of the literature.",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "Soumita Modak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08972"
  },
  {
    "id": "arXiv:2210.08973",
    "title": "FAIR for AI: An interdisciplinary, international, inclusive, and diverse  community building perspective",
    "abstract": "A foundational set of findable, accessible, interoperable, and reusable\n(FAIR) principles were proposed in 2016 as prerequisites for proper data\nmanagement and stewardship, with the goal of enabling the reusability of\nscholarly data. The principles were also meant to apply to other digital\nassets, at a high level, and over time, the FAIR guiding principles have been\nre-interpreted or extended to include the software, tools, algorithms, and\nworkflows that produce data. FAIR principles are now being adapted in the\ncontext of AI models and datasets. Here, we present the perspectives, vision,\nand experiences of researchers from different countries, disciplines, and\nbackgrounds who are leading the definition and adoption of FAIR principles in\ntheir communities of practice, and discuss outcomes that may result from\npursuing and incentivizing FAIR AI research. The material for this report\nbuilds on the FAIR for AI Workshop held at Argonne National Laboratory on June\n7, 2022.",
    "descriptor": "\nComments: 10 pages, comments welcome!\n",
    "authors": [
      "E.A. Huerta",
      "Ben Blaiszik",
      "L. Catherine Brinson",
      "Kristofer E. Bouchard",
      "Daniel Diaz",
      "Caterina Doglioni",
      "Javier M. Duarte",
      "Murali Emani",
      "Ian Foster",
      "Geoffrey Fox",
      "Philip Harris",
      "Lukas Heinrich",
      "Shantenu Jha",
      "Daniel S. Katz",
      "Volodymyr Kindratenko",
      "Christine R. Kirkpatrick",
      "Kati Lassila-Perini",
      "Ravi K. Madduri",
      "Mark S. Neubauer",
      "Fotis E. Psomopoulos",
      "Avik Roy",
      "Oliver R\u00fcbel",
      "Zhizhen Zhao",
      "Ruike Zhu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2210.08973"
  },
  {
    "id": "arXiv:2210.08974",
    "title": "Coordinated Science Laboratory 70th Anniversary Symposium: The Future of  Computing",
    "abstract": "In 2021, the Coordinated Science Laboratory CSL, an Interdisciplinary\nResearch Unit at the University of Illinois Urbana-Champaign, hosted the Future\nof Computing Symposium to celebrate its 70th anniversary. CSL's research covers\nthe full computing stack, computing's impact on society and the resulting need\nfor social responsibility. In this white paper, we summarize the major\ntechnological points, insights, and directions that speakers brought forward\nduring the Future of Computing Symposium.\nParticipants discussed topics related to new computing paradigms,\ntechnologies, algorithms, behaviors, and research challenges to be expected in\nthe future. The symposium focused on new computing paradigms that are going\nbeyond traditional computing and the research needed to support their\nrealization. These needs included stressing security and privacy, the end to\nend human cyber physical systems and with them the analysis of the end to end\nartificial intelligence needs. Furthermore, advances that enable immersive\nenvironments for users, the boundaries between humans and machines will blur\nand become seamless. Particular integration challenges were made clear in the\nfinal discussion on the integration of autonomous driving, robo taxis,\npedestrians, and future cities. Innovative approaches were outlined to motivate\nthe next generation of researchers to work on these challenges.\nThe discussion brought out the importance of considering not just individual\nresearch areas, but innovations at the intersections between computing research\nefforts and relevant application domains, such as health care, transportation,\nenergy systems, and manufacturing.",
    "descriptor": "",
    "authors": [
      "Klara Nahrstedt",
      "Naresh Shanbhag",
      "Vikram Adve",
      "Nancy Amato",
      "Romit Roy Choudhury",
      "Carl Gunter",
      "Nam Sung Kim",
      "Olgica Milenkovic",
      "Sayan Mitra",
      "Lav Varshney",
      "Yurii Vlasov",
      "Sarita Adve",
      "Rashid Bashir",
      "Andreas Cangellaris",
      "James DiCarlo",
      "Katie Driggs-Campbell",
      "Nick Feamster",
      "Mattia Gazzola",
      "Karrie Karahalios",
      "Sanmi Koyejo",
      "Paul Kwiat",
      "Bo Li",
      "Negar Mehr",
      "Ravish Mehra",
      "Andrew Miller",
      "Daniela Rus",
      "Alex Schwing",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08974"
  },
  {
    "id": "arXiv:2210.08975",
    "title": "Prioritizing emergency evacuations under compounding levels of  uncertainty",
    "abstract": "Well-executed emergency evacuations can save lives and reduce suffering.\nHowever, decision makers struggle to determine optimal evacuation policies\ngiven the chaos, uncertainty, and value judgments inherent in emergency\nevacuations. We propose and analyze a decision support tool for pre-crisis\ntraining exercises for teams preparing for civilian evacuations and explore the\ntool in the case of the 2021 U.S.-led evacuation from Afghanistan. We use\ndifferent classes of Markov decision processes (MDPs) to capture compounding\nlevels of uncertainty in (1) the priority category of who appears next at the\ngate for evacuation, (2) the distribution of priority categories at the\npopulation level, and (3) individuals' claimed priority category. We compare\nthe number of people evacuated by priority status under eight heuristic\npolicies. The optimized MDP policy achieves the best performance compared to\nall heuristic baselines. We also show that accounting for the compounding\nlevels of model uncertainty incurs added complexity without improvement in\npolicy performance. Useful heuristics can be extracted from the optimized\npolicies to inform human decision makers. We open-source all tools to encourage\nrobust dialogue about the trade-offs, limitations, and potential of integrating\nalgorithms into high-stakes humanitarian decision-making.",
    "descriptor": "\nComments: Submitted to the IEEE Global Humanitarian Technology Conference\n",
    "authors": [
      "Lisa J. Einstein",
      "Robert J. Moss",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08975"
  },
  {
    "id": "arXiv:2210.08976",
    "title": "Global technology access in biolabs -- from DIY trend to an open source  transformation",
    "abstract": "This article illustrates how open hardware solutions are implemented by\nresearchers as a strategy to access technology for cutting-edge research.\nSpecifically, it is discussed what kind of open technologies are most enabling\nin scientific environments characterized by economic and infrastructural\nconstraints. It is demonstrated that do-it-yourself (DIY) technologies are\nalready wide spread, in particular in countries with lower science funding,\nwhich in turn is the basis for the development of open technologies. Beyond\nfinancial accessibility, open hardware can be transformational to the\ntechnology access of laboratories through advantages in local production and\ndirect knowledge transfer. Central drivers of the adoption of appropriate\ntechnologies in biolabs globally are open sharing, digital fabrication, local\nproduction, standard parts use, and detailed documentation.",
    "descriptor": "",
    "authors": [
      "Tobias Wenzel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Hardware Architecture (cs.AR)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2210.08976"
  },
  {
    "id": "arXiv:2210.08978",
    "title": "Decentralized nation, solving the web identity crisis",
    "abstract": "The web of today whether you prefer to call it web 2.0, web 3.0, web 5.0 or\neven the metaverse is at a critical stage of evolution and challenge, largely\ncentered around its crisis of identity. Like teenagers who cannot assess\nproperly their reason for being and do not seem ready to take responsibility\nfor their actions, we are constantly blaming the very system we are trying to\nget away from. To truly realize the benefits from innovation and technology,\nthis crisis has to be resolved, not just through tactical solutions but through\ndevelopments that enhance the sustainability of the web and its benefits.\nSignificant strides are being made in the evolution of digital services enabled\nby technology, regulation, and the sheer pace of societal change. The journey\nto the decentralized web is mirroring the convergence of the physical and\ndigital worlds across all economies and is increasingly embracing the digital\nnative world. Technology has provided the foundational platform for individuals\nand entities to create and manage wealth, potentially without the need for big\ninstitutions. Ironically, despite all of the advancements, we are still facing\nan unprecedented and increasing wealth gap. Clearly, the system is broken, not\njust around the edges but at the very core of the democratic underpinning of\nour society. In this whitepaper, we propose how artificial intelligence on\nblockchain can be used to generate a new class of identity through direct human\ncomputer interaction. We demonstrate how this, combined with new perspectives\nfor sustaining community and governance embedded within the use of blockchain\ntechnology, will underpin a sustainable solution to protect identity,\nauthorship and privacy at the same time while contributing to restore trust\namongst members of a future decentralized nation and hence contribute to\nsolving the web most significant identity crisis.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Frederic Jumelle",
      "Timothy Pagett",
      "Ryan Lemand"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08978"
  },
  {
    "id": "arXiv:2210.08981",
    "title": "Towards sustainability assessment of artificial intelligence in artistic  practices",
    "abstract": "An increasing number of artists use Ai in their creative practices\n(Creative-Ai) and their works have by now become visible at prominent art\nvenues. The research community has, on the other hand, recognized that there\nare sustainability concerns of using Ai technologies related to, for instance,\nenergy consumption and the increasing size and complexity of models. These two\nconflicting trajectories constitute the starting point of our research. Here,\nwe discuss insights from our currently on-going fieldwork research and outline\nconsiderations for drawing various limitations in sustainability assessment\nstudies of Ai art. We provide ground for further, more specific sustainability\nassessments in the domain, as well as knowledge on the state of sustainability\nassessments in this domain.",
    "descriptor": "",
    "authors": [
      "Petra J\u00e4\u00e4skel\u00e4inen",
      "Daniel Pargman",
      "Andr\u00e9 Holzapfel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.08981"
  },
  {
    "id": "arXiv:2210.08982",
    "title": "Data Flex: On-Platform Organisations",
    "abstract": "The natural alignment between business and architecture within big techs has\nboosted their transformation (crucially, upon API-fication and synergies\nexploitation) compared to that in the rest of organisations. The efficiency gap\nis so large that even the latter fear the irruption of big techs in their own\narenas. Nevertheless, organisations have lately lost control of their\narchitectures. They have become a mix of services offered by big techs and\norchestrated by external consultants. Such a dynamic has naturally led to a\nlarge convergence between architectures across industries in spite of their\nidiosyncratic differences. Hence, there is room for improvement through a\ntransformation governance that optimally weighs both microeconomics and\nmicroservices. As neither of the fields is easy to master, such an improvement\nremains a greenfield. This paper proposes a novel data architecture paradigm,\nData Flex, that helps organisations take control of their transformation\njourney by becoming platforms - i.e. unlocking convergence with big techs\nefficiency levels. Further, it surpasses the theory by having evolved Data Flex\nfirst instance for the last 7 years. Along that time, the authors gathered real\nexamples that filled out a cube defined by a series of dimensions significant\nenough to assert the universal validity of their approach.",
    "descriptor": "",
    "authors": [
      "Alvarez-Telena Sergio",
      "Diez-Fernandez Marta"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2210.08982"
  },
  {
    "id": "arXiv:2210.08983",
    "title": "Temporal Analysis and Gender Bias in Computing",
    "abstract": "Recent studies of gender bias in computing use large datasets involving\nautomatic predictions of gender to analyze computing publications, conferences,\nand other key populations. Gender bias is partly defined by software-driven\nalgorithmic analysis, but widely used gender prediction tools can result in\nunacknowledged gender bias when used for historical research. Many names change\nascribed gender over decades: the \"Leslie problem.\" Systematic analysis of the\nSocial Security Administration dataset -- each year, all given names,\nidentified by ascribed gender and frequency of use -- in 1900, 1925, 1950,\n1975, and 2000 permits a rigorous assessment of the \"Leslie problem.\" This\narticle identifies 300 given names with measurable \"gender shifts\" across\n1925-1975, spotlighting the 50 given names with the largest such shifts. This\narticle demonstrates, quantitatively, there is net \"female shift\" that likely\nresults in the overcounting of women (and undercounting of men) in earlier\ndecades, just as computer science was professionalizing. Some aspects of the\nwidely accepted 'making programming masculine' perspective may need revision.",
    "descriptor": "\nComments: 18 pages, 2 figures, 1 table\n",
    "authors": [
      "Thomas J. Misa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08983"
  },
  {
    "id": "arXiv:2210.08984",
    "title": "AI Governance and Ethics Framework for Sustainable AI and Sustainability",
    "abstract": "AI is transforming the existing technology landscape at a rapid phase\nenabling data-informed decision making and autonomous decision making. Unlike\nany other technology, because of the decision-making ability of AI, ethics and\ngovernance became a key concern. There are many emerging AI risks for humanity,\nsuch as autonomous weapons, automation-spurred job loss, socio-economic\ninequality, bias caused by data and algorithms, privacy violations and\ndeepfakes. Social diversity, equity and inclusion are considered key success\nfactors of AI to mitigate risks, create values and drive social justice.\nSustainability became a broad and complex topic entangled with AI. Many\norganizations (government, corporate, not-for-profits, charities and NGOs) have\ndiversified strategies driving AI for business optimization and\nsocial-and-environmental justice. Partnerships and collaborations become\nimportant more than ever for equity and inclusion of diversified and\ndistributed people, data and capabilities. Therefore, in our journey towards an\nAI-enabled sustainable future, we need to address AI ethics and governance as a\npriority. These AI ethics and governance should be underpinned by human ethics.",
    "descriptor": "\nComments: Attribution: M. Samarawickrama, AI Governance and Ethics Framework for Sustainable AI and Sustainability, Submission in response to the Department of the Prime Minister and Cabinet issues paper Positioning Australia as a leader in digital economy regulation - Automated Decision Making and AI Regulation, Apr. 2022, ISBN: 978-0-6454693-0-1\n",
    "authors": [
      "Mahendra Samarawickrama"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08984"
  },
  {
    "id": "arXiv:2210.08985",
    "title": "Election of government ministers",
    "abstract": "The executive branch (the government) is usually not directly elected by the\npeople, but is created by another elected body or person such as the parliament\nor the president. As a result, its members are not directly accountable to the\npeople, individually or as a group.\nWe propose a scenario where government members are directly elected by the\npeople, and seek to achieve proportional representation in the process.\nWe will present a formal model for the allocation of K offices, each\nassociated with a disjoint set of candidates contesting for that seat.\nA group of voters provides ballots for each of the offices. Since using\nsimple majority voting for each office independently may result in minority\npreferences being completely ignored, here we adapt the greedy version of\nproportional approval voting (GreedyPAV) to our framework.\nIn the article Electing the Executive Branch you can find an in-depth\nexplanation of the model and a demonstration - through computer-based\nsimulations - of how voting for all offices together using this rule overcomes\nthis weakness and upholds the axiom of proportionality.\nIn this article, we will present the implementation of the algorithm\n(GreedyPAV) proposed by Rutvik Page, Ehud Shapiro, and Nimrod Talmon in the\narticle mentioned above. In addition, we tested our implementation through a\nsurvey, the results of which will be presented and analyzed later in the\narticle.",
    "descriptor": "",
    "authors": [
      "Itai Lashover",
      "Liav Weiss",
      "Amichai Kafka",
      "Shoshana Levin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.08985"
  },
  {
    "id": "arXiv:2210.08987",
    "title": "Active Informed Consent to Boost the Application of Machine Learning in  Medicine",
    "abstract": "Machine Learning may push research in precision medicine to unprecedented\nheights. To succeed, machine learning needs a large amount of data, often\nincluding personal data. Therefore, machine learning applied to precision\nmedicine is on a cliff edge: if it does not learn to fly, it will deeply fall\ndown. In this paper, we present Active Informed Consent (AIC) as a novel hybrid\nlegal-technological tool to foster the gathering of a large amount of data for\nmachine learning. We carefully analyzed the compliance of this technological\ntool to the legal intricacies protecting the privacy of European Citizens.",
    "descriptor": "",
    "authors": [
      "Marco Gerardi",
      "Katarzyna Barud",
      "Marie-Catherine Wagner",
      "Nikolaus Forgo",
      "Francesca Fallucchi",
      "Noemi Scarpato",
      "Fiorella Guadagni",
      "Fabio Massimo Zanzotto"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08987"
  },
  {
    "id": "arXiv:2210.08988",
    "title": "Heterogeneous Feature Distillation Network for SAR Image Semantic  Segmentation",
    "abstract": "Semantic segmentation for SAR (Synthetic Aperture Radar) images has attracted\nincreasing attention in the remote sensing community recently, due to SAR's\nall-time and all-weather imaging capability. However, SAR images are generally\nmore difficult to be segmented than their EO (Electro-Optical) counterparts,\nsince speckle noises and layovers are inevitably involved in SAR images. To\naddress this problem, we investigate how to introduce EO features to assist the\ntraining of a SAR-segmentation model, and propose a heterogeneous feature\ndistillation network for segmenting SAR images, called HFD-Net, where a\nSAR-segmentation student model gains knowledge from a pre-trained\nEO-segmentation teacher model. In the proposed HFD-Net, both the student and\nteacher models employ an identical architecture but different parameter\nconfigurations, and a heterogeneous feature distillation model is explored for\ntransferring latent EO features from the teacher model to the student model and\nthen enhancing the ability of the student model for SAR image segmentation. In\naddition, a heterogeneous feature alignment module is explored to aggregate\nmulti-scale features for segmentation in each of the student model and teacher\nmodel. Extensive experimental results on two public datasets demonstrate that\nthe proposed HFD-Net outperforms seven state-of-the-art SAR image semantic\nsegmentation methods.",
    "descriptor": "",
    "authors": [
      "Gao Mengyu",
      "Dong Qiulei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08988"
  },
  {
    "id": "arXiv:2210.08990",
    "title": "Unsupervised Object-Centric Learning with Bi-Level Optimized Query Slot  Attention",
    "abstract": "The ability to decompose complex natural scenes into meaningful\nobject-centric abstractions lies at the core of human perception and reasoning.\nIn the recent culmination of unsupervised object-centric learning, the\nSlot-Attention module has played an important role with its simple yet\neffective design and fostered many powerful variants. These methods, however,\nhave been exceedingly difficult to train without supervision and are ambiguous\nin the notion of object, especially for complex natural scenes. In this paper,\nwe propose to address these issues by (1) initializing Slot-Attention modules\nwith learnable queries and (2) optimizing the model with bi-level optimization.\nWith simple code adjustments on the vanilla Slot-Attention, our model, Bi-level\nOptimized Query Slot Attention, achieves state-of-the-art results on both\nsynthetic and complex real-world datasets in unsupervised image segmentation\nand reconstruction, outperforming previous baselines by a large margin (~10%).\nWe provide thorough ablative studies to validate the necessity and\neffectiveness of our design. Additionally, our model exhibits excellent\npotential for concept binding and zero-shot learning. We hope our effort could\nprovide a single home for the design and learning of slot-based models and pave\nthe way for more challenging tasks in object-centric learning. Our\nimplementation is publicly available at\nhttps://github.com/Wall-Facer-liuyu/BO-QSA.",
    "descriptor": "",
    "authors": [
      "Baoxiong Jia",
      "Yu Liu",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08990"
  },
  {
    "id": "arXiv:2210.08992",
    "title": "Language-agnostic Code-Switching in End-To-End Speech Recognition",
    "abstract": "Code-Switching (CS) is referred to the phenomenon of alternately using words\nand phrases from different languages. While today's neural end-to-end (E2E)\nmodels deliver state-of-the-art performances on the task of automatic speech\nrecognition (ASR) it is commonly known that these systems are very\ndata-intensive. However, there is only a few transcribed and aligned CS speech\navailable. To overcome this problem and train multilingual systems which can\ntranscribe CS speech, we propose a simple yet effective data augmentation in\nwhich audio and corresponding labels of different source languages are\nconcatenated. By using this training data, our E2E model improves on\ntranscribing CS speech and improves performance over the multilingual model, as\nwell. The results show that this augmentation technique can even improve the\nmodel's performance on inter-sentential language switches not seen during\ntraining by 5,03\\% WER.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Enes Yavuz Ugan",
      "Christian Huber",
      "Juan Hussain",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.08992"
  },
  {
    "id": "arXiv:2210.08993",
    "title": "When Digital Economy Meets Web 3.0: Applications and Challenges",
    "abstract": "With the continuous development of web technology, Web 3.0 has attracted a\nconsiderable amount of attention due to its unique decentralized\ncharacteristics. The digital economy is an important driver of high-quality\neconomic development and is currently in a rapid development stage. In the\ndigital economy scenario, the centralized nature of the Internet and other\ncharacteristics often bring about security issues such as infringement and\nprivacy leakage. Therefore, by exploring the digital economy and Web 3.0, it is\nnecessary to investigate how to use Web 3.0 technologies to solve the pain\npoints encountered in the development of the digital economy. In this paper, we\ndiscuss the aspects of Web 3.0 that should be integrated with the digital\neconomy to better find the entry point to solve the problems by examining the\nlatest advances of Web 3.0 in machine learning, finance, and data management.\nWe hope this research will inspire those involved in academia and industry and\nhelp build a favourable ecology for the digital economy.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Chuan Chen",
      "Lei Zhang",
      "Yihao Li",
      "Tianchi Liao",
      "Siran Zhao",
      "Huawei Huang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08993"
  },
  {
    "id": "arXiv:2210.08994",
    "title": "Knowledge Representation for Conceptual, Motivational, and Affective  Processes in Natural Language Communication",
    "abstract": "Natural language communication is an intricate and complex process. The\nspeaker usually begins with an intention and motivation of what is to be\ncommunicated, and what effects are expected from the communication, while\ntaking into consideration the listener's mental model to concoct an appropriate\nsentence. The listener likewise has to interpret what the speaker means, and\nrespond accordingly, also with the speaker's mental state in mind. To do this\nsuccessfully, conceptual, motivational, and affective processes have to be\nrepresented appropriately to drive the language generation and understanding\nprocesses. Language processing has succeeded well with the big data approach in\napplications such as chatbots and machine translation. However, in human-robot\ncollaborative social communication and in using natural language for delivering\nprecise instructions to robots, a deeper representation of the conceptual,\nmotivational, and affective processes is needed. This paper capitalizes on the\nUGALRS (Unified General Autonomous and Language Reasoning System) framework and\nthe CD+ (Conceptual Representation Plus) representational scheme to illustrate\nhow social communication through language is supported by a knowledge\nrepresentational scheme that handles conceptual, motivational, and affective\nprocesses in a deep and general way. Though a small set of concepts,\nmotivations, and emotions is treated in this paper, its main contribution is in\narticulating a general framework of knowledge representation and processing to\nlink these aspects together in serving the purpose of natural language\ncommunication for an intelligent system.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Seng-Beng Ho",
      "Zhaoxia Wang",
      "Boon-Kiat Quek",
      "Erik Cambria"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08994"
  },
  {
    "id": "arXiv:2210.08995",
    "title": "AI, Opacity, and Personal Autonomy",
    "abstract": "Advancements in machine learning have fuelled the popularity of using AI\ndecision algorithms in procedures such as bail hearings (Feller et al. 2016),\nmedical diagnoses (Rajkomar et al. 2018; Esteva et al. 2019) and recruitment\n(Heilweil 2019, Van Esch et al. 2019). Academic articles (Floridi et al. 2018),\npolicy texts (HLEG 2019), and popularizing books (O'Neill 2016, Eubanks 2018)\nalike warn that such algorithms tend to be _opaque_: they do not provide\nexplanations for their outcomes. Building on a causal account of transparency\nand opacity as well as recent work on the value of causal explanation (Lombrozo\n2011, Hitchcock 2012), I formulate a moral concern for opaque algorithms that\nis yet to receive a systematic treatment in the literature: when such\nalgorithms are used in life-changing decisions, they can obstruct us from\neffectively shaping our lives according to our goals and preferences, thus\nundermining our autonomy. I argue that this concern deserves closer attention\nas it furnishes the call for transparency in algorithmic decision-making with\nboth new tools and new challenges.",
    "descriptor": "",
    "authors": [
      "Bram Vaassen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08995"
  },
  {
    "id": "arXiv:2210.08997",
    "title": "AIM 2022 Challenge on Instagram Filter Removal: Methods and Results",
    "abstract": "This paper introduces the methods and the results of AIM 2022 challenge on\nInstagram Filter Removal. Social media filters transform the images by\nconsecutive non-linear operations, and the feature maps of the original content\nmay be interpolated into a different domain. This reduces the overall\nperformance of the recent deep learning strategies. The main goal of this\nchallenge is to produce realistic and visually plausible images where the\nimpact of the filters applied is mitigated while preserving the content. The\nproposed solutions are ranked in terms of the PSNR value with respect to the\noriginal images. There are two prior studies on this task as the baseline, and\na total of 9 teams have competed in the final phase of the challenge. The\ncomparison of qualitative results of the proposed solutions and the benchmark\nfor the challenge are presented in this report.",
    "descriptor": "\nComments: 14 pages, 9 figures, Challenge report of AIM 2022 Instagram Filter Removal Challenge in conjunction with ECCV 2022\n",
    "authors": [
      "Furkan K\u0131nl\u0131",
      "Sami Mente\u015f",
      "Bar\u0131\u015f \u00d6zcan",
      "Furkan K\u0131ra\u00e7",
      "Radu Timofte",
      "Yi Zuo",
      "Zitao Wang",
      "Xiaowen Zhang",
      "Yu Zhu",
      "Chenghua Li",
      "Cong Leng",
      "Jian Cheng",
      "Shuai Liu",
      "Chaoyu Feng",
      "Furui Bai",
      "Xiaotao Wang",
      "Lei Lei",
      "Tianzhi Ma",
      "Zihan Gao",
      "Wenxin He",
      "Woon-Ha Yeo",
      "Wang-Taek Oh",
      "Young-Il Kim",
      "Han-Cheol Ryu",
      "Gang He",
      "Shaoyi Long",
      "S. M. A. Sharif",
      "Rizwan Ali Naqvi",
      "Sungjun Kim",
      "Guisik Kim",
      "Seohyeon Lee",
      "Sabari Nathan",
      "Priya Kansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08997"
  },
  {
    "id": "arXiv:2210.08998",
    "title": "A Symbolic Representation of Human Posture for Interpretable Learning  and Reasoning",
    "abstract": "Robots that interact with humans in a physical space or application need to\nthink about the person's posture, which typically comes from visual sensors\nlike cameras and infra-red. Artificial intelligence and machine learning\nalgorithms use information from these sensors either directly or after some\nlevel of symbolic abstraction, and the latter usually partitions the range of\nobserved values to discretize the continuous signal data. Although these\nrepresentations have been effective in a variety of algorithms with respect to\naccuracy and task completion, the underlying models are rarely interpretable,\nwhich also makes their outputs more difficult to explain to people who request\nthem. Instead of focusing on the possible sensor values that are familiar to a\nmachine, we introduce a qualitative spatial reasoning approach that describes\nthe human posture in terms that are more familiar to people. This paper\nexplores the derivation of our symbolic representation at two levels of detail\nand its preliminary use as features for interpretable activity recognition.",
    "descriptor": "\nComments: Accepted for presentation at the AAAI 2022 Fall Symposium Series, in the symposium for Artificial Intelligence for Human-Robot Interaction\n",
    "authors": [
      "Richard G. Freedman",
      "Joseph B. Mueller",
      "Jack Ladwig",
      "Steven Johnston",
      "Helen Wauck",
      "Ruta Wheelock",
      "Hayley Borck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08998"
  },
  {
    "id": "arXiv:2210.09002",
    "title": "A review of modern surveillance techniques and their presence in our  society",
    "abstract": "Technology is now omnipresent around us. Especially with the recent health\ncrisis, many people started working remotely, bringing home an additional\ncomputer. Combining this with our smartphones that we could never leave behind,\nwe are always surrounded by these technological marvels. However, they come\nalong with a rather dark side from which many people choose to look away,\npreferring to live in denial: the surveillance. All of these devices can be\nused to keep a close eye and ear on us. The modern surveillance machine has\nreached a new, groundbreaking, size; and we will attempt to understand how we\nended up in this situation. To have a complete understanding of the problem, it\nis important to gather some historical background to comprehend where this\nissue comes from as well as a review of the different actors. Each actor has a\nspecific skillset it will use to acquire the desired information, and what\ninformation they choose to gather depends strongly on their motives. We will go\nover the many tricks used to gather our information, as well as its relevance\nin the current surveillance climate.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Alexis Roger"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09002"
  },
  {
    "id": "arXiv:2210.09004",
    "title": "Real-Time Automated Answer Scoring",
    "abstract": "In recent years, the role of big data analytics has exponentially grown and\nis now slowly making its way into the education industry. Several attempts are\nbeing made in this sphere in order to improve the quality of education being\nprovided to students and while many collaborations have been carried out\nbefore, automated scoring of answers has been explored to a rather limited\nextent. One of the biggest hurdles to choosing constructed-response assessments\nover multiple-choice assessments is the effort and large cost that comes with\ntheir evaluation and this is precisely the issue that this project aims to\nsolve. The aim is to accept raw-input from the student in the form of their\nanswer, preprocess the answer, and automatically score the answer. In addition,\nwe have made this a real-time system that captures \"snapshots\" of the writer's\nprogress with respect to the answer, allowing us to unearth trends with respect\nto the way a student thinks, and how the student has arrived at their final\nanswer.",
    "descriptor": "\nComments: This paper was originally written in mid 2018\n",
    "authors": [
      "Akash Nagaraj",
      "Mukund Sood",
      "Gowri Srinivasa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09004"
  },
  {
    "id": "arXiv:2210.09010",
    "title": "Good AI for Good: How AI Strategies of the Nordic Countries Address the  Sustainable Development Goals",
    "abstract": "Developed and used responsibly Artificial Intelligence (AI) is a force for\nglobal sustainable development. Given this opportunity, we expect that the many\nof the existing guidelines and recommendations for trustworthy or responsible\nAI will provide explicit guidance on how AI can contribute to the achievement\nof United Nations' Sustainable Development Goals (SDGs). This would in\nparticular be the case for the AI strategies of the Nordic countries, at least\ngiven their high ranking and overall political focus when it comes to the\nachievement of the SDGs. In this paper, we present an analysis of existing AI\nrecommendations from 10 different countries or organisations based on topic\nmodelling techniques to identify how much these strategy documents refer to the\nSDGs. The analysis shows no significant difference on how much these documents\nrefer to SDGs. Moreover, the Nordic countries are not different from the others\nalbeit their long-term commitment to SDGs. More importantly, references to\n\\textit{gender equality} (SDG 5) and \\textit{inequality} (SDG 10), as well as\nreferences to environmental impact of AI development and use, and in particular\nthe consequences for life on earth, are notably missing from the guidelines.",
    "descriptor": "\nComments: IJCAI-AIofAI 2022 : 2nd Workshop on Adverse Impacts and Collateral Effects of AI Technologies\n",
    "authors": [
      "Andreas Theodorou",
      "Juan Carlos Nieves",
      "Virginia Dignum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09010"
  },
  {
    "id": "arXiv:2210.09011",
    "title": "ANFIS-based prediction of power generation for combined cycle power  plant",
    "abstract": "This paper presents the application of an adaptive neuro-fuzzy inference\nsystem (ANFIS) to predict the generated electrical power in a combined cycle\npower plant. The ANFIS architecture is implemented in MATLAB through a code\nthat utilizes a hybrid algorithm that combines gradient descent and the least\nsquare estimator to train the network. The Model is verified by applying it to\napproximate a nonlinear equation with three variables, the time series\nMackey-Glass equation and the ANFIS toolbox in MATLAB. Once its validity is\nconfirmed, ANFIS is implemented to forecast the generated electrical power by\nthe power plant. The ANFIS has three inputs: temperature, pressure, and\nrelative humidity. Each input is fuzzified by three Gaussian membership\nfunctions. The first-order Sugeno type defuzzification approach is utilized to\nevaluate a crisp output. Proposed ANFIS is cable of successfully predicting\npower generation with extremely high accuracy and being much faster than\nToolbox, which makes it a promising tool for energy generation applications.",
    "descriptor": "",
    "authors": [
      "Mary Pa",
      "Amin Kazemi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09011"
  },
  {
    "id": "arXiv:2210.09012",
    "title": "SAICL: Student Modelling with Interaction-level Auxiliary Contrastive  Tasks for Knowledge Tracing and Dropout Prediction",
    "abstract": "Knowledge tracing and dropout prediction are crucial for online education to\nestimate students' knowledge states or to prevent dropout rates. While\ntraditional systems interacting with students suffered from data sparsity and\noverfitting, recent sample-level contrastive learning helps to alleviate this\nissue. One major limitation of sample-level approaches is that they regard\nstudents' behavior interaction sequences as a bundle, so they often fail to\nencode temporal contexts and track their dynamic changes, making it hard to\nfind optimal representations for knowledge tracing and dropout prediction. To\napply temporal context within the sequence, this study introduces a novel\nstudent modeling framework, SAICL: \\textbf{s}tudent modeling with\n\\textbf{a}uxiliary \\textbf{i}nteraction-level \\textbf{c}ontrastive\n\\textbf{l}earning. In detail, SAICL can utilize both proposed\nself-supervised/supervised interaction-level contrastive objectives: MilCPC\n(\\textbf{M}ulti-\\textbf{I}nteraction-\\textbf{L}evel \\textbf{C}ontrastive\n\\textbf{P}redictive \\textbf{C}oding) and SupCPC (\\textbf{Sup}ervised\n\\textbf{C}ontrastive \\textbf{P}redictive \\textbf{C}oding). While previous\nsample-level contrastive methods for student modeling are highly dependent on\ndata augmentation methods, the SAICL is free of data augmentation while showing\nbetter performance in both self-supervised and supervised settings. By\ncombining cross-entropy with contrastive objectives, the proposed SAICL\nachieved comparable knowledge tracing and dropout prediction performance with\nother state-of-art models without compromising inference costs.",
    "descriptor": "\nComments: preprint, under review\n",
    "authors": [
      "Jungbae Park",
      "Jinyoung Kim",
      "Soonwoo Kwan",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09012"
  },
  {
    "id": "arXiv:2210.09013",
    "title": "Knowledge Tracing for Complex Problem Solving: Granular Rank-Based  Tensor Factorization",
    "abstract": "Knowledge Tracing (KT), which aims to model student knowledge level and\npredict their performance, is one of the most important applications of user\nmodeling. Modern KT approaches model and maintain an up-to-date state of\nstudent knowledge over a set of course concepts according to students'\nhistorical performance in attempting the problems. However, KT approaches were\ndesigned to model knowledge by observing relatively small problem-solving steps\nin Intelligent Tutoring Systems. While these approaches were applied\nsuccessfully to model student knowledge by observing student solutions for\nsimple problems, they do not perform well for modeling complex problem solving\nin students.M ost importantly, current models assume that all problem attempts\nare equally valuable in quantifying current student knowledge.However, for\ncomplex problems that involve many concepts at the same time, this assumption\nis deficient. In this paper, we argue that not all attempts are equivalently\nimportant in discovering students' knowledge state, and some attempts can be\nsummarized together to better represent student performance. We propose a novel\nstudent knowledge tracing approach, Granular RAnk based TEnsor factorization\n(GRATE), that dynamically selects student attempts that can be aggregated while\npredicting students' performance in problems and discovering the concepts\npresented in them. Our experiments on three real-world datasets demonstrate the\nimproved performance of GRATE, compared to the state-of-the-art baselines, in\nthe task of student performance prediction. Our further analysis shows that\nattempt aggregation eliminates the unnecessary fluctuations from students'\ndiscovered knowledge states and helps in discovering complex latent concepts in\nthe problems.",
    "descriptor": "\nComments: Accepted by UMAP-2021\n",
    "authors": [
      "Chunpai Wang",
      "Shaghayegh Sahebi",
      "Siqian Zhao",
      "Peter Brusilovsky",
      "Laura O. Moraes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09013"
  },
  {
    "id": "arXiv:2210.09014",
    "title": "Addressing contingency in algorithmic misinformation detection: Toward a  responsible innovation agenda",
    "abstract": "Machine learning (ML) enabled classification models are becoming increasingly\npopular for tackling the sheer volume and speed of online misinformation. In\nbuilding these models, data scientists need to take a stance on the legitimacy,\nauthoritativeness and objectivity of the sources of `truth' used for model\ntraining and testing. This has political, ethical and epistemic implications\nwhich are rarely addressed in technical papers. Despite (and due to) their\nreported high performance, ML-driven moderation systems have the potential to\nshape online public debate and create downstream negative impacts such as undue\ncensorship and reinforcing false beliefs. This article reports on a responsible\ninnovation (RI) inflected collaboration at the intersection of social studies\nof science and data science. We identify a series of algorithmic\ncontingencies--key moments during model development which could lead to\ndifferent future outcomes, uncertainty and harmful effects. We conclude by\noffering an agenda of reflexivity and responsible development of ML tools for\ncombating misinformation.",
    "descriptor": "\nComments: 47 pg, 1 figure\n",
    "authors": [
      "Andr\u00e9s Dom\u00ednguez Hern\u00e1ndez",
      "Richard Owen",
      "Dan Saattrup Nielsen",
      "Ryan McConville"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09014"
  },
  {
    "id": "arXiv:2210.09015",
    "title": "Visual Debates",
    "abstract": "The natural way of obtaining different perspectives on any given topic is by\nconducting a debate, where participants argue for and against the topic. Here,\nwe propose a novel debate framework for understanding the classifier's\nreasoning for making a particular prediction by modelling it as a multiplayer\nsequential zero-sum game. The players aim to maximise their utilities by\nadjusting their arguments with respect to other players' counterarguments. The\ncontrastive nature of our framework encourages players to put forward diverse\narguments, picking up the reasoning trails missed by their opponents. Thus, our\nframework answers the question: why did the classifier make a certain\nprediction?, by allowing players to argue for and against the classifier's\ndecision. In the proposed setup, given the question and the classifier's latent\nknowledge, both agents take turns in proposing arguments to support or\ncontradict the classifier's decision; arguments here correspond to the\nselection of specific features from the discretised latent space of the\ncontinuous classifier. By the end of the debate, we collect sets of supportive\nand manipulative features, serving as an explanation depicting the internal\nreasoning of the classifier. We demonstrate our Visual Debates on the geometric\nSHAPE and MNIST datasets for subjective validation, followed by the\nhigh-resolution AFHQ dataset. For further investigation, our framework is\navailable at \\url{https://github.com/koriavinash1/VisualDebates}.",
    "descriptor": "",
    "authors": [
      "Avinash Kori",
      "Ben Glocker",
      "Francesca Toni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09015"
  },
  {
    "id": "arXiv:2210.09017",
    "title": "Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems",
    "abstract": "In this paper, a robust data-driven moving horizon estimation (MHE) scheme\nfor linear time-invariant discrete-time systems is introduced. The scheme\nsolely relies on offline collected data without employing any system\nidentification step. First, robust global exponential stability is proven under\nstandard assumptions for a nominal case where the offline collected data are\nnoise-free but the online measured outputs are corrupted by some non-vanishing\nmeasurement noise. Second, practical robust exponential stability is shown for\nthe case where, in addition to the measurement noise in the online phase, the\noffline collected data are corrupted by some non-vanishing and bounded noise.\nThe behavior of the novel robust data-driven MHE scheme is illustrated by means\nof a simulation example and compared to a standard model-based MHE, where the\nmodel is identified using the same offline data as for the data-driven MHE.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Tobias M. Wolff",
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09017"
  },
  {
    "id": "arXiv:2210.09020",
    "title": "Defects of Convolutional Decoder Networks in Frequency Representation",
    "abstract": "In this paper, we prove representation bottlenecks of a cascaded\nconvolutional decoder network, considering the capacity of representing\ndifferent frequency components of an input sample. We conduct the discrete\nFourier transform on each channel of the feature map in an intermediate layer\nof the decoder network. Then, we introduce the rule of the forward propagation\nof such intermediate-layer spectrum maps, which is equivalent to the forward\npropagation of feature maps through a convolutional layer. Based on this, we\nfind that each frequency component in the spectrum map is forward propagated\nindependently with other frequency components. Furthermore, we prove two\nbottlenecks in representing feature spectrums. First, we prove that the\nconvolution operation, the zero-padding operation, and a set of other settings\nall make a convolutional decoder network more likely to weaken high-frequency\ncomponents. Second, we prove that the upsampling operation generates a feature\nspectrum, in which strong signals repetitively appears at certain frequencies.",
    "descriptor": "",
    "authors": [
      "Ling Tang",
      "Wen Shen",
      "Zhanpeng Zhou",
      "Yuefeng Chen",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09020"
  },
  {
    "id": "arXiv:2210.09021",
    "title": "Histopathological Image Classification based on Self-Supervised Vision  Transformer and Weak Labels",
    "abstract": "Whole Slide Image (WSI) analysis is a powerful method to facilitate the\ndiagnosis of cancer in tissue samples. Automating this diagnosis poses various\nissues, most notably caused by the immense image resolution and limited\nannotations. WSIs commonly exhibit resolutions of 100Kx100K pixels. Annotating\ncancerous areas in WSIs on the pixel level is prohibitively labor-intensive and\nrequires a high level of expert knowledge. Multiple instance learning (MIL)\nalleviates the need for expensive pixel-level annotations. In MIL, learning is\nperformed on slide-level labels, in which a pathologist provides information\nabout whether a slide includes cancerous tissue. Here, we propose Self-ViT-MIL,\na novel approach for classifying and localizing cancerous areas based on\nslide-level annotations, eliminating the need for pixel-wise annotated training\ndata. Self-ViT- MIL is pre-trained in a self-supervised setting to learn rich\nfeature representation without relying on any labels. The recent Vision\nTransformer (ViT) architecture builds the feature extractor of Self-ViT-MIL.\nFor localizing cancerous regions, a MIL aggregator with global attention is\nutilized. To the best of our knowledge, Self-ViT- MIL is the first approach to\nintroduce self-supervised ViTs in MIL-based WSI analysis tasks. We showcase the\neffectiveness of our approach on the common Camelyon16 dataset. Self-ViT-MIL\nsurpasses existing state-of-the-art MIL-based approaches in terms of accuracy\nand area under the curve (AUC).",
    "descriptor": "",
    "authors": [
      "Ahmet Gokberk Gul",
      "Oezdemir Cetin",
      "Christoph Reich",
      "Tim Prangemeier",
      "Nadine Flinner",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09021"
  },
  {
    "id": "arXiv:2210.09022",
    "title": "Distilling Object Detectors With Global Knowledge",
    "abstract": "Knowledge distillation learns a lightweight student model that mimics a\ncumbersome teacher. Existing methods regard the knowledge as the feature of\neach instance or their relations, which is the instance-level knowledge only\nfrom the teacher model, i.e., the local knowledge. However, the empirical\nstudies show that the local knowledge is much noisy in object detection tasks,\nespecially on the blurred, occluded, or small instances. Thus, a more intrinsic\napproach is to measure the representations of instances w.r.t. a group of\ncommon basis vectors in the two feature spaces of the teacher and the student\ndetectors, i.e., global knowledge. Then, the distilling algorithm can be\napplied as space alignment. To this end, a novel prototype generation module\n(PGM) is proposed to find the common basis vectors, dubbed prototypes, in the\ntwo feature spaces. Then, a robust distilling module (RDM) is applied to\nconstruct the global knowledge based on the prototypes and filtrate noisy\nglobal and local knowledge by measuring the discrepancy of the representations\nin two feature spaces. Experiments with Faster-RCNN and RetinaNet on PASCAL and\nCOCO datasets show that our method achieves the best performance for distilling\nobject detectors with various backbones, which even surpasses the performance\nof the teacher model. We also show that the existing methods can be easily\ncombined with global knowledge and obtain further improvement. Code is\navailable: https://github.com/hikvision-research/DAVAR-Lab-ML.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Sanli Tang",
      "Zhongyu Zhang",
      "Zhanzhan Cheng",
      "Jing Lu",
      "Yunlu Xu",
      "Yi Niu",
      "Fan He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09022"
  },
  {
    "id": "arXiv:2210.09026",
    "title": "WILD-SCAV: Benchmarking FPS Gaming AI on Unity3D-based Environments",
    "abstract": "Recent advances in deep reinforcement learning (RL) have demonstrated complex\ndecision-making capabilities in simulation environments such as Arcade Learning\nEnvironment, MuJoCo, and ViZDoom. However, they are hardly extensible to more\ncomplicated problems, mainly due to the lack of complexity and variations in\nthe environments they are trained and tested on. Furthermore, they are not\nextensible to an open-world environment to facilitate long-term exploration\nresearch. To learn realistic task-solving capabilities, we need to develop an\nenvironment with greater diversity and complexity. We developed WILD-SCAV, a\npowerful and extensible environment based on a 3D open-world FPS (First-Person\nShooter) game to bridge the gap. It provides realistic 3D environments of\nvariable complexity, various tasks, and multiple modes of interaction, where\nagents can learn to perceive 3D environments, navigate and plan, compete and\ncooperate in a human-like manner. WILD-SCAV also supports different\ncomplexities, such as configurable maps with different terrains, building\nstructures and distributions, and multi-agent settings with cooperative and\ncompetitive tasks. The experimental results on configurable complexity,\nmulti-tasking, and multi-agent scenarios demonstrate the effectiveness of\nWILD-SCAV in benchmarking various RL algorithms, as well as it is potential to\ngive rise to intelligent agents with generalized task-solving abilities. The\nlink to our open-sourced code can be found here\nhttps://github.com/inspirai/wilderness-scavenger.",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Tianyu Shi",
      "Qingpeng Zhao",
      "Yuchen Sun",
      "Yunfei Gao",
      "Xiangjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09026"
  },
  {
    "id": "arXiv:2210.09028",
    "title": "Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2",
    "abstract": "Did you know that over 70 million of Dota2 players have their in-game data\nfreely accessible? What if such data is used in malicious ways? This paper is\nthe first to investigate such a problem.\nMotivated by the widespread popularity of video games, we propose the first\nthreat model for Attribute Inference Attacks (AIA) in the Dota2 context. We\nexplain how (and why) attackers can exploit the abundant public data in the\nDota2 ecosystem to infer private information about its players. Due to lack of\nconcrete evidence on the efficacy of our AIA, we empirically prove and assess\ntheir impact in reality. By conducting an extensive survey on $\\sim$500 Dota2\nplayers spanning over 26k matches, we verify whether a correlation exists\nbetween a player's Dota2 activity and their real-life. Then, after finding such\na link ($p\\!<\\!0.01$ and $\\rho>0.3$), we ethically perform diverse AIA. We\nleverage the capabilities of machine learning to infer real-life attributes of\nthe respondents of our survey by using their publicly available in-game data.\nOur results show that, by applying domain expertise, some AIA can reach up to\n98% precision and over 90% accuracy. This paper hence raises the alarm on a\nsubtle, but concrete threat that can potentially affect the entire competitive\ngaming landscape. We alerted the developers of Dota2.",
    "descriptor": "",
    "authors": [
      "Pier Paolo Tricomi",
      "Lisa Facciolo",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09028"
  },
  {
    "id": "arXiv:2210.09034",
    "title": "Analysing Donors' Behaviour in Non-profit Organisations for Disaster  Resilience: The 2019--2020 Australian Bushfires Case Study",
    "abstract": "With the advancement and proliferation of technology, non-profit\norganisations have embraced social media platforms to improve their operational\ncapabilities through brand advocacy, among many other strategies. The effect of\nsuch social media campaigns on these institutions, however, remains largely\nunderexplored, especially during disaster periods. This work introduces and\napplies a quantitative investigative framework to understand how social media\ninfluence the behaviour of donors and their usage of these platforms throughout\n(natural) disasters. More specifically, we explore how on-line engagement -- as\ncaptured by Facebook interactions and Google search trends -- corresponds to\nthe donors' behaviour during the catastrophic 2019--2020 Australian bushfire\nseason. To discover this relationship, we analyse the record of donations made\nto the Australian Red Cross throughout this period. Our exploratory study\nreveals that social media campaigns are effective in encouraging on-line\ndonations made via a dedicated website. We also compare this mode of giving to\nmore regular, direct deposit gifting.",
    "descriptor": "",
    "authors": [
      "Dilini Rajapaksha",
      "Kacper Sokol",
      "Jeffrey Chan",
      "Flora Salim",
      "Mukesh Prasad",
      "Mahendra Samarawickrama"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09034"
  },
  {
    "id": "arXiv:2210.09037",
    "title": "Hyper-differential sensitivity analysis with respect to model  discrepancy: mathematics and computation",
    "abstract": "Model discrepancy (the difference between model predictions and reality) is\nubiquitous in computational models for physical systems. It is common to derive\npartial differential equations (PDEs) from first principles physics, but make\nsimplifying assumptions to produce tractable expressions for the governing\nequations or closure models. These PDEs are then used for analysis and design\nto achieve desirable performance. The end goal in many such cases is solving a\nPDE-constrained optimization (PDECO) problem. This article considers the\nsensitivity of PDECO problems with respect to model discrepancy. We introduce a\ngeneral representation of discrepancy and apply post-optimality sensitivity\nanalysis to derive an expression for the sensitivity of the optimal solution\nwith respect to it. An efficient algorithm is presented which combines the PDE\ndiscretization, post-optimality sensitivity operator, adjoint-based\nderivatives, and a randomized generalized singular value decomposition to\nenable scalable computation of the sensitivity of the optimal solution with\nrespect to model discrepancy. Kronecker product structure in the underlying\nlinear algebra and infrastructure investment in PDECO is exploited to yield a\ngeneral purpose algorithm which is computationally efficient and portable\nacross applications. Known physics and problem specific characteristics of\ndiscrepancy are imposed softly through user specified weighting matrices. We\ndemonstrate our proposed framework on two nonlinear PDECO problems to highlight\nits computational efficiency and rich insight.",
    "descriptor": "",
    "authors": [
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09037"
  },
  {
    "id": "arXiv:2210.09039",
    "title": "Research Data Management and Services in South Asian Academic Libraries",
    "abstract": "The study examined the research data management and related services offered\nby South Asian countries' academic libraries. Research applied quantitative\napproach and survey research design method were used for this study. The survey\nquestionnaire was distributed randomly to academic library professionals in\nfive countries: Afghanistan, Bangladesh, India, Pakistan, and Sri Lanka. The\nsample population comprised 67 library professionals from various institutes of\nfive countries. The study recommends that institutes or funding organizations\nsupport staff to attend conferences and workshops on research data management,\nlibrary professionals have to join MOOC to take courses related to research\ndata services, Institute or professionals conduct in-house staff workshops and\npresentations. The study also found that 64.2 per cent agreed compliance with\nfunder requirements and preservation are major issues.",
    "descriptor": "",
    "authors": [
      "Jahnavi Yidavalapati",
      "Priyanka Sinha",
      "Subaveerapandiyan A"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09039"
  },
  {
    "id": "arXiv:2210.09041",
    "title": "Approximation analysis of CNNs from feature extraction view",
    "abstract": "Deep learning based on deep neural networks has been very successful in many\npractical applications, but it lacks enough theoretical understanding due to\nthe network architectures and structures. In this paper, we establish the\nanalysis for linear feature extraction by deep multi-channel convolutional\nneural networks(CNNs), which demonstrates the power of deep learning over\ntraditional linear transformations, like Fourier, Wavelets, and Redundant\ndictionary coding methods. Moreover, we give an exact construction presenting\nhow linear features extraction can be conducted efficiently with multi-channel\nCNNs. It can be applied to lower the essential dimension for approximating a\nhigh-dimensional function. Rates of function approximation by such deep\nnetworks implemented with channels and followed by fully-connected layers are\ninvestigated as well. Harmonic analysis for factorizing linear features into\nmulti-resolution convolutions plays an essential role in our work.\nNevertheless, a dedicate vectorization of matrices is constructed, which\nbridges 1D CNN and 2D CNN and allows us have corresponding 2D analysis.",
    "descriptor": "",
    "authors": [
      "Han Feng",
      "Jianfei Li",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.09041"
  },
  {
    "id": "arXiv:2210.09043",
    "title": "ST-former for short-term passenger flow prediction during COVID-19 in  urban rail transit system",
    "abstract": "Accurate passenger flow prediction of urban rail transit is essential for\nimproving the performance of intelligent transportation systems, especially\nduring the epidemic. How to dynamically model the complex spatiotemporal\ndependencies of passenger flow is the main issue in achieving accurate\npassenger flow prediction during the epidemic. To solve this issue, this paper\nproposes a brand-new transformer-based architecture called STformer under the\nencoder-decoder framework specifically for COVID-19. Concretely, we develop a\nmodified self-attention mechanism named Causal-Convolution ProbSparse\nSelf-Attention (CPSA) to model the multiple temporal dependencies of passenger\nflow with low computational costs. To capture the complex and dynamic spatial\ndependencies, we introduce a novel Adaptive Multi-Graph Convolution Network\n(AMGCN) by leveraging multiple graphs in a self-adaptive manner. Additionally,\nthe Multi-source Data Fusion block fuses the passenger flow data, COVID-19\nconfirmed case data, and the relevant social media data to study the impact of\nCOVID-19 to passenger flow. Experiments on real-world passenger flow datasets\ndemonstrate the superiority of ST-former over the other eleven state-of-the-art\nmethods. Several ablation studies are carried out to verify the effectiveness\nand reliability of our model structure. Results can provide critical insights\nfor the operation of URT systems.",
    "descriptor": "\nComments: 18 pages, 18 figures\n",
    "authors": [
      "Shuxin Zhang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Chengcheng Wang",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09043"
  },
  {
    "id": "arXiv:2210.09044",
    "title": "Hyper-differential sensitivity analysis with respect to model  discrepancy: Calibration and optimal solution updating",
    "abstract": "Optimization constrained by computational models is common across science and\nengineering. However, in many cases a high-fidelity model of the system cannot\nbe optimized due to its complexity and computational cost. Rather, a\nlow(er)-fidelity model is constructed to enable intrusive and many query\nalgorithms needed for large-scale optimization. As a result of the discrepancy\nbetween the high and low-fidelity models, the optimal solution determined using\nthe low-fidelity model is frequently far from true optimality. In this article\nwe introduce a novel approach which uses limited high-fidelity data to\ncalibrate the model discrepancy in a Bayesian framework and propagate it\nthrough the optimization problem. The result provides both an improvement in\nthe optimal solution and a characterization of uncertainty due to the limited\naccessibility of high-fidelity data. Our formulation exploits structure in the\npost-optimality sensitivity operator to ensure computational scalability.\nNumerical results demonstrate how an optimal solution computed using a\nlow-fidelity model may be significantly improved with as little as one\nevaluation of a high-fidelity model.",
    "descriptor": "",
    "authors": [
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09044"
  },
  {
    "id": "arXiv:2210.09045",
    "title": "Natural Scene Image Annotation Using Local Semantic Concepts and Spatial  Bag of Visual Words",
    "abstract": "The use of bag of visual words (BOW) model for modelling images based on\nlocal invariant features computed at interest point locations has become a\nstandard choice for many computer vision tasks. Visual vocabularies generated\nfrom image feature vectors are expected to produce visual words that are\ndiscriminative to improve the performance of image annotation systems. Most\ntechniques that adopt the BOW model in annotating images declined favorable\ninformation that can be mined from image categories to build discriminative\nvisual vocabularies. To this end, this paper introduces a detailed framework\nfor automatically annotating natural scene images with local semantic labels\nfrom a predefined vocabulary. The framework is based on a hypothesis that\nassumes that, in natural scenes, intermediate semantic concepts are correlated\nwith the local keypoints. Based on this hypothesis, image regions can be\nefficiently represented by BOW model and using a machine learning approach,\nsuch as SVM, to label image regions with semantic annotations. Another\nobjective of this paper is to address the implications of generating visual\nvocabularies from image halves, instead of producing them from the whole image,\non the performance of annotating image regions with semantic labels. All\nBOW-based approaches as well as baseline methods have been extensively\nevaluated on 6-categories dataset of natural scenes using the SVM and KNN\nclassifiers. The reported results have shown the plausibility of using the BOW\nmodel to represent the semantic information of image regions and thus to\nautomatically annotate image regions with labels.",
    "descriptor": "",
    "authors": [
      "Yousef Alqasrawi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09045"
  },
  {
    "id": "arXiv:2210.09049",
    "title": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition",
    "abstract": "Few-shot Named Entity Recognition (NER) aims to identify named entities with\nvery little annotated data. Previous methods solve this problem based on\ntoken-wise classification, which ignores the information of entity boundaries,\nand inevitably the performance is affected by the massive non-entity tokens. To\nthis end, we propose a seminal span-based prototypical network (SpanProto) that\ntackles few-shot NER via a two-stage approach, including span extraction and\nmention classification. In the span extraction stage, we transform the\nsequential tags into a global boundary matrix, enabling the model to focus on\nthe explicit boundary information. For mention classification, we leverage\nprototypical learning to capture the semantic representations for each labeled\nspan and make the model better adapt to novel-class entities. To further\nimprove the model performance, we split out the false positives generated by\nthe span extractor but not labeled in the current episode set, and then present\na margin-based loss to separate them from each prototype region. Experiments\nover multiple benchmarks demonstrate that our model outperforms strong\nbaselines by a large margin.",
    "descriptor": "\nComments: 11 pages, 5 figures. This paper has been accepted for the main conference of EMNLP2022 (long paper)\n",
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Songfang Huang",
      "Jun Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09049"
  },
  {
    "id": "arXiv:2210.09052",
    "title": "Digital Image Forensics using Deep Learning",
    "abstract": "During the investigation of criminal activity when evidence is available, the\nissue at hand is determining the credibility of the video and ascertaining that\nthe video is real. Today, one way to authenticate the footage is to identify\nthe camera that was used to capture the image or video in question. While a\nvery common way to do this is by using image meta-data, this data can easily be\nfalsified by changing the video content or even splicing together content from\ntwo different cameras. Given the multitude of solutions proposed to this\nproblem, it is yet to be sufficiently solved. The aim of our project is to\nbuild an algorithm that identifies which camera was used to capture an image\nusing traces of information left intrinsically in the image, using filters,\nfollowed by a deep neural network on these filters. Solving this problem would\nhave a big impact on the verification of evidence used in criminal and civil\ntrials and even news reporting.",
    "descriptor": "\nComments: This paper was written in 2018 as a part of our submission to the 2018 IEEE Signal Processing Cup: Forensic Camera Model Identification Challenge\n",
    "authors": [
      "Akash Nagaraj",
      "Mukund Sood",
      "Vivek Kapoor",
      "Yash Mathur",
      "Bishesh Sinha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.09052"
  },
  {
    "id": "arXiv:2210.09053",
    "title": "Cross-domain Variational Capsules for Information Extraction",
    "abstract": "In this paper, we present a characteristic extraction algorithm and the\nMulti-domain Image Characteristics Dataset of characteristic-tagged images to\nsimulate the way a human brain classifies cross-domain information and\ngenerates insight. The intent was to identify prominent characteristics in data\nand use this identification mechanism to auto-generate insight from data in\nother unseen domains. An information extraction algorithm is proposed which is\na combination of Variational Autoencoders (VAEs) and Capsule Networks. Capsule\nNetworks are used to decompose images into their individual features and VAEs\nare used to explore variations on these decomposed features. Thus, making the\nmodel robust in recognizing characteristics from variations of the data. A\nnoteworthy point is that the algorithm uses efficient hierarchical decoding of\ndata which helps in richer output interpretation. Noticing a dearth in the\nnumber of datasets that contain visible characteristics in images belonging to\nvarious domains, the Multi-domain Image Characteristics Dataset was created and\nmade publicly available. It consists of thousands of images across three\ndomains. This dataset was created with the intent of introducing a new\nbenchmark for fine-grained characteristic recognition tasks in the future.",
    "descriptor": "\nComments: This paper was originally written in 2020\n",
    "authors": [
      "Akash Nagaraj",
      "Akhil K",
      "Akshay Venkatesh",
      "Srikanth HR"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09053"
  },
  {
    "id": "arXiv:2210.09055",
    "title": "Data-driven multi-scale modeling and robust optimization of composite  structure with uncertainty quantification",
    "abstract": "It is important to accurately model materials' properties at lower length\nscales (micro-level) while translating the effects to the components and/or\nsystem level (macro-level) can significantly reduce the amount of\nexperimentation required to develop new technologies. Robustness analysis of\nfuel and structural performance for harsh environments (such as power uprated\nreactor systems or aerospace applications) using machine learning-based\nmulti-scale modeling and robust optimization under uncertainties are required.\nThe fiber and matrix material characteristics are potential sources of\nuncertainty at the microscale. The stacking sequence (angles of stacking and\nthickness of layers) of composite layers causes meso-scale uncertainties. It is\nalso possible for macro-scale uncertainties to arise from system properties,\nlike the load or the initial conditions. This chapter demonstrates advanced\ndata-driven methods and outlines the specific capability that must be\ndeveloped/added for the multi-scale modeling of advanced composite materials.\nThis chapter proposes a multi-scale modeling method for composite structures\nbased on a finite element method (FEM) simulation driven by surrogate\nmodels/emulators based on microstructurally informed meso-scale materials\nmodels to study the impact of operational parameters/uncertainties using\nmachine learning approaches. To ensure optimal composite materials, composite\nproperties are optimized with respect to initial materials volume fraction\nusing data-driven numerical algorithms.",
    "descriptor": "",
    "authors": [
      "Kazuma Kobayashi",
      "Shoaib Usman",
      "Carlos Castano",
      "Ayodeji Alajo",
      "Dinesh Kumar",
      "Syed Alam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09055"
  },
  {
    "id": "arXiv:2210.09059",
    "title": "Space Trusted Autonomy Readiness Levels",
    "abstract": "Technology Readiness Levels are a mainstay for organizations that fund,\ndevelop, test, acquire, or use technologies. Technology Readiness Levels\nprovide a standardized assessment of a technology's maturity and enable\nconsistent comparison among technologies. They inform decisions throughout a\ntechnology's development life cycle, from concept, through development, to use.\nA variety of alternative Readiness Levels have been developed, including\nAlgorithm Readiness Levels, Manufacturing Readiness Levels, Human Readiness\nLevels, Commercialization Readiness Levels, Machine Learning Readiness Levels,\nand Technology Commitment Levels. However, while Technology Readiness Levels\nhave been increasingly applied to emerging disciplines, there are unique\nchallenges to assessing the rapidly developing capabilities of autonomy. This\npaper adopts the moniker of Space Trusted Autonomy Readiness Levels to identify\na two-dimensional scale of readiness and trust appropriate for the special\nchallenges of assessing autonomy technologies that seek space use. It draws\ninspiration from other readiness levels' definitions, and from the rich field\nof trust and trustworthiness. The Space Trusted Autonomy Readiness Levels were\ndeveloped by a collaborative Space Trusted Autonomy subgroup, which was created\nfrom The Space Science and Technology Partnership Forum between the United\nStates Space Force, the National Aeronautics and Space Administration, and the\nNational Reconnaissance Office.",
    "descriptor": "",
    "authors": [
      "Kerianne L. Hobbs",
      "Joseph B. Lyons",
      "Martin S. Feather",
      "Benjamen P Bycroft",
      "Sean Phillips",
      "Michelle Simon",
      "Mark Harter",
      "Kenneth Costello",
      "Yuri Gawdiak",
      "Stephen Paine"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.09059"
  },
  {
    "id": "arXiv:2210.09060",
    "title": "An introduction to programming Physics-Informed Neural Network-based  computational solid mechanics",
    "abstract": "Physics-informed neural network (PINN) has recently gained increasing\ninterest in computational mechanics. In this work, we present a detailed\nintroduction to programming PINN-based computational solid mechanics. Besides,\ntwo prevailingly used physics-informed loss functions for PINN-based\ncomputational solid mechanics are summarised. Moreover, numerical examples\nranging from 1D to 3D solid problems are presented to show the performance of\nPINN-based computational solid mechanics. The programs are built via Python\ncoding language and TensorFlow library with step-by-step explanations. It is\nworth highlighting that PINN-based computational mechanics is easy to implement\nand can be extended for more challenging applications. This work aims to help\nthe researchers who are interested in the PINN-based solid mechanics solver to\nhave a clear insight into this emerging area. The programs for all the\nnumerical examples presented in this work are available on\nhttps://github.com/JinshuaiBai/PINN_Comp_Mech.",
    "descriptor": "\nComments: 24 pages, 13 figures are include in this manuscript. This work will be submitted to International Journal of Computational Methods\n",
    "authors": [
      "Jinshuai Bai",
      "Hyogu Jeong",
      "C. P. Batuwatta-Gamage",
      "Shusheng Xiao",
      "Qingxia Wang",
      "C.M. Rathnayaka",
      "Laith Alzubaidi",
      "Gui-Rong Liu",
      "Yuantong Gu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.09060"
  },
  {
    "id": "arXiv:2210.09071",
    "title": "Attention Attention Everywhere: Monocular Depth Prediction with Skip  Attention",
    "abstract": "Monocular Depth Estimation (MDE) aims to predict pixel-wise depth given a\nsingle RGB image. For both, the convolutional as well as the recent\nattention-based models, encoder-decoder-based architectures have been found to\nbe useful due to the simultaneous requirement of global context and pixel-level\nresolution. Typically, a skip connection module is used to fuse the encoder and\ndecoder features, which comprises of feature map concatenation followed by a\nconvolution operation. Inspired by the demonstrated benefits of attention in a\nmultitude of computer vision problems, we propose an attention-based fusion of\nencoder and decoder features. We pose MDE as a pixel query refinement problem,\nwhere coarsest-level encoder features are used to initialize pixel-level\nqueries, which are then refined to higher resolutions by the proposed Skip\nAttention Module (SAM). We formulate the prediction problem as ordinal\nregression over the bin centers that discretize the continuous depth range and\nintroduce a Bin Center Predictor (BCP) module that predicts bins at the\ncoarsest level using pixel queries. Apart from the benefit of image adaptive\ndepth binning, the proposed design helps learn improved depth embedding in\ninitial pixel queries via direct supervision from the ground truth. Extensive\nexperiments on the two canonical datasets, NYUV2 and KITTI, show that our\narchitecture outperforms the state-of-the-art by 5.3% and 3.9%, respectively,\nalong with an improved generalization performance by 9.4% on the SUNRGBD\ndataset. Code is available at https://github.com/ashutosh1807/PixelFormer.git.",
    "descriptor": "\nComments: Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Ashutosh Agarwal",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09071"
  },
  {
    "id": "arXiv:2210.09074",
    "title": "Reversing Image Signal Processors by Reverse Style Transferring",
    "abstract": "RAW image datasets are more suitable than the standard RGB image datasets for\nthe ill-posed inverse problems in low-level vision, but not common in the\nliterature. There are also a few studies to focus on mapping sRGB images to RAW\nformat. Mapping from sRGB to RAW format could be a relevant domain for reverse\nstyle transferring since the task is an ill-posed reversing problem. In this\nstudy, we seek an answer to the question: Can the ISP operations be modeled as\nthe style factor in an end-to-end learning pipeline? To investigate this idea,\nwe propose a novel architecture, namely RST-ISP-Net, for learning to reverse\nthe ISP operations with the help of adaptive feature normalization. We\nformulate this problem as a reverse style transferring and mostly follow the\npractice used in the prior work. We have participated in the AIM Reversed ISP\nchallenge with our proposed architecture. Results indicate that the idea of\nmodeling disruptive or modifying factors as style is still valid, but further\nimprovements are required to be competitive in such a challenge.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Furkan K\u0131nl\u0131",
      "Bar\u0131\u015f \u00d6zcan",
      "Furkan K\u0131ra\u00e7"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09074"
  },
  {
    "id": "arXiv:2210.09076",
    "title": "An Assessment of Safety-Based Driver Behavior Modeling in Microscopic  Simulation Utilizing Real-Time Vehicle Trajectories",
    "abstract": "Accurate representation of observed driving behavior is critical for\neffectively evaluating safety and performance interventions in simulation\nmodeling. In this study, we implement and evaluate a safety-based Optimal\nVelocity Model (OVM) to provide a high-fidelity replication of safety-critical\nbehavior in microscopic simulation and showcase its implications for\nsafety-focused assessments of traffic control strategies. A comprehensive\nsimulation model is created for the site of study in PTV VISSIM utilizing\ndetailed vehicle trajectory information extracted from real-time video\ninference, which are also used to calibrate the parameters of the safety-based\nOVM to replicate the observed driving behavior in the site of study. The\ncalibrated model is then incorporated as an external driver model that\novertakes VISSIM's default Wiedemann 74 model during simulated car-following\nepisodes. The results of the preliminary analysis show the significant\nimprovements achieved by using our model in replicating the existing safety\nconflicts observed at the site of the study. We then utilize this improved\nrepresentation of the status quo to assess the potential impact of different\nscenarios of signal control and speed limit enforcement in reducing those\nexisting conflicts by up to 23%. The results of this study showcase the\nconsiderable improvements that can be achieved by utilizing data-driven\ncar-following behavior modeling, and the workflow presented provides an\nend-to-end, scalable, automated, and generalizable approach for replicating the\nexisting driving behavior observed at a site of interest in microscopic\nsimulation by utilizing vehicle trajectories efficiently extracted via roadside\nvideo inference.",
    "descriptor": "",
    "authors": [
      "Awad Abdelhalim",
      "Montasir Abbas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09076"
  },
  {
    "id": "arXiv:2210.09078",
    "title": "Machine Learning Technique Predicting Video Streaming Views to Reduce  Cost of Cloud Services",
    "abstract": "Video streams tremendously occupied the highest portion of online traffic.\nMultiple versions of a video are created to fit the user's device\nspecifications. In cloud storage, Keeping all versions of frequently accessed\nvideo streams in the repository for the long term imposes a significant cost\npaid by video streaming providers. Generally, the popularity of a video changes\neach period of time, which means the number of views received by a video could\nbe dropped, thus, the video must be deleted from the repository. Therefore, in\nthis paper, we develop a method that predicts the popularity of each video\nstream in the repository in the next period. On the other hand, we propose an\nalgorithm that utilizes the predicted popularity of a video to compute the\nstorage cost, and then it decides whether the video will be kept or deleted\nfrom the cloud repository. The experiment results show a cost reduction of the\ncloud services by 15% compared to keeping all video streams.",
    "descriptor": "",
    "authors": [
      "Mahmoud Darwich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09078"
  },
  {
    "id": "arXiv:2210.09081",
    "title": "Asymptotic-Preserving Neural Networks for hyperbolic systems with  diffusive scaling",
    "abstract": "With the rapid advance of Machine Learning techniques and the deep increment\nof availability of scientific data, data-driven approaches have started to\nbecome progressively popular across science, causing a fundamental shift in the\nscientific method after proving to be powerful tools with a direct impact in\nmany areas of society. Nevertheless, when attempting to analyze the dynamics of\ncomplex multiscale systems, the usage of standard Deep Neural Networks (DNNs)\nand even standard Physics-Informed Neural Networks (PINNs) may lead to\nincorrect inferences and predictions, due to the presence of small scales\nleading to reduced or simplified models in the system that have to be applied\nconsistently during the learning process. In this Chapter, we will address\nthese issues in light of recent results obtained in the development of\nAsymptotic-Preserving Neural Networks (APNNs) for hyperbolic models with\ndiffusive scaling. Several numerical tests show how APNNs provide considerably\nbetter results with respect to the different scales of the problem when\ncompared with standard DNNs and PINNs, especially when analyzing scenarios in\nwhich only little and scattered information is available.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.12625\n",
    "authors": [
      "Giulia Bertaglia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09081"
  },
  {
    "id": "arXiv:2210.09082",
    "title": "A Solver-Free Framework for Scalable Learning in Neural ILP  Architectures",
    "abstract": "There is a recent focus on designing architectures that have an Integer\nLinear Programming (ILP) layer within a neural model (referred to as Neural ILP\nin this paper). Neural ILP architectures are suitable for pure reasoning tasks\nthat require data-driven constraint learning or for tasks requiring both\nperception (neural) and reasoning (ILP). A recent SOTA approach for end-to-end\ntraining of Neural ILP explicitly defines gradients through the ILP black box\n(Paulus et al. 2021) - this trains extremely slowly, owing to a call to the\nunderlying ILP solver for every training data point in a minibatch. In\nresponse, we present an alternative training strategy that is solver-free,\ni.e., does not call the ILP solver at all at training time. Neural ILP has a\nset of trainable hyperplanes (for cost and constraints in ILP), together\nrepresenting a polyhedron. Our key idea is that the training loss should impose\nthat the final polyhedron separates the positives (all constraints satisfied)\nfrom the negatives (at least one violated constraint or a suboptimal cost\nvalue), via a soft-margin formulation. While positive example(s) are provided\nas part of the training data, we devise novel techniques for generating\nnegative samples. Our solution is flexible enough to handle equality as well as\ninequality constraints. Experiments on several problems, both perceptual as\nwell as symbolic, which require learning the constraints of an ILP, show that\nour approach has superior performance and scales much better compared to purely\nneural baselines and other state-of-the-art models that require solver-based\ntraining. In particular, we are able to obtain excellent performance in 9 x 9\nsymbolic and visual sudoku, to which the other Neural ILP solver is not able to\nscale.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Yatin Nandwani",
      "Rishabh Ranjan",
      "Mausam",
      "Parag Singla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09082"
  },
  {
    "id": "arXiv:2210.09083",
    "title": "Nish: A Novel Negative Stimulated Hybrid Activation Function",
    "abstract": "Activation functions play a crucial role in the performance and stability of\nneural networks. In this study, we propose a novel non-monotonic activation\nfunction is called Negative Stimulated Hybrid Activation Function (Nish). It\nbehaves like a Rectified Linear Unit (ReLU) function for values greater than\nzero, and a sinus-sigmoidal function for values less than zero. The proposed\nfunction incorporates the sigmoid and sine wave, allowing new dynamics over\ntraditional ReLU activations. We evaluate robustness of the Nish for different\ncombinations of well-established architectures as well as recently proposed\nactivation functions using on various well-known benchmarks. The results\nindicate that the accuracy rates obtained by the proposed activation function\nare slightly higher than those obtained using the set of weights calculated by\nMish activation.",
    "descriptor": "\nComments: 9 pages, 2 figures, 2 tables\n",
    "authors": [
      "Yildiray Anaguna",
      "Sahin Isik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09083"
  },
  {
    "id": "arXiv:2210.09084",
    "title": "Multi-Agent Automated Machine Learning",
    "abstract": "In this paper, we propose multi-agent automated machine learning (MA2ML) with\nthe aim to effectively handle joint optimization of modules in automated\nmachine learning (AutoML). MA2ML takes each machine learning module, such as\ndata augmentation (AUG), neural architecture search (NAS), or hyper-parameters\n(HPO), as an agent and the final performance as the reward, to formulate a\nmulti-agent reinforcement learning problem. MA2ML explicitly assigns credit to\neach agent according to its marginal contribution to enhance cooperation among\nmodules, and incorporates off-policy learning to improve search efficiency.\nTheoretically, MA2ML guarantees monotonic improvement of joint optimization.\nExtensive experiments show that MA2ML yields the state-of-the-art top-1\naccuracy on ImageNet under constraints of computational cost, e.g.,\n$79.7\\%/80.5\\%$ with FLOPs fewer than 600M/800M. Extensive ablation studies\nverify the benefits of credit assignment and off-policy learning of MA2ML.",
    "descriptor": "",
    "authors": [
      "Zhaozhi Wang",
      "Kefan Su",
      "Jian Zhang",
      "Huizhu Jia",
      "Qixiang Ye",
      "Xiaodong Xie",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09084"
  },
  {
    "id": "arXiv:2210.09086",
    "title": "Artificial Intelligence Nomenclature Identified From Delphi Study on Key  Issues Related to Trust and Barriers to Adoption for Autonomous Systems",
    "abstract": "The rapid integration of artificial intelligence across traditional research\ndomains has generated an amalgamation of nomenclature. As cross-discipline\nteams work together on complex machine learning challenges, finding a consensus\nof basic definitions in the literature is a more fundamental problem. As a step\nin the Delphi process to define issues with trust and barriers to the adoption\nof autonomous systems, our study first collected and ranked the top concerns\nfrom a panel of international experts from the fields of engineering, computer\nscience, medicine, aerospace, and defence, with experience working with\nartificial intelligence. This document presents a summary of the literature\ndefinitions for nomenclature derived from expert feedback.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Thomas E. Doyle",
      "Victoria Tucci",
      "Calvin Zhu",
      "Yifei Zhang",
      "Basem Yassa",
      "Sajjad Rashidiani",
      "Md Asif Khan",
      "Reza Samavi",
      "Michael Noseworthy",
      "Steven Yule"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09086"
  },
  {
    "id": "arXiv:2210.09089",
    "title": "On uncertainty quantification of eigenpairs with higher multiplicity",
    "abstract": "We consider generalized operator eigenvalue problems in variational form with\nrandom perturbations in the bilinear forms. This setting is motivated by\nvariational forms of partial differential equations such as the diffusion\nequation or Maxwell's equations with random material laws, for example. The\nconsidered eigenpairs can be of higher but finite multiplicity. We investigate\nstochastic quantities of interest of the eigenpairs and discuss why, for\nmultiplicity greater than 1, only the stochastic properties of the eigenspaces\nare meaningful, but not the ones of individual eigenpairs. To that end, we\ncharacterize the Fr\\'echet derivatives of the eigenpairs with respect to the\nperturbation and provide a new linear characterization for eigenpairs of higher\nmultiplicity. As a side result, we prove local analyticity of the eigenspaces.\nBased on the Fr\\'echet derivatives of the eigenpairs we discuss a meaningful\nMonte Carlo sampling strategy for multiple eigenvalues and develop an\nuncertainty quantification perturbation approach. Numerical examples are\npresented to illustrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "J\u00fcrgen D\u00f6lz",
      "David Ebert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09089"
  },
  {
    "id": "arXiv:2210.09090",
    "title": "Modeling the Lighting in Scenes as Style for Auto White-Balance  Correction",
    "abstract": "Style may refer to different concepts (e.g. painting style, hairstyle,\ntexture, color, filter, etc.) depending on how the feature space is formed. In\nthis work, we propose a novel idea of interpreting the lighting in the single-\nand multi-illuminant scenes as the concept of style. To verify this idea, we\nintroduce an enhanced auto white-balance (AWB) method that models the lighting\nin single- and mixed-illuminant scenes as the style factor. Our AWB method does\nnot require any illumination estimation step, yet contains a network learning\nto generate the weighting maps of the images with different WB settings.\nProposed network utilizes the style information, extracted from the scene by a\nmulti-head style extraction module. AWB correction is completed after blending\nthese weighting maps and the scene. Experiments on single- and mixed-illuminant\ndatasets demonstrate that our proposed method achieves promising correction\nresults when compared to the recent works. This shows that the lighting in the\nscenes with multiple illuminations can be modeled by the concept of style.\nSource code and trained models are available on\nhttps://github.com/birdortyedi/lighting-as-style-awb-correction.",
    "descriptor": "\nComments: 11 pages, 5 figures, Accepted to WACV 2023\n",
    "authors": [
      "Furkan K\u0131nl\u0131",
      "Do\u011fa Y\u0131lmaz",
      "Bar\u0131\u015f \u00d6zcan",
      "Furkan K\u0131ra\u00e7"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09090"
  },
  {
    "id": "arXiv:2210.09099",
    "title": "Cutting-Splicing data augmentation: A novel technology for medical image  segmentation",
    "abstract": "Background: Medical images are more difficult to acquire and annotate than\nnatural images, which results in data augmentation technologies often being\nused in medical image segmentation tasks. Most data augmentation technologies\nused in medical segmentation were originally developed on natural images and do\nnot take into account the characteristic that the overall layout of medical\nimages is standard and fixed. Methods: Based on the characteristics of medical\nimages, we developed the cutting-splicing data augmentation (CS-DA) method, a\nnovel data augmentation technology for medical image segmentation. CS-DA\naugments the dataset by splicing different position components cut from\ndifferent original medical images into a new image. The characteristics of the\nmedical image result in the new image having the same layout as and similar\nappearance to the original image. Compared with classical data augmentation\ntechnologies, CS-DA is simpler and more robust. Moreover, CS-DA does not\nintroduce any noise or fake information into the newly created image. Results:\nTo explore the properties of CS-DA, many experiments are conducted on eight\ndiverse datasets. On the training dataset with the small sample size, CS-DA can\neffectively increase the performance of the segmentation model. When CS-DA is\nused together with classical data augmentation technologies, the performance of\nthe segmentation model can be further improved and is much better than that of\nCS-DA and classical data augmentation separately. We also explored the\ninfluence of the number of components, the position of the cutting line, and\nthe splicing method on the CS-DA performance. Conclusions: The excellent\nperformance of CS-DA in the experiment has confirmed the effectiveness of\nCS-DA, and provides a new data augmentation idea for the small sample\nsegmentation task.",
    "descriptor": "\nComments: 31 pages, 10 figures\n",
    "authors": [
      "Lianting Hu",
      "Huiying Liang",
      "Jiajie Tang",
      "Xin Li",
      "Li Huang",
      "Long Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09099"
  },
  {
    "id": "arXiv:2210.09100",
    "title": "Estimating the Cost of Executing Link Traversal based SPARQL Queries",
    "abstract": "An increasing number of organisations in almost all fields have started\nadopting semantic web technologies for publishing their data as open, linked\nand interoperable (RDF) datasets, queryable through the SPARQL language and\nprotocol. Link traversal has emerged as a SPARQL query processing method that\nexploits the Linked Data principles and the dynamic nature of the Web to\ndynamically discover data relevant for answering a query by resolving online\nresources (URIs) during query evaluation. However, the execution time of link\ntraversal queries can become prohibitively high for certain query types due to\nthe high number of resources that need to be accessed during query execution.\nIn this paper we propose and evaluate baseline methods for estimating the\nevaluation cost of link traversal queries. Such methods can be very useful for\ndeciding on-the-fly the query execution strategy to follow for a given query,\nthereby reducing the load of a SPARQL endpoint and increasing the overall\nreliability of the query service. To evaluate the performance of the proposed\nmethods, we have created (and make publicly available) a ground truth dataset\nconsisting of 2,425 queries.",
    "descriptor": "",
    "authors": [
      "Antonis Sklavos",
      "Pavlos Fafalios",
      "Yannis Tzitzikas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.09100"
  },
  {
    "id": "arXiv:2210.09107",
    "title": "ISEE.U: Distributed online active target localization with unpredictable  targets",
    "abstract": "This paper addresses target localization with an online active learning\nalgorithm defined by distributed, simple and fast computations at each node,\nwith no parameters to tune and where the estimate of the target position at\neach agent is asymptotically equal in expectation to the centralized\nmaximum-likelihood estimator. ISEE.U takes noisy distances at each agent and\nfinds a control that maximizes localization accuracy. We do not assume specific\ntarget dynamics and, thus, our method is robust when facing unpredictable\ntargets. Each agent computes the control that maximizes overall target position\naccuracy via a local estimate of the Fisher Information Matrix. We compared the\nproposed method with a state of the art algorithm outperforming it when the\ntarget movements do not follow a prescribed trajectory, with x100 less\ncomputation time, even when our method is running in one central CPU.",
    "descriptor": "",
    "authors": [
      "Miguel Vasques",
      "Claudia Soares",
      "Jo\u00e3o Gomes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09107"
  },
  {
    "id": "arXiv:2210.09108",
    "title": "Detect and Classify IoT Camera Traffic",
    "abstract": "Deployment of IoT cameras in an organization threatens security and privacy\npolicies, and the classification of network traffic without using IP addresses\nand port numbers has been challenging. In this paper, we have designed,\nimplemented and deployed a system called iCamInspector to classify network\ntraffic arising from IoT camera in a mixed networking environment. We have\ncollected a total of about 36GB of network traffic containing video data from\nthree different types of applications (four online audio/video conferencing\napplications, two video sharing applications and six IoT camera from different\nmanufacturers) in our IoT laboratory. We show that with the help of a limited\nnumber of flow-based features, iCamInspector achieves an average accuracy of\nmore than 98% in a 10-fold cross-validation with a false rate of about 1.5% in\ntesting phase of the system. A real deployment of our system in an unseen\nenvironment achieves a commendable performance of detecting IoT camera with an\naverage detection probability higher than 0.9.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Priyanka Rushikesh Chaudhary",
      "Rajib Ranjan Maiti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09108"
  },
  {
    "id": "arXiv:2210.09112",
    "title": "Reconstructing a space-dependent source term via the quasi-reversibility  method",
    "abstract": "The aim of this paper is to solve an important inverse source problem which\narises from the well-known inverse scattering problem. We propose to truncate\nthe Fourier series of the solution to the governing equation with respect to a\nspecial basis of L2. By this, we obtain a system of linear elliptic equations.\nSolutions to this system are the Fourier coefficients of the solution to the\ngoverning equation. After computing these Fourier coefficients, we can directly\nfind the desired source function. Numerical examples are presented.",
    "descriptor": "",
    "authors": [
      "Loc H. Nguyen",
      "Huong T. Vu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.09112"
  },
  {
    "id": "arXiv:2210.09114",
    "title": "INSANE: Cross-Domain UAV Data Sets with Increased Number of Sensors for  developing Advanced and Novel Estimators",
    "abstract": "For real-world applications, autonomous mobile robotic platforms must be\ncapable of navigating safely in a multitude of different and dynamic\nenvironments with accurate and robust localization being a key prerequisite. To\nsupport further research in this domain, we present the INSANE data sets - a\ncollection of versatile Micro Aerial Vehicle (MAV) data sets for\ncross-environment localization. The data sets provide various scenarios with\nmultiple stages of difficulty for localization methods. These scenarios range\nfrom trajectories in the controlled environment of an indoor motion capture\nfacility, to experiments where the vehicle performs an outdoor maneuver and\ntransitions into a building, requiring changes of sensor modalities, up to\npurely outdoor flight maneuvers in a challenging Mars analog environment to\nsimulate scenarios which current and future Mars helicopters would need to\nperform. The presented work aims to provide data that reflects real-world\nscenarios and sensor effects. The extensive sensor suite includes various\nsensor categories, including multiple Inertial Measurement Units (IMUs) and\ncameras. Sensor data is made available as raw measurements and each data set\nprovides highly accurate ground truth, including the outdoor experiments where\na dual Real-Time Kinematic (RTK) Global Navigation Satellite System (GNSS)\nsetup provides sub-degree and centimeter accuracy (1-sigma). The sensor suite\nalso includes a dedicated high-rate IMU to capture all the vibration dynamics\nof the vehicle during flight to support research on novel machine\nlearning-based sensor signal enhancement methods for improved localization. The\ndata sets and post-processing tools are available at:\nhttps://sst.aau.at/cns/datasets",
    "descriptor": "",
    "authors": [
      "Christian Brommer",
      "Alessandro Fornasier",
      "Martin Scheiber",
      "Jeff Delaune",
      "Roland Brockers",
      "Jan Steinbrener",
      "Stephan Weiss"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09114"
  },
  {
    "id": "arXiv:2210.09125",
    "title": "Stable Discrete Minimization of Conformal Energy for Disk Conformal  Parameterization",
    "abstract": "Conformal energy minimization is an efficient approach to compute conformal\nparameterization. In this paper, we develop a stable algorithm to compute\nconformal parameterization of simply connected open surface, termed Stable\nDiscrete Minimization of Conformal Energy (SDMCE). The stability of SDMCE is\nreflected in the guarantee of one-to-one and on-to property of computed\nparameterization and the insensitivity on the initial value. On one hand, SDMCE\ncan avoid degeneration and overlap of solution, also, SDMCE is folding free. On\nthe other hand, even if given poor initial value, it can still correct it in\nvery little computational time. The numerical experiments indicate SDMCE is\nstable and competitive with state-of-the-art algorithms in efficiency.",
    "descriptor": "",
    "authors": [
      "Zhong-Heng Tan",
      "Zhenyue Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09125"
  },
  {
    "id": "arXiv:2210.09126",
    "title": "Verifiable and Provably Secure Machine Unlearning",
    "abstract": "Machine unlearning aims to remove points from the training dataset of a\nmachine learning model after training; for example when a user requests their\ndata to be deleted. While many machine unlearning methods have been proposed,\nnone of them enable users to audit the unlearning procedure and verify that\ntheir data was indeed unlearned. To address this, we define the first\ncryptographic framework to formally capture the security of verifiable machine\nunlearning. While our framework is generally applicable to different\napproaches, its advantages are perhaps best illustrated by our instantiation\nfor the canonical approach to unlearning: retraining the model without the data\nto be unlearned. In our cryptographic protocol, the server first computes a\nproof that the model was trained on a dataset~$D$. Given a user data point $d$,\nthe server then computes a proof of unlearning that shows that $d \\notin D$. We\nrealize our protocol using a SNARK and Merkle trees to obtain proofs of update\nand unlearning on the data. Based on cryptographic assumptions, we then present\na formal game-based proof that our instantiation is secure. Finally, we\nvalidate the practicality of our constructions for unlearning in linear\nregression, logistic regression, and neural networks.",
    "descriptor": "",
    "authors": [
      "Thorsten Eisenhofer",
      "Doreen Riepel",
      "Varun Chandrasekaran",
      "Esha Ghosh",
      "Olga Ohrimenko",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09126"
  },
  {
    "id": "arXiv:2210.09128",
    "title": "Sparse Kronecker Product Decomposition: A General Framework of Signal  Region Detection in Image Regression",
    "abstract": "This paper aims to present the first Frequentist framework on signal region\ndetection in high-resolution and high-order image regression problems. Image\ndata and scalar-on-image regression are intensively studied in recent years.\nHowever, most existing studies on such topics focused on outcome prediction,\nwhile the research on image region detection is rather limited, even though the\nlatter is often more important. In this paper, we develop a general framework\nnamed Sparse Kronecker Product Decomposition (SKPD) to tackle this issue. The\nSKPD framework is general in the sense that it works for both matrices (e.g.,\n2D grayscale images) and (high-order) tensors (e.g., 2D colored images, brain\nMRI/fMRI data) represented image data. Moreover, unlike many Bayesian\napproaches, our framework is computationally scalable for high-resolution image\nproblems. Specifically, our framework includes: 1) the one-term SKPD; 2) the\nmulti-term SKPD; and 3) the nonlinear SKPD. We propose nonconvex optimization\nproblems to estimate the one-term and multi-term SKPDs and develop\npath-following algorithms for the nonconvex optimization. The computed\nsolutions of the path-following algorithm are guaranteed to converge to the\ntruth with a particularly chosen initialization even though the optimization is\nnonconvex. Moreover, the region detection consistency could also be guaranteed\nby the one-term and multi-term SKPD. The nonlinear SKPD is highly connected to\nshallow convolutional neural networks (CNN), particular to CNN with one\nconvolutional layer and one fully connected layer. Effectiveness of SKPDs is\nvalidated by real brain imaging data in the UK Biobank database.",
    "descriptor": "",
    "authors": [
      "Sanyou Wu",
      "Long Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09128"
  },
  {
    "id": "arXiv:2210.09132",
    "title": "Pseudo-OOD training for robust language models",
    "abstract": "While pre-trained large-scale deep models have garnered attention as an\nimportant topic for many downstream natural language processing (NLP) tasks,\nsuch models often make unreliable predictions on out-of-distribution (OOD)\ninputs. As such, OOD detection is a key component of a reliable\nmachine-learning model for any industry-scale application. Common approaches\noften assume access to additional OOD samples during the training stage,\nhowever, outlier distribution is often unknown in advance. Instead, we propose\na post hoc framework called POORE - POsthoc pseudo-Ood REgularization, that\ngenerates pseudo-OOD samples using in-distribution (IND) data. The model is\nfine-tuned by introducing a new regularization loss that separates the\nembeddings of IND and OOD data, which leads to significant gains on the OOD\nprediction task during testing. We extensively evaluate our framework on three\nreal-world dialogue systems, achieving new state-of-the-art in OOD detection.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Dhanasekar Sundararaman",
      "Nikhil Mehta",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09132"
  },
  {
    "id": "arXiv:2210.09134",
    "title": "Principled Pruning of Bayesian Neural Networks through Variational Free  Energy Minimization",
    "abstract": "Bayesian model reduction provides an efficient approach for comparing the\nperformance of all nested sub-models of a model, without re-evaluating any of\nthese sub-models. Until now, Bayesian model reduction has been applied mainly\nin the computational neuroscience community. In this paper, we formulate and\napply Bayesian model reduction to perform principled pruning of Bayesian neural\nnetworks, based on variational free energy minimization. This novel parameter\npruning scheme solves the shortcomings of many current state-of-the-art pruning\nmethods that are used by the signal processing community. The proposed approach\nhas a clear stopping criterion and minimizes the same objective that is used\nduring training. Next to these theoretical benefits, our experiments indicate\nbetter model performance in comparison to state-of-the-art pruning schemes.",
    "descriptor": "",
    "authors": [
      "Jim Beckers",
      "Bart van Erp",
      "Ziyue Zhao",
      "Kirill Kondrashov",
      "Bert de Vries"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09134"
  },
  {
    "id": "arXiv:2210.09135",
    "title": "Gated Recurrent Unit for Video Denoising",
    "abstract": "Current video denoising methods perform temporal fusion by designing\nconvolutional neural networks (CNN) or combine spatial denoising with temporal\nfusion into basic recurrent neural networks (RNNs). However, there have not yet\nbeen works which adapt gated recurrent unit (GRU) mechanisms for video\ndenoising. In this letter, we propose a new video denoising model based on GRU,\nnamely GRU-VD. First, the reset gate is employed to mark the content related to\nthe current frame in the previous frame output. Then the hidden activation\nworks as an initial spatial-temporal denoising with the help from the marked\nrelevant content. Finally, the update gate recursively fuses the initial\ndenoised result with previous frame output to further increase accuracy. To\nhandle various light conditions adaptively, the noise standard deviation of the\ncurrent frame is also fed to these three modules. A weighted loss is adopted to\nregulate initial denoising and final fusion at the same time. The experimental\nresults show that the GRU-VD network not only can achieve better quality than\nstate of the arts objectively and subjectively, but also can obtain satisfied\nsubjective quality on real video.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Kai Guo",
      "Seungwon Choi",
      "Jongseong Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09135"
  },
  {
    "id": "arXiv:2210.09136",
    "title": "SA4U: Practical Static Analysis for Unit Type Error Detection",
    "abstract": "Unit type errors, where values with physical unit types (e.g., meters, hours)\nare used incorrectly in a computation, are common in today's unmanned aerial\nsystem (UAS) firmware. Recent studies show that unit type errors represent over\n10% of bugs in UAS firmware. Moreover, the consequences of unit type errors are\nsevere. Over 30% of unit type errors cause UAS crashes. This paper proposes\nSA4U: a practical system for detecting unit type errors in real-world UAS\nfirmware. SA4U requires no modifications to firmware or developer annotations.\nIt deduces the unit types of program variables by analyzing simulation traces\nand protocol definitions. SA4U uses the deduced unit types to identify when\nunit type errors occur. SA4U is effective: it identified 14 previously\nundetected bugs in two popular open-source firmware (ArduPilot & PX4.)",
    "descriptor": "\nComments: ASE 2022\n",
    "authors": [
      "Max Taylor",
      "Johnathon Aurand",
      "Feng Qin",
      "Xiaorui Wang",
      "Brandon Henry",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09136"
  },
  {
    "id": "arXiv:2210.09138",
    "title": "An Open-source Benchmark of Deep Learning Models for Audio-visual  Apparent and Self-reported Personality Recognition",
    "abstract": "Personality is crucial for understanding human internal and external states.\nThe majority of existing personality computing approaches suffer from complex\nand dataset-specific pre-processing steps and model training tricks. In the\nabsence of a standardized benchmark with consistent experimental settings, it\nis not only impossible to fairly compare the real performances of these\npersonality computing models but also makes them difficult to be reproduced. In\nthis paper, we present the first reproducible audio-visual benchmarking\nframework to provide a fair and consistent evaluation of eight existing\npersonality computing models (e.g., audio, visual and audio-visual) and seven\nstandard deep learning models on both self-reported and apparent personality\nrecognition tasks. We conduct a comprehensive investigation into all the\nbenchmarked models to demonstrate their capabilities in modelling personality\ntraits on two publicly available datasets, audio-visual apparent personality\n(ChaLearn First Impression) and self-reported personality (UDIVA) datasets. The\nexperimental results conclude: (i) apparent personality traits, inferred from\nfacial behaviours by most benchmarked deep learning models, show more\nreliability than self-reported ones; (ii) visual models frequently achieved\nsuperior performances than audio models on personality recognition; and (iii)\nnon-verbal behaviours contribute differently in predicting different\npersonality traits. We make the code publicly available at\nhttps://github.com/liaorongfan/DeepPersonality .",
    "descriptor": "",
    "authors": [
      "Rongfan Liao",
      "Siyang Song",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09138"
  },
  {
    "id": "arXiv:2210.09140",
    "title": "SmartProduct: a prototype platform for product monitoring-as-a-service,  leveraging IoT technologies and the EPCIS standard",
    "abstract": "Internet of Things (IoT) technologies have received significant attention in\nrecent years by encompassing a set of technologies that enable a variety of\nheterogeneous physical objects, called things, to interact and communicate\nthrough efficient networking protocols. These technologies have already been\nused in several domains such as in manufacturing, healthcare, agriculture, etc.\nAnother domain in which IoT can be applicable and useful, is that of supply\nchain tracing, where products are monitored throughout the whole supply chain.\nIoT data collection can enable the proliferation of applications, which are\nable to track environmental-related information per product (e.g. storage\nconditions), and combine them together with traceability data in order to\nprovide full product monitoring services.\nTraditional supply chain tracing methods (e.g. product tracing, storage\nconditions' monitoring, transport vehicles used, etc.) involve costly and\nerror-prone procedures, as human involvement is often required. Severe\nfragmentation is also possible, as the various stakeholders involved\n(producers, distributors, retailers), do not use interoperable technologies and\nstandards.\nTo overcome these limitations, we propose a flexible and secure prototype\nplatform that leverages IoT technologies, jointly with the Electronic Product\nCode Information Service (EPCIS) standard. The IoT software/hardware modules of\nthe platform are used to collect IoT data (i.e. geographical location, ambient\ntemperature, humidity, etc.), while the EPCIS-based software collects and\nrecords conventional supply chain traceability data (e.g. type of product\nmanufactured, product loaded/unloaded into/from a truck, product transformed to\nanother product, etc.). A rich RESTful API with strong\nauthentication/authorisation mechanisms is used to offer\nProduct-Monitoring-as-a-Service (PMaaS) to third-party applications.",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "Petros Zervoudakis",
      "Maria Plevraki",
      "Eleftheria Plevridi",
      "Alexandros Fragkiadakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09140"
  },
  {
    "id": "arXiv:2210.09147",
    "title": "PARTIME: Scalable and Parallel Processing Over Time with Deep Neural  Networks",
    "abstract": "In this paper, we present PARTIME, a software library written in Python and\nbased on PyTorch, designed specifically to speed up neural networks whenever\ndata is continuously streamed over time, for both learning and inference.\nExisting libraries are designed to exploit data-level parallelism, assuming\nthat samples are batched, a condition that is not naturally met in applications\nthat are based on streamed data. Differently, PARTIME starts processing each\ndata sample at the time in which it becomes available from the stream. PARTIME\nwraps the code that implements a feed-forward multi-layer network and it\ndistributes the layer-wise processing among multiple devices, such as Graphics\nProcessing Units (GPUs). Thanks to its pipeline-based computational scheme,\nPARTIME allows the devices to perform computations in parallel. At inference\ntime this results in scaling capabilities that are theoretically linear with\nrespect to the number of devices. During the learning stage, PARTIME can\nleverage the non-i.i.d. nature of the streamed data with samples that are\nsmoothly evolving over time for efficient gradient computations. Experiments\nare performed in order to empirically compare PARTIME with classic non-parallel\nneural computations in online learning, distributing operations on up to 8\nNVIDIA GPUs, showing significant speedups that are almost linear in the number\nof devices, mitigating the impact of the data transfer overhead.",
    "descriptor": "\nComments: 9 pages, accepted at International Conference on Machine Learning and Applications\n",
    "authors": [
      "Enrico Meloni",
      "Lapo Faggi",
      "Simone Marullo",
      "Alessandro Betti",
      "Matteo Tiezzi",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09147"
  },
  {
    "id": "arXiv:2210.09148",
    "title": "Pruning-based Topology Refinement of 3D Mesh using a 2D Alpha Mask",
    "abstract": "Image-based 3D reconstruction has increasingly stunning results over the past\nfew years with the latest improvements in computer vision and graphics.\nGeometry and topology are two fundamental concepts when dealing with 3D mesh\nstructures. But the latest often remains a side issue in the 3D mesh-based\nreconstruction literature. Indeed, performing per-vertex elementary\ndisplacements over a 3D sphere mesh only impacts its geometry and leaves the\ntopological structure unchanged and fixed. Whereas few attempts propose to\nupdate the geometry and the topology, all need to lean on costly 3D\nground-truth to determine the faces/edges to prune. We present in this work a\nmethod that aims to refine the topology of any 3D mesh through a face-pruning\nstrategy that extensively relies upon 2D alpha masks and camera pose\ninformation. Our solution leverages a differentiable renderer that renders each\nface as a 2D soft map. Its pixel intensity reflects the probability of being\ncovered during the rendering process by such a face. Based on the 2D soft-masks\navailable, our method is thus able to quickly highlight all the incorrectly\nrendered faces for a given viewpoint. Because our module is agnostic to the\nnetwork that produces the 3D mesh, it can be easily plugged into any\nself-supervised image-based (either synthetic or natural) 3D reconstruction\npipeline to get complex meshes with a non-spherical topology.",
    "descriptor": "\nComments: 11 pages ; published at ISVC,Oral - 2022\n",
    "authors": [
      "Ga\u00ebtan Landreau",
      "Mohamed Tamaazousti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09148"
  },
  {
    "id": "arXiv:2210.09150",
    "title": "Prompting GPT-3 To Be Reliable",
    "abstract": "Large language models (LLMs) show impressive abilities via few-shot\nprompting. Commercialized APIs such as OpenAI GPT-3 further increase their use\nin real-world language applications. However, existing research focuses on\nmodels' accuracy on standard benchmarks and largely ignores their reliability,\nwhich is crucial for avoiding catastrophic real-world harms. While reliability\nis a broad and vaguely defined term, this work decomposes reliability into four\nfacets: generalizability, fairness, calibration, and factuality. We establish\nsimple and effective prompts to demonstrate GPT-3's reliability in these four\naspects: 1) generalize out-of-domain, 2) balance demographic distribution to\nreduce social biases, 3) calibrate language model probabilities, and 4) update\nthe LLM's knowledge. We find that by employing appropriate prompts, GPT-3\noutperforms smaller-scale supervised models by large margins on all these\nfacets. We release all processed datasets, evaluation scripts, and model\npredictions to facilitate future analysis. Our findings not only shed new\ninsights on the reliability of prompting LLMs, but more importantly, our\nprompting strategies can help practitioners more reliably use large language\nmodels like GPT-3.",
    "descriptor": "\nComments: Preprint; Feedback is welcome\n",
    "authors": [
      "Chenglei Si",
      "Zhe Gan",
      "Zhengyuan Yang",
      "Shuohang Wang",
      "Jianfeng Wang",
      "Jordan Boyd-Graber",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09150"
  },
  {
    "id": "arXiv:2210.09151",
    "title": "Symbol Guided Hindsight Priors for Reward Learning from Human  Preferences",
    "abstract": "Specifying rewards for reinforcement learned (RL) agents is challenging.\nPreference-based RL (PbRL) mitigates these challenges by inferring a reward\nfrom feedback over sets of trajectories. However, the effectiveness of PbRL is\nlimited by the amount of feedback needed to reliably recover the structure of\nthe target reward. We present the PRIor Over Rewards (PRIOR) framework, which\nincorporates priors about the structure of the reward function and the\npreference feedback into the reward learning process. Imposing these priors as\nsoft constraints on the reward learning objective reduces the amount of\nfeedback required by half and improves overall reward recovery. Additionally,\nwe demonstrate that using an abstract state space for the computation of the\npriors further improves the reward learning and the agent's performance.",
    "descriptor": "",
    "authors": [
      "Mudit Verma",
      "Katherine Metcalf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09151"
  },
  {
    "id": "arXiv:2210.09153",
    "title": "Face Pasting Attack",
    "abstract": "Cujo AI and Adversa AI hosted the MLSec face recognition challenge. The goal\nwas to attack a black box face recognition model with targeted attacks. The\nmodel returned the confidence of the target class and a stealthiness score. For\nan attack to be considered successful the target class has to have the highest\nconfidence among all classes and the stealthiness has to be at least 0.5. In\nour approach we paste the face of a target into a source image. By utilizing\nposition, scaling, rotation and transparency attributes we reached 3rd place.\nOur approach took approximately 200 queries per attack for the final highest\nscore and about ~7.7 queries minimum for a successful attack. The code is\navailable at https://github.com/bunni90/ FacePastingAttack",
    "descriptor": "",
    "authors": [
      "Niklas Bunzel",
      "Lukas Graner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09153"
  },
  {
    "id": "arXiv:2210.09162",
    "title": "Table-To-Text generation and pre-training with TabT5",
    "abstract": "Encoder-only transformer models have been successfully applied to different\ntable understanding tasks, as in TAPAS (Herzig et al., 2020). A major\nlimitation of these architectures is that they are constrained to\nclassification-like tasks such as cell selection or entailment detection. We\npresent TABT5, an encoder-decoder model that generates natural language text\nbased on tables and textual inputs. TABT5 overcomes the encoder-only limitation\nby incorporating a decoder component and leverages the input structure with\ntable specific embeddings and pre-training. TABT5 achieves new state-of-the-art\nresults on several domains, including spreadsheet formula prediction with a 15%\nincrease in sequence accuracy, QA with a 2.5% increase in sequence accuracy and\ndata-to-text generation with a 2.5% increase in BLEU.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Ewa Andrejczuk",
      "Julian Martin Eisenschlos",
      "Francesco Piccinno",
      "Syrine Krichene",
      "Yasemin Altun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09162"
  },
  {
    "id": "arXiv:2210.09163",
    "title": "KPI-EDGAR: A Novel Dataset and Accompanying Metric for Relation  Extraction from Financial Documents",
    "abstract": "We introduce KPI-EDGAR, a novel dataset for Joint Named Entity Recognition\nand Relation Extraction building on financial reports uploaded to the\nElectronic Data Gathering, Analysis, and Retrieval (EDGAR) system, where the\nmain objective is to extract Key Performance Indicators (KPIs) from financial\ndocuments and link them to their numerical values and other attributes. We\nfurther provide four accompanying baselines for benchmarking potential future\nresearch. Additionally, we propose a new way of measuring the success of said\nextraction process by incorporating a word-level weighting scheme into the\nconventional F1 score to better model the inherently fuzzy borders of the\nentity pairs of a relation in this domain.",
    "descriptor": "\nComments: Accepted at ICMLA 2022, 6 pages, 5 tables\n",
    "authors": [
      "Tobias Deu\u00dfer",
      "Syed Musharraf Ali",
      "Lars Hillebrand",
      "Desiana Nurchalifah",
      "Basil Jacob",
      "Christian Bauckhage",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09163"
  },
  {
    "id": "arXiv:2210.09167",
    "title": "How do we get there? Evaluating transformer neural networks as cognitive  models for English past tense inflection",
    "abstract": "There is an ongoing debate on whether neural networks can grasp the\nquasi-regularities in languages like humans. In a typical quasi-regularity\ntask, English past tense inflections, the neural network model has long been\ncriticized that it learns only to generalize the most frequent pattern, but not\nthe regular pattern, thus can not learn the abstract categories of regular and\nirregular and is dissimilar to human performance. In this work, we train a set\nof transformer models with different settings to examine their behavior on this\ntask. The models achieved high accuracy on unseen regular verbs and some\naccuracy on unseen irregular verbs. The models' performance on the regulars is\nheavily affected by type frequency and ratio but not token frequency and ratio,\nand vice versa for the irregulars. The different behaviors on the regulars and\nirregulars suggest that the models have some degree of symbolic learning on the\nregularity of the verbs. In addition, the models are weakly correlated with\nhuman behavior on nonce verbs. Although the transformer model exhibits some\nlevel of learning on the abstract category of verb regularity, its performance\ndoes not fit human data well, suggesting that it might not be a good cognitive\nmodel.",
    "descriptor": "\nComments: AACL-IJCNLP 2022 camera-ready\n",
    "authors": [
      "Xiaomeng Ma",
      "Lingyu Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09167"
  },
  {
    "id": "arXiv:2210.09168",
    "title": "Fast Gaussian Process Predictions on Large Geospatial Fields with  Prediction-Point Dependent Basis Functions",
    "abstract": "In order to perform GP predictions fast in large geospatial fields with\nsmall-scale variations, a computational complexity that is independent of the\nnumber of measurements $N$ and the size of the field is crucial. In this\nsetting, GP approximations using $m$ basis functions requires\n$\\mathcal{O}(Nm^2+m^3)$ computations. Using finite-support basis functions\nreduces the required number of computations to perform a single prediction to\n$\\mathcal{O}(m^3)$, after a one-time training cost of $O(N)$. The prediction\ncost increases with increasing field size, as the number of required basis\nfunctions $m$ grows with the size of the field relative to the size of the\nspatial variations. To prevent the prediction speed from depending on field\nsize, we propose leveraging the property that a subset of the trained system is\na trained subset of the system to use only a local subset of $m'\\ll m$\nfinite-support basis functions centered around each prediction point to perform\npredictions. Our proposed approximation requires $\\mathcal{O}(m'^3)$ operations\nto perform each prediction after a one-time training cost of $\\mathcal{O}(N)$.\nWe show on real-life spatial data that our approach matches the prediction\nerror of state-of-the-art methods and that it performs faster predictions, also\ncompared to state-of-the-art approximations that lower the prediction cost of\n$\\mathcal{O}(m^3)$ to $\\mathcal{O}(m\\log(m))$ using a conjugate gradient\nsolver. Finally, we demonstrate that our approach can perform fast predictions\non a global bathymetry dataset using millions of basis functions and tens of\nmillions of measurements on a laptop computer.",
    "descriptor": "",
    "authors": [
      "Frida Marie Viset",
      "Rudy Helmons",
      "Manon Kok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09168"
  },
  {
    "id": "arXiv:2210.09171",
    "title": "Data-driven Modeling of Mach-Zehnder Interferometer-based Optical Matrix  Multipliers",
    "abstract": "Photonic integrated circuits are facilitating the development of optical\nneural networks, which have the potential to be both faster and more energy\nefficient than their electronic counterparts since optical signals are\nespecially well-suited for implementing matrix multiplications. However,\naccurate programming of photonic chips for optical matrix multiplication\nremains a difficult challenge. Here, we describe both simple analytical models\nand data-driven models for offline training of optical matrix multipliers. We\ntrain and evaluate the models using experimental data obtained from a\nfabricated chip featuring a Mach-Zehnder interferometer mesh implementing\n3-by-3 matrix multiplication. The neural network-based models outperform the\nsimple physics-based models in terms of prediction error. Furthermore, the\nneural network models are also able to predict the spectral variations in the\nmatrix weights for up to 100 frequency channels covering the C-band. The use of\nneural network models for programming the chip for optical matrix\nmultiplication yields increased performance on multiple machine learning tasks.",
    "descriptor": "\nComments: 11 pages, 17 figures, submitted to Jorunal of Lightwave Technology\n",
    "authors": [
      "Ali Cem",
      "Siqi Yan",
      "Yunhong Ding",
      "Darko Zibar",
      "Francesco Da Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2210.09171"
  },
  {
    "id": "arXiv:2210.09173",
    "title": "Visual onoma-to-wave: environmental sound synthesis from visual  onomatopoeias and sound-source images",
    "abstract": "We propose a method for synthesizing environmental sounds from visually\nrepresented onomatopoeias and sound sources. An onomatopoeia is a word that\nimitates a sound structure, i.e., the text representation of sound. From this\nperspective, onoma-to-wave has been proposed to synthesize environmental sounds\nfrom the desired onomatopoeia texts. Onomatopoeias have another representation:\nvisual-text representations of sounds in comics, advertisements, and virtual\nreality. A visual onomatopoeia (visual text of onomatopoeia) contains rich\ninformation that is not present in the text, such as a long-short duration of\nthe image, so the use of this representation is expected to synthesize diverse\nsounds. Therefore, we propose visual onoma-to-wave for environmental sound\nsynthesis from visual onomatopoeia. The method can transfer visual concepts of\nthe visual text and sound-source image to the synthesized sound. We also\npropose a data augmentation method focusing on the repetition of onomatopoeias\nto enhance the performance of our method. An experimental evaluation shows that\nthe methods can synthesize diverse environmental sounds from visual text and\nsound-source images.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Hien Ohnaka",
      "Shinnosuke Takamichi",
      "Keisuke Imoto",
      "Yuki Okamoto",
      "Kazuki Fujii",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09173"
  },
  {
    "id": "arXiv:2210.09175",
    "title": "Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task  Generalization",
    "abstract": "Training language models to learn from human instructions for zero-shot\ncross-task generalization has attracted much attention in NLP communities.\nRecently, instruction tuning (IT), which fine-tunes a pre-trained language\nmodel on a massive collection of tasks described via human-craft instructions,\nhas been shown effective in instruction learning for unseen tasks. However, IT\nrelies on a large amount of human-annotated samples, which restricts its\ngeneralization. Unlike labeled data, unlabeled data are often massive and cheap\nto obtain. In this work, we study how IT can be improved with unlabeled data.\nWe first empirically explore the IT performance trends versus the number of\nlabeled data, instructions, and training tasks. We find it critical to enlarge\nthe number of training instructions, and the instructions can be underutilized\ndue to the scarcity of labeled data. Then, we propose Unlabeled Data Augmented\nInstruction Tuning (UDIT) to take better advantage of the instructions during\nIT by constructing pseudo-labeled data from unlabeled plain texts. We conduct\nextensive experiments to show UDIT's effectiveness in various scenarios of\ntasks and datasets. We also comprehensively analyze the key factors of UDIT to\ninvestigate how to better improve IT with unlabeled data. The code is publicly\navailable at https://github.com/thu-coai/UDIT.",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2022\n",
    "authors": [
      "Yuxian Gu",
      "Pei Ke",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09175"
  },
  {
    "id": "arXiv:2210.09179",
    "title": "Zero-Shot Ranking Socio-Political Texts with Transformer Language Models  to Reduce Close Reading Time",
    "abstract": "We approach the classification problem as an entailment problem and apply\nzero-shot ranking to socio-political texts. Documents that are ranked at the\ntop can be considered positively classified documents and this reduces the\nclose reading time for the information extraction process. We use Transformer\nLanguage Models to get the entailment probabilities and investigate different\ntypes of queries. We find that DeBERTa achieves higher mean average precision\nscores than RoBERTa and when declarative form of the class label is used as a\nquery, it outperforms dictionary definition of the class label. We show that\none can reduce the close reading time by taking some percentage of the ranked\ndocuments that the percentage depends on how much recall they want to achieve.\nHowever, our findings also show that percentage of the documents that should be\nread increases as the topic gets broader.",
    "descriptor": "\nComments: Accepted at CASE 2022\n",
    "authors": [
      "Kiymet Akdemir",
      "Ali H\u00fcrriyeto\u011flu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09179"
  },
  {
    "id": "arXiv:2210.09183",
    "title": "On the linear convergence of additive Schwarz methods for the  $p$-Laplacian",
    "abstract": "We consider additive Schwarz methods for boundary value problems involving\nthe $p$-Laplacian. While the existing theoretical estimates for the convergence\nrate of the additive Schwarz methods for the $p$-Laplacian are sublinear, the\nactual convergence rate observed by numerical experiments is linear. In this\npaper, we close the gap between these theoretical and numerical results; we\nprove the linear convergence of the additive Schwarz methods for the\n$p$-Laplacian. The linear convergence of the methods is derived based on a new\nconvergence theory written in terms of a distance-like function that behaves\nlike the Bregman distance of the convex energy functional associated to the\nproblem. The result is then further extended to handle variational inequalities\ninvolving the $p$-Laplacian as well.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Young-Ju Lee",
      "Jongho Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09183"
  },
  {
    "id": "arXiv:2210.09184",
    "title": "Packed-Ensembles for Efficient Uncertainty Estimation",
    "abstract": "Deep Ensembles (DE) are a prominent approach achieving excellent performance\non key metrics such as accuracy, calibration, uncertainty estimation, and\nout-of-distribution detection. However, hardware limitations of real-world\nsystems constrain to smaller ensembles and lower capacity networks,\nsignificantly deteriorating their performance and properties. We introduce\nPacked-Ensembles (PE), a strategy to design and train lightweight structured\nensembles by carefully modulating the dimension of their encoding space. We\nleverage grouped convolutions to parallelize the ensemble into a single common\nbackbone and forward pass to improve training and inference speeds. PE is\ndesigned to work under the memory budget of a single standard neural network.\nThrough extensive studies we show that PE faithfully preserve the properties of\nDE, e.g., diversity, and match their performance in terms of accuracy,\ncalibration, out-of-distribution detection and robustness to distribution\nshift.",
    "descriptor": "",
    "authors": [
      "Olivier Laurent",
      "Adrien Lafage",
      "Enzo Tartaglione",
      "Geoffrey Daniel",
      "Jean-Marc Martinez",
      "Andrei Bursuc",
      "Gianni Franchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09184"
  },
  {
    "id": "arXiv:2210.09186",
    "title": "Implicit models, latent compression, intrinsic biases, and cheap lunches  in community detection",
    "abstract": "The task of community detection, which aims to partition a network into\nclusters of nodes to summarize its large-scale structure, has spawned the\ndevelopment of many competing algorithms with varying objectives. Some\ncommunity detection methods are inferential, explicitly deriving the clustering\nobjective through a probabilistic generative model, while other methods are\ndescriptive, dividing a network according to an objective motivated by a\nparticular application, making it challenging to compare these methods on the\nsame scale. Here we present a solution to this problem that associates any\ncommunity detection objective, inferential or descriptive, with its\ncorresponding implicit network generative model. This allows us to compute the\ndescription length of a network and its partition under arbitrary objectives,\nproviding a principled measure to compare the performance of different\nalgorithms without the need for \"ground truth\" labels. Our approach also gives\naccess to instances of the community detection problem that are optimal to any\ngiven algorithm, and in this way reveals intrinsic biases in popular\ndescriptive methods, explaining their tendency to overfit. Using our framework,\nwe compare a number of community detection methods on artificial networks, and\non a corpus of over 500 structurally diverse empirical networks. We find that\nmore expressive community detection methods exhibit consistently superior\ncompression performance on structured data instances, without having degraded\nperformance on a minority of situations where more specialized algorithms\nperform optimally. Our results undermine the implications of the \"no free\nlunch\" theorem for community detection, both conceptually and in practice,\nsince it is confined to unstructured data instances, unlike relevant community\ndetection problems which are structured by requirement.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Tiago P. Peixoto",
      "Alec Kirkley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09186"
  },
  {
    "id": "arXiv:2210.09187",
    "title": "Nonlinear Detection of Voltage Source Converter Control Systems in Wind  Farms Based on Higher-Order Spectral Analysis",
    "abstract": "In recent years, the sub-synchronous oscillation (SSO) accidents caused by\nwind power have received extensive attention. A method is needed to detect the\nnonlinearity of the collected equal-amplitude accident waveform record. The\ntheory of higher-order statistics (HOS) has become a powerful nonlinear\ndetection tool since 1960s. However, HOS analysis was most applied in condition\nmonitoring and fault diagnosis of mechanical equipment, even in the power\nsystem and wind farms. This paper focuses on the VSC control systems in wind\nfarms and classifies the nonlinearity based on HOS analysis. First, the\ntraditional describing function is extended to obtain more frequency domain\ninformation, and hereby the harmonic characteristics of bilateral and the\nunilateral saturation hard limit are studied. Then the bispectrum and\ntrispectrum are introduced as HOS, which are extended into bicoherence and\ntricoherence spectrums to eliminate the effects from linear parts in the VSC\ncontrol system. The effectiveness of nonlinear detection and classification\nbased on HOS is strictly proved and its detailed calculation and estimation\nprocess is listed. Finally, the proposed method is demonstrated and further\ndiscussed through simulation results.",
    "descriptor": "",
    "authors": [
      "Zetian Zheng",
      "Chen Shen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09187"
  },
  {
    "id": "arXiv:2210.09188",
    "title": "Sub-8-bit quantization for on-device speech recognition: a  regularization-free approach",
    "abstract": "For on-device automatic speech recognition (ASR), quantization aware training\n(QAT) is ubiquitous to achieve the trade-off between model predictive\nperformance and efficiency. Among existing QAT methods, one major drawback is\nthat the quantization centroids have to be predetermined and fixed. To overcome\nthis limitation, we introduce a regularization-free, \"soft-to-hard\" compression\nmechanism with self-adjustable centroids in a mu-Law constrained space,\nresulting in a simpler yet more versatile quantization scheme, called General\nQuantizer (GQ). We apply GQ to ASR tasks using Recurrent Neural Network\nTransducer (RNN-T) and Conformer architectures on both LibriSpeech and\nde-identified far-field datasets. Without accuracy degradation, GQ can compress\nboth RNN-T and Conformer into sub-8-bit, and for some RNN-T layers, to 1-bit\nfor fast and accurate inference. We observe a 30.73% memory footprint saving\nand 31.75% user-perceived latency reduction compared to 8-bit QAT via physical\ndevice benchmarking.",
    "descriptor": "\nComments: Accepted for publication at IEEE SLT'22\n",
    "authors": [
      "Kai Zhen",
      "Martin Radfar",
      "Hieu Duy Nguyen",
      "Grant P. Strimel",
      "Nathan Susanj",
      "Athanasios Mouchtaris"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09188"
  },
  {
    "id": "arXiv:2210.09194",
    "title": "Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class",
    "abstract": "In recent years, machine learning models have been shown to be vulnerable to\nbackdoor attacks. Under such attacks, an adversary embeds a stealthy backdoor\ninto the trained model such that the compromised models will behave normally on\nclean inputs but will misclassify according to the adversary's control on\nmaliciously constructed input with a trigger. While these existing attacks are\nvery effective, the adversary's capability is limited: given an input, these\nattacks can only cause the model to misclassify toward a single pre-defined or\ntarget class. In contrast, this paper exploits a novel backdoor attack with a\nmuch more powerful payload, denoted as Marksman, where the adversary can\narbitrarily choose which target class the model will misclassify given any\ninput during inference. To achieve this goal, we propose to represent the\ntrigger function as a class-conditional generative model and to inject the\nbackdoor in a constrained optimization framework, where the trigger function\nlearns to generate an optimal trigger pattern to attack any target class at\nwill while simultaneously embedding this generative backdoor into the trained\nmodel. Given the learned trigger-generation function, during inference, the\nadversary can specify an arbitrary backdoor attack target class, and an\nappropriate trigger causing the model to classify toward this target class is\ncreated accordingly. We show empirically that the proposed framework achieves\nhigh attack performance while preserving the clean-data performance in several\nbenchmark datasets, including MNIST, CIFAR10, GTSRB, and TinyImageNet. The\nproposed Marksman backdoor attack can also easily bypass existing backdoor\ndefenses that were originally designed against backdoor attacks with a single\ntarget class. Our work takes another significant step toward understanding the\nextensive risks of backdoor attacks in practice.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Khoa D. Doan",
      "Yingjie Lao",
      "Ping Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09194"
  },
  {
    "id": "arXiv:2210.09196",
    "title": "Efficient Parallelization of 5G-PUSCH on a Scalable RISC-V Many-core  Processor",
    "abstract": "5G Radio access network disaggregation and softwarization pose challenges in\nterms of computational performance to the processing units. At the physical\nlayer level, the baseband processing computational effort is typically\noffloaded to specialized hardware accelerators. However, the trend toward\nsoftware-defined radio-access networks demands flexible, programmable\narchitectures. In this paper, we explore the software design, parallelization\nand optimization of the key kernels of the lower physical layer (PHY) for\nphysical uplink shared channel (PUSCH) reception on MemPool and TeraPool, two\nmanycore systems having respectively 256 and 1024 small and efficient RISC-V\ncores with a large shared L1 data memory. PUSCH processing is demanding and\nstrictly time-constrained, it represents a challenge for the baseband\nprocessors, and it is also common to most of the uplink channels. Our analysis\nthus generalizes to the entire lower PHY of the uplink receiver at gNodeB\n(gNB). Based on the evaluation of the computational effort (in\nmultiply-accumulate operations) required by the PUSCH algorithmic stages, we\nfocus on the parallel implementation of the dominant kernels, namely fast\nFourier transform, matrix-matrix multiplication, and matrix decomposition\nkernels for the solution of linear systems. Our optimized parallel kernels\nachieve respectively on MemPool and TeraPool speedups of 211, 225, 158, and\n762, 880, 722, at high utilization (0.81, 0.89, 0.71, and 0.74, 0.88, 0.71),\ncomparable a single-core serial execution, moving a step closer toward a\nfull-software PUSCH implementation.",
    "descriptor": "\nComments: 6 pages, 9 figures, conference paper\n",
    "authors": [
      "Marco Bertuletti",
      "Yichao Zhang",
      "Alessandro Vanelli-Coralli",
      "Luca Benini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09196"
  },
  {
    "id": "arXiv:2210.09197",
    "title": "On the Impact of Temporal Concept Drift on Model Explanations",
    "abstract": "Explanation faithfulness of model predictions in natural language processing\nis typically evaluated on held-out data from the same temporal distribution as\nthe training data (i.e. synchronous settings). While model performance often\ndeteriorates due to temporal variation (i.e. temporal concept drift), it is\ncurrently unknown how explanation faithfulness is impacted when the time span\nof the target data is different from the data used to train the model (i.e.\nasynchronous settings). For this purpose, we examine the impact of temporal\nvariation on model explanations extracted by eight feature attribution methods\nand three select-then-predict models across six text classification tasks. Our\nexperiments show that (i)faithfulness is not consistent under temporal\nvariations across feature attribution methods (e.g. it decreases or increases\ndepending on the method), with an attention-based method demonstrating the most\nrobust faithfulness scores across datasets; and (ii) select-then-predict models\nare mostly robust in asynchronous settings with only small degradation in\npredictive performance. Finally, feature attribution methods show conflicting\nbehavior when used in FRESH (i.e. a select-and-predict model) and for measuring\nsufficiency/comprehensiveness (i.e. as post-hoc methods), suggesting that we\nneed more robust metrics to evaluate post-hoc explanation faithfulness.",
    "descriptor": "\nComments: Accepted at EMNLP Findings 2022\n",
    "authors": [
      "Zhixue Zhao",
      "George Chrysostomou",
      "Kalina Bontcheva",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09197"
  },
  {
    "id": "arXiv:2210.09198",
    "title": "Pixel-Aligned Non-parametric Hand Mesh Reconstruction",
    "abstract": "Non-parametric mesh reconstruction has recently shown significant progress in\n3D hand and body applications. In these methods, mesh vertices and edges are\nvisible to neural networks, enabling the possibility to establish a direct\nmapping between 2D image pixels and 3D mesh vertices. In this paper, we seek to\nestablish and exploit this mapping with a simple and compact architecture. The\nnetwork is designed with these considerations: 1) aggregating both local 2D\nimage features from the encoder and 3D geometric features captured in the mesh\ndecoder; 2) decoding coarse-to-fine meshes along the decoding layers to make\nthe best use of the hierarchical multi-scale information. Specifically, we\npropose an end-to-end pipeline for hand mesh recovery tasks which consists of\nthree phases: a 2D feature extractor constructing multi-scale feature maps, a\nfeature mapping module transforming local 2D image features to 3D vertex\nfeatures via 3D-to-2D projection, and a mesh decoder combining the graph\nconvolution and self-attention to reconstruct mesh. The decoder aggregate both\nlocal image features in pixels and geometric features in vertices. It also\nregresses the mesh vertices in a coarse-to-fine manner, which can leverage\nmulti-scale information. By exploiting the local connection and designing the\nmesh decoder, Our approach achieves state-of-the-art for hand mesh\nreconstruction on the public FreiHAND dataset.",
    "descriptor": "",
    "authors": [
      "Shijian Jiang",
      "Guwen Han",
      "Danhang Tang",
      "Yang Zhou",
      "Xiang Li",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09198"
  },
  {
    "id": "arXiv:2210.09202",
    "title": "High-efficiency Blockchain-based Supply Chain Traceability",
    "abstract": "Supply chain traceability refers to product tracking from the source to\ncustomers, demanding transparency, authenticity, and high efficiency. In recent\nyears, blockchain has been widely adopted in supply chain traceability to\nprovide transparency and authenticity, while the efficiency issue is\nunderstudied. In practice, as the numerous product records accumulate, the\ntime- and storage- efficiencies will decrease remarkably. To the best of our\nknowledge, this paper is the first work studying the efficiency issue in\nblockchain-based supply chain traceability. Compared to the traditional method,\nwhich searches the records stored in a single chunk sequentially, we replicate\nthe records in multiple chunks and employ parallel search to boost the time\nefficiency. However, allocating the record searching primitives to the chunks\nwith maximized parallelization ratio is challenging. To this end, we model the\nrecords and chunks as a bipartite graph and solve the allocation problem using\na maximum matching algorithm. The experimental results indicate that the time\noverhead can be reduced by up to 85.1% with affordable storage overhead.",
    "descriptor": "\nComments: IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Hanqing Wu",
      "Shan Jiang",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.09202"
  },
  {
    "id": "arXiv:2210.09204",
    "title": "ArtFacePoints: High-resolution Facial Landmark Detection in Paintings  and Prints",
    "abstract": "Facial landmark detection plays an important role for the similarity analysis\nin artworks to compare portraits of the same or similar artists. With facial\nlandmarks, portraits of different genres, such as paintings and prints, can be\nautomatically aligned using control-point-based image registration. We propose\na deep-learning-based method for facial landmark detection in high-resolution\nimages of paintings and prints. It divides the task into a global network for\ncoarse landmark prediction and multiple region networks for precise landmark\nrefinement in regions of the eyes, nose, and mouth that are automatically\ndetermined based on the predicted global landmark coordinates. We created a\nsynthetically augmented facial landmark art dataset including artistic style\ntransfer and geometric landmark shifts. Our method demonstrates an accurate\ndetection of the inner facial landmarks for our high-resolution dataset of\nartworks while being comparable for a public low-resolution artwork dataset in\ncomparison to competing methods.",
    "descriptor": "\nComments: 16 pages, 8 figures, 3 tables, accepted to VISART workshop at ECCV 2022\n",
    "authors": [
      "Aline Sindel",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09204"
  },
  {
    "id": "arXiv:2210.09213",
    "title": "Segmentation-guided Domain Adaptation for Efficient Depth Completion",
    "abstract": "Complete depth information and efficient estimators have become vital\ningredients in scene understanding for automated driving tasks. A major problem\nfor LiDAR-based depth completion is the inefficient utilization of convolutions\ndue to the lack of coherent information as provided by the sparse nature of\nuncorrelated LiDAR point clouds, which often leads to complex and\nresource-demanding networks. The problem is reinforced by the expensive\naquisition of depth data for supervised training. In this work, we propose an\nefficient depth completion model based on a vgg05-like CNN architecture and\npropose a semi-supervised domain adaptation approach to transfer knowledge from\nsynthetic to real world data to improve data-efficiency and reduce the need for\na large database. In order to boost spatial coherence, we guide the learning\nprocess using segmentations as additional source of information. The efficiency\nand accuracy of our approach is evaluated on the KITTI dataset. Our approach\nimproves on previous efficient and low parameter state of the art approaches\nwhile having a noticeably lower computational footprint.",
    "descriptor": "",
    "authors": [
      "Fabian M\u00e4rkert",
      "Martin Sunkel",
      "Anselm Haselhoff",
      "Stefan Rudolph"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09213"
  },
  {
    "id": "arXiv:2210.09215",
    "title": "A Systematic Review of Machine Learning Techniques for Cattle  Identification: Datasets, Methods and Future Directions",
    "abstract": "Increased biosecurity and food safety requirements may increase demand for\nefficient traceability and identification systems of livestock in the supply\nchain. The advanced technologies of machine learning and computer vision have\nbeen applied in precision livestock management, including critical disease\ndetection, vaccination, production management, tracking, and health monitoring.\nThis paper offers a systematic literature review (SLR) of vision-based cattle\nidentification. More specifically, this SLR is to identify and analyse the\nresearch related to cattle identification using Machine Learning (ML) and Deep\nLearning (DL). For the two main applications of cattle detection and cattle\nidentification, all the ML based papers only solve cattle identification\nproblems. However, both detection and identification problems were studied in\nthe DL based papers. Based on our survey report, the most used ML models for\ncattle identification were support vector machine (SVM), k-nearest neighbour\n(KNN), and artificial neural network (ANN). Convolutional neural network (CNN),\nresidual network (ResNet), Inception, You Only Look Once (YOLO), and Faster\nR-CNN were popular DL models in the selected papers. Among these papers, the\nmost distinguishing features were the muzzle prints and coat patterns of\ncattle. Local binary pattern (LBP), speeded up robust features (SURF),\nscale-invariant feature transform (SIFT), and Inception or CNN were identified\nas the most used feature extraction methods.",
    "descriptor": "\nComments: 34 pages, 14 figures\n",
    "authors": [
      "Md Ekramul Hossain",
      "Muhammad Ashad Kabir",
      "Lihong Zheng",
      "Dave L. Swain",
      "Shawn McGrath",
      "Jonathan Medway"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09215"
  },
  {
    "id": "arXiv:2210.09220",
    "title": "A Saccaded Visual Transformer for General Object Spotting",
    "abstract": "This paper presents the novel combination of a visual transformer style patch\nclassifier with saccaded local attention. A novel optimisation paradigm for\ntraining object models is also presented, rather than the optimisation function\nminimising class membership probability error the network is trained to\nestimate the normalised distance to the centroid of labelled objects. This\napproach builds a degree of transnational invariance directly into the model\nand allows fast saccaded search with gradient ascent to find object centroids.\nThe resulting saccaded visual transformer is demonstrated on human faces.",
    "descriptor": "\nComments: 11 pages mostly figure, central idea is to train on distance a patch is form a labelled feature\n",
    "authors": [
      "Willem.T.Pye",
      "David.A.Sinclair"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09220"
  },
  {
    "id": "arXiv:2210.09221",
    "title": "Vision Transformers provably learn spatial structure",
    "abstract": "Vision Transformers (ViTs) have achieved comparable or superior performance\nthan Convolutional Neural Networks (CNNs) in computer vision. This empirical\nbreakthrough is even more remarkable since, in contrast to CNNs, ViTs do not\nembed any visual inductive bias of spatial locality. Yet, recent works have\nshown that while minimizing their training loss, ViTs specifically learn\nspatially localized patterns. This raises a central question: how do ViTs learn\nthese patterns by solely minimizing their training loss using gradient-based\nmethods from random initialization? In this paper, we provide some theoretical\njustification of this phenomenon. We propose a spatially structured dataset and\na simplified ViT model. In this model, the attention matrix solely depends on\nthe positional encodings. We call this mechanism the positional attention\nmechanism. On the theoretical side, we consider a binary classification task\nand show that while the learning problem admits multiple solutions that\ngeneralize, our model implicitly learns the spatial structure of the dataset\nwhile generalizing: we call this phenomenon patch association. We prove that\npatch association helps to sample-efficiently transfer to downstream datasets\nthat share the same structure as the pre-training one but differ in the\nfeatures. Lastly, we empirically verify that a ViT with positional attention\nperforms similarly to the original one on CIFAR-10/100, SVHN and ImageNet.",
    "descriptor": "",
    "authors": [
      "Samy Jelassi",
      "Michael E. Sander",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09221"
  },
  {
    "id": "arXiv:2210.09222",
    "title": "MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human  Activity Recognition",
    "abstract": "Multimodal sensors (e.g., visual, non-visual, and wearable) provide\ncomplementary information to develop robust perception systems for recognizing\nactivities. However, most existing algorithms use dense sampling and\nheterogeneous sub-network to extract unimodal features and fuse them at the end\nof their framework, which causes data redundancy, lack of complementary\nmultimodal information and high computational cost. In this paper, we propose a\nnew novel multimodal neural architecture based on RGB and IMU wearable sensors\n(e.g., accelerometer, gyroscope) for human activity recognition called\nMultimodal Temporal Segment Attention Network (MMTSA). MMTSA first employs a\nmultimodal data isomorphism mechanism based on Gramian Angular Field (GAF) and\nthen applies a novel multimodal sparse sampling method to reduce redundancy.\nMoreover, we propose an inter-segment attention module in MMTSA to fuse\nmultimodal features effectively and efficiently. We demonstrate the importance\nof imu data imaging and attention mechanism in human activity recognition by\nrigorous evaluation on three public datasets, and achieve superior improvements\n($11.13\\%$ on the MMAct dataset) than the previous state-of-the-art methods.\nThe code is available at: https://github.com/THU-CS-PI/MMTSA.",
    "descriptor": "",
    "authors": [
      "Ziqi Gao",
      "Jianguo Chen",
      "Junliang Xing",
      "Shwetak Patel",
      "Yuanchun Shi",
      "Xin Liu",
      "Yuntao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09222"
  },
  {
    "id": "arXiv:2210.09223",
    "title": "oViT: An Accurate Second-Order Pruning Framework for Vision Transformers",
    "abstract": "Models from the Vision Transformer (ViT) family have recently provided\nbreakthrough results across image classification tasks such as ImageNet. Yet,\nthey still face barriers to deployment, notably the fact that their accuracy\ncan be severely impacted by compression techniques such as pruning. In this\npaper, we take a step towards addressing this issue by introducing Optimal ViT\nSurgeon (oViT), a new state-of-the-art method for the weight sparsification of\nVision Transformers (ViT) models. At the technical level, oViT introduces a new\nweight pruning algorithm which leverages second-order information, specifically\nadapted to be both highly-accurate and efficient in the context of ViTs. We\ncomplement this accurate one-shot pruner with an in-depth investigation of\ngradual pruning, augmentation, and recovery schedules for ViTs, which we show\nto be critical for successful ViT compression. We validate our method via\nextensive experiments on classical ViT and DeiT models, as well as on newer\nvariants, such as XCiT, EfficientFormer and Swin. Moreover, our results are\neven relevant to recently-proposed highly-accurate ResNets. Our results show\nfor the first time that ViT-family models can in fact be pruned to high\nsparsity levels (e.g. $\\geq 75\\%$) with low impact on accuracy ($\\leq 1\\%$\nrelative drop), and that our approach outperforms prior methods by significant\nmargins at high sparsities. In addition, we show that our method is compatible\nwith structured pruning methods and quantization, and that it can lead to\nsignificant speedups on a sparsity-aware inference engine.",
    "descriptor": "",
    "authors": [
      "Denis Kuznedelev",
      "Eldar Kurtic",
      "Elias Frantar",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09223"
  },
  {
    "id": "arXiv:2210.09224",
    "title": "Self-Supervised Learning Through Efference Copies",
    "abstract": "Self-supervised learning (SSL) methods aim to exploit the abundance of\nunlabelled data for machine learning (ML), however the underlying principles\nare often method-specific. An SSL framework derived from biological first\nprinciples of embodied learning could unify the various SSL methods, help\nelucidate learning in the brain, and possibly improve ML. SSL commonly\ntransforms each training datapoint into a pair of views, uses the knowledge of\nthis pairing as a positive (i.e. non-contrastive) self-supervisory sign, and\npotentially opposes it to unrelated, (i.e. contrastive) negative examples.\nHere, we show that this type of self-supervision is an incomplete\nimplementation of a concept from neuroscience, the Efference Copy (EC).\nSpecifically, the brain also transforms the environment through efference, i.e.\nmotor commands, however it sends to itself an EC of the full commands, i.e.\nmore than a mere SSL sign. In addition, its action representations are likely\negocentric. From such a principled foundation we formally recover and extend\nSSL methods such as SimCLR, BYOL, and ReLIC under a common theoretical\nframework, i.e. Self-supervision Through Efference Copies (S-TEC). Empirically,\nS-TEC restructures meaningfully the within- and between-class representations.\nThis manifests as improvement in recent strong SSL baselines in image\nclassification, segmentation, object detection, and in audio. These results\nhypothesize a testable positive influence from the brain's motor outputs onto\nits sensory representations.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Franz Scherr",
      "Qinghai Guo",
      "Timoleon Moraitis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.09224"
  },
  {
    "id": "arXiv:2210.09228",
    "title": "Data-Driven Joint Inversions for PDE Models",
    "abstract": "The task of simultaneously reconstructing multiple physical coefficients in\npartial differential equations from observed data is ubiquitous in\napplications. In this work, we propose an integrated data-driven and\nmodel-based iterative reconstruction framework for such joint inversion\nproblems where additional data on the unknown coefficients are supplemented for\nbetter reconstructions. Our method couples the supplementary data with the PDE\nmodel to make the data-driven modeling process consistent with the model-based\nreconstruction procedure. We characterize the impact of learning uncertainty on\nthe joint inversion results for two typical model inverse problems. Numerical\nevidences are provided to demonstrate the feasibility of using data-driven\nmodels to improve joint inversion of physical models.",
    "descriptor": "",
    "authors": [
      "Kui Ren",
      "Lu Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.09228"
  },
  {
    "id": "arXiv:2210.09230",
    "title": "Security and Privacy in Big Data Sharing: State-of-the-Art and Research  Directions",
    "abstract": "Big Data Sharing (BDS) refers to the act of the data owners to share data so\nthat users can find, access and use data according to the agreement. In recent\nyears, BDS has been an emerging topic due to its wide applications, such as big\ndata trading and cross-domain data analytics. However, as the multiple parties\nare involved in a BDS platform, the issue of security and privacy violation\narises. There have been a number of solutions for enhancing security and\npreserving privacy at different big data operations (e.g., data operation, data\nsearching, data sharing and data outsourcing). To the best of our knowledge,\nthere is no existing survey that has particularly focused on the broad and\nsystematic developments of these security and privacy solutions. In this study,\nwe conduct a comprehensive survey of the state-of-the-art solutions introduced\nto tackle security and privacy issues in BDS. For a better understanding, we\nfirst introduce a general model for BDS and identify the security and privacy\nrequirements. We discuss and classify the state-of-the-art security and privacy\nsolutions for BDS according to the identified requirements. Finally, based on\nthe insights gained, we present and discuss new promising research directions.",
    "descriptor": "\nComments: 33 pages, 8 figures\n",
    "authors": [
      "Houda Ferradi",
      "Jiannong Cao",
      "Shan Jiang",
      "Yinfeng Cao",
      "Divya Saxena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09230"
  },
  {
    "id": "arXiv:2210.09232",
    "title": "Confound-leakage: Confound Removal in Machine Learning Leads to Leakage",
    "abstract": "Machine learning (ML) approaches to data analysis are now widely adopted in\nmany fields including epidemiology and medicine. To apply these approaches,\nconfounds must first be removed as is commonly done by featurewise removal of\ntheir variance by linear regression before applying ML. Here, we show this\ncommon approach to confound removal biases ML models, leading to misleading\nresults. Specifically, this common deconfounding approach can leak information\nsuch that what are null or moderate effects become amplified to near-perfect\nprediction when nonlinear ML approaches are subsequently applied. We identify\nand evaluate possible mechanisms for such confound-leakage and provide\npractical guidance to mitigate its negative impact. We demonstrate the\nreal-world importance of confound-leakage by analyzing a clinical dataset where\naccuracy is overestimated for predicting attention deficit hyperactivity\ndisorder (ADHD) with depression as a confound. Our results have wide-reaching\nimplications for implementation and deployment of ML workflows and beg caution\nagainst na\\\"ive use of standard confound removal approaches.",
    "descriptor": "",
    "authors": [
      "Sami Hamdan",
      "Bradley C. Love",
      "Georg G. von Polier",
      "Susanne Weis",
      "Holger Schwender",
      "Simon B. Eickhoff",
      "Kaustubh R. Patil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09232"
  },
  {
    "id": "arXiv:2210.09234",
    "title": "Improving Contrastive Learning on Visually Homogeneous Mars Rover Images",
    "abstract": "Contrastive learning has recently demonstrated superior performance to\nsupervised learning, despite requiring no training labels. We explore how\ncontrastive learning can be applied to hundreds of thousands of unlabeled Mars\nterrain images, collected from the Mars rovers Curiosity and Perseverance, and\nfrom the Mars Reconnaissance Orbiter. Such methods are appealing since the vast\nmajority of Mars images are unlabeled as manual annotation is labor intensive\nand requires extensive domain knowledge. Contrastive learning, however, assumes\nthat any given pair of distinct images contain distinct semantic content. This\nis an issue for Mars image datasets, as any two pairs of Mars images are far\nmore likely to be semantically similar due to the lack of visual diversity on\nthe planet's surface. Making the assumption that pairs of images will be in\nvisual contrast - when they are in fact not - results in pairs that are falsely\nconsidered as negatives, impacting training performance. In this study, we\npropose two approaches to resolve this: 1) an unsupervised deep clustering step\non the Mars datasets, which identifies clusters of images containing similar\nsemantic content and corrects false negative errors during training, and 2) a\nsimple approach which mixes data from different domains to increase visual\ndiversity of the total training dataset. Both cases reduce the rate of false\nnegative pairs, thus minimizing the rate in which the model is incorrectly\npenalized during contrastive training. These modified approaches remain fully\nunsupervised end-to-end. To evaluate their performance, we add a single linear\nlayer trained to generate class predictions based on these\ncontrastively-learned features and demonstrate increased performance compared\nto supervised models; observing an improvement in classification accuracy of\n3.06% using only 10% of the labeled data.",
    "descriptor": "\nComments: Accepted at the AI4Space 2022 Workshop at ECCV 2022\n",
    "authors": [
      "Isaac Ronald Ward",
      "Charles Moore",
      "Kai Pak",
      "Jingdao Chen",
      "Edwin Goh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09234"
  },
  {
    "id": "arXiv:2210.09236",
    "title": "ZooD: Exploiting Model Zoo for Out-of-Distribution Generalization",
    "abstract": "Recent advances on large-scale pre-training have shown great potentials of\nleveraging a large set of Pre-Trained Models (PTMs) for improving\nOut-of-Distribution (OoD) generalization, for which the goal is to perform well\non possible unseen domains after fine-tuning on multiple training domains.\nHowever, maximally exploiting a zoo of PTMs is challenging since fine-tuning\nall possible combinations of PTMs is computationally prohibitive while accurate\nselection of PTMs requires tackling the possible data distribution shift for\nOoD tasks. In this work, we propose ZooD, a paradigm for PTMs ranking and\nensemble with feature selection. Our proposed metric ranks PTMs by quantifying\ninter-class discriminability and inter-domain stability of the features\nextracted by the PTMs in a leave-one-domain-out cross-validation manner. The\ntop-K ranked models are then aggregated for the target OoD task. To avoid\naccumulating noise induced by model ensemble, we propose an efficient\nvariational EM algorithm to select informative features. We evaluate our\nparadigm on a diverse model zoo consisting of 35 models for various OoD tasks\nand demonstrate: (i) model ranking is better correlated with fine-tuning\nranking than previous methods and up to 9859x faster than brute-force\nfine-tuning; (ii) OoD generalization after model ensemble with feature\nselection outperforms the state-of-the-art methods and the accuracy on most\nchallenging task DomainNet is improved from 46.5\\% to 50.6\\%. Furthermore, we\nprovide the fine-tuning results of 35 PTMs on 7 OoD datasets, hoping to help\nthe research of model zoo and OoD generalization. Code will be available at\nhttps://gitee.com/mindspore/models/tree/master/research/cv/zood.",
    "descriptor": "",
    "authors": [
      "Qishi Dong",
      "Awais Muhammad",
      "Fengwei Zhou",
      "Chuanlong Xie",
      "Tianyang Hu",
      "Yongxin Yang",
      "Sung-Ho Bae",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09236"
  },
  {
    "id": "arXiv:2210.09241",
    "title": "Boosting Offline Reinforcement Learning via Data Rebalancing",
    "abstract": "Offline reinforcement learning (RL) is challenged by the distributional shift\nbetween learning policies and datasets. To address this problem, existing works\nmainly focus on designing sophisticated algorithms to explicitly or implicitly\nconstrain the learned policy to be close to the behavior policy. The constraint\napplies not only to well-performing actions but also to inferior ones, which\nlimits the performance upper bound of the learned policy. Instead of aligning\nthe densities of two distributions, aligning the supports gives a relaxed\nconstraint while still being able to avoid out-of-distribution actions.\nTherefore, we propose a simple yet effective method to boost offline RL\nalgorithms based on the observation that resampling a dataset keeps the\ndistribution support unchanged. More specifically, we construct a better\nbehavior policy by resampling each transition in an old dataset according to\nits episodic return. We dub our method ReD (Return-based Data Rebalance), which\ncan be implemented with less than 10 lines of code change and adds negligible\nrunning time. Extensive experiments demonstrate that ReD is effective at\nboosting offline RL performance and orthogonal to decoupling strategies in\nlong-tailed classification. New state-of-the-arts are achieved on the D4RL\nbenchmark.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Yang Yue",
      "Bingyi Kang",
      "Xiao Ma",
      "Zhongwen Xu",
      "Gao Huang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09241"
  },
  {
    "id": "arXiv:2210.09245",
    "title": "Learning Object Affordance with Contact and Grasp Generation",
    "abstract": "Understanding object affordance can help in designing better and more robust\nrobotic grasping. Existing work in the computer vision community formulates the\nobject affordance understanding as a grasping pose generation problem, which\ntreats the problem as a black box by learning a mapping between objects and the\ndistributions of possible grasping poses for the objects. On the other hand, in\nthe robotics community, estimating object affordance represented by contact\nmaps is of the most importance as localizing the positions of the possible\naffordance can help the planning of grasping actions. In this paper, we propose\nto formulate the object affordance understanding as both contacts and grasp\nposes generation. we factorize the learning task into two sequential stages,\nrather than the black-box strategy: (1) we first reason the contact maps by\nallowing multi-modal contact generation; (2) assuming that grasping poses are\nfully constrained given contact maps, we learn a one-to-one mapping from the\ncontact maps to the grasping poses. Further, we propose a penetration-aware\npartial optimization from the intermediate contacts. It combines local and\nglobal optimization for the refinement of the partial poses of the generated\ngrasps exhibiting penetration. Extensive validations on two public datasets\nshow our method outperforms state-of-the-art methods regarding grasp generation\non various metrics.",
    "descriptor": "",
    "authors": [
      "Haoming Li",
      "Xinzhuo Lin",
      "Yang Zhou",
      "Xiang Li",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09245"
  },
  {
    "id": "arXiv:2210.09255",
    "title": "A Unified Algorithm for Stochastic Path Problems",
    "abstract": "We study reinforcement learning in stochastic path (SP) problems. The goal in\nthese problems is to maximize the expected sum of rewards until the agent\nreaches a terminal state. We provide the first regret guarantees in this\ngeneral problem by analyzing a simple optimistic algorithm. Our regret bound\nmatches the best known results for the well-studied special case of stochastic\nshortest path (SSP) with all non-positive rewards. For SSP, we present an\nadaptation procedure for the case when the scale of rewards $B_\\star$ is\nunknown. We show that there is no price for adaptation, and our regret bound\nmatches that with a known $B_\\star$. We also provide a scale adaptation\nprocedure for the special case of stochastic longest paths (SLP) where all\nrewards are non-negative. However, unlike in SSP, we show through a lower bound\nthat there is an unavoidable price for adaptation.",
    "descriptor": "",
    "authors": [
      "Christoph Dann",
      "Chen-Yu Wei",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09255"
  },
  {
    "id": "arXiv:2210.09256",
    "title": "On Uncertainty in Deep State Space Models for Model-Based Reinforcement  Learning",
    "abstract": "Improved state space models, such as Recurrent State Space Models (RSSMs),\nare a key factor behind recent advances in model-based reinforcement learning\n(RL). Yet, despite their empirical success, many of the underlying design\nchoices are not well understood. We show that RSSMs use a suboptimal inference\nscheme and that models trained using this inference overestimate the aleatoric\nuncertainty of the ground truth system. We find this overestimation implicitly\nregularizes RSSMs and allows them to succeed in model-based RL. We postulate\nthat this implicit regularization fulfills the same functionality as explicitly\nmodeling epistemic uncertainty, which is crucial for many other model-based RL\napproaches. Yet, overestimating aleatoric uncertainty can also impair\nperformance in cases where accurately estimating it matters, e.g., when we have\nto deal with occlusions, missing observations, or fusing sensor modalities at\ndifferent frequencies. Moreover, the implicit regularization is a side-effect\nof the inference scheme and not the result of a rigorous, principled\nformulation, which renders analyzing or improving RSSMs difficult. Thus, we\npropose an alternative approach building on well-understood components for\nmodeling aleatoric and epistemic uncertainty, dubbed Variational Recurrent\nKalman Network (VRKN). This approach uses Kalman updates for exact smoothing\ninference in a latent space and Monte Carlo Dropout to model epistemic\nuncertainty. Due to the Kalman updates, the VRKN can naturally handle missing\nobservations or sensor fusion problems with varying numbers of observations per\ntime step. Our experiments show that using the VRKN instead of the RSSM\nimproves performance in tasks where appropriately capturing aleatoric\nuncertainty is crucial while matching it in the deterministic standard\nbenchmarks.",
    "descriptor": "\nComments: Published in TMLR, October 2022\n",
    "authors": [
      "Philipp Becker",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09256"
  },
  {
    "id": "arXiv:2210.09257",
    "title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural  Equilibrium Solvers",
    "abstract": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse\nCorrelated Equilibria are useful components for many multiagent machine\nlearning algorithms. Unfortunately, solving a normal-form game could take\nprohibitive or non-deterministic time to converge, and could fail. We introduce\nthe Neural Equilibrium Solver which utilizes a special equivariant neural\nnetwork architecture to approximately solve the space of all games of fixed\nshape, buying speed and determinism. We define a flexible equilibrium selection\nframework, that is capable of uniquely selecting an equilibrium that minimizes\nrelative entropy, or maximizes welfare. The network is trained without needing\nto generate any supervised training data. We show remarkable zero-shot\ngeneralization to larger games. We argue that such a network is a powerful\ncomponent for many possible multiagent algorithms.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Luke Marris",
      "Ian Gemp",
      "Thomas Anthony",
      "Andrea Tacchetti",
      "Siqi Liu",
      "Karl Tuyls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.09257"
  },
  {
    "id": "arXiv:2210.09261",
    "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    "abstract": "BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that\nfocuses on tasks believed to be beyond the capabilities of current language\nmodels. Language models have already made good progress on this benchmark, with\nthe best model in the BIG-Bench paper outperforming average reported\nhuman-rater results on 65% of the BIG-Bench tasks via few-shot prompting. But\non what tasks do language models fall short of average human-rater performance,\nand are those tasks actually unsolvable by current language models?\nIn this work, we focus on a suite of 23 challenging BIG-Bench tasks which we\ncall BIG-Bench Hard (BBH). These are the task for which prior language model\nevaluations did not outperform the average human-rater. We find that applying\nchain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the\naverage human-rater performance on 10 of the 23 tasks, and Codex\n(code-davinci-002) to surpass the average human-rater performance on 17 of the\n23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot\nprompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al.,\n2022), substantially underestimates the best performance and capabilities of\nlanguage models, which is better captured via CoT prompting. As further\nanalysis, we explore the interaction between CoT and model scale on BBH,\nfinding that CoT enables emergent task performance on several BBH tasks with\notherwise flat scaling curves.",
    "descriptor": "\nComments: GitHub repository: this https URL\n",
    "authors": [
      "Mirac Suzgun",
      "Nathan Scales",
      "Nathanael Sch\u00e4rli",
      "Sebastian Gehrmann",
      "Yi Tay",
      "Hyung Won Chung",
      "Aakanksha Chowdhery",
      "Quoc V. Le",
      "Ed H. Chi",
      "Denny Zhou",
      "Jason Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09261"
  },
  {
    "id": "arXiv:2210.09263",
    "title": "Vision-Language Pre-training: Basics, Recent Advances, and Future Trends",
    "abstract": "This paper surveys vision-language pre-training (VLP) methods for multimodal\nintelligence that have been developed in the last few years. We group these\napproaches into three categories: ($i$) VLP for image-text tasks, such as image\ncaptioning, image-text retrieval, visual question answering, and visual\ngrounding; ($ii$) VLP for core computer vision tasks, such as (open-set) image\nclassification, object detection, and segmentation; and ($iii$) VLP for\nvideo-text tasks, such as video captioning, video-text retrieval, and video\nquestion answering. For each category, we present a comprehensive review of\nstate-of-the-art methods, and discuss the progress that has been made and\nchallenges still being faced, using specific systems and models as case\nstudies. In addition, for each category, we discuss advanced topics being\nactively explored in the research community, such as big foundation models,\nunified modeling, in-context few-shot learning, knowledge, robustness, and\ncomputer vision in the wild, to name a few.",
    "descriptor": "\nComments: A survey paper/book on Vision-Language Pre-training (102 pages)\n",
    "authors": [
      "Zhe Gan",
      "Linjie Li",
      "Chunyuan Li",
      "Lijuan Wang",
      "Zicheng Liu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09263"
  },
  {
    "id": "arXiv:2210.09266",
    "title": "Predicting Dynamic Stability from Static Features in Power Grid Models  using Machine Learning",
    "abstract": "A reliable supply with electric power is vital for our society. Transmission\nline failures are among the biggest threats for power grid stability as they\nmay lead to a splitting of the grid into mutual asynchronous fragments. New\nconceptual methods are needed to assess system stability that complement\nexisting simulation models. In this article we propose a combination of network\nscience metrics and machine learning models to predict the risk of\ndesynchronisation events. Network science provides metrics for essential\nproperties of transmission lines such as their redundancy or centrality.\nMachine learning models perform inherent feature selection and thus reveal key\nfactors that determine network robustness and vulnerability. As a case study,\nwe train and test such models on simulated data from several synthetic test\ngrids. We find that the integrated models are capable of predicting\ndesynchronisation events after line failures with an average precision greater\nthan $0.996$ when averaging over all data sets. Learning transfer between\ndifferent data sets is generally possible, at a slight loss of prediction\nperformance. Our results suggest that power grid desynchronisation is\nessentially governed by only a few network metrics that quantify the networks\nability to reroute flow without creating exceedingly high static line loadings.",
    "descriptor": "",
    "authors": [
      "Maurizio Titz",
      "Franz Kaiser",
      "Johannes Kruse",
      "Dirk Witthaut"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.09266"
  },
  {
    "id": "arXiv:2210.09267",
    "title": "CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for  Robust 3D Object Detection",
    "abstract": "Robust 3D object detection is critical for safe autonomous driving. Camera\nand radar sensors are synergistic as they capture complementary information and\nwork well under different environmental conditions. Fusing camera and radar\ndata is challenging, however, as each of the sensors lacks information along a\nperpendicular axis, that is, depth is unknown to camera and elevation is\nunknown to radar. We propose the camera-radar matching network CramNet, an\nefficient approach to fuse the sensor readings from camera and radar in a joint\n3D space. To leverage radar range measurements for better camera depth\npredictions, we propose a novel ray-constrained cross-attention mechanism that\nresolves the ambiguity in the geometric correspondences between camera features\nand radar features. Our method supports training with sensor modality dropout,\nwhich leads to robust 3D~object detection, even when a camera or radar sensor\nsuddenly malfunctions on a vehicle. We demonstrate the effectiveness of our\nfusion approach through extensive experiments on the RADIATE dataset, one of\nthe few large-scale datasets that provide radar radio frequency imagery. A\ncamera-only variant of our method achieves competitive performance in monocular\n3D~object detection on the Waymo Open Dataset.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Jyh-Jing Hwang",
      "Henrik Kretzschmar",
      "Joshua Manela",
      "Sean Rafferty",
      "Nicholas Armstrong-Crews",
      "Tiffany Chen",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09267"
  },
  {
    "id": "arXiv:2210.09269",
    "title": "Identification, Amplification and Measurement: A bridge to Gaussian  Differential Privacy",
    "abstract": "Gaussian differential privacy (GDP) is a single-parameter family of privacy\nnotions that provides coherent guarantees to avoid the exposure of sensitive\nindividual information. Despite the extra interpretability and tighter bounds\nunder composition GDP provides, many widely used mechanisms (e.g., the Laplace\nmechanism) inherently provide GDP guarantees but often fail to take advantage\nof this new framework because their privacy guarantees were derived under a\ndifferent background. In this paper, we study the asymptotic properties of\nprivacy profiles and develop a simple criterion to identify algorithms with GDP\nproperties. We propose an efficient method for GDP algorithms to narrow down\npossible values of an optimal privacy measurement, $\\mu$ with an arbitrarily\nsmall and quantifiable margin of error. For non GDP algorithms, we provide a\npost-processing procedure that can amplify existing privacy guarantees to meet\nthe GDP condition. As applications, we compare two single-parameter families of\nprivacy notions, $\\epsilon$-DP, and $\\mu$-GDP, and show that all $\\epsilon$-DP\nalgorithms are intrinsically also GDP. Lastly, we show that the combination of\nour measurement process and the composition theorem of GDP is a powerful and\nconvenient tool to handle compositions compared to the traditional standard and\nadvanced composition theorems.",
    "descriptor": "",
    "authors": [
      "Yi Liu",
      "Ke Sun",
      "Linglong Kong",
      "Bei Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09269"
  },
  {
    "id": "arXiv:2210.09276",
    "title": "Imagic: Text-Based Real Image Editing with Diffusion Models",
    "abstract": "Text-conditioned image editing has recently attracted considerable interest.\nHowever, most methods are currently either limited to specific editing types\n(e.g., object overlay, style transfer), or apply to synthetically generated\nimages, or require multiple input images of a common object. In this paper we\ndemonstrate, for the very first time, the ability to apply complex (e.g.,\nnon-rigid) text-guided semantic edits to a single real image. For example, we\ncan change the posture and composition of one or multiple objects inside an\nimage, while preserving its original characteristics. Our method can make a\nstanding dog sit down or jump, cause a bird to spread its wings, etc. -- each\nwithin its single high-resolution natural image provided by the user. Contrary\nto previous work, our proposed method requires only a single input image and a\ntarget text (the desired edit). It operates on real images, and does not\nrequire any additional inputs (such as image masks or additional views of the\nobject). Our method, which we call \"Imagic\", leverages a pre-trained\ntext-to-image diffusion model for this task. It produces a text embedding that\naligns with both the input image and the target text, while fine-tuning the\ndiffusion model to capture the image-specific appearance. We demonstrate the\nquality and versatility of our method on numerous inputs from various domains,\nshowcasing a plethora of high quality complex semantic image edits, all within\na single unified framework.",
    "descriptor": "",
    "authors": [
      "Bahjat Kawar",
      "Shiran Zada",
      "Oran Lang",
      "Omer Tov",
      "Huiwen Chang",
      "Tali Dekel",
      "Inbar Mosseri",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09276"
  },
  {
    "id": "arXiv:2210.09277",
    "title": "Unsupervised Optimal Power Flow Using Graph Neural Networks",
    "abstract": "Optimal power flow (OPF) is a critical optimization problem that allocates\npower to the generators in order to satisfy the demand at a minimum cost.\nSolving this problem exactly is computationally infeasible in the general case.\nIn this work, we propose to leverage graph signal processing and machine\nlearning. More specifically, we use a graph neural network to learn a nonlinear\nparametrization between the power demanded and the corresponding allocation. We\nlearn the solution in an unsupervised manner, minimizing the cost directly. In\norder to take into account the electrical constraints of the grid, we propose a\nnovel barrier method that is differentiable and works on initially infeasible\npoints. We show through simulations that the use of GNNs in this unsupervised\nlearning context leads to solutions comparable to standard solvers while being\ncomputationally efficient and avoiding constraint violations most of the time.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Power Systems\n",
    "authors": [
      "Damian Owerko",
      "Fernando Gama",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09277"
  },
  {
    "id": "arXiv:2210.09290",
    "title": "Automated Identification of Tree Species by Bark Texture Classification  Using Convolutional Neural Networks",
    "abstract": "Identification of tree species plays a key role in forestry related tasks\nlike forest conservation, disease diagnosis and plant production. There had\nbeen a debate regarding the part of the tree to be used for differentiation,\nwhether it should be leaves, fruits, flowers or bark. Studies have proven that\nbark is of utmost importance as it will be present despite seasonal variations\nand provides a characteristic identity to a tree by variations in the\nstructure. In this paper, a deep learning based approach is presented by\nleveraging the method of computer vision to classify 50 tree species, on the\nbasis of bark texture using the BarkVN-50 dataset. This is the maximum number\nof trees being considered for bark classification till now. A convolutional\nneural network(CNN), ResNet101 has been implemented using transfer-learning\nbased technique of fine tuning to maximise the model performance. The model\nproduced an overall accuracy of >94% during the evaluation. The performance\nvalidation has been done using K-Fold Cross Validation and by testing on unseen\ndata collected from the Internet, this proved the model's generalization\ncapability for real-world uses.",
    "descriptor": "\nComments: 11 Pages, 10 Figures and 2 Tables\n",
    "authors": [
      "Sahil Faizal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09290"
  },
  {
    "id": "arXiv:2210.09291",
    "title": "Embodying the Glitch: Perspectives on Generative AI in Dance Practice",
    "abstract": "What role does the break from realism play in the potential for generative\nartificial intelligence as a creative tool? Through exploration of glitch, we\nexamine the prospective value of these artefacts in creative practice. This\npaper describes findings from an exploration of AI-generated \"mistakes\" when\nusing movement produced by a generative deep learning model as an inspiration\nsource in dance composition.",
    "descriptor": "",
    "authors": [
      "Benedikte Wallace",
      "Charles P. Martin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09291"
  },
  {
    "id": "arXiv:2210.09292",
    "title": "Efficient Diffusion Models for Vision: A Survey",
    "abstract": "Diffusion Models (DMs) have demonstrated state-of-the-art performance in\ncontent generation without requiring adversarial training. These models are\ntrained using a two-step process. First, a forward process gradually adds noise\nto a datum (usually an image). Then, a backward process gradually removes the\nnoise to turn it into a sample of the target distribution being modelled. DMs\nare inspired by non-equilibrium thermodynamics and have inherent high\ncomputational complexity. Due to frequent function evaluations and gradient\ncalculations in high-dimensional spaces, these models incur considerable\ncomputational overhead during both the training and inference stages. This can\nnot only preclude democratization of diffusion-based modelling, but also hinder\nthe adaption of diffusion models in real-life applications. Not to mention, the\nefficiency of computational models is fast becoming a significant concern due\nto excessive energy consumption and environmental scares. These factors have\nled to multiple contributions in the literature that focus on devising\ncomputationally efficient DMs. In this review, we present the most recent\nadvances in diffusion models for vision, specifically focusing on the important\ndesign aspects that affect the computational efficiency of DMs. In particular,\nwe emphasize the recently proposed design choices that have led to more\nefficient DMs. Unlike the other recent reviews, which discuss diffusion models\nfrom a broad perspective, this survey is aimed at pushing this research\ndirection forward by highlighting the design strategies in the literature that\nare resulting in practicable models for the broader research community. We also\nprovide a future outlook of diffusion models in vision from their computational\nefficiency viewpoint.",
    "descriptor": "\nComments: 14 Pages, 5 Figures\n",
    "authors": [
      "Anwaar Ulhaq",
      "Naveed Akhtar",
      "Ganna Pogrebna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09292"
  },
  {
    "id": "arXiv:2210.09293",
    "title": "Learning Texture Transformer Network for Light Field Super-Resolution",
    "abstract": "Hand-held light field cameras suffer from low spatial resolution due to the\ninherent spatio-angular tradeoff. In this paper, we propose a method to improve\nthe spatial resolution of light field images with the aid of the Texture\nTransformer Network (TTSR). The proposed method consists of three modules: the\nfirst module produces an all-in focus high-resolution perspective image which\nserves as a reference image for the second module, i.e. TTSR, which in turn\nproduces a high-resolution light field. The last module refines the spatial\nresolution by imposing a light field prior. The results demonstrate around 4 dB\nto 6 dB PSNR gain over a bicubically resized light field image",
    "descriptor": "\nComments: European Conference on Visual Media Production (CVMP) 2022 short paper\n",
    "authors": [
      "Javeria Shabbir",
      "M. Zeshan Alam",
      "M. Umair Mukati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09293"
  },
  {
    "id": "arXiv:2210.09294",
    "title": "Story Designer: Towards a Mixed-Initiative Tool to Create Narrative  Structures",
    "abstract": "Narratives are a predominant part of games, and their design poses challenges\nwhen identifying, encoding, interpreting, evaluating, and generating them. One\nway to address this would be to approach narrative design in a more abstract\nlayer, such as narrative structures. This paper presents Story Designer, a\nmixed-initiative co-creative narrative structure tool built on top of the\nEvolutionary Dungeon Designer (EDD) that uses tropes, narrative conventions\nfound across many media types, to design these structures. Story Designer uses\ntropes as building blocks for narrative designers to compose complete narrative\nstructures by interconnecting them in graph structures called narrative graphs.\nOur mixed-initiative approach lets designers manually create their narrative\ngraphs and feeds an underlying evolutionary algorithm with those, creating\nquality-diverse suggestions using MAP-Elites. Suggestions are visually\nrepresented for designers to compare and evaluate and can then be incorporated\ninto the design for further manual editions. At the same time, we use the\nlevels designed within EDD as constraints for the narrative structure,\nintertwining both level design and narrative. We evaluate the impact of these\nconstraints and the system's adaptability and expressiveness, resulting in a\npotential tool to create narrative structures combining level design aspects\nwith narrative.",
    "descriptor": "\nComments: 9 pages, Accepted and to appear in Proceedings of the 17th International Conference on the Foundations of Digital Games (FDG), 2022\n",
    "authors": [
      "Alberto Alvarez",
      "Jose Font",
      "Julian Togelius"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09294"
  },
  {
    "id": "arXiv:2210.09296",
    "title": "3rd Place Solution for Google Universal Image Embedding",
    "abstract": "This paper presents the 3rd place solution to the Google Universal Image\nEmbedding Competition on Kaggle. We use ViT-H/14 from OpenCLIP for the backbone\nof ArcFace, and trained in 2 stage. 1st stage is done with freezed backbone,\nand 2nd stage is whole model training. We achieve 0.692 mean Precision @5 on\nprivate leaderboard. Code available at\nhttps://github.com/YasumasaNamba/google-universal-image-embedding",
    "descriptor": "\nComments: 3 pages, 5 figures\n",
    "authors": [
      "Nobuaki Aoki",
      "Yasumasa Namba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09296"
  },
  {
    "id": "arXiv:2210.09297",
    "title": "Neural Contact Fields: Tracking Extrinsic Contact with Tactile Sensing",
    "abstract": "We present Neural Contact Fields, a method that brings together neural fields\nand tactile sensing to address the problem of tracking extrinsic contact\nbetween object and environment. Knowing where the external contact occurs is a\nfirst step towards methods that can actively control it in facilitating\ndownstream manipulation tasks. Prior work for localizing environmental contacts\ntypically assume a contact type (e.g. point or line), does not capture\ncontact/no-contact transitions, and only works with basic geometric-shaped\nobjects. Neural Contact Fields are the first method that can track arbitrary\nmulti-modal extrinsic contacts without making any assumptions about the contact\ntype. Our key insight is to estimate the probability of contact for any 3D\npoint in the latent space of object shapes, given vision-based tactile inputs\nthat sense the local motion resulting from the external contact. In\nexperiments, we find that Neural Contact Fields are able to localize multiple\ncontact patches without making any assumptions about the geometry of the\ncontact, and capture contact/no-contact transitions for known categories of\nobjects with unseen shapes in unseen environment configurations. In addition to\nNeural Contact Fields, we also release our YCB-Extrinsic-Contact dataset of\nsimulated extrinsic contact interactions to enable further research in this\narea. Project repository: https://github.com/carolinahiguera/NCF",
    "descriptor": "",
    "authors": [
      "Carolina Higuera",
      "Siyuan Dong",
      "Byron Boots",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09297"
  },
  {
    "id": "arXiv:2210.09298",
    "title": "What Makes Convolutional Models Great on Long Sequence Modeling?",
    "abstract": "Convolutional models have been widely used in multiple domains. However, most\nexisting models only use local convolution, making the model unable to handle\nlong-range dependency efficiently. Attention overcomes this problem by\naggregating global information but also makes the computational complexity\nquadratic to the sequence length. Recently, Gu et al. [2021] proposed a model\ncalled S4 inspired by the state space model. S4 can be efficiently implemented\nas a global convolutional model whose kernel size equals the input sequence\nlength. S4 can model much longer sequences than Transformers and achieve\nsignificant gains over SoTA on several long-range tasks. Despite its empirical\nsuccess, S4 is involved. It requires sophisticated parameterization and\ninitialization schemes. As a result, S4 is less intuitive and hard to use. Here\nwe aim to demystify S4 and extract basic principles that contribute to the\nsuccess of S4 as a global convolutional model. We focus on the structure of the\nconvolution kernel and identify two critical but intuitive principles enjoyed\nby S4 that are sufficient to make up an effective global convolutional model:\n1) The parameterization of the convolutional kernel needs to be efficient in\nthe sense that the number of parameters should scale sub-linearly with sequence\nlength. 2) The kernel needs to satisfy a decaying structure that the weights\nfor convolving with closer neighbors are larger than the more distant ones.\nBased on the two principles, we propose a simple yet effective convolutional\nmodel called Structured Global Convolution (SGConv). SGConv exhibits strong\nempirical performance over several tasks: 1) With faster speed, SGConv\nsurpasses S4 on Long Range Arena and Speech Command datasets. 2) When plugging\nSGConv into standard language and vision models, it shows the potential to\nimprove both efficiency and performance.",
    "descriptor": "\nComments: The code is available at this https URL\n",
    "authors": [
      "Yuhong Li",
      "Tianle Cai",
      "Yi Zhang",
      "Deming Chen",
      "Debadeepta Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09298"
  },
  {
    "id": "arXiv:2210.09304",
    "title": "Non-Contrastive Learning Meets Language-Image Pre-Training",
    "abstract": "Contrastive language-image pre-training (CLIP) serves as a de-facto standard\nto align images and texts. Nonetheless, the loose correlation between images\nand texts of web-crawled data renders the contrastive objective data\ninefficient and craving for a large training batch size. In this work, we\nexplore the validity of non-contrastive language-image pre-training (nCLIP),\nand study whether nice properties exhibited in visual self-supervised models\ncan emerge. We empirically observe that the non-contrastive objective nourishes\nrepresentation learning while sufficiently underperforming under zero-shot\nrecognition. Based on the above study, we further introduce xCLIP, a\nmulti-tasking framework combining CLIP and nCLIP, and show that nCLIP aids CLIP\nin enhancing feature semantics. The synergy between two objectives lets xCLIP\nenjoy the best of both worlds: superior performance in both zero-shot transfer\nand representation learning. Systematic evaluation is conducted spanning a wide\nvariety of downstream tasks including zero-shot classification, out-of-domain\nclassification, retrieval, visual representation learning, and textual\nrepresentation learning, showcasing a consistent performance gain and\nvalidating the effectiveness of xCLIP.",
    "descriptor": "",
    "authors": [
      "Jinghao Zhou",
      "Li Dong",
      "Zhe Gan",
      "Lijuan Wang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09304"
  },
  {
    "id": "arXiv:2210.09305",
    "title": "Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor  Attacks in Federated Learning",
    "abstract": "Federated learning is particularly susceptible to model poisoning and\nbackdoor attacks because individual users have direct control over the training\ndata and model updates. At the same time, the attack power of an individual\nuser is limited because their updates are quickly drowned out by those of many\nother users. Existing attacks do not account for future behaviors of other\nusers, and thus require many sequential updates and their effects are quickly\nerased. We propose an attack that anticipates and accounts for the entire\nfederated learning pipeline, including behaviors of other clients, and ensures\nthat backdoors are effective quickly and persist even after multiple rounds of\ncommunity updates. We show that this new attack is effective in realistic\nscenarios where the attacker only contributes to a small fraction of randomly\nsampled rounds and demonstrate this attack on image classification, next-word\nprediction, and sentiment analysis.",
    "descriptor": "\nComments: Code is available at \\url{this https URL}\n",
    "authors": [
      "Yuxin Wen",
      "Jonas Geiping",
      "Liam Fowl",
      "Hossein Souri",
      "Rama Chellappa",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09305"
  },
  {
    "id": "arXiv:2210.09306",
    "title": "Mitigating Covertly Unsafe Text within Natural Language Systems",
    "abstract": "An increasingly prevalent problem for intelligent technologies is text\nsafety, as uncontrolled systems may generate recommendations to their users\nthat lead to injury or life-threatening consequences. However, the degree of\nexplicitness of a generated statement that can cause physical harm varies. In\nthis paper, we distinguish types of text that can lead to physical harm and\nestablish one particularly underexplored category: covertly unsafe text. Then,\nwe further break down this category with respect to the system's information\nand discuss solutions to mitigate the generation of text in each of these\nsubcategories. Ultimately, our work defines the problem of covertly unsafe\nlanguage that causes physical harm and argues that this subtle yet dangerous\nissue needs to be prioritized by stakeholders and regulators. We highlight\nmitigation strategies to inspire future researchers to tackle this challenging\nproblem and help improve safety within smart systems.",
    "descriptor": "\nComments: To Appear In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "Alex Mei",
      "Anisha Kabir",
      "Sharon Levy",
      "Melanie Subbiah",
      "Emily Allaway",
      "John Judge",
      "Desmond Patton",
      "Bruce Bimber",
      "Kathleen McKeown",
      "William Yang Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09306"
  },
  {
    "id": "arXiv:2210.06747",
    "title": "DCANet: Differential Convolution Attention Network for RGB-D Semantic  Segmentation",
    "abstract": "Combining RGB images and the corresponding depth maps in semantic\nsegmentation proves the effectiveness in the past few years. Existing RGB-D\nmodal fusion methods either lack the non-linear feature fusion ability or treat\nboth modal images equally, regardless of the intrinsic distribution gap or\ninformation loss. Here we find that depth maps are suitable to provide\nintrinsic fine-grained patterns of objects due to their local depth continuity,\nwhile RGB images effectively provide a global view. Based on this, we propose a\npixel differential convolution attention (DCA) module to consider geometric\ninformation and local-range correlations for depth data. Furthermore, we extend\nDCA to ensemble differential convolution attention (EDCA) which propagates\nlong-range contextual dependencies and seamlessly incorporates spatial\ndistribution for RGB data. DCA and EDCA dynamically adjust convolutional\nweights by pixel difference to enable self-adaptive in local and long range,\nrespectively. A two-branch network built with DCA and EDCA, called Differential\nConvolutional Network (DCANet), is proposed to fuse local and global\ninformation of two-modal data. Consequently, the individual advantage of RGB\nand depth data are emphasized. Our DCANet is shown to set a new\nstate-of-the-art performance for RGB-D semantic segmentation on two challenging\nbenchmark datasets, i.e., NYUDv2 and SUN-RGBD.",
    "descriptor": "",
    "authors": [
      "Lizhi Bai",
      "Jun Yang",
      "Chunqi Tian",
      "Yaoru Sun",
      "Maoyu Mao",
      "Yanjun Xu",
      "Weirong Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06747"
  },
  {
    "id": "arXiv:2210.08004",
    "title": "Misaligned orientations of 4f optical neural network for image  classification accuracy on various datasets",
    "abstract": "In recent years, the optical 4f system has drawn much attention in building\nhigh-speed and ultra-low-power optical neural networks (ONNs). Most optical\nsystems suffer from the misalignment of the optical devices during installment.\nThe performance of ONN based on the optical 4f system (4f-ONN) is considered\nsensitive to the misalignment in the optical path introduced. In order to\ncomprehensively investigate the influence caused by the misalignment, we\nproposed a method for estimating the performance of a 4f-ONN in response to\nvarious misalignment in the context of the image classification task.The\nmisalignment in numerical simulation is estimated by manipulating the optical\nintensity distributions in the fourth focus plane in the 4f system. Followed by\na series of physical experiments to validate the simulation results. Using our\nmethod to test the impact of misalignment of 4f system on the classification\naccuracy of two popular image classification datasets, MNIST and Quickdraw16.\nOn both datasets, we found that the performances of 4f-ONN generally degraded\ndramatically as the positioning error increased. Different positioning error\ntolerance in the misalignment orientations was observed over the two datasets.\nClassification performance could be preserved by positioning errors up to 200\nmicrons in a specific direction.",
    "descriptor": "",
    "authors": [
      "Yanbing Liu",
      "Wei Li",
      "Kun Cheng",
      "Xun Liu",
      "Wei Yang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.08004"
  },
  {
    "id": "arXiv:2210.08016",
    "title": "Prediction of drug effectiveness in rheumatoid arthritis patients based  on machine learning algorithms",
    "abstract": "Rheumatoid arthritis (RA) is an autoimmune condition caused when patients'\nimmune system mistakenly targets their own tissue. Machine learning (ML) has\nthe potential to identify patterns in patient electronic health records (EHR)\nto forecast the best clinical treatment to improve patient outcomes. This study\nintroduced a \\textbf{D}rug \\textbf{R}esponse \\textbf{P}rediction (DRP)\nframework with two main goals: 1) design a data processing pipeline to extract\ninformation from tabular clinical data, and then preprocess it for functional\nuse, and 2) predict RA patient's responses to drugs and evaluate classification\nmodels' performance. We propose a novel two-stage ML framework based on\nEuropean Alliance of Associations for Rheumatology (EULAR) criteria cutoffs to\nmodel drug effectiveness. Our model Stacked-Ensemble DRP was developed and\ncross-validated using data from 425 RA patients. The evaluation used a subset\nof 124 patients (30\\%) from the same data source. In the evaluation of the test\nset, two-stage DRP leads to improved classification accuracy over other\nend-to-end classification models for binary classification. Our proposed method\nprovides a complete pipeline to predict disease activity scores and identify\nthe group that does not respond well to anti-TNF treatments, thus showing\npromise in supporting clinical decisions based on EHR information. Codes and\nsample fictional datasets to test our model are given at \\url{\nhttps://github.com/Gaskell-1206/Ensemble_DRP}.",
    "descriptor": "\nComments: 13 pages, 5 figures, to be published in ICBBE 2022\n",
    "authors": [
      "Shengjia Chen",
      "Nikunj Gupta",
      "Woodward B. Galbraith",
      "Valay Shah",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.08016"
  },
  {
    "id": "arXiv:2210.08027",
    "title": "Predicting Good Quantum Circuit Compilation Options",
    "abstract": "Any potential application of quantum computing, once encoded as a quantum\ncircuit, needs to be compiled in order to be executed on a quantum computer.\nDeciding which qubit technology, which device, which compiler, and which\ncorresponding settings are best for the considered problem -- according to a\nmeasure of goodness -- requires expert knowledge and is overwhelming for\nend-users from different domains trying to use quantum computing to their\nadvantage. In this work, we treat the problem as a statistical classification\ntask and explore the utilization of supervised machine learning techniques to\noptimize the compilation of quantum circuits. Based on that, we propose a\nframework that, given a quantum circuit, predicts the best combination of these\noptions and, by that, automatically makes these decisions for the end-user.\nExperimental evaluations show that, considering a prototypical setting with\nover 2000 quantum circuits, the proposed framework achieves great performance:\nfor more than three quarters of all unseen test circuits, the best combination\nof compilation options is determined. Moreover, for more than 90% of the\ncircuits, a combination of compilation options within the top-three is\ndetermined. Furthermore, the resulting methodology does not only provide\nend-users with a prediction on the best compilation options, but additionally\nprovides means to extract explicit knowledge from the machine learning\ntechnique. This knowledge helps in two ways: it lays the foundation for further\napplications of machine learning in this domain and, also, allows to quickly\nverify whether a machine learning algorithm is reasonably trained. The\ncorresponding framework and the pre-trained classifier are publicly available\non GitHub (https://github.com/cda-tum/MQTPredictor).",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Nils Quetschlich",
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.08027"
  },
  {
    "id": "arXiv:2210.08087",
    "title": "Movement Penalized Bayesian Optimization with Application to Wind Energy  Systems",
    "abstract": "Contextual Bayesian optimization (CBO) is a powerful framework for sequential\ndecision-making given side information, with important applications, e.g., in\nwind energy systems. In this setting, the learner receives context (e.g.,\nweather conditions) at each round, and has to choose an action (e.g., turbine\nparameters). Standard algorithms assume no cost for switching their decisions\nat every round. However, in many practical applications, there is a cost\nassociated with such changes, which should be minimized. We introduce the\nepisodic CBO with movement costs problem and, based on the online learning\napproach for metrical task systems of Coester and Lee (2019), propose a novel\nrandomized mirror descent algorithm that makes use of Gaussian Process\nconfidence bounds. We compare its performance with the offline optimal sequence\nfor each episode and provide rigorous regret guarantees. We further demonstrate\nour approach on the important real-world application of altitude optimization\nfor Airborne Wind Energy Systems. In the presence of substantial movement\ncosts, our algorithm consistently outperforms standard CBO algorithms.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Shyam Sundhar Ramesh",
      "Pier Giuseppe Sessa",
      "Andreas Krause",
      "Ilija Bogunovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08087"
  },
  {
    "id": "arXiv:2210.08104",
    "title": "Gibbs Sampling of Periodic Potentials on a Quantum Computer",
    "abstract": "Motivated by applications in machine learning, we present a quantum algorithm\nfor Gibbs sampling from a continuous real-valued function defined on a high\ndimensional torus. Our algorithm relies on techniques for solving linear\nsystems and partial differential equations and performs zeroeth order queries\nto a quantum oracle computing the energy function. We then analyze the query\nand gate complexity of our algorithm and prove that the algorithm has a\npolylogarithmic dependence on approximation error (in total variation distance)\nand a polynomial dependence on the number of variables, although it suffers\nfrom an exponentially poor dependence on temperature.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Arsalan Motamedi",
      "Pooya Ronagh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.08104"
  },
  {
    "id": "arXiv:2210.08110",
    "title": "A Multistep Frank-Wolfe Method",
    "abstract": "The Frank-Wolfe algorithm has regained much interest in its use in\nstructurally constrained machine learning applications. However, one major\nlimitation of the Frank-Wolfe algorithm is the slow local convergence property\ndue to the zig-zagging behavior. We observe the zig-zagging phenomenon in the\nFrank-Wolfe method as an artifact of discretization, and propose multistep\nFrank-Wolfe variants where the truncation errors decay as $O(\\Delta^p)$, where\n$p$ is the method's order. This strategy \"stabilizes\" the method, and allows\ntools like line search and momentum to have more benefits. However, our results\nsuggest that the worst case convergence rate of Runge-Kutta-type discretization\nschemes cannot improve upon that of the vanilla Frank-Wolfe method for a rate\ndepending on $k$. Still, we believe that this analysis adds to the growing\nknowledge of flow analysis for optimization methods, and is a cautionary tale\non the ultimate usefulness of multistep methods.",
    "descriptor": "\nComments: 12 pages, Continuous time methods for machine learning International Conference on Machine Learning Workshop, Baltimore, Maryland, USA, 2022. arXiv admin note: substantial text overlap with arXiv:2106.05753\n",
    "authors": [
      "Zhaoyue Chen",
      "Yifan Sun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08110"
  },
  {
    "id": "arXiv:2210.08114",
    "title": "QuAnt: Quantum Annealing with Learnt Couplings",
    "abstract": "Modern quantum annealers can find high-quality solutions to combinatorial\noptimisation objectives given as quadratic unconstrained binary optimisation\n(QUBO) problems. Unfortunately, obtaining suitable QUBO forms in computer\nvision remains challenging and currently requires problem-specific analytical\nderivations. Moreover, such explicit formulations impose tangible constraints\non solution encodings. In stark contrast to prior work, this paper proposes to\nlearn QUBO forms from data through gradient backpropagation instead of deriving\nthem. As a result, the solution encodings can be chosen flexibly and compactly.\nFurthermore, our methodology is general and virtually independent of the\nspecifics of the target problem type. We demonstrate the advantages of learnt\nQUBOs on the diverse problem types of graph matching, 2D point cloud alignment\nand 3D rotation estimation. Our results are competitive with the previous\nquantum state of the art while requiring much fewer logical and physical\nqubits, enabling our method to scale to larger problems. The code and the new\ndataset will be open-sourced.",
    "descriptor": "\nComments: incl. appendix\n",
    "authors": [
      "Marcel Seelbach Benkner",
      "Maximilian Krahn",
      "Edith Tretschk",
      "Zorah L\u00e4hner",
      "Michael Moeller",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08114"
  },
  {
    "id": "arXiv:2210.08131",
    "title": "Model-Free Characterizations of the Hamilton-Jacobi-Bellman Equation and  Convex Q-Learning in Continuous Time",
    "abstract": "Convex Q-learning is a recent approach to reinforcement learning, motivated\nby the possibility of a firmer theory for convergence, and the possibility of\nmaking use of greater a priori knowledge regarding policy or value function\nstructure. This paper explores algorithm design in the continuous time domain,\nwith finite-horizon optimal control objective. The main contributions are (i)\nAlgorithm design is based on a new Q-ODE, which defines the model-free\ncharacterization of the Hamilton-Jacobi-Bellman equation. (ii) The Q-ODE\nmotivates a new formulation of Convex Q-learning that avoids the approximations\nappearing in prior work. The Bellman error used in the algorithm is defined by\nfiltered measurements, which is beneficial in the presence of measurement\nnoise. (iii) A characterization of boundedness of the constraint region is\nobtained through a non-trivial extension of recent results from the discrete\ntime setting. (iv) The theory is illustrated in application to resource\nallocation for distributed energy resources, for which the theory is ideally\nsuited.",
    "descriptor": "",
    "authors": [
      "Fan Lu",
      "Joel Mathias",
      "Sean Meyn",
      "Karanjit Kalsi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08131"
  },
  {
    "id": "arXiv:2210.08135",
    "title": "Quantum Network Utility Maximization",
    "abstract": "Network Utility Maximization (NUM) is a mathematical framework that has\nendowed researchers with powerful methods for designing and analyzing classical\ncommunication protocols. NUM has also enabled the development of distributed\nalgorithms for solving the resource allocation problem, while at the same time\nproviding certain guarantees, e.g., that of fair treatment, to the users of a\nnetwork. We extend here the notion of NUM to quantum networks, and propose\nthree quantum utility functions -- each incorporating a different entanglement\nmeasure. We aim both to gain an understanding of some of the ways in which\nquantum users may perceive utility, as well as to explore structured and\ntheoretically-motivated methods of simultaneously servicing multiple users in\ndistributed quantum systems. Using our quantum NUM constructions, we develop an\noptimization framework for networks that use the single-photon scheme for\nentanglement generation, which enables us to solve the resource allocation\nproblem while exploring rate-fidelity tradeoffs within the network topologies\nthat we consider. We learn that two of our utility functions, which are based\non distillable entanglement and secret key fraction, are in close agreement\nwith each other and produce similar solutions to the optimization problems we\nstudy. Our third utility, based on entanglement negativity, has more favorable\nmathematical properties, and tends to place a higher value on the rate at which\nusers receive entangled resources, compared to the two previous utilities,\nwhich put a higher emphasis on end-to-end fidelity. These contrasting behaviors\nthus provide ideas regarding the suitability of quantum network utility\ndefinitions to different quantum applications.",
    "descriptor": "",
    "authors": [
      "Gayane Vardoyan",
      "Stephanie Wehner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.08135"
  },
  {
    "id": "arXiv:2210.08140",
    "title": "A Kernel Approach for PDE Discovery and Operator Learning",
    "abstract": "This article presents a three-step framework for learning and solving partial\ndifferential equations (PDEs) using kernel methods. Given a training set\nconsisting of pairs of noisy PDE solutions and source/boundary terms on a mesh,\nkernel smoothing is utilized to denoise the data and approximate derivatives of\nthe solution. This information is then used in a kernel regression model to\nlearn the algebraic form of the PDE. The learned PDE is then used within a\nkernel based solver to approximate the solution of the PDE with a new\nsource/boundary term, thereby constituting an operator learning framework. The\nproposed method is mathematically interpretable and amenable to analysis, and\nconvenient to implement. Numerical experiments compare the method to\nstate-of-the-art algorithms and demonstrate its superior performance on small\namounts of training data and for PDEs with spatially variable coefficients.",
    "descriptor": "",
    "authors": [
      "Da Long",
      "Nicole Mrvaljevic",
      "Shandian Zhe",
      "Bamdad Hosseini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08140"
  },
  {
    "id": "arXiv:2210.08150",
    "title": "Encoding subshifts through sliding block codes",
    "abstract": "We prove a generalization of Krieger's embedding theorem, in the spirit of\nzero-error information theory. Specifically, given a mixing shift of finite\ntype $X$, a mixing sofic shift $Y$, and a surjective sliding block code $\\pi: X\n\\to Y$, we give necessary and sufficient conditions for a subshift $Z$ of\ntopological entropy strictly lower than that of $Y$ to admit an embedding\n$\\psi: Z \\to X$ such that $\\pi \\circ \\psi$ is injective.",
    "descriptor": "\nComments: 12 pages, no figures\n",
    "authors": [
      "Sophie MacDonald"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08150"
  },
  {
    "id": "arXiv:2210.08165",
    "title": "a quantum secure multiparty computation protocol for least common  multiple",
    "abstract": "In this paper, we present a secure multiparty computation (SMC) protocol for\nleast common multiple (LCM) based on Shor's quantum period-finding algorithm\n(QPA). Our protocol is based on the following principle: the connection of\nmultiple periodic functions is also a periodic function whose period is exactly\nthe least common multiple of all small periods. Since QPA is a probabilistic\nalgorithm, we also propose a one-vote-down vote protocol based on the existing\nsecure multi-party quantum summation protocol, which is used to verify the\nresults of the proposed LCM protocol. Security analysis shows that under the\nsemi-honest model, the proposed protocol is secure with high probability, while\nthe computational consumption remains at polynomial complexity. The protocol\nproposed in this paper solves the problem of efficient and secure multiparty\ncomputation of LCM, demonstrating quantum computation potential.",
    "descriptor": "\nComments: 16 pages, 0 figures\n",
    "authors": [
      "Zixian Li",
      "Wenjie Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08165"
  },
  {
    "id": "arXiv:2210.08190",
    "title": "TopGen: Topology-Aware Bottom-Up Generator for Variational Quantum  Circuits",
    "abstract": "Variational Quantum Algorithms (VQA) are promising to demonstrate quantum\nadvantages on near-term devices. Designing ansatz, a variational circuit with\nparameterized gates, is of paramount importance for VQA as it lays the\nfoundation for parameter optimizations. Due to the large noise on\nNoisy-Intermediate Scale Quantum (NISQ) machines, considering circuit size and\nreal device noise in the ansatz design process is necessary. Unfortunately,\nrecent works on ansatz design either consider no noise impact or only treat the\nreal device as a black box with no specific noise information. In this work, we\npropose to open the black box by designing specific ansatz tailored for the\nqubit topology on target machines. Specifically, we propose a bottom-up\napproach to generate topology-specific ansatz. Firstly, we generate\ntopology-compatible sub-circuits with desirable properties such as high\nexpressibility and entangling capability. Then, the sub-circuits are combined\ntogether to form an initial ansatz. We further propose circuits stitching to\nsolve the sparse connectivity issue between sub-circuits, and dynamic circuit\ngrowing to improve the accuracy. The ansatz constructed with this method is\nhighly flexible and thus we can explore a much larger design space than\nprevious state-of-the-art method in which all ansatz candidates are strict\nsubsets of a pre-defined large ansatz. We use a popular VQA algorithm - Quantum\nNeural Networks (QNN) for Machine Learning (ML) task as the benchmarks.\nExperiments on 14 ML tasks show that under the same performance, the\nTopGen-searched ansatz can reduce the circuit depth and the number of CNOT\ngates by up to 2 * and 4 * respectively. Experiments on three real quantum\nmachines demonstrate on average 17% accuracy improvements over baselines.",
    "descriptor": "\nComments: 13 pages, 14 figures\n",
    "authors": [
      "Jinglei Cheng",
      "Hanrui Wang",
      "Zhiding Liang",
      "Yiyu Shi",
      "Song Han",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08190"
  },
  {
    "id": "arXiv:2210.08220",
    "title": "Min max method, shape, topological derivatives, averaged Lagrangian,  homogenization, two scale convergence, Helmholtz equation",
    "abstract": "In this paper, we perform a rigourous version of shape and topological\nderivatives for optimizations problems under constraint Helmoltz problems. A\nshape and topological optimization problem is formulated by introducing cost\nfunctional. We derive first by considering the lagradian method the shape\nderivative of the functional. It is also proven a topological derivative with\nthe same approach. An application to several unconstrained shape functions\narising from differential geometry are also given.",
    "descriptor": "",
    "authors": [
      "Mame Gor Ngom",
      "Ibrahima Faye",
      "Diaraf Seck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08220"
  },
  {
    "id": "arXiv:2210.08225",
    "title": "Learned Video Compression for YUV 4:2:0 Content Using Flow-based  Conditional Inter-frame Coding",
    "abstract": "This paper proposes a learning-based video compression framework for\nvariable-rate coding on YUV 4:2:0 content. Most existing learning-based video\ncompression models adopt the traditional hybrid-based coding architecture,\nwhich involves temporal prediction followed by residual coding. However, recent\nstudies have shown that residual coding is sub-optimal from the\ninformation-theoretic perspective. In addition, most existing models are\noptimized with respect to RGB content. Furthermore, they require separate\nmodels for variable-rate coding. To address these issues, this work presents an\nattempt to incorporate the conditional inter-frame coding for YUV 4:2:0\ncontent. We introduce a conditional flow-based inter-frame coder to improve the\ninter-frame coding efficiency. To adapt our codec to YUV 4:2:0 content, we\nadopt a simple strategy of using space-to-depth and depth-to-space conversions.\nLastly, we employ a rate-adaption net to achieve variable-rate coding without\ntraining multiple models. Experimental results show that our model performs\nbetter than x265 on UVG and MCL-JCV datasets in terms of PSNR-YUV. However, on\nthe more challenging datasets from ISCAS'22 GC, there is still ample room for\nimprovement. This insufficient performance is due to the lack of inter-frame\ncoding capability at a large GOP size and can be mitigated by increasing the\nmodel capacity and applying an error propagation-aware training strategy.",
    "descriptor": "\nComments: Accepted by ISCAS 2022\n",
    "authors": [
      "Yung-Han Ho",
      "Chih-Hsuan Lin",
      "Peng-Yu Chen",
      "Mu-Jung Chen",
      "Chih-Peng Chang",
      "Wen-Hsiao Peng",
      "Hsueh-Ming Hang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08225"
  },
  {
    "id": "arXiv:2210.08289",
    "title": "AI-powered tiebreak mechanisms: An application to chess",
    "abstract": "In this paper, we propose that AI systems serve as a judge in the event of a\ndraw in games such as chess and in the event of a tie in tournaments. More\nspecifically, we introduce a family of AI-based scoring mechanisms and the\nconcept of \"tiebreak strategyproofness\" in $n$-person zero-sum games. A\nmechanism is called tiebreak strategyproof (TSP) if it is always in the best\ninterest of every player to choose the \"best\" action according to a given AI\nsystem. As such, we introduce a practicable scoring mechanism in chess and show\nthat it is TSP, i.e., it is never in the interest of a player to deliberately\nplay a worse move to increase their advantage in case the game goes to the\ntiebreak. In other words, TSP mechanisms are immune to such strategic\nmanipulations. We also show that the current \"speed-chess\" tiebreaks are not\nTSP or immune to manipulation with an example from 2018 world chess\nchampionship between Carlsen and Caruana.",
    "descriptor": "",
    "authors": [
      "Nejat Anbarci",
      "Mehmet S. Ismail"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08289"
  },
  {
    "id": "arXiv:2210.08312",
    "title": "Disordered Systems Insights on Computational Hardness",
    "abstract": "In this review article, we discuss connections between the physics of\ndisordered systems, phase transitions in inference problems, and computational\nhardness. We introduce two models representing the behavior of glassy systems,\nthe spiked tensor model and the generalized linear model. We discuss the random\n(non-planted) versions of these problems as prototypical optimization problems,\nas well as the planted versions (with a hidden solution) as prototypical\nproblems in statistical inference and learning. Based on ideas from physics,\nmany of these problems have transitions where they are believed to jump from\neasy (solvable in polynomial time) to hard (requiring exponential time). We\ndiscuss several emerging ideas in theoretical computer science and statistics\nthat provide rigorous evidence for hardness by proving that large classes of\nalgorithms fail in the conjectured hard regime. This includes the overlap gap\nproperty, a particular mathematization of clustering or dynamical\nsymmetry-breaking, which can be used to show that many algorithms that are\nlocal or robust to changes in their input fail. We also discuss the\nsum-of-squares hierarchy, which places bounds on proofs or algorithms that use\nlow-degree polynomials such as standard spectral methods and semidefinite\nrelaxations, including the Sherrington-Kirkpatrick model. Throughout the\nmanuscript, we present connections to the physics of disordered systems and\nassociated replica symmetry breaking properties.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "David Gamarnik",
      "Cristopher Moore",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.08312"
  },
  {
    "id": "arXiv:2210.08326",
    "title": "Distributionally Robust Causal Inference with Observational Data",
    "abstract": "We consider the estimation of average treatment effects in observational\nstudies without the standard assumption of unconfoundedness. We propose a new\nframework of robust causal inference under the general observational study\nsetting with the possible existence of unobserved confounders. Our approach is\nbased on the method of distributionally robust optimization and proceeds in two\nsteps. We first specify the maximal degree to which the distribution of\nunobserved potential outcomes may deviate from that of obsered outcomes. We\nthen derive sharp bounds on the average treatment effects under this\nassumption. Our framework encompasses the popular marginal sensitivity model as\na special case and can be extended to the difference-in-difference and\nregression discontinuity designs as well as instrumental variables. Through\nsimulation and empirical studies, we demonstrate the applicability of the\nproposed methodology to real-world settings.",
    "descriptor": "",
    "authors": [
      "Dimitris Bertsimas",
      "Kosuke Imai",
      "Michael Lingzhi Li"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08326"
  },
  {
    "id": "arXiv:2210.08330",
    "title": "Aplicaci\u00f3n de redes neuronales convolucionales profundas al  diagn\u00f3stico asistido de la enfermedad de Alzheimer",
    "abstract": "Currently, the diagnosis of Alzheimer's disease is a complex and error-prone\nprocess. Improving this diagnosis could allow earlier detection of the disease\nand improve the quality of life of patients and their families. For this work,\nwe will use 249 brain images from two modalities: PET and MRI, taken from the\nADNI database, and labelled into three classes according to the degree of\ndevelopment of Alzheimer's disease. We propose the development of a\nconvolutional neural network to perform the classification of these images,\nduring which, we will study the appropriate depth of the networks for this\nproblem, the importance of pre-processing medical images, the use of transfer\nlearning and data augmentation techniques as tools to reduce the effects of the\nproblem of having too little data, and the simultaneous use of multiple medical\nimaging modalities. We also propose the application of an evaluation method\nthat guarantees a good degree of repeatability of the results even when using a\nsmall dataset. Following this evaluation method, our best final model, which\nmakes use of transfer learning with COVID-19 data, achieves an accuracy d 68\\%.\nIn addition, in an independent test set, this same model achieves 70\\%\naccuracy, a promising result given the small size of our dataset. We further\nconclude that augmenting the depth of the networks helps with this problem,\nthat image pre-processing is a fundamental process to address this type of\nmedical problem, and that the use of data augmentation and the use of\npre-trained networks with images of other diseases can provide significant\nimprovements.",
    "descriptor": "\nComments: in Spanish language\n",
    "authors": [
      "\u00c1ngel de la Vega Jim\u00e9nez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08330"
  },
  {
    "id": "arXiv:2210.08357",
    "title": "Vehicle Risk Assessment and Control for Lane-Keeping and Collision  Avoidance in Urban and Highway Driving Scenarios",
    "abstract": "This article examines a symbolic numerical approach to optimize a vehicle's\ntrack for autonomous driving and collision avoidance. The new approach uses the\nclassical cost function definition incorporating the essential aspects of the\ndynamic state of the vehicle as position, orientation, time sampling, and\nconstraints on slip angles of tires. The optimization processes minimize the\ncost function and simultaneously determine the optimal track by varying\nsteering and breaking amplitudes. The current velocity of the vehicle is\nlimited to a maximal velocity, thus, allowing a stable search of the optimal\ntrack. The parametric definition of obstacles generates a flexible environment\nfor low and high speed simulations. The minimal number of influential\noptimization variables guarantees a stable and direct generation of optimal\nresults. By the current new approach to control a vehicle on an optimal track,\nwe are able to autonomously move the vehicle on an arbitrary track approximated\nby low order polynomials. The optimization approach is also able to deal with a\nvariety of different obstacles and the corresponding optimal smooth obstacle\npath. The computations demonstrate the effective control of a four wheel\nvehicle in normal operation and exceptional obstacle avoidance with\ncontinuously differentiable obstacle avoidance tracks. Simulation tests are\ndone using vehicle's velocities of 3m/s, 6m/s, 7.6m/s, 10m/s, 12m/s, and 18m/s.\nAt higher vehicle's velocities, a mathematical-only approach is not sufficient\nand a mechanical intervention for tires is needed as a complimentary part to\ncontrol the slip angle. The results shows that the cost function reached a\nconsiderably high average convergence-to-zero rate success in most of the\ntested scenarios.",
    "descriptor": "\nComments: 15 pages, 17 figures, 6 tables, 29 equations\n",
    "authors": [
      "Hazem Fahmy",
      "Mohamed A. Abd El Ghany",
      "Gerd Baumann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08357"
  },
  {
    "id": "arXiv:2210.08382",
    "title": "Machine-Learning Love: classifying the equation of state of neutron  stars with Transformers",
    "abstract": "The use of the Audio Spectrogram Transformer (AST) model for\ngravitational-wave data analysis is investigated. The AST machine-learning\nmodel is a convolution-free classifier that captures long-range global\ndependencies through a purely attention-based mechanism. In this paper a model\nis applied to a simulated dataset of inspiral gravitational wave signals from\nbinary neutron star coalescences, built from five distinct, cold equations of\nstate (EOS) of nuclear matter. From the analysis of the mass dependence of the\ntidal deformability parameter for each EOS class it is shown that the AST model\nachieves a promising performance in correctly classifying the EOS purely from\nthe gravitational wave signals, especially when the component masses of the\nbinary system are in the range $[1,1.5]M_{\\odot}$. Furthermore, the\ngeneralization ability of the model is investigated by using gravitational-wave\nsignals from a new EOS not used during the training of the model, achieving\nfairly satisfactory results. Overall, the results, obtained using the\nsimplified setup of noise-free waveforms, show that the AST model, once\ntrained, might allow for the instantaneous inference of the cold nuclear matter\nEOS directly from the inspiral gravitational-wave signals produced in binary\nneutron star coalescences.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Gon\u00e7alo Gon\u00e7alves",
      "M\u00e1rcio Ferreira",
      "Jo\u00e3o Aveiro",
      "Antonio Onofre",
      "Felipe F. Freitas",
      "Constan\u00e7a Provid\u00eancia",
      "Jos\u00e9 A. Font"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2210.08382"
  },
  {
    "id": "arXiv:2210.08383",
    "title": "Comment: The Essential Role of Policy Evaluation for the 2020 Census  Disclosure Avoidance System",
    "abstract": "In \"Differential Perspectives: Epistemic Disconnects Surrounding the US\nCensus Bureau's Use of Differential Privacy,\" boyd and Sarathy argue that\nempirical evaluations of the Census Disclosure Avoidance System (DAS),\nincluding our published analysis, failed to recognize how the benchmark data\nagainst which the 2020 DAS was evaluated is never a ground truth of population\ncounts. In this commentary, we explain why policy evaluation, which was the\nmain goal of our analysis, is still meaningful without access to a perfect\nground truth. We also point out that our evaluation leveraged features specific\nto the decennial Census and redistricting data, such as block-level population\ninvariance under swapping and voter file racial identification, better\napproximating a comparison with the ground truth. Lastly, we show that accurate\nstatistical predictions of individual race based on the Bayesian Improved\nSurname Geocoding, while not a violation of differential privacy, substantially\nincreases the disclosure risk of private information the Census Bureau sought\nto protect. We conclude by arguing that policy makers must confront a key\ntrade-off between data utility and privacy protection, and an epistemic\ndisconnect alone is insufficient to explain disagreements between policy\nchoices.",
    "descriptor": "\nComments: Version accepted to Harvard Data Science Review\n",
    "authors": [
      "Christopher T. Kenny",
      "Shiro Kuriwaki",
      "Cory McCartan",
      "Evan T. R. Rosenman",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.08383"
  },
  {
    "id": "arXiv:2210.08387",
    "title": "Time-Varying Semidefinite Programming: Path Following a Burer--Monteiro  Factorization",
    "abstract": "We present an online algorithm for time-varying semidefinite programs\n(TV-SDPs), based on the tracking of the solution trajectory of a low-rank\nmatrix factorization, also known as the Burer--Monteiro factorization, in a\npath-following procedure. There, a predictor-corrector algorithm solves a\nsequence of linearized systems. This requires the introduction of a horizontal\nspace constraint to ensure the local injectivity of the low-rank factorization.\nThe method produces a sequence of approximate solutions for the original TV-SDP\nproblem, for which we show that they stay close to the optimal solution path if\nproperly initialized. Numerical experiments for a time-varying Max-Cut SDP\nrelaxation demonstrate the computational advantages of the proposed method for\ntracking TV-SDPs in terms of runtime compared to off-the-shelf interior point\nmethods.",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "Antonio Bellon",
      "Mareike Dressler",
      "Vyacheslav Kungurtsev",
      "Jakub Marecek",
      "Andr\u00e9 Uschmajew"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08387"
  },
  {
    "id": "arXiv:2210.08440",
    "title": "Consistency pays off in science",
    "abstract": "The exponentially growing number of scientific papers stimulates a discussion\non the interplay between quantity and quality in science. In particular, one\nmay wonder which publication strategy may offer more chances of success:\npublishing lots of papers, producing a few hit papers, or something in between.\nHere we tackle this question by studying the scientific portfolios of Nobel\nPrize laureates. A comparative analysis of different citation-based indicators\nof individual impact suggests that the best path to success may rely on\nconsistently producing high-quality work. Such a pattern is especially rewarded\nby a new metric, the $E$-index, which identifies excellence better than\nstate-of-the-art measures.",
    "descriptor": "\nComments: 8 pages, 4 figures, 8 tables\n",
    "authors": [
      "Sirag Erkol",
      "Satyaki Sikdar",
      "Filippo Radicchi",
      "Santo Fortunato"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.08440"
  },
  {
    "id": "arXiv:2210.08484",
    "title": "End-to-end Two-dimensional Sound Source Localization With Ad-hoc  Microphone Arrays",
    "abstract": "Conventional sound source localization methods are mostly based on a single\nmicrophone array that consists of multiple microphones. They are usually\nformulated as the estimation of the direction of arrival problem. In this\npaper, we propose a deep-learning-based end-to-end sound source localization\nmethod with ad-hoc microphone arrays, where an ad-hoc microphone array is a set\nof randomly distributed microphone arrays that collaborate with each other. It\ncan produce two-dimensional locations of speakers with only a single microphone\nper node. Specifically, we divide a targeted indoor space into multiple local\nareas. We encode each local area by a one-hot code, therefore, the node and\nspeaker locations can be represented by the one-hot codes. Accordingly, the\nsound source localization problem is formulated as such a classification task\nof recognizing the one-hot code of the speaker given the one hot codes of the\nmicrophone nodes and their speech recordings. An end-to-end spatial-temporal\ndeep model is designed for the classification problem. It utilizes a\nspatial-temporal attention architecture with a fusion layer inserted in the\nmiddle of the architecture, which is able to handle arbitrarily different\nnumbers of microphone nodes during the model training and test. Experimental\nresults show that the proposed method yields good performance in highly\nreverberant and noisy environments.",
    "descriptor": "\nComments: 6 pages, 4 figures, coference\n",
    "authors": [
      "Yijun Gong",
      "Shupei Liu",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.08484"
  },
  {
    "id": "arXiv:2210.08516",
    "title": "A lower bound for the smallest eigenvalue of a graph and an application  to the associahedron graph",
    "abstract": "In this paper, we obtain a lower bound for the smallest eigenvalue of a\nregular graph containing many copies of a smaller fixed subgraph. This\ngeneralizes a result of Aharoni, Alon, and Berger in which the subgraph is a\ntriangle. We apply our results to obtain a lower bound on the smallest\neigenvalue of the associahedron graph, and we prove that this bound gives the\ncorrect order of magnitude of this eigenvalue. We also survey what is known\nregarding the second-largest eigenvalue of the associahedron graph.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Sebastian M. Cioab\u0103",
      "Vishal Gupta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08516"
  },
  {
    "id": "arXiv:2210.08545",
    "title": "D/M/1 Queue: Policies and Control",
    "abstract": "Equilibrium G/M/1-FIFO waiting times are exponentially distributed, as first\nproved by Smith (1953). For other client-sorting policies, such generality is\nnot feasible. Assume that interarrival times are constant. Symbolics for the\nD/M/1-LIFO density are completely known; numerics for D/M/1-SIRO arise via an\nunpublished recursion due to Burke (1967). Consider a weighted sum of two\ncosts, one from keeping clients waiting for treatment and the other from having\nthe server idle. With this in mind, what is the optimal interarrival time and\nhow does this depend on the choice of policy?",
    "descriptor": "\nComments: 14 pages; 2 figures\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2210.08545"
  },
  {
    "id": "arXiv:2210.08549",
    "title": "Automatic Emergency Dust-Free solution on-board International Space  Station with Bi-GRU (AED-ISS)",
    "abstract": "With a rising attention for the issue of PM2.5 or PM0.3, particulate matters\nhave become not only a potential threat to both the environment and human, but\nalso a harming existence to instruments onboard International Space Station\n(ISS). Our team is aiming to relate various concentration of particulate\nmatters to magnetic fields, humidity, acceleration, temperature, pressure and\nCO2 concentration. Our goal is to establish an early warning system (EWS),\nwhich is able to forecast the levels of particulate matters and provides ample\nreaction time for astronauts to protect their instruments in some experiments\nor increase the accuracy of the measurements; In addition, the constructed\nmodel can be further developed into a prototype of a remote-sensing smoke alarm\nfor applications related to fires. In this article, we will implement the\nBi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for\npast 90 minutes and predict the levels of particulates which over 2.5\nmicrometer per 0.1 liter for the next 1 minute, which is classified as an early\nwarning",
    "descriptor": "\nComments: 10 pages, 5 figures, and 1 table\n",
    "authors": [
      "Po-Han Hou",
      "Hong-Chun Hou",
      "Wei-Chih Lin",
      "Yu-Hao Huang",
      "Jih-Hong Shue"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08549"
  },
  {
    "id": "arXiv:2210.08566",
    "title": "Theory for Equivariant Quantum Neural Networks",
    "abstract": "Most currently used quantum neural network architectures have little-to-no\ninductive biases, leading to trainability and generalization issues. Inspired\nby a similar problem, recent breakthroughs in classical machine learning\naddress this crux by creating models encoding the symmetries of the learning\ntask. This is materialized through the usage of equivariant neural networks\nwhose action commutes with that of the symmetry. In this work, we import these\nideas to the quantum realm by presenting a general theoretical framework to\nunderstand, classify, design and implement equivariant quantum neural networks.\nAs a special implementation, we show how standard quantum convolutional neural\nnetworks (QCNN) can be generalized to group-equivariant QCNNs where both the\nconvolutional and pooling layers are equivariant under the relevant symmetry\ngroup. Our framework can be readily applied to virtually all areas of quantum\nmachine learning, and provides hope to alleviate central challenges such as\nbarren plateaus, poor local minima, and sample complexity.",
    "descriptor": "\nComments: 20+21 pages, 9 + 2 figures\n",
    "authors": [
      "Quynh T. Nguyen",
      "Louis Schatzki",
      "Paolo Braccia",
      "Michael Ragone",
      "Patrick J. Coles",
      "Frederic Sauvage",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08566"
  },
  {
    "id": "arXiv:2210.08574",
    "title": "Machine Learning based Discrimination for Excited State Promoted Readout",
    "abstract": "A limiting factor for readout fidelity for superconducting qubits is the\nrelaxation of the qubit to the ground state before the time needed for the\nresonator to reach its final target state. A technique known as excited state\npromoted (ESP) readout was proposed to reduce this effect and further improve\nthe readout contrast on superconducting hardware. In this work, we use readout\ndata from five-qubit IBMQ devices to measure the effectiveness of using deep\nneural networks, like feedforward neural networks, and various classification\nalgorithms, like k-nearest neighbors, decision trees, and Gaussian naive Bayes,\nfor single-qubit and multi-qubit discrimination. These methods were compared to\nstandardly used linear and quadratic discriminant analysis algorithms based on\ntheir qubit-state-assignment fidelity performance, robustness to readout\ncrosstalk, and training time.",
    "descriptor": "\nComments: Accepted at ACM/IEE Quantum'22. 6 pages, 5 figures and 1 table\n",
    "authors": [
      "Utkarsh Azad",
      "Helena Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08574"
  },
  {
    "id": "arXiv:2210.08576",
    "title": "Skeptical inferences in multi-label ranking with sets of probabilities",
    "abstract": "In this paper, we consider the problem of making skeptical inferences for the\nmulti-label ranking problem. We assume that our uncertainty is described by a\nconvex set of probabilities (i.e. a credal set), defined over the set of\nlabels. Instead of learning a singleton prediction (or, a completed ranking\nover the labels), we thus seek for skeptical inferences in terms of set-valued\npredictions consisting of completed rankings.",
    "descriptor": "",
    "authors": [
      "Yonatan Carlos Carranza Alarc\u00f3n",
      "Vu-Linh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.08576"
  },
  {
    "id": "arXiv:2210.08599",
    "title": "Near-Optimal Performance of Stochastic Predictive Control",
    "abstract": "We study the performance of stochastic predictive control (SPC) for linear\nsystems with a quadratic performance index and additive and multiplicative\nuncertainties. Under a finite support assumption, the problem can be cast as a\nfinite-dimensional quadratic program, but the problem becomes quickly\nintractable as the problem size grows exponentially in the horizon length. SPC\naims to compute approximate solutions by solving a sequence of problems with\ntruncated prediction horizons and committing the solution in a receding-horizon\nfashion. While this approach is widely used in practice, its performance\nrelative to the optimal solution is not well understood. This article reports\nfor the first time a rigorous performance guarantee of SPC: under the standard\nstabilizability and detectability conditions, the dynamic regret of SPC is\nexponentially small in the prediction horizon length. Therefore, SPC can\nachieve near-optimal performance -- the expected performance can be made\narbitrarily close to the optimal solution -- at a substantially reduced\ncomputational expense.",
    "descriptor": "",
    "authors": [
      "Sungho Shin",
      "Sen Na",
      "Mihai Anitescu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08599"
  },
  {
    "id": "arXiv:2210.08603",
    "title": "CTCBERT: Advancing Hidden-unit BERT with CTC Objectives",
    "abstract": "In this work, we present a simple but effective method, CTCBERT, for\nadvancing hidden-unit BERT (HuBERT). HuBERT applies a frame-level cross-entropy\n(CE) loss, which is similar to most acoustic model training. However, CTCBERT\nperforms the model training with the Connectionist Temporal Classification\n(CTC) objective after removing duplicated IDs in each masked region. The idea\nstems from the observation that there can be significant errors in alignments\nwhen using clustered or aligned IDs. CTC learns alignments implicitly,\nindicating that learning with CTC can be more flexible when misalignment\nexists. We examine CTCBERT on IDs from HuBERT Iter1, HuBERT Iter2, and PBERT.\nThe CTC training brings consistent improvements compared to the CE training.\nFurthermore, when loading blank-related parameters during finetuning, slight\nimprovements are observed. Evaluated on the Librispeech 960-100h setting, the\nrelative WER improvements of CTCBERT are 2%-11% over HuBERT and PERT on\ntest-other data.",
    "descriptor": "",
    "authors": [
      "Ruchao Fan",
      "Yiming Wang",
      "Yashesh Gaur",
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.08603"
  },
  {
    "id": "arXiv:2210.08611",
    "title": "Automated quantum error mitigation based on probabilistic error  reduction",
    "abstract": "Current quantum computers suffer from a level of noise that prohibits\nextracting useful results directly from longer computations. The figure of\nmerit in many near-term quantum algorithms is an expectation value measured at\nthe end of the computation, which experiences a bias in the presence of\nhardware noise. A systematic way to remove such bias is probabilistic error\ncancellation (PEC). PEC requires a full characterization of the noise and\nintroduces a sampling overhead that increases exponentially with circuit depth,\nprohibiting high-depth circuits at realistic noise levels. Probabilistic error\nreduction (PER) is a related quantum error mitigation method that\nsystematically reduces the sampling overhead at the cost of reintroducing bias.\nIn combination with zero-noise extrapolation, PER can yield expectation values\nwith an accuracy comparable to PEC.Noise reduction through PER is broadly\napplicable to near-term algorithms, and the automated implementation of PER is\nthus desirable for facilitating its widespread use. To this end, we present an\nautomated quantum error mitigation software framework that includes noise\ntomography and application of PER to user-specified circuits. We provide a\nmulti-platform Python package that implements a recently developed Pauli noise\ntomography (PNT) technique for learning a sparse Pauli noise model and exploits\na Pauli noise scaling method to carry out PER.We also provide software tools\nthat leverage a previously developed toolchain, employing PyGSTi for gate set\ntomography and providing a functionality to use the software Mitiq for PER and\nzero-noise extrapolation to obtain error-mitigated expectation values on a\nuser-defined circuit.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Benjamin McDonough",
      "Andrea Mari",
      "Nathan Shammah",
      "Nathaniel T. Stemen",
      "Misty Wahl",
      "William J. Zeng",
      "Peter P. Orth"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.08611"
  },
  {
    "id": "arXiv:2210.08620",
    "title": "Twin-width of Planar Graphs is at most 8",
    "abstract": "The structural parameter twin-width was introduced by Bonnet et al. in [FOCS\n2020], and already this first paper included an asymptotic argument bounding\nthe twin-width of planar graphs by a non-explicit constant. Quite recently, we\nhave seen first small explicit upper bounds of 183 by Jacob and Pilipczuk\n[arXiv, January 2022, also WG'22], 583 by Bonnet et al. [arXiv, February 2022],\nof 37 by Bekos et al. [arXiv, April 2022], and of 9 by the first author [arXiv,\nJune 2022]. We further elaborate on the approach used in the last paper and\nimprove the upper bound to 8. This is already very close to the currently best\nlower bound of 7 by Kr\\'al and Lamaison [arXiv,September 2022].",
    "descriptor": "",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Jan Jedelsk\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08620"
  },
  {
    "id": "arXiv:2210.08624",
    "title": "Attention-Based Audio Embeddings for Query-by-Example",
    "abstract": "An ideal audio retrieval system efficiently and robustly recognizes a short\nquery snippet from an extensive database. However, the performance of\nwell-known audio fingerprinting systems falls short at high signal distortion\nlevels. This paper presents an audio retrieval system that generates noise and\nreverberation robust audio fingerprints using the contrastive learning\nframework. Using these fingerprints, the method performs a comprehensive search\nto identify the query audio and precisely estimate its timestamp in the\nreference audio. Our framework involves training a CNN to maximize the\nsimilarity between pairs of embeddings extracted from clean audio and its\ncorresponding distorted and time-shifted version. We employ a channel-wise\nspectral-temporal attention mechanism to better discriminate the audio by\ngiving more weight to the salient spectral-temporal patches in the signal.\nExperimental results indicate that our system is efficient in computation and\nmemory usage while being more accurate, particularly at higher distortion\nlevels, than competing state-of-the-art systems and scalable to a larger\ndatabase.",
    "descriptor": "",
    "authors": [
      "Anup Singh",
      "Kris Demuynck",
      "Vipul Arora"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.08624"
  },
  {
    "id": "arXiv:2210.08629",
    "title": "A Note On $\\ell$-Rauzy Graphs for the Infinite Fibonacci Word",
    "abstract": "The $\\ell$-Rauzy graph of order $k$ for any infinite word is a directed graph\nin which an arc $(v_1,v_2)$ is formed if the concatenation of the word $v_1$\nand the suffix of $v_2$ of length $k-\\ell$ is a subword of the infinite word.\nIn this paper, we consider one of the important aperiodic recurrent words, the\ninfinite Fibonacci word for discussion. We prove a few basic properties of the\n$\\ell$-Rauzy graph of the infinite Fibonacci word. We also prove that the\n$\\ell$-Rauzy graphs for the infinite Fibonacci word are strongly connected.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Rajavel Praveen M",
      "Rama R"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08629"
  },
  {
    "id": "arXiv:2210.08657",
    "title": "Enumerating moves in the optimal solution of the Tower of Hanoi",
    "abstract": "In the Tower of Hanoi problem, there is six types of moves between the three\npegs. The main purpose of the present paper is to find out the number of each\nof these six elementary moves in the optimal sequence of moves. We present a\nrecursive function based on indicator functions, which counts the number of\neach elementary move, we investigate some of its properties including\ncombinatorial identities, recursive formulas and generating functions. Also we\nfound and interesting sequence that is strongly related to counting each type\nof these elementary moves that we'll establish some if its properties as well.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Hac\u00e8ne Belbachir",
      "El-Mehdi Mehiri"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08657"
  },
  {
    "id": "arXiv:2210.08663",
    "title": "A Formal Logic for Formal Category Theory",
    "abstract": "We present a domain-specific type theory for constructions and proofs in\ncategory theory. The type theory axiomatizes notions of category, functor,\nprofunctor and a generalized form of natural transformations. The type theory\nimposes an ordered linear restriction on standard predicate logic, which\nguarantees that all functions between categories are functorial, all relations\nare profunctorial, and all transformations are natural by construction, with no\nseparate proofs necessary. Important category theoretic proofs such as the\nYoneda lemma and Co-yoneda lemma become simple type theoretic proofs about the\nrelationship between unit, tensor and (ordered) function types, and can be seen\nto be ordered refinements of theorems in predicate logic. The type theory is\nsound and complete for a categorical model in \\emph{virtual equipments}, which\nmodel both internal and enriched category theory. While the proofs in our type\ntheory look like standard set-based arguments, the syntactic discipline ensure\nthat all proofs and constructions carry over to enriched and internal settings\nas well.",
    "descriptor": "",
    "authors": [
      "Max S. New",
      "Daniel R. Licata"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.08663"
  },
  {
    "id": "arXiv:2210.08665",
    "title": "Acoustic-aware Non-autoregressive Spell Correction with Mask Sample  Decoding",
    "abstract": "Masked language model (MLM) has been widely used for understanding tasks,\ne.g. BERT. Recently, MLM has also been used for generation tasks. The most\npopular one in speech is using Mask-CTC for non-autoregressive speech\nrecognition. In this paper, we take one step further, and explore the\npossibility of using MLM as a non-autoregressive spell correction (SC) model\nfor transformer-transducer (TT), denoted as MLM-SC. Our initial experiments\nshow that MLM-SC provides no improvements on Librispeech data. The problem\nmight be the choice of modeling units (word pieces) and the inaccuracy of the\nTT confidence scores for English data. To solve the problem, we propose a mask\nsample decoding (MS-decode) method where the masked tokens can have the choice\nof being masked or not to compensate for the inaccuracy. As a result, we reduce\nthe WER of a streaming TT from 7.6% to 6.5% on the Librispeech test-other data\nand the CER from 7.3% to 6.1% on the Aishell test data, respectively.",
    "descriptor": "",
    "authors": [
      "Ruchao Fan",
      "Guoli Ye",
      "Yashesh Gaur",
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.08665"
  },
  {
    "id": "arXiv:2210.08721",
    "title": "RbX: Region-based explanations of prediction models",
    "abstract": "We introduce region-based explanations (RbX), a novel, model-agnostic method\nto generate local explanations of scalar outputs from a black-box prediction\nmodel using only query access. RbX is based on a greedy algorithm for building\na convex polytope that approximates a region of feature space where model\npredictions are close to the prediction at some target point. This region is\nfully specified by the user on the scale of the predictions, rather than on the\nscale of the features. The geometry of this polytope - specifically the change\nin each coordinate necessary to escape the polytope - quantifies the local\nsensitivity of the predictions to each of the features. These \"escape\ndistances\" can then be standardized to rank the features by local importance.\nRbX is guaranteed to satisfy a \"sparsity axiom,\" which requires that features\nwhich do not enter into the prediction model are assigned zero importance. At\nthe same time, real data examples and synthetic experiments show how RbX can\nmore readily detect all locally relevant features than existing methods.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Ismael Lemhadri",
      "Harrison H. Li",
      "Trevor Hastie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08721"
  },
  {
    "id": "arXiv:2210.08734",
    "title": "How many radiographs are needed to re-train a deep learning system for  object detection?",
    "abstract": "Background: Object detection in radiograph computer vision has largely\nbenefited from progress in deep convolutional neural networks and can, for\nexample, annotate a radiograph with a box around a knee joint or intervertebral\ndisc. Is deep learning capable of detect small (less than 1% of the image) in\nradiographs? And how many radiographs do we need use when re-training a deep\nlearning model?\nMethods: We annotated 396 radiographs of left and right carpi dorsal 75\nmedial to palmarolateral oblique (DMPLO) projection with the location of\nradius, proximal row of carpal bones, distal row of carpal bones, accessory\ncarpal bone, first carpal bone (if present), and metacarpus (metacarpal II,\nIII, and IV). The radiographs and respective annotations were splited into sets\nthat were used to leave-one-out cross-validation of models created using\ntransfer learn from YOLOv5s.\nResults: Models trained using 96 radiographs or more achieved precision,\nrecall and mAP above 0.95, including for the first carpal bone, when trained\nfor 32 epochs. The best model needed the double of epochs to learn to detect\nthe first carpal bone compared with the other bones.\nConclusions: Free and open source state of the art object detection models\nbased on deep learning can be re-trained for radiograph computer vision\napplications with 100 radiographs and achieved precision, recall and mAP above\n0.95.",
    "descriptor": "",
    "authors": [
      "Raniere Silva",
      "Khizar Hayat",
      "Christopher M Riggs",
      "Michael Doube"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08734"
  },
  {
    "id": "arXiv:2210.08740",
    "title": "Risk-Sensitive Markov Decision Processes with Long-Run CVaR Criterion",
    "abstract": "CVaR (Conditional Value at Risk) is a risk metric widely used in finance.\nHowever, dynamically optimizing CVaR is difficult since it is not a standard\nMarkov decision process (MDP) and the principle of dynamic programming fails.\nIn this paper, we study the infinite-horizon discrete-time MDP with a long-run\nCVaR criterion, from the view of sensitivity-based optimization. By introducing\na pseudo CVaR metric, we derive a CVaR difference formula which quantifies the\ndifference of long-run CVaR under any two policies. The optimality of\ndeterministic policies is derived. We obtain a so-called Bellman local\noptimality equation for CVaR, which is a necessary and sufficient condition for\nlocal optimal policies and only necessary for global optimal policies. A CVaR\nderivative formula is also derived for providing more sensitivity information.\nThen we develop a policy iteration type algorithm to efficiently optimize CVaR,\nwhich is shown to converge to local optima in the mixed policy space. We\nfurther discuss some extensions including the mean-CVaR optimization and the\nmaximization of CVaR. Finally, we conduct numerical experiments relating to\nportfolio management to demonstrate the main results. Our work may shed light\non dynamically optimizing CVaR from a sensitivity viewpoint.",
    "descriptor": "\nComments: 33 pages, 7 figures, 4 tables. A risk-sensitive MDP methodology for optimizing long-run CVaR, which is extensive to data-driven learning scenarios\n",
    "authors": [
      "Li Xia",
      "Peter W. Glynn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08740"
  },
  {
    "id": "arXiv:2210.08744",
    "title": "Modified C0 interior penalty analysis for fourth order Dirichlet  boundary control problem and a posteriori error estimate",
    "abstract": "We revisit the L2 norm error estimate for the C0 interior penalty analysis of\nfourth order Dirichlet boundary control problem. The L2 norm estimate for the\noptimal control is derived under reduced regularity assumption and this\nanalysis can be carried out on any convex polygonal domains. Residual based\na-posteriori error bounds are derived for optimal control, state and adjoint\nstate variables under minimal regularity assumptions. The estimators are shown\nto be reliable and locally efficient. The theoretical findings are illustrated\nby numerical experiments.",
    "descriptor": "\nComments: 37 pages, 6 figures\n",
    "authors": [
      "Sudipto Chowdhury",
      "Divay Garg",
      "Ravina Shokeen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08744"
  },
  {
    "id": "arXiv:2210.08761",
    "title": "Protein Sequence and Structure Co-Design with Equivariant Translation",
    "abstract": "Proteins are macromolecules that perform essential functions in all living\norganisms. Designing novel proteins with specific structures and desired\nfunctions has been a long-standing challenge in the field of bioengineering.\nExisting approaches generate both protein sequence and structure using either\nautoregressive models or diffusion models, both of which suffer from high\ninference costs. In this paper, we propose a new approach capable of protein\nsequence and structure co-design, which iteratively translates both protein\nsequence and structure into the desired state from random initialization, based\non context features given a priori. Our model consists of a trigonometry-aware\nencoder that reasons geometrical constraints and interactions from context\nfeatures, and a roto-translation equivariant decoder that translates protein\nsequence and structure interdependently. Notably, all protein amino acids are\nupdated in one shot in each translation step, which significantly accelerates\nthe inference process. Experimental results across multiple tasks show that our\nmodel outperforms previous state-of-the-art baselines by a large margin, and is\nable to design proteins of high fidelity as regards both sequence and\nstructure, with running time orders of magnitude less than sampling-based\nmethods.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Chence Shi",
      "Chuanrui Wang",
      "Jiarui Lu",
      "Bozitao Zhong",
      "Jian Tang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08761"
  },
  {
    "id": "arXiv:2210.08802",
    "title": "spatial-dccrn: dccrn equipped with frame-level angle feature and hybrid  filtering for multi-channel speech enhancement",
    "abstract": "Recently, multi-channel speech enhancement has drawn much interest due to the\nuse of spatial information to distinguish target speech from interfering\nsignal. To make full use of spatial information and neural network based\nmasking estimation, we propose a multi-channel denoising neural network --\nSpatial DCCRN. Firstly, we extend S-DCCRN to multi-channel scenario, aiming at\nperforming cascaded sub-channel and full-channel processing strategy, which can\nmodel different channels separately. Moreover, instead of only adopting\nmulti-channel spectrum or concatenating first-channel's magnitude and IPD as\nthe model's inputs, we apply an angle feature extraction module (AFE) to\nextract frame-level angle feature embeddings, which can help the model to\napparently perceive spatial information. Finally, since the phenomenon of\nresidual noise will be more serious when the noise and speech exist in the same\ntime frequency (TF) bin, we particularly design a masking and mapping filtering\nmethod to substitute the traditional filter-and-sum operation, with the purpose\nof cascading coarsely denoising, dereverberation and residual noise\nsuppression. The proposed model, Spatial-DCCRN, has surpassed EaBNet, FasNet as\nwell as several competitive models on the L3DAS22 Challenge dataset. Not only\nthe 3D scenario, Spatial-DCCRN outperforms state-of-the-art (SOTA) model\nMIMO-UNet by a large margin in multiple evaluation metrics on the multi-channel\nConferencingSpeech2021 Challenge dataset. Ablation studies also demonstrate the\neffectiveness of different contributions.",
    "descriptor": "",
    "authors": [
      "Shubo Lv",
      "Yihui Fu",
      "Yukai Jv",
      "Lei Xie",
      "Weixin Zhu",
      "Wei Rao",
      "Yannan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.08802"
  },
  {
    "id": "arXiv:2210.08868",
    "title": "Cerebrovascular Segmentation via Vessel Oriented Filtering Network",
    "abstract": "Accurate cerebrovascular segmentation from Magnetic Resonance Angiography\n(MRA) and Computed Tomography Angiography (CTA) is of great significance in\ndiagnosis and treatment of cerebrovascular pathology. Due to the complexity and\ntopology variability of blood vessels, complete and accurate segmentation of\nvascular network is still a challenge. In this paper, we proposed a Vessel\nOriented Filtering Network (VOF-Net) which embeds domain knowledge into the\nconvolutional neural network. We design oriented filters for blood vessels\naccording to vessel orientation field, which is obtained by orientation\nestimation network. Features extracted by oriented filtering are injected into\nsegmentation network, so as to make use of the prior information that the blood\nvessels are slender and curved tubular structure. Experimental results on\ndatasets of CTA and MRA show that the proposed method is effective for vessel\nsegmentation, and embedding the specific vascular filter improves the\nsegmentation performance.",
    "descriptor": "",
    "authors": [
      "Zhanqiang Guo",
      "Yao Luan",
      "Jianjiang Feng",
      "Wangsheng Lu",
      "Yin Yin",
      "Guangming Yang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08868"
  },
  {
    "id": "arXiv:2210.08886",
    "title": "Regret Bounds for Learning Decentralized Linear Quadratic Regulator with  Partially Nested Information Structure",
    "abstract": "We study the problem of learning decentralized linear quadratic regulator\nunder a partially nested information constraint, when the system model is\nunknown a priori. We propose an online learning algorithm that adaptively\ndesigns a control policy as new data samples from a single system trajectory\nbecome available. Our algorithm design uses a disturbance-feedback\nrepresentation of state-feedback controllers coupled with online convex\noptimization with memory and delayed feedback. We show that our online\nalgorithm yields a controller that satisfies the desired information constraint\nand enjoys an expected regret that scales as $\\sqrt{T}$ with the time horizon\n$T$.",
    "descriptor": "",
    "authors": [
      "Lintao Ye",
      "Ming Chi",
      "Vijay Gupta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.08886"
  },
  {
    "id": "arXiv:2210.08911",
    "title": "Forget Unlearning: Towards True Data-Deletion in Machine Learning",
    "abstract": "Unlearning has emerged as a technique to efficiently erase information of\ndeleted records from learned models. We show, however, that the influence\ncreated by the original presence of a data point in the training set can still\nbe detected after running certified unlearning algorithms (which can result in\nits reconstruction by an adversary). Thus, under realistic assumptions about\nthe dynamics of model releases over time and in the presence of adaptive\nadversaries, we show that unlearning is not equivalent to data deletion and\ndoes not guarantee the \"right to be forgotten.\" We then propose a more robust\ndata-deletion guarantee and show that it is necessary to satisfy differential\nprivacy to ensure true data deletion. Under our notion, we propose an accurate,\ncomputationally efficient, and secure data-deletion machine learning algorithm\nin the online setting based on noisy gradient descent algorithm.",
    "descriptor": "\nComments: Submitted to ICLR 2023\n",
    "authors": [
      "Rishav Chourasia",
      "Neil Shah",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08911"
  },
  {
    "id": "arXiv:2210.08955",
    "title": "Monitoring edge-geodetic sets: hardness and graph products",
    "abstract": "Foucaud, Krishna and Lekshmi recently introduced the concept of monitoring\nedge-geodetic sets in graphs, and a related graph invariant. These are sets of\nvertices such that the removal of any edge changes the distance between some\npair of vertices in the set. They studied the minimum possible size of such a\nset in a given graph, which we call the monitoring edge-geodetic number.\nWe show that the decision problem for the monitoring edge-geodetic number is\nNP-complete. We also give best-possible upper and lower bounds for the\nCartesian and strong products of two graphs. These bounds establish the exact\nvalue in many cases, including many new examples of graphs whose only\nmonitoring edge-geodetic set is the whole vertex set.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "John Haslegrave"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08955"
  },
  {
    "id": "arXiv:2210.08964",
    "title": "Prompt-Based Time Series Forecasting: A New Task and Dataset",
    "abstract": "The research of time series forecasting benefits a wide range of applications\nfrom weather forecasting to human mobility or traffic prediction. This paper\nstudies the time series forecasting problem from a whole new perspective. In\nthe existing methods, the forecasting models take a sequence of numerical\nvalues as input and yield numerical values as output. Inspired by the successes\nof pre-trained language foundation models, we pose a question about whether\nthese models can also be adapted to time series forecasting tasks. Thus, we\npropose a novel prompt-based time series forecasting (PromptCast) task. In this\ntask, the numerical input and output are transformed into language sentence\nprompts. We frame the forecasting task in a sentence-to-sentence manner which\nmakes it possible to directly apply language models for the forecasting\npurpose. To support and facilitate the research of this task, we also present a\nlarge-scale dataset (PISA) that includes three real-world forecasting scenarios\nin this paper. We evaluate different state-of-the-art numerical-based\nforecasting methods and language generation models such as Bart and Bigbird.\nThe benchmark results demonstrate that the proposed prompt-based time series\nforecasting with language generation models is a promising research direction.\nIn addition, in comparison to conventional numerical-based forecasting,\nprompt-based forecasting shows a better generalization ability. We believe that\nthe proposed PromptCast benchmark task as well as our PISA dataset could\nprovide novel insights and further lead to new research directions in the time\nseries forecasting domain.",
    "descriptor": "",
    "authors": [
      "Hao Xue",
      "Flora D.Salim"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.08964"
  },
  {
    "id": "arXiv:2210.08977",
    "title": "On the Security of Offloading Post-Processing for Quantum Key  Distribution",
    "abstract": "Quantum key distribution (QKD) has been researched for almost four decades\nand is currently making its way to commercial applications. However, deployment\nof the technology at scale is challenging, because of the very particular\nnature of QKD and its physical limitations. Among others, QKD is\ncomputationally intensive in the post-processing phase and devices are\ntherefore complex and power hungry, which leads to problems in certain\napplication scenarios. In this work we study the possibility to offload\ncomputationally intensive parts in the QKD post-processing stack in a secure\nway to untrusted hardware. We show how error correction can be securely\noffloaded for discrete-variable QKD to a single untrusted server and that the\nsame method cannot be used for long distance continuous-variable QKD.\nFurthermore, we analyze possibilities for multi-server protocols to be used for\nerror correction and privacy amplification. Even in cases where it is not\npossible to offload to an external server, being able to delegate computation\nto untrusted hardware components on the device could improve the cost and\ncertification effort for device manufacturers.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Thomas Loruenser",
      "Stephan Krenn",
      "Christoph Pacher",
      "Bernhard Schrenk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.08977"
  },
  {
    "id": "arXiv:2210.08979",
    "title": "An Interactive Interpretability System for Breast Cancer Screening with  Deep Learning",
    "abstract": "Deep learning methods, in particular convolutional neural networks, have\nemerged as a powerful tool in medical image computing tasks. While these\ncomplex models provide excellent performance, their black-box nature may hinder\nreal-world adoption in high-stakes decision-making. In this paper, we propose\nan interactive system to take advantage of state-of-the-art interpretability\ntechniques to assist radiologists with breast cancer screening. Our system\nintegrates a deep learning model into the radiologists' workflow and provides\nnovel interactions to promote understanding of the model's decision-making\nprocess. Moreover, we demonstrate that our system can take advantage of user\ninteractions progressively to provide finer-grained explainability reports with\nlittle labeling overhead. Due to the generic nature of the adopted\ninterpretability technique, our system is domain-agnostic and can be used for\nmany different medical image computing tasks, presenting a novel perspective on\nhow we can leverage visual analytics to transform originally static\ninterpretability techniques to augment human decision making and promote the\nadoption of medical AI.",
    "descriptor": "",
    "authors": [
      "Yuzhe Lu",
      "Adam Perer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08979"
  },
  {
    "id": "arXiv:2210.08989",
    "title": "Finding community structure using the ordered random graph model",
    "abstract": "Visualization of the adjacency matrix enables us to capture macroscopic\nfeatures of a network when the matrix elements are aligned properly. Community\nstructure, a network consisting of several densely connected components, is a\nparticularly important feature, and the structure can be identified through the\nadjacency matrix when it is close to a block-diagonal form. However, classical\nordering algorithms for matrices fail to align matrix elements such that the\ncommunity structure is visible. In this study, we propose an ordering algorithm\nbased on the maximum-likelihood estimate of the ordered random graph model. We\nshow that the proposed method allows us to more clearly identify community\nstructures than the existing ordering algorithms.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Masaki Ochi",
      "Tatsuro Kawamoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.08989"
  },
  {
    "id": "arXiv:2210.09006",
    "title": "Fourier theoretic inequalities for inclusion of simple C*-algebras",
    "abstract": "This paper originates from a naive attempt to establish various\nnon-commutative Fourier theoretic inequalities for an inclusion of simple\nC*-algebras equipped with a conditional expectation of index-finite type. In\nthis setting, we discuss the Hausdorff-Young inequality and Young's inequality.\nAs a consequence, we prove the Hirschman-Beckner uncertainty principle and\nDonoho-Stark uncertainty principle. Our results generalize some of the results\nof Jiang, Liu and Wu [Noncommutative uncertainty principle, J. Funct. Anal.,\n270(1): 264--311, 2016].",
    "descriptor": "\nComments: 35 pages, 2 figures. Comments are welcome\n",
    "authors": [
      "Keshab Chandra Bakshi",
      "Satyajit Guin",
      "Sruthymurali"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.09006"
  },
  {
    "id": "arXiv:2210.09023",
    "title": "Ratio convergence rates for Euclidean first-passage percolation:  Applications to the graph infinity Laplacian",
    "abstract": "In this paper we prove the first quantitative convergence rates for the graph\ninfinity Laplace equation for length scales at the connectivity threshold. In\nthe graph-based semi-supervised learning community this equation is also known\nas Lipschitz learning. The graph infinity Laplace equation is characterized by\nthe metric on the underlying space, and convergence rates follow from\nconvergence rates for graph distances. At the connectivity threshold, this\nproblem is related to Euclidean first passage percolation, which is concerned\nwith the Euclidean distance function $d_{h}(x,y)$ on a homogeneous Poisson\npoint process on $\\mathbb{R}^d$, where admissible paths have step size at most\n$h>0$. Using a suitable regularization of the distance function and\nsubadditivity we prove that ${d_{h_s}(0,se_1)}/ s \\to \\sigma$ as $s\\to\\infty$\nalmost surely where $\\sigma \\geq 1$ is a dimensional constant and $h_s\\gtrsim\n\\log(s)^\\frac{1}{d}$. A convergence rate is not available due to a lack of\napproximate superadditivity when $h_s\\to \\infty$. Instead, we prove convergence\nrates for the ratio $\\frac{d_{h}(0,se_1)}{d_{h}(0,2se_1)}\\to \\frac{1}{2}$ when\n$h$ is frozen and does not depend on $s$. Combining this with the techniques\nthat we developed in (Bungert, Calder, Roith, IMA Journal of Numerical\nAnalysis, 2022), we show that this notion of ratio convergence is sufficient to\nestablish uniform convergence rates for solutions of the graph infinity Laplace\nequation at percolation length scales.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09023"
  },
  {
    "id": "arXiv:2210.09024",
    "title": "Periodic Artifact Reduction in Fourier transforms of Full Field Atomic  Resolution Images",
    "abstract": "The discrete Fourier transform is among the most routine tools used in\nhigh-resolution scanning / transmission electron microscopy (S/TEM). However,\nwhen calculating a Fourier transform, periodic boundary conditions are imposed\nand sharp discontinuities between the edges of an image cause a cross patterned\nartifact along the reciprocal space axes. This artifact can interfere with the\nanalysis of reciprocal lattice peaks of an atomic resolution image. Here we\ndemonstrate that the recently developed Periodic Plus Smooth Decomposition\ntechnique provides a simple, efficient method for reliable removal of artifacts\ncaused by edge discontinuities. In this method, edge artifacts are reduced by\nsubtracting a smooth background that solves Poisson's equation with boundary\nconditions set by the image's edges. Unlike the traditional windowed Fourier\ntransforms, Periodic Plus Smooth Decomposition maintains sharp reciprocal\nlattice peaks from the image's entire field of view.",
    "descriptor": "",
    "authors": [
      "Robert Hovden",
      "Yi Jiang",
      "Huolin L. Xin",
      "Lena F. Kourkoutis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09024"
  },
  {
    "id": "arXiv:2210.09054",
    "title": "On the Identifiability and Estimation of Causal Location-Scale Noise  Models",
    "abstract": "We study the class of location-scale or heteroscedastic noise models (LSNMs),\nin which the effect $Y$ can be written as a function of the cause $X$ and a\nnoise source $N$ independent of $X$, which may be scaled by a positive function\n$g$ over the cause, i.e., $Y = f(X) + g(X)N$. Despite the generality of the\nmodel class, we show the causal direction is identifiable up to some\npathological cases. To empirically validate these theoretical findings, we\npropose two estimators for LSNMs: an estimator based on (non-linear) feature\nmaps, and one based on probabilistic neural networks. Both model the\nconditional distribution of $Y$ given $X$ as a Gaussian parameterized by its\nnatural parameters. Since the neural network approach can fit functions of\narbitrary complexity, it has an edge over the feature map-based approach in\nterms of empirical performance. When the feature maps are correctly specified,\nhowever, we can prove that our estimator is jointly concave, which allows us to\nderive stronger guarantees for the cause-effect identification task.",
    "descriptor": "",
    "authors": [
      "Alexander Immer",
      "Christoph Schultheiss",
      "Julia E. Vogt",
      "Bernhard Sch\u00f6lkopf",
      "Peter B\u00fchlmann",
      "Alexander Marx"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09054"
  },
  {
    "id": "arXiv:2210.09058",
    "title": "Forward-Backward Latent State Inference for Hidden Continuous-Time  semi-Markov Chains",
    "abstract": "Hidden semi-Markov Models (HSMM's) - while broadly in use - are restricted to\na discrete and uniform time grid. They are thus not well suited to explain\noften irregularly spaced discrete event data from continuous-time phenomena. We\nshow that non-sampling-based latent state inference used in HSMM's can be\ngeneralized to latent Continuous-Time semi-Markov Chains (CTSMC's). We\nformulate integro-differential forward and backward equations adjusted to the\nobservation likelihood and introduce an exact integral equation for the\nBayesian posterior marginals and a scalable Viterbi-type algorithm for\nposterior path estimates. The presented equations can be efficiently solved\nusing well-known numerical methods. As a practical tool, variable-step HSMM's\nare introduced. We evaluate our approaches in latent state inference scenarios\nin comparison to classical HSMM's.",
    "descriptor": "\nComments: 10 content pages, 2 figures, to be published at NeurIPS 2022\n",
    "authors": [
      "Nicolai Engelmann",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09058"
  },
  {
    "id": "arXiv:2210.09104",
    "title": "Advanced Characterization-Informed Framework and Quantitative Insight to  Irradiated Annular U-10Zr Metallic Fuels",
    "abstract": "U-10Zr-based metallic nuclear fuel is a promising fuel candidate for\nnext-generation sodium-cooled fast reactors.The research experience of the\nIdaho National Laboratory for this type of fuel dates back to the 1960s. Idaho\nNational Laboratory researchers have accumulated a considerable amount of\nexperience and knowledge regarding fuel performance at the engineering scale.\nThe limitation of advanced characterization and lack of proper data analysis\ntools prevented a mechanistic understanding of fuel microstructure evolution\nand properties degradation during irradiation. This paper proposed a new\nworkflow, coupled with domain knowledge obtained by advanced post-irradiation\nexamination methods, to provide unprecedented and quantified insights into the\nfission gas bubbles and pores, and lanthanide distribution in an annular fuel\nirradiated in the Advanced Test Reactor. In the study, researchers identify and\nconfirm that the Zr-bearing secondary phases exist and generate the\nquantitative ratios of seven microstructures along the thermal gradient.\nMoreover, the distributions of fission gas bubbles on two samples of U-10Zr\nadvanced fuels were quantitatively compared. Conclusive findings were obtained\nand allowed for evaluation of the lanthanide transportation through connected\nbubbles based on approximately 67,000 fission gas bubbles of the two advanced\nsamples.",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Fei Xu",
      "Lu Cai",
      "Daniele Salvato",
      "Fidelma Dilemma",
      "Luca Capriotti",
      "Tiankai Yao"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09104"
  },
  {
    "id": "arXiv:2210.09141",
    "title": "Data Subsampling for Bayesian Neural Networks",
    "abstract": "Markov Chain Monte Carlo (MCMC) algorithms do not scale well for large\ndatasets leading to difficulties in Neural Network posterior sampling. In this\npaper, we apply a generalization of the Metropolis Hastings algorithm that\nallows us to restrict the evaluation of the likelihood to small mini-batches in\na Bayesian inference context. Since it requires the computation of a so-called\n\"noise penalty\" determined by the variance of the training loss function over\nthe mini-batches, we refer to this data subsampling strategy as Penalty\nBayesian Neural Networks - PBNNs. Its implementation on top of MCMC is\nstraightforward, as the variance of the loss function merely reduces the\nacceptance probability. Comparing to other samplers, we empirically show that\nPBNN achieves good predictive performance for a given mini-batch size. Varying\nthe size of the mini-batches enables a natural calibration of the predictive\ndistribution and provides an inbuilt protection against overfitting. We expect\nPBNN to be particularly suited for cases when data sets are distributed across\nmultiple decentralized devices as typical in federated learning.",
    "descriptor": "",
    "authors": [
      "Eiji Kawasaki",
      "Markus Holzmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09141"
  },
  {
    "id": "arXiv:2210.09149",
    "title": "A Note on Quantum Divide and Conquer for Minimal String Rotation",
    "abstract": "Lexicographically minimal string rotation is a fundamental problem on string\nprocessing that has recently attracted a lot of attention in quantum computing.\nNear-optimal quantum algorithms have been proposed during its development, with\nnew ideas such as quantum divide and conquer introduced. In this note, we\nfurther study its quantum query complexity. Slightly improved quantum\nalgorithms by divide and conquer are proposed:\n1. For the function problem, its query complexity is shown to be $\\sqrt{n}\n\\cdot 2^{O\\left(\\sqrt{\\log n}\\right)}$, improving the recent result of\n$\\sqrt{n} \\cdot 2^{\\left(\\log n\\right)^{1/2+\\varepsilon}}$ by Akmal and Jin\n(2022).\n2. For the decision problem, its query complexity is shown to be\n$O\\left(\\sqrt{n \\log^3 n \\log \\log n}\\right)$, improving the recent result of\n$O\\left(\\sqrt{n \\log^5 n}\\right)$ by Childs et al. (2022).\nThe purpose of this note is to point out some useful algorithmic tricks,\ne.g., preprocessing and level-wise optimization, that can be used to improve\nquantum algorithms, especially for those with a divide-and-conquer structure.",
    "descriptor": "\nComments: 19 pages, 1 table\n",
    "authors": [
      "Qisheng Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09149"
  },
  {
    "id": "arXiv:2210.09155",
    "title": "Quantum Event Learning and Gentle Random Measurements",
    "abstract": "We prove the expected disturbance caused to a quantum system by a sequence of\nrandomly ordered two-outcome projective measurements is upper bounded by the\nsquare root of the probability that at least one measurement in the sequence\naccepts. We call this bound the \\textit{Gentle Random Measurement Lemma}.\nWe also extend the techniques used to prove this lemma to develop protocols\nfor problems in which we are given sample access to an unknown state $\\rho$ and\nasked to estimate properties of the accepting probabilities $\\text{Tr}[M_i\n\\rho]$ of a set of measurements $\\{M_1, M_2, ... , M_m\\}$. We call these types\nof problems \\textit{Quantum Event Learning Problems}. In particular, we show\nrandomly ordering projective measurements solves the Quantum OR problem,\nanswering an open question of Aaronson. We also give a Quantum OR protocol\nwhich works on non-projective measurements and which outperforms both the\nrandom measurement protocol analyzed in this paper and the protocol of Harrow,\nLin, and Montanaro. However, this protocol requires a more complicated type of\nmeasurement, which we call a \\textit{Blended Measurement}. When the total\n(summed) accepting probability of unlikely events is bounded, we show the\nrandom and blended measurement Quantum OR protocols developed in this paper can\nalso be used to find a measurement $M_i$ such that $\\text{Tr}[M_i \\rho]$ is\nlarge. We call the problem of finding such a measurement \\textit{Quantum Event\nFinding}. Finally, we show Blended Measurements also give a sample-efficient\nprotocol for \\textit{Quantum Mean Estimation}: a problem in which the goal is\nto estimate the average accepting probability of a set of measurements on an\nunknown state.",
    "descriptor": "",
    "authors": [
      "Adam Bene Watts",
      "John Bostanci"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.09155"
  },
  {
    "id": "arXiv:2210.09160",
    "title": "Statistical, Robustness, and Computational Guarantees for Sliced  Wasserstein Distances",
    "abstract": "Sliced Wasserstein distances preserve properties of classic Wasserstein\ndistances while being more scalable for computation and estimation in high\ndimensions. The goal of this work is to quantify this scalability from three\nkey aspects: (i) empirical convergence rates; (ii) robustness to data\ncontamination; and (iii) efficient computational methods. For empirical\nconvergence, we derive fast rates with explicit dependence of constants on\ndimension, subject to log-concavity of the population distributions. For\nrobustness, we characterize minimax optimal, dimension-free robust estimation\nrisks, and show an equivalence between robust sliced 1-Wasserstein estimation\nand robust mean estimation. This enables lifting statistical and algorithmic\nguarantees available for the latter to the sliced 1-Wasserstein setting. Moving\non to computational aspects, we analyze the Monte Carlo estimator for the\naverage-sliced distance, demonstrating that larger dimension can result in\nfaster convergence of the numerical integration error. For the max-sliced\ndistance, we focus on a subgradient-based local optimization algorithm that is\nfrequently used in practice, albeit without formal guarantees, and establish an\n$O(\\epsilon^{-4})$ computational complexity bound for it. Our theory is\nvalidated by numerical experiments, which altogether provide a comprehensive\nquantitative account of the scalability question.",
    "descriptor": "",
    "authors": [
      "Sloan Nietert",
      "Ritwik Sadhu",
      "Ziv Goldfeld",
      "Kengo Kato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09160"
  },
  {
    "id": "arXiv:2210.09206",
    "title": "Model Predictive Control via On-Policy Imitation Learning",
    "abstract": "In this paper, we leverage the rapid advances in imitation learning, a topic\nof intense recent focus in the Reinforcement Learning (RL) literature, to\ndevelop new sample complexity results and performance guarantees for\ndata-driven Model Predictive Control (MPC) for constrained linear systems. In\nits simplest form, imitation learning is an approach that tries to learn an\nexpert policy by querying samples from an expert. Recent approaches to\ndata-driven MPC have used the simplest form of imitation learning known as\nbehavior cloning to learn controllers that mimic the performance of MPC by\nonline sampling of the trajectories of the closed-loop MPC system. Behavior\ncloning, however, is a method that is known to be data inefficient and suffer\nfrom distribution shifts. As an alternative, we develop a variant of the\nforward training algorithm which is an on-policy imitation learning method\nproposed by Ross et al. (2010). Our algorithm uses the structure of constrained\nlinear MPC, and our analysis uses the properties of the explicit MPC solution\nto theoretically bound the number of online MPC trajectories needed to achieve\noptimal performance. We validate our results through simulations and show that\nthe forward training algorithm is indeed superior to behavior cloning when\napplied to MPC.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Kwangjun Ahn",
      "Zakaria Mhammedi",
      "Horia Mania",
      "Zhang-Wei Hong",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09206"
  },
  {
    "id": "arXiv:2210.09211",
    "title": "Conditional Neural Processes for Molecules",
    "abstract": "Neural processes (NPs) are models for transfer learning with properties\nreminiscent of Gaussian Processes (GPs). They are adept at modelling data\nconsisting of few observations of many related functions on the same input\nspace and are trained by minimizing a variational objective, which is\ncomputationally much less expensive than the Bayesian updating required by GPs.\nSo far, most studies of NPs have focused on low-dimensional datasets which are\nnot representative of realistic transfer learning tasks. Drug discovery is one\napplication area that is characterized by datasets consisting of many chemical\nproperties or functions which are sparsely observed, yet depend on shared\nfeatures or representations of the molecular inputs. This paper applies the\nconditional neural process (CNP) to DOCKSTRING, a dataset of docking scores for\nbenchmarking ML models. CNPs show competitive performance in few-shot learning\ntasks relative to supervised learning baselines common in QSAR modelling, as\nwell as an alternative model for transfer learning based on pre-training and\nrefining neural network regressors. We present a Bayesian optimization\nexperiment which showcases the probabilistic nature of CNPs and discuss\nshortcomings of the model in uncertainty quantification.",
    "descriptor": "",
    "authors": [
      "Miguel Garcia-Ortegon",
      "Andreas Bender",
      "Sergio Bacallado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09211"
  },
  {
    "id": "arXiv:2210.09226",
    "title": "A Fault Detection Scheme Utilizing Convolutional Neural Network for PV  Solar Panels with High Accuracy",
    "abstract": "Solar energy is one of the most dependable renewable energy technologies, as\nit is feasible almost everywhere globally. However, improving the efficiency of\na solar PV system remains a significant challenge. To enhance the robustness of\nthe solar system, this paper proposes a trained convolutional neural network\n(CNN) based fault detection scheme to divide the images of photovoltaic\nmodules. For binary classification, the algorithm classifies the input images\nof PV cells into two categories (i.e. faulty or normal). To further assess the\nnetwork's capability, the defective PV cells are organized into shadowy,\ncracked, or dusty cells, and the model is utilized for multiple\nclassifications. The success rate for the proposed CNN model is 91.1% for\nbinary classification and 88.6% for multi-classification. Thus, the proposed\ntrained CNN model remarkably outperforms the CNN model presented in a previous\nstudy which used the same datasets. The proposed CNN-based fault detection\nmodel is straightforward, simple and effective and could be applied in the\nfault detection of solar panel.",
    "descriptor": "",
    "authors": [
      "Mary Pa",
      "Amin Kazemi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09226"
  },
  {
    "id": "arXiv:2210.09227",
    "title": "A multidimensional Ramsey Theorem",
    "abstract": "Ramsey theory is a central and active branch of combinatorics. Although\nRamsey numbers for graphs have been extensively investigated since Ramsey's\nwork in the 1930s, there is still an exponential gap between the best known\nlower and upper bounds. For $k$-uniform hypergraphs, the bounds are of\ntower-type, where the height grows with $k$. Here, we give a multidimensional\ngeneralisation of Ramsey's Theorem to Cartesian products of graphs, proving\nthat a doubly exponential upper bound suffices in every dimension. More\nprecisely, we prove that for every positive integers $r,n,d$, in any\n$r$-colouring of the edges of the Cartesian product $\\square^{d} K_N$ of $d$\ncopies of $K_N$, there is a copy of $\\square^{d} K_n$ such that the edges in\neach direction are monochromatic, provided that $N\\geq 2^{2^{C_drn^{d}}}$. As\nan application of our approach we also obtain improvements on the\nmultidimensional Erd\\H{o}s-Szekeres Theorem proved by Fishburn and Graham $30$\nyears ago. Their bound was recently improved by Buci\\'c, Sudakov, and Tran, who\ngave an upper bound that is triply exponential in four or more dimensions. We\nimprove upon their results showing that a doubly expoenential upper bounds\nholds any number of dimensions.",
    "descriptor": "",
    "authors": [
      "Ant\u00f3nio Gir\u00e3o",
      "Gal Kronenberg",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.09227"
  },
  {
    "id": "arXiv:2210.09248",
    "title": "Provable Phase Retrieval with Mirror Descent",
    "abstract": "In this paper, we consider the problem of phase retrieval, which consists of\nrecovering an $n$-dimensional real vector from the magnitude of its $m$ linear\nmeasurements. We propose a mirror descent (or Bregman gradient descent)\nalgorithm based on a wisely chosen Bregman divergence, hence allowing to remove\nthe classical global Lipschitz continuity requirement on the gradient of the\nnon-convex phase retrieval objective to be minimized. We apply the mirror\ndescent for two random measurements: the \\iid standard Gaussian and those\nobtained by multiple structured illuminations through Coded Diffraction\nPatterns (CDP). For the Gaussian case, we show that when the number of\nmeasurements $m$ is large enough, then with high probability, for almost all\ninitializers, the algorithm recovers the original vector up to a global sign\nchange. For both measurements, the mirror descent exhibits a local linear\nconvergence behaviour with a dimension-independent convergence rate. Our\ntheoretical results are finally illustrated with various numerical experiments,\nincluding an application to the reconstruction of images in precision optics.",
    "descriptor": "",
    "authors": [
      "Jean-Jacques Godeme",
      "Jalal Fadili",
      "Xavier Buet",
      "Myriam Zerrad",
      "Michel Lequime",
      "Claude Amra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09248"
  },
  {
    "id": "arXiv:2210.09295",
    "title": "Virtual-Reality based Vestibular Ocular Motor Screening for Concussion  Detection using Machine-Learning",
    "abstract": "Sport-related concussion (SRC) depends on sensory information from visual,\nvestibular, and somatosensory systems. At the same time, the current clinical\nadministration of Vestibular/Ocular Motor Screening (VOMS) is subjective and\ndeviates among administrators. Therefore, for the assessment and management of\nconcussion detection, standardization is required to lower the risk of injury\nand increase the validation among clinicians. With the advancement of\ntechnology, virtual reality (VR) can be utilized to advance the standardization\nof the VOMS, increasing the accuracy of testing administration and decreasing\noverall false positive rates. In this paper, we experimented with multiple\nmachine learning methods to detect SRC on VR-generated data using VOMS. In our\nobservation, the data generated from VR for smooth pursuit (SP) and the Visual\nMotion Sensitivity (VMS) tests are highly reliable for concussion detection.\nFurthermore, we train and evaluate these models, both qualitatively and\nquantitatively. Our findings show these models can reach high\ntrue-positive-rates of around 99.9 percent of symptom provocation on the VR\nstimuli-based VOMS vs. current clinical manual VOMS.",
    "descriptor": "\nComments: Accepted in 17th International Symposium on Visual Computing,2022\n",
    "authors": [
      "Khondker Fariha Hossain",
      "Sharif Amit Kamran",
      "Prithul Sarker",
      "Philip Pavilionis",
      "Isayas Adhanom",
      "Nicholas Murray",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09295"
  },
  {
    "id": "arXiv:0711.2010",
    "title": "A Polynomial Time Algorithm for Graph Isomorphism",
    "abstract": "A Polynomial Time Algorithm for Graph Isomorphism",
    "descriptor": "",
    "authors": [
      "Reiner Czerwinski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/0711.2010"
  },
  {
    "id": "arXiv:1405.4189",
    "title": "Termination Analysis by Learning Terminating Programs",
    "abstract": "Termination Analysis by Learning Terminating Programs",
    "descriptor": "",
    "authors": [
      "Matthias Heizmann",
      "Jochen Hoenicke",
      "Andreas Podelski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1405.4189"
  },
  {
    "id": "arXiv:1704.08798",
    "title": "Word Affect Intensities",
    "abstract": "Comments: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). this https URL",
    "descriptor": "\nComments: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). this https URL\n",
    "authors": [
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1704.08798"
  },
  {
    "id": "arXiv:1904.09601",
    "title": "MiniMax Entropy Network: Learning Category-Invariant Features for Domain  Adaptation",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Chaofan Tao",
      "Fengmao Lv",
      "Lixin Duan",
      "Min Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.09601"
  },
  {
    "id": "arXiv:1905.08563",
    "title": "Optimal Space Lower Bound for Deterministic Self-Stabilizing Leader  Election Algorithms",
    "abstract": "Comments: The paper as been rewritten. It appeared in the arxiv, and as a brief announcment at DISC 2019, under the name \"Memory Lower Bounds for Self-Stabilization\". This is a revision for the journal version",
    "descriptor": "\nComments: The paper as been rewritten. It appeared in the arxiv, and as a brief announcment at DISC 2019, under the name \"Memory Lower Bounds for Self-Stabilization\". This is a revision for the journal version\n",
    "authors": [
      "L\u00e9lia Blin",
      "Laurent Feuilloley",
      "Gabriel Le Bouder"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1905.08563"
  },
  {
    "id": "arXiv:1909.07589",
    "title": "A Linear Exponential Comonad in s-finite Transition Kernels and  Probabilistic Coherent Spaces",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Masahiro Hamano"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/1909.07589"
  },
  {
    "id": "arXiv:1909.13371",
    "title": "Gradient Descent: The Ultimate Optimizer",
    "abstract": "Gradient Descent: The Ultimate Optimizer",
    "descriptor": "",
    "authors": [
      "Kartik Chandra",
      "Audrey Xie",
      "Jonathan Ragan-Kelley",
      "Erik Meijer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.13371"
  },
  {
    "id": "arXiv:2002.00540",
    "title": "Optimizing Query Predicates with Disjunctions for Column Stores",
    "abstract": "Optimizing Query Predicates with Disjunctions for Column Stores",
    "descriptor": "",
    "authors": [
      "Albert Kim",
      "Atalay Mert Ileri",
      "Sam Madden"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.00540"
  },
  {
    "id": "arXiv:2003.02395",
    "title": "A Simple Convergence Proof of Adam and Adagrad",
    "abstract": "Comments: final TMLR version",
    "descriptor": "\nComments: final TMLR version\n",
    "authors": [
      "Alexandre D\u00e9fossez",
      "L\u00e9on Bottou",
      "Francis Bach",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.02395"
  },
  {
    "id": "arXiv:2004.12002",
    "title": "Finding Planted Cliques in Sublinear Time",
    "abstract": "Finding Planted Cliques in Sublinear Time",
    "descriptor": "",
    "authors": [
      "Jay Mardia",
      "Hilal Asi",
      "Kabir Aladin Chandrasekher"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.12002"
  },
  {
    "id": "arXiv:2005.08454",
    "title": "Reliability and Robustness analysis of Machine Learning based Phishing  URL Detectors",
    "abstract": "Comments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions)",
    "descriptor": "\nComments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions)\n",
    "authors": [
      "Bushra Sabir",
      "M. Ali Babar",
      "Raj Gaire",
      "Alsharif Abuadbba"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.08454"
  },
  {
    "id": "arXiv:2006.02570",
    "title": "Exploration of Interpretability Techniques for Deep COVID-19  Classification using Chest X-ray Images",
    "abstract": "Exploration of Interpretability Techniques for Deep COVID-19  Classification using Chest X-ray Images",
    "descriptor": "",
    "authors": [
      "Soumick Chatterjee",
      "Fatima Saad",
      "Chompunuch Sarasaen",
      "Suhita Ghosh",
      "Valerie Krug",
      "Rupali Khatun",
      "Rahul Mishra",
      "Nirja Desai",
      "Petia Radeva",
      "Georg Rose",
      "Sebastian Stober",
      "Oliver Speck",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.02570"
  },
  {
    "id": "arXiv:2006.06049",
    "title": "On Mixup Regularization",
    "abstract": "On Mixup Regularization",
    "descriptor": "",
    "authors": [
      "Luigi Carratino",
      "Moustapha Ciss\u00e9",
      "Rodolphe Jenatton",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06049"
  },
  {
    "id": "arXiv:2007.10785",
    "title": "Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review",
    "abstract": "Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Marjane Khodatars",
      "Roohallah Alizadehsani",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Ali Khadem",
      "Delaram Sadeghi",
      "Sadiq Hussain",
      "Assef Zare",
      "Zahra Alizadeh Sani",
      "Javad Bazeli",
      "Fahime Khozeimeh",
      "Abbas Khosravi",
      "Saeid Nahavandi",
      "U. Rajendra Acharya",
      "Juan M. Gorriz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.10785"
  },
  {
    "id": "arXiv:2008.05865",
    "title": "DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis",
    "abstract": "DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis",
    "descriptor": "",
    "authors": [
      "Ming Tao",
      "Hao Tang",
      "Fei Wu",
      "Xiao-Yuan Jing",
      "Bing-Kun Bao",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.05865"
  },
  {
    "id": "arXiv:2008.13276",
    "title": "Proportional Participatory Budgeting with Additive Utilities",
    "abstract": "Comments: 26 pages, improved presentation, renamed voting rule to the Method of Equal Shares",
    "descriptor": "\nComments: 26 pages, improved presentation, renamed voting rule to the Method of Equal Shares\n",
    "authors": [
      "Dominik Peters",
      "Grzegorz Pierczy\u0144ski",
      "Piotr Skowron"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2008.13276"
  },
  {
    "id": "arXiv:2010.02990",
    "title": "First-Order Optimization Inspired from Finite-Time Convergent Flows",
    "abstract": "First-Order Optimization Inspired from Finite-Time Convergent Flows",
    "descriptor": "",
    "authors": [
      "Siqi Zhang",
      "Mouhacine Benosman",
      "Orlando Romero",
      "Anoop Cherian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.02990"
  },
  {
    "id": "arXiv:2010.11740",
    "title": "Robust Low-tubal-rank Tensor Completion based on Tensor Factorization  and Maximum Correntopy Criterion",
    "abstract": "Robust Low-tubal-rank Tensor Completion based on Tensor Factorization  and Maximum Correntopy Criterion",
    "descriptor": "",
    "authors": [
      "Yicong He",
      "George K. Atia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.11740"
  },
  {
    "id": "arXiv:2010.13575",
    "title": "Load balancing policies without feedback using timed replicas",
    "abstract": "Comments: 30 pages, 13 figures",
    "descriptor": "\nComments: 30 pages, 13 figures\n",
    "authors": [
      "Rooji Jinan",
      "Ajay Badita",
      "Tejas Bodas",
      "Parimal Parag"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.13575"
  },
  {
    "id": "arXiv:2011.00813",
    "title": "Multi-Armed Bandits with Censored Consumption of Resources",
    "abstract": "Multi-Armed Bandits with Censored Consumption of Resources",
    "descriptor": "",
    "authors": [
      "Viktor Bengs",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.00813"
  },
  {
    "id": "arXiv:2011.02796",
    "title": "FederBoost: Private Federated Learning for GBDT",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Zhihua Tian",
      "Rui Zhang",
      "Xiaoyang Hou",
      "Jian Liu",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.02796"
  },
  {
    "id": "arXiv:2011.06259",
    "title": "Learning to Segment Dynamic Objects using SLAM Outliers",
    "abstract": "Comments: Published in the proceedings of ICPR 2020 (25th International Conference on Pattern Recognition): this https URL",
    "descriptor": "\nComments: Published in the proceedings of ICPR 2020 (25th International Conference on Pattern Recognition): this https URL\n",
    "authors": [
      "Adrian Bojko",
      "Romain Dupont",
      "Mohamed Tamaazousti",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.06259"
  },
  {
    "id": "arXiv:2011.10850",
    "title": "Robust Data Hiding Using Inverse Gradient Attention",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Honglei Zhang",
      "Hu Wang",
      "Yuanzhouhan Cao",
      "Chunhua Shen",
      "Yidong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.10850"
  },
  {
    "id": "arXiv:2012.07975",
    "title": "Learning Visual Robotic Control Efficiently with Contrastive  Pre-training and Data Augmentation",
    "abstract": "Learning Visual Robotic Control Efficiently with Contrastive  Pre-training and Data Augmentation",
    "descriptor": "",
    "authors": [
      "Albert Zhan",
      "Ruihan Zhao",
      "Lerrel Pinto",
      "Pieter Abbeel",
      "Michael Laskin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07975"
  },
  {
    "id": "arXiv:2012.09700",
    "title": "RainNet: A Large-Scale Imagery Dataset and Benchmark for Spatial  Precipitation Downscaling",
    "abstract": "Comments: Accepted at NeurIPS 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Project page: this https URL\n",
    "authors": [
      "Xuanhong Chen",
      "Kairui Feng",
      "Naiyuan Liu",
      "Bingbing Ni",
      "Yifan Lu",
      "Zhengyan Tong",
      "Ziang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09700"
  },
  {
    "id": "arXiv:2012.15198",
    "title": "Crossover-SGD: A gossip-based communication in distributed deep learning  for alleviating large mini-batch problem and enhancing scalability",
    "abstract": "Comments: Under review as a journal paper at CCPE",
    "descriptor": "\nComments: Under review as a journal paper at CCPE\n",
    "authors": [
      "Sangho Yeo",
      "Minho Bae",
      "Minjoong Jeong",
      "Oh-kyoung Kwon",
      "Sangyoon Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.15198"
  },
  {
    "id": "arXiv:2101.12690",
    "title": "Towards Generalising Neural Implicit Representations",
    "abstract": "Comments: ECCVW 2022",
    "descriptor": "\nComments: ECCVW 2022\n",
    "authors": [
      "Theo W. Costain",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.12690"
  },
  {
    "id": "arXiv:2102.04211",
    "title": "Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion",
    "abstract": "Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion",
    "descriptor": "",
    "authors": [
      "Dimitri Ognibene",
      "Davide Taibi",
      "Udo Kruschwitz",
      "Rodrigo Souza Wilkens",
      "Davinia Hernandez-Leo",
      "Emily Theophilou",
      "Lidia Scifo",
      "Rene Alejandro Lobo",
      "Francesco Lomonaco",
      "Sabrina Eimler",
      "H. Ulrich Hoppe",
      "Nils Malzahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.04211"
  },
  {
    "id": "arXiv:2102.11008",
    "title": "InsNet: An Efficient, Flexible, and Performant Insertion-based Text  Generation Model",
    "abstract": "Comments: Accepted as a poster paper at NeurIPS 2022",
    "descriptor": "\nComments: Accepted as a poster paper at NeurIPS 2022\n",
    "authors": [
      "Sidi Lu",
      "Tao Meng",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.11008"
  },
  {
    "id": "arXiv:2102.11598",
    "title": "Biologically Plausible Learning using GAIT-prop Scales to ImageNet",
    "abstract": "Biologically Plausible Learning using GAIT-prop Scales to ImageNet",
    "descriptor": "",
    "authors": [
      "Sander Dalm",
      "Nasir Ahmad",
      "Luca Ambrogioni",
      "Marcel van Gerven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11598"
  },
  {
    "id": "arXiv:2103.11395",
    "title": "ScanMix: Learning from Severe Label Noise via Semantic Clustering and  Semi-Supervised Learning",
    "abstract": "Comments: Paper accepted at Pattern Recognition",
    "descriptor": "\nComments: Paper accepted at Pattern Recognition\n",
    "authors": [
      "Ragav Sachdeva",
      "Filipe R Cordeiro",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11395"
  },
  {
    "id": "arXiv:2104.09987",
    "title": "Differentiable Model Compression via Pseudo Quantization Noise",
    "abstract": "Comments: final TMLR version",
    "descriptor": "\nComments: final TMLR version\n",
    "authors": [
      "Alexandre D\u00e9fossez",
      "Yossi Adi",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09987"
  },
  {
    "id": "arXiv:2104.12436",
    "title": "Designing Optimal Key Lengths and Control Laws for Encrypted Control  Systems based on Sample Identifying Complexity and Deciphering Time",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Kaoru Teranishi",
      "Tomonori Sadamoto",
      "Aranya Chakrabortty",
      "Kiminao Kogiso"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.12436"
  },
  {
    "id": "arXiv:2104.12508",
    "title": "Resynchronized Uniformization and Definability Problems for Rational  Relations",
    "abstract": "Resynchronized Uniformization and Definability Problems for Rational  Relations",
    "descriptor": "",
    "authors": [
      "Christof L\u00f6ding",
      "Sarah Winter"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.12508"
  },
  {
    "id": "arXiv:2105.00117",
    "title": "InfoNEAT: Information Theory-based NeuroEvolution of Augmenting  Topologies for Side-channel Analysis",
    "abstract": "InfoNEAT: Information Theory-based NeuroEvolution of Augmenting  Topologies for Side-channel Analysis",
    "descriptor": "",
    "authors": [
      "Rabin Yu Acharya",
      "Fatemeh Ganji",
      "Domenic Forte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00117"
  },
  {
    "id": "arXiv:2105.08309",
    "title": "Time and Query Optimal Quantum Algorithms Based on Decision Trees",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Salman Beigi",
      "Leila Taghavi",
      "Artin Tajdini"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.08309"
  },
  {
    "id": "arXiv:2105.10867",
    "title": "EXoN: EXplainable encoder Network",
    "abstract": "EXoN: EXplainable encoder Network",
    "descriptor": "",
    "authors": [
      "SeungHwan An",
      "Hosik Choi",
      "Jong-June Jeon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10867"
  },
  {
    "id": "arXiv:2105.11818",
    "title": "SGD with Coordinate Sampling: Theory and Practice",
    "abstract": "Comments: Journal of Machine Learning Research 2022",
    "descriptor": "\nComments: Journal of Machine Learning Research 2022\n",
    "authors": [
      "R\u00e9mi Leluc",
      "Fran\u00e7ois Portier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11818"
  },
  {
    "id": "arXiv:2106.12133",
    "title": "A General Lotto game with asymmetric budget uncertainty",
    "abstract": "A General Lotto game with asymmetric budget uncertainty",
    "descriptor": "",
    "authors": [
      "Keith Paarporn",
      "Rahul Chandan",
      "Mahnoosh Alizadeh",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.12133"
  },
  {
    "id": "arXiv:2106.12231",
    "title": "ParK: Sound and Efficient Kernel Ridge Regression by Feature Space  Partitions",
    "abstract": "ParK: Sound and Efficient Kernel Ridge Regression by Feature Space  Partitions",
    "descriptor": "",
    "authors": [
      "Luigi Carratino",
      "Stefano Vigogna",
      "Daniele Calandriello",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12231"
  },
  {
    "id": "arXiv:2106.16028",
    "title": "Real-world Video Deblurring: A Benchmark Dataset and An Efficient  Recurrent Neural Network",
    "abstract": "Comments: Accepted by IJCV (extended version of ECCV2020)",
    "descriptor": "\nComments: Accepted by IJCV (extended version of ECCV2020)\n",
    "authors": [
      "Zhihang Zhong",
      "Ye Gao",
      "Yinqiang Zheng",
      "Bo Zheng",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16028"
  },
  {
    "id": "arXiv:2107.04885",
    "title": "Filling MIS Vertices by Myopic Luminous Robots",
    "abstract": "Comments: A version of this paper appears in the Proceedings of ICDCIT'23",
    "descriptor": "\nComments: A version of this paper appears in the Proceedings of ICDCIT'23\n",
    "authors": [
      "Subhajit Pramanick",
      "Sai Vamshi Samala",
      "Debasish Pattanayak",
      "Partha Sarathi Mandal"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.04885"
  },
  {
    "id": "arXiv:2107.08146",
    "title": "Picard understanding Darmok: A Dataset and Model for Metaphor-Rich  Translation in a Constructed Language",
    "abstract": "Comments: Accepted to the the 2022 Workshop on Figurative Language Processing (at EMNLP 2022)",
    "descriptor": "\nComments: Accepted to the the 2022 Workshop on Figurative Language Processing (at EMNLP 2022)\n",
    "authors": [
      "Peter Jansen",
      "Jordan Boyd-Graber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.08146"
  },
  {
    "id": "arXiv:2107.09047",
    "title": "Know Thyself: Transferable Visual Control Policies Through  Robot-Awareness",
    "abstract": "Comments: Updated to ICLR22 version",
    "descriptor": "\nComments: Updated to ICLR22 version\n",
    "authors": [
      "Edward S. Hu",
      "Kun Huang",
      "Oleh Rybkin",
      "Dinesh Jayaraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.09047"
  },
  {
    "id": "arXiv:2108.00065",
    "title": "Model Preserving Compression for Neural Networks",
    "abstract": "Comments: 26 pages, 15 figures. To be published in Advances in Neural Information Processing Systems 35",
    "descriptor": "\nComments: 26 pages, 15 figures. To be published in Advances in Neural Information Processing Systems 35\n",
    "authors": [
      "Jerry Chee",
      "Megan Renz",
      "Anil Damle",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00065"
  },
  {
    "id": "arXiv:2108.01578",
    "title": "SPG-VTON: Semantic Prediction Guidance for Multi-pose Virtual Try-on",
    "abstract": "SPG-VTON: Semantic Prediction Guidance for Multi-pose Virtual Try-on",
    "descriptor": "",
    "authors": [
      "Bingwen Hu",
      "Ping Liu",
      "Zhedong Zheng",
      "Mingwu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01578"
  },
  {
    "id": "arXiv:2108.05970",
    "title": "Derandomization of Cell Sampling",
    "abstract": "Derandomization of Cell Sampling",
    "descriptor": "",
    "authors": [
      "Alexander Golovnev",
      "Tom Gur",
      "Igor Shinkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.05970"
  },
  {
    "id": "arXiv:2108.06084",
    "title": "The Stability-Efficiency Dilemma: Investigating Sequence Length Warmup  for Training GPT Models",
    "abstract": "Comments: Published in NeurIPS 2022. This paper was previously titled \"Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training\" in early arxiv preprint versions",
    "descriptor": "\nComments: Published in NeurIPS 2022. This paper was previously titled \"Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training\" in early arxiv preprint versions\n",
    "authors": [
      "Conglong Li",
      "Minjia Zhang",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.06084"
  },
  {
    "id": "arXiv:2108.07265",
    "title": "The Integrated Probabilistic Data Association Filter Adapted to Lie  Groups",
    "abstract": "Comments: 21 pages, 10 figures, 1 table will be submitted",
    "descriptor": "\nComments: 21 pages, 10 figures, 1 table will be submitted\n",
    "authors": [
      "Mark E. Petersen",
      "Randal W. Beard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.07265"
  },
  {
    "id": "arXiv:2108.07622",
    "title": "Two-Timescale Design for Reconfigurable Intelligent Surface-Aided  Massive MIMO Systems with Imperfect CSI",
    "abstract": "Comments: Revision in IEEE TIT. Keywords: Reconfigurable Intelligent Surface, Intelligent Reflecting Surface, Massive MIMO, Channel estimation, etc",
    "descriptor": "\nComments: Revision in IEEE TIT. Keywords: Reconfigurable Intelligent Surface, Intelligent Reflecting Surface, Massive MIMO, Channel estimation, etc\n",
    "authors": [
      "Kangda Zhi",
      "Cunhua Pan",
      "Hong Ren",
      "Kezhi Wang",
      "Maged Elkashlan",
      "Marco Di Renzo",
      "Robert Schober",
      "H. Vincent Poor",
      "Jiangzhou Wang",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.07622"
  },
  {
    "id": "arXiv:2109.03025",
    "title": "Linear equations for unordered data vectors in $[D]^k\\to{}Z^d$",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Piotr Hofman",
      "Jakub R\u00f3\u017cycki"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.03025"
  },
  {
    "id": "arXiv:2109.03560",
    "title": "X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning",
    "abstract": "Comments: Accepted by CIKM'2022",
    "descriptor": "\nComments: Accepted by CIKM'2022\n",
    "authors": [
      "Baoyu Jing",
      "Shengyu Feng",
      "Yuejia Xiang",
      "Xi Chen",
      "Yu Chen",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03560"
  },
  {
    "id": "arXiv:2109.03631",
    "title": "Renovo: Prototype of a Low-Cost Sensor-Based Therapeutic System for  Upper Limb Rehabilitation",
    "abstract": "Comments: 27 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 27 pages, 10 figures, 5 tables\n",
    "authors": [
      "Mohammad Ridwan Kabir",
      "Mohammad Anas Jawad",
      "Mohaimin Ehsan",
      "Hasan Mahmud",
      "Md. Kamrul Hasan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.03631"
  },
  {
    "id": "arXiv:2109.04352",
    "title": "PhysGNN: A Physics-Driven Graph Neural Network Based Model for  Predicting Soft Tissue Deformation in Image-Guided Neurosurgery",
    "abstract": "Comments: Accepted to the main track of NeurIPS 2022. Camera-ready version",
    "descriptor": "\nComments: Accepted to the main track of NeurIPS 2022. Camera-ready version\n",
    "authors": [
      "Yasmin Salehi",
      "Dennis Giannacopoulos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04352"
  },
  {
    "id": "arXiv:2109.07846",
    "title": "Telehealthcare and Telepathology in Pandemic: A Noninvasive, Low-Cost  Micro-Invasive and Multimodal Real-Time Online Application for Early  Diagnosis of COVID-19 Infection",
    "abstract": "Comments: 32 Pages. This article has been submitted for review to a prestigious journal",
    "descriptor": "\nComments: 32 Pages. This article has been submitted for review to a prestigious journal\n",
    "authors": [
      "Abdullah Bin Shams",
      "Md. Mohsin Sarker Raihan",
      "Md. Mohi Uddin Khan",
      "Ocean Monjur",
      "Rahat Bin Preo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2109.07846"
  },
  {
    "id": "arXiv:2109.10529",
    "title": "Numerical Continued Fraction Interpolation",
    "abstract": "Comments: corrected a few typos and added a reference",
    "descriptor": "\nComments: corrected a few typos and added a reference\n",
    "authors": [
      "Oliver Salazar Celis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.10529"
  },
  {
    "id": "arXiv:2109.10619",
    "title": "Eliciting Thinking Hierarchy without a Prior",
    "abstract": "Eliciting Thinking Hierarchy without a Prior",
    "descriptor": "",
    "authors": [
      "Yuqing Kong",
      "Yunqi Li",
      "Yubo Zhang",
      "Zhihuan Huang",
      "Jinzhao Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.10619"
  },
  {
    "id": "arXiv:2109.12221",
    "title": "Ground material classification for UAV-based photogrammetric 3D data A  2D-3D Hybrid Approach",
    "abstract": "Ground material classification for UAV-based photogrammetric 3D data A  2D-3D Hybrid Approach",
    "descriptor": "",
    "authors": [
      "Meida Chen",
      "Andrew Feng",
      "Yu Hou",
      "Kyle McCullough",
      "Pratusha Bhuvana Prasad",
      "Lucio Soibelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12221"
  },
  {
    "id": "arXiv:2109.12784",
    "title": "Learning from Few Samples: Transformation-Invariant SVMs with  Composition and Locality at Multiple Scales",
    "abstract": "Comments: Will appear in NeurIPS 2022",
    "descriptor": "\nComments: Will appear in NeurIPS 2022\n",
    "authors": [
      "Tao Liu",
      "P. R. Kumar",
      "Ruida Zhou",
      "Xi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.12784"
  },
  {
    "id": "arXiv:2109.12887",
    "title": "ICMRec: Item Cluster-Wise Multi-Objective Optimization for Unbiased  Recommendation",
    "abstract": "ICMRec: Item Cluster-Wise Multi-Objective Optimization for Unbiased  Recommendation",
    "descriptor": "",
    "authors": [
      "Yule Wang",
      "Xin Xin",
      "Yue Ding",
      "Yunzhe Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.12887"
  },
  {
    "id": "arXiv:2110.01519",
    "title": "Weak-shot Semantic Segmentation by Transferring Semantic Affinity and  Boundary",
    "abstract": "Comments: 29 pages, 8 figures",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Siyuan Zhou",
      "Li Niu",
      "Jianlou Si",
      "Chen Qian",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01519"
  },
  {
    "id": "arXiv:2110.03605",
    "title": "Robust Feature-Level Adversaries are Interpretability Tools",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Dylan Hadfield-Menell",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03605"
  },
  {
    "id": "arXiv:2110.04645",
    "title": "Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free  Reinforcement Learning",
    "abstract": "Comments: Short version in Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021); Full version in Information and Inference: A Journal of the IMA",
    "descriptor": "\nComments: Short version in Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021); Full version in Information and Inference: A Journal of the IMA\n",
    "authors": [
      "Gen Li",
      "Laixi Shi",
      "Yuxin Chen",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04645"
  },
  {
    "id": "arXiv:2110.05706",
    "title": "Deep Fusion Prior for Plenoptic Super-Resolution All-in-Focus Imaging",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Yuanjie Gu",
      "Yinghan Guan",
      "Zhibo Xiao",
      "Haoran Dai",
      "Cheng Liu",
      "Shouyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05706"
  },
  {
    "id": "arXiv:2110.05740",
    "title": "Temporal Abstraction in Reinforcement Learning with the Successor  Representation",
    "abstract": "Comments: 69 pages, 30 figures",
    "descriptor": "\nComments: 69 pages, 30 figures\n",
    "authors": [
      "Marlos C. Machado",
      "Andre Barreto",
      "Doina Precup",
      "Michael Bowling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05740"
  },
  {
    "id": "arXiv:2110.05781",
    "title": "BERTraffic: BERT-based Joint Speaker Role and Speaker Change Detection  for Air Traffic Control Communications",
    "abstract": "Comments: To be published in the 2022 IEEE Spoken Language Technology Workshop (SLT) (SLT 2022)",
    "descriptor": "\nComments: To be published in the 2022 IEEE Spoken Language Technology Workshop (SLT) (SLT 2022)\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Seyyed Saeed Sarfjoo",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Petr Motlicek",
      "Karel Ondrej",
      "Oliver Ohneiser",
      "Hartmut Helmke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05781"
  },
  {
    "id": "arXiv:2110.07566",
    "title": "Practical Benefits of Feature Feedback Under Distribution Shift",
    "abstract": "Practical Benefits of Feature Feedback Under Distribution Shift",
    "descriptor": "",
    "authors": [
      "Anurag Katakkar",
      "Clay H. Yoo",
      "Weiqin Wang",
      "Zachary C. Lipton",
      "Divyansh Kaushik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07566"
  },
  {
    "id": "arXiv:2110.08057",
    "title": "Almost Optimal Batch-Regret Tradeoff for Batch Linear Contextual Bandits",
    "abstract": "Almost Optimal Batch-Regret Tradeoff for Batch Linear Contextual Bandits",
    "descriptor": "",
    "authors": [
      "Zihan Zhang",
      "Xiangyang Ji",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08057"
  },
  {
    "id": "arXiv:2110.08500",
    "title": "On Model Selection Consistency of Lasso for High-Dimensional Ising  Models",
    "abstract": "On Model Selection Consistency of Lasso for High-Dimensional Ising  Models",
    "descriptor": "",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.08500"
  },
  {
    "id": "arXiv:2110.10267",
    "title": "Recognizability of morphisms",
    "abstract": "Recognizability of morphisms",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Dominique Perrin",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.10267"
  },
  {
    "id": "arXiv:2110.12184",
    "title": "Domain Adaptation via Maximizing Surrogate Mutual Information",
    "abstract": "Domain Adaptation via Maximizing Surrogate Mutual Information",
    "descriptor": "",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Qinyu Chen",
      "Zhi-Hong Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12184"
  },
  {
    "id": "arXiv:2110.12658",
    "title": "Operator Shifting for Model-based Policy Evaluation",
    "abstract": "Operator Shifting for Model-based Policy Evaluation",
    "descriptor": "",
    "authors": [
      "Xun Tang",
      "Lexing Ying",
      "Yuhua Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12658"
  },
  {
    "id": "arXiv:2110.14553",
    "title": "GenURL: A General Framework for Unsupervised Representation Learning",
    "abstract": "Comments: Tech report (revision) with 12 pages and 14 figures",
    "descriptor": "\nComments: Tech report (revision) with 12 pages and 14 figures\n",
    "authors": [
      "Siyuan Li",
      "Zicheng Liu",
      "Zelin Zang",
      "Di Wu",
      "Zhiyuan Chen",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14553"
  },
  {
    "id": "arXiv:2111.00701",
    "title": "Discourse Comprehension: A Question Answering Framework to Represent  Sentence Connections",
    "abstract": "Comments: EMNLP 2022 Camera Ready",
    "descriptor": "\nComments: EMNLP 2022 Camera Ready\n",
    "authors": [
      "Wei-Jen Ko",
      "Cutter Dalton",
      "Mark Simmons",
      "Eliza Fisher",
      "Greg Durrett",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00701"
  },
  {
    "id": "arXiv:2111.00841",
    "title": "Free Probability for predicting the performance of feed-forward fully  connected neural networks",
    "abstract": "Comments: 20 pages, many figures ; v1: Preliminary version ; v2: Added numerical benchmarks, and changed presentation; v3: Accepted in Neurips2022",
    "descriptor": "\nComments: 20 pages, many figures ; v1: Preliminary version ; v2: Added numerical benchmarks, and changed presentation; v3: Accepted in Neurips2022\n",
    "authors": [
      "Reda Chhaibi",
      "Tariq Daouda",
      "Ezechiel Kahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.00841"
  },
  {
    "id": "arXiv:2111.05850",
    "title": "Towards Green Automated Machine Learning: Status Quo and Future  Directions",
    "abstract": "Towards Green Automated Machine Learning: Status Quo and Future  Directions",
    "descriptor": "",
    "authors": [
      "Tanja Tornede",
      "Alexander Tornede",
      "Jonas Hanselle",
      "Marcel Wever",
      "Felix Mohr",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05850"
  },
  {
    "id": "arXiv:2111.06206",
    "title": "Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep  Models",
    "abstract": "Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep  Models",
    "descriptor": "",
    "authors": [
      "Jie Ren",
      "Mingjie Li",
      "Qirui Chen",
      "Huiqi Deng",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06206"
  },
  {
    "id": "arXiv:2111.07902",
    "title": "Deep Semantic Manipulation of Facial Videos",
    "abstract": "Comments: 4th Workshop and Competition on Affective Behavior Analysis in-the-wild (ABAW), European Conference on Computer Vision (ECCV), Tel Aviv, Israel, October 2022",
    "descriptor": "\nComments: 4th Workshop and Competition on Affective Behavior Analysis in-the-wild (ABAW), European Conference on Computer Vision (ECCV), Tel Aviv, Israel, October 2022\n",
    "authors": [
      "Girish Kumar Solanki",
      "Anastasios Roussos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.07902"
  },
  {
    "id": "arXiv:2111.08969",
    "title": "Addition Machines, Automatic Functions and Open Problems of Floyd and  Knuth",
    "abstract": "Addition Machines, Automatic Functions and Open Problems of Floyd and  Knuth",
    "descriptor": "",
    "authors": [
      "Sanjay Jain",
      "Xiaodong Jia",
      "Ammar Fathin Sabili",
      "Frank Stephan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.08969"
  },
  {
    "id": "arXiv:2111.09852",
    "title": "The Power of Selecting Key Blocks with Local Pre-ranking for Long  Document Information Retrieval",
    "abstract": "Comments: 34 pages, accepted by ACM Transactions on Information Systems (TOIS)",
    "descriptor": "\nComments: 34 pages, accepted by ACM Transactions on Information Systems (TOIS)\n",
    "authors": [
      "Minghan Li",
      "Diana Nicoleta Popa",
      "Johan Chagnon",
      "Yagmur Gizem Cinar",
      "Eric Gaussier"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.09852"
  },
  {
    "id": "arXiv:2111.10962",
    "title": "Enhancing Multilingual Language Model with Massive Multilingual  Knowledge Triples",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Linlin Liu",
      "Xin Li",
      "Ruidan He",
      "Lidong Bing",
      "Shafiq Joty",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10962"
  },
  {
    "id": "arXiv:2111.11840",
    "title": "Subgraph Permutation Equivariant Networks",
    "abstract": "Comments: Automorphism equivariant update function on sub-graphs",
    "descriptor": "\nComments: Automorphism equivariant update function on sub-graphs\n",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11840"
  },
  {
    "id": "arXiv:2111.14771",
    "title": "A fast algorithm on average for solving the Hamilton Cycle problem",
    "abstract": "A fast algorithm on average for solving the Hamilton Cycle problem",
    "descriptor": "",
    "authors": [
      "Michael Anastos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.14771"
  },
  {
    "id": "arXiv:2111.14971",
    "title": "Classification of animal sounds in a hyperdiverse rainforest using  Convolutional Neural Networks",
    "abstract": "Classification of animal sounds in a hyperdiverse rainforest using  Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Yuren Sun",
      "Tatiana Midori Maeda",
      "Claudia Solis-Lemus",
      "Daniel Pimentel-Alarcon",
      "Zuzana Burivalova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14971"
  },
  {
    "id": "arXiv:2112.01047",
    "title": "DKPLM: Decomposable Knowledge-enhanced Pre-trained Language Model for  Natural Language Understanding",
    "abstract": "Comments: Accepted by AAAI22",
    "descriptor": "\nComments: Accepted by AAAI22\n",
    "authors": [
      "Taolin Zhang",
      "Chengyu Wang",
      "Nan Hu",
      "Minghui Qiu",
      "Chengguang Tang",
      "Xiaofeng He",
      "Jun Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01047"
  },
  {
    "id": "arXiv:2112.02215",
    "title": "Deep Policy Iteration with Integer Programming for Inventory Management",
    "abstract": "Comments: Prior shorter version accepted to NeurIPS 2021 Deep RL Workshop. Authors are listed in alphabetical order",
    "descriptor": "\nComments: Prior shorter version accepted to NeurIPS 2021 Deep RL Workshop. Authors are listed in alphabetical order\n",
    "authors": [
      "Pavithra Harsha",
      "Ashish Jagmohan",
      "Jayant R. Kalagnanam",
      "Brian Quanz",
      "Divya Singhvi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.02215"
  },
  {
    "id": "arXiv:2112.03677",
    "title": "On Baker-Gill-Solovay Oracle Turing Machines and Relativization Barrier",
    "abstract": "Comments: Typos corrected. arXiv admin note: substantial text overlap with arXiv:2110.06211, arXiv:2110.05942, arXiv:2106.11886",
    "descriptor": "\nComments: Typos corrected. arXiv admin note: substantial text overlap with arXiv:2110.06211, arXiv:2110.05942, arXiv:2106.11886\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.03677"
  },
  {
    "id": "arXiv:2112.04388",
    "title": "A graph representation based on fluid diffusion model for data analysis:  theoretical aspects and enhanced community detection",
    "abstract": "Comments: 30 pages, 25 figures",
    "descriptor": "\nComments: 30 pages, 25 figures\n",
    "authors": [
      "Andrea Marinoni",
      "Christian Jutten",
      "Mark Girolami"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04388"
  },
  {
    "id": "arXiv:2112.04585",
    "title": "MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Rex Liu",
      "Huanle Zhang",
      "Hamed Pirsiavash",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04585"
  },
  {
    "id": "arXiv:2112.04607",
    "title": "Constrained Mean Shift Using Distant Yet Related Neighbors for  Representation Learning",
    "abstract": "Comments: Code is available at this https URL arXiv admin note: text overlap with arXiv:2110.10309",
    "descriptor": "\nComments: Code is available at this https URL arXiv admin note: text overlap with arXiv:2110.10309\n",
    "authors": [
      "KL Navaneet",
      "Soroush Abbasi Koohpayegani",
      "Ajinkya Tejankar",
      "Kossar Pourahmadi",
      "Akshayvarun Subramanya",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04607"
  },
  {
    "id": "arXiv:2112.05814",
    "title": "Deep ViT Features as Dense Visual Descriptors",
    "abstract": "Comments: Revised version - high res figures",
    "descriptor": "\nComments: Revised version - high res figures\n",
    "authors": [
      "Shir Amir",
      "Yossi Gandelsman",
      "Shai Bagon",
      "Tali Dekel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05814"
  },
  {
    "id": "arXiv:2112.06733",
    "title": "Measuring Context-Word Biases in Lexical Semantic Datasets",
    "abstract": "Comments: EMNLP 2022 main conference long paper",
    "descriptor": "\nComments: EMNLP 2022 main conference long paper\n",
    "authors": [
      "Qianchu Liu",
      "Diana McCarthy",
      "Anna Korhonen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06733"
  },
  {
    "id": "arXiv:2112.08723",
    "title": "Distilled Dual-Encoder Model for Vision-Language Understanding",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zekun Wang",
      "Wenhui Wang",
      "Haichao Zhu",
      "Ming Liu",
      "Bing Qin",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08723"
  },
  {
    "id": "arXiv:2112.11573",
    "title": "Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly  Types",
    "abstract": "Comments: WACV2023",
    "descriptor": "\nComments: WACV2023\n",
    "authors": [
      "Kihyuk Sohn",
      "Jinsung Yoon",
      "Chun-Liang Li",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11573"
  },
  {
    "id": "arXiv:2112.14518",
    "title": "Mutual influence between language and perception in multi-agent  communication games",
    "abstract": "Mutual influence between language and perception in multi-agent  communication games",
    "descriptor": "",
    "authors": [
      "Xenia Ohmer",
      "Michael Marino",
      "Michael Franke",
      "Peter K\u00f6nig"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.14518"
  },
  {
    "id": "arXiv:2112.15348",
    "title": "Training Recurrent Neural Networks by Sequential Least Squares and the  Alternating Direction Method of Multipliers",
    "abstract": "Comments: 23 pages, 4 figures. Submitted for publication",
    "descriptor": "\nComments: 23 pages, 4 figures. Submitted for publication\n",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.15348"
  },
  {
    "id": "arXiv:2201.04234",
    "title": "Leveraging Unlabeled Data to Predict Out-of-Distribution Performance",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Saurabh Garg",
      "Sivaraman Balakrishnan",
      "Zachary C. Lipton",
      "Behnam Neyshabur",
      "Hanie Sedghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.04234"
  },
  {
    "id": "arXiv:2201.04429",
    "title": "Constraint Learning to Define Trust Regions in Predictive-Model Embedded  Optimization",
    "abstract": "Constraint Learning to Define Trust Regions in Predictive-Model Embedded  Optimization",
    "descriptor": "",
    "authors": [
      "Chenbo Shi",
      "Mohsen Emadikhiav",
      "Leonardo Lozano",
      "David Bergman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.04429"
  },
  {
    "id": "arXiv:2201.04545",
    "title": "On generalization bounds for deep networks based on loss surface  implicit regularization",
    "abstract": "Comments: To appear in IEEE Transaction on Information Theory",
    "descriptor": "\nComments: To appear in IEEE Transaction on Information Theory\n",
    "authors": [
      "Masaaki Imaizumi",
      "Johannes Schmidt-Hieber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04545"
  },
  {
    "id": "arXiv:2201.05575",
    "title": "Reasoning Through Memorization: Nearest Neighbor Knowledge Graph  Embeddings",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ningyu Zhang",
      "Xin Xie",
      "Xiang Chen",
      "Xu Cheng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.05575"
  },
  {
    "id": "arXiv:2201.07199",
    "title": "Invariant Representation Driven Neural Classifier for Anti-QCD Jet  Tagging",
    "abstract": "Comments: 32 pages, 15 figures. To appear in the Journal of High Energy Physics",
    "descriptor": "\nComments: 32 pages, 15 figures. To appear in the Journal of High Energy Physics\n",
    "authors": [
      "Taoli Cheng",
      "Aaron Courville"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2201.07199"
  },
  {
    "id": "arXiv:2201.11115",
    "title": "CsFEVER and CTKFacts: Acquiring Czech data for fact verification",
    "abstract": "Comments: submitted to LREV journal for review, resubmission, changed title according to reviewer suggestion",
    "descriptor": "\nComments: submitted to LREV journal for review, resubmission, changed title according to reviewer suggestion\n",
    "authors": [
      "Herbert Ullrich",
      "Jan Drchal",
      "Martin R\u00fdpar",
      "Hana Vincourov\u00e1",
      "V\u00e1clav Moravec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11115"
  },
  {
    "id": "arXiv:2201.12437",
    "title": "Mobile Robot Manipulation using Pure Object Detection",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Brent Griffin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12437"
  },
  {
    "id": "arXiv:2201.12570",
    "title": "AntBO: Towards Real-World Automated Antibody Design with Combinatorial  Bayesian Optimisation",
    "abstract": "AntBO: Towards Real-World Automated Antibody Design with Combinatorial  Bayesian Optimisation",
    "descriptor": "",
    "authors": [
      "Asif Khan",
      "Alexander I. Cowen-Rivers",
      "Antoine Grosnit",
      "Derrick-Goh-Xin Deik",
      "Philippe A. Robert",
      "Victor Greiff",
      "Eva Smorodina",
      "Puneet Rawat",
      "Kamil Dreczkowski",
      "Rahmad Akbar",
      "Rasul Tutunov",
      "Dany Bou-Ammar",
      "Jun Wang",
      "Amos Storkey",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12570"
  },
  {
    "id": "arXiv:2201.13230",
    "title": "POTATO: exPlainable infOrmation exTrAcTion framewOrk",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "\u00c1d\u00e1m Kov\u00e1cs",
      "Kinga G\u00e9mes",
      "Eszter Ikl\u00f3di",
      "G\u00e1bor Recski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13230"
  },
  {
    "id": "arXiv:2202.00666",
    "title": "Locally Typical Sampling",
    "abstract": "Comments: TACL 2022",
    "descriptor": "\nComments: TACL 2022\n",
    "authors": [
      "Clara Meister",
      "Tiago Pimentel",
      "Gian Wiher",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00666"
  },
  {
    "id": "arXiv:2202.01336",
    "title": "Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation",
    "abstract": "Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation",
    "descriptor": "",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zachary C. Lipton",
      "Li Erran Li",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01336"
  },
  {
    "id": "arXiv:2202.01341",
    "title": "Robust Binary Models by Pruning Randomly-initialized Networks",
    "abstract": "Comments: Accepted as NeurIPS 2022 paper",
    "descriptor": "\nComments: Accepted as NeurIPS 2022 paper\n",
    "authors": [
      "Chen Liu",
      "Ziqi Zhao",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01341"
  },
  {
    "id": "arXiv:2202.01824",
    "title": "Waveform inversion via reduced order modeling",
    "abstract": "Waveform inversion via reduced order modeling",
    "descriptor": "",
    "authors": [
      "Liliana Borcea",
      "Josselin Garnier",
      "Alexander V. Mamonov",
      "J\u00f6rn Zimmerling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01824"
  },
  {
    "id": "arXiv:2202.01908",
    "title": "Sampling with Riemannian Hamiltonian Monte Carlo in a Constrained Space",
    "abstract": "Comments: Mixing-rate proof added. To appear in NeurIPS 2022",
    "descriptor": "\nComments: Mixing-rate proof added. To appear in NeurIPS 2022\n",
    "authors": [
      "Yunbum Kook",
      "Yin Tat Lee",
      "Ruoqi Shen",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01908"
  },
  {
    "id": "arXiv:2202.02215",
    "title": "A Survey on Safety-Critical Driving Scenario Generation -- A  Methodological Perspective",
    "abstract": "Comments: 18 pages, 5 figures",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Wenhao Ding",
      "Chejian Xu",
      "Mansur Arief",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02215"
  },
  {
    "id": "arXiv:2202.02671",
    "title": "Stable factorization for phase factors of quantum signal processing",
    "abstract": "Stable factorization for phase factors of quantum signal processing",
    "descriptor": "",
    "authors": [
      "Lexing Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02671"
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04777"
  },
  {
    "id": "arXiv:2202.05599",
    "title": "ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization",
    "abstract": "Comments: Accepted to EMNLP 2022 (main conference)",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (main conference)\n",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Ziyao Lu",
      "Duo Zheng",
      "Zhixu Li",
      "Jianfeng Qu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05599"
  },
  {
    "id": "arXiv:2202.05826",
    "title": "End-to-end Algorithm Synthesis with Recurrent Networks: Logical  Extrapolation Without Overthinking",
    "abstract": "End-to-end Algorithm Synthesis with Recurrent Networks: Logical  Extrapolation Without Overthinking",
    "descriptor": "",
    "authors": [
      "Arpit Bansal",
      "Avi Schwarzschild",
      "Eitan Borgnia",
      "Zeyad Emam",
      "Furong Huang",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05826"
  },
  {
    "id": "arXiv:2202.06574",
    "title": "I-Tuning: Tuning Frozen Language Models with Image for Lightweight Image  Captioning",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ziyang Luo",
      "Zhipeng Hu",
      "Yadong Xi",
      "Rongsheng Zhang",
      "Jing Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06574"
  },
  {
    "id": "arXiv:2202.08370",
    "title": "CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data",
    "abstract": "CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data",
    "descriptor": "",
    "authors": [
      "Keyon Vafa",
      "Emil Palikot",
      "Tianyu Du",
      "Ayush Kanodia",
      "Susan Athey",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.08370"
  },
  {
    "id": "arXiv:2202.09312",
    "title": "Learning Predictions for Algorithms with Predictions",
    "abstract": "Comments: NeurIPS 2022 camera-ready",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready\n",
    "authors": [
      "Mikhail Khodak",
      "Maria-Florina Balcan",
      "Ameet Talwalkar",
      "Sergei Vassilvitskii"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09312"
  },
  {
    "id": "arXiv:2202.10643",
    "title": "Equivariant Graph Hierarchy-Based Neural Networks",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Jiaqi Han",
      "Wenbing Huang",
      "Tingyang Xu",
      "Yu Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10643"
  },
  {
    "id": "arXiv:2202.11451",
    "title": "Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified  Multilingual Prompt",
    "abstract": "Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified  Multilingual Prompt",
    "descriptor": "",
    "authors": [
      "Lianzhe Huang",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11451"
  },
  {
    "id": "arXiv:2202.11614",
    "title": "Nonstationary Dual Averaging and Online Fair Allocation",
    "abstract": "Comments: Neurips 2022",
    "descriptor": "\nComments: Neurips 2022\n",
    "authors": [
      "Luofeng Liao",
      "Yuan Gao",
      "Christian Kroer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.11614"
  },
  {
    "id": "arXiv:2202.11672",
    "title": "Learning Fast and Slow for Online Time Series Forecasting",
    "abstract": "Learning Fast and Slow for Online Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Quang Pham",
      "Chenghao Liu",
      "Doyen Sahoo",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11672"
  },
  {
    "id": "arXiv:2202.12104",
    "title": "A Transformer-based Network for Deformable Medical Image Registration",
    "abstract": "Comments: 12 pages, 7 figures, 25 conferences",
    "descriptor": "\nComments: 12 pages, 7 figures, 25 conferences\n",
    "authors": [
      "Yibo Wang",
      "Wen Qian",
      "Xuming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12104"
  },
  {
    "id": "arXiv:2203.03535",
    "title": "Influencing Long-Term Behavior in Multiagent Reinforcement Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022. The earlier version was presented at the Gamification and Multiagent Solutions Workshop (ICLR 2022) with a spotlight. Code at this https URL and videos at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. The earlier version was presented at the Gamification and Multiagent Solutions Workshop (ICLR 2022) with a spotlight. Code at this https URL and videos at this https URL\n",
    "authors": [
      "Dong-Ki Kim",
      "Matthew Riemer",
      "Miao Liu",
      "Jakob N. Foerster",
      "Michael Everett",
      "Chuangchuang Sun",
      "Gerald Tesauro",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.03535"
  },
  {
    "id": "arXiv:2203.04703",
    "title": "LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph  Embeddings",
    "abstract": "LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph  Embeddings",
    "descriptor": "",
    "authors": [
      "Md Rashad Al Hasan Rony",
      "Mirza Mohtashim Alam",
      "Semab Ali",
      "Jens Lehmann",
      "Sahar Vahdati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04703"
  },
  {
    "id": "arXiv:2203.05363",
    "title": "Differentially Private Learning Needs Hidden State (Or Much Faster  Convergence)",
    "abstract": "Differentially Private Learning Needs Hidden State (Or Much Faster  Convergence)",
    "descriptor": "",
    "authors": [
      "Jiayuan Ye",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05363"
  },
  {
    "id": "arXiv:2203.07593",
    "title": "Distraction is All You Need for Fairness",
    "abstract": "Distraction is All You Need for Fairness",
    "descriptor": "",
    "authors": [
      "Mehdi Yazdani-Jahromi",
      "AmirArsalan Rajabi",
      "Aida Tayebi",
      "Ozlem Ozmen Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07593"
  },
  {
    "id": "arXiv:2203.07738",
    "title": "DICS-Net: Dictionary-guided Implicit-Component-Supervision Network for  Few-Shot Classification",
    "abstract": "DICS-Net: Dictionary-guided Implicit-Component-Supervision Network for  Few-Shot Classification",
    "descriptor": "",
    "authors": [
      "Shuai Shao",
      "Lei Xing",
      "Weifeng Liu",
      "Yanjiang Wang",
      "Baodi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07738"
  },
  {
    "id": "arXiv:2203.10838",
    "title": "Faster Randomized Block Sparse Kaczmarz by Averaging",
    "abstract": "Faster Randomized Block Sparse Kaczmarz by Averaging",
    "descriptor": "",
    "authors": [
      "Lionel Tondji",
      "Dirk A Lorenz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.10838"
  },
  {
    "id": "arXiv:2203.11635",
    "title": "Feature Distribution Matching for Federated Domain Generalization",
    "abstract": "Comments: Accepted for Asian Conference on Machine Learning (ACML 2022)",
    "descriptor": "\nComments: Accepted for Asian Conference on Machine Learning (ACML 2022)\n",
    "authors": [
      "Yuwei Sun",
      "Ng Chong",
      "Hideya Ochiai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11635"
  },
  {
    "id": "arXiv:2203.11933",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models  with Adversarial Learning",
    "abstract": "Comments: 17 pages, 4 figures, 7 tables. For code and trained token embeddings, see this https URL; Changed to use ACL layout, added joint training with comparison figure; This paper is accepted for publication at AACL 2022, the official version of record is in the ACL Anthology",
    "descriptor": "\nComments: 17 pages, 4 figures, 7 tables. For code and trained token embeddings, see this https URL; Changed to use ACL layout, added joint training with comparison figure; This paper is accepted for publication at AACL 2022, the official version of record is in the ACL Anthology\n",
    "authors": [
      "Hugo Berg",
      "Siobhan Mackenzie Hall",
      "Yash Bhalgat",
      "Wonsuk Yang",
      "Hannah Rose Kirk",
      "Aleksandar Shtedritski",
      "Max Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.11933"
  },
  {
    "id": "arXiv:2203.16309",
    "title": "Zero-shot meta-learning for small-scale data from human subjects",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Julie Jiang",
      "Kristina Lerman",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16309"
  },
  {
    "id": "arXiv:2203.16822",
    "title": "How Does Pre-trained Wav2Vec 2.0 Perform on Domain Shifted ASR? An  Extensive Benchmark on Air Traffic Control Communications",
    "abstract": "Comments: To be published in the 2022 IEEE Spoken Language Technology Workshop (SLT) (SLT 2022)",
    "descriptor": "\nComments: To be published in the 2022 IEEE Spoken Language Technology Workshop (SLT) (SLT 2022)\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Saeed Sarfjoo",
      "Petr Motlicek",
      "Matthias Kleinert",
      "Hartmut Helmke",
      "Oliver Ohneiser",
      "Qingran Zhan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16822"
  },
  {
    "id": "arXiv:2204.00043",
    "title": "Efficient Active Learning with Abstention",
    "abstract": "Comments: To appear at NeurIPS 2022",
    "descriptor": "\nComments: To appear at NeurIPS 2022\n",
    "authors": [
      "Yinglun Zhu",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00043"
  },
  {
    "id": "arXiv:2204.01815",
    "title": "Tensor Completion with Provable Consistency and Fairness Guarantees for  Recommender Systems",
    "abstract": "Comments: Changed to more descriptive title; polished text and proofs",
    "descriptor": "\nComments: Changed to more descriptive title; polished text and proofs\n",
    "authors": [
      "Tung Nguyen",
      "Jeffrey Uhlmann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01815"
  },
  {
    "id": "arXiv:2204.02553",
    "title": "RODD: A Self-Supervised Approach for Robust Out-of-Distribution  Detection",
    "abstract": "Comments: Accepted in CVPR Art of Robustness Workshop Proceedings",
    "descriptor": "\nComments: Accepted in CVPR Art of Robustness Workshop Proceedings\n",
    "authors": [
      "Umar Khalid",
      "Ashkan Esmaeili",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02553"
  },
  {
    "id": "arXiv:2204.02915",
    "title": "Compact Post-Quantum Signatures from Proofs of Knowledge leveraging  Structure for the PKP, SD and RSD Problems",
    "abstract": "Compact Post-Quantum Signatures from Proofs of Knowledge leveraging  Structure for the PKP, SD and RSD Problems",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Bidoux",
      "Philippe Gaborit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02915"
  },
  {
    "id": "arXiv:2204.04327",
    "title": "Show, Don't Tell: Demonstrations Outperform Descriptions for  Schema-Guided Task-Oriented Dialogue",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Raghav Gupta",
      "Harrison Lee",
      "Jeffrey Zhao",
      "Abhinav Rastogi",
      "Yuan Cao",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04327"
  },
  {
    "id": "arXiv:2204.04371",
    "title": "Learning to Schedule Multi-Server Jobs with Fluctuated Processing Speeds",
    "abstract": "Learning to Schedule Multi-Server Jobs with Fluctuated Processing Speeds",
    "descriptor": "",
    "authors": [
      "Hailiang Zhao",
      "Shuiguang Deng",
      "Feiyi Chen",
      "Jianwei Yin",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04371"
  },
  {
    "id": "arXiv:2204.06168",
    "title": "ENO-Based High-Order Data-Bounded and Constrained Positivity-Preserving  Interpolation",
    "abstract": "ENO-Based High-Order Data-Bounded and Constrained Positivity-Preserving  Interpolation",
    "descriptor": "",
    "authors": [
      "Timbwaoga A. J. Ouermi",
      "Robert M. Kirby",
      "Martin Berzins"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.06168"
  },
  {
    "id": "arXiv:2204.06251",
    "title": "Experimental Standards for Deep Learning in Natural Language Processing  Research",
    "abstract": "Experimental Standards for Deep Learning in Natural Language Processing  Research",
    "descriptor": "",
    "authors": [
      "Dennis Ulmer",
      "Elisa Bassignana",
      "Max M\u00fcller-Eberstein",
      "Daniel Varab",
      "Mike Zhang",
      "Rob van der Goot",
      "Christian Hardmeier",
      "Barbara Plank"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06251"
  },
  {
    "id": "arXiv:2204.07054",
    "title": "BrainGB: A Benchmark for Brain Network Analysis with Graph Neural  Networks",
    "abstract": "Comments: In submission to IEEE Transactions on Medical Imaging",
    "descriptor": "\nComments: In submission to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Hejie Cui",
      "Wei Dai",
      "Yanqiao Zhu",
      "Xuan Kan",
      "Antonio Aodong Chen Gu",
      "Joshua Lukemire",
      "Liang Zhan",
      "Lifang He",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07054"
  },
  {
    "id": "arXiv:2204.07615",
    "title": "TabNAS: Rejection Sampling for Neural Architecture Search on Tabular  Datasets",
    "abstract": "Comments: NeurIPS 2022; 30 pages, 15 figures, 7 tables",
    "descriptor": "\nComments: NeurIPS 2022; 30 pages, 15 figures, 7 tables\n",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07615"
  },
  {
    "id": "arXiv:2204.08152",
    "title": "Back to the Future: Bidirectional Information Decoupling Network for  Multi-turn Dialogue Modeling",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08152"
  },
  {
    "id": "arXiv:2204.09042",
    "title": "Accelerating Inhibitor Discovery With A Deep Generative Foundation  Model: Validation for SARS-CoV-2 Drug Targets",
    "abstract": "Comments: Revised title, abstract, and text; additional figures",
    "descriptor": "\nComments: Revised title, abstract, and text; additional figures\n",
    "authors": [
      "Vijil Chenthamarakshan",
      "Samuel C. Hoffman",
      "C. David Owen",
      "Petra Lukacik",
      "Claire Strain-Damerell",
      "Daren Fearon",
      "Tika R. Malla",
      "Anthony Tumber",
      "Christopher J. Schofield",
      "Helen M.E. Duyvesteyn",
      "Wanwisa Dejnirattisai",
      "Loic Carrique",
      "Thomas S. Walter",
      "Gavin R. Screaton",
      "Tetiana Matviiuk",
      "Aleksandra Mojsilovic",
      "Jason Crain",
      "Martin A. Walsh",
      "David I. Stuart",
      "Payel Das"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.09042"
  },
  {
    "id": "arXiv:2204.09079",
    "title": "Music Source Separation with Generative Flow",
    "abstract": "Comments: Accepted by Signal Processing Letters",
    "descriptor": "\nComments: Accepted by Signal Processing Letters\n",
    "authors": [
      "Ge Zhu",
      "Jordan Darefsky",
      "Fei Jiang",
      "Anton Selitskiy",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.09079"
  },
  {
    "id": "arXiv:2204.09113",
    "title": "Representation of short distances in structurally sparse graphs",
    "abstract": "Comments: 33 pages, no figures; v3: Added an improved approximation subject to VC-dimension constraints and an application for the approximation of distance domination and independence number",
    "descriptor": "\nComments: 33 pages, no figures; v3: Added an improved approximation subject to VC-dimension constraints and an application for the approximation of distance domination and independence number\n",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.09113"
  },
  {
    "id": "arXiv:2204.09656",
    "title": "A Fast Post-Training Pruning Framework for Transformers",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Woosuk Kwon",
      "Sehoon Kim",
      "Michael W. Mahoney",
      "Joseph Hassoun",
      "Kurt Keutzer",
      "Amir Gholami"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09656"
  },
  {
    "id": "arXiv:2204.10321",
    "title": "Future Object Detection with Spatiotemporal Transformers",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Adam Tonderski",
      "Joakim Johnander",
      "Christoffer Petersson",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10321"
  },
  {
    "id": "arXiv:2204.10465",
    "title": "Hardness of Approximation in P via Short Cycle Removal: Cycle Detection,  Distance Oracles, and Beyond",
    "abstract": "Comments: The abstract was slightly shortened to meet arXiv requirements. Appears in STOC 2022",
    "descriptor": "\nComments: The abstract was slightly shortened to meet arXiv requirements. Appears in STOC 2022\n",
    "authors": [
      "Amir Abboud",
      "Karl Bringmann",
      "Seri Khoury",
      "Or Zamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.10465"
  },
  {
    "id": "arXiv:2204.13596",
    "title": "Generative Multi-hop Retrieval",
    "abstract": "Comments: published at EMNLP 2022",
    "descriptor": "\nComments: published at EMNLP 2022\n",
    "authors": [
      "Hyunji Lee",
      "Sohee Yang",
      "Hanseok Oh",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.13596"
  },
  {
    "id": "arXiv:2204.13822",
    "title": "HashNWalk: Hash and Random Walk Based Anomaly Detection in Hyperedge  Streams",
    "abstract": "Comments: Accepted in IJCAI 2022",
    "descriptor": "\nComments: Accepted in IJCAI 2022\n",
    "authors": [
      "Geon Lee",
      "Minyoung Choe",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.13822"
  },
  {
    "id": "arXiv:2205.00504",
    "title": "Domain Adaptation meets Individual Fairness. And they get along",
    "abstract": "Comments: Published at NeurIPS 2022",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Debarghya Mukherjee",
      "Felix Petersen",
      "Mikhail Yurochkin",
      "Yuekai Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00504"
  },
  {
    "id": "arXiv:2205.03963",
    "title": "NOVA: A Practical Method for Creating Notebook-Ready Visual Analytics",
    "abstract": "Comments: Accepted to IEEE VIS 2022 (poster). 2 pages, 1 figure. For a live demo, visit this https URL For method application examples, see this https URL",
    "descriptor": "\nComments: Accepted to IEEE VIS 2022 (poster). 2 pages, 1 figure. For a live demo, visit this https URL For method application examples, see this https URL\n",
    "authors": [
      "Zijie J. Wang",
      "David Munechika",
      "Seongmin Lee",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.03963"
  },
  {
    "id": "arXiv:2205.05435",
    "title": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "abstract": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "descriptor": "",
    "authors": [
      "Rabab Alkhalifa",
      "Elena Kochkina",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05435"
  },
  {
    "id": "arXiv:2205.05775",
    "title": "CSI-fingerprinting Indoor Localization via Attention-Augmented Residual  Convolutional Neural Network",
    "abstract": "Comments: 32 pages, Added references in section 2,3; Added explanations for some academic terms; Corrected typos; Added experiments in section 5, previous results unchanged; is under review for possible publication",
    "descriptor": "\nComments: 32 pages, Added references in section 2,3; Added explanations for some academic terms; Corrected typos; Added experiments in section 5, previous results unchanged; is under review for possible publication\n",
    "authors": [
      "Bowen Zhang",
      "Houssem Sifaou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05775"
  },
  {
    "id": "arXiv:2205.06342",
    "title": "Generalized Variational Inference in Function Spaces: Gaussian Measures  meet Bayesian Deep Learning",
    "abstract": "Generalized Variational Inference in Function Spaces: Gaussian Measures  meet Bayesian Deep Learning",
    "descriptor": "",
    "authors": [
      "Veit D. Wild",
      "Robert Hu",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.06342"
  },
  {
    "id": "arXiv:2205.08121",
    "title": "Design of Joint Source-Channel Codes Based on a Generic Protograph",
    "abstract": "Comments: 20 pages, 15 figures, 5 tables",
    "descriptor": "\nComments: 20 pages, 15 figures, 5 tables\n",
    "authors": [
      "Jia Zhan",
      "Francis C.M. Lau"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.08121"
  },
  {
    "id": "arXiv:2205.08524",
    "title": "Supervised Learning for Coverage-Directed Test Selection in  Simulation-Based Verification",
    "abstract": "Supervised Learning for Coverage-Directed Test Selection in  Simulation-Based Verification",
    "descriptor": "",
    "authors": [
      "Nyasha Masamba",
      "Kerstin Eder",
      "Tim Blackmore"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.08524"
  },
  {
    "id": "arXiv:2205.08540",
    "title": "Bi-Phasic Quasistatic Brain Communication for Fully Untethered Connected  Brain Implants",
    "abstract": "Comments: 24 pages, 10 figures",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Baibhab Chatterjee",
      "Mayukh Nath",
      "Gaurav Kumar K",
      "Shulan Xiao",
      "Krishna Jayant",
      "Shreyas Sen"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.08540"
  },
  {
    "id": "arXiv:2205.09459",
    "title": "Neural Network Architecture Beyond Width and Depth",
    "abstract": "Neural Network Architecture Beyond Width and Depth",
    "descriptor": "",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09459"
  },
  {
    "id": "arXiv:2205.09552",
    "title": "Hybrid Intelligent Testing in Simulation-Based Verification",
    "abstract": "Hybrid Intelligent Testing in Simulation-Based Verification",
    "descriptor": "",
    "authors": [
      "Nyasha Masamba",
      "Kerstin Eder",
      "Tim Blackmore"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09552"
  },
  {
    "id": "arXiv:2205.09873",
    "title": "Differentially Private Linear Sketches: Efficient Implementations and  Applications",
    "abstract": "Differentially Private Linear Sketches: Efficient Implementations and  Applications",
    "descriptor": "",
    "authors": [
      "Fuheng Zhao",
      "Dan Qiao",
      "Rachel Redberg",
      "Divyakant Agrawal",
      "Amr El Abbadi",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09873"
  },
  {
    "id": "arXiv:2205.10041",
    "title": "Posterior Refinement Improves Sample Efficiency in Bayesian Neural  Networks",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Agustinus Kristiadi",
      "Runa Eschenhagen",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.10041"
  },
  {
    "id": "arXiv:2205.10102",
    "title": "Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral  Compressive Imaging",
    "abstract": "Comments: NeurIPS 2022; The first Transformer-based deep unfolding method for spectral compressive imaging",
    "descriptor": "\nComments: NeurIPS 2022; The first Transformer-based deep unfolding method for spectral compressive imaging\n",
    "authors": [
      "Yuanhao Cai",
      "Jing Lin",
      "Haoqian Wang",
      "Xin Yuan",
      "Henghui Ding",
      "Yulun Zhang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10102"
  },
  {
    "id": "arXiv:2205.10155",
    "title": "Large-Signal Stability Guarantees for Cycle-by-Cycle Controlled DC-DC  Converters",
    "abstract": "Comments: typos corrected, references added, title, abstract, and introduction revised, results unchanged",
    "descriptor": "\nComments: typos corrected, references added, title, abstract, and introduction revised, results unchanged\n",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.10155"
  },
  {
    "id": "arXiv:2205.10637",
    "title": "Symmetry Teleportation for Accelerated Optimization",
    "abstract": "Comments: 20 pages, 8 figures, NeurIPS 2022",
    "descriptor": "\nComments: 20 pages, 8 figures, NeurIPS 2022\n",
    "authors": [
      "Bo Zhao",
      "Nima Dehmamy",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10637"
  },
  {
    "id": "arXiv:2205.10686",
    "title": "Post-breach Recovery: Protection against White-box Adversarial Examples  for Leaked DNN Models",
    "abstract": "Post-breach Recovery: Protection against White-box Adversarial Examples  for Leaked DNN Models",
    "descriptor": "",
    "authors": [
      "Shawn Shan",
      "Wenxin Ding",
      "Emily Wenger",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.10686"
  },
  {
    "id": "arXiv:2205.10721",
    "title": "System-Level Evaluation of Beam Hopping in NR-Based LEO Satellite  Communication System",
    "abstract": "Comments: 6 pages, 13 figures",
    "descriptor": "\nComments: 6 pages, 13 figures\n",
    "authors": [
      "Jingwei Zhang",
      "Dali Qin",
      "Chuili Kong",
      "Feiran Zhao",
      "Rong Li",
      "Jun Wang",
      "Ye Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.10721"
  },
  {
    "id": "arXiv:2205.10732",
    "title": "Robust Flow-based Conformal Inference (FCI) with Statistical Guarantee",
    "abstract": "Robust Flow-based Conformal Inference (FCI) with Statistical Guarantee",
    "descriptor": "",
    "authors": [
      "Youhui Ye",
      "Meimei Liu",
      "Xin Xing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10732"
  },
  {
    "id": "arXiv:2205.10733",
    "title": "GraB: Finding Provably Better Data Permutations than Random Reshuffling",
    "abstract": "GraB: Finding Provably Better Data Permutations than Random Reshuffling",
    "descriptor": "",
    "authors": [
      "Yucheng Lu",
      "Wentao Guo",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10733"
  },
  {
    "id": "arXiv:2205.10762",
    "title": "How sensitive are translation systems to extra contexts? Mitigating  gender bias in Neural Machine Translation models through relevant contexts",
    "abstract": "Comments: EMNLP Findings 2022",
    "descriptor": "\nComments: EMNLP Findings 2022\n",
    "authors": [
      "Shanya Sharma",
      "Manan Dey",
      "Koustuv Sinha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10762"
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representations",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Jing Chen",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10852"
  },
  {
    "id": "arXiv:2205.11640",
    "title": "Generalization Gap in Amortized Inference",
    "abstract": "Generalization Gap in Amortized Inference",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Peter Hayes",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11640"
  },
  {
    "id": "arXiv:2205.12035",
    "title": "RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked  Auto-Encoder",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Shitao Xiao",
      "Zheng Liu",
      "Yingxia Shao",
      "Zhao Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12035"
  },
  {
    "id": "arXiv:2205.12268",
    "title": "Wavelet Feature Maps Compression for Image-to-Image CNNs",
    "abstract": "Wavelet Feature Maps Compression for Image-to-Image CNNs",
    "descriptor": "",
    "authors": [
      "Shahaf E. Finder",
      "Yair Zohav",
      "Maor Ashkenazi",
      "Eran Treister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.12268"
  },
  {
    "id": "arXiv:2205.12331",
    "title": "Certified Robustness Against Natural Language Attacks by Causal  Intervention",
    "abstract": "Certified Robustness Against Natural Language Attacks by Causal  Intervention",
    "descriptor": "",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Zhi-Hong Deng",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12331"
  },
  {
    "id": "arXiv:2205.12404",
    "title": "FLUTE: Figurative Language Understanding through Textual Explanations",
    "abstract": "Comments: EMNLP 2022 Main Conference (Long Paper)",
    "descriptor": "\nComments: EMNLP 2022 Main Conference (Long Paper)\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Arkadiy Saakyan",
      "Debanjan Ghosh",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12404"
  },
  {
    "id": "arXiv:2205.13011",
    "title": "Flying Hydraulically Amplified Electrostatic Gripper System for Aerial  Object Manipulation",
    "abstract": "Comments: 16 pages, 12 figures, accepted and presented at the International Symposium on Robotics Research (ISRR) 2022. Video: youtube.com/watch?v=7PmZ8C0Ji08",
    "descriptor": "\nComments: 16 pages, 12 figures, accepted and presented at the International Symposium on Robotics Research (ISRR) 2022. Video: youtube.com/watch?v=7PmZ8C0Ji08\n",
    "authors": [
      "Dario Tscholl",
      "Stephan-Daniel Gravert",
      "Aurel X. Appius",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.13011"
  },
  {
    "id": "arXiv:2205.13213",
    "title": "Fast Vision Transformers with HiLo Attention",
    "abstract": "Comments: NeurIPS 2022 camera ready",
    "descriptor": "\nComments: NeurIPS 2022 camera ready\n",
    "authors": [
      "Zizheng Pan",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13213"
  },
  {
    "id": "arXiv:2205.13328",
    "title": "How Powerful are K-hop Message Passing Graph Neural Networks",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Jiarui Feng",
      "Yixin Chen",
      "Fuhai Li",
      "Anindya Sarkar",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13328"
  },
  {
    "id": "arXiv:2205.13535",
    "title": "AdaptFormer: Adapting Vision Transformers for Scalable Visual  Recognition",
    "abstract": "Comments: Accepted by NeurIPS 2022. Code: this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Code: this https URL\n",
    "authors": [
      "Shoufa Chen",
      "Chongjian Ge",
      "Zhan Tong",
      "Jiangliu Wang",
      "Yibing Song",
      "Jue Wang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13535"
  },
  {
    "id": "arXiv:2205.13627",
    "title": "Experimental Design for Linear Functionals in Reproducing Kernel Hilbert  Spaces",
    "abstract": "Experimental Design for Linear Functionals in Reproducing Kernel Hilbert  Spaces",
    "descriptor": "",
    "authors": [
      "Mojm\u00edr Mutn\u00fd",
      "Andreas Krause"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.13627"
  },
  {
    "id": "arXiv:2205.13634",
    "title": "BagFlip: A Certified Defense against Data Poisoning",
    "abstract": "Comments: Neurips 2022",
    "descriptor": "\nComments: Neurips 2022\n",
    "authors": [
      "Yuhao Zhang",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13634"
  },
  {
    "id": "arXiv:2205.14027",
    "title": "Learning Dynamical Systems via Koopman Operator Regression in  Reproducing Kernel Hilbert Spaces",
    "abstract": "Comments: Main text: 10 pages, 2 figures, 1 table. Supplementary informations: 18 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: Main text: 10 pages, 2 figures, 1 table. Supplementary informations: 18 pages, 5 figures, 2 tables\n",
    "authors": [
      "Vladimir Kostic",
      "Pietro Novelli",
      "Andreas Maurer",
      "Carlo Ciliberto",
      "Lorenzo Rosasco",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.14027"
  },
  {
    "id": "arXiv:2205.14107",
    "title": "Spartan: Differentiable Sparsity via Regularized Transportation",
    "abstract": "Comments: NeurIPS 2022 camera ready",
    "descriptor": "\nComments: NeurIPS 2022 camera ready\n",
    "authors": [
      "Kai Sheng Tai",
      "Taipeng Tian",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14107"
  },
  {
    "id": "arXiv:2205.14229",
    "title": "Learning to Find Proofs and Theorems by Learning to Refine Search  Strategies: The Case of Loop Invariant Synthesis",
    "abstract": "Learning to Find Proofs and Theorems by Learning to Refine Search  Strategies: The Case of Loop Invariant Synthesis",
    "descriptor": "",
    "authors": [
      "Jonathan Laurent",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14229"
  },
  {
    "id": "arXiv:2205.14522",
    "title": "A Character-Level Length-Control Algorithm for Non-Autoregressive  Sentence Summarization",
    "abstract": "Comments: Accepted by NeurIPS22",
    "descriptor": "\nComments: Accepted by NeurIPS22\n",
    "authors": [
      "Puyuan Liu",
      "Xiang Zhang",
      "Lili Mou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14522"
  },
  {
    "id": "arXiv:2205.14552",
    "title": "Staggered Rollout Designs Enable Causal Inference Under Interference  Without Network Knowledge",
    "abstract": "Comments: 28 pages, 6 figures, accepted to Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 28 pages, 6 figures, accepted to Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Mayleen Cortez",
      "Matthew Eichhorn",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.14552"
  },
  {
    "id": "arXiv:2205.15241",
    "title": "Multi-Game Decision Transformers",
    "abstract": "Comments: NeurIPS 2022. 24 pages, 16 figures. Additional information, videos and code can be seen at this https URL",
    "descriptor": "\nComments: NeurIPS 2022. 24 pages, 16 figures. Additional information, videos and code can be seen at this https URL\n",
    "authors": [
      "Kuang-Huei Lee",
      "Ofir Nachum",
      "Mengjiao Yang",
      "Lisa Lee",
      "Daniel Freeman",
      "Winnie Xu",
      "Sergio Guadarrama",
      "Ian Fischer",
      "Eric Jang",
      "Henryk Michalewski",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15241"
  },
  {
    "id": "arXiv:2205.15585",
    "title": "Decomposing NeRF for Editing via Feature Field Distillation",
    "abstract": "Comments: Accepted to NeurIPS 2022 this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 this https URL\n",
    "authors": [
      "Sosuke Kobayashi",
      "Eiichi Matsumoto",
      "Vincent Sitzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.15585"
  },
  {
    "id": "arXiv:2205.15902",
    "title": "Variational inference via Wasserstein gradient flows",
    "abstract": "Comments: 52 pages, 15 figures",
    "descriptor": "\nComments: 52 pages, 15 figures\n",
    "authors": [
      "Marc Lambert",
      "Sinho Chewi",
      "Francis Bach",
      "Silv\u00e8re Bonnabel",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.15902"
  },
  {
    "id": "arXiv:2206.00050",
    "title": "FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear  Modulation",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Mehmet Ozgur Turkoglu",
      "Alexander Becker",
      "H\u00fcseyin Anil G\u00fcnd\u00fcz",
      "Mina Rezaei",
      "Bernd Bischl",
      "Rodrigo Caye Daudt",
      "Stefano D'Aronco",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00050"
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2102.08581",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.08581\n",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00518"
  },
  {
    "id": "arXiv:2206.00888",
    "title": "Squeezeformer: An Efficient Transformer for Automatic Speech Recognition",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Sehoon Kim",
      "Amir Gholami",
      "Albert Shaw",
      "Nicholas Lee",
      "Karttikeya Mangalam",
      "Jitendra Malik",
      "Michael W. Mahoney",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.00888"
  },
  {
    "id": "arXiv:2206.01018",
    "title": "Score-Based Generative Models Detect Manifolds",
    "abstract": "Score-Based Generative Models Detect Manifolds",
    "descriptor": "",
    "authors": [
      "Jakiw Pidstrigach"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.01018"
  },
  {
    "id": "arXiv:2206.01315",
    "title": "Sample-Efficient Reinforcement Learning of Partially Observable Markov  Games",
    "abstract": "Sample-Efficient Reinforcement Learning of Partially Observable Markov  Games",
    "descriptor": "",
    "authors": [
      "Qinghua Liu",
      "Csaba Szepesv\u00e1ri",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01315"
  },
  {
    "id": "arXiv:2206.01535",
    "title": "Rethinking and Scaling Up Graph Contrastive Learning: An Extremely  Efficient Approach with Group Discrimination",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Yizhen Zheng",
      "Shirui Pan",
      "Vincent Cs Lee",
      "Yu Zheng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01535"
  },
  {
    "id": "arXiv:2206.01724",
    "title": "SNAKE: Shape-aware Neural 3D Keypoint Field",
    "abstract": "Comments: Accepted by NeurIPS 2022. Codes are available at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Codes are available at this https URL\n",
    "authors": [
      "Chengliang Zhong",
      "Peixing You",
      "Xiaoxue Chen",
      "Hao Zhao",
      "Fuchun Sun",
      "Guyue Zhou",
      "Xiaodong Mu",
      "Chuang Gan",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01724"
  },
  {
    "id": "arXiv:2206.01794",
    "title": "Additive MIL: Intrinsically Interpretable Multiple Instance Learning for  Pathology",
    "abstract": "Additive MIL: Intrinsically Interpretable Multiple Instance Learning for  Pathology",
    "descriptor": "",
    "authors": [
      "Syed Ashar Javed",
      "Dinkar Juyal",
      "Harshith Padigela",
      "Amaro Taylor-Weiner",
      "Limin Yu",
      "Aaditya Prakash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01794"
  },
  {
    "id": "arXiv:2206.01913",
    "title": "Neural Lyapunov Control of Unknown Nonlinear Systems with Stability  Guarantees",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Ruikun Zhou",
      "Thanin Quartz",
      "Hans De Sterck",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01913"
  },
  {
    "id": "arXiv:2206.02013",
    "title": "Causal Discovery in Heterogeneous Environments Under the Sparse  Mechanism Shift Hypothesis",
    "abstract": "Comments: NeurIPS 2022 camera-ready version. JvK and BS are shared last authors. 10 pages + Bibliography + Appendix (26 pages total)",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready version. JvK and BS are shared last authors. 10 pages + Bibliography + Appendix (26 pages total)\n",
    "authors": [
      "Ronan Perry",
      "Julius von K\u00fcgelgen",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02013"
  },
  {
    "id": "arXiv:2206.02063",
    "title": "Active Bayesian Causal Inference",
    "abstract": "Comments: NeurIPS 2022 camera-ready version. RP & JvK are shared last authors. 10 pages + Bibliography + Appendix (34 pages total)",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready version. RP & JvK are shared last authors. 10 pages + Bibliography + Appendix (34 pages total)\n",
    "authors": [
      "Christian Toth",
      "Lars Lorch",
      "Christian Knoll",
      "Andreas Krause",
      "Franz Pernkopf",
      "Robert Peharz",
      "Julius von K\u00fcgelgen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02063"
  },
  {
    "id": "arXiv:2206.02927",
    "title": "Spectral Bias Outside the Training Set for Deep Networks in the Kernel  Regime",
    "abstract": "Comments: 38 pages, 1 figure, to be published in NeurIPS 2022",
    "descriptor": "\nComments: 38 pages, 1 figure, to be published in NeurIPS 2022\n",
    "authors": [
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02927"
  },
  {
    "id": "arXiv:2206.04477",
    "title": "Receding Horizon Inverse Reinforcement Learning",
    "abstract": "Comments: The paper is accepted by Conference on Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: The paper is accepted by Conference on Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Yiqing Xu",
      "Wei Gao",
      "David Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04477"
  },
  {
    "id": "arXiv:2206.04756",
    "title": "An Empirical Study on Disentanglement of Negative-free Contrastive  Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022; 10 pages main text + 15 pages appendix",
    "descriptor": "\nComments: Accepted to NeurIPS 2022; 10 pages main text + 15 pages appendix\n",
    "authors": [
      "Jinkun Cao",
      "Ruiqian Nai",
      "Qing Yang",
      "Jialei Huang",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04756"
  },
  {
    "id": "arXiv:2206.05644",
    "title": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "abstract": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "descriptor": "",
    "authors": [
      "Ildebrando Magnani"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05644"
  },
  {
    "id": "arXiv:2206.06583",
    "title": "Exploring evolution-aware & -free protein language models as protein  function predictors",
    "abstract": "Exploring evolution-aware & -free protein language models as protein  function predictors",
    "descriptor": "",
    "authors": [
      "Mingyang Hu",
      "Fajie Yuan",
      "Kevin K. Yang",
      "Fusong Ju",
      "Jin Su",
      "Hui Wang",
      "Fei Yang",
      "Qiuyang Ding"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06583"
  },
  {
    "id": "arXiv:2206.07260",
    "title": "On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot  Adaptation",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Markus Hiller",
      "Mehrtash Harandi",
      "Tom Drummond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07260"
  },
  {
    "id": "arXiv:2206.07267",
    "title": "Rethinking Generalization in Few-Shot Classification",
    "abstract": "Comments: Accepted at NeurIPS 2022. Code available at this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Code available at this https URL\n",
    "authors": [
      "Markus Hiller",
      "Rongkai Ma",
      "Mehrtash Harandi",
      "Tom Drummond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07267"
  },
  {
    "id": "arXiv:2206.07275",
    "title": "CARD: Classification and Regression Diffusion Models",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Xizewen Han",
      "Huangjie Zheng",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.07275"
  },
  {
    "id": "arXiv:2206.07376",
    "title": "Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement  Learning",
    "abstract": "Comments: Accecpted by Journal of Artificial Intelligence Research",
    "descriptor": "\nComments: Accecpted by Journal of Artificial Intelligence Research\n",
    "authors": [
      "Xiaoteng Ma",
      "Shuai Ma",
      "Li Xia",
      "Qianchuan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07376"
  },
  {
    "id": "arXiv:2206.07659",
    "title": "Model-based RL with Optimistic Posterior Sampling: Structural Conditions  and Sample Complexity",
    "abstract": "Comments: NeurIPS 2022 camera ready version",
    "descriptor": "\nComments: NeurIPS 2022 camera ready version\n",
    "authors": [
      "Alekh Agarwal",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07659"
  },
  {
    "id": "arXiv:2206.07669",
    "title": "A Unified Sequence Interface for Vision Tasks",
    "abstract": "Comments: The first three authors contributed equally",
    "descriptor": "\nComments: The first three authors contributed equally\n",
    "authors": [
      "Ting Chen",
      "Saurabh Saxena",
      "Lala Li",
      "Tsung-Yi Lin",
      "David J. Fleet",
      "Geoffrey Hinton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07669"
  },
  {
    "id": "arXiv:2206.07751",
    "title": "On the Identifiability of Nonlinear ICA: Sparsity and Beyond",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yujia Zheng",
      "Ignavier Ng",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07751"
  },
  {
    "id": "arXiv:2206.07902",
    "title": "On Privacy and Personalization in Cross-Silo Federated Learning",
    "abstract": "Comments: NeurIPS 2022, 37 pages",
    "descriptor": "\nComments: NeurIPS 2022, 37 pages\n",
    "authors": [
      "Ziyu Liu",
      "Shengyuan Hu",
      "Zhiwei Steven Wu",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07902"
  },
  {
    "id": "arXiv:2206.08127",
    "title": "Random Access Concatenated Libraries and dd enable a short-latency  high-content website on an inexpensive shared server",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Don Krieger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.08127"
  },
  {
    "id": "arXiv:2206.08129",
    "title": "Trajectory-guided Control Prediction for End-to-end Autonomous Driving:  A Simple yet Strong Baseline",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Penghao Wu",
      "Xiaosong Jia",
      "Li Chen",
      "Junchi Yan",
      "Hongyang Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08129"
  },
  {
    "id": "arXiv:2206.08457",
    "title": "Wireless Picosecond Time Synchronization for Distributed Antenna Arrays",
    "abstract": "Wireless Picosecond Time Synchronization for Distributed Antenna Arrays",
    "descriptor": "",
    "authors": [
      "Jason M. Merlo",
      "Serge R. Mghabghab",
      "Jeffrey A. Nanzer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.08457"
  },
  {
    "id": "arXiv:2206.08496",
    "title": "Self-Supervised Contrastive Pre-Training For Time Series via  Time-Frequency Consistency",
    "abstract": "Comments: Accepted by NeruIPS 2022; 32pages (14 pages main paper + 18 pages supplementary materials). Code: this https URL",
    "descriptor": "\nComments: Accepted by NeruIPS 2022; 32pages (14 pages main paper + 18 pages supplementary materials). Code: this https URL\n",
    "authors": [
      "Xiang Zhang",
      "Ziyuan Zhao",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08496"
  },
  {
    "id": "arXiv:2206.08526",
    "title": "k-Sliced Mutual Information: A Quantitative Study of Scalability with  Dimension",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ziv Goldfeld",
      "Kristjan Greenewald",
      "Theshani Nuradha",
      "Galen Reeves"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08526"
  },
  {
    "id": "arXiv:2206.08742",
    "title": "Near-Optimal No-Regret Learning Dynamics for General Convex Games",
    "abstract": "Comments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback",
    "descriptor": "\nComments: To appear at NeurIPS 2022. V2 incorporates reviewers' feedback\n",
    "authors": [
      "Gabriele Farina",
      "Ioannis Anagnostides",
      "Haipeng Luo",
      "Chung-Wei Lee",
      "Christian Kroer",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08742"
  },
  {
    "id": "arXiv:2206.09319",
    "title": "TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification",
    "abstract": "TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification",
    "descriptor": "",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Daran Xu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09319"
  },
  {
    "id": "arXiv:2206.10071",
    "title": "BOND: Benchmarking Unsupervised Outlier Node Detection on Static  Attributed Graphs",
    "abstract": "Comments: NeurIPS 2022. Benchmark available at this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Benchmark available at this https URL\n",
    "authors": [
      "Kay Liu",
      "Yingtong Dou",
      "Yue Zhao",
      "Xueying Ding",
      "Xiyang Hu",
      "Ruitong Zhang",
      "Kaize Ding",
      "Canyu Chen",
      "Hao Peng",
      "Kai Shu",
      "Lichao Sun",
      "Jundong Li",
      "George H. Chen",
      "Zhihao Jia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10071"
  },
  {
    "id": "arXiv:2206.10910",
    "title": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "abstract": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "descriptor": "",
    "authors": [
      "Xiao Feng Zhang",
      "Chao Chen Gu",
      "Shan Ying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10910"
  },
  {
    "id": "arXiv:2206.11168",
    "title": "Ordered Subgraph Aggregation Networks",
    "abstract": "Comments: Accepted at NeurIPS 2022. Fixed link to code repository",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Fixed link to code repository\n",
    "authors": [
      "Chendi Qian",
      "Gaurav Rattan",
      "Floris Geerts",
      "Christopher Morris",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11168"
  },
  {
    "id": "arXiv:2206.11707",
    "title": "Cooperative Hybrid Networks with Active Relays and RISs for B5G:  Applications, Challenges, and Research Directions",
    "abstract": "Comments: 10 pages, 6 figures. This work has been submitted to the IEEE for a possible publication",
    "descriptor": "\nComments: 10 pages, 6 figures. This work has been submitted to the IEEE for a possible publication\n",
    "authors": [
      "Zaid Abdullah",
      "Steven Kisseleff",
      "Wallace Alves Martins",
      "Gaojie Chen",
      "Luca Sanguinetti",
      "Konstantinos Ntontin",
      "Anastasios Papazafeiropoulos",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.11707"
  },
  {
    "id": "arXiv:2206.12162",
    "title": "Ultrafast carbon nanotube photodetectors with bandwidth over 60 GHz",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Weifeng Wu",
      "Fan Yang",
      "Xiansong Fang",
      "Xiang Cai",
      "Xiaohui Liu",
      "Fan Zhang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12162"
  },
  {
    "id": "arXiv:2206.12558",
    "title": "FastBVP-Net: a lightweight pulse simulation network for measuring heart  rhythm via facial videos",
    "abstract": "Comments: 8 pages, 2figures",
    "descriptor": "\nComments: 8 pages, 2figures\n",
    "authors": [
      "Jialiang Zhuang",
      "Yuheng Chen",
      "Yun Zhang",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12558"
  },
  {
    "id": "arXiv:2206.12680",
    "title": "Topology-aware Generalization of Decentralized SGD",
    "abstract": "Comments: Accepted for publication in the 39th International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: Accepted for publication in the 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Tongtian Zhu",
      "Fengxiang He",
      "Lan Zhang",
      "Zhengyang Niu",
      "Mingli Song",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12680"
  },
  {
    "id": "arXiv:2206.13448",
    "title": "Distinguishing Learning Rules with Brain Machine Interfaces",
    "abstract": "Comments: 24 pages, 14 figures. Final version, published at NeurIPS 2022",
    "descriptor": "\nComments: 24 pages, 14 figures. Final version, published at NeurIPS 2022\n",
    "authors": [
      "Jacob P. Portes",
      "Christian Schmid",
      "James M. Murray"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13448"
  },
  {
    "id": "arXiv:2206.13464",
    "title": "When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online  Reinforcement Learning",
    "abstract": "When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Haoyi Niu",
      "Shubham Sharma",
      "Yiwen Qiu",
      "Ming Li",
      "Guyue Zhou",
      "Jianming Hu",
      "Xianyuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13464"
  },
  {
    "id": "arXiv:2206.13597",
    "title": "NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors",
    "abstract": "NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors",
    "descriptor": "",
    "authors": [
      "Jiepeng Wang",
      "Peng Wang",
      "Xiaoxiao Long",
      "Christian Theobalt",
      "Taku Komura",
      "Lingjie Liu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13597"
  },
  {
    "id": "arXiv:2206.13937",
    "title": "A Deep Learning Approach to Nonconvex Energy Minimization for  Martensitic Phase Transitions",
    "abstract": "A Deep Learning Approach to Nonconvex Energy Minimization for  Martensitic Phase Transitions",
    "descriptor": "",
    "authors": [
      "Xiaoli Chen",
      "Phoebus Rosakis",
      "Zhizhang Wu",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.13937"
  },
  {
    "id": "arXiv:2206.14254",
    "title": "No imputation without representation",
    "abstract": "No imputation without representation",
    "descriptor": "",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14254"
  },
  {
    "id": "arXiv:2206.14820",
    "title": "Strong Lensing Source Reconstruction Using Continuous Neural Fields",
    "abstract": "Comments: 9+2 pages, 3+2 figures, Spotlight at the Machine Learning for Astrophysics Workshop at ICML 2022; v2, references added",
    "descriptor": "\nComments: 9+2 pages, 3+2 figures, Spotlight at the Machine Learning for Astrophysics Workshop at ICML 2022; v2, references added\n",
    "authors": [
      "Siddharth Mishra-Sharma",
      "Ge Yang"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14820"
  },
  {
    "id": "arXiv:2206.15476",
    "title": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "abstract": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Marius Dragoi",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15476"
  },
  {
    "id": "arXiv:2207.00411",
    "title": "Adversarial Robustness is at Odds with Lazy Training",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yunjuan Wang",
      "Enayat Ullah",
      "Poorya Mianjy",
      "Raman Arora"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.00411"
  },
  {
    "id": "arXiv:2207.01555",
    "title": "Multi-class Classification from Multiple Unlabeled Datasets with Partial  Risk Regularization",
    "abstract": "Comments: ACML 2022 camera-ready version",
    "descriptor": "\nComments: ACML 2022 camera-ready version\n",
    "authors": [
      "Yuting Tang",
      "Nan Lu",
      "Tianyi Zhang",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01555"
  },
  {
    "id": "arXiv:2207.02121",
    "title": "Adapting to Online Label Shift with Provable Guarantees",
    "abstract": "Comments: To appear at NeurIPS 2022; the first two authors contributed equally",
    "descriptor": "\nComments: To appear at NeurIPS 2022; the first two authors contributed equally\n",
    "authors": [
      "Yong Bai",
      "Yu-Jie Zhang",
      "Peng Zhao",
      "Masashi Sugiyama",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.02121"
  },
  {
    "id": "arXiv:2207.02182",
    "title": "ST-CoNAL: Consistency-Based Acquisition Criterion Using Temporal  Self-Ensemble for Active Learning",
    "abstract": "ST-CoNAL: Consistency-Based Acquisition Criterion Using Temporal  Self-Ensemble for Active Learning",
    "descriptor": "",
    "authors": [
      "Jae Soon Baik",
      "In Young Yoon",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02182"
  },
  {
    "id": "arXiv:2207.02628",
    "title": "The alignment property of SGD noise and how it helps select flat minima:  A stability analysis",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Lei Wu",
      "Mingze Wang",
      "Weijie Su"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02628"
  },
  {
    "id": "arXiv:2207.02808",
    "title": "Improved conformalized quantile regression",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Martim Sousa",
      "Ana Maria Tom\u00e9",
      "Jos\u00e9 Moreira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02808"
  },
  {
    "id": "arXiv:2207.02829",
    "title": "Online Bilevel Optimization: Regret Analysis of Online Alternating  Gradient Methods",
    "abstract": "Comments: v3: lower bound is provided",
    "descriptor": "\nComments: v3: lower bound is provided\n",
    "authors": [
      "Davoud Ataee Tarzanagh",
      "Laura Balzano"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02829"
  },
  {
    "id": "arXiv:2207.02910",
    "title": "Ant Hill Colonization optimization algorithm(AHCOA) for controlling the  side lobe of a uniform linear array",
    "abstract": "Comments: major modification in paper required, withdraw immediately",
    "descriptor": "\nComments: major modification in paper required, withdraw immediately\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.02910"
  },
  {
    "id": "arXiv:2207.03433",
    "title": "Semi-supervised Object Detection via Virtual Category Learning",
    "abstract": "Comments: ECCV2022 Oral",
    "descriptor": "\nComments: ECCV2022 Oral\n",
    "authors": [
      "Changrui Chen",
      "Kurt Debattista",
      "Jungong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.03433"
  },
  {
    "id": "arXiv:2207.04046",
    "title": "Optimal Pattern synthesis of linear antenna array using Ant Hill  Colonization Optimization algorithm(AHCOA)",
    "abstract": "Comments: major modification required, I want to add few major data and stuff",
    "descriptor": "\nComments: major modification required, I want to add few major data and stuff\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04046"
  },
  {
    "id": "arXiv:2207.04221",
    "title": "Learning to Register Unbalanced Point Pairs",
    "abstract": "Learning to Register Unbalanced Point Pairs",
    "descriptor": "",
    "authors": [
      "Kanghee Lee",
      "Junha Lee",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04221"
  },
  {
    "id": "arXiv:2207.04867",
    "title": "The Lepto-Variance of Stock Returns",
    "abstract": "The Lepto-Variance of Stock Returns",
    "descriptor": "",
    "authors": [
      "Vassilis Polimenis"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2207.04867"
  },
  {
    "id": "arXiv:2207.05579",
    "title": "Are We Building on the Rock? On the Importance of Data Preprocessing for  Code Summarization",
    "abstract": "Are We Building on the Rock? On the Importance of Data Preprocessing for  Code Summarization",
    "descriptor": "",
    "authors": [
      "Lin Shi",
      "Fangwen Mu",
      "Xiao Chen",
      "Song Wang",
      "Junjie Wang",
      "Ye Yang",
      "Ge Li",
      "Xin Xia",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.05579"
  },
  {
    "id": "arXiv:2207.06025",
    "title": "URANUS: Radio Frequency Tracking, Classification and Identification of  Unmanned Aircraft Vehicles",
    "abstract": "URANUS: Radio Frequency Tracking, Classification and Identification of  Unmanned Aircraft Vehicles",
    "descriptor": "",
    "authors": [
      "Domenico Lof\u00f9",
      "Pietro Tedeschi",
      "Tommaso Di Noia",
      "Eugenio Di Sciascio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06025"
  },
  {
    "id": "arXiv:2207.06635",
    "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic  Differential Equations",
    "abstract": "Comments: NIPS 2022",
    "descriptor": "\nComments: NIPS 2022\n",
    "authors": [
      "Min Zhao",
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06635"
  },
  {
    "id": "arXiv:2207.06652",
    "title": "Everyone's Preference Changes Differently: Weighted Multi-Interest  Retrieval Model",
    "abstract": "Everyone's Preference Changes Differently: Weighted Multi-Interest  Retrieval Model",
    "descriptor": "",
    "authors": [
      "Hui Shi",
      "Yupeng Gu",
      "Yitong Zhou",
      "Bo Zhao",
      "Sicun Gao",
      "Jishen Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06652"
  },
  {
    "id": "arXiv:2207.07450",
    "title": "Z-polyregular functions",
    "abstract": "Comments: 23 pages, 2 figures",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "Thomas Colcombet",
      "Ga\u00ebtan Dou\u00e9neau-Tabot",
      "Aliaume Lopez"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.07450"
  },
  {
    "id": "arXiv:2207.07614",
    "title": "Fixed Points and Noetherian Topologies",
    "abstract": "Comments: 18 pages, 2 figures",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Aliaume Lopez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.07614"
  },
  {
    "id": "arXiv:2207.08192",
    "title": "BusyBot: Learning to Interact, Reason, and Plan in a BusyBoard  Environment",
    "abstract": "Comments: CoRL 2022 camera-ready; Website: this https URL",
    "descriptor": "\nComments: CoRL 2022 camera-ready; Website: this https URL\n",
    "authors": [
      "Zeyi Liu",
      "Zhenjia Xu",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08192"
  },
  {
    "id": "arXiv:2207.08799",
    "title": "Hidden Progress in Deep Learning: SGD Learns Parities Near the  Computational Limit",
    "abstract": "Comments: v2: camera-ready revisions for NeurIPS 2022",
    "descriptor": "\nComments: v2: camera-ready revisions for NeurIPS 2022\n",
    "authors": [
      "Boaz Barak",
      "Benjamin L. Edelman",
      "Surbhi Goel",
      "Sham Kakade",
      "Eran Malach",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.08799"
  },
  {
    "id": "arXiv:2207.08945",
    "title": "Gauge-equivariant flow models for sampling in lattice field theories  with pseudofermions",
    "abstract": "Comments: 15 pages, 7 figures. v3: accepted version for publication. New appendix C",
    "descriptor": "\nComments: 15 pages, 7 figures. v3: accepted version for publication. New appendix C\n",
    "authors": [
      "Ryan Abbott",
      "Michael S. Albergo",
      "Denis Boyda",
      "Kyle Cranmer",
      "Daniel C. Hackett",
      "Gurtej Kanwar",
      "S\u00e9bastien Racani\u00e8re",
      "Danilo J. Rezende",
      "Fernando Romero-L\u00f3pez",
      "Phiala E. Shanahan",
      "Betsy Tian",
      "Julian M. Urban"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08945"
  },
  {
    "id": "arXiv:2207.09081",
    "title": "Generalizing Goal-Conditioned Reinforcement Learning with Variational  Causal Reasoning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2207.09081"
  },
  {
    "id": "arXiv:2207.09531",
    "title": "LR-Net: A Block-based Convolutional Neural Network for Low-Resolution  Image Classification",
    "abstract": "Comments: Submitted to Iranian Journal of Science and Technology, Transactions of Electrical Engineering. Containing 7 pages, 5 figures and 2 tables",
    "descriptor": "\nComments: Submitted to Iranian Journal of Science and Technology, Transactions of Electrical Engineering. Containing 7 pages, 5 figures and 2 tables\n",
    "authors": [
      "Ashkan Ganj",
      "Mohsen Ebadpour",
      "Mahdi Darvish",
      "Hamid Bahador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09531"
  },
  {
    "id": "arXiv:2207.09639",
    "title": "DC-BENCH: Dataset Condensation Benchmark",
    "abstract": "DC-BENCH: Dataset Condensation Benchmark",
    "descriptor": "",
    "authors": [
      "Justin Cui",
      "Ruochen Wang",
      "Si Si",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09639"
  },
  {
    "id": "arXiv:2207.09745",
    "title": "Benchmarking tools for a priori identifiability analysis",
    "abstract": "Comments: 15 pages, 1 figure, corrected RORC-DF results and description",
    "descriptor": "\nComments: 15 pages, 1 figure, corrected RORC-DF results and description\n",
    "authors": [
      "Xabier Rey Barreiro",
      "Alejandro F. Villaverde"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.09745"
  },
  {
    "id": "arXiv:2207.09747",
    "title": "Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription",
    "abstract": "Comments: Camera ready version of ISMIR 2022 submission",
    "descriptor": "\nComments: Camera ready version of ISMIR 2022 submission\n",
    "authors": [
      "Longshen Ou",
      "Xiangming Gu",
      "Ye Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09747"
  },
  {
    "id": "arXiv:2207.10265",
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "abstract": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "descriptor": "",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10265"
  },
  {
    "id": "arXiv:2207.10774",
    "title": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
    "abstract": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
    "descriptor": "",
    "authors": [
      "Bastian Wittmann",
      "Fernando Navarro",
      "Suprosanna Shit",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10774"
  },
  {
    "id": "arXiv:2207.10894",
    "title": "What are Your Pronouns? Examining Gender Pronoun Usage on Twitter",
    "abstract": "Comments: 13 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 13 pages, 10 figures, 2 tables\n",
    "authors": [
      "Julie Jiang",
      "Emily Chen",
      "Luca Luceri",
      "Goran Muri\u0107",
      "Francesco Pierri",
      "Ho-Chun Herbert Chang",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10894"
  },
  {
    "id": "arXiv:2207.12126",
    "title": "PirouNet: Creating Dance through Artist-Centric Deep Learning",
    "abstract": "Comments: 18 pages, 6 figures",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Mathilde Papillon",
      "Mariel Pettee",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.12126"
  },
  {
    "id": "arXiv:2207.12369",
    "title": "Toward reliable signals decoding for electroencephalogram: A benchmark  study to EEGNeX",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Xia Chen",
      "Xiangbin Teng",
      "Han Chen",
      "Yafeng Pan",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.12369"
  },
  {
    "id": "arXiv:2207.12849",
    "title": "Bessel Equivariant Networks for Inversion of Transmission Effects in  Multi-Mode Optical Fibres",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Joshua Mitton",
      "Simon Peter Mekhail",
      "Miles Padgett",
      "Daniele Faccio",
      "Marco Aversa",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.12849"
  },
  {
    "id": "arXiv:2207.13048",
    "title": "Domain Adaptation under Open Set Label Shift",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Saurabh Garg",
      "Sivaraman Balakrishnan",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.13048"
  },
  {
    "id": "arXiv:2207.14219",
    "title": "A general framework for multi-step ahead adaptive conformal  heteroscedastic time series forecasting",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Martim Sousa",
      "Ana Maria Tom\u00e9",
      "Jos\u00e9 Moreira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14219"
  },
  {
    "id": "arXiv:2208.02164",
    "title": "On the Identity Problem and the Group Problem in nilpotent groups",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Ruiwen Dong"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Group Theory (math.GR)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2208.02164"
  },
  {
    "id": "arXiv:2208.02201",
    "title": "Statistical Decoding 2.0: Reducing Decoding to LPN",
    "abstract": "Statistical Decoding 2.0: Reducing Decoding to LPN",
    "descriptor": "",
    "authors": [
      "Kevin Carrier",
      "Thomas Debris-Alazard",
      "Charles Meyer-Hilfiger",
      "Jean-Pierre Tillich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.02201"
  },
  {
    "id": "arXiv:2208.02724",
    "title": "Disentangled Representation Learning for RF Fingerprint Extraction under  Unknown Channel Statistics",
    "abstract": "Disentangled Representation Learning for RF Fingerprint Extraction under  Unknown Channel Statistics",
    "descriptor": "",
    "authors": [
      "Renjie Xie",
      "Wei Xu",
      "Jiabao Yu",
      "Aiqun Hu",
      "Derrick Wing Kwan Ng",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02724"
  },
  {
    "id": "arXiv:2208.02772",
    "title": "Decentralized Risk-Aware Tracking of Multiple Targets",
    "abstract": "Comments: Accepted by DARS2022",
    "descriptor": "\nComments: Accepted by DARS2022\n",
    "authors": [
      "Jiazhen Liu",
      "Lifeng Zhou",
      "Ragesh Ramachandran",
      "Gaurav S. Sukhatme",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.02772"
  },
  {
    "id": "arXiv:2208.05810",
    "title": "Towards Sequence-Level Training for Visual Tracking",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Minji Kim",
      "Seungkwan Lee",
      "Jungseul Ok",
      "Bohyung Han",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.05810"
  },
  {
    "id": "arXiv:2208.05895",
    "title": "Shielding Federated Learning Systems against Inference Attacks with ARM  TrustZone",
    "abstract": "Comments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197",
    "descriptor": "\nComments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197\n",
    "authors": [
      "Aghiles Ait Messaoud",
      "Sonia Ben Mokhtar",
      "Vlad Nitu",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.05895"
  },
  {
    "id": "arXiv:2208.06213",
    "title": "What is it like to program with artificial intelligence?",
    "abstract": "Comments: Proceedings of the 33rd Annual Conference of the Psychology of Programming Interest Group (PPIG 2022)",
    "descriptor": "\nComments: Proceedings of the 33rd Annual Conference of the Psychology of Programming Interest Group (PPIG 2022)\n",
    "authors": [
      "Advait Sarkar",
      "Andrew D. Gordon",
      "Carina Negreanu",
      "Christian Poelitz",
      "Sruti Srinivasa Ragavan",
      "Ben Zorn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.06213"
  },
  {
    "id": "arXiv:2208.06368",
    "title": "Markov Observation Models",
    "abstract": "Markov Observation Models",
    "descriptor": "",
    "authors": [
      "Michael A. Kouritzin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2208.06368"
  },
  {
    "id": "arXiv:2208.07734",
    "title": "Self-supervision is not magic: Understanding Data Augmentation in Image  Anomaly Detection",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Jaemin Yoo",
      "Tiancheng Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07734"
  },
  {
    "id": "arXiv:2208.07905",
    "title": "Reshi: Recommending Resources for Scientific Workflow Tasks on  Heterogeneous Infrastructures",
    "abstract": "Comments: Paper accepted in 41st IEEE International Performance Computing and Communications Conference (IPCCC 2022)",
    "descriptor": "\nComments: Paper accepted in 41st IEEE International Performance Computing and Communications Conference (IPCCC 2022)\n",
    "authors": [
      "Jonathan Bader",
      "Fabian Lehmann",
      "Alexander Groth",
      "Lauritz Thamsen",
      "Dominik Scheinert",
      "Jonathan Will",
      "Ulf Leser",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.07905"
  },
  {
    "id": "arXiv:2208.08369",
    "title": "Radial basis approximation of tensor fields on manifolds: From operator  estimation to manifold learning",
    "abstract": "Comments: 14 figures",
    "descriptor": "\nComments: 14 figures\n",
    "authors": [
      "John Harlim",
      "Shixiao Willing Jiang",
      "John Wilson Peoples"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.08369"
  },
  {
    "id": "arXiv:2208.08738",
    "title": "RFLA: Gaussian Receptive Field based Label Assignment for Tiny Object  Detection",
    "abstract": "Comments: ECCV2022",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Chang Xu",
      "Jinwang Wang",
      "Wen Yang",
      "Huai Yu",
      "Lei Yu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08738"
  },
  {
    "id": "arXiv:2208.09047",
    "title": "Machine learning algorithms for three-dimensional mean-curvature  computation in the level-set method",
    "abstract": "Machine learning algorithms for three-dimensional mean-curvature  computation in the level-set method",
    "descriptor": "",
    "authors": [
      "Luis \u00c1ngel Larios-C\u00e1rdenas",
      "Fr\u00e9d\u00e9ric Gibou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09047"
  },
  {
    "id": "arXiv:2208.09852",
    "title": "Efficient Multiparty Protocols Using Generalized Parseval's Identity and  the Theta Algebra",
    "abstract": "Comments: 17 pages and 10 Figures",
    "descriptor": "\nComments: 17 pages and 10 Figures\n",
    "authors": [
      "Giorgio Sonnino",
      "Alberto Sonnino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09852"
  },
  {
    "id": "arXiv:2208.10004",
    "title": "A diverse large-scale building dataset and a novel plug-and-play domain  generalization method for building extraction",
    "abstract": "A diverse large-scale building dataset and a novel plug-and-play domain  generalization method for building extraction",
    "descriptor": "",
    "authors": [
      "Muying Luo",
      "Shunping Ji",
      "Shiqing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10004"
  },
  {
    "id": "arXiv:2208.10224",
    "title": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "abstract": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Yu Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10224"
  },
  {
    "id": "arXiv:2208.11064",
    "title": "Multi-Modal Representation Learning with Self-Adaptive Threshold for  Commodity Verification",
    "abstract": "Multi-Modal Representation Learning with Self-Adaptive Threshold for  Commodity Verification",
    "descriptor": "",
    "authors": [
      "Chenchen Han",
      "Heng Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.11064"
  },
  {
    "id": "arXiv:2208.11451",
    "title": "Q-Net: Query-Informed Few-Shot Medical Image Segmentation",
    "abstract": "Q-Net: Query-Informed Few-Shot Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Qianqian Shen",
      "Yanan Li",
      "Jiyong Jin",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11451"
  },
  {
    "id": "arXiv:2208.12926",
    "title": "Overparameterization from Computational Constraints",
    "abstract": "Overparameterization from Computational Constraints",
    "descriptor": "",
    "authors": [
      "Sanjam Garg",
      "Somesh Jha",
      "Saeed Mahloujifar",
      "Mohammad Mahmoody",
      "Mingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.12926"
  },
  {
    "id": "arXiv:2208.13141",
    "title": "Federated Learning of Large Models at the Edge via Principal Sub-Model  Training",
    "abstract": "Federated Learning of Large Models at the Edge via Principal Sub-Model  Training",
    "descriptor": "",
    "authors": [
      "Yue Niu",
      "Saurav Prakash",
      "Souvik Kundu",
      "Sunwoo Lee",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.13141"
  },
  {
    "id": "arXiv:2208.13780",
    "title": "Autoinverse: Uncertainty Aware Inversion of Neural Networks",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Navid Ansari",
      "Hans-Peter Seidel",
      "Nima Vahidi Ferdowsi",
      "Vahid Babaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.13780"
  },
  {
    "id": "arXiv:2208.14963",
    "title": "Reconstruction of a Single String from a Part of its Composition  Multiset",
    "abstract": "Comments: 25 pages; errors corrected",
    "descriptor": "\nComments: 25 pages; errors corrected\n",
    "authors": [
      "Zuo Ye",
      "Ohad Elishco"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.14963"
  },
  {
    "id": "arXiv:2209.01170",
    "title": "First Hitting Diffusion Models for Generating Manifold, Graph and  Categorical Data",
    "abstract": "First Hitting Diffusion Models for Generating Manifold, Graph and  Categorical Data",
    "descriptor": "",
    "authors": [
      "Mao Ye",
      "Lemeng Wu",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.01170"
  },
  {
    "id": "arXiv:2209.01498",
    "title": "StreamNet: A WAE for White Matter Streamline Analysis",
    "abstract": "StreamNet: A WAE for White Matter Streamline Analysis",
    "descriptor": "",
    "authors": [
      "Andrew Lizarraga",
      "Katherine L. Narr",
      "Kirsten A. Donald",
      "Shantanu H. Joshi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.01498"
  },
  {
    "id": "arXiv:2209.02332",
    "title": "Ecosystem for Demand-side Flexibility Revisited: The Danish Solution",
    "abstract": "Ecosystem for Demand-side Flexibility Revisited: The Danish Solution",
    "descriptor": "",
    "authors": [
      "Peter Alexander Vistar Gade",
      "Trygve Skj\u00f8tskift",
      "Henrik W. Bindner",
      "Jalal Kazempour"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.02332"
  },
  {
    "id": "arXiv:2209.02528",
    "title": "Rethinking Symmetric Matrix Factorization: A More General and Better  Clustering Perspective",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Mengyuan Zhang",
      "Kai Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.02528"
  },
  {
    "id": "arXiv:2209.03136",
    "title": "Wavelength-aware 2D Convolutions for Hyperspectral Imaging",
    "abstract": "Comments: Accepted WACV23",
    "descriptor": "\nComments: Accepted WACV23\n",
    "authors": [
      "Leon Amadeus Varga",
      "Martin Messmer",
      "Nuri Benbarka",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03136"
  },
  {
    "id": "arXiv:2209.03138",
    "title": "Treating Motion as Option to Reduce Motion Dependency in Unsupervised  Video Object Segmentation",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Chaewon Park",
      "Donghyeong Kim",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03138"
  },
  {
    "id": "arXiv:2209.03592",
    "title": "Multi-Granularity Prediction for Scene Text Recognition",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Peng Wang",
      "Cheng Da",
      "Cong Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03592"
  },
  {
    "id": "arXiv:2209.03753",
    "title": "Improved Robust Algorithms for Learning with Discriminative Feature  Feedback",
    "abstract": "Comments: Fixed typos",
    "descriptor": "\nComments: Fixed typos\n",
    "authors": [
      "Sivan Sabato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.03753"
  },
  {
    "id": "arXiv:2209.03895",
    "title": "IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation  Identification Through a Prompt-based Few-shot Approach",
    "abstract": "Comments: To be published in CASE@EMNLP 2022 (5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text)",
    "descriptor": "\nComments: To be published in CASE@EMNLP 2022 (5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text)\n",
    "authors": [
      "Sergio Burdisso",
      "Juan Zuluaga-Gomez",
      "Esau Villatoro-Tello",
      "Martin Fajcik",
      "Muskaan Singh",
      "Pavel Smrz",
      "Petr Motlicek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03895"
  },
  {
    "id": "arXiv:2209.05045",
    "title": "Gradient-Free Methods for Deterministic and Stochastic Nonsmooth  Nonconvex Optimization",
    "abstract": "Comments: Accepted by NeurIPS 2022; 32 pages, 18 figures; Fix a confusing part in the proof of Theorem 3.1: we use Bertsekas [1973, Proposition 2.3] rather than Bertsekas [1973, Proposition 2.4] here and do not assume the convexity of the function f",
    "descriptor": "\nComments: Accepted by NeurIPS 2022; 32 pages, 18 figures; Fix a confusing part in the proof of Theorem 3.1: we use Bertsekas [1973, Proposition 2.3] rather than Bertsekas [1973, Proposition 2.4] here and do not assume the convexity of the function f\n",
    "authors": [
      "Tianyi Lin",
      "Zeyu Zheng",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.05045"
  },
  {
    "id": "arXiv:2209.05434",
    "title": "3DFaceShop: Explicitly Controllable 3D-Aware Portrait Generation",
    "abstract": "Comments: Project webpage: this https URL",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Junshu Tang",
      "Bo Zhang",
      "Binxin Yang",
      "Ting Zhang",
      "Dong Chen",
      "Lizhuang Ma",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.05434"
  },
  {
    "id": "arXiv:2209.06498",
    "title": "Evaluation of Text Selection Techniques in Virtual Reality Head-Mounted  Displays",
    "abstract": "Comments: IEEE ISMAR'22 conference track; 10 pages; There was a mistake in Section 4.4.1 reagrding the symbol, it has been updated in this version",
    "descriptor": "\nComments: IEEE ISMAR'22 conference track; 10 pages; There was a mistake in Section 4.4.1 reagrding the symbol, it has been updated in this version\n",
    "authors": [
      "Wenge Xu",
      "Xuanru Meng",
      "Kangyou Yu",
      "Sayan Sacar",
      "Hai-Ning Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.06498"
  },
  {
    "id": "arXiv:2209.06779",
    "title": "Efficient Planar Pose Estimation via UWB Measurements",
    "abstract": "Comments: Correct several typos and revise the proof",
    "descriptor": "\nComments: Correct several typos and revise the proof\n",
    "authors": [
      "Haodong Jiang",
      "Wentao Wang",
      "Yuan Shen",
      "Xinghan Li",
      "Xiaoqiang Ren",
      "Biqiang Mu",
      "Junfeng Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06779"
  },
  {
    "id": "arXiv:2209.06825",
    "title": "An Exploration of Hands-free Text Selection for Virtual Reality  Head-Mounted Displays",
    "abstract": "Comments: IEEE ISMAR'22 conference track; 8 pages. arXiv admin note: text overlap with arXiv:2209.06498 There was a mistake in symbol in Section 4.5.1 where we have updated in this version",
    "descriptor": "\nComments: IEEE ISMAR'22 conference track; 8 pages. arXiv admin note: text overlap with arXiv:2209.06498 There was a mistake in symbol in Section 4.5.1 where we have updated in this version\n",
    "authors": [
      "Xuanru Meng",
      "Wenge Xu",
      "Hai-Ning Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.06825"
  },
  {
    "id": "arXiv:2209.06970",
    "title": "Generative Visual Prompt: Unifying Distributional Control of Pre-Trained  Generative Models",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Chen Henry Wu",
      "Saman Motamed",
      "Shaunak Srivastava",
      "Fernando De la Torre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.06970"
  },
  {
    "id": "arXiv:2209.07288",
    "title": "Optimistic Curiosity Exploration and Conservative Exploitation with  Linear Reward Shaping",
    "abstract": "Optimistic Curiosity Exploration and Conservative Exploitation with  Linear Reward Shaping",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Lei Han",
      "Rui Yang",
      "Xiaoteng Ma",
      "Jian Guo",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07288"
  },
  {
    "id": "arXiv:2209.07376",
    "title": "Understanding Deep Neural Function Approximation in Reinforcement  Learning via $\u03b5$-Greedy Exploration",
    "abstract": "Comments: Accepted by NeurIPS22",
    "descriptor": "\nComments: Accepted by NeurIPS22\n",
    "authors": [
      "Fanghui Liu",
      "Luca Viano",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07376"
  },
  {
    "id": "arXiv:2209.07396",
    "title": "Towards Healing the Blindness of Score Matching",
    "abstract": "Towards Healing the Blindness of Score Matching",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Oscar Key",
      "Peter Hayes",
      "David Barber",
      "Brooks Paige",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07396"
  },
  {
    "id": "arXiv:2209.07655",
    "title": "Multiscale Adaptive Scheduling and Path-Planning for Power-Constrained  UAV-Relays via SMDPs",
    "abstract": "Comments: 7 pages and 5 figures. Accepted at ASILOMAR 2022. Extended version submitted to IEEE TCCN (under review)",
    "descriptor": "\nComments: 7 pages and 5 figures. Accepted at ASILOMAR 2022. Extended version submitted to IEEE TCCN (under review)\n",
    "authors": [
      "Bharath Keshavamurthy",
      "Nicolo Michelusi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.07655"
  },
  {
    "id": "arXiv:2209.07702",
    "title": "Federated Coordinate Descent for Privacy-Preserving Multiparty Linear  Regression",
    "abstract": "Comments: 14 pages, 19 figures (Under review)",
    "descriptor": "\nComments: 14 pages, 19 figures (Under review)\n",
    "authors": [
      "Xinlin Leng",
      "Chenxu Li",
      "Weifeng Xu",
      "Yuyan Sun",
      "Hongtao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07702"
  },
  {
    "id": "arXiv:2209.07736",
    "title": "Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a  Polynomial Net Study",
    "abstract": "Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a  Polynomial Net Study",
    "descriptor": "",
    "authors": [
      "Yongtao Wu",
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07736"
  },
  {
    "id": "arXiv:2209.08591",
    "title": "Resource Allocation of STAR-RIS Assisted Full-Duplex Systems",
    "abstract": "Comments: 13 pages, 8 figures, This work has been submitted for possible publication",
    "descriptor": "\nComments: 13 pages, 8 figures, This work has been submitted for possible publication\n",
    "authors": [
      "Mohammad Reza Kavianinia",
      "Mohammad Javad Emadi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.08591"
  },
  {
    "id": "arXiv:2209.08911",
    "title": "Universal Proof Theory: Feasible Admissibility in Intuitionistic Modal  Logics",
    "abstract": "Universal Proof Theory: Feasible Admissibility in Intuitionistic Modal  Logics",
    "descriptor": "",
    "authors": [
      "Amirhossein Akbar Tabatabai",
      "Raheleh Jalali"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.08911"
  },
  {
    "id": "arXiv:2209.09407",
    "title": "DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for  Open-world Detection",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Lewei Yao",
      "Jianhua Han",
      "Youpeng Wen",
      "Xiaodan Liang",
      "Dan Xu",
      "Wei Zhang",
      "Zhenguo Li",
      "Chunjing Xu",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09407"
  },
  {
    "id": "arXiv:2209.09449",
    "title": "Data-Centric AI Paradigm Based on Application-Driven Fine-Grained  Dataset Design",
    "abstract": "Data-Centric AI Paradigm Based on Application-Driven Fine-Grained  Dataset Design",
    "descriptor": "",
    "authors": [
      "Huan Hu",
      "Yajie Cui",
      "Zhaoxiang Liu",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09449"
  },
  {
    "id": "arXiv:2209.09502",
    "title": "GAMA: Generative Adversarial Multi-Object Scene Attacks",
    "abstract": "Comments: Accepted at NeurIPS 2022; First two authors contributed equally; Includes Supplementary Material",
    "descriptor": "\nComments: Accepted at NeurIPS 2022; First two authors contributed equally; Includes Supplementary Material\n",
    "authors": [
      "Abhishek Aich",
      "Calvin-Khang Ta",
      "Akash Gupta",
      "Chengyu Song",
      "Srikanth V. Krishnamurthy",
      "M. Salman Asif",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09502"
  },
  {
    "id": "arXiv:2209.09513",
    "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science  Question Answering",
    "abstract": "Comments: Accepted to NeurIPS 2022. 22 pages, 17 figures, 9 tables. Project: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. 22 pages, 17 figures, 9 tables. Project: this https URL\n",
    "authors": [
      "Pan Lu",
      "Swaroop Mishra",
      "Tony Xia",
      "Liang Qiu",
      "Kai-Wei Chang",
      "Song-Chun Zhu",
      "Oyvind Tafjord",
      "Peter Clark",
      "Ashwin Kalyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.09513"
  },
  {
    "id": "arXiv:2209.09845",
    "title": "Relational Reasoning via Set Transformers: Provable Efficiency and  Applications to MARL",
    "abstract": "Relational Reasoning via Set Transformers: Provable Efficiency and  Applications to MARL",
    "descriptor": "",
    "authors": [
      "Fengzhuo Zhang",
      "Boyi Liu",
      "Kaixin Wang",
      "Vincent Y. F. Tan",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.09845"
  },
  {
    "id": "arXiv:2209.09874",
    "title": "Open-vocabulary Queryable Scene Representations for Real World Planning",
    "abstract": "Comments: v2, added references to concurrent work and acknowledgments",
    "descriptor": "\nComments: v2, added references to concurrent work and acknowledgments\n",
    "authors": [
      "Boyuan Chen",
      "Fei Xia",
      "Brian Ichter",
      "Kanishka Rao",
      "Keerthana Gopalakrishnan",
      "Michael S. Ryoo",
      "Austin Stone",
      "Daniel Kappler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09874"
  },
  {
    "id": "arXiv:2209.10064",
    "title": "Off-Policy Evaluation for Episodic Partially Observable Markov Decision  Processes under Non-Parametric Models",
    "abstract": "Off-Policy Evaluation for Episodic Partially Observable Markov Decision  Processes under Non-Parametric Models",
    "descriptor": "",
    "authors": [
      "Rui Miao",
      "Zhengling Qi",
      "Xiaoke Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2209.10064"
  },
  {
    "id": "arXiv:2209.11134",
    "title": "Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "abstract": "Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "descriptor": "",
    "authors": [
      "Qihong Yang",
      "Yangtao Deng",
      "Yu Yang",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11134"
  },
  {
    "id": "arXiv:2209.11233",
    "title": "Evaluating Latent Space Robustness and Uncertainty of EEG-ML Models  under Realistic Distribution Shifts",
    "abstract": "Comments: NeurIPS 2022 camera ready version. Code available at this https URL tl;dr - We develop model diagnostic measures to identify failure modes of EEG-ML models before deployment without access to out-of-distribution data. Keywords - dataset shift, EEG, representation learning, robustness, latent space, uncertainty quantification, distribution shift",
    "descriptor": "\nComments: NeurIPS 2022 camera ready version. Code available at this https URL tl;dr - We develop model diagnostic measures to identify failure modes of EEG-ML models before deployment without access to out-of-distribution data. Keywords - dataset shift, EEG, representation learning, robustness, latent space, uncertainty quantification, distribution shift\n",
    "authors": [
      "Neeraj Wagh",
      "Jionghao Wei",
      "Samarth Rawal",
      "Brent M. Berry",
      "Yogatheesan Varatharajah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11233"
  },
  {
    "id": "arXiv:2209.11422",
    "title": "LEADER: Learning Attention over Driving Behaviors for Planning under  Uncertainty",
    "abstract": "Comments: CoRL 2022 (oral)",
    "descriptor": "\nComments: CoRL 2022 (oral)\n",
    "authors": [
      "Mohamad H. Danesh",
      "Panpan Cai",
      "David Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11422"
  },
  {
    "id": "arXiv:2209.12086",
    "title": "One-Shot Learning of Stochastic Differential Equations with Data Adapted  Kernels",
    "abstract": "Comments: 22 pages, 21 figures",
    "descriptor": "\nComments: 22 pages, 21 figures\n",
    "authors": [
      "Matthieu Darcy",
      "Boumediene Hamzi",
      "Giulia Livieri",
      "Houman Owhadi",
      "Peyman Tavallali"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12086"
  },
  {
    "id": "arXiv:2209.12105",
    "title": "Secrecy Rate Analysis of STAR-RIS in Presence of Energy Harvesting  Eavesdroppers",
    "abstract": "Comments: 6 Pages, 5 figures, This work has been submitted for possible publication",
    "descriptor": "\nComments: 6 Pages, 5 figures, This work has been submitted for possible publication\n",
    "authors": [
      "Mohammad Reza Kavianinia",
      "Mohammad Javad Emadi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2209.12105"
  },
  {
    "id": "arXiv:2209.12202",
    "title": "Multimodal Exponentially Modified Gaussian Oscillators",
    "abstract": "Comments: IEEE International Ultrasonic Symposium 2022",
    "descriptor": "\nComments: IEEE International Ultrasonic Symposium 2022\n",
    "authors": [
      "Christopher Hahne"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.12202"
  },
  {
    "id": "arXiv:2209.12226",
    "title": "Re-contextualizing Fairness in NLP: The Case of India",
    "abstract": "Comments: Accepted to AACL-IJCNLP 2022",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Shaily Bhatt",
      "Sunipa Dev",
      "Partha Talukdar",
      "Shachi Dave",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.12226"
  },
  {
    "id": "arXiv:2209.12573",
    "title": "Digital Audio Forensics: Blind Human Voice Mimicry Detection",
    "abstract": "Comments: 11 pages, 4 figures (6 if you count subfigures), 2 tables",
    "descriptor": "\nComments: 11 pages, 4 figures (6 if you count subfigures), 2 tables\n",
    "authors": [
      "Sahar Al Ajmi",
      "Khizar Hayat",
      "Alaa M. Al Obaidi",
      "Naresh Kumar",
      "Munaf Najmuldeen",
      "Baptiste Magnier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.12573"
  },
  {
    "id": "arXiv:2209.13487",
    "title": "Sentiment is all you need to win US Presidential elections",
    "abstract": "Comments: NLP4DH Workshop in AACL-IJCNLP 2022",
    "descriptor": "\nComments: NLP4DH Workshop in AACL-IJCNLP 2022\n",
    "authors": [
      "Sovesh Mohapatra",
      "Somesh Mohapatra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.13487"
  },
  {
    "id": "arXiv:2209.13645",
    "title": "PearNet: A Pearson Correlation-based Graph Attention Network for Sleep  Stage Recognition",
    "abstract": "PearNet: A Pearson Correlation-based Graph Attention Network for Sleep  Stage Recognition",
    "descriptor": "",
    "authors": [
      "Jianchao Lu",
      "Yuzhe Tian",
      "Shuang Wang",
      "Michael Sheng",
      "Xi Zheng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13645"
  },
  {
    "id": "arXiv:2209.13657",
    "title": "Suture Thread Spline Reconstruction from Endoscopic Images for Robotic  Surgery with Reliability-driven Keypoint Detection",
    "abstract": "Comments: Submitted to ICRA",
    "descriptor": "\nComments: Submitted to ICRA\n",
    "authors": [
      "Neelay Joglekar",
      "Fei Liu",
      "Ryan Orosco",
      "Michael Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.13657"
  },
  {
    "id": "arXiv:2209.13727",
    "title": "Deep Learning Based Detection of Enlarged Perivascular Spaces on Brain  MRI",
    "abstract": "Deep Learning Based Detection of Enlarged Perivascular Spaces on Brain  MRI",
    "descriptor": "",
    "authors": [
      "Tanweer Rashid",
      "Hangfan Liu",
      "Jeffrey B. Ware",
      "Karl Li",
      "Jose Rafael Romero",
      "Elyas Fadaee",
      "Ilya M. Nasrallah",
      "Saima Hilal",
      "R. Nick Bryan",
      "Timothy M. Hughes",
      "Christos Davatzikos",
      "Lenore Launer",
      "Sudha Seshadri",
      "Susan R. Heckbert",
      "Mohamad Habes"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13727"
  },
  {
    "id": "arXiv:2209.13820",
    "title": "High-order accurate multi-sub-step implicit integration algorithms with  dissipation control for second-order hyperbolic problems",
    "abstract": "Comments: 38 pages, 24 figures, and 4 tables",
    "descriptor": "\nComments: 38 pages, 24 figures, and 4 tables\n",
    "authors": [
      "Jinze Li",
      "Hua Li",
      "Kaiping Yu",
      "Rui Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.13820"
  },
  {
    "id": "arXiv:2209.13964",
    "title": "Graph Soft-Contrastive Learning via Neighborhood Ranking",
    "abstract": "Graph Soft-Contrastive Learning via Neighborhood Ranking",
    "descriptor": "",
    "authors": [
      "Zhiyuan Ning",
      "Pengfei Wang",
      "Pengyang Wang",
      "Ziyue Qiao",
      "Wei Fan",
      "Denghui Zhang",
      "Yi Du",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13964"
  },
  {
    "id": "arXiv:2209.14008",
    "title": "Keyword Extraction from Short Texts with a Text-To-Text Transfer  Transformer",
    "abstract": "Comments: Accepted to ACIIDS 2022. The proceedings of ACIIDS 2022 will be published by Springer in series Lecture Notes in Artificial Intelligence (LNAI) and Communications in Computer and Information Science (CCIS)",
    "descriptor": "\nComments: Accepted to ACIIDS 2022. The proceedings of ACIIDS 2022 will be published by Springer in series Lecture Notes in Artificial Intelligence (LNAI) and Communications in Computer and Information Science (CCIS)\n",
    "authors": [
      "Piotr P\u0119zik",
      "Agnieszka Miko\u0142ajczyk-Bare\u0142a",
      "Adam Wawrzy\u0144ski",
      "Bart\u0142omiej Nito\u0144",
      "Maciej Ogrodniczuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.14008"
  },
  {
    "id": "arXiv:2209.14171",
    "title": "Programmable and Customized Intelligence for Traffic Steering in 5G  Networks Using Open RAN Architectures",
    "abstract": "Comments: 15 pages, 2 algorithms, 1 table, 11 figures, 42 references",
    "descriptor": "\nComments: 15 pages, 2 algorithms, 1 table, 11 figures, 42 references\n",
    "authors": [
      "Andrea Lacava",
      "Michele Polese",
      "Rajarajan Sivaraj",
      "Rahul Soundrarajan",
      "Bhawani Shanker Bhati",
      "Tarunjeet Singh",
      "Tommaso Zugno",
      "Francesca Cuomo",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.14171"
  },
  {
    "id": "arXiv:2209.14449",
    "title": "Parameterized Quantum Circuits with Quantum Kernels for Machine  Learning: A Hybrid Quantum-Classical Approach",
    "abstract": "Parameterized Quantum Circuits with Quantum Kernels for Machine  Learning: A Hybrid Quantum-Classical Approach",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14449"
  },
  {
    "id": "arXiv:2209.14754",
    "title": "On Physics-Informed Neural Networks for Quantum Computers",
    "abstract": "Comments: Updated the previous work section and abstract, fixed typos, and changed the title",
    "descriptor": "\nComments: Updated the previous work section and abstract, fixed typos, and changed the title\n",
    "authors": [
      "Stefano Markidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.14754"
  },
  {
    "id": "arXiv:2209.15342",
    "title": "Emergent Communication: Generalization and Overfitting in Lewis Games",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Mathieu Rita",
      "Corentin Tallec",
      "Paul Michel",
      "Jean-Bastien Grill",
      "Olivier Pietquin",
      "Emmanuel Dupoux",
      "Florian Strub"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.15342"
  },
  {
    "id": "arXiv:2210.00077",
    "title": "E-Branchformer: Branchformer with Enhanced merging for speech  recognition",
    "abstract": "Comments: Accepted to SLT 2022",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Kwangyoun Kim",
      "Felix Wu",
      "Yifan Peng",
      "Jing Pan",
      "Prashant Sridhar",
      "Kyu J. Han",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00077"
  },
  {
    "id": "arXiv:2210.00423",
    "title": "Improved Algorithms for Neural Active Learning",
    "abstract": "Comments: NeurIPS 2022, 34 Pages",
    "descriptor": "\nComments: NeurIPS 2022, 34 Pages\n",
    "authors": [
      "Yikun Ban",
      "Yuheng Zhang",
      "Hanghang Tong",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00423"
  },
  {
    "id": "arXiv:2210.00943",
    "title": "Simple Pooling Front-ends For Efficient Audio Classification",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xubo Liu",
      "Haohe Liu",
      "Qiuqiang Kong",
      "Xinhao Mei",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.00943"
  },
  {
    "id": "arXiv:2210.01202",
    "title": "SinGRAV: Learning a Generative Radiance Volume from a Single Natural  Scene",
    "abstract": "Comments: see project page at this https URL",
    "descriptor": "\nComments: see project page at this https URL\n",
    "authors": [
      "Yujie Wang",
      "Xuelin Chen",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01202"
  },
  {
    "id": "arXiv:2210.01276",
    "title": "Probabilistic Volumetric Fusion for Dense Monocular SLAM",
    "abstract": "Comments: 9 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 9 pages, 6 figures, 2 tables\n",
    "authors": [
      "Antoni Rosinol",
      "John J. Leonard",
      "Luca Carlone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01276"
  },
  {
    "id": "arXiv:2210.01438",
    "title": "Complementary consistency semi-supervised learning for 3D left atrial  image segmentation",
    "abstract": "Complementary consistency semi-supervised learning for 3D left atrial  image segmentation",
    "descriptor": "",
    "authors": [
      "Hejun Huang",
      "Zuguo Chen",
      "Chaoyang Chen",
      "Ming Lu",
      "Ying Zou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01438"
  },
  {
    "id": "arXiv:2210.01796",
    "title": "Multi-objective Deep Data Generation with Correlated Property Control",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2022",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2022\n",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Xuanyang Lin",
      "Bo Pan",
      "Yuanqi Du",
      "Yinkai Wang",
      "Yanfang Ye",
      "Ashley Ann Petersen",
      "Austin Leitgeb",
      "Saleh AlKhalifa",
      "Kevin Minbiole",
      "William Wuest",
      "Amarda Shehu",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01796"
  },
  {
    "id": "arXiv:2210.02614",
    "title": "Federated Learning with Server Learning: Enhancing Performance for  Non-IID Data",
    "abstract": "Comments: 20 pages, 11 figures",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Van Sy Mai",
      "Richard J. La",
      "Tao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.02614"
  },
  {
    "id": "arXiv:2210.02841",
    "title": "Detecting Irregular Network Activity with Adversarial Learning and  Expert Feedback",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Gopikrishna Rathinavel",
      "Nikhil Muralidhar",
      "Timothy O'Shea",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02841"
  },
  {
    "id": "arXiv:2210.02845",
    "title": "A unified steady and unsteady formulation for hydrodynamic potential  flow simulations with fully nonlinear free surface boundary conditions",
    "abstract": "A unified steady and unsteady formulation for hydrodynamic potential  flow simulations with fully nonlinear free surface boundary conditions",
    "descriptor": "",
    "authors": [
      "Andrea Mola",
      "Nicola Giuliani",
      "\u00d3scar Crego",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.02845"
  },
  {
    "id": "arXiv:2210.03069",
    "title": "A Better Way to Decay: Proximal Gradient Training Algorithms for Neural  Nets",
    "abstract": "A Better Way to Decay: Proximal Gradient Training Algorithms for Neural  Nets",
    "descriptor": "",
    "authors": [
      "Liu Yang",
      "Jifan Zhang",
      "Joseph Shenouda",
      "Dimitris Papailiopoulos",
      "Kangwook Lee",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03069"
  },
  {
    "id": "arXiv:2210.03501",
    "title": "Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity  Modeling with Knowledge Enhancement",
    "abstract": "Comments: Accepted by EMNLP2022",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03501"
  },
  {
    "id": "arXiv:2210.03526",
    "title": "A Unified Hard-Constraint Framework for Solving Geometrically Complex  PDEs",
    "abstract": "Comments: 10 pages, 5 figures, NeurIPS 2022",
    "descriptor": "\nComments: 10 pages, 5 figures, NeurIPS 2022\n",
    "authors": [
      "Songming Liu",
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03526"
  },
  {
    "id": "arXiv:2210.03543",
    "title": "A2: Efficient Automated Attacker for Boosting Adversarial Training",
    "abstract": "Comments: Accepted by NeurIPS2022",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Zhuoer Xu",
      "Guanghui Zhu",
      "Changhua Meng",
      "Shiwen Cui",
      "Zhenzhe Ying",
      "Weiqiang Wang",
      "Ming GU",
      "Yihua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03543"
  },
  {
    "id": "arXiv:2210.03856",
    "title": "Disordered vectors in R: introducing the disordR package",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Robin K. S. Hankin"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2210.03856"
  },
  {
    "id": "arXiv:2210.03859",
    "title": "Spectrally-Corrected and Regularized Linear Discriminant Analysis for  Spiked Covariance Model",
    "abstract": "Spectrally-Corrected and Regularized Linear Discriminant Analysis for  Spiked Covariance Model",
    "descriptor": "",
    "authors": [
      "Hua Li",
      "Wenya Luo",
      "Zhidong Bai",
      "Huanchao Zhou",
      "Zhangni Pu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03859"
  },
  {
    "id": "arXiv:2210.03923",
    "title": "Sparse Teachers Can Be Dense with Knowledge",
    "abstract": "Comments: 12 pages, 8 figures, 6 tables, accepted to EMNLP 2022. Code is available at this https URL",
    "descriptor": "\nComments: 12 pages, 8 figures, 6 tables, accepted to EMNLP 2022. Code is available at this https URL\n",
    "authors": [
      "Yi Yang",
      "Chen Zhang",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03923"
  },
  {
    "id": "arXiv:2210.04081",
    "title": "SlenderGNN: Accurate, Robust, and Interpretable GNN, and the Reasons for  its Success",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Jaemin Yoo",
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04081"
  },
  {
    "id": "arXiv:2210.04267",
    "title": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "abstract": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "descriptor": "",
    "authors": [
      "Omkar Gokhale",
      "Aditya Kane",
      "Shantanu Patankar",
      "Tanmay Chavan",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04267"
  },
  {
    "id": "arXiv:2210.04502",
    "title": "A Reunion of Godel, Tarski, Carnap, and Rosser",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Saeed Salehi"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.04502"
  },
  {
    "id": "arXiv:2210.04578",
    "title": "Is your noise correction noisy? PLS: Robustness to label noise with two  stage detection",
    "abstract": "Comments: 9 pages 4 figures. Accepted at WACV 2023",
    "descriptor": "\nComments: 9 pages 4 figures. Accepted at WACV 2023\n",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Tarun Krishna",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04578"
  },
  {
    "id": "arXiv:2210.04620",
    "title": "FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in  Realistic Healthcare Settings",
    "abstract": "Comments: Accepted to NeurIPS, Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted to NeurIPS, Datasets and Benchmarks Track\n",
    "authors": [
      "Jean Ogier du Terrail",
      "Samy-Safwan Ayed",
      "Edwige Cyffers",
      "Felix Grimberg",
      "Chaoyang He",
      "Regis Loeb",
      "Paul Mangold",
      "Tanguy Marchand",
      "Othmane Marfoq",
      "Erum Mushtaq",
      "Boris Muzellec",
      "Constantin Philippenko",
      "Santiago Silva",
      "Maria Tele\u0144czuk",
      "Shadi Albarqouni",
      "Salman Avestimehr",
      "Aur\u00e9lien Bellet",
      "Aymeric Dieuleveut",
      "Martin Jaggi",
      "Sai Praneeth Karimireddy",
      "Marco Lorenzi",
      "Giovanni Neglia",
      "Marc Tommasi",
      "Mathieu Andreux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.04620"
  },
  {
    "id": "arXiv:2210.04929",
    "title": "Batch Exchanges with Constant Function Market Makers: Axioms,  Equilibria, and Computation",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Geoffrey Ramseyer",
      "Mohak Goyal",
      "Ashish Goel",
      "David Mazi\u00e8res"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.04929"
  },
  {
    "id": "arXiv:2210.04982",
    "title": "REV: Information-Theoretic Evaluation of Free-Text Rationales",
    "abstract": "REV: Information-Theoretic Evaluation of Free-Text Rationales",
    "descriptor": "",
    "authors": [
      "Hanjie Chen",
      "Faeze Brahman",
      "Xiang Ren",
      "Yangfeng Ji",
      "Yejin Choi",
      "Swabha Swayamdipta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04982"
  },
  {
    "id": "arXiv:2210.05128",
    "title": "On fast greedy block Kaczmarz methods for solving large consistent  linear systems",
    "abstract": "Comments: 11 pages, 1 figure",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Aqin Xiao",
      "Junfeng Yin",
      "Ning Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.05128"
  },
  {
    "id": "arXiv:2210.05189",
    "title": "Neural Networks are Decision Trees",
    "abstract": "Comments: This paper has significant overlaps with some other papers, kindly read &cite others that are indicated in last paragraph of Introduction section",
    "descriptor": "\nComments: This paper has significant overlaps with some other papers, kindly read &cite others that are indicated in last paragraph of Introduction section\n",
    "authors": [
      "Caglar Aytekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05189"
  },
  {
    "id": "arXiv:2210.05236",
    "title": "Planning Assembly Sequence with Graph Transformer",
    "abstract": "Comments: Submitted to ICRA2023",
    "descriptor": "\nComments: Submitted to ICRA2023\n",
    "authors": [
      "Lin Ma",
      "Jiangtao Gong",
      "Hao Xu",
      "Hao Chen",
      "Hao Zhao",
      "Wenbing Huang",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05236"
  },
  {
    "id": "arXiv:2210.05318",
    "title": "CASAPose: Class-Adaptive and Semantic-Aware Multi-Object Pose Estimation",
    "abstract": "Comments: Accepted at BMVC 2022 (this submission includes the paper and supplementary material)",
    "descriptor": "\nComments: Accepted at BMVC 2022 (this submission includes the paper and supplementary material)\n",
    "authors": [
      "Niklas Gard",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05318"
  },
  {
    "id": "arXiv:2210.05385",
    "title": "Enhancing Branch-and-Bound for Multi-Objective 0-1 Programming",
    "abstract": "Enhancing Branch-and-Bound for Multi-Objective 0-1 Programming",
    "descriptor": "",
    "authors": [
      "Nicolas Forget",
      "Sophie N. Parragh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.05385"
  },
  {
    "id": "arXiv:2210.05714",
    "title": "Visual Language Maps for Robot Navigation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Chenguang Huang",
      "Oier Mees",
      "Andy Zeng",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05714"
  },
  {
    "id": "arXiv:2210.05795",
    "title": "Online Team Formation under Different Synergies",
    "abstract": "Comments: 37 pages, extended version of WINE 2022 accepted paper including all proofs",
    "descriptor": "\nComments: 37 pages, extended version of WINE 2022 accepted paper including all proofs\n",
    "authors": [
      "Matthew Eichhorn",
      "Siddhartha Banerjee",
      "David Kempe"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.05795"
  },
  {
    "id": "arXiv:2210.05889",
    "title": "Building Heterogeneous Cloud System for Machine Learning Inference",
    "abstract": "Building Heterogeneous Cloud System for Machine Learning Inference",
    "descriptor": "",
    "authors": [
      "Baolin Li",
      "Siddharth Samsi",
      "Vijay Gadepally",
      "Devesh Tiwari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05889"
  },
  {
    "id": "arXiv:2210.05916",
    "title": "Hate-CLIPper: Multimodal Hateful Meme Classification based on  Cross-modal Interaction of CLIP Features",
    "abstract": "Comments: Accepted at EMNLP 2022 Workshop on NLP for Positive Impact",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Workshop on NLP for Positive Impact\n",
    "authors": [
      "Gokul Karthik Kumar",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.05916"
  },
  {
    "id": "arXiv:2210.06071",
    "title": "Self-Validated Physics-Embedding Network: A General Framework for  Inverse Modelling",
    "abstract": "Comments: 32 pages, 25 figures, four tables",
    "descriptor": "\nComments: 32 pages, 25 figures, four tables\n",
    "authors": [
      "Ruiyuan Kang",
      "Dimitrios C. Kyritsis",
      "Panos Liatsis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.06071"
  },
  {
    "id": "arXiv:2210.06300",
    "title": "Generalised Mutual Information for Discriminative Clustering",
    "abstract": "Comments: To be published in Neural Information Processing Systems 2022",
    "descriptor": "\nComments: To be published in Neural Information Processing Systems 2022\n",
    "authors": [
      "Louis Ohl",
      "Pierre-Alexandre Mattei",
      "Charles Bouveyron",
      "Warith Harchaoui",
      "Micka\u00ebl Leclercq",
      "Arnaud Droit",
      "Frederic Precioso"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2210.06300"
  },
  {
    "id": "arXiv:2210.06327",
    "title": "Betting the system: Using lineups to predict football scores",
    "abstract": "Comments: 8 Page paper submitted for review for SDM23",
    "descriptor": "\nComments: 8 Page paper submitted for review for SDM23\n",
    "authors": [
      "George Peters",
      "Diogo Pacheco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06327"
  },
  {
    "id": "arXiv:2210.06346",
    "title": "Predicting the clinical citation count of biomedical papers using  multilayer perceptron neural network",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Qikai Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06346"
  },
  {
    "id": "arXiv:2210.06443",
    "title": "On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning",
    "abstract": "Comments: 22 pages, 8 figures, typos corrected. Accepted at the thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022), New Orleans, US",
    "descriptor": "\nComments: 22 pages, 8 figures, typos corrected. Accepted at the thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022), New Orleans, US\n",
    "authors": [
      "Lorenzo Bonicelli",
      "Matteo Boschini",
      "Angelo Porrello",
      "Concetto Spampinato",
      "Simone Calderara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06443"
  },
  {
    "id": "arXiv:2210.06597",
    "title": "Find Your Friends: Personalized Federated Learning with the Right  Collaborators",
    "abstract": "Find Your Friends: Personalized Federated Learning with the Right  Collaborators",
    "descriptor": "",
    "authors": [
      "Yi Sui",
      "Junfeng Wen",
      "Yenson Lau",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06597"
  },
  {
    "id": "arXiv:2210.06642",
    "title": "What's in a Decade? Transforming Faces Through Time",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Eric Ming Chen",
      "Jin Sun",
      "Apoorv Khandelwal",
      "Dani Lischinski",
      "Noah Snavely",
      "Hadar Averbuch-Elor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.06642"
  },
  {
    "id": "arXiv:2210.06681",
    "title": "Brain Network Transformer",
    "abstract": "Comments: Accepted to NeurIPS 2022. The previous version is accepted for Workshop ICML-IMLH 2022 (Oral, no proceedings)",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. The previous version is accepted for Workshop ICML-IMLH 2022 (Oral, no proceedings)\n",
    "authors": [
      "Xuan Kan",
      "Wei Dai",
      "Hejie Cui",
      "Zilong Zhang",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.06681"
  },
  {
    "id": "arXiv:2210.06694",
    "title": "SubeventWriter: Iterative Sub-event Sequence Generation with Coherence  Controller",
    "abstract": "Comments: Accepted to the main conference of EMNLP 2022. (Changed some format issues)",
    "descriptor": "\nComments: Accepted to the main conference of EMNLP 2022. (Changed some format issues)\n",
    "authors": [
      "Zhaowei Wang",
      "Hongming Zhang",
      "Tianqing Fang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06694"
  },
  {
    "id": "arXiv:2210.06774",
    "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision",
    "abstract": "Comments: To appear at EMNLP 2022",
    "descriptor": "\nComments: To appear at EMNLP 2022\n",
    "authors": [
      "Kevin Yang",
      "Yuandong Tian",
      "Nanyun Peng",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06774"
  },
  {
    "id": "arXiv:2210.06909",
    "title": "HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial  Networks",
    "abstract": "Comments: Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Georg W\u00f6lflein",
      "In Hwa Um",
      "David J Harrison",
      "Ognjen Arandjelovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.06909"
  },
  {
    "id": "arXiv:2210.06928",
    "title": "Sentence Ambiguity, Grammaticality and Complexity Probes",
    "abstract": "Comments: Accepted at BlackboxNLP @ EMNLP 2022",
    "descriptor": "\nComments: Accepted at BlackboxNLP @ EMNLP 2022\n",
    "authors": [
      "Sunit Bhattacharya",
      "Vil\u00e9m Zouhar",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06928"
  },
  {
    "id": "arXiv:2210.07024",
    "title": "Self-explaining deep models with logic rule reasoning",
    "abstract": "Comments: 26 pages including reference, checklist, and appendix. Accepted in NeurIPS 2022",
    "descriptor": "\nComments: 26 pages including reference, checklist, and appendix. Accepted in NeurIPS 2022\n",
    "authors": [
      "Seungeon Lee",
      "Xiting Wang",
      "Sungwon Han",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07024"
  },
  {
    "id": "arXiv:2210.07032",
    "title": "Prompt-based Connective Prediction Method for Fine-grained Implicit  Discourse Relation Recognition",
    "abstract": "Comments: Findings of EMNLP 2022 Accepted",
    "descriptor": "\nComments: Findings of EMNLP 2022 Accepted\n",
    "authors": [
      "Hao Zhou",
      "Man Lan",
      "Yuanbin Wu",
      "Yuefeng Chen",
      "Meirong Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07032"
  },
  {
    "id": "arXiv:2210.07182",
    "title": "PDEBENCH: An Extensive Benchmark for Scientific Machine Learning",
    "abstract": "Comments: 16 pages (main body) + 34 pages (supplemental material), accepted for publication in NeurIPS 2022 Track Datasets and Benchmarks",
    "descriptor": "\nComments: 16 pages (main body) + 34 pages (supplemental material), accepted for publication in NeurIPS 2022 Track Datasets and Benchmarks\n",
    "authors": [
      "Makoto Takamoto",
      "Timothy Praditia",
      "Raphael Leiteritz",
      "Dan MacKinlay",
      "Francesco Alesiani",
      "Dirk Pfl\u00fcger",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.07182"
  },
  {
    "id": "arXiv:2210.07301",
    "title": "3D GAN Inversion with Pose Optimization",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Jaehoon Ko",
      "Kyusun Cho",
      "Daewon Choi",
      "Kwangrok Ryoo",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07301"
  },
  {
    "id": "arXiv:2210.07374",
    "title": "A Relational Macrostate Theory Guides Artificial Intelligence to Learn  Macro and Design Micro",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yanbo Zhang",
      "Sara Imari Walker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2210.07374"
  },
  {
    "id": "arXiv:2210.07426",
    "title": "Skill-Based Reinforcement Learning with Intrinsic Reward Matching",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Ademi Adeniji",
      "Amber Xie",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07426"
  },
  {
    "id": "arXiv:2210.07592",
    "title": "TSP-Bot: Robotic TSP Pen Art using High-DoF Manipulators",
    "abstract": "Comments: Submitted to IEEE ICRA 2023",
    "descriptor": "\nComments: Submitted to IEEE ICRA 2023\n",
    "authors": [
      "Daeun Song",
      "Eunjung Lim",
      "Jiyoon Park",
      "Minjung Jung",
      "Young J. Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07592"
  },
  {
    "id": "arXiv:2210.07632",
    "title": "Stability of Decentralized Queueing Networks Beyond Complete Bipartite  Cases",
    "abstract": "Comments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)",
    "descriptor": "\nComments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)\n",
    "authors": [
      "Hu Fu",
      "Qun Hu",
      "Jia'nan Lin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07632"
  },
  {
    "id": "arXiv:2210.07749",
    "title": "LeVoice ASR Systems for the ISCSLP 2022 Intelligent Cockpit Speech  Recognition Challenge",
    "abstract": "Comments: There are experimental errors",
    "descriptor": "\nComments: There are experimental errors\n",
    "authors": [
      "Yan Jia",
      "Mi Hong",
      "Jingyu Hou",
      "Kailong Ren",
      "Sifan Ma",
      "Jin Wang",
      "Fangzhen Peng",
      "Yinglin Ji",
      "Lin Yang",
      "Junjie Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.07749"
  },
  {
    "id": "arXiv:2210.07762",
    "title": "Controllable Style Transfer via Test-time Training of Implicit Neural  Representation",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Sunwoo Kim",
      "Youngjo Min",
      "Younghun Jung",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07762"
  },
  {
    "id": "arXiv:2210.07780",
    "title": "Federated Best Arm Identification with Heterogeneous Clients",
    "abstract": "Federated Best Arm Identification with Heterogeneous Clients",
    "descriptor": "",
    "authors": [
      "Zhirui Chen",
      "P. N. Karthik",
      "Vincent Y. F. Tan",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.07780"
  },
  {
    "id": "arXiv:2210.07808",
    "title": "Optimal AdaBoost Converges",
    "abstract": "Optimal AdaBoost Converges",
    "descriptor": "",
    "authors": [
      "Conor Snedeker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07808"
  },
  {
    "id": "arXiv:2210.07809",
    "title": "Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks",
    "abstract": "Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks",
    "descriptor": "",
    "authors": [
      "Run Wang",
      "Jixing Ren",
      "Boheng Li",
      "Tianyi She",
      "Chenhao Lin",
      "Liming Fang",
      "Jing Chen",
      "Chao Shen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.07809"
  },
  {
    "id": "arXiv:2210.07811",
    "title": "SAILOR: Scaling Anchors via Insights into Latent Object Representation",
    "abstract": "Comments: WACV 2023; code is available at this https URL",
    "descriptor": "\nComments: WACV 2023; code is available at this https URL\n",
    "authors": [
      "Du\u0161an Mali\u0107",
      "Christian Fruhwirth-Reisinger",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07811"
  },
  {
    "id": "arXiv:2210.07839",
    "title": "Contrastive Audio-Visual Masked Autoencoder",
    "abstract": "Contrastive Audio-Visual Masked Autoencoder",
    "descriptor": "",
    "authors": [
      "Yuan Gong",
      "Andrew Rouditchenko",
      "Alexander H. Liu",
      "David Harwath",
      "Leonid Karlinsky",
      "Hilde Kuehne",
      "James Glass"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07839"
  },
  {
    "id": "arXiv:2210.07851",
    "title": "Learning to Autonomously Reach Objects with NICO and Grow-When-Required  Networks",
    "abstract": "Comments: Accepted at the 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022)",
    "descriptor": "\nComments: Accepted at the 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022)\n",
    "authors": [
      "Nima Rahrakhshan",
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Nicolas Duczek",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07851"
  },
  {
    "id": "arXiv:2210.07883",
    "title": "One Model to Edit Them All: Free-Form Text-Driven Image Manipulation  with Semantic Modulations",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yiming Zhu",
      "Hongyu Liu",
      "Yibing Song",
      "ziyang Yuan",
      "Xintong Han",
      "Chun Yuan",
      "Qifeng Chen",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07883"
  },
  {
    "id": "arXiv:2210.07976",
    "title": "Wide Range MRI Artifact Removal with Transformers",
    "abstract": "Comments: BMVC22",
    "descriptor": "\nComments: BMVC22\n",
    "authors": [
      "Lennart Alexander Van der Goten",
      "Kevin Smith"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07976"
  }
]
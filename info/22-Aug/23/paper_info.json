[
  {
    "id": "arXiv:2208.09482",
    "title": "A New Outlook on the Profitability of Rogue Mining Strategies in the  Bitcoin Network",
    "abstract": "Many of the recent works on the profitability of rogue mining strategies\nhinge on a parameter called $\\gamma$ that measures the proportion of the honest\nnetwork attracted by the attacker to mine on top of his fork. These works, see\narXiv:1808.01041 and arXiv.1805.08281, have surmised conclusions based on\npremises that erroneously treat $\\gamma$ to be constant. In this paper, we\ntreat $\\gamma$ as a stochastic process and attempt to find its distribution\nthrough a Markov analysis. We begin by making strong assumptions on gamma's\nbehaviour and proceed to translate them mathematically in order to apply them\nin a Markov setting. The aforementioned is executed in two separate occasions\nfor two different models. Furthermore, we model the Bitcoin network and\nnumerically derive a limiting distribution whereby the relative accuracy of our\nmodels is tested through a likelihood analysis. Finally, we conclude that even\nwith control of 20% of the total hashrate, honest mining is the strongly\ndominant strategy.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Pantelis Tassopoulos",
      "Yorgos Protonotarios"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2208.09482"
  },
  {
    "id": "arXiv:2208.09493",
    "title": "Near-optimal fitting of ellipsoids to random points",
    "abstract": "Given independent standard Gaussian points $v_1, \\ldots, v_n$ in dimension\n$d$, for what values of $(n, d)$ does there exist with high probability an\norigin-symmetric ellipsoid that simultaneously passes through all of the\npoints? This basic problem of fitting an ellipsoid to random points has\nconnections to low-rank matrix decompositions, independent component analysis,\nand principal component analysis. Based on strong numerical evidence,\nSaunderson, Parrilo, and Willsky [Proc. of Conference on Decision and Control,\npp. 6031-6036, 2013] conjecture that the ellipsoid fitting problem transitions\nfrom feasible to infeasible as the number of points $n$ increases, with a sharp\nthreshold at $n \\sim d^2/4$. We resolve this conjecture up to logarithmic\nfactors by constructing a fitting ellipsoid for some $n = \\Omega( \\,\nd^2/\\log^5(d) \\,)$, improving prior work of Ghosh et al. [Proc. of Symposium on\nFoundations of Computer Science, pp. 954-965, 2020] that requires $n =\no(d^{3/2})$. Our proof demonstrates feasibility of the least squares\nconstruction of Saunderson et al. using a careful analysis of the eigenvectors\nand eigenvalues of a certain non-standard random matrix.",
    "descriptor": "",
    "authors": [
      "Prayaag Venkat",
      "Paxton Turner",
      "Alexander S. Wein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09493"
  },
  {
    "id": "arXiv:2208.09495",
    "title": "Topical: Learning Repository Embeddings from Source Code using Attention",
    "abstract": "Machine learning on source code (MLOnCode) promises to transform how software\nis delivered. By mining the context and relationship between software\nartefacts, MLOnCode augments the software developers capabilities with code\nauto-generation, code recommendation, code auto-tagging and other data-driven\nenhancements. For many of these tasks a script level representation of code is\nsufficient, however, in many cases a repository level representation that takes\ninto account various dependencies and repository structure is imperative, for\nexample, auto-tagging repositories with topics or auto-documentation of\nrepository code etc. Existing methods for computing repository level\nrepresentations suffer from (a) reliance on natural language documentation of\ncode (for example, README files) (b) naive aggregation of method/script-level\nrepresentation, for example, by concatenation or averaging. This paper\nintroduces Topical a deep neural network to generate repository level\nembeddings of publicly available GitHub code repositories directly from source\ncode. Topical incorporates an attention mechanism that projects the source\ncode, the full dependency graph and the script level textual information into a\ndense repository-level representation. To compute the repository-level\nrepresentations, Topical is trained to predict the topics associated with a\nrepository, on a dataset of publicly available GitHub repositories that were\ncrawled along with their ground truth topic tags. Our experiments show that the\nembeddings computed by Topical are able to outperform multiple baselines,\nincluding baselines that naively combine the method-level representations\nthrough averaging or concatenation at the task of repository auto-tagging.",
    "descriptor": "\nComments: Pre-print, under review\n",
    "authors": [
      "Agathe Lherondelle",
      "Yash Satsangi",
      "Fran Silavong",
      "Shaltiel Eloul",
      "Sean Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09495"
  },
  {
    "id": "arXiv:2208.09496",
    "title": "Characterizing narrative time in books through fluctuations in power and  danger arcs",
    "abstract": "While recent studies have focused on quantifying word usage to find the\noverall shapes of narrative emotional arcs, certain features of narratives\nwithin narratives remain to be explored. Here, we characterize the narrative\ntime scale of sub-narratives by finding the length of text at which\nfluctuations in word usage begin to be relevant. We represent more than 30,000\nProject Gutenberg books as time series using ousiometrics, a power-danger\nframework for essential meaning, itself a reinterpretation of the\nvalence-arousal-dominance framework derived from semantic differentials. We\ndecompose each book's power and danger time series using empirical mode\ndecomposition into a sum of constituent oscillatory modes and a non-oscillatory\ntrend. By comparing the decomposition of the original power and danger time\nseries with those derived from shuffled text, we find that shorter books\nexhibit only a general trend, while longer books have fluctuations in addition\nto the general trend, similar to how subplots have arcs within an overall\nnarrative arc. These fluctuations typically have a period of a few thousand\nwords regardless of the book length or library classification code, but vary\ndepending on the content and structure of the book. Our method provides a\ndata-driven denoising approach that works for text of various lengths, in\ncontrast to the more traditional approach of using large window sizes that may\ninadvertently smooth out relevant information, especially for shorter texts.",
    "descriptor": "",
    "authors": [
      "Mikaela Irene Fudolig",
      "Thayer Alshaabi",
      "Kathryn Cramer",
      "Christopher M. Danforth",
      "Peter Sheridan Dodds"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.09496"
  },
  {
    "id": "arXiv:2208.09500",
    "title": "Explainable Biometrics in the Age of Deep Learning",
    "abstract": "Systems capable of analyzing and quantifying human physical or behavioral\ntraits, known as biometrics systems, are growing in use and application\nvariability. Since its evolution from handcrafted features and traditional\nmachine learning to deep learning and automatic feature extraction, the\nperformance of biometric systems increased to outstanding values. Nonetheless,\nthe cost of this fast progression is still not understood. Due to its opacity,\ndeep neural networks are difficult to understand and analyze, hence, hidden\ncapacities or decisions motivated by the wrong motives are a potential risk.\nResearchers have started to pivot their focus towards the understanding of deep\nneural networks and the explanation of their predictions. In this paper, we\nprovide a review of the current state of explainable biometrics based on the\nstudy of 47 papers and discuss comprehensively the direction in which this\nfield should be developed.",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Pedro C. Neto",
      "Tiago Gon\u00e7alves",
      "Jo\u00e3o Ribeiro Pinto",
      "Wilson Silva",
      "Ana F. Sequeira",
      "Arun Ross",
      "Jaime S. Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09500"
  },
  {
    "id": "arXiv:2208.09505",
    "title": "Metamorphic Testing for Web System Security",
    "abstract": "Security testing aims at verifying that the software meets its security\nproperties. In modern Web systems, however, this often entails the verification\nof the outputs generated when exercising the system with a very large set of\ninputs. Full automation is thus required to lower costs and increase the\neffectiveness of security testing. Unfortunately, to achieve such automation,\nin addition to strategies for automatically deriving test inputs, we need to\naddress the oracle problem, which refers to the challenge, given an input for a\nsystem, of distinguishing correct from incorrect behavior. In this paper, we\npropose Metamorphic Security Testing for Web-interactions (MST-wi), a\nmetamorphic testing approach that integrates test input generation strategies\ninspired by mutational fuzzing and alleviates the oracle problem in security\ntesting. It enables engineers to specify metamorphic relations (MRs) that\ncapture many security properties of Web systems. To facilitate the\nspecification of such MRs, we provide a domain-specific language accompanied by\nan Eclipse editor. MST-wi automatically collects the input data and transforms\nthe MRs into executable Java code to automatically perform security testing. It\nautomatically tests Web systems to detect vulnerabilities based on the\nrelations and collected data. We provide a catalog of 76 system-agnostic MRs to\nautomate security testing in Web systems. It covers 39% of the OWASP security\ntesting activities not automated by state-of-the-art techniques; further, our\nMRs can automatically discover 102 different types of vulnerabilities, which\ncorrespond to 45% of the vulnerabilities due to violations of security design\nprinciples according to the MITRE CWE database. We also define guidelines that\nenable test engineers to improve the testability of the system under test with\nrespect to our approach.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1912.05278\n",
    "authors": [
      "Nazanin Bayati Chaleshtari",
      "Fabrizio Pastore",
      "Arda Goknil",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.09505"
  },
  {
    "id": "arXiv:2208.09513",
    "title": "Globus Automation Services: Research process automation across the  space-time continuum",
    "abstract": "Research process automation--the reliable, efficient, and reproducible\nexecution of linked sets of actions on scientific instruments, computers, data\nstores, and other resources--has emerged as an essential element of modern\nscience. We report here on new services within the Globus research data\nmanagement platform that enable the specification of diverse research processes\nas reusable sets of actions, flows, and the execution of such flows in\nheterogeneous research environments. To support flows with broad spatial extent\n(e.g., from scientific instrument to remote data center) and temporal extent\n(from seconds to weeks), these Globus automation services feature: 1) cloud\nhosting for reliable execution of even long-lived flows despite sporadic\nfailures; 2) a declarative notation, and extensible asynchronous action\nprovider API, for defining and executing a wide variety of actions and flow\nspecifications involving arbitrary resources; 3) authorization delegation\nmechanisms for secure invocation of actions. These services permit researchers\nto outsource and automate the management of a broad range of research tasks to\na reliable, scalable, and secure cloud platform. We present use cases for\nGlobus automation services, describe the design and implementation of the\nservices, present microbenchmark studies, and review experiences applying the\nservices in a range of applications",
    "descriptor": "",
    "authors": [
      "Ryan Chard",
      "Jim Pruyne",
      "Kurt McKee",
      "Josh Bryan",
      "Brigitte Raumann",
      "Rachana Ananthakrishnan",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09513"
  },
  {
    "id": "arXiv:2208.09515",
    "title": "Spectral Decomposition Representation for Reinforcement Learning",
    "abstract": "Representation learning often plays a critical role in reinforcement learning\nby managing the curse of dimensionality. A representative class of algorithms\nexploits a spectral decomposition of the stochastic transition dynamics to\nconstruct representations that enjoy strong theoretical properties in an\nidealized setting. However, current spectral methods suffer from limited\napplicability because they are constructed for state-only aggregation and\nderived from a policy-dependent transition kernel, without considering the\nissue of exploration. To address these issues, we propose an alternative\nspectral method, Spectral Decomposition Representation (SPEDER), that extracts\na state-action abstraction from the dynamics without inducing spurious\ndependence on the data collection policy, while also balancing the\nexploration-versus-exploitation trade-off during learning. A theoretical\nanalysis establishes the sample efficiency of the proposed algorithm in both\nthe online and offline settings. In addition, an experimental investigation\ndemonstrates superior performance over current state-of-the-art algorithms\nacross several benchmarks.",
    "descriptor": "\nComments: The first two authors contribute equally\n",
    "authors": [
      "Tongzheng Ren",
      "Tianjun Zhang",
      "Lisa Lee",
      "Joseph E. Gonzalez",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09515"
  },
  {
    "id": "arXiv:2208.09517",
    "title": "Exploring Popularity Bias in Music Recommendation Models and Commercial  Steaming Services",
    "abstract": "Popularity bias is the idea that a recommender system will unduly favor\npopular artists when recommending artists to users. As such, they may\ncontribute to a winner-take-all marketplace in which a small number of artists\nreceive nearly all of the attention, while similarly meritorious artists are\nunlikely to be discovered. In this paper, we attempt to measure popularity bias\nin three state-of-art recommender system models (e.g., SLIM, Multi-VAE, WRMF)\nand on three commercial music streaming services (Spotify, Amazon Music,\nYouTube). We find that the most accurate model (SLIM) also has the most\npopularity bias while less accurate models have less popularity bias. We also\nfind no evidence of popularity bias in the commercial recommendations based on\na simulated user experiment.",
    "descriptor": "\nComments: Music Recommendation, Popularity bias, Recommender Systems, 6 pages\n",
    "authors": [
      "Douglas R. Turnbull",
      "Sean McQuillan",
      "Vera Crabtree",
      "John Hunter",
      "Sunny Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.09517"
  },
  {
    "id": "arXiv:2208.09518",
    "title": "Recurrent Neural Network-based Anti-jamming Framework for Defense  Against Multiple Jamming Policies",
    "abstract": "Conventional anti-jamming methods mainly focus on preventing single jammer\nattacks with an invariant jamming policy or jamming attacks from multiple\njammers with similar jamming policies. These anti-jamming methods are\nineffective against a single jammer following several different jamming\npolicies or multiple jammers with distinct policies. Therefore, this paper\nproposes an anti-jamming method that can adapt its policy to the current\njamming attack. Moreover, for the multiple jammers scenario, an anti-jamming\nmethod that estimates the future occupied channels using the jammers' occupied\nchannels in previous time slots is proposed. In both single and multiple\njammers scenarios, the interaction between the users and jammers is modeled\nusing recurrent neural networks (RNN)s. The performance of the proposed\nanti-jamming methods is evaluated by calculating the users' successful\ntransmission rate (STR) and ergodic rate (ER), and compared to a baseline based\non Q-learning (DQL). Simulation results show that for the single jammer\nscenario, all the considered jamming policies are perfectly detected and high\nSTR and ER are maintained. Moreover, when 70 % of the spectrum is under jamming\nattacks from multiple jammers, the proposed method achieves an STR and ER\ngreater than 75 % and 80 %, respectively. These values rise to 90 % when 30 %\nof the spectrum is under jamming attacks. In addition, the proposed\nanti-jamming methods significantly outperform the DQL method for all the\nconsidered cases and jamming scenarios.",
    "descriptor": "",
    "authors": [
      "Ali Pourranjbar",
      "Georges Kaddoum",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09518"
  },
  {
    "id": "arXiv:2208.09519",
    "title": "Resource Allocation in Serverless Query Processing",
    "abstract": "Data lakes hold a growing amount of cold data that is infrequently accessed,\nyet require interactive response times. Serverless functions are seen as a way\nto address this use case since they offer an appealing alternative to\nmaintaining (and paying for) a fixed infrastructure. Recent research has\nanalyzed the potential of serverless for data processing. In this paper, we\nexpand on such work by looking into the question of serverless resource\nallocation to data processing tasks (number and size of the functions). We\nformulate a general model to roughly estimate completion time and financial\ncost, which we apply to augment an existing serverless data processing system\nwith an advisory tool that automatically identifies configurations striking a\ngood balance -- which we define as being close to the \"knee\" of their Pareto\nfrontier. The model takes into account key aspects of serverless: start-up,\ncomputation, network transfers, and overhead as a function of the input sizes\nand intermediate result exchanges. Using (micro)benchmarks and parts of TPC-H,\nwe show that this advisor is capable of pinpointing configurations desirable to\nthe user. Moreover, we identify and discuss several aspects of data processing\non serverless affecting efficiency. By using an automated tool to configure the\nresources, the barrier to using serverless for data processing is lowered and\nthe narrow window where it is cost effective can be expanded by using a more\noptimal allocation instead of having to over-provision the design.",
    "descriptor": "",
    "authors": [
      "Simon Kassing",
      "Ingo M\u00fcller",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2208.09519"
  },
  {
    "id": "arXiv:2208.09520",
    "title": "Accelerating Vision Transformer Training via a Patch Sampling Schedule",
    "abstract": "We introduce the notion of a Patch Sampling Schedule (PSS), that varies the\nnumber of Vision Transformer (ViT) patches used per batch during training.\nSince all patches are not equally important for most vision objectives (e.g.,\nclassification), we argue that less important patches can be used in fewer\ntraining iterations, leading to shorter training time with minimal impact on\nperformance. Additionally, we observe that training with a PSS makes a ViT more\nrobust to a wider patch sampling range during inference. This allows for a\nfine-grained, dynamic trade-off between throughput and accuracy during\ninference. We evaluate using PSSs on ViTs for ImageNet both trained from\nscratch and pre-trained using a reconstruction loss function. For the\npre-trained model, we achieve a 0.26% reduction in classification accuracy for\na 31% reduction in training time (from 25 to 17 hours) compared to using all\npatches each iteration. Code, model checkpoints and logs are available at\nhttps://github.com/BradMcDanel/pss.",
    "descriptor": "\nComments: 7 pages, 3 page appendix, 13 figures\n",
    "authors": [
      "Bradley McDanel",
      "Chi Phuong Huynh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09520"
  },
  {
    "id": "arXiv:2208.09522",
    "title": "Packet Forwarding with a Locally Bursty Adversary",
    "abstract": "We consider packet forwarding in the adversarial queueing theory (AQT) model\nintroduced by Borodin et al. We introduce a refinement of the AQT $(\\rho,\n\\sigma)$-bounded adversary, which we call a \\emph{locally bursty adversary}\n(LBA) that parameterizes injection patterns jointly by edge utilization and\npacket origin. For constant ($O(1)$) parameters, the LBA model is strictly more\npermissive than the $(\\rho, \\sigma)$ model. For example, there are injection\npatterns in the LBA model with constant parameters that can only be realized as\n$(\\rho, \\sigma)$-bounded injection patterns with $\\rho + \\sigma = \\Omega(n)$\n(where $n$ is the network size). We show that the LBA model (unlike the $(\\rho,\n\\sigma)$ model) is closed under packet bundling and discretization operations.\nThus, the LBA model allows one to reduce the study of general (uniform)\ncapacity networks and inhomogenous packet sizes to unit capacity networks with\nhomogeneous packets.\nOn the algorithmic side, we focus on information gathering networks -- i.e.,\nnetworks in which all packets share a common destination, and the union of\npacket routes forms a tree. We show that the Odd-Even Downhill (OED) forwarding\nprotocol described independently by Dobrev et al.\\ and Patt-Shamir and\nRosenbaum achieves buffer space usage of $O(\\log n)$ against all LBAs with\nconstant parameters. OED is a local protocol, but we show that the upper bound\nis tight even when compared to centralized protocols. Our lower bound for the\nLBA model is in contrast to the $(\\rho, \\sigma)$-model, where centralized\nprotocols can achieve worst-case buffer space usage $O(1)$ for $\\rho, \\sigma =\nO(1)$, while the $O(\\log n)$ upper bound for OED is optimal only for local\nprotocols.",
    "descriptor": "\nComments: To appear in International Symposium on Distributed Computing (DISC) 2022\n",
    "authors": [
      "Will Rosenbaum"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09522"
  },
  {
    "id": "arXiv:2208.09525",
    "title": "Glass-Vault: A Generic Transparent Privacy-preserving Exposure  Notification Analytics Platform",
    "abstract": "The highly transmissible COVID-19 disease is a serious threat to people's\nhealth and life. To automate tracing those who have been in close physical\ncontact with newly infected people and/or to analyse tracing-related data,\nresearchers have proposed various ad-hoc programs that require being executed\non users' smartphones. Nevertheless, the existing solutions have two primary\nlimitations: (1) lack of generality: for each type of analytic task, a certain\nkind of data needs to be sent to an analyst; (2) lack of transparency: parties\nwho provide data to an analyst are not necessarily infected individuals;\ntherefore, infected individuals' data can be shared with others (e.g., the\nanalyst) without their fine-grained and direct consent. In this work, we\npresent Glass-Vault, a protocol that addresses both limitations simultaneously.\nIt allows an analyst to run authorised programs over the collected data of\ninfectious users, without learning the input data. Glass-Vault relies on a new\nvariant of generic Functional Encryption that we propose in this work. This new\nvariant, called DD-Steel, offers these two additional properties: dynamic and\ndecentralised. We illustrate the security of both Glass-Vault and DD-Steel in\nthe Universal Composability setting. Glass-Vault is the first UC-secure\nprotocol that allows analysing the data of Exposure Notification users in a\nprivacy-preserving manner. As a sample application, we indicate how it can be\nused to generate \"infection heatmaps\".",
    "descriptor": "",
    "authors": [
      "Lorenzo Martinico",
      "Aydin Abadi",
      "Thomas Zacharias",
      "Thomas Win"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09525"
  },
  {
    "id": "arXiv:2208.09529",
    "title": "Intersection of Parallels as an Early Stopping Criterion",
    "abstract": "A common way to avoid overfitting in supervised learning is early stopping,\nwhere a held-out set is used for iterative evaluation during training to find a\nsweet spot in the number of training steps that gives maximum generalization.\nHowever, such a method requires a disjoint validation set, thus part of the\nlabeled data from the training set is usually left out for this purpose, which\nis not ideal when training data is scarce. Furthermore, when the training\nlabels are noisy, the performance of the model over a validation set may not be\nan accurate proxy for generalization. In this paper, we propose a method to\nspot an early stopping point in the training iterations without the need for a\nvalidation set. We first show that in the overparameterized regime the randomly\ninitialized weights of a linear model converge to the same direction during\ntraining. Using this result, we propose to train two parallel instances of a\nlinear model, initialized with different random seeds, and use their\nintersection as a signal to detect overfitting. In order to detect\nintersection, we use the cosine distance between the weights of the parallel\nmodels during training iterations. Noticing that the final layer of a NN is a\nlinear map of pre-last layer activations to output logits, we build on our\ncriterion for linear models and propose an extension to multi-layer networks,\nusing the new notion of counterfactual weights. We conduct experiments on two\nareas that early stopping has noticeable impact on preventing overfitting of a\nNN: (i) learning from noisy labels; and (ii) learning to rank in IR. Our\nexperiments on four widely used datasets confirm the effectiveness of our\nmethod for generalization. For a wide range of learning rates, our method,\ncalled Cosine-Distance Criterion (CDC), leads to better generalization on\naverage than all the methods that we compare against in almost all of the\ntested cases.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Ali Vardasbi",
      "Maarten de Rijke",
      "Mostafa Dehghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09529"
  },
  {
    "id": "arXiv:2208.09535",
    "title": "On computing Ollivier-Ricci curvatures of graphs: fine-grained  reductions and local algorithms",
    "abstract": "Characterizing shapes of high-dimensional objects via Ricci curvatures plays\na critical role in many research areas in mathematics and physics. However,\neven though several discretizations of Ricci curvatures for discrete\ncombinatorial objects such as networks have been proposed and studied by\nmathematicians, the computational complexity aspects of these discretizations\nhave escaped the attention of theoretical computer scientists to a large\nextent. In this paper, we study one such discretization, namely the\nOllivier-Ricci curvature, from the perspective of efficient computation by\nfine-grained reductions and local query-based algorithms. Our main\ncontributions are the following.\n(a) We relate our curvature computation problem to minimum weight perfect\nmatching problem on complete bipartite graphs via fine-grained reduction.\n(b) We formalize the computational aspects of the curvature computation\nproblems in suitable frameworks so that they can be studied by researchers in\nlocal algorithms.\n(c) We provide the first known lower and upper bounds on queries for\nquery-based algorithms for the curvature computation problems in our local\nalgorithms framework.\nWe believe that our results bring forth an intriguing set of research\nquestions, motivated both in theory and practice, regarding designing efficient\nalgorithms for curvatures of objects.",
    "descriptor": "",
    "authors": [
      "Bhaskar DasGupta",
      "Elena Grigorescu",
      "Tamalika Mukherjee"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2208.09535"
  },
  {
    "id": "arXiv:2208.09536",
    "title": "[Re] Differentiable Spatial Planning using Transformers",
    "abstract": "This report covers our reproduction effort of the paper 'Differentiable\nSpatial Planning using Transformers' by Chaplot et al. . In this paper, the\nproblem of spatial path planning in a differentiable way is considered. They\nshow that their proposed method of using Spatial Planning Transformers\noutperforms prior data-driven models and leverages differentiable structures to\nlearn mapping without a ground truth map simultaneously. We verify these claims\nby reproducing their experiments and testing their method on new data. We also\ninvestigate the stability of planning accuracy with maps with increased\nobstacle complexity. Efforts to investigate and verify the learnings of the\nMapper module were met with failure stemming from a paucity of computational\nresources and unreachable authors.",
    "descriptor": "",
    "authors": [
      "Rohit Ranjan",
      "Himadri Bhakta",
      "Animesh Jha",
      "Parv Maheshwari",
      "Debashish Chakravarty"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09536"
  },
  {
    "id": "arXiv:2208.09539",
    "title": "Meta Learning for High-dimensional Ising Model Selection Using  $\\ell_1$-regularized Logistic Regression",
    "abstract": "In this paper, we consider the meta learning problem for estimating the\ngraphs associated with high-dimensional Ising models, using the method of\n$\\ell_1$-regularized logistic regression for neighborhood selection of each\nnode. Our goal is to use the information learned from the auxiliary tasks in\nthe learning of the novel task to reduce its sufficient sample complexity. To\nthis end, we propose a novel generative model as well as an improper estimation\nmethod. In our setting, all the tasks are \\emph{similar} in their \\emph{random}\nmodel parameters and supports. By pooling all the samples from the auxiliary\ntasks to \\emph{improperly} estimate a single parameter vector, we can recover\nthe true support union, assumed small in size, with a high probability with a\nsufficient sample complexity of $\\Omega(1) $ per task, for $K = \\Omega(d^3 \\log\np ) $ tasks of Ising models with $p$ nodes and a maximum neighborhood size $d$.\nThen, with the support for the novel task restricted to the estimated support\nunion, we prove that consistent neighborhood selection for the novel task can\nbe obtained with a reduced sufficient sample complexity of $\\Omega(d^3 \\log\nd)$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1010.0311, arXiv:0804.4202 by other authors\n",
    "authors": [
      "Huiming Xie",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2208.09539"
  },
  {
    "id": "arXiv:2208.09540",
    "title": "Technical Report: Asymmetric Mutual Exclusion for RDMA",
    "abstract": "Coordinating concurrent access to a shared resource using mutual exclusion is\na fundamental problem in computation. In this paper, we present a novel\napproach to mutual exclusion designed specifically for distributed systems\nleveraging a popular network communication technology, remote direct memory\naccess (RDMA). Our approach enables local processes to avoid using RDMA\noperations entirely, limits the number of RDMA operations required by remote\nprocesses, and guarantees both starvation-freedom and fairness.",
    "descriptor": "",
    "authors": [
      "Jacob Nelson-Slivon",
      "Lewis Tseng",
      "Roberto Palmieri"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09540"
  },
  {
    "id": "arXiv:2208.09549",
    "title": "Generalized Projection Matrices",
    "abstract": "Projection matrices are necessary for a large portion of rendering computer\ngraphics. There are primarily two different types of projection matrices --\nperspective and orthographic -- which are used frequently, and are\ntraditionally treated as mutually incompatible with each other in how they are\ndefined. Here, we bridge the gap between the two different forms of projection\nmatrices to present a single generalized projection matrix that can represent\nboth.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "S. J. D. MacIntosh"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.09549"
  },
  {
    "id": "arXiv:2208.09551",
    "title": "Game-Theoretic Algorithms for Conditional Moment Matching",
    "abstract": "A variety of problems in econometrics and machine learning, including\ninstrumental variable regression and Bellman residual minimization, can be\nformulated as satisfying a set of conditional moment restrictions (CMR). We\nderive a general, game-theoretic strategy for satisfying CMR that scales to\nnonlinear problems, is amenable to gradient-based optimization, and is able to\naccount for finite sample uncertainty. We recover the approaches of Dikkala et\nal. and Dai et al. as special cases of our general framework before detailing\nvarious extensions and how to efficiently solve the game defined by CMR.",
    "descriptor": "",
    "authors": [
      "Gokul Swamy",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09551"
  },
  {
    "id": "arXiv:2208.09554",
    "title": "Evaluating Diverse Knowledge Sources for Online One-shot Learning of  Novel Tasks",
    "abstract": "Online autonomous agents are able to draw on a wide variety of potential\nsources of task knowledge; however current approaches invariably focus on only\none or two. Here we investigate the challenges and impact of exploiting diverse\nknowledge sources to learn, in one-shot, new tasks for a simulated household\nmobile robot. The resulting agent, developed in the Soar cognitive\narchitecture, uses the following sources of domain and task knowledge:\ninteraction with the environment, task execution and planning knowledge, human\nnatural language instruction, and responses retrieved from a large language\nmodel (GPT-3). We explore the distinct contributions of these knowledge sources\nand evaluate the performance of different combinations in terms of learning\ncorrect task knowledge, human workload, and computational costs. The results\nfrom combining all sources demonstrate that integration improves one-shot task\nlearning overall in terms of computational costs and human workload.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "James R. Kirk",
      "Robert E. Wray",
      "Peter Lindes",
      "John E. Laird"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09554"
  },
  {
    "id": "arXiv:2208.09556",
    "title": "Minecraft: An Engaging Platform to Learn Programming",
    "abstract": "Teaching programming effectively is difficult. This paper explores the\nbenefits of using Minecraft Education Edition to teach Python programming.\nEducators can use the game to teach various programming concepts ranging from\nfundamental programming concepts, object-oriented programming, event-driven\nprogramming, and parallel programming. It has several benefits, including being\nhighly engaging, sharpen creativity and problem-solving skill, motivating the\nstudy of mathematics, and making students realizes the importance of\nprogramming.",
    "descriptor": "",
    "authors": [
      "Worasait Suwannik"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09556"
  },
  {
    "id": "arXiv:2208.09558",
    "title": "Personalized Decision Making -- A Conceptual Introduction",
    "abstract": "Personalized decision making targets the behavior of a specific individual,\nwhile population-based decision making concerns a sub-population resembling\nthat individual. This paper clarifies the distinction between the two and\nexplains why the former leads to more informed decisions. We further show that\nby combining experimental and observational studies we can obtain valuable\ninformation about individual behavior and, consequently, improve decisions over\nthose obtained from experimental studies alone.",
    "descriptor": "",
    "authors": [
      "Scott Mueller",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.09558"
  },
  {
    "id": "arXiv:2208.09562",
    "title": "A Dual Modality Approach For (Zero-Shot) Multi-Label Classification",
    "abstract": "In computer vision, multi-label classification, including zero-shot\nmulti-label classification are important tasks with many real-world\napplications. In this paper, we propose a novel algorithm, Aligned Dual\nmoDality ClaSsifier (ADDS), which includes a Dual-Modal decoder (DM-decoder)\nwith alignment between visual and textual features, for multi-label\nclassification tasks. Moreover, we design a simple and yet effective method\ncalled Pyramid-Forwarding to enhance the performance for inputs with high\nresolutions. Extensive experiments conducted on standard multi-label benchmark\ndatasets, MS-COCO and NUS-WIDE, demonstrate that our approach significantly\noutperforms previous methods and provides state-of-the-art performance for\nconventional multi-label classification, zero-shot multi-label classification,\nand an extreme case called single-to-multi label classification where models\ntrained on single-label datasets (ImageNet-1k, ImageNet-21k) are tested on\nmulti-label ones (MS-COCO and NUS-WIDE). We also analyze how visual-textual\nalignment contributes to the proposed approach, validate the significance of\nthe DM-decoder, and demonstrate the effectiveness of Pyramid-Forwarding on\nvision transformer.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Shichao Xu",
      "Yikang Li",
      "Jenhao Hsiao",
      "Chiuman Ho",
      "Zhu Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09562"
  },
  {
    "id": "arXiv:2208.09567",
    "title": "Multiple Instance Neuroimage Transformer",
    "abstract": "For the first time, we propose using a multiple instance learning based\nconvolution-free transformer model, called Multiple Instance Neuroimage\nTransformer (MINiT), for the classification of T1weighted (T1w) MRIs. We first\npresent several variants of transformer models adopted for neuroimages. These\nmodels extract non-overlapping 3D blocks from the input volume and perform\nmulti-headed self-attention on a sequence of their linear projections. MINiT,\non the other hand, treats each of the non-overlapping 3D blocks of the input\nMRI as its own instance, splitting it further into non-overlapping 3D patches,\non which multi-headed self-attention is computed. As a proof-of-concept, we\nevaluate the efficacy of our model by training it to identify sex from T1w-MRIs\nof two public datasets: Adolescent Brain Cognitive Development (ABCD) and the\nNational Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA).\nThe learned attention maps highlight voxels contributing to identifying sex\ndifferences in brain morphometry. The code is available at\nhttps://github.com/singlaayush/MINIT.",
    "descriptor": "",
    "authors": [
      "Ayush Singla",
      "Qingyu Zhao",
      "Daniel K. Do",
      "Yuyin Zhou",
      "Kilian M. Pohl",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09567"
  },
  {
    "id": "arXiv:2208.09568",
    "title": "Probabilities of Causation with Nonbinary Treatment and Effect",
    "abstract": "This paper deals with the problem of estimating the probabilities of\ncausation when treatment and effect are not binary. Tian and Pearl derived\nsharp bounds for the probability of necessity and sufficiency (PNS), the\nprobability of sufficiency (PS), and the probability of necessity (PN) using\nexperimental and observational data. In this paper, we provide theoretical\nbounds for all types of probabilities of causation to multivalued treatments\nand effects. We further discuss examples where our bounds guide practical\ndecisions and use simulation studies to evaluate how informative the bounds are\nfor various combinations of data.",
    "descriptor": "",
    "authors": [
      "Ang Li",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09568"
  },
  {
    "id": "arXiv:2208.09569",
    "title": "Unit Selection with Nonbinary Treatment and Effect",
    "abstract": "The unit selection problem aims to identify a set of individuals who are most\nlikely to exhibit a desired mode of behavior, for example, selecting\nindividuals who would respond one way if encouraged and a different way if not\nencouraged. Using a combination of experimental and observational data, Li and\nPearl derived tight bounds on the \"benefit function\", which is the payoff/cost\nassociated with selecting an individual with given characteristics. This paper\nextends the benefit function to the general form such that the treatment and\neffect are not restricted to binary. We propose an algorithm to test the\nidentifiability of the nonbinary benefit function and an algorithm to compute\nthe bounds of the nonbinary benefit function using experimental and\nobservational data.",
    "descriptor": "",
    "authors": [
      "Ang Li",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09569"
  },
  {
    "id": "arXiv:2208.09570",
    "title": "Calculus on MDPs: Potential Shaping as a Gradient",
    "abstract": "In reinforcement learning, different reward functions can be equivalent in\nterms of the optimal policies they induce. A particularly well-known and\nimportant example is potential shaping, a class of functions that can be added\nto any reward function without changing the optimal policy set under arbitrary\ntransition dynamics. Potential shaping is conceptually similar to potentials,\nconservative vector fields and gauge transformations in math and physics, but\nthis connection has not previously been formally explored. We develop a\nformalism for discrete calculus on graphs that abstract a Markov Decision\nProcess, and show how potential shaping can be formally interpreted as a\ngradient within this framework. This allows us to strengthen results from Ng et\nal. (1999) describing conditions under which potential shaping is the only\nadditive reward transformation to always preserve optimal policies. As an\nadditional application of our formalism, we define a rule for picking a single\nunique reward function from each potential shaping equivalence class.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Erik Jenner",
      "Herke van Hoof",
      "Adam Gleave"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09570"
  },
  {
    "id": "arXiv:2208.09574",
    "title": "Study of Novel Sparse Array Design Based on the Maximum Inter-Element  Spacing Criterion",
    "abstract": "A novel sparse array (SA) structure is proposed based on the maximum\ninter-element spacing (IES) constraint (MISC) criterion. Compared with the\ntraditional MISC array, the proposed SA configurations, termed as improved MISC\n(IMISC) has significantly increased uniform degrees of freedom (uDOF) and\nreduced mutual coupling. In particular, the IMISC arrays are composed of six\nuniform linear arrays (ULAs), which can be determined by an IES set. The IES\nset is constrained by two parameters, namely the maximum IES and the number of\nsensors. The uDOF of the IMISC arrays is derived and the weight function of the\nIMISC arrays is analyzed as well. The proposed IMISC arrays have a great\nadvantage in terms of uDOF against the existing SAs, while their mutual\ncoupling remains at a low level. Simulations are carried out to demonstrate the\nadvantages of the IMISC arrays.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "W. Shi",
      "Y. Li",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09574"
  },
  {
    "id": "arXiv:2208.09577",
    "title": "Real-time Short Video Recommendation on Mobile Devices",
    "abstract": "Short video applications have attracted billions of users in recent years,\nfulfilling their various needs with diverse content. Users usually watch short\nvideos on many topics on mobile devices in a short period of time, and give\nexplicit or implicit feedback very quickly to the short videos they watch. The\nrecommender system needs to perceive users' preferences in real-time in order\nto satisfy their changing interests. Traditionally, recommender systems\ndeployed at server side return a ranked list of videos for each request from\nclient. Thus it cannot adjust the recommendation results according to the\nuser's real-time feedback before the next request. Due to client-server\ntransmitting latency, it is also unable to make immediate use of users'\nreal-time feedback. However, as users continue to watch videos and feedback,\nthe changing context leads the ranking of the server-side recommendation system\ninaccurate. In this paper, we propose to deploy a short video recommendation\nframework on mobile devices to solve these problems. Specifically, we design\nand deploy a tiny on-device ranking model to enable real-time re-ranking of\nserver-side recommendation results. We improve its prediction accuracy by\nexploiting users' real-time feedback of watched videos and client-specific\nreal-time features. With more accurate predictions, we further consider\ninteractions among candidate videos, and propose a context-aware re-ranking\nmethod based on adaptive beam search. The framework has been deployed on\nKuaishou, a billion-user scale short video application, and improved effective\nview, like and follow by 1.28\\%, 8.22\\% and 13.6\\% respectively.",
    "descriptor": "\nComments: Accepted by CIKM 2022, 10 pages\n",
    "authors": [
      "Xudong Gong",
      "Qinlin Feng",
      "Yuan Zhang",
      "Jiangling Qin",
      "Weijie Ding",
      "Biao Li",
      "Peng Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09577"
  },
  {
    "id": "arXiv:2208.09578",
    "title": "Contrastive Domain Adaptation for Early Misinformation Detection: A Case  Study on COVID-19",
    "abstract": "Despite recent progress in improving the performance of misinformation\ndetection systems, classifying misinformation in an unseen domain remains an\nelusive challenge. To address this issue, a common approach is to introduce a\ndomain critic and encourage domain-invariant input features. However, early\nmisinformation often demonstrates both conditional and label shifts against\nexisting misinformation data (e.g., class imbalance in COVID-19 datasets),\nrendering such methods less effective for detecting early misinformation. In\nthis paper, we propose contrastive adaptation network for early misinformation\ndetection (CANMD). Specifically, we leverage pseudo labeling to generate\nhigh-confidence target examples for joint training with source data. We\nadditionally design a label correction component to estimate and correct the\nlabel shifts (i.e., class priors) between the source and target domains.\nMoreover, a contrastive adaptation loss is integrated in the objective function\nto reduce the intra-class discrepancy and enlarge the inter-class discrepancy.\nAs such, the adapted model learns corrected class priors and an invariant\nconditional distribution across both domains for improved estimation of the\ntarget data distribution. To demonstrate the effectiveness of the proposed\nCANMD, we study the case of COVID-19 early misinformation detection and perform\nextensive experiments using multiple real-world datasets. The results suggest\nthat CANMD can effectively adapt misinformation detection systems to the unseen\nCOVID-19 target domain with significant improvements compared to the\nstate-of-the-art baselines.",
    "descriptor": "\nComments: Accepted to CIKM 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09578"
  },
  {
    "id": "arXiv:2208.09579",
    "title": "Learning in Audio-visual Context: A Review, Analysis, and New  Perspective",
    "abstract": "Sight and hearing are two senses that play a vital role in human\ncommunication and scene understanding. To mimic human perception ability,\naudio-visual learning, aimed at developing computational approaches to learn\nfrom both audio and visual modalities, has been a flourishing field in recent\nyears. A comprehensive survey that can systematically organize and analyze\nstudies of the audio-visual field is expected. Starting from the analysis of\naudio-visual cognition foundations, we introduce several key findings that have\ninspired our computational studies. Then, we systematically review the recent\naudio-visual learning studies and divide them into three categories:\naudio-visual boosting, cross-modal perception and audio-visual collaboration.\nThrough our analysis, we discover that, the consistency of audio-visual data\nacross semantic, spatial and temporal support the above studies. To revisit the\ncurrent development of the audio-visual learning field from a more macro view,\nwe further propose a new perspective on audio-visual scene understanding, then\ndiscuss and analyze the feasible future direction of the audio-visual learning\narea. Overall, this survey reviews and outlooks the current audio-visual\nlearning field from different aspects. We hope it can provide researchers with\na better understanding of this area. A website including constantly-updated\nsurvey is released: \\url{https://gewu-lab.github.io/audio-visual-learning/}.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yake Wei",
      "Di Hu",
      "Yapeng Tian",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09579"
  },
  {
    "id": "arXiv:2208.09580",
    "title": "Using Affect as a Communication Modality to Improve Human-Robot  Communication in Robot-Assisted Search and Rescue Scenarios",
    "abstract": "Emotions can provide a natural communication modality to complement the\nexisting multi-modal capabilities of social robots, such as text and speech, in\nmany domains. We conducted three online studies with 112, 223, and 151\nparticipants to investigate the benefits of using emotions as a communication\nmodality for Search And Rescue (SAR) robots. In the first experiment, we\ninvestigated the feasibility of conveying information related to SAR situations\nthrough robots' emotions, resulting in mappings from SAR situations to\nemotions. The second study used Affect Control Theory as an alternative method\nfor deriving such mappings. This method is more flexible, e.g. allows for such\nmappings to be adjusted for different emotion sets and different robots. In the\nthird experiment, we created affective expressions for an\nappearance-constrained outdoor field research robot using LEDs as an expressive\nchannel. Using these affective expressions in a variety of simulated SAR\nsituations, we evaluated the effect of these expressions on participants'\n(adopting the role of rescue workers) situational awareness. Our results and\nproposed methodologies provide (a) insights on how emotions could help\nconveying messages in the context of SAR, and (b) evidence on the effectiveness\nof adding emotions as a communication modality in a (simulated) SAR\ncommunication context.",
    "descriptor": "",
    "authors": [
      "Sami Alperen Akgun",
      "Moojan Ghafurian",
      "Mark Crowley",
      "Kerstin Dautenhahn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.09580"
  },
  {
    "id": "arXiv:2208.09583",
    "title": "Approximation Algorithms for Matroidal and Cardinal Generalizations of  Stable Matching",
    "abstract": "The Stable Marriage problem (SM), solved by the famous deferred acceptance\nalgorithm of Gale and Shapley (GS), has many natural generalizations. If we\nallow ties in preferences, then the problem of finding a maximum solution\nbecomes NP-hard, and the best known approximation ratio is $1.5$ (McDermid\nICALP 2009, Paluch WAOA 2011, Z. Kir\\'aly MATCH-UP 2012), achievable by running\nGS on a cleverly constructed modified instance. Another elegant generalization\nof SM is the matroid kernel problem introduced by Fleiner (IPCO 2001), which is\nsolvable in polynomial time using an abstract matroidal version of GS. Our main\nresult is a simple $1.5$-approximation algorithm for the matroid kernel problem\nwith ties. We also show that the algorithm works for several other versions of\nstability defined for cardinal preferences, by appropriately modifying the\ninstance on which GS is executed. The latter results are new even for the\nstable marriage setting.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Gergely Cs\u00e1ji",
      "Tam\u00e1s Kir\u00e1ly",
      "Yu Yokoi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.09583"
  },
  {
    "id": "arXiv:2208.09586",
    "title": "HySAGE: A Hybrid Static and Adaptive Graph Embedding Network for  Context-Drifting Recommendations",
    "abstract": "The recent popularity of edge devices and Artificial Intelligent of Things\n(AIoT) has driven a new wave of contextual recommendations, such as location\nbased Point of Interest (PoI) recommendations and computing resource-aware\nmobile app recommendations. In many such recommendation scenarios, contexts are\ndrifting over time. For example, in a mobile game recommendation, contextual\nfeatures like locations, battery, and storage levels of mobile devices are\nfrequently drifting over time. However, most existing graph-based collaborative\nfiltering methods are designed under the assumption of static features.\nTherefore, they would require frequent retraining and/or yield graphical models\nburgeoning in sizes, impeding their suitability for context-drifting\nrecommendations.\nIn this work, we propose a specifically tailor-made Hybrid Static and\nAdaptive Graph Embedding (HySAGE) network for context-drifting recommendations.\nOur key idea is to disentangle the relatively static user-item interaction and\nrapidly drifting contextual features. Specifically, our proposed HySAGE network\nlearns a relatively static graph embedding from user-item interaction and an\nadaptive embedding from drifting contextual features. These embeddings are\nincorporated into an interest network to generate the user interest in some\ncertain context. We adopt an interactive attention module to learn the\ninteractions among static graph embeddings, adaptive contextual embeddings, and\nuser interest, helping to achieve a better final representation. Extensive\nexperiments on real-world datasets demonstrate that HySAGE significantly\nimproves the performance of the existing state-of-the-art recommendation\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Sichun Luo",
      "Xinyi Zhang",
      "Yuanzhang Xiao",
      "Linqi Song"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09586"
  },
  {
    "id": "arXiv:2208.09588",
    "title": "Review on Action Recognition for Accident Detection in Smart City  Transportation Systems",
    "abstract": "Action detection and public traffic safety are crucial aspects of a safe\ncommunity and a better society. Monitoring traffic flows in a smart city using\ndifferent surveillance cameras can play a significant role in recognizing\naccidents and alerting first responders. The utilization of action recognition\n(AR) in computer vision tasks has contributed towards high-precision\napplications in video surveillance, medical imaging, and digital signal\nprocessing. This paper presents an intensive review focusing on action\nrecognition in accident detection and autonomous transportation systems for a\nsmart city. In this paper, we focused on AR systems that used diverse sources\nof traffic video capturing, such as static surveillance cameras on traffic\nintersections, highway monitoring cameras, drone cameras, and dash-cams.\nThrough this review, we identified the primary techniques, taxonomies, and\nalgorithms used in AR for autonomous transportation and accident detection. We\nalso examined data sets utilized in the AR tasks, identifying the main sources\nof datasets and features of the datasets. This paper provides potential\nresearch direction to develop and integrate accident detection systems for\nautonomous cars and public traffic safety systems by alerting emergency\npersonnel and law enforcement in the event of road accidents to minimize human\nerror in accident reporting and provide a spontaneous response to victims",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Victor Adewopo",
      "Nelly Elsayed",
      "Zag ElSayed",
      "Murat Ozer",
      "Ahmed Abdelgawad",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09588"
  },
  {
    "id": "arXiv:2208.09590",
    "title": "Data-Driven Causal Effect Estimation Based on Graphical Causal  Modelling: A Survey",
    "abstract": "In many fields of scientific research and real-world applications, unbiased\nestimation of causal effects from non-experimental data is crucial for\nunderstanding the mechanism underlying the data and for decision-making on\neffective responses or interventions. A great deal of research has been\nconducted on this challenging problem from different angles. For causal effect\nestimation in data, assumptions such as Markov property, faithfulness and\ncausal sufficiency are always made. Under the assumptions, full knowledge such\nas, a set of covariates or an underlying causal graph, is still required. A\npractical challenge is that in many applications, no such full knowledge or\nonly some partial knowledge is available. In recent years, research has emerged\nto use a search strategy based on graphical causal modelling to discover useful\nknowledge from data for causal effect estimation, with some mild assumptions,\nand has shown promose in tackling the practical challenge. In this survey, we\nreview the methods and focus on the challenges the data-driven methods face. We\ndiscuss the assumptions, strengths and limitations of the data-driven methods.\nWe hope this review will motivate more researchers to design better data-driven\nmethods based on graphical causal modelling for the challenging problem of\ncausal effect estimation.",
    "descriptor": "\nComments: 25 pages, 7 figures and 1 table\n",
    "authors": [
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09590"
  },
  {
    "id": "arXiv:2208.09591",
    "title": "TopoDiff: A Performance and Constraint-Guided Diffusion Model for  Topology Optimization",
    "abstract": "Structural topology optimization, which aims to find the optimal physical\nstructure that maximizes mechanical performance, is vital in engineering design\napplications in aerospace, mechanical, and civil engineering. Generative\nadversarial networks (GANs) have recently emerged as a popular alternative to\ntraditional iterative topology optimization methods. However, these models are\noften difficult to train, have limited generalizability, and due to their goal\nof mimicking optimal topologies, neglect manufacturability and performance\nobjectives like mechanical compliance. We propose TopoDiff, a conditional\ndiffusion-model-based architecture to perform performance-aware and\nmanufacturability-aware topology optimization that overcomes these issues. Our\nmodel introduces a surrogate model-based guidance strategy that actively favors\nstructures with low compliance and good manufacturability. Our method\nsignificantly outperforms a state-of-art conditional GAN by reducing the\naverage error on physical performance by a factor of eight and by producing 11\ntimes fewer infeasible samples. By introducing diffusion models to topology\noptimization, we show that conditional diffusion models have the ability to\noutperform GANs in engineering design synthesis applications too. Our work also\nsuggests a general framework for engineering optimization problems using\ndiffusion models and external performance and constraint-aware guidance.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Maz\u00e9",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.09591"
  },
  {
    "id": "arXiv:2208.09592",
    "title": "Transforming the Interactive Segmentation for Medical Imaging",
    "abstract": "The goal of this paper is to interactively refine the automatic segmentation\non challenging structures that fall behind human performance, either due to the\nscarcity of available annotations or the difficulty nature of the problem\nitself, for example, on segmenting cancer or small organs. Specifically, we\npropose a novel Transformer-based architecture for Interactive Segmentation\n(TIS), that treats the refinement task as a procedure for grouping pixels with\nsimilar features to those clicks given by the end users. Our proposed\narchitecture is composed of Transformer Decoder variants, which naturally\nfulfills feature comparison with the attention mechanisms. In contrast to\nexisting approaches, our proposed TIS is not limited to binary segmentations,\nand allows the user to edit masks for arbitrary number of categories. To\nvalidate the proposed approach, we conduct extensive experiments on three\nchallenging datasets and demonstrate superior performance over the existing\nstate-of-the-art methods. The project page is: https://wtliu7.github.io/tis/.",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Wentao Liu",
      "Chaofan Ma",
      "Yuhuan Yang",
      "Weidi Xie",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09592"
  },
  {
    "id": "arXiv:2208.09595",
    "title": "The Saddle-Point Accountant for Differential Privacy",
    "abstract": "We introduce a new differential privacy (DP) accountant called the\nsaddle-point accountant (SPA). SPA approximates privacy guarantees for the\ncomposition of DP mechanisms in an accurate and fast manner. Our approach is\ninspired by the saddle-point method -- a ubiquitous numerical technique in\nstatistics. We prove rigorous performance guarantees by deriving upper and\nlower bounds for the approximation error offered by SPA. The crux of SPA is a\ncombination of large-deviation methods with central limit theorems, which we\nderive via exponentially tilting the privacy loss random variables\ncorresponding to the DP mechanisms. One key advantage of SPA is that it runs in\nconstant time for the $n$-fold composition of a privacy mechanism. Numerical\nexperiments demonstrate that SPA achieves comparable accuracy to\nstate-of-the-art accounting methods with a faster runtime.",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Wael Alghamdi",
      "Shahab Asoodeh",
      "Flavio P. Calmon",
      "Juan Felipe Gomez",
      "Oliver Kosut",
      "Lalitha Sankar",
      "Fei Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2208.09595"
  },
  {
    "id": "arXiv:2208.09596",
    "title": "Vision-Language Matching for Text-to-Image Synthesis via Generative  Adversarial Networks",
    "abstract": "Text-to-image synthesis aims to generate a photo-realistic and semantic\nconsistent image from a specific text description. The images synthesized by\noff-the-shelf models usually contain limited components compared with the\ncorresponding image and text description, which decreases the image quality and\nthe textual-visual consistency. To address this issue, we propose a novel\nVision-Language Matching strategy for text-to-image synthesis, named VLMGAN*,\nwhich introduces a dual vision-language matching mechanism to strengthen the\nimage quality and semantic consistency. The dual vision-language matching\nmechanism considers textual-visual matching between the generated image and the\ncorresponding text description, and visual-visual consistent constraints\nbetween the synthesized image and the real image. Given a specific text\ndescription, VLMGAN* firstly encodes it into textual features and then feeds\nthem to a dual vision-language matching-based generative model to synthesize a\nphoto-realistic and textual semantic consistent image. Besides, the popular\nevaluation metrics for text-to-image synthesis are borrowed from simple image\ngeneration, which mainly evaluates the reality and diversity of the synthesized\nimages. Therefore, we introduce a metric named Vision-Language Matching Score\n(VLMS) to evaluate the performance of text-to-image synthesis which can\nconsider both the image quality and the semantic consistency between\nsynthesized image and the description. The proposed dual multi-level\nvision-language matching strategy can be applied to other text-to-image\nsynthesis methods. We implement this strategy on two popular baselines, which\nare marked with ${\\text{VLMGAN}_{+\\text{AttnGAN}}}$ and\n${\\text{VLMGAN}_{+\\text{DFGAN}}}$. The experimental results on two widely-used\ndatasets show that the model achieves significant improvements over other\nstate-of-the-art methods.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Qingrong Cheng",
      "Keyu Wen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09596"
  },
  {
    "id": "arXiv:2208.09600",
    "title": "Looking For A Match: Self-supervised Clustering For Automatic Doubt  Matching In e-learning Platforms",
    "abstract": "Recently, e-learning platforms have grown as a place where students can post\ndoubts (as a snap taken with smart phones) and get them resolved in minutes.\nHowever, the significant increase in the number of student-posted doubts with\nhigh variance in quality on these platforms not only presents challenges for\nteachers' navigation to address them but also increases the resolution time per\ndoubt. Both are not acceptable, as high doubt resolution time hinders the\nstudents learning progress. This necessitates ways to automatically identify if\nthere exists a similar doubt in repository and then serve it to the teacher as\nthe plausible solution to validate and communicate with the student. Supervised\nlearning techniques (like Siamese architecture) require labels to identify the\nmatches, which is not feasible as labels are scarce and expensive. In this\nwork, we, thus, developed a label-agnostic doubt matching paradigm based on the\nrepresentations learnt via self-supervised technique. Building on prior\ntheoretical insights of BYOL (bootstrap your own latent space), we propose\ncustom BYOL which combines domain-specific augmentation with contrastive\nobjective over a varied set of appropriately constructed data views. Results\nhighlighted that, custom BYOL improves the top-1 matching accuracy by\napproximately 6\\% and 5\\% as compared to both BYOL and supervised learning\ninstances, respectively. We further show that both BYOL-based learning\ninstances performs either on par or better than human labeling.",
    "descriptor": "",
    "authors": [
      "Vedant Sandeep Joshi",
      "Sivanagaraja Tatinati",
      "Yubo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09600"
  },
  {
    "id": "arXiv:2208.09601",
    "title": "Using Multi-Encoder Fusion Strategies to Improve Personalized Response  Selection",
    "abstract": "Personalized response selection systems are generally grounded on persona.\nHowever, there exists a co-relation between persona and empathy, which is not\nexplored well in these systems. Also, faithfulness to the conversation context\nplunges when a contradictory or an off-topic response is selected. This paper\nattempts to address these issues by proposing a suite of fusion strategies that\ncapture the interaction between persona, emotion, and entailment information of\nthe utterances. Ablation studies on the Persona-Chat dataset show that\nincorporating emotion and entailment improves the accuracy of response\nselection. We combine our fusion strategies and concept-flow encoding to train\na BERT-based model which outperforms the previous methods by margins larger\nthan 2.3 % on original personas and 1.9 % on revised personas in terms of\nhits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the\nPersona-Chat dataset.",
    "descriptor": "\nComments: COLING 2022. arXiv admin note: text overlap with arXiv:2105.09050 by other authors\n",
    "authors": [
      "Souvik Das",
      "Sougata Saha",
      "Rohini K. Srihari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09601"
  },
  {
    "id": "arXiv:2208.09602",
    "title": "Analyzing Adversarial Robustness of Vision Transformers against Spatial  and Spectral Attacks",
    "abstract": "Vision Transformers have emerged as a powerful architecture that can\noutperform convolutional neural networks (CNNs) in image classification tasks.\nSeveral attempts have been made to understand robustness of Transformers\nagainst adversarial attacks, but existing studies draw inconsistent results,\ni.e., some conclude that Transformers are more robust than CNNs, while some\nothers find that they have similar degrees of robustness. In this paper, we\naddress two issues unexplored in the existing studies examining adversarial\nrobustness of Transformers. First, we argue that the image quality should be\nsimultaneously considered in evaluating adversarial robustness. We find that\nthe superiority of one architecture to another in terms of robustness can\nchange depending on the attack strength expressed by the quality of the\nattacked images. Second, by noting that Transformers and CNNs rely on different\ntypes of information in images, we formulate an attack framework, called\nFourier attack, as a tool for implementing flexible attacks, where an image can\nbe attacked in the spectral domain as well as in the spatial domain. This\nattack perturbs the magnitude and phase information of particular frequency\ncomponents selectively. Through extensive experiments, we find that\nTransformers tend to rely more on phase information and low frequency\ninformation than CNNs, and thus sometimes they are even more vulnerable under\nfrequency-selective attacks. It is our hope that this work provides new\nperspectives in understanding the properties and adversarial robustness of\nTransformers.",
    "descriptor": "\nComments: 11 pages, 13 figures\n",
    "authors": [
      "Gihyun Kim",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09602"
  },
  {
    "id": "arXiv:2208.09606",
    "title": "General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase  Generation",
    "abstract": "Training keyphrase generation (KPG) models requires a large amount of\nannotated data, which can be prohibitively expensive and often limited to\nspecific domains. In this study, we first demonstrate that large distribution\nshifts among different domains severely hinder the transferability of KPG\nmodels. We then propose a three-stage pipeline, which gradually guides KPG\nmodels' learning focus from general syntactical features to domain-related\nsemantics, in a data-efficient manner. With Domain-general Phrase pre-training,\nwe pre-train Sequence-to-Sequence models with generic phrase annotations that\nare widely available on the web, which enables the models to generate phrases\nin a wide range of domains. The resulting model is then applied in the Transfer\nLabeling stage to produce domain-specific pseudo keyphrases, which help adapt\nmodels to a new domain. Finally, we fine-tune the model with limited data with\ntrue labels to fully adapt it to the target domain. Our experiment results show\nthat the proposed process can produce good quality keyphrases in new domains\nand achieve consistent improvements after adaptation with limited in-domain\nannotated data.",
    "descriptor": "",
    "authors": [
      "Rui Meng",
      "Tong Wang",
      "Xingdi Yuan",
      "Yingbo Zhou",
      "Daqing He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09606"
  },
  {
    "id": "arXiv:2208.09610",
    "title": "MemoNav: Selecting Informative Memories for Visual Navigation",
    "abstract": "Image-goal navigation is a challenging task, as it requires the agent to\nnavigate to a target indicated by an image in a previously unseen scene.\nCurrent methods introduce diverse memory mechanisms which save navigation\nhistory to solve this task. However, these methods use all observations in the\nmemory for generating navigation actions without considering which fraction of\nthis memory is informative. To address this limitation, we present the MemoNav,\na novel memory mechanism for image-goal navigation, which retains the agent's\ninformative short-term memory and long-term memory to improve the navigation\nperformance on a multi-goal task. The node features on the agent's topological\nmap are stored in the short-term memory, as these features are dynamically\nupdated. To aid the short-term memory, we also generate long-term memory by\ncontinuously aggregating the short-term memory via a graph attention module.\nThe MemoNav retains the informative fraction of the short-term memory via a\nforgetting module based on a Transformer decoder and then incorporates this\nretained short-term memory and the long-term memory into working memory.\nLastly, the agent uses the working memory for action generation. We evaluate\nour model on a new multi-goal navigation dataset. The experimental results show\nthat the MemoNav outperforms the SoTA methods by a large margin with a smaller\nfraction of navigation history. The results also empirically show that our\nmodel is less likely to be trapped in a deadlock, which further validates that\nthe MemoNav improves the agent's navigation efficiency by reducing redundant\nsteps.",
    "descriptor": "\nComments: Submitted to ICLR2023\n",
    "authors": [
      "Hongxin Li",
      "Xu Yang",
      "Yuran Yang",
      "Shuqi Mei",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09610"
  },
  {
    "id": "arXiv:2208.09611",
    "title": "Weighted Maximum Entropy Inverse Reinforcement Learning",
    "abstract": "We study inverse reinforcement learning (IRL) and imitation learning (IM),\nthe problems of recovering a reward or policy function from expert's\ndemonstrated trajectories. We propose a new way to improve the learning process\nby adding a weight function to the maximum entropy framework, with the\nmotivation of having the ability to learn and recover the stochasticity (or the\nbounded rationality) of the expert policy. Our framework and algorithms allow\nto learn both a reward (or policy) function and the structure of the entropy\nterms added to the Markov Decision Processes, thus enhancing the learning\nprocedure. Our numerical experiments using human and simulated demonstrations\nand with discrete and continuous IRL/IM tasks show that our approach\noutperforms prior algorithms.",
    "descriptor": "",
    "authors": [
      "Viet Bui",
      "Tien Mai",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09611"
  },
  {
    "id": "arXiv:2208.09612",
    "title": "AntCritic: Argument Mining for Free-Form and Visually-Rich Financial  Comments",
    "abstract": "The task of argument mining aims to detect all possible argumentative\ncomponents and identify their relationships automatically. As a thriving field\nin natural language processing, there has been a large amount of corpus for\nacademic study and application development in argument mining. However, the\nresearch in this area is still constrained by the inherent limitations of\nexisting datasets. Specifically, all the publicly available datasets are\nrelatively small in scale, and few of them provide information from other\nmodalities to facilitate the learning process. Moreover, the statements and\nexpressions in these corpora are usually in a compact form, which means\nnon-adjacent clauses or text segments will always be regarded as multiple\nindividual components, thus restricting the generalization ability of models.\nTo this end, we collect and contribute a novel dataset AntCritic to serve as a\nhelpful complement to this area, which consists of about 10k free-form and\nvisually-rich financial comments and supports both argument component detection\nand argument relation prediction tasks. Besides, in order to cope with the\nchallenges and difficulties brought by scenario expansion and problem setting\nmodification, we thoroughly explore the fine-grained relation prediction and\nstructure reconstruction scheme for free-form documents and discuss the\nencoding mechanism for visual styles and layouts. And based on these analyses,\nwe design two simple but effective model architectures and conduct various\nexperiments on this dataset to provide benchmark performances as a reference\nand verify the practicability of our proposed architecture.",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Wenqiang Xu",
      "Xuan Lin",
      "Jingjing Huo",
      "Hong Chen",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09612"
  },
  {
    "id": "arXiv:2208.09613",
    "title": "Controlling Congestion via In-Network Content Adaptation",
    "abstract": "Realizing that it is inherently difficult to precisely match the sending\nrates at the endhost with the available capacity on dynamic cellular links, we\nbuild a system, Octopus, that sends real-time data streams over cellular\nnetworks using an imprecise controller (that errs on the side of\nover-estimating network capacity), and then drops appropriate packets in the\ncellular network buffers to match the actual capacity. We design parameterized\nprimitives for implementing the packet dropping logic, that the applications at\nthe endhost can configure differently to express different content adaptation\npolicies. Octopus transport encodes the app-specified parameters in packet\nheader fields, which the routers parse to execute the desired dropping\nbehavior. Our evaluation shows how real-time applications involving standard\nand volumetric videos can be designed to exploit Octopus, and achieve 1.5-50\ntimes better performance than state-of-the-art schemes.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Yongzhou Chen",
      "Ammar Tahir",
      "Radhika Mittal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.09613"
  },
  {
    "id": "arXiv:2208.09614",
    "title": "An ensemble meta-estimator to predict source code testability",
    "abstract": "Software testing could be a lengthy and costly process, especially if the\nsoftware under test is not testable. Refactoring techniques may enhance\ntestability by improving the software metrics affecting testability. The\nmetrics are determined while building regression models learning how to relate\nmetrics computed for a source code to its testability. We identified 15\nsoftware metrics highly affecting testability while interpreting our\ntestability prediction model. Our experiments with 42 java classes reveal that\nrefactorings that improve these 15 metrics could enhance testability by an\naverage of 15.57%, besides improving some other quality attributes. Our\ntestability prediction model is trained to map source code metrics to test\neffectiveness and efficiency as two significant ingredients of testable\nsoftware. Test effectiveness improves as the coverage gained by the test suite\nincreases. On the other hand, the test efficiency reduces as the size of the\ntest suite increases. This article offers a mathematical model to compute class\ntestability in terms of the size and coverage of the test suite. We use this\nmathematical model to compute testability as the target of our testability\nprediction model. The mathematical model requires the execution of the class\nunder test to compute test coverage, while our regression model measures\ntestability statically. Prediction of test results in terms of testability\nshould precede the test to avoid unnecessary costs. Our testability prediction\nmodel has been trained and tested on 23,886 Java classes and 262 software\nmetrics. The learned model predicts testability with an R2 of 0.68 and a mean\nsquared error of 0.03.",
    "descriptor": "\nComments: 33 pages, 10 figures\n",
    "authors": [
      "Morteza Zakeri-Nasrabadi",
      "Saeed Parsa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09614"
  },
  {
    "id": "arXiv:2208.09615",
    "title": "Reconfigurable Intelligent Surfaces and Capacity Optimization: A Large  System Analysis",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs), comprising large numbers of\nlow-cost and almost passive metamaterials with tunable reflection properties,\nhave been recently proposed as an enabling technology for programmable wireless\npropagation environments. In this paper, we present asymptotic closed-form\nexpressions for the mean and variance of the mutual information metric for a\nmulti-antenna transmitter-receiver pair in the presence of multiple RISs, using\nmethods from statistical physics. While nominally valid in the large system\nlimit, we show that the derived Gaussian approximation for the mutual\ninformation can be quite accurate, even for modest-sized antenna arrays and\nmetasurfaces. The above results are particularly useful when fast-fading\nconditions are present, which renders instantaneous channel estimation\nextremely challenging. We find that, when the channel close to an RIS is\ncorrelated, for instance due to small angle spread, which is reasonable for\nwireless systems with increasing carrier frequencies, the communication link\nbenefits significantly from statistical RIS phase optimization, resulting in\ngains that are surprisingly higher than the nearly uncorrelated case. Using our\nnovel asymptotic properties of the correlation matrices of the impinging and\noutgoing signals at the RISs, we can optimize the metasurfaces without\nbrute-force numerical optimization. Furthermore, when the desired reflection\nfrom any of the RISs departs significantly from geometrical optics, the\nmetasurfaces can be optimized to provide robust communication links, without\nsignificant need for their optimal placement.",
    "descriptor": "\nComments: 14 pages, 7 figures, submitted to an IEEE Transactions journal. arXiv admin note: text overlap with arXiv:2109.07754\n",
    "authors": [
      "Aris L. Moustakas",
      "George C. Alexandropoulos",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2208.09615"
  },
  {
    "id": "arXiv:2208.09616",
    "title": "Applications of a space-time FOSLS formulation for parabolic PDEs",
    "abstract": "In this work, we show that the space-time first-order system least-squares\n(FOSLS) formulation [F\\\"uhrer, Karkulik, Comput. Math. Appl. 92 (2021)] for the\nheat equation and its recent generalization [Gantner, Stevenson, ESAIM Math.\nModel. Numer. Anal. 55 (2021)] to arbitrary second-order parabolic PDEs can be\nused to efficiently solve parameter-dependent problems, optimal control\nproblems, and problems on time-dependent spatial domains.",
    "descriptor": "",
    "authors": [
      "Gregor Gantner",
      "Rob Stevenson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09616"
  },
  {
    "id": "arXiv:2208.09617",
    "title": "Pretrained Language Encoders are Natural Tagging Frameworks for Aspect  Sentiment Triplet Extraction",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract the spans of\naspect, opinion, and their sentiment relations as sentiment triplets. Existing\nworks usually formulate the span detection as a 1D token tagging problem, and\nmodel the sentiment recognition with a 2D tagging matrix of token pairs.\nMoreover, by leveraging the token representation of Pretrained Language\nEncoders (PLEs) like BERT, they can achieve better performance. However, they\nsimply leverage PLEs as feature extractors to build their modules but never\nhave a deep look at what specific knowledge does PLEs contain. In this paper,\nwe argue that instead of further designing modules to capture the inductive\nbias of ASTE, PLEs themselves contain \"enough\" features for 1D and 2D tagging:\n(1) The token representation contains the contextualized meaning of token\nitself, so this level feature carries necessary information for 1D tagging. (2)\nThe attention matrix of different PLE layers can further capture multi-level\nlinguistic knowledge existing in token pairs, which benefits 2D tagging. (3)\nFurthermore, with simple transformations, these two features can also be easily\nconverted to the 2D tagging matrix and 1D tagging sequence, respectively. That\nwill further boost the tagging results. By doing so, PLEs can be natural\ntagging frameworks and achieve a new state of the art, which is verified by\nextensive experiments and deep analyses.",
    "descriptor": "",
    "authors": [
      "Yanjie Gou",
      "Yinjie Lei",
      "Lingqiao Liu",
      "Yong Dai",
      "Chunxu Shen",
      "Yongqi Tong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09617"
  },
  {
    "id": "arXiv:2208.09618",
    "title": "Fully Automated End-to-End Fake Audio Detection",
    "abstract": "The existing fake audio detection systems often rely on expert experience to\ndesign the acoustic features or manually design the hyperparameters of the\nnetwork structure. However, artificial adjustment of the parameters can have a\nrelatively obvious influence on the results. It is almost impossible to\nmanually set the best set of parameters. Therefore this paper proposes a fully\nautomated end-toend fake audio detection method. We first use wav2vec\npre-trained model to obtain a high-level representation of the speech.\nFurthermore, for the network structure, we use a modified version of the\ndifferentiable architecture search (DARTS) named light-DARTS. It learns deep\nspeech representations while automatically learning and optimizing complex\nneural structures consisting of convolutional operations and residual blocks.\nThe experimental results on the ASVspoof 2019 LA dataset show that our proposed\nsystem achieves an equal error rate (EER) of 1.08%, which outperforms the\nstate-of-the-art single system.",
    "descriptor": "",
    "authors": [
      "Chenglong Wang",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Haiyang Sun",
      "Xun Chen",
      "Zhengkun Tian",
      "Haoxin Ma",
      "Cunhang Fan",
      "Ruibo Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.09618"
  },
  {
    "id": "arXiv:2208.09619",
    "title": "A Novel Hybrid Sampling Framework for Imbalanced Learning",
    "abstract": "Class imbalance is a frequently occurring scenario in classification tasks.\nLearning from imbalanced data poses a major challenge, which has instigated a\nlot of research in this area. Data preprocessing using sampling techniques is a\nstandard approach to deal with the imbalance present in the data. Since\nstandard classification algorithms do not perform well on imbalanced data, the\ndataset needs to be adequately balanced before training. This can be\naccomplished by oversampling the minority class or undersampling the majority\nclass. In this study, a novel hybrid sampling algorithm has been proposed. To\novercome the limitations of the sampling techniques while ensuring the quality\nof the retained sampled dataset, a sophisticated framework has been developed\nto properly combine three different sampling techniques. Neighborhood Cleaning\nrule is first applied to reduce the imbalance. Random undersampling is then\nstrategically coupled with the SMOTE algorithm to obtain an optimal balance in\nthe dataset. This proposed hybrid methodology, termed \"SMOTE-RUS-NC\", has been\ncompared with other state-of-the-art sampling techniques. The strategy is\nfurther incorporated into the ensemble learning framework to obtain a more\nrobust classification algorithm, termed \"SRN-BRF\". Rigorous experimentation has\nbeen conducted on 26 imbalanced datasets with varying degrees of imbalance. In\nvirtually all datasets, the proposed two algorithms outperformed existing\nsampling strategies, in many cases by a substantial margin. Especially in\nhighly imbalanced datasets where popular sampling techniques failed utterly,\nthey achieved unparalleled performance. The superior results obtained\ndemonstrate the efficacy of the proposed models and their potential to be\npowerful sampling algorithms in imbalanced domain.",
    "descriptor": "\nComments: Submitted to \"Expert Systems with Applications\"\n",
    "authors": [
      "Asif Newaz",
      "Farhan Shahriyar Haq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09619"
  },
  {
    "id": "arXiv:2208.09623",
    "title": "Learning to predict test effectiveness",
    "abstract": "The high cost of the test can be dramatically reduced, provided that the\ncoverability as an inherent feature of the code under test is predictable. This\narticle offers a machine learning model to predict the extent to which the test\ncould cover a class in terms of a new metric called Coverageability. The\nprediction model consists of an ensemble of four regression models. The\nlearning samples consist of feature vectors, where features are source code\nmetrics computed for a class. The samples are labeled by the Coverageability\nvalues computed for their corresponding classes. We offer a mathematical model\nto evaluate test effectiveness in terms of size and coverage of the test suite\ngenerated automatically for each class. We extend the size of the feature space\nby introducing a new approach to defining sub-metrics in terms of existing\nsource code metrics. Using feature importance analysis on the learned\nprediction models, we sort source code metrics in the order of their impact on\nthe test effectiveness. As a result of which, we found the class strict\ncyclomatic complexity as the most influential source code metric. Our\nexperiments with the prediction models on a large corpus of Java projects\ncontaining about 23,000 classes demonstrate the Mean Absolute Error (MAE) of\n0.032, Mean Squared Error (MSE) of 0.004, and an R2-score of 0.855. Compared\nwith the state-of-the-art coverage prediction models, our models improve MAE,\nMSE, and an R2-score by 5.78%, 2.84%, and 20.71%, respectively.",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Morteza Zakeri-Nasrabadi",
      "Saeed Parsa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09623"
  },
  {
    "id": "arXiv:2208.09625",
    "title": "Representing Knowledge by Spans: A Knowledge-Enhanced Model for  Information Extraction",
    "abstract": "Knowledge-enhanced pre-trained models for language representation have been\nshown to be more effective in knowledge base construction tasks (i.e.,~relation\nextraction) than language models such as BERT. These knowledge-enhanced\nlanguage models incorporate knowledge into pre-training to generate\nrepresentations of entities or relationships. However, existing methods\ntypically represent each entity with a separate embedding. As a result, these\nmethods struggle to represent out-of-vocabulary entities and a large amount of\nparameters, on top of their underlying token models (i.e.,~the transformer),\nmust be used and the number of entities that can be handled is limited in\npractice due to memory constraints. Moreover, existing models still struggle to\nrepresent entities and relationships simultaneously. To address these problems,\nwe propose a new pre-trained model that learns representations of both entities\nand relationships from token spans and span pairs in the text respectively. By\nencoding spans efficiently with span modules, our model can represent both\nentities and their relationships but requires fewer parameters than existing\nmodels. We pre-trained our model with the knowledge graph extracted from\nWikipedia and test it on a broad range of supervised and unsupervised\ninformation extraction tasks. Results show that our model learns better\nrepresentations for both entities and relationships than baselines, while in\nsupervised settings, fine-tuning our model outperforms RoBERTa consistently and\nachieves competitive results on information extraction tasks.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Jiacheng Li",
      "Yannis Katsis",
      "Tyler Baldwin",
      "Ho-Cheol Kim",
      "Andrew Bartko",
      "Julian McAuley",
      "Chun-Nan Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09625"
  },
  {
    "id": "arXiv:2208.09626",
    "title": "Persuasion Strategies in Advertisements: Dataset, Modeling, and  Baselines",
    "abstract": "Modeling what makes an advertisement persuasive, i.e., eliciting the desired\nresponse from consumer, is critical to the study of propaganda, social\npsychology, and marketing. Despite its importance, computational modeling of\npersuasion in computer vision is still in its infancy, primarily due to the\nlack of benchmark datasets that can provide persuasion-strategy labels\nassociated with ads. Motivated by persuasion literature in social psychology\nand marketing, we introduce an extensive vocabulary of persuasion strategies\nand build the first ad image corpus annotated with persuasion strategies. We\nthen formulate the task of persuasion strategy prediction with multi-modal\nlearning, where we design a multi-task attention fusion model that can leverage\nother ad-understanding tasks to predict persuasion strategies. Further, we\nconduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500\ncompanies where we use our model's predictions to analyze which strategies work\nwith different demographics (age and gender). The dataset also provides image\nsegmentation masks, which labels persuasion strategies in the corresponding ad\nimages on the test split. We publicly release our code and dataset\nhttps://midas-research.github.io/persuasion-advertisements/.",
    "descriptor": "",
    "authors": [
      "Yaman Kumar Singla",
      "Rajat Jha",
      "Arunim Gupta",
      "Milan Aggarwal",
      "Aditya Garg",
      "Ayush Bhardwaj",
      "Tushar",
      "Balaji Krishnamurthy",
      "Rajiv Ratn Shah",
      "Changyou Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09626"
  },
  {
    "id": "arXiv:2208.09627",
    "title": "Phase Shift-Free Passive Beamforming for Reconfigurable Intelligent  Surfaces",
    "abstract": "Reconfigurable intelligent surface (RIS)-assisted communications recently\nappeared as a game-changing technology for next-generation wireless\ncommunications due to its unprecedented ability to reform the propagation\nenvironment. One of the main aspects of using RISs is the exploitation of the\nso-called passive beamforming (PB), which is carried out by adjusting the\nreflection coefficients (mainly the phase shifts) of the individual RIS\nelements. However, practically, this individual phase shift adjustment is\nassociated with many issues in hardware implementation, limiting the RIS\nachievable gain. In this paper, we propose a low-cost, phase shift-free and\nnovel PB scheme by only optimizing the on/off states of the RIS elements while\nfixing their phase shifts. The proposed PB scheme is shown to achieve the same\nscaling law (quadratic growth with the RIS size) for the signal-to-noise ratio\nas in the classical phase shift-based PB scheme, yet, with far less sensitivity\nto spatial correlation and phase errors. We provide a unified mathematical\nanalysis that characterizes the performance of the proposed PB scheme and\nobtain the outage probability for the considered RIS-assisted system. Based on\nthe provided computer simulations, the proposed PB scheme is shown to have a\nclear superiority over the classical one under different performance metrics.",
    "descriptor": "\nComments: To appear in IEEE TCOM\n",
    "authors": [
      "Aymen Khaleel",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.09627"
  },
  {
    "id": "arXiv:2208.09628",
    "title": "Are You Comfortable Now: Deep Learning the Temporal Variation in Thermal  Comfort in Winters",
    "abstract": "Indoor thermal comfort in smart buildings has a significant impact on the\nhealth and performance of occupants. Consequently, machine learning (ML) is\nincreasingly used to solve challenges related to indoor thermal comfort.\nTemporal variability of thermal comfort perception is an important problem that\nregulates occupant well-being and energy consumption. However, in most ML-based\nthermal comfort studies, temporal aspects such as the time of day, circadian\nrhythm, and outdoor temperature are not considered. This work addresses these\nproblems. It investigates the impact of circadian rhythm and outdoor\ntemperature on the prediction accuracy and classification performance of ML\nmodels. The data is gathered through month-long field experiments carried out\nin 14 classrooms of 5 schools, involving 512 primary school students. Four\nthermal comfort metrics are considered as the outputs of Deep Neural Networks\nand Support Vector Machine models for the dataset. The effect of temporal\nvariability on school children's comfort is shown through a \"time of day\"\nanalysis. Temporal variability in prediction accuracy is demonstrated (up to\n80%). Furthermore, we show that outdoor temperature (varying over time)\npositively impacts the prediction performance of thermal comfort models by up\nto 30%. The importance of spatio-temporal context is demonstrated by\ncontrasting micro-level (location specific) and macro-level (6 locations across\na city) performance. The most important finding of this work is that a\ndefinitive improvement in prediction accuracy is shown with an increase in the\ntime of day and sky illuminance, for multiple thermal comfort metrics.",
    "descriptor": "\nComments: Accepted for publication in IEEE SMC 2022\n",
    "authors": [
      "Betty Lala",
      "Srikant Manas Kala",
      "Anmol Rastogi",
      "Kunal Dahiya",
      "Aya Hagishima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09628"
  },
  {
    "id": "arXiv:2208.09632",
    "title": "Adam Can Converge Without Any Modification on Update Rules",
    "abstract": "Ever since Reddi et al. 2018 pointed out the divergence issue of Adam, many\nnew variants have been designed to obtain convergence. However, vanilla Adam\nremains exceptionally popular and it works well in practice. Why is there a gap\nbetween theory and practice? We point out there is a mismatch between the\nsettings of theory and practice: Reddi et al. 2018 pick the problem after\npicking the hyperparameters of Adam, i.e., $(\\beta_1, \\beta_2)$; while\npractical applications often fix the problem first and then tune $(\\beta_1,\n\\beta_2)$. Due to this observation, we conjecture that the empirical\nconvergence can be theoretically justified, only if we change the order of\npicking the problem and hyperparameter. In this work, we confirm this\nconjecture. We prove that, when $\\beta_2$ is large and $\\beta_1 <\n\\sqrt{\\beta_2}<1$, Adam converges to the neighborhood of critical points. The\nsize of the neighborhood is propositional to the variance of stochastic\ngradients. Under an extra condition (strong growth condition), Adam converges\nto critical points. As $\\beta_2$ increases, our convergence result can cover\nany $\\beta_1 \\in [0,1)$ including $\\beta_1=0.9$, which is the default setting\nin deep learning libraries. Our result shows that Adam can converge under a\nwide range of hyperparameters without any modification on its update rules. To\nour knowledge, we are the first to prove this result without strong assumptions\nsuch as bounded gradients. When $\\beta_2$ is small, we further point out a\nlarge region of $(\\beta_1,\\beta_2)$ where Adam can diverge to infinity. Our\ndivergence result considers the same setting as our convergence result,\nindicating a phase transition from divergence to convergence when increasing\n$\\beta_2$. These positive and negative results can provide suggestions on how\nto tune Adam hyperparameters.",
    "descriptor": "\nComments: 66 pages\n",
    "authors": [
      "Yushun Zhang",
      "Congliang Chen",
      "Naichen Shi",
      "Ruoyu Sun",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09632"
  },
  {
    "id": "arXiv:2208.09634",
    "title": "An $O(k\\log n)$ Time Fourier Set Query Algorithm",
    "abstract": "Fourier transformation is an extensively studied problem in many research\nfields. It has many applications in machine learning, signal processing,\ncompressed sensing, and so on. In many real-world applications, approximated\nFourier transformation is sufficient and we only need to do the Fourier\ntransform on a subset of coordinates. Given a vector $x \\in \\mathbb{C}^{n}$, an\napproximation parameter $\\epsilon$ and a query set $S \\subset [n]$ of size $k$,\nwe propose an algorithm to compute an approximate Fourier transform result $x'$\nwhich uses $O(\\epsilon^{-1} k \\log(n/\\delta))$ Fourier measurements, runs in\n$O(\\epsilon^{-1} k \\log(n/\\delta))$ time and outputs a vector $x'$ such that\n$\\| ( x' - \\widehat{x} )_S \\|_2^2 \\leq \\epsilon \\| \\widehat{x}_{\\bar{S}} \\|_2^2\n+ \\delta \\| \\widehat{x} \\|_1^2 $ holds with probability of at least $9/10$.",
    "descriptor": "",
    "authors": [
      "Yeqi Gao",
      "Zhao Song",
      "Baocheng Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09634"
  },
  {
    "id": "arXiv:2208.09635",
    "title": "Mobile Robot Navigation in Complex Polygonal Workspaces Using Conformal  Navigation Transformations",
    "abstract": "This work proposes a novel transformation termed the conformal navigation\ntransformation to achieve collision-free navigation of a robot in a workspace\npopulated with arbitrary polygonal obstacles. The properties of the conformal\nnavigation transformation in the polygonal workspace are investigated in this\nwork as well as its capability to provide a solution to the navigation problem.\n%The properties of the conformal navigation transformation are investigated,\nwhich contribute to the solution of the robot navigation problem in complex\npolygonal environments. %which facilitates the navigation of robots in complex\nenvironments. The definition of the navigation function is generalized to\naccommodate non-smooth obstacle boundaries. Based on the proposed\ntransformation and the generalized navigation function, a provably correct\nfeedback controller is derived for the automatic guidance and motion control of\nthe kinematic mobile robot. Moreover, an iterative method is proposed to\nconstruct the conformal navigation transformation in a multi-connected\npolygonal workspace, which transforms the multi-connected problem into multiple\nsingle-connected problems to achieve fast convergence.In addition to the\nanalytic guarantees, the simulation study verifies the effectiveness of the\nproposed methodology in a workspace with non-trivial polygonal obstacles.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.06876\n",
    "authors": [
      "Li Fan",
      "Jianchang Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09635"
  },
  {
    "id": "arXiv:2208.09639",
    "title": "Mesh Quality Agglomeration algorithm for the Virtual Element Method  applied to Discrete Fracture Networks",
    "abstract": "We propose a quality-based optimization strategy to reduce the total number\nof degrees of freedom associated to a discrete problem defined over a polygonal\ntessellation with the Virtual Element Method. The presented Quality\nAgglomeration algorithm relies only on the geometrical properties of the\nproblem polygonal mesh, agglomerating groups of neighboring elements. We test\nthis approach in the context of fractured porous media, in which the generation\nof a global conforming mesh on a Discrete Fracture Network leads to a\nconsiderable number of unknowns, due to the presence of highly complex\ngeometries and the significant size of the computational domains. We show the\nefficiency and the robustness of our approach, applied independently on each\nfracture for different network configurations, exploiting the flexibility of\nthe Virtual Element Method in handling general polygonal elements.",
    "descriptor": "",
    "authors": [
      "Tommaso Sorgente",
      "Fabio Vicini",
      "Stefano Berrone",
      "Silvia Biasotti",
      "Gianmarco Manzini",
      "Michela Spagnuolo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09639"
  },
  {
    "id": "arXiv:2208.09643",
    "title": "The computational complexity of some explainable clustering problems",
    "abstract": "We study the computational complexity of some explainable clustering problems\nin the framework proposed by [Dasgupta et al., ICML 2020], where explainability\nis achieved via axis-aligned decision trees. We consider the $k$-means,\n$k$-medians, $k$-centers and the spacing cost functions. We prove that the\nfirst three are hard to optimize while the latter can be optimized in\npolynomial time.",
    "descriptor": "\nComments: 14 pages and 1 figure\n",
    "authors": [
      "Eduardo Sany Laber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09643"
  },
  {
    "id": "arXiv:2208.09646",
    "title": "An Initial Investigation for Detecting Vocoder Fingerprints of Fake  Audio",
    "abstract": "Many effective attempts have been made for fake audio detection. However,\nthey can only provide detection results but no countermeasures to curb this\nharm. For many related practical applications, what model or algorithm\ngenerated the fake audio also is needed. Therefore, We propose a new problem\nfor detecting vocoder fingerprints of fake audio. Experiments are conducted on\nthe datasets synthesized by eight state-of-the-art vocoders. We have\npreliminarily explored the features and model architectures. The t-SNE\nvisualization shows that different vocoders generate distinct vocoder\nfingerprints.",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2022 Workshop: First International Workshop on Deepfake Detection for Audio Multimedia\n",
    "authors": [
      "Xinrui Yan",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chenglong Wang",
      "Haoxin Ma",
      "Tao Wang",
      "Shiming Wang",
      "Ruibo Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.09646"
  },
  {
    "id": "arXiv:2208.09650",
    "title": "Visual Exploratory Data Analysis of the Covid-19 Vaccination Progress in  Nigeria",
    "abstract": "The coronavirus outbreak in 2020 devastated the world's economy, including\nNigeria, even resulted in a severe recession. Slowly the country is building\nback again, and the vaccines are helping to reduce the spread of covid-19.\nSince the covid-19 vaccine came to Nigeria; 18,728,188 people have been fully\nvaccinated as at May 31st, 2022. This is roughly 10% of the Nigerian population\nestimated at 206.7 million [1]. This paper presents a visual Exploratory Data\nAnalysis of the covid-19 vaccination progress in Nigeria using the R-tidyverse\npackage in R studio IDE for data cleaning & analysis, and Tableau for the\nvisualizations. Our dataset is from the Nigerian National Primary Health Care\nDevelopment Agency (NPHCDA) in charge of the vaccines. The data used for this\nresearch contain the state-by-state breakdown of Covid-19 vaccine distribution\nrecorded between March 5th, 2021, and May 31st, 2022. This paper aims to show\nhow these data analytics tools and techniques can be useful in finding insights\nin raw data by presenting the results of the EDA visually thus reducing the\nambiguity and possible confusions that is associated with data in tables.\nFurthermore, our findings contribute to the growing literature on Covid-19\nresearch by showcasing the Covid-19 vaccination trend in Nigeria and the state\nby state distribution.",
    "descriptor": "",
    "authors": [
      "Ugochukwu Orji",
      "Chikodili Ugwuishiwu",
      "Mathew Okoronkwo",
      "Caroline Asogwa",
      "Nnaemeka Ogbene"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.09650"
  },
  {
    "id": "arXiv:2208.09652",
    "title": "Few-Shot Learning of Accurate Folding Landscape for Protein Structure  Prediction",
    "abstract": "Data-driven predictive methods which can efficiently and accurately transform\nprotein sequences into biologically active structures are highly valuable for\nscientific research and therapeutical development. Determining accurate folding\nlandscape using co-evolutionary information is fundamental to the success of\nmodern protein structure prediction methods. As the state of the art,\nAlphaFold2 has dramatically raised the accuracy without performing explicit\nco-evolutionary analysis. Nevertheless, its performance still shows strong\ndependence on available sequence homologs. We investigated the cause of such\ndependence and presented EvoGen, a meta generative model, to remedy the\nunderperformance of AlphaFold2 for poor MSA targets. EvoGen allows us to\nmanipulate the folding landscape either by denoising the searched MSA or by\ngenerating virtual MSA, and helps AlphaFold2 fold accurately in low-data regime\nor even achieve encouraging performance with single-sequence predictions. Being\nable to make accurate predictions with few-shot MSA not only generalizes\nAlphaFold2 better for orphan sequences, but also democratizes its use for\nhigh-throughput applications. Besides, EvoGen combined with AlphaFold2 yields a\nprobabilistic structure generation method which could explore alternative\nconformations of protein sequences, and the task-aware differentiable algorithm\nfor sequence generation will benefit other related tasks including protein\ndesign.",
    "descriptor": "\nComments: version 1.0; 18 pages, 6 figures\n",
    "authors": [
      "Jun Zhang",
      "Sirui Liu",
      "Mengyun Chen",
      "Haotian Chu",
      "Min Wang",
      "Zidong Wang",
      "Jialiang Yu",
      "Ningxi Ni",
      "Fan Yu",
      "Diqing Chen",
      "Yi Isaac Yang",
      "Boxin Xue",
      "Lijiang Yang",
      "Yuan Liu",
      "Yi Qin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.09652"
  },
  {
    "id": "arXiv:2208.09656",
    "title": "A Domain Generalization Approach for Out-Of-Distribution 12-lead ECG  Classification with Convolutional Neural Networks",
    "abstract": "Deep Learning systems have achieved great success in the past few years, even\nsurpassing human intelligence in several cases. As of late, they have also\nestablished themselves in the biomedical and healthcare domains, where they\nhave shown a lot of promise, but have not yet achieved widespread adoption.\nThis is in part due to the fact that most methods fail to maintain their\nperformance when they are called to make decisions on data that originate from\na different distribution than the one they were trained on, namely\nOut-Of-Distribution (OOD) data. For example, in the case of biosignal\nclassification, models often fail to generalize well on datasets from different\nhospitals, due to the distribution discrepancy amongst different sources of\ndata. Our goal is to demonstrate the Domain Generalization problem present\nbetween distinct hospital databases and propose a method that classifies\nabnormalities on 12-lead Electrocardiograms (ECGs), by leveraging information\nextracted across the architecture of a Deep Neural Network, and capturing the\nunderlying structure of the signal. To this end, we adopt a ResNet-18 as the\nbackbone model and extract features from several intermediate convolutional\nlayers of the network. To evaluate our method, we adopt publicly available ECG\ndatasets from four sources and handle them as separate domains. To simulate the\ndistributional shift present in real-world settings, we train our model on a\nsubset of the domains and leave-out the remaining ones. We then evaluate our\nmodel both on the data present at training time (intra-distribution) and the\nheld-out data (out-of-distribution), achieving promising results and surpassing\nthe baseline of a vanilla Residual Network in most of the cases.",
    "descriptor": "\nComments: This paper has been accepted at: IEEE BigDataService2022 (this http URL)\n",
    "authors": [
      "Aristotelis Ballas",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09656"
  },
  {
    "id": "arXiv:2208.09657",
    "title": "A Visual Analytics Framework for Composing a Hierarchical Classification  for Medieval Illuminations",
    "abstract": "Annotated data is a requirement for applying supervised machine learning\nmethods, and the quality of annotations is crucial for the result. Especially\nwhen working with cultural heritage collections that inhere a manifold of\nuncertainties, annotating data remains a manual, arduous task to be carried out\nby domain experts. Our project started with two already annotated sets of\nmedieval manuscript images which however were incomplete and comprised\nconflicting metadata based on scholarly and linguistic differences. Our aims\nwere to create (1) a uniform set of descriptive labels for the combined data\nset, and (2) a hierarchical classification of a high quality that can be used\nas a valuable input for supervised machine learning. To reach these goals, we\ndeveloped a visual analytics system to enable medievalists to combine,\nregularize and extend the vocabulary used to describe these data sets. Visual\ninterfaces for word and image embeddings as well as co-occurrences of the\nannotations across the data sets enable annotating multiple images at the same\ntime, recommend annotation label candidates and support composing a\nhierarchical classification of labels. Our system itself implements a\nsemi-supervised method as it updates visual representations based on the\nmedievalists' feedback, and a series of usage scenarios document its value for\nthe target community.",
    "descriptor": "",
    "authors": [
      "Christofer Meinecke",
      "Estelle Gu\u00e9ville",
      "David Joseph Wrisley",
      "Stefan J\u00e4nicke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.09657"
  },
  {
    "id": "arXiv:2208.09658",
    "title": "A biologically-inspired evaluation of molecular generative machine  learning",
    "abstract": "While generative models have recently become ubiquitous in many scientific\nareas, less attention has been paid to their evaluation. For molecular\ngenerative models, the state-of-the-art examines their output in isolation or\nin relation to its input. However, their biological and functional properties,\nsuch as ligand-target interaction is not being addressed. In this study, a\nnovel biologically-inspired benchmark for the evaluation of molecular\ngenerative models is proposed. Specifically, three diverse reference datasets\nare designed and a set of metrics are introduced which are directly relevant to\nthe drug discovery process. In particular we propose a recreation metric, apply\ndrug-target affinity prediction and molecular docking as complementary\ntechniques for the evaluation of generative outputs. While all three metrics\nshow consistent results across the tested generative models, a more detailed\ncomparison of drug-target affinity binding and molecular docking scores\nrevealed that unimodal predictiors can lead to erroneous conclusions about\ntarget binding on a molecular level and a multi-modal approach is thus\npreferrable. The key advantage of this framework is that it incorporates prior\nphysico-chemical domain knowledge into the benchmarking process by focusing\nexplicitly on ligand-target interactions and thus creating a highly efficient\ntool not only for evaluating molecular generative outputs in particular, but\nalso for enriching the drug discovery process in general.",
    "descriptor": "\nComments: 59 pages, 26 figures Project GitHub repository, this https URL\n",
    "authors": [
      "Elizaveta Vinogradova",
      "Abay Artykbayev",
      "Alisher Amanatay",
      "Mukhamejan Karatayev",
      "Maxim Mametkulov",
      "Albina Li",
      "Anuar Suleimenov",
      "Abylay Salimzhanov",
      "Karina Pats",
      "Rustam Zhumagambetov",
      "Ferdinand Moln\u00e1r",
      "Vsevolod Peshkov",
      "Siamac Fazli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.09658"
  },
  {
    "id": "arXiv:2208.09659",
    "title": "Trigger-free Event Detection via Derangement Reading Comprehension",
    "abstract": "Event detection (ED), aiming to detect events from texts and categorize them,\nis vital to understanding actual happenings in real life. However, mainstream\nevent detection models require high-quality expert human annotations of\ntriggers, which are often costly and thus deter the application of ED to new\ndomains. Therefore, in this paper, we focus on low-resource ED without triggers\nand aim to tackle the following formidable challenges: multi-label\nclassification, insufficient clues, and imbalanced events distribution. We\npropose a novel trigger-free ED method via Derangement mechanism on a machine\nReading Comprehension (DRC) framework. More specifically, we treat the input\ntext as Context and concatenate it with all event type tokens that are deemed\nas Answers with an omitted default question. So we can leverage the\nself-attention in pre-trained language models to absorb semantic relations\nbetween input text and the event types. Moreover, we design a simple yet\neffective event derangement module (EDM) to prevent major events from being\nexcessively learned so as to yield a more balanced training process. The\nexperiment results show that our proposed trigger-free ED model is remarkably\ncompetitive to mainstream trigger-based models, showing its strong performance\non low-source event detection.",
    "descriptor": "",
    "authors": [
      "Jiachen Zhao",
      "Haiqin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09659"
  },
  {
    "id": "arXiv:2208.09660",
    "title": "From Time Series to Networks in R with the ts2net Package",
    "abstract": "Network science established itself as a prominent tool for modeling time\nseries and complex systems. This modeling process consists of transforming a\nset or a single time series into a network. Nodes may represent complete time\nseries, segments, or single values, while links define associations or\nsimilarities between the represented parts. R is one of the main programming\nlanguages used in data science, statistics, and machine learning, with many\npackages available. However, no single package provides the necessary methods\nto transform time series into networks. This paper presents ts2net, an R\npackage for modeling one or multiple time series into networks. The package\nprovides the time series distance functions that can be easily computed in\nparallel and in supercomputers to process larger data sets and methods to\ntransform distance matrices into networks. Ts2net also provides methods to\ntransform a single time series into a network, such as recurrence networks,\nvisibility graphs, and transition networks. Together with other packages,\nts2net permits using network science and graph mining tools to extract\ninformation from time series.",
    "descriptor": "",
    "authors": [
      "Leonardo N. Ferreira"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09660"
  },
  {
    "id": "arXiv:2208.09662",
    "title": "Offline Handwritten Mathematical Recognition using Adversarial Learning  and Transformers",
    "abstract": "Offline Handwritten Mathematical Expression Recognition (HMER) is a major\narea in the field of mathematical expression recognition. Offline HMER is often\nviewed as a much harder problem as compared to online HMER due to a lack of\ntemporal information and variability in writing style. In this paper, we\npurpose a encoder-decoder model that uses paired adversarial learning.\nSemantic-invariant features are extracted from handwritten mathematical\nexpression images and their printed mathematical expression counterpart in the\nencoder. Learning of semantic-invariant features combined with the DenseNet\nencoder and transformer decoder, helped us to improve the expression rate from\nprevious studies. Evaluated on the CROHME dataset, we have been able to improve\nlatest CROHME 2019 test set results by 4% approx.",
    "descriptor": "",
    "authors": [
      "Ujjwal Thakur",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09662"
  },
  {
    "id": "arXiv:2208.09665",
    "title": "Visual Analysis of Neural Architecture Spaces for Summarizing Design  Principles",
    "abstract": "Recent advances in artificial intelligence largely benefit from better neural\nnetwork architectures. These architectures are a product of a costly process of\ntrial-and-error. To ease this process, we develop ArchExplorer, a visual\nanalysis method for understanding a neural architecture space and summarizing\ndesign principles. The key idea behind our method is to make the architecture\nspace explainable by exploiting structural distances between architectures. We\nformulate the pairwise distance calculation as solving an all-pairs shortest\npath problem. To improve efficiency, we decompose this problem into a set of\nsingle-source shortest path problems. The time complexity is reduced from\nO(kn^2N) to O(knN). Architectures are hierarchically clustered according to the\ndistances between them. A circle-packing-based architecture visualization has\nbeen developed to convey both the global relationships between clusters and\nlocal neighborhoods of the architectures in each cluster. Two case studies and\na post-analysis are presented to demonstrate the effectiveness of ArchExplorer\nin summarizing design principles and selecting better-performing architectures.",
    "descriptor": "\nComments: 11 pages, 11 figures; accepted for IEEE VIS 2022\n",
    "authors": [
      "Jun Yuan",
      "Mengchen Liu",
      "Fengyuan Tian",
      "Shixia Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09665"
  },
  {
    "id": "arXiv:2208.09666",
    "title": "Modeling, Quantifying, and Predicting Subjectivity of Image Aesthetics",
    "abstract": "Assessing image aesthetics is a challenging computer vision task. One reason\nis that aesthetic preference is highly subjective and may vary significantly\namong people for certain images. Thus, it is important to properly model and\nquantify such \\textit{subjectivity}, but there has not been much effort to\nresolve this issue. In this paper, we propose a novel unified probabilistic\nframework that can model and quantify subjective aesthetic preference based on\nthe subjective logic. In this framework, the rating distribution is modeled as\na beta distribution, from which the probabilities of being definitely pleasing,\nbeing definitely unpleasing, and being uncertain can be obtained. We use the\nprobability of being uncertain to define an intuitive metric of subjectivity.\nFurthermore, we present a method to learn deep neural networks for prediction\nof image aesthetics, which is shown to be effective in improving the\nperformance of subjectivity prediction via experiments. We also present an\napplication scenario where the framework is beneficial for aesthetics-based\nimage recommendation.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Hyeongnam Jang",
      "Yeejin Lee",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09666"
  },
  {
    "id": "arXiv:2208.09668",
    "title": "Generalised Co-Salient Object Detection",
    "abstract": "Conventional co-salient object detection (CoSOD) has a strong assumption that\n\\enquote{a common salient object exists in every image of the same group}.\nHowever, the biased assumption contradicts real scenarios where co-salient\nobjects could be partially or completely absent in a group of images. We\npropose a random sampling based Generalised CoSOD Training (GCT) strategy to\ndistill the awareness of inter-image absence of co-salient object(s) into CoSOD\nmodels. In addition, the random sampling process inherent in GCT enables the\ngeneration of a high-quality uncertainty map, with which we can further\nremediate less confident model predictions that are prone to localising\nnon-common salient objects. To evaluate the generalisation ability of CoSOD\nmodels, we propose two new testing datasets, namely CoCA-Common and CoCA-Zero,\nwhere a common salient object is partially present in the former and completely\nabsent in the latter. Extensive experiments demonstrate that our proposed\nmethod significantly improves the generalisation ability of CoSOD models on the\ntwo new datasets, while not negatively impacting its performance under the\nconventional CoSOD setting. Codes are available at\nhttps://github.com/Carlisle-Liu/GCoSOD.",
    "descriptor": "",
    "authors": [
      "Jiawei Liu",
      "Jing Zhang",
      "Kaihao Zhang",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09668"
  },
  {
    "id": "arXiv:2208.09669",
    "title": "Lost in Context? On the Sense-wise Variance of Contextualized Word  Embeddings",
    "abstract": "Contextualized word embeddings in language models have given much advance to\nNLP. Intuitively, sentential information is integrated into the representation\nof words, which can help model polysemy. However, context sensitivity also\nleads to the variance of representations, which may break the semantic\nconsistency for synonyms. We quantify how much the contextualized embeddings of\neach word sense vary across contexts in typical pre-trained models. Results\nshow that contextualized embeddings can be highly consistent across contexts.\nIn addition, part-of-speech, number of word senses, and sentence length have an\ninfluence on the variance of sense representations. Interestingly, we find that\nword representations are position-biased, where the first words in different\ncontexts tend to be more similar. We analyze such a phenomenon and also propose\na simple way to alleviate such bias in distance-based word sense disambiguation\nsettings.",
    "descriptor": "",
    "authors": [
      "Yile Wang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09669"
  },
  {
    "id": "arXiv:2208.09671",
    "title": "Safe Subjoins in Acyclic Joins",
    "abstract": "It is expensive to compute joins, often due to large intermediate relations.\nFor acyclic joins, monotone join expressions are guaranteed to produce\nintermediate relations not larger than the size of the output of the join when\nit is computed on a fully reduced database. Any subexpression of an acyclic\njoin does not offer this guarantee, as it is easy to prove. In this paper, we\nconsider joins with projections too and we ask the question whether we can\ncharacterize join subexpressions that produce, on every fully reduced database,\nan output without dangling tuples (which translates, in the case of joins\nwithout projections, to an output of size not larger than the size of the\noutput of the join). We call such a subexpression a safe subjoin. Surprisingly,\nwe prove that there is a simple characterization which is the following: A\nsubjoin is safe if and only if there is a parse tree of the join (a.k.a. join\ntree) such that the relations in the subjoin form a subtree of it. We provide\nan algorithm that finds such a parse tree, if there is one.",
    "descriptor": "",
    "authors": [
      "Foto N. Afrati"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2208.09671"
  },
  {
    "id": "arXiv:2208.09672",
    "title": "Comparing graph data science libraries for querying and analysing  datasets: towards data science queries on graphs",
    "abstract": "This paper presents an experimental study to compare analysis tools with\nmanagement systems for querying and analysing graphs. Our experiment compares\nclassic graph navigational operations queries where analytics tools and\nmanagement systems adopt different execution strategies. Then, our experiment\naddresses data science pipelines with clustering and prediction models applied\nto graphs. In this kind of experiment, we underline the interest in combining\nboth approaches and the interest of relying on a parallel execution platform\nfor executing queries.",
    "descriptor": "",
    "authors": [
      "Genoveva Vargas-Solar",
      "Pierre Marrec",
      "Mirian Halfeld Ferrari Alves"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2208.09672"
  },
  {
    "id": "arXiv:2208.09673",
    "title": "Graph analytics workflows enactment on just in time data centres,  Position Paper",
    "abstract": "This paper discusses our vision of multirole-capable decision-making systems\nacross a broad range of Data Science (DS) workflows working on graphs through\ndisaggregated data centres. Our vision is that an alternative is possible to\nwork on a disaggregated solution for the provision of computational services\nunder the notion of a disaggregated data centre. We define this alternative as\na virtual entity that dynamically provides resources crosscutting the layers of\nedge, fog and data centre according to the workloads submitted by the workflows\nand their Service Level Objectives.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.07978\n",
    "authors": [
      "Ali Akoglu",
      "Jos\u00e9-Luis Zechinelli-Martini",
      "Hamamache Kheddouci",
      "Genoveva Vargas-Solar"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2208.09673"
  },
  {
    "id": "arXiv:2208.09676",
    "title": "Intelligent Omni-Surfaces: Simultaneous Refraction and Reflection for  Full-dimensional Wireless Communications",
    "abstract": "The development of metasurfaces has unlocked various use cases in wireless\ncommunication networks to improve performance by manipulating the propagation\nenvironment. Intelligent omni-surface (IOS), an innovative technique in this\ncategory, is proposed for coverage extension. In contrast to the widely studied\nreflective metasurfaces, i.e., intelligent reflecting surfaces (IRSs), which\ncan only serve receivers located on the same side of the transmitter, the IOS\ncan achieve full-dimensional wireless communications by enabling the\nsimultaneous reflection and refraction of the surface, and thus users on both\nsides can be served. In this paper, we provide a comprehensive overview of the\nstate-of-the-art in IOS from the perspective of wireless communications, with\nthe emphasis on their design principles, channel modeling, beamforming design,\nexperimental implementation and measurements, as well as possible applications\nin future cellular networks. We first describe the basic concepts of\nmetasurfaces, and introduce the corresponding design principles for different\ntypes of metasurfaces. Moreover, we elaborate on the reflective-refractive\nmodel for each IOS element and the channel model for IOS-aided wireless\ncommunication systems. Furthermore, we show how to achieve full-dimensional\nwireless communications with the IOS for three different scenarios. In\nparticular, we present the implementation of an IOS-aided wireless\ncommunication prototype and report its experimental measurement results.\nFinally, we outline some potential future directions and challenges in this\narea.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hongliang Zhang",
      "Boya Di"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.09676"
  },
  {
    "id": "arXiv:2208.09677",
    "title": "Net2Brain: A Toolbox to compare artificial vision models with human  brain responses",
    "abstract": "We introduce Net2Brain, a graphical and command-line user interface toolbox\nfor comparing the representational spaces of artificial deep neural networks\n(DNNs) and human brain recordings. While different toolboxes facilitate only\nsingle functionalities or only focus on a small subset of supervised image\nclassification models, Net2Brain allows the extraction of activations of more\nthan 600 DNNs trained to perform a diverse range of vision-related tasks (e.g\nsemantic segmentation, depth estimation, action recognition, etc.), over both\nimage and video datasets. The toolbox computes the representational\ndissimilarity matrices (RDMs) over those activations and compares them to brain\nrecordings using representational similarity analysis (RSA), weighted RSA, both\nin specific ROIs and with searchlight search. In addition, it is possible to\nadd a new data set of stimuli and brain recordings to the toolbox for\nevaluation. We demonstrate the functionality and advantages of Net2Brain with\nan example showcasing how it can be used to test hypotheses of cognitive\ncomputational neuroscience.",
    "descriptor": "\nComments: 4 Pages, 3 figures, submitted and accepted to CCNeuro 2022. For associated repository, see this https URL\n",
    "authors": [
      "Domenic Bersch",
      "Kshitij Dwivedi",
      "Martina Vilas",
      "Radoslaw M. Cichy",
      "Gemma Roig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2208.09677"
  },
  {
    "id": "arXiv:2208.09678",
    "title": "Finding Emotions in Faces: A Meta-Classifier",
    "abstract": "Machine learning has been used to recognize emotions in faces, typically by\nlooking for 8 different emotional states (neutral, happy, sad, surprise, fear,\ndisgust, anger and contempt). We consider two approaches: feature recognition\nbased on facial landmarks and deep learning on all pixels; each produced 58%\noverall accuracy. However, they produced different results on different images\nand thus we propose a new meta-classifier combining these approaches. It\nproduces far better results with 77% accuracy",
    "descriptor": "",
    "authors": [
      "Siddartha Dalal",
      "Sierra Vo",
      "Michael Lesk",
      "Wesley Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09678"
  },
  {
    "id": "arXiv:2208.09684",
    "title": "Combining Compressions for Multiplicative Size Scaling on Natural  Language Tasks",
    "abstract": "Quantization, knowledge distillation, and magnitude pruning are among the\nmost popular methods for neural network compression in NLP. Independently,\nthese methods reduce model size and can accelerate inference, but their\nrelative benefit and combinatorial interactions have not been rigorously\nstudied. For each of the eight possible subsets of these techniques, we compare\naccuracy vs. model size tradeoffs across six BERT architecture sizes and eight\nGLUE tasks. We find that quantization and distillation consistently provide\ngreater benefit than pruning. Surprisingly, except for the pair of pruning and\nquantization, using multiple methods together rarely yields diminishing\nreturns. Instead, we observe complementary and super-multiplicative reductions\nto model size. Our work quantitatively demonstrates that combining compression\nmethods can synergistically reduce model size, and that practitioners should\nprioritize (1) quantization, (2) knowledge distillation, and (3) pruning to\nmaximize accuracy vs. model size tradeoffs.",
    "descriptor": "\nComments: Accepted as short paper at COLING 2022. 5 pages main text, 5 pages appendix\n",
    "authors": [
      "Rajiv Movva",
      "Jinhao Lei",
      "Shayne Longpre",
      "Ajay Gupta",
      "Chris DuBois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09684"
  },
  {
    "id": "arXiv:2208.09686",
    "title": "YOLOV: Making Still Image Object Detectors Great at Video Object  Detection",
    "abstract": "Video object detection (VID) is challenging because of the high variation of\nobject appearance as well as the diverse deterioration in some frames. On the\npositive side, the detection in a certain frame of a video, compared with in a\nstill image, can draw support from other frames. Hence, how to aggregate\nfeatures across different frames is pivotal to the VID problem. Most of\nexisting aggregation algorithms are customized for two-stage detectors. But,\nthe detectors in this category are usually computationally expensive due to the\ntwo-stage nature. This work proposes a simple yet effective strategy to address\nthe above concerns, which spends marginal overheads with significant gains in\naccuracy. Concretely, different from the traditional two-stage pipeline, we\nadvocate putting the region-level selection after the one-stage detection to\navoid processing massive low-quality candidates. Besides, a novel module is\nconstructed to evaluate the relationship between a target frame and its\nreference ones, and guide the aggregation. Extensive experiments and ablation\nstudies are conducted to verify the efficacy of our design, and reveal its\nsuperiority over other state-of-the-art VID approaches in both effectiveness\nand efficiency. Our YOLOX-based model can achieve promising performance (e.g.,\n87.5\\% AP50 at over 30 FPS on the ImageNet VID dataset on a single 2080Ti GPU),\nmaking it attractive for large-scale or real-time applications. The\nimplementation is simple, the demo code and models have been made available at\nhttps://github.com/YuHengsss/YOLOV .",
    "descriptor": "",
    "authors": [
      "Yuheng Shi",
      "Naiyan Wang",
      "Xiaojie Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09686"
  },
  {
    "id": "arXiv:2208.09688",
    "title": "Learning Sub-Pixel Disparity Distribution for Light Field Depth  Estimation",
    "abstract": "Existing light field (LF) depth estimation methods generally consider depth\nestimation as a regression problem, supervised by a pixel-wise L1 loss between\nthe regressed disparity map and the groundtruth one. However, the disparity map\nis only a sub-space projection (i.e., an expectation) of the disparity\ndistribution, while the latter one is more essential for models to learn. In\nthis paper, we propose a simple yet effective method to learn the sub-pixel\ndisparity distribution by fully utilizing the power of deep networks. In our\nmethod, we construct the cost volume at sub-pixel level to produce a finer\ndepth distribution and design an uncertainty-aware focal loss to supervise the\ndisparity distribution to be close to the groundtruth one. Extensive\nexperimental results demonstrate the effectiveness of our method. Our method,\ncalled SubFocal, ranks the first place among 99 submitted algorithms on the HCI\n4D LF Benchmark in terms of all the five accuracy metrics (i.e., BadPix0.01,\nBadPix0.03, BadPix0.07, MSE and Q25), and significantly outperforms recent\nstate-of-the-art LF depth methods such as OACC-Net and AttMLFNet. Code and\nmodel are available at https://github.com/chaowentao/SubFocal.",
    "descriptor": "",
    "authors": [
      "Wentao Chao",
      "Xuechun Wang",
      "Yingqian Wang",
      "Liang Chang",
      "Fuqing Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09688"
  },
  {
    "id": "arXiv:2208.09690",
    "title": "Gradient Descent Ascent in Min-Max Stackelberg Games",
    "abstract": "Min-max optimization problems (i.e., min-max games) have attracted a great\ndeal of attention recently as their applicability to a wide range of machine\nlearning problems has become evident. In this paper, we study min-max games\nwith dependent strategy sets, where the strategy of the first player constrains\nthe behavior of the second. Such games are best understood as sequential, i.e.,\nStackelberg, games, for which the relevant solution concept is Stackelberg\nequilibrium, a generalization of Nash. One of the most popular algorithms for\nsolving min-max games is gradient descent ascent (GDA). We present a\nstraightforward generalization of GDA to min-max Stackelberg games with\ndependent strategy sets, but show that it may not converge to a Stackelberg\nequilibrium. We then introduce two variants of GDA, which assume access to a\nsolution oracle for the optimal Karush Kuhn Tucker (KKT) multipliers of the\ngames' constraints. We show that such an oracle exists for a large class of\nconvex-concave min-max Stackelberg games, and provide proof that our GDA\nvariants with such an oracle converge in $O(\\frac{1}{\\varepsilon^2})$\niterations to an $\\varepsilon$-Stackelberg equilibrium, improving on the most\nefficient algorithms currently known which converge in\n$O(\\frac{1}{\\varepsilon^3})$ iterations. We then show that solving Fisher\nmarkets, a canonical example of a min-max Stackelberg game, using our novel\nalgorithm, corresponds to buyers and sellers using myopic best-response\ndynamics in a repeated market, allowing us to prove the convergence of these\ndynamics in $O(\\frac{1}{\\varepsilon^2})$ iterations in Fisher markets. We close\nby describing experiments on Fisher markets which suggest potential ways to\nextend our theoretical results, by demonstrating how different properties of\nthe objective function can affect the convergence and convergence rate of our\nalgorithms.",
    "descriptor": "\nComments: 13 pages, 1 figure, Games, Agents, and Incentives Workshop (AAMAS'22). arXiv admin note: text overlap with arXiv:2110.05192, arXiv:2203.14126\n",
    "authors": [
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2208.09690"
  },
  {
    "id": "arXiv:2208.09693",
    "title": "Judge a Sentence by Its Content to Generate Grammatical Errors",
    "abstract": "Data sparsity is a well-known problem for grammatical error correction (GEC).\nGenerating synthetic training data is one widely proposed solution to this\nproblem, and has allowed models to achieve state-of-the-art (SOTA) performance\nin recent years. However, these methods often generate unrealistic errors, or\naim to generate sentences with only one error. We propose a learning based two\nstage method for synthetic data generation for GEC that relaxes this constraint\non sentences containing only one error. Errors are generated in accordance with\nsentence merit. We show that a GEC model trained on our synthetically generated\ncorpus outperforms models trained on synthetic data from prior work.",
    "descriptor": "",
    "authors": [
      "Chowdhury Rafeed Rahman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09693"
  },
  {
    "id": "arXiv:2208.09694",
    "title": "Effectiveness of Function Matching in Driving Scene Recognition",
    "abstract": "Knowledge distillation is an effective approach for training compact\nrecognizers required in autonomous driving. Recent studies on image\nclassification have shown that matching student and teacher on a wide range of\ndata points is critical for improving performance in distillation. This concept\n(called function matching) is suitable for driving scene recognition, where\ngenerally an almost infinite amount of unlabeled data are available. In this\nstudy, we experimentally investigate the impact of using such a large amount of\nunlabeled data for distillation on the performance of student models in\nstructured prediction tasks for autonomous driving. Through extensive\nexperiments, we demonstrate that the performance of the compact student model\ncan be improved dramatically and even match the performance of the large-scale\nteacher by knowledge distillation with massive unlabeled data.",
    "descriptor": "\nComments: Autonomous Vehicle Vision (AVVision) Workshop at ECCV2022\n",
    "authors": [
      "Shingo Yashima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09694"
  },
  {
    "id": "arXiv:2208.09697",
    "title": "Study on the Concept and Development of a Mobile Incubator",
    "abstract": "Creating the best possible conditions is essential for proper cell growth.\nIncubators, a type of biotechnological instrument, are used to simulate this\ncondition and maintain the cells within them. The processes involved in\ncreating a mobile incubator, which are essential for monitoring a cell\nculture's physiological parameters, are outlined in this article. The goal is\nto keep image-taking during cell development from compromising data accuracy.\nThe cell culture is prone to contamination once it has been removed from the\nincubation environment for further monitoring. The proposed approach allows for\non-the-go monitoring of the cell culture. Moreover, it enables constant\nmonitoring.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Fehmi Can Ay",
      "Nesim Bilici",
      "Rahmetullah Varol",
      "Atasangu Yilmaz",
      "Ufuk Gorkem Kirabali",
      "Abdurrahim Yilmaz",
      "Huseyin Uvet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09697"
  },
  {
    "id": "arXiv:2208.09698",
    "title": "Fuse and Attend: Generalized Embedding Learning for Art and Sketches",
    "abstract": "While deep Embedding Learning approaches have witnessed widespread success in\nmultiple computer vision tasks, the state-of-the-art methods for representing\nnatural images need not necessarily perform well on images from other domains,\nsuch as paintings, cartoons, and sketch. This is because of the huge shift in\nthe distribution of data from across these domains, as compared to natural\nimages. Domains like sketch often contain sparse informative pixels. However,\nrecognizing objects in such domains is crucial, given multiple relevant\napplications leveraging such data, for instance, sketch to image retrieval.\nThus, achieving an Embedding Learning model that could perform well across\nmultiple domains is not only challenging, but plays a pivotal role in computer\nvision. To this end, in this paper, we propose a novel Embedding Learning\napproach with the goal of generalizing across different domains. During\ntraining, given a query image from a domain, we employ gated fusion and\nattention to generate a positive example, which carries a broad notion of the\nsemantics of the query object category (from across multiple domains). By\nvirtue of Contrastive Learning, we pull the embeddings of the query and\npositive, in order to learn a representation which is robust across domains. At\nthe same time, to teach the model to be discriminative against examples from\ndifferent semantic categories (across domains), we also maintain a pool of\nnegative embeddings (from different categories). We show the prowess of our\nmethod using the DomainBed framework, on the popular PACS (Photo, Art painting,\nCartoon, and Sketch) dataset.",
    "descriptor": "\nComments: Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: DIRA\n",
    "authors": [
      "Ujjal Kr Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09698"
  },
  {
    "id": "arXiv:2208.09699",
    "title": "An Approach of Adjusting the Switch Probability based on Dimension Size:  A Case Study for Performance Improvement of the Flower Pollination Algorithm",
    "abstract": "Numerous meta-heuristic algorithms have been influenced by nature. Over the\npast couple of decades, their quantity has been significantly escalating. The\nmajority of these algorithms attempt to emulate natural biological and physical\nphenomena. This research concentrates on the Flower Pollination algorithm,\nwhich is one of several bio-inspired algorithms. The original approach was\nsuggested for pollen grain exploration and exploitation in confined space using\na specific global pollination and local pollination strategy. As a \"swarm\nintelligence\" meta-heuristic algorithm, its strength lies in locating the\nvicinity of the optimum solution rather than identifying the minimum. A\nmodification to the original method is detailed in this work. This research\nfound that by changing the specific value of \"switch probability\" with dynamic\nvalues of different dimension sizes and functions, the outcome was mainly\nimproved over the original flower pollination method.",
    "descriptor": "\nComments: 9 pages, 2 figures, 3 tables\n",
    "authors": [
      "Tahsin Aziz",
      "Tashreef Muhammad",
      "Md. Rashedul Karim Chowdhury",
      "Mohammad Shafiul Alam"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.09699"
  },
  {
    "id": "arXiv:2208.09701",
    "title": "On the equivalence issue of a class of $2$-dimensional linear Maximum  Rank Distance codes",
    "abstract": "Recently A. Neri, P. Santonastaso and F. Zullo extended a family of\n$2$-dimensional $\\mathbb{F}_{q^{2t}}$-linear MRD codes found by G. Longobardi,\nG. Marino, R. Trombetti and Y. Zhou. Also, for $t \\geq 5$ they determined\nequivalence classes of the elements in this new family, and provided the exact\nnumber of inequivalent codes in it. In this article we complete the study of\nthe equivalence issue removing the restriction $t \\geq 5$. Moreover, we prove\nthat in the case when $t=4$, the linear sets of the projective line\n$\\mathrm{PG}(1,q^{8})$ ensuing from codes in the relevant family, are not\nequivalent to any one known so far.",
    "descriptor": "",
    "authors": [
      "S. Gupta",
      "G. Longobardi",
      "R. Trombetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.09701"
  },
  {
    "id": "arXiv:2208.09702",
    "title": "Minimizing Visible Edges in Polyhedra",
    "abstract": "We prove that, given a polyhedron $\\mathcal P$ in $\\mathbb{R}^3$, every point\nin $\\mathbb R^3$ that does not see any vertex of $\\mathcal P$ must see eight or\nmore edges of $\\mathcal P$; this bound is tight. More generally, this remains\ntrue if $\\mathcal P$ is any finite arrangement of internally disjoint polygons\nin $\\mathbb{R}^3$.",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Csaba D. T\u00f3th",
      "Jorge Urrutia",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.09702"
  },
  {
    "id": "arXiv:2208.09703",
    "title": "SnowFormer: Scale-aware Transformer via Context Interaction for Single  Image Desnowing",
    "abstract": "Single image desnowing is a common yet challenging task. The complex snow\ndegradations and diverse degradation scales demand strong representation\nability. In order for the desnowing network to see various snow degradations\nand model the context interaction of local details and global information, we\npropose a powerful architecture dubbed as SnowFormer. First, it performs\nScale-aware Feature Aggregation in the encoder to capture rich snow information\nof various degradations. Second, in order to tackle with large-scale\ndegradation, it uses a novel Context Interaction Transformer Block in the\ndecoder, which conducts context interaction of local details and global\ninformation from previous scale-aware feature aggregation in global context\ninteraction. And the introduction of local context interaction improves\nrecovery of scene details. Third, we devise a Heterogeneous Feature Projection\nHead which progressively fuse features from both the encoder and decoder and\nproject the refined feature into the clean image. Extensive experiments\ndemonstrate that the proposed SnowFormer achieves significant improvements over\nother SOTA methods. Compared with SOTA single image desnowing method HDCW-Net,\nit boosts the PSNR metric by 9.2dB on the CSD testset. Moreover, it also\nachieves a 5.13dB increase in PSNR compared with general image restoration\narchitecture NAFNet, which verifies the strong representation ability of our\nSnowFormer for snow removal task. The code is released in\n\\url{https://github.com/Ephemeral182/SnowFormer}.",
    "descriptor": "",
    "authors": [
      "Sixiang Chen",
      "Tian Ye",
      "Yun Liu",
      "Erkang Chen",
      "Jun Shi",
      "Jingchun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09703"
  },
  {
    "id": "arXiv:2208.09705",
    "title": "gBuilder: A Scalable Knowledge Graph Construction System for  Unstructured Corpus",
    "abstract": "We design a user-friendly and scalable knowledge graph construction (KGC)\nsystem for extracting structured knowledge from the unstructured corpus.\nDifferent from existing KGC systems, gBuilder provides a flexible and\nuser-defined pipeline to embracing the rapid development of IE models. More\nbuilt-in template-based or heuristic operators and programmable operators are\navailable for adapting to data from different domains. Furthermore, we also\ndesign a cloud-based self-adaptive task scheduling for gBuilder to ensure its\nscalability on large-scale knowledge graph construction. Experimental\nevaluation not only demonstrates the ability of gBuilder to organize multiple\ninformation extraction models for knowledge graph construction in a uniform\nplatform, and also confirms its high scalability on large-scale KGC task.",
    "descriptor": "\nComments: This is a preview version\n",
    "authors": [
      "Yanzeng Li",
      "Lei Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09705"
  },
  {
    "id": "arXiv:2208.09706",
    "title": "Dual Space Coupling Model Guided Overlap-Free Scatterplot",
    "abstract": "The overdraw problem of scatterplots seriously interferes with the visual\ntasks. Existing methods, such as data sampling, node dispersion, subspace\nmapping, and visual abstraction, cannot guarantee the correspondence and\nconsistency between the data points that reflect the intrinsic original data\ndistribution and the corresponding visual units that reveal the presented data\ndistribution, thus failing to obtain an overlap-free scatterplot with unbiased\nand lossless data distribution. A dual space coupling model is proposed in this\npaper to represent the complex bilateral relationship between data space and\nvisual space theoretically and analytically. Under the guidance of the model,\nan overlap-free scatterplot method is developed through integration of the\nfollowing: a geometry-based data transformation algorithm, namely\nDistributionTranscriptor; an efficient spatial mutual exclusion guided view\ntransformation algorithm, namely PolarPacking; an overlap-free oriented visual\nencoding configuration model and a radius adjustment tool, namely\n$f_{r_{draw}}$. Our method can ensure complete and accurate information\ntransfer between the two spaces, maintaining consistency between the newly\ncreated scatterplot and the original data distribution on global and local\nfeatures. Quantitative evaluation proves our remarkable progress on\ncomputational efficiency compared with the state-of-the-art methods. Three\napplications involving pattern enhancement, interaction improvement, and\noverdraw mitigation of trajectory visualization demonstrate the broad prospects\nof our method.",
    "descriptor": "",
    "authors": [
      "Zeyu Li",
      "Ruizhi Shi",
      "Yan Liu",
      "Shizhuo Long",
      "Ziheng Guo",
      "Shichao Jia",
      "Jiawan Zhang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.09706"
  },
  {
    "id": "arXiv:2208.09708",
    "title": "DenseShift: Towards Accurate and Transferable Low-Bit Shift Network",
    "abstract": "Deploying deep neural networks on low-resource edge devices is challenging\ndue to their ever-increasing resource requirements. Recent investigations\npropose multiplication-free neural networks to reduce computation and memory\nconsumption. Shift neural network is one of the most effective tools towards\nthese reductions. However, existing low-bit shift networks are not as accurate\nas their full precision counterparts and cannot efficiently transfer to a wide\nrange of tasks due to their inherent design flaws. We propose DenseShift\nnetwork that exploits the following novel designs. First, we demonstrate that\nthe zero-weight values in low-bit shift networks are neither useful to the\nmodel capacity nor simplify the model inference. Therefore, we propose to use a\nzero-free shifting mechanism to simplify inference while increasing the model\ncapacity. Second, we design a new metric to measure the weight freezing issue\nin training low-bit shift networks, and propose a sign-scale decomposition to\nimprove the training efficiency. Third, we propose the low-variance random\ninitialization strategy to improve the model's performance in transfer learning\nscenarios. We run extensive experiments on various computer vision and speech\ntasks. The experimental results show that DenseShift network significantly\noutperforms existing low-bit multiplication-free networks and can achieve\ncompetitive performance to the full-precision counterpart. It also exhibits\nstrong transfer learning performance with no drop in accuracy.",
    "descriptor": "",
    "authors": [
      "Xinlin Li",
      "Bang Liu",
      "Rui Heng Yang",
      "Vanessa Courville",
      "Chao Xing",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09708"
  },
  {
    "id": "arXiv:2208.09709",
    "title": "BSpell: A CNN-blended BERT Based Bengali Spell Checker",
    "abstract": "Bengali typing is mostly performed using English keyboard and can be highly\nerroneous due to the presence of compound and similarly pronounced letters.\nSpelling correction of a misspelled word requires understanding of word typing\npattern as well as the context of the word usage. We propose a specialized BERT\nmodel, BSpell targeted towards word for word correction in sentence level.\nBSpell contains an end-to-end trainable CNN sub-model named SemanticNet along\nwith specialized auxiliary loss. This allows BSpell to specialize in highly\ninflected Bengali vocabulary in the presence of spelling errors. We further\npropose hybrid pretraining scheme for BSpell combining word level and character\nlevel masking. Utilizing this pretraining scheme, BSpell achieves 91.5%\naccuracy on real life Bengali spelling correction validation set. Detailed\ncomparison on two Bengali and one Hindi spelling correction dataset shows the\nsuperiority of proposed BSpell over existing spell checkers.",
    "descriptor": "",
    "authors": [
      "Chowdhury Rafeed Rahman",
      "MD. Hasibur Rahman",
      "Samiha Zakir",
      "Mohammad Rafsan",
      "Mohammed Eunus Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09709"
  },
  {
    "id": "arXiv:2208.09711",
    "title": "Improving Multilayer-Perceptron(MLP)-based Network Anomaly Detection  with Birch Clustering on CICIDS-2017 Dataset",
    "abstract": "Machine learning algorithms have been widely used in intrusion detection\nsystems, including Multi-layer Perceptron (MLP). In this study, we proposed a\ntwo-stage model that combines the Birch clustering algorithm and MLP classifier\nto improve the performance of network anomaly multi-classification. In our\nproposed method, we first apply Birch or Kmeans as an unsupervised clustering\nalgorithm to the CICIDS-2017 dataset to pre-group the data. The generated\npseudo-label is then added as an additional feature to the training of the\nMLP-based classifier. The experimental results show that using Birch and\nK-Means clustering for data pre-grouping can improve intrusion detection system\nperformance. Our method can achieve 99.73% accuracy in multi-classification\nusing Birch clustering, which is better than similar researches using a\nstand-alone MLP model.",
    "descriptor": "",
    "authors": [
      "Yuhua Yin",
      "Julian Jang-Jaccard",
      "Fariza Sabrina",
      "Jin Kwak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09711"
  },
  {
    "id": "arXiv:2208.09715",
    "title": "SemEval-2022 Task 8: Multi-lingual News Article Similarity",
    "abstract": "This work is about finding the similarity between a pair of news articles.\nThere are seven different objective similarity metrics provided in the dataset\nfor each pair and the news articles are in multiple different languages. On top\nof the pre-trained embedding model, we calculated cosine similarity for\nbaseline results and feed-forward neural network was then trained on top of it\nto improve the results. We also built separate pipelines for each similarity\nmetric for feature extraction. We could see significant improvement from\nbaseline results using feature extraction and feed-forward neural network.",
    "descriptor": "",
    "authors": [
      "Nikhil Goel",
      "Ranjith Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09715"
  },
  {
    "id": "arXiv:2208.09716",
    "title": "zk-PCN: A Privacy-Preserving Payment Channel Network Using zk-SNARKs",
    "abstract": "Payment channel network (PCN) is a layer-two scaling solution that enables\nfast off-chain transactions but does not involve on-chain transaction\nsettlement. PCNs raise new privacy issues including balance secrecy,\nrelationship anonymity and payment privacy. Moreover, protecting privacy causes\nlow transaction success rates. To address this dilemma, we propose zk-PCN, a\nprivacy-preserving payment channel network using zk-SNARKs. We prevent from\nexposing true balances by setting up \\textit{public balances} instead. Using\npublic balances, zk-PCN can guarantee high transaction success rates and\nprotect PCN privacy with zero-knowledge proofs. Additionally, zk-PCN is\ncompatible with the existing routing algorithms of PCNs. To support such\ncompatibility, we propose zk-IPCN to improve zk-PCN with a novel proof\ngeneration (RPG) algorithm. zk-IPCN reduces the overheads of storing channel\ninformation and lowers the frequency of generating zero-knowledge proofs.\nFinally, extensive simulations demonstrate the effectiveness and efficiency of\nzk-PCN in various settings.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Wenxuan Yu",
      "Minghui Xu",
      "Dongxiao Yu",
      "Xiuzhen Cheng",
      "Qin Hu",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09716"
  },
  {
    "id": "arXiv:2208.09717",
    "title": "Learning Primitive-aware Discriminative Representations for FSL",
    "abstract": "Few-shot learning (FSL) aims to learn a classifier that can be easily adapted\nto recognize novel classes,given only a few labeled examples per class.Limited\ndata keep this task challenging for deep learning.Recent metric-based methods\nhas achieved promising performance based on image-level features.However,these\nglobal features ignore abundant local and structural information that is\ntransferable and consistent between seen and unseen classes.Some study in\ncognitive science argue that humans can recognize novel classes with the\nlearned primitives.We expect to mine both transferable and discriminative\nrepresentation from base classes and adopt them to recognize novel\nclasses.Building on the episodic training mechanism,We propose a Primitive\nMining and Reasoning Network(PMRN) to learn primitive-aware representation in\nan end-to-end manner for metric-based FSL model.We first add self-supervision\nauxiliary task,forcing feature extractor to learn tvisual pattern corresponding\nto primitives.To further mine and produce transferable primitive-aware\nrepresentations,we design an Adaptive Channel Grouping(ACG)module to synthesize\na set of visual primitives from object embedding by enhancing informative\nchannel maps while suppressing useless ones. Based on the learned primitive\nfeature,a Semantic Correlation Reasoning (SCR) module is proposed to capture\ninternal relations among them.Finally,we learn the task-specific importance of\nprimitives and conduct primitive-level metric based on the task-specific\nattention feature.Extensive experiments show that our method achieves\nstate-of-the-art results on six standard benchmarks.",
    "descriptor": "",
    "authors": [
      "Jianpeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09717"
  },
  {
    "id": "arXiv:2208.09719",
    "title": "Cognitive Modeling of Semantic Fluency Using Transformers",
    "abstract": "Can deep language models be explanatory models of human cognition? If so,\nwhat are their limits? In order to explore this question, we propose an\napproach called hyperparameter hypothesization that uses predictive\nhyperparameter tuning in order to find individuating descriptors of\ncognitive-behavioral profiles. We take the first step in this approach by\npredicting human performance in the semantic fluency task (SFT), a well-studied\ntask in cognitive science that has never before been modeled using\ntransformer-based language models (TLMs). In our task setup, we compare several\napproaches to predicting which word an individual performing SFT will utter\nnext. We report preliminary evidence suggesting that, despite obvious\nimplementational differences in how people and TLMs learn and use language,\nTLMs can be used to identify individual differences in human fluency task\nbehaviors better than existing computational models, and may offer insights\ninto human memory retrieval strategies -- cognitive process not typically\nconsidered to be the kinds of things TLMs can model. Finally, we discuss the\nimplications of this work for cognitive modeling of knowledge representations.",
    "descriptor": "\nComments: Cognitive Aspects of Knowledge Representation workshop at IJCAI-ECAI 2022\n",
    "authors": [
      "Animesh Nighojkar",
      "Anna Khlyzova",
      "John Licato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09719"
  },
  {
    "id": "arXiv:2208.09723",
    "title": "Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform  Sampling and CUR Sampling",
    "abstract": "While uniform sampling has been widely studied in the matrix completion\nliterature, CUR sampling approximates a low-rank matrix via row and column\nsamples. Unfortunately, both sampling models lack flexibility for various\ncircumstances in real-world applications. In this work, we propose a novel and\neasy-to-implement sampling strategy, coined Cross-Concentrated Sampling (CCS).\nBy bridging uniform sampling and CUR sampling, CCS provides extra flexibility\nthat can potentially save sampling costs in applications. In addition, we also\nprovide a sufficient condition for CCS-based matrix completion. Moreover, we\npropose a highly efficient non-convex algorithm, termed Iterative CUR\nCompletion (ICURC), for the proposed CCS model. Numerical experiments verify\nthe empirical advantages of CCS and ICURC against uniform sampling and its\nbaseline algorithms, on both synthetic and real-world datasets.",
    "descriptor": "",
    "authors": [
      "HanQin Cai",
      "Longxiu Huang",
      "Pengyu Li",
      "Deanna Needell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09723"
  },
  {
    "id": "arXiv:2208.09727",
    "title": "Security Implications of Large Language Model Code Assistants: A User  Study",
    "abstract": "Advances in Deep Learning have led to the emergence of Large Language Models\n(LLMs) such as OpenAI Codex which powers GitHub Copilot. LLMs have been fine\ntuned and packaged so that programmers can use them in an Integrated\nDevelopment Environment (IDE) to write code. An emerging line of work is\nassessing the code quality of code written with the help of these LLMs, with\nsecurity studies warning that LLMs do not fundamentally have any understanding\nof the code they are writing, so they are more likely to make mistakes that may\nbe exploitable. We thus conducted a user study (N=58) to assess the security of\ncode written by student programmers when guided by LLMs. Half of the students\nin our study had the help of the LLM and the other half did not. The students\nwere asked to write code in C that performed operations over a singly linked\nlist, including node operations such as inserting, updating, removing,\ncombining, and others. While the results of our study showed that the students\nwho had the help of an LLM were more likely to write functional code, no\ngeneralizable impact on security was observed -- the security impacts were\nlocalized to individual functions. We also investigate systematic stylistic\ndifferences between unaided and LLM-assisted code, finding that LLM code is\nmore repetitive, which may have an amplifying effect if vulnerable code is\nrepeated in addition to the impact on source code attribution.",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "Gustavo Sandoval",
      "Hammond Pearce",
      "Teo Nys",
      "Ramesh Karri",
      "Brendan Dolan-Gavitt",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09727"
  },
  {
    "id": "arXiv:2208.09731",
    "title": "Solving systems of linear equations through zero forcing set and  application to lights out",
    "abstract": "Let $\\mathbb{F}$ be any field, we consider solving $Ax=b$ repeatedly for a\nmatrix $A\\in\\mathbb{F}^{n\\times n}$ of $m$ non-zero elements, and multiple\ndifferent $b\\in\\mathbb{F}^{n}$. If we are given a zero forcing set of $A$ of\nsize $k$, we can then build a data structure in $O(mk)$ time, such that each\ninstance of $Ax=b$ can be solved in $O(k^2+m)$ time. As an application, we show\nhow the lights out game in an $n\\times n$ grid is solved in $O(n^3)$ time, and\nthen improve the running time to $O(n^\\omega\\log n)$ by exploiting the repeated\nstructure in grids.",
    "descriptor": "",
    "authors": [
      "Jianbo Wang",
      "Chao Xu",
      "Siyun Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09731"
  },
  {
    "id": "arXiv:2208.09734",
    "title": "A Multi-Head Model for Continual Learning via Out-of-Distribution Replay",
    "abstract": "This paper studies class incremental learning (CIL) of continual learning\n(CL). Many approaches have been proposed to deal with catastrophic forgetting\n(CF) in CIL. Most methods incrementally construct a single classifier for all\nclasses of all tasks in a single head network. To prevent CF, a popular\napproach is to memorize a small number of samples from previous tasks and\nreplay them during training of the new task. However, this approach still\nsuffers from serious CF as the parameters learned for previous tasks are\nupdated or adjusted with only the limited number of saved samples in the\nmemory. This paper proposes an entirely different approach that builds a\nseparate classifier (head) for each task (called a multi-head model) using a\ntransformer network, called MORE. Instead of using the saved samples in memory\nto update the network for previous tasks/classes in the existing approach, MORE\nleverages the saved samples to build a task specific classifier (adding a new\nclassification head) without updating the network learned for previous\ntasks/classes. The model for the new task in MORE is trained to learn the\nclasses of the task and also to detect samples that are not from the same data\ndistribution (i.e., out-of-distribution (OOD)) of the task. This enables the\nclassifier for the task to which the test instance belongs to produce a high\nscore for the correct class and the classifiers of other tasks to produce low\nscores because the test instance is not from the data distributions of these\nclassifiers. Experimental results show that MORE outperforms state-of-the-art\nbaselines and is also naturally capable of performing OOD detection in the\ncontinual learning setting.",
    "descriptor": "",
    "authors": [
      "Gyuhak Kim",
      "Zixuan Ke",
      "Bing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09734"
  },
  {
    "id": "arXiv:2208.09736",
    "title": "C$^{2}$IMUFS: Complementary and Consensus Learning-based Incomplete  Multi-view Unsupervised Feature Selection",
    "abstract": "Multi-view unsupervised feature selection (MUFS) has been demonstrated as an\neffective technique to reduce the dimensionality of multi-view unlabeled data.\nThe existing methods assume that all of views are complete. However, multi-view\ndata are usually incomplete, i.e., a part of instances are presented on some\nviews but not all views. Besides, learning the complete similarity graph, as an\nimportant promising technology in existing MUFS methods, cannot achieve due to\nthe missing views. In this paper, we propose a complementary and consensus\nlearning-based incomplete multi-view unsupervised feature selection method\n(C$^{2}$IMUFS) to address the aforementioned issues. Concretely, C$^{2}$IMUFS\nintegrates feature selection into an extended weighted non-negative matrix\nfactorization model equipped with adaptive learning of view-weights and a\nsparse $\\ell_{2,p}$-norm, which can offer better adaptability and flexibility.\nBy the sparse linear combinations of multiple similarity matrices derived from\ndifferent views, a complementary learning-guided similarity matrix\nreconstruction model is presented to obtain the complete similarity graph in\neach view. Furthermore, C$^{2}$IMUFS learns a consensus clustering indicator\nmatrix across different views and embeds it into a spectral graph term to\npreserve the local geometric structure. Comprehensive experimental results on\nreal-world datasets demonstrate the effectiveness of C$^{2}$IMUFS compared with\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yanyong Huang",
      "Zongxin Shen",
      "Yuxin Cai",
      "Xiuwen Yi",
      "Dongjie Wang",
      "Fengmao Lv",
      "Tianrui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09736"
  },
  {
    "id": "arXiv:2208.09740",
    "title": "Just-in-Time Aggregation for Federated Learning",
    "abstract": "The increasing number and scale of federated learning (FL) jobs necessitates\nresource efficient scheduling and management of aggregation to make the\neconomics of cloud-hosted aggregation work. Existing FL research has focused on\nthe design of FL algorithms and optimization, and less on the efficacy of\naggregation. Existing FL platforms often employ aggregators that actively wait\nfor model updates. This wastes computational resources on the cloud, especially\nin large scale FL settings where parties are intermittently available for\ntraining.\nIn this paper, we propose a new FL aggregation paradigm -- \"just-in-time\"\n(JIT) aggregation that leverages unique properties of FL jobs, especially the\nperiodicity of model updates, to defer aggregation as much as possible and free\ncompute resources for other FL jobs or other datacenter workloads. We describe\na novel way to prioritize FL jobs for aggregation, and demonstrate using\nmultiple datasets, models and FL aggregation algorithms that our techniques can\nreduce resource usage by 60+\\% when compared to eager aggregation used in\nexisting FL platforms. We also demonstrate that using JIT aggregation has\nnegligible overhead and impact on the latency of the FL job.",
    "descriptor": "\nComments: 10 pages. Extended version of the paper accepted to MASCOTS 2022. arXiv admin note: text overlap with arXiv:2203.12163\n",
    "authors": [
      "K. R. Jayaram",
      "Ashish Verma",
      "Gegi Thomas",
      "Vinod Muthusamy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09740"
  },
  {
    "id": "arXiv:2208.09741",
    "title": "Sensor Security: Current Progress, Research Challenges, and Future  Roadmap",
    "abstract": "Sensors are one of the most pervasive and integral components of today's\nsafety-critical systems. Sensors serve as a bridge between physical quantities\nand connected systems. The connected systems with sensors blindly believe the\nsensor as there is no way to authenticate the signal coming from a sensor. This\ncould be an entry point for an attacker. An attacker can inject a fake input\nsignal along with the legitimate signal by using a suitable spoofing technique.\nAs the sensor's transducer is not smart enough to differentiate between a fake\nand legitimate signal, the injected fake signal eventually can collapse the\nconnected system. This type of attack is known as the transduction attack. Over\nthe last decade, several works have been published to provide a defense against\nthe transduction attack. However, the defenses are proposed on an ad-hoc basis;\nhence, they are not well-structured. Our work begins to fill this gap by\nproviding a checklist that a defense technique should always follow to be\nconsidered as an ideal defense against the transduction attack. We name this\nchecklist as the Golden reference of sensor defense. We provide insights on how\nthis Golden reference can be achieved and argue that sensors should be\nredesigned from the transducer level to the sensor electronics level. We point\nout that only hardware or software modification is not enough; instead, a\nhardware/software (HW/SW) co-design approach is required to ride on this future\nroadmap to the robust and resilient sensor.",
    "descriptor": "",
    "authors": [
      "Anomadarshi Barua",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09741"
  },
  {
    "id": "arXiv:2208.09743",
    "title": "Where Shall I Touch? Vision-Guided Tactile Poking for Transparent Object  Grasping",
    "abstract": "Picking up transparent objects is still a challenging task for robots. The\nvisual properties of transparent objects such as reflection and refraction make\nthe current grasping methods that rely on camera sensing fail to detect and\nlocalise them. However, humans can handle the transparent object well by first\nobserving its coarse profile and then poking an area of interest to get a fine\nprofile for grasping. Inspired by this, we propose a novel framework of\nvision-guided tactile poking for transparent objects grasping. In the proposed\nframework, a segmentation network is first used to predict the horizontal upper\nregions named as poking regions, where the robot can poke the object to obtain\na good tactile reading while leading to minimal disturbance to the object's\nstate. A poke is then performed with a high-resolution GelSight tactile sensor.\nGiven the local profiles improved with the tactile reading, a heuristic grasp\nis planned for grasping the transparent object. To mitigate the limitations of\nreal-world data collection and labelling for transparent objects, a large-scale\nrealistic synthetic dataset was constructed. Extensive experiments demonstrate\nthat our proposed segmentation network can predict the potential poking region\nwith a high mean Average Precision (mAP) of 0.360, and the vision-guided\ntactile poking can enhance the grasping success rate significantly from 38.9%\nto 85.2%. Thanks to its simplicity, our proposed approach could also be adopted\nby other force or tactile sensors and could be used for grasping of other\nchallenging objects. All the materials used in this paper are available at\nhttps://sites.google.com/view/tactilepoking.",
    "descriptor": "\nComments: 11 pages, 11 figures, accepted by T-Mech\n",
    "authors": [
      "Jiaqi Jiang",
      "Guanqun Cao",
      "Aaron Butterworth",
      "Thanh-Toan Do",
      "Shan Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.09743"
  },
  {
    "id": "arXiv:2208.09744",
    "title": "A Neural Approach to Spatio-Temporal Data Release with User-Level  Differential Privacy",
    "abstract": "Several companies (e.g., Meta, Google) have initiated \"data-for-good\"\nprojects where aggregate location data are first sanitized and released\npublicly, which is useful to many applications in transportation, public health\n(e.g., COVID-19 spread) and urban planning. Differential privacy (DP) is the\nprotection model of choice to ensure the privacy of the individuals who\ngenerated the raw location data. However, current solutions fail to preserve\ndata utility when each individual contributes multiple location reports (i.e.,\nunder user-level privacy). To offset this limitation, public releases by Meta\nand Google use high privacy budgets (e.g., $\\epsilon$=10-100), resulting in\npoor privacy. We propose a novel approach to release spatio-temporal data\nprivately and accurately. We employ the pattern recognition power of neural\nnetworks, specifically variational auto-encoders (VAE), to reduce the noise\nintroduced by DP mechanisms such that accuracy is increased, while the privacy\nrequirement is still satisfied. Our extensive experimental evaluation on real\ndatasets shows the clear superiority of our approach compared to benchmarks.",
    "descriptor": "\nComments: SIGMOD 2023\n",
    "authors": [
      "Ritesh Ahuja",
      "Sepanta Zeighami",
      "Gabriel Ghinita",
      "Cyrus Shahabi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09744"
  },
  {
    "id": "arXiv:2208.09747",
    "title": "Near-Optimal $\u03a6$-Regret Learning in Extensive-Form Games",
    "abstract": "In this paper, we establish efficient and uncoupled learning dynamics so\nthat, when employed by all players in multiplayer perfect-recall\nimperfect-information extensive-form games, the \\emph{trigger regret} of each\nplayer grows as $O(\\log T)$ after $T$ repetitions of play. This improves\nexponentially over the prior best known trigger-regret bound of $O(T^{1/4})$,\nand settles a recent open question by Bai et al. (2022). As an immediate\nconsequence, we guarantee convergence to the set of \\emph{extensive-form\ncorrelated equilibria} and \\emph{coarse correlated equilibria} at a\nnear-optimal rate of $\\frac{\\log T}{T}$.\nBuilding on prior work, at the heart of our construction lies a more general\nresult regarding fixed points deriving from rational functions with\n\\emph{polynomial degree}, a property that we establish for the fixed points of\n\\emph{(coarse) trigger deviation functions}. Moreover, our construction\nleverages a refined \\textit{regret circuit} for the convex hull, which --\nunlike prior guarantees -- preserves the \\emph{RVU property} introduced by\nSyrgkanis et al. (NIPS, 2015); this observation has an independent interest in\nestablishing near-optimal regret under learning dynamics based on a CFR-type\ndecomposition of the regret.",
    "descriptor": "",
    "authors": [
      "Ioannis Anagnostides",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09747"
  },
  {
    "id": "arXiv:2208.09749",
    "title": "Strategic Communication with Cost-Dependent Decoders via the Gray-Wyner  Network",
    "abstract": "In decentralized decision-making problems, communicating agents choose their\nactions based on locally available information and knowledge about decision\nrules or strategies of other agents. In this work, we consider a strategic\ncommunication game between an informed encoder and two decoders communicating\nvia a Gray-Wyner network. All three agents are assumed to be rational and\nendowed with distinct objectives captured by non-aligned cost functions. The\nencoder selects and announces beforehand the compression scheme to be\nimplemented. Then, it transmits three signals: a public signal, and a private\nsignal to each decoder inducing a Bayesian game among the decoders. Our goal is\nto characterize the encoder's minimal long-run cost function subject to the\noptimal compression scheme that satisfies both decoders incentives constraints.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.06201\n",
    "authors": [
      "Rony Bou Rouphael",
      "Ma\u00ebl Le Treust"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.09749"
  },
  {
    "id": "arXiv:2208.09751",
    "title": "MLExchange -- A web-based platform enabling exchangeable machine  learning workflows",
    "abstract": "Machine learning (ML) algorithms are showing a growing trend in helping the\nscientific communities across different disciplines and institutions to address\nlarge and diverse data problems. However, many available ML tools are\nprogrammatically demanding and computationally costly. The MLExchange project\naims to build a collaborative platform equipped with enabling tools that allow\nscientists and facility users who do not have a profound ML background to use\nML and computational resources in scientific discovery. At the high level, we\nare targeting a full user experience where managing and exchanging ML\nalgorithms, workflows, and data are readily available through web applications.\nSo far, we have built four major components, i.e, the central job manager, the\ncentralized content registry, user portal, and search engine, and successfully\ndeployed these components on a testing server.\nSince each component is an independent container, the whole platform or its\nindividual service(s) can be easily deployed at servers of different scales,\nranging from a laptop (usually a single user) to high performance clusters\n(HPC) accessed (simultaneously) by many users. Thus, MLExchange renders\nflexible using scenarios -- users could either access the services and\nresources from a remote server or run the whole platform or its individual\nservice(s) within their local network.",
    "descriptor": "\nComments: Submitting to The Int'l Conference for High Performance Computing, Networking, Storage, and Analysis\n",
    "authors": [
      "Zhuowen Zhao",
      "Tanny Chavez",
      "Elizabeth Holman",
      "Guanhua Hao",
      "Adam Green",
      "Harinarayan Krishnan",
      "Dylan McReynolds",
      "Ronald Pandolfi",
      "Eric J. Roberts",
      "Petrus H. Zwart",
      "Howard Yanxon",
      "Nicholas Schwarz",
      "Subramanian Sankaranarayanan",
      "Sergei V. Kalinin",
      "Apurva Mehta",
      "Stuart Campbel",
      "Alexander Hexemer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09751"
  },
  {
    "id": "arXiv:2208.09753",
    "title": "A Modified Trapezoidal Rule for a Class of Weakly Singular Integrals in  n Dimensions",
    "abstract": "In this paper we propose and analyze a general arbitrarily high-order\nmodified trapezoidal rule for a class of weakly singular integrals of the forms\n$I = \\int_{\\mathbb{R}^n}\\phi(x)s(x)dx$ in $n$ dimensions, where $\\phi\\in\nC_c^N(\\mathbb{R}^n)$ for some sufficiently large $N$ and $s$ is the weakly\nsingular kernel. The admissible class of weakly singular kernel requires $s$\nsatisfies dilation and symmetry properties and is large enough to contain\nfunctions of the form $\\frac{P(x)}{|x|^r}$ where $r > 0$ and $P(x)$ is any\nmonomials such that $\\text{deg} P < r < \\text{deg} P + n$. The modified\ntrapezoidal rule is the singularity-punctured trapezoidal rule added by\ncorrection terms involving the correction weights for grid points around\nsingularity. Correction weights are determined by enforcing the quadrature rule\nexactly evaluates some monomials and solving corresponding linear systems. A\nlong-standing difficulty of these type of methods is establishing the\nnon-singularity of the linear system, despite strong numerical evidences. By\nusing an algebraic-combinatorial argument, we show the non-singularity always\nholds and prove the general order of convergence of the modified quadrature\nrule. We present numerical experiments to validate the order of convergence.",
    "descriptor": "",
    "authors": [
      "Senbao Jiang",
      "Xiaofan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09753"
  },
  {
    "id": "arXiv:2208.09754",
    "title": "FLIS: Clustered Federated Learning via Inference Similarity for Non-IID  Data Distribution",
    "abstract": "Classical federated learning approaches yield significant performance\ndegradation in the presence of Non-IID data distributions of participants. When\nthe distribution of each local dataset is highly different from the global one,\nthe local objective of each client will be inconsistent with the global optima\nwhich incur a drift in the local updates. This phenomenon highly impacts the\nperformance of clients. This is while the primary incentive for clients to\nparticipate in federated learning is to obtain better personalized models. To\naddress the above-mentioned issue, we present a new algorithm, FLIS, which\ngroups the clients population in clusters with jointly trainable data\ndistributions by leveraging the inference similarity of clients' models. This\nframework captures settings where different groups of users have their own\nobjectives (learning tasks) but by aggregating their data with others in the\nsame cluster (same learning task) to perform more efficient and personalized\nfederated learning. We present experimental results to demonstrate the benefits\nof FLIS over the state-of-the-art benchmarks on CIFAR-100/10, SVHN, and FMNIST\ndatasets. Our code is available at https://github.com/MMorafah/FLIS.",
    "descriptor": "",
    "authors": [
      "Mahdi Morafah",
      "Saeed Vahidian",
      "Weijia Wang",
      "Bill Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09754"
  },
  {
    "id": "arXiv:2208.09756",
    "title": "Artifact-Based Domain Generalization of Skin Lesion Models",
    "abstract": "Deep Learning failure cases are abundant, particularly in the medical area.\nRecent studies in out-of-distribution generalization have advanced considerably\non well-controlled synthetic datasets, but they do not represent medical\nimaging contexts. We propose a pipeline that relies on artifacts annotation to\nenable generalization evaluation and debiasing for the challenging skin lesion\nanalysis context. First, we partition the data into levels of increasingly\nhigher biased training and test sets for better generalization assessment.\nThen, we create environments based on skin lesion artifacts to enable domain\ngeneralization methods. Finally, after robust training, we perform a test-time\ndebiasing procedure, reducing spurious features in inference images. Our\nexperiments show our pipeline improves performance metrics in biased cases, and\navoids artifacts when using explanation methods. Still, when evaluating such\nmodels in out-of-distribution data, they did not prefer clinically-meaningful\nfeatures. Instead, performance only improved in test sets that present similar\nartifacts from training, suggesting models learned to ignore the known set of\nartifacts. Our results raise a concern that debiasing models towards a single\naspect may not be enough for fair skin lesion analysis.",
    "descriptor": "\nComments: Accepted to the ISIC Skin Image Analysis Workshop @ ECCV 2022\n",
    "authors": [
      "Alceu Bissoto",
      "Catarina Barata",
      "Eduardo Valle",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09756"
  },
  {
    "id": "arXiv:2208.09759",
    "title": "ReckOn: A 28nm Sub-mm2 Task-Agnostic Spiking Recurrent Neural Network  Processor Enabling On-Chip Learning over Second-Long Timescales",
    "abstract": "A robust real-world deployment of autonomous edge devices requires on-chip\nadaptation to user-, environment- and task-induced variability. Due to on-chip\nmemory constraints, prior learning devices were limited to static stimuli with\nno temporal contents. We propose a 0.45-mm$^2$ spiking RNN processor enabling\ntask-agnostic online learning over seconds, which we demonstrate for\nnavigation, gesture recognition, and keyword spotting within a 0.8-% memory\noverhead and a <150-$\\mu$W training power budget.",
    "descriptor": "\nComments: Published in the 2022 IEEE International Solid-State Circuits Conference (ISSCC), 2022\n",
    "authors": [
      "Charlotte Frenkel",
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2208.09759"
  },
  {
    "id": "arXiv:2208.09764",
    "title": "GAIROSCOPE: Injecting Data from Air-Gapped Computers to Nearby  Gyroscopes",
    "abstract": "It is known that malware can leak data from isolated, air-gapped computers to\nnearby smartphones using ultrasonic waves. However, this covert channel\nrequires access to the smartphone's microphone, which is highly protected in\nAndroid OS and iOS, and might be non-accessible, disabled, or blocked.\nIn this paper we present `GAIROSCOPE,' an ultrasonic covert channel that\ndoesn't require a microphone on the receiving side. Our malware generates\nultrasonic tones in the resonance frequencies of the MEMS gyroscope. These\ninaudible frequencies produce tiny mechanical oscillations within the\nsmartphone's gyroscope, which can be demodulated into binary information.\nNotably, the gyroscope in smartphones is considered to be a 'safe' sensor that\ncan be used legitimately from mobile apps and javascript. We introduce the\nadversarial attack model and present related work. We provide the relevant\ntechnical background and show the design and implementation of GAIROSCOPE. We\npresent the evaluation results and discuss a set of countermeasures to this\nthreat. Our experiments show that attackers can exfiltrate sensitive\ninformation from air-gapped computers to smartphones located a few meters away\nvia Speakers-to-Gyroscope covert channel.",
    "descriptor": "",
    "authors": [
      "Mordechai Guri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09764"
  },
  {
    "id": "arXiv:2208.09770",
    "title": "Z-Code++: A Pre-trained Language Model Optimized for Abstractive  Summarization",
    "abstract": "This paper presents Z-Code++, a new pre-trained language model optimized for\nabstractive text summarization. The model extends the state of the art\nencoder-decoder model using three techniques. First, we use a two-phase\npre-training process to improve model's performance on low-resource\nsummarization tasks. The model is first pre-trained using text corpora for\nlanguage understanding, and then is continually pre-trained on summarization\ncorpora for grounded text generation. Second, we replace self-attention layers\nin the encoder with disentangled attention layers, where each word is\nrepresented using two vectors that encode its content and position,\nrespectively. Third, we use fusion-in-encoder, a simple yet effective method of\nencoding long sequences in a hierarchical manner. Z-Code++ creates new state of\nthe art on 9 out of 13 text summarization tasks across 5 languages. Our model\nis parameter-efficient in that it outperforms the 600x larger PaLM-540B on\nXSum, and the finetuned 200x larger GPT3-175B on SAMSum. In zero-shot and\nfew-shot settings, our model substantially outperforms the competing models.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Pengcheng He",
      "Baolin Peng",
      "Liyang Lu",
      "Song Wang",
      "Jie Mei",
      "Yang Liu",
      "Ruochen Xu",
      "Hany Hassan Awadalla",
      "Yu Shi",
      "Chenguang Zhu",
      "Wayne Xiong",
      "Michael Zeng",
      "Jianfeng Gao",
      "Xuedong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2208.09770"
  },
  {
    "id": "arXiv:2208.09776",
    "title": "Privacy-Preserving Protocols for Smart Cameras and Other IoT Devices",
    "abstract": "Millions of consumers depend on smart camera systems to remotely monitor\ntheir homes and businesses. However, the architecture and design of popular\ncommercial systems require users to relinquish control of their data to\nuntrusted third parties, such as service providers (e.g., the cloud). Third\nparties therefore can (and in some instances have) access the video footage\nwithout the users' knowledge or consent -- violating the core tenet of user\nprivacy. In this paper, we introduce CaCTUs, a privacy-preserving smart camera\nsystem that returns control to the user; the root of trust begins with the user\nand is maintained through a series of cryptographic protocols designed to\nsupport popular features, such as sharing, deleting, and viewing videos live.\nIn so doing, we demonstrate that it is feasible to implement a performant\nsmart-camera system that leverages the convenience of a cloud-based model while\nretaining the ability to control access to (private) data. We then discuss how\nour techniques and protocols can also be extended to privacy-preserving designs\nof other IoT devices recording time series data.",
    "descriptor": "\nComments: Extension of arXiv:2201.09338\n",
    "authors": [
      "Yohan Beugin",
      "Quinn Burke",
      "Blaine Hoak",
      "Ryan Sheatsley",
      "Eric Pauley",
      "Gang Tan",
      "Syed Rafiul Hussain",
      "Patrick McDaniel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09776"
  },
  {
    "id": "arXiv:2208.09777",
    "title": "JVLDLoc: a Joint Optimization of Visual-LiDAR Constraints and Direction  Priors for Localization in Driving Scenario",
    "abstract": "The ability for a moving agent to localize itself in environment is the basic\ndemand for emerging applications, such as autonomous driving, etc. Many\nexisting methods based on multiple sensors still suffer from drift. We propose\na scheme that fuses map prior and vanishing points from images, which can\nestablish an energy term that is only constrained on rotation, called the\ndirection projection error. Then we embed these direction priors into a\nvisual-LiDAR SLAM system that integrates camera and LiDAR measurements in a\ntightly-coupled way at backend. Specifically, our method generates visual\nreprojection error and point to Implicit Moving Least Square(IMLS) surface of\nscan constraints, and solves them jointly along with direction projection error\nat global optimization. Experiments on KITTI, KITTI-360 and Oxford Radar\nRobotcar show that we achieve lower localization error or Absolute Pose Error\n(APE) than prior map, which validates our method is effective.",
    "descriptor": "\nComments: 28 pages (including supplementary material)\n",
    "authors": [
      "Longrui Dong",
      "Gang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.09777"
  },
  {
    "id": "arXiv:2208.09778",
    "title": "The Development of a Labelled te reo M\u0101ori-English Bilingual Database  for Language Technology",
    "abstract": "Te reo M\\=aori (referred to as M\\=aori), New Zealand's indigenous language,\nis under-resourced in language technology. M\\=aori speakers are bilingual,\nwhere M\\=aori is code-switched with English. Unfortunately, there are minimal\nresources available for M\\=aori language technology, language detection and\ncode-switch detection between M\\=aori-English pair. Both English and M\\=aori\nuse Roman-derived orthography making rule-based systems for detecting language\nand code-switching restrictive. Most M\\=aori language detection is done\nmanually by language experts. This research builds a M\\=aori-English bilingual\ndatabase of 66,016,807 words with word-level language annotation. The New\nZealand Parliament Hansard debates reports were used to build the database. The\nlanguage labels are assigned using language-specific rules and expert manual\nannotations. Words with the same spelling, but different meanings, exist for\nM\\=aori and English. These words could not be categorised as M\\=aori or English\nbased on word-level language rules. Hence, manual annotations were necessary.\nAn analysis reporting the various aspects of the database such as metadata,\nyear-wise analysis, frequently occurring words, sentence length and N-grams is\nalso reported. The database developed here is a valuable tool for future\nlanguage and speech technology development for Aotearoa New Zealand. The\nmethodology followed to label the database can also be followed by other\nlow-resourced language pairs.",
    "descriptor": "\nComments: Submitted to Springer Language Resources and Evaluation Journal 2022\n",
    "authors": [
      "Jesin James",
      "Isabella Shields",
      "Vithya Yogarajan",
      "Peter J. Keegan",
      "Catherine Watson",
      "Peter-Lucas Jones",
      "Keoni Mahelona"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09778"
  },
  {
    "id": "arXiv:2208.09779",
    "title": "Robust Node Classification on Graphs: Jointly from Bayesian Label  Transition and Topology-based Label Propagation",
    "abstract": "Node classification using Graph Neural Networks (GNNs) has been widely\napplied in various real-world scenarios. However, in recent years, compelling\nevidence emerges that the performance of GNN-based node classification may\ndeteriorate substantially by topological perturbation, such as random\nconnections or adversarial attacks. Various solutions, such as topological\ndenoising methods and mechanism design methods, have been proposed to develop\nrobust GNN-based node classifiers but none of these works can fully address the\nproblems related to topological perturbations. Recently, the Bayesian label\ntransition model is proposed to tackle this issue but its slow convergence may\nlead to inferior performance. In this work, we propose a new label inference\nmodel, namely LInDT, which integrates both Bayesian label transition and\ntopology-based label propagation for improving the robustness of GNNs against\ntopological perturbations. LInDT is superior to existing label transition\nmethods as it improves the label prediction of uncertain nodes by utilizing\nneighborhood-based label propagation leading to better convergence of label\ninference. Besides, LIndT adopts asymmetric Dirichlet distribution as a prior,\nwhich also helps it to improve label inference. Extensive experiments on five\ngraph datasets demonstrate the superiority of LInDT for GNN-based node\nclassification under three scenarios of topological perturbations.",
    "descriptor": "\nComments: The paper is accepted for CIKM 2022\n",
    "authors": [
      "Jun Zhuang",
      "Mohammad Al Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09779"
  },
  {
    "id": "arXiv:2208.09781",
    "title": "Co-optimizing Distributed Energy Resources in Linear Complexity under  Net Energy Metering",
    "abstract": "The co-optimization of behind-the-meter distributed energy resources is\nconsidered for residential and commercial prosumers. The distributed energy\nresources include renewable generations, flexible demands, and battery storage.\nAn energy management system schedules the consumptions and battery storage\nbased on locally available stochastic renewables by maximizing the expected\noperation surplus under the net energy metering tariff. A stochastic dynamic\nprogramming formulation is introduced for which structural properties of the\ndynamic optimization are derived. A closed-form scheduling of co-optimized\nconsumption and storage is proposed, which achieves optimality when the storage\ncapacity constraint is nonbinding. The closed-form solution results in a\nlinear-complexity storage-consumption co-optimization that can be implemented\nin a decentralized fashion. The economic benefits of the prosumers and the\ndistribution system operator are evaluated in numerical simulations.",
    "descriptor": "\nComments: 14 pages, 7 figures, 3 tables\n",
    "authors": [
      "Ahmed S. Alahmed",
      "Lang Tong",
      "Qing Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09781"
  },
  {
    "id": "arXiv:2208.09785",
    "title": "High-Performance Transmission Mechanism Design of Multi-Stream Carrier  Aggregation for 5G Non-Standalone Network",
    "abstract": "Multi-stream carrier aggregation is a key technology to expand bandwidth and\nimprove the throughput of the fifth-generation wireless communication systems.\nHowever, due to the diversified propagation properties of different frequency\nbands, the traffic migration task is much more challenging, especially in\nhybrid sub-6 GHz and millimeter wave bands scenario. Existing schemes either\nneglected to consider the transmission rate difference between multi-stream\ncarrier, or only consider simple low mobility scenario. In this paper, we\npropose a low-complexity traffic splitting algorithm based on fuzzy\nproportional integral derivative control mechanism. The proposed algorithm only\nrelies on the local radio link control buffer information of sub-6 GHz and\nmmWave bands, while frequent feedback from user equipment (UE) side is\nminimized. As shown in the numerical examples, the proposed traffic splitting\nmechanism can achieve more than 90% link resource utilization ratio for\ndifferent UE transmission requirements with different mobilities, which\ncorresponds to 10% improvement if compared with conventional baselines.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Jun Yu",
      "Shunqing Zhang",
      "Jiayun Sun",
      "Shugong Xu",
      "Shan Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09785"
  },
  {
    "id": "arXiv:2208.09787",
    "title": "RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking",
    "abstract": "RGB-D object tracking has attracted considerable attention recently,\nachieving promising performance thanks to the symbiosis between visual and\ndepth channels. However, given a limited amount of annotated RGB-D tracking\ndata, most state-of-the-art RGB-D trackers are simple extensions of\nhigh-performance RGB-only trackers, without fully exploiting the underlying\npotential of the depth channel in the offline training stage. To address the\ndataset deficiency issue, a new RGB-D dataset named RGBD1K is released in this\npaper. The RGBD1K contains 1,050 sequences with about 2.5M frames in total. To\ndemonstrate the benefits of training on a larger RGB-D data set in general, and\nRGBD1K in particular, we develop a transformer-based RGB-D tracker, named SPT,\nas a baseline for future visual object tracking studies using the new dataset.\nThe results, of extensive experiments using the SPT tracker emonstrate the\npotential of the RGBD1K dataset to improve the performance of RGB-D tracking,\ninspiring future developments of effective tracker designs. The dataset and\ncodes will be available on the project homepage:\nhttps://will.be.available.at.this.website.",
    "descriptor": "",
    "authors": [
      "Xue-Feng Zhu",
      "Tianyang Xu",
      "Zhangyong Tang",
      "Zucheng Wu",
      "Haodong Liu",
      "Xiao Yang",
      "Xiao-Jun Wu",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09787"
  },
  {
    "id": "arXiv:2208.09788",
    "title": "FaceOff: A Video-to-Video Face Swapping System",
    "abstract": "Doubles play an indispensable role in the movie industry. They take the place\nof the actors in dangerous stunt scenes or in scenes where the same actor plays\nmultiple characters. The double's face is later replaced with the actor's face\nand expressions manually using expensive CGI technology, costing millions of\ndollars and taking months to complete. An automated, inexpensive, and fast way\ncan be to use face-swapping techniques that aim to swap an identity from a\nsource face video (or an image) to a target face video. However, such methods\ncan not preserve the source expressions of the actor important for the scene's\ncontext. % essential for the scene. % that are essential in cinemas. To tackle\nthis challenge, we introduce video-to-video (V2V) face-swapping, a novel task\nof face-swapping that can preserve (1) the identity and expressions of the\nsource (actor) face video and (2) the background and pose of the target\n(double) video. We propose FaceOff, a V2V face-swapping system that operates by\nlearning a robust blending operation to merge two face videos following the\nconstraints above. It first reduces the videos to a quantized latent space and\nthen blends them in the reduced space. FaceOff is trained in a self-supervised\nmanner and robustly tackles the non-trivial challenges of V2V face-swapping. As\nshown in the experimental section, FaceOff significantly outperforms alternate\napproaches qualitatively and quantitatively.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Aditya Agarwal",
      "Bipasha Sen",
      "Rudrabha Mukhopadhyay",
      "Vinay Namboodiri",
      "C.V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09788"
  },
  {
    "id": "arXiv:2208.09790",
    "title": "Preemptive Scheduling of EV Charging for Providing Demand Response  Services",
    "abstract": "We develop a new algorithm for scheduling the charging process of a large\nnumber of electric vehicles (EVs) over a finite horizon. We assume that EVs\narrive at the charging stations with different charge levels and different\nflexibility windows. The arrival process is assumed to have a known\ndistribution and that the charging process of EVs can be preemptive. We pose\nthe scheduling problem as a dynamic program with constraints. We show that the\nresulting formulation leads to a monotone dynamic program with Lipschitz\ncontinuous value functions that are robust against perturbation of system\nparameters. We propose a simulation based fitted value iteration algorithm to\ndetermine the value function approximately, and derive the sample complexity\nfor computing the approximately optimal solution.",
    "descriptor": "",
    "authors": [
      "Shiping Shao",
      "Farshad Harirchi",
      "Devang Dave",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09790"
  },
  {
    "id": "arXiv:2208.09795",
    "title": "Stop&Hop: Early Classification of Irregular Time Series",
    "abstract": "Early classification algorithms help users react faster to their machine\nlearning model's predictions. Early warning systems in hospitals, for example,\nlet clinicians improve their patients' outcomes by accurately predicting\ninfections. While early classification systems are advancing rapidly, a major\ngap remains: existing systems do not consider irregular time series, which have\nuneven and often-long gaps between their observations. Such series are\nnotoriously pervasive in impactful domains like healthcare. We bridge this gap\nand study early classification of irregular time series, a new setting for\nearly classifiers that opens doors to more real-world problems. Our solution,\nStop&Hop, uses a continuous-time recurrent network to model ongoing irregular\ntime series in real time, while an irregularity-aware halting policy, trained\nwith reinforcement learning, predicts when to stop and classify the streaming\nseries. By taking real-valued step sizes, the halting policy flexibly decides\nexactly when to stop ongoing series in real time. This way, Stop&Hop seamlessly\nintegrates information contained in the timing of observations, a new and vital\nsource for early classification in this setting, with the time series values to\nprovide early classifications for irregular time series. Using four synthetic\nand three real-world datasets, we demonstrate that Stop&Hop consistently makes\nearlier and more-accurate predictions than state-of-the-art alternatives\nadapted to this new problem. Our code is publicly available at\nhttps://github.com/thartvigsen/StopAndHop.",
    "descriptor": "\nComments: This paper was accepted to CIKM'22. Code at this https URL\n",
    "authors": [
      "Thomas Hartvigsen",
      "Walter Gerych",
      "Jidapa Thadajarassiri",
      "Xiangnan Kong",
      "Elke Rundensteiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09795"
  },
  {
    "id": "arXiv:2208.09796",
    "title": "Towards MOOCs for Lip Reading: Using Synthetic Talking Heads to Train  Humans in Lipreading at Scale",
    "abstract": "Many people with some form of hearing loss consider lipreading as their\nprimary mode of day-to-day communication. However, finding resources to learn\nor improve one's lipreading skills can be challenging. This is further\nexacerbated in COVID$19$ pandemic due to restrictions on direct interactions\nwith peers and speech therapists. Today, online MOOCs platforms like Coursera\nand Udemy have become the most effective form of training for many kinds of\nskill development. However, online lipreading resources are scarce as creating\nsuch resources is an extensive process needing months of manual effort to\nrecord hired actors. Because of the manual pipeline, such platforms are also\nlimited in the vocabulary, supported languages, accents, and speakers, and have\na high usage cost. In this work, we investigate the possibility of replacing\nreal human talking videos with synthetically generated videos. Synthetic data\ncan be used to easily incorporate larger vocabularies, variations in accent,\nand even local languages, and many speakers. We propose an end-to-end automated\npipeline to develop such a platform using state-of-the-art talking heading\nvideo generator networks, text-to-speech models, and computer vision\ntechniques. We then perform an extensive human evaluation using carefully\nthought out lipreading exercises to validate the quality of our designed\nplatform against the existing lipreading platforms. Our studies concretely\npoint towards the potential of our approach for the development of a\nlarge-scale lipreading MOOCs platform that can impact millions of people with\nhearing loss.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Aditya Agarwal",
      "Bipasha Sen",
      "Rudrabha Mukhopadhyay",
      "Vinay Namboodiri",
      "C.V Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09796"
  },
  {
    "id": "arXiv:2208.09798",
    "title": "Scalable link prediction in Twitter using self-configured framework",
    "abstract": "Link prediction analysis becomes vital to acquire a deeper understanding of\nevents underlying social networks interactions and connections especially in\ncurrent evolving and large-scale social networks. Traditional link prediction\napproaches underperformed for most large-scale social networks in terms of its\nscalability and efficiency. Spark is a distributed open-source framework that\nfacilitate scalable link prediction efficiency in large-scale social networks.\nThe framework provides numerous tunable properties for users to manually\nconfigure the parameters for the applications. However, manual configurations\nopen to performance issue when the applications start scaling tremendously,\nwhich is hard to set up and expose to human errors. This paper introduced a\nnovel Self-Configured Framework (SCF) to provide an autonomous feature in Spark\nthat predicts and sets the best configuration instantly before the application\nexecution using XGBoost classifier. SCF is evaluated on the Twitter social\nnetwork using three link prediction applications: Graph Clustering (GC),\nOverlapping Community Detection (OCD), and Redundant Graph Clustering (RGD) to\nassess the impact of shifting data sizes on different applications in Twitter.\nThe result demonstrates a 40% reduction in prediction time as well as a\nbalanced resource consumption that makes full use of resources, especially for\nlimited number and size of clusters",
    "descriptor": "",
    "authors": [
      "Nur Nasuha Daud",
      "Siti Hafizah Ab Hamid",
      "Chempaka Seri",
      "Muntadher Saadoon",
      "Nor Badrul Anuar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.09798"
  },
  {
    "id": "arXiv:2208.09800",
    "title": "Zeno: A Scalable Capability-Based Secure Architecture",
    "abstract": "Despite the numerous efforts of security researchers, memory vulnerabilities\nremain a top issue for modern computing systems. Capability-based solutions aim\nto solve whole classes of memory vulnerabilities at the hardware level by\nencoding access permissions with each memory reference. While some capability\nsystems have seen commercial adoption, little work has been done to apply a\ncapability model to datacenter-scale systems. Cloud and high-performance\ncomputing often require programs to share memory across many compute nodes.\nThis presents a challenge for existing capability models, as capabilities must\nbe enforceable across multiple nodes. Each node must agree on what access\npermissions a capability has and overheads of remote memory access must remain\nmanageable.\nTo address these challenges, we introduce Zeno, a new capability-based\narchitecture. Zeno supports a Namespace-based capability model to support\nglobally shareable capabilities in a large-scale, multi-node system. In this\nwork, we describe the Zeno architecture, define Zeno's security properties,\nevaluate the scalability of Zeno as a large-scale capability architecture, and\nmeasure the hardware overhead with an FPGA implementation.",
    "descriptor": "",
    "authors": [
      "Alan Ehret",
      "Jacob Abraham",
      "Mihailo Isakov",
      "Michel A. Kinsy"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09800"
  },
  {
    "id": "arXiv:2208.09801",
    "title": "PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D  Point Cloud Recognition",
    "abstract": "3D Point cloud is becoming a critical data representation in many real-world\napplications like autonomous driving, robotics, and medical imaging. Although\nthe success of deep learning further accelerates the adoption of 3D point\nclouds in the physical world, deep learning is notorious for its vulnerability\nto adversarial attacks. In this work, we first identify that the\nstate-of-the-art empirical defense, adversarial training, has a major\nlimitation in applying to 3D point cloud models due to gradient obfuscation. We\nfurther propose PointDP, a purification strategy that leverages diffusion\nmodels to defend against 3D adversarial attacks. We extensively evaluate\nPointDP on six representative 3D point cloud architectures, and leverage 10+\nstrong and adaptive attacks to demonstrate its lower-bound robustness. Our\nevaluation shows that PointDP achieves significantly better robustness than\nstate-of-the-art purification methods under strong attacks. Results of\ncertified defenses on randomized smoothing combined with PointDP will be\nincluded in the near future.",
    "descriptor": "",
    "authors": [
      "Jiachen Sun",
      "Weili Nie",
      "Zhiding Yu",
      "Z. Morley Mao",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09801"
  },
  {
    "id": "arXiv:2208.09803",
    "title": "Turing Machines with Two-level Memory: A Deep Look into the Input/Output  Complexity",
    "abstract": "The input/output complexity, which is the complexity of data exchange between\nthe main memory and the external memory, has been elaborately studied by a lot\nof former researchers. However, the existing works failed to consider the\ninput/output complexity in a computation model point of view. In this paper we\nremedy this by proposing three variants of Turing machine that include external\nmemory and the mechanism of exchanging data between main memory and external\nmemory. Based on these new models, the input/output complexity is deeply\nstudied. We discussed the relationship between input/output complexity and the\nother complexity measures such as time complexity and parameterized complexity,\nwhich is not considered by former researchers. We also define the external\naccess trace complexity, which reflects the physical behavior of magnetic disks\nand gives a theoretical evidence of IO-efficient algorithms.",
    "descriptor": "",
    "authors": [
      "Hengzhao Ma",
      "Jianzhong Li",
      "Xiangyu Gao",
      "Tianpeng Gao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2208.09803"
  },
  {
    "id": "arXiv:2208.09809",
    "title": "A Work-Efficient Parallel Algorithm for Longest Increasing Subsequence",
    "abstract": "This paper studies parallel algorithms for the longest increasing subsequence\n(LIS) problem. Let $n$ be the input size and $k$ be the LIS length of the\ninput. Sequentially, LIS is a simple textbook problem that can be solved using\ndynamic programming (DP) in $O(n\\log n)$ work. However, parallelizing LIS is a\nlong-standing challenge. We are unaware of any parallel LIS algorithm that has\noptimal $O(n\\log n)$ work and non-trivial parallelism (i.e., $\\tilde{O}(k)$ or\n$o(n)$ span). Here, the work of a parallel algorithm is the total number of\noperations, and the span is the longest dependent instructions.\nThis paper proposes a parallel LIS algorithm that costs $O(n\\log k)$ work,\n$\\tilde{O}(k)$ span, and $O(n)$ space, and is \\emph{much simpler} than the\nprevious parallel LIS algorithms. We also generalize the algorithm to a\nweighted version of LIS, which maximizes the weighted sum for all objects in an\nincreasing subsequence. Our weighted LIS algorithm has $O(n\\log^2 n)$ work and\n$\\tilde{O}(k)$ span.\nWe also implemented our parallel LIS algorithms. Due to simplicity, our\nimplementation is light-weighted, efficient, and scalable. On input size\n$10^9$, our LIS algorithm outperforms a highly-optimized sequential algorithm\n(with $O(n\\log k)$ cost) on inputs with $k\\le 3\\times 10^5$. Our algorithm is\nalso much faster than the best existing parallel implementation by Shen et al.\non all input instances.",
    "descriptor": "",
    "authors": [
      "Yan Gu",
      "Zheqi Shen",
      "Yihan Sun",
      "Zijin Wan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09809"
  },
  {
    "id": "arXiv:2208.09814",
    "title": "Critical Bach Size Minimizes Stochastic First-Order Oracle Complexity of  Deep Learning Optimizer using Hyperparameters Close to One",
    "abstract": "Practical results have shown that deep learning optimizers using small\nconstant learning rates, hyperparameters close to one, and large batch sizes\ncan find the model parameters of deep neural networks that minimize the loss\nfunctions. We first show theoretical evidence that the momentum method\n(Momentum) and adaptive moment estimation (Adam) perform well in the sense that\nthe upper bound of the theoretical performance measure is small with a small\nconstant learning rate, hyperparameters close to one, and a large batch size.\nNext, we show that there exists a batch size called the critical batch size\nminimizing the stochastic first-order oracle (SFO) complexity, which is the\nstochastic gradient computation cost, and that SFO complexity increases once\nthe batch size exceeds the critical batch size. Finally, we provide numerical\nresults that support our theoretical results. That is, the numerical results\nindicate that Adam using a small constant learning rate, hyperparameters close\nto one, and the critical batch size minimizing SFO complexity has faster\nconvergence than Momentum and stochastic gradient descent (SGD).",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.07163\n",
    "authors": [
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09814"
  },
  {
    "id": "arXiv:2208.09815",
    "title": "LWA-HAND: Lightweight Attention Hand for Interacting Hand Reconstruction",
    "abstract": "Hand reconstruction has achieved great success in real-time applications such\nas visual reality and augmented reality while interacting with two-hand\nreconstruction through efficient transformers is left unexplored. In this\npaper, we propose a method called lightweight attention hand (LWA-HAND) to\nreconstruct hands in low flops from a single RGB image. To solve the occlusion\nand interaction challenges in efficient attention architectures, we introduce\nthree mobile attention modules. The first module is a lightweight feature\nattention module that extracts both local occlusion representation and global\nimage patch representation in a coarse-to-fine manner. The second module is a\ncross image and graph bridge module which fuses image context and hand vertex.\nThe third module is a lightweight cross-attention mechanism that uses\nelement-wise operation for cross attention of two hands in linear complexity.\nThe resulting model achieves comparable performance on the InterHand2.6M\nbenchmark in comparison with the state-of-the-art models. Simultaneously, it\nreduces the flops to $0.47GFlops$ while the state-of-the-art models have heavy\ncomputations between $10GFlops$ and $20GFlops$.",
    "descriptor": "\nComments: Accepted by ECCV 2022 Computer Vision for Metaverse Workshop (17 pages, 6 figures, 1 table). arXiv admin note: substantial text overlap with arXiv:2203.09364 by other authors\n",
    "authors": [
      "Xinhan Di",
      "Pengqian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09815"
  },
  {
    "id": "arXiv:2208.09818",
    "title": "Rate-Splitting Multiple Access for Intelligent Reflecting Surface-Aided  Secure Transmission",
    "abstract": "In this letter, we study a rate-splitting multiple access (RSMA)-based\nintelligent reflecting surface (IRS)-aided multi-user multiple-input\nsingle-output (MISO) secure communication system with a potential eavesdropper\n(Eve). Aiming to maximize the minimum secrecy rate (SR) among all the\nlegitimate users (LUs), a design problem for jointly optimizing the transmit\nbeamforming with artificial noise (AN), the IRS beamforming, and the secrecy\ncommon rate allocation is formulated. Since the design problem is highly\nnon-convex with coupled optimization variables, we develop a computationally\nefficient algorithm based on the alternating optimization (AO) technique to\nsolve it suboptimally. Numerical results demonstrate that the proposed design\ncan significantly improve the max-min SR over the benchmark schemes adopting\nother multiple access techniques. In particular, employing the RSMA strategy\ncan substantially reduce the required numbers of IRS elements for achieving a\ntarget level of secrecy performance compared with the benchmark schemes.",
    "descriptor": "\nComments: 5 pages, 6 figures, submitted to IEEE journal for possible publication\n",
    "authors": [
      "Ying Gao",
      "Qingqing Wu",
      "Wen Chen",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.09818"
  },
  {
    "id": "arXiv:2208.09821",
    "title": "On The Robustness of Channel Allocation in Joint Radar And Communication  Systems: An Auction Approach",
    "abstract": "Joint radar and communication (JRC) is a promising technique for spectrum\nre-utilization, which enables radar sensing and data transmission to operate on\nthe same frequencies and the same devices. However, due to the multi-objective\nproperty of JRC systems, channel allocation to JRC nodes should be carefully\ndesigned to maximize system performance. Additionally, because of the broadcast\nnature of wireless signals, a watchful adversary, i.e., a warden, can detect\nongoing transmissions and attack the system. Thus, we develop a covert JRC\nsystem that minimizes the detection probability by wardens, in which friendly\njammers are deployed to improve the covertness of the JRC nodes during radar\nsensing and data transmission operations. Furthermore, we propose a robust\nmulti-item auction design for channel allocation for such a JRC system that\nconsiders the uncertainty in bids. The proposed auction mechanism achieves the\nproperties of truthfulness, individual rationality, budget feasibility, and\ncomputational efficiency. The simulations clearly show the benefits of our\ndesign to support covert JRC systems and to provide incentive to the JRC nodes\nin obtaining spectrum, in which the auction-based channel allocation mechanism\nis robust against perturbations in the bids, which is highly effective for JRC\nnodes working in uncertain environments.",
    "descriptor": "",
    "authors": [
      "Ismail Lotfi",
      "Hongyang Du",
      "Dusit Niyato",
      "Sumei Sun",
      "Dong In Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.09821"
  },
  {
    "id": "arXiv:2208.09822",
    "title": "IAAT: A Input-Aware Adaptive Tuning framework for Small GEMM",
    "abstract": "GEMM with the small size of input matrices is becoming widely used in many\nfields like HPC and machine learning. Although many famous BLAS libraries\nalready supported small GEMM, they cannot achieve near-optimal performance.\nThis is because the costs of pack operations are high and frequent boundary\nprocessing cannot be neglected. This paper proposes an input-aware adaptive\ntuning framework(IAAT) for small GEMM to overcome the performance bottlenecks\nin state-of-the-art implementations. IAAT consists of two stages, the\ninstall-time stage and the run-time stage. In the run-time stage, IAAT tiles\nmatrices into blocks to alleviate boundary processing. This stage utilizes an\ninput-aware adaptive tile algorithm and plays the role of runtime tuning. In\nthe install-time stage, IAAT auto-generates hundreds of kernels of different\nsizes to remove pack operations. Finally, IAAT finishes the computation of\nsmall GEMM by invoking different kernels, which corresponds to the size of\nblocks. The experimental results show that IAAT gains better performance than\nother BLAS libraries on ARMv8 platform.",
    "descriptor": "",
    "authors": [
      "Jianyu Yao",
      "Boqian Shi",
      "Chunyang Xiang",
      "Haipeng Jia",
      "Chendi Li",
      "Hang Cao",
      "Yunquan Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2208.09822"
  },
  {
    "id": "arXiv:2208.09823",
    "title": "Depth-Assisted ResiDualGAN for Cross-Domain Aerial Images Semantic  Segmentation",
    "abstract": "Unsupervised domain adaptation (UDA) is an approach to minimizing domain gap.\nGenerative methods are common approaches to minimizing the domain gap of aerial\nimages which improves the performance of the downstream tasks, e.g.,\ncross-domain semantic segmentation. For aerial images, the digital surface\nmodel (DSM) is usually available in both the source domain and the target\ndomain. Depth information in DSM brings external information to generative\nmodels. However, little research utilizes it. In this paper, depth-assisted\nResiDualGAN (DRDG) is proposed where depth supervised loss (DSL), and depth\ncycle consistency loss (DCCL) are used to bring depth information into the\ngenerative model. Experimental results show that DRDG reaches state-of-the-art\naccuracy between generative methods in cross-domain semantic segmentation\ntasks.",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Peng Guo",
      "Han Gao",
      "Xiuwan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09823"
  },
  {
    "id": "arXiv:2208.09825",
    "title": "Hilti-Oxford Dataset: A Millimetre-Accurate Benchmark for Simultaneous  Localization and Mapping",
    "abstract": "Simultaneous Localization and Mapping (SLAM) is being deployed in real-world\napplications, however many state-of-the-art solutions still struggle in many\ncommon scenarios. A key necessity in progressing SLAM research is the\navailability of high-quality datasets and fair and transparent benchmarking. To\nthis end, we have created the Hilti-Oxford Dataset, to push state-of-the-art\nSLAM systems to their limits. The dataset has a variety of challenges ranging\nfrom sparse and regular construction sites to a 17th century neoclassical\nbuilding with fine details and curved surfaces. To encourage multi-modal SLAM\napproaches, we designed a data collection platform featuring a lidar, five\ncameras, and an IMU (Inertial Measurement Unit). With the goal of benchmarking\nSLAM algorithms for tasks where accuracy and robustness are paramount, we\nimplemented a novel ground truth collection method that enables our dataset to\naccurately measure SLAM pose errors with millimeter accuracy. To further ensure\naccuracy, the extrinsics of our platform were verified with a\nmicrometer-accurate scanner, and temporal calibration was managed online using\nhardware time synchronization. The multi-modality and diversity of our dataset\nattracted a large field of academic and industrial researchers to enter the\nsecond edition of the Hilti SLAM challenge, which concluded in June 2022. The\nresults of the challenge show that while the top three teams could achieve\naccuracy of 2cm or better for some sequences, the performance dropped off in\nmore difficult sequences.",
    "descriptor": "",
    "authors": [
      "Lintong Zhang",
      "Michael Helmberger",
      "Lanke Frank Tarimo Fu",
      "David Wisth",
      "Marco Camurri",
      "Davide Scaramuzza",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09825"
  },
  {
    "id": "arXiv:2208.09827",
    "title": "A Survey on Transactional Stream Processing",
    "abstract": "Transactional stream processing (TSP) has been increasingly gaining traction.\nTSP aims to provide a single unified model that offers both transaction- and\nstream-oriented guarantees. Over the past decade, considerable efforts have\nresulted in the development of alternative TSP systems, which enables us to\nexplore the commonalities and differences across these solutions. However, a\nwidely accepted standard approach to the integration of transactional\nfunctionality with stream processing is still lacking. Existing TSP systems\ntypically focus on a limited number of application features with non-trivial\ndesign trade-offs. This survey initially examines diverse transaction models\nover streams and TSP specific transactional properties, followed by a\ndiscussion on the consequences of certain design decisions on system\nimplementations. Subsequently, we highlight a set of representative scenarios,\nwhere TSP is employed, as well as discuss some open problems. The aim of this\nsurvey is twofold. First, to provide insight into disparate TSP requirements\nand techniques. Second, to engage the design and development of novel TSP\nsystems.",
    "descriptor": "",
    "authors": [
      "Shuhao Zhang",
      "Juan Soto",
      "Volker Markl"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09827"
  },
  {
    "id": "arXiv:2208.09828",
    "title": "I Know What You Do Not Know: Knowledge Graph Embedding via  Co-distillation Learning",
    "abstract": "Knowledge graph (KG) embedding seeks to learn vector representations for\nentities and relations. Conventional models reason over graph structures, but\nthey suffer from the issues of graph incompleteness and long-tail entities.\nRecent studies have used pre-trained language models to learn embeddings based\non the textual information of entities and relations, but they cannot take\nadvantage of graph structures. In the paper, we show empirically that these two\nkinds of features are complementary for KG embedding. To this end, we propose\nCoLE, a Co-distillation Learning method for KG Embedding that exploits the\ncomplementarity of graph structures and text information. Its graph embedding\nmodel employs Transformer to reconstruct the representation of an entity from\nits neighborhood subgraph. Its text embedding model uses a pre-trained language\nmodel to generate entity representations from the soft prompts of their names,\ndescriptions, and relational neighbors. To let the two model promote each\nother, we propose co-distillation learning that allows them to distill\nselective knowledge from each other's prediction logits. In our co-distillation\nlearning, each model serves as both a teacher and a student. Experiments on\nbenchmark datasets demonstrate that the two models outperform their related\nbaselines, and the ensemble method CoLE with co-distillation learning advances\nthe state-of-the-art of KG embedding.",
    "descriptor": "\nComments: Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)\n",
    "authors": [
      "Yang Liu",
      "Zequn Sun Guangyao Li",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09828"
  },
  {
    "id": "arXiv:2208.09829",
    "title": "CenDerNet: Center and Curvature Representations for Render-and-Compare  6D Pose Estimation",
    "abstract": "We introduce CenDerNet, a framework for 6D pose estimation from multi-view\nimages based on center and curvature representations. Finding precise poses for\nreflective, textureless objects is a key challenge for industrial robotics. Our\napproach consists of three stages: First, a fully convolutional neural network\npredicts center and curvature heatmaps for each view; Second, center heatmaps\nare used to detect object instances and find their 3D centers; Third, 6D object\nposes are estimated using 3D centers and curvature heatmaps. By jointly\noptimizing poses across views using a render-and-compare approach, our method\nnaturally handles occlusions and object symmetries. We show that CenDerNet\noutperforms previous methods on two industry-relevant datasets: DIMO and\nT-LESS.",
    "descriptor": "\nComments: 19 pages, 14 figures\n",
    "authors": [
      "Peter De Roovere",
      "Rembert Daems",
      "Jonathan Croenen",
      "Taoufik Bourgana",
      "Joris de Hoog",
      "Francis wyffels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09829"
  },
  {
    "id": "arXiv:2208.09830",
    "title": "Representation Learning with Graph Neural Networks for Speech Emotion  Recognition",
    "abstract": "Learning expressive representation is crucial in deep learning. In speech\nemotion recognition (SER), vacuum regions or noises in the speech interfere\nwith expressive representation learning. However, traditional RNN-based models\nare susceptible to such noise. Recently, Graph Neural Network (GNN) has\ndemonstrated its effectiveness for representation learning, and we adopt this\nframework for SER. In particular, we propose a cosine similarity-based graph as\nan ideal graph structure for representation learning in SER. We present a\nCosine similarity-based Graph Convolutional Network (CoGCN) that is robust to\nperturbation and noise. Experimental results show that our method outperforms\nstate-of-the-art methods or provides competitive results with a significant\nmodel size reduction with only 1/30 parameters.",
    "descriptor": "\nComments: AAAI 2022 Workshop on Graphs and More Complex Structures for Learning and Reasoning (GCLR)\n",
    "authors": [
      "Junghun Kim",
      "Jihie Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.09830"
  },
  {
    "id": "arXiv:2208.09833",
    "title": "Combating Noisy-Labeled and Imbalanced Data by Two Stage Bi-Dimensional  Sample Selection",
    "abstract": "Robust learning on noisy-labeled data has been an important task in real\napplications, because label noise directly leads to the poor generalization of\ndeep learning models. Existing label-noise learning methods usually assume that\nthe ground-truth classes of the training data are balanced. However, the\nreal-world data is often imbalanced, leading to the inconsistency between\nobserved and intrinsic class distribution due to label noises. Distribution\ninconsistency makes the problem of label-noise learning more challenging\nbecause it is hard to distinguish clean samples from noisy samples on the\nintrinsic tail classes. In this paper, we propose a learning framework for\nlabel-noise learning with intrinsically long-tailed data. Specifically, we\npropose a robust sample selection method called two-stage bi-dimensional sample\nselection (TBSS) to better separate clean samples from noisy samples,\nespecially for the tail classes. TBSS consists of two new separation metrics to\njointly separate samples in each class. Extensive experiments on multiple\nnoisy-labeled datasets with intrinsically long-tailed class distribution\ndemonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Yiliang Zhang",
      "Yang Lu",
      "Bo Han",
      "Yiu-ming Cheung",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09833"
  },
  {
    "id": "arXiv:2208.09836",
    "title": "qDWI-Morph: Motion-compensated quantitative Diffusion-Weighted MRI  analysis for fetal lung maturity assessment",
    "abstract": "Quantitative analysis of fetal lung Diffusion-Weighted MRI (DWI) data shows\npotential in providing quantitative imaging biomarkers that indirectly reflect\nfetal lung maturation. However, fetal motion during the acquisition hampered\nquantitative analysis of the acquired DWI data and, consequently, reliable\nclinical utilization. We introduce qDWI-morph, an unsupervised\ndeep-neural-network architecture for motion compensated quantitative DWI (qDWI)\nanalysis. Our approach couples a registration sub-network with a quantitative\nDWI model fitting sub-network. We simultaneously estimate the qDWI parameters\nand the motion model by minimizing a bio-physically-informed loss function\nintegrating a registration loss and a model fitting quality loss. We\ndemonstrated the added-value of qDWI-morph over: 1) a baseline qDWI analysis\nwithout motion compensation and 2) a baseline deep-learning model incorporating\nregistration loss solely. The qDWI-morph achieved a substantially improved\ncorrelation with the gestational age through in-vivo qDWI analysis of fetal\nlung DWI data (R-squared=0.32 vs. 0.13, 0.28). Our qDWI-morph has the potential\nto enable motion-compensated quantitative analysis of DWI data and to provide\nclinically feasible bio-markers for non-invasive fetal lung maturity\nassessment. Our code is available at:\nhttps://github.com/TechnionComputationalMRILab/qDWI-Morph.",
    "descriptor": "\nComments: Accepted to ECCV-MCV: this https URL\n",
    "authors": [
      "Yael Zaffrani-Reznikov",
      "Onur Afacan",
      "Sila Kurugol",
      "Simon Warfield",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09836"
  },
  {
    "id": "arXiv:2208.09837",
    "title": "Comparison-based Conversational Recommender System with Relative Bandit  Feedback",
    "abstract": "With the recent advances of conversational recommendations, the recommender\nsystem is able to actively and dynamically elicit user preference via\nconversational interactions. To achieve this, the system periodically queries\nusers' preference on attributes and collects their feedback. However, most\nexisting conversational recommender systems only enable the user to provide\nabsolute feedback to the attributes. In practice, the absolute feedback is\nusually limited, as the users tend to provide biased feedback when expressing\nthe preference. Instead, the user is often more inclined to express comparative\npreferences, since user preferences are inherently relative. To enable users to\nprovide comparative preferences during conversational interactions, we propose\na novel comparison-based conversational recommender system. The relative\nfeedback, though more practical, is not easy to be incorporated since its\nfeedback scale is always mismatched with users' absolute preferences. With\neffectively collecting and understanding the relative feedback from an\ninteractive manner, we further propose a new bandit algorithm, which we call\nRelativeConUCB. The experiments on both synthetic and real-world datasets\nvalidate the advantage of our proposed method, compared to the existing bandit\nalgorithms in the conversational recommender systems.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted by SIGIR 2021\n",
    "authors": [
      "Zhihui Xie",
      "Tong Yu",
      "Canzhe Zhao",
      "Shuai Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09837"
  },
  {
    "id": "arXiv:2208.09838",
    "title": "Tyche: A library for probabilistic reasoning and belief modelling in  Python",
    "abstract": "This paper presents Tyche, a Python library to facilitate probabilistic\nreasoning in uncertain worlds through the construction, querying, and learning\nof belief models. Tyche uses aleatoric description logic (ADL), which provides\ncomputational advantages in its evaluation over other description logics. Tyche\nbelief models can be succinctly created by defining classes of individuals, the\nprobabilistic beliefs about them (concepts), and the probabilistic\nrelationships between them (roles). We also introduce a method of observation\npropagation to facilitate learning from complex ADL observations. A\ndemonstration of Tyche to predict the author of anonymised messages, and to\nextract author writing tendencies from anonymised messages, is provided. Tyche\nhas the potential to assist in the development of expert systems, knowledge\nextraction systems, and agents to play games with incomplete and probabilistic\ninformation.",
    "descriptor": "\nComments: 21 pages, submitted to AJCAI2022\n",
    "authors": [
      "Padraig X. Lamont"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.09838"
  },
  {
    "id": "arXiv:2208.09840",
    "title": "Teaching the Burrows-Wheeler Transform via the Positional  Burrows-Wheeler Transform",
    "abstract": "The Burrows-Wheeler Transform (BWT) is often taught in undergraduate courses\non algorithmic bioinformatics, because it underlies the FM-index and thus\nimportant tools such as Bowtie and BWA. Its admirers consider the BWT a thing\nof beauty but, despite thousands of pages being written about it over nearly\nthirty years, to undergraduates seeing it for the first time it still often\nseems like magic. Some who persevere are later shown the Positional BWT (PBWT),\nwhich was published twenty years after the BWT. In this paper we argue that the\nPBWT should be taught {\\em before} the BWT.\nWe first use the PBWT's close relation to a right-to-left radix sort to\nexplain how to use it as a fast and space-efficient index for {\\em positional\nsearch} on a set of strings (that is, given a pattern and a position, quickly\nlist the strings containing that pattern starting in that position). We then\nobserve that {\\em prefix search} (listing all the strings that start with the\npattern) is an easy special case of positional search, and that prefix search\non the suffixes of a single string is equivalent to {\\em substring search} in\nthat string (listing all the starting positions of occurrences of the pattern\nin the string).\nStoring na\\\"ively a PBWT of the suffixes of a string is space-{\\em\ninefficient} but, in even reasonably small examples, most of its columns are\nnearly the same. It is not difficult to show that if we store a PBWT of the\ncyclic shifts of the string, instead of its suffixes, then all the columns are\nexactly the same -- and equal to the BWT of the string. Thus we can teach the\nBWT and the FM-index via the PBWT.",
    "descriptor": "",
    "authors": [
      "Travis Gagie",
      "Giovanni Manzini",
      "Marinella Sciortino"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09840"
  },
  {
    "id": "arXiv:2208.09843",
    "title": "CODER: Coupled Diversity-Sensitive Momentum Contrastive Learning for  Image-Text Retrieval",
    "abstract": "Image-Text Retrieval (ITR) is challenging in bridging visual and lingual\nmodalities. Contrastive learning has been adopted by most prior arts. Except\nfor limited amount of negative image-text pairs, the capability of constrastive\nlearning is restricted by manually weighting negative pairs as well as\nunawareness of external knowledge. In this paper, we propose our novel Coupled\nDiversity-Sensitive Momentum Constrastive Learning (CODER) for improving\ncross-modal representation. Firstly, a novel diversity-sensitive contrastive\nlearning (DCL) architecture is invented. We introduce dynamic dictionaries for\nboth modalities to enlarge the scale of image-text pairs, and\ndiversity-sensitiveness is achieved by adaptive negative pair weighting.\nFurthermore, two branches are designed in CODER. One learns instance-level\nembeddings from image/text, and it also generates pseudo online clustering\nlabels for its input image/text based on their embeddings. Meanwhile, the other\nbranch learns to query from commonsense knowledge graph to form concept-level\ndescriptors for both modalities. Afterwards, both branches leverage DCL to\nalign the cross-modal embedding spaces while an extra pseudo clustering label\nprediction loss is utilized to promote concept-level representation learning\nfor the second branch. Extensive experiments conducted on two popular\nbenchmarks, i.e. MSCOCO and Flicker30K, validate CODER remarkably outperforms\nthe state-of-the-art approaches.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Haoran Wang",
      "Dongliang He",
      "Wenhao Wu",
      "Boyang Xia",
      "Min Yang",
      "Fu Li",
      "Yunlong Yu",
      "Zhong Ji",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09843"
  },
  {
    "id": "arXiv:2208.09844",
    "title": "CycleTrans: Learning Neutral yet Discriminative Features for  Visible-Infrared Person Re-Identification",
    "abstract": "Visible-infrared person re-identification (VI-ReID) is a task of matching the\nsame individuals across the visible and infrared modalities. Its main challenge\nlies in the modality gap caused by cameras operating on different spectra.\nExisting VI-ReID methods mainly focus on learning general features across\nmodalities, often at the expense of feature discriminability. To address this\nissue, we present a novel cycle-construction-based network for neutral yet\ndiscriminative feature learning, termed CycleTrans. Specifically, CycleTrans\nuses a lightweight Knowledge Capturing Module (KCM) to capture rich semantics\nfrom the modality-relevant feature maps according to pseudo queries.\nAfterwards, a Discrepancy Modeling Module (DMM) is deployed to transform these\nfeatures into neutral ones according to the modality-irrelevant prototypes. To\nensure feature discriminability, another two KCMs are further deployed for\nfeature cycle constructions. With cycle construction, our method can learn\neffective neutral features for visible and infrared images while preserving\ntheir salient semantics. Extensive experiments on SYSU-MM01 and RegDB datasets\nvalidate the merits of CycleTrans against a flurry of state-of-the-art methods,\n+4.57% on rank-1 in SYSU-MM01 and +2.2% on rank-1 in RegDB.",
    "descriptor": "",
    "authors": [
      "Qiong Wu",
      "Jiaer Xia",
      "Pingyang Dai",
      "Yiyi Zhou",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09844"
  },
  {
    "id": "arXiv:2208.09846",
    "title": "A Contrastive Pre-training Approach to Learn Discriminative Autoencoder  for Dense Retrieval",
    "abstract": "Dense retrieval (DR) has shown promising results in information retrieval. In\nessence, DR requires high-quality text representations to support effective\nsearch in the representation space. Recent studies have shown that pre-trained\nautoencoder-based language models with a weak decoder can provide high-quality\ntext representations, boosting the effectiveness and few-shot ability of DR\nmodels. However, even a weak autoregressive decoder has the bypass effect on\nthe encoder. More importantly, the discriminative ability of learned\nrepresentations may be limited since each token is treated equally important in\ndecoding the input texts. To address the above problems, in this paper, we\npropose a contrastive pre-training approach to learn a discriminative\nautoencoder with a lightweight multi-layer perception (MLP) decoder. The basic\nidea is to generate word distributions of input text in a non-autoregressive\nfashion and pull the word distributions of two masked versions of one text\nclose while pushing away from others. We theoretically show that our\ncontrastive strategy can suppress the common words and highlight the\nrepresentative words in decoding, leading to discriminative representations.\nEmpirical results show that our method can significantly outperform the\nstate-of-the-art autoencoder-based language models and other pre-trained models\nfor dense retrieval.",
    "descriptor": "\nComments: Accepted by CIKM2022\n",
    "authors": [
      "Xinyu Ma",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09846"
  },
  {
    "id": "arXiv:2208.09847",
    "title": "Scattered or Connected? An Optimized Parameter-efficient Tuning Approach  for Information Retrieval",
    "abstract": "Pre-training and fine-tuning have achieved significant advances in the\ninformation retrieval (IR). A typical approach is to fine-tune all the\nparameters of large-scale pre-trained models (PTMs) on downstream tasks. As the\nmodel size and the number of tasks increase greatly, such approach becomes less\nfeasible and prohibitively expensive. Recently, a variety of\nparameter-efficient tuning methods have been proposed in natural language\nprocessing (NLP) that only fine-tune a small number of parameters while still\nattaining strong performance. Yet there has been little effort to explore\nparameter-efficient tuning for IR.\nIn this work, we first conduct a comprehensive study of existing\nparameter-efficient tuning methods at both the retrieval and re-ranking stages.\nUnlike the promising results in NLP, we find that these methods cannot achieve\ncomparable performance to full fine-tuning at both stages when updating less\nthan 1\\% of the original model parameters. More importantly, we find that the\nexisting methods are just parameter-efficient, but not learning-efficient as\nthey suffer from unstable training and slow convergence. To analyze the\nunderlying reason, we conduct a theoretical analysis and show that the\nseparation of the inserted trainable modules makes the optimization difficult.\nTo alleviate this issue, we propose to inject additional modules alongside the\n\\acp{PTM} to make the original scattered modules connected. In this way, all\nthe trainable modules can form a pathway to smooth the loss surface and thus\nhelp stabilize the training process. Experiments at both retrieval and\nre-ranking stages show that our method outperforms existing parameter-efficient\nmethods significantly, and achieves comparable or even better performance over\nfull fine-tuning.",
    "descriptor": "\nComments: Accepted by CIKM2022\n",
    "authors": [
      "Xinyu Ma",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09847"
  },
  {
    "id": "arXiv:2208.09848",
    "title": "Multi-task Learning for Monocular Depth and Defocus Estimations with  Real Images",
    "abstract": "Monocular depth estimation and defocus estimation are two fundamental tasks\nin computer vision. Most existing methods treat depth estimation and defocus\nestimation as two separate tasks, ignoring the strong connection between them.\nIn this work, we propose a multi-task learning network consisting of an encoder\nwith two decoders to estimate the depth and defocus map from a single focused\nimage. Through the multi-task network, the depth estimation facilitates the\ndefocus estimation to get better results in the weak texture region and the\ndefocus estimation facilitates the depth estimation by the strong physical\nconnection between the two maps. We set up a dataset (named ALL-in-3D dataset)\nwhich is the first all-real image dataset consisting of 100K sets of\nall-in-focus images, focused images with focus depth, depth maps, and defocus\nmaps. It enables the network to learn features and solid physical connections\nbetween the depth and real defocus images. Experiments demonstrate that the\nnetwork learns more solid features from the real focused images than the\nsynthetic focused images. Benefiting from this multi-task structure where\ndifferent tasks facilitate each other, our depth and defocus estimations\nachieve significantly better performance than other state-of-art algorithms.\nThe code and dataset will be publicly available at\nhttps://github.com/cubhe/MDDNet.",
    "descriptor": "",
    "authors": [
      "Renzhi He",
      "Hualin Hong",
      "Boya Fu",
      "Fei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09848"
  },
  {
    "id": "arXiv:2208.09849",
    "title": "Semantic-enhanced Image Clustering",
    "abstract": "Image clustering is an important, and open challenge task in computer vision.\nAlthough many methods have been proposed to solve the image clustering task,\nthey only explore images and uncover clusters according to the image features,\nthus are unable to distinguish visually similar but semantically different\nimages. In this paper, we propose to investigate the task of image clustering\nwith the help of visual-language pre-training model. Different from the\nzero-shot setting in which the class names are known, we only know the number\nof clusters in this setting. Therefore, how to map images to a proper semantic\nspace and how to cluster images from both image and semantic spaces are two key\nproblems. To solve the above problems, we propose a novel image clustering\nmethod guided by the visual-language pre-training model CLIP, named as\n\\textbf{Semantic-enhanced Image Clustering (SIC)}. In this new method, we\npropose a method to map the given images to a proper semantic space first and\nefficient methods to generate pseudo-labels according to the relationships\nbetween images and semantics. Finally, we propose to perform clustering with\nthe consistency learning in both image space and semantic space, in a\nself-supervised learning fashion. Theoretical result on convergence analysis\nshows that our proposed method can converge in sublinear speed. Theoretical\nanalysis on expectation risk also shows that we can reduce the expectation risk\nby improving the neighborhood consistency or prediction confidence or reducing\nneighborhood imbalance. Experimental results on five benchmark datasets clearly\nshow the superiority of our new method.",
    "descriptor": "",
    "authors": [
      "Shaotian Cai",
      "Liping Qiu",
      "Xiaojun Chen",
      "Qin Zhang",
      "Longteng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09849"
  },
  {
    "id": "arXiv:2208.09852",
    "title": "Efficient Multiparty Protocols Using Generalized Parseval's Identity and  the Theta Algebra",
    "abstract": "We propose a protocol able to show publicly addition and multiplication on\nsecretly shared values. To this aim we developed a protocol based on the use of\nmasks and on the FMPC (Fourier Multi-Party Computation). FMPC is a novel\nmultiparty computation protocol of arithmetic circuits based on secret-sharing,\ncapable to compute addition and multiplication of secrets with no\ncommunication. We achieve this task by introducing the first generalisation of\nParseval's identity for Fourier series applicable to an arbitrary number of\ninputs and a new algebra referred to as the \"Theta-algebra\". FMPC operates in a\nsetting where users wish to compute a function over some secret inputs by\nsubmitting the computation to a set of nodes, without revealing them those\ninputs. FMPC offloads most of the computational complexity to the end users,\nand includes an online phase that mainly consists of each node locally\nevaluating specific functions. FMPC paves the way for a new kind of multiparty\ncomputation protocols; making it possible to compute addition and\nmultiplication of secrets stepping away from circuit garbling and the\ntraditional algebra introduced by Donald Beaver in 1991. Our protocol is\ncapable to compute addition and multiplication with no communication and its\nsimplicity provides efficiency and ease of implementation.",
    "descriptor": "\nComments: 23 pages and 10 Figures\n",
    "authors": [
      "Giorgio Sonnino",
      "Alberto Sonnino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09852"
  },
  {
    "id": "arXiv:2208.09855",
    "title": "Last-Iterate Convergence with Full- and Noisy-Information Feedback in  Two-Player Zero-Sum Games",
    "abstract": "The theory of learning in games is prominent in the AI community, motivated\nby several rising applications such as multi-agent reinforcement learning and\nGenerative Adversarial Networks. We propose Mutation-driven Multiplicative\nWeights Update (M2WU) for learning an equilibrium in two-player zero-sum\nnormal-form games and prove that it exhibits the last-iterate convergence\nproperty in both full- and noisy-information feedback settings. In the\nfull-information feedback setting, the players observe their exact gradient\nvectors of the utility functions. On the other hand, in the noisy-information\nfeedback setting, they can only observe the noisy gradient vectors. Existing\nalgorithms, including the well-known Multiplicative Weights Update (MWU) and\nOptimistic MWU (OMWU) algorithms, fail to converge to a Nash equilibrium with\nnoisy-information feedback. In contrast, M2WU exhibits the last-iterate\nconvergence to a stationary point near a Nash equilibrium in both of the\nfeedback settings. We then prove that it converges to an exact Nash equilibrium\nby adapting the mutation term iteratively. We empirically confirm that M2WU\noutperforms MWU and OMWU in exploitability and convergence rates.",
    "descriptor": "",
    "authors": [
      "Kenshi Abe",
      "Kaito Ariu",
      "Mitsuki Sakamoto",
      "Kentaro Toyoshima",
      "Atsushi Iwasaki"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09855"
  },
  {
    "id": "arXiv:2208.09859",
    "title": "Emergence of hierarchical modes from deep learning",
    "abstract": "Large-scale deep neural networks consume expensive training costs, but the\ntraining results in less-interpretable weight matrices constructing the\nnetworks. Here, we propose a mode decomposition learning that can interpret the\nweight matrices as a hierarchy of latent modes. These modes are akin to\npatterns in physics studies of memory networks. The mode decomposition learning\nnot only saves a significant large amount of training costs, but also explains\nthe network performance with the leading modes. The mode learning scheme shows\na progressively compact latent space across the network hierarchy, and the\nleast number of modes increases only logarithmically with the network width.\nOur mode decomposition learning is also studied in an analytic on-line learning\nsetting, which reveals multi-stage of learning dynamics. Therefore, the\nproposed mode decomposition learning points to a cheap and interpretable route\ntowards the magical deep learning.",
    "descriptor": "\nComments: 5 pages, 4 figures, and SM is available upon request\n",
    "authors": [
      "Chan Li",
      "Haiping Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2208.09859"
  },
  {
    "id": "arXiv:2208.09861",
    "title": "The Single Robot Line Coverage Problem: Theory, Algorithms and  Experiments",
    "abstract": "Line coverage is the task of servicing a given set of one-dimensional\nfeatures in an environment. It is important for the inspection of linear\ninfrastructure such as road networks, power lines, and oil and gas pipelines.\nThis paper addresses the single robot line coverage problem for aerial and\nground robots by modeling it as an optimization problem on a graph. The problem\nbelongs to the broad class of arc routing problems and is closely related to\nthe asymmetric rural postman problem (RPP). The paper presents an integer\nlinear programming formulation with proof of correctness. Using the minimum\ncost flow problem, we develop approximation algorithms with guarantees on the\nsolution quality. These guarantees also improve the existing results for the\nasymmetric RPP. The main algorithm partitions the problem into three cases\nbased on the structure of the required graph, i.e., the graph induced by the\nfeatures that require servicing. We evaluate our algorithms on road networks\nfrom the 50 most populous cities in the world. The algorithms, augmented with\nimprovement heuristics, run within 3s and generate solutions that are within\n10% of the optimum. We experimentally demonstrate our algorithms with\ncommercial UAVs on the UNC Charlotte campus road network.",
    "descriptor": "",
    "authors": [
      "Saurav Agarwal",
      "Srinivas Akella"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.09861"
  },
  {
    "id": "arXiv:2208.09862",
    "title": "Twin Papers: A Simple Framework of Causal Inference for Citations via  Coupling",
    "abstract": "The research process includes many decisions, e.g., how to entitle and where\nto publish the paper. In this paper, we introduce a general framework for\ninvestigating the effects of such decisions. The main difficulty in\ninvestigating the effects is that we need to know counterfactual results, which\nare not available in reality. The key insight of our framework is inspired by\nthe existing counterfactual analysis using twins, where the researchers regard\ntwins as counterfactual units. The proposed framework regards a pair of papers\nthat cite each other as twins. Such papers tend to be parallel works, on\nsimilar topics, and in similar communities. We investigate twin papers that\nadopted different decisions, observe the progress of the research impact\nbrought by these studies, and estimate the effect of decisions by the\ndifference in the impacts of these studies. We release our code and data, which\nwe believe are highly beneficial owing to the scarcity of the dataset on\ncounterfactual studies.",
    "descriptor": "\nComments: CIKM 2022 short paper\n",
    "authors": [
      "Ryoma Sato",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09862"
  },
  {
    "id": "arXiv:2208.09864",
    "title": "Towards Principled User-side Recommender Systems",
    "abstract": "Traditionally, recommendation algorithms have been designed for service\ndevelopers. However, recently, a new paradigm called user-side recommender\nsystems has been proposed and they enable web service users to construct their\nown recommender systems without access to trade-secret data. This approach\nopens the door to user-defined fair systems even if the official recommender\nsystem of the service is not fair. While existing methods for user-side\nrecommender systems have addressed the challenging problem of building\nrecommender systems without using log data, they rely on heuristic approaches,\nand it is still unclear whether constructing user-side recommender systems is a\nwell-defined problem from theoretical point of view. In this paper, we provide\ntheoretical justification of user-side recommender systems. Specifically, we\nsee that hidden item features can be recovered from the information available\nto the user, making the construction of user-side recommender system\nwell-defined. However, this theoretically grounded approach is not efficient.\nTo realize practical yet theoretically sound recommender systems, we propose\nthree desirable properties of user-side recommender systems and propose an\neffective and efficient user-side recommender system, \\textsc{Consul}, based on\nthese foundations. We prove that \\textsc{Consul} satisfies all three\nproperties, whereas existing user-side recommender systems lack at least one of\nthem. In the experiments, we empirically validate the theory of feature\nrecovery via numerical experiments. We also show that our proposed method\nachieves an excellent trade-off between effectiveness and efficiency and\ndemonstrate via case studies that the proposed method can retrieve information\nthat the provider's official recommender system cannot.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09864"
  },
  {
    "id": "arXiv:2208.09865",
    "title": "Area Coverage with Multiple Capacity-Constrained Robots",
    "abstract": "The area coverage problem is the task of efficiently servicing a given\ntwo-dimensional surface using sensors mounted on robots such as unmanned aerial\nvehicles (UAVs) and unmanned ground vehicles (UGVs). We present a novel\nformulation for generating coverage routes for multiple capacity-constrained\nrobots, where capacity can be specified in terms of battery life or flight\ntime. Traversing the environment incurs demands on the robot resources, which\nhave capacity limits. The central aspect of our approach is transforming the\narea coverage problem into a line coverage problem (i.e., coverage of linear\nfeatures), and then generating routes that minimize the total cost of travel\nwhile respecting the capacity constraints. We define two modes of travel: (1)\nservicing and (2) deadheading, which correspond to whether a robot is\nperforming task-specific actions or not. Our formulation allows separate and\nasymmetric travel costs and demands for the two modes. Furthermore, the cells\ncomputed from cell decomposition, aimed at minimizing the number of turns, are\nnot required to be monotone polygons. We develop new procedures for cell\ndecomposition and generation of service tracks that can handle non-monotone\npolygons with or without holes. We establish the efficacy of our algorithm on a\nground robot dataset with 25 indoor environments and an aerial robot dataset\nwith 300 outdoor environments. The algorithm generates solutions whose costs\nare 10% lower on average than state-of-the-art methods. We additionally\ndemonstrate our algorithm in experiments with UAVs.",
    "descriptor": "\nComments: Published at IEEE Robotics and Automation Letters, 2022\n",
    "authors": [
      "Saurav Agarwal",
      "Srinivas Akella"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2208.09865"
  },
  {
    "id": "arXiv:2208.09867",
    "title": "Automatic tagging of knowledge points for K12 math problems",
    "abstract": "Automatic tagging of knowledge points for practice problems is the basis for\nmanaging question bases and improving the automation and intelligence of\neducation. Therefore, it is of great practical significance to study the\nautomatic tagging technology for practice problems. However, there are few\nstudies on the automatic tagging of knowledge points for math problems. Math\ntexts have more complex structures and semantics compared with general texts\nbecause they contain unique elements such as symbols and formulas. Therefore,\nit is difficult to meet the accuracy requirement of knowledge point prediction\nby directly applying the text classification techniques in general domains. In\nthis paper, K12 math problems taken as the research object, the LABS model\nbased on label-semantic attention and multi-label smoothing combining textual\nfeatures is proposed to improve the automatic tagging of knowledge points for\nmath problems. The model combines the text classification techniques in general\ndomains and the unique features of math texts. The results show that the models\nusing label-semantic attention or multi-label smoothing perform better on\nprecision, recall, and F1-score metrics than the traditional BiLSTM model,\nwhile the LABS model using both performs best. It can be seen that label\ninformation can guide the neural networks to extract meaningful information\nfrom the problem text, which improves the text classification performance of\nthe model. Moreover, multi-label smoothing combining textual features can fully\nexplore the relationship between text and labels, improve the model's\nprediction ability for new data and improve the model's classification\naccuracy.",
    "descriptor": "",
    "authors": [
      "Xiaolu Wang",
      "Ziqi Ding",
      "Liangyu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09867"
  },
  {
    "id": "arXiv:2208.09870",
    "title": "Objects Can Move: 3D Change Detection by Geometric Transformation  Constistency",
    "abstract": "AR/VR applications and robots need to know when the scene has changed. An\nexample is when objects are moved, added, or removed from the scene. We propose\na 3D object discovery method that is based only on scene changes. Our method\ndoes not need to encode any assumptions about what is an object, but rather\ndiscovers objects by exploiting their coherent move. Changes are initially\ndetected as differences in the depth maps and segmented as objects if they\nundergo rigid motions. A graph cut optimization propagates the changing labels\nto geometrically consistent regions. Experiments show that our method achieves\nstate-of-the-art performance on the 3RScan dataset against competitive\nbaselines. The source code of our method can be found at\nhttps://github.com/katadam/ObjectsCanMove.",
    "descriptor": "",
    "authors": [
      "Aikaterini Adam",
      "Torsten Sattler",
      "Konstantinos Karantzalos",
      "Tomas Pajdla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09870"
  },
  {
    "id": "arXiv:2208.09872",
    "title": "Provably Tightest Linear Approximation for Robustness Verification of  Sigmoid-like Neural Networks",
    "abstract": "The robustness of deep neural networks is crucial to modern AI-enabled\nsystems and should be formally verified. Sigmoid-like neural networks have been\nadopted in a wide range of applications. Due to their non-linearity,\nSigmoid-like activation functions are usually over-approximated for efficient\nverification, which inevitably introduces imprecision. Considerable efforts\nhave been devoted to finding the so-called tighter approximations to obtain\nmore precise verification results. However, existing tightness definitions are\nheuristic and lack theoretical foundations. We conduct a thorough empirical\nanalysis of existing neuron-wise characterizations of tightness and reveal that\nthey are superior only on specific neural networks. We then introduce the\nnotion of network-wise tightness as a unified tightness definition and show\nthat computing network-wise tightness is a complex non-convex optimization\nproblem. We bypass the complexity from different perspectives via two\nefficient, provably tightest approximations. The results demonstrate the\npromising performance achievement of our approaches over state of the art: (i)\nachieving up to 251.28% improvement to certified lower robustness bounds; and\n(ii) exhibiting notably more precise verification results on convolutional\nnetworks.",
    "descriptor": "\nComments: Accepted at ASE 2022\n",
    "authors": [
      "Zhaodi Zhang",
      "Yiting Wu",
      "Si Liu",
      "Jing Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09872"
  },
  {
    "id": "arXiv:2208.09873",
    "title": "A Failed Proof Can Yield a Useful Test",
    "abstract": "A successful automated program proof is, in software verification, the\nultimate triumph. In practice, however, the road to such success is paved with\nmany failed proof attempts. Unlike a failed test, which provides concrete\nevidence of an actual bug in the program, failed proofs leave the programmer\nguessing. Can we put them to good use?\nThe work reported here takes advantage of the rich internal information that\nautomatic provers collect about the program when attempting a proof. If the\nproof fails, we use the counterexample generated by the prover (specifically,\nthe SMT solver underlying the proof environment Boogie, used in the AutoProof\nsystem to perform correctness proofs of contract-equipped Eiffel programs) to\nproduce a failed test, which provides the programmer with immediately\nexploitable information to correct the program. The discussion presents the\nProof2Test tool implementing these ideas and demonstrates their application to\na collection of examples.",
    "descriptor": "",
    "authors": [
      "Li Huang",
      "Bertrand Meyer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.09873"
  },
  {
    "id": "arXiv:2208.09878",
    "title": "DPTNet: A Dual-Path Transformer Architecture for Scene Text Detection",
    "abstract": "The prosperity of deep learning contributes to the rapid progress in scene\ntext detection. Among all the methods with convolutional networks,\nsegmentation-based ones have drawn extensive attention due to their superiority\nin detecting text instances of arbitrary shapes and extreme aspect ratios.\nHowever, the bottom-up methods are limited to the performance of their\nsegmentation models. In this paper, we propose DPTNet (Dual-Path Transformer\nNetwork), a simple yet effective architecture to model the global and local\ninformation for the scene text detection task. We further propose a parallel\ndesign that integrates the convolutional network with a powerful self-attention\nmechanism to provide complementary clues between the attention path and\nconvolutional path. Moreover, a bi-directional interaction module across the\ntwo paths is developed to provide complementary clues in the channel and\nspatial dimensions. We also upgrade the concentration operation by adding an\nextra multi-head attention layer to it. Our DPTNet achieves state-of-the-art\nresults on the MSRA-TD500 dataset, and provides competitive results on other\nstandard benchmarks in terms of both detection accuracy and speed.",
    "descriptor": "",
    "authors": [
      "Jingyu Lin",
      "Jie Jiang",
      "Yan Yan",
      "Chunchao Guo",
      "Hongfa Wang",
      "Wei Liu",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09878"
  },
  {
    "id": "arXiv:2208.09879",
    "title": "Space-time finite element methods for parabolic distributed optimal  control problems",
    "abstract": "We present a method for the numerical approximation of distributed optimal\ncontrol problems constrained by parabolic partial differential equations. We\ncomplement the first-order optimality condition by a recently developed\nspace-time variational formulation of parabolic equations which is coercive in\nthe energy norm, and a Lagrangian multiplier. Our final formulation fulfills\nthe Babu\\v{s}ka-Brezzi conditions on the continuous as well as discrete level,\nwithout restrictions. Consequently, we can allow for final-time desired states,\nand obtain an a-posteriori error estimator which is efficient and reliable.\nNumerical experiments confirm our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Thomas F\u00fchrer",
      "Michael Karkulik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09879"
  },
  {
    "id": "arXiv:2208.09881",
    "title": "Masked Video Modeling with Correlation-aware Contrastive Learning for  Breast Cancer Diagnosis in Ultrasound",
    "abstract": "Breast cancer is one of the leading causes of cancer deaths in women. As the\nprimary output of breast screening, breast ultrasound (US) video contains\nexclusive dynamic information for cancer diagnosis. However, training models\nfor video analysis is non-trivial as it requires a voluminous dataset which is\nalso expensive to annotate. Furthermore, the diagnosis of breast lesion faces\nunique challenges such as inter-class similarity and intra-class variation. In\nthis paper, we propose a pioneering approach that directly utilizes US videos\nin computer-aided breast cancer diagnosis. It leverages masked video modeling\nas pretraning to reduce reliance on dataset size and detailed annotations.\nMoreover, a correlation-aware contrastive loss is developed to facilitate the\nidentifying of the internal and external relationship between benign and\nmalignant lesions. Experimental results show that our proposed approach\nachieved promising classification performance and can outperform other\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by MICCAI-REMIA 2022\n",
    "authors": [
      "Zehui Lin",
      "Ruobing Huang",
      "Dong Ni",
      "Jiayi Wu",
      "Baoming Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09881"
  },
  {
    "id": "arXiv:2208.09883",
    "title": "Learning high dimensional stochastic partial differential equations in a  predictor-corrector framework",
    "abstract": "In this paper, we propose a deep learning-based numerical method for\napproximating high dimensional stochastic partial differential equations in a\npredictor-corrector framework. At each time step, the original equation is\ndecomposed into a degenerate stochastic partial differential equation to serve\nas the prediction step, and a second-order deterministic partial differential\nequation to serve as the correction step. The solution of the degenerate\nstochastic partial differential equation is approximated by the Euler method,\nand the solution of the partial differential equation is approximated by neural\nnetworks via the equivalent backward stochastic differential equation. Under\nstandard assumptions, the rate of convergence and the error estimates in terms\nof the approximation error of neural networks are provided. The efficiency and\naccuracy of the proposed algorithm are illustrated by the numerical results.",
    "descriptor": "",
    "authors": [
      "He Zhang",
      "Ran Zhang",
      "Tao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09883"
  },
  {
    "id": "arXiv:2208.09884",
    "title": "DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples  Discrimination",
    "abstract": "Given data with label noise (i.e., incorrect data), deep neural networks\nwould gradually memorize the label noise and impair model performance. To\nrelieve this issue, curriculum learning is proposed to improve model\nperformance and generalization by ordering training samples in a meaningful\n(e.g., easy to hard) sequence. Previous work takes incorrect samples as generic\nhard ones without discriminating between hard samples (i.e., hard samples in\ncorrect data) and incorrect samples. Indeed, a model should learn from hard\nsamples to promote generalization rather than overfit to incorrect ones. In\nthis paper, we address this problem by appending a novel loss function\nDiscrimLoss, on top of the existing task loss. Its main effect is to\nautomatically and stably estimate the importance of easy samples and difficult\nsamples (including hard and incorrect samples) at the early stages of training\nto improve the model performance. Then, during the following stages,\nDiscrimLoss is dedicated to discriminating between hard and incorrect samples\nto improve the model generalization. Such a training strategy can be formulated\ndynamically in a self-supervised manner, effectively mimicking the main\nprinciple of curriculum learning. Experiments on image classification, image\nregression, text sequence regression, and event relation reasoning demonstrate\nthe versatility and effectiveness of our method, particularly in the presence\nof diversified noise levels.",
    "descriptor": "",
    "authors": [
      "Tingting Wu",
      "Xiao Ding",
      "Hao Zhang",
      "Jinglong Gao",
      "Li Du",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09884"
  },
  {
    "id": "arXiv:2208.09885",
    "title": "HST: Hierarchical Swin Transformer for Compressed Image Super-resolution",
    "abstract": "Compressed Image Super-resolution has achieved great attention in recent\nyears, where images are degraded with compression artifacts and low-resolution\nartifacts. Since the complex hybrid distortions, it is hard to restore the\ndistorted image with the simple cooperation of super-resolution and compression\nartifacts removing. In this paper, we take a step forward to propose the\nHierarchical Swin Transformer (HST) network to restore the low-resolution\ncompressed image, which jointly captures the hierarchical feature\nrepresentations and enhances each-scale representation with Swin transformer,\nrespectively. Moreover, we find that the pretraining with Super-resolution (SR)\ntask is vital in compressed image super-resolution. To explore the effects of\ndifferent SR pretraining, we take the commonly-used SR tasks (e.g., bicubic and\ndifferent real super-resolution simulations) as our pretraining tasks, and\nreveal that SR plays an irreplaceable role in the compressed image\nsuper-resolution. With the cooperation of HST and pre-training, our HST\nachieves the fifth place in AIM 2022 challenge on the low-quality compressed\nimage super-resolution track, with the PSNR of 23.51dB. Extensive experiments\nand ablation studies have validated the effectiveness of our proposed methods.",
    "descriptor": "\nComments: Accepted by ECCV2022 Workshop (AIM2022)\n",
    "authors": [
      "Bingchen Li",
      "Xin Li",
      "Yiting Lu",
      "Sen Liu",
      "Ruoyu Feng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09885"
  },
  {
    "id": "arXiv:2208.09894",
    "title": "Byzantines can also Learn from History: Fall of Centered Clipping in  Federated Learning",
    "abstract": "The increasing popularity of the federated learning framework due to its\nsuccess in a wide range of collaborative learning tasks also induces certain\nsecurity concerns regarding the learned model due to the possibility of\nmalicious clients participating in the learning process. Hence, the objective\nis to neutralize the impact of the malicious participants and to ensure the\nfinal model is trustable. One common observation regarding the Byzantine\nattacks is that the higher the variance among the clients' models/updates, the\nmore space for attacks to be hidden. To this end, it has been recently shown\nthat by utilizing momentum, thus reducing the variance, it is possible to\nweaken the strength of the known Byzantine attacks. The Centered Clipping\nframework (ICML 2021) has further shown that, besides reducing the variance,\nthe momentum term from the previous iteration can be used as a reference point\nto neutralize the Byzantine attacks and show impressive performance against\nwell-known attacks. However, in the scope of this work, we show that the\ncentered clipping framework has certain vulnerabilities, and existing attacks\ncan be revised based on these vulnerabilities to circumvent the centered\nclipping defense. Hence, we introduce a strategy to design an attack to\ncircumvent the centered clipping framework and numerically illustrate its\neffectiveness against centered clipping as well as other known defense\nstrategies by reducing test accuracy to 5-40 on best-case scenarios.",
    "descriptor": "",
    "authors": [
      "Kerem Ozfatura",
      "Emre Ozfatura",
      "Alptekin Kupcu",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09894"
  },
  {
    "id": "arXiv:2208.09896",
    "title": "SIM2E: Benchmarking the Group Equivariant Capability of Correspondence  Matching Algorithms",
    "abstract": "Correspondence matching is a fundamental problem in computer vision and\nrobotics applications. Solving correspondence matching problems using neural\nnetworks has been on the rise recently. Rotation-equivariance and\nscale-equivariance are both critical in correspondence matching applications.\nClassical correspondence matching approaches are designed to withstand scaling\nand rotation transformations. However, the features extracted using\nconvolutional neural networks (CNNs) are only translation-equivariant to a\ncertain extent. Recently, researchers have strived to improve the\nrotation-equivariance of CNNs based on group theories. Sim(2) is the group of\nsimilarity transformations in the 2D plane. This paper presents a specialized\ndataset dedicated to evaluating sim(2)-equivariant correspondence matching\nalgorithms. We compare the performance of 16 state-of-the-art (SoTA)\ncorrespondence matching approaches. The experimental results demonstrate the\nimportance of group equivariant algorithms for correspondence matching on\nvarious sim(2) transformation conditions. Since the subpixel accuracy achieved\nby CNN-based correspondence matching approaches is unsatisfactory, this\nspecific area requires more attention in future works. Our dataset is publicly\navailable at: mias.group/SIM2E.",
    "descriptor": "\nComments: ECCV2022 Workshop Paper\n",
    "authors": [
      "Shuai Su",
      "Zhongkai Zhao",
      "Yixin Fei",
      "Shuda Li",
      "Qijun Chen",
      "Rui Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09896"
  },
  {
    "id": "arXiv:2208.09899",
    "title": "Adaptively restarted block Krylov subspace methods with  low-synchronization skeletons",
    "abstract": "With the recent realization of exascale performace by Oak Ridge National\nLaboratory's Frontier supercomputer, reducing communication in kernels like QR\nfactorization has become even more imperative. Low-synchronization Gram-Schmidt\nmethods, first introduced in [K. \\'{S}wirydowicz, J. Langou, S. Ananthan, U.\nYang, and S. Thomas, Low Synchronization Gram-Schmidt and Generalized Minimum\nResidual Algorithms, Numer. Lin. Alg. Appl., Vol. 28(2), e2343, 2020], have\nbeen shown to improve the scalability of the Arnoldi method in high-performance\ndistributed computing. Block versions of low-synchronization Gram-Schmidt show\nfurther potential for speeding up algorithms, as column-batching allows for\nmaximizing cache usage with matrix-matrix operations. In this work,\nlow-synchronization block Gram-Schmidt variants from [E. Carson, K. Lund, M.\nRozlo\\v{z}n\\'{i}k, and S. Thomas, Block Gram-Schmidt algorithms and their\nstability properties, Lin. Alg. Appl., 638, pp. 150--195, 2022] are transformed\ninto block Arnoldi variants for use in block full orthogonalization methods\n(BFOM) and block generalized minimal residual methods (BGMRES). An adaptive\nrestarting heuristic is developed to handle instabilities that arise with the\nincreasing condition number of the Krylov basis. The performance, accuracy, and\nstability of these methods are assessed via a flexible benchmarking tool\nwritten in MATLAB. The modularity of the tool additionally permits generalized\nblock inner products, like the global inner product.",
    "descriptor": "",
    "authors": [
      "Kathryn Lund"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09899"
  },
  {
    "id": "arXiv:2208.09900",
    "title": "Provable Adaptivity in Adam",
    "abstract": "Adaptive Moment Estimation (Adam) optimizer is widely used in deep learning\ntasks because of its fast convergence properties. However, the convergence of\nAdam is still not well understood. In particular, the existing analysis of Adam\ncannot clearly demonstrate the advantage of Adam over SGD. We attribute this\ntheoretical embarrassment to $L$-smooth condition (i.e., assuming the gradient\nis globally Lipschitz continuous with constant $L$) adopted by literature,\nwhich has been pointed out to often fail in practical neural networks. To\ntackle this embarrassment, we analyze the convergence of Adam under a relaxed\ncondition called $(L_0,L_1)$ smoothness condition, which allows the gradient\nLipschitz constant to change with the local gradient norm. $(L_0,L_1)$ is\nstrictly weaker than $L$-smooth condition and it has been empirically verified\nto hold for practical deep neural networks. Under the $(L_0,L_1)$ smoothness\ncondition, we establish the convergence for Adam with practical\nhyperparameters. Specifically, we argue that Adam can adapt to the local\nsmoothness condition, justifying the \\emph{adaptivity} of Adam. In contrast,\nSGD can be arbitrarily slow under this condition. Our result might shed light\non the benefit of adaptive gradient methods over non-adaptive ones.",
    "descriptor": "",
    "authors": [
      "Bohan Wang",
      "Yushun Zhang",
      "Huishuai Zhang",
      "Qi Meng",
      "Zhi-Ming Ma",
      "Tie-Yan Liu",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09900"
  },
  {
    "id": "arXiv:2208.09901",
    "title": "Scalable mRMR feature selection to handle high dimensional datasets:  Vertical partitioning based Iterative MapReduce framework",
    "abstract": "While building machine learning models, Feature selection (FS) stands out as\nan essential preprocessing step used to handle the uncertainty and vagueness in\nthe data. Recently, the minimum Redundancy and Maximum Relevance (mRMR)\napproach has proven to be effective in obtaining the irredundant feature\nsubset. Owing to the generation of voluminous datasets, it is essential to\ndesign scalable solutions using distributed/parallel paradigms. MapReduce\nsolutions are proven to be one of the best approaches to designing\nfault-tolerant and scalable solutions. This work analyses the existing\nMapReduce approaches for mRMR feature selection and identifies the limitations\nthereof. In the current study, we proposed VMR_mRMR, an efficient vertical\npartitioning-based approach using a memorization approach, thereby overcoming\nthe extant approaches limitations. The experiment analysis says that VMR_mRMR\nsignificantly outperformed extant approaches and achieved a better\ncomputational gain (C.G). In addition, we also conducted a comparative analysis\nwith the horizontal partitioning approach HMR_mRMR [1] to assess the strengths\nand limitations of the proposed approach.",
    "descriptor": "\nComments: 20 pages, 3 Figures, 5 Tables\n",
    "authors": [
      "Yelleti Vivek",
      "P.S.V.S. Sai Prasad"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.09901"
  },
  {
    "id": "arXiv:2208.09905",
    "title": "MentorGNN: Deriving Curriculum for Pre-Training GNNs",
    "abstract": "Graph pre-training strategies have been attracting a surge of attention in\nthe graph mining community, due to their flexibility in parameterizing graph\nneural networks (GNNs) without any label information. The key idea lies in\nencoding valuable information into the backbone GNNs, by predicting the masked\ngraph signals extracted from the input graphs. In order to balance the\nimportance of diverse graph signals (e.g., nodes, edges, subgraphs), the\nexisting approaches are mostly hand-engineered by introducing hyperparameters\nto re-weight the importance of graph signals. However, human interventions with\nsub-optimal hyperparameters often inject additional bias and deteriorate the\ngeneralization performance in the downstream applications. This paper addresses\nthese limitations from a new perspective, i.e., deriving curriculum for\npre-training GNNs. We propose an end-to-end model named MentorGNN that aims to\nsupervise the pre-training process of GNNs across graphs with diverse\nstructures and disparate feature spaces. To comprehend heterogeneous graph\nsignals at different granularities, we propose a curriculum learning paradigm\nthat automatically re-weighs graph signals in order to ensure a good\ngeneralization in the target domain. Moreover, we shed new light on the problem\nof domain adaption on relational data (i.e., graphs) by deriving a natural and\ninterpretable upper bound on the generalization error of the pre-trained GNNs.\nExtensive experiments on a wealth of real graphs validate and verify the\nperformance of MentorGNN.",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Dawei Zhou",
      "Lecheng Zheng",
      "Dongqi Fu",
      "Jiawei Han",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09905"
  },
  {
    "id": "arXiv:2208.09910",
    "title": "Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic  Segmentation",
    "abstract": "In this work, we revisit the weak-to-strong consistency framework,\npopularized by FixMatch from semi-supervised classification, where the\nprediction of a weakly perturbed image serves as supervision for its strongly\nperturbed version. Intriguingly, we observe that such a simple pipeline already\nachieves competitive results against recent advanced works, when transferred to\nour segmentation scenario. Its success heavily relies on the manual design of\nstrong data augmentations, however, which may be limited and inadequate to\nexplore a broader perturbation space. Motivated by this, we propose an\nauxiliary feature perturbation stream as a supplement, leading to an expanded\nperturbation space. On the other, to sufficiently probe original image-level\naugmentations, we present a dual-stream perturbation technique, enabling two\nstrong views to be simultaneously guided by a common weak view. Consequently,\nour overall Unified Dual-Stream Perturbations approach (UniMatch) surpasses all\nexisting methods significantly across all evaluation protocols on the Pascal,\nCityscapes, and COCO benchmarks. We also demonstrate the superiority of our\nmethod in remote sensing interpretation and medical image analysis. Code is\navailable at https://github.com/LiheYoung/UniMatch.",
    "descriptor": "\nComments: 18 pages, 18 tables\n",
    "authors": [
      "Lihe Yang",
      "Lei Qi",
      "Litong Feng",
      "Wayne Zhang",
      "Yinghuan Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09910"
  },
  {
    "id": "arXiv:2208.09912",
    "title": "A Syntax Aware BERT for Identifying Well-Formed Queries in a Curriculum  Framework",
    "abstract": "A well formed query is defined as a query which is formulated in the manner\nof an inquiry, and with correct interrogatives, spelling and grammar. While\nidentifying well formed queries is an important task, few works have attempted\nto address it. In this paper we propose transformer based language model -\nBidirectional Encoder Representations from Transformers (BERT) to this task. We\nfurther imbibe BERT with parts-of-speech information inspired from earlier\nworks. Furthermore, we also train the model in multiple curriculum settings for\nimprovement in performance. Curriculum Learning over the task is experimented\nwith Baby Steps and One Pass techniques. Proposed architecture performs\nexceedingly well on the task. The best approach achieves accuracy of 83.93%,\noutperforming previous state-of-the-art at 75.0% and reaching close to the\napproximate human upper bound of 88.4%.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Avinash Madasu",
      "Anvesh Rao Vijjini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09912"
  },
  {
    "id": "arXiv:2208.09913",
    "title": "A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function  Perspective",
    "abstract": "We propose the first unified theoretical analysis of mixed sample data\naugmentation (MSDA), such as Mixup and CutMix. Our theoretical results show\nthat regardless of the choice of the mixing strategy, MSDA behaves as a\npixel-level regularization of the underlying training loss and a regularization\nof the first layer parameters. Similarly, our theoretical results support that\nthe MSDA training strategy can improve adversarial robustness and\ngeneralization compared to the vanilla training strategy. Using the theoretical\nresults, we provide a high-level understanding of how different design choices\nof MSDA work differently. For example, we show that the most popular MSDA\nmethods, Mixup and CutMix, behave differently, e.g., CutMix regularizes the\ninput gradients by pixel distances, while Mixup regularizes the input gradients\nregardless of pixel distances. Our theoretical results also show that the\noptimal MSDA strategy depends on tasks, datasets, or model parameters. From\nthese observations, we propose generalized MSDAs, a Hybrid version of Mixup and\nCutMix (HMix) and Gaussian Mixup (GMix), simple extensions of Mixup and CutMix.\nOur implementation can leverage the advantages of Mixup and CutMix, while our\nimplementation is very efficient, and the computation cost is almost\nneglectable as Mixup and CutMix. Our empirical study shows that our HMix and\nGMix outperform the previous state-of-the-art MSDA methods in CIFAR-100 and\nImageNet classification tasks. Source code is available at\nhttps://github.com/naver-ai/hmix-gmix",
    "descriptor": "\nComments: First two authors contributed equally; 29 pages\n",
    "authors": [
      "Chanwoo Park",
      "Sangdoo Yun",
      "Sanghyuk Chun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09913"
  },
  {
    "id": "arXiv:2208.09915",
    "title": "MockingBERT: A Method for Retroactively Adding Resilience to NLP Models",
    "abstract": "Protecting NLP models against misspellings whether accidental or adversarial\nhas been the object of research interest for the past few years. Existing\nremediations have typically either compromised accuracy or required full model\nre-training with each new class of attacks. We propose a novel method of\nretroactively adding resilience to misspellings to transformer-based NLP\nmodels. This robustness can be achieved without the need for re-training of the\noriginal NLP model and with only a minimal loss of language understanding\nperformance on inputs without misspellings. Additionally we propose a new\nefficient approximate method of generating adversarial misspellings, which\nsignificantly reduces the cost needed to evaluate a model's resilience to\nadversarial attacks.",
    "descriptor": "\nComments: 8 pages (excl. bibiography and appendix), 2 figures The code necessary for reproduction is available at this https URL To be published in Proceedings of the 29th International Conference on Computational Linguistics (COLING 2022)\n",
    "authors": [
      "Jan Jezabek",
      "Akash Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09915"
  },
  {
    "id": "arXiv:2208.09916",
    "title": "A Web Application for Experimenting and Validating Remote Measurement of  Vital Signs",
    "abstract": "With a surge in online medical advising remote monitoring of patient vitals\nis required. This can be facilitated with the Remote Photoplethysmography\n(rPPG) techniques that compute vital signs from facial videos. It involves\nprocessing video frames to obtain skin pixels, extracting the cardiac data from\nit and applying signal processing filters to extract the Blood Volume Pulse\n(BVP) signal. Different algorithms are applied to the BVP signal to estimate\nthe various vital signs. We implemented a web application framework to measure\na person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation\n(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face\nvideo. The rPPG technique is highly sensitive to illumination and motion\nvariation. The web application guides the users to reduce the noise due to\nthese variations and thereby yield a cleaner BVP signal. The accuracy and\nrobustness of the framework was validated with the help of volunteers.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Amtul Haq Ayesha",
      "Donghao Qiao",
      "Farhana Zulkernine"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09916"
  },
  {
    "id": "arXiv:2208.09921",
    "title": "Alexa, Predict My Flight Delay",
    "abstract": "Airlines are critical today for carrying people and commodities on time. Any\ndelay in the schedule of these planes can potentially disrupt the business and\ntrade of thousands of employees at any given time. Therefore, precise flight\ndelay prediction is beneficial for the aviation industry and passenger travel.\nRecent research has focused on using artificial intelligence algorithms to\npredict the possibility of flight delays. Earlier prediction algorithms were\ndesigned for a specific air route or airfield. Many present flight delay\nprediction algorithms rely on tiny samples and are challenging to understand,\nallowing almost no room for machine learning implementation. This research\nstudy develops a flight delay prediction system by analyzing data from domestic\nflights inside the United States of America. The proposed models learn about\nthe factors that cause flight delays and cancellations and the link between\ndeparture and arrival delays.",
    "descriptor": "",
    "authors": [
      "Sia Gholami",
      "Saba Khashe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09921"
  },
  {
    "id": "arXiv:2208.09926",
    "title": "A semi-supervised Teacher-Student framework for surgical tool detection  and localization",
    "abstract": "Surgical tool detection in minimally invasive surgery is an essential part of\ncomputer-assisted interventions. Current approaches are mostly based on\nsupervised methods which require large fully labeled data to train supervised\nmodels and suffer from pseudo label bias because of class imbalance issues.\nHowever large image datasets with bounding box annotations are often scarcely\navailable. Semi-supervised learning (SSL) has recently emerged as a means for\ntraining large models using only a modest amount of annotated data; apart from\nreducing the annotation cost. SSL has also shown promise to produce models that\nare more robust and generalizable. Therefore, in this paper we introduce a\nsemi-supervised learning (SSL) framework in surgical tool detection paradigm\nwhich aims to mitigate the scarcity of training data and the data imbalance\nthrough a knowledge distillation approach. In the proposed work, we train a\nmodel with labeled data which initialises the Teacher-Student joint learning,\nwhere the Student is trained on Teacher-generated pseudo labels from unlabeled\ndata. We propose a multi-class distance with a margin based classification loss\nfunction in the region-of-interest head of the detector to effectively\nsegregate foreground classes from background region. Our results on\nm2cai16-tool-locations dataset indicate the superiority of our approach on\ndifferent supervised data settings (1%, 2%, 5%, 10% of annotated data) where\nour model achieves overall improvements of 8%, 12% and 27% in mAP (on 1%\nlabeled data) over the state-of-the-art SSL methods and a fully supervised\nbaseline, respectively. The code is available at\nhttps://github.com/Mansoor-at/Semi-supervised-surgical-tool-det",
    "descriptor": "\nComments: Paper accepted at Augmented Reality, Augmented Environments for Computer Assisted Interventions (AE-CAI), Computer Assisted and Robotic Endoscopy (CARE) and Context-Aware Operating Theaters (OR 2.0) at MICCAI 2022\n",
    "authors": [
      "Mansoor Ali",
      "Gilberto Ochoa-Ruiz",
      "Sharib Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09926"
  },
  {
    "id": "arXiv:2208.09927",
    "title": "Sparsification of Large Ultrametric Matrices: Insights into the  Microbial Tree of Life",
    "abstract": "Ultrametric matrices have a rich structure that is not apparent from their\ndefinition. Notably, the subclass of strictly ultrametric matrices are\ncovariance matrices of certain weighted rooted binary trees. In applications,\nthese matrices can be large and dense, making them difficult to store and\nhandle. In this manuscript, we exploit the underlying tree structure of these\nmatrices to sparsify them via a similarity transformation based on Haar-like\nwavelets. We show that, with overwhelmingly high probability, only an\nasymptotically negligible fraction of the off-diagonal entries in random but\nlarge strictly ultrametric matrices remain non-zero after the transformation;\nand develop a fast algorithm to compress such matrices directly from their tree\nrepresentation. We also identify the subclass of matrices diagonalized by the\nwavelets and supply a sufficient condition to approximate the spectrum of\nstrictly ultrametric matrices outside this subclass. Our methods give\ncomputational access to a covariance model of the microbiologists' Tree of\nLife, which was previously inaccessible due to its size, and motivate defining\na new but wavelet-based phylogenetic $\\beta$-diversity metric. Applying this\nmetric to a metagenomic dataset demonstrates that it can provide novel insight\ninto noisy high-dimensional samples and localize speciation events that may be\nmost important in determining relationships between environmental factors and\nmicrobial composition.",
    "descriptor": "\nComments: 30 pages, 10 figures, 1 table (embedded in figure), 1 algorithm (pseudo-code), link to GitHub\n",
    "authors": [
      "Evan D. Gorman",
      "Manuel E. Lladser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Discrete Mathematics (cs.DM)",
      "Genomics (q-bio.GN)",
      "Populations and Evolution (q-bio.PE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.09927"
  },
  {
    "id": "arXiv:2208.09929",
    "title": "A Survey of Augmented Piano Prototypes: Has Augmentation Improved  Learning Experiences?",
    "abstract": "Humans have been developing and playing musical instruments for millennia.\nWith technological advancements, instruments were becoming ever more\nsophisticated. In recent decades computer-supported innovations have also been\nintroduced in hardware design, usability, and aesthetics. One of the most\ncommonly digitally augmented instruments is the piano. Besides electronic\nkeyboards, several prototypes augmenting pianos with different projections\nproviding various levels of interactivity on and around the keyboard have been\nimplemented in order to support piano players. However, it is still not\nunderstood if these solutions are indeed supporting the learning process. In\nthis paper we present a systematic review of augmented piano prototypes\nfocusing on instrument learning, which is based on the four themes derived from\ninterviews of piano experts to better understand the problems of teaching the\npiano. These themes are: (i) synchronised movement and body posture, (ii)\nsight-reading, (iii) ensuring motivation, and (iv) encouraging improvisation.\nWe found that prototypes are saturated on the synchronisation themes, and there\nare opportunities for sight-reading, motivation, and improvisation themes. We\nconclude by presenting recommendations on augmenting piano systems towards\nenriching the piano learning experience as well as on possible directions to\nexpand knowledge in the area.",
    "descriptor": "\nComments: 28 pages, 5 figures, 3 tables, Proceedings of ISS'22\n",
    "authors": [
      "Jordan Aiko Deja",
      "Sven Mayer",
      "Klen \u010copi\u010d Pucihar",
      "Matja\u017e Kljun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.09929"
  },
  {
    "id": "arXiv:2208.09931",
    "title": "ProPaLL: Probabilistic Partial Label Learning",
    "abstract": "Partial label learning is a type of weakly supervised learning, where each\ntraining instance corresponds to a set of candidate labels, among which only\none is true. In this paper, we introduce ProPaLL, a novel probabilistic\napproach to this problem, which has at least three advantages compared to the\nexisting approaches: it simplifies the training process, improves performance,\nand can be applied to any deep architecture. Experiments conducted on\nartificial and real-world datasets indicate that ProPaLL outperforms the\nexisting approaches.",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Struski",
      "Jacek Tabor",
      "Bartosz Zieli\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09931"
  },
  {
    "id": "arXiv:2208.09932",
    "title": "Improving GANs for Long-Tailed Data through Group Spectral  Regularization",
    "abstract": "Deep long-tailed learning aims to train useful deep networks on practical,\nreal-world imbalanced distributions, wherein most labels of the tail classes\nare associated with a few samples. There has been a large body of work to train\ndiscriminative models for visual recognition on long-tailed distribution. In\ncontrast, we aim to train conditional Generative Adversarial Networks, a class\nof image generation models on long-tailed distributions. We find that similar\nto recognition, state-of-the-art methods for image generation also suffer from\nperformance degradation on tail classes. The performance degradation is mainly\ndue to class-specific mode collapse for tail classes, which we observe to be\ncorrelated with the spectral explosion of the conditioning parameter matrix. We\npropose a novel group Spectral Regularizer (gSR) that prevents the spectral\nexplosion alleviating mode collapse, which results in diverse and plausible\nimage generation even for tail classes. We find that gSR effectively combines\nwith existing augmentation and regularization techniques, leading to\nstate-of-the-art image generation performance on long-tailed data. Extensive\nexperiments demonstrate the efficacy of our regularizer on long-tailed datasets\nwith different degrees of imbalance.",
    "descriptor": "\nComments: ECCV 2022. Project Page: this https URL\n",
    "authors": [
      "Harsh Rangwani",
      "Naman Jaswani",
      "Tejan Karmali",
      "Varun Jampani",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09932"
  },
  {
    "id": "arXiv:2208.09937",
    "title": "An Incentive-Compatible Mechanism for Decentralized Storage Network",
    "abstract": "The dominance of a few big companies in the storage market arising various\nconcerns including single point of failure, privacy violation, and oligopoly.\nTo eliminate the dependency on such a centralized storage architecture, several\nDecentralized Storage Network (DSN) schemes such as Filecoin, Sia, and Storj\nhave been introduced. DSNs leverage blockchain technology to create a storage\nplatform such that the micro storage providers can also participate in the\nstorage market. To verify the accurate data storage by the storage providers\nduring a storage contract, DSNs apply a Proof of Storage (PoS) scheme to\ncontinuously inspect the storage service. However, continuous verification of\nthe storage provider imposes an extra cost to the network and therefore\nend-users. Moreover, DSN's PoS verification is vulnerable to a service denying\nattack in which the storage provider submits valid PoS to the network while\ndenying the service to the client.\nConsidering the benefits and existing challenges of DSNs, this paper\nintroduces a novel incentive-compatible DSN scheme. In this scheme, the PoS is\nconducted only if the client submits a challenge request. We model the storage\nservice as a repeated dynamic game and set the players' payoffs such that the\nstorage provider's dominant strategy is to honestly follow the storage\ncontract. Our proposed mechanism leverages the smart-contract and oracle\nnetwork to govern the storage agreement between the client and storage provider\nefficiently. Furthermore, our scheme is independent of a specific blockchain\nplatform but can be plugged into any blockchain platform with smart-contract\nexecution capability. As a proof of concept, we have implemented our scheme\nusing solidity language and chainlink oracle network. The performance analysis\ndemonstrates the applicability of our scheme.",
    "descriptor": "",
    "authors": [
      "Iman Vakilinia",
      "Weihong Wang",
      "Jiajun Xin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.09937"
  },
  {
    "id": "arXiv:2208.09938",
    "title": "Instability and Local Minima in GAN Training with Kernel Discriminators",
    "abstract": "Generative Adversarial Networks (GANs) are a widely-used tool for generative\nmodeling of complex data. Despite their empirical success, the training of GANs\nis not fully understood due to the min-max optimization of the generator and\ndiscriminator. This paper analyzes these joint dynamics when the true samples,\nas well as the generated samples, are discrete, finite sets, and the\ndiscriminator is kernel-based. A simple yet expressive framework for analyzing\ntraining called the $\\textit{Isolated Points Model}$ is introduced. In the\nproposed model, the distance between true samples greatly exceeds the kernel\nwidth, so each generated point is influenced by at most one true point. Our\nmodel enables precise characterization of the conditions for convergence, both\nto good and bad minima. In particular, the analysis explains two common failure\nmodes: (i) an approximate mode collapse and (ii) divergence. Numerical\nsimulations are provided that predictably replicate these behaviors.",
    "descriptor": "",
    "authors": [
      "Evan Becker",
      "Parthe Pandit",
      "Sundeep Rangan",
      "Alyson K. Fletcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09938"
  },
  {
    "id": "arXiv:2208.09940",
    "title": "Efficient numerical method for reliable upper and lower bounds on  homogenized parameters",
    "abstract": "A numerical procedure providing guaranteed two-sided bounds on the effective\ncoefficients of elliptic partial differential operators is presented. The upper\nbounds are obtained in a standard manner through the variational formulation of\nthe problem and by applying the finite element method. To obtain the lower\nbounds we formulate the dual variational problem and introduce appropriate\napproximation spaces employing the finite element method as well. We deal with\nthe 3D setting, which has been rarely considered in the literature so far. The\ntheoretical justification of the procedure is presented and supported with\nillustrative examples.",
    "descriptor": "\nComments: 17 pages, 1 table\n",
    "authors": [
      "Liya Gaynutdinova",
      "Martin Ladeck\u00fd",
      "Ale\u0161 Nekvinda",
      "Ivana Pultarov\u00e1",
      "Jan Zeman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09940"
  },
  {
    "id": "arXiv:2208.09941",
    "title": "Why So Inflammatory? Explainability in Automatic Detection of  Inflammatory Social Media Users",
    "abstract": "Hate speech and misinformation, spread over social networking services (SNS)\nsuch as Facebook and Twitter, have inflamed ethnic and political violence in\ncountries across the globe. We argue that there is limited research on this\nproblem within the context of the Global South and present an approach for\ntackling them. Prior works have shown how machine learning models built with\nuser-level interaction features can effectively identify users who spread\ninflammatory content. While this technique is beneficial in low-resource\nlanguage settings where linguistic resources such as ground truth data and\nprocessing capabilities are lacking, it is still unclear how these interaction\nfeatures contribute to model performance. In this work, we investigate and show\nsignificant differences in interaction features between users who spread\ninflammatory content and others who do not, applying explainability tools to\nunderstand our trained model. We find that features with higher interaction\nsignificance (such as account age and activity count) show higher explanatory\npower than features with lower interaction significance (such as name length\nand if the user has a location on their bio). Our work extends research\ndirections that aim to understand the nature of inflammatory content in\nlow-resource, high-risk contexts as the growth of social media use in the\nGlobal South outstrips moderation efforts.",
    "descriptor": "\nComments: 6 pages. Spotlight paper at PML4DC 2022 workshop, co-located with ICLR 2022\n",
    "authors": [
      "Cuong Nguyen",
      "Daniel Nkemelu",
      "Ankit Mehta",
      "Michael Best"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.09941"
  },
  {
    "id": "arXiv:2208.09942",
    "title": "SeNMFk-SPLIT: Large Corpora Topic Modeling by Semantic Non-negative  Matrix Factorization with Automatic Model Selection",
    "abstract": "As the amount of text data continues to grow, topic modeling is serving an\nimportant role in understanding the content hidden by the overwhelming quantity\nof documents. One popular topic modeling approach is non-negative matrix\nfactorization (NMF), an unsupervised machine learning (ML) method. Recently,\nSemantic NMF with automatic model selection (SeNMFk) has been proposed as a\nmodification to NMF. In addition to heuristically estimating the number of\ntopics, SeNMFk also incorporates the semantic structure of the text. This is\nperformed by jointly factorizing the term frequency-inverse document frequency\n(TF-IDF) matrix with the co-occurrence/word-context matrix, the values of which\nrepresent the number of times two words co-occur in a predetermined window of\nthe text. In this paper, we introduce a novel distributed method, SeNMFk-SPLIT,\nfor semantic topic extraction suitable for large corpora. Contrary to SeNMFk,\nour method enables the joint factorization of large documents by decomposing\nthe word-context and term-document matrices separately. We demonstrate the\ncapability of SeNMFk-SPLIT by applying it to the entire artificial intelligence\n(AI) and ML scientific literature uploaded on arXiv.",
    "descriptor": "\nComments: Accepted at ACM Symposium on Document Engineering 2022 (DocEng 22), 2022\n",
    "authors": [
      "Maksim E. Eren",
      "Nick Solovyev",
      "Manish Bhattarai",
      "Kim Rasmussen",
      "Charles Nicholas",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09942"
  },
  {
    "id": "arXiv:2208.09944",
    "title": "MolGraph: a Python package for the implementation of small molecular  graphs and graph neural networks with TensorFlow and Keras",
    "abstract": "Molecular machine learning (ML) has proven important for tackling various\nmolecular problems, including the prediction of protein-drug interactions and\nblood brain-barrier permeability. Since relatively recently, so-called graph\nneural networks (GNNs) have been implemented for molecular ML, showing\ncomparable or superior performance to descriptor-based approaches. Although\nvarious tools and packages exist to apply GNNs for molecular ML, a new GNN\npackage, named MolGraph (https://github.com/akensert/molgraph), was developed\nin this work with the motivation to create GNNs highly compatible with the\nTensorFlow and Keras application programming interface (API). As MolGraph\nfocuses specifically and exclusively on molecular ML, a chemistry module was\nimplemented to accommodate the generation of molecular graphs $\\unicode{x2014}$\nwhich could then be inputted to the GNNs for molecular ML. To validate the\nGNNs, they were benchmarked against the datasets of MoleculeNet, as well as\nthree chromatographic retention time datasets. The results on these benchmarks\nshow that the GNNs performed as expected. Additionally, the GNNs proved useful\nfor molecular identification and improved interpretability of chromatographic\nretention data.",
    "descriptor": "\nComments: 16 pages, 4 figures, 5 tables\n",
    "authors": [
      "Alexander Kensert",
      "Gert Desmet",
      "Deirdre Cabooter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.09944"
  },
  {
    "id": "arXiv:2208.09948",
    "title": "Counting Cycles on Planar Graphs in Subexponential Time",
    "abstract": "We study the problem of counting all cycles or self-avoiding walks (SAWs) on\ntriangulated planar graphs. We present a subexponential $2^{O(\\sqrt{n})}$ time\nalgorithm for this counting problem. Among the technical ingredients used in\nthis algorithm are the planar separator theorem and a delicate analysis using\npairs of Motzkin paths and Motzkin numbers. We can then adapt this algorithm to\nuniformly sample SAWs, in subexponential time. Our work is motivated by the\nproblem of gerrymandered districting maps.",
    "descriptor": "\nComments: 28 pages, 6 figures, COCOON 2022\n",
    "authors": [
      "Jin-Yi Cai",
      "Ashwin Maran"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.09948"
  },
  {
    "id": "arXiv:2208.09950",
    "title": "Equalization and Brightness Mapping Modes of Color-to-Gray Projection  Operators",
    "abstract": "In this article, the conversion of color RGB images to grayscale is covered\nby characterizing the mathematical operators used to project 3 color channels\nto a single one. Based on the fact that most operators assign each of the\n$256^3$ colors a single gray level, ranging from 0 to 255, they are clustering\nalgorithms that distribute the color population into 256 clusters of increasing\nbrightness. To visualize the way operators work the sizes of the clusters and\nthe average brightness of each cluster are plotted. The equalization mode (EQ)\nintroduced in this work focuses on cluster sizes, while the brightness mapping\n(BM) mode describes the CIE L* luminance distribution per cluster. Three\nclasses of EQ modes and two classes of BM modes were found in linear operators,\ndefining a 6-class taxonomy. The theoretical/methodological framework\nintroduced was applied in a case study considering the equal-weights uniform\noperator, the NTSC standard operator, and an operator chosen as ideal to\nlighten the faces of black people to improve facial recognition in current\nbiased classifiers. It was found that most current metrics used to assess the\nquality of color-to-gray conversions better assess one of the two BM mode\nclasses, but the ideal operator chosen by a human team belongs to the other\nclass. Therefore, this cautions against using these general metrics for\nspecific purpose color-to-gray conversions. It should be noted that eventual\napplications of this framework to non-linear operators can give rise to new\nclasses of EQ and BM modes. The main contribution of this article is to provide\na tool to better understand color to gray converters in general, even those\nbased on machine learning, within the current trend of better explainability of\nmodels.",
    "descriptor": "",
    "authors": [
      "Diego Frias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.09950"
  },
  {
    "id": "arXiv:2208.09951",
    "title": "Bipartite Matchings with Group Fairness and Individual Fairness  Constraints",
    "abstract": "We address group as well as individual fairness constraints in matchings in\nthe context of assigning items to platforms. Each item belongs to certain\ngroups and has a preference ordering over platforms. Each platform enforces\ngroup fairness by specifying an upper and a lower bound on the number of items\nthat can be matched to it from each group. There could be multiple optimal\nsolutions that satisfy the group fairness constraints. To achieve individual\nfairness, we introduce `probabilistic individual fairness', where the goal is\nto compute a distribution over `group fair' matchings such that every item has\na reasonable probability of being matched to a platform among its top choices.\nIn the case where each item belongs to exactly one group, we provide a\npolynomial-time algorithm that computes a probabilistic individually fair\ndistribution over group fair matchings. When an item can belong to multiple\ngroups, and the group fairness constraints are specified as only upper bounds,\nwe rehash the same algorithm to achieve three different polynomial-time\napproximation algorithms.",
    "descriptor": "",
    "authors": [
      "Atasi Panda",
      "Anand Louis",
      "Prajakta Nibhorkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.09951"
  },
  {
    "id": "arXiv:2208.09956",
    "title": "Energy-aware Scheduling of Virtualized Base Stations in O-RAN with  Online Learning",
    "abstract": "The design of Open Radio Access Network (O-RAN) compliant systems for\nconfiguring the virtualized Base Stations (vBSs) is of paramount importance for\nnetwork operators. This task is challenging since optimizing the vBS scheduling\nprocedure requires knowledge of parameters, which are erratic and demanding to\nobtain in advance. In this paper, we propose an online learning algorithm for\nbalancing the performance and energy consumption of a vBS. This algorithm\nprovides performance guarantees under unforeseeable conditions, such as\nnon-stationary traffic and network state, and is oblivious to the vBS operation\nprofile. We study the problem in its most general form and we prove that the\nproposed technique achieves sub-linear regret (i.e., zero average optimality\ngap) even in a fast-changing environment. By using real-world data and various\ntrace-driven evaluations, our findings indicate savings of up to 74.3% in the\npower consumption of a vBS in comparison with state-of-the-art benchmarks.",
    "descriptor": "",
    "authors": [
      "Michail Kalntis",
      "George Iosifidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09956"
  },
  {
    "id": "arXiv:2208.09957",
    "title": "Heterogeneous Graph Masked Autoencoders",
    "abstract": "Generative self-supervised learning (SSL), especially masked autoencoders,\nhas become one of the most exciting learning paradigms and has shown great\npotential in handling graph data. However, real-world graphs are always\nheterogeneous, which poses three critical challenges that existing methods\nignore: 1) how to capture complex graph structure? 2) how to incorporate\nvarious node attributes? and 3) how to encode different node positions? In\nlight of this, we study the problem of generative SSL on heterogeneous graphs\nand propose HGMAE, a novel heterogeneous graph masked autoencoder model to\naddress these challenges. HGMAE captures comprehensive graph information via\ntwo innovative masking techniques and three unique training strategies. In\nparticular, we first develop metapath masking and adaptive attribute masking\nwith dynamic mask rate to enable effective and stable learning on heterogeneous\ngraphs. We then design several training strategies including metapath-based\nedge reconstruction to adopt complex structural information, target attribute\nrestoration to incorporate various node attributes, and positional feature\nprediction to encode node positional information. Extensive experiments\ndemonstrate that HGMAE outperforms both contrastive and generative\nstate-of-the-art baselines on several tasks across multiple datasets.",
    "descriptor": "",
    "authors": [
      "Yijun Tian",
      "Kaiwen Dong",
      "Chunhui Zhang",
      "Chuxu Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09957"
  },
  {
    "id": "arXiv:2208.09959",
    "title": "Exploring and Improving the Accessibility of Data Privacy-related  Information for People Who Are Blind or Low-vision",
    "abstract": "We present a study of privacy attitudes and behaviors of people who are blind\nor low vision. Our study involved in-depth interviews with 21 US participants.\nThe study explores their risk perceptions and also whether and how they go\nabout obtaining information about the data practices of digital technologies\nwith which they interact. One objective of the study is to better understand\nthis user group's needs for more accessible privacy tools. We also share some\nreflections on the challenge of recruiting an inclusive sample of participants\nfrom an already underrepresented user group in computing and how we were able\nto overcome this challenge.",
    "descriptor": "\nComments: Peer-reviewed short article at the 7th Workshop on Inclusive Privacy and Security (WIPS2022)\n",
    "authors": [
      "Yuanyuan Feng",
      "Abhilasha Ravichander",
      "Yaxing Yao",
      "Shikun Zhang",
      "Norman Sadeh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09959"
  },
  {
    "id": "arXiv:2208.09966",
    "title": "Performance, Opaqueness, Consequences, and Assumptions: Simple questions  for responsible planning of machine learning solutions",
    "abstract": "The data revolution has generated a huge demand for data-driven solutions.\nThis demand propels a growing number of easy-to-use tools and training for\naspiring data scientists that enable the rapid building of predictive models.\nToday, weapons of math destruction can be easily built and deployed without\ndetailed planning and validation. This rapidly extends the list of AI failures,\ni.e. deployments that lead to financial losses or even violate democratic\nvalues such as equality, freedom and justice. The lack of planning, rules and\nstandards around the model development leads to the ,,anarchisation of AI\".\nThis problem is reported under different names such as validation debt,\nreproducibility crisis, and lack of explainability. Post-mortem analysis of AI\nfailures often reveals mistakes made in the early phase of model development or\ndata acquisition. Thus, instead of curing the consequences of deploying harmful\nmodels, we shall prevent them as early as possible by putting more attention to\nthe initial planning stage.\nIn this paper, we propose a quick and simple framework to support planning of\nAI solutions. The POCA framework is based on four pillars: Performance,\nOpaqueness, Consequences, and Assumptions. It helps to set the expectations and\nplan the constraints for the AI solution before any model is built and any data\nis collected. With the help of the POCA method, preliminary requirements can be\ndefined for the model-building process, so that costly model misspecification\nerrors can be identified as soon as possible or even avoided. AI researchers,\nproduct owners and business analysts can use this framework in the initial\nstages of building AI solutions.",
    "descriptor": "",
    "authors": [
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.09966"
  },
  {
    "id": "arXiv:2208.09967",
    "title": "Inferring Sensitive Attributes from Model Explanations",
    "abstract": "Model explanations provide transparency into a trained machine learning\nmodel's blackbox behavior to a model builder. They indicate the influence of\ndifferent input attributes to its corresponding model prediction. The\ndependency of explanations on input raises privacy concerns for sensitive user\ndata. However, current literature has limited discussion on privacy risks of\nmodel explanations.\nWe focus on the specific privacy risk of attribute inference attack wherein\nan adversary infers sensitive attributes of an input (e.g., race and sex) given\nits model explanations. We design the first attribute inference attack against\nmodel explanations in two threat models where model builder either (a) includes\nthe sensitive attributes in training data and input or (b) censors the\nsensitive attributes by not including them in the training data and input.\nWe evaluate our proposed attack on four benchmark datasets and four\nstate-of-the-art algorithms. We show that an adversary can successfully infer\nthe value of sensitive attributes from explanations in both the threat models\naccurately. Moreover, the attack is successful even by exploiting only the\nexplanations corresponding to sensitive attributes. These suggest that our\nattack is effective against explanations and poses a practical threat to data\nprivacy.\nOn combining the model predictions (an attack surface exploited by prior\nattacks) with explanations, we note that the attack success does not improve.\nAdditionally, the attack success on exploiting model explanations is better\ncompared to exploiting only model predictions. These suggest that model\nexplanations are a strong attack surface to exploit for an adversary.",
    "descriptor": "\nComments: ACM CIKM 2022\n",
    "authors": [
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09967"
  },
  {
    "id": "arXiv:2208.09969",
    "title": "Interior over-stabilized enriched Galerkin methods for second order  elliptic equations",
    "abstract": "In this paper we propose a variant of enriched Galerkin methods for second\norder elliptic equations with over-stabilization of interior jump terms. The\nbilinear form with interior over-stabilization gives a non-standard norm which\nis different from the discrete energy norm in the classical discontinuous\nGalerkin methods. Nonetheless we prove that optimal a priori error estimates\nwith the standard discrete energy norm can be obtained by combining a priori\nand a posteriori error analysis techniques. We also show that the interior\nover-stabilization is advantageous for constructing preconditioners robust to\nmesh refinement by analyzing spectral equivalence of bilinear forms. Numerical\nresults are included to illustrate the convergence and preconditioning results.",
    "descriptor": "",
    "authors": [
      "Jeonghun J. Lee",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09969"
  },
  {
    "id": "arXiv:2208.09973",
    "title": "Development of a CAV-based Intersection Control System and Corridor  Level Impact Assessment",
    "abstract": "This paper presents a signal-free intersection control system for CAVs by\ncombination of a pixel reservation algorithm and a Deep Reinforcement Learning\n(DRL) decision-making logic, followed by a corridor-level impact assessment of\nthe proposed model. The pixel reservation algorithm detects potential colliding\nmaneuvers and the DRL logic optimizes vehicles' movements to avoid collision\nand minimize the overall delay at the intersection. The proposed control system\nis called Decentralized Sparse Coordination System (DSCLS) since each vehicle\nhas its own control logic and interacts with other vehicles in coordinated\nstates only. Due to the chain impact of taking random actions in the DRL's\ntraining course, the trained model can deal with unprecedented volume\nconditions, which poses the main challenge in intersection management. The\nperformance of the developed model is compared with conventional and CAV-based\ncontrol systems, including fixed traffic lights, actuated traffic lights, and\nthe Longest Queue First (LQF) control system under three volume regimes in a\ncorridor of four intersections in VISSIM software. The simulation result\nrevealed that the proposed model reduces delay by 50%, 29%, and 23% in\nmoderate, high, and extreme volume regimes compared to the other CAV-based\ncontrol system. Improvements in travel time, fuel consumption, emission, and\nSurrogate Safety Measures (SSM) are also noticeable.",
    "descriptor": "",
    "authors": [
      "Ardeshir Mirbakhsh",
      "Joyoung Lee",
      "Dejan Besenski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.09973"
  },
  {
    "id": "arXiv:2208.09975",
    "title": "ETHERLED: Sending Covert Morse Signals from Air-Gapped Devices via  Network Card (NIC) LEDs",
    "abstract": "Highly secure devices are often isolated from the Internet or other public\nnetworks due to the confidential information they process. This level of\nisolation is referred to as an 'air-gap .'\nIn this paper, we present a new technique named ETHERLED, allowing attackers\nto leak data from air-gapped networked devices such as PCs, printers, network\ncameras, embedded controllers, and servers. Networked devices have an\nintegrated network interface controller (NIC) that includes status and activity\nindicator LEDs. We show that malware installed on the device can control the\nstatus LEDs by blinking and alternating colors, using documented methods or\nundocumented firmware commands. Information can be encoded via simple encoding\nsuch as Morse code and modulated over these optical signals. An attacker can\nintercept and decode these signals from tens to hundreds of meters away. We\nshow an evaluation and discuss defensive and preventive countermeasures for\nthis exfiltration attack.",
    "descriptor": "",
    "authors": [
      "Mordechai Guri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09975"
  },
  {
    "id": "arXiv:2208.09979",
    "title": "Revisiting Item Promotion in GNN-based Collaborative Filtering: A Masked  Targeted Topological Attack Perspective",
    "abstract": "Graph neural networks (GNN) based collaborative filtering (CF) have attracted\nincreasing attention in e-commerce and social media platforms. However, there\nstill lack efforts to evaluate the robustness of such CF systems in deployment.\nFundamentally different from existing attacks, this work revisits the item\npromotion task and reformulates it from a targeted topological attack\nperspective for the first time. Specifically, we first develop a targeted\nattack formulation to maximally increase a target item's popularity. We then\nleverage gradient-based optimizations to find a solution. However, we observe\nthe gradient estimates often appear noisy due to the discrete nature of a\ngraph, which leads to a degradation of attack ability. To resolve noisy\ngradient effects, we then propose a masked attack objective that can remarkably\nenhance the topological attack ability. Furthermore, we design a\ncomputationally efficient approach to the proposed attack, thus making it\nfeasible to evaluate large-large CF systems. Experiments on two real-world\ndatasets show the effectiveness of our attack in analyzing the robustness of\nGNN-based CF more practically.",
    "descriptor": "",
    "authors": [
      "Yongwei Wang",
      "Yong Liu",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09979"
  },
  {
    "id": "arXiv:2208.09982",
    "title": "GRETEL: Graph Contrastive Topic Enhanced Language Model for Long  Document Extractive Summarization",
    "abstract": "Recently, neural topic models (NTMs) have been incorporated into pre-trained\nlanguage models (PLMs), to capture the global semantic information for text\nsummarization. However, in these methods, there remain limitations in the way\nthey capture and integrate the global semantic information. In this paper, we\npropose a novel model, the graph contrastive topic enhanced language model\n(GRETEL), that incorporates the graph contrastive topic model with the\npre-trained language model, to fully leverage both the global and local\ncontextual semantics for long document extractive summarization. To better\ncapture and incorporate the global semantic information into PLMs, the graph\ncontrastive topic model integrates the hierarchical transformer encoder and the\ngraph contrastive learning to fuse the semantic information from the global\ndocument context and the gold summary. To this end, GRETEL encourages the model\nto efficiently extract salient sentences that are topically related to the gold\nsummary, rather than redundant sentences that cover sub-optimal topics.\nExperimental results on both general domain and biomedical datasets demonstrate\nthat our proposed method outperforms SOTA methods.",
    "descriptor": "\nComments: Accepted by COLING2022\n",
    "authors": [
      "Qianqian Xie",
      "Jimin Huang",
      "Tulika Saha",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.09982"
  },
  {
    "id": "arXiv:2208.09983",
    "title": "Collaboration between parallel connected neural networks -- A possible  criterion for distinguishing artificial neural networks from natural organs",
    "abstract": "We find experimentally that when artificial neural networks are connected in\nparallel and trained together, they display the following properties. (i) When\nthe parallel-connected neural network (PNN) is optimized, each sub-network in\nthe connection is not optimized. (ii) The contribution of an inferior\nsub-network to the whole PNN can be on par with that of the superior\nsub-network. (iii) The PNN can output the correct result even when all\nsub-networks give incorrect results. These properties are unlikely for natural\nbiological sense organs. Therefore, they could serve as a simple yet effective\ncriterion for measuring the bionic level of neural networks. With this\ncriterion, we further show that when serving as the activation function, the\nReLU function can make an artificial neural network more bionic than the\nsigmoid and Tanh functions do.",
    "descriptor": "\nComments: 9 pages, 8 figures, 3 tables\n",
    "authors": [
      "Guang Ping He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.09983"
  },
  {
    "id": "arXiv:2208.09985",
    "title": "Scrooge: A Fast and Memory-Frugal Genomic Sequence Aligner for CPUs,  GPUs, and ASICs",
    "abstract": "Motivation: Pairwise sequence alignment is a very time-consuming step in\ncommon bioinformatics pipelines. Speeding up this step requires heuristics,\nefficient implementations and/or hardware acceleration. A promising candidate\nfor all of the above is the recently proposed GenASM algorithm. We identify and\naddress three inefficiencies in the GenASM algorithm: it has a high amount of\ndata movement, a large memory footprint, and does some unnecessary work.\nResults: We propose Scrooge, a fast and memory-frugal genomic sequence\naligner. Scrooge includes three novel algorithmic improvements which reduce the\ndata movement, memory footprint, and the number of operations in the GenASM\nalgorithm. We provide efficient open-source implementations of the Scrooge\nalgorithm for CPUs and GPUs, which demonstrate the significant benefits of our\nalgorithmic improvements. For long reads the CPU version of Scrooge achieves a\n15x, 1.7x, and 1.9x speedup over KSW2, Edlib, and a CPU implementation of\nGenASM, respectively. The GPU version of Scrooge achieves a 4.2x 63x, 7.4x, 11x\nand 5.9x speedup over the CPU version of Scrooge, KSW2, Edlib, Darwin-GPU, and\na GPU implementation of GenASM, respectively. We estimate an ASIC\nimplementation of Scrooge to use 3.6x less chip area and 2.1x less power than a\nGenASM ASIC while maintaining the same throughput. Further, we systematically\nanalyze the throughput and accuracy behavior of GenASM and Scrooge under a\nvariety of configurations. As the optimal configuration of Scrooge depends on\nthe computing platform, we make several observations that can help guide future\nimplementations of Scrooge.\nAvailability and implementation: https://github.com/CMU-SAFARI/Scrooge",
    "descriptor": "",
    "authors": [
      "Jo\u00ebl Lindegger",
      "Damla Senol Cali",
      "Mohammed Alser",
      "Juan G\u00f3mez-Luna",
      "Nika Mansouri Ghiasi",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2208.09985"
  },
  {
    "id": "arXiv:2208.09998",
    "title": "Antecedent Predictions Are Dominant for Tree-Based Code Generation",
    "abstract": "Code generation focuses on the automatic conversion of natural language (NL)\nutterances into code snippets. The sequence-to-tree (Seq2Tree) methods, e.g.,\nTRANX, are proposed for code generation, with the guarantee of the\ncompilability of the generated code, which generate the subsequent Abstract\nSyntax Tree (AST) node relying on antecedent predictions of AST nodes. Existing\nSeq2Tree methods tend to treat both antecedent predictions and subsequent\npredictions equally. However, under the AST constraints, it is difficult for\nSeq2Tree models to produce the correct subsequent prediction based on incorrect\nantecedent predictions. Thus, antecedent predictions ought to receive more\nattention than subsequent predictions. To this end, in this paper, we propose\nan effective method, named APTRANX (Antecedent Prioritized TRANX), on the basis\nof TRANX. APTRANX contains an Antecedent Prioritized (AP) Loss, which helps the\nmodel attach importance to antecedent predictions by exploiting the position\ninformation of the generated AST nodes. With better antecedent predictions and\naccompanying subsequent predictions, APTRANX significantly improves the\nperformance. We conduct extensive experiments on several benchmark datasets,\nand the experimental results demonstrate the superiority and generality of our\nproposed method compared with the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.09998"
  },
  {
    "id": "arXiv:2208.09999",
    "title": "PLMCL: Partial-Label Momentum Curriculum Learning for Multi-Label Image  Classification",
    "abstract": "Multi-label image classification aims to predict all possible labels in an\nimage. It is usually formulated as a partial-label learning problem, given the\nfact that it could be expensive in practice to annotate all labels in every\ntraining image. Existing works on partial-label learning focus on the case\nwhere each training image is annotated with only a subset of its labels. A\nspecial case is to annotate only one positive label in each training image. To\nfurther relieve the annotation burden and enhance the performance of the\nclassifier, this paper proposes a new partial-label setting in which only a\nsubset of the training images are labeled, each with only one positive label,\nwhile the rest of the training images remain unlabeled. To handle this new\nsetting, we propose an end-to-end deep network, PLMCL (Partial Label Momentum\nCurriculum Learning), that can learn to produce confident pseudo labels for\nboth partially-labeled and unlabeled training images. The novel momentum-based\nlaw updates soft pseudo labels on each training image with the consideration of\nthe updating velocity of pseudo labels, which help avoid trapping to\nlow-confidence local minimum, especially at the early stage of training in lack\nof both observed labels and confidence on pseudo labels. In addition, we\npresent a confidence-aware scheduler to adaptively perform easy-to-hard\nlearning for different labels. Extensive experiments demonstrate that our\nproposed PLMCL outperforms many state-of-the-art multi-label classification\nmethods under various partial-label settings on three different datasets.",
    "descriptor": "\nComments: Accepted in ECCVw\n",
    "authors": [
      "Rabab Abdelfattah",
      "Xin Zhang",
      "Zhenyao Wu",
      "Xinyi Wu",
      "Xiaofeng Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09999"
  },
  {
    "id": "arXiv:2208.10002",
    "title": "TransNet: Category-Level Transparent Object Pose Estimation",
    "abstract": "Transparent objects present multiple distinct challenges to visual perception\nsystems. First, their lack of distinguishing visual features makes transparent\nobjects harder to detect and localize than opaque objects. Even humans find\ncertain transparent surfaces with little specular reflection or refraction,\ne.g. glass doors, difficult to perceive. A second challenge is that common\ndepth sensors typically used for opaque object perception cannot obtain\naccurate depth measurements on transparent objects due to their unique\nreflective properties. Stemming from these challenges, we observe that\ntransparent object instances within the same category (e.g. cups) look more\nsimilar to each other than to ordinary opaque objects of that same category.\nGiven this observation, the present paper sets out to explore the possibility\nof category-level transparent object pose estimation rather than instance-level\npose estimation. We propose TransNet, a two-stage pipeline that learns to\nestimate category-level transparent object pose using localized depth\ncompletion and surface normal estimation. TransNet is evaluated in terms of\npose estimation accuracy on a recent, large-scale transparent object dataset\nand compared to a state-of-the-art category-level pose estimation approach.\nResults from this comparison demonstrate that TransNet achieves improved pose\nestimation accuracy on transparent objects and key findings from the included\nablation studies suggest future directions for performance improvements.",
    "descriptor": "",
    "authors": [
      "Huijie Zhang",
      "Anthony Opipari",
      "Xiaotong Chen",
      "Jiyue Zhu",
      "Zeren Yu",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10002"
  },
  {
    "id": "arXiv:2208.10003",
    "title": "Locally Defined Independence Systems on Graphs",
    "abstract": "The maximization for the independence systems defined on graphs is a\ngeneralization of combinatorial optimization problems such as the maximum\n$b$-matching, the unweighted MAX-SAT, the matchoid, and the maximum timed\nmatching problems. In this paper, we consider the problem under the local\noracle model to investigate the global approximability of the problem by using\nthe local approximability. We first analyze two simple algorithms FixedOrder\nand Greedy for the maximization under the model, which shows that they have no\nconstant approximation ratio. Here algorithms FixedOrder and Greedy apply local\noracles with fixed and greedy orders of vertices, respectively. We then propose\ntwo approximation algorithms for the $k$-degenerate graphs, whose approximation\nratios are $\\alpha +2k -2$ and $\\alpha k$, where $\\alpha$ is the approximation\nratio of local oracles. The second one can be generalized to the hypergraph\nsetting. We also propose an $(\\alpha + k)$-approximation algorithm for\nbipartite graphs, in which the local independence systems in the one-side of\nvertices are $k$-systems with independence oracles.",
    "descriptor": "",
    "authors": [
      "Yuki Amano"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.10003"
  },
  {
    "id": "arXiv:2208.10004",
    "title": "A diverse large-scale building dataset and a novel plug-and-play domain  generalization method for building extraction",
    "abstract": "In this paper, we introduce a new building dataset and propose a novel domain\ngeneralization method to facilitate the development of building extraction from\nhigh-resolution remote sensing images. The problem with the current building\ndatasets involves that they lack diversity, the quality of the labels is\nunsatisfactory, and they are hardly used to train a building extraction model\nwith good generalization ability, so as to properly evaluate the real\nperformance of a model in practical scenes. To address these issues, we built a\ndiverse, large-scale, and high-quality building dataset named the WHU-Mix\nbuilding dataset, which is more practice-oriented. The WHU-Mix building dataset\nconsists of a training/validation set containing 43,727 diverse images\ncollected from all over the world, and a test set containing 8402 images from\nfive other cities on five continents. In addition, to further improve the\ngeneralization ability of a building extraction model, we propose a domain\ngeneralization method named batch style mixing (BSM), which can be embedded as\nan efficient plug-and-play module in the frond-end of a building extraction\nmodel, providing the model with a progressively larger data distribution to\nlearn data-invariant knowledge. The experiments conducted in this study\nconfirmed the potential of the WHU-Mix building dataset to improve the\nperformance of a building extraction model, resulting in a 6-36% improvement in\nmIoU, compared to the other existing datasets. The adverse impact of the\ninaccurate labels in the other datasets can cause about 20% IoU decrease. The\nexperiments also confirmed the high performance of the proposed BSM module in\nenhancing the generalization ability and robustness of a model, exceeding the\nbaseline model without domain generalization by 13% and the recent domain\ngeneralization methods by 4-15% in mIoU.",
    "descriptor": "",
    "authors": [
      "Muying Luo",
      "Shunping Ji",
      "Shiqing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10004"
  },
  {
    "id": "arXiv:2208.10010",
    "title": "NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs",
    "abstract": "While Graph Neural Networks (GNNs) have demonstrated their efficacy in\ndealing with non-Euclidean structural data, they are difficult to be deployed\nin real applications due to the scalability constraint imposed by multi-hop\ndata dependency. Existing methods attempt to address this scalability issue by\ntraining multi-layer perceptrons (MLPs) exclusively on node content features\nusing labels derived from trained GNNs. Even though the performance of MLPs can\nbe significantly improved, two issues prevent MLPs from outperforming GNNs and\nbeing used in practice: the ignorance of graph structural information and the\nsensitivity to node feature noises. In this paper, we propose to learn\nNOise-robust Structure-aware MLPs On Graphs (NOSMOG) to overcome the\nchallenges. Specifically, we first complement node content with position\nfeatures to help MLPs capture graph structural information. We then design a\nnovel representational similarity distillation strategy to inject structural\nnode similarities into MLPs. Finally, we introduce the adversarial feature\naugmentation to ensure stable learning against feature noises and further\nimprove performance. Extensive experiments demonstrate that NOSMOG outperforms\nGNNs and the state-of-the-art method in both transductive and inductive\nsettings across seven datasets, while maintaining a competitive inference\nefficiency.",
    "descriptor": "",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Zhichun Guo",
      "Xiangliang Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10010"
  },
  {
    "id": "arXiv:2208.10011",
    "title": "A Two-phase On-line Joint Scheduling of Pricing and Control for Welfare  Maximization of Charging Station",
    "abstract": "The large adoption of EVs brings practical interest to the operation\noptimization of the charging station. The joint scheduling of pricing and\ncharging control will achieve a win-win situation both for the charging station\nand EV drivers, thus enhancing the operational capability of the station. We\nconsider this important problem in this paper and make the following\ncontributions. First, a joint scheduling model of pricing and charging control\nis developed to maximize the expected social welfare of the charging station\nconsidering the Quality of Service and the price fluctuation sensitivity of EV\ndrivers. It is formulated as a Markov decision process with variance criterion\nto capture uncertainties during operation. Second, a two-phase on-line policy\nlearning algorithm is proposed to solve this joint scheduling problem. In the\nfirst phase, it implements event-based policy iteration to find the optimal\npricing scheme, while in the second phase, it implements scenario-based model\npredictive control for smart charging under the updated pricing scheme. Third,\nby leveraging the performance difference theory, the optimality of the proposed\nalgorithm is theoretically analyzed. Numerical experiments for a charging\nstation with distributed generation and hydrogen energy storage demonstrate the\neffectiveness of the proposed method and the improved social warfare of the\ncharging station.",
    "descriptor": "",
    "authors": [
      "Qilong Huang",
      "Qing-Shan Jia",
      "Li Yang",
      "Xiang Wu",
      "Xiaohong Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10011"
  },
  {
    "id": "arXiv:2208.10013",
    "title": "FairDisCo: Fairer AI in Dermatology via Disentanglement Contrastive  Learning",
    "abstract": "Deep learning models have achieved great success in automating skin lesion\ndiagnosis. However, the ethnic disparity in these models' predictions, where\nlesions on darker skin types are usually underrepresented and have lower\ndiagnosis accuracy, receives little attention. In this paper, we propose\nFairDisCo, a disentanglement deep learning framework with contrastive learning\nthat utilizes an additional network branch to remove sensitive attributes, i.e.\nskin-type information from representations for fairness and another contrastive\nbranch to enhance feature extraction. We compare FairDisCo to three fairness\nmethods, namely, resampling, reweighting, and attribute-aware, on two newly\nreleased skin lesion datasets with different skin types: Fitzpatrick17k and\nDiverse Dermatology Images (DDI). We adapt two fairness-based metrics DPM and\nEOM for our multiple classes and sensitive attributes task, highlighting the\nskin-type bias in skin lesion classification. Extensive experimental evaluation\ndemonstrates the effectiveness of FairDisCo, with fairer and superior\nperformance on skin lesion classification tasks.",
    "descriptor": "\nComments: 14 pages, 3 figures, accepted by European Conference on Computer Vision (ECCV) ISIC Workshops, 2022\n",
    "authors": [
      "Siyi Du",
      "Ben Hers",
      "Nourhan Bayasi",
      "Ghassan Hamarneh",
      "Rafeef Garbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10013"
  },
  {
    "id": "arXiv:2208.10022",
    "title": "Generalized Relative Neighborhood Graph (GRNG) for Similarity Search",
    "abstract": "Similarity search is a fundamental building block for information retrieval\non a variety of datasets. The notion of a neighbor is often based on binary\nconsiderations, such as the k nearest neighbors. However, considering that data\nis often organized as a manifold with low intrinsic dimension, the notion of a\nneighbor must recognize higher-order relationship, to capture neighbors in all\ndirections. Proximity graphs, such as the Relative Neighbor Graphs (RNG), use\ntrinary relationships which capture the notion of direction and have been\nsuccessfully used in a number of applications. However, the current algorithms\nfor computing the RNG, despite widespread use, are approximate and not\nscalable. This paper proposes a novel type of graph, the Generalized Relative\nNeighborhood Graph (GRNG) for use in a pivot layer that then guides the\nefficient and exact construction of the RNG of a set of exemplars. It also\nshows how to extend this to a multi-layer hierarchy which significantly\nimproves over the state-of-the-art methods which can only construct an\napproximate RNG.",
    "descriptor": "",
    "authors": [
      "Cole Foster",
      "Berk Sevilmis",
      "Benjamin Kimia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.10022"
  },
  {
    "id": "arXiv:2208.10024",
    "title": "GCISG: Guided Causal Invariant Learning for Improved Syn-to-real  Generalization",
    "abstract": "Training a deep learning model with artificially generated data can be an\nalternative when training data are scarce, yet it suffers from poor\ngeneralization performance due to a large domain gap. In this paper, we\ncharacterize the domain gap by using a causal framework for data generation. We\nassume that the real and synthetic data have common content variables but\ndifferent style variables. Thus, a model trained on synthetic dataset might\nhave poor generalization as the model learns the nuisance style variables. To\nthat end, we propose causal invariance learning which encourages the model to\nlearn a style-invariant representation that enhances the syn-to-real\ngeneralization. Furthermore, we propose a simple yet effective feature\ndistillation method that prevents catastrophic forgetting of semantic knowledge\nof the real domain. In sum, we refer to our method as Guided Causal Invariant\nSyn-to-real Generalization that effectively improves the performance of\nsyn-to-real generalization. We empirically verify the validity of proposed\nmethods, and especially, our method achieves state-of-the-art on visual\nsyn-to-real domain generalization tasks such as image classification and\nsemantic segmentation.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Gilhyun Nam",
      "Gyeongjae Choi",
      "Kyungmin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10024"
  },
  {
    "id": "arXiv:2208.10025",
    "title": "Simple and Optimal Stochastic Gradient Methods for Nonsmooth Nonconvex  Optimization",
    "abstract": "We propose and analyze several stochastic gradient algorithms for finding\nstationary points or local minimum in nonconvex, possibly with nonsmooth\nregularizer, finite-sum and online optimization problems. First, we propose a\nsimple proximal stochastic gradient algorithm based on variance reduction\ncalled ProxSVRG+. We provide a clean and tight analysis of ProxSVRG+, which\nshows that it outperforms the deterministic proximal gradient descent (ProxGD)\nfor a wide range of minibatch sizes, hence solves an open problem proposed in\nReddi et al. (2016b). Also, ProxSVRG+ uses much less proximal oracle calls than\nProxSVRG (Reddi et al., 2016b) and extends to the online setting by avoiding\nfull gradient computations. Then, we further propose an optimal algorithm,\ncalled SSRGD, based on SARAH (Nguyen et al., 2017) and show that SSRGD further\nimproves the gradient complexity of ProxSVRG+ and achieves the optimal upper\nbound, matching the known lower bound of (Fang et al., 2018; Li et al., 2021).\nMoreover, we show that both ProxSVRG+ and SSRGD enjoy automatic adaptation with\nlocal structure of the objective function such as the Polyak-\\L{}ojasiewicz\n(PL) condition for nonconvex functions in the finite-sum case, i.e., we prove\nthat both of them can automatically switch to faster global linear convergence\nwithout any restart performed in prior work ProxSVRG (Reddi et al., 2016b).\nFinally, we focus on the more challenging problem of finding an $(\\epsilon,\n\\delta)$-local minimum instead of just finding an $\\epsilon$-approximate\n(first-order) stationary point (which may be some bad unstable saddle points).\nWe show that SSRGD can find an $(\\epsilon, \\delta)$-local minimum by simply\nadding some random perturbations. Our algorithm is almost as simple as its\ncounterpart for finding stationary points, and achieves similar optimal rates.",
    "descriptor": "\nComments: 60 pages. To appear in JMLR. arXiv admin note: text overlap with arXiv:1904.09265\n",
    "authors": [
      "Zhize Li",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.10025"
  },
  {
    "id": "arXiv:2208.10033",
    "title": "Evaluating and Crafting Datasets Effective for Deep Learning With Data  Maps",
    "abstract": "Rapid development in deep learning model construction has prompted an\nincreased need for appropriate training data. The popularity of large datasets\n- sometimes known as \"big data\" - has diverted attention from assessing their\nquality. Training on large datasets often requires excessive system resources\nand an infeasible amount of time. Furthermore, the supervised machine learning\nprocess has yet to be fully automated: for supervised learning, large datasets\nrequire more time for manually labeling samples. We propose a method of\ncurating smaller datasets with comparable out-of-distribution model accuracy\nafter an initial training session using an appropriate distribution of samples\nclassified by how difficult it is for a model to learn from them.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Jay Bishnu",
      "Andrew Gondoputro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10033"
  },
  {
    "id": "arXiv:2208.10035",
    "title": "A Simple Baseline for Multi-Camera 3D Object Detection",
    "abstract": "3D object detection with surrounding cameras has been a promising direction\nfor autonomous driving. In this paper, we present SimMOD, a Simple baseline for\nMulti-camera Object Detection, to solve the problem. To incorporate multi-view\ninformation as well as build upon previous efforts on monocular 3D object\ndetection, the framework is built on sample-wise object proposals and designed\nto work in a two-stage manner. First, we extract multi-scale features and\ngenerate the perspective object proposals on each monocular image. Second, the\nmulti-view proposals are aggregated and then iteratively refined with\nmulti-view and multi-scale visual features in the DETR3D-style. The refined\nproposals are end-to-end decoded into the detection results. To further boost\nthe performance, we incorporate the auxiliary branches alongside the proposal\ngeneration to enhance the feature learning. Also, we design the methods of\ntarget filtering and teacher forcing to promote the consistency of two-stage\ntraining. We conduct extensive experiments on the 3D object detection benchmark\nof nuScenes to demonstrate the effectiveness of SimMOD and achieve new\nstate-of-the-art performance. Code will be available at\nhttps://github.com/zhangyp15/SimMOD.",
    "descriptor": "",
    "authors": [
      "Yunpeng Zhang",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Guan Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10035"
  },
  {
    "id": "arXiv:2208.10039",
    "title": "Towards Unifying Resilience and Sustainability for Transportation  Infrastructure Systems: Conceptual Framework, Critical Indicators, and  Research Needs",
    "abstract": "Sustainability aspects of transportation infrastructure systems primarily\nfocus on system performance based on environmental, social, and economic\nimpacts. In contrast, resilience aspects demonstrate the ability to withstand\nexternal shocks i.e. robustness as well as to recover from the loss of\nfunctionality due to such disruptions i.e. rapidity. Therefore, sustainability\nand resilience are two key aspects which should be given adequate attention\nduring the planning, design, construction, operations, and maintenance phases\nof any civil infrastructure system. As both concepts are equally important to\nsustain an infrastructure for a longer duration, their concurrent assessments\nwithin a unified framework are highly desirable. While there has been a recent\nfocus towards solving this dilemma, review of existing studies revealed the\nlack of such unifying frameworks that can quantify sustainability and\nresilience indicators to simultaneously assess system performance. Moreover, a\nsingle decision or performance indicator could reinforce one and undermine\nanother. As such, this study proposed a forward-looking unification framework,\nwhere the sustainability and resilience of transportation infrastructure\nsystems can be analyzed simultaneously. In this regard, the proposed unifying\nframework is explained using seven critical indicators including emission,\nspeed, temperature, energy consumption, delay, mobility, and accessibility.\nThis study also investigates the interdependencies, relationships, and\ntradeoffs between sustainability and resilience based on these indices. While\nsome indices would help the system to attain both at the same time, they are\ncompromised in some cases. Finally, the study identifies immediate research\nneeds as well as the ones in the long-term.",
    "descriptor": "\nComments: 01 tables + 11 figures + 5671 words\n",
    "authors": [
      "H M Imran Kays",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10039"
  },
  {
    "id": "arXiv:2208.10041",
    "title": "Mission Apollo: Landing Optical Circuit Switching at Datacenter Scale",
    "abstract": "In this paper, we describe Apollo, to the best of our knowledge, the world's\nfirst large-scale production deployment of optical circuit switches (OCSes) for\ndatacenter networking. We will first describe the infrastructure challenges and\nuse cases that motivated optical switching inside datacenters. We then delve\ninto the requirements of OCSes for datacenter applications: balancing cost,\nport count, switching time, and optical performance, which drive design choices\nand implementation details of our internally developed 3D MEMS-based OCS. To\nenable the Apollo optical switching layer, we employ circulators to realize\nbidirectional links through the OCS, effectively doubling the OCS radix. The\nOCS and circulator design choices were critical for meeting network bandwidth,\nscale, and cost targets. We review the critical co-design of WDM transceiver\ntechnology for these OCS plus circulator-based bidirectional links and their\ncorresponding physical impairments, delivered over four generations/speeds of\noptical interconnect. Finally, we conclude with thoughts on future directions\nin hardware development and associated applications.",
    "descriptor": "\nComments: 13 pages, 14 figures\n",
    "authors": [
      "Ryohei Urata",
      "Hong Liu",
      "Kevin Yasumura",
      "Erji Mao",
      "Jill Berger",
      "Xiang Zhou",
      "Cedric Lam",
      "Roy Bannon",
      "Darren Hutchinson",
      "Daniel Nelson",
      "Leon Poutievski",
      "Arjun Singh",
      "Joon Ong",
      "Amin Vahdat"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.10041"
  },
  {
    "id": "arXiv:2208.10043",
    "title": "Towards Calibrated Hyper-Sphere Representation via Distribution Overlap  Coefficient for Long-tailed Learning",
    "abstract": "Long-tailed learning aims to tackle the crucial challenge that head classes\ndominate the training procedure under severe class imbalance in real-world\nscenarios. However, little attention has been given to how to quantify the\ndominance severity of head classes in the representation space. Motivated by\nthis, we generalize the cosine-based classifiers to a von Mises-Fisher (vMF)\nmixture model, denoted as vMF classifier, which enables to quantitatively\nmeasure representation quality upon the hyper-sphere space via calculating\ndistribution overlap coefficient. To our knowledge, this is the first work to\nmeasure representation quality of classifiers and features from the perspective\nof distribution overlap coefficient. On top of it, we formulate the inter-class\ndiscrepancy and class-feature consistency loss terms to alleviate the\ninterference among the classifier weights and align features with classifier\nweights. Furthermore, a novel post-training calibration algorithm is devised to\nzero-costly boost the performance via inter-class overlap coefficients. Our\nmethod outperforms previous work with a large margin and achieves\nstate-of-the-art performance on long-tailed image classification, semantic\nsegmentation, and instance segmentation tasks (e.g., we achieve 55.0\\% overall\naccuracy with ResNetXt-50 in ImageNet-LT). Our code is available at\nhttps://github.com/VipaiLab/vMF\\_OP.",
    "descriptor": "",
    "authors": [
      "Hualiang Wang",
      "Siming Fu",
      "Xiaoxuan He",
      "Hangxiang Fang",
      "Zuozhu Liu",
      "Haoji Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10043"
  },
  {
    "id": "arXiv:2208.10044",
    "title": "Multilayer deep feature extraction for visual texture recognition",
    "abstract": "Convolutional neural networks have shown successful results in image\nclassification achieving real-time results superior to the human level.\nHowever, texture images still pose some challenge to these models due, for\nexample, to the limited availability of data for training in several problems\nwhere these images appear, high inter-class similarity, the absence of a global\nviewpoint of the object represented, and others. In this context, the present\npaper is focused on improving the accuracy of convolutional neural networks in\ntexture classification. This is done by extracting features from multiple\nconvolutional layers of a pretrained neural network and aggregating such\nfeatures using Fisher vector. The reason for using features from earlier\nconvolutional layers is obtaining information that is less domain specific. We\nverify the effectiveness of our method on texture classification of benchmark\ndatasets, as well as on a practical task of Brazilian plant species\nidentification. In both scenarios, Fisher vectors calculated on multiple layers\noutperform state-of-art methods, confirming that early convolutional layers\nprovide important information about the texture image for classification.",
    "descriptor": "",
    "authors": [
      "Lucas O. Lyra",
      "Antonio Elias Fabris",
      "Joao B. Florindo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10044"
  },
  {
    "id": "arXiv:2208.10046",
    "title": "Reference-Limited Compositional Zero-Shot Learning",
    "abstract": "Compositional zero-shot learning (CZSL) refers to recognizing unseen\ncompositions of known visual primitives, which is an essential ability for\nartificial intelligence systems to learn and understand the world. While\nconsiderable progress has been made on existing benchmarks, we suspect whether\npopular CZSL methods can address the challenges of few-shot and few referential\ncompositions, which is common when learning in real-world unseen environments.\nTo this end, we study the challenging reference-limited compositional zero-shot\nlearning (RL-CZSL) problem in this paper, i.e. , given limited seen\ncompositions that contain only a few samples as reference, unseen compositions\nof observed primitives should be identified. We propose a novel Meta\nCompositional Graph Learner (MetaCGL) that can efficiently learn the\ncompositionality from insufficient referential information and generalize to\nunseen compositions. Besides, we build a benchmark with two new large-scale\ndatasets that consist of natural images with diverse compositional labels,\nproviding more realistic environments for RL-CZSL. Extensive experiments in the\nbenchmarks show that our method achieves state-of-the-art performance in\nrecognizing unseen compositions when reference is limited for compositional\nlearning.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Siteng Huang",
      "Qiyao Wei",
      "Donglin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10046"
  },
  {
    "id": "arXiv:2208.10049",
    "title": "Quantifying Community Evolution in Developer Social Networks: Proof of  Indices' Properties",
    "abstract": "The document provides the proof to properties of community evolution indices\nincluding community split and shrink in paper: Liang Wang, Ying Li, Jierui\nZhang, and Xianping Tao. 2022. Quantifying Community Evolution in Developer\nSocial Networks. In Proceedings of the30th ACM Joint European Software\nEngineering Conference and Symposiumon the Foundations of Software Engineering\n(ESEC/FSE 22), November 14 - 18, 2022, Singapore, Singapore. ACM, New York, NY,\nUSA, 12 pages. Proof to properties of community merge and expand is similar.",
    "descriptor": "",
    "authors": [
      "Liang Wang",
      "Ying Li",
      "Jierui Zhang",
      "Xianping Tao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.10049"
  },
  {
    "id": "arXiv:2208.10051",
    "title": "Observer-based Leader-following Consensus for Positive Multi-agent  Systems Over Time-varying Graphs",
    "abstract": "This paper is devoted to the leader-following consensus problem for a\ncollection of discrete-time positive linear systems. In this problem, the state\nvariables of all agents are confined in the positive orthant and we aim at\ndistributed rules for the followers to track a reference signal generated by a\npositive leader. To tackle such a problem, we first propose a novel distributed\npositive observer of the positive leader over time-varying communication\ntopologies. Then, we construct both state feedback and output feedback rules\nfor these followers combing the developed distributed positive observers to\nsolve the formulated leader-following positive consensus problem. We also\nprovide a simulation example to illustrate the effectiveness of our design.",
    "descriptor": "",
    "authors": [
      "Ruonan Li",
      "Yichen Zhang",
      "Yutao Tang",
      "Shurong Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.10051"
  },
  {
    "id": "arXiv:2208.10053",
    "title": "Robust Bayesian Nonnegative Matrix Factorization with Implicit  Regularizers",
    "abstract": "We introduce a probabilistic model with implicit norm regularization for\nlearning nonnegative matrix factorization (NMF) that is commonly used for\npredicting missing values and finding hidden patterns in the data, in which the\nmatrix factors are latent variables associated with each data dimension. The\nnonnegativity constraint for the latent factors is handled by choosing priors\nwith support on the nonnegative subspace, e.g., exponential density or\ndistribution based on exponential function. Bayesian inference procedure based\non Gibbs sampling is employed. We evaluate the model on several real-world\ndatasets including Genomics of Drug Sensitivity in Cancer (GDSC $IC_{50}$) and\nGene body methylation with different sizes and dimensions, and show that the\nproposed Bayesian NMF GL$_2^2$ and GL$_\\infty$ models lead to robust\npredictions for different data values and avoid overfitting compared with\ncompetitive Bayesian NMF approaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.11025\n",
    "authors": [
      "Jun Lu",
      "Christine P. Chai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10053"
  },
  {
    "id": "arXiv:2208.10056",
    "title": "Minkowski Tracker: A Sparse Spatio-Temporal R-CNN for Joint Object  Detection and Tracking",
    "abstract": "Recent research in multi-task learning reveals the benefit of solving related\nproblems in a single neural network. 3D object detection and multi-object\ntracking (MOT) are two heavily intertwined problems predicting and associating\nan object instance location across time. However, most previous works in 3D MOT\ntreat the detector as a preceding separated pipeline, disjointly taking the\noutput of the detector as an input to the tracker. In this work, we present\nMinkowski Tracker, a sparse spatio-temporal R-CNN that jointly solves object\ndetection and tracking. Inspired by region-based CNN (R-CNN), we propose to\nsolve tracking as a second stage of the object detector R-CNN that predicts\nassignment probability to tracks. First, Minkowski Tracker takes 4D point\nclouds as input to generate a spatio-temporal Bird's-eye-view (BEV) feature map\nthrough a 4D sparse convolutional encoder network. Then, our proposed\nTrackAlign aggregates the track region-of-interest (ROI) features from the BEV\nfeatures. Finally, Minkowski Tracker updates the track and its confidence score\nbased on the detection-to-track match probability predicted from the ROI\nfeatures. We show in large-scale experiments that the overall performance gain\nof our method is due to four factors: 1. The temporal reasoning of the 4D\nencoder improves the detection performance 2. The multi-task learning of object\ndetection and MOT jointly enhances each other 3. The detection-to-track match\nscore learns implicit motion model to enhance track assignment 4. The\ndetection-to-track match score improves the quality of the track confidence\nscore. As a result, Minkowski Tracker achieved the state-of-the-art performance\non Nuscenes dataset tracking task without hand-designed motion models.",
    "descriptor": "",
    "authors": [
      "JunYoung Gwak",
      "Silvio Savarese",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10056"
  },
  {
    "id": "arXiv:2208.10060",
    "title": "Abstraction-Free Control Synthesis to Satisfy Temporal Logic Constraints  under Sensor Faults and Attacks",
    "abstract": "We study the problem of synthesizing a controller to satisfy a complex task\nin the presence of sensor faults and attacks. We model the task using Gaussian\ndistribution temporal logic (GDTL), and propose a solution approach that does\nnot rely on computing any finite abstraction to model the system. We decompose\nthe GDTL specification into a sequence of reach-avoid sub-tasks. We develop a\nclass of fault-tolerant finite time convergence control barrier functions\n(CBFs) to guarantee that a dynamical system reaches a set within finite time\nalmost surely in the presence of malicious attacks. We use the fault-tolerant\nfinite time convergence CBFs to guarantee the satisfaction of `reach' property.\nWe ensure `avoid' part in each sub-task using fault-tolerant zeroing CBFs.\nThese fault-tolerant CBFs formulate a set of linear constraints on the control\ninput for each sub-task. We prove that if the error incurred by system state\nestimation is bounded by a certain threshold, then our synthesized controller\nfulfills each reach-avoid sub-task almost surely for any possible sensor fault\nand attack, and thus the GDTL specification is satisfied with probability one.\nWe demonstrate our proposed approach using a numerical study on the\ncoordination of two wheeled mobile robots.",
    "descriptor": "",
    "authors": [
      "Luyao Niu",
      "Zhouchi Li",
      "Andrew Clark"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10060"
  },
  {
    "id": "arXiv:2208.10061",
    "title": "Improving Knowledge-aware Recommendation with Multi-level Interactive  Contrastive Learning",
    "abstract": "Incorporating Knowledge Graphs (KG) into recommeder system has attracted\nconsiderable attention. Recently, the technical trend of Knowledge-aware\nRecommendation (KGR) is to develop end-to-end models based on graph neural\nnetworks (GNNs). However, the extremely sparse user-item interactions\nsignificantly degrade the performance of the GNN-based models, as: 1) the\nsparse interaction, means inadequate supervision signals and limits the\nsupervised GNN-based models; 2) the combination of sparse interactions (CF\npart) and redundant KG facts (KG part) results in an unbalanced information\nutilization. Besides, the GNN paradigm aggregates local neighbors for node\nrepresentation learning, while ignoring the non-local KG facts and making the\nknowledge extraction insufficient. Inspired by the recent success of\ncontrastive learning in mining supervised signals from data itself, in this\npaper, we focus on exploring contrastive learning in KGR and propose a novel\nmulti-level interactive contrastive learning mechanism. Different from\ntraditional contrastive learning methods which contrast nodes of two generated\ngraph views, interactive contrastive mechanism conducts layer-wise\nself-supervised learning by contrasting layers of different parts within\ngraphs, which is also an \"interaction\" action. Specifically, we first construct\nlocal and non-local graphs for user/item in KG, exploring more KG facts for\nKGR. Then an intra-graph level interactive contrastive learning is performed\nwithin each graph, which contrasts layers of the CF and KG parts, for more\nconsistent information leveraging. Besides, an inter-graph level interactive\ncontrastive learning is performed between the local and non-local graphs, for\nsufficiently and coherently extracting non-local KG signals. Extensive\nexperiments conducted on three benchmark datasets show the superior performance\nof our proposed method over the state-of-the-arts.",
    "descriptor": "\nComments: Accepted to CIKM 2022\n",
    "authors": [
      "Ding Zou",
      "Wei Wei",
      "Ziyang Wang",
      "Xian-Ling Mao",
      "Feida Zhu",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.10061"
  },
  {
    "id": "arXiv:2208.10063",
    "title": "Selection Collider Bias in Large Language Models",
    "abstract": "In this paper we motivate the causal mechanisms behind sample selection\ninduced collider bias (selection collider bias) that can cause Large Language\nModels (LLMs) to learn unconditional dependence between entities that are\nunconditionally independent in the real world. We show that selection collider\nbias can be amplified in underspecified learning tasks, and that the magnitude\nof the resulting spurious correlations appear scale agnostic. While selection\ncollider bias can be difficult to overcome, we describe a method to exploit the\nresulting spurious correlations for determination of when a model may be\nuncertain about its prediction, and demonstrate that it matches human\nuncertainty in tasks with gender pronoun underspecification on an extended\nversion of the Winogender Schemas evaluation set.",
    "descriptor": "\nComments: 10 pages, 16 figures, UAI 2022 Causal Representation Learning Workshop\n",
    "authors": [
      "Emily McMilin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10063"
  },
  {
    "id": "arXiv:2208.10068",
    "title": "Tree-structured Auxiliary Online Knowledge Distillation",
    "abstract": "Traditional knowledge distillation adopts a two-stage training process in\nwhich a teacher model is pre-trained and then transfers the knowledge to a\ncompact student model. To overcome the limitation, online knowledge\ndistillation is proposed to perform one-stage distillation when the teacher is\nunavailable. Recent researches on online knowledge distillation mainly focus on\nthe design of the distillation objective, including attention or gate\nmechanism. Instead, in this work, we focus on the design of the global\narchitecture and propose Tree-Structured Auxiliary online knowledge\ndistillation (TSA), which adds more parallel peers for layers close to the\noutput hierarchically to strengthen the effect of knowledge distillation.\nDifferent branches construct different views of the inputs, which can be the\nsource of the knowledge. The hierarchical structure implies that the knowledge\ntransfers from general to task-specific with the growth of the layers.\nExtensive experiments on 3 computer vision and 4 natural language processing\ndatasets show that our method achieves state-of-the-art performance without\nbells and whistles. To the best of our knowledge, we are the first to\ndemonstrate the effectiveness of online knowledge distillation for machine\ntranslation tasks.",
    "descriptor": "\nComments: Accepted by IJCNN2022\n",
    "authors": [
      "Wenye Lin",
      "Yangning Li",
      "Yifeng Ding",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.10068"
  },
  {
    "id": "arXiv:2208.10072",
    "title": "A Survey on Intelligent Computation Offloading and Pricing Strategy in  UAV-Enabled MEC Network: Challenges and Research Directions",
    "abstract": "The Mobile Network Operator (MNO) must select how to delegate Mobile Device\n(MD) queries to its Mobile Edge Computing (MEC) server in order to maximize the\noverall benefit of admitted requests with varying latency needs. Unmanned\nAerial Vehicles (UAVs) and Artificial Intelligent (AI) can increase MNO\nperformance because of their flexibility in deployment, high mobility of UAV,\nand efficiency of AI algorithms. There is a trade-off between the cost incurred\nby the MD and the profit received by the MNO. Intelligent computing offloading\nto UAV-enabled MEC, on the other hand, is a promising way to bridge the gap\nbetween MDs' limited processing resources, as well as the intelligent\nalgorithms that are utilized for computation offloading in the UAV-MEC network\nand the high computing demands of upcoming applications. This study looks at\nsome of the research on the benefits of computation offloading process in the\nUAV-MEC network, as well as the intelligent models that are utilized for\ncomputation offloading. In addition, this article examines several intelligent\npricing techniques in different structures in the UAV-MEC network. Finally,\nthis work highlights some important open research issues and future research\ndirections of Artificial Intelligent (AI) in computation offloading and\napplying intelligent pricing strategies in the UAV-MEC network.",
    "descriptor": "",
    "authors": [
      "Asrar Ahmed Baktayan",
      "Ibrahim Ahmed Al-Baltah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.10072"
  },
  {
    "id": "arXiv:2208.10073",
    "title": "Local Geometry of Nonconvex Spike Deconvolution from Low-Pass  Measurements",
    "abstract": "Spike deconvolution is the problem of recovering the point sources from their\nconvolution with a known point spread function, which plays a fundamental role\nin many sensing and imaging applications. In this paper, we investigate the\nlocal geometry of recovering the parameters of point\nsources$\\unicode{x2014}$including both amplitudes and\nlocations$\\unicode{x2014}$by minimizing a natural nonconvex least-squares loss\nfunction measuring the observation residuals. We propose preconditioned\nvariants of gradient descent (GD), where the search direction is scaled via\nsome carefully designed preconditioning matrices. We begin with a simple fixed\npreconditioner design, which adjusts the learning rates of the locations at a\ndifferent scale from those of the amplitudes, and show it achieves a linear\nrate of convergence$\\unicode{x2014}$in terms of entrywise\nerrors$\\unicode{x2014}$when initialized close to the ground truth, as long as\nthe separation between the true spikes is sufficiently large. However, the\nconvergence rate slows down significantly when the dynamic range of the source\namplitudes is large. To bridge this issue, we introduce an adaptive\npreconditioner design, which compensates for the learning rates of different\nsources in an iteration-varying manner based on the current estimate. The\nadaptive design provably leads to an accelerated convergence rate that is\nindependent of the dynamic range, highlighting the benefit of adaptive\npreconditioning in nonconvex spike deconvolution. Numerical experiments are\nprovided to corroborate the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Maxime Ferreira Da Costa",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10073"
  },
  {
    "id": "arXiv:2208.10077",
    "title": "Identifying Auxiliary or Adversarial Tasks Using Necessary Condition  Analysis for Adversarial Multi-task Video Understanding",
    "abstract": "There has been an increasing interest in multi-task learning for video\nunderstanding in recent years. In this work, we propose a generalized notion of\nmulti-task learning by incorporating both auxiliary tasks that the model should\nperform well on and adversarial tasks that the model should not perform well\non. We employ Necessary Condition Analysis (NCA) as a data-driven approach for\ndeciding what category these tasks should fall in. Our novel proposed\nframework, Adversarial Multi-Task Neural Networks (AMT), penalizes adversarial\ntasks, determined by NCA to be scene recognition in the Holistic Video\nUnderstanding (HVU) dataset, to improve action recognition. This upends the\ncommon assumption that the model should always be encouraged to do well on all\ntasks in multi-task learning. Simultaneously, AMT still retains all the\nbenefits of multi-task learning as a generalization of existing methods and\nuses object recognition as an auxiliary task to aid action recognition. We\nintroduce two challenging Scene-Invariant test splits of HVU, where the model\nis evaluated on action-scene co-occurrences not encountered in training. We\nshow that our approach improves accuracy by ~3% and encourages the model to\nattend to action features instead of correlation-biasing scene features.",
    "descriptor": "",
    "authors": [
      "Stephen Su",
      "Samuel Kwong",
      "Qingyu Zhao",
      "De-An Huang",
      "Juan Carlos Niebles",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10077"
  },
  {
    "id": "arXiv:2208.10078",
    "title": "A Filon-Clenshaw-Curtis-Smolyak rule for multi-dimensional oscillatory  integrals with application to a UQ problem for the Helmholtz equation",
    "abstract": "In this paper, we combine the Smolyak technique for multi-dimensional\ninterpolation with the Filon-Clenshaw-Curtis (FCC) rule for one-dimensional\noscillatory integration, to obtain a new Filon-Clenshaw-Curtis-Smolyak (FCCS)\nrule for oscillatory integrals with linear phase over the $d-$dimensional cube\n$[-1,1]^d$. By combining stability and convergence estimates for the FCC rule\nwith error estimates for the Smolyak interpolation operator, we obtain an error\nestimate for the FCCS rule, consisting of the product of a Smolyak-type error\nestimate multiplied by a term that decreases with\n$\\mathcal{O}(k^{-\\tilde{d}})$, where $k$ is the wavenumber and $\\tilde{d}$ is\nthe number of oscillatory dimensions. If all dimensions are oscillatory, a\nhigher negative power of $k$ appears in the estimate. As an application, we\nconsider the forward problem of uncertainty quantification (UQ) for a\none-space-dimensional Helmholtz problem with wavenumber $k$ and a random\nheterogeneous refractive index, depending in an affine way on $d$ i.i.d.\nuniform random variables. After applying a classical hybrid\nnumerical-asymptotic approximation, expectations of functionals of the solution\nof this problem can be formulated as a sum of oscillatory integrals over\n$[-1,1]^d$, which we compute using the FCCS rule. We give numerical results for\nthe FCCS rule and the UQ algorithm showing that accuracy improves when both $k$\nand the order of the rule increase. We also give results for dimension-adaptive\nsparse grid FCCS quadrature showing its efficiency as dimension increases.",
    "descriptor": "",
    "authors": [
      "Zhizhang Wu",
      "Ivan G. Graham",
      "Dingjiong Ma",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10078"
  },
  {
    "id": "arXiv:2208.10081",
    "title": "Type-enriched Hierarchical Contrastive Strategy for Fine-Grained Entity  Typing",
    "abstract": "Fine-grained entity typing (FET) aims to deduce specific semantic types of\nthe entity mentions in text. Modern methods for FET mainly focus on learning\nwhat a certain type looks like. And few works directly model the type\ndifferences, that is, let models know the extent that one type is different\nfrom others. To alleviate this problem, we propose a type-enriched hierarchical\ncontrastive strategy for FET. Our method can directly model the differences\nbetween hierarchical types and improve the ability to distinguish multi-grained\nsimilar types. On the one hand, we embed type into entity contexts to make type\ninformation directly perceptible. On the other hand, we design a constrained\ncontrastive strategy on the hierarchical structure to directly model the type\ndifferences, which can simultaneously perceive the distinguishability between\ntypes at different granularity. Experimental results on three benchmarks, BBN,\nOntoNotes, and FIGER show that our method achieves significant performance on\nFET by effectively modeling type differences.",
    "descriptor": "\nComments: Accepted by COLING2022, Long paper, 13 pages, 6 figures\n",
    "authors": [
      "Xinyu Zuo",
      "Haijin Liang",
      "Ning Jing",
      "Shuang Zeng",
      "Zhou Fang",
      "Yu Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10081"
  },
  {
    "id": "arXiv:2208.10083",
    "title": "MetaRF: Differentiable Random Forest for Reaction Yield Prediction with  a Few Trails",
    "abstract": "Artificial intelligence has deeply revolutionized the field of medicinal\nchemistry with many impressive applications, but the success of these\napplications requires a massive amount of training samples with high-quality\nannotations, which seriously limits the wide usage of data-driven methods. In\nthis paper, we focus on the reaction yield prediction problem, which assists\nchemists in selecting high-yield reactions in a new chemical space only with a\nfew experimental trials. To attack this challenge, we first put forth MetaRF,\nan attention-based differentiable random forest model specially designed for\nthe few-shot yield prediction, where the attention weight of a random forest is\nautomatically optimized by the meta-learning framework and can be quickly\nadapted to predict the performance of new reagents while given a few additional\nsamples. To improve the few-shot learning performance, we further introduce a\ndimension-reduction based sampling method to determine valuable samples to be\nexperimentally tested and then learned. Our methodology is evaluated on three\ndifferent datasets and acquires satisfactory performance on few-shot\nprediction. In high-throughput experimentation (HTE) datasets, the average\nyield of our methodology's top 10 high-yield reactions is relatively close to\nthe results of ideal yield selection.",
    "descriptor": "",
    "authors": [
      "Kexin Chen",
      "Guangyong Chen",
      "Junyou Li",
      "Yuansheng Huang",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.10083"
  },
  {
    "id": "arXiv:2208.10087",
    "title": "A Trust Framework for Government Use of Artificial Intelligence and  Automated Decision Making",
    "abstract": "This paper identifies the current challenges of the mechanisation,\ndigitisation and automation of public sector systems and processes, and\nproposes a modern and practical framework to ensure and assure ethical and high\nveracity Artificial Intelligence (AI) or Automated Decision Making (ADM)\nsystems in public institutions. This framework is designed for the specific\ncontext of the public sector, in the jurisdictional and constitutional context\nof Australia, but is extendable to other jurisdictions and private sectors. The\ngoals of the framework are to: 1) earn public trust and grow public confidence\nin government systems; 2) to ensure the unique responsibilities and\naccountabilities (including to the public) of public institutions under\nAdministrative Law are met effectively; and 3) to assure a positive human,\nsocietal and ethical impact from the adoption of such systems. The framework\ncould be extended to assure positive environmental or other impacts, but this\npaper focuses on human/societal outcomes and public trust. This paper is meant\nto complement principles-based frameworks like Australia's Artificial\nIntelligence Ethics Framework and the EU Assessment List for Trustworthy AI. In\nmany countries, COVID created a bubble of improved trust, a bubble which has\narguably already popped, and in an era of unprecedented mistrust of public\ninstitutions (but even in times of high trust) it is not enough that a service\nis faster, or more cost-effective. This paper proposes recommendations for\ngovernment systems (technology platforms, operations, culture, governance,\nengagement, etc.) that would help to improve public confidence and trust in\npublic institutions, policies and services, whilst meeting the special\nobligations and responsibilities of the public sector.",
    "descriptor": "\nComments: Comments were integrated into the paper from all peer reviewers. Am happy to provide a copied history of comments if useful\n",
    "authors": [
      "Pia Andrews",
      "Tim de Sousa",
      "Bruce Haefele",
      "Matt Beard",
      "Marcus Wigan",
      "Abhinav Palia",
      "Kathy Reid",
      "Saket Narayan",
      "Morgan Dumitru",
      "Alex Morrison",
      "Geoff Mason",
      "Aurelie Jacquet"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.10087"
  },
  {
    "id": "arXiv:2208.10091",
    "title": "Incorporating Domain Knowledge through Task Augmentation for Front-End  JavaScript Code Generation",
    "abstract": "Code generation aims to generate a code snippet automatically from natural\nlanguage descriptions. Generally, the mainstream code generation methods rely\non a large amount of paired training data, including both the natural language\ndescription and the code. However, in some domain-specific scenarios, building\nsuch a large paired corpus for code generation is difficult because there is no\ndirectly available pairing data, and a lot of effort is required to manually\nwrite the code descriptions to construct a high-quality training dataset. Due\nto the limited training data, the generation model cannot be well trained and\nis likely to be overfitting, making the model's performance unsatisfactory for\nreal-world use. To this end, in this paper, we propose a task augmentation\nmethod that incorporates domain knowledge into code generation models through\nauxiliary tasks and a Subtoken-TranX model by extending the original TranX\nmodel to support subtoken-level code generation. To verify our proposed\napproach, we collect a real-world code generation dataset and conduct\nexperiments on it. Our experimental results demonstrate that the subtoken-level\nTranX model outperforms the original TranX model and the Transformer model on\nour dataset, and the exact match accuracy of Subtoken-TranX improves\nsignificantly by 12.75\\% with the help of our task augmentation method. The\nmodel performance on several code categories has satisfied the requirements for\napplication in industrial systems. Our proposed approach has been adopted by\nAlibaba's \\emph{BizCook} platform. To the best of our knowledge, this is the\nfirst domain code generation system adopted in industrial development\nenvironments.",
    "descriptor": "",
    "authors": [
      "Sijie Shen",
      "Xiang Zhu",
      "Yihong Dong",
      "Qizhi Guo",
      "Yankun Zhen",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10091"
  },
  {
    "id": "arXiv:2208.10095",
    "title": "Socially Fair Center-based and Linear Subspace Clustering",
    "abstract": "Center-based clustering (e.g., $k$-means, $k$-medians) and clustering using\nlinear subspaces are two most popular techniques to partition real-world data\ninto smaller clusters. However, when the data consists of sensitive demographic\ngroups, significantly different clustering cost per point for different\nsensitive groups can lead to fairness-related harms (e.g., different\nquality-of-service). The goal of socially fair clustering is to minimize the\nmaximum cost of clustering per point over all groups. In this work, we propose\na unified framework to solve socially fair center-based clustering and linear\nsubspace clustering, and give practical, efficient approximation algorithms for\nthese problems. We do extensive experiments to show that on multiple benchmark\ndatasets our algorithms either closely match or outperform state-of-the-art\nbaselines.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Sruthi Gorantla",
      "Kishen N. Gowda",
      "Amit Deshpande",
      "Anand Louis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.10095"
  },
  {
    "id": "arXiv:2208.10099",
    "title": "Recent Advances in Text-to-SQL: A Survey of What We Have and What We  Expect",
    "abstract": "Text-to-SQL has attracted attention from both the natural language processing\nand database communities because of its ability to convert the semantics in\nnatural language into SQL queries and its practical application in building\nnatural language interfaces to database systems. The major challenges in\ntext-to-SQL lie in encoding the meaning of natural utterances, decoding to SQL\nqueries, and translating the semantics between these two forms. These\nchallenges have been addressed to different extents by the recent advances.\nHowever, there is still a lack of comprehensive surveys for this task. To this\nend, we review recent progress on text-to-SQL for datasets, methods, and\nevaluation and provide this systematic survey, addressing the aforementioned\nchallenges and discussing potential future directions. We hope that this survey\ncan serve as quick access to existing work and motivate future research.",
    "descriptor": "\nComments: COLING 2022 oral. Github page: this https URL\n",
    "authors": [
      "Naihao Deng",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10099"
  },
  {
    "id": "arXiv:2208.10100",
    "title": "Lirot.ai: A Novel Platform for Crowd-Sourcing Retinal Image  Segmentations",
    "abstract": "Introduction: For supervised deep learning (DL) tasks, researchers need a\nlarge annotated dataset. In medical data science, one of the major limitations\nto develop DL models is the lack of annotated examples in large quantity. This\nis most often due to the time and expertise required to annotate. We introduce\nLirot.ai, a novel platform for facilitating and crowd-sourcing image\nsegmentations. Methods: Lirot.ai is composed of three components; an iPadOS\nclient application named Lirot.ai-app, a backend server named Lirot.ai-server\nand a python API name Lirot.ai-API. Lirot.ai-app was developed in Swift 5.6 and\nLirot.ai-server is a firebase backend. Lirot.ai-API allows the management of\nthe database. Lirot.ai-app can be installed on as many iPadOS devices as needed\nso that annotators may be able to perform their segmentation simultaneously and\nremotely. We incorporate Apple Pencil compatibility, making the segmentation\nfaster, more accurate, and more intuitive for the expert than any other\ncomputer-based alternative. Results: We demonstrate the usage of Lirot.ai for\nthe creation of a retinal fundus dataset with reference vasculature\nsegmentations. Discussion and future work: We will use active learning\nstrategies to continue enlarging our retinal fundus dataset by including a more\nefficient process to select the images to be annotated and distribute them to\nannotators.",
    "descriptor": "",
    "authors": [
      "Jonathan Fhima",
      "Jan Van Eijgen",
      "Moti Freiman",
      "Ingeborg Stalmans",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10100"
  },
  {
    "id": "arXiv:2208.10103",
    "title": "Model-Based Insights on the Performance, Fairness, and Stability of BBR",
    "abstract": "Google's BBR is the most prominent result of the recently revived quest for\nefficient, fair, and flexible congestion-control algorithms (CCAs). While the\nperformance of BBR has been investigated by numerous studies, previous work\nstill leaves gaps in the understanding of BBR performance: Experiment-based\nstudies generally only consider network settings that researchers can set up\nwith manageable effort, and model-based studies neglect important issues like\nconvergence.\nTo complement previous BBR analyses, this paper presents a fluid model of\nBBRv1 and BBRv2, allowing both efficient simulation under a wide variety of\nnetwork settings and analytical treatment such as stability analysis. By\nexperimental validation, we show that our fluid model provides highly accurate\npredictions of BBR behavior. Through extensive simulations and theoretical\nanalysis, we arrive at several insights into both BBR versions, including a\npreviously unknown bufferbloat issue in BBRv2.",
    "descriptor": "\nComments: Accepted at the ACM Internet Measurement Conference 2021 (IMC'21)\n",
    "authors": [
      "Simon Scherrer",
      "Markus Legner",
      "Adrian Perrig",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.10103"
  },
  {
    "id": "arXiv:2208.10110",
    "title": "Improved constructions of permutation and multi-permutation codes  correcting a burst of stable deletions",
    "abstract": "Permutation codes and multi-permutation codes have been widely considered due\nto their various applications, especially in flash memory. In this paper, we\nconsider permutation codes and multi-permutation codes against a burst of\nstable deletions. In particular, we propose a construction of permutation codes\ncorrecting a burst stable deletion of length $s$, with redundancy $\\log n + 2\n\\log \\log n + O(1)$. Compared to the previous known results, our improvement\nrelies on a different strategy to retrieve the missing symbol on the first row\nof the array representation of a permutation. We also generalize our\nconstructions for multi-permutations and the variable length burst model.",
    "descriptor": "",
    "authors": [
      "Yubo Sun",
      "Yiwei Zhang",
      "Gennian Ge"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10110"
  },
  {
    "id": "arXiv:2208.10120",
    "title": "A Survey of Distributed Ledger Technology for IoT Verticals",
    "abstract": "The Internet of Things (IoT) and Distributed ledger technology (DLT) have\nsignificantly changed our daily lives. Due to their distributed operational\nenvironment and naturally decentralized applications, the convergence of these\ntwo technologies indicates a more lavish arrangement for the future. This\narticle develops a comprehensive survey to investigate and illustrate\nstate-of-the-art DLT for various IoT use cases, from smart homes to autonomous\nvehicles and smart cities. We develop a novel framework for conducting a\nsystematic and comprehensive review of DLT over IoT by extending the knowledge\ngraph approach. With relevant insights from this review, we extract innovative\nand pragmatic techniques to DLT design that enable high-performance,\nsustainable, and highly scalable IoT systems. Our findings support designing an\nend-to-end IoT-native DLT architecture for the future that fully coordinates\nnetwork-assisted functionalities.",
    "descriptor": "\nComments: Preprint submitted to ACM Computing Surveys\n",
    "authors": [
      "Rongxin Xu",
      "Qiujun Lan",
      "Shiva Raj Pokhrel",
      "Gang Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.10120"
  },
  {
    "id": "arXiv:2208.10121",
    "title": "Reachability Games and Parity Games",
    "abstract": "Parity games are positionally determined. This is a fundamental and classical\nresult. In 2010, Calude et al. showed a breakthrough result for finite parity\ngames: the winning regions and their positional winning strategies can be\ncomputed in quasi-polynomial time.\nIn the present paper we give a self-contained and detailed proofs for both\nresults. The results in this paper are not meant to be original. The positional\ndeterminacy result is shown for possibly infinite parity games using the ideas\nof Zielonka which he published in 1998. In order to show quasi-polynomial time,\nwe follow Lehtinen's register games, which she introduced in 2018. Although the\ntime complexity of Lehtinen's algorithm is not optimal, register games are\nconceptually simple and interesting in their own right. Various of our proofs\nare either new or simplifications of the original proofs. The topics in this\npaper include the definition and the computation of optimal attractors for\nreachability games, too.",
    "descriptor": "",
    "authors": [
      "Volker Diekert",
      "Manfred Kufleitner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10121"
  },
  {
    "id": "arXiv:2208.10126",
    "title": "Revising Image-Text Retrieval via Multi-Modal Entailment",
    "abstract": "An outstanding image-text retrieval model depends on high-quality labeled\ndata. While the builders of existing image-text retrieval datasets strive to\nensure that the caption matches the linked image, they cannot prevent a caption\nfrom fitting other images. We observe that such a many-to-many matching\nphenomenon is quite common in the widely-used retrieval datasets, where one\ncaption can describe up to 178 images. These large matching-lost data not only\nconfuse the model in training but also weaken the evaluation accuracy. Inspired\nby visual and textual entailment tasks, we propose a multi-modal entailment\nclassifier to determine whether a sentence is entailed by an image plus its\nlinked captions. Subsequently, we revise the image-text retrieval datasets by\nadding these entailed captions as additional weak labels of an image and\ndevelop a universal variable learning rate strategy to teach a retrieval model\nto distinguish the entailed captions from other negative samples. In\nexperiments, we manually annotate an entailment-corrected image-text retrieval\ndataset for evaluation. The results demonstrate that the proposed entailment\nclassifier achieves about 78% accuracy and consistently improves the\nperformance of image-text retrieval baselines.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xu Yan",
      "Chunhui Ai",
      "Ziqiang Cao",
      "Min Cao",
      "Sujian Li",
      "Wenjie Chen",
      "Guohong Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10126"
  },
  {
    "id": "arXiv:2208.10127",
    "title": "From Distributed Quantum Computing to Quantum Internet Computing: an  Overview",
    "abstract": "The possibility of quantum computing has been proposed decades ago, at least\nas far back as the 1980s, and distributed quantum computing have been studied\naround two decades ago. Recent times have seen experimental successes and\nadvances in quantum computer hardware and in quantum networking, leading\ntowards the quantum Internet. We provide in this paper an overview of concepts\nand ideas in distributed quantum computing since over two decades ago as well\nrecent efforts in the area, and consider how, with the development of the\nquantum Internet, distributed quantum computing is evolving into quantum\nInternet computing.",
    "descriptor": "",
    "authors": [
      "Seng W. Loke"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2208.10127"
  },
  {
    "id": "arXiv:2208.10128",
    "title": "SWEM: Towards Real-Time Video Object Segmentation with Sequential  Weighted Expectation-Maximization",
    "abstract": "Matching-based methods, especially those based on space-time memory, are\nsignificantly ahead of other solutions in semi-supervised video object\nsegmentation (VOS). However, continuously growing and redundant template\nfeatures lead to an inefficient inference. To alleviate this, we propose a\nnovel Sequential Weighted Expectation-Maximization (SWEM) network to greatly\nreduce the redundancy of memory features. Different from the previous methods\nwhich only detect feature redundancy between frames, SWEM merges both\nintra-frame and inter-frame similar features by leveraging the sequential\nweighted EM algorithm. Further, adaptive weights for frame features endow SWEM\nwith the flexibility to represent hard samples, improving the discrimination of\ntemplates. Besides, the proposed method maintains a fixed number of template\nfeatures in memory, which ensures the stable inference complexity of the VOS\nsystem. Extensive experiments on commonly used DAVIS and YouTube-VOS datasets\nverify the high efficiency (36 FPS) and high performance (84.3\\%\n$\\mathcal{J}\\&\\mathcal{F}$ on DAVIS 2017 validation dataset) of SWEM. Code is\navailable at: https://github.com/lmm077/SWEM.",
    "descriptor": "\nComments: 15 pages with Supplementary Material\n",
    "authors": [
      "Zhihui Lin",
      "Tianyu Yang",
      "Maomao Li",
      "Ziyu Wang",
      "Chun Yuan",
      "Wenhao Jiang",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10128"
  },
  {
    "id": "arXiv:2208.10134",
    "title": "SoK: Machine Learning with Confidential Computing",
    "abstract": "Privacy and security challenges in Machine Learning (ML) have become a\ncritical topic to address, along with ML's pervasive development and the recent\ndemonstration of large attack surfaces. As a mature system-oriented approach,\nconfidential computing has been increasingly utilized in both academia and\nindustry to improve privacy and security in various ML scenarios. In this\npaper, we systematize the findings on confidential computing-assisted ML\nsecurity and privacy techniques for providing i) confidentiality guarantees and\nii) integrity assurances. We further identify key challenges and provide\ndedicated analyses of the limitations in existing Trusted Execution Environment\n(TEE) systems for ML use cases. We discuss prospective works, including\ngrounded privacy definitions, partitioned ML executions, dedicated TEE designs\nfor ML, TEE-aware ML, and ML full pipeline guarantee. These potential solutions\ncan help achieve a much strong TEE-enabled ML for privacy guarantees without\nintroducing computation and system costs.",
    "descriptor": "\nComments: Survey paper\n",
    "authors": [
      "Fan Mo",
      "Zahra Tarkhani",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10134"
  },
  {
    "id": "arXiv:2208.10135",
    "title": "Fault-Tolerant Graph Realizations in the Congested Clique",
    "abstract": "In this paper, we study the graph realization problem in the Congested Clique\nmodel of distributed computing under crash faults. We consider {\\em\ndegree-sequence realization}, in which each node $v$ is associated with a\ndegree value $d(v)$, and the resulting degree sequence is realizable if it is\npossible to construct an overlay network with the given degrees.\nOur main result is a $O(f)$-round deterministic algorithm for the\ndegree-sequence realization problem in a $n$-node Congested Clique, of which\n$f$ nodes could be faulty ($f<n$). The algorithm uses $O(n^2)$ messages. We\ncomplement the result with lower bounds to show that the algorithm is tight\nw.r.t the number of rounds and the messages simultaneously.\nWe also extend our result to the Node Capacitated Clique (NCC) model, where\neach node is restricted to sending and receiving at-most $O(\\log n)$ messages\nper round. In the NCC model, our algorithm solves degree-sequence realization\nin $O(nf/\\log n)$ rounds and $O(n^2)$ messages.\nFor both settings, our algorithms work without the knowledge of $f$, the\nnumber of faults. To the best of our knowledge, these are the first results for\nthe graph realization problem in the crash-fault distributed network.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Anisur Rahaman Molla",
      "Manish Kumar",
      "Sumathi Sivasubramaniam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.10135"
  },
  {
    "id": "arXiv:2208.10136",
    "title": "On Information Bottleneck for Gaussian Processes",
    "abstract": "The information bottleneck problem (IB) of jointly stationary Gaussian\nsources is considered. A water-filling solution for the IB rate is given in\nterms of its SNR spectrum and whose rate is attained via frequency domain\ntest-channel realization. A time-domain realization of the IB rate, based on\nlinear prediction, is also proposed, which lends itself to an efficient\nimplementation of the corresponding remote source-coding problem. A compound\nversion of the problem is addressed, in which the joint distribution of the\nsource is not precisely specified but rather in terms of a lower bound on the\nguaranteed mutual information. It is proved that a white SNR spectrum is\noptimal for this setting.",
    "descriptor": "\nComments: Complementary proofs for the ITW2022 conference paper\n",
    "authors": [
      "Michael Dikshtein",
      "Nir Weinberger",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10136"
  },
  {
    "id": "arXiv:2208.10138",
    "title": "Learning Correlated Equilibria in Mean-Field Games",
    "abstract": "The designs of many large-scale systems today, from traffic routing\nenvironments to smart grids, rely on game-theoretic equilibrium concepts.\nHowever, as the size of an $N$-player game typically grows exponentially with\n$N$, standard game theoretic analysis becomes effectively infeasible beyond a\nlow number of players. Recent approaches have gone around this limitation by\ninstead considering Mean-Field games, an approximation of anonymous $N$-player\ngames, where the number of players is infinite and the population's state\ndistribution, instead of every individual player's state, is the object of\ninterest. The practical computability of Mean-Field Nash equilibria, the most\nstudied Mean-Field equilibrium to date, however, typically depends on\nbeneficial non-generic structural properties such as monotonicity or\ncontraction properties, which are required for known algorithms to converge. In\nthis work, we provide an alternative route for studying Mean-Field games, by\ndeveloping the concepts of Mean-Field correlated and coarse-correlated\nequilibria. We show that they can be efficiently learnt in \\emph{all games},\nwithout requiring any additional assumption on the structure of the game, using\nthree classical algorithms. Furthermore, we establish correspondences between\nour notions and those already present in the literature, derive optimality\nbounds for the Mean-Field - $N$-player transition, and empirically demonstrate\nthe convergence of these algorithms on simple games.",
    "descriptor": "",
    "authors": [
      "Paul Muller",
      "Romuald Elie",
      "Mark Rowland",
      "Mathieu Lauriere",
      "Julien Perolat",
      "Sarah Perrin",
      "Matthieu Geist",
      "Georgios Piliouras",
      "Olivier Pietquin",
      "Karl Tuyls"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.10138"
  },
  {
    "id": "arXiv:2208.10139",
    "title": "Rethinking Knowledge Distillation via Cross-Entropy",
    "abstract": "Knowledge Distillation (KD) has developed extensively and boosted various\ntasks. The classical KD method adds the KD loss to the original cross-entropy\n(CE) loss. We try to decompose the KD loss to explore its relation with the CE\nloss. Surprisingly, we find it can be regarded as a combination of the CE loss\nand an extra loss which has the identical form as the CE loss. However, we\nnotice the extra loss forces the student's relative probability to learn the\nteacher's absolute probability. Moreover, the sum of the two probabilities is\ndifferent, making it hard to optimize. To address this issue, we revise the\nformulation and propose a distributed loss. In addition, we utilize teachers'\ntarget output as the soft target, proposing the soft loss. Combining the soft\nloss and the distributed loss, we propose a new KD loss (NKD). Furthermore, we\nsmooth students' target output to treat it as the soft target for training\nwithout teachers and propose a teacher-free new KD loss (tf-NKD). Our method\nachieves state-of-the-art performance on CIFAR-100 and ImageNet. For example,\nwith ResNet-34 as the teacher, we boost the ImageNet Top-1 accuracy of ResNet18\nfrom 69.90% to 71.96%. In training without teachers, MobileNet, ResNet-18 and\nSwinTransformer-Tiny achieve 70.04%, 70.76%, and 81.48%, which are 0.83%,\n0.86%, and 0.30% higher than the baseline, respectively. The code is available\nat https://github.com/yzd-v/cls_KD.",
    "descriptor": "\nComments: 2 figures, 8 tables\n",
    "authors": [
      "Zhendong Yang",
      "Zhe Li",
      "Yuan Gong",
      "Tianke Zhang",
      "Shanshan Lao",
      "Chun Yuan",
      "Yu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10139"
  },
  {
    "id": "arXiv:2208.10142",
    "title": "Learning Ball-balancing Robot Through Deep Reinforcement Learning",
    "abstract": "The ball-balancing robot (ballbot) is a good platform to test the\neffectiveness of a balancing controller. Considering balancing control,\nconventional model-based feedback control methods have been widely used.\nHowever, contacts and collisions are difficult to model, and often lead to\nfailure in balancing control, especially when the ballbot tilts a large angle.\nTo explore the maximum initial tilting angle of the ballbot, the balancing\ncontrol is interpreted as a recovery task using Reinforcement Learning (RL). RL\nis a powerful technique for systems that are difficult to model, because it\nallows an agent to learn policy by interacting with the environment. In this\npaper, by combining the conventional feedback controller with the RL method, a\ncompound controller is proposed. We show the effectiveness of the compound\ncontroller by training an agent to successfully perform a recovery task\ninvolving contacts and collisions. Simulation results demonstrate that using\nthe compound controller, the ballbot can keep balance under a larger set of\ninitial tilting angles, compared to the conventional model-based controller.",
    "descriptor": "\nComments: 7+1 pages\n",
    "authors": [
      "Yifan Zhou",
      "Jianghao Lin",
      "Shuai Wang",
      "Chong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10142"
  },
  {
    "id": "arXiv:2208.10143",
    "title": "Plain convergence of goal-oriented adaptive FEM",
    "abstract": "We discuss goal-oriented adaptivity in the frame of conforming finite element\nmethods and plain convergence of the related a posteriori error estimator for\ndifferent general marking strategies. We present an abstract analysis for two\ndifferent settings. First, we consider problems where a local discrete\nefficiency estimate holds. Second, we show plain convergence in a setting that\nrelies only on structural properties of the error estimators, namely stability\non non-refined elements as well as reduction on refined elements. In\nparticular, the second setting does not require reliability and efficiency\nestimates. Numerical experiments underline our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Valentin Helml",
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10143"
  },
  {
    "id": "arXiv:2208.10145",
    "title": "STS: Surround-view Temporal Stereo for Multi-view 3D Detection",
    "abstract": "Learning accurate depth is essential to multi-view 3D object detection.\nRecent approaches mainly learn depth from monocular images, which confront\ninherent difficulties due to the ill-posed nature of monocular depth learning.\nInstead of using a sole monocular depth method, in this work, we propose a\nnovel Surround-view Temporal Stereo (STS) technique that leverages the geometry\ncorrespondence between frames across time to facilitate accurate depth\nlearning. Specifically, we regard the field of views from all cameras around\nthe ego vehicle as a unified view, namely surroundview, and conduct temporal\nstereo matching on it. The resulting geometrical correspondence between\ndifferent frames from STS is utilized and combined with the monocular depth to\nyield final depth prediction. Comprehensive experiments on nuScenes show that\nSTS greatly boosts 3D detection ability, notably for medium and long distance\nobjects. On BEVDepth with ResNet-50 backbone, STS improves mAP and NDS by 2.6%\nand 1.4%, respectively. Consistent improvements are observed when using a\nlarger backbone and a larger image resolution, demonstrating its effectiveness",
    "descriptor": "",
    "authors": [
      "Zengran Wang",
      "Chen Min",
      "Zheng Ge",
      "Yinhao Li",
      "Zeming Li",
      "Hongyu Yang",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10145"
  },
  {
    "id": "arXiv:2208.10156",
    "title": "Meta-Causal Feature Learning for Out-of-Distribution Generalization",
    "abstract": "Causal inference has become a powerful tool to handle the out-of-distribution\n(OOD) generalization problem, which aims to extract the invariant features.\nHowever, conventional methods apply causal learners from multiple data splits,\nwhich may incur biased representation learning from imbalanced data\ndistributions and difficulty in invariant feature learning from heterogeneous\nsources. To address these issues, this paper presents a balanced meta-causal\nlearner (BMCL), which includes a balanced task generation module (BTG) and a\nmeta-causal feature learning module (MCFL). Specifically, the BTG module learns\nto generate balanced subsets by a self-learned partitioning algorithm with\nconstraints on the proportions of sample classes and contexts. The MCFL module\ntrains a meta-learner adapted to different distributions. Experiments conducted\non NICO++ dataset verified that BMCL effectively identifies the class-invariant\nvisual regions for classification and may serve as a general framework to\nimprove the performance of the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yuqing Wang",
      "Xiangxian Li",
      "Zhuang Qi",
      "Jingyu Li",
      "Xuelong Li",
      "Xiangxu Meng",
      "Lei Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10156"
  },
  {
    "id": "arXiv:2208.10159",
    "title": "Prompt-Matched Semantic Segmentation",
    "abstract": "The objective of this work is to explore how to effectively and efficiently\nadapt pre-trained foundation models to various downstream tasks of image\nsemantic segmentation. Conventional methods usually fine-tuned the whole\nnetworks for each specific dataset and it was burdensome to store the massive\nparameters of these networks. A few recent works attempted to insert some\ntrainable parameters into the frozen network to learn visual prompts for\nefficient tuning. However, these works significantly modified the original\nstructure of standard modules, making them inoperable on many existing\nhigh-speed inference devices, where standard modules and their parameters have\nbeen embedded. To facilitate prompt-based semantic segmentation, we propose a\nnovel Inter-Stage Prompt-Matched Framework, which maintains the original\nstructure of the foundation model while generating visual prompts adaptively\nfor task-oriented tuning. Specifically, the pre-trained model is first divided\ninto multiple stages, and their parameters are frozen and shared for all\nsemantic segmentation tasks. A lightweight module termed Semantic-aware Prompt\nMatcher is then introduced to hierarchically interpolate between two stages to\nlearn reasonable prompts for each specific task under the guidance of interim\nsemantic maps. In this way, we can better stimulate the pre-trained knowledge\nof the frozen model to learn semantic concepts effectively on downstream\ndatasets. Extensive experiments conducted on five benchmarks show that the\nproposed method can achieve a promising trade-off between parameter efficiency\nand performance effectiveness.",
    "descriptor": "",
    "authors": [
      "Lingbo Liu",
      "Bruce X.B. Yu",
      "Jianlong Chang",
      "Qi Tian",
      "Chang-Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10159"
  },
  {
    "id": "arXiv:2208.10160",
    "title": "PANDA: Prompt Transfer Meets Knowledge Distillation for Efficient Model  Adaptation",
    "abstract": "Prompt-tuning, which freezes pretrained language models (PLMs) and only\nfine-tunes few parameters of additional soft prompt, shows competitive\nperformance against full-parameter fine-tuning (i.e.model-tuning) when the PLM\nhas billions of parameters, but still performs poorly in the case of smaller\nPLMs. Hence, prompt transfer (PoT), which initializes the target prompt with\nthe trained prompt of similar source tasks, is recently proposed to improve\nover prompt-tuning. However, such a vanilla PoT approach usually achieves\nsub-optimal performance, as (i) the PoT is sensitive to the similarity of\nsource-target pair and (ii) directly fine-tuning the prompt initialized with\nsource prompt on target task might lead to catastrophic forgetting of source\nknowledge. In response to these problems, we propose a new metric to accurately\npredict the prompt transferability (regarding (i)), and a novel PoT approach\n(namely PANDA) that leverages the knowledge distillation technique to transfer\nthe \"knowledge\" from the source prompt to the target prompt in a subtle manner\nand alleviate the catastrophic forgetting effectively (regarding (ii)).\nFurthermore, to achieve adaptive prompt transfer for each source-target pair,\nwe use our metric to control the knowledge transfer in our PANDA approach.\nExtensive and systematic experiments on 189 combinations of 21 source and 9\ntarget datasets across 5 scales of PLMs demonstrate that: 1) our proposed\nmetric works well to predict the prompt transferability; 2) our PANDA\nconsistently outperforms the vanilla PoT approach by 2.3% average score (up to\n24.1%) among all tasks and model sizes; 3) with our PANDA approach,\nprompt-tuning can achieve competitive and even better performance than\nmodel-tuning in various PLM scales scenarios. Code and models will be released\nupon acceptance.",
    "descriptor": "",
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10160"
  },
  {
    "id": "arXiv:2208.10161",
    "title": "BRIEF but Powerful: Byzantine-Robust and Privacy-Preserving Federated  Learning via Model Segmentation and Secure clustering",
    "abstract": "Byzantine-robust Federated Learning (FL) aims to counter malicious clients\nand to train an accurate global model while maintaining an extremely low attack\nsuccess rate. Most of the existing systems, however, are only robust in\nhonest/semi-honest majority settings. FLTrust (NDSS '21) extends the context to\nthe malicious majority for clients but with a strong restriction that the\nserver should be provided with an auxiliary dataset before training in order to\nfilter malicious inputs. Private FLAME/FLGUARD (USENIX '22) gives a solution to\nguarantee both robustness and updates confidentiality in the semi-honest\nmajority context. It is so far impossible to balance the trade-off among\nmalicious context, robustness, and updates confidentiality. To tackle this\nproblem, we propose a novel Byzantine-robust and privacy-preserving FL system,\ncalled BRIEF, to capture malicious minority and majority for server and client\nsides. Specifically, based on the DBSCAN algorithm, we design a new method for\nclustering via pairwise adjusted cosine similarity to boost the accuracy of the\nclustering results. To thwart attacks of malicious majority, we develop an\nalgorithm called Model Segmentation, where local updates in the same cluster\nare aggregated together, and the aggregations are sent back to corresponding\nclients correctly. We also leverage multiple cryptographic tools to conduct\nclustering tasks without sacrificing training correctness and updates\nconfidentiality. We present detailed security proof and empirical evaluation\nalong with convergence analysis for BRIEF. The experimental results demonstrate\nthat the testing accuracy of BRIEF is practically close to the FL baseline\n(0.8% gap on average). At the same time, the attack success rate is around\n0%-5%. We further optimize our design so that the communication overhead and\nruntime can be decreased by {67%-89.17% and 66.05%-68.75%}, respectively.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Xingkai Wang",
      "Huanhuan Chen",
      "Stjepan Picek",
      "Zhen Liu",
      "Kaitai Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10161"
  },
  {
    "id": "arXiv:2208.10162",
    "title": "Unscented Kalman filter with stable embedding for simple, accurate and  computationally efficient state estimation of systems on manifolds in  Euclidean space",
    "abstract": "This paper proposes a simple, accurate and computationally efficient method\nto apply the ordinary unscented Kalman filter developed in Euclidean space to\nsystems whose dynamics evolve on manifolds.We use the mathematical theory\ncalled stable embedding to make a variant of unscented Kalman filter that keeps\nstate estimates in closeproximity to the manifold while exhibiting excellent\nestimation performance. We confirm the performance of our devised filter by\napplying it to the satellite system model and comparing the performance with\nother unscented Kalman filters devised specifically for systems on manifolds.\nOur devised filter has a low estimation error, keeps the state estimates in\nclose proximity to the manifold as expected, and consumes a minor amount of\ncomputation time. Also our devised filter is simple and easy to use because our\nfilter directly employs the off-the-shelf standard unscented Kalman filter\ndevised in Euclidean space without any particular manifold-structure-preserving\ndiscretization method or coordinate transformation.",
    "descriptor": "\nComments: This paper is under 2nd review of International Journal of Robust and Nonliner Control\n",
    "authors": [
      "Jae-Hyeon Park",
      "Dong Eui Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10162"
  },
  {
    "id": "arXiv:2208.10165",
    "title": "Exploring Task-oriented Communication in Multi-agent System: A Deep  Reinforcement Learning Approach",
    "abstract": "The multi-agent system (MAS) enables the sharing of capabilities among\nagents, such that collaborative tasks can be accomplished with high scalability\nand efficiency. MAS is increasingly widely applied in various fields.\nMeanwhile, the large-scale and time-sensitive data transmission between agents\nbrings challenges to the communication system. The traditional wireless\ncommunication ignores the content of the data and its impact on the task\nexecution at the receiver, which makes it difficult to guarantee the timeliness\nand relevance of the information. This limitation leads to that traditional\nwireless communication struggles to effectively support emerging multi-agent\ncollaborative applications. Faced with this dilemma, task-oriented\ncommunication is a potential solution, which aims to transmit task-relevant\ninformation to improve task execution performance. However, multi-agent\ncollaboration itself is a complex class of sequential decision problems. It is\nchallenging to explore efficient information flow in this context. In this\narticle, we use deep reinforcement learning (DRL) to explore task-oriented\ncommunication in MAS. We begin with a discussion on the application of DRL to\ntask-oriented communication. We then envision a task-oriented communication\narchitecture for MAS, and discuss the designs based on DRL. Finally, we discuss\nopen problems for future research and conclude this article.",
    "descriptor": "",
    "authors": [
      "Guojun He"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.10165"
  },
  {
    "id": "arXiv:2208.10167",
    "title": "Interdisciplinary Research with Older Adults in the area of ICT:  Selected Ethical Considerations and Challenges",
    "abstract": "In this paper we analyse, classify and discuss some ethical considerations\nand challenges related to pursuing exploratory and interdisciplinary research\nprojects in the area of ICT, especially those involving older adults. First, we\nidentify spotlight areas, which are especially prominent in these fields. Next,\nwe explore possible pitfalls interdisciplinary researchers may stumble onto\nwhen planning, conducting and presenting exploratory research activities.\nFinally, some of these are selected and discussed more closely, while related\nopen questions are posed.",
    "descriptor": "",
    "authors": [
      "Kinga Skorupska",
      "Ewa Makowska",
      "Anna Jaskulska"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.10167"
  },
  {
    "id": "arXiv:2208.10168",
    "title": "\u00d5ptimal Dual Vertex Failure Connectivity Labels",
    "abstract": "In this paper we present succinct labeling schemes for supporting\nconnectivity queries under vertex faults. For a given $n$-vertex graph $G$, an\n$f$-VFT (resp., EFT) connectivity labeling scheme is a distributed data\nstructure that assigns each of the graph edges and vertices a short label, such\nthat given the labels of a vertex pair $u$ and $v$, and the labels of at most\n$f$ failing vertices (resp., edges) $F$, one can determine if $u$ and $v$ are\nconnected in $G \\setminus F$. The primary complexity measure is the length of\nthe individual labels. Since their introduction by [Courcelle, Twigg, STACS\n'07], FT labeling schemes have been devised only for a limited collection of\ngraph families. A recent work [Dory and Parter, PODC 2021] provided EFT\nlabeling schemes for general graphs under edge failures, leaving the vertex\nfailure case fairly open. We provide the first sublinear $f$-VFT labeling\nschemes for $f \\geq 2$ for any $n$-vertex graph. Our key result is $2$-VFT\nconnectivity labels with $O(\\log^3 n)$ bits. Our constructions are based on\nanalyzing the structure of dual failure replacement paths on top of the\nwell-known heavy-light tree decomposition technique of [Sleator and Tarjan,\nSTOC 1981]. We also provide $f$-VFT labels with sub-linear length (in $|V|$)\nfor any $f=o(\\log\\log n)$, that are based on a reduction to the existing EFT\nlabels.",
    "descriptor": "\nComments: DISC 2022\n",
    "authors": [
      "Merav Parter",
      "Asaf Petruschka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.10168"
  },
  {
    "id": "arXiv:2208.10169",
    "title": "Multi-Granularity Distillation Scheme Towards Lightweight  Semi-Supervised Semantic Segmentation",
    "abstract": "Albeit with varying degrees of progress in the field of Semi-Supervised\nSemantic Segmentation, most of its recent successes are involved in unwieldy\nmodels and the lightweight solution is still not yet explored. We find that\nexisting knowledge distillation techniques pay more attention to pixel-level\nconcepts from labeled data, which fails to take more informative cues within\nunlabeled data into account. Consequently, we offer the first attempt to\nprovide lightweight SSSS models via a novel multi-granularity distillation\n(MGD) scheme, where multi-granularity is captured from three aspects: i)\ncomplementary teacher structure; ii) labeled-unlabeled data cooperative\ndistillation; iii) hierarchical and multi-levels loss setting. Specifically,\nMGD is formulated as a labeled-unlabeled data cooperative distillation scheme,\nwhich helps to take full advantage of diverse data characteristics that are\nessential in the semi-supervised setting. Image-level semantic-sensitive loss,\nregion-level content-aware loss, and pixel-level consistency loss are set up to\nenrich hierarchical distillation abstraction via structurally complementary\nteachers. Experimental results on PASCAL VOC2012 and Cityscapes reveal that MGD\ncan outperform the competitive approaches by a large margin under diverse\npartition protocols. For example, the performance of ResNet-18 and MobileNet-v2\nbackbone is boosted by 11.5% and 4.6% respectively under 1/16 partition\nprotocol on Cityscapes. Although the FLOPs of the model backbone is compressed\nby 3.4-5.3x (ResNet-18) and 38.7-59.6x (MobileNetv2), the model manages to\nachieve satisfactory segmentation results.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Jie Qin",
      "Jie Wu",
      "Ming Li",
      "Xuefeng Xiao",
      "Min Zheng",
      "Xingang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10169"
  },
  {
    "id": "arXiv:2208.10172",
    "title": "Algorithms of Real-Time Navigation and Control of Autonomous Unmanned  Vehicles",
    "abstract": "The rapid development of robotics has benefited by more and more people\nputting their attention to it. With the demand for robots is growing for the\npurpose of fulfilling tasks instead of humans, how to control the robot better\nis becoming a hot topic. For obstacle avoidance, we proposed algorithms for\nboth 2D planar environments and 3D space environments. The example cases we\nraise are those that need to be addressed but have always been ignored. In\naddition, we put efforts into trajectory planning for robots. The two scenarios\nwe set are self-driving cars on the road and reconnaissance and surveillance of\ndrones. For future expectations, there are some possible directions. How to\ncombine traditional navigation algorithms and high-tech algorithms together so\nas to fulfill the tasks perfectly while the computational efficiency is not too\nhigh is a worthy topic. In addition, extending the obstacle avoidance\nalgorithms to more competitive situations. Moreover, cooperation among multi\nrobots are worth attention by researchers. All in all, there is still a long\nway to go for the development of navigation and control of mobile robots.\nDespite this, we believe we do not need to wait for too long time to see the\nrevolution of robots.",
    "descriptor": "",
    "authors": [
      "Yang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10172"
  },
  {
    "id": "arXiv:2208.10174",
    "title": "KEEP: An Industrial Pre-Training Framework for Online Recommendation via  Knowledge Extraction and Plugging",
    "abstract": "An industrial recommender system generally presents a hybrid list that\ncontains results from multiple subsystems. In practice, each subsystem is\noptimized with its own feedback data to avoid the disturbance among different\nsubsystems. However, we argue that such data usage may lead to sub-optimal\nonline performance because of the \\textit{data sparsity}. To alleviate this\nissue, we propose to extract knowledge from the \\textit{super-domain} that\ncontains web-scale and long-time impression data, and further assist the online\nrecommendation task (downstream task). To this end, we propose a novel\nindustrial \\textbf{K}nowl\\textbf{E}dge \\textbf{E}xtraction and\n\\textbf{P}lugging (\\textbf{KEEP}) framework, which is a two-stage framework\nthat consists of 1) a supervised pre-training knowledge extraction module on\nsuper-domain, and 2) a plug-in network that incorporates the extracted\nknowledge into the downstream model. This makes it friendly for incremental\ntraining of online recommendation. Moreover, we design an efficient empirical\napproach for KEEP and introduce our hands-on experience during the\nimplementation of KEEP in a large-scale industrial system. Experiments\nconducted on two real-world datasets demonstrate that KEEP can achieve\npromising results. It is notable that KEEP has also been deployed on the\ndisplay advertising system in Alibaba, bringing a lift of $+5.4\\%$ CTR and\n$+4.7\\%$ RPM.",
    "descriptor": "\nComments: Accepted at CIKM 2022, 10 pages. Yujing Zhang and Zhangming Chan contributed equally to this work\n",
    "authors": [
      "Yujing Zhang",
      "Zhangming Chan",
      "Shuhao Xu",
      "Weijie Bian",
      "Shuguang Han",
      "Hongbo Deng",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10174"
  },
  {
    "id": "arXiv:2208.10176",
    "title": "Competition for popularity and identification of interventions on a  Chinese microblogging site",
    "abstract": "Microblogging sites are important vehicles for the users to obtain\ninformation and shape public opinion thus they are arenas of continuous\ncompetition for popularity. Most popular topics are usually indicated on\nranking lists. In this study, we investigate the public attention dynamics\nthrough the Hot Search List (HSL) of the Chinese microblog Sina Weibo, where\ntrending hashtags are ranked based on a multi-dimensional search volume index.\nWe characterize the rank dynamics by the time spent by hashtags on the list,\nthe time of the day they appear there, the rank diversity, and by the ranking\ntrajectories. We show how the circadian rhythm affects the popularity of\nhashtags, and observe categories of their rank trajectories by a machine\nlearning classification algorithm. By analyzing patterns of the ranking\ndynamics we identify anomalies that are likely to result from the platform\nprovider's intervention into the ranking, including the anchoring of hashtags\nto certain ranks on the HSL. We propose a simple model of ranking that explains\nthe mechanism of this anchoring effect.",
    "descriptor": "\nComments: Main paper 14 pages, 6 figure. Supplementary information 2 pages, 3 figures\n",
    "authors": [
      "Hao Cui",
      "J\u00e1nos Kert\u00e9sz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10176"
  },
  {
    "id": "arXiv:2208.10180",
    "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
    "abstract": "As textual attributes like font are core design elements of document format\nand page style, automatic attributes recognition favor comprehensive practical\napplications. Existing approaches already yield satisfactory performance in\ndifferentiating disparate attributes, but they still suffer in distinguishing\nsimilar attributes with only subtle difference. Moreover, their performance\ndrop severely in real-world scenarios where unexpected and obvious imaging\ndistortions appear. In this paper, we aim to tackle these problems by proposing\nTaCo, a contrastive framework for textual attribute recognition tailored toward\nthe most common document scenes. Specifically, TaCo leverages contrastive\nlearning to dispel the ambiguity trap arising from vague and open-ended\nattributes. To realize this goal, we design the learning paradigm from three\nperspectives: 1) generating attribute views, 2) extracting subtle but crucial\ndetails, and 3) exploiting valued view pairs for learning, to fully unlock the\npre-training potential. Extensive experiments show that TaCo surpasses the\nsupervised counterparts and advances the state-of-the-art remarkably on\nmultiple attribute recognition tasks. Online services of TaCo will be made\navailable.",
    "descriptor": "",
    "authors": [
      "Chang Nie",
      "Yiqing Hu",
      "Yanqiu Qu",
      "Hao Liu",
      "Deqiang Jiang",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10180"
  },
  {
    "id": "arXiv:2208.10181",
    "title": "Aesthetics Driven Autonomous Time-Lapse Photography Generation by  Virtual and Real Robots",
    "abstract": "Time-lapse photography is employed in movies and promotional films because it\ncan reflect the passage of time in a short time and strengthen the visual\nattraction. However, since it takes a long time and requires the stable\nshooting, it is a great challenge for the photographer.\nIn this article, we propose a time-lapse photography system with virtual and\nreal robots. To help users shoot time-lapse videos efficiently, we first\nparameterize the time-lapse photography and propose a parameter optimization\nmethod. For different parameters, different aesthetic models, including image\nand video aesthetic quality assessment networks, are used to generate optimal\nparameters. Then we propose a time-lapse photography interface to facilitate\nusers to view and adjust parameters and use virtual robots to conduct virtual\nphotography in a three-dimensional scene. The system can also export the\nparameters and provide them to real robots so that the time-lapse videos can be\nfilmed in the real world.\nIn addition, we propose a time-lapse photography aesthetic assessment method\nthat can automatically evaluate the aesthetic quality of time-lapse video.\nThe experimental results show that our method can efficiently obtain the\ntime-lapse videos. We also conduct a user study. The results show that our\nsystem has the similar effect as professional photographers and is more\nefficient.",
    "descriptor": "\nComments: 5 pages, 3 figures, on going research\n",
    "authors": [
      "Xiaobo Gao",
      "Qi Kuang",
      "Xin Jin",
      "Bin Zhou",
      "Boyan Dong",
      "Xunyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10181"
  },
  {
    "id": "arXiv:2208.10188",
    "title": "The oriented relative clique number of triangle-free planar graphs is 10",
    "abstract": "In relation to oriented coloring and chromatic number, the parameter oriented\nrelative clique number of an oriented graph $\\overrightarrow{G}$, denoted by\n$\\omega_{ro}(\\overrightarrow{G})$, is the main focus of this work. We solve an\nopen problem mentioned in the recent survey on oriented coloring by Sopena\n(Discrete Mathematics 2016), and positively settle a conjecture due to Sen (PhD\nthesis 2014), by proving that the maximum value of\n$\\omega_{ro}(\\overrightarrow{G})$ is $10$ when $\\overrightarrow{G}$ is a planar\ngraph.",
    "descriptor": "",
    "authors": [
      "Soura Sena Das",
      "Soumen Nandi",
      "Sagnik Sen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.10188"
  },
  {
    "id": "arXiv:2208.10192",
    "title": "Towards Confidence-aware Calibrated Recommendation",
    "abstract": "Recommender systems utilize users' historical data to learn and predict their\nfuture interests, providing them with suggestions tailored to their tastes.\nCalibration ensures that the distribution of recommended item categories is\nconsistent with the user's historical data. Mitigating miscalibration brings\nvarious benefits to a recommender system. For example, it becomes less likely\nthat a system overlooks categories with less interaction on a user's profile by\nonly recommending popular categories. Despite the notable success, calibration\nmethods have several drawbacks, such as limiting the diversity of the\nrecommended items and not considering the calibration confidence. This work,\npresents a set of properties that address various aspects of a desired\ncalibrated recommender system. Considering these properties, we propose a\nconfidence-aware optimization-based re-ranking algorithm to find the balance\nbetween calibration, relevance, and item diversity, while simultaneously\naccounting for calibration confidence based on user profile size. Our model\noutperforms state-of-the-art methods in terms of various accuracy and\nbeyond-accuracy metrics for different user groups.",
    "descriptor": "\nComments: CIKM 2022\n",
    "authors": [
      "Mohammadmehdi Naghiaei",
      "Hossein A. Rahmani",
      "Mohammad Aliannejadi",
      "Nasim Sonboli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.10192"
  },
  {
    "id": "arXiv:2208.10193",
    "title": "Learning Low Bending and Low Distortion Manifold Embeddings: Theory and  Applications",
    "abstract": "Autoencoders, which consist of an encoder and a decoder, are widely used in\nmachine learning for dimension reduction of high-dimensional data. The encoder\nembeds the input data manifold into a lower-dimensional latent space, while the\ndecoder represents the inverse map, providing a parametrization of the data\nmanifold by the manifold in latent space. A good regularity and structure of\nthe embedded manifold may substantially simplify further data processing tasks\nsuch as cluster analysis or data interpolation. We propose and analyze a novel\nregularization for learning the encoder component of an autoencoder: a loss\nfunctional that prefers isometric, extrinsically flat embeddings and allows to\ntrain the encoder on its own. To perform the training it is assumed that for\npairs of nearby points on the input manifold their local Riemannian distance\nand their local Riemannian average can be evaluated. The loss functional is\ncomputed via Monte Carlo integration with different sampling strategies for\npairs of points on the input manifold. Our main theorem identifies a geometric\nloss functional of the embedding map as the $\\Gamma$-limit of the\nsampling-dependent loss functionals. Numerical tests, using image data that\nencodes different explicitly given data manifolds, show that smooth manifold\nembeddings into latent space are obtained. Due to the promotion of extrinsic\nflatness, these embeddings are regular enough such that interpolation between\nnot too distant points on the manifold is well approximated by linear\ninterpolation in latent space as one possible postprocessing.",
    "descriptor": "\nComments: 27 pages, 10 figures. This publication is an extended version of the previous conference proceeding presented at DiffCVML 2021\n",
    "authors": [
      "Juliane Braunsmann",
      "Marko Rajkovi\u0107",
      "Martin Rumpf",
      "Benedikt Wirth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10193"
  },
  {
    "id": "arXiv:2208.10198",
    "title": "Markovian queues with Poisson control",
    "abstract": "We investigate Markovian queues that are examined by a controller at random\ntimes determined by a Poisson process. Upon examination, the controller sets\nthe service speed to be equal to the minimum of the current number of customers\nin the queue and a certain maximum service speed; this service speed prevails\nuntil the next examination time. We study the resulting two-dimensional Markov\nprocess of queue length and server speed, in particular two regimes with time\nscale separation, specifically for infinitely frequent and infinitely long\nexamination times. In the intermediate regime the analysis proves to be\nextremely challenging. To gain further insight into the model dynamics we then\nanalyse two variants of the model in which the controller is just an observer\nand does not change the speed of the server.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "R. N\u00fa\u00f1ez-Queija",
      "B.J. Prabhu",
      "J.A.C. Resing"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2208.10198"
  },
  {
    "id": "arXiv:2208.10201",
    "title": "On uniqueness and stable estimation of multiple parameters in the  Cahn-Hilliard equation",
    "abstract": "We consider the identifiability and stable numerical estimation of multiple\nparameters in a Cahn-Hilliard model for phase separation. Spatially resolved\nmeasurements of the phase fraction are assumed to be accessible, with which the\nidentifiability of single and multiple parameters up to certain scaling\ninvariances is established. A regularized equation error approach is proposed\nfor the stable numerical solution of the parameter identification problems, and\nconvergence of the regularized approximations is proven under reasonable\nassumptions on the data noise. The viability of the theoretical results and the\nproposed methods is demonstrated in numerical tests.",
    "descriptor": "",
    "authors": [
      "Aaron Brunk",
      "Herbert Egger",
      "Oliver Habrich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10201"
  },
  {
    "id": "arXiv:2208.10205",
    "title": "LTE4G: Long-Tail Experts for Graph Neural Networks",
    "abstract": "Existing Graph Neural Networks (GNNs) usually assume a balanced situation\nwhere both the class distribution and the node degree distribution are\nbalanced. However, in real-world situations, we often encounter cases where a\nfew classes (i.e., head class) dominate other classes (i.e., tail class) as\nwell as in the node degree perspective, and thus naively applying existing GNNs\neventually fall short of generalizing to the tail cases. Although recent\nstudies proposed methods to handle long-tail situations on graphs, they only\nfocus on either the class long-tailedness or the degree long-tailedness. In\nthis paper, we propose a novel framework for training GNNs, called Long-Tail\nExperts for Graphs (LTE4G), which jointly considers the class long-tailedness,\nand the degree long-tailedness for node classification. The core idea is to\nassign an expert GNN model to each subset of nodes that are split in a balanced\nmanner considering both the class and degree long-tailedness. After having\ntrained an expert for each balanced subset, we adopt knowledge distillation to\nobtain two class-wise students, i.e., Head class student and Tail class\nstudent, each of which is responsible for classifying nodes in the head classes\nand tail classes, respectively. We demonstrate that LTE4G outperforms a wide\nrange of state-of-the-art methods in node classification evaluated on both\nmanual and natural imbalanced graphs. The source code of LTE4G can be found at\nhttps://github.com/SukwonYun/LTE4G.",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Sukwon Yun",
      "Kibum Kim",
      "Kanghoon Yoon",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10205"
  },
  {
    "id": "arXiv:2208.10211",
    "title": "PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling",
    "abstract": "Training state-of-the-art models for human pose estimation in videos requires\ndatasets with annotations that are really hard and expensive to obtain.\nAlthough transformers have been recently utilized for body pose sequence\nmodeling, related methods rely on pseudo-ground truth to augment the currently\nlimited training data available for learning such models. In this paper, we\nintroduce PoseBERT, a transformer module that is fully trained on 3D Motion\nCapture (MoCap) data via masked modeling. It is simple, generic and versatile,\nas it can be plugged on top of any image-based model to transform it in a\nvideo-based model leveraging temporal information. We showcase variants of\nPoseBERT with different inputs varying from 3D skeleton keypoints to rotations\nof a 3D parametric model for either the full body (SMPL) or just the hands\n(MANO). Since PoseBERT training is task agnostic, the model can be applied to\nseveral tasks such as pose refinement, future pose prediction or motion\ncompletion without finetuning. Our experimental results validate that adding\nPoseBERT on top of various state-of-the-art pose estimation methods\nconsistently improves their performances, while its low computational cost\nallows us to use it in a real-time demo for smoothly animating a robotic hand\nvia a webcam. Test code and models are available at\nhttps://github.com/naver/posebert.",
    "descriptor": "",
    "authors": [
      "Fabien Baradel",
      "Romain Br\u00e9gier",
      "Thibault Groueix",
      "Philippe Weinzaepfel",
      "Yannis Kalantidis",
      "Gr\u00e9gory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10211"
  },
  {
    "id": "arXiv:2208.10214",
    "title": "An explicit approximation for super-linear stochastic functional  differential equations",
    "abstract": "Since it is difficult to implement implicit schemes on the\ninfinite-dimensional space, we aim to develop the explicit numerical method for\napproximating super-linear stochastic functional differential equations\n(SFDEs). Precisely, borrowing the truncation idea and linear interpolation we\npropose an explicit truncated Euler-Maruyama scheme for super-linear SFDEs, and\nobtain the boundedness and convergence in L^p. We also yield the convergence\nrate with 1/2 order. Different from some previous works, we release the global\nLipschitz restriction on the diffusion coefficient. Furthermore, we reveal that\nnumerical solutions preserve the underlying exponential stability. Moreover, we\ngive several examples to support our theory.",
    "descriptor": "",
    "authors": [
      "Xiaoyue Li",
      "Xuerong Mao",
      "Guoting Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10214"
  },
  {
    "id": "arXiv:2208.10218",
    "title": "A Virtual 2D Tactile Array for Soft Actuators Using Acoustic Sensing",
    "abstract": "We create a virtual 2D tactile array for soft pneumatic actuators using\nembedded audio components. We detect contact-specific changes in sound\nmodulation to infer tactile information. We evaluate different sound\nrepresentations and learning methods to detect even small contact variations.\nWe demonstrate the acoustic tactile sensor array by the example of a PneuFlex\nactuator and use a Braille display to individually control the contact of 29x4\npins with the actuator's 90x10 mm palmar surface. Evaluating the spatial\nresolution, the acoustic sensor localizes edges in x- and y-direction with a\nroot-mean-square regression error of 1.67 mm and 0.0 mm, respectively. Even\nlight contacts of a single Braille pin with a lifting force of 0.17 N are\nmeasured with high accuracy. Finally, we demonstrate the sensor's sensitivity\nto complex contact shapes by successfully reading the 26 letters of the Braille\nalphabet from a single display cell with a classification rate of 88%.",
    "descriptor": "\nComments: Accepted at 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Vincent Wall",
      "Oliver Brock"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10218"
  },
  {
    "id": "arXiv:2208.10221",
    "title": "Dynamic Adaptive Threshold based Learning for Noisy Annotations Robust  Facial Expression Recognition",
    "abstract": "The real-world facial expression recognition (FER) datasets suffer from noisy\nannotations due to crowd-sourcing, ambiguity in expressions, the subjectivity\nof annotators and inter-class similarity. However, the recent deep networks\nhave strong capacity to memorize the noisy annotations leading to corrupted\nfeature embedding and poor generalization. To handle noisy annotations, we\npropose a dynamic FER learning framework (DNFER) in which clean samples are\nselected based on dynamic class specific threshold during training.\nSpecifically, DNFER is based on supervised training using selected clean\nsamples and unsupervised consistent training using all the samples. During\ntraining, the mean posterior class probabilities of each mini-batch is used as\ndynamic class-specific threshold to select the clean samples for supervised\ntraining. This threshold is independent of noise rate and does not need any\nclean data unlike other methods. In addition, to learn from all samples, the\nposterior distributions between weakly-augmented image and strongly-augmented\nimage are aligned using an unsupervised consistency loss. We demonstrate the\nrobustness of DNFER on both synthetic as well as on real noisy annotated FER\ndatasets like RAFDB, FERPlus, SFEW and AffectNet.",
    "descriptor": "",
    "authors": [
      "Darshan Gera",
      "Naveen Siva Kumar Badveeti",
      "Bobbili Veerendra Raj Kumar",
      "S Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10221"
  },
  {
    "id": "arXiv:2208.10224",
    "title": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "abstract": "A powerful category of data poisoning attacks modify a subset of training\nexamples by small adversarial perturbations to change the prediction of certain\ntest-time data. Existing defense mechanisms are not desirable to deploy in\npractice, as they often drastically harm the generalization performance, or are\nattack-specific and prohibitively slow to apply. Here, we propose a simple but\nhighly effective approach that unlike existing methods breaks various types of\npoisoning attacks with the slightest drop in the generalization performance. We\nmake the key observation that attacks exploit sharp loss regions to craft\nadversarial perturbations which can substantially alter examples' gradient or\nrepresentations under small perturbations. To break poisoning attacks, our\napproach comprises two components: an optimized friendly noise that is\ngenerated to maximally perturb examples without degrading the performance, and\na random varying noise component. The first component takes examples farther\naway from the sharp loss regions, and the second component smooths out the loss\nlandscape. The combination of both components builds a very light-weight but\nextremely effective defense against the most powerful triggerless targeted and\nhidden-trigger backdoor poisoning attacks, including Gradient Matching,\nBulls-eye Polytope, and Sleeper Agent. We show that our friendly noise is\ntransferable to other architectures, and adaptive attacks cannot break our\ndefense due to its random noise component.",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Yu Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10224"
  },
  {
    "id": "arXiv:2208.10226",
    "title": "From Easy to Hard: A Dual Curriculum Learning Framework for  Context-Aware Document Ranking",
    "abstract": "Contextual information in search sessions is important for capturing users'\nsearch intents. Various approaches have been proposed to model user behavior\nsequences to improve document ranking in a session. Typically, training samples\nof (search context, document) pairs are sampled randomly in each training\nepoch. In reality, the difficulty to understand user's search intent and to\njudge document's relevance varies greatly from one search context to another.\nMixing up training samples of different difficulties may confuse the model's\noptimization process. In this work, we propose a curriculum learning framework\nfor context-aware document ranking, in which the ranking model learns matching\nsignals between the search context and the candidate document in an\neasy-to-hard manner. In so doing, we aim to guide the model gradually toward a\nglobal optimum. To leverage both positive and negative examples, two curricula\nare designed. Experiments on two real query log datasets show that our proposed\nframework can improve the performance of several existing methods\nsignificantly, demonstrating the effectiveness of curriculum learning for\ncontext-aware document ranking.",
    "descriptor": "\nComments: CIKM 2022 Camera Ready\n",
    "authors": [
      "Yutao Zhu",
      "Jian-Yun Nie",
      "Yixuan Su",
      "Haonan Chen",
      "Xinyu Zhang",
      "Zhicheng Dou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10226"
  },
  {
    "id": "arXiv:2208.10227",
    "title": "One Model, Any CSP: Graph Neural Networks as Fast Global Search  Heuristics for Constraint Satisfaction",
    "abstract": "We propose a universal Graph Neural Network architecture which can be trained\nas an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP).\nOur architecture can be trained unsupervised with policy gradient descent to\ngenerate problem specific heuristics for any CSP in a purely data driven\nmanner. The approach is based on a novel graph representation for CSPs that is\nboth generic and compact and enables us to process every possible CSP instance\nwith one GNN, regardless of constraint arity, relations or domain size. Unlike\nprevious RL-based methods, we operate on a global search action space and allow\nour GNN to modify any number of variables in every step of the stochastic\nsearch. This enables our method to properly leverage the inherent parallelism\nof GNNs. We perform a thorough empirical evaluation where we learn heuristics\nfor well known and important CSPs from random data, including graph coloring,\nMaxCut, 3-SAT and MAX-k-SAT. Our approach outperforms prior approaches for\nneural combinatorial optimization by a substantial margin. It can compete with,\nand even improve upon, conventional search heuristics on test instances that\nare several orders of magnitude larger and structurally more complex than those\nseen during training.",
    "descriptor": "",
    "authors": [
      "Jan T\u00f6nshoff",
      "Berke Kisin",
      "Jakob Lindner",
      "Martin Grohe"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.10227"
  },
  {
    "id": "arXiv:2208.10228",
    "title": "Survey of NLP in Pharmacology: Methodology, Tasks, Resources, Knowledge,  and Tools",
    "abstract": "Natural language processing (NLP) is an area of artificial intelligence that\napplies information technologies to process the human language, understand it\nto a certain degree, and use it in various applications. This area has rapidly\ndeveloped in the last few years and now employs modern variants of deep neural\nnetworks to extract relevant patterns from large text corpora. The main\nobjective of this work is to survey the recent use of NLP in the field of\npharmacology. As our work shows, NLP is a highly relevant information\nextraction and processing approach for pharmacology. It has been used\nextensively, from intelligent searches through thousands of medical documents\nto finding traces of adversarial drug interactions in social media. We split\nour coverage into five categories to survey modern NLP methodology, commonly\naddressed tasks, relevant textual data, knowledge bases, and useful programming\nlibraries. We split each of the five categories into appropriate subcategories,\ndescribe their main properties and ideas, and summarize them in a tabular form.\nThe resulting survey presents a comprehensive overview of the area, useful to\npractitioners and interested observers.",
    "descriptor": "\nComments: 35 pages, 2 figures, 7 tables\n",
    "authors": [
      "Dimitar Trajanov",
      "Vangel Trajkovski",
      "Makedonka Dimitrieva",
      "Jovana Dobreva",
      "Milos Jovanovik",
      "Matej Klemen",
      "Ale\u0161 \u017dagar",
      "Marko Robnik-\u0160ikonja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10228"
  },
  {
    "id": "arXiv:2208.10231",
    "title": "An anomaly detection approach for backdoored neural networks: face  recognition as a case study",
    "abstract": "Backdoor attacks allow an attacker to embed functionality jeopardizing proper\nbehavior of any algorithm, machine learning or not. This hidden functionality\ncan remain inactive for normal use of the algorithm until activated by the\nattacker. Given how stealthy backdoor attacks are, consequences of these\nbackdoors could be disastrous if such networks were to be deployed for\napplications as critical as border or access control. In this paper, we propose\na novel backdoored network detection method based on the principle of anomaly\ndetection, involving access to the clean part of the training data and the\ntrained network. We highlight its promising potential when considering various\ntriggers, locations and identity pairs, without the need to make any\nassumptions on the nature of the backdoor and its setup. We test our method on\na novel dataset of backdoored networks and report detectability results with\nperfect scores.",
    "descriptor": "\nComments: Accepted at Biosig 2022, 8 pages, 4 figures\n",
    "authors": [
      "Alexander Unnervik",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10231"
  },
  {
    "id": "arXiv:2208.10233",
    "title": "Proceedings of the 20th International Overture Workshop",
    "abstract": "This volume contains the papers presented at the 20th International Overture\nWorkshop, which was held in an hybrid format: online and physically at Aarhus,\nDenmark on 05th July 2022. This event was the latest in a series of workshops\naround the Vienna Development Method (VDM), the open-source project Overture,\nand related tools and formalisms. VDM is one of the longest established formal\nmethods for systems development. A lively community of researchers and\npractitioners has grown up in academia and industry around the modelling\nlanguages (VDM-SL, VDM++, VDM-RT, CML) and tools (VDMTools, Overture, VDM\nVSCode extension, Crescendo, Symphony, the INTO-CPS chain, and ViennaTalk).\nTogether, these provide a platform for work on modelling and analysis\ntechnology that includes static and dynamic analysis, test generation,\nexecution support, and model checking. This workshop provided updates on the\nemerging technology of VDM/Overture, including collaboration infrastructure,\ncollaborative modelling and co-simulation for Cyber-Physical Systems.",
    "descriptor": "",
    "authors": [
      "Hugo Daniel Macedo",
      "Ken Pierce"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.10233"
  },
  {
    "id": "arXiv:2208.10234",
    "title": "Time Encoding via Unlimited Sampling: Theory, Algorithms and Hardware  Validation",
    "abstract": "An alternative to conventional uniform sampling is that of time encoding,\nwhich converts continuous-time signals into streams of trigger times. This\ngives rise to Event-Driven Sampling (EDS) models. The data-driven nature of EDS\nacquisition is advantageous in terms of power consumption and time resolution\nand is inspired by the information representation in biological nervous\nsystems. If an analog signal is outside a predefined dynamic range, then EDS\ngenerates a low density of trigger times, which in turn leads to recovery\ndistortion due to aliasing. In this paper, inspired by the Unlimited Sensing\nFramework (USF), we propose a new EDS architecture that incorporates a modulo\nnonlinearity prior to acquisition that we refer to as the modulo EDS or MEDS.\nIn MEDS, the modulo nonlinearity folds high dynamic range inputs into low\ndynamic range amplitudes, thus avoiding recovery distortion. In particular, we\nconsider the asynchronous sigma-delta modulator (ASDM), previously used for low\npower analog-to-digital conversion. This novel MEDS based acquisition is\nenabled by a recent generalization of the modulo nonlinearity called\nmodulo-hysteresis. We design a mathematically guaranteed recovery algorithm for\nbandlimited inputs based on a sampling rate criterion and provide\nreconstruction error bounds. We go beyond numerical experiments and also\nprovide a first hardware validation of our approach, thus bridging the gap\nbetween theory and practice, while corroborating the conceptual underpinnings\nof our work.",
    "descriptor": "\nComments: 27 pgs, 11 figures, IEEE Trans. Sig. Proc., accepted with minor revisions\n",
    "authors": [
      "Dorian Florescu",
      "Ayush Bhandari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.10234"
  },
  {
    "id": "arXiv:2208.10238",
    "title": "Learning Branched Fusion and Orthogonal Projection for Face-Voice  Association",
    "abstract": "Recent years have seen an increased interest in establishing association\nbetween faces and voices of celebrities leveraging audio-visual information\nfrom YouTube. Prior works adopt metric learning methods to learn an embedding\nspace that is amenable for associated matching and verification tasks. Albeit\nshowing some progress, such formulations are, however, restrictive due to\ndependency on distance-dependent margin parameter, poor run-time training\ncomplexity, and reliance on carefully crafted negative mining procedures. In\nthis work, we hypothesize that an enriched representation coupled with an\neffective yet efficient supervision is important towards realizing a\ndiscriminative joint embedding space for face-voice association tasks. To this\nend, we propose a light-weight, plug-and-play mechanism that exploits the\ncomplementary cues in both modalities to form enriched fused embeddings and\nclusters them based on their identity labels via orthogonality constraints. We\ncoin our proposed mechanism as fusion and orthogonal projection (FOP) and\ninstantiate in a two-stream network. The overall resulting framework is\nevaluated on VoxCeleb1 and MAV-Celeb datasets with a multitude of tasks,\nincluding cross-modal verification and matching. Results reveal that our method\nperforms favourably against the current state-of-the-art methods and our\nproposed formulation of supervision is more effective and efficient than the\nones employed by the contemporary methods. In addition, we leverage cross-modal\nverification and matching tasks to analyze the impact of multiple languages on\nface-voice association. Code is available:\n\\url{https://github.com/msaadsaeed/FOP}",
    "descriptor": "\nComments: Submitted: IEEE Transactions on Multimedia. arXiv admin note: substantial text overlap with arXiv:2112.10483\n",
    "authors": [
      "Muhammad Saad Saeed",
      "Shah Nawaz",
      "Muhammad Haris Khan",
      "Sajid Javed",
      "Muhammad Haroon Yousaf",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10238"
  },
  {
    "id": "arXiv:2208.10240",
    "title": "A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data  for Interpretable In-Hospital Mortality Prediction",
    "abstract": "Deep-learning-based clinical decision support using structured electronic\nhealth records (EHR) has been an active research area for predicting risks of\nmortality and diseases. Meanwhile, large amounts of narrative clinical notes\nprovide complementary information, but are often not integrated into predictive\nmodels. In this paper, we provide a novel multimodal transformer to fuse\nclinical notes and structured EHR data for better prediction of in-hospital\nmortality. To improve interpretability, we propose an integrated gradients (IG)\nmethod to select important words in clinical notes and discover the critical\nstructured EHR features with Shapley values. These important words and clinical\nfeatures are visualized to assist with interpretation of the prediction\noutcomes. We also investigate the significance of domain adaptive pretraining\nand task adaptive fine-tuning on the Clinical BERT, which is used to learn the\nrepresentations of clinical notes. Experiments demonstrated that our model\noutperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).",
    "descriptor": "",
    "authors": [
      "Weimin Lyu",
      "Xinyu Dong",
      "Rachel Wong",
      "Songzhu Zheng",
      "Kayley Abell-Hart",
      "Fusheng Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10240"
  },
  {
    "id": "arXiv:2208.10241",
    "title": "SciAnnotate: A Tool for Integrating Weak Labeling Sources for Sequence  Labeling",
    "abstract": "Weak labeling is a popular weak supervision strategy for Named Entity\nRecognition (NER) tasks, with the goal of reducing the necessity for\nhand-crafted annotations. Although there are numerous remarkable annotation\ntools for NER labeling, the subject of integrating weak labeling sources is\nstill unexplored. We introduce a web-based tool for text annotation called\nSciAnnotate, which stands for scientific annotation tool. Compared to\nfrequently used text annotation tools, our annotation tool allows for the\ndevelopment of weak labels in addition to providing a manual annotation\nexperience. Our tool provides users with multiple user-friendly interfaces for\ncreating weak labels. SciAnnotate additionally allows users to incorporate\ntheir own language models and visualize the output of their model for\nevaluation. In this study, we take multi-source weak label denoising as an\nexample, we utilized a Bertifying Conditional Hidden Markov Model to denoise\nthe weak label generated by our tool. We also evaluate our annotation tool\nagainst the dataset provided by Mysore which contains 230 annotated materials\nsynthesis procedures. The results shows that a 53.7% reduction in annotation\ntime obtained AND a 1.6\\% increase in recall using weak label denoising. Online\ndemo is available at https://sciannotate.azurewebsites.net/(demo account can be\nfound in README), but we don't host a model server with it, please check the\nREADME in supplementary material for model server usage.",
    "descriptor": "",
    "authors": [
      "Mengyang Liu",
      "Haozheng Luo",
      "Leonard Thong",
      "Yinghao Li",
      "Chao Zhang",
      "Le Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10241"
  },
  {
    "id": "arXiv:2208.10244",
    "title": "Unit Testing for Concepts in Neural Networks",
    "abstract": "Many complex problems are naturally understood in terms of symbolic concepts.\nFor example, our concept of \"cat\" is related to our concepts of \"ears\" and\n\"whiskers\" in a non-arbitrary way. Fodor (1998) proposes one theory of\nconcepts, which emphasizes symbolic representations related via constituency\nstructures. Whether neural networks are consistent with such a theory is open\nfor debate. We propose unit tests for evaluating whether a system's behavior is\nconsistent with several key aspects of Fodor's criteria. Using a simple visual\nconcept learning task, we evaluate several modern neural architectures against\nthis specification. We find that models succeed on tests of groundedness,\nmodularlity, and reusability of concepts, but that important questions about\ncausality remain open. Resolving these will require new methods for analyzing\nmodels' internal states.",
    "descriptor": "\nComments: TACL, In Press. 12 Pages\n",
    "authors": [
      "Charles Lovering",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10244"
  },
  {
    "id": "arXiv:2208.10245",
    "title": "When BERT Fails -- The Limits of EHR Classification",
    "abstract": "Transformers are powerful text representation learners, useful for all kinds\nof clinical decision support tasks. Although they outperform baselines on\nreadmission prediction, they are not infallible. Here, we look into one such\nfailure case, and report patterns that lead to inferior predictive performance.",
    "descriptor": "",
    "authors": [
      "Augusto Garcia-Agundez",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10245"
  },
  {
    "id": "arXiv:2208.10246",
    "title": "SDBERT: SparseDistilBERT, a faster and smaller BERT model",
    "abstract": "In this work we introduce a new transformer architecture called\nSparseDistilBERT (SDBERT), which is a combination of sparse attention and\nknowledge distillantion (KD). We implemented sparse attention mechanism to\nreduce quadratic dependency on input length to linear. In addition to reducing\ncomputational complexity of the model, we used knowledge distillation (KD). We\nwere able to reduce the size of BERT model by 60% while retaining 97%\nperformance and it only took 40% of time to train.",
    "descriptor": "",
    "authors": [
      "Devaraju Vinoda",
      "Pawan Kumar Yadav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10246"
  },
  {
    "id": "arXiv:2208.10247",
    "title": "Generalized Attention Mechanism and Relative Position for Transformer",
    "abstract": "In this paper, we propose generalized attention mechanism (GAM) by first\nsuggesting a new interpretation for self-attention mechanism of Vaswani et al.\n. Following the interpretation, we provide description for different variants\nof attention mechanism which together form GAM. Further, we propose a new\nrelative position representation within the framework of GAM. This\nrepresentation can be easily utilized for cases in which elements next to each\nother in input sequence can be at random locations in actual dataset/corpus.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "R. V. R. Pandya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10247"
  },
  {
    "id": "arXiv:2208.10248",
    "title": "Composing RNNs and FSTs for Small Data: Recovering Missing Characters in  Old Hawaiian Text",
    "abstract": "In contrast to the older writing system of the 19th century, modern Hawaiian\northography employs characters for long vowels and glottal stops. These extra\ncharacters account for about one-third of the phonemes in Hawaiian, so\nincluding them makes a big difference to reading comprehension and\npronunciation. However, transliterating between older and newer texts is a\nlaborious task when performed manually. We introduce two related methods to\nhelp solve this transliteration problem automatically, given that there were\nnot enough data to train an end-to-end deep learning model. One method is\nimplemented, end-to-end, using finite state transducers (FSTs). The other is a\nhybrid deep learning approach which approximately composes an FST with a\nrecurrent neural network (RNN). We find that the hybrid approach outperforms\nthe end-to-end FST by partitioning the original problem into one part that can\nbe modelled by hand, using an FST, and into another part, which is easily\nsolved by an RNN trained on the available data.",
    "descriptor": "\nComments: This paper originally appeared in a NeurIPS Workshop in 2018: IRASL - Interpretability and Robustness in Audio, Speech, and Language. It builds on a shorter paper that appeared in the Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP). See acknowledgements for details\n",
    "authors": [
      "Oiwi Parker Jones",
      "Brendan Shillingford"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10248"
  },
  {
    "id": "arXiv:2208.10249",
    "title": "Prediction of User Request and Complaint in Spoken Customer-Agent  Conversations",
    "abstract": "We present the corpus called HealthCall. This was recorded in real-life\nconditions in the call center of Malakoff Humanis. It includes two separate\naudio channels, the first one for the customer and the second one for the\nagent. Each conversation was anonymized respecting the General Data Protection\nRegulation. This corpus includes a transcription of the spoken conversations\nand was divided into two sets: Train and Devel sets. Two important customer\nrelationship management tasks were assessed on the HealthCall corpus: Automatic\nprediction of type of user requests and complaints detection. For this purpose,\nwe have investigated 14 feature sets: 6 linguistic feature sets, 6 audio\nfeature sets and 2 vocal interaction feature sets. We have used Bidirectional\nEncoder Representation from Transformers models for the linguistic features,\nopenSMILE and Wav2Vec 2.0 for the audio features. The vocal interaction feature\nsets were designed and developed from Turn Takings. The results show that the\nlinguistic features always give the best results (91.2% for the Request task\nand 70.3% for the Complaint task). The Wav2Vec 2.0 features seem more suitable\nfor these two tasks than the ComPaRe16 features. Vocal interaction features\noutperformed ComPaRe16 features on Complaint task with a 57% rate achieved with\nonly six features.",
    "descriptor": "\nComments: 5 pages, 1 figure, 4 tables\n",
    "authors": [
      "Nikola Lackovic",
      "Claude Montaci\u00e9",
      "Gauthier Lalande",
      "Marie-Jos\u00e9 Caraty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10249"
  },
  {
    "id": "arXiv:2208.10250",
    "title": "Multi-Task Learning for Depression Detection in Dialogs",
    "abstract": "Depression is a serious mental illness that impacts the way people\ncommunicate, especially through their emotions, and, allegedly, the way they\ninteract with others. This work examines depression signals in dialogs, a less\nstudied setting that suffers from data sparsity. We hypothesize that depression\nand emotion can inform each other, and we propose to explore the influence of\ndialog structure through topic and dialog act prediction. We investigate a\nMulti-Task Learning (MTL) approach, where all tasks mentioned above are learned\njointly with dialog-tailored hierarchical modeling. We experiment on the DAIC\nand DailyDialog corpora-both contain dialogs in English-and show important\nimprovements over state-ofthe-art on depression detection (at best 70.6% F 1),\nwhich demonstrates the correlation of depression with emotion and dialog\norganization and the power of MTL to leverage information from different\nsources.",
    "descriptor": "",
    "authors": [
      "Chuyuan Li",
      "Chlo\u00e9 Braud",
      "Maxime Amblard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10250"
  },
  {
    "id": "arXiv:2208.10251",
    "title": "Rethinking Textual Adversarial Defense for Pre-trained Language Models",
    "abstract": "Although pre-trained language models (PrLMs) have achieved significant\nsuccess, recent studies demonstrate that PrLMs are vulnerable to adversarial\nattacks. By generating adversarial examples with slight perturbations on\ndifferent levels (sentence / word / character), adversarial attacks can fool\nPrLMs to generate incorrect predictions, which questions the robustness of\nPrLMs. However, we find that most existing textual adversarial examples are\nunnatural, which can be easily distinguished by both human and machine. Based\non a general anomaly detector, we propose a novel metric (Degree of Anomaly) as\na constraint to enable current adversarial attack approaches to generate more\nnatural and imperceptible adversarial examples. Under this new constraint, the\nsuccess rate of existing attacks drastically decreases, which reveals that the\nrobustness of PrLMs is not as fragile as they claimed. In addition, we find\nthat four types of randomization can invalidate a large portion of textual\nadversarial examples. Based on anomaly detector and randomization, we design a\nuniversal defense framework, which is among the first to perform textual\nadversarial defense without knowing the specific attack. Empirical results show\nthat our universal defense framework achieves comparable or even higher\nafter-attack accuracy with other specific defenses, while preserving higher\noriginal accuracy at the same time. Our work discloses the essence of textual\nadversarial attacks, and indicates that (1) further works of adversarial\nattacks should focus more on how to overcome the detection and resist the\nrandomization, otherwise their adversarial examples would be easily detected\nand invalidated; and (2) compared with the unnatural and perceptible\nadversarial examples, it is those undetectable adversarial examples that pose\nreal risks for PrLMs and require more attention for future robustness-enhancing\nstrategies.",
    "descriptor": "",
    "authors": [
      "Jiayi Wang",
      "Rongzhou Bao",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10251"
  },
  {
    "id": "arXiv:2208.10252",
    "title": "An Exploratory Study of Tweets about the SARS-CoV-2 Omicron Variant:  Insights from Sentiment Analysis, Language Interpretation, Source Tracking,  Type Classification, and Embedded URL Detection",
    "abstract": "This paper presents the findings of an exploratory study on the continuously\ngenerating Big Data on Twitter related to the sharing of information, news,\nviews, opinions, ideas, feedback, and experiences about the COVID-19 pandemic,\nwith a specific focus on the Omicron variant, which is the globally dominant\nvariant of SARS-CoV-2 at this time. A total of 12028 tweets about the Omicron\nvariant were studied, and the specific characteristics of tweets that were\nanalyzed include - sentiment, language, source, type, and embedded URLs. The\nfindings of this study are manifold. First, from sentiment analysis, it was\nobserved that 50.5% of tweets had a neutral emotion. The other emotions - bad,\ngood, terrible, and great were found in 15.6%, 14.0%, 12.5%, and 7.5% of the\ntweets, respectively. Second, the findings of language interpretation showed\nthat 65.9% of the tweets were posted in English. It was followed by Spanish,\nFrench, Italian, and other languages. Third, the findings from source tracking\nshowed that Twitter for Android was associated with 35.2% of tweets. It was\nfollowed by Twitter Web App, Twitter for iPhone, Twitter for iPad, and other\nsources. Fourth, studying the type of tweets revealed that retweets accounted\nfor 60.8% of the tweets, it was followed by original tweets and replies that\naccounted for 19.8% and 19.4% of the tweets, respectively. Fifth, in terms of\nembedded URL analysis, the most common domain embedded in the tweets was found\nto be twitter.com, which was followed by biorxiv.org, nature.com, and other\ndomains. Finally, to support similar research in this field, we have developed\na Twitter dataset that comprises more than 500,000 tweets about the SARS-CoV-2\nomicron variant since the first detected case of this variant on November 24,\n2021.",
    "descriptor": "",
    "authors": [
      "Nirmalya Thakur",
      "Chia Y. Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.10252"
  },
  {
    "id": "arXiv:2208.10253",
    "title": "The Economics of Privacy and Utility: Investment Strategies",
    "abstract": "The inevitable leakage of privacy as a result of unrestrained disclosure of\npersonal information has motivated extensive research on robust\nprivacy-preserving mechanisms. However, existing research is mostly limited to\nsolving the problem in a static setting with disregard for the privacy leakage\nover time. Unfortunately, this treatment of privacy is insufficient in\npractical settings where users continuously disclose their personal information\nover time resulting in an accumulated leakage of the users' sensitive\ninformation. In this paper, we consider privacy leakage over a finite time\nhorizon and investigate optimal strategies to maximize the utility of the\ndisclosed data while limiting the finite-horizon privacy leakage. We consider a\nsimple privacy mechanism that involves compressing the user's data before each\ndisclosure to meet the desired constraint on future privacy. We further\nmotivate several algorithms to optimize the dynamic privacy-utility tradeoff\nand evaluate their performance via extensive synthetic performance tests.",
    "descriptor": "",
    "authors": [
      "Chandra Sharma",
      "George Amariucai",
      "Shuangqing Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10253"
  },
  {
    "id": "arXiv:2208.10255",
    "title": "On the non-efficient PAC learnability of acyclic conjunctive queries",
    "abstract": "This note serves three purposes: (i) we provide a self-contained exposition\nof the fact that conjunctive queries are not efficiently learnable in the\nProbably-Approximately-Correct (PAC) model, paying clear attention to the\ncomplicating fact that this concept class lacks the polynomial-size fitting\nproperty, a property that is tacitly assumed in much of the computational\nlearning theory literature; (ii) we establish a strong negative PAC\nlearnability result that applies to many restricted classes of conjunctive\nqueries (CQs), including acyclic CQs for a wide range of notions of\n\"acyclicity\"; (iii) we show that CQs are efficiently PAC learnable with\nmembership queries.",
    "descriptor": "",
    "authors": [
      "Balder ten Cate",
      "Maurice Funk",
      "Jean Christoph Jung",
      "Carsten Lutz"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10255"
  },
  {
    "id": "arXiv:2208.10256",
    "title": "Information-Theoretic Equivalence of Entropic Multi-Marginal Optimal  Transport: a Theory for Multi-Agent Communication",
    "abstract": "In this paper, we propose our information-theoretic equivalence of entropic\nmulti-marginal optimal transport (MOT). This equivalence can be easily reduced\nto the case of entropic optimal transport (OT). Because OT is widely used to\ncompare differences between knowledge or beliefs, we apply this result to the\ncommunication between agents with different beliefs. Our results formally prove\nthe statement that entropic OT is information-theoretically optimal given by\nWang et al. [2020] and generalize it to the multi-agent case. We believe that\nour work can shed light on OT theory in future multi-agent teaming systems.",
    "descriptor": "\nComments: This work is the unfinished doctoral thesis of Mr. Shuchan Wang at Sorbonne University and EURECOM. Mr. Wang has to leave EURECOM and is therefore unable to continue his study\n",
    "authors": [
      "Shuchan Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10256"
  },
  {
    "id": "arXiv:2208.10259",
    "title": "Meta-Learning Online Control for Linear Dynamical Systems",
    "abstract": "In this paper, we consider the problem of finding a meta-learning online\ncontrol algorithm that can learn across the tasks when faced with a sequence of\n$N$ (similar) control tasks. Each task involves controlling a linear dynamical\nsystem for a finite horizon of $T$ time steps. The cost function and system\nnoise at each time step are adversarial and unknown to the controller before\ntaking the control action. Meta-learning is a broad approach where the goal is\nto prescribe an online policy for any new unseen task exploiting the\ninformation from other tasks and the similarity between the tasks. We propose a\nmeta-learning online control algorithm for the control setting and characterize\nits performance by \\textit{meta-regret}, the average cumulative regret across\nthe tasks. We show that when the number of tasks are sufficiently large, our\nproposed approach achieves a meta-regret that is smaller by a factor $D/D^{*}$\ncompared to an independent-learning online control algorithm which does not\nperform learning across the tasks, where $D$ is a problem constant and $D^{*}$\nis a scalar that decreases with increase in the similarity between tasks. Thus,\nwhen the sequence of tasks are similar the regret of the proposed meta-learning\nonline control is significantly lower than that of the naive approaches without\nmeta-learning. We also present experiment results to demonstrate the superior\nperformance achieved by our meta-learning algorithm.",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Dileep Kalathil",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10259"
  },
  {
    "id": "arXiv:2208.10264",
    "title": "Using Large Language Models to Simulate Multiple Humans",
    "abstract": "We propose a method for using a large language model, such as GPT-3, to\nsimulate responses of different humans in a given context. We test our method\nby attempting to reproduce well-established economic, psycholinguistic, and\nsocial experiments. The method requires prompt templates for each experiment.\nSimulations are run by varying the (hypothetical) subject details such as name\nand analyzing the text generated by the language model. We validate our\nmethodology by using GPT-3, to show that it is possible to simulate responses\nof different people and that their responses are consistent with prior human\nstudies from the literature. We find that the distributions generated by larger\nlanguage models better align with prior experimental results, suggesting a\ntrend that future language models may be used for even more faithful\nsimulations of human responses. Our use of a language model for simulation is\ncontrasted with anthropomorphic views of a language model as having its own\nbehavior.",
    "descriptor": "",
    "authors": [
      "Gati Aher",
      "Rosa I. Arriaga",
      "Adam Tauman Kalai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10264"
  },
  {
    "id": "arXiv:2208.10265",
    "title": "A semantic web approach to uplift decentralized household energy data",
    "abstract": "In a decentralized household energy system comprised of various devices such\nas home appliances, electric vehicles, and solar panels, end-users are able to\ndig deeper into the system's details and further achieve energy sustainability\nif they are presented with data on the electric energy consumption and\nproduction at the granularity of the device. However, many databases in this\nfield are siloed from other domains, including solely information pertaining to\nenergy. This may result in the loss of information (\\textit{e.g.} weather) on\neach device's energy use. Meanwhile, a large number of these datasets have been\nextensively used in computational modeling techniques such as machine learning\nmodels. While such computational approaches achieve great accuracy and\nperformance by concentrating only on a local view of datasets, model\nreliability cannot be guaranteed since such models are very vulnerable to data\ninput fluctuations when information omission is taken into account. This\narticle tackles the data isolation issue in the field of smart energy systems\nby examining Semantic Web methods on top of a household energy system. We offer\nan ontology-based approach for managing decentralized data at the device-level\nresolution in a system. As a consequence, the scope of the data associated with\neach device may easily be expanded in an interoperable manner throughout the\nWeb, and additional information, such as weather, can be obtained from the Web,\nprovided that the data is organized according to W3C standards.",
    "descriptor": "\nComments: Published in Sustainable Energy, Grids and Networks (SEGAN)\n",
    "authors": [
      "Jiantao Wu",
      "Fabrizio Orlandi",
      "Tarek AlSkaif",
      "Declan O'Sullivan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10265"
  },
  {
    "id": "arXiv:2208.10267",
    "title": "Construction of binary linear constant weight codes by symmetric  differences of supports",
    "abstract": "We give a construction for the binary linear constant weight codes by using\nthe symmetric differences of the supports of the codewords. Moreover, we give a\ncharacterization for the constant weight codes with given parameters in terms\nof supports of the codewords. We also prove that the constant weight codes with\nthe same parameters (length, dimension, weight) are permutation equivalent.\nLastly, we prove that the order of the permutation automorphism group of a\ngiven constant weight code of the dimension $\\ge 2$ is a multiple of six.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Fatma Altunbulak Aksu",
      "Murat Altunbulak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.10267"
  },
  {
    "id": "arXiv:2208.10269",
    "title": "To EVM or Not to EVM: Blockchain Compatibility and Network Effects",
    "abstract": "We study the competition between blockchains in a \\emph{multi-chain}\nenvironment, where a dominant EVM-compatible blockchain (e.g., Ethereum)\nco-exists with an alternative EVM-compatible (e.g., Avalanche) and an\nEVM-incompatible (e.g., Algorand) blockchain. While EVM compatibility allows\nexisting Ethereum users and developers to migrate more easily over to the\nalternative layer-1, EVM incompatibility might allow the firms to build more\nloyal and ``sticky'' user base, and in turn a more robust ecosystem. As such,\nthe choice to be EVM-compatible is not merely a technological decision, but\nalso an important strategic decision. In this paper, we develop a game\ntheoretic model to study this competitive dynamic, and find that at\nequilibrium, new entrants/developers tend to adopt the dominant blockchain. To\navoid adoption failure, the alternative blockchains have to either (1) directly\nsubsidize the new entrant firms or (2) offer better features, which in practice\ncan take form in lower transaction costs, faster finality, or larger network\neffects. We find that it is easier for EVM-compatible blockchains to attract\nusers through direct subsidy, while it is more efficient for EVM-incompatible\nblockchains to attract users through offering better features/products.",
    "descriptor": "",
    "authors": [
      "Ruizhe Jia",
      "Steven Yin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.10269"
  },
  {
    "id": "arXiv:2208.10270",
    "title": "To show or not to show: Redacting sensitive text from videos of  electronic displays",
    "abstract": "With the increasing prevalence of video recordings there is a growing need\nfor tools that can maintain the privacy of those recorded. In this paper, we\ndefine an approach for redacting personally identifiable text from videos using\na combination of optical character recognition (OCR) and natural language\nprocessing (NLP) techniques. We examine the relative performance of this\napproach when used with different OCR models, specifically Tesseract and the\nOCR system from Google Cloud Vision (GCV). For the proposed approach the\nperformance of GCV, in both accuracy and speed, is significantly higher than\nTesseract. Finally, we explore the advantages and disadvantages of both models\nin real-world applications.",
    "descriptor": "",
    "authors": [
      "Abhishek Mukhopadhyay",
      "Shubham Agarwal",
      "Patrick Dylan Zwick",
      "Pradipta Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10270"
  },
  {
    "id": "arXiv:2208.10271",
    "title": "Agent-based Model of Initial Token Allocations: Evaluating Wealth  Concentration in Fair Launches",
    "abstract": "With advancements in distributed ledger technologies and smart contracts,\ntokenized voting rights gained prominence within Decentralized Finance (DeFi).\nVoting rights tokens (aka. governance tokens) are fungible tokens that grant\nindividual holders the right to vote upon the fate of a project. The motivation\nbehind these tokens is to achieve decentral control. Because the initial\nallocations of these tokens is often un-democratic, the DeFi project Yearn\nFinance experimented with a fair launch allocation where no tokens are\npre-mined and all participants have an equal opportunity to receive them.\nRegardless, research on voting rights tokens highlights the formation of\noligarchies over time. The hypothesis is that the tokens' tradability is the\ncause of concentration. To examine this proposition, this paper uses an\nAgent-based Model to simulate and analyze the concentration of voting rights\ntokens post fair launch under different trading modalities. It serves to\nexamine three distinct token allocation scenarios considered as fair. The\nresults show that regardless of the allocation, concentration persistently\noccurs. It confirms the hypothesis that the disease is endogenous: the cause of\nconcentration is the tokens tradablility. The findings inform theoretical\nunderstandings and practical implications for on-chain governance mediated by\ntokens.",
    "descriptor": "",
    "authors": [
      "Joaquin Delgado Fernandez",
      "Tom Barbereau",
      "Orestis Papageorgiou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.10271"
  },
  {
    "id": "arXiv:2208.10273",
    "title": "Long-Short History of Gradients is All You Need: Detecting Malicious and  Unreliable Clients in Federated Learning",
    "abstract": "Federated learning offers a framework of training a machine learning model in\na distributed fashion while preserving privacy of the participants. As the\nserver cannot govern the clients' actions, nefarious clients may attack the\nglobal model by sending malicious local gradients. In the meantime, there could\nalso be unreliable clients who are benign but each has a portion of low-quality\ntraining data (e.g., blur or low-resolution images), thus may appearing similar\nas malicious clients. Therefore, a defense mechanism will need to perform a\nthree-fold differentiation which is much more challenging than the conventional\n(two-fold) case. This paper introduces MUD-HoG, a novel defense algorithm that\naddresses this challenge in federated learning using long-short history of\ngradients, and treats the detected malicious and unreliable clients\ndifferently. Not only this, but we can also distinguish between targeted and\nuntargeted attacks among malicious clients, unlike most prior works which only\nconsider one type of the attacks. Specifically, we take into account\nsign-flipping, additive-noise, label-flipping, and multi-label-flipping\nattacks, under a non-IID setting. We evaluate MUD-HoG with six state-of-the-art\nmethods on two datasets. The results show that MUD-HoG outperforms all of them\nin terms of accuracy as well as precision and recall, in the presence of a\nmixture of multiple (four) types of attackers as well as unreliable clients.\nMoreover, unlike most prior works which can only tolerate a low population of\nharmful users, MUD-HoG can work with and successfully detect a wide range of\nmalicious and unreliable clients - up to 47.5% and 10%, respectively, of the\ntotal population. Our code is open-sourced at\nhttps://github.com/LabSAINT/MUD-HoG_Federated_Learning.",
    "descriptor": "\nComments: European Symposium on Research in Computer Security (ESORICS) 2022\n",
    "authors": [
      "Ashish Gupta",
      "Tie Luo",
      "Mao V. Ngo",
      "Sajal K. Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10273"
  },
  {
    "id": "arXiv:2208.10276",
    "title": "An Input-Aware Mimic Defense Theory and its Practice",
    "abstract": "The current security problems in cyberspace are characterized by strong and\ncomplex threats. Defenders face numerous problems such as lack of prior\nknowledge, various threats, and unknown vulnerabilities, which urgently need\nnew fundamental theories to support. To address these issues, this article\nproposes a generic theoretical model for cyberspace defense and a new mimic\ndefense framework, that is, Spatiotemporally heterogeneous, Input aware, and\nDynamically updated Mimic Defense (SIDMD). We make the following contributions:\n(1) We first redefine vulnerabilities from the input space perspective to\nnormalize the diverse cyberspace security problem. (2) We propose a novel\nunknown vulnerability discovery method and a dynamic scheduling strategy\nconsidering temporal and spatial dimensions without prior knowledge.\nTheoretical analysis and experimental results show that SIDMD has the best\nsecurity performance in complex attack scenarios, and the probability of\nsuccessful attacks is greatly reduced compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Jiale Fu",
      "Yali Yuan",
      "Jiajun He",
      "Sichu Liang",
      "Zhe Huang",
      "Hongyu Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.10276"
  },
  {
    "id": "arXiv:2208.10278",
    "title": "Practical Vertical Federated Learning with Unsupervised Representation  Learning",
    "abstract": "As societal concerns on data privacy recently increase, we have witnessed\ndata silos among multiple parties in various applications. Federated learning\nemerges as a new learning paradigm that enables multiple parties to\ncollaboratively train a machine learning model without sharing their raw data.\nVertical federated learning, where each party owns different features of the\nsame set of samples and only a single party has the label, is an important and\nchallenging topic in federated learning. Communication costs among different\nparties have been a major hurdle for practical vertical learning systems. In\nthis paper, we propose a novel communication-efficient vertical federated\nlearning algorithm named FedOnce, which requires only one-shot communication\namong parties. To improve model accuracy and provide privacy guarantee, FedOnce\nfeatures unsupervised learning representations in the federated setting and\nprivacy-preserving techniques based on moments accountant. The comprehensive\nexperiments on 10 datasets demonstrate that FedOnce achieves close performance\ncompared to state-of-the-art vertical federated learning algorithms with much\nlower communication costs. Meanwhile, our privacy-preserving technique\nsignificantly outperforms the state-of-the-art approaches under the same\nprivacy budget.",
    "descriptor": "",
    "authors": [
      "Zhaomin Wu",
      "Qinbin Li",
      "Bingsheng He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10278"
  },
  {
    "id": "arXiv:2208.10279",
    "title": "Defensive Distillation based Adversarial Attacks Mitigation Method for  Channel Estimation using Deep Learning Models in Next-Generation Wireless  Networks",
    "abstract": "Future wireless networks (5G and beyond) are the vision of forthcoming\ncellular systems, connecting billions of devices and people together. In the\nlast decades, cellular networks have been dramatically growth with advanced\ntelecommunication technologies for high-speed data transmission, high cell\ncapacity, and low latency. The main goal of those technologies is to support a\nwide range of new applications, such as virtual reality, metaverse, telehealth,\nonline education, autonomous and flying vehicles, smart cities, smart grids,\nadvanced manufacturing, and many more. The key motivation of NextG networks is\nto meet the high demand for those applications by improving and optimizing\nnetwork functions. Artificial Intelligence (AI) has a high potential to achieve\nthese requirements by being integrated in applications throughout all layers of\nthe network. However, the security concerns on network functions of NextG using\nAI-based models, i.e., model poising, have not been investigated deeply.\nTherefore, it needs to design efficient mitigation techniques and secure\nsolutions for NextG networks using AI-based methods. This paper proposes a\ncomprehensive vulnerability analysis of deep learning (DL)-based channel\nestimation models trained with the dataset obtained from MATLAB's 5G toolbox\nfor adversarial attacks and defensive distillation-based mitigation methods.\nThe adversarial attacks produce faulty results by manipulating trained DL-based\nmodels for channel estimation in NextG networks, while making models more\nrobust against any attacks through mitigation methods. This paper also presents\nthe performance of the proposed defensive distillation mitigation method for\neach adversarial attack against the channel estimation model. The results\nindicated that the proposed mitigation method can defend the DL-based channel\nestimation models against adversarial attacks in NextG networks.",
    "descriptor": "\nComments: 13 Pages\n",
    "authors": [
      "Ferhat Ozgur Catak",
      "Murat Kuzlu",
      "Evren Catak",
      "Umit Cali",
      "Ozgur Guler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10279"
  },
  {
    "id": "arXiv:2208.10280",
    "title": "A Twitter-Driven Deep Learning Mechanism for the Determination of  Vehicle Hijacking Spots in Cities",
    "abstract": "Vehicle hijacking is one of the leading crimes in many cities. For instance,\nin South Africa, drivers must constantly remain vigilant on the road in order\nto ensure that they do not become hijacking victims. This work is aimed at\ndeveloping a map depicting hijacking spots in a city by using Twitter data.\nTweets, which include the keyword \"hijacking\", are obtained in a designated\ncity of Cape Town, in this work. In order to extract relevant tweets, these\ntweets are analyzed by using the following machine learning techniques: 1) a\nMulti-layer Feed-forward Neural Network (MLFNN); 2) Convolutional Neural\nNetwork; and Bidirectional Encoder Representations from Transformers (BERT).\nThrough training and testing, CNN achieved an accuracy of 99.66%, while MLFNN\nand BERT achieve accuracies of 98.99% and 73.99% respectively. In terms of\nRecall, Precision and F1-score, CNN also achieved the best results. Therefore,\nCNN was used for the identification of relevant tweets. The relevant reports\nthat it generates are visually presented on a points map of the City of Cape\nTown. This work used a small dataset of 426 tweets. In future, the use of\nevolutionary computation will be explored for purposes of optimizing the deep\nlearning models. A mobile application is under development to make this\ninformation usable by the general public.",
    "descriptor": "",
    "authors": [
      "Taahir Aiyoob Patel",
      "Clement N. Nyirenda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10280"
  },
  {
    "id": "arXiv:2208.10281",
    "title": "Language-independence of DisCoCirc's Text Circuits: English and Urdu",
    "abstract": "DisCoCirc is a newly proposed framework for representing the grammar and\nsemantics of texts using compositional, generative circuits. While it\nconstitutes a development of the Categorical Distributional Compositional\n(DisCoCat) framework, it exposes radically new features. In particular, [14]\nsuggested that DisCoCirc goes some way toward eliminating grammatical\ndifferences between languages. In this paper we provide a sketch that this is\nindeed the case for restricted fragments of English and Urdu. We first develop\nDisCoCirc for a fragment of Urdu, as it was done for English in [14]. There is\na simple translation from English grammar to Urdu grammar, and vice versa. We\nthen show that differences in grammatical structure between English and Urdu -\nprimarily relating to the ordering of words and phrases - vanish when passing\nto DisCoCirc circuits.",
    "descriptor": "\nComments: In Proceedings E2ECOMPVEC, arXiv:2208.05313\n",
    "authors": [
      "Muhammad Hamza Waseem",
      "Jonathon Liu",
      "Vincent Wang-Ma\u015bcianica",
      "Bob Coecke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10281"
  },
  {
    "id": "arXiv:2208.10282",
    "title": "LogStamp: Automatic Online Log Parsing Based on Sequence Labelling",
    "abstract": "Logs are one of the most critical data for service management. It contains\nrich runtime information for both services and users. Since size of logs are\noften enormous in size and have free handwritten constructions, a typical\nlog-based analysis needs to parse logs into structured format first. However,\nwe observe that most existing log parsing methods cannot parse logs online,\nwhich is essential for online services. In this paper, we present an automatic\nonline log parsing method, name as LogStamp. We extensively evaluate LogStamp\non five public datasets to demonstrate the effectiveness of our proposed\nmethod. The experiments show that our proposed method can achieve high accuracy\nwith only a small portion of the training set. For example, it can achieve an\naverage accuracy of 0.956 when using only 10% of the data training.",
    "descriptor": "",
    "authors": [
      "Shimin Tao",
      "Weibin Meng",
      "Yimeng Chen",
      "Yichen Zhu",
      "Ying Liu Chunning Du",
      "Tao Han",
      "Yongpeng Zhao",
      "Xiangguang Wang",
      "Hao Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.10282"
  },
  {
    "id": "arXiv:2208.10284",
    "title": "Contributions \u00e0 l'asservissement visuel et \u00e0 l'imagerie en  m\u00e9decine",
    "abstract": "This manuscript gives an overview of my research work carried out within the\nFEMTO-ST institute in Besan\\c{c}on, more particularly in the Automatic and\nMicro-Mechatronic Systems (AS2M) department. It is above all the result of my\n(co)-supervision of interns, PhD students and postdocs. I would like to pay\ntribute to them, for their major contribution to scientific research, here and\nelsewhere.",
    "descriptor": "\nComments: 126 pages, in French language, 100 figures, report\n",
    "authors": [
      "Brahim Tamadazte"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10284"
  },
  {
    "id": "arXiv:2208.10290",
    "title": "Deterministic Graph-Walking Program Mining",
    "abstract": "Owing to their versatility, graph structures admit representations of\nintricate relationships between the separate entities comprising the data. We\nformalise the notion of connection between two vertex sets in terms of edge and\nvertex features by introducing graph-walking programs. We give two algorithms\nfor mining of deterministic graph-walking programs that yield programs in the\norder of increasing length. These programs characterise linear long-distance\nrelationships between the given two vertex sets in the context of the whole\ngraph.",
    "descriptor": "\nComments: Paper accepted for an oral presentation at Advanced Data Mining and Applications (ADMA) 2022. 15 pages, 3 figures\n",
    "authors": [
      "Peter Belcak",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.10290"
  },
  {
    "id": "arXiv:2208.10291",
    "title": "Efficient Planning in a Compact Latent Action Space",
    "abstract": "While planning-based sequence modelling methods have shown great potential in\ncontinuous control, scaling them to high-dimensional state-action sequences\nremains an open challenge due to the high computational complexity and innate\ndifficulty of planning in high-dimensional spaces. We propose the Trajectory\nAutoencoding Planner (TAP), a planning-based sequence modelling RL method that\nscales to high state-action dimensionalities. Using a state-conditional\nVector-Quantized Variational Autoencoder (VQ-VAE), TAP models the conditional\ndistribution of the trajectories given the current state. When deployed as an\nRL agent, TAP avoids planning step-by-step in a high-dimensional continuous\naction space but instead looks for the optimal latent code sequences by beam\nsearch. Unlike $O(D^3)$ complexity of Trajectory Transformer, TAP enjoys\nconstant $O(C)$ planning computational complexity regarding state-action\ndimensionality $D$. Our empirical evaluation also shows the increasingly strong\nperformance of TAP with the growing dimensionality. For Adroit robotic hand\nmanipulation tasks with high state and action dimensionality, TAP surpasses\nexisting model-based methods, including TT, with a large margin and also beats\nstrong model-free actor-critic baselines.",
    "descriptor": "",
    "authors": [
      "Zhengyao Jiang",
      "Tianjun Zhang",
      "Michael Janner",
      "Yueying Li",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10291"
  },
  {
    "id": "arXiv:2208.10295",
    "title": "Physical LiDAR Simulation in Real-Time Engine",
    "abstract": "Designing and validating sensor applications and algorithms in simulation is\nan important step in the modern development process. Furthermore, modern\nopen-source multi-sensor simulation frameworks are moving towards the usage of\nvideo-game engines such as the Unreal Engine. Simulation of a sensor such as a\nLiDAR can prove to be difficult in such real-time software. In this paper we\npresent a GPU-accelerated simulation of LiDAR based on its physical properties\nand interaction with the environment. We provide a generation of the depth and\nintensity data based on the properties of the sensor as well as the surface\nmaterial and incidence angle at which the light beams hit the surface. It is\nvalidated against a real LiDAR sensor and shown to be accurate and precise\nalthough highly depended on the spectral data used for the material properties.",
    "descriptor": "\nComments: Accepted at IEEE Sensors 2022conference\n",
    "authors": [
      "Wouter Jansen",
      "Nico Huebel",
      "Jan Steckel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.10295"
  },
  {
    "id": "arXiv:2208.10296",
    "title": "Sequential Circuits Synthesis for Rapid Single Flux Quantum Logic Based  on Finite State Machine Decomposition",
    "abstract": "Rapid Single Flux Quantum (RSFQ) logic is a promising technology to supersede\nComplementary metal-oxide-semiconductor (CMOS) logic in some specialized areas\ndue to providing ultra-fast and energy-efficient circuits. To realize a\nlarge-scale integration design, electronic design automation (EDA) tools\nspecialized for RSFQ logic are required due to the divergences in logic type,\ntiming constraints, and circuit structure compared with CMOS logic. Logic\nsynthesis is crucial in converting behavioral circuit description into circuit\nnetlist, typically combining combinational and sequential circuit synthesis.\nFor the RSFQ logic, the sequential circuit synthesis is challenging, especially\nfor non-linear sequential blocks with feedback loops. Thus, this paper presents\na sequential circuit synthesis algorithm based on finite state machine (FSM)\ndecomposition, which ensures design functionality, lowers costs, and improves\nthe RSFQ circuit performance. Additionally, we present the synthesis processes\nof the feedback logic and the 2-bit counter to demonstrate how the proposed\nalgorithm operates, and ISCAS89 benchmark circuits reveal our method's ability\nto synthesize large-scale sequential circuits.",
    "descriptor": "",
    "authors": [
      "Shucheng Yang",
      "Xiaoping Gao",
      "Jie Ren"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.10296"
  },
  {
    "id": "arXiv:2208.10297",
    "title": "Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question  Answering",
    "abstract": "Multi-hop reasoning requires aggregating multiple documents to answer a\ncomplex question. Existing methods usually decompose the multi-hop question\ninto simpler single-hop questions to solve the problem for illustrating the\nexplainable reasoning process. However, they ignore grounding on the supporting\nfacts of each reasoning step, which tends to generate inaccurate\ndecompositions. In this paper, we propose an interpretable stepwise reasoning\nframework to incorporate both single-hop supporting sentence identification and\nsingle-hop question generation at each intermediate step, and utilize the\ninference of the current hop for the next until reasoning out the final result.\nWe employ a unified reader model for both intermediate hop reasoning and final\nhop inference and adopt joint optimization for more accurate and robust\nmulti-hop reasoning. We conduct experiments on two benchmark datasets HotpotQA\nand 2WikiMultiHopQA. The results show that our method can effectively boost\nperformance and also yields a better interpretable reasoning process without\ndecomposition supervision.",
    "descriptor": "\nComments: 11 pages, 6 figures, 6 tables, accepted as a long paper to COLING 2022\n",
    "authors": [
      "Siyuan Wang",
      "Zhongyu Wei",
      "Zhihao Fan",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10297"
  },
  {
    "id": "arXiv:2208.10298",
    "title": "Analysis of Approximate sorting in I/O model",
    "abstract": "We consider the problem of approximate sorting in I/O model. The goal of\napproximate sorting in I/O model is to find out a permutation that is as close\nas possible to the true ordering of elements in $t$ I/O operations. However,\nthe quality of approximate sorting in I/O model can not be well measured by the\nexisting metrics on permutation space. Thus, we propose a new kind of metric\nnamed External metric, which ignores the errors and dislocation that happened\nin each I/O block. We consider the \\textit{External Spearman's footrule metric}\n(short for \\textit{ESP}) (\\textit{Spearman's footrule metric} in RAM model) and\na new metric \\textit{external errors} (short for \\textit{EE}) (\\textit{errors}\nin RAM model). \\textit{ESP} shows the block dislocation distance of each\nelement and \\textit{EE} states the number of the dislocation elements in the\napproximate result. According to the rate-distortion relationship endowed by\nthese two metrics, we find the lower bound of these two metrics of the\npermutation generated by any external approximate sorting algorithm with $t$\nI/O operations. Finally, we propose a k-pass external approximate sorting\nalgorithm that is asymptotically optimal in I/O model.",
    "descriptor": "",
    "authors": [
      "Tianpeng Gao",
      "Jianzhong Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10298"
  },
  {
    "id": "arXiv:2208.10299",
    "title": "Passive and Active Acoustic Sensing for Soft Pneumatic Actuators",
    "abstract": "We propose a sensorization method for soft pneumatic actuators that uses an\nembedded microphone and speaker to measure different actuator properties. The\nphysical state of the actuator determines the specific modulation of sound as\nit travels through the structure. Using simple machine learning, we create a\ncomputational sensor that infers the corresponding state from sound recordings.\nWe demonstrate the acoustic sensor on a soft pneumatic continuum actuator and\nuse it to measure contact locations, contact forces, object materials, actuator\ninflation, and actuator temperature. We show that the sensor is reliable\n(average classification rate for six contact locations of 93%), precise (mean\nspatial accuracy of 3.7 mm), and robust against common disturbances like\nbackground noise. Finally, we compare different sounds and learning methods and\nachieve best results with 20 ms of white noise and a support vector classifier\nas the sensor model.",
    "descriptor": "\nComments: This paper is currently under review in The International Journal of Robotics Research\n",
    "authors": [
      "Vincent Wall",
      "Gabriel Z\u00f6ller",
      "Oliver Brock"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10299"
  },
  {
    "id": "arXiv:2208.10300",
    "title": "Efficient Utility Function Learning for Multi-Objective Parameter  Optimization with Prior Knowledge",
    "abstract": "The current state-of-the-art in multi-objective optimization assumes either a\ngiven utility function, learns a utility function interactively or tries to\ndetermine the complete Pareto front, requiring a post elicitation of the\npreferred result. However, result elicitation in real world problems is often\nbased on implicit and explicit expert knowledge, making it difficult to define\na utility function, whereas interactive learning or post elicitation requires\nrepeated and expensive expert involvement. To mitigate this, we learn a utility\nfunction offline, using expert knowledge by means of preference learning. In\ncontrast to other works, we do not only use (pairwise) result preferences, but\nalso coarse information about the utility function space. This enables us to\nimprove the utility function estimate, especially when using very few results.\nAdditionally, we model the occurring uncertainties in the utility function\nlearning task and propagate them through the whole optimization chain. Our\nmethod to learn a utility function eliminates the need of repeated expert\ninvolvement while still leading to high-quality results. We show the sample\nefficiency and quality gains of the proposed method in 4 domains, especially in\ncases where the surrogate utility function is not able to exactly capture the\ntrue expert utility function. We also show that to obtain good results, it is\nimportant to consider the induced uncertainties and analyze the effect of\nbiased samples, which is a common problem in real world domains.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Farha A. Khan",
      "J\u00f6rg P. Dietrich",
      "Christian Wirth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10300"
  },
  {
    "id": "arXiv:2208.10302",
    "title": "Event-Triggered Model Predictive Control with Deep Reinforcement  Learning for Autonomous Driving",
    "abstract": "Event-triggered model predictive control (eMPC) is a popular optimal control\nmethod with an aim to alleviate the computation and/or communication burden of\nMPC. However, it generally requires priori knowledge of the closed-loop system\nbehavior along with the communication characteristics for designing the\nevent-trigger policy. This paper attempts to solve this challenge by proposing\nan efficient eMPC framework and demonstrate successful implementation of this\nframework on the autonomous vehicle path following. First of all, a model-free\nreinforcement learning (RL) agent is used to learn the optimal event-trigger\npolicy without the need for a complete dynamical system and communication\nknowledge in this framework. Furthermore, techniques including prioritized\nexperience replay (PER) buffer and long-short term memory (LSTM) are employed\nto foster exploration and improve training efficiency. In this paper, we use\nthe proposed framework with three deep RL algorithms, i.e., Double Q-learning\n(DDQN), Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC), to\nsolve this problem. Experimental results show that all three deep RL-based eMPC\n(deep-RL-eMPC) can achieve better evaluation performance than the conventional\nthreshold-based and previous linear Q-based approach in the autonomous path\nfollowing. In particular, PPO-eMPC with LSTM and DDQN-eMPC with PER and LSTM\nobtains a superior balance between the closed-loop control performance and\nevent-trigger frequency. The associated code is open-sourced and available at:\nhttps://github.com/DangFengying/RL-based-event-triggered-MPC.",
    "descriptor": "",
    "authors": [
      "Fengying Dang",
      "Dong Chen",
      "Jun Chen",
      "Zhaojian Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10302"
  },
  {
    "id": "arXiv:2208.10303",
    "title": "Data-Driven Control of Distributed Event-Triggered Network Systems",
    "abstract": "The present paper deals with data-driven event-triggered control of a class\nof unknown discrete-time interconnected systems (a.k.a. network systems). To\nthis end, we start by putting forth a novel distributed event-triggering\ntransmission strategy based on periodic sampling, under which a model-based\nstability criterion for the closed-loop network system is derived, by\nleveraging a discrete-time looped-functional approach. Marrying the model-based\ncriterion with a data-driven system representation recently developed in the\nliterature, a purely data-driven stability criterion expressed in the form of\nlinear matrix inequalities (LMIs) is established. Meanwhile, the data-driven\nstability criterion suggests a means for co-designing the event-triggering\ncoefficient matrix and the feedback control gain matrix using only some offline\ncollected state-input data. Finally, numerical results corroborate the efficacy\nof the proposed distributed data-driven ETS in cutting off data transmissions\nand the co-design procedure.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Xin Wang",
      "Jian Sun",
      "Gang Wang",
      "Frank Allg\u00f6wer",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10303"
  },
  {
    "id": "arXiv:2208.10308",
    "title": "On Dimensions of Plausibility for Narrative Information Access to  Digital Libraries",
    "abstract": "Designing keyword-based access paths is a common practice in digital\nlibraries. They are easy to use and accepted by users and come with moderate\ncosts for content providers. However, users usually have to break down the\nsearch into pieces if they search for stories of interest that are more complex\nthan searching for a few keywords. After searching for every piece one by one,\ninformation must then be reassembled manually. In previous work we recommended\nnarrative information access, i.e., users can precisely state their information\nneeds as graph patterns called narratives. Then a system takes a narrative and\nsearches for evidence for each of its parts. If the whole query, i.e., every\npart, can be bound against data, the narrative is considered plausible and,\nthus, the query is answered. But is it as easy as that? In this work we perform\ncase studies to analyze the process of making a given narrative plausible.\nTherefore, we summarize conceptual problems and challenges to face. Moreover,\nwe contribute a set of dimensions that must be considered when realizing\nnarrative information access in digital libraries.",
    "descriptor": "\nComments: Accepted at TPDL2022 (9 pages)\n",
    "authors": [
      "Hermann Kroll",
      "Niklas Mainzer",
      "Wolf-Tilo Balke"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.10308"
  },
  {
    "id": "arXiv:2208.10310",
    "title": "A Novel Multi-Task Learning Approach for Context-Sensitive Compound Type  Identification in Sanskrit",
    "abstract": "The phenomenon of compounding is ubiquitous in Sanskrit. It serves for\nachieving brevity in expressing thoughts, while simultaneously enriching the\nlexical and structural formation of the language. In this work, we focus on the\nSanskrit Compound Type Identification (SaCTI) task, where we consider the\nproblem of identifying semantic relations between the components of a compound\nword. Earlier approaches solely rely on the lexical information obtained from\nthe components and ignore the most crucial contextual and syntactic information\nuseful for SaCTI. However, the SaCTI task is challenging primarily due to the\nimplicitly encoded context-sensitive semantic relation between the compound\ncomponents.\nThus, we propose a novel multi-task learning architecture which incorporates\nthe contextual information and enriches the complementary syntactic information\nusing morphological tagging and dependency parsing as two auxiliary tasks.\nExperiments on the benchmark datasets for SaCTI show 6.1 points (Accuracy) and\n7.7 points (F1-score) absolute gain compared to the state-of-the-art system.\nFurther, our multi-lingual experiments demonstrate the efficacy of the proposed\narchitecture in English and Marathi languages.The code and datasets are\npublicly available at https://github.com/ashishgupta2598/SaCTI",
    "descriptor": "\nComments: The work is accepted at COLING22, Gyeongju, Republic of Korea\n",
    "authors": [
      "Jivnesh Sandhan",
      "Ashish Gupta",
      "Hrishikesh Terdalkar",
      "Tushar Sandhan",
      "Suvendu Samanta",
      "Laxmidhar Behera",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10310"
  },
  {
    "id": "arXiv:2208.10312",
    "title": "BigBraveBN: algorithm of structural learning for bayesian networks with  a large number of nodes",
    "abstract": "Learning a Bayesian network is an NP-hard problem and with an increase in the\nnumber of nodes, classical algorithms for learning the structure of Bayesian\nnetworks become inefficient. In recent years, some methods and algorithms for\nlearning Bayesian networks with a high number of nodes (more than 50) were\ndeveloped. But these solutions have their disadvantages, for instance, they\nonly operate one type of data (discrete or continuous) or their algorithm has\nbeen created to meet a specific nature of data (medical, social, etc.). The\narticle presents a BigBraveBN algorithm for learning large Bayesian Networks\nwith a high number of nodes (over 100). The algorithm utilizes the Brave\ncoefficient that measures the mutual occurrence of instances in several groups.\nTo form these groups, we use the method of nearest neighbours based on the\nMutual information (MI) measure. In the experimental part of the article, we\ncompare the performance of BigBraveBN to other existing solutions on multiple\ndata sets both discrete and continuous. The experimental part also represents\ntests on real data. The aforementioned experimental results demonstrate the\nefficiency of the BigBraveBN algorithm in structure learning of Bayesian\nNetworks.",
    "descriptor": "\nComments: The article contains 10 pages and 10 figures\n",
    "authors": [
      "Yury Kaminsky",
      "Irina Deeva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10312"
  },
  {
    "id": "arXiv:2208.10315",
    "title": "Semi-supervised classification using a supervised autoencoder for  biomedical applications",
    "abstract": "In this paper we present a new approach to solve semi-supervised\nclassification tasks for biomedical applications, involving a supervised\nautoencoder network. We create a network architecture that encodes labels into\nthe latent space of an autoencoder, and define a global criterion combining\nclassification and reconstruction losses. We train the Semi-Supervised\nAutoEncoder (SSAE) on labelled data using a double descent algorithm. Then, we\nclassify unlabelled samples using the learned network thanks to a softmax\nclassifier applied to the latent space which provides a classification\nconfidence score for each class.\nWe implemented our SSAE method using the PyTorch framework for the model,\noptimizer, schedulers, and loss functions. We compare our semi-supervised\nautoencoder method (SSAE) with classical semi-supervised methods such as Label\nPropagation and Label Spreading, and with a Fully Connected Neural Network\n(FCNN). Experiments show that the SSAE outperforms Label Propagation and\nSpreading and the Fully Connected Neural Network both on a synthetic dataset\nand on two real-world biological datasets.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Cyprien Gille",
      "Frederic Guyard",
      "Michel Barlaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.10315"
  },
  {
    "id": "arXiv:2208.10317",
    "title": "Latent Neural Stochastic Differential Equations for Change Point  Detection",
    "abstract": "The purpose of change point detection algorithms is to locate an abrupt\nchange in the time evolution of a process. In this paper, we introduce an\napplication of latent neural stochastic differential equations for change point\ndetection problem. We demonstrate the detection capabilities and performance of\nour model on a range of synthetic and real-world datasets and benchmarks. Most\nof the studied scenarios show that the proposed algorithm outperforms the\nstate-of-the-art algorithms. We also discuss the strengths and limitations of\nthis approach and indicate directions for further improvements.",
    "descriptor": "",
    "authors": [
      "Artem Ryzhikov",
      "Mikhail Hushchyn",
      "Denis Derkach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10317"
  },
  {
    "id": "arXiv:2208.10322",
    "title": "Mix-Pooling Strategy for Attention Mechanism",
    "abstract": "Recently many effective self-attention modules are proposed to boot the model\nperformance by exploiting the internal information of convolutional neural\nnetworks in computer vision. In general, many previous works ignore considering\nthe design of the pooling strategy of the self-attention mechanism since they\nadopt the global average pooling for granted, which hinders the further\nimprovement of the performance of the self-attention mechanism. However, we\nempirically find and verify a phenomenon that the simple linear combination of\nglobal max-pooling and global min-pooling can produce pooling strategies that\nmatch or exceed the performance of global average pooling. Based on this\nempirical observation, we propose a simple-yet-effective self-attention module\nSPENet, which adopts a self-adaptive pooling strategy based on global\nmax-pooling and global min-pooling and a lightweight module for producing the\nattention map. The effectiveness of SPENet is demonstrated by extensive\nexperiments on widely used benchmark datasets and popular self-attention\nnetworks.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Shanshan Zhong",
      "Wushao Wen",
      "Jinghui Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10322"
  },
  {
    "id": "arXiv:2208.10327",
    "title": "Incorporating Rivalry in Reinforcement Learning for a Competitive Game",
    "abstract": "Recent advances in reinforcement learning with social agents have allowed\nsuch models to achieve human-level performance on specific interaction tasks.\nHowever, most interactive scenarios do not have a version alone as an end goal;\ninstead, the social impact of these agents when interacting with humans is as\nimportant and largely unexplored. In this regard, this work proposes a novel\nreinforcement learning mechanism based on the social impact of rivalry\nbehavior. Our proposed model aggregates objective and social perception\nmechanisms to derive a rivalry score that is used to modulate the learning of\nartificial agents. To investigate our proposed model, we design an interactive\ngame scenario, using the Chef's Hat Card Game, and examine how the rivalry\nmodulation changes the agent's playing style, and how this impacts the\nexperience of human players in the game. Our results show that humans can\ndetect specific social characteristics when playing against rival agents when\ncompared to common agents, which directly affects the performance of the human\nplayers in subsequent games. We conclude our work by discussing how the\ndifferent social and objective features that compose the artificial rivalry\nscore contribute to our results.",
    "descriptor": "\nComments: Accepted at the Neural Computing and Applications Journal\n",
    "authors": [
      "Pablo Barros",
      "Ozge Nilay Yalc\u0131n",
      "Ana Tanevska",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10327"
  },
  {
    "id": "arXiv:2208.10328",
    "title": "Repurposing Knowledge Graph Embeddings for Triple Representation via  Weak Supervision",
    "abstract": "The majority of knowledge graph embedding techniques treat entities and\npredicates as separate embedding matrices, using aggregation functions to build\na representation of the input triple. However, these aggregations are lossy,\ni.e. they do not capture the semantics of the original triples, such as\ninformation contained in the predicates. To combat these shortcomings, current\nmethods learn triple embeddings from scratch without utilizing entity and\npredicate embeddings from pre-trained models. In this paper, we design a novel\nfine-tuning approach for learning triple embeddings by creating weak\nsupervision signals from pre-trained knowledge graph embeddings. We develop a\nmethod for automatically sampling triples from a knowledge graph and estimating\ntheir pairwise similarities from pre-trained embedding models. These pairwise\nsimilarity scores are then fed to a Siamese-like neural architecture to\nfine-tune triple representations. We evaluate the proposed method on two widely\nstudied knowledge graphs and show consistent improvement over other\nstate-of-the-art triple embedding methods on triple classification and triple\nclustering tasks.",
    "descriptor": "",
    "authors": [
      "Alexander Kalinowski",
      "Yuan An"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10328"
  },
  {
    "id": "arXiv:2208.10334",
    "title": "FORBID: Fast Overlap Removal By stochastic gradIent Descent for Graph  Drawing",
    "abstract": "While many graph drawing algorithms consider nodes as points, graph\nvisualization tools often represent them as shapes. These shapes support the\ndisplay of information such as labels or encode various data with size or\ncolor. However, they can create overlaps between nodes which hinder the\nexploration process by hiding parts of the information. It is therefore of\nutmost importance to remove these overlaps to improve graph visualization\nreadability. If not handled by the layout process, Overlap Removal (OR)\nalgorithms have been proposed as layout post-processing. As graph layouts\nusually convey information about their topology, it is important that OR\nalgorithms preserve them as much as possible. We propose a novel algorithm that\nmodels OR as a joint stress and scaling optimization problem, and leverages\nefficient stochastic gradient descent. This approach is compared with\nstate-of-the-art algorithms, and several quality metrics demonstrate its\nefficiency to quickly remove overlaps while retaining the initial layout\nstructures.",
    "descriptor": "\nComments: Appears in the Proceedings of the 30th International Symposium on Graph Drawing and Network Visualization (GD 2022)\n",
    "authors": [
      "Loann Giovannangeli",
      "Frederic Lalanne",
      "Romain Giot",
      "Romain Bourqui"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10334"
  },
  {
    "id": "arXiv:2208.10335",
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the  Wild",
    "abstract": "Compared with the image-based static facial expression recognition (SFER)\ntask, the dynamic facial expression recognition (DFER) task based on video\nsequences is closer to the natural expression recognition scene. However, DFER\nis often more challenging. One of the main reasons is that video sequences\noften contain frames with different expression intensities, especially for the\nfacial expressions in the real-world scenarios, while the images in SFER\nfrequently present uniform and high expression intensities. However, if the\nexpressions with different intensities are treated equally, the features\nlearned by the networks will have large intra-class and small inter-class\ndifferences, which is harmful to DFER. To tackle this problem, we propose the\nglobal convolution-attention block (GCA) to rescale the channels of the feature\nmaps. In addition, we introduce the intensity-aware loss (IAL) in the training\nprocess to help the network distinguish the samples with relatively low\nexpression intensities. Experiments on two in-the-wild dynamic facial\nexpression datasets (i.e., DFEW and FERV39k) indicate that our method\noutperforms the state-of-the-art DFER approaches. The source code will be made\npublicly available.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Hanting Li",
      "Hongjing Niu",
      "Zhaoqing Zhu",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10335"
  },
  {
    "id": "arXiv:2208.10338",
    "title": "Optimal Topology Transition",
    "abstract": "Network topology has significant impacts on operational performance of power\nsystems. While extensive research efforts have been devoted to optimization of\nnetwork topology for improving various system performances, the problem of how\nto transition from the initial topology to the desired optimal topology\nrequires study. To address this problem, we propose the concept of optimal\ntopology transition (OTT). This aims to find the topology transition trajectory\nfrom an initial topology to a desired terminal topology, which optimizes\ncertain transition performance and satisfies operational constraints. The OTT\nproblem is further formulated as a mixed-integer program under certain\nassumptions. Next, we propose the formulation of transition-embedded topology\noptimization that is capable of optimizing network topology and its transition\ntrajectory simultaneously. Considering the time complexity of directly solving\nthe mixed-integer programs, an efficient problem-specific solution algorithm is\ndeveloped. Finally, numerical studies demonstrate the effectiveness of the\nproposed OTT and transition-embedded topology optimization models, as well as\nthe superiority of the obtained optimal transition trajectories compared to ad\nhoc transition trajectories.",
    "descriptor": "\nComments: 13 page, accepted by TPWRS\n",
    "authors": [
      "Tong Han",
      "David J. Hill",
      "Yue Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10338"
  },
  {
    "id": "arXiv:2208.10347",
    "title": "A robust class of languages of 2-nested words",
    "abstract": "Regular nested word languages (a.k.a. visibly pushdown languages) strictly\nextend regular word languages, while preserving their main closure and\ndecidability properties. Previous works have shown that considering languages\nof 2-nested words, i.e. words enriched with two matchings (a.k.a. 2-visibly\npushdown languages), is not as successful: the corresponding model of automata\nis not closed under determinization. In this work, inspired by homomorphic\nrepresentations of indexed languages, we identify a subclass of 2-nested words,\nwhich we call 2-wave words. This class strictly extends the class of nested\nwords, while preserving its main properties. More precisely, we prove closure\nunder determinization of the corresponding automaton model, we provide a\nlogical characterization of the recognized languages, and show that the\ncorresponding graphs have bounded treewidth. As a consequence, we derive\nimportant closure and decidability properties. Last, we show that the word\nprojections of the languages we define belong to the class of linear indexed\nlanguages.",
    "descriptor": "\nComments: Extended version of paper published at MFCS 2022\n",
    "authors": [
      "S\u00e9verine Fratani",
      "Guillaume Maurras",
      "Pierre-Alain Reynier"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10347"
  },
  {
    "id": "arXiv:2208.10353",
    "title": "Neuro-Symbolic Visual Dialog",
    "abstract": "We propose Neuro-Symbolic Visual Dialog (NSVD) -the first method to combine\ndeep learning and symbolic program execution for multi-round visually-grounded\nreasoning. NSVD significantly outperforms existing purely-connectionist methods\non two key challenges inherent to visual dialog: long-distance co-reference\nresolution as well as vanishing question-answering performance. We demonstrate\nthe latter by proposing a more realistic and stricter evaluation scheme in\nwhich we use predicted answers for the full dialog history when calculating\naccuracy. We describe two variants of our model and show that using this new\nscheme, our best model achieves an accuracy of 99.72% on CLEVR-Dialog -a\nrelative improvement of more than 10% over the state of the art while only\nrequiring a fraction of training data. Moreover, we demonstrate that our\nneuro-symbolic models have a higher mean first failure round, are more robust\nagainst incomplete dialog histories, and generalise better not only to dialogs\nthat are up to three times longer than those seen during training but also to\nunseen question types and scenes.",
    "descriptor": "\nComments: To appear at COLING 2022\n",
    "authors": [
      "Adnen Abdessaied",
      "Mihai B\u00e2ce",
      "Andreas Bulling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10353"
  },
  {
    "id": "arXiv:2208.10354",
    "title": "Real-world-robustness of tree-based classifiers",
    "abstract": "The concept of trustworthy AI has gained widespread attention lately. One of\nthe aspects relevant to trustworthy AI is robustness of ML models. In this\nstudy, we show how to compute the recently introduced measure of\nreal-world-robustness - a measure for robustness against naturally occurring\ndistortions of input data - for tree-based classifiers. The original method for\ncomputing real-world-robustness works for all black box classifiers, but is\nonly an approximation. Here we show how real-world-robustness, under the\nassumption that the natural distortions are given by multivariate normal\ndistributions, can be exactly computed for tree-based classifiers.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Christoph Schweimer",
      "Sebastian Scher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10354"
  },
  {
    "id": "arXiv:2208.10358",
    "title": "A Medical Semantic-Assisted Transformer for Radiographic Report  Generation",
    "abstract": "Automated radiographic report generation is a challenging cross-domain task\nthat aims to automatically generate accurate and semantic-coherence reports to\ndescribe medical images. Despite the recent progress in this field, there are\nstill many challenges at least in the following aspects. First, radiographic\nimages are very similar to each other, and thus it is difficult to capture the\nfine-grained visual differences using CNN as the visual feature extractor like\nmany existing methods. Further, semantic information has been widely applied to\nboost the performance of generation tasks (e.g. image captioning), but existing\nmethods often fail to provide effective medical semantic features. Toward\nsolving those problems, in this paper, we propose a memory-augmented sparse\nattention block utilizing bilinear pooling to capture the higher-order\ninteractions between the input fine-grained image features while producing\nsparse attention. Moreover, we introduce a novel Medical Concepts Generation\nNetwork (MCGN) to predict fine-grained semantic concepts and incorporate them\ninto the report generation process as guidance. Our proposed method shows\npromising performance on the recently released largest benchmark MIMIC-CXR. It\noutperforms multiple state-of-the-art methods in image captioning and medical\nreport generation.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Zhanyu Wang",
      "Mingkang Tang",
      "Lei Wang",
      "Xiu Li",
      "Luping Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10358"
  },
  {
    "id": "arXiv:2208.10362",
    "title": "Massively Parallel Universal Linear Transformations using a  Wavelength-Multiplexed Diffractive Optical Network",
    "abstract": "We report deep learning-based design of a massively parallel broadband\ndiffractive neural network for all-optically performing a large group of\narbitrarily-selected, complex-valued linear transformations between an input\nand output field-of-view, each with N_i and N_o pixels, respectively. This\nbroadband diffractive processor is composed of N_w wavelength channels, each of\nwhich is uniquely assigned to a distinct target transformation. A large set of\narbitrarily-selected linear transformations can be individually performed\nthrough the same diffractive network at different illumination wavelengths,\neither simultaneously or sequentially (wavelength scanning). We demonstrate\nthat such a broadband diffractive network, regardless of its material\ndispersion, can successfully approximate N_w unique complex-valued linear\ntransforms with a negligible error when the number of diffractive neurons (N)\nin its design matches or exceeds 2 x N_w x N_i x N_o. We further report that\nthe spectral multiplexing capability (N_w) can be increased by increasing N;\nour numerical analyses confirm these conclusions for N_w > 180, which can be\nfurther increased to e.g., ~2000 depending on the upper bound of the\napproximation error. Massively parallel, wavelength-multiplexed diffractive\nnetworks will be useful for designing high-throughput intelligent machine\nvision systems and hyperspectral processors that can perform statistical\ninference and analyze objects/scenes with unique spectral properties.",
    "descriptor": "\nComments: 30 Pages, 9 Figures\n",
    "authors": [
      "Jingxi Li",
      "Bijie Bai",
      "Yi Luo",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2208.10362"
  },
  {
    "id": "arXiv:2208.10364",
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks",
    "abstract": "Recent years have seen a surge in research on dynamic graph representation\nlearning, which aims to model temporal graphs that are dynamic and evolving\nconstantly over time. However, current work typically models graph dynamics\nwith recurrent neural networks (RNNs), making them suffer seriously from\ncomputation and memory overheads on large temporal graphs. So far, scalability\nof dynamic graph representation learning on large temporal graphs remains one\nof the major challenges. In this paper, we present a scalable framework, namely\nSpikeNet, to efficiently capture the temporal and structural patterns of\ntemporal graphs. We explore a new direction in that we can capture the evolving\ndynamics of temporal graphs with spiking neural networks (SNNs) instead of\nRNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics\nas spike trains of neuron populations and enable spike-based propagation in an\nefficient way. Experiments on three large real-world temporal graph datasets\ndemonstrate that SpikeNet outperforms strong baselines on the temporal node\nclassification task with lower computational costs. Particularly, SpikeNet\ngeneralizes to a large temporal graph (2M nodes and 13M edges) with\nsignificantly fewer parameters and computation overheads. Our code is publicly\navailable at https://github.com/EdisonLeeeee/SpikeNet",
    "descriptor": "\nComments: Preprint; Code available at this https URL\n",
    "authors": [
      "Jintang Li",
      "Zhouxin Yu",
      "Zulun Zhu",
      "Liang Chen",
      "Qi Yu",
      "Zibin Zheng",
      "Sheng Tian",
      "Ruofan Wu",
      "Changhua Meng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10364"
  },
  {
    "id": "arXiv:2208.10366",
    "title": "High-quality Task Division for Large-scale Entity Alignment",
    "abstract": "Entity Alignment (EA) aims to match equivalent entities that refer to the\nsame real-world objects and is a key step for Knowledge Graph (KG) fusion. Most\nneural EA models cannot be applied to large-scale real-life KGs due to their\nexcessive consumption of GPU memory and time. One promising solution is to\ndivide a large EA task into several subtasks such that each subtask only needs\nto match two small subgraphs of the original KGs. However, it is challenging to\ndivide the EA task without losing effectiveness. Existing methods display low\ncoverage of potential mappings, insufficient evidence in context graphs, and\nlargely differing subtask sizes.\nIn this work, we design the DivEA framework for large-scale EA with\nhigh-quality task division. To include in the EA subtasks a high proportion of\nthe potential mappings originally present in the large EA task, we devise a\ncounterpart discovery method that exploits the locality principle of the EA\ntask and the power of trained EA models. Unique to our counterpart discovery\nmethod is the explicit modelling of the chance of a potential mapping. We also\nintroduce an evidence passing mechanism to quantify the informativeness of\ncontext entities and find the most informative context graphs with flexible\ncontrol of the subtask size. Extensive experiments show that DivEA achieves\nhigher EA performance than alternative state-of-the-art solutions.",
    "descriptor": "",
    "authors": [
      "Bing Liu",
      "Wen Hua",
      "Guido Zuccon",
      "Genghong Zhao",
      "Xia Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10366"
  },
  {
    "id": "arXiv:2208.10367",
    "title": "Multi-View Attention Transfer for Efficient Speech Enhancement",
    "abstract": "Recent deep learning models have achieved high performance in speech\nenhancement; however, it is still challenging to obtain a fast and\nlow-complexity model without significant performance degradation. Previous\nknowledge distillation studies on speech enhancement could not solve this\nproblem because their output distillation methods do not fit the speech\nenhancement task in some aspects. In this study, we propose multi-view\nattention transfer (MV-AT), a feature-based distillation, to obtain efficient\nspeech enhancement models in the time domain. Based on the multi-view features\nextraction model, MV-AT transfers multi-view knowledge of the teacher network\nto the student network without additional parameters. The experimental results\nshow that the proposed method consistently improved the performance of student\nmodels of various sizes on the Valentini and deep noise suppression (DNS)\ndatasets. MANNER-S-8.1GF with our proposed method, a lightweight model for\nefficient deployment, achieved 15.4x and 4.71x fewer parameters and\nfloating-point operations (FLOPs), respectively, compared to the baseline model\nwith similar performance.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Wooseok Shin",
      "Hyun Joon Park",
      "Jin Sob Kim",
      "Byung Hoon Lee",
      "Sung Won Han"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.10367"
  },
  {
    "id": "arXiv:2208.10371",
    "title": "Collaborative Perception for Autonomous Driving: Current Status and  Future Trend",
    "abstract": "Perception is one of the crucial module of the autonomous driving system,\nwhich has made great progress recently. However, limited ability of individual\nvehicles results in the bottleneck of improvement of the perception\nperformance. To break through the limits of individual perception,\ncollaborative perception has been proposed which enables vehicles to share\ninformation to perceive the environments beyond line-of-sight and\nfield-of-view. In this paper, we provide a review of the related work about the\npromising collaborative perception technology, including introducing the\nfundamental concepts, generalizing the collaboration modes and summarizing the\nkey ingredients and applications of collaborative perception. Finally, we\ndiscuss the open challenges and issues of this research area and give some\npotential further directions.",
    "descriptor": "\nComments: Published in Proceedings of CCSICC 2021\n",
    "authors": [
      "Shunli Ren",
      "Siheng Chen",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10371"
  },
  {
    "id": "arXiv:2208.10373",
    "title": "Fight Fire With Fire: Reversing Skin Adversarial Examples by Multiscale  Diffusive and Denoising Aggregation Mechanism",
    "abstract": "Reliable skin cancer diagnosis models play an essential role in early\nscreening and medical intervention. Prevailing computer-aided skin cancer\nclassification systems employ deep learning approaches. However, recent studies\nreveal their extreme vulnerability to adversarial attacks -- often\nimperceptible perturbations to significantly reduce performances of skin cancer\ndiagnosis models. To mitigate these threats, this work presents a simple,\neffective and resource-efficient defense framework by reverse engineering\nadversarial perturbations in skin cancer images. Specifically, a multiscale\nimage pyramid is first established to better preserve discriminative structures\nin medical imaging domain. To neutralize adversarial effects, skin images at\ndifferent scales are then progressively diffused by injecting isotropic\nGaussian noises to move the adversarial examples to the clean image manifold.\nCrucially, to further reverse adversarial noises and suppress redundant\ninjected noises, a novel multiscale denoising mechanism is carefully designed\nthat aggregates image information from neighboring scales. We evaluated the\ndefensive effectiveness of our method on ISIC 2019, a largest skin cancer\nmulticlass classification dataset. Experimental results demonstrate that the\nproposed method can successfully reverse adversarial perturbations from\ndifferent attacks and significantly outperform some state-of-the-art methods in\ndefending skin cancer diagnosis models.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yongwei Wang",
      "Yuan Li",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10373"
  },
  {
    "id": "arXiv:2208.10375",
    "title": "Simulation-Informed Revenue Extrapolation with Confidence Estimate for  Scaleup Companies Using Scarce Time-Series Data",
    "abstract": "Investment professionals rely on extrapolating company revenue into the\nfuture (i.e. revenue forecast) to approximate the valuation of scaleups\n(private companies in a high-growth stage) and inform their investment\ndecision. This task is manual and empirical, leaving the forecast quality\nheavily dependent on the investment professionals' experiences and insights.\nFurthermore, financial data on scaleups is typically proprietary, costly and\nscarce, ruling out the wide adoption of data-driven approaches. To this end, we\npropose a simulation-informed revenue extrapolation (SiRE) algorithm that\ngenerates fine-grained long-term revenue predictions on small datasets and\nshort time-series. SiRE models the revenue dynamics as a linear dynamical\nsystem (LDS), which is solved using the EM algorithm. The main innovation lies\nin how the noisy revenue measurements are obtained during training and\ninferencing. SiRE works for scaleups that operate in various sectors and\nprovides confidence estimates. The quantitative experiments on two practical\ntasks show that SiRE significantly surpasses the baseline methods by a large\nmargin. We also observe high performance when SiRE extrapolates from short\ntime-series and predicts for long-term. The performance-efficiency balance and\nresult explainability of SiRE are also validated empirically. Evaluated from\nthe perspective of investment professionals, SiRE can precisely locate the\nscaleups that have a great potential return in 2 to 5 years. Furthermore, our\nqualitative inspection illustrates some advantageous attributes of the SiRE\nrevenue forecasts.",
    "descriptor": "\nComments: Accepted by CIKM 2022 as full applied research paper (12 pages and 6 figures). For source code and datasets, see this https URL\n",
    "authors": [
      "Lele Cao",
      "Sonja Horn",
      "Vilhelm von Ehrenheim",
      "Richard Anselmo Stahl",
      "Henrik Landgren"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10375"
  },
  {
    "id": "arXiv:2208.10378",
    "title": "Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities",
    "abstract": "Over the years, reasoning over knowledge graphs (KGs), which aims to infer\nnew conclusions from known facts, has mostly focused on static KGs. The\nunceasing growth of knowledge in real life raises the necessity to enable the\ninductive reasoning ability on expanding KGs. Existing inductive work assumes\nthat new entities all emerge once in a batch, which oversimplifies the real\nscenario that new entities continually appear. This study dives into a more\nrealistic and challenging setting where new entities emerge in multiple\nbatches. We propose a walk-based inductive reasoning model to tackle the new\nsetting. Specifically, a graph convolutional network with adaptive relation\naggregation is designed to encode and update entities using their neighboring\nrelations. To capture the varying neighbor importance, we employ a query-aware\nfeedback attention mechanism during the aggregation. Furthermore, to alleviate\nthe sparse link problem of new entities, we propose a link augmentation\nstrategy to add trustworthy facts into KGs. We construct three new datasets for\nsimulating this multi-batch emergence scenario. The experimental results show\nthat our proposed model outperforms state-of-the-art embedding-based,\nwalk-based and rule-based models on inductive KG reasoning.",
    "descriptor": "\nComments: Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)\n",
    "authors": [
      "Yuanning Cui",
      "Yuxin Wang",
      "Zequn Sun",
      "Wenqiang Liu",
      "Yiqiao Jiang",
      "Kexin Han",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10378"
  },
  {
    "id": "arXiv:2208.10379",
    "title": "Enhanced IoT Batteryless D2D Communications Using Reconfigurable  Intelligent Surfaces",
    "abstract": "Recent research on reconfigurable intelligent surfaces (RIS) suggests that\nthe RIS panel, containing passive elements, enhances channel performance for\nthe internet of things (IoT) systems by reflecting transmitted signals to the\nreceiving nodes. This paper investigates RIS panel assisted-wireless network to\ninstigate minimal base station (BS) transmit power in the form of energy\nharvesting for batteryless IoT sensors to maximize bits transmission in the\nsignificant multi-path environment, such as urban areas. Batteryless IoT\nsensors harvest energy through the RIS panel from external sources, such as\nfrom nearby BS radio frequency (RF) signal in the first optimal time frame, for\na given time frame. The bits transmission among IoT sensors, followed by a\ndevice-to-device (D2D) communications protocol, is maximized using harvested\nenergy in the final optimal time frame. The bits transmission is at least equal\nto the number of bits sampled by the IoT sensor. We formulate a non-convex\nmixed-integer non-linear problem to maximize the number of communicating bits\nsubject to energy harvesting from BS RF signals, RIS panel energy consumption,\nand required time. We propose a robust solution by presenting an iterative\nalgorithm. We perform extensive simulation results based on the 3GPP Urban\nMicro channel model to validate our model.",
    "descriptor": "",
    "authors": [
      "Shakil Ahmed",
      "Mohamed Y. Selim",
      "Ahmed E. Kamal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10379"
  },
  {
    "id": "arXiv:2208.10382",
    "title": "Security Enhancement for Coupled Phase-Shift STAR-RIS Networks",
    "abstract": "The secure transmission of the simultaneously transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) aided communication system is\ninvestigated. Considering the coupled phase shifts of STAR-RISs and the fair\nsecrecy requirement of users, a novel secure beamforming design is proposed for\naddressing the unique full-space mutual eavesdropping of STAR-RIS aided\ncommunication. In particular, a penalty based secrecy beamforming algorithm is\ndeveloped to solve the resulting non-convex optimization problem, where the\nclosed-form solutions of the coupled transmission/reflection coefficients are\nobtained in each iteration. Numerical results demonstrate that 1) the proposed\nscheme achieves higher secrecy capacity than conventional RIS; 2) 4-bit\ndiscrete phase shifters are sufficient for secrecy guarantee.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Zheng Zhang",
      "Zhaolin Wang",
      "Yuanwei Liu",
      "Bingtao He",
      "Lu Lv",
      "Jian Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10382"
  },
  {
    "id": "arXiv:2208.10384",
    "title": "The optimality of word lengths. Theoretical foundations and an empirical  study",
    "abstract": "One of the most robust patterns found in human languages is Zipf's law of\nabbreviation, that is, the tendency of more frequent words to be shorter. Since\nZipf's pioneering research, this law has been viewed as a manifestation of\ncompression, i.e. the minimization of the length of forms - a universal\nprinciple of natural communication. Although the claim that languages are\noptimized has become trendy, attempts to measure the degree of optimization of\nlanguages have been rather scarce. Here we demonstrate that compression\nmanifests itself in a wide sample of languages without exceptions, and\nindependently of the unit of measurement. It is detectable for both word\nlengths in characters of written language as well as durations in time in\nspoken language. Moreover, to measure the degree of optimization, we derive a\nsimple formula for a random baseline and present two scores that are dualy\nnormalized, namely, they are normalized with respect to both the minimum and\nthe random baseline. We analyze the theoretical and statistical advantages and\ndisadvantages of these and other scores. Harnessing the best score, we quantify\nfor the first time the degree of optimality of word lengths in languages. This\nindicates that languages are optimized to 62 or 67 percent on average\n(depending on the source) when word lengths are measured in characters, and to\n65 percent on average when word lengths are measured in time. In general,\nspoken word durations are more optimized than written word lengths in\ncharacters. Beyond the analyses reported here, our work paves the way to\nmeasure the degree of optimality of the vocalizations or gestures of other\nspecies, and to compare them against written, spoken, or signed human\nlanguages.",
    "descriptor": "",
    "authors": [
      "Sonia Petrini",
      "Antoni Casas-i-Mu\u00f1oz",
      "Jordi Cluet-i-Martinell",
      "Mengxue Wang",
      "Christian Bentz",
      "Ramon Ferrer-i-Cancho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.10384"
  },
  {
    "id": "arXiv:2208.10386",
    "title": "Multiple Shooting Approach for Finding Approximately Shortest Paths for  Autonomous Robots in Unknown Environments in 2D",
    "abstract": "An autonomous robot with a limited vision range finds a path to the goal in\nan unknown environment in 2D avoiding polygonal obstacles. In the process of\ndiscovering the environmental map, the robot has to return to some positions\nmarked previously, the regions where the robot traverses to return are defined\nas sequences of bundles of line segments. This paper presents a novel algorithm\nfor finding approximately shortest paths along the sequences of bundles of line\nsegments based on the method of multiple shooting. Three factors of the\napproach including bundle partition, collinear condition, and update of\nshooting points are presented. We then show that if the collinear condition\nholds, the exactly shortest paths of the problems are determined, otherwise,\nthe sequence of paths obtained by the update of the method converges to the\nshortest path. The algorithm is implemented in Python and some numerical\nexamples show that the running time of path-planning for autonomous robots\nusing our method is faster than that using the rubber band technique of Li and\nKlette in Euclidean Shortest Paths, Springer, 53-89 (2011).",
    "descriptor": "\nComments: 26 pages, 39 figures\n",
    "authors": [
      "Phan Thanh An",
      "Nguyen Thi Le"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.10386"
  },
  {
    "id": "arXiv:2208.10387",
    "title": "Constants of motion network",
    "abstract": "The beauty of physics is that there is usually a conserved quantity in an\nalways-changing system, known as the constant of motion. Finding the constant\nof motion is important in understanding the dynamics of the system, but\ntypically requires mathematical proficiency and manual analytical work. In this\npaper, we present a neural network that can simultaneously learn the dynamics\nof the system and the constants of motion from data. By exploiting the\ndiscovered constants of motion, it can produce better predictions on dynamics\nand can work on a wider range of systems than Hamiltonian-based neural\nnetworks. In addition, the training progresses of our method can be used as an\nindication of the number of constants of motion in a system which could be\nuseful in studying a novel physical system.",
    "descriptor": "",
    "authors": [
      "Muhammad Firmansyah Kasim",
      "Yi Heng Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10387"
  },
  {
    "id": "arXiv:2208.10389",
    "title": "Bounding the Optimal Length of Pliable Index Coding via a  Hypergraph-based Approach",
    "abstract": "In pliable index coding (PICOD), a number of clients are connected via a\nnoise-free broadcast channel to a server which has a list of messages. Each\nclient has a unique subset of messages at the server as side-information and\nrequests for any one message not in the side-information. A PICOD scheme of\nlength $\\ell$ is a set of $\\ell$ encoded transmissions broadcast from the\nserver such that all clients are satisfied. Finding the optimal (minimum)\nlength of PICOD and designing PICOD schemes that have small length are the\nfundamental questions in PICOD. In this paper, we use a hypergraph-based\napproach to derive new achievability and converse results for PICOD. We present\nan algorithm which gives an achievable scheme for PICOD with length at most\n$\\Delta(\\mathcal{H})$, where $\\Delta(\\mathcal{H})$ is the maximum degree of any\nvertex in a hypergraph that represents the PICOD problem. We also give a lower\nbound for the optimal PICOD length using a new structural parameter associated\nwith the PICOD hypergraph called the nesting number. Finally, we identify a\nclass of problems for which our converse is tight, and also characterize the\noptimal PICOD lengths of problems with $\\Delta(\\mathcal{H})\\in\\{1,2,3\\}$.",
    "descriptor": "\nComments: Accepted at the IEEE Information Theory Workshop, 2022\n",
    "authors": [
      "Tulasi Sowjanya B.",
      "Visvesh Subramanian",
      "Prasad Krishnan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.10389"
  },
  {
    "id": "arXiv:2208.10390",
    "title": "Minimizing the Effect of Noise and Limited Dataset Size in Image  Classification Using Depth Estimation as an Auxiliary Task with Deep  Multitask Learning",
    "abstract": "Generalizability is the ultimate goal of Machine Learning (ML) image\nclassifiers, for which noise and limited dataset size are among the major\nconcerns. We tackle these challenges through utilizing the framework of deep\nMultitask Learning (dMTL) and incorporating image depth estimation as an\nauxiliary task. On a customized and depth-augmented derivation of the MNIST\ndataset, we show a) multitask loss functions are the most effective approach of\nimplementing dMTL, b) limited dataset size primarily contributes to\nclassification inaccuracy, and c) depth estimation is mostly impacted by noise.\nIn order to further validate the results, we manually labeled the NYU Depth V2\ndataset for scene classification tasks. As a contribution to the field, we have\nmade the data in python native format publicly available as an open-source\ndataset and provided the scene labels. Our experiments on MNIST and\nNYU-Depth-V2 show dMTL improves generalizability of the classifiers when the\ndataset is noisy and the number of examples is limited.",
    "descriptor": "",
    "authors": [
      "Khashayar Namdar",
      "Partoo Vafaeikia",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10390"
  },
  {
    "id": "arXiv:2208.10391",
    "title": "MOM: Matrix Operations in MLIR",
    "abstract": "Modern research in code generators for dense linear algebra computations has\nshown the ability to produce optimized code with a performance which compares\nand often exceeds the one of state-of-the-art implementations by domain\nexperts. However, the underlying infrastructure is often developed in isolation\nmaking the interconnection of logically combinable systems complicated if not\nimpossible. In this paper, we propose to leverage MLIR as a unifying compiler\ninfrastructure for the optimization of dense linear algebra operations. We\npropose a new MLIR dialect for expressing linear algebraic computations\nincluding matrix properties to enable high-level algorithmic transformations.\nThe integration of this new dialect in MLIR enables end-to-end compilation of\nmatrix computations via conversion to existing lower-level dialects already\nprovided by the framework.",
    "descriptor": "\nComments: 3 pages, 1 figure, 1 table, and 3 listings. Short paper presented at 12th International Workshop on Polyhedral Compilation Techniques (IMPACT 22)\n",
    "authors": [
      "Lorenzo Chelini",
      "Henrik Barthels",
      "Paolo Bientinesi",
      "Marcin Copik",
      "Tobias Grosser",
      "Daniele G. Spampinato"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2208.10391"
  },
  {
    "id": "arXiv:2208.10400",
    "title": "DP-Rewrite: Towards Reproducibility and Transparency in Differentially  Private Text Rewriting",
    "abstract": "Text rewriting with differential privacy (DP) provides concrete theoretical\nguarantees for protecting the privacy of individuals in textual documents. In\npractice, existing systems may lack the means to validate their\nprivacy-preserving claims, leading to problems of transparency and\nreproducibility. We introduce DP-Rewrite, an open-source framework for\ndifferentially private text rewriting which aims to solve these problems by\nbeing modular, extensible, and highly customizable. Our system incorporates a\nvariety of downstream datasets, models, pre-training procedures, and evaluation\nmetrics to provide a flexible way to lead and validate private text rewriting\nresearch. To demonstrate our software in practice, we provide a set of\nexperiments as a case study on the ADePT DP text rewriting system, detecting a\nprivacy leak in its pre-training approach. Our system is publicly available,\nand we hope that it will help the community to make DP text rewriting research\nmore accessible and transparent.",
    "descriptor": "\nComments: Accepted at COLING 2022\n",
    "authors": [
      "Timour Igamberdiev",
      "Thomas Arnold",
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.10400"
  },
  {
    "id": "arXiv:2208.10404",
    "title": "SVD-NAS: Coupling Low-Rank Approximation and Neural Architecture Search",
    "abstract": "The task of compressing pre-trained Deep Neural Networks has attracted wide\ninterest of the research community due to its great benefits in freeing\npractitioners from data access requirements. In this domain, low-rank\napproximation is a promising method, but existing solutions considered a\nrestricted number of design choices and failed to efficiently explore the\ndesign space, which lead to severe accuracy degradation and limited compression\nratio achieved. To address the above limitations, this work proposes the\nSVD-NAS framework that couples the domains of low-rank approximation and neural\narchitecture search. SVD-NAS generalises and expands the design choices of\nprevious works by introducing the Low-Rank architecture space, LR-space, which\nis a more fine-grained design space of low-rank approximation. Afterwards, this\nwork proposes a gradient-descent-based search for efficiently traversing the\nLR-space. This finer and more thorough exploration of the possible design\nchoices results in improved accuracy as well as reduction in parameters, FLOPS,\nand latency of a CNN model. Results demonstrate that the SVD-NAS achieves\n2.06-12.85pp higher accuracy on ImageNet than state-of-the-art methods under\nthe data-limited problem setting. SVD-NAS is open-sourced at\nhttps://github.com/Yu-Zhewen/SVD-NAS.",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Zhewen Yu",
      "Christos-Savvas Bouganis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10404"
  },
  {
    "id": "arXiv:2208.10409",
    "title": "Automated Noncontact Trapping of Moving Micro-particle with Ultrasonic  Phased Array System and Microscopic Vision",
    "abstract": "Noncontact particle manipulation (NPM) technology has significantly extended\nmankind's analysis capability into micro and nano scale, which in turn greatly\npromoted the development of material science and life science. Though NPM by\nmeans of electric, magnetic, and optical field has achieved great success, from\nthe robotic perspective, it is still labor-intensive manipulation since\nprofessional human assistance is somehow mandatory in early preparation stage.\nTherefore, developing automated noncontact trapping of moving particles is\nworthwhile, particularly for applications where particle samples are rare,\nfragile or contact sensitive. Taking advantage of latest dynamic acoustic field\nmodulating technology, and particularly by virtue of the great scalability of\nacoustic manipulation from micro-scale to sub-centimeter-scale, we propose an\nautomated noncontact trapping of moving micro-particles with ultrasonic phased\narray system and microscopic vision in this paper. The main contribution of\nthis work is for the first time, as far as we know, we achieved fully automated\nmoving micro-particle trapping in acoustic NPM field by resorting to robotic\napproach. In short, the particle moving status is observed and predicted by\nbinocular microscopic vision system, by referring to which the acoustic\ntrapping zone is calculated and generated to capture and stably hold the\nparticle. The problem of hand-eye relationship of noncontact robotic\nend-effector is also solved in this work. Experiments demonstrated the\neffectiveness of this work.",
    "descriptor": "\nComments: 7 pages, 12 figures, submitted to the 40th IEEE Conference on Robotics and Automation (ICRA 2023)\n",
    "authors": [
      "Mingyue Wang",
      "Jiaqi Li",
      "Yuyu Jia",
      "Zhenhuan Sun",
      "Yuhang Liu",
      "Teng Li",
      "Song Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10409"
  },
  {
    "id": "arXiv:2208.10411",
    "title": "Nonlinear Control Allocation Using A Piecewise Multi-Linear  Representation",
    "abstract": "Nonlinear control allocation is an important part of modern nonlinear dynamic\ninversion based flight control systems which require highly accurate model of\naircraft aerodynamics. Generally, an accurately implemented onboard model\ndetermines how well the system nonlinearities can be canceled. Thus, more\naccurate model results in better cancellation, leading to the higher\nperformance of the controller. In this paper, a new control system is presented\nthat combines nonlinear dynamic inversion with a piecewise multi-linear\nrepresentation based control allocation. The piecewise multi-linear\nrepresentation is developed through a new generalization of Kronecker product\nfor block matrices, combined with the canonical piecewise linear representation\nof nonlinear functions. Analytical expressions for the Jacobian of the\npiecewise multi-linear model are also presented. Proposed formulation gives an\nexact representation of piecewise multi-linear aerodynamic data and thus is\ncapable of accurately modeling nonlinear aerodynamics over the entire flight\nenvelope of an aircraft. Resulting nonlinear controller is applied to control\nof a tailless flying wing aircraft with ten independently operating control\nsurfaces. The simulation results for two innovative control surface\nconfigurations indicate that perfect control allocation performance can be\nachieved, leading to better tracking performance compared with ordinary\npolynomial-based control allocation.",
    "descriptor": "\nComments: 10 pages, 5 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems\n",
    "authors": [
      "Jahanzeb Rajput",
      "Hafiz Zeeshan Iqbal Khan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.10411"
  },
  {
    "id": "arXiv:2208.10413",
    "title": "On Deep Learning in Password Guessing, a Survey",
    "abstract": "The security of passwords is dependent on a thorough understanding of the\nstrategies used by attackers. Unfortunately, real-world adversaries use\npragmatic guessing tactics like dictionary attacks, which are difficult to\nsimulate in password security research. Dictionary attacks must be carefully\nconfigured and modified to be representative of the actual threat. This\napproach, however, needs domain-specific knowledge and expertise that are\ndifficult to duplicate. This paper compares various deep learning-based\npassword guessing approaches that do not require domain knowledge or\nassumptions about users' password structures and combinations. The involved\nmodel categories are Recurrent Neural Networks, Generative Adversarial\nNetworks, Autoencoder, and Attention mechanisms. Additionally, we proposed a\npromising research experimental design on using variations of IWGAN on password\nguessing under non-targeted offline attacks. Using these advanced strategies,\nwe can enhance password security and create more accurate and efficient\nPassword Strength Meters.",
    "descriptor": "\nComments: 8 pages, 4 figures, 3 tables. arXiv admin note: substantial text overlap with arXiv:2208.06943\n",
    "authors": [
      "Fangyi Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10413"
  },
  {
    "id": "arXiv:2208.10414",
    "title": "MetaFi: Device-Free Pose Estimation via Commodity WiFi for Metaverse  Avatar Simulation",
    "abstract": "Avatar refers to a representative of a physical user in the virtual world\nthat can engage in different activities and interact with other objects in\nmetaverse. Simulating the avatar requires accurate human pose estimation.\nThough camera-based solutions yield remarkable performance, they encounter the\nprivacy issue and degraded performance caused by varying illumination,\nespecially in smart home. In this paper, we propose a WiFi-based IoT-enabled\nhuman pose estimation scheme for metaverse avatar simulation, namely MetaFi.\nSpecifically, a deep neural network is designed with customized convolutional\nlayers and residual blocks to map the channel state information to human pose\nlandmarks. It is enforced to learn the annotations from the accurate computer\nvision model, thus achieving cross-modal supervision. WiFi is ubiquitous and\nrobust to illumination, making it a feasible solution for avatar applications\nin smart home. The experiments are conducted in the real world, and the results\nshow that the MetaFi achieves very high performance with a PCK@50 of 95.23%.",
    "descriptor": "\nComments: 6 pages, 3 figures, 3 tables\n",
    "authors": [
      "Jianfei Yang",
      "Yunjiao Zhou",
      "He Huang",
      "Han Zou",
      "Lihua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.10414"
  },
  {
    "id": "arXiv:2208.10415",
    "title": "NLDS-QL: From natural language data science questions to queries on  graphs: analysing patients conditions & treatments",
    "abstract": "This paper introduces NLDS-QL, a translator of data science questions\nexpressed in natural language (NL) into data science queries on graph\ndatabases. Our translator is based on a simplified NL described by a grammar\nthat specifies sentences combining keywords to refer to operations on graphs\nwith the vocabulary of the graph schema. The demonstration proposed in this\npaper shows NLDS-QL in action within a scenario to explore and analyse a graph\nbase on patient diagnoses generated with the open-source Synthea.",
    "descriptor": "",
    "authors": [
      "Genoveva Vargas-Solar",
      "Karim Dao",
      "Mirian Halfeld Ferrari Alves"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2208.10415"
  },
  {
    "id": "arXiv:2208.10422",
    "title": "FurryGAN: High Quality Foreground-aware Image Synthesis",
    "abstract": "Foreground-aware image synthesis aims to generate images as well as their\nforeground masks. A common approach is to formulate an image as an masked\nblending of a foreground image and a background image. It is a challenging\nproblem because it is prone to reach the trivial solution where either image\noverwhelms the other, i.e., the masks become completely full or empty, and the\nforeground and background are not meaningfully separated. We present FurryGAN\nwith three key components: 1) imposing both the foreground image and the\ncomposite image to be realistic, 2) designing a mask as a combination of coarse\nand fine masks, and 3) guiding the generator by an auxiliary mask predictor in\nthe discriminator. Our method produces realistic images with remarkably\ndetailed alpha masks which cover hair, fur, and whiskers in a fully\nunsupervised manner.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Jeongmin Bae",
      "Mingi Kwon",
      "Youngjung Uh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10422"
  },
  {
    "id": "arXiv:2208.10423",
    "title": "Graph Connectivity with Noisy Queries",
    "abstract": "Graph connectivity is a fundamental combinatorial optimization problem that\narises in many practical applications, where usually a spanning subgraph of a\nnetwork is used for its operation. However, in the real world, links may fail\nunexpectedly deeming the networks non-operational, while checking whether a\nlink is damaged is costly and possibly erroneous. After an event that has\ndamaged an arbitrary subset of the edges, the network operator must find a\nspanning tree of the network using non-damaged edges by making as few checks as\npossible.\nMotivated by such questions, we study the problem of finding a spanning tree\nin a network, when we only have access to noisy queries of the form \"Does edge\ne exist?\". We design efficient algorithms, even when edges fail adversarially,\nfor all possible error regimes; 2-sided error (where any answer might be\nerroneous), false positives (where \"no\" answers are always correct) and false\nnegatives (where \"yes\" answers are always correct). In the first two regimes we\nprovide efficient algorithms and give matching lower bounds for general graphs.\nIn the False Negative case we design efficient algorithms for large interesting\nfamilies of graphs (e.g. bounded treewidth, sparse). Using the previous\nresults, we provide tight algorithms for the practically useful family of\nplanar graphs in all error regimes.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Dimitris Fotakis",
      "Evangelia Gergatsouli",
      "Charilaos Pipis",
      "Miltiadis Stouras",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.10423"
  },
  {
    "id": "arXiv:2208.10428",
    "title": "Equivariant Hypergraph Neural Networks",
    "abstract": "Many problems in computer vision and machine learning can be cast as learning\non hypergraphs that represent higher-order relations. Recent approaches for\nhypergraph learning extend graph neural networks based on message passing,\nwhich is simple yet fundamentally limited in modeling long-range dependencies\nand expressive power. On the other hand, tensor-based equivariant neural\nnetworks enjoy maximal expressiveness, but their application has been limited\nin hypergraphs due to heavy computation and strict assumptions on fixed-order\nhyperedges. We resolve these problems and present Equivariant Hypergraph Neural\nNetwork (EHNN), the first attempt to realize maximally expressive equivariant\nlayers for general hypergraph learning. We also present two practical\nrealizations of our framework based on hypernetworks (EHNN-MLP) and\nself-attention (EHNN-Transformer), which are easy to implement and\ntheoretically more expressive than most message passing approaches. We\ndemonstrate their capability in a range of hypergraph learning problems,\nincluding synthetic k-edge identification, semi-supervised classification, and\nvisual keypoint matching, and report improved performances over strong message\npassing baselines. Our implementation is available at\nhttps://github.com/jw9730/ehnn.",
    "descriptor": "\nComments: 29 pages, 2 figures\n",
    "authors": [
      "Jinwoo Kim",
      "Saeyoon Oh",
      "Sungjun Cho",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10428"
  },
  {
    "id": "arXiv:2208.10429",
    "title": "Patient-level Microsatellite Stability Assessment from Whole Slide  Images By Combining Momentum Contrast Learning and Group Patch Embeddings",
    "abstract": "Assessing microsatellite stability status of a patient's colorectal cancer is\ncrucial in personalizing treatment regime. Recently,\nconvolutional-neural-networks (CNN) combined with transfer-learning approaches\nwere proposed to circumvent traditional laboratory testing for determining\nmicrosatellite status from hematoxylin and eosin stained biopsy whole slide\nimages (WSI). However, the high resolution of WSI practically prevent direct\nclassification of the entire WSI. Current approaches bypass the WSI high\nresolution by first classifying small patches extracted from the WSI, and then\naggregating patch-level classification logits to deduce the patient-level\nstatus. Such approaches limit the capacity to capture important information\nwhich resides at the high resolution WSI data. We introduce an effective\napproach to leverage WSI high resolution information by momentum contrastive\nlearning of patch embeddings along with training a patient-level classifier on\ngroups of those embeddings. Our approach achieves up to 7.4\\% better accuracy\ncompared to the straightforward patch-level classification and patient level\naggregation approach with a higher stability (AUC, $0.91 \\pm 0.01$ vs. $0.85\n\\pm 0.04$, p-value$<0.01$). Our code can be found at\nhttps://github.com/TechnionComputationalMRILab/colorectal_cancer_ai.",
    "descriptor": "\nComments: To appear in the proceedings of the ECCV workshop on Medical Computer Vision (ECCV-MCV 2022). Link: this https URL\n",
    "authors": [
      "Daniel Shats",
      "Hadar Hezi",
      "Guy Shani",
      "Yosef E. Maruvka",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.10429"
  },
  {
    "id": "arXiv:2208.10431",
    "title": "ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers  for Interpretable Image Recognition",
    "abstract": "Prototypical part network (ProtoPNet) has drawn wide attention and boosted\nmany follow-up studies due to its self-explanatory property for explainable\nartificial intelligence (XAI). However, when directly applying ProtoPNet on\nvision transformer (ViT) backbones, learned prototypes have a ''distraction''\nproblem: they have a relatively high probability of being activated by the\nbackground and pay less attention to the foreground. The powerful capability of\nmodeling long-term dependency makes the transformer-based ProtoPNet hard to\nfocus on prototypical parts, thus severely impairing its inherent\ninterpretability. This paper proposes prototypical part transformer\n(ProtoPFormer) for appropriately and effectively applying the prototype-based\nmethod with ViTs for interpretable image recognition. The proposed method\nintroduces global and local prototypes for capturing and highlighting the\nrepresentative holistic and partial features of targets according to the\narchitectural characteristics of ViTs. The global prototypes are adopted to\nprovide the global view of objects to guide local prototypes to concentrate on\nthe foreground while eliminating the influence of the background. Afterwards,\nlocal prototypes are explicitly supervised to concentrate on their respective\nprototypical visual parts, increasing the overall interpretability. Extensive\nexperiments demonstrate that our proposed global and local prototypes can\nmutually correct each other and jointly make final decisions, which faithfully\nand transparently reason the decision-making processes associatively from the\nwhole and local perspectives, respectively. Moreover, ProtoPFormer consistently\nachieves superior performance and visualization results over the\nstate-of-the-art (SOTA) prototype-based baselines. Our code has been released\nat https://github.com/zju-vipa/ProtoPFormer.",
    "descriptor": "\nComments: Arxiv preprint; 9 pages, 6 figures, 2 tables\n",
    "authors": [
      "Mengqi Xue",
      "Qihan Huang",
      "Haofei Zhang",
      "Lechao Cheng",
      "Jie Song",
      "Minghui Wu",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10431"
  },
  {
    "id": "arXiv:2208.10439",
    "title": "Design and Development of Miniature long distance multi-moving robots  for 3D Smart Sensing for underground Pipe Inspection",
    "abstract": "Designing an in-pipe climbing robot that manipulates sharp gears to study\ncomplex line relationships. Traditional rolling/happening pipe climbing robots\ntend to slide when exploring pipe curves. The proposed gearbox connects to the\nfarthest ground plane of a standard dual output gearbox. Instrumentation helps\nachieve a very well-defined deceleration sequence in which the robot slides and\npulls as it moves forward. This instrument takes into account the forces\nexerted on each track within the line relationship and intentionally modifies\nthe robot's track speed, unlocking the key to fine-tuning. This makes the 3\noutput transmissions take a lot of time. Deflection of the robot on a pipe\nnetwork with various bearings and non-slip pipe bends demonstrates the\nintegrity of the proposed structure.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Alireza Pulles",
      "Weiyao Lai",
      "Erika Sahari",
      "XiaoQi Guo",
      "Marc Bernhard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10439"
  },
  {
    "id": "arXiv:2208.10441",
    "title": "The GENEA Challenge 2022: A large evaluation of data-driven co-speech  gesture generation",
    "abstract": "This paper reports on the second GENEA Challenge to benchmark data-driven\nautomatic co-speech gesture generation. Participating teams used the same\nspeech and motion dataset to build gesture-generation systems. Motion generated\nby all these systems was rendered to video using a standardised visualisation\npipeline and evaluated in several large, crowdsourced user studies. Unlike when\ncomparing different research papers, differences in results are here only due\nto differences between methods, enabling direct comparison between systems.\nThis year's dataset was based on 18 hours of full-body motion capture,\nincluding fingers, of different persons engaging in dyadic conversation. Ten\nteams participated in the challenge across two tiers: full-body and upper-body\ngesticulation. For each tier we evaluated both the human-likeness of the\ngesture motion and its appropriateness for the specific speech signal. Our\nevaluations decouple human-likeness from gesture appropriateness, which\npreviously was a major challenge in the field.\nThe evaluation results are a revolution, and a revelation. Some synthetic\nconditions are rated as significantly more human-like than human motion\ncapture. To the best of our knowledge, this has never been shown before on a\nhigh-fidelity avatar. On the other hand, all synthetic motion is found to be\nvastly less appropriate for the speech than the original motion-capture\nrecordings. Additional material is available via the project website at\nhttps://youngwoo-yoon.github.io/GENEAchallenge2022/",
    "descriptor": "\nComments: 12 pages, 5 figures; final version for ACM ICMI 2022\n",
    "authors": [
      "Youngwoo Yoon",
      "Pieter Wolfert",
      "Taras Kucherenko",
      "Carla Viegas",
      "Teodor Nikolov",
      "Mihail Tsakov",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.10441"
  },
  {
    "id": "arXiv:2208.10442",
    "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and  Vision-Language Tasks",
    "abstract": "A big convergence of language, vision, and multimodal pretraining is\nemerging. In this work, we introduce a general-purpose multimodal foundation\nmodel BEiT-3, which achieves state-of-the-art transfer performance on both\nvision and vision-language tasks. Specifically, we advance the big convergence\nfrom three aspects: backbone architecture, pretraining task, and model scaling\nup. We introduce Multiway Transformers for general-purpose modeling, where the\nmodular architecture enables both deep fusion and modality-specific encoding.\nBased on the shared backbone, we perform masked \"language\" modeling on images\n(Imglish), texts (English), and image-text pairs (\"parallel sentences\") in a\nunified manner. Experimental results show that BEiT-3 obtains state-of-the-art\nperformance on object detection (COCO), semantic segmentation (ADE20K), image\nclassification (ImageNet), visual reasoning (NLVR2), visual question answering\n(VQAv2), image captioning (COCO), and cross-modal retrieval (Flickr30K, COCO).",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Wenhui Wang",
      "Hangbo Bao",
      "Li Dong",
      "Johan Bjorck",
      "Zhiliang Peng",
      "Qiang Liu",
      "Kriti Aggarwal",
      "Owais Khan Mohammed",
      "Saksham Singhal",
      "Subhojit Som",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10442"
  },
  {
    "id": "arXiv:2208.10443",
    "title": "Rapid evaluation of Newtonian potentials on planar domains",
    "abstract": "The accurate and efficient evaluation of Newtonian potentials over general\n2-D domains is a subject of great importance for the numerical solution of\nPoisson's equation and volume integral equations. Complicated domains typically\nrequire discretization by unstructured meshes, over which the direct evaluation\nof the potential by quadrature becomes costly. In this paper, we present a\nsimple and effective algorithm for computing Newtonian potentials, based on the\nuse of Green's third identity for transforming the volume integral into a\ncollection of boundary integrals, which can then be easily handled by the\nHelsing-Ojala method. As a result, the time cost of the classically expensive\nnear field and self-interaction computations over an unstructured mesh becomes\nroughly the same as the time cost of the FMM-based far field interaction\ncomputation. One of the key components of our algorithm is the high-order 2-D\nmonomial expansion approximation of a function over a mesh element, which is\noften regarded as an ill-conditioned problem, since it involves the solution of\na Vandermonde linear system. In fact, it has long been observed that, when the\nfunction is sufficiently smooth, and when an appropriate linear system solver\nis used, the resulting monomial expansion can approximate the function\nuniformly to high accuracy. We rigorously formalize this observation in this\npaper. The performance of our algorithm is illustrated through several\nnumerical experiments.",
    "descriptor": "\nComments: 31 pages, 4 tables, 6 figures\n",
    "authors": [
      "Zewen Shen",
      "Kirill Serkh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10443"
  },
  {
    "id": "arXiv:2208.10445",
    "title": "Membership-Doctor: Comprehensive Assessment of Membership Inference  Against Machine Learning Models",
    "abstract": "Machine learning models are prone to memorizing sensitive data, making them\nvulnerable to membership inference attacks in which an adversary aims to infer\nwhether an input sample was used to train the model. Over the past few years,\nresearchers have produced many membership inference attacks and defenses.\nHowever, these attacks and defenses employ a variety of strategies and are\nconducted in different models and datasets. The lack of comprehensive\nbenchmark, however, means we do not understand the strengths and weaknesses of\nexisting attacks and defenses.\nWe fill this gap by presenting a large-scale measurement of different\nmembership inference attacks and defenses. We systematize membership inference\nthrough the study of nine attacks and six defenses and measure the performance\nof different attacks and defenses in the holistic evaluation. We then quantify\nthe impact of the threat model on the results of these attacks. We find that\nsome assumptions of the threat model, such as same-architecture and\nsame-distribution between shadow and target models, are unnecessary. We are\nalso the first to execute attacks on the real-world data collected from the\nInternet, instead of laboratory datasets. We further investigate what\ndetermines the performance of membership inference attacks and reveal that the\ncommonly believed overfitting level is not sufficient for the success of the\nattacks. Instead, the Jensen-Shannon distance of entropy/cross-entropy between\nmember and non-member samples correlates with attack performance much better.\nThis gives us a new way to accurately predict membership inference risks\nwithout running the attack. Finally, we find that data augmentation degrades\nthe performance of existing attacks to a larger extent, and we propose an\nadaptive attack using augmentation to train shadow and attack models that\nimprove attack performance.",
    "descriptor": "",
    "authors": [
      "Xinlei He",
      "Zheng Li",
      "Weilin Xu",
      "Cory Cornelius",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10445"
  },
  {
    "id": "arXiv:2208.10448",
    "title": "Dialogue Term Extraction using Transfer Learning and Topological Data  Analysis",
    "abstract": "Goal oriented dialogue systems were originally designed as a natural language\ninterface to a fixed data-set of entities that users might inquire about,\nfurther described by domain, slots, and values. As we move towards adaptable\ndialogue systems where knowledge about domains, slots, and values may change,\nthere is an increasing need to automatically extract these terms from raw\ndialogues or related non-dialogue data on a large scale. In this paper, we take\nan important step in this direction by exploring different features that can\nenable systems to discover realizations of domains, slots, and values in\ndialogues in a purely data-driven fashion. The features that we examine stem\nfrom word embeddings, language modelling features, as well as topological\nfeatures of the word embedding space. To examine the utility of each feature\nset, we train a seed model based on the widely used MultiWOZ data-set. Then, we\napply this model to a different corpus, the Schema-Guided Dialogue data-set.\nOur method outperforms the previously proposed approach that relies solely on\nword embeddings. We also demonstrate that each of the features is responsible\nfor discovering different kinds of content. We believe our results warrant\nfurther research towards ontology induction, and continued harnessing of\ntopological data analysis for dialogue and natural language processing\nresearch.",
    "descriptor": "\nComments: Accepted as a long paper to SIGDIAL 2022 (Edinburgh)\n",
    "authors": [
      "Renato Vukovic",
      "Michael Heck",
      "Benjamin Matthias Ruppik",
      "Carel van Niekerk",
      "Marcus Zibrowius",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.10448"
  },
  {
    "id": "arXiv:2208.10449",
    "title": "SCONE: Surface Coverage Optimization in Unknown Environments by  Volumetric Integration",
    "abstract": "Next Best View computation (NBV) is a long-standing problem in robotics, and\nconsists in identifying the next most informative sensor position(s) for\nreconstructing a 3D object or scene efficiently and accurately. Like most\ncurrent methods, we consider NBV prediction from a depth sensor. Learning-based\nmethods relying on a volumetric representation of the scene are suitable for\npath planning, but do not scale well with the size of the scene and have lower\naccuracy than methods using a surface-based representation. However, the latter\nconstrain the camera to a small number of poses. To obtain the advantages of\nboth representations, we show that we can maximize surface metrics by Monte\nCarlo integration over a volumetric representation. Our method scales to large\nscenes and handles free camera motion: It takes as input an arbitrarily large\npoint cloud gathered by a depth sensor like Lidar systems as well as camera\nposes to predict NBV. We demonstrate our approach on a novel dataset made of\nlarge and complex 3D scenes.",
    "descriptor": "",
    "authors": [
      "Antoine Gu\u00e9don",
      "Pascal Monasse",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10449"
  },
  {
    "id": "arXiv:2208.10451",
    "title": "Minimax AUC Fairness: Efficient Algorithm with Provable Convergence",
    "abstract": "The use of machine learning models in consequential decision making often\nexacerbates societal inequity, in particular yielding disparate impact on\nmembers of marginalized groups defined by race and gender. The area under the\nROC curve (AUC) is widely used to evaluate the performance of a scoring\nfunction in machine learning, but is studied in algorithmic fairness less than\nother performance metrics. Due to the pairwise nature of the AUC, defining an\nAUC-based group fairness metric is pairwise-dependent and may involve both\n\\emph{intra-group} and \\emph{inter-group} AUCs. Importantly, considering only\none category of AUCs is not sufficient to mitigate unfairness in AUC\noptimization. In this paper, we propose a minimax learning and bias mitigation\nframework that incorporates both intra-group and inter-group AUCs while\nmaintaining utility. Based on this Rawlsian framework, we design an efficient\nstochastic optimization algorithm and prove its convergence to the minimum\ngroup-level AUC. We conduct numerical experiments on both synthetic and\nreal-world datasets to validate the effectiveness of the minimax framework and\nthe proposed optimization algorithm.",
    "descriptor": "",
    "authors": [
      "Zhenhuan Yang",
      "Yan Lok Ko",
      "Kush R. Varshney",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.10451"
  },
  {
    "id": "arXiv:2208.10455",
    "title": "Examining Audio Communication Mechanisms for Supervising Fleets of  Agricultural Robots",
    "abstract": "Agriculture is facing a labor crisis, leading to increased interest in fleets\nof small, under-canopy robots (agbots) that can perform precise, targeted\nactions (e.g., crop scouting, weeding, fertilization), while being supervised\nby human operators remotely. However, farmers are not necessarily experts in\nrobotics technology and will not adopt technologies that add to their workload\nor do not provide an immediate payoff. In this work, we explore methods for\ncommunication between a remote human operator and multiple agbots and examine\nthe impact of audio communication on the operator's preferences and\nproductivity. We develop a simulation platform where agbots are deployed across\na field, randomly encounter failures, and call for help from the operator. As\nthe agbots report errors, various audio communication mechanisms are tested to\nconvey which robot failed and what type of failure occurs. The human is tasked\nwith verbally diagnosing the failure while completing a secondary task. A user\nstudy was conducted to test three audio communication methods: earcons,\nsingle-phrase commands, and full sentence communication. Each participant\ncompleted a survey to determine their preferences and each method's overall\neffectiveness. Our results suggest that the system using single phrases is the\nmost positively perceived by participants and may allow for the human to\ncomplete the secondary task more efficiently. The code is available at:\nhttps://github.com/akamboj2/Agbot-Sim.",
    "descriptor": "\nComments: Camera ready version for IEEE RO-MAN 2022\n",
    "authors": [
      "Abhi Kamboj",
      "Tianchen Ji",
      "Katie Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2208.10455"
  },
  {
    "id": "arXiv:2208.10456",
    "title": "Verification-Preserving Inlining in Automatic Separation Logic Verifiers  (extended version)",
    "abstract": "Bounded verification has proved useful to detect bugs and to increase\nconfidence in the correctness of a program. In contrast to unbounded\nverification, reasoning about calls via (bounded) inlining and about loops via\n(bounded) unrolling does not require method specifications and loop invariants\nand, therefore, reduces the annotation overhead to the bare minimum, namely\nspecifications of the properties to be verified. For verifiers based on\ntraditional program logics, verification via inlining (and unrolling) is\nverification-preserving: successful unbounded verification of a program w.r.t.\nsome annotation implies successful verification of the inlined program. That\nis, any error detected in the inlined program reveals a true error in the\noriginal program. However, this essential property might not hold for automatic\nseparation logic verifiers such as Caper, GRASShopper, RefinedC, Steel,\nVeriFast, and verifiers based on Viper. In this setting, inlining generally\nchanges the resources owned by method executions, which may affect automatic\nproof search algorithms and introduce spurious errors.\nIn this paper, we present the first technique for verification-preserving\ninlining in automatic separation logic verifiers. We identify a semantic\ncondition on programs and prove in Isabelle/HOL that it ensures\nverification-preserving inlining for state-of-the-art automatic separation\nlogic verifiers. We also prove a dual result: successful verification of the\ninlined program ensures that there are method and loop annotations that enable\nthe verification of the original program for bounded executions. To check our\nsemantic condition automatically, we present two approximations that can be\nchecked syntactically and with a program verifier, respectively. We implemented\nthese checks in Viper and demonstrate that they are effective for non-trivial\nexamples from different verifiers.",
    "descriptor": "",
    "authors": [
      "Thibault Dardinier",
      "Gaurav Parthasarathy",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10456"
  },
  {
    "id": "arXiv:2208.10458",
    "title": "Minimax-Optimal Multi-Agent RL in Zero-Sum Markov Games With a  Generative Model",
    "abstract": "This paper is concerned with two-player zero-sum Markov games -- arguably the\nmost basic setting in multi-agent reinforcement learning -- with the goal of\nlearning a Nash equilibrium (NE) sample-optimally. All prior results suffer\nfrom at least one of the two obstacles: the curse of multiple agents and the\nbarrier of long horizon, regardless of the sampling protocol in use. We take a\nstep towards settling this problem, assuming access to a flexible sampling\nmechanism: the generative model. Focusing on non-stationary finite-horizon\nMarkov games, we develop a learning algorithm\n$\\mathsf{Nash}\\text{-}\\mathsf{Q}\\text{-}\\mathsf{FTRL}$ and an adaptive sampling\nscheme that leverage the optimism principle in adversarial learning\n(particularly the Follow-the-Regularized-Leader (FTRL) method), with a delicate\ndesign of bonus terms that ensure certain decomposability under the FTRL\ndynamics. Our algorithm learns an $\\varepsilon$-approximate Markov NE policy\nusing\n$$ \\widetilde{O}\\bigg( \\frac{H^4 S(A+B)}{\\varepsilon^2} \\bigg) $$ samples,\nwhere $S$ is the number of states, $H$ is the horizon, and $A$ (resp.~$B$)\ndenotes the number of actions for the max-player (resp.~min-player). This is\nnearly un-improvable in a minimax sense. Along the way, we derive a refined\nregret bound for FTRL that makes explicit the role of variance-type quantities,\nwhich might be of independent interest.",
    "descriptor": "",
    "authors": [
      "Gen Li",
      "Yuejie Chi",
      "Yuting Wei",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.10458"
  },
  {
    "id": "arXiv:2208.10460",
    "title": "Towards Clause Learning \u00e0 la Carte through VarMonads",
    "abstract": "More and more languages have a need for constraint solving capabilities for\nfeatures like error detection or automatic code generation. Imagine a\ndependently typed language that can immediately implement a program as soon as\nits type is given. In SAT-solving, there have been several techniques to speed\nup a search process for satisfying assignments to variables that could be used\nfor program synthesis. One of these techniques is clause learning where, if a\nsearch branch runs into a conflict, the cause of the conflict is analysed and\nused to create a new clause that lets a branch fail earlier if the conflict\narises again. We provide a framework with which this technique can come for\nfree not just for Boolean solvers, but for any constraint solver running on\nrecursive algebraic data types. We achieve this by tracking the read operations\nthat happen before a variable is assigned and use this information to create\nthe dependency graph needed for conflict analysis.\nOur results are implemented in Agda for best readability, but they transfer\nto other functional languages as well. For brevity, we do not provide an entire\nsearch system utilizing the clause learning, but it will become clear from the\nformalisms that our technique indeed enables a clause learning search system to\nbe built.",
    "descriptor": "\nComments: Paper presented at the 32nd International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2022), Tbilisi, Georgia, and Virtual, September 22-23, 2022 (arXiv:2208.04235)\n",
    "authors": [
      "Arved Friedemann",
      "Oliver Keszocze"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.10460"
  },
  {
    "id": "arXiv:2208.10462",
    "title": "Shapelet-Based Counterfactual Explanations for Multivariate Time Series",
    "abstract": "As machine learning and deep learning models have become highly prevalent in\na multitude of domains, the main reservation in their adoption for\ndecision-making processes is their black-box nature. The Explainable Artificial\nIntelligence (XAI) paradigm has gained a lot of momentum lately due to its\nability to reduce models opacity. XAI methods have not only increased\nstakeholders' trust in the decision process but also helped developers ensure\nits fairness. Recent efforts have been invested in creating transparent models\nand post-hoc explanations. However, fewer methods have been developed for time\nseries data, and even less when it comes to multivariate datasets. In this\nwork, we take advantage of the inherent interpretability of shapelets to\ndevelop a model agnostic multivariate time series (MTS) counterfactual\nexplanation algorithm. Counterfactuals can have a tremendous impact on making\nblack-box models explainable by indicating what changes have to be performed on\nthe input to change the final decision. We test our approach on a real-life\nsolar flare prediction dataset and prove that our approach produces\nhigh-quality counterfactuals. Moreover, a comparison to the only MTS\ncounterfactual generation algorithm shows that, in addition to being visually\ninterpretable, our explanations are superior in terms of proximity, sparsity,\nand plausibility.",
    "descriptor": "\nComments: Appeared in ACM SIGKDD Workshop on Mining and Learning from Time Series (KDD-MiLeTS 2022)\n",
    "authors": [
      "Omar Bahri",
      "Soukaina Filali Boubrahimi",
      "Shah Muhammad Hamdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10462"
  },
  {
    "id": "arXiv:2208.10463",
    "title": "Survey of Machine Learning Techniques To Predict Heartbeat Arrhythmias",
    "abstract": "Many works in biomedical computer science research use machine learning\ntechniques to give accurate results. However, these techniques may not be\nfeasible for real-time analysis of data pulled from live hospital feeds. In\nthis project, different machine learning techniques are compared from various\nsources to find one that provides not only high accuracy but also low latency\nand memory overhead to be used in real-world health care systems.",
    "descriptor": "",
    "authors": [
      "Samuel Armstrong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.10463"
  },
  {
    "id": "arXiv:2208.10469",
    "title": "Get It in Writing: Formal Contracts Mitigate Social Dilemmas in  Multi-Agent RL",
    "abstract": "Multi-agent reinforcement learning (MARL) is a powerful tool for training\nautomated systems acting independently in a common environment. However, it can\nlead to sub-optimal behavior when individual incentives and group incentives\ndiverge. Humans are remarkably capable at solving these social dilemmas. It is\nan open problem in MARL to replicate such cooperative behaviors in selfish\nagents. In this work, we draw upon the idea of formal contracting from\neconomics to overcome diverging incentives between agents in MARL. We propose\nan augmentation to a Markov game where agents voluntarily agree to binding\nstate-dependent transfers of reward, under pre-specified conditions. Our\ncontributions are theoretical and empirical. First, we show that this\naugmentation makes all subgame-perfect equilibria of all fully observed Markov\ngames exhibit socially optimal behavior, given a sufficiently rich space of\ncontracts. Next, we complement our game-theoretic analysis by showing that\nstate-of-the-art RL algorithms learn socially optimal policies given our\naugmentation. Our experiments include classic static dilemmas like Stag Hunt,\nPrisoner's Dilemma and a public goods game, as well as dynamic interactions\nthat simulate traffic, pollution management and common pool resource\nmanagement.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Phillip J.K. Christoffersen",
      "Andreas A. Haupt",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2208.10469"
  },
  {
    "id": "arXiv:2208.10472",
    "title": "Automated Pruning of Polyculture Plants",
    "abstract": "Polyculture farming has environmental advantages but requires substantially\nmore pruning than monoculture farming. We present novel hardware and algorithms\nfor automated pruning. Using an overhead camera to collect data from a physical\nscale garden testbed, the autonomous system utilizes a learned Plant\nPhenotyping convolutional neural network and a Bounding Disk Tracking algorithm\nto evaluate the individual plant distribution and estimate the state of the\ngarden each day. From this garden state, AlphaGardenSim selects plants to\nautonomously prune. A trained neural network detects and targets specific prune\npoints on the plant. Two custom-designed pruning tools, compatible with a\nFarmBot gantry system, are experimentally evaluated and execute autonomous cuts\nthrough controlled algorithms. We present results for four 60-day garden\ncycles. Results suggest the system can autonomously achieve 0.94 normalized\nplant diversity with pruning shears while maintaining an average canopy\ncoverage of 0.84 by the end of the cycles. For code, videos, and datasets, see\nhttps://sites.google.com/berkeley.edu/pruningpolyculture.",
    "descriptor": "\nComments: CASE 2022, 8 pages. arXiv admin note: substantial text overlap with arXiv:2111.06014\n",
    "authors": [
      "Mark Presten",
      "Rishi Parikh",
      "Shrey Aeron",
      "Sandeep Mukherjee",
      "Simeon Adebola",
      "Satvik Sharma",
      "Mark Theis",
      "Walter Teitelbaum",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10472"
  },
  {
    "id": "arXiv:2208.10473",
    "title": "Autonomous Ground Navigation in Highly Constrained Spaces: Lessons  learned from The BARN Challenge at ICRA 2022",
    "abstract": "The BARN (Benchmark Autonomous Robot Navigation) Challenge took place at the\n2022 IEEE International Conference on Robotics and Automation (ICRA 2022) in\nPhiladelphia, PA. The aim of the challenge was to evaluate state-of-the-art\nautonomous ground navigation systems for moving robots through highly\nconstrained environments in a safe and efficient manner. Specifically, the task\nwas to navigate a standardized, differential-drive ground robot from a\npredefined start location to a goal location as quickly as possible without\ncolliding with any obstacles, both in simulation and in the real world. Five\nteams from all over the world participated in the qualifying simulation\ncompetition, three of which were invited to compete with each other at a set of\nphysical obstacle courses at the conference center in Philadelphia. The\ncompetition results suggest that autonomous ground navigation in highly\nconstrained spaces, despite seeming ostensibly simple even for experienced\nroboticists, is actually far from being a solved problem. In this article, we\ndiscuss the challenge, the approaches used by the top three winning teams, and\nlessons learned to direct future research.",
    "descriptor": "",
    "authors": [
      "Xuesu Xiao",
      "Zifan Xu",
      "Zizhao Wang",
      "Yunlong Song",
      "Garrett Warnell",
      "Peter Stone",
      "Tingnan Zhang",
      "Shravan Ravi",
      "Gary Wang",
      "Haresh Karnan",
      "Joydeep Biswas",
      "Nicholas Mohammad",
      "Lauren Bramblett",
      "Rahul Peddi",
      "Nicola Bezzo",
      "Zhanteng Xie",
      "Philip Dames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10473"
  },
  {
    "id": "arXiv:2208.10478",
    "title": "Secret-Key Agreement Using Physical Identifiers for Degraded and Less  Noisy Authentication Channels",
    "abstract": "Secret-key agreement based on biometric or physical identifiers is a\npromising security protocol for authenticating users or devices with small\nchips and has been extensively studied recently. Kittichokechai and Caire\n(2015) investigated the optimal trade-off in a secret-key agreement model with\nphysical identifiers, where the structure of the authentication channels is\nsimilar to the wiretap channels, from information-theoretic approaches. Later,\nthe model was extended by G\\\"unl\\\"u et al.\\ (2018) introducing noise in the\nenrollment phase and cost-constrained actions at the decoder. The results of\nthese studies show that two auxiliary random variables are involved in the\nexpressions of the optimal rate regions of secret-key, storage, and\nprivacy-leakage rates. However, with these two auxiliary random variables, the\ncomplexity of computing the rate region may be prohibitively high. Due to this\nproblem, we are interested in exploring classes of authentication channels that\nneed only one auxiliary random variable in the capacity region expression for\ndiscrete source settings. The result shows for the class of degraded and less\nnoisy authentication channels, a single auxiliary random variable is sufficient\nto express the capacity region of the model. As an example, we also derive the\ncapacity region of secret-key, storage, and privacy-leakage rates for binary\nsources. Furthermore, the capacity region for scalar Gaussian sources is\nderived under Gaussian authentication channels.",
    "descriptor": "\nComments: This work is accepted to be presented at ITW 2022\n",
    "authors": [
      "Vamoua Yachongka",
      "Hideki Yagi",
      "Hideki Ochiai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.10478"
  },
  {
    "id": "arXiv:2208.10480",
    "title": "Regular languages defined by first-order formulas without quantifier  alternation",
    "abstract": "We give a simple new proof that regular languages defined by first-order\nsentences with no quantifier alteration can be defined by such sentences in\nwhich only regular atomic formulas appear. Earlier proofs of this fact relied\non arguments from circuit complexity or algebra. Our proof is much more\nelementary, and uses only the most basic facts about finite automata.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Andreas Krebs",
      "Howard Straubing"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2208.10480"
  },
  {
    "id": "arXiv:2208.10481",
    "title": "BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based  Reinforcement Learning",
    "abstract": "Robustness to adversarial perturbations has been explored in many areas of\ncomputer vision. This robustness is particularly relevant in vision-based\nreinforcement learning, as the actions of autonomous agents might be\nsafety-critic or impactful in the real world. We investigate the susceptibility\nof vision-based reinforcement learning agents to gradient-based adversarial\nattacks and evaluate a potential defense. We observe that Bottleneck Attention\nModules (BAM) included in CNN architectures can act as potential tools to\nincrease robustness against adversarial attacks. We show how learned attention\nmaps can be used to recover activations of a convolutional layer by restricting\nthe spatial activations to salient regions. Across a number of RL environments,\nBAM-enhanced architectures show increased robustness during inference. Finally,\nwe discuss potential future research directions.",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables\n",
    "authors": [
      "Eugene Bykovets",
      "Yannick Metz",
      "Mennatallah El-Assady",
      "Daniel A. Keim",
      "Joachim M. Buhmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10481"
  },
  {
    "id": "arXiv:2208.10483",
    "title": "Prioritizing Samples in Reinforcement Learning with Reducible Loss",
    "abstract": "Most reinforcement learning algorithms take advantage of an experience replay\nbuffer to repeatedly train on samples the agent has observed in the past. This\nprevents catastrophic forgetting, however simply assigning equal importance to\neach of the samples is a naive strategy. In this paper, we propose a method to\nprioritize samples based on how much we can learn from a sample. We define the\nlearn-ability of a sample as the steady decrease of the training loss\nassociated with this sample over time. We develop an algorithm to prioritize\nsamples with high learn-ability, while assigning lower priority to those that\nare hard-to-learn, typically caused by noise or stochasticity. We empirically\nshow that our method is more robust than random sampling and also better than\njust prioritizing with respect to the training loss, i.e. the temporal\ndifference loss, which is used in vanilla prioritized experience replay.",
    "descriptor": "",
    "authors": [
      "Shivakanth Sujit",
      "Somjit Nath",
      "Pedro H. M. Braga",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10483"
  },
  {
    "id": "arXiv:2208.07166",
    "title": "Stock Performance Evaluation for Portfolio Design from Different Sectors  of the Indian Stock Market",
    "abstract": "The stock market offers a platform where people buy and sell shares of\npublicly listed companies. Generally, stock prices are quite volatile; hence\npredicting them is a daunting task. There is still much research going to\ndevelop more accuracy in stock price prediction. Portfolio construction refers\nto the allocation of different sector stocks optimally to achieve a maximum\nreturn by taking a minimum risk. A good portfolio can help investors earn\nmaximum profit by taking a minimum risk. Beginning with Dow Jones Theory a lot\nof advancement has happened in the area of building efficient portfolios. In\nthis project, we have tried to predict the future value of a few stocks from\nsix important sectors of the Indian economy and also built a portfolio. As part\nof the project, our team has conducted a study of the performance of various\nTime series, machine learning, and deep learning models in stock price\nprediction on selected stocks from the chosen six important sectors of the\neconomy. As part of building an efficient portfolio, we have studied multiple\nportfolio optimization theories beginning with the Modern Portfolio theory. We\nhave built a minimum variance portfolio and optimal risk portfolio for all the\nsix chosen sectors by using the daily stock prices over the past five years as\ntraining data and have also conducted back testing to check the performance of\nthe portfolio. We look forward to continuing our study in the area of stock\nprice prediction and asset allocation and consider this project as the first\nstepping stone.",
    "descriptor": "\nComments: The report is 113 pages long. The report is based on the capstone project done in the post graduate course of data science in Praxis Business School, Kolkata, India - Group 5 of the Autumn Batch, 2021. arXiv admin note: text overlap with arXiv:2201.05570; text overlap with arXiv:2005.11417 by other authors\n",
    "authors": [
      "Jaydip Sen",
      "Arpit Awad",
      "Aaditya Raj",
      "Gourav Ray",
      "Pusparna Chakraborty",
      "Sanket Das",
      "Subhasmita Mishra"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07166"
  },
  {
    "id": "arXiv:2208.09481",
    "title": "Graph neural networks for materials science and chemistry",
    "abstract": "Machine learning plays an increasingly important role in many areas of\nchemistry and materials science, e.g. to predict materials properties, to\naccelerate simulations, to design new materials, and to predict synthesis\nroutes of new materials. Graph neural networks (GNNs) are one of the fastest\ngrowing classes of machine learning models. They are of particular relevance\nfor chemistry and materials science, as they directly work on a graph or\nstructural representation of molecules and materials and therefore have full\naccess to all relevant information required to characterize materials. In this\nreview article, we provide an overview of the basic principles of GNNs, widely\nused datasets, and state-of-the-art architectures, followed by a discussion of\na wide range of recent applications of GNNs in chemistry and materials science,\nand concluding with a road-map for the further development and application of\nGNNs.",
    "descriptor": "\nComments: 37 pages, 2 figures\n",
    "authors": [
      "Patrick Reiser",
      "Marlen Neubert",
      "Andr\u00e9 Eberhard",
      "Luca Torresi",
      "Chen Zhou",
      "Chen Shao",
      "Houssam Metni",
      "Clint van Hoesel",
      "Henrik Schopmans",
      "Timo Sommer",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09481"
  },
  {
    "id": "arXiv:2208.09483",
    "title": "Blind Image Deblurring with Unknown Kernel Size and Substantial Noise",
    "abstract": "Blind image deblurring (BID) has been extensively studied in computer vision\nand adjacent fields. Modern methods for BID can be grouped into two categories:\nsingle-instance methods that deal with individual instances using statistical\ninference and numerical optimization, and data-driven methods that train\ndeep-learning models to deblur future instances directly. Data-driven methods\ncan be free from the difficulty in deriving accurate blur models, but are\nfundamentally limited by the diversity and quality of the training data --\ncollecting sufficiently expressive and realistic training data is a standing\nchallenge. In this paper, we focus on single-instance methods that remain\ncompetitive and indispensable. However, most such methods do not prescribe how\nto deal with unknown kernel size and substantial noise, precluding practical\ndeployment. Indeed, we show that several state-of-the-art (SOTA)\nsingle-instance methods are unstable when the kernel size is overspecified,\nand/or the noise level is high. On the positive side, we propose a practical\nBID method that is stable against both, the first of its kind. Our method\nbuilds on the recent ideas of solving inverse problems by integrating the\nphysical models and structured deep neural networks, without extra training\ndata. We introduce several crucial modifications to achieve the desired\nstability. Extensive empirical tests on standard synthetic datasets, as well as\nreal-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and\npracticality of our BID method compared to SOTA single-instance as well as\ndata-driven methods. The code of our method is available at:\n\\url{https://github.com/sun-umn/Blind-Image-Deblurring}.",
    "descriptor": "",
    "authors": [
      "Zhong Zhuang",
      "Taihui Li",
      "Hengkang Wang",
      "Ju Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.09483"
  },
  {
    "id": "arXiv:2208.09484",
    "title": "In Silico Prediction of Blood-Brain Barrier Permeability of Chemical  Compounds through Molecular Feature Modeling",
    "abstract": "The introduction of computational techniques to analyze chemical data has\ngiven rise to the analytical study of biological systems, known as\n\"bioinformatics\". One facet of bioinformatics is using machine learning (ML)\ntechnology to detect multivariable trends in various cases. Amongst the most\npressing cases is predicting blood-brain barrier (BBB) permeability. The\ndevelopment of new drugs to treat central nervous system disorders presents\nunique challenges due to poor penetration efficacy across the blood-brain\nbarrier. In this research, we aim to mitigate this problem through an ML model\nthat analyzes chemical features. To do so: (i) An overview into the relevant\nbiological systems and processes as well as the use case is given. (ii) Second,\nan in-depth literature review of existing computational techniques for\ndetecting BBB permeability is undertaken. From there, an aspect unexplored\nacross current techniques is identified and a solution is proposed. (iii)\nLastly, a two-part in silico model to quantify likelihood of permeability of\ndrugs with defined features across the BBB through passive diffusion is\ndeveloped, tested, and reflected on. Testing and validation with the dataset\ndetermined the predictive logBB model's mean squared error to be around 0.112\nunits and the neuroinflammation model's mean squared error to be approximately\n0.3 units, outperforming all relevant studies found.",
    "descriptor": "\nComments: Editor Praveen Kumar Pandian Shanmuganathan, 17 pages, 5 figures\n",
    "authors": [
      "Tanish Jain",
      "Praveen Kumar Pandian Shanmuganathan"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09484"
  },
  {
    "id": "arXiv:2208.09512",
    "title": "Exploring the Limits of Synthetic Creation of Solar EUV Images via  Image-to-Image Translation",
    "abstract": "The Solar Dynamics Observatory (SDO), a NASA multi-spectral decade-long\nmission that has been daily producing terabytes of observational data from the\nSun, has been recently used as a use-case to demonstrate the potential of\nmachine learning methodologies and to pave the way for future deep-space\nmission planning. In particular, the idea of using image-to-image translation\nto virtually produce extreme ultra-violet channels has been proposed in several\nrecent studies, as a way to both enhance missions with less available channels\nand to alleviate the challenges due to the low downlink rate in deep space.\nThis paper investigates the potential and the limitations of such a deep\nlearning approach by focusing on the permutation of four channels and an\nencoder--decoder based architecture, with particular attention to how\nmorphological traits and brightness of the solar surface affect the neural\nnetwork predictions. In this work we want to answer the question: can synthetic\nimages of the solar corona produced via image-to-image translation be used for\nscientific studies of the Sun? The analysis highlights that the neural network\nproduces high-quality images over three orders of magnitude in count rate\n(pixel intensity) and can generally reproduce the covariance across channels\nwithin a 1% error. However the model performance drastically diminishes in\ncorrespondence of extremely high energetic events like flares, and we argue\nthat the reason is related to the rareness of such events posing a challenge to\nmodel training.",
    "descriptor": "\nComments: 16 pages, 8 figures. To be published on ApJ (submitted on Feb 21st, accepted on July 28th)\n",
    "authors": [
      "Valentina Salvatelli",
      "Luiz F. G. dos Santos",
      "Souvik Bose",
      "Brad Neuberg",
      "Mark C. M. Cheung",
      "Miho Janvier",
      "Meng Jin",
      "Yarin Gal",
      "Atilim Gunes Baydin"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09512"
  },
  {
    "id": "arXiv:2208.09538",
    "title": "Predicting Exotic Hadron Masses with Data Augmentation Using Multilayer  Perceptron",
    "abstract": "Recently, there have been significant developments in neural networks; thus,\nneural networks have been frequently used in the physics literature. This work\nestimates the masses of exotic hadrons, doubly charmed and bottomed baryons\nfrom the meson and baryon masses using neural networks. Subsequently, the\nnumber of data has been increased using the artificial data augmentation\ntechnique proposed recently. We have observed that the neural network's\npredictive ability increases using augmented data. This study has shown that\ndata augmentation techniques play an essential role in improving neural network\npredictions; moreover, neural networks can make reasonable predictions for\nexotic hadrons, doubly charmed, and doubly bottomed baryons. The results are\nalso comparable to Gaussian Process and Constituent Quark Model.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Huseyin Bahtiyar"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2208.09538"
  },
  {
    "id": "arXiv:2208.09550",
    "title": "Sudakov-Fernique post-AMP, and a new proof of the local convexity of the  TAP free energy",
    "abstract": "In many problems in modern statistics and machine learning, it is often of\ninterest to establish that a first order method on a non-convex risk function\neventually enters a region of parameter space in which the risk is locally\nconvex. We derive an asymptotic comparison inequality, which we call the\nSudakov-Fernique post-AMP inequality, which, in a certain class of problems\ninvolving a GOE matrix, is able to probe properties of an optimization\nlandscape locally around the iterates of an approximate message passing (AMP)\nalgorithm. As an example of its use, we provide a new, and arguably simpler,\nproof of some of the results of Celentano et al. (2021), which establishes that\nthe so-called TAP free energy in the $\\mathbb{Z}_2$-synchronization problem is\nlocally convex in the region to which AMP converges. We further prove a\nconjecture of El Alaoui et al. (2022) involving the local convexity of a\nrelated but distinct TAP free energy, which, as a consequence, confirms that\ntheir algorithm efficiently samples from the Sherrington-Kirkpatrick Gibbs\nmeasure throughout the \"easy\" regime.",
    "descriptor": "",
    "authors": [
      "Michael Celentano"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2208.09550"
  },
  {
    "id": "arXiv:2208.09559",
    "title": "Neural network facilitated ab initio derivation of linear formula: A  case study on formulating the relationship between DNA motifs and gene  expression",
    "abstract": "Developing models with high interpretability and even deriving formulas to\nquantify relationships between biological data is an emerging need. We propose\nhere a framework for ab initio derivation of sequence motifs and linear formula\nusing a new approach based on the interpretable neural network model called\ncontextual regression model. We showed that this linear model could predict\ngene expression levels using promoter sequences with a performance comparable\nto deep neural network models. We uncovered a list of 300 motifs with important\nregulatory roles on gene expression and showed that they also had significant\ncontributions to cell-type specific gene expression in 154 diverse cell types.\nThis work illustrates the possibility of deriving formulas to represent biology\nlaws that may not be easily elucidated.\n(https://github.com/Wang-lab-UCSD/Motif_Finding_Contextual_Regression)",
    "descriptor": "",
    "authors": [
      "Chengyu Liu",
      "Wei Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09559"
  },
  {
    "id": "arXiv:2208.09576",
    "title": "Two eggs any style -- generalizing egg-drop experiments",
    "abstract": "The egg-drop experiment introduced by Konhauser, Velleman, and Wagon, later\ngeneralized by Boardman, is further generalized to two additional types. The\nthree separate types of egg-drop experiment under consideration are examined in\nthe context of binary decision trees. It is shown that all three types of\negg-drop experiment are binary decision problems that can be solved efficiently\nusing a non-redundant algorithm -- a class of algorithms introduced here. The\npreceding theoretical results are applied to the three types of egg-drop\nexperiment to compute, for each, the maximum height of a building that can be\ndealt with using a given number of egg-droppings.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Harold R. Parks",
      "Dean C. Wills"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.09576"
  },
  {
    "id": "arXiv:2208.09585",
    "title": "Sharp Analysis of Sketch-and-Project Methods via a Connection to  Randomized Singular Value Decomposition",
    "abstract": "Sketch-and-project is a framework which unifies many known iterative methods\nfor solving linear systems and their variants, as well as further extensions to\nnon-linear optimization problems. It includes popular methods such as\nrandomized Kaczmarz, coordinate descent, variants of the Newton method in\nconvex optimization, and others. In this paper, we obtain sharp guarantees for\nthe convergence rate of sketch-and-project methods via new tight spectral\nbounds for the expected sketched projection matrix. Our estimates reveal a\nconnection between the sketch-and-project convergence rate and the\napproximation error of another well-known but seemingly unrelated family of\nalgorithms, which use sketching to accelerate popular matrix factorizations\nsuch as QR and SVD. This connection brings us closer to precisely quantifying\nhow the performance of sketch-and-project solvers depends on their sketch size.\nOur analysis covers not only Gaussian and sub-gaussian sketching matrices, but\nalso a family of efficient sparse sketching methods known as LESS embeddings.\nOur experiments back up the theory and demonstrate that even extremely sparse\nsketches show the same convergence properties in practice.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Derezi\u0144ski",
      "Elizaveta Rebrova"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09585"
  },
  {
    "id": "arXiv:2208.09594",
    "title": "Transferable Cross-Tokamak Disruption Prediction with Deep Hybrid Neural  Network Feature Extractor",
    "abstract": "Predicting disruptions across different tokamaks is a great obstacle to\novercome. Future tokamaks can hardly tolerate disruptions at high performance\ndischarge. Few disruption discharges at high performance can hardly compose an\nabundant training set, which makes it difficult for current data-driven methods\nto obtain an acceptable result. A machine learning method capable of\ntransferring a disruption prediction model trained on one tokamak to another is\nrequired to solve the problem. The key is a disruption prediction model\ncontaining a feature extractor that is able to extract common disruption\nprecursor traces in tokamak diagnostic data, and a transferable disruption\nclassifier. Based on the concerns above, the paper first presents a deep fusion\nfeature extractor designed specifically for extracting disruption precursor\nfeatures from common diagnostics on tokamaks according to currently known\nprecursors of disruption, providing a promising foundation for transferable\nmodels. The fusion feature extractor is proved by comparing with manual feature\nextraction on J-TEXT. Based on the feature extractor trained on J-TEXT, the\ndisruption prediction model was transferred to EAST data with mere 20\ndischarges from EAST experiment. The performance is comparable with a model\ntrained with 1896 discharges from EAST. From the comparison among other model\ntraining scenarios, transfer learning showed its potential in predicting\ndisruptions across different tokamaks.",
    "descriptor": "",
    "authors": [
      "Wei Zheng",
      "Fengming Xue",
      "Ming Zhang",
      "Zhongyong Chen",
      "Chengshuo Shen",
      "Xinkun Ai",
      "Nengchao Wang",
      "Dalong Chen",
      "Bihao Guo",
      "Yonghua Ding",
      "Zhipeng Chen",
      "Zhoujun Yang",
      "Biao Shen",
      "Bingjia Xiao",
      "Yuan Pan"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09594"
  },
  {
    "id": "arXiv:2208.09636",
    "title": "PARSE challenge 2022: Pulmonary Arteries Segmentation using Swin U-Net  Transformer(Swin UNETR) and U-Net",
    "abstract": "In this work, we present our proposed method to segment the pulmonary\narteries from the CT scans using Swin UNETR and U-Net-based deep neural network\narchitecture. Six models, three models based on Swin UNETR, and three models\nbased on 3D U-net with residual units were ensemble using a weighted average to\nmake the final segmentation masks. Our team achieved a multi-level dice score\nof 84.36 percent through this method. The code of our work is available on the\nfollowing link: https://github.com/akansh12/parse2022. This work is part of the\nMICCAI PARSE 2022 challenge.",
    "descriptor": "",
    "authors": [
      "Akansh Maurya",
      "Kunal Dashrath Patil",
      "Rohan Padhy",
      "Kalluri Ramakrishna",
      "Ganapathy Krishnamurthi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09636"
  },
  {
    "id": "arXiv:2208.09642",
    "title": "Exploring Price Accuracy on Uniswap V3 in Times of Distress",
    "abstract": "Financial markets have evolved over centuries, and exchanges have converged\nto rely on the order book mechanism for market making. Latency on the\nblockchain, however, has prevented decentralized exchanges (DEXes) from\nutilizing the order book mechanism and instead gave rise to the development of\nmarket designs that are better suited to a blockchain. Although the first\nwidely popularized DEX, Uniswap V2, stood out through its astonishing\nsimplicity, a recent design overhaul introduced with Uniswap V3 has introduced\nincreasing levels of complexity aiming to increase capital efficiency.\nIn this work, we empirically study the ability of Unsiwap V3 to handle\nunexpected price shocks. Our analysis finds that the prices on Uniswap V3 were\ninaccurate during the recent abrupt price drops of two stablecoins: UST and\nUSDT. We identify the lack of agility required of Unsiwap V3 liquidity\nproviders as the root cause of these worrying price inaccuracies. Additionally,\nwe outline that there are too few incentives for liquidity providers to enter\nliquidity pools, given the elevated volatility in such market conditions.",
    "descriptor": "",
    "authors": [
      "Lioba Heimbach",
      "Eric Schertenleib",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.09642"
  },
  {
    "id": "arXiv:2208.09683",
    "title": "Machine learning based surrogate models for microchannel heat sink  optimization",
    "abstract": "In this paper, microchannel designs with secondary channels and with ribs are\ninvestigated using computational fluid dynamics and are coupled with a\nmulti-objective optimization algorithm to determine and propose optimal\nsolutions based on observed thermal resistance and pumping power. A workflow\nthat combines Latin hypercube sampling, machine learning-based surrogate\nmodeling and multi-objective optimization is proposed. Random forests, gradient\nboosting algorithms and neural networks were considered during the search for\nthe best surrogate. We demonstrated that tuned neural networks can make\naccurate predictions and be used to create an acceptable surrogate model.\nOptimized solutions show a negligible difference in overall performance when\ncompared to the conventional optimization approach. Additionally, solutions are\ncalculated in one-fifth of the original time. Generated designs attain\ntemperatures that are lower by more than 10% under the same pressure limits as\na convectional microchannel design. When limited by temperature, pressure drops\nare reduced by more than 25%. Finally, the influence of each design variable on\nthe thermal resistance and pumping power was investigated by employing the\nSHapley Additive exPlanations technique. Overall, we have demonstrated that the\nproposed framework has merit and can be used as a viable methodology in\nmicrochannel heat sink design optimization.",
    "descriptor": "\nComments: 30 pages, brief appendix\n",
    "authors": [
      "Ante Sikirica",
      "Luka Grb\u010di\u0107",
      "Lado Kranj\u010devi\u0107"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09683"
  },
  {
    "id": "arXiv:2208.09710",
    "title": "Adversarial contamination of networks in the setting of vertex  nomination: a new trimming method",
    "abstract": "As graph data becomes more ubiquitous, the need for robust inferential graph\nalgorithms to operate in these complex data domains is crucial. In many cases\nof interest, inference is further complicated by the presence of adversarial\ndata contamination. The effect of the adversary is frequently to change the\ndata distribution in ways that negatively affect statistical and algorithmic\nperformance. We study this phenomenon in the context of vertex nomination, a\nsemi-supervised information retrieval task for network data. Here, a common\nsuite of methods relies on spectral graph embeddings, which have been shown to\nprovide both good algorithmic performance and flexible settings in which\nregularization techniques can be implemented to help mitigate the effect of an\nadversary. Many current regularization methods rely on direct network trimming\nto effectively excise the adversarial contamination, although this direct\ntrimming often gives rise to complicated dependency structures in the resulting\ngraph. We propose a new trimming method that operates in model space which can\naddress both block structure contamination and white noise contamination\n(contamination whose distribution is unknown). This model trimming is more\namenable to theoretical analysis while also demonstrating superior performance\nin a number of simulations, compared to direct trimming.",
    "descriptor": "",
    "authors": [
      "Sheyda Peyman",
      "Minh Tang",
      "Vince Lyzinski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09710"
  },
  {
    "id": "arXiv:2208.09724",
    "title": "Conic Idempotent Residuated Lattices",
    "abstract": "We give a structural decomposition of conic idempotent residuated lattices,\nshowing that each of them is an ordinal sum of certain simpler partially\nordered structures. This ordinal sum is indexed by a totally ordered residuated\nlattice, which serves as its skeleton and is both a subalgebra and nuclear\nimage, and we equationally characterize which totally ordered residuated\nlattices appear as such skeletons. Using the two inverse operations induced by\nthe residuals, we further characterize both congruence and subalgebra\ngeneration in conic idempotent residuated lattices. We show that every variety\ngenerated by conic idempotent residuated lattices enjoys the congruence\nextension property. In particular, this holds for semilinear idempotent\nresiduated lattices. Moreover, we provide a detailed analysis of the structure\nof idempotent residuated chains serving as index sets on two levels: as certain\nenriched Galois connections and as enhanced monoidal preorders. Using this, we\nshow that although conic idempotent residuated lattices do not enjoy the\namalgamation property, the natural class of rigid and conjunctive conic\nidempotent residuated lattices has the strong amalgamation property, and\nconsequently has surjective epimorphisms. We extend this result to the variety\ngenerated by rigid and conjunctive conic idempotent residuated lattices, and\nestablish the amalgamation, strong amalgamation, and epimorphism-surjectivity\nproperties for several important subvarieties. Based on this algebraic work, we\nobtain local deduction theorems, the deductive interpolation property, and the\nprojective Beth definability property for the corresponding substructural\nlogics.",
    "descriptor": "",
    "authors": [
      "Wesley Fussner",
      "Nick Galatos"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2208.09724"
  },
  {
    "id": "arXiv:2208.09725",
    "title": "On Robustness in Nonconvex Optimization with Application to Defense  Planning",
    "abstract": "In the context of structured nonconvex optimization, we estimate the increase\nin minimum value for a decision that is robust to parameter perturbations as\ncompared to the value of a nominal problem. The estimates rely on detailed\nexpressions for subgradients and local Lipschitz moduli of min-value functions\nin nonconvex robust optimization and require only the solution of the nominal\nproblem. The theoretical results are illustrated by examples from military\noperations research involving mixed-integer optimization models. Across 54\ncases examined, the median error in estimating the increase in minimum value is\n12%. Therefore, the derived expressions for subgradients and local Lipschitz\nmoduli may accurately inform analysts about the possibility of obtaining\ncost-effective, parameter-robust decisions in nonconvex optimization.",
    "descriptor": "",
    "authors": [
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09725"
  },
  {
    "id": "arXiv:2208.09762",
    "title": "Some improved bounds in sampling discretization of integral norms",
    "abstract": "The paper addresses a problem of sampling discretization of integral norms of\nelements of finite-dimensional subspaces satisfying some conditions. We prove\nsampling discretization results under a standard assumption formulated in terms\nof the Nikol'skii-type inequality. {In particular, we obtain} some upper bounds\non the number of sample points sufficient for good discretization of the\nintegral $L_p$ norms, $1\\le p<2$, of functions from finite-dimensional\nsubspaces of continuous functions. Our new results improve upon the known\nresults in this direction. We use a new technique based on deep results of\nTalagrand from functional analysis.",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "F. Dai",
      "E. Kosov",
      "V. Temlyakov"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2208.09762"
  },
  {
    "id": "arXiv:2208.09775",
    "title": "Visualising Model Training via Vowel Space for Text-To-Speech Systems",
    "abstract": "With the recent developments in speech synthesis via machine learning, this\nstudy explores incorporating linguistics knowledge to visualise and evaluate\nsynthetic speech model training. If changes to the first and second formant (in\nturn, the vowel space) can be seen and heard in synthetic speech, this\nknowledge can inform speech synthesis technology developers. A speech synthesis\nmodel trained on a large General American English database was fine-tuned into\na New Zealand English voice to identify if the changes in the vowel space of\nsynthetic speech could be seen and heard. The vowel spaces at different\nintervals during the fine-tuning were analysed to determine if the model\nlearned the New Zealand English vowel space. Our findings based on vowel space\nanalysis show that we can visualise how a speech synthesis model learns the\nvowel space of the database it is trained on. Perception tests confirmed that\nhumans could perceive when a speech synthesis model has learned characteristics\nof the speech database it is training on. Using the vowel space as an\nintermediary evaluation helps understand what sounds are to be added to the\ntraining database and build speech synthesis models based on linguistics\nknowledge.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Binu Abeysinghe",
      "Jesin James",
      "Catherine I. Watson",
      "Felix Marattukalam"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2208.09775"
  },
  {
    "id": "arXiv:2208.09791",
    "title": "Joint Communications and Sensing Employing Optimized MIMO-OFDM Signals",
    "abstract": "Joint communication and sensing (JCAS) has the potential to improve the\noverall energy, cost and frequency efficiency of IoT systems. As a first\neffort, we propose to optimize the MIMO-OFDM data symbols carried by\nsub-carriers for better time- and spatial-domain signal orthogonality. This not\nonly boosts the availability of usable signals for JCAS, but also significantly\nfacilitates Internet-of-Things (IoT) devices to perform high-quality sensing.\nWe establish an optimization problem that modifies data symbols on sub-carriers\nto enhance the above-mentioned signal orthogonality. We also develop an\nefficient algorithm to solve the problem based on the majorization-minimization\nframework. Moreover, we discover unique signal structures and features from the\nnewly modeled problem, which substantially reduce the complexity of majorizing\nthe objective function. We also develop new projectors to enforce the\nfeasibility of the obtained solution. Simulations show that, compared with the\noriginal communication waveform to achieve the same sensing performance, the\noptimized waveform can reduce the signal-to-noise ratio (SNR) requirement by\n3~4.5 dB, while the SNR loss for the uncoded bit error rate is only 1~1.5 dB.",
    "descriptor": "\nComments: 15 pages, 7 figures; submitted to an IEEE journal\n",
    "authors": [
      "Kai Wu",
      "J. Andrew Zhang",
      "Zhitong Ni",
      "Xiaojing Huang",
      "Y. Jay Guo",
      "Shanzhi Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09791"
  },
  {
    "id": "arXiv:2208.09792",
    "title": "Simultaneous Beam and User Selection for the Beamspace mmWave/THz  Massive MIMO Downlink",
    "abstract": "Beamspace millimeter-wave (mmWave) and terahertz (THz) massive MIMO\nconstitute attractive schemes for next-generation communications, given their\nabundant bandwidth and high throughput. However, their user and beam selection\nproblem has to be efficiently addressed. Inspired by this challenge, we develop\nlow-complexity solutions explicitly. We introduce the dirty paper coding (DPC)\ninto the joint user and beam selection problem, unveil the compelling\nproperties of the DPC sum rate optimization in beamspace massive MIMO and\nexploit them for substantially simplifying the problem. We also develop three\nalgorithms for solving the simplified problem, each having its unique merits.\nFurthermore, we derive the sum rate bound of the algorithms and analyze their\ncomplexity. Our simulation results validate the effectiveness of the proposed\ndesign and analysis, confirming their superiority over prior solutions.",
    "descriptor": "\nComments: 10 pages, 5 figures; submitted to an IEEE journal\n",
    "authors": [
      "Kai Wu",
      "J. Andrew Zhang",
      "Xiaojing Huang",
      "Y. Jay Guo",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09792"
  },
  {
    "id": "arXiv:2208.09793",
    "title": "FastCPH: Efficient Survival Analysis for Neural Networks",
    "abstract": "The Cox proportional hazards model is a canonical method in survival analysis\nfor prediction of the life expectancy of a patient given clinical or genetic\ncovariates -- it is a linear model in its original form. In recent years,\nseveral methods have been proposed to generalize the Cox model to neural\nnetworks, but none of these are both numerically correct and computationally\nefficient. We propose FastCPH, a new method that runs in linear time and\nsupports both the standard Breslow and Efron methods for tied events. We also\ndemonstrate the performance of FastCPH combined with LassoNet, a neural network\nthat provides interpretability through feature sparsity, on survival datasets.\nThe final procedure is efficient, selects useful covariates and outperforms\nexisting CoxPH approaches.",
    "descriptor": "",
    "authors": [
      "Xuelin Yang",
      "Louis Abraham",
      "Sejin Kim",
      "Petr Smirnov",
      "Feng Ruan",
      "Benjamin Haibe-Kains",
      "Robert Tibshirani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2208.09793"
  },
  {
    "id": "arXiv:2208.09799",
    "title": "Forensic Dental Age Estimation Using Modified Deep Learning Neural  Network",
    "abstract": "Dental age is one of the most reliable methods to identify an individual's\nage. By using dental panoramic radiography (DPR) images, physicians and\npathologists in forensic sciences try to establish the chronological age of\nindividuals with no valid legal records or registered patients. The current\nmethods in practice demand intensive labor, time, and qualified experts. The\ndevelopment of deep learning algorithms in the field of medical image\nprocessing has improved the sensitivity of predicting truth values while\nreducing the processing speed of imaging time. This study proposed an automated\napproach to estimate the forensic ages of individuals ranging in age from 8 to\n68 using 1,332 DPR images. Initially, experimental analyses were performed with\nthe transfer learning-based models, including InceptionV3, DenseNet201,\nEfficientNetB4, MobileNetV2, VGG16, and ResNet50V2; and accordingly, the\nbest-performing model, InceptionV3, was modified, and a new neural network\nmodel was developed. Reducing the number of the parameters already available in\nthe developed model architecture resulted in a faster and more accurate dental\nage estimation. The performance metrics of the results attained were as\nfollows: mean absolute error (MAE) was 3.13, root mean square error (RMSE) was\n4.77, and correlation coefficient R$^2$ was 87%. It is conceivable to propose\nthe new model as potentially dependable and practical ancillary equipment in\nforensic sciences and dental medicine.",
    "descriptor": "\nComments: 18 pages, 10 figures, 3 tables\n",
    "authors": [
      "Isa Atas",
      "Cuneyt Ozdemir",
      "Musa Atas",
      "Yahya Dogan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09799"
  },
  {
    "id": "arXiv:2208.09808",
    "title": "Determining Parameter Ranges for High Accuracy Large Eddy Simulation by  Lax-Wendroff Method",
    "abstract": "The analysis of Lax-Wendroff (LW) method is performed by the generic modified\ndifferential equation (MDE) approach in the spectral plane using Fourier\ntransform. In this approach, the concept of dispersion relation plays a major\nrole relating spatial and temporal dependence of the governing differential\nequation, including initial and boundary conditions in developing high accuracy\nschemes. Such dispersion relation preserving schemes are calibrated in the\nspectral plane using the global spectral analysis for the numerical method in\nthe full domain. In this framework, the numerical methods are calibrated by\nstudying convection and diffusion as the underlying physical processes for this\ncanonical model problem. In the LW method spatial and temporal discretizations\nare considered together, with time derivatives replaced by corresponding\nspatial derivatives using the governing equation. Here the LW method is studied\nfor the convection-diffusion equation (CDE) to establish limits for numerical\nparameters for an explicit central difference scheme that invokes third and\nfourth spatial derivatives in the MDE, in its general form. Thus, for the LW\nmethod, two different MDEs are obtained, depending on whether the LW method is\napplied only on the convection operator, or both on the convection and\ndiffusion operators. Motivated by a one-to-one correspondence of the\nNavier-Stokes equation with the linear CDE established in \"Effects of numerical\nanti-diffusion in closed unsteady flows governed by two-dimensional\nNavier-Stokes equation- Suman et al. Comput. Fluids, 201, 104479 (2020)\", an\nassessment is made here to solve flow problems by these two variants of the LW\nmethod. Apart from mapping the numerical properties for performing large eddy\nsimulation for the LW methods, simulations of the canonical lid-driven cavity\nproblem are performed for a super-critical Reynolds number for a uniform grid.",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "V.K. Suman",
      "Soumyo Sengupta",
      "P. Sundaram",
      "Aditi Sengupta",
      "Tapan K. Sengupta"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09808"
  },
  {
    "id": "arXiv:2208.09819",
    "title": "Robust Tests in Online Decision-Making",
    "abstract": "Bandit algorithms are widely used in sequential decision problems to maximize\nthe cumulative reward. One potential application is mobile health, where the\ngoal is to promote the user's health through personalized interventions based\non user specific information acquired through wearable devices. Important\nconsiderations include the type of, and frequency with which data is collected\n(e.g. GPS, or continuous monitoring), as such factors can severely impact app\nperformance and users' adherence. In order to balance the need to collect data\nthat is useful with the constraint of impacting app performance, one needs to\nbe able to assess the usefulness of variables. Bandit feedback data are\nsequentially correlated, so traditional testing procedures developed for\nindependent data cannot apply. Recently, a statistical testing procedure was\ndeveloped for the actor-critic bandit algorithm. An actor-critic algorithm\nmaintains two separate models, one for the actor, the action selection policy,\nand the other for the critic, the reward model. The performance of the\nalgorithm as well as the validity of the test are guaranteed only when the\ncritic model is correctly specified. However, misspecification is frequent in\npractice due to incorrect functional form or missing covariates. In this work,\nwe propose a modified actor-critic algorithm which is robust to critic\nmisspecification and derive a novel testing procedure for the actor parameters\nin this case.",
    "descriptor": "\nComments: 17 pages, 1 figure, supplementary material for \"Robust Tests in Online Decision-Making\" published in Proceedings of the AAAI Conference on Artificial Intelligence (2022)\n",
    "authors": [
      "Gi-Soo Kim",
      "Hyun-Joon Yang",
      "Jane P. Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09819"
  },
  {
    "id": "arXiv:2208.09875",
    "title": "Tensor-based flow reconstruction from optimally located sensor  measurements",
    "abstract": "Reconstructing high-resolution flow fields from sparse measurements is a\nmajor challenge in fluid dynamics. Existing methods often vectorize the flow by\nstacking different spatial directions on top of each other, hence overlooking\nthe information encoded in different dimensions. Here, we introduce a\ntensor-based sensor placement and flow reconstruction method which retains and\nexploits the inherent multidimensionality of the flow. We derive estimates for\nthe flow reconstruction error, storage requirements and computational cost of\nour method. We show, with examples, that our tensor-based method is\nsignificantly more accurate than similar vectorized methods. Furthermore, the\nvariance of the error is smaller when using our tensor-based method. While the\ncomputational cost of our method is comparable to similar vectorized methods,\nit reduces the storage cost by several orders of magnitude. The reduced storage\ncost becomes even more pronounced as the dimension of the flow increases. We\ndemonstrate the efficacy of our method on two examples: a chaotic Kolmogorov\nflow and the in-situ and satellite measurements of the global sea surface\ntemperature.",
    "descriptor": "\nComments: 3 figures, 11 pages\n",
    "authors": [
      "Mohammad Farazmand",
      "Arvind K. Saibaba"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.09875"
  },
  {
    "id": "arXiv:2208.09889",
    "title": "G2\u03a6net: Relating Genotype and Biomechanical Phenotype of Tissues  with Deep Learning",
    "abstract": "Many genetic mutations adversely affect the structure and function of\nload-bearing soft tissues, with clinical sequelae often responsible for\ndisability or death. Parallel advances in genetics and histomechanical\ncharacterization provide significant insight into these conditions, but there\nremains a pressing need to integrate such information. We present a novel\ngenotype-to-biomechanical-phenotype neural network (G2{\\Phi}net) for\ncharacterizing and classifying biomechanical properties of soft tissues, which\nserve as important functional readouts of tissue health or disease. We\nillustrate the utility of our approach by inferring the nonlinear,\ngenotype-dependent constitutive behavior of the aorta for four mouse models\ninvolving defects or deficiencies in extracellular constituents. We show that\nG2{\\Phi}net can infer the biomechanical response while simultaneously ascribing\nthe associated genotype correctly by utilizing limited, noisy, and unstructured\nexperimental data. More broadly, G2{\\Phi}net provides a powerful method and a\nparadigm shift for correlating genotype and biomechanical phenotype\nquantitatively, promising a better understanding of their interplay in\nbiological tissues.",
    "descriptor": "\nComments: 41 pages, 9 figures\n",
    "authors": [
      "Enrui Zhang",
      "Bart Spronck",
      "Jay D. Humphrey",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09889"
  },
  {
    "id": "arXiv:2208.09897",
    "title": "Multiple Descent in the Multiple Random Feature Model",
    "abstract": "Recent works have demonstrated a double descent phenomenon in\nover-parameterized learning: as the number of model parameters increases, the\nexcess risk has a $\\mathsf{U}$-shape at beginning, then decreases again when\nthe model is highly over-parameterized. Although this phenomenon has been\ninvestigated by recent works under different settings such as linear models,\nrandom feature models and kernel methods, it has not been fully understood in\ntheory. In this paper, we consider a double random feature model (DRFM)\nconsisting of two types of random features, and study the excess risk achieved\nby the DRFM in ridge regression. We calculate the precise limit of the excess\nrisk under the high dimensional framework where the training sample size, the\ndimension of data, and the dimension of random features tend to infinity\nproportionally. Based on the calculation, we demonstrate that the risk curves\nof DRFMs can exhibit triple descent. We then provide an explanation of the\ntriple descent phenomenon, and discuss how the ratio between random feature\ndimensions, the regularization parameter and the signal-to-noise ratio control\nthe shape of the risk curves of DRFMs. At last, we extend our study to the\nmultiple random feature model (MRFM), and show that MRFMs with $K$ types of\nrandom features may exhibit $(K+1)$-fold descent. Our analysis points out that\nrisk curves with a specific number of descent generally exist in random feature\nbased regression. Another interesting finding is that our result can recover\nthe risk peak locations reported in the literature when learning neural\nnetworks are in the \"neural tangent kernel\" regime.",
    "descriptor": "\nComments: 81 pages, 9 figures\n",
    "authors": [
      "Xuran Meng",
      "Jianfeng Yao",
      "Yuan Cao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09897"
  },
  {
    "id": "arXiv:2208.09914",
    "title": "An Implementation of the Quantum Verification of Matrix Products  Algorithm",
    "abstract": "We present a space-efficient implementation of the quantum verification of\nmatrix products (QVMP) algorithm and demonstrate its functionality by running\nit on the Aer simulator with two simulation methods: statevector and matrix\nproduct state (MPS). We report circuit metrics (gate count, qubit count,\ncircuit depth), transpilation time, simulation time, and a proof of Grover\noracle correctness. Our study concludes that while QVMP can be simulated on\nmoderately sized inputs, it cannot scale to a degree where we can observe any\nquantum advantage on current quantum hardware due to circuit depth and qubit\ncount constraints. Further, the choice of simulation method has a noticeable\nimpact on the size of the transpiled circuit which slows down development.",
    "descriptor": "",
    "authors": [
      "Elton Pinto"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.09914"
  },
  {
    "id": "arXiv:2208.09933",
    "title": "AA-Forecast: Anomaly-Aware Forecast for Extreme Events",
    "abstract": "Time series models often deal with extreme events and anomalies, both\nprevalent in real-world datasets. Such models often need to provide careful\nprobabilistic forecasting, which is vital in risk management for extreme events\nsuch as hurricanes and pandemics. However, it is challenging to automatically\ndetect and learn to use extreme events and anomalies for large-scale datasets,\nwhich often require manual effort. Hence, we propose an anomaly-aware forecast\nframework that leverages the previously seen effects of anomalies to improve\nits prediction accuracy during and after the presence of extreme events.\nSpecifically, the framework automatically extracts anomalies and incorporates\nthem through an attention mechanism to increase its accuracy for future extreme\nevents. Moreover, the framework employs a dynamic uncertainty optimization\nalgorithm that reduces the uncertainty of forecasts in an online manner. The\nproposed framework demonstrated consistent superior accuracy with less\nuncertainty on three datasets with different varieties of anomalies over the\ncurrent prediction models.",
    "descriptor": "\nComments: Data Mining and Knowledge Discovery\n",
    "authors": [
      "Ashkan Farhangi",
      "Jiang Bian",
      "Arthur Huang",
      "Haoyi Xiong",
      "Jun Wang",
      "Zhishan Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09933"
  },
  {
    "id": "arXiv:2208.09953",
    "title": "Do-AIQ: A Design-of-Experiment Approach to Quality Evaluation of AI  Mislabel Detection Algorithm",
    "abstract": "The quality of Artificial Intelligence (AI) algorithms is of significant\nimportance for confidently adopting algorithms in various applications such as\ncybersecurity, healthcare, and autonomous driving. This work presents a\nprincipled framework of using a design-of-experimental approach to\nsystematically evaluate the quality of AI algorithms, named as Do-AIQ.\nSpecifically, we focus on investigating the quality of the AI mislabel data\nalgorithm against data poisoning. The performance of AI algorithms is affected\nby hyperparameters in the algorithm and data quality, particularly, data\nmislabeling, class imbalance, and data types. To evaluate the quality of the AI\nalgorithms and obtain a trustworthy assessment on the quality of the\nalgorithms, we establish a design-of-experiment framework to construct an\nefficient space-filling design in a high-dimensional constraint space and\ndevelop an effective surrogate model using additive Gaussian process to enable\nthe emulation of the quality of AI algorithms. Both theoretical and numerical\nstudies are conducted to justify the merits of the proposed framework. The\nproposed framework can set an exemplar for AI algorithm to enhance the AI\nassurance of robustness, reproducibility, and transparency.",
    "descriptor": "",
    "authors": [
      "J. Lian",
      "K. Choi",
      "B. Veeramani",
      "A. Hu",
      "L. Freeman",
      "E. Bowen",
      "X. Deng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.09953"
  },
  {
    "id": "arXiv:2208.09968",
    "title": "Transfer Ranking in Finance: Applications to Cross-Sectional Momentum  with Data Scarcity",
    "abstract": "Cross-sectional strategies are a classical and popular trading style, with\nrecent high performing variants incorporating sophisticated neural\narchitectures. While these strategies have been applied successfully to\ndata-rich settings involving mature assets with long histories, deploying them\non instruments with limited samples generally produces over-fitted models with\ndegraded performance. In this paper, we introduce Fused Encoder Networks -- a\nhybrid parameter-sharing transfer ranking model. The model fuses information\nextracted using an encoder-attention module operated on a source dataset with a\nsimilar but separate module focused on a smaller target dataset of interest. In\naddition to mitigating the issue of target data scarcity, the model's\nself-attention mechanism enables interactions among instruments to be accounted\nfor, not just at the loss level during model training, but also at inference\ntime. Focusing on momentum applied to the top ten cryptocurrencies by market\ncapitalisation as a demonstrative use-case, the Fused Encoder Networks\noutperforms the reference benchmarks on most performance measures, delivering a\nthree-fold boost in the Sharpe ratio over classical momentum as well as an\nimprovement of approximately 50% against the best benchmark model without\ntransaction costs. It continues outperforming baselines even after accounting\nfor the high transaction costs associated with trading cryptocurrencies.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Daniel Poh",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2208.09968"
  },
  {
    "id": "arXiv:2208.09978",
    "title": "Bayesian Complementary Kernelized Learning for Multidimensional  Spatiotemporal Data",
    "abstract": "Probabilistic modeling of multidimensional spatiotemporal data is critical to\nmany real-world applications. However, real-world spatiotemporal data often\nexhibits complex dependencies that are nonstationary, i.e., correlation\nstructure varies with location/time, and nonseparable, i.e., dependencies exist\nbetween space and time. Developing effective and computationally efficient\nstatistical models to accommodate nonstationary/nonseparable processes\ncontaining both long-range and short-scale variations becomes a challenging\ntask, especially for large-scale datasets with various corruption/missing\nstructures. In this paper, we propose a new statistical framework -- Bayesian\nComplementary Kernelized Learning (BCKL) -- to achieve scalable probabilistic\nmodeling for multidimensional spatiotemporal data. To effectively describe\ncomplex dependencies, BCKL integrates kernelized low-rank factorization with\nshort-range spatiotemporal Gaussian processes (GP), in which the two components\ncomplement each other. Specifically, we use a multi-linear low-rank\nfactorization component to capture the global/long-range correlations in the\ndata and introduce an additive short-scale GP based on compactly supported\nkernel functions to characterize the remaining local variabilities. We develop\nan efficient Markov chain Monte Carlo (MCMC) algorithm for model inference and\nevaluate the proposed BCKL framework on both synthetic and real-world\nspatiotemporal datasets. Our results confirm the superior performance of BCKL\nin providing accurate posterior mean and high-quality uncertainty estimates.",
    "descriptor": "",
    "authors": [
      "Mengying Lei",
      "Aurelie Labbe",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09978"
  },
  {
    "id": "arXiv:2208.09980",
    "title": "M/D/1 Queues with LIFO and SIRO Policies",
    "abstract": "While symbolics for the equilibrium M/D/1-LIFO waiting time density are\ncompletely known, corresponding numerics for M/D/1-SIRO are derived from\nrecursions due to Burke (1959). Implementing an inverse Laplace transform-based\napproach for the latter remains unworkable.",
    "descriptor": "\nComments: 11 pages; 2 figures\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2208.09980"
  },
  {
    "id": "arXiv:2208.09992",
    "title": "Efficient construction of canonical polyadic approximations of tensor  networks",
    "abstract": "We consider the problem of constructing a canonical polyadic (CP)\ndecomposition for a tensor network, rather than a single tensor. We illustrate\nhow it is possible to reduce the complexity of constructing an approximate CP\nrepresentation of the network by leveraging its structure in the course of the\nCP factor optimization. The utility of this technique is demonstrated for the\norder-4 Coulomb interaction tensor approximated by 2 order-3 tensors via an\napproximate generalized square-root (SQ) factorization, such as density fitting\nor (pivoted) Cholesky. The complexity of constructing a 4-way CP decomposition\nis reduced from $\\mathcal{O}(n^4 R_\\text{CP})$ (for the non-approximated\nCoulomb tensor) to $\\mathcal{O}(n^3 R_\\text{CP})$ for the SQ-factorized tensor,\nwhere $n$ and $R_\\text{CP}$ are the basis and CP ranks, respectively. This\nreduces the cost of constructing the CP approximation of 2-body interaction\ntensors of relevance to accurate many-body electronic structure by up to 2\norders of magnitude for systems with up to 36 atoms studied here. The full\n4-way CP approximation of the Coulomb interaction tensor is shown to be more\naccurate than the known approaches utilizing CP-decomposed SQ factors (also\nobtained at the $\\mathcal{O}(n^3 R_\\text{CP})$ cost), such as the algebraic\npseudospectral and tensor hypercontraction approaches. The CP decomposed SQ\nfactors can also serve as a robust initial guess for the 4-way CP factors.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Karl Pierce",
      "Edward F Valeev"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.09992"
  },
  {
    "id": "arXiv:2208.09997",
    "title": "Spatially Selective Active Noise Control Systems",
    "abstract": "Wearable active noise control (ANC) systems are commonly designed to achieve\nmaximal sound reduction regardless of the incident direction of the sound. When\ndesired sound is present, the state-of-the-art methods add a separate system to\nreconstruct it, often with distortion and latency. In this work, we propose a\nmulti-channel ANC system that only controls the sound from the undesired\ndirections. The system truly preserves the desired sound instead of reproducing\nit. The proposed algorithm imposes a spatial constraint on the hybrid ANC cost\nfunction to achieve spatial selectivity. We simulated the proposed algorithm\nbased on a microphone array on a pair of augmented eye-glasses and compared it\nwith the existing methods in the literature. Not only did the proposed system\nprovide better noise reduction while preserving the physical sound wave from\nthe desired source, but it also consumed much less energy, which is critical\nfor lightweight wearable devices. Overall, the proposed method has demonstrated\nsignificant advantages over the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Tong Xiao",
      "Buye Xu",
      "Chuming Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.09997"
  },
  {
    "id": "arXiv:2208.10027",
    "title": "Learning Invariant Representations under General Interventions on the  Response",
    "abstract": "It has become increasingly common nowadays to collect observations of feature\nand response pairs from different environments. As a consequence, one has to\napply learned predictors to data with a different distribution due to\ndistribution shifts. One principled approach is to adopt the structural causal\nmodels to describe training and test models, following the invariance principle\nwhich says that the conditional distribution of the response given its\npredictors remains the same across environments. However, this principle might\nbe violated in practical settings when the response is intervened. A natural\nquestion is whether it is still possible to identify other forms of invariance\nto facilitate prediction in unseen environments. To shed light on this\nchallenging scenario, we introduce invariant matching property (IMP) which is\nan explicit relation to capture interventions through an additional feature.\nThis leads to an alternative form of invariance that enables a unified\ntreatment of general interventions on the response. We analyze the asymptotic\ngeneralization errors of our method under both the discrete and continuous\nenvironment settings, where the continuous case is handled by relating it to\nthe semiparametric varying coefficient models. We present algorithms that show\ncompetitive performance compared to existing methods over various experimental\nsettings.",
    "descriptor": "",
    "authors": [
      "Kang Du",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10027"
  },
  {
    "id": "arXiv:2208.10052",
    "title": "An explicit Milstein-type scheme for interacting particle systems and  McKean--Vlasov SDEs with common noise and non-differentiable drift  coefficients",
    "abstract": "We propose an explicit drift-randomised Milstein scheme for both\nMcKean--Vlasov stochastic differential equations and associated\nhigh-dimensional interacting particle systems with common noise. By using a\ndrift-randomisation step in space and measure, we establish the scheme's strong\nconvergence rate of $1$ under reduced regularity assumptions on the drift\ncoefficient: no classical (Euclidean) derivatives in space or measure\nderivatives (e.g., Lions/Fr\\'echet) are required. The main result is\nestablished by enriching the concepts of bistability and consistency of\nnumerical schemes used previously for standard SDE. We introduce certain\nSpijker-type norms (and associated Banach spaces) to deal with the interaction\nof particles present in the stochastic systems being analysed. A discussion of\nthe scheme's complexity is provided.",
    "descriptor": "\nComments: 32 pages including appendix\n",
    "authors": [
      "Sani Biswas",
      "Chaman Kumar",
      "Neelima",
      "Gon\u00e7alo dos Reis",
      "Christoph Reisinger"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.10052"
  },
  {
    "id": "arXiv:2208.10059",
    "title": "Sampling Gaussian Stationary Random Fields: A Stochastic Realization  Approach",
    "abstract": "Generating large-scale samples of stationary random fields is of great\nimportance in the fields such as geomaterial modeling and uncertainty\nquantification. Traditional methodologies based on covariance matrix\ndecomposition have the diffculty of being computationally expensive, which is\neven more serious when the dimension of the random field is large. This paper\nproposes an effcient stochastic realization approach for sampling Gaussian\nstationary random fields from a systems and control point of view.\nSpecifically, we take the exponential and Gaussian covariance functions as\nexamples and make a decoupling assumption when there are multiple dimensions.\nThen a rational spectral density is constructed in each dimension using\ntechniques from covariance extension, and the corresponding autoregressive\nmoving-average (ARMA) model is obtained via spectral factorization. As a\nresult, samples of the random field with a specific covariance function can be\ngenerated very effciently in the space domain by implementing the ARMA\nrecursion using a white noise input. Such a procedure is computationally cheap\ndue to the fact that the constructed ARMA model has a low order. Furthermore,\nthe same method is integrated to multiscale simulations where interpolations of\nthe generated samples are achieved when one zooms into finer scales. Both\ntheoretical analysis and simulation results show that our approach performs\nfavorably compared with covariance matrix decomposition methods.",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "Bin Zhu",
      "Jiahao Liu",
      "Zhengshou Lai",
      "Tao Qian"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10059"
  },
  {
    "id": "arXiv:2208.10074",
    "title": "Product structure of graph classes with strongly sublinear separators",
    "abstract": "We investigate the product structure of hereditary graph classes admitting\nstrongly sublinear separators. We characterise such classes as subgraphs of the\nstrong product of a star and a complete graph of strongly sublinear size. In a\nmore precise result, we show that if any hereditary graph class $\\mathcal{G}$\nadmits $O(n^{1-\\epsilon})$ separators, then for any fixed\n$\\delta\\in(0,\\epsilon)$ every $n$-vertex graph in $\\mathcal{G}$ is a subgraph\nof the strong product of a graph $H$ with bounded tree-depth and a complete\ngraph of size $O(n^{1-\\epsilon+\\delta})$. This result holds with $\\delta=0$ if\nwe allow $H$ to have tree-depth $O(\\log\\log n)$. We prove a product\nstrengthening of the result of Dvo\\v{r}\\'ak and Norin [SIAM J. Discrete Math.,\n2016] for graphs of polynomial expansion. Finally, we prove that $n$-vertex\ngraphs of bounded treewidth are subgraphs of the product of a graph with\ntree-depth $d$ and a complete graph of size $O(n^{1/d})$, which is best\npossible.",
    "descriptor": "",
    "authors": [
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.10074"
  },
  {
    "id": "arXiv:2208.10113",
    "title": "Hierarchical Capsule Prediction Network for Marketing Campaigns Effect",
    "abstract": "Marketing campaigns are a set of strategic activities that can promote a\nbusiness's goal. The effect prediction for marketing campaigns in a real\nindustrial scenario is very complex and challenging due to the fact that prior\nknowledge is often learned from observation data, without any intervention for\nthe marketing campaign. Furthermore, each subject is always under the\ninterference of several marketing campaigns simultaneously. Therefore, we\ncannot easily parse and evaluate the effect of a single marketing campaign. To\nthe best of our knowledge, there are currently no effective methodologies to\nsolve such a problem, i.e., modeling an individual-level prediction task based\non a hierarchical structure with multiple intertwined events. In this paper, we\nprovide an in-depth analysis of the underlying parse tree-like structure\ninvolved in the effect prediction task and we further establish a Hierarchical\nCapsule Prediction Network (HapNet) for predicting the effects of marketing\ncampaigns. Extensive results based on both the synthetic data and real data\ndemonstrate the superiority of our model over the state-of-the-art methods and\nshow remarkable practicability in real industrial applications.",
    "descriptor": "\nComments: Proceedings of the 31st ACM International Conference on Information and Knowledge Management (CIKM '22)\n",
    "authors": [
      "Zhixuan Chu",
      "Hui Ding",
      "Guang Zeng",
      "Yuchen Huang",
      "Tan Yan",
      "Yulin Kang",
      "Sheng Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10113"
  },
  {
    "id": "arXiv:2208.10171",
    "title": "Noise-Adaptive Intelligent Programmable Meta-Imager",
    "abstract": "We present an intelligent programmable computational meta-imager that tailors\nits sequence of coherent scene illuminations not only to a specific\ninformation-extraction task (e.g., object recognition) but also adapts to\ndifferent types and levels of noise. We systematically study how the learned\nillumination patterns depend on the noise, and we discover that trends in\nintensity and overlap of the learned illumination patterns can be understood\nintuitively. We conduct our analysis based on an analytical coupled-dipole\nforward model of a microwave dynamic metasurface antenna (DMA); we formulate a\ndifferentiable end-to-end information-flow pipeline comprising the programmable\nphysical measurement process including noise as well as the subsequent digital\nprocessing layers. This pipeline allows us to jointly inverse-design the\nprogrammable physical weights (DMA configurations that determine the coherent\nscene illuminations) and the trainable digital weights. Our noise-adaptive\nintelligent meta-imager outperforms the conventional use of pseudo-random\nillumination patterns most clearly under conditions that make the extraction of\nsufficient task-relevant information challenging: latency constraints (limiting\nthe number of allowed measurements) and strong noise. Programmable microwave\nmeta-imagers in indoor surveillance and earth observation will be confronted\nwith these conditions.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Chenqi Qian",
      "Philipp del Hougne"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2208.10171"
  },
  {
    "id": "arXiv:2208.10189",
    "title": "Generalised Gately Values of Cooperative Games",
    "abstract": "We investigate Gately's solution concept for cooperative games with\ntransferable utilities. Gately's solution conception is a bargaining solution\nand tries to minimise the maximal quantified \"propensity to disrupt\" the\nnegotiation of the players over the allocation of the generated collective\npayoffs. We show that Gately's solution concept is well-defined for a broad\nclass of games. We consider a generalisation based on a parameter-based\nquantification of the propensity to disrupt. Furthermore, we investigate the\nrelationship of Gately's solution and its generalisation with the Core. We show\nthat Gately's solution is in the Core for all regular 3-player games. We also\nidentify precise conditions under which generalised Gately values are Core\nimputations for arbitrary regular cooperative games. We construct the dual of\ngeneralised Gately values and devise an axiomatisation of these values for the\nclass of regular cooperative games. We conclude the paper with an application\nof the Gately value to the measurement of power in hierarchical social\nnetworks.",
    "descriptor": "",
    "authors": [
      "Robert P. Gilles",
      "Lina Mallozzi"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10189"
  },
  {
    "id": "arXiv:2208.10215",
    "title": "On the monophonic convexity number of the complementary prisms",
    "abstract": "A set $S$ of vertices of a graph $G$ is \\emph{monophonic convex} if $S$\ncontains all the vertices belonging to any induced path connecting two vertices\nof $S$. The cardinality of a maximum proper monophonic convex set of $G$ is\ncalled the \\emph{monophonic convexity number} of $G$. The \\emph{complementary\nprism} $G\\bar G$ of $G$ is obtained from the disjoint union of $G$ and its\ncomplement $\\bar{G}$ by adding the edges of a perfect matching between them. In\nthis work, we determine the monophonic convexity number of the complementary\nprisms of all graphs.",
    "descriptor": "",
    "authors": [
      "Neethu P. K.",
      "Ullas Chandran S. V."
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.10215"
  },
  {
    "id": "arXiv:2208.10230",
    "title": "Predicting the protein-ligand affinity from molecular dynamics  trajectories",
    "abstract": "The accurate protein-ligand binding affinity prediction is essential in drug\ndesign and many other molecular recognition problems. Despite many advances in\naffinity prediction based on machine learning techniques, they are still\nlimited since the protein-ligand binding is determined by the dynamics of atoms\nand molecules. To this end, we curated an MD dataset containing 3,218 dynamic\nprotein-ligand complexes and further developed Dynaformer, a graph-based deep\nlearning framework. Dynaformer can fully capture the dynamic binding rules by\nconsidering various geometric characteristics of the interaction. Our method\nshows superior performance over the methods hitherto reported. Moreover, we\nperformed virtual screening on heat shock protein 90 (HSP90) by integrating our\nmodel with structure-based docking. We benchmarked our performance against\nother baselines, demonstrating that our method can identify the molecule with\nthe highest experimental potency. We anticipate that large-scale MD dataset and\nmachine learning models will form a new synergy, providing a new route towards\naccelerated drug discovery and optimization.",
    "descriptor": "\nComments: initial version\n",
    "authors": [
      "Yaosen Min",
      "Ye Wei",
      "Peizhuo Wang",
      "Nian Wu",
      "Stefan Bauer",
      "Shuxin Zheng",
      "Yu Shi",
      "Yingheng Wang",
      "Dan Zhao",
      "Ji Wu",
      "Jianyang Zeng"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2208.10230"
  },
  {
    "id": "arXiv:2208.10266",
    "title": "An Entropy-based Measure of Intelligence Degree of System Structures",
    "abstract": "In this paper, we investigate how to measure the intelligence of systems\nunder specific structures. Two indicators are adopted to characterize the\nintelligence of a given structure, namely the function diversity of the\nstructure, and the ability to generate order under specific environments. A\nmeasure of intelligence degree is proposed, with which the intelligence degree\nof several basic structures is calculated. It is shown that some structures are\nindeed \"smarter\" than the others under the proposed measure. The results add a\npossible way of revealing the evolution mechanism of natural life and\nconstructing life-like structures with high intelligence degree.",
    "descriptor": "",
    "authors": [
      "Wei Su"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10266"
  },
  {
    "id": "arXiv:2208.10320",
    "title": "Optimising Chest X-Rays for Image Analysis by Identifying and Removing  Confounding Factors",
    "abstract": "During the COVID-19 pandemic, the sheer volume of imaging performed in an\nemergency setting for COVID-19 diagnosis has resulted in a wide variability of\nclinical CXR acquisitions. This variation is seen in the CXR projections used,\nimage annotations added and in the inspiratory effort and degree of rotation of\nclinical images. The image analysis community has attempted to ease the burden\non overstretched radiology departments during the pandemic by developing\nautomated COVID-19 diagnostic algorithms, the input for which has been CXR\nimaging. Large publicly available CXR datasets have been leveraged to improve\ndeep learning algorithms for COVID-19 diagnosis. Yet the variable quality of\nclinically-acquired CXRs within publicly available datasets could have a\nprofound effect on algorithm performance. COVID-19 diagnosis may be inferred by\nan algorithm from non-anatomical features on an image such as image labels.\nThese imaging shortcuts may be dataset-specific and limit the generalisability\nof AI systems. Understanding and correcting key potential biases in CXR images\nis therefore an essential first step prior to CXR image analysis. In this\nstudy, we propose a simple and effective step-wise approach to pre-processing a\nCOVID-19 chest X-ray dataset to remove undesired biases. We perform ablation\nstudies to show the impact of each individual step. The results suggest that\nusing our proposed pipeline could increase accuracy of the baseline COVID-19\ndetection algorithm by up to 13%.",
    "descriptor": "",
    "authors": [
      "Shahab Aslani",
      "Watjana Lilaonitkul",
      "Vaishnavi Gnanananthan",
      "Divya Raj",
      "Bojidar Rangelov",
      "Alexandra L Young",
      "Yipeng Hu",
      "Paul Taylor",
      "Daniel C Alexander",
      "Joseph Jacob"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10320"
  },
  {
    "id": "arXiv:2208.10321",
    "title": "Data-driven distributionally robust optimization over a network via  distributed semi-infinite programming",
    "abstract": "This paper focuses on solving a data-driven distributionally robust\noptimization problem over a network of agents. The agents aim to minimize the\nworst-case expected cost computed over a Wasserstein ambiguity set that is\ncentered at the empirical distribution. The samples of the uncertainty are\ndistributed across the agents. Our approach consists of reformulating the\nproblem as a semi-infinite program and then designing a distributed algorithm\nthat solves a generic semi-infinite problem that has the same information\nstructure as the reformulated problem. In particular, the decision variables\nconsist of both local ones that agents are free to optimize over and global\nones where they need to agree on. Our distributed algorithm is an iterative\nprocedure that combines the notions of distributed ADMM and the cutting-surface\nmethod. We show that the iterates converge asymptotically to a solution of the\ndistributionally robust problem to any pre-specified accuracy. Simulations\nillustrate our results.",
    "descriptor": "\nComments: 8 pages, to appear in IEEE Conference on Decision and Control 2022\n",
    "authors": [
      "Ashish Cherukuri",
      "Alireza Zolanvari",
      "Goran Banjac",
      "Ashish R. Hota"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10321"
  },
  {
    "id": "arXiv:2208.10325",
    "title": "Exploiting Temporal Structures of Cyclostationary Signals for  Data-Driven Single-Channel Source Separation",
    "abstract": "We study the problem of single-channel source separation (SCSS), and focus on\ncyclostationary signals, which are particularly suitable in a variety of\napplication domains. Unlike classical SCSS approaches, we consider a setting\nwhere only examples of the sources are available rather than their models,\ninspiring a data-driven approach. For source models with underlying\ncyclostationary Gaussian constituents, we establish a lower bound on the\nattainable mean squared error (MSE) for any separation method, model-based or\ndata-driven. Our analysis further reveals the operation for optimal separation\nand the associated implementation challenges. As a computationally attractive\nalternative, we propose a deep learning approach using a U-Net architecture,\nwhich is competitive with the minimum MSE estimator. We demonstrate in\nsimulation that, with suitable domain-informed architectural choices, our U-Net\nmethod can approach the optimal performance with substantially reduced\ncomputational burden.",
    "descriptor": "",
    "authors": [
      "Gary C.F. Lee",
      "Amir Weiss",
      "Alejandro Lancho",
      "Jennifer Tang",
      "Yuheng Bu",
      "Yury Polyanskiy",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10325"
  },
  {
    "id": "arXiv:2208.10356",
    "title": "A general framework for decomposing the phase field fracture driving  force, particularised to a Drucker-Prager failure surface",
    "abstract": "Due to its computational robustness and versatility, the phase field fracture\nmodel has become the preferred tool for predicting a wide range of cracking\nphenomena. However, in its conventional form, its intrinsic tension-compression\nsymmetry in damage evolution prevents its application to the modelling of\ncompressive failures in brittle and quasi-brittle solids, such as concrete or\nrock materials. In this work, we present a general methodology for decomposing\nthe phase field fracture driving force, the strain energy density, so as to\nreproduce asymmetrical tension-compression fracture behaviour. The generalised\napproach presented is particularised to the case of linear elastic solids and\nthe Drucker-Prager failure criterion. The ability of the presented model to\ncapture the compressive failure of brittle materials is showcased by\nnumerically implementing the resulting strain energy split formulation and\naddressing four case studies of particular interest. Firstly, insight is gained\ninto the capabilities of the model in predicting friction and dilatancy effects\nunder shear loading. Secondly, virtual direct shear tests are conducted to\nassess fracture predictions under different pressure levels. Thirdly, a\nconcrete cylinder is subjected to uniaxial and triaxial compression to\ninvestigate the influence of confinement. Finally, the localised failure of a\nsoil slope is predicted and the results are compared with other formulations\nfor the strain energy decomposition proposed in the literature. The results\nprovide a good qualitative agreement with experimental observations and\ndemonstrate the capabilities of phase field fracture methods to predict crack\nnucleation and growth under multi-axial loading in materials exhibiting\nasymmetric tension-compression fracture behaviour.",
    "descriptor": "",
    "authors": [
      "Y. Navidtehrani",
      "C. Beteg\u00f3n",
      "E. Mart\u00ednez-Pa\u00f1eda"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10356"
  },
  {
    "id": "arXiv:2208.10392",
    "title": "Fast identification and stabilization of unknown linear systems",
    "abstract": "In the present paper, we present a simple algorithm for stabilizing an\nunknown linear time-invariant system in the minimum time of $n+m$ steps, where\n$n$ is the dimension of the state of the considered system and $m$ is the\ndimension of the input. Our approach is based on first identifying the system\nmatrices on the controllable subspace, which we do in minimum time by applying\na suitable exciting input signal and then choosing a stabilizing controller\ngain.",
    "descriptor": "",
    "authors": [
      "Dennis Gramlich",
      "Christian Ebenbauer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10392"
  },
  {
    "id": "arXiv:2208.10434",
    "title": "A simple learning agent interacting with an agent-based market model",
    "abstract": "We consider the learning dynamics of a single reinforcement learning optimal\nexecution trading agent when it interacts with an event driven agent-based\nfinancial market model. Trading takes place asynchronously through a matching\nengine in event time. The optimal execution agent is considered at different\nlevels of initial order-sizes and differently sized state spaces. The resulting\nimpact on the agent-based model and market are considered using a calibration\napproach that explores changes in the empirical stylised facts and price impact\ncurves. Convergence, volume trajectory and action trace plots are used to\nvisualise the learning dynamics. This demonstrates how an optimal execution\nagent learns optimal trading decisions inside a simulated reactive market\nframework and how this in turn generates a back-reaction that changes the\nsimulated market through the introduction of strategic order-splitting.",
    "descriptor": "\nComments: 67 pages, 45 figures\n",
    "authors": [
      "Matthew Dicks",
      "Tim Gebbie"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.10434"
  },
  {
    "id": "arXiv:2208.10461",
    "title": "Scale invariant process regression",
    "abstract": "Gaussian processes are the leading method for non-parametric regression on\nsmall to medium datasets. One main challenge is the choice of kernel and\noptimization of hyperparameters. We propose a novel regression method that does\nnot require specification of a kernel, length scale, variance, nor prior mean.\nIts only hyperparameter is the assumed regularity (degree of differentiability)\nof the true function.\nWe achieve this with a novel non-Gaussian stochastic process that we\nconstruct from minimal assumptions of translation and scale invariance. The\nprocess can be thought of as a hierarchical Gaussian process model, where the\nhyperparameters have been incorporated into the process itself. To perform\ninference with this process we develop the required mathematical tools.\nIt turns out that for interpolation, the posterior is a t-process with a\npolyharmonic spline as mean. For regression, we state the exact posterior and\nfind its mean (again a polyharmonic spline) and approximate variance with a\nsampling method. Experiments show a performance equal to that of Gaussian\nprocesses with optimized hyperparameters.\nThe most important insight is that it is possible to derive a working machine\nlearning method by assuming nothing but regularity and scale- and translation\ninvariance, without any other model assumptions.",
    "descriptor": "",
    "authors": [
      "Matthias Wieler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2208.10461"
  },
  {
    "id": "arXiv:2208.10475",
    "title": "A Tight Upper Bound on the Average Order of Dominating Sets of a Graph",
    "abstract": "In this paper we study the the average order of dominating sets in a graph,\n$\\operatorname{avd}(G)$. Like other average graph parameters, the extremal\ngraphs are of interest. Beaton and Brown (2021) conjectured that for all graphs\n$G$ of order $n$ without isolated vertices, $\\operatorname{avd}(G) \\leq 2n/3$.\nRecently, Erey (2021) proved the conjecture for forests without isolated\nvertices. In this paper we prove the conjecture and classify which graphs have\n$\\operatorname{avd}(G) = 2n/3$.",
    "descriptor": "",
    "authors": [
      "Iain Beaton",
      "Ben Cameron"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.10475"
  },
  {
    "id": "arXiv:1205.5923",
    "title": "Integration of ontology with machine learning to predict the presence of  covid-19 based on symptoms",
    "abstract": "Integration of ontology with machine learning to predict the presence of  covid-19 based on symptoms",
    "descriptor": "",
    "authors": [
      "Hakim El Massari",
      "Noreddine Gherabi",
      "Sajida Mhammedi",
      "Hamza Ghandi",
      "Fatima Qanouni",
      "Mohamed Bahaj"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/1205.5923"
  },
  {
    "id": "arXiv:1905.11475",
    "title": "GAT: Generative Adversarial Training for Adversarial Example Detection  and Robust Classification",
    "abstract": "Comments: ICLR 2020, code is available at this https URL",
    "descriptor": "\nComments: ICLR 2020, code is available at this https URL\n",
    "authors": [
      "Xuwang Yin",
      "Soheil Kolouri",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11475"
  },
  {
    "id": "arXiv:1910.00482",
    "title": "Estimating Smooth GLM in Non-interactive Local Differential Privacy  Model with Public Unlabeled Data",
    "abstract": "Comments: Revised version, fix some errors in the first version",
    "descriptor": "\nComments: Revised version, fix some errors in the first version\n",
    "authors": [
      "Di Wang",
      "Lijie Hu",
      "Huanyu Zhang",
      "Marco Gaboardi",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.00482"
  },
  {
    "id": "arXiv:1910.01615",
    "title": "Fair Division of Goods in the Shadow of Market Values",
    "abstract": "Comments: 49 pages, 9 figures, 14 tables",
    "descriptor": "\nComments: 49 pages, 9 figures, 14 tables\n",
    "authors": [
      "Marco Dall'Aglio"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1910.01615"
  },
  {
    "id": "arXiv:1910.03359",
    "title": "Error Bounds for a Least Squares Meshless Finite Difference Method on  Closed Manifolds",
    "abstract": "Error Bounds for a Least Squares Meshless Finite Difference Method on  Closed Manifolds",
    "descriptor": "",
    "authors": [
      "Oleg Davydov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1910.03359"
  },
  {
    "id": "arXiv:1910.06461",
    "title": "Intelligent Physical Attack Against Mobile Robots With  Obstacle-Avoidance",
    "abstract": "Comments: 19 pages; accepted by IEEE Transactions on Robotics",
    "descriptor": "\nComments: 19 pages; accepted by IEEE Transactions on Robotics\n",
    "authors": [
      "Yushan Li",
      "Jianping He",
      "Cailian Chen",
      "Xinping Guan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1910.06461"
  },
  {
    "id": "arXiv:2001.06588",
    "title": "FlexiBO: A Decoupled Cost-Aware Multi-Objective Optimization Approach  for Deep Neural Networks",
    "abstract": "FlexiBO: A Decoupled Cost-Aware Multi-Objective Optimization Approach  for Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Md Shahriar Iqbal",
      "Jianhai Su",
      "Lars Kotthoff",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.06588"
  },
  {
    "id": "arXiv:2002.09145",
    "title": "Leveraging Cross Feedback of User and Item Embeddings with Attention for  Variational Autoencoder based Collaborative Filtering",
    "abstract": "Leveraging Cross Feedback of User and Item Embeddings with Attention for  Variational Autoencoder based Collaborative Filtering",
    "descriptor": "",
    "authors": [
      "Yuan Jin",
      "He Zhao",
      "Ming Liu",
      "Ye Zhu",
      "Lan Du",
      "Longxiang Gao",
      "He Zhang",
      "Yunfeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.09145"
  },
  {
    "id": "arXiv:2003.01936",
    "title": "Automatic Signboard Detection and Localization in Densely Populated  Developing Cities",
    "abstract": "Automatic Signboard Detection and Localization in Densely Populated  Developing Cities",
    "descriptor": "",
    "authors": [
      "Md. Sadrul Islam Toaha",
      "Sakib Bin Asad",
      "Chowdhury Rafeed Rahman",
      "S.M. Shahriar Haque",
      "Mahfuz Ara Proma",
      "Md. Ahsan Habib Shuvo",
      "Tashin Ahmed",
      "Md. Amimul Basher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.01936"
  },
  {
    "id": "arXiv:2003.03835",
    "title": "Multivariate Boosted Trees and Applications to Forecasting and Control",
    "abstract": "Multivariate Boosted Trees and Applications to Forecasting and Control",
    "descriptor": "",
    "authors": [
      "Lorenzo Nespoli",
      "Vasco Medici"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03835"
  },
  {
    "id": "arXiv:2009.08158",
    "title": "p-Edge/Vertex-Connected Vertex Cover: Parameterized and Approximation  Algorithms",
    "abstract": "p-Edge/Vertex-Connected Vertex Cover: Parameterized and Approximation  Algorithms",
    "descriptor": "",
    "authors": [
      "Carl Einarson",
      "Gregory Gutin",
      "Bart M. P. Jansen",
      "Diptapriyo Majumdar",
      "Magnus Wahlstrom"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.08158"
  },
  {
    "id": "arXiv:2010.03161",
    "title": "Model-Free Non-Stationary RL: Near-Optimal Regret and Applications in  Multi-Agent RL and Inventory Control",
    "abstract": "Comments: A preliminary version of this work has appeared in ICML 2021",
    "descriptor": "\nComments: A preliminary version of this work has appeared in ICML 2021\n",
    "authors": [
      "Weichao Mao",
      "Kaiqing Zhang",
      "Ruihao Zhu",
      "David Simchi-Levi",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.03161"
  },
  {
    "id": "arXiv:2010.12450",
    "title": "Repairing DoS Vulnerability of Real-World Regexes",
    "abstract": "Repairing DoS Vulnerability of Real-World Regexes",
    "descriptor": "",
    "authors": [
      "Nariyoshi Chida",
      "Tachio Terauchi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.12450"
  },
  {
    "id": "arXiv:2010.13723",
    "title": "Optimal Client Sampling for Federated Learning",
    "abstract": "Comments: Published in Transactions on Machine Learning Research, code available: this https URL",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research, code available: this https URL\n",
    "authors": [
      "Wenlin Chen",
      "Samuel Horvath",
      "Peter Richtarik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.13723"
  },
  {
    "id": "arXiv:2011.00786",
    "title": "Actor and Action Modular Network for Text-based Video Segmentation",
    "abstract": "Comments: Accepted By IEEE Transactions on Image Processing",
    "descriptor": "\nComments: Accepted By IEEE Transactions on Image Processing\n",
    "authors": [
      "Jianhua Yang",
      "Yan Huang",
      "Kai Niu",
      "Linjiang Huang",
      "Zhanyu Ma",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.00786"
  },
  {
    "id": "arXiv:2011.01516",
    "title": "Quadratic Metric Elicitation for Fairness and Beyond",
    "abstract": "Comments: The paper to appear at UAI 2022. This version includes the camera-ready edits. Paper 48 pages, 11 figures, and 5 tables",
    "descriptor": "\nComments: The paper to appear at UAI 2022. This version includes the camera-ready edits. Paper 48 pages, 11 figures, and 5 tables\n",
    "authors": [
      "Gaurush Hiranandani",
      "Jatin Mathur",
      "Harikrishna Narasimhan",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01516"
  },
  {
    "id": "arXiv:2011.10977",
    "title": "A Novel NOMA Solution with RIS Partitioning",
    "abstract": "Comments: More simulation results and mathematical analysis have been provided (published in IEEE JSTSP)",
    "descriptor": "\nComments: More simulation results and mathematical analysis have been provided (published in IEEE JSTSP)\n",
    "authors": [
      "Aymen Khaleel",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.10977"
  },
  {
    "id": "arXiv:2012.11654",
    "title": "Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for  Deep ReLU Networks",
    "abstract": "Comments: appeared at ICML 2021, this version corrects a mistake in Lemma 5.4 which also affects Lemma 5.5. These two Lemmas have been edited and the corresponding proofs corrected. All the other results remain untouched",
    "descriptor": "\nComments: appeared at ICML 2021, this version corrects a mistake in Lemma 5.4 which also affects Lemma 5.5. These two Lemmas have been edited and the corresponding proofs corrected. All the other results remain untouched\n",
    "authors": [
      "Quynh Nguyen",
      "Marco Mondelli",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11654"
  },
  {
    "id": "arXiv:2101.05141",
    "title": "Approximation of the spectral fractional powers of the Laplace-Beltrami  Operator",
    "abstract": "Comments: 23 pages, 6 figures",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Andrea Bonito",
      "Wenyu Lei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.05141"
  },
  {
    "id": "arXiv:2101.06969",
    "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to  Neuron-Level Backdoor Attacks",
    "abstract": "Red Alarm for Pre-trained Models: Universal Vulnerability to  Neuron-Level Backdoor Attacks",
    "descriptor": "",
    "authors": [
      "Zhengyan Zhang",
      "Guangxuan Xiao",
      "Yongwei Li",
      "Tian Lv",
      "Fanchao Qi",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Xin Jiang",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06969"
  },
  {
    "id": "arXiv:2102.02115",
    "title": "TEyeD: Over 20 million real-world eye images with Pupil, Eyelid, and  Iris 2D and 3D Segmentations, 2D and 3D Landmarks, 3D Eyeball, Gaze Vector,  and Eye Movement Types",
    "abstract": "Comments: Just connect via FTP as user TEyeDUser and without password to nephrit.cs.uni-tuebingen.de (this ftp URL)",
    "descriptor": "\nComments: Just connect via FTP as user TEyeDUser and without password to nephrit.cs.uni-tuebingen.de (this ftp URL)\n",
    "authors": [
      "Wolfgang Fuhl",
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.02115"
  },
  {
    "id": "arXiv:2102.08663",
    "title": "Preventing Oversmoothing in VAE via Generalized Variance  Parameterization",
    "abstract": "Comments: 35 pages with 12 figures, accepted for Neurocomputing",
    "descriptor": "\nComments: 35 pages with 12 figures, accepted for Neurocomputing\n",
    "authors": [
      "Yuhta Takida",
      "Wei-Hsiang Liao",
      "Chieh-Hsin Lai",
      "Toshimitsu Uesaka",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08663"
  },
  {
    "id": "arXiv:2103.11341",
    "title": "Parameterised-Response Zero-Intelligence Traders",
    "abstract": "Comments: 55 pages, 23 figures, 90 references",
    "descriptor": "\nComments: 55 pages, 23 figures, 90 references\n",
    "authors": [
      "Dave Cliff"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2103.11341"
  },
  {
    "id": "arXiv:2103.14321",
    "title": "Online Learning Koopman operator for closed-loop electrical  neurostimulation in epilepsy",
    "abstract": "Online Learning Koopman operator for closed-loop electrical  neurostimulation in epilepsy",
    "descriptor": "",
    "authors": [
      "Zhichao Liang",
      "Zixiang Luo",
      "Keyin Liu",
      "Jingwei Qiu",
      "Quanying Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2103.14321"
  },
  {
    "id": "arXiv:2104.04181",
    "title": "Stability Conditions for Remote State Estimation of Multiple Systems  over Multiple Markov Fading Channels",
    "abstract": "Comments: Paper accepted by IEEE Transactions on Automatic Control. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Paper accepted by IEEE Transactions on Automatic Control. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wanchun Liu",
      "Daniel E. Quevedo",
      "Karl H. Johansson",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.04181"
  },
  {
    "id": "arXiv:2104.08808",
    "title": "Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation  for Few-shot Learning",
    "abstract": "Comments: Accepted at Findings of EMNLP 2021; Fixed an error in Table 3 (see footnote 4); Updated Q3 in Sec. 4.2",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2021; Fixed an error in Table 3 (see footnote 4); Updated Q3 in Sec. 4.2\n",
    "authors": [
      "Xisen Jin",
      "Bill Yuchen Lin",
      "Mohammad Rostami",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08808"
  },
  {
    "id": "arXiv:2104.14370",
    "title": "Graph-Embedded Subspace Support Vector Data Description",
    "abstract": "Comments: 25 pages manuscript (3 tables, 4 figures), 63 pages supplementary material (43 tables, 34 figures). The manuscript and supplementary material are combined as a single .pdf (88 pages) file",
    "descriptor": "\nComments: 25 pages manuscript (3 tables, 4 figures), 63 pages supplementary material (43 tables, 34 figures). The manuscript and supplementary material are combined as a single .pdf (88 pages) file\n",
    "authors": [
      "Fahad Sohrab",
      "Alexandros Iosifidis",
      "Moncef Gabbouj",
      "Jenni Raitoharju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14370"
  },
  {
    "id": "arXiv:2105.00408",
    "title": "A structured proof of Kolmogorov's Superposition Theorem",
    "abstract": "Comments: 7 pages, 1 figure",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "S. Dzhenzher",
      "A. Skopenkov"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00408"
  },
  {
    "id": "arXiv:2105.01981",
    "title": "The Logic of Collective Action Revisited",
    "abstract": "Comments: 12 pages, 14 figures",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Ian Benson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.01981"
  },
  {
    "id": "arXiv:2105.04742",
    "title": "Incremental Graph Computation: Anchored Vertex Tracking in Dynamic  Social Networks",
    "abstract": "Comments: The manuscript has been accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)",
    "descriptor": "\nComments: The manuscript has been accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Taotao Cai",
      "Shuiqiao Yang",
      "Jianxin Li",
      "Quan Z. Sheng",
      "Jian Yang",
      "Xin Wang",
      "Wei Emma Zhang",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.04742"
  },
  {
    "id": "arXiv:2105.07770",
    "title": "$p$-robust equilibrated flux reconstruction in ${\\boldsymbol  H}(\\mathrm{curl})$ based on local minimizations. Application to a posteriori  analysis of the curl-curl problem",
    "abstract": "$p$-robust equilibrated flux reconstruction in ${\\boldsymbol  H}(\\mathrm{curl})$ based on local minimizations. Application to a posteriori  analysis of the curl-curl problem",
    "descriptor": "",
    "authors": [
      "Th\u00e9ophile Chaumont-Frelet",
      "Martin Vohral\u00edk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.07770"
  },
  {
    "id": "arXiv:2105.11675",
    "title": "An Upper Limit of Decaying Rate with Respect to Frequency in Deep Neural  Network",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.03238",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.03238\n",
    "authors": [
      "Tao Luo",
      "Zheng Ma",
      "Zhiwei Wang",
      "Zhi-Qin John Xu",
      "Yaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.11675"
  },
  {
    "id": "arXiv:2105.13755",
    "title": "The Generation of Security Scoring Systems Leveraging Human Expert  Opinion",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Peter Mell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13755"
  },
  {
    "id": "arXiv:2105.14111",
    "title": "Goal Misgeneralization in Deep Reinforcement Learning",
    "abstract": "Comments: Published in ICML 2022. 9 Pages",
    "descriptor": "\nComments: Published in ICML 2022. 9 Pages\n",
    "authors": [
      "Lauro Langosco",
      "Jack Koch",
      "Lee Sharkey",
      "Jacob Pfau",
      "Laurent Orseau",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14111"
  },
  {
    "id": "arXiv:2105.14363",
    "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback",
    "abstract": "Comments: Published at NeurIPS 2022",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Niladri S. Chatterji",
      "Aldo Pacchiano",
      "Peter L. Bartlett",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14363"
  },
  {
    "id": "arXiv:2105.14697",
    "title": "An Automated Approach to the Collatz Conjecture",
    "abstract": "An Automated Approach to the Collatz Conjecture",
    "descriptor": "",
    "authors": [
      "Emre Yolcu",
      "Scott Aaronson",
      "Marijn J.H. Heule"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14697"
  },
  {
    "id": "arXiv:2106.06873",
    "title": "Robust Graph Meta-learning for Weakly-supervised Few-shot Node  Classification",
    "abstract": "Robust Graph Meta-learning for Weakly-supervised Few-shot Node  Classification",
    "descriptor": "",
    "authors": [
      "Kaize Ding",
      "Jianling Wang",
      "Jundong Li",
      "James Caverlee",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06873"
  },
  {
    "id": "arXiv:2106.09229",
    "title": "An Evaluation of Self-Supervised Pre-Training for Skin-Lesion Analysis",
    "abstract": "Comments: 18 pages, 3 figures. Accepted at Seventh ISIC Skin Image Analysis Workshop @ECCV 2022",
    "descriptor": "\nComments: 18 pages, 3 figures. Accepted at Seventh ISIC Skin Image Analysis Workshop @ECCV 2022\n",
    "authors": [
      "Levy Chaves",
      "Alceu Bissoto",
      "Eduardo Valle",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09229"
  },
  {
    "id": "arXiv:2106.09906",
    "title": "Influence of agent's self-disclosure on human empathy",
    "abstract": "Comments: 24 pages, 9 figures, 3 tables, submitted to PLOS ONE Journal",
    "descriptor": "\nComments: 24 pages, 9 figures, 3 tables, submitted to PLOS ONE Journal\n",
    "authors": [
      "Takahiro Tsumura",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09906"
  },
  {
    "id": "arXiv:2106.11054",
    "title": "Visual Probing: Cognitive Framework for Explaining Self-Supervised Image  Representations",
    "abstract": "Comments: Submitted to IEEE Access",
    "descriptor": "\nComments: Submitted to IEEE Access\n",
    "authors": [
      "Witold Oleszkiewicz",
      "Dominika Basaj",
      "Igor Sieradzki",
      "Micha\u0142 G\u00f3rszczak",
      "Barbara Rychalska",
      "Koryna Lewandowska",
      "Tomasz Trzci\u0144ski",
      "Bartosz Zieli\u0144ski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11054"
  },
  {
    "id": "arXiv:2107.03962",
    "title": "On recovering the second-order convergence of the lattice Boltzmann  method with reaction-type source terms",
    "abstract": "Comments: Revised manuscript",
    "descriptor": "\nComments: Revised manuscript\n",
    "authors": [
      "Grzegorz Gruszczy\u0144ski",
      "Micha\u0142 Dzikowski",
      "\u0141ukasz \u0141aniewski-Wo\u0142\u0142k"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.03962"
  },
  {
    "id": "arXiv:2107.05486",
    "title": "Inapproximability of counting hypergraph colourings",
    "abstract": "Comments: abstract shortened for arXiv",
    "descriptor": "\nComments: abstract shortened for arXiv\n",
    "authors": [
      "Andreas Galanis",
      "Heng Guo",
      "Jiaheng Wang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05486"
  },
  {
    "id": "arXiv:2107.09179",
    "title": "OSLO: On-the-Sphere Learning for Omnidirectional images and its  application to 360-degree image compression",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Image Processing",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Image Processing\n",
    "authors": [
      "Navid Mahmoudian Bidgoli",
      "Roberto G. de A. Azevedo",
      "Thomas Maugey",
      "Aline Roumy",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09179"
  },
  {
    "id": "arXiv:2107.10706",
    "title": "Distributed Saddle-Point Problems Under Similarity",
    "abstract": "Comments: Appears in: Advances in Neural Information Processing Systems 34 (NeurIPS 2021). Minor modifications with respect to the NeurIPS version. 35 pages, 3 algorithms, 4 figures, 1 table",
    "descriptor": "\nComments: Appears in: Advances in Neural Information Processing Systems 34 (NeurIPS 2021). Minor modifications with respect to the NeurIPS version. 35 pages, 3 algorithms, 4 figures, 1 table\n",
    "authors": [
      "Aleksandr Beznosikov",
      "Gesualdo Scutari",
      "Alexander Rogozin",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.10706"
  },
  {
    "id": "arXiv:2108.04482",
    "title": "Complexity of Inexact Proximal Point Algorithm for minimizing convex  functions with Holderian Growth",
    "abstract": "Complexity of Inexact Proximal Point Algorithm for minimizing convex  functions with Holderian Growth",
    "descriptor": "",
    "authors": [
      "Andrei Patrascu",
      "Paul Irofti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04482"
  },
  {
    "id": "arXiv:2108.06688",
    "title": "Complex Knowledge Base Question Answering: A Survey",
    "abstract": "Comments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644",
    "descriptor": "\nComments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644\n",
    "authors": [
      "Yunshi Lan",
      "Gaole He",
      "Jinhao Jiang",
      "Jing Jiang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.06688"
  },
  {
    "id": "arXiv:2109.01369",
    "title": "Instance-wise or Class-wise? A Tale of Neighbor Shapley for  Concept-based Explanation",
    "abstract": "Instance-wise or Class-wise? A Tale of Neighbor Shapley for  Concept-based Explanation",
    "descriptor": "",
    "authors": [
      "Jiahui Li",
      "Kun Kuang",
      "Lin Li",
      "Long Chen",
      "Songyang Zhang",
      "Jian Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01369"
  },
  {
    "id": "arXiv:2109.01664",
    "title": "Exploring Separable Attention for Multi-Contrast MR Image  Super-Resolution",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.08949 this https URL",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.08949 this https URL\n",
    "authors": [
      "Chun-Mei Feng",
      "Yunlu Yan",
      "Kai Yu",
      "Yong Xu",
      "Ling Shao",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01664"
  },
  {
    "id": "arXiv:2109.05806",
    "title": "On the equivalence of two post-quantum cryptographic families",
    "abstract": "Comments: Accepted for publication in Annali di Matematica Pura ed Applicata (1923 -)",
    "descriptor": "\nComments: Accepted for publication in Annali di Matematica Pura ed Applicata (1923 -)\n",
    "authors": [
      "Alessio Meneghetti",
      "Alex Pellegrini",
      "Massimiliano Sala"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.05806"
  },
  {
    "id": "arXiv:2109.06557",
    "title": "The concept of class invariant in object-oriented programming",
    "abstract": "Comments: Revised version following refereeing",
    "descriptor": "\nComments: Revised version following refereeing\n",
    "authors": [
      "Bertrand Meyer",
      "Alisa Arkadova",
      "Alexander Kogtenkov"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06557"
  },
  {
    "id": "arXiv:2109.07320",
    "title": "Error estimation and adaptivity for stochastic collocation finite  elements Part I: single-level approximation",
    "abstract": "Comments: 20 pages; 9 figures",
    "descriptor": "\nComments: 20 pages; 9 figures\n",
    "authors": [
      "Alex Bespalov",
      "David Silvester",
      "Feng Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07320"
  },
  {
    "id": "arXiv:2109.09889",
    "title": "A Simple Unified Framework for Anomaly Detection in Deep Reinforcement  Learning",
    "abstract": "Comments: 19 pages, 21 figures",
    "descriptor": "\nComments: 19 pages, 21 figures\n",
    "authors": [
      "Hongming Zhang",
      "Ke Sun",
      "Bo Xu",
      "Linglong Kong",
      "Martin M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09889"
  },
  {
    "id": "arXiv:2109.10767",
    "title": "HybridSDF: Combining Deep Implicit Shapes and Geometric Primitives for  3D Shape Representation and Manipulation",
    "abstract": "Comments: Accepted to 3DV 2022",
    "descriptor": "\nComments: Accepted to 3DV 2022\n",
    "authors": [
      "Subeesh Vasu",
      "Nicolas Talabot",
      "Artem Lukoianov",
      "Pierre Baqu\u00e9",
      "Jonathan Donier",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.10767"
  },
  {
    "id": "arXiv:2110.01119",
    "title": "Cloud-Cluster Architecture for Detection in Intermittently Connected  Sensor Networks",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions on Wireless Communications. Preliminary results were presented in part at the IEEE Global Communications Conference 2020, arXiv:2005.12495",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Wireless Communications. Preliminary results were presented in part at the IEEE Global Communications Conference 2020, arXiv:2005.12495\n",
    "authors": [
      "Michal Yemini",
      "Stephanie Gil",
      "Andrea J. Goldsmith"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Retrieval (cs.IR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.01119"
  },
  {
    "id": "arXiv:2110.02047",
    "title": "Hierarchical information matters: Text classification via tree based  graph neural network",
    "abstract": "Comments: COLING 2022(Oral)",
    "descriptor": "\nComments: COLING 2022(Oral)\n",
    "authors": [
      "Chong Zhang",
      "He Zhu",
      "Xingyu Peng",
      "Junran Wu",
      "Ke Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02047"
  },
  {
    "id": "arXiv:2110.02667",
    "title": "Attentive Walk-Aggregating Graph Neural Networks",
    "abstract": "Comments: Published in TMLR (Transactions on Machine Learning Research) (08/2022) 32 pages",
    "descriptor": "\nComments: Published in TMLR (Transactions on Machine Learning Research) (08/2022) 32 pages\n",
    "authors": [
      "Mehmet F. Demirel",
      "Shengchao Liu",
      "Siddhant Garg",
      "Zhenmei Shi",
      "Yingyu Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02667"
  },
  {
    "id": "arXiv:2110.04047",
    "title": "TRUNet: Transformer-Recurrent-U Network for Multi-channel Reverberant  Sound Source Separation",
    "abstract": "TRUNet: Transformer-Recurrent-U Network for Multi-channel Reverberant  Sound Source Separation",
    "descriptor": "",
    "authors": [
      "Ali Aroudi",
      "Stefan Uhlich",
      "Marc Ferras Font"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04047"
  },
  {
    "id": "arXiv:2110.04291",
    "title": "Local and Global Context-Based Pairwise Models for Sentence Ordering",
    "abstract": "Comments: This is a post-print of an article published in Knowledge-Based Systems. For the journal-typeset version, please see this https URL",
    "descriptor": "\nComments: This is a post-print of an article published in Knowledge-Based Systems. For the journal-typeset version, please see this https URL\n",
    "authors": [
      "Ruskin Raj Manku",
      "Aditya Jyoti Paul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.04291"
  },
  {
    "id": "arXiv:2110.05804",
    "title": "Complexity of direct and iterative solvers on space-time formulations  versus time--marching schemes for h-refined grids towards singularities",
    "abstract": "Comments: 36 pages, 13 figures, 9 tables",
    "descriptor": "\nComments: 36 pages, 13 figures, 9 tables\n",
    "authors": [
      "Marcin Skotniczny",
      "Anna Paszynska",
      "Sergio Rojas",
      "Maciej Paszynski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05804"
  },
  {
    "id": "arXiv:2110.05808",
    "title": "Worst-case Delay Bounds in Time-Sensitive Networks with Packet  Replication and Elimination",
    "abstract": "Comments: published",
    "descriptor": "\nComments: published\n",
    "authors": [
      "Ludovic Thomas",
      "Ahlem Mifdaoui",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05808"
  },
  {
    "id": "arXiv:2110.06513",
    "title": "Benchmarking the Robustness of Spatial-Temporal Models Against  Corruptions",
    "abstract": "Comments: Accepted to NeurIPs 2021 Dataset and Benchmark Track. Our codes are available on this https URL",
    "descriptor": "\nComments: Accepted to NeurIPs 2021 Dataset and Benchmark Track. Our codes are available on this https URL\n",
    "authors": [
      "Chenyu Yi",
      "Siyuan Yang",
      "Haoliang Li",
      "Yap-peng Tan",
      "Alex Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06513"
  },
  {
    "id": "arXiv:2111.00213",
    "title": "Adjacency constraint for efficient hierarchical reinforcement learning",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence. DOI: 10.1109/TPAMI.2022.3192418. arXiv admin note: substantial text overlap with arXiv:2006.11485",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence. DOI: 10.1109/TPAMI.2022.3192418. arXiv admin note: substantial text overlap with arXiv:2006.11485\n",
    "authors": [
      "Tianren Zhang",
      "Shangqi Guo",
      "Tian Tan",
      "Xiaolin Hu",
      "Feng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00213"
  },
  {
    "id": "arXiv:2111.01415",
    "title": "Callee: Recovering Call Graphs for Binaries with Transfer and  Contrastive Learning",
    "abstract": "Callee: Recovering Call Graphs for Binaries with Transfer and  Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Wenyu Zhu",
      "Zhiyao Feng",
      "Zihan Zhang",
      "Jianjun Chen",
      "Zhijian Ou",
      "Min Yang",
      "Chao Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01415"
  },
  {
    "id": "arXiv:2111.02041",
    "title": "A Comparative Study of Speaker Role Identification in Air Traffic  Communication Using Deep Learning Approaches",
    "abstract": "Comments: This work has been submitted to the ACM TALLIP for possible publication",
    "descriptor": "\nComments: This work has been submitted to the ACM TALLIP for possible publication\n",
    "authors": [
      "Dongyue Guo",
      "Jianwei Zhang",
      "Bo Yang",
      "Yi Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.02041"
  },
  {
    "id": "arXiv:2111.02156",
    "title": "Continual Adaptation of Semantic Segmentation using Complementary 2D-3D  Data Representations",
    "abstract": "Comments: Accepted for IEEE Robotics and Automation Letters (R-AL 2022)",
    "descriptor": "\nComments: Accepted for IEEE Robotics and Automation Letters (R-AL 2022)\n",
    "authors": [
      "Jonas Frey",
      "Hermann Blum",
      "Francesco Milano",
      "Roland Siegwart",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02156"
  },
  {
    "id": "arXiv:2111.02336",
    "title": "An Improved Algorithm for The $k$-Dyck Edit Distance Problem",
    "abstract": "Comments: Journal version",
    "descriptor": "\nComments: Journal version\n",
    "authors": [
      "Dvir Fried",
      "Shay Golan",
      "Tomasz Kociumaka",
      "Tsvi Kopelowitz",
      "Ely Porat",
      "Tatiana Starikovskaya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02336"
  },
  {
    "id": "arXiv:2111.05628",
    "title": "Machine Learning Models Disclosure from Trusted Research Environments  (TRE), Challenges and Opportunities",
    "abstract": "Machine Learning Models Disclosure from Trusted Research Environments  (TRE), Challenges and Opportunities",
    "descriptor": "",
    "authors": [
      "Esma Mansouri-Benssassi",
      "Simon Rogers",
      "Jim Smith",
      "Felix Ritchie",
      "Emily Jefferson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.05628"
  },
  {
    "id": "arXiv:2111.06014",
    "title": "AlphaGarden: Learning to Autonomously Tend a Polyculture Garden",
    "abstract": "Comments: Paper revised, extended, and resubmitted. See \"Automated Pruning of Polyculture Plants.\"",
    "descriptor": "\nComments: Paper revised, extended, and resubmitted. See \"Automated Pruning of Polyculture Plants.\"\n",
    "authors": [
      "Mark Presten",
      "Yahav Avigal",
      "Mark Theis",
      "Satvik Sharma",
      "Rishi Parikh",
      "Shrey Aeron",
      "Sandeep Mukherjee",
      "Sebastian Oehme",
      "Simeon Adebola",
      "Walter Teitelbaum",
      "Varun Kamat",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.06014"
  },
  {
    "id": "arXiv:2111.10647",
    "title": "Staggered Residual Distribution scheme for compressible flow",
    "abstract": "Staggered Residual Distribution scheme for compressible flow",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Abgrall",
      "Ksenya Ivanova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.10647"
  },
  {
    "id": "arXiv:2111.12215",
    "title": "Explainable multiple abnormality classification of chest CT volumes",
    "abstract": "Comments: Published in Artificial Intelligence in Medicine, 2022. 8 figures, 7 tables",
    "descriptor": "\nComments: Published in Artificial Intelligence in Medicine, 2022. 8 figures, 7 tables\n",
    "authors": [
      "Rachel Lea Draelos",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12215"
  },
  {
    "id": "arXiv:2111.14273",
    "title": "On augmented finite element formulation for the Navier--Stokes equations  with vorticity and variable viscosity",
    "abstract": "On augmented finite element formulation for the Navier--Stokes equations  with vorticity and variable viscosity",
    "descriptor": "",
    "authors": [
      "Veronica Anaya",
      "Ruben Caraballo",
      "Ricardo Ruiz-Baier",
      "Hector Torres"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.14273"
  },
  {
    "id": "arXiv:2111.15162",
    "title": "CLIP Meets Video Captioning: Concept-Aware Representation Learning Does  Matter",
    "abstract": "Comments: to appear in the 5th Chinese Conference on Pattern Recognition and Computer Vision (PRCV 2022)",
    "descriptor": "\nComments: to appear in the 5th Chinese Conference on Pattern Recognition and Computer Vision (PRCV 2022)\n",
    "authors": [
      "Bang Yang",
      "Tong Zhang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15162"
  },
  {
    "id": "arXiv:2112.01040",
    "title": "Perform Like an Engine: A Closed-Loop Neural-Symbolic Learning Framework  for Knowledge Graph Inference",
    "abstract": "Comments: The full version of a long paper accepted to COLING 2022, 9 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: The full version of a long paper accepted to COLING 2022, 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Guanglin Niu",
      "Bo Li",
      "Yongfei Zhang",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01040"
  },
  {
    "id": "arXiv:2112.02891",
    "title": "Seeing Objects in dark with Continual Contrastive Learning",
    "abstract": "Comments: Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: IWDSC",
    "descriptor": "\nComments: Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: IWDSC\n",
    "authors": [
      "Ujjal Kr Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02891"
  },
  {
    "id": "arXiv:2112.04155",
    "title": "Towards the classification of Self-Sovereign Identity properties",
    "abstract": "Towards the classification of Self-Sovereign Identity properties",
    "descriptor": "",
    "authors": [
      "\u0160pela \u010cu\u010dko",
      "\u0160eila Be\u0107irovi\u0107",
      "Aida Kami\u0161ali\u0107",
      "Sa\u0161a Mrdovi\u0107",
      "Muhamed Turkanovi\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.04155"
  },
  {
    "id": "arXiv:2112.06128",
    "title": "R2: A Distributed Remote Function Execution Mechanism With Built-in  Metadata",
    "abstract": "Comments: Accepted in in IEEE/ACM Transactions on Networking, 2022. arXiv admin note: text overlap with arXiv:1905.10083 by other authors",
    "descriptor": "\nComments: Accepted in in IEEE/ACM Transactions on Networking, 2022. arXiv admin note: text overlap with arXiv:1905.10083 by other authors\n",
    "authors": [
      "Jianpeng Qi",
      "Rui Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.06128"
  },
  {
    "id": "arXiv:2112.06267",
    "title": "DiVA: A Scalable, Interactive and Customizable Visual Analytics Platform  for Information Diffusion on Large Networks",
    "abstract": "Comments: 33 pages, 12 figures, 11 tables",
    "descriptor": "\nComments: 33 pages, 12 figures, 11 tables\n",
    "authors": [
      "Dhruv Sahnan",
      "Vasu Goel",
      "Sarah Masud",
      "Chhavi Jain",
      "Vikram Goyal",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.06267"
  },
  {
    "id": "arXiv:2112.09362",
    "title": "Colloquium: Advances in automation of quantum dot devices control",
    "abstract": "Comments: 24 pages, 11 figures, accepted for publication as a Colloquium in Reviews of Modern Physics",
    "descriptor": "\nComments: 24 pages, 11 figures, accepted for publication as a Colloquium in Reviews of Modern Physics\n",
    "authors": [
      "Justyna P. Zwolak",
      "Jacob M. Taylor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09362"
  },
  {
    "id": "arXiv:2112.09669",
    "title": "Explain, Edit, and Understand: Rethinking User Study Design for  Evaluating Model Explanations",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Siddhant Arora",
      "Danish Pruthi",
      "Norman Sadeh",
      "William W. Cohen",
      "Zachary C. Lipton",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09669"
  },
  {
    "id": "arXiv:2112.11258",
    "title": "PointCaps: Raw Point Cloud Processing using Capsule Networks with  Euclidean Distance Routing",
    "abstract": "Comments: Accepted to be published in Journal of Visual Communication and Image Representation (Elsevier), 16 Pages, 4 Figures, 5 Tables",
    "descriptor": "\nComments: Accepted to be published in Journal of Visual Communication and Image Representation (Elsevier), 16 Pages, 4 Figures, 5 Tables\n",
    "authors": [
      "Dishanika Denipitiyage",
      "Vinoj Jayasundara",
      "Ranga Rodrigo",
      "Chamira U. S. Edussooriya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11258"
  },
  {
    "id": "arXiv:2112.11267",
    "title": "The Impact of Side Information on Physical Layer Security under  Correlated Fading Channels",
    "abstract": "The Impact of Side Information on Physical Layer Security under  Correlated Fading Channels",
    "descriptor": "",
    "authors": [
      "Farshad Rostami Ghadi",
      "F. Javier Lopez-Martinez",
      "Wei-Ping Zhu",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.11267"
  },
  {
    "id": "arXiv:2112.11607",
    "title": "The Complexity of Iterated Reversible Computation",
    "abstract": "Comments: 32 pages, 7 figures. This version adds FP^PSPACE-completeness",
    "descriptor": "\nComments: 32 pages, 7 figures. This version adds FP^PSPACE-completeness\n",
    "authors": [
      "David Eppstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.11607"
  },
  {
    "id": "arXiv:2112.12845",
    "title": "Automatic Meta-Path Discovery for Effective Graph-Based Recommendation",
    "abstract": "Comments: This paper is accepted by CIKM 2022",
    "descriptor": "\nComments: This paper is accepted by CIKM 2022\n",
    "authors": [
      "Wentao Ning",
      "Reynold Cheng",
      "Jiajun Shen",
      "Nur Al Hasan Haldar",
      "Ben Kao",
      "Xiao Yan",
      "Nan Huo",
      "Wai Kit Lam",
      "Tian Li",
      "Bo Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12845"
  },
  {
    "id": "arXiv:2201.00150",
    "title": "Cross-Domain Deep Code Search with Meta Learning",
    "abstract": "Comments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)",
    "descriptor": "\nComments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)\n",
    "authors": [
      "Yitian Chai",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.00150"
  },
  {
    "id": "arXiv:2201.00344",
    "title": "A Bound on the Minimal Field Size of LRCs, and Cyclic MR Codes That  Attain It",
    "abstract": "A Bound on the Minimal Field Size of LRCs, and Cyclic MR Codes That  Attain It",
    "descriptor": "",
    "authors": [
      "Han Cai",
      "Moshe Schwartz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.00344"
  },
  {
    "id": "arXiv:2201.00519",
    "title": "Stochastic Weight Averaging Revisited",
    "abstract": "Stochastic Weight Averaging Revisited",
    "descriptor": "",
    "authors": [
      "Hao Guo",
      "Jiyong Jin",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00519"
  },
  {
    "id": "arXiv:2201.01608",
    "title": "Botometer 101: Social bot practicum for computational social scientists",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Kai-Cheng Yang",
      "Emilio Ferrara",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.01608"
  },
  {
    "id": "arXiv:2201.05057",
    "title": "On Adversarial Robustness of Trajectory Prediction for Autonomous  Vehicles",
    "abstract": "Comments: 13 pages, 13 figures, accepted by CVPR 2022",
    "descriptor": "\nComments: 13 pages, 13 figures, accepted by CVPR 2022\n",
    "authors": [
      "Qingzhao Zhang",
      "Shengtuo Hu",
      "Jiachen Sun",
      "Qi Alfred Chen",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.05057"
  },
  {
    "id": "arXiv:2201.05233",
    "title": "Density reconstruction from schlieren images through Bayesian  nonparametric models",
    "abstract": "Density reconstruction from schlieren images through Bayesian  nonparametric models",
    "descriptor": "",
    "authors": [
      "Bryn Noel Ubald",
      "Pranay Seshadri",
      "Andrew Duncan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05233"
  },
  {
    "id": "arXiv:2201.06455",
    "title": "Make Reddit Great Again: Assessing Community Effects of Moderation  Interventions on r/The_Donald",
    "abstract": "Comments: Accepted at CSCW'22",
    "descriptor": "\nComments: Accepted at CSCW'22\n",
    "authors": [
      "Amaury Trujillo",
      "Stefano Cresci"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.06455"
  },
  {
    "id": "arXiv:2201.06541",
    "title": "Event-Based Beam Tracking with Dynamic Beamwidth Adaptation in Terahertz  (THz) Communications",
    "abstract": "Comments: 30 pages, 10 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 30 pages, 10 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yasemin Karacora",
      "Christina Chaccour",
      "Aydin Sezgin",
      "Walid Saad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.06541"
  },
  {
    "id": "arXiv:2201.09058",
    "title": "DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture  Fleeting Intraday Trading Opportunities",
    "abstract": "DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture  Fleeting Intraday Trading Opportunities",
    "descriptor": "",
    "authors": [
      "Shuo Sun",
      "Wanqi Xue",
      "Rundong Wang",
      "Xu He",
      "Junlei Zhu",
      "Jian Li",
      "Bo An"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09058"
  },
  {
    "id": "arXiv:2201.09263",
    "title": "Exploring Differential Geometry in Neural Implicits",
    "abstract": "Exploring Differential Geometry in Neural Implicits",
    "descriptor": "",
    "authors": [
      "Tiago Novello",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Vinicius da Silva",
      "Helio Lopes",
      "Luiz Velho"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09263"
  },
  {
    "id": "arXiv:2201.09751",
    "title": "Adversarial Classification under Gaussian Mechanism: Calibrating the  Attack to Sensitivity",
    "abstract": "Adversarial Classification under Gaussian Mechanism: Calibrating the  Attack to Sensitivity",
    "descriptor": "",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.09751"
  },
  {
    "id": "arXiv:2201.10747",
    "title": "Learning Multiple Probabilistic Degradation Generators for Unsupervised  Real World Image Super Resolution",
    "abstract": "Comments: Accepted to ECCVW 2022",
    "descriptor": "\nComments: Accepted to ECCVW 2022\n",
    "authors": [
      "Sangyun Lee",
      "Sewoong Ahn",
      "Kwangjin Yoon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10747"
  },
  {
    "id": "arXiv:2201.11727",
    "title": "Multi-Agent Reinforcement Learning for Network Load Balancing in Data  Center",
    "abstract": "Multi-Agent Reinforcement Learning for Network Load Balancing in Data  Center",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding",
      "Thomas Clausen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11727"
  },
  {
    "id": "arXiv:2201.13013",
    "title": "Filtering In Neural Implicit Functions",
    "abstract": "Comments: Source code at this https URL",
    "descriptor": "\nComments: Source code at this https URL\n",
    "authors": [
      "Yixin Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13013"
  },
  {
    "id": "arXiv:2202.00100",
    "title": "Calibration of P-values for calibration and for deviation of a  subpopulation from the full population",
    "abstract": "Comments: 22 pages, 8 figures",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Mark Tygert"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00100"
  },
  {
    "id": "arXiv:2202.00348",
    "title": "Learning entanglement breakdown as a phase transition by confusion",
    "abstract": "Comments: 14 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 14 pages, 9 figures, 4 tables\n",
    "authors": [
      "M.A. Gavreev",
      "A.S. Mastiukova",
      "E.O. Kiktenko",
      "A.K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00348"
  },
  {
    "id": "arXiv:2202.00817",
    "title": "Do Differentiable Simulators Give Better Policy Gradients?",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "H.J. Terry Suh",
      "Max Simchowitz",
      "Kaiqing Zhang",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00817"
  },
  {
    "id": "arXiv:2202.03747",
    "title": "STC: Spatio-Temporal Contrastive Learning for Video Instance  Segmentation",
    "abstract": "STC: Spatio-Temporal Contrastive Learning for Video Instance  Segmentation",
    "descriptor": "",
    "authors": [
      "Zhengkai Jiang",
      "Zhangxuan Gu",
      "Jinlong Peng",
      "Hang Zhou",
      "Liang Liu",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03747"
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": "Comments: Accepted at ECCV Workshop on Adversarial Robustness in the Real World (AROW 2022)",
    "descriptor": "\nComments: Accepted at ECCV Workshop on Adversarial Robustness in the Real World (AROW 2022)\n",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05152"
  },
  {
    "id": "arXiv:2202.06390",
    "title": "Deep Learning based Coverage and Rate Manifold Estimation in Cellular  Networks",
    "abstract": "Deep Learning based Coverage and Rate Manifold Estimation in Cellular  Networks",
    "descriptor": "",
    "authors": [
      "Washim Uddin Mondal",
      "Praful D. Mankar",
      "Goutam Das",
      "Vaneet Aggarwal",
      "Satish V. Ukkusuri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06390"
  },
  {
    "id": "arXiv:2202.06914",
    "title": "A Generic Self-Supervised Framework of Learning Invariant Discriminative  Features",
    "abstract": "A Generic Self-Supervised Framework of Learning Invariant Discriminative  Features",
    "descriptor": "",
    "authors": [
      "Foivos Ntelemis",
      "Yaochu Jin",
      "Spencer A. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06914"
  },
  {
    "id": "arXiv:2202.07300",
    "title": "Choosing an algorithmic fairness metric for an online marketplace:  Detecting and quantifying algorithmic bias on LinkedIn",
    "abstract": "Choosing an algorithmic fairness metric for an online marketplace:  Detecting and quantifying algorithmic bias on LinkedIn",
    "descriptor": "",
    "authors": [
      "YinYin Yu",
      "Guillaume Saint-Jacques"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07300"
  },
  {
    "id": "arXiv:2202.12416",
    "title": "Microgrid Optimal Energy Scheduling Considering Neural Network based  Battery Degradation",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12416"
  },
  {
    "id": "arXiv:2202.13620",
    "title": "Cutting a tree with Subgraph Complementation is hard, except for some  small trees",
    "abstract": "Comments: 33 Pages, 17 figures",
    "descriptor": "\nComments: 33 Pages, 17 figures\n",
    "authors": [
      "Dhanyamol Antony",
      "Sagartanu Pal",
      "R. B. Sandeep",
      "R. Subashini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.13620"
  },
  {
    "id": "arXiv:2203.00836",
    "title": "CandidateDrug4Cancer: An Open Molecular Graph Learning Benchmark on Drug  Discovery for Cancer",
    "abstract": "Comments: Accepted by Workshop on Graph Learning Benchmarks, The Web Conference 2021",
    "descriptor": "\nComments: Accepted by Workshop on Graph Learning Benchmarks, The Web Conference 2021\n",
    "authors": [
      "Xianbin Ye",
      "Ziliang Li",
      "Fei Ma",
      "Zongbi Yi",
      "Pengyong Li",
      "Jun Wang",
      "Peng Gao",
      "Yixuan Qiao",
      "Guotong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.00836"
  },
  {
    "id": "arXiv:2203.02606",
    "title": "Sustainable Verbal and Non-verbal Human-Robot Interaction Through Cloud  Services",
    "abstract": "Comments: 15 pages, 10 figures, associated video this https URL",
    "descriptor": "\nComments: 15 pages, 10 figures, associated video this https URL\n",
    "authors": [
      "Lucrezia Grassi",
      "Carmine Tommaso Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.02606"
  },
  {
    "id": "arXiv:2203.03949",
    "title": "RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering",
    "abstract": "Comments: Accepted by ECCV 2022, Project Page: this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022, Project Page: this https URL\n",
    "authors": [
      "Di Chang",
      "Alja\u017e Bo\u017ei\u010d",
      "Tong Zhang",
      "Qingsong Yan",
      "Yingcong Chen",
      "Sabine S\u00fcsstrunk",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03949"
  },
  {
    "id": "arXiv:2203.05057",
    "title": "On Linking Level Segments",
    "abstract": "On Linking Level Segments",
    "descriptor": "",
    "authors": [
      "Colan Biemer",
      "Seth Cooper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05057"
  },
  {
    "id": "arXiv:2203.05335",
    "title": "Non-generative Generalized Zero-shot Learning via Task-correlated  Disentanglement and Controllable Samples Synthesis",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yaogong Feng",
      "Xiaowen Huang",
      "Pengbo Yang",
      "Jian Yu",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05335"
  },
  {
    "id": "arXiv:2203.05471",
    "title": "A Full Dive into Realizing the Edge-enabled Metaverse: Visions, Enabling  Technologies,and Challenges",
    "abstract": "A Full Dive into Realizing the Edge-enabled Metaverse: Visions, Enabling  Technologies,and Challenges",
    "descriptor": "",
    "authors": [
      "Minrui Xu",
      "Wei Chong Ng",
      "Wei Yang Bryan Lim",
      "Jiawen Kang",
      "Zehui Xiong",
      "Dusit Niyato",
      "Qiang Yang",
      "Xuemin Sherman Shen",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05471"
  },
  {
    "id": "arXiv:2203.05936",
    "title": "Are discrete units necessary for Spoken Language Modeling?",
    "abstract": "Are discrete units necessary for Spoken Language Modeling?",
    "descriptor": "",
    "authors": [
      "Tu Anh Nguyen",
      "Benoit Sagot",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05936"
  },
  {
    "id": "arXiv:2203.06271",
    "title": "Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory",
    "abstract": "Comments: This is the first part of a two-part paper and has 29 pages and 6 figures. The second part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications\". This part has been significantly revised. In particular, we relate BMDR to the mismatched decoding framework that exists in the literature, and have rewritten the claims and proof of the main theorem",
    "descriptor": "\nComments: This is the first part of a two-part paper and has 29 pages and 6 figures. The second part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications\". This part has been significantly revised. In particular, we relate BMDR to the mismatched decoding framework that exists in the literature, and have rewritten the claims and proof of the main theorem\n",
    "authors": [
      "K. Pavan Srinath",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06271"
  },
  {
    "id": "arXiv:2203.06589",
    "title": "AugShuffleNet: Communicate More, Compute Less",
    "abstract": "AugShuffleNet: Communicate More, Compute Less",
    "descriptor": "",
    "authors": [
      "Longqing Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06589"
  },
  {
    "id": "arXiv:2203.10359",
    "title": "FPGA-extended General Purpose Computer Architecture",
    "abstract": "Comments: Accepted at the 18th International Symposium on Applied Reconfigurable Computing (ARC) 2022",
    "descriptor": "\nComments: Accepted at the 18th International Symposium on Applied Reconfigurable Computing (ARC) 2022\n",
    "authors": [
      "Philippos Papaphilippou",
      "Myrtle Shah"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2203.10359"
  },
  {
    "id": "arXiv:2203.10539",
    "title": "End-to-End Video Text Spotting with Transformer",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Weijia Wu",
      "Yuanqiang Cai",
      "Chunhua Shen",
      "Debing Zhang",
      "Ying Fu",
      "Hong Zhou",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10539"
  },
  {
    "id": "arXiv:2203.10769",
    "title": "ASE: Anomaly Scoring Based Ensemble Learning for Imbalanced Datasets",
    "abstract": "ASE: Anomaly Scoring Based Ensemble Learning for Imbalanced Datasets",
    "descriptor": "",
    "authors": [
      "Xiayu Liang",
      "Ying Gao",
      "Shanrong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10769"
  },
  {
    "id": "arXiv:2203.10776",
    "title": "K-space and Image Domain Collaborative Energy based Model for Parallel  MRI Reconstruction",
    "abstract": "Comments: 25 pages,11 figures. arXiv admin note: text overlap with arXiv:2109.03237",
    "descriptor": "\nComments: 25 pages,11 figures. arXiv admin note: text overlap with arXiv:2109.03237\n",
    "authors": [
      "Zongjiang Tu",
      "Chen Jiang",
      "Yu Guan",
      "Shanshan Wang",
      "Jijun Liu",
      "Qiegen Liu",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10776"
  },
  {
    "id": "arXiv:2203.11853",
    "title": "ImageNet Challenging Classification with the Raspberry Pi: An  Incremental Local Stochastic Gradient Descent Algorithm",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Thanh-Nghi Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11853"
  },
  {
    "id": "arXiv:2203.12612",
    "title": "StructToken : Rethinking Semantic Segmentation with Structural Prior",
    "abstract": "StructToken : Rethinking Semantic Segmentation with Structural Prior",
    "descriptor": "",
    "authors": [
      "Fangjian Lin",
      "Zhanhao Liang",
      "Sitong Wu",
      "Junjun He",
      "Kai Chen",
      "Shengwei Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12612"
  },
  {
    "id": "arXiv:2203.13238",
    "title": "Open-set Recognition via Augmentation-based Similarity Learning",
    "abstract": "Open-set Recognition via Augmentation-based Similarity Learning",
    "descriptor": "",
    "authors": [
      "Sepideh Esmaeilpour",
      "Lei Shu",
      "Bing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13238"
  },
  {
    "id": "arXiv:2203.13430",
    "title": "Plagiarism Detection in the Bengali Language: A Text Similarity-Based  Approach",
    "abstract": "Comments: ACCEPTED AT 3RD INTERNATIONAL CONFERENCE ON ENGINEERING AND ADVANCEMENT IN TECHNOLOGY (ICEAT 2022)",
    "descriptor": "\nComments: ACCEPTED AT 3RD INTERNATIONAL CONFERENCE ON ENGINEERING AND ADVANCEMENT IN TECHNOLOGY (ICEAT 2022)\n",
    "authors": [
      "Satyajit Ghosh",
      "Aniruddha Ghosh",
      "Bittaswer Ghosh",
      "Abhishek Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13430"
  },
  {
    "id": "arXiv:2203.14557",
    "title": "Visual Mechanisms Inspired Efficient Transformers for Image and Video  Quality Assessment",
    "abstract": "Visual Mechanisms Inspired Efficient Transformers for Image and Video  Quality Assessment",
    "descriptor": "",
    "authors": [
      "Junyong You",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14557"
  },
  {
    "id": "arXiv:2203.15854",
    "title": "Locomotion Policy Guided Traversability Learning using Volumetric  Representations of Complex Environments",
    "abstract": "Comments: accepted for 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: accepted for 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Jonas Frey",
      "David Hoeller",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15854"
  },
  {
    "id": "arXiv:2203.16037",
    "title": "Enhancing Zero-Shot Many to Many Voice Conversion with Self-Attention  VAE",
    "abstract": "Enhancing Zero-Shot Many to Many Voice Conversion with Self-Attention  VAE",
    "descriptor": "",
    "authors": [
      "Ziang Long",
      "Yunling Zheng",
      "Meng Yu",
      "Jack Xin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16037"
  },
  {
    "id": "arXiv:2203.16760",
    "title": "Effective data screening technique for crowdsourced speech  intelligibility experiments: Evaluation with IRM-based speech enhancement",
    "abstract": "Comments: This paper was submitted to APSIPA ASC 2022 (this https URL). The original title [v1] was \"Subjective intelligibility of speech sounds enhanced by ideal ratio mask via crowdsourced remote experiments with effective data screening.\"",
    "descriptor": "\nComments: This paper was submitted to APSIPA ASC 2022 (this https URL). The original title [v1] was \"Subjective intelligibility of speech sounds enhanced by ideal ratio mask via crowdsourced remote experiments with effective data screening.\"\n",
    "authors": [
      "Ayako Yamamoto",
      "Toshio Irino",
      "Shoko Araki",
      "Kenichi Arai",
      "Atsunori Ogawa",
      "Keisuke Kinoshita",
      "Tomohiro Nakatani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16760"
  },
  {
    "id": "arXiv:2204.01437",
    "title": "Disentangling Abstraction from Statistical Pattern Matching in Human and  Machine Learning",
    "abstract": "Disentangling Abstraction from Statistical Pattern Matching in Human and  Machine Learning",
    "descriptor": "",
    "authors": [
      "Sreejan Kumar",
      "Ishita Dasgupta",
      "Raja Marjieh",
      "Nathaniel D. Daw",
      "Jonathan D. Cohen",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.01437"
  },
  {
    "id": "arXiv:2204.01943",
    "title": "Unified Implicit Neural Stylization",
    "abstract": "Unified Implicit Neural Stylization",
    "descriptor": "",
    "authors": [
      "Zhiwen Fan",
      "Yifan Jiang",
      "Peihao Wang",
      "Xinyu Gong",
      "Dejia Xu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01943"
  },
  {
    "id": "arXiv:2204.02725",
    "title": "Match-Prompt: Improving Multi-task Generalization Ability for Neural  Text Matching via Prompt Learning",
    "abstract": "Comments: Accepted by CIKM 2022",
    "descriptor": "\nComments: Accepted by CIKM 2022\n",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02725"
  },
  {
    "id": "arXiv:2204.03297",
    "title": "A Multi-Transformation Evolutionary Framework for Influence Maximization  in Social Networks",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chao Wang",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Licheng Jiao",
      "Jing Liu",
      "Kai Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03297"
  },
  {
    "id": "arXiv:2204.03649",
    "title": "Unsupervised Prompt Learning for Vision-Language Models",
    "abstract": "Unsupervised Prompt Learning for Vision-Language Models",
    "descriptor": "",
    "authors": [
      "Tony Huang",
      "Jack Chu",
      "Fangyun Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03649"
  },
  {
    "id": "arXiv:2204.03874",
    "title": "On-Policy Pixel-Level Grasping Across the Gap Between Simulation and  Reality",
    "abstract": "On-Policy Pixel-Level Grasping Across the Gap Between Simulation and  Reality",
    "descriptor": "",
    "authors": [
      "Dexin Wang",
      "Faliang Chang",
      "Chunsheng Liu",
      "Rurui Yang",
      "Nanjun Li",
      "Hengqiang Huan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03874"
  },
  {
    "id": "arXiv:2204.04138",
    "title": "EfficientFi: Towards Large-Scale Lightweight WiFi Sensing via CSI  Compression",
    "abstract": "Comments: Published in IEEE Internet of Things Journal",
    "descriptor": "\nComments: Published in IEEE Internet of Things Journal\n",
    "authors": [
      "Jianfei Yang",
      "Xinyan Chen",
      "Han Zou",
      "Dazhuo Wang",
      "Qianwen Xu",
      "Lihua Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04138"
  },
  {
    "id": "arXiv:2204.05128",
    "title": "Linking Scientific Instruments and HPC: Patterns, Technologies,  Experiences",
    "abstract": "Linking Scientific Instruments and HPC: Patterns, Technologies,  Experiences",
    "descriptor": "",
    "authors": [
      "Rafael Vescovi",
      "Ryan Chard",
      "Nickolaus Saint",
      "Ben Blaiszik",
      "Jim Pruyne",
      "Tekin Bicer",
      "Alex Lavens",
      "Zhengchun Liu",
      "Michael E. Papka",
      "Suresh Narayanan",
      "Nicholas Schwarz",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.05128"
  },
  {
    "id": "arXiv:2204.05248",
    "title": "Learning Downstream Task by Selectively Capturing Complementary  Knowledge from Multiple Self-supervisedly Learning Pretexts",
    "abstract": "Learning Downstream Task by Selectively Capturing Complementary  Knowledge from Multiple Self-supervisedly Learning Pretexts",
    "descriptor": "",
    "authors": [
      "Jiayu Yao",
      "Qingyuan Wu",
      "Quan Feng",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05248"
  },
  {
    "id": "arXiv:2204.07372",
    "title": "A Personalized Dialogue Generator with Implicit User Persona Detection",
    "abstract": "Comments: 9 pages, 7 figures, Accepted by Coling2022",
    "descriptor": "\nComments: 9 pages, 7 figures, Accepted by Coling2022\n",
    "authors": [
      "Itsugun Cho",
      "Dongyang Wang",
      "Ryota Takahashi",
      "Hiroaki Saito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07372"
  },
  {
    "id": "arXiv:2204.07630",
    "title": "Prismatic Soft Actuator Augments the Workspace of Soft Continuum Robots",
    "abstract": "Prismatic Soft Actuator Augments the Workspace of Soft Continuum Robots",
    "descriptor": "",
    "authors": [
      "Philipp Wand",
      "Oliver Fischer",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07630"
  },
  {
    "id": "arXiv:2204.07916",
    "title": "On representing the degree sequences of sublogarithmic-degree Wheeler  graphs",
    "abstract": "On representing the degree sequences of sublogarithmic-degree Wheeler  graphs",
    "descriptor": "",
    "authors": [
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07916"
  },
  {
    "id": "arXiv:2204.09973",
    "title": "Merging of neural networks",
    "abstract": "Merging of neural networks",
    "descriptor": "",
    "authors": [
      "Martin Pa\u0161en",
      "Vladim\u00edr Bo\u017ea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09973"
  },
  {
    "id": "arXiv:2204.11280",
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "abstract": "Deconstructed Generation-Based Zero-Shot Model",
    "descriptor": "",
    "authors": [
      "Dubing Chen",
      "Yuming Shen",
      "Haofeng Zhang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11280"
  },
  {
    "id": "arXiv:2204.12404",
    "title": "Hierarchical Bayesian Modelling for Knowledge Transfer Across  Engineering Fleets via Multitask Learning",
    "abstract": "Hierarchical Bayesian Modelling for Knowledge Transfer Across  Engineering Fleets via Multitask Learning",
    "descriptor": "",
    "authors": [
      "L.A. Bull",
      "D. Di Francesco",
      "M. Dhada",
      "O. Steinert",
      "T. Lindgren",
      "A.K. Parlikad",
      "A.B. Duncan",
      "M. Girolami"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.12404"
  },
  {
    "id": "arXiv:2204.12507",
    "title": "Refining Control Barrier Functions through Hamilton-Jacobi Reachability",
    "abstract": "Comments: To appear at IEEE/RSJ International Conference on Intelligent Robots & Systems (IROS) 2022",
    "descriptor": "\nComments: To appear at IEEE/RSJ International Conference on Intelligent Robots & Systems (IROS) 2022\n",
    "authors": [
      "Sander Tonkens",
      "Sylvia Herbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.12507"
  },
  {
    "id": "arXiv:2204.12521",
    "title": "Quantifying the selective, stochastic, and complementary drivers of the  institutional evolution in online communities",
    "abstract": "Comments: 34 pages, 5 figures",
    "descriptor": "\nComments: 34 pages, 5 figures\n",
    "authors": [
      "Qiankun Zhong",
      "Seth Frey",
      "Martin Hilbert"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.12521"
  },
  {
    "id": "arXiv:2205.02022",
    "title": "A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models  for African News Translation",
    "abstract": "Comments: Accepted to NAACL 2022 (added evaluation data for amh, kin, nya, sna, xho)",
    "descriptor": "\nComments: Accepted to NAACL 2022 (added evaluation data for amh, kin, nya, sna, xho)\n",
    "authors": [
      "David Ifeoluwa Adelani",
      "Jesujoba Oluwadara Alabi",
      "Angela Fan",
      "Julia Kreutzer",
      "Xiaoyu Shen",
      "Machel Reid",
      "Dana Ruiter",
      "Dietrich Klakow",
      "Peter Nabende",
      "Ernie Chang",
      "Tajuddeen Gwadabe",
      "Freshia Sackey",
      "Bonaventure F. P. Dossou",
      "Chris Chinenye Emezue",
      "Colin Leong",
      "Michael Beukman",
      "Shamsuddeen Hassan Muhammad",
      "Guyo Dub Jarso",
      "Oreen Yousuf",
      "Andre Niyongabo Rubungo",
      "Gilles Hacheme",
      "Eric Peter Wairagala",
      "Muhammad Umair Nasir",
      "Benjamin Ayoade Ajibade",
      "Tunde Oluwaseyi Ajayi",
      "Yvonne Wambui Gitau",
      "Jade Abbott",
      "Mohamed Ahmed",
      "Millicent Ochieng",
      "Anuoluwapo Aremu",
      "Perez Ogayo",
      "Jonathan Mukiibi",
      "Fatoumata Ouoba Kabore",
      "Godson Koffi Kalipe",
      "Derguene Mbaye",
      "Allahsera Auguste Tapo",
      "Victoire Memdjokam Koagne",
      "Edwin Munkoh-Buabeng",
      "Valencia Wagner",
      "Idris Abdulmumin",
      "Ayodele Awokoya",
      "Happy Buzaaba",
      "Blessing Sibanda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02022"
  },
  {
    "id": "arXiv:2205.03117",
    "title": "NP-hardness of Computing Uniform Nash Equilibria on Planar Bimatrix  Games",
    "abstract": "Comments: v3: the hardness result is strengthened",
    "descriptor": "\nComments: v3: the hardness result is strengthened\n",
    "authors": [
      "Takashi Ishizuka",
      "Naoyuki Kamiyama"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.03117"
  },
  {
    "id": "arXiv:2205.03339",
    "title": "Transferring Chemical and Energetic Knowledge Between Molecular Systems  with Machine Learning",
    "abstract": "Transferring Chemical and Energetic Knowledge Between Molecular Systems  with Machine Learning",
    "descriptor": "",
    "authors": [
      "Sajjad Heydari",
      "Stefano Raniolo",
      "Lorenzo Livi",
      "Vittorio Limongelli"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2205.03339"
  },
  {
    "id": "arXiv:2205.04553",
    "title": "An efficient acceleration technique for methods for finding the nearest  point in a polytope and computing the distance between two polytopes",
    "abstract": "An efficient acceleration technique for methods for finding the nearest  point in a polytope and computing the distance between two polytopes",
    "descriptor": "",
    "authors": [
      "M.V. Dolgopolik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.04553"
  },
  {
    "id": "arXiv:2205.04594",
    "title": "A General Formula for Uniform Common Randomness Capacity",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.06451",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.06451\n",
    "authors": [
      "Rami Ezzine",
      "Moritz Wiese",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.04594"
  },
  {
    "id": "arXiv:2205.04860",
    "title": "Universal Caching",
    "abstract": "Comments: To appear in the Information Theory Workshop (ITW), 2022",
    "descriptor": "\nComments: To appear in the Information Theory Workshop (ITW), 2022\n",
    "authors": [
      "Ativ Joshi",
      "Abhishek Sinha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04860"
  },
  {
    "id": "arXiv:2205.06039",
    "title": "Reactive Synthesis of Smart Contract Control Flows",
    "abstract": "Reactive Synthesis of Smart Contract Control Flows",
    "descriptor": "",
    "authors": [
      "Bernd Finkbeiner",
      "Jana Hofmann",
      "Florian Kohn",
      "Noemi Passing"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.06039"
  },
  {
    "id": "arXiv:2205.06781",
    "title": "Codes for Preventing Zeros at Partially Defective Memory Positions",
    "abstract": "Comments: 5 pages plus extra one reference page, 1 figure, this work has been accepted in the IEEE Information Theory Workshop (ITW 2022), a conference of the IEEE Information Theory Society, Mumbai, India",
    "descriptor": "\nComments: 5 pages plus extra one reference page, 1 figure, this work has been accepted in the IEEE Information Theory Workshop (ITW 2022), a conference of the IEEE Information Theory Society, Mumbai, India\n",
    "authors": [
      "Haider Al Kim",
      "Kai Jie Chan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.06781"
  },
  {
    "id": "arXiv:2205.07674",
    "title": "Conditional Born machine for Monte Carlo event generation",
    "abstract": "Comments: 12 pages, 9 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 9 figures, 6 tables\n",
    "authors": [
      "Oriel Kiss",
      "Michele Grossi",
      "Enrique Kajomovitz",
      "Sofia Vallecorsa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2205.07674"
  },
  {
    "id": "arXiv:2205.09104",
    "title": "Coarsest-level improvements in multigrid for lattice QCD on large-scale  computers",
    "abstract": "Coarsest-level improvements in multigrid for lattice QCD on large-scale  computers",
    "descriptor": "",
    "authors": [
      "Jesus Espinoza-Valverde",
      "Andreas Frommer",
      "Gustavo Ramirez-Hidalgo",
      "Matthias Rottmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2205.09104"
  },
  {
    "id": "arXiv:2205.09404",
    "title": "Binary completely reachable automata",
    "abstract": "Comments: 13 pages, 4 figures. A conference version of this paper has been accepted for LATIN 2022. The present version incorporates many useful comments and suggestions by the anonymous reviewers of the conference version",
    "descriptor": "\nComments: 13 pages, 4 figures. A conference version of this paper has been accepted for LATIN 2022. The present version incorporates many useful comments and suggestions by the anonymous reviewers of the conference version\n",
    "authors": [
      "David Casas",
      "Mikhail V. Volkov"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.09404"
  },
  {
    "id": "arXiv:2205.09485",
    "title": "A Boosting Algorithm for Positive-Unlabeled Learning",
    "abstract": "Comments: 18 pages, 20 figures",
    "descriptor": "\nComments: 18 pages, 20 figures\n",
    "authors": [
      "Yawen Zhao",
      "Mingzhe Zhang",
      "Chenhao Zhang",
      "Weitong Chen",
      "Nan Ye",
      "Miao Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09485"
  },
  {
    "id": "arXiv:2205.10781",
    "title": "A Hierarchical MPC Approach to Car-Following via Linearly Constrained  Quadratic Programming",
    "abstract": "Comments: 6 pages, 7 figures",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Fangyu Wu",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.10781"
  },
  {
    "id": "arXiv:2205.12021",
    "title": "PatchNR: Learning from Small Data by Patch Normalizing Flow  Regularization",
    "abstract": "PatchNR: Learning from Small Data by Patch Normalizing Flow  Regularization",
    "descriptor": "",
    "authors": [
      "Fabian Altekr\u00fcger",
      "Alexander Denker",
      "Paul Hagemann",
      "Johannes Hertrich",
      "Peter Maass",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.12021"
  },
  {
    "id": "arXiv:2205.13094",
    "title": "Undersampling is a Minimax Optimal Robustness Intervention in  Nonparametric Classification",
    "abstract": "Undersampling is a Minimax Optimal Robustness Intervention in  Nonparametric Classification",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Saminul Haque",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13094"
  },
  {
    "id": "arXiv:2205.13863",
    "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of  Expressive Power",
    "abstract": "Why Robust Generalization in Deep Learning is Difficult: Perspective of  Expressive Power",
    "descriptor": "",
    "authors": [
      "Binghui Li",
      "Jikai Jin",
      "Han Zhong",
      "John E. Hopcroft",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13863"
  },
  {
    "id": "arXiv:2205.13888",
    "title": "Task-load-Aware Game-Theoretic Framework for Wireless Federated Learning",
    "abstract": "Task-load-Aware Game-Theoretic Framework for Wireless Federated Learning",
    "descriptor": "",
    "authors": [
      "Jiawei Liu",
      "Guopeng Zhang",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.13888"
  },
  {
    "id": "arXiv:2205.14100",
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "abstract": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "descriptor": "",
    "authors": [
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Xiaowei Hu",
      "Linjie Li",
      "Kevin Lin",
      "Zhe Gan",
      "Zicheng Liu",
      "Ce Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14100"
  },
  {
    "id": "arXiv:2205.15549",
    "title": "VC Theoretical Explanation of Double Descent",
    "abstract": "VC Theoretical Explanation of Double Descent",
    "descriptor": "",
    "authors": [
      "Eng Hock Lee",
      "Vladimir Cherkassky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15549"
  },
  {
    "id": "arXiv:2206.00227",
    "title": "Rethinking the Augmentation Module in Contrastive Learning: Learning  Hierarchical Augmentation Invariance with Expanded Views",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Junbo Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00227"
  },
  {
    "id": "arXiv:2206.00502",
    "title": "Fast generation of simple directed social network graphs with reciprocal  edges and high clustering",
    "abstract": "Comments: 6 pages, 1 figure",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Christoph Schweimer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00502"
  },
  {
    "id": "arXiv:2206.01160",
    "title": "DE-Net: Dynamic Text-guided Image Editing Adversarial Networks",
    "abstract": "DE-Net: Dynamic Text-guided Image Editing Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Ming Tao",
      "Bing-Kun Bao",
      "Hao Tang",
      "Fei Wu",
      "Longhui Wei",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.01160"
  },
  {
    "id": "arXiv:2206.02014",
    "title": "Actuarial Applications of Natural Language Processing Using  Transformers: Case Studies for Using Text Features in an Actuarial Context",
    "abstract": "Comments: 43 pages, 30 figures",
    "descriptor": "\nComments: 43 pages, 30 figures\n",
    "authors": [
      "Andreas Troxler",
      "J\u00fcrg Schelldorfer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02014"
  },
  {
    "id": "arXiv:2206.02050",
    "title": "Learning Speaker-specific Lip-to-Speech Generation",
    "abstract": "Comments: Accepted at ICPR 2022",
    "descriptor": "\nComments: Accepted at ICPR 2022\n",
    "authors": [
      "Munender Varshney",
      "Ravindra Yadav",
      "Vinay P. Namboodiri",
      "Rajesh M Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02050"
  },
  {
    "id": "arXiv:2206.02114",
    "title": "Speech Detection Task Against Asian Hate: BERT the Central, While  Data-Centric Studies the Crucial",
    "abstract": "Speech Detection Task Against Asian Hate: BERT the Central, While  Data-Centric Studies the Crucial",
    "descriptor": "",
    "authors": [
      "Xin Lian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02114"
  },
  {
    "id": "arXiv:2206.02256",
    "title": "Use-Case-Grounded Simulations for Explanation Evaluation",
    "abstract": "Use-Case-Grounded Simulations for Explanation Evaluation",
    "descriptor": "",
    "authors": [
      "Valerie Chen",
      "Nari Johnson",
      "Nicholay Topin",
      "Gregory Plumb",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02256"
  },
  {
    "id": "arXiv:2206.03031",
    "title": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
    "abstract": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
    "descriptor": "",
    "authors": [
      "Sharadhi Alape Suryanarayana",
      "David Sarne",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.03031"
  },
  {
    "id": "arXiv:2206.04434",
    "title": "Regret Analysis of Certainty Equivalence Policies in Continuous-Time  Linear-Quadratic Systems",
    "abstract": "Regret Analysis of Certainty Equivalence Policies in Continuous-Time  Linear-Quadratic Systems",
    "descriptor": "",
    "authors": [
      "Mohamad Kazem Shirani Faradonbeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04434"
  },
  {
    "id": "arXiv:2206.04635",
    "title": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "abstract": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "descriptor": "",
    "authors": [
      "Amir Hossein Fahim Raouf",
      "Chethan Kumar Anjinappa",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04635"
  },
  {
    "id": "arXiv:2206.05490",
    "title": "Discovery and density estimation of latent confounders in Bayesian  networks with evidence lower bound",
    "abstract": "Discovery and density estimation of latent confounders in Bayesian  networks with evidence lower bound",
    "descriptor": "",
    "authors": [
      "Kiattikun Chobtham",
      "Anthony C. Constantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05490"
  },
  {
    "id": "arXiv:2206.06053",
    "title": "KATKA: A KRAKEN-like tool with $k$ given at query time",
    "abstract": "KATKA: A KRAKEN-like tool with $k$ given at query time",
    "descriptor": "",
    "authors": [
      "Travis Gagie",
      "Sana Kashgouli",
      "Ben Langmead"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06053"
  },
  {
    "id": "arXiv:2206.07128",
    "title": "Stability of Image-Reconstruction Algorithms",
    "abstract": "Comments: 11 pages, 6 figures, 1 appendix",
    "descriptor": "\nComments: 11 pages, 6 figures, 1 appendix\n",
    "authors": [
      "Pol del Aguila Pla",
      "Sebastian Neumayer",
      "Michael Unser"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07128"
  },
  {
    "id": "arXiv:2206.07556",
    "title": "KE-QI: A Knowledge Enhanced Article Quality Identification Dataset",
    "abstract": "KE-QI: A Knowledge Enhanced Article Quality Identification Dataset",
    "descriptor": "",
    "authors": [
      "Chunhui Ai",
      "Derui Wang",
      "Xu Yan",
      "Yang Xu",
      "Wenrui Xie",
      "Ziqiang Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.07556"
  },
  {
    "id": "arXiv:2206.07908",
    "title": "Simultaneously Learning Stochastic and Adversarial Bandits with General  Graph Feedback",
    "abstract": "Comments: Published in ICML 2022",
    "descriptor": "\nComments: Published in ICML 2022\n",
    "authors": [
      "Fang Kong",
      "Yichi Zhou",
      "Shuai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07908"
  },
  {
    "id": "arXiv:2206.08621",
    "title": "A Graph-Enhanced Click Model for Web Search",
    "abstract": "Comments: 10 pages; Accepted by SIGIR 2021",
    "descriptor": "\nComments: 10 pages; Accepted by SIGIR 2021\n",
    "authors": [
      "Jianghao Lin",
      "Weiwen Liu",
      "Xinyi Dai",
      "Weinan Zhang",
      "Shuai Li",
      "Ruiming Tang",
      "Xiuqiang He",
      "Jianye Hao",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08621"
  },
  {
    "id": "arXiv:2206.09191",
    "title": "Gender Artifacts in Visual Datasets",
    "abstract": "Gender Artifacts in Visual Datasets",
    "descriptor": "",
    "authors": [
      "Nicole Meister",
      "Dora Zhao",
      "Angelina Wang",
      "Vikram V. Ramaswamy",
      "Ruth Fong",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09191"
  },
  {
    "id": "arXiv:2206.09244",
    "title": "GAN2X: Non-Lambertian Inverse Rendering of Image GANs",
    "abstract": "Comments: Accepted to 3DV 2022. The video demo is available at the project page: this https URL",
    "descriptor": "\nComments: Accepted to 3DV 2022. The video demo is available at the project page: this https URL\n",
    "authors": [
      "Xingang Pan",
      "Ayush Tewari",
      "Lingjie Liu",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09244"
  },
  {
    "id": "arXiv:2206.10093",
    "title": "DeePKS+ABACUS as a Bridge between Expensive Quantum Mechanical Models  and Machine Learning Potentials",
    "abstract": "DeePKS+ABACUS as a Bridge between Expensive Quantum Mechanical Models  and Machine Learning Potentials",
    "descriptor": "",
    "authors": [
      "Wenfei Li",
      "Qi Ou",
      "Yixiao Chen",
      "Yu Cao",
      "Renxi Liu",
      "Chunyi Zhang",
      "Daye Zheng",
      "Chun Cai",
      "Xifan Wu",
      "Han Wang",
      "Mohan Chen",
      "Linfeng Zhang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10093"
  },
  {
    "id": "arXiv:2206.10351",
    "title": "Novel total hip surgery robotic system based on self-localization and  optical measurement",
    "abstract": "Novel total hip surgery robotic system based on self-localization and  optical measurement",
    "descriptor": "",
    "authors": [
      "Weibo Ning",
      "Jiaqi Zhu",
      "Hongjiang Chen",
      "Weijun Zhou",
      "Shuxing He",
      "Yecheng Tan",
      "Qianrui Xu",
      "Ye Yuan",
      "Jun Hu",
      "Zhun Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10351"
  },
  {
    "id": "arXiv:2206.11834",
    "title": "Non-Determinism and the Lawlessness of Machine Learning Code",
    "abstract": "Comments: Proceedings of the 2022 Symposium on Computer Science and Law (CSLAW '22)",
    "descriptor": "\nComments: Proceedings of the 2022 Symposium on Computer Science and Law (CSLAW '22)\n",
    "authors": [
      "A. Feder Cooper",
      "Jonathan Frankle",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11834"
  },
  {
    "id": "arXiv:2206.12779",
    "title": "Evolutionary Preference Learning via Graph Nested GRU ODE for  Session-based Recommendation",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Jiayan Guo",
      "Peiyan Zhang",
      "Chaozhuo Li",
      "Xing Xie",
      "Yan Zhang",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.12779"
  },
  {
    "id": "arXiv:2206.13677",
    "title": "Towards Global-Scale Crowd+AI Techniques to Map and Assess Sidewalks for  People with Disabilities",
    "abstract": "Comments: CVPR 2022 AVA (Accessibility, Vision, and Autonomy Meet) Workshop",
    "descriptor": "\nComments: CVPR 2022 AVA (Accessibility, Vision, and Autonomy Meet) Workshop\n",
    "authors": [
      "Maryam Hosseini",
      "Mikey Saugstad",
      "Fabio Miranda",
      "Andres Sevtsuk",
      "Claudio T. Silva",
      "Jon E. Froehlich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13677"
  },
  {
    "id": "arXiv:2207.00208",
    "title": "e-CLIP: Large-Scale Vision-Language Representation Learning in  E-commerce",
    "abstract": "Comments: Accepted to CIKM 2022",
    "descriptor": "\nComments: Accepted to CIKM 2022\n",
    "authors": [
      "Wonyoung Shin",
      "Jonghun Park",
      "Taekang Woo",
      "Yongwoo Cho",
      "Kwangjin Oh",
      "Hwanjun Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00208"
  },
  {
    "id": "arXiv:2207.00741",
    "title": "A Distributionally Robust Resilience Enhancement Strategy for  Distribution Networks Considering Decision-Dependent Contingencies",
    "abstract": "A Distributionally Robust Resilience Enhancement Strategy for  Distribution Networks Considering Decision-Dependent Contingencies",
    "descriptor": "",
    "authors": [
      "Yujia Li",
      "Shunbo Lei",
      "Wei Sun",
      "Chenxi Hu",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.00741"
  },
  {
    "id": "arXiv:2207.00907",
    "title": "Emotion Analysis using Multi-Layered Networks for Graphical  Representation of Tweets",
    "abstract": "Emotion Analysis using Multi-Layered Networks for Graphical  Representation of Tweets",
    "descriptor": "",
    "authors": [
      "Anna Nguyen",
      "Antonio Longa",
      "Massimiliano Luca",
      "Joe Kaul",
      "Gabriel Lopez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.00907"
  },
  {
    "id": "arXiv:2207.01188",
    "title": "Learning to Rank with Small Set of Ground Truth Data",
    "abstract": "Comments: Master thesis at the University of Melbourne",
    "descriptor": "\nComments: Master thesis at the University of Melbourne\n",
    "authors": [
      "Jiashu Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.01188"
  },
  {
    "id": "arXiv:2207.01886",
    "title": "WeSinger 2: Fully Parallel Singing Voice Synthesis via Multi-Singer  Conditional Adversarial Training",
    "abstract": "Comments: correct citations",
    "descriptor": "\nComments: correct citations\n",
    "authors": [
      "Zewang Zhang",
      "Yibin Zheng",
      "Xinhui Li",
      "Li Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.01886"
  },
  {
    "id": "arXiv:2207.02173",
    "title": "DBN-Mix: Training Dual Branch Network Using Bilateral Mixup Augmentation  for Long-Tailed Visual Recognition",
    "abstract": "DBN-Mix: Training Dual Branch Network Using Bilateral Mixup Augmentation  for Long-Tailed Visual Recognition",
    "descriptor": "",
    "authors": [
      "Jae Soon Baik",
      "In Young Yoon",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02173"
  },
  {
    "id": "arXiv:2207.02552",
    "title": "A Construction of Type-II ZCCS of Arbitrary Sequence Length with Low  PMEPR",
    "abstract": "A Construction of Type-II ZCCS of Arbitrary Sequence Length with Low  PMEPR",
    "descriptor": "",
    "authors": [
      "Rajen Kumar",
      "Prashant Kumar Srivastava",
      "Sudhan Majhi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.02552"
  },
  {
    "id": "arXiv:2207.04994",
    "title": "Uncertainty-Aware Mixed-Variable Machine Learning for Materials Design",
    "abstract": "Uncertainty-Aware Mixed-Variable Machine Learning for Materials Design",
    "descriptor": "",
    "authors": [
      "Hengrui Zhang",
      "Wei Wayne Chen",
      "Akshay Iyer",
      "Daniel W. Apley",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04994"
  },
  {
    "id": "arXiv:2207.05514",
    "title": "A semi-supervised methodology for fishing activity detection using the  geometry behind the trajectory of multiple vessels",
    "abstract": "Comments: Ferreira, M.D.; Spadon, G.; Soares, A.; Matwin, S. A Semi-Supervised Methodology for Fishing Activity Detection Using the Geometry behind the Trajectory of Multiple Vessels. Sensors 2022, 22, 6063. this https URL",
    "descriptor": "\nComments: Ferreira, M.D.; Spadon, G.; Soares, A.; Matwin, S. A Semi-Supervised Methodology for Fishing Activity Detection Using the Geometry behind the Trajectory of Multiple Vessels. Sensors 2022, 22, 6063. this https URL\n",
    "authors": [
      "Martha Dais Ferreira",
      "Gabriel Spadon",
      "Amilcar Soares",
      "Stan Matwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05514"
  },
  {
    "id": "arXiv:2207.07241",
    "title": "Classification of Bark Beetle-Induced Forest Tree Mortality using Deep  Learning",
    "abstract": "Comments: Extended abstract submitted to VAIB Worskhop at ICPR 2022. 4 pages, 6 figures. The code and results are publicly available at this https URL",
    "descriptor": "\nComments: Extended abstract submitted to VAIB Worskhop at ICPR 2022. 4 pages, 6 figures. The code and results are publicly available at this https URL\n",
    "authors": [
      "Rudraksh Kapil",
      "Seyed Mojtaba Marvasti-Zadeh",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07241"
  },
  {
    "id": "arXiv:2207.07256",
    "title": "Improving Task-free Continual Learning by Distributionally Robust Memory  Evolution",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Zhenyi Wang",
      "Li Shen",
      "Le Fang",
      "Qiuling Suo",
      "Tiehang Duan",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07256"
  },
  {
    "id": "arXiv:2207.08003",
    "title": "SSMTL++: Revisiting Self-Supervised Multi-Task Learning for Video  Anomaly Detection",
    "abstract": "Comments: Under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: Under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Antonio Barbalau",
      "Radu Tudor Ionescu",
      "Mariana-Iuliana Georgescu",
      "Jacob Dueholm",
      "Bharathkumar Ramachandra",
      "Kamal Nasrollahi",
      "Fahad Shahbaz Khan",
      "Thomas B. Moeslund",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08003"
  },
  {
    "id": "arXiv:2207.08730",
    "title": "On stabilizing reinforcement learning without Lyapunov functions",
    "abstract": "On stabilizing reinforcement learning without Lyapunov functions",
    "descriptor": "",
    "authors": [
      "Pavel Osinenko",
      "Grigory Yaremenko",
      "Georgiy Malaniya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.08730"
  },
  {
    "id": "arXiv:2207.10003",
    "title": "BYEL : Bootstrap Your Emotion Latent",
    "abstract": "Comments: ECCVW 2022 Accepted",
    "descriptor": "\nComments: ECCVW 2022 Accepted\n",
    "authors": [
      "Hyungjun Lee",
      "Hwangyu Lim",
      "Sejoon Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10003"
  },
  {
    "id": "arXiv:2207.11734",
    "title": "Tighter Bound Estimation for Efficient Biquadratic Optimization Over  Unit Spheres",
    "abstract": "Comments: 26 pages, 6 figures",
    "descriptor": "\nComments: 26 pages, 6 figures\n",
    "authors": [
      "Shigui Li",
      "Linzhang Lu",
      "Xing Qiu",
      "Zhen Chen",
      "Delu Zeng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.11734"
  },
  {
    "id": "arXiv:2207.12534",
    "title": "Trainability Preserving Neural Structured Pruning",
    "abstract": "Comments: 18 pages, 4 figures, 5 tables",
    "descriptor": "\nComments: 18 pages, 4 figures, 5 tables\n",
    "authors": [
      "Huan Wang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.12534"
  },
  {
    "id": "arXiv:2207.13162",
    "title": "Retrieval-Augmented Transformer for Image Captioning",
    "abstract": "Comments: CBMI 2022",
    "descriptor": "\nComments: CBMI 2022\n",
    "authors": [
      "Sara Sarto",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.13162"
  },
  {
    "id": "arXiv:2207.14382",
    "title": "Large Language Models and the Reverse Turing Test",
    "abstract": "Comments: The parable of the talking dog",
    "descriptor": "\nComments: The parable of the talking dog\n",
    "authors": [
      "Terrence Sejnowski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14382"
  },
  {
    "id": "arXiv:2207.14499",
    "title": "Class-Difficulty Based Methods for Long-Tailed Visual Recognition",
    "abstract": "Comments: Published in IJCV. Paper URL: this https URL",
    "descriptor": "\nComments: Published in IJCV. Paper URL: this https URL\n",
    "authors": [
      "Saptarshi Sinha",
      "Hiroki Ohashi",
      "Katsuyuki Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.14499"
  },
  {
    "id": "arXiv:2207.14682",
    "title": "Towards Unconstrained Audio Splicing Detection and Localization with  Neural Networks",
    "abstract": "Comments: Accepted at MMFORWILD 2022, ICPR Workshops - Code: this https URL",
    "descriptor": "\nComments: Accepted at MMFORWILD 2022, ICPR Workshops - Code: this https URL\n",
    "authors": [
      "Denise Moussa",
      "Germans Hirsch",
      "Christian Riess"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.14682"
  },
  {
    "id": "arXiv:2208.01123",
    "title": "Energy-Efficient Backscatter-Assisted Coded Cooperative-NOMA for B5G  Wireless Communications",
    "abstract": "Comments: 30, 7",
    "descriptor": "\nComments: 30, 7\n",
    "authors": [
      "Muhammad Asif",
      "Asim Ihsan",
      "Wali Ullah Khan",
      "Ali Ranjha",
      "Shengli Zhang",
      "Sissi Xiaoxiao Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.01123"
  },
  {
    "id": "arXiv:2208.01138",
    "title": "Generalized Singleton Type Upper Bounds",
    "abstract": "Comments: 35 pages, the list size L=1 case of arXiv:2109.02818, some old papers were included in the references",
    "descriptor": "\nComments: 35 pages, the list size L=1 case of arXiv:2109.02818, some old papers were included in the references\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.01138"
  },
  {
    "id": "arXiv:2208.02178",
    "title": "KD-SCFNet: Towards More Accurate and Efficient Salient Object Detection  via Knowledge Distillation",
    "abstract": "Comments: The paper has a fatal description error",
    "descriptor": "\nComments: The paper has a fatal description error\n",
    "authors": [
      "Jin Zhang",
      "Qiuwei Liang",
      "Yanjiao Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.02178"
  },
  {
    "id": "arXiv:2208.02400",
    "title": "Evolutionary bagging for ensemble learning",
    "abstract": "Evolutionary bagging for ensemble learning",
    "descriptor": "",
    "authors": [
      "Giang Ngo",
      "Rodney Beard",
      "Rohitash Chandra"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.02400"
  },
  {
    "id": "arXiv:2208.02447",
    "title": "DL-DRL: A double-layer deep reinforcement learning approach for  large-scale task scheduling of multi-UAV",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Xiao Mao",
      "Guohua Wu",
      "Mingfeng Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.02447"
  },
  {
    "id": "arXiv:2208.03288",
    "title": "Convolutional Ensembling based Few-Shot Defect Detection Technique",
    "abstract": "Comments: 7 pages, 7 images",
    "descriptor": "\nComments: 7 pages, 7 images\n",
    "authors": [
      "Soumyajit Karmakar",
      "Abeer Banerjee",
      "Prashant Sadashiv Gidde",
      "Sumeet Saurav",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.03288"
  },
  {
    "id": "arXiv:2208.03298",
    "title": "Quantifying and Mitigating Popularity Bias in Conversational Recommender  Systems",
    "abstract": "Comments: to appear in CIKM22",
    "descriptor": "\nComments: to appear in CIKM22\n",
    "authors": [
      "Allen Lin",
      "Jianling Wang",
      "Ziwei Zhu",
      "James Caverlee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.03298"
  },
  {
    "id": "arXiv:2208.03325",
    "title": "Isoform Function Prediction Using Deep Neural Network",
    "abstract": "Comments: It needs a final review from co-authors",
    "descriptor": "\nComments: It needs a final review from co-authors\n",
    "authors": [
      "Sara Ghazanfari",
      "Ali Rasteh",
      "Seyed Abolfazl Motahari",
      "Mahdieh Soleymani Baghshah"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03325"
  },
  {
    "id": "arXiv:2208.03486",
    "title": "HaloAE: An HaloNet based Local Transformer Auto-Encoder for Anomaly  Detection and Localization",
    "abstract": "Comments: 21 pages, 6 figures, rejected to ECCV 2023",
    "descriptor": "\nComments: 21 pages, 6 figures, rejected to ECCV 2023\n",
    "authors": [
      "E. Mathian",
      "H. Liu",
      "L. Fernandez-Cuesta",
      "D. Samaras",
      "M. Foll",
      "L. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.03486"
  },
  {
    "id": "arXiv:2208.03646",
    "title": "A Length Adaptive Algorithm-Hardware Co-design of Transformer on FPGA  Through Sparse Attention and Dynamic Pipelining",
    "abstract": "Comments: 2022 59th ACM/IEEE Design Automation Conference (DAC)",
    "descriptor": "\nComments: 2022 59th ACM/IEEE Design Automation Conference (DAC)\n",
    "authors": [
      "Hongwu Peng",
      "Shaoyi Huang",
      "Shiyang Chen",
      "Bingbing Li",
      "Tong Geng",
      "Ang Li",
      "Weiwen Jiang",
      "Wujie Wen",
      "Jinbo Bi",
      "Hang Liu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.03646"
  },
  {
    "id": "arXiv:2208.03854",
    "title": "Towards Fair Conversational Recommender Systems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2208.03298",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.03298\n",
    "authors": [
      "Allen Lin",
      "Ziwei Zhu",
      "Jianling Wang",
      "James Caverlee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.03854"
  },
  {
    "id": "arXiv:2208.06032",
    "title": "CORNET: A neurosymbolic approach to learning conditional table  formatting rules by example",
    "abstract": "CORNET: A neurosymbolic approach to learning conditional table  formatting rules by example",
    "descriptor": "",
    "authors": [
      "Mukul Singh",
      "Jos\u00e9 Cambronero",
      "Sumit Gulwani",
      "Vu Le",
      "Carina Negreanu",
      "Mohammad Raza",
      "Gust Verbruggen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.06032"
  },
  {
    "id": "arXiv:2208.06150",
    "title": "Pre-training Tasks for User Intent Detection and Embedding Retrieval in  E-commerce Search",
    "abstract": "Comments: 5 pages, 3 figures; accepted by CIKM2022",
    "descriptor": "\nComments: 5 pages, 3 figures; accepted by CIKM2022\n",
    "authors": [
      "Yiming Qiu",
      "Chenyu Zhao",
      "Han Zhang",
      "Jingwei Zhuo",
      "Tianhao Li",
      "Xiaowei Zhang",
      "Songlin Wang",
      "Sulong Xu",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.06150"
  },
  {
    "id": "arXiv:2208.06155",
    "title": "What Features Influence Impact Feel? A Study of Impact Feedback in  Action Games",
    "abstract": "Comments: Accepted by The IEEE CTSoc International Conference on Games Entertainment & Media 2022 (GEM 2022)",
    "descriptor": "\nComments: Accepted by The IEEE CTSoc International Conference on Games Entertainment & Media 2022 (GEM 2022)\n",
    "authors": [
      "Zhonghao Lin",
      "Haihan Duan",
      "Zikai Alex Wen",
      "Wei Cai"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.06155"
  },
  {
    "id": "arXiv:2208.06187",
    "title": "Stabilizer quantum codes defined by trace-depending polynomials",
    "abstract": "Stabilizer quantum codes defined by trace-depending polynomials",
    "descriptor": "",
    "authors": [
      "Carlos Galindo",
      "Fernando Hernando",
      "Helena Mart\u00edn-Cruz",
      "Diego Ruano"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.06187"
  },
  {
    "id": "arXiv:2208.06348",
    "title": "An Empirical Exploration of Cross-domain Alignment between Language and  Electroencephalogram",
    "abstract": "An Empirical Exploration of Cross-domain Alignment between Language and  Electroencephalogram",
    "descriptor": "",
    "authors": [
      "William Han",
      "Jielin Qiu",
      "Jiacheng Zhu",
      "Mengdi Xu",
      "Douglas Weber",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06348"
  },
  {
    "id": "arXiv:2208.06551",
    "title": "ExpansionNet v2: Block Static Expansion in fast end to end training for  Image Captioning",
    "abstract": "ExpansionNet v2: Block Static Expansion in fast end to end training for  Image Captioning",
    "descriptor": "",
    "authors": [
      "Jia Cheng Hu",
      "Roberto Cavicchioli",
      "Alessandro Capotondi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06551"
  },
  {
    "id": "arXiv:2208.06876",
    "title": "Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces",
    "abstract": "Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces",
    "descriptor": "",
    "authors": [
      "Li Fan",
      "Jianchang Liu",
      "Wenle Zhang",
      "Peng Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.06876"
  },
  {
    "id": "arXiv:2208.06879",
    "title": "Who Finds the Short Proof? An Exploration of Variants of Boolos' Curious  Inference using Higher-order Automated Theorem Provers",
    "abstract": "Comments: 12 pages, 7 appendices (data and proofs)",
    "descriptor": "\nComments: 12 pages, 7 appendices (data and proofs)\n",
    "authors": [
      "Christoph Benzm\u00fcller",
      "David Fuenmayor",
      "Alexander Steen",
      "Geoff Sutcliffe"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2208.06879"
  },
  {
    "id": "arXiv:2208.06947",
    "title": "Towards Spatio-Temporal Cross-Platform Graph Embedding Fusion for Urban  Traffic Flow Prediction",
    "abstract": "Comments: 5 pages, UrbComp 2022",
    "descriptor": "\nComments: 5 pages, UrbComp 2022\n",
    "authors": [
      "Mahan Tabatabaie",
      "James Maniscalco",
      "Connor Lynch",
      "Suining He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.06947"
  },
  {
    "id": "arXiv:2208.06980",
    "title": "Faster Attention Is What You Need: A Fast Self-Attention Neural Network  Backbone Architecture for the Edge via Double-Condensing Attention Condensers",
    "abstract": "Faster Attention Is What You Need: A Fast Self-Attention Neural Network  Backbone Architecture for the Edge via Double-Condensing Attention Condensers",
    "descriptor": "",
    "authors": [
      "Alexander Wong",
      "Mohammad Javad Shafiee",
      "Saad Abbasi",
      "Saeejith Nair",
      "Mahmoud Famouri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.06980"
  },
  {
    "id": "arXiv:2208.07009",
    "title": "Copula-based analysis of the generalized friendship paradox in clustered  networks",
    "abstract": "Comments: 8 pages, 3 figures. arXiv admin note: text overlap with arXiv:2107.05838",
    "descriptor": "\nComments: 8 pages, 3 figures. arXiv admin note: text overlap with arXiv:2107.05838\n",
    "authors": [
      "Hang-Hyun Jo",
      "Eun Lee",
      "Young-Ho Eom"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07009"
  },
  {
    "id": "arXiv:2208.07059",
    "title": "UPST-NeRF: Universal Photorealistic Style Transfer of Neural Radiance  Fields for 3D Scene",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2205.12183 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.12183 by other authors\n",
    "authors": [
      "Yaosen Chen",
      "Qi Yuan",
      "Zhiqiang Li",
      "Yuegen Liu",
      "Wei Wang",
      "Chaoping Xie",
      "Xuming Wen",
      "Qien Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07059"
  },
  {
    "id": "arXiv:2208.07109",
    "title": "Context-aware Mixture-of-Experts for Unbiased Scene Graph Generation",
    "abstract": "Context-aware Mixture-of-Experts for Unbiased Scene Graph Generation",
    "descriptor": "",
    "authors": [
      "Liguang Zhou",
      "Yuhongze Zhou",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07109"
  },
  {
    "id": "arXiv:2208.07677",
    "title": "FedMR: Fedreated Learning via Model Recombination",
    "abstract": "FedMR: Fedreated Learning via Model Recombination",
    "descriptor": "",
    "authors": [
      "Ming Hu",
      "Zhihao Yue",
      "Zhiwei Ling",
      "Xian Wei",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07677"
  },
  {
    "id": "arXiv:2208.07734",
    "title": "Role of Data Augmentation in Unsupervised Anomaly Detection",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Jaemin Yoo",
      "Tiancheng Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07734"
  },
  {
    "id": "arXiv:2208.08236",
    "title": "DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular  Simulation",
    "abstract": "DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular  Simulation",
    "descriptor": "",
    "authors": [
      "Duo Zhang",
      "Hangrui Bi",
      "Fu-Zhi Dai",
      "Wanrun Jiang",
      "Linfeng Zhang",
      "Han Wang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.08236"
  },
  {
    "id": "arXiv:2208.08315",
    "title": "Video-TransUNet: Temporally Blended Vision Transformer for CT VFSS  Instance Segmentation",
    "abstract": "Comments: Accepted by International Conference on Machine Vision 2022",
    "descriptor": "\nComments: Accepted by International Conference on Machine Vision 2022\n",
    "authors": [
      "Chengxi Zeng",
      "Xinyu Yang",
      "Majid Mirmehdi",
      "Alberto M Gambaruto",
      "Tilo Burghardt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08315"
  },
  {
    "id": "arXiv:2208.08340",
    "title": "Class-Aware Visual Prompt Tuning for Vision-Language Pre-Trained Model",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yinghui Xing",
      "Qirui Wu",
      "De Cheng",
      "Shizhou Zhang",
      "Guoqiang Liang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08340"
  },
  {
    "id": "arXiv:2208.08768",
    "title": "TSCom-Net: Coarse-to-Fine 3D Textured Shape Completion Network",
    "abstract": "Comments: Accepted in European Conference on Computer Vision Workshop (ECCVW) 2022",
    "descriptor": "\nComments: Accepted in European Conference on Computer Vision Workshop (ECCVW) 2022\n",
    "authors": [
      "Ahmet Serdar Karadeniz",
      "Sk Aziz Ali",
      "Anis Kacem",
      "Elona Dupont",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08768"
  },
  {
    "id": "arXiv:2208.08789",
    "title": "Towards Label-efficient Automatic Diagnosis and Analysis: A  Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,  Semi-supervised and Self-supervised Techniques in Histopathological Image  Analysis",
    "abstract": "Comments: Comprehensive survey for Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis (total of 212 references)",
    "descriptor": "\nComments: Comprehensive survey for Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis (total of 212 references)\n",
    "authors": [
      "Linhao Qu",
      "Siyu Liu",
      "Xiaoyu Liu",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08789"
  },
  {
    "id": "arXiv:2208.08807",
    "title": "COPE: End-to-end trainable Constant Runtime Object Pose Estimation",
    "abstract": "COPE: End-to-end trainable Constant Runtime Object Pose Estimation",
    "descriptor": "",
    "authors": [
      "Stefan Thalhammer",
      "Timothy Patten",
      "Markus Vincze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08807"
  },
  {
    "id": "arXiv:2208.08871",
    "title": "Network inference via process motifs for lagged correlation in linear  stochastic processes",
    "abstract": "Comments: 28 pages, 17 figures",
    "descriptor": "\nComments: 28 pages, 17 figures\n",
    "authors": [
      "Alice C. Schwarze",
      "Sara M. Ichinaga",
      "Bingni W. Brunton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.08871"
  },
  {
    "id": "arXiv:2208.08873",
    "title": "Robust Artificial Delay based Impedance Control of Robotic Manipulators  with Uncertain Dynamics",
    "abstract": "Robust Artificial Delay based Impedance Control of Robotic Manipulators  with Uncertain Dynamics",
    "descriptor": "",
    "authors": [
      "Udayan Banerjee",
      "Bhabani Shankar Dey",
      "Indra Narayan Kar",
      "Subir Kumar Saha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08873"
  },
  {
    "id": "arXiv:2208.08982",
    "title": "Quality issues in Machine Learning Software Systems",
    "abstract": "Comments: Accepted as a registered report by ICSME 2022",
    "descriptor": "\nComments: Accepted as a registered report by ICSME 2022\n",
    "authors": [
      "Pierre-Olivier C\u00f4t\u00e9",
      "Amin Nikanjam",
      "Rached Bouchoucha",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08982"
  },
  {
    "id": "arXiv:2208.09292",
    "title": "UnCommonSense: Informative Negative Knowledge about Everyday Concepts",
    "abstract": "UnCommonSense: Informative Negative Knowledge about Everyday Concepts",
    "descriptor": "",
    "authors": [
      "Hiba Arnaout",
      "Simon Razniewski",
      "Gerhard Weikum",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09292"
  },
  {
    "id": "arXiv:2208.09406",
    "title": "Dance Style Transfer with Cross-modal Transformer",
    "abstract": "Dance Style Transfer with Cross-modal Transformer",
    "descriptor": "",
    "authors": [
      "Wenjie Yin",
      "Hang Yin",
      "Kim Baraka",
      "Danica Kragic",
      "M\u00e5rten Bj\u00f6rkman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.09406"
  },
  {
    "id": "arXiv:2208.09411",
    "title": "Wildfire Forecasting with Satellite Images and Deep Generative Model",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2002.09219 by other authors",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2002.09219 by other authors\n",
    "authors": [
      "Thai-Nam Hoang",
      "Sang Truong",
      "Chris Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09411"
  }
]